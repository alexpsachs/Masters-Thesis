{
    "mbostock": "Very exciting! I'll look at this shortly.\n. Looks good! Included in v0.2.0.\n. Looks good to me. Integrated into 0.27.1.\n. Looks good! Thanks for the fix.\n. OK, on closer inspection that's really ugly. :) I was hoping we could maybe simplify a bit\u2026 and preferably not have conditionals inside the d3_array routine.\nOne thing that may help is that d3_array is actually used in two places: 1 to convert an arguments into an array, and 2 to convert a NodeList into an array. We could easily use different routines for these conversions if required on different browsers. Ideally, what I'd like to see is something like this:\n```\nvar d3_arrayArguments = d3_arrayPush, // conversion for arguments\n    d3_arrayNodes = d3_arraySlice; // conversion for NodeLists\nfunction d3_arraySlow(psuedoarray) {\n  var i = -1, n = psuedoarray.length, array = [];\n  while (++i < n) array.push(psuedoarray[i]);\n  return array;\n}\nfunction d3_arrayPush(psuedoarray) {\n  var array = [];\n  array.push.apply(array, psuedoarray);\n  return array;\n}\nfunction d3_arraySlice(psuedoarray) {\n  return Array.prototype.slice.call(psuedoarray);\n}\ntry {\n  d3_arrayNodes(document.getElementsByTagName(\"html\"));\n} catch(e) {\n  d3_arrayNodes = d3_arraySlow;\n}\ntry {\n  (function() {\n    d3_arrayArguments(arguments);\n  })();\n} catch(e) {\n  d3_arrayArguments = d3_arraySlow;\n}\n```\nAlthough, I'm not sure whether we should default both to using slice (if that's faster), or whether we should fallback first to push and then to slow.\n. Re. d3_ease, yeah. That's a case of d3_arrayArguments. Although, in that case we're also shaving off the first argument, passing the remaining optional arguments to the easing function. That way, you can call d3.ease(\"poly\", 2), which is equivalent to saying d3_ease.poly(2). The reason that factory is there is so we can apply the \"-in\", \"-out\", \"-in-out\", and \"-out-in\" modifiers to arbitrary easy functions.\nI think this case is simple enough that we could avoid d3_array altogether, and just support a fixed number of additional arguments. Something like:\nd3.ease = function(name, a, b) {\n  var i = name.indexOf(\"-\"),\n      t = i >= 0 ? name.substring(0, i) : name,\n      m = i >= 0 ? name.substring(i + 1) : \"in\";\n  return d3_ease_mode[m](d3_ease[t].call(null, a, b));\n};\n. Do you know if IE is barfing on NodeList conversion or arguments conversion?\n. Using document.documentElement.childNodes instead of document.getElementsByTagName(\"html\") seems smart. Sounds like we only need the fallback for d3_arrayNodes, then!\nI'm wondering if it's worth trying d3_arrayPush, for nodes? It might be nice if that works, but there's also a limit to the number of arguments you can pass to a function in JavaScript. I believe the limit is a few thousand; not sure if we'll have that many nodes in a selection, but it might be better to just fallback to d3_arraySlow if slice doesn't work.\n. Yeah, probably just get rid of d3_arrayArguments and just change d3_call. I think you can rewrite it to avoid the slice altogether:\nfunction d3_call(callback, var_args) {\n  var f = callback;\n  var_args[0] = this;\n  f.apply(this, var_args);\n  return this;\n}\n. OK, I updated d3_call in 1.0.1. So I'll pull your code and do the merge! Looks great.\n. Do you have any thoughts on how projections should handle locations outside of their normal bounds? For example, if I chose the North Pole perspective, I probably don't want to see Antarctica at all; currently Antarctica fills the circle.\nSimilarly, is there a clever way to deal with nonlinear distortion caused by the projection? We have the same problem with the Albers projection today, but only if you zoom out and try to show more of the world. For small viewports, it's fine because it's conformal. But if we wanted to show the whole world with Albers, then continuing to use polygons to represent shapes doesn't work very well\u2014straight lines become elliptical arcs:\nhttp://en.wikipedia.org/wiki/File:World-albers.png\n. I've implemented the Sutherland-Hodgman clipping algorithm in d3.geom.polygon; of course, that's designed for polygon-polygon clipping whereas in this case you want to clip polygons against a circle.\nBut, as you say, maybe it's not even necessary to do clipping manually\u2014we can use SVG to clip against arbitrary paths (including circles).\nYou're right that we can replace \"lineto\" with elliptical arcs in SVG fairly easily, although it would complicate d3.geo.path and/or the projection API a bit, since currently we assume everything stays a polygon across projection. But it would be freaking cool if we could get these types of projections working; I imagine they make all those nice SVG images on Wikipedia in desktop GIS applications, and if we get it working in D3 we can make them interactive. :)\n. I took another look at this, so that we now support both stereographic and orthographic azimuthal projections! I'd still like to figure out clipping, but I think only on a point-basis. Doing the conversion to arcs and fancy stuff like that is too much logic, at least for now.\n. Hmm. The other thing I would consider would be modifying the domain method to force conversion to numbers:\nx0 = +x[0];\nx1 = +x[1];\nThe + is a short and fast JavaScript hack to convert any object to its numeric value. That way we avoid implicitly re-converting the dates to numbers every time we apply the scale.\nThe next question is whether the scale should then be type-aware, i.e., even if it stores x0 and x1 as numbers internally, it could still represent the domain as other objects, assuming those objects have a valueOf method defined that converts them to a primitive number. The problem is, even if we can convert those objects to numbers, we can't necessarily convert numbers back into objects without knowing their type. I suppose it's reasonable to special-case Date since it is so common, but I feel like, if we open the door, it would be nice if it were generalizable to other types as well. Not sure how to make that happen without specifying something like a reverse-interpolator or constructor/factory method.\nLet me think about this for a bit and get back to you. Coercing to numbers seems safe.\n. Also, thanks for submitting a pull request! :) I appreciate the contribution.\n. Closing this out, as scales have supported Date objects in the domain (where they are converted to numbers) since @723a53187460b8a960c24c204c27395c48f92145. It'd still be nice to have proper ticks for dates; that is tracked in #44.\n. Thanks! Fixed in 1.6.1.\nI like the idea of testing both minified and unminified code. I could see testing unminified during the development cycle and then minified as part of the merge, say.\n. Now in 1.6.1. We should probably file a bug with Google for that arguments over-optimization.\n. Looks good. There's probably a clever way to structure the regular expression so as to disambiguate commas versus newlines more immediately, but this implementation is perfectly sufficient.\n. Also, I noticed there's a slight bug where we won't detect \\r or \\r\\n properly after a quoted value, because of L39:\nif (text.charCodeAt(i + 1) == 10) eol = true;\nPerhaps we need a separate regular expression for line separators?\n. Ah, nice. I like the fix. I'll pull it in shortly!\n. Looks good. Integrated in 1.8.1.\n. Looks good. (That file is copied from the master branch, btw.) Integrated in 1.8.1.\n. Good idea! Will integrate soon.\n. This is great, ya. We'll probably want a little more description as to when you'd use some of the methods, but starting with a simple description of what the method does is a big help.\n. Sounds like you're on the right track! This looks good.\n. Excellent, thank you!\n. Some quick feedback, since I don't have time this morning to give it justice. This looks great!\nI would call this a \"chart\" rather than a \"layout\". The layouts in D3 (unlike Protovis) are representation-independent. That is, they create helper data structures that can then be used to control the layout of graphical elements. For example, the force layout creates node objects with x and y fields; these objects are then used to position svg:circle elements or whatever representation is desired to display them. Similarly the other layouts create (or modify, in the case of stack) data structures rather than directly rendering anything.\nSo, I propose we create a new chart module for D3, and put this in d3.chart.js.\nI like the API using call and embedding the chart widget inside an svg:g.\nI think you can make the chart implementation more flexible by using functions for the data, rather than passing in constants. In fact, what I would do as the simplest implementation would be to depend on data that is bound to the containing svg:g element. A data structure like this would work well:\n{\n  \"ranges\": [2.1e6, 2.85e6, 4e6],\n  \"measures\": [2.3e6, 3.01e6],\n  \"markers\": [1.15e6, 3.0e6]\n}\nThen, inside bullet.js, you'd initialize your private variables a bit differently:\nranges = function(d) { return d.ranges; },\nmeasures = function(d) { return d.measures; },\nmarkers = function(d) { return d.markers; },\nBut, note that your code later on, when you call the data operator, stays the same!\nOK, I'm glossing over a bit. There's actually a tricky part where you want to evaluate the ranges/measures/markers ahead of time, so you can compute the rangeColor/measureColor/scale etc. But ideally we figure out a way to do this so that the bullet chart works automatically for small multiples. What I'd like to see is if I call a bullet chart on a selection with multiple svg:g elements (each with their own data structure already bound, as above), the chart implementation correctly generates small multiples. But note that you'll want the scale to be consistent across the multiples, so some gymnastics is needed to pull out the data from the this selection and do initialization!\nLet me know if this makes sense / doesn't make sense. If I get some time later, I can help hack!\nCheers,\nMike\n. Ah yes, that's the other thing. Transitions should be totally doable by re-selecting existing elements within the svg:g, rather than assuming it's empty. Can't look now but will look again later! Ciao.\n. Yeah, if you want to avoid transitions on enter you can split the code into enter + update. For example:\n```\nvar range = chart.selectAll('rect.range')\n    .data(ranges);\nrange.enter().append('svg:rect')\n    .attr('class', 'range')\n    .attr('width', scale)\n    .attr('height', height)\n    .style('fill', function(d, i) { return rangeColor(i); });\nrange.transition()\n    .attr('width', scale)\n    .attr('height', height)\n    .style('fill', function(d, i) { return rangeColor(i); });\n```\nNow there's a bit of code duplication, which you could avoid by a call to a function that sets width + height + fill. And actually in this case the range colors can't change, so you don't technically need to update them (though it might be a good idea to allow configurable colors in the future).\nThe other issue is that the number of ranges could change, so you might want to exit().remove()? You could define special transitions for enter and exit as well, if you wanted to fancy!\n. Wow. Just looked at bullet-multiples.html! AWESOME!\n. OK, I took a pass at it. Mainly, I cleaned up the transitions so there's object constancy for ticks, and we deal correctly with changing scales (entering objects should be initialized with the old x-scale, then transition to the new scale as they fade in).\nI restructured the code a bit. That wasn't really intentional---sorry if that makes the merge difficult. I'm open to ideas on how to reduce the code duplication between enter + update + exit, but I often find that there is always slightly different operators needed for these three phases, so refactoring into a reusable function doesn't help much.\nAnyway, take a look. The transitions are slick!\nhttps://github.com/mbostock/d3/commit/1b1a9485cb8204c0dc3eb5576479884271832136\nIf you want, pull from my 'bullet' branch, and then keep hacking. Then we can pull this into the master branch when you're ready.\nOne related question: should we track this under the same master version number? In which case any non-backwards-compatible change to the chart API requires bumping the major version number? Or should we have a separate version number for separate libraries? I have a feeling the latter fragmentation will be confusing. Probably we should be conservative about backwards-incompatible changes and use a single version number.\n. Re. the \"type\" attribute, and single vs. double quotes, and conventions for naming functions: I'm quite OCD about all this stuff. I am sure you are right that my way is not necessarily the best way. :) But I do think consistency is important for readability, so I try to make everything look the same. It's difficult to force someone to conform precisely to my (pedantic) style, so I'm happy to do little style tweaks if you don't mind the merge overhead!\nI would say re. function naming that using\nfunction foo() { \u2026 }\nis a bit more flexible than\nvar foo = function() { \u2026 };\nmainly because the former is hoisted: it can be called before it's defined in the code. Whereas in the latter, the function itself is anonymous, and is not bound to the var foo until the line on which is defined.\n. I'm thinking of leaving the title and subtitle out of the chart implementation. It should be easy enough to plug that in after adding the chart type, and since the text is static I don't see a strong value in baking it into the chart. Plus, this way it avoids the hard-coded \"translate(120)\", allowing more flexibility in how the titles are displayed. Does that sound reasonable?\n. Ah, there's a design problem here. We can't throw away the bullet chart instance because it is stateful\u2014it's caching the old scale, x0. So if we throw the bullet chart away, then we lose the old scale and can't compute the transitions appropriately. Either we need to squirrel away the old scale on the outer svg:g node (which is icky), or we should change the bullet-multiples example to cache chart instances rather than recreating them on each transition.\n. You can see the bug in the transitions more easily with the ticks. It helps to slow down the duration, say to 5000 ms. For example, the first time you click \"Randomize!\" you'll see the new ticks for 900, 800, 700 and 600 appear at x=0, because the domain on x0 is reset to [0, \u221e]. Similarly, if a new measure is added, I'd strongly prefer it being positioned initially using the old scale, even if that is out-of-bounds.\nI've hacked it locally by binding the vis to an array of d3.chart.bullet instances rather than an array of orientations.\n. Yeah. I'm going to simplify the example a bit. It's nice that you can derive chart instances from data, but it will be much more common to just hard-code a particular orientation. Since people will likely use this as an example to derive their own visualizations it'll be good if we can keep it \"dumb\". Should have a commit incoming soon.\n. Another interesting issue here is that sometimes you want the same scale across bullet charts, and other times you don't! In the initial data that we're using (in bullets.js) for example, each chart shows a different dimension, so there's no reason to force them to use the same scale. Probably this should be a flag on the chart instance, or perhaps we restore the ability to set the x-domain.\n. Alright, I feel like this might be good to go? What do you think? Should we push the chart state into the element data, or keep it as-is? I made a feeble attempt at pushing it into the element data, but it was a bit more difficult than I expected; in some ways, maybe leaving it as chart state is more flexible?\n. Let me know if you've changed your mind after sleeping on it. Otherwise, I'll push to master.\nAnd ya, lots of fun. :) Looking forward to subsequent chart templates!\n. OK, I updated the implementation to use g.each internally. I like doing this inside the chart implementation so that the chart can decide whether to use call or each. I removed computation of a shared scale across multiples.\nThe old scale is now stashed in a __chart__ field on the containing node. This is a bit of a hack but it seems like a reasonable place to hide old chart state solely for transitions. You're right that we could create nodes to store this information explicitly, even as data- attributes to serialize the state into the DOM! But it also seems reasonable to hide the state on the DOM and consider it semi-private state of the chart.\nPotentially, the __chart__ field could be used for cross-type transitions, too. For example, you could replace a bar chart with a line chart and the bar chart would know the line chart's old scale. If we go that route, it'd be good to document the API of the __chart__ field more formally, but for now we could consider it \"package private\" (in Java terminology).\n. Also: I decided not to add enter to select.\nI think it's best if the entering and exiting selection are limited to the data operator. There it's symmetric and it's more obvious that you need to apply the data operator in order to define the entering and exiting selection. And, that ties the definition of the entering and exiting selection more closely to the relational join between nodes and data.\nAnother reason select can't support the entering selection is that the selectAll operator currently determines the parent node for subsequent appends and inserts (group.parentNode). I'd have to change the implementation of entering selections to support append or insert into arbitrary nodes. That wouldn't be too hard, but it feels like the code is resisting this new feature so I think it's best to leave it out, at least for now.\n. Good work! I refactored the bullet example for the website. Let me know if you want to make any additional changes!\n. Ya, I wouldn't worry too much about supporting transitions between orientations\u2014that's going to be much less common than data updates. How will you handle text if you use a rotate transform?\n. Closing, but thanks for the quick fix. :)\n. Historical note: the join function was originally specified as two functions: one that was run on the nodes, and one that was run on the data. This made the join much more explicit, but also more tedious to specify. My fix works because this refers to the current element when the join function is evaluated on existing elements, while this refers to the data array when the join function is evaluated on data; in the later case, this.textContent is undefined.\nPerhaps the data operator could take three arguments, something like:\n.data(data, format, function() { return this.textContent; })\nthat way, the explicit join function run on the nodes is still optional, but there's no confusing variation in the value of this. The old way was this:\n.data(data, {\n  dataKey: format,\n  nodeKey: function() { return this.textContent; }\n})\nThe relevant commit is f8ae20d.\n. OK, I hacked on it some more, tried to make the code more readable and added a radial example. What do you think?\n. Can you elaborate on this: \"I didn't follow the interpolate suggestion because a scale can only have one interpolate function.\" Why would you need more than one interpolation function?\n. Rename clamped to clamp, and I'll merge. If you do that, it will look good to me!\n. OK, I made some simplifications in the pack branch.\n. I think I'll replace flare.json with a symlink, but otherwise, this looks great! I'll bundle your changes together into the next minor release (1.11) to minimize version creep.\n. I've added B\u00e9zier links as @MoritzStefaner did for MACE. Possibly, this could be a separate helper method, similar to d3.svg.chord. Maybe \"chordLine\" or \"radialParentPath\"? I can't think of a good name. It feels radial- and hierarchy-specific because it's a link between parent and child in polar coordinates.\n. \u2026 in the cluster branch.\n. Yeah, d3.svg.curve might be a nice name. The problem is you can't specify it in Cartesian coordinates\u2014you really need to specify it in polar coordinates. Equivalently, you can specify the start and end in Cartesian coordinates, but then you also need to specify the center of the circle to compute the tangents.\n. Or a related note, maybe we need radial scales to simplify the conversion from polar to Cartesian coordinates.\n. Yeah. I put the control points midway: http://jsfiddle.net/mbostock/EVnvj/\n. I like the idea of a projection. I think I'd change it to behave more like d3.svg.line, so the edge object would be a function that takes a two coordinates and returns a path string. Something like:\nvar path = d3.svg.diagonal()\n    .projection(function(p) {\n      var a = (p[0] - 90) / 180 * Math.PI;\n      return [p[1] * Math.cos(a), p[1] * Math.sin(a)];\n    });\nAnd later on:\n.attr(\"d\", function(d) { return diagonal(d.parent, d.child); })\nAlthough, maybe taking a single argument is a bit more flexible. You could either expect an array with two elements (source, target) or source & target accessors. That might look like this:\n.attr(\"d\", function(d) { return diagonal([d.parent, d.child]); })\nOr this:\nvar path = d3.svg.diagonal()\n    .source(function(d) { return d.parent; })\n    .target(function(d) { return d.child; })\n    .projection(function(p) {\n      var a = (p[0] - 90) / 180 * Math.PI;\n      return [p[1] * Math.cos(a), p[1] * Math.sin(a)];\n    });\nAnd:\n.attr(\"d\", diagonal)\nThat feels like overkill to me, though. I feel like this is a whole lot of machinery for something that's very simple. The only complexity is that there are two coordinate spaces to deal with: the coordinate space in which we interpolate the start and end point (polar, here) and the coordinate space of the resulting path coordinates (Cartesian).\nFor example, I could have a helper like this:\nfunction diagonal(from, to) {\n  var m = (from[1] + to[1]) / 2;\n  return [from, [from[0], m], [to[0], m], to];\n}\nThen, do something like this:\nvar p0 = [0, 50], p1 = [45, 150];\ndiagonal(p0, p1).map(projection);\nHmm.\n. FYI, I made some changes in my cluster branch.\n. Looks bueno.\n. I'm pretty torn by this pull request. I appreciate the usefulness of creating text nodes, but I'm not sure it fits well into the D3 paradigm. I see two problems:\n1. Text nodes are not elements, so the selection breaks down.\nYou can see this not just in the creation of the nodes, but in the implementation of the text operator. Furthermore, most of the other operators are broken on text nodes: attr, style, transition, select, selectAll, append, insert, classed, html, on, etc. I could see having a different selection implementation for text nodes (similar to d3_selectionEnter) where we only support a subset of operators on text nodes, and can cleanly plug in an alternate implementation for the text operator. But, it still seems somewhat fraught with inconsistency.\n2. You cannot reselect #text nodes after creating them.\nThis seems the bigger problem, to me. You can't select text nodes with the W3C Selectors API (or CSS)! You can only select elements. The recommended way of selecting text is to use the span element.\nI'm tempted to require span elements. Would that be a bad thing?\n. OK, closing. Thanks for the work! At least we resolved the design issue. :)\n. Another thought: perhaps the whiskers function returns the lower and upper indices into the data array. For example, the default implementation would be [0, length - 1]. That way, anything below the lower index would be displayed as an outlier (a dot), as with anything above the upper index.\n. Eh, I would probably just draw a circle and not allow it to be configured. I don't think there's a strong need to add a categorical encoding on outlier symbol type, and we could always add it in the future if needed.\nA couple questions:\n1. Rename to d3.chart.box?\n2. Should the dashed line only extend from the first to last whisker? Right now it's extending from the minimum to maximum value, which looks different than the Wikipedia example.\n. I made a number of improvements in my box branch. Check it out and tell me what you think?\nI originally created the branch to explore using call to reduce some of the duplicate function declarations. I decided in the end that it made the code a bit more difficult to read, so I left it as-is. However, I then decided to tackle some of the tricker issues with transitions, especially in light of the dynamic way in which whiskers and outliers are specified!\n. Also, I'll say again: Great work! :) I'm really excited about the potential for these reusable chart templates.\n. Oops, yes! Thanks for the fix.\n. This looks good. I'll do a bit of testing and integrate soon. Thanks a bunch for the contribution!\n. Heh, cool! Thanks for all the pull requests! Keep 'em comin!\nI'd probably put this in a separate example folder. Ya, they both use lines, but the current line example is for line charts, and a spline or spline-editor example would be a better place for this.\nAlso, the transitions really highlight D3's lack of built-in smart path interpolation. I'd recommend disabling the transitions for now, because in most cases they don't make sense\u2014there are a different number of numbers in the paths strings depending on the interpolation method, so you can't just naively interpolate each number. Rapha\u00ebl does better path interpolation, but it's not perfect either. At any rate, I don't think implementing better automatic path transitions should hold up this example, but perhaps it'd be something nice to play with in the future!\nThere's some graphics research in shape interpolation, which is the 3D version of this problem.\n. I renamed this to flush rather than immediate to give it more of a verby name, and separated the implementation\u2014the d3_timer_step code is very much an inner loop for all transitions, so I don't want to risk any overhead for this rare case. It's in commit @1893d286e70e0ee1b35e50eafa49a55c7ef2ecae.\nI have an outstanding question, though: should charts flush the timer queue? Or should the user do it after calling one or more charts? I guess if flushing the queue is idempotent and cheap, there's no risk of sprinkling a few calls inside the charts as standard practice, and users can always do it safely in addition in their own code, if they do other transitions\u2026 It seems like requiring users to do it would be somewhat painful.\n. Removed t0 in @1c70462de5b0aced98cc and @995ab7e64b2f1c6d7c04.\n. I love it, especially in parallel! I love this example, too: http://www.jasondavies.com/sorting/\n. This looks reasonable, but I'm not sure that the layout module is the right place for it\u2026 It feels more like a stats or math or data utility? I need to think about how to organize this sort of code into modules.\n. I gave it a bit more thought, and layout seems like a reasonable place to put this. But yeah, I could also imagine a stats package.\n. OK, I'm thinking of adding a d3.search now that I've seen it in three places (histogram, polylinear scales, quantile scales). The Python bisect methods are a useful reference, since they support optional lo and hi arguments:\nhttp://docs.python.org/library/bisect.html\n. OK, implemented in @6ba3097766e39ab68cb3d04e4c8b81b6f51a29c5. Looks like we should have another release soon!\n. Yay, thanks for this!\n. Nice! I could imagine another variant of monotone interpolation that flips x & y, but this seems like a reasonable starting point. I'll take a look soon.\n. I added basis-open and cardinal-open interpolate in commits @d1c406f43c2acb2bc5187db1a3a72f156b45df88 @a0d4d0bd8e49a48f6fd55809c9df02e310f796f0. It's useful if you want to control the tangents manually (for example, to color a segmented cardinal or basis spline). Any thoughts?\n. Cool, will merge this shortly!\n. This doesn't work in Chrome (not sure about WebKit). className.toString() returns \"[object SVGAnimatedString]\". Also assigning className = \"foo\" doesn't work; you need to assign className.baseVal = \"foo\".\n. I think if classList exists, it's reasonable to assume that it's the right type, so we could say if (this.classList). Also, that way you can reduce the code slightly, e.g.,\nif (c = this.classList) return c.contains(name);\nI was worried an in check might be necessary if baseVal could be set to null. But that doesn't appear to be a concern so I actually like your original, simpler check better. :) Sorry for leading you astray.\nThis looks good!\n. \u00a1Excellente!\n. This change isn't backwards-compatible. :\\\nIt seems arbitrary (and confusing) that Object.keys has different behavior from for in\u2014shouldn't they have named it Object.ownKeys? The recommended approach seems to assume to a particular use case for prototypal inheritance: that all prototype attributes are inherited methods, and own properties are fields. As you've surely noticed, I don't use the standard prototype in D3 or Polymaps, because closures are required for private state, though I have occasionally used Object.create for object inheritance.\nSince we can't rely on the existence of Object.keys, and d3.keys isn't a performance bottleneck, it's probably best to be conservative and leave d3.keys as-is. If someone wants to use Object.keys instead, they're welcome to do so and they can rely on its unusual behavior regarding the prototype. We could add a comment to d3.keys as a reminder.\n. I'm going to pull this in so that we have a test for keys, but I'm not going to change the implementation. :)\n. OK, let's go with standard prototypes!\n. Also, wow, Object.create is slow: http://jsperf.com/structs-vs-objects/3\n. Hooray! Really happy to see this feature returning. Thanks for the flood of pull requests!\n. I took a pass at refactoring this to reduce some code, and also avoid the binary search in common case of a \"bilinear\" scale. Also, this opens the door for invert working on non-numeric ranges in the future\u2026 I'm pretty jazzed about this approach. What do you think? See commit @e67e7d7d8b9a8b0d3e0c27cafae5bf1fd8028274.\n. Hooray! This looks like a reasonable solution. The data is bound to the node permanently, but the index is transient and only valid in the context of a selection.\n. That's correct; I was thinking data(null) would unbind the data (delete node.__data__) and not compute any join. I don't see this feature as being commonly-used, but potentially handy if someone wants to delete data to free up memory.\nThe other case of retrieving data() is interesting. For the other operators, when they are called as a getter, they return the value on the first non-null node. For example, calling attr(\"name\") returns the value of the \"name\" attribute for the first non-null node (which is typically the first node).\nThe data operator, though, is a bit special. Unlike the other operators, it gets evaluated per group rather than per node: it returns an array of elements for the group, rather than the specific data element for an individual node. This is needed in order to compute the join between the array of data elements and nodes. For symmetry, probably the right thing then is to return the array of data elements for the first group? And importantly, the index of the data array should match the index of each element\u2014so if the node is null, then there should be an undefined entry in the corresponding slot in the data array.\nOf course, one of the reasons I hemmed and hawed about adding this feature is that I wasn't sure about the use case. The use case for retrieving the value of an attribute or style is pretty obvious\u2014you select a single node and then you can use D3 to inspect it more easily than saying node.getAttributeNS(\u2026) or window.getComputedStyle(\u2026)\u2026. I'm not totally sure of what the right use case is for inspecting data. It could either be select an array of nodes and return the associated array of data, or select a single node and return that element's data. But the latter case is asymmetric with the operator, and also not that much more convenient than saying node.__data__.\nAny thoughts on how these new operators might be used?\n. A variant of this is now in v2.8.0. Long time comin'!\n. This is looking great. I like the stuff you've added to the stats module. I'm also wondering about some simpler stuff that could be considered \"stats\", such as: mean (average), mode, median, min, max, sum, variance, deviation. I guess if we consider Python's built-in functions as precedent, then we could keep min, max and sum as globals on d3, with mean, mode, median, variance, deviation etc. on d3.stats.\n. Remaining tasks on this pull request:\n- Break out d3.sum to a separate request for inclusion to core.\n- Make above requested changes to sum (accessor, NaN-handling).\n- Remove dependency from d3.chart -> d3.stats.\n- Code review for d3.stats package.\nI fixed the implementation of d3.scale.quantile not long ago. I still wonder whether we should have duplication between d3.scale and d3.stats, but it's probably okay.\n. d3.sum was added in 1.22.0!\nFor the rest, I think it makes sense to start a new library. I see stats as being very useful in conjunction with D3, but the stats methods themselves probably won't have any dependencies on the d3.core module. I'd be happy to link to your library on GitHub and include it in the lib/ directory if you want to use it in any D3 examples. I think there are a ton of people that would be interested in rich statistics (as in R) within JavaScript. Maybe you could even collaborate on atoll.js if you like the looks of it.\nI'll leave this pull request open, as I'd like to include the kde example. If you move the stats code into lib/stats (or whatever name you desire), and add a license of your choosing, this should be good to go.\n. Nice work. Looks good.\n. Yeah, and what if you want to handle multi-touch? I could imagine a d3.svg.touches(container) method that returns an array of x-y coordinates for each current touch.\nAnd that implementation could reuse code for mapping local x-y to screen x-y. The general API would let you pass in an object with pageX, pageY, clientX and clientY properties, maybe? Or maybe we just leave that private for now, and reuse it in both mouse and touches?\n. Oh, I think using d3_array is totally fine, I was just wondering why it was necessary\u2014there's no performance issue here (never going to be more than a few touches). I'd go with whatever makes smaller code.\n. Neat! Looking forward to trying this on my iPhone.\nFor zoom, I'd say double-tap should zoom to the next integer zoom level, if there is such a concept\u2014there is in slippy maps. So, if we're currently at zoom level z, then zoom to floor(z) + 1. And ya, I'd also support two-finger pinch for zooming in and out, while panning simultaneously. Take a look at how it's implemented in Polymaps:\nhttps://github.com/simplegeo/polymaps/blob/master/src/Touch.js\n. There appears to be a small bug in this implementation: when I'm zooming with two fingers, when I stop zooming there's a tendency to jump (pan). I suspect that this is because when I release my two fingers, there is a brief interval where I only have one finger down, and this gets interpreted as a pan event.\n. I like the work you've done here, but I'm tempted to leave the examples as-is for the sake of simplicity. It'd be great to build more multitouch examples designed specifically for the iPad / iPhone, though, especially if we can make them simple enough that they perform well.\n. Closing this to keep the examples simpler. If you still feel inspired perhaps we could create another multitouch example (specific to iOS) in the touch folder? It is great that we have touch support for the zoom behavior though!\n. Wow, speedy delivery! :D With tests even!\nI was hoping that there was a way of rounding a number to significant digits without using exponent notation, but I guess there isn't (in Python). So, if I have 341,230 and I want 3 significant digits, I get 341,000. But on closer read it looks like you're doing the correct thing with g, so\u2026 hrm.\nI'll review this soon. Thanks much!\n. Yep, if we want to continue to pull inspiration from Python, we could implement d3.round:\nhttp://docs.python.org/library/functions.html#round\n. OK, implemented @01fdc1d93d4725c5d57666958e26a2309f2d6ba3.\n. And since d3.round isn't that useful by itself, I also added new r and p format types in @85a6feec66a0120f9c403b4a2dda79beae3bdc76.\n. I made a number of improvements in @a15165398d8633d0eeb929cade77c0557def0479. Looks good to me. Any additional work before I release? I'm tempted to work on transitions for changing the number of bands, but it's not urgent. :)\n. I added transitioning for bands, which looks awesome. :) I fudged it a little bit\u2014technically, I need to store the number of bands that were previously shown, rather than assuming we're only off by one. But close enough!\n. Merging this in now. For the sake of simplicity, I opted to only support single-touch in the force layout. Multi-touch is nice, but it's complicated to track all the touches. I'm starting out conservatively, and we can always add multi-touch in the future.\nSomewhat influencing my decision is that the force-directed layout examples don't work all that well on the iPhone/iPad to begin with: rendering is slow, and the touches are often misinterpreted as scrolling the window.\nMore generally, I think it's best to keep our touch examples separate from the rest. This avoids additional complexity\u2014I want the examples to be as simple as possible so that people can learn from them easily. Also, making something work on iOS with interactivity is never \"free\"; one must design the page to fit appropriately in the iPhone's viewport, make larger touch targets, and do all sorts of other things while considering the specifics of the platform. The existing multi-touch example demonstrates this principle.\n. Thanks! Yeah, I think we could either preventDefault on the entire background of the chart area, or make the nodes larger, or use the meta viewport to fit the page to the native screen resolution.\n. Wow, great work! Really excited to see more reusable charts!\n. These are somewhat related to Sankey diagrams. I wonder if there's an opportunity for reuse there; we'll know when we build a Sankey chart template, maybe. Here's a couple examples:\nhttp://aspoireland.files.wordpress.com/2011/05/global-energy-conversion-to-economic-services1.png\nhttp://vadim.ogievetsky.com/projects/sankey/sankey.html\nThe latter shows how to use the monotone interpolator, too, which might obviate the need for explicit x-padding (not sure about that, though). Similarly, we might be able to obviate the need for y-padding by just using a thick white stroke around the paths. Together that would simplify the API nicely.\n. Closing chart-related pull requests, since we have new plans for building chart templates in a separate project. \n. Released in 1.18.0!\n. According to http://docs.python.org/library/functions.html#zip, \"The returned list is truncated in length to the length of the shortest argument sequence. \u2026 With a single sequence argument, it returns a list of 1-tuples. With no arguments, it returns an empty list.\"\nAlso, this generates an error: d3.zip([1, 2, 3, 4, 5], [2, 4, 6, 8, 10]). I'll check this out and make some fixes. :)\n. It's okay. Sometimes I'm so tired in the morning that I pour my coffee beans into the toaster rather than the grinder.\n. Does UglifyJS do this for us automatically? Otherwise, looks fine.\n. Yay, thanks! I added a check for null (and undefined), too.\n. Impressive! Do you have an example in mind to demonstrate interpolation? Also, what about moving this to d3.geom? I think it's probably worth keeping the default build small, although it would be nice for lazily-loaded modules to register extensions of d3.interpolate automatically.\n. Hmm, good point. d3.geom.matrix.determinant is a bit long, and plus matrix math isn't really geometry, so d3.geom might not be the best place. Maybe put everything in a new d3.vector module? So, d3.vector.determinant, d3.vector.cross, etc. I mean, you could call the module d3.matrix, but the Wikipedia describes linear algebra as the mathematics of vector spaces. :)\n. Yeah, don't do that. :) d3.core should not have an explicit dependency on d3.vector. I was thinking something like dependency injection/late binding. For example, we could have a registry of d3.interpolators. These are applied in reverse order by d3.interpolate, and the first one that returns non-null is used as the default interpolator. For example:\nd3.interpolators = [\n  d3.interpolateObject,\n  function(a, b) { return b instanceof Array && d3.interpolateArray(a, b); },\n  function(a, b) { return typeof b === \"string\" && d3.interpolateString(\"\"+a, b); },\n  function(a, b) { return b in d3_rgb_names || /^(#|rgb\\(|hsl\\()/.test(b) && d3.interpolateString(\"\"+a, b); },\n  function(a, b) { return typeof b === \"number\" && d3.interpolateNumber(+a, b); }\n];\nThen you could push d3.interpolateMatrix with a similar conditional onto the end of the list, so it takes priority of the less specific interpolators. (Alternatively, we could reverse the list of interpolators, but then you'd need to use unshift to push the more specific interpolator onto the front.)\n. Nice, looks great!\n. FYI, I extracted the interpolators registry and cherry picked it into release 1.20.0. I'm waiting on the new d3.vector module until we have an example that shows how to use it. Sound fair?\n. This is kind of amazing. It feels a shame to close this pull request, but I agree that the use case for this is fairly rare and I don't think we've come up with a great example for it yet. I'm being pretty ruthless about closing stalled pull requests, but we can always reopen this in the future if we change our minds. \n. Nice work. I agree the current behavior is confusing and I'll review your fix!\n. I'd rather require that the keys are unique than define order-dependent behavior for non-unique keys.\n. Awesome. You beat me to it! Was going to be my weekend project. ;) Next on the list is a reusable Sankey chart & a reusable Parallel Coordinates chart.\n. Wow. The transitions are beautiful! Great job!\n. Closing chart-related pull requests, since we have new plans for building chart templates in a separate project. \n. Woot, great idea. I've wanted this for a while! This will be useful in all our charts. I think we can figure out a way to include either ticks or background lines, maybe as a simple mode switch, since those seem like the most common options that are used everywhere.\n. Subsumed by radar pull request.\n. You might like this example by @biovisualize: http://bl.ocks.org/1020902\n. I decided not to pull this in, for the sake of keeping the code size small. But thank you for submitting anyway! And feel free to link your heart example from the wiki.\n. Nice fix on the axis bug\u2014I noticed that, too, but I haven't investigated yet. This would also have been fixed by #167, but I think it's clearer to have unique keys. The subdivision of ticks was sort of a hack so I could play with ggplot2-style ticks. Not sure whether I'll keep that always turned on.\nNice work on the the radar chart too. It looks great! I'll figure out the merges. It's hard to keep up with you!\n. Whoah, that's neat. I don't think you need #142 for polar interpolation (though if you find it's a cleaner way to do it, then go for it), because you can access the data from a custom tween like we do for the donut chart animation. The tricky part that's still to-do with the polar transition is to get the old axis to collapse onto the x-axis, and the new axes to come out of the x-axis.\nAlso, there's the problem that the axes could be reordered! That's easy enough to do with the axes, but it's a bit tricky with the path since you'd need to swap the path control points at the exact instant that the axes crossover\u2026 I guess that's not so hard if you have a unified tween, but it'll be a bit tricky. Hopefully if we get it right we can apply the same technique to transitioning parallel coordinates, and blow people's minds. :)\nI'm still thinking about the reusable axis. I love the idea, but I'm not sure we have the API correct yet. For example, in the radar chart I'd like to see ticks on each of the axes, though I'd only want to see labels on the x-axis. It seems like it wouldn't be hard for the radar chart to apply a rotate transform to the axis output after \"rubber stamping\" a few of them. I was also thinking it'd be nice to distinguish the production of ticks from the production of reference lines; this is what I was originally thinking with the \"mode\" flag, so maybe I should restore that, or maybe there should be a boolean for turning the reference lines on or off. And, I also think the major/minor grid lines (don't need minor ticks) should be another toggle, so we don't always generate minor grid lines unless we want ggplot2 style. So, perhaps then the \"mode\" parameter could be a \"lines\" parameter, which accepts the value \"none\", \"major\", or \"minor\". The latter would subdivide the ticks and produce 2x the number of lines. And perhaps we'd label them with the \"major line\" and \"minor line\" classes so they're easier to style appropriately.\nOK, and then one last thought\u2026 Using an Archimedean spiral segment for the radar chart would be cool. :) Essentially, it's linear interpolation (a straight line) in polar coordinates. Then we could draw circles though the ticks on each axis for better reference lines. Vadim wrote some code to do this in Protovis that I've been meaning to port to D3 if I can remember where it is. But we can certainly punt on this for now.\nBreakfast now.\nCiao,\nMike\n. Spent a good chunk of time hacking on this today, but it's still a work in progress. I'm excited about more reusable chart components, but I haven't figured out a clean way of integrating them while still offering sufficient flexibility. The previous approach of having separate, \"monolithic\" chart templates was simpler from an interface and perhaps maintenance perspective, although it resulted in more duplicate code and less flexibility. The new modular chart components should ultimately make it easier for us to develop new chart templates, while allow the user greater flexibility in assembling charts. So I'm excited about it but there are still some design challenges to solve. :)\n. Also, another thing to keep in mind will be different types of axes\u2014particularly ordinal and quantitative. The current component handles quantitative well, and you can plug in different scales, but it wouldn't handle ordinal. Also, scales like dates might need different behavior, for example labeling sections of the axis (November, December) rather than discrete points (1, 2). Avoiding duplication with the existing scales would be nice.\nLastly, if we can't figure out a good way to encapsulate the axes, a more conservative approach might be a private class that's used by the different chart templates. This way, we can reuse code but we don't have to tackle the design issues immediately. Although, it'd still be nice if people could reuse the axis component in custom charts.\n. Vadim actually wrote some pretty awesome code to render \"radial\" paths (expressed as a sequence of [radius, angle] points) as Archimedean spiral segments, automatically creating piecewise cubic B\u00e9ziers. I've currently lost my copy of it, but I should be able to find it again. Anyway, future work. :)\n. Added some thoughts on axis design here:\nhttps://github.com/mbostock/d3/wiki/Axes\nI think the next step would be to implement such a component that works reliably. (For example, enabling or disabling minor/major grid lines across the transition complicates the implementation\u2014but still totally doable.) Then we can adopt it from the chart templates.\n. Just thought of another complication: layering. Updated the Axes design document. Perhaps we need both d3.chart.axis and d3.chart.grid as separate components so we can control layering.\n. You mean, have an axis component, but allow the user to insert their content between the different groups of content generated by the axis component? That might work.\n. Yeah, I haven't decided yet. It is tempting to require the specification of axes separately, to avoid duplication, and to separate responsibilities from the other charts\u2014otherwise there's a lot of redundant specification going on. But what I haven't figured out yet, as you've discussed, is how to coordinate the scales between charts and axes. We also need to coordinate transitions so they have the same duration. Perhaps you still create axes explicitly, but you register them with a parent chart so as to coordinate scales and transitions. I dunno. \n. Closing chart-related pull requests, since we have new plans for building chart templates in a separate project. \n. This is a remarkably intuitive refactoring. I like it! The next question is, how might one customize the category symbols, colors, and sizes of the scatterplot symbols? Probably it's best to expose these as functions on the scatter chart. Although, it's also possible for the user to select elements that are created by the scatter chart and restyle them.\n. Heh, those transitions are awesome. Try adding this as the delay to the three transitions:\njavascript\n.delay(function(d, i) { return x1(d) * 5; })\n. Yeah, I'm not sure. We'll have to try it and see. It seems like some things are doable by post-processing, but other things (such as the transition delay, the tick counts, etc.) are better done as configuration options of the chart component. I'd like to spend some time today working on the reusable axis & grid components, and see how it feels.\n. Closing chart-related pull requests, since we have new plans for building chart templates in a separate project. \n. Awesome, thanks for implementing this! I think we'll want pow.nice, too, but I assume that can be done by rebinding the linear scale's method.\nOne thing to improve will be the nice behavior for polylinear scales. The current implementation checks if the domain has more than two values, but then immediately sets the domain to have two values; this won't play nice with the range. I think it'd be reasonable to set the first ([0]th) and last value of the domain, rather than hard-coding the creation of a two-element domain. This way, you can still use polylinear scales with nice, and it only affects the minimum and maximum value and nothing in-between.\n. Looks good! Thank you.\n. Fantastic! I'd like to restructure this a bit as d3.svg.superformula, so that people can customize the various parameters. I'm imagining something like\njavascript\nvar star = d3.svg.superformula()\n    .param(\"m\", 5)\n    .param(\"n1\", 30)\n    .param(\"n2\", 100)\n    .param(\"n3\", 100)\n    .param(\"a\", 1)\n    .param(\"b\", 1);\nI'd still like to support some of the built-in shapes, as you've done. So, you might say something like\njavascript\nvar star = d3.svg.superformula()\n    .type(\"star\")\n    .param(\"b\", 1.1);\nto override one of the star's parameters. It might also be useful to override thetaSteps, though the tweening behavior would be undesirable if thetaSteps changed across transitions. (You could always use the higher of the two values during the transition, then swap to the end value when the transition completes, though.)\n. I took a crack at it here, so you can see what I'm thinking:\nhttps://github.com/mbostock/d3/tree/superformula\nYou should be able to sync to your branch like this, assuming you have a remote named \"upstream\" pointing at my repository:\ngit fetch upstream\ngit merge upstream/superformula\nI'll merge in those new symbols you added now.\n. Thanks. :) Do you think the rotation parameter is necessary? We can also say attr(\"transform\", \"rotate(90)\") on the path element, which seems a bit more flexible and simplifies the implementation.\n. Hooray, integrated into master as of release 1.20.1. Thank you!\n. See related discussions in #55 and #65. The key comment: \"That suggests we could support taking a map for attr, style and on\u2014and defer supporting a function that returns a map until a future release (if at all).\"\nSo, yeah. I'm onboard with this pull request, and I'd be happy to include it in the next release. I think we should extend this syntax to style and on. Technically, it'd also be good to return a map if these methods are called with no arguments, but we could potentially defer that to a future release, along with the function form (for generating the map dynamically per element).\n. > I interpreted the \"function form\" you both mentioned as passing in anonymous functions as values in the map, but delaying their execution until mapped to data. That should be the current behavior. Is this correct?\nNo, the inverse of that, which is \"a function that returns a map\". For example:\njavascript\n    .attr(function() { return {rand: Math.random()}; })\nIt's possible to support both, though I'm a little worried about the complexity and performance. But being similar to jQuery is also valuable. I'll take a look at your implementation and see if I have any suggestions. Thanks!\n. Nice work! I think it's probably overkill to support functions that contain functions, although I appreciate your attention to detail and desire to support consistent behavior. We started with two types of input:\n1- A constant, such as 42.\n2- A function, such as function(d) { return d * 2; }.\nInitially, I was thinking of adding two more types, in the single-argument form of attr:\n3- A constant map, such as {cx: 42}.\n4- A function that returns a constant map, such as function(d) { return {cx: d * 2}; }.\nThis latter form should be sufficient for the single-argument form, where you might even want to control dynamically which attributes you specify. Now, I agree there are other possible forms:\n- A map that contains functions, such as {cx: function(d) { return d * 2; }}.\n- A function that returns a map that contains functions.\nWhile these might be expected, for consistency's sake, they don't seem particularly useful given that they can always be expressed by the fourth form above. For the sake of keeping the implementation small and fast, I'd prefer to support as few forms as possible. I'm normally in favor of strict parsimony, so for me the fourth form is the really convincing use case, as it's the one that lets you alter which attributes you specify as a function of data.\n. Yep, if you say attr({cx: null}), it should delete the \"cx\" attribute, as if you said attr(\"cx\", null).\nIf it's simpler to support a map that contains functions, then I say go for it. :) I'll take a look.\n. Assuming we have a method attrs(map), here's how it might work. First, define a method that handles the evaluation and application of the map function:\njavascript\nfunction attrMapFunction() {\n  var x = map.apply(this, arguments), name, value;\n  for (name in x) {\n    value = x[name];\n    name = d3.ns.qualify(name);\n    value == null\n        ? (name.local ? this.removeAttributeNS(name.space, name.local) : this.removeAttribute(name))\n        : (name.local ? this.setAttribute(name, value) : this.setAttributeNS(name.space, name.local, value));\n  }\n}\nThen, use a typeof check to branch evaluation for constants or functions:\njavascript\nif (typeof map === \"function\") {\n  groups.each(attrMapFunction);\n} else for (var name in map) {\n  groups.attr(name, map[name]);\n}\nreturn groups;\nI think that's pretty small and fast. What do you think?\n. Oh, it might be cool if calling selection.attrs() returned a map of the defined attributes (mapping namespaces back to prefixes to match the input format)\u2026 More work, though. :)\n. My implementation branch is available in the map branch, with the main commit being @5603474872ac2cd9abe38b0eceac5e679b5a9080. I haven't tested the performance implications of this change, but it should be negligible. \nI decided not to implement the mode where attr() returns a map of all defined attributes. I think it's possible, though a cursory investigation suggested that support for inspecting the list of defined attributes is spotty (however, in browsers that support SVG I suspect it's doable). Moreover, inspecting all attributes at once doesn't seem like an immediate requirement, so I think it's best to punt on that for now and keep the code small.\nIf you're happy with my implementation, we could work on extending it to style, classed, property and on. In the case of style, we should still allow the priority to be specified, but it would affect all of the entries in the map. We'd also need to support map-style input for transitions: attr, attrTween, style and styleTween. So, while this appears to be a fairly innocuous overloading of one of the operators it's actually a fairly extensive change to the core API. :) Seems like a good change, though!\n. Not yet. There's a lot more work to do to implement proper map support, including other operators. I've merged master into my map branch if you want to keep hacking on it.\n. Yep. And probably a bunch of refactoring to avoid code duplication between the map and non-map based methods.\n. Merged into #277.\n. You can do this using call:\njavascript\nvis.selectAll(\"g.arc\")\n    .data(arcs(data0, data1))\n  .enter()\n    .call(function() { console.log(\"Data: \", this); })\n  .append(\"svg:path\")\n    .attr(\"d\", arc)\n    .call(function() { console.log(\"End of chain: \", this); })\n. I discovered that you get a major performance boost in interactivity if you use style rather than attr to set the fill color, and you don't use a tooltip. In section.js:\njavascript\nfunction refresh() {\n  svg.selectAll(\"g\").selectAll(\"rect\")\n    .data(cross(b))\n    .style(\"fill\", color);\n}\n. Thanks for sharing, @jrus.\n. I'm cleaning up some stalled pulled requests. I like the idea of optional CIE or Lab colorspace support you can pull in, but that could either be a d3.lab module (d3.lab.js?) or chromatist. Also I agree with @jrus that we could have better examples of how these colorspaces are used. Perhaps, for example, generating random categorical color scales with maximally-distinguishable colors?\n. I haven't decided yet if this qualifies as a backwards-compatible change. This is very much core functionality! On the other hand, none of the existing examples required any changes, so the impact should be minimal. The worst case is that redundant operations are performed on entering nodes.\n. I think the current behavior with exit is sufficient; the exit selection isn't part of the update selection, and if you remove the exit selection, it stays out of the update selection. So really it's just a question of whether to merge enter into update.\n. This was integrated into the axis branch, and will be part of the 2.0 release.\n. Cool! I updated the example to color the Voronoi cells by area.\nMy thoughts regarding esoteric / experimental stuff: we should put them in the examples directory, as I did with the superformula. This way, we keep the core library small, and we can make non-backwards compatible changes without bumping the major version number. After it matures for a bit, we can decide to promote it into the core library or a new module, and then we'll start officially tracking it with semantic versioning. This allows us to experiment to our heart's content, and it makes a clear distinction to our users as to what's officially supported and what's experimental.\n. Yeah, that'd be best. Thank you!\n. +1\n. @lynaghk beat you to it by about 50 minutes in pull request #193. Thanks, though! :)\n. Looks great!\n. Nice work, and thank you for this! But maybe we're going about this the wrong way? I do like @strongh's commit 7cbb78219e7ccfb63a6a52eab0d98b03a5744f61, which adds support for x0 and x1, such that you can change the orientation of the area. (You can also do this by apply a \"rotate(90)\" transform, but it seems cleaner to support x0 and x1.)\nI think we should add x0 and x1, but perhaps we should also add convenience methods for setting both to have the same value:\n``` javascript\narea.x = function(x) {\n  if (!arguments.length) return x1;\n  x0 = x1 = x;\n  return area;\n};\narea.y = function(y) {\n  if (!arguments.length) return y1;\n  y0 = y1 = y;\n  return area;\n};\n```\nThe really nice thing about this is that you could define all four (x0, x1, y0, y1) and do a radial area, as in Flickr Flow!\nPerhaps then, we'd want to do an identity check to see if x0 === x1 or y0 === y1, and if so, reuse the previously-computed value rather than evaluating the accessor again.\n. We could also add a d3.svg.area.radial, which would have radius, innerRadius, outerRadius, angle, startAngle and endAngle in place of x, x0, x1, y, y0 and y1 \u2026\n. Merged in 1.22.0.\n. Awesome work! Thank you very much for doing this.\nSome things I'd like to figure out:\n- How to specify whether cluster or tree is used? Can we make the tree layout independent, so that the user can specify any sort of layout algorithm for the tree, and we just compute the hierarchical paths? I've seen hierarchical edge bundling used in conjunction with treemaps, for example, and it would be pretty cool to show how flexible our layout is.\n- For the tree and other layouts, the two-dimensional size specification is a bit limiting. I'd like to see us specify the range of the x and y dimensions, so that the inner radius (for example) of a radial layout can be non-zero.\n. Yes, it's definitely possible (and something I considered in the original design) to always use [0,1] as the output range for x and y in the layouts. But, it's not particularly convenient, especially because some of the other parameters then become less intuitive. For example, with the force layout, you probably want to think of the link distance in pixels, rather than as some fraction of the layout size.\nAlso, the treemap layout has a round property, which rounds to even integers. The treemap layout also needs to know the aspect ratio of the output range so that it can squarify correctly. So it really needs to know the dimensions of x and y rather than always using [0,1].\nIt's true that adding this functionality to the layouts is a bit redundant, and I think that's why I original specified a size rather than output ranges. Perhaps the existing size specification is sufficient. It just feels a bit awkward to me in the case where I want to specify an inner radius for the tree layout: part of that happens inside the layout, and the remainder of it happens as part of the transform. Of course, I could use the default size of 1x1 here and then use scales for the transform.\nAt any rate, we're somewhat committed to supporting a size property on the layouts, as removing it would be a non-backwards compatible change. Also, in addition to being required for the treemap layout (and sensible for the force layout), it's convenient\u2014requiring people to use scales in the common case is not unreasonable but it does seem like a bit of extra work. I wonder if there is a way to pass a scale, or a projection, or an output range and make it more convenient for some of the other cases, too.\n. I pushed some improvements in the bundle branch, @0aba0702a55e15e7c510725895f669fa978aaab7.\nRemaining tasks:\n- Rename d3.svg.line's beta property to straighten or straightness?\n- If possible, reduce code duplication in wrangling dependency-data into hierarchy & links.\n- If possible, eliminate cos & sin from radial lines, and diagonal projections.\nIf you have other thoughts on how the examples could be pared down further, let me know! Really excited to see this coming together.\n. Fascinating.\nI was thinking of something like d3.svg.line.radial and d3.svg.diagonal.radial, where the coordinates are interpreted as polar--radius and angle rather than x and y (or vice versa, I forget). I'm not sure yet whether these should be new classes or simply default configurations of the existing classes. But something more convenient for radial shapes.\n. OK, I added d3.svg.line.radial and d3.svg.diagonal.radial in commits @e60ac77e25fab847ecc532546c911a12a2df644f and @96a565e3142eb7b0b07f2f4c01500798f5b7d0fe. What do you think? It's still necessary to override the projection to swap x & y, and to convert from degrees to radians. And I don't especially like that the projection function takes an object with x and y attributes and returns a two-element array of numbers. But, it feels like a minor improvement to get rid of the trigonometry\u2026\n. Pushed a few more commits to bundle. Still a bit nervous about the new radial types but otherwise it looks good to me. Any last minute requests?\n. OK, I replaced the beta parameter with the existing tension parameter. For backwards-compatibility, I added a new \"bundle\" interpolator, which is the same as \"basis\", except it uses the tension parameter to straighten the spline. This seems like a reasonable interpretation and avoids adding a new API, which I like.\n. Merged in 1.22.0.\n. I don't think any change is necessary to d3.scale.linear for descending domains; it seems reasonable to me that the ticks are returned in ascending order even if the domain is in descending order. Is the existing behavior breaking something? I'm also happy with the current behavior of linear scales with poly domains; if someone wants different behavior they can implement their own ticks. :) Poly domains are most often used for colors where there are no ticks, anyway.\nThe main thing we need to do to Fix #185 is to support poly domains for d3.scale.log. And I think that can be done simply by replacing d[0] with d3.min(d), and d[1] with d3.max(d) in log.js#L36.\nWhile we're at it, we could probably replace the (x[0] || x[1]) < 0 check with the simpler x[0] < 0, since it's not valid for a log scale's domain to include zero anyway. And, if we want to extend this to poly domains, saying x.some(function(d) { return d < 0; }) is overkill because either all of the values are negative, or all of them are positive. Anything else and your log scale is broken, so I don't see that we need to handle degenerate domains.\nLastly, it might be a bit tricky to detect whether a poly domain is descending, because potentially you could see the same value repeated, e.g., [0, 0, 1]. So checking d[0] < d[1] won't always work. And that's why I think it's good to use d3.min and d3.max, and not worry about having the order of ticks match the order of the domain.\n. I take it back\u2026 now that you've implemented it, we might as well return ticks in the same order as the domain. That's a nice feature. :)\n. Merged in 1.22.0.\n. What about making a new static method to optimize? Then you eliminate the arguments check, the closure creation, the attribute assignment, and two multiplications:\njavascript\nd3.geom.polygon.centroid = function(coordinates) {\n  var i = -1,\n      n = coordinates.length - 1,\n      x = 0,\n      y = 0,\n      a,\n      b,\n      c;\n  while (++i < n) {\n    a = coordinates[i];\n    b = coordinates[i + 1];\n    c = a[0] * b[1] - b[0] * a[1];\n    x += (a[0] + b[0]) * c;\n    y += (a[1] + b[1]) * c;\n  }\n  return [x, y];\n};\nThen, you can use this from d3.geom.polygon, like so:\njavascript\ncoordinates.centroid = function(k) {\n  var centroid = d3.geom.polygon.centroid(coordinates);\n  if (!arguments.length) k = 1 / (6 * coordinates.area());\n  centroid[0] *= k;\n  centroid[1] *= k;\n  return centroid;\n};\nWhereas from d3.geo.path, you can say:\njavascript\nvar polygon = coordinates[0].map(projection),\n    centroid = d3.geom.polygon.centroid(polygon),\n    x = centroid[0],\n    y = centroid[1],\n    z = Math.abs(d3.geom.polygon.area(polygon)),\netc. So I'd guess you need a static version of the area method too. Is there some amazing example where you are computing lots of centroids that benefits from this optimization? I'm really curious!\n. Closing this to cleanup some long-standing stalled pull requests. We can do the static method thing if there's an example that would benefit from this acceleration. Otherwise, I'd rather preserve the existing behavior since we generally do arguments.length checks everywhere; its more robust than checking for null.\n. I think you could say require(\"../\"), right? I wonder if this is a case-sensitive file system issue. What OS are you running? Otherwise, looks good!\n. Looks good. Thank you!\n. Oops, I meant to delete all the symlinks and point the paths to the moved data folder. Thanks for the fix!\n. Nice, thank you!\n. Looks great! I would love to see variable link strengths, too\u2014I think that's usually what you want for force-directed graph layout where the links are weighted.\nWhat do you think about a new linkStrength property, then using alpha * strengths[i]? And renaming distance to linkDistance with an alias for backwards-compatibility?\nWould also be fantastic to have an example to go along with this\u2014Dorling cartogram!\n. New commits look good.\nWell, there are a couple ways to implement Dorling cartograms. One version connects dots based on shared geographic boundaries (for example, connecting Wales and Shropshire). The other version\u2014the one we built for Protovis\u2014doesn't use links at all, and instead fixes each node to a given geographic location, and then tries to resolve collisions using relaxation.\nYou could implement either of these in D3. If you wanted to use variable-length links, then you'd need to specify how the geographic features are connected, and then compute the link distance based on the summed radius of each pair of connected features. On the other hand, if you wanted to use the collision-detection version, then there would be no links. Instead, you'd fix each point to a centroid as in this example: http://bl.ocks.org/1021953. You'd also do collision detection and resolution inside the \"tick\" event handler. (Ideally, you might use the quadtree to optimize collision detection, but that's probably best left out to keep the example simple if there are a small number of nodes.)\n. Re. configurable constraints\u2014I'd be thinking it was simpler to just have people do this sort of customization in the tick handler. Then we don't have to design a new abstraction for customization. But, if you think it'd be cleaner to register constraint functions, I'm listening. :)\n. Careful there, you're detecting collisions between a node and itself. Also, you want the adjustment distance to be based on the error (desired distance - actual distance). Something like this:\njavascript\nvar k = e.alpha;\nnodes.forEach(function(a, i) {\n  nodes.slice(i + 1).forEach(function(b, i) {\n    var dx = a.x - b.x,\n        dy = a.y - b.y,\n        l = Math.sqrt(dx * dx + dy * dy),\n        d = a.r + b.r;\n    if (l < d) {\n      l = (l - d) / l * k;\n      dx *= l;\n      dy *= l;\n      a.x -= dx;\n      a.y -= dy;\n      b.x += dx;\n      b.y += dy;\n    }\n  });\n});\nAlso, the Dorling cartogram needs centroid gravity for each node, so the points don't fly off into space. You can also experiment with using a positive charge force. This worked pretty well:\njavascript\nvar force = d3.layout.force()\n    .gravity(0)\n    .charge(5)\n    .size([960, 500]);\nDon't need the linkDistance in this example anymore, either. :)\n. Wales +1 !\n. Hm, I'd rather have this customization done in a \"tick\" handler than provide a hook for it in the layout\u2014seems too specific.\n. Thanks for the examples, @drio. I think these are sufficiently similar to the existing ones, so I'm going to leave them out of the repository, but you're welcome to host them on bl.ocks and link to them from the wiki.\n. Yep, looks good!\n. Looks good!\n. Looks good! Thank you!\n. Seems fair, given we do this same check in selection.remove().\n. Looks good, thanks!\n. Oops, thanks for fixing this!\nTests would be great, but I expect there are lower-level components (particularly layouts!) that would benefit more from greater test coverage in the short term.\nAlso, related to charts\u2014I started work again on a new axis component. It's posted my axis branch if you want to take a look. Still fairly preliminary and I need to add support for transitions, and figure out a good way of sharing scale state between the axis and other chart components. But I think it'll be very useful.\n. Excellent ideas, thank you. And sorry for not replying sooner.\nI haven't totally decided yet as to how the charts will bind state. Related, I'm also somewhat undecided as to how useful it is to have charts as generic transformations of data (reusable \"rubber stamps\" to create multiple charts, similar to layouts), versus the simpler model where create a new chart instance for each chart. But I'm going to stick with the more powerful transformation approach unless I find it unwieldy, as it seems the better idiomatic approach and consistent with the rest of D3.\nI think you're right that charts should expose their scales, rather than hiding them internally. That's pretty much required for the axis component to be useful, since you'll pass a scale to the axis component, and it must be consistent with whatever else uses the scale (such as a horizon chart, or a custom d3.svg.area).\nOne of the first things I've started work on is a mechanism to clone scales, such that the axis can capture the scale in its current state for a subsequent enter transition. This could be useful in other contexts as well, and it's an easy feature to implement and test.\nWith scale cloning, I only need to bind a scale once to an axis component, and subsequent calls to the component can do the right thing with the transition. But I haven't decided what the rest of the API looks like yet, entirely (such as whether the axis component should support ordinal scales in addition to quantitative scales). There are other complexities, such as whether the axis component can transition between two different types of axes, but I think it's best to punt on these as much as possible, and focus on the simpler common cases.\n. The new commit is good. Yes, we should compute root.area for consistency. It looks like it's still possible for the area to be NaN, though, if the value is NaN? (Because k is NaN in the scale function?) Can you double-check this doesn't cause badness when a layout node has a 0, negative, or NaN value? (Even better, write a tiny test!)\n. Few more comments but this is lookin' good!\n. Looks good!\n. Submitting some fixes and pushing a new release. Thanks!\n. Nice! Thank you. Minor suggestion, since the value of ie never changes, you can say:\n```\nvar setStyleProperty = ie\n    ? function(obj, name, value, priority) { obj.style[name] = value; }\n    :  function(obj, name, value, priority) { obj.style.setProperty(name, value, priority); };\nvar removeStyleProperty = ie\n    ? function(obj, name) { delete obj.style[name]; }\n    : function(obj, name) { obj.style.removeProperty(name); };\n```\nAlso, I imagine we'll want one for getStyleProperty, too. And ideally, we detect whether this is necessary by inspecting a candidate style object:\njavascript\nvar ie = !document.body.style.setProperty;\n. How about document.head.style.setProperty? Or document.createElement(\"div\").style.setProperty?\n. Argh, that's annoying. Thanks, IE. Still, I could see branching three implementations based on calling setProperty on a trial element. If there's no such method, we fallback to direct-set; if the method throws a TypeError, we use a string-coercing setProperty; otherwise, we use the default on all standard browsers.\n. The solution suggested by @macduy is pretty awesome. Seems like we'd have to detect whether those methods are already defined, and whether or not they perform string coercion, though.\n. OK, I committed a workaround for IE9's style.setProperty here: @c2e37352ac84eb8b4be89feed90bc2249866f715. It should make it into the next release, if I can get someone to test IE9: http://bl.ocks.org/1177588\n. Fixed in 2.1.0.\n. @toolfishes And what is the value of CSSStyleDeclaration.prototype.setProperty in IE9 after loading d3.js?\n. If the value is null, setProperty isn't called; it calls removeProperty instead.\n. Don't use compatibility mode.\n. If you want to force a particular time interval for ticks, you should just call the appropriate interval method (e.g., d3.time.days) rather than using the scale ticks. I don't see that this functionality needs to be added to the scales given that we already have a method for producing ticks for a specific interval. Unless there's something I'm missing?\nI could see, however, making it a bit more convenient to map a time scale's domain to the arguments to the interval method. Currently you have to compute the extent (domain[0], domain[1]) by hand, not that it's hard, but it's a bit tedious.\n. I've added the ability to force a particular time interval for time scale ticks in 1.29.0. For example, you can now say:\njavascript\nx.ticks(d3.time.seconds, 15)\nAnd you will get 15-second ticks. The way it works under the hood is that the range method now take an optional third argument which specifies the step, so d3.time.seconds(t0, t1, 15) will return the 15-second dates between t0 (inclusive) and t1 (exclusive). Just be sure that you match the appropriate local- or UTC-range method with your scale.\n. Huh. I thought we just fixed this? Clearly we need more tests. :) I'll take a look soon. Thanks for submitting the fix!\n. Including the generated files is nice but not required. I always rebuild everything as part of merging and testing, anyway. I initially resisted including the generated files in the repo, but including them makes it a lot easier for people to download the repo and have things work out of the box.\n. Neat idea! However, I'm against adding methods to the core selection class that change the behavior of the underlying representation.\nThe D3 kernel is intended to be \"transparent\", in the sense that each operator is a direct pass-through to the underlying W3C DOM method. For example, style(\"foo\") sets the \"foo\" style property, and attr(\"bar\") sets the \"bar\" attribute, even though D3 doesn't know what the \"foo\" style or \"bar\" attribute mean. In other words, there are no special-cases or assumptions about what the attributes or styles mean, or even whether they're supported.\nThis is also why I say D3 is not a compatibility layer. For example, in theory, you might be able to silently transform SVG elements to VML under the hood, but that's a ton of work and breaks the simplicity of the design, and the ability to inspect the DOM using the browser's developer tools.\nThis is all a long way of saying, I'm happy using the existing sort and style(\"z-index\") attributes, rather than creating a helper method that tries to choose between them intelligently. You're of course welcome to use such a helper in your own code, but it shouldn't be part of the kernel.\nThanks again for the contribution. I hope my response is reasonable even though I closed the request! :)\n. I started work on attr & style taking maps; see commit @5603474872ac2cd9abe38b0eceac5e679b5a9080. Unfortunately progress has not been as quick as I would like because there are a number of different ways to overload using maps (for example, a function that returns a map, and a map that contains functions). Plus, other operators such as on and property should also take maps for consistency.\nI'm also wondering if there's a better way to define the selection as a subclass of array. I'm not aware of a \"correct\" way to subclass arrays in JavaScript, and I do general prefer literals and closures (for Crockford's private and privileged method pattern). But if we were to define D3 selections using a prototype, that has the nice property that it can be extended if you want to define your own custom operators. Of course, that would also be possible if we provided a registry for selection methods, as with do with interpolators (see d3.interpolators).\n. I think there are times where you can receive a mouseup event, and it will be at a different position from the previous mousemove event. So, the reason the mousemove trigger is there is to make sure that on mouseup, the node and the mouse are at the same position.\nIf we move this check, it's now possible that the mousedown and mouseup could be in different positions, with no mousemove in between. But, I think it's safe to still interpret that as a click, since in all realistic drag situations there must be at least one (and typically many) mousemove events.\nOne minor formatting comment. I typically use one of two styles for if statements. One-liners:\njavascript\nif (d3.event.type === \"mouseup\") d3_layout_forceDragMove();\nAnd multi-liners:\njavascript\nif (d3.event.type === \"mouseup\") {\n  d3_layout_forceDragMove();\n}\nLooks good!\n. Thanks for the fix!\n. Neat. I wonder what the right solution is regarding the new dependency. We could include this as part of 2.0 and break backwards compatibility. Or we could bundle d3.behavior.js into d3.layout.js. I don't like automatic bundling (large files) and I'm not a big fan of implicit dependencies either (lots of files, knowledge required). Ideally we have something like CommonJS require (or whatever Google closure does), but that sounds like a lot of extra complexity. Bah!\n. Sure, let's do that.\n. Argh, you deleted a few features of the existing drag behavior: preserving the offset between the mouse position and the element's position (e.g., the force directed states of america), and setting the fixed flag on mouseover. Fixing those now!\n. You're welcome! I think we can probably write tests for a few of these things now. JSDOM has the ability to trigger events (not sure if they use the W3C dispatchEvent API for it, though), so there's probably something we can do to get coverage for behaviors and layouts.\n. Ah, thanks. Me talk pretty one day.\n. sudo make me a sandwich\n. Neat!\n. Thanks. The semicolon part looks good, though I might use echo -n to strip the trailing newline.\nI'm hesitant to add a d3.all.js target, though; the point of a modular system is for people to choose what parts they need, rather than getting everything, and everything growing arbitrarily large. Although, I guess the whole thing is still ~30KB gzipped, so maybe I'm being too conservative.\n. It occurs to me that concatenating the minified files is worse than generating a single minified file with all of the desired components. The individual files are wrapped with anonymous self-executing functions to prevent private fields from leaking into the global namespace, but only one of these is needed for the entire file.\nSo perhaps the right solution is to get rid of the semicolon stuff and add a d3.custom.js target with a comment suggesting that people can edit the rule description to create their own custom build. This target would not be included in the all target (and d3.custom.js would not be checked in to the repo), but can be generated on demand.\n. Octal constants are explicitly disallowed in ECMAScript 5, so these should be fine. Does it break node-jscoverage?\n. Wow, awesome! Thank you!\nMike\n. Nice, thank you!\n. Bravo!\n. Nice work! Thanks for the unit tests, too!\n. Bellissimo.\n. Thanks for this. Due to the massive code restructuring in 2.0.0, I'm not able to pull your changes in easily, but I have updated the map branch to support multi-value maps for attr. I think we can extend that approach to style and the other operators as well. If you want to follow along there or send me updated pull requests, please do!\n. Merged into #277.\n. I'm wondering if this class should have properties (more higher-order programming) similar to, say, d3.svg.chord. For example, perhaps you define a source and target accessor for d3.geo.greatCircle, so that it can take the standard d, i arguments and be used in conjunction with attr(\"d\"). Sort of like d3.geo.path, too.\nProviding a default n would be nice, too. Even better, making it intelligent so that it can be specified as precision rather than number of segments. ;) But that's probably too much work!\n. Would you mind renaming this to d3.geo.greatCircle, since \"great circle\" is two words?\nOtherwise, looks good!\n. There's probably a way to structure the code into two methods (a getter and a setter) per operator, and then write a generic wrapper that detects multi-valued maps and dispatches accordingly.\n. No, that's not what I meant. I meant that we could add multi-value map support for transition.style, but potentially transition.styleTween would still only support single values. Though it would be preferable for it to support a map for consistency with other operators.\n. Nope; still need to add support for transition.attr and transition.style, at the least. I might be okay deferring selection.classed and selection.on to a later release. Feel free to lend a hand if you want to see this happen more quickly!\n. Shooting for the next minor release, 2.9. Hopefully that should be within the next couple of weeks.\n. Related #55 #65\n. So far, I have added support for accepting both a map and a function that returns a map. When a map is specified (say to selection.attr), it can contain constants or functions. However if a function is specified, the map it returns can only specify constants. I was striving for consistency with other methods that allow either constants or functions, but I feel like this adds too many equivalent signatures and fails at parsimony. For example, these are all equivalent:\njs\nselection.attr(\"foo\", 42); // constant\nselection.attr(\"foo\", function() { return 42; }); // function\nselection.attr({foo: 42}); // map of constants\nselection.attr({foo: function() { return 42; }}); // map of functions\nselection.attr(function() { return {foo: 42}; }); // function returning a map of constants\nIn the earlier discussion for #55 and #65, it seemed like the last variant is probably overkill. It\u2019s arguably the most powerful of the five signatures because you can share work across multiple attributes and compute attribute names dynamically. However, you can already structure your code this way using selection.each, though perhaps with a bit more typing and perhaps slightly worse performance:\njs\nselection.each(function() { d3.select(this).attr(\"foo\", 42); });\nAlso consider this implies three signatures for selection.on:\njs\nselection.on(\"click\", listener); // listener\nselection.on({click: listener}); // map of listeners\nselection.on(function() { return {click: listener}; }); // function returning a map of listeners\nI\u2019d like to kill support for the single-function signatures. That would leave four signatures for selection.attr (ignoring the fifth signature when used as a getter):\njs\nselection.attr(\"foo\", 42); // constant\nselection.attr(\"foo\", function() { return 42; }); // function\nselection.attr({foo: 42}); // map of constants\nselection.attr({foo: function() { return 42; }}); // map of functions\nAnd two for selection.on:\njs\nselection.on(\"click\", listener); // listener\nselection.on({click: listener}); // map of listeners\nThis preserves D3\u2019s philosophy of encouraging only values (and not names) to be specified as functions.\n. A small point, but you can collapse the map of functions slightly in your example:\njs\nselection.attr({\n  cx: x,\n  cy: y,\n  fill: color\n});\nOr in CoffeeScript:\ncoffee\nselection.attr\n  cx: x\n  cy: y\n  fill: color\nThis only works when the functions x, y and color take the standard signature (d, i). You wouldn\u2019t derive this advantage from the function that returns a map, since you have to invoke the functions manually.\n. @idibidiart True, but that also applies to the previous syntax:\njs\nselection\n    .attr(\"cx\", x)\n    .attr(\"cy\", y)\n    .attr(\"fill\", color);\n. Merged into #756; staged for 2.10.0.\n. @coli This is discussed in #2109, and I think we can do this for 4.0 as selection.attrs (plural).\n. Nice! I thought that fill-rule: evenodd was required for this case, but this is great. Looks good to me.\n. I still had a few problems with the fixed implementation. See for example this dataset, which was showing coincident circles:\njavascript\n{\n \"name\": \"flare\",\n \"children\": [\n  {\n   \"name\": \"animate\",\n   \"children\": [\n    {\"name\": \"Easing\", \"size\": 17010},\n    {\"name\": \"FunctionSequence\", \"size\": 5842},\n    {\"name\": \"interpolate\", \"size\": 0},\n    {\"name\": \"Transitioner\", \"size\": 0}\n   ]\n  },\n  {\n   \"name\": \"data\",\n   \"children\": [\n    {\n     \"name\": \"converters\",\n     \"children\": [\n      {\"name\": \"Converters\", \"size\": 721},\n      {\"name\": \"DelimitedTextConverter\", \"size\": 4294},\n      {\"name\": \"GraphMLConverter\", \"size\": 9800},\n      {\"name\": \"IDataConverter\", \"size\": 1314},\n      {\"name\": \"JSONConverter\", \"size\": 2220}\n     ]\n    },\n    {\"name\": \"DataField\", \"size\": 1759},\n    {\"name\": \"DataSchema\", \"size\": 2165},\n    {\"name\": \"DataSet\", \"size\": 586},\n    {\"name\": \"DataSource\", \"size\": 3331},\n    {\"name\": \"DataTable\", \"size\": 772},\n    {\"name\": \"DataUtil\", \"size\": 3322}\n   ]\n  }\n ]\n}\nHowever, I think I also discovered the fix. When the conditional fails in d3_layout_packPlace, set c.x to a.x + db rather than a.x; this avoids any coincident circles.\nThe \"can handle residual floating point error\" is a bit hard to follow. I have no idea what those numbers mean. If you get a chance, could you rewrite the test in a way that makes it more obvious what you were testing? For example, if you mean to test that none of the numbers are NaN, you could say assert.isFalse(numbers.some(isNaN)).\n. I think d3.layout.cluster has a bug here, too; if you look at the d3_layout_clusterLeft and d3_layout_clusterRight methods, for example, you'll see that they assume that the children array is non-empty if it exists. There might be other places where we make similar assumptions.\n. Nice work. Are there tests that use the old API rather than calling nodes directly? I was sorely tempted to force everyone over to the new API in 2.0.0 but in the end decided against backwards incompatibility.\n. Thanks for bringing the tests up-to-date; I'd like everyone to use inlining. Eventually it'd be nice to remove the deprecated code entirely. Is it still necessary to have hierarchy.nodes, or can we remove it now?\n. The equidistant and equalarea modes work great for me, but the gnomic one does not. I'm not sure whether it's an issue with the projection, or the fact that we're trying to draw the entire world rather than just the visible surface of the sphere in the current viewport. Is that the expected behavior?\n. Yeah, no major version bump please. That should happen approximately once a year. Thanks, and nice work!\n. I am blown away by the demo. The great circle clipping is amazing, and all the projections look great! It's fantastic to have this functionality at last.\n. Almost there. Some questions:\nHaving d3.geo.clip's angle be in degrees is surprising to me, given that we use radians everywhere else. Am I understanding correctly that d3.geo.clip will clip to a great circle if and only if angle equals 90\u00b0? So the purpose would be to clip to a smaller circle? On the other hand, latitude and longitude is specified in degrees, so it probably does make sense in a \u201cgeo\u201d context.\nAnd, on a related note: what about folding d3.geo.clip into a clip method on d3.geo.greatCircle? I recognize that this is less functionality, but it's a smaller addition to the API\u2019s surface area as well. Especially so since d3.geo.clip is a very generic name, but it only supports clipping of a particular type\u2014and for the time being we only need to clip to great circles.\nThough I see that in the examples you\u2019re using 89\u00b0 rather than 90\u00b0. Is there some boundary condition at 90\u00b0 that we need to account for (and should that be the default behavior if we add a clip method to d3.geo.greatCircle)?\nIf we do want customizable angle, I suppose another option would be to rename d3.geo.greatCircle into d3.geo.circle, and then add an angle property. And then we\u2019d support rendering (polylines) both great and non-great circles. :)\n. I think for rectangular clipping, it would be just as easy to define a new class (similar to d3.geo.circle, say, d3.geo.rectangle or even d3.geo.polygon). That class could, like greatCircle, support both rendering and clipping. Although, we already have d3.geo.path for rendering polygons, so perhaps it's a mistake to add a new class. (Would it be possible to add a clip method to d3.geo.path? That could be awesome, though more challenging to implement and perhaps even awkward to use.)\nIt just seems to me that if you do want to make d3.geo.clip support rectangles in the future, you'll need a different API to specify whether it should clip as a rectangle or as a circle, and there may not be a lot of overlap in the API; origin and angle are specific to circles. That's why it feels like a different class, even if both classes could support a clip method.\nI'm happy with this stuff living in d3.geo, rather than d3.geom, if they deal with specifics to geography. But I agree there's an inevitable potential for overlap with d3.geom.\n. I'll probably take a crack at the proposed refactoring tonight, since it sounds like we agree. Then we can get this lovely feature merged!\n. That's great; I'm looking forward to the new stuff! But I think we have good functionality that's ready to go in this pull request if we shift it around to the proposed API (namely, greatCircle.clip).\n. I'm working on this now, and I realized there's a problem (or at least a source of confusion). The d3.geo.greatCircle class doesn't represent a great circle; it represents an arc segment along a great circle. That's why d3.geo.clip is specified in terms of an origin (and angle), while d3.geo.greatCircle is specified in terms of a source and target. Perhaps the way to fix this is to introduce the new d3.geo.circle class, and leave d3.geo.greatCircle as an arc, perhaps using d3.geo.circle under the hood.\nI'm also inclined to extract the clipping functionality from d3.geo.path. Rather than specifying a clip function to the path, you compose them together. For example, you might say:\njavascript\npath.attr(\"d\", function(d) { return path(circle.clip(d)); });\nHere d is a GeoJSON feature (or similar JavaScript object). The circle.clip method returns a clipped GeoJSON feature, which when passed to path returns an SVG path data string.\n. Argh, this is really hurting my head. Can you give me a quick explanation of how these components are wired up in the azimuthal demo? It's rather confusing to me that you have both clip and circle.polyline being used together, loosely-coupled through the coordinates accessor. Here's what I think should happen:\njavascript\ncircle.clip(feature) // returns the feature clipped to the (great) circle\nBut it seems like you are doing something magical where first the feature is resampled such that there are great arcs between each adjacent pair of coordinates (using d3.geo.greatCircle's polyline method), and then clipping those resampled coordinates (using d3.geo.clip). It isn't necessary to create great arcs between coordinates that will not be clipped, though, correct? Or is it possible that even though neither of two adjacent coordinates are clipped, the points in-between would be clipped, and so we must first create the great arcs and then perform clipping.\n. OK, I finally wrapped my head around it. :) I had the order of operations reversed (it was rather hard to follow path.clip -> circle.polyline -> clip.coordinates): the coordinates are clipped, projected onto the great circle as necessary, and then resampled. I've just pushed my refactoring to my gnomonic branch for your review.\nThe one part I haven't decided on is using GeoJSON for the interface. It's definitely convenient to have d3.geo.greatArc generate a LineString GeoJSON object so that it can be passed directly to d3.geo.path for rendering. And it's nice that you can clip arbitrary GeoJSON objects using greatCircle.clip. But I suspect it would be more efficient if greatArc returned a simple array of coordinates, and likewise greatCircle.clip took as input a simple array of coordinates\u2014more like what you had previously with path.clip.\n. Thanks for the explanation. I am going to sleep now! :)\n. I understand about gnomonic now. Seems like we could have a way to disable resampling in circle.clip; that happens implicitly if the precision is large enough. I'm not too worried about optimizing the performance for that specific projection, though.\nYou mention \u201cnew code\u201d: have you pushed your code, or are you going through the merge now?\nRe. d3.geo.circle vs. d3.geo.greatCircle, I am imagining that the latter is a subclass (or special case) of the former. I hadn\u2019t implemented small-circle clipping yet (or rendering paths for small or great circles), so I figured it would be reasonable to only add a greatCircle. But you\u2019re correct; small circle clipping is easy and useful. So what I can do is rename greatCircle to circle, and then have this:\njavascript\nd3.geo.greatCircle = function() {\n  return d3.geo.circle().angle(90);\n};\nWell, we could even have d3.geo.circle\u2019s angle default to 90 and then leave greatCircle as an alias:\njavascript\nd3.geo.greatCircle = d3.geo.circle;\nI\u2019ll think more about the GeoJSON interface. It is nice to distinguish between polylines, polygons and points for clipping. I also need to tweak the implementation of precision so that we create more useful intermediary points when the precision is approximately equal to the arc length.\nI can wait for your merge before I push release 2.3. Any other things you\u2019d like to see before we release?\n. As long as we agree on the API, we can also push this stuff now and then improve the implementation after. :)\n. Hooray! OK, I'll get this pushed soon.\n. I see what you're getting at, and thank you for the contribution and context, but I don't see this as being necessary. I'm a strong believer in parsimony for APIs: if you can do something one way, rather than multiple ways, it should be easier for people to learn the right way to do something. Put another way: it's good to minimize the surface area of an API. If we introduce innerRadius and outerRadius to pie layout, now users need to ask whether they should set the radius on the layout or the arc (or both, ack!).\nThe issue of arc.centroid returning NaN is surprising. It shouldn't do that, since you presumably defined the arc's innerRadius to 0 and the outerRadius to 100. The centroid method has the same behavior as the path data generator itself, so centroid will work even if the pie layout doesn't compute the radius.\nLet me know what you think, and if you don't agree, please reopen this request! I'd love to figure out why arc.centroid didn't work for you, too. Is it possible you were using a default d3.svg.arc instance rather than the same one you were using to render the arcs from the pie layout?\n. Hmm. I'm tempted to use the same behavior as d3.svg.axis's ticks function (which lets you specify arguments which are passed to the underlying scale). But that, alas, would not support your particular use case.\n. Thanks for the pull request, Ben. However, we're in the process of extracting chart templates from the core library into a separate project, so I'm going to close this.\n. It'd be nice if the bullets function were consistent with the other functions, so I agree with passing the data object but not the scale. Having access to the scale is useful, but it's a special case. For example, the d3.svg.axis component allows you to specify arguments that are passed to the scale's ticks function. However, this makes it difficult to override the ticks generation in arbitrary ways\u2026\n. Related #326\n. I would implement this differently. Rather than inspecting a chargeMultiplier property, which requires people to structure their input data in a particular way, I'd allow you to specify a function for the layout's charge property, rather than requiring a constant. The charge would default to -30 as before, but you could replace it with a function, say:\njavascript\nforce.charge(function(d) { return d.charge; });\nOr perhaps you'd define it as a function of data or other attribute of graph structure. Can you give an example of how you want to use this?\nThis function would then be evaluated when the layout is started. If we can, it's nice to avoid writing new attributes onto the node itself, because that can lead to collision with other data being stored on the nodes. It can also lead to feedback loops. (For example, if we evaluated the charge function and stored that back on the node as the charge property, then a charge function such as function(d) { return d.charge / 2; } would be buggy.) That's why the link distances and strengths are stored in arrays rather than as attributes of the link object.\nSo, if we stored the node charge in an array, charges, then we could modify force accumulation like so:\njavascript\nvar charge = charges[quad.point.index];\nquad.count += charge;\ncx += quad.point.x * charge;\ncy += quad.point.y * charge;\nHow does that sound?\nMy only other reservation is adding any complexity to force layouts for an uncommon case, since the performance of the force layout is a bottleneck. But this looks like minimal impact, so I'm okay with it. I'd still like to better understand your use case, though.\n. Nice progress. The only remaining change I'd like to see is not using d3.functor; I'd rather not wrap constants in a function, for backwards compatibility. For example, you can call force.charge() and inspect the current charge amounts (as a number), but wrapping it in a function makes it a bit more opaque.\nI'd probably say:\njavascript\nif (typeof charge === \"function\") for (i = 0; i < n; ++i) charges[i] = +charge.call(this, nodes[i], i);\nelse for(i = 0; i < n; ++i) charges[i] = charge;\nOh, I added number coercion to the result, too. That's a good idea. Likewise on input:\njavascript\ncharge = typeof x === \"function\" ? x : +x;\n. Almost there. :)\n. Looks good.\n. Nice, thank you.\n. Nice work! Thank you!\n. Crap. The subtle differences (lack of array extras) with NodeList are annoying. I made this change for the sake of performance, but given that the performance benefit is likely negligible in common usage, it was probably a mistake to break the API. I see two options:\n1. Continue to treat the internal arrays as an implementation detail, and fix any place within D3 that requires array extras. As far as I can tell, this is only the sort operator. We could probably say Array.prototype.sort.call(list, comparator) rather than list.sort(comparator).\n2. Recognize that the internal arrays are part of the public API, and restore them to their full glory.\nI'm tempted by the second option, since that avoids any gotchas that occur when you access the arrays directly as selection[i] outside of D3 operators. Also, there are cases such as the filter operator where you end up with arrays rather than NodeLists anyway. But this assumes that the performance benefit is negligible, as most things are relative to rendering, and I haven't measured it.\n. And if we go the slice route, we're back to needing d3_array for IE, correct? (And was that for IE8 or IE9, I forget\u2026)\n. Awesome! I just wanted this to implement a new parallel coordinates example, too. A couple things I'd like to figure out:\n- Can we customize the behavior when the selection reaches the end of the allowed range? In the zoom example, if I drag the region beyond the defined range, the selection shrinks and is eventually empty. I think it'd be nicer in that case if the selection doesn't resize, but instead the position is clamped so that it fits entirely within the defined range.\n- How could we add resize thumbs on the edge of the selection? The model from Mac OS X Lion would work pretty well, in that there's a few pixels available on the edge of the selected region that allow you to resize the region along that dimension (or both dimensions) rather than dragging. There are some nuances to this: the thumb region displays a different cursor, and the thumb region extends slightly beyond the selected region.\nIt might be difficult to make these work automatically. On the other hand, we could make something like d3.svg.axis, where the component creates the content as well as defines the behavior. This would make it SVG-specific, but that might be a reasonable sacrifice if it makes it more usable. Another option is to have both d3.behavior.select and d3.svg.selector.\n. Yeah, I agree re. the three orientations. I could imagine using a transform to rotate a selection (for example, if you wanted one-dimensional selection along the axes of a radar chart), in which case that could be treated as either horizontal or vertical selection.\n. OK, I've got a prototype of d3.svg.brush up in my brush branch. We could call it d3.svg.selector, but I thought that was a bit too close to W3C selectors which D3 already uses heavily. And plus, this pays homage to the standard interaction technique: brushing and linking.\n. True... And crosshairs for the outside.\n. I've added resize thumbs. Last thing to figure out is how to get the selection from the brush when a \"brush\" event is received. I was considering using d3.event.x and d3.event.y\u2026 but I think it might also be nice to allow the caller to get or set the brush selection programmatically.\n. The cursor problem is annoying but fixable. You have to disable the other cursors while dragging\u2026 It's too bad there isn't an easy way to make the cursor temporarily sticky. Another small problem is that the corner resizers should probably be slightly bigger. As far as I can tell, Mac OS X Lion gives you an invisible 6px-wide strip on the sides, but at 12\u00d712px square on the corners.\nI haven't yet implemented a way to set the selection externally. In part, this is because the d3.svg.brush isn't bound to a particular element: like d3.svg.axis, it gets implicitly bound when you selection.call(brush). However, you could set the selection externally and then update the UI by calling selection.call(brush) again. There's a related issue as to whether this should dispatch a \"brush\" event, and what the context and arguments to the listeners would be in this case; normally it is the brush element and the associated data, but there is none when the selection is set programmatically!\n. Lots of improvements just pushed to the brush branch. You can now using the option/alt and space key to modify resizing behavior, which I quite enjoy!\n. If you want to experiment with it and let me know if you run into any design issues, that would be fantastic. I just ported the SPLOM example to use d3.svg.brush and tweaked the design a little bit. I'll be trying parallel coordinates next.\n. You mean reorder the axes? Ya, that'd be sweet.\nFunny I just had the same thought regarding d3.extent. I did the quick thing of using array.map, but a single loop could work too.\nI think the one outstanding design issue that makes me nervous is the interaction between setting the brush extent programmatically and notifying listeners. Originally I had it notify the listeners, because that's often what you want if someone external sets the brush extent (e.g., you click on a button to highlight a pre-determined region). But then when I added the splom example, changing one brush cleared the other brushes, which lead to an infinite loop of notification. I'm wondering though if it's possible to implement the splom example using just one brush rather than many brushes.\n. I filed a couple bugs related to extent/min/max: #360 #362. I haven't totally decided what the right behavior should be. Personally, I find it a bit weird that map skips missing entries. I suppose there's no reason to be slaves to the built-in method as long as we're locally consistent. Any preference?\n. Merged into 2.5.0 as the d3.svg.brush component.\n. Looks good. Thank you!\n. This only works when you have a single node selected, which doesn't seem much in the spirit of data-driven documents. Still, it might be nice to have a way of appending off-screen nodes. That's possible now by passing a function to select or selectAll, but I could perhaps see a similar function for append. And maybe a simple node for singleton selections, though I also wonder about appending an existing selection to another selection, pairing up nodes. That might allow us to create off-screen selections and then merge them into the document.\n. You can write reusable functions that take a selection as an argument and append nodes to them. Then you can use the call operator. I'm closing this to cleanup some stalled pulled requests, but feel free to continue the discussion on how to move around existing nodes, and we can reopen this if we come up with a good strategy.\n. Related #4\n. Nice fix. Thank you!\n. What problem was this solving? I understand the explanation of canceling the next click, but if you started dragging, don't you always want to cancel the click, regardless of where the mouse ends up?\n. Awesome. Thank your for all the background info!\n. Ah, yes. I believe npm does the right thing if you create a node_modules directory first, but not if you don't already have such a directory. I think we should add a Makefile rule that ensures the directory exists before running npm install. But, I still like your fix!\n. This gives NaN for a parallel 0\u00b0: 1/tan(0) is \u221e, and then \u221e \u00d7 0 = NaN.\n. I'm working on a fix also. Something like this:\njavascript\n  function bonne(coordinates) {\n    var x = coordinates[0] * d3_geo_radians - x0,\n        y = coordinates[1] * d3_geo_radians - y0;\n    if (y1) {\n      var p = c1 + y1 - y, E = x * Math.cos(y) / p;\n      x = p * Math.sin(E);\n      y = p * Math.cos(E) - c1;\n    } else {\n      x *= Math.cos(y);\n      y *= -1;\n    }\n    return [\n      scale * x + translate[0],\n      scale * y + translate[1]\n    ];\n  }\n. Yar, I renamed things a little bit to match the Wikipedia functions. Sorry! :)\n. Hmm, I see what you're getting at, but I'm not convinced we should change the current behavior in regards to the children attribute and the prototype chain. Strictly speaking, requiring the children attribute to be defined on the node object rather than on its prototype chain would be backwards-incompatible, say if someone created a shallow clone of an existing node via Object.create, so as to override other properties.\nPhilosophically, I don't like having to check Object.hasOwnProperty. Deriving a new object from a prototype should be transparent, at least in the common case: downstream code shouldn't care whether the attribute is defined on the object or its prototype. Also, implementing a hierarchy this way is inefficient (O(n^2)), because you are scanning over the entire array of nodes (data.filter) for each node in your hierarchy. \nIf, despite the above, you want to stick with this approach, it seems like you could avoid the infinite loop by explicitly setting the children attribute of leaf nodes to null or the empty array. That way, it won't be inherited by default. For example:\n``` javascript\nzero = root = {};\n  one = child(zero);\n    oneOne = child(one);\n    oneTwo = child(one);\n  two = child(zero);\n  three = child(zero);\nfunction child(parent) {\n  var child = Object.create(parent);\n  child.children = null;\n  return child;\n}\n```\nYou could also define the children property using Object.create directly, but you'd need to make it writeable since it will later be assigned by the hierarchy layout.\n. Would it be possible to make this composable with a given projection? For example, rather than project(point), you'd say project(rotate(point))? And similarly, rather than project.invert(point), you'd say rotate.invert(project.invert(point)).\n. I'd love to see a refactoring of our projections that extracts two parts:\n1. Transforming spherical coordinates pre-projection. This appears to be what d3.geo.rotate does, which looks great! Now we should adopt it for the other projections that take an origin.\n2. Transforming Cartesian coordinates post-projection. This is the standard translate and scale supported by all projections.\nThat would simplify the projection implementations, which would only need to support mapping between normalized spherical coordinates and normalized Cartesian coordinates.\n. Another option to consider would be to rename the class to d3.geo.transform, and allow the user to specify the full matrix (either as a 9-element array or as a nested 3x3-element array). Then you could have a convenience constructor d3.geo.rotate(x, y, z) that rotates by z then y then x. This would be as convenient as the current class, but more flexible if someone wants to do something crazy in the future.\n. Although maybe d3.geo.transform is too generic if we also have Cartesian transforms.\n. This is looking good. A few questions:\n1. Should every projection use d3.geo.rotate? I notice that Albers and Azimuthal both have origins, but neither use d3.geo.rotate. Perhaps I'm not understanding correctly, but I thought the purpose of d3.geo.rotate was to consolidate logic for handling the origin.\n2. If the origin is <0,0> we might want to optimize d3.geo.rotate to return the identity function. That seems like a common case, at least for some projections (Mercator). I like how the new immutable design lends itself to more easily optimized implementations.\n. Yeah, if there's a performance penalty to using d3.geo.rotate, that'd be good to know. Likewise, if it's possible to optimize d3.geo.rotate to support those projections more efficiently, that might be another option.\n. The cylindrical example fails for me. I get:\njavascript\nUncaught TypeError: Object function conic(coordinates) {\n    var t = (n || 1) * (d3_geo_radians * coordinates[0] - lng0),\n        p = mode === \"equalarea\" ? (n ? Math.sqrt(C - 2 * n * Math.sin(d3_geo_radians * coordinates[1])) / n : C)\n          : mode === \"equidistant\" ? d3_geo_radians * -coordinates[1]\n          : n ? C / Math.pow(Math.tan(Math.PI / 4 + coordinates[1] * d3_geo_radians / 2), n) : C;\n    return zoom([\n      n ? p * Math.sin(t) : C * t,\n      mode === \"equalarea\" ? n ? (p * Math.cos(t) - p0) : -Math.sin(d3_geo_radians * coordinates[1]) / C\n      : mode === \"equidistant\" ? p\n      : n ? p * Math.cos(t) - p0 : -Math.log(Math.tan(Math.PI / 4 + coordinates[1] * d3_geo_radians / 2))\n    ]);\n  } has no method 'parallel'\n. Perhaps we should make a cylindrical.parallel(x) method on that maps to conic.parallels([+x, -x]), rather than doing the typeof == number check inside conic.parallels?\n. I'm tempted to move the azimuthal, bonne and equirectangular projections to the d3-plugins repository. That would leave only Albers and Mercator, which I think is the minimal set of projections needed in core. (This would not happen until D3 v3, since it is backwards-incompatible.) I suspect that would also be a good place for an extended set of projections to live, such as collignon and cylindrical. What do you think? I'm hoping there are other things you might want to put in the plugins repository, such as your word cloud implementation!\n. Yeah, I really like azimuthal too. Well, we're not going to make any immediate movements to the current projections in core. I just want to have a more discoverable home for the new ones. So let's start there!\n. I'd like to try adding some of these projections into the new d3.geo.projection plugin. Eventually, I may decide to merge that plugin into d3 core because with the new design most of the projection definitions are extremely cheap to implement.\nI'd prefer to have separate projection implementations rather than projection modes with conditional branching, though it might be possible to reuse projections (or abstract projections) similar to how winkel3 is implemented on top of aitoff. So I'm imagining things like conicEqualArea separate from conicConformal or whatever. We'll see.\nI haven't decided what to do with d3.geo.rotate yet. I like the idea but often rotated features become unusable because they cross the date line. I was thinking something like d3.geo.rotate might split rotated features when they cross the antemeridian, but I feel like it'll be a bunch of work to get right (and that only handles the case where the longitude is shifted, not latitude & z). For now I've avoided adding longitude rotation to projection implementations because I do think it would be nice to use rotation as a pre-processing step shared by multiple implementations. (Perhaps the user could use d3.geo.rotate to generate rotated GeoJSON features and then cache the result, but that might be tedious.)\nRobust geo-clipping would make a nice additional D3 plugin, too.\n. Which type of cylindrical projections does this class support? Obviously it supersedes the previous equirectangular (plate carr\u00e9e) projection, but Mercator is also a cylindrical projection, as is Lambert cylindrical and Gall\u2013Peters.\nWhat does the parallel mean in this context? I see a number of projections reference the central meridian and the standard latitude.\nThere's no mode setter, so although the code appears to support both equalarea and equidistant, only equidistant is usable. \n. This looks lovely! I love the unification of the projections into standard categories, with only little bits of special-casing for different modes. If that special-casing grows too large then I'd say break things into separate projections again (or perhaps dispatch to a subclass method or similar). But so far, looks great. Do you want to merge this into your other pull request for d3.geo.rotate?\n. Thanks, Bixente. You're welcome to add a link to this from the wiki if you like, but I don't think it needs to be included with the git repository. FWIW, I normally use OGR for this:\nbash\nogr2ogr -f GeoJSON countries.json countries.shp\n. That was fast. :)\n. I'm concerned that tickArguments could be empty. Also, in theory some ticks function in the future could accept an array as arguments. Also, functions have a 'length' property describing the number of expected arguments: https://developer.mozilla.org/en/JavaScript/Reference/Global_Objects/Function/length\nSaying tickArguments[0] instanceof Array would be safer, though this breaks if a subclass of Array is used. (We probably don't care, but it's worth mentioning.) We could use Array.isArray, but that isn't universally supported so we'd probably want to add a polyfill for IE.\nBlargh\u2026\nYou can also do this by overwriting the ticks function on the scale itself: scale.ticks = function() { return [1, 2, 3, 4]; }. Kinda hacky though.\n. I think the easiest way to avoid ambiguity here is to have a separate setter method, let's call it tickValues. If tickValues is null, then scale.ticks is used. This would let us specify the array of tick values either as a constant array or as a function that returns array eliminating the ambiguity with tick arguments. It's ever so slightly more code for the caller, but I think it makes it much more obvious what is happening and makes it future-compatible with any scale's ticks function.\n. That looks good. I think regarding keeping ticks and tickValues in sync, setting tickValues could set ticks to null, and vice versa; you can only have one set. So in your example, if you tickValues([1, 2, 3]), then ticks() would return null. Similarly, if you ticks([10]), then tickValues() would return null.\n. LGTM\n. Hmm, I see what you're getting at now with keeping tickValues.length and tickArguments_[0] in sync. But it seems a bit fishy to assume that tickArguments_[0] is always the count of desired ticks. That's a reasonable default, and that's true of today's scales, but what if you plug in a scale that has different behavior? It seems like you would need to able to set them independently. Which suggests that rather than tickValues setting tickArguments_ to null (and passing tickValues to the tickFormat method), the explicitly-set tickValues would always take priority over the default tickArguments_, if set. If you want to get back to auto-generated ticks, you'd need to tickValues(null) to reset.\n. Merged into v2.8.0.\n. Wow, += is broken in Opera? How is that possible?\n. The return value of += is explicitly defined in ECMAScript, \u00a711.13.2:\n\"\"\"\n5\u0001\u0001. Let r be the result of applying operator @ to lval and rval.\n\u2026\n8\u0001\u0001. Return r.\n\"\"\"\n. So it turns out it's not a bug with +=, the problem is that Opera reorders the statements in the object literal definition. Thus, the endAngle is being computed (and assigned) before the startAngle.\n. Merged in 2.5.0.\n. Is there a way to do this without duplicating the rule definition?\n. Yeah. That's better. A small tweak:\nMakefile\nd3.%: Makefile\n    @rm -f $@\n    cat $(filter %.js,$^) > $@\n    @chmod a-w $@\nI'm also tempted to add:\n``` Makefile\nJS_FILES = \\\n    d3.js \\\n    d3.chart.js \\\n    d3.layout.js \\\n    d3.csv.js \\\n    d3.geo.js \\\n    d3.geom.js \\\n    d3.time.js\nall: \\\n  $(JS_FILES) \\\n  $(JS_FILES:.js=.min.js) \\\n  package.json\n``\n. Can you give me a code example of how you could use this?\n. Superseded by d3.geo.projection center (and rotate), part of the new geo.projection work to be released in 3.0. See #846 for details.\n. Thanks for taking a crack at this! Your implementation looks functionally correct but I think there's a way to optimize it. One possibility might be a sentinel value returned by tween.call(\u2026). If the tween factory returns d3_transitionRemove (= {}), then we remove the attribute and function attrTween(d, i) returns null, so that no tween is run.\n. Awesome, this looks great!\n. Looks good to me. I'm okay with not relying on the return value of removeAttribute; it'd be nice to rely on it, but it's not too much trouble to avoid it.\n. Added missing src/core/mean.js.\n. Excellent!!\n. Looks good!\n. Nice, thank you! I tweaked your implementation a bit to isolate the change to d3_scale_nice.\n. Looks good, thank you!\n. I'm going to cherry-pick that commit rather than risk a force push of my own!\n. Merged in 2.5.0.\n. I think I'll probably rename \"extents\" to \"extent\" for consistency with d3.svg.brush (and org.polymaps.map, long before). It's multi-dimensional, but it's still a single extent. :)\n. Can you give me an example of how the origin feature is used? I don't see it used in any of our existing examples.\n. And a few more questions:\n- Why is the default extent for x & y [Infinity, -Infinity] rather than [-Infinity, Infinity]?\n- Why is the extent set toObjectif the input extent _x_ is null?\n- Do we need to support origin as a function, or would a constant be sufficient (as with extent)?\n. Re-merged to my zoom branch.\n. OK, merged into 2.5.0!\n. Yup, it's in.\n. Merged into 2.5.0.\n. Merged into 2.5.0.\n. Closing to keep the examples in the repo simple, but we'll have lots more interesting examples linked from the gallery.\n. Hmm, I think if something is draggable, you should get the dragstart right away. For example, if you wanted to change the color of a draggable element on mousedown (dragstart), then you'd want to know on mousedown, rather than on the first mousemove. Admittedly, you could do this by listening to mousedown directly\u2026 but I think the convention is that the drag event starts on mousedown, even if it's a trivial (zero-pixel) drag.\n. No, I don't want to support multiple semantics. You can listen to the first move by listening for the first move. :)\n. /cc @jasondavies\n. Fixes #266.\n. Did you read [the documentation for drag.origin](https://github.com/mbostock/d3/wiki/Drag-Behavior#wiki-origin)? The use of the functionObjectas the origin accessor is simply shorthand for the identity function: the data bound to the element is the object withxandy` attributes that specifies the origin.\n. I've edited the documentation to make it more helpful. Sorry for the\nconfusion.\nMike\n. If you use python -m SimpleHTTPServer 8888 & (as explained in the readme), it will generate this for you automatically.\n. Ah, I see; thanks for the explanation. Two downsides, though. One, you have to remember to run it when you add a new example. Two, it creates an auto-generated file, so we have to decide whether to check that file in (and risk it being out of date, like d3.js), or we have to add it to the .gitignore file.\nPersonally, I think it's simpler to just leave the current behavior as-is, even though it's not ideal to click twice. If anything, I'd like to move more of the examples to the main website and have a better gallery. That way, you can see all of the examples without needing to clone the git repo. Though, I think it's definitely nice to include the examples in the master branch for people to use as starting points for their own visualizations.\n. Oops, I already worked on this yesterday. Would you mind checking out my transform branch and comparing my fix to yours?\n. Yeah, I think there are two ways of doing it (either in x or y). I tried your way as part of my exploration but I thought I encountered another bug. We should create a test suite that we can run in the browser, at least, that verifies we are parsing transforms correctly.\nI also based mine on unmatrix.c, btw. It looks like that version flips all scale factors, not just x, because of the for loop and U_SCALEX+i.\nMike\n. The two versions that seemed to work for me involved either flipping x or flipping y, but not both. Not sure what I was doing wrong, though.\n. Bravo. :)\n. This is a beautiful thing.\n. Nice, forgot that one.\n. Merged into order branch and staged for 2.7 release.\n. Hmm. I think jsdom must have to count as a dependency, because you can't use D3 (currently) without also providing a fake browser environment for it to run in. But, it seems safe to exclude vows and uglify-js.\n. Yep, looks good.\n. Looks good. Thank you for adding tests!\n. LGTM\n. Hooray, thanks for doing this!\nI think it would be ever so slightly shorter if you checked for v == null rather than typeof v == \"undefined\", and then you could map both null and undefined to the empty string, rather than null. Sound good?\n. This fails locally. I'm assuming that's because it depends on a version of jsdom that hasn't been released yet? I wonder if we can patch this\u2026\n. What's the visible drawing error? This is what I see:\n\n. Yep, that looks correct. Coincidentally, I fixed this in my talk slides but forgot to push the fix back into master. In parallel someone else also submitted the same fix: #417. I'll integrate both into master and then update gh-pages. Thank you!\n. I'm a fan of parsimony, and I'd rather not introduce a new way of doing something unless there's a substantial benefit. Here are three ways to do the same thing:\njavascript\nd3.max(d3.pluck(data, \"x\"))\nd3.max(data, function(d) { return d.x; })\nd3.max(data.map(function(d) { return d.x; }))\nDespite being the longest to type, I'm leaning towards standardizing on the last approach: it builds on the standard way of mapping data (array.map) rather than having to explain what the accessor function does. And, I'd actually like to change the behavior of d3.min and d3.max so that they return the object (d) rather than the value used for comparison (d.x), making it compatible with Underscore:\njavascript\nd3.max(data, function(d) { return d.x; }).x\nThe pluck approach is even shorter, but it doesn't handle nested objects (such as d.foo.bar), and seems more like a syntax convenience than a visualization primitive. I think, if you really wanted pluck, I'd probably include Underscore. Also, CoffeeScript is a good choice if you really want to make the code as concise as possible. I don't want to duplicate effort with these two projects if I can help it.\nThanks for the request!\n. I noticed you're not handling the case where the operator is called with a function that returns a map. This is one of the reasons why supporting multi-value maps is tricky. Consider the following example:\njavascript\nselection.attr(function(d, i) {\n  var map = {};\n  map[d.name] = d.value;\n  return map;\n});\nThe same could apply to classed, on, transition.attr, etc. So there are actually six versions of attr, as hinted in the comments:\n- attr(object) - set or remove multiple attributes; each value can be null, a function, or other\n- attr(function) - set or remove multiple attributes; the function returns a map of null or other\n- attr(other) - get the specified attribute\n- attr(other, function) - set or remove an attribute; the function returns null or other\n- attr(other, null) - remove an attribute\n- attr(other, other) - set an attribute\nIn the case of \"other\", the value is coerced to a string. This applies to both names and to attribute values.\n. This is promising. However, it is a bit hard to follow because of the indirect nature in which the functions are invoked. For example, setter returns a setter function, while getter returns the value itself. The setter function is then called by each\u2014except in the case of map:function, where it's wrapped. I'm also a little concerned that changing this code path will have a performance penalty, so I'd be interested to measure the impact. (I expect the largest cost will always be rendering, but it's worthwhile to know.)\nI wonder if it's worthwhile to use a different named method for map support. This might avoid some ambiguity. For example, leave the existing implementation as-is:\n- attr(other)\n- attr(other, function)\n- attr(other, other)\nAnd introduce a new attrs method that takes a function or an object:\n- attrs(function)\n- attrs(other) - other is assumed to be an object\nThen, you could replace d3_multimap with something like this:\n``` javascript\nfunction d3_selection_method(setter) {\n  return function(value, opts) {\n// If a function is specified, process each element separately.\nif (typeof value === \"function\") {\n  return this.each(function() {\n    var object = value.apply(this, arguments);\n    for (var name in object) setter(name, object[name], opts).apply(this, arguments);\n  });\n}\n\nfor (var name in value) this.each(setter(name, value[name], opts));\nreturn this;\n\n};\n}\n```\nAnd in selection-attr.js:\n``` javascript\nd3_selectionPrototype.attr = function(name, value) {\n// If no value is specified, return the first value.\n  if (arguments.length < 2) {\n    var node = this.node();\n    name = d3.ns.qualify(name);\n    return name.local\n        ? node.getAttributeNS(name.space, name.local)\n        : node.getAttribute(name);\n  }\nreturn this.each(d3_selection_attr(name, value));\n};\nd3_selectionPrototype.attrs = d3_selection_method(d3_selection_attr);\n```\nI added an opts to d3_selection_method so that you can use it for selection.on and selection.style.\n. I haven't figured out how this will work with transitions, though. With transitions, there's a tweens map per selection. So, if you said transition.attrs(function), you'd have to defer invoking the function until the transition started, per element. Meaning that if you said something like this:\njavascript\ntransition\n    .attrs(function() { return {foo: \"bar\"}; })\n    .attr(\"foo\", \"baz\");\nThen you probably end up transitioning the foo attribute to \"bar\" rather than \"baz\", because you had to defer the invocation of the function until the transition started (so that the function has access to the current value of the attribute, which is needed to create the tween).\nBlah!\n. I have to say, I'm still on the fence as to whether this change is a good idea. It feels quite complicated, there's a performance risk, the benefit seems very small, and it violates the parsimony principle. Another strike against map support is that some browsers (such as opera) don't evaluate literal object properties in the order they are defined, so with attrs the evaluation order of attributes is undefined.\n. Yeah, it's been a long trip. :)\nAnother option is to use filter, which I think it's a bit more declarative and probably more efficient:\n``` javascript\nselection.filter(function(d, i) { return i & 1 == 1; })\n    .attr(\"foo\", 0)\n    .attr(\"bar\", 10);\nselection.filter(function(d, i) { return i & 1 == 0; })\n    .attr(\"foo\", 10)\n    .attr(\"bar\", 0);\n```\nAdmittedly, you have to call filter twice. I'm not sure how to improve on that.\n. @jrus This has not yet been integrated. There were some design issues raised a couple months ago that have not yet been resolved. It's still possible that this will happen, but it's a lot more complicated than it looks to do it consistently across the API. If we figure out the design issues, then this could happen, but it hasn't been my highest priority due to the design challenge, the efficient implementation challenge, and comparatively modest improvement in functionality over today's design.\n. @jrus Thanks, that's helpful input.\n. Folding this into #277.\n. I was wondering if that would improve performance. Looks good!\n. Let's add aliases for d3.svg.mouse and d3.svg.touches for backwards-compatibility. Then we can include this in the upcoming 2.8 release.\n. On second thought, I'm wondering if we should give these the shorter names d3.mouse and d3.touches? That would have parity with d3.event. These aren't behaviors per se (which are relatively high-level interactions), and given that we're bundling them with the core library, and that they're used fairly frequently, I don't see a strong argument against short names.\n. OK, I did some research on getBoundingClientRect:\nhttp://bl.ocks.org/1854471\njs\nvar ox;\nif (\"offsetX\" in d3.event) {\n  ox = d3.event.offsetX;\n  oy = d3.event.offsetY;\n} else {\n  ox = d3.event.layerX;\n  oy = d3.event.layerY;\n}\nox -= this.clientLeft;\noy -= this.clientTop;\n. You're right; my solution is probably buggy on IE9. (I haven't tested.)\nHowever, the only other solution I would think of was traversing the offsetParent chain and subtracting offsetLeft + clientLeft, and that was buggy too. It sucks that such a basic task is still broken in modern browsers.\n. I think it'd be fairly easy to test for that case\u2026 create an offscreen element, dispatch an event, check to see if offsetX includes clientLeft or not, and change the behavior accordingly. Although, I guess Opera is another case too since it uses content box rather than border box.\nAny other ideas?\n. Fascinating. This appears to work correctly even if there is an absolutely-positioned child that is outside of the bounding client rect, so that's good! http://bl.ocks.org/1865422\nThis LGTM if you want to update your pull request!\n. Beautiful! The real test would be a pure-HTML force-directed graph with draggable nodes, now, right? Want to give it a go? :)\n. Wow, I can't believe you got the links working! Too much!\n. Merged into the v2.8.0 branch. Great work, Jason!\n. Sorry, I haven't had time to think about this.\nNot directly related to your needs, but I was thinking the other day that perhaps the Voronoi method should be more like a layout, taking accessor functions to be flexible about the structure of the input. Currently, it assumes that the input is an array of two-element arrays (vertices: [[x1, y1], [x2, y2], \u2026]). Most of the other layouts allow you to define the data in a more flexible way. For example, you might say something like:\njs\nvar voronoi = d3.geom.voronoi()\n    .x(function(d) { return d.x; })\n    .y(function(d) { return d.y; });\nAnd now you'd have a function voronoi that you could pass an array of nodes to (say, from a force-directed layout). Potentially the returned polygons could have meta data associated with them. For example, polygon[i].data could point back to the corresponding input vertex (d) that the polygon contains.\nThat might allow you to annotate the polygon with an array of neighbors, too. polygon[i].neighbors could be an array of input vertices. Or perhaps it should be the neighboring polygons? Or the neighboring indexes? I'm not sure.\nAnyway, I'm pretty sure I don't want to pass in callback functions, because that's more white-box inheritance. Just my quick thoughts. Thanks for the pull request! Let me know what you think.\n. Ah, I see; I misunderstood which data you wanted. Could you elaborate on why you want this data? Perhaps I could suggest a solution better if I understood the application. Thanks!\n. The new d3-voronoi module for 4.0 returns the full Voronoi diagram, so it should be possible to track neighbors and other related operations. See the Voronoi Topology example.\n. Hi @mccannf! Thanks for the examples and glad you're enjoying D3.\nIf you'd like to share your examples with the world, please post them online and link them from the D3 wiki. I find it's easier to view examples if they are online. Plus, I'm trying to keep the bundled examples small so it's easier for me to keep them up-to-date with new releases.\nIf you don't want to host the examples yourself, an easy way of sharing them is to create a GitHub gist with an index.html file; you can take the gist number and view it live on bl.ocks.org. For example: http://bl.ocks.org/1624660\n. Also fixes #452.\n. This is most excellent! Thank you!\nI'll need to move your edit to the source file in src/core/round.js (d3.js is generated), but otherwise, looks good!\n. These are not equivalent. [,] is a sparse array of length one. [] is an empty array (with length zero). Since the value of the array element doesn't matter, a fix would be [0].\n. LGTM\n. Merged into v2.8.0.\n. If you set the previous position to the current position before simulating the forces, you're effectively setting the particle velocities to zero.\nI think you're correct that the previous position isn't being updated correctly because of the way this implementation updates o.x and o.y directly when applying forces. Perhaps the other forces should apply to o.px and o.py (in reverse) rather than to o.x and o.y. Alternatively, we could accumulate the forces in o.fx and o.fy, and then apply them at the end. This is the more common approach; I was trying to be clever by eliminating those extra variables, but that cleverness is introducing the artifacts you've discovered so it's probably premature optimization.\n. Neat, I hope to try this out soon. It looks similar to the commit 5390ac3f853e6f48b4db66dd81e97885bbea530b from a while back. A good test case for stability is one node connected to a hundred other nodes in a star pattern.\n. Hmm. I tried this out, and it looks a lot less stable in the force-directed graph example in the repo (examples/force/force.html). The nodes oscillate more strongly at the beginning and on interaction. That's not to say we can't improve this, but it's going to require further investigation.\n. Closing this, but thank you for the contribution. Please reopen if you can provide a good example of how it improves stability, and I'll take another look!\n. I agree that the accessor should not be applied to the search value x.\nOne thing I was thinking regarding optional arguments was a d3.bisector method, so you could say d3.bisector(accessor)(array, x, lo, hi). Assuming you use the same accessor in multiple places, you could stash the bisector rather than recreating it.\nAnother option would be something like bisect(array[, accessor], x[, lo[, hi]]), which you could disambiguate as long as you don't expect people to bisect an array of functions\u2026 which seems like a relatively safe assumption. In other words, if (typeof arguments[1] === \"function\"), then the second argument is the accessor, and otherwise it's the search value. We do function checking in a number of other places in d3 so this seems reasonable.\nAny preference between these?\n. I did some performance testing at http://jsperf.com/bisect-vs-bisector to see if there would be any performance impact to the non-accessor case. Seems like the impact is minimal. I also compared using closures (the bisector approach) to using an optional accessor: the closure is slightly faster in Chrome, about the same in Safari, and slower in Firefox. I'm somewhat fond of the bisector idea, but I'm perfectly happy with an optional accessor too.\nLGTM\n. Merged into v2.8.0. In the end, I opted for closures!\n. Yeah, I think this is a good idea. In fact, I think defaulting to \"100%\" on both might be reasonable?\n. Ah, hrm, now that I think about it, this isn't quite right, because we need to change the height of the extent rect and the resizers as well. I normally do something like this:\njs\nd3.selectAll(\".brush rect\").attr(\"y\", \"0%\").attr(\"height\", \"100%\");\nBut, the tricky part is we only want to do this for y if x is undefined, and vice versa.\n. And actually, this also doesn't really work because of transforms that are commonly applied to the chart content area. Consider this one:\nhttps://github.com/mbostock/d3/blob/master/examples/brush/brush-y.html#L51-55\nThe margin-left is 40px and the margin-top is 10px, so if we default the brush width to [0%, 100%], that's actually from 40px to 160px. Meaning, it extends off the right edge of the chart. So, we really don't have enough information to determine the appropriate size for a one-dimensional brush. This is why the examples that use the brush do a post-selectAll to set the other dimension:\nhttps://github.com/mbostock/d3/blob/master/examples/brush/brush-y.html#L73-74\nI'm going to close this. But if you think we can come up with a reasonable way of solving this, please reopen!\n. Yay!\n. We use getComputedStyle so that when styles are inherited from a stylesheet, and we can start a transition from those inherited styles. For example, if you say:\ncss\ndiv { background-color: red; }\nThen later, you can d3.select(\"div\") and start a transition to a new background-color. If you look at style.getPropertyValue, it will say that the starting background color of the div is null, so you'll get a transition from opaque black (the interpretation of the color \"null\") to red.\nYou could force people to initialize the color explicitly before the transition, by calling style before starting the transition. Or you could force people to write a custom tween that specifies the starting color. But both of those changes would be pretty inconvenient (and arguably backwards-incompatible).\nRegarding your issues. For # 1, full-page zooming is just broken in WebKit, period. It looks like crap and events have buggy positions. If we can workaround bugs in zooming, that's nice, but given the other issues that remain this doesn't feel like a strong argument (relative to the above concerns). For # 2, the browser doesn't allow subpixel font-sizes or text positions, so even if we were able to determine the right subpixel starting value, I don't think it would improve the appearance of the transition due to rendering limitations. I hope in the future both of these issues are fixed by the browser vendors!\nHope that clears things up. Feel free to reopen if you have other ideas on this topic!\n. Sounds great! I pushed some improvements to my dispatch-chain branch. Take a look and let me know what you think?\n. Merged into v2.8.0.\n. As much as I prefer the 24-hour format, I feel it's best to stick with U.S. convention. If you're interested, a customizable multiscale time format that allows you to override formats for different intervals would be great.\n. Interesting. This reminds me of digital differential analyzers and Bresenham's line algorithm. It's a bit confusing that you can multiply two floats to get an exact integer; would it be possible to convert start, stop and step to integers, and then rescale to floats when calling range.push?\n. Thanks for the contribution! I'm a bit worried about deviating from the \"standard\" strptime and strftime behavior, but I see there's precedent for this in PHP, django, and datejs\u2026 so it may be worthwhile to include.\nAlso, ideally, there's feature parity between formatting and parsing. So, if you add %s to the format, the parser should probably be able to ignore the ordinal suffix when you parse \"Jan 1st\", e.g.\n. This implementation needs to be localized using the new code structure introduced in release 3.4.\nSomeone with knowledge of ordinal indicators in other languages should comment on whether this is a reasonable approach, and if not suggest a different suitable parameterized implementation. (Wikipedia has some information on ordinal indicators; it looks like some languages use prefixes rather than suffixes. At the least we should be capable of supporting FIGS, CJK and Russian.)\nIf having a array of up to ten ordinal suffixes (or prefixes?) is reasonable, then the implementation should also be abbreviated as described in my comment above.\n. I will be working on this for 4.0, over in the d3-time-format repo.\n. Superseded by d3/d3-time-format#10.\n. LGTM\n. Hi @johan. Thanks for contributing. I don't see a strong need to have continuous integration tracking at the moment, since I'm currently the only person with permissions to push to master; maintaining this will only mean extra overhead for me in the short-term. But, I'll keep this in mind in the future!\n. Thanks for the example! I'd prefer to keep the existing example as-is, mostly because I want the example to be as simple as possible (to use as a starting point). This would make a good example for the wiki.\nThough, I'd prefer if you implemented a center constraint (\u00e0 la Polymaps) rather than the stricter visible-area constraint. If you zoom all the way out in your implementation, and then zoom in on a point in Antarctica (for example), then you get temporarily weird zooming due some zoom levels being constrained, but other zoom levels not being constrained. The center constraint has the nice property that it the map's currently-visible center is valid at any zoom level, so it never swims while zooming.\nIf you want to reopen this with a new example file, say, mercator-zoom-constrained.html, and implement the center constraint\u2026 then I would be happy to pull this in!\n. Nicely done! Except, you need to tell the zoom behavior that the translation has changed, or the two get out of sync:\njs\nvar t = d3.event.translate,\n    s = d3.event.scale;\nt[0] = Math.max(-s / 2, Math.min(width + s / 2, t[0]));\nt[1] = Math.max(-s / 2, Math.min(height + s / 2, t[1]));\nzoom.translate(t);\nprojection.translate(t).scale(s);\nTechnically, I've modified the translate array that the zoom behavior gave me (and it's not a defensive copy), so you don't have to call zoom.translate(t); but I'm not sure it's a good idea to rely on this behavior.\n. Merged into v2.8.0.\n. Related #459\n. I understand why the stop event is useful, but what's the use case for the resume event? You're in control of when resume happens, with the exception of the drag behavior which automatically resumes the layout.\nAlso, I was considering the names \"tickstart\", \"tick\" and \"tickend\" (mostly for parity with the brush component, which uses \"brushstart\", \"brush\" and \"brushend\"). On the other hand, \"forcestart\", \"forcemove\" and \"forceend\" are probably better, if I were to pick names from scratch. The old adage: \"There are two hard things in computer science: cache invalidation, naming things, and off-by-one errors.\"\n. I like the names \"start\", \"move\", \"end\". I think we could use those for d3.svg.brush and d3.behavior.drag, too. I was originally thinking of using a prefix for parity with native events such as \"mousemove\" and \"mouseup\", but I think you're right; those prefixes only exist because there are many different types of events from the same source (a DOM element), whereas in this case, the source of the event is sufficient to disambiguate the type.\n. Thanks for the offer, but I'll probably beat you to it. :) I need to figure out whether we can make the new \"move\" name backwards-compatible with the old \"tick\" name. I'm also going to experiment with updating the other components to be consistent (such as d3.svg.brush and d3.behavior.drag). Might as well change everything simultaneously if possible. Of course, if you want to update things and don't mind potential duplication, have at it!\n. Yeah, I'd like to avoid the overhead\u2014the \"tick\" event is fired ~60 times per second.\n. Alright, it's merged. I punted on renaming \"tick\" to \"move\"; we'll just use \"tick\" for now. But we are using \"start\" and \"end\" for the new events. I also changed it so that setting the alpha property will automatically resume or stop the simulation as appropriate. So now resume and stop are simply aliases for setting the alpha to .1 and 0, respectively. Thanks for your help!\n. Yes!\n. Awesome! Thanks for this. Any chance you feel like merging it with the decorative-brush-resizers branch?\nAnother interpretation for two fingers is to select everything between the two fingers (replacing the current selection). The Stocks App on iOS does this.\n. Thanks. I think it just ignores the third finger. :)\n. Merged into decorative-brush-resizers.\n. Merged into v2.8.0.\n. Neat. I think we'd need to update d3.interpolators as well, so that it can detect HSV colors and interpolate them automatically. You'd probably also want a d3.interpolateHsv method.\n. With some help from @brewmook, I\u2019ve created the d3-hsv module. Should be easy to implement d3.interpolateHsv and d3.interpolateHsvLong there, too.\n. Great find. I was thinking it would be simpler to use Object.create(null) rather than hasOwnProperty, but I guess there are two reasons not to: Object.create is newer than object.hasOwnProperty, so it might be less supported? And, \"__proto__\" in Object.create(null) is still true. :disappointed:\n. OK, I think I have an idea of how to make this correct (as you've done) but without Object.hasOwnProperty.call everywhere. I think we should write our own d3_map class that supports has, get, set, and keys methods. The constructor can take an object as input, and copy all the values into the map using a for\u2026in loop. Something like this:\n``` js\nfunction d3_map(object) {\n  var map = new d3_Map();\n  for (var key in object) map.set(key, object[key]);\n  return map;\n}\nvar d3_map_prefix = \"-\"; // prevent collision with built-ins\nd3_Map.prototype.has = function(key) {\n  return d3_map_prefix + key in this;\n};\nd3_Map.prototype.get = function(key) {\n  return this[d3_map_prefix + key];\n};\nd3_Map.prototype.set = function(key, value) {\n  this[d3_map_prefix + key] = value;\n};\n```\nOK, that's a rough stab at the idea. Need to investigate whether it will work, still. We might want to plug in ES6's Map class if it's available.\n. Pushed to builtin-properties branch. Take a look?\n. I was thinking of using d3.map to create d3_nsPrefix and d3_rgb_names by wrapping them, and then using d3_nsPrefix.has(key) rather than key in d3_nsPrefix, etc.\n. Although, now that you mention it, d3_nsPrefix is public, so that would be a non-backwards-compatible change. Phooey!\n. Hmm, so stick with d3_nsPrefix.hasOwnProperty, and use d3.map for everything else?\n. Superseded by #520.\n. I normally implement custom forces using the \"tick\" event listener. It might be nice to make the registration of the built-in forces optional, or have some modular way of reusing custom forces (e.g., multiple gravity forces). But we have to be careful to keep the default configuration fast.\n. Closing because I'd prefer to stick with the current approach of using custom forces in the \"tick\" listener (which allows complete generality). However, a mechanism of registering and unregistering forces, and perhaps some standard reusable forces (like \"gravity\" and \"charge\") might be nice.\n. Found another one: d3.rgb(\"hasOwnProperty\") returns {r: undefined, g: undefined, b: undefined} rather than {r: 0, g: 0, b: 0}. Fixing it!\n. Also found a similar problem with d3_svg_symbols.\n. Rule of thumb:\n- If the names come externally, we should use d3.map.\n- If the names are set internally, and are \"reasonable\", we can simply use hasOwnProperty.\nHigh-priority concerns:\n- d3.scale.ordinal doesn't deal well with built-ins, since it assumes that they are always in the domain. It needs to use a d3.map internally.\n- The fix for d3.interpolateObject introduces overhead, and only fixes the extremely unlikely scenario of interpolating enumerable properties in a, and inherited non-enumerable properties in b (or vice versa). I am tempted to remove the use of d3.map here, as the only situation where it would help is if you were interpolating between, say, {hasOwnProperty: 1} to {}; arguably, the original behavior might be considered correct, given the ambiguity.\n- d3.dispatch's internal listenerByName should use d3.map, in case you register an event such as \"mouseover.hasOwnProperty\".\n- d3.transition tween registry should use d3.map. It has bad behavior if you try to register a tween called \"__proto__\".\nMedium-priority concerns:\n- d3_ease and d3_ease_mode should use hasOwnProperty, since this could allow execution of strange code (e.g., interpolate(\"hasOwnProperty-defineProperty\")).\n- d3_geo_type should use hasOwnProperty. Affects d3.geo.circle.clip, d3.geo.path, d3.geo.path.area.\n- d3.layout.stack should use hasOwnProperty. Affects offset and order.\n- d3.svg.line should use hasOwnProperty. Affects interpolation for both lines and areas (d3_svg_lineInterpolators).\n- d3_time_monthAbbrevLookup, d3_time_monthLookup and d3_time_amPmLookup should use hasOwnProperty.\n- d3_format_types should use hasOwnProperty.\nLow-priority concerns:\n- d3_selectionPrototype.on is relatively safe because names are prefixed by \"__on\". But, it would be safer to use the prefix \"\\0\".\nThings we just have to live with:\n- d3.dispatch has bad behavior if you try to register the event type \"__proto__\". I don't think we care, and there's nothing we could do to fix this that would be backwards-compatible.\n. I have resolved all the high- and medium-priority, and will leave selection.on and d3.dispatch as-is, for simplicity's sake.\n. The diff LGTM.\nRe. d3.selection.extend, did you mean to extend the selection prototype or d3.selection (as in, for static methods)? Either way, I'm not sure an explicit method is needed, as you can easily assign to the d3.selection.prototype, as appropriate. I suppose it'd be possible for the d3.selection.prototype to inherit from d3.selection.enter.prototype, so you'd only need to assign to one\u2026 but that feels a little weird to me at the moment.\n. Merged into v2.8.0.\n. See discussion in #520.\n. Merged into 2.8.0.\n. If you keep the original code structure, but add new lines and one-line comments between each block, describing what each does, I'll take your pull request. ;)\n. Works fine for me:\n``` js\n\nd3.csv.parse(\"%foo,%bar\\n1,2\\n\")\n[ { '%foo': '1',\n    '%bar': '2' } ]\n```\n\nI'm guessing your problem is elsewhere. You can't use the column name __proto__, but that should be about the only restriction. Can you give me a reproducible test case?\n. Replaced by #573.\n. Related #400 #492\n. The problem with your alternative is: how would the subtransition (tick.exit().transition) know the corresponding element from g to inherit from? You need the context anyway.\n. @eparejatobes Nope, sorry.\n.  One potential issue is the the likelihood of collision between the node\u2019s internal value and the node\u2019s aggregate value computed by the layout. Currently that aggregate value is stored back as node.value after being computed, so using function(node) { return node.value; } as the internal value property accessor would overwrite the internal value with the aggregate value, and thereby cause problems if the layout was computed multiple times on the same input dataset.\nAn alternative solution for this problem is to use dummy nodes that are present in the dataset but not displayed. These dummy nodes are a child of the node with an internal value, have no children themselves, and are marked (e.g., node.dummy is true) so that they can be ignored during rendering.\n. The reason value is used is for simplicity\u2014you can refer to a leaf\u2019s value and an internal node\u2019s aggregate value the same way. I prefer not to come up with a new name if I can avoid it. :)\nUsing value doesn\u2019t prevent nodes from having an internal value, but it does require that the internal value be stored on a differently-named property than the computed aggregate value. This is not an issue when only leaf nodes have values because the two are identical.\nFor example, if you defined the value as function(d) { return d.size; }, as in the examples, then value refers to the computed aggregate value and size returns to the internal value. Or you could use nodeValue or internalValue if you prefer something more explicit. For that matter you could use function(d) { return +d; } and then have nodes implement object.valueOf.\n. This has been implemented in d3-hierarchy for 4.0!\n. Nice work, and thank for you the contribution!\nRelated #183 - d3.lab\nRelated #517 - d3.hsv\nRelated https://github.com/jrus/chromatist\nDo you have any recommendation as to how to choose between XYZ, CIE Lab or CIE LCh? Is there a pressing need for all three, or did you include them for completeness' sake? My main reservation here is feature creep. Still, given the interest I could be convinced of the usefulness of including at least one perceptually-based colorspace in core. (Probably CIE Lab?) The other colorspaces are useful, but I wonder if it might be better to have a d3-chromatist plugin that adds additional colorspaces on demand?\nImplementation comment: if we have more than two color spaces, then having methods on every color space to convert to every other color space probably won't scale. Fortunately, it's also unnecessary because all of them must support a toString() method that returns the \"#rrggbb\" format (for browser compatibility); as long as all the constructors support parsing the same format and converting to the respective colorspace, then we only have to deal with conversion to and from RGB. \nSo, we shouldn't remove the existing methods for backwards-compatibility, but you should only have to implement an rgb() and a toString() method on the new colorspaces, and leave the conversion to the constructors. For example, to go from xyz to lab, you might say myLab = d3.lab(myXyz) rather than myLab = myXyz.lab().\n/cc @jrus @jheer @alex\n. Would you be interested in exposing this as a D3 plugin? I've created a repository at d3/d3-plugins, and I could give you push access to submit your code there. To help you get started, I made some scaffolding of a d3.cie plugin to show you what I was imagining; you're of course welcome to propose an alternative structure, but I think it could fit in nicely.\n. Great! I just gave you push privileges. Let me know if you want a hand.\n. I combined your code with @jheer's earlier implementation of Lab color and it is now available as the d3.cie plugin. Here's an example demonstrating Lab and LCH interpolation.\nIf you want to make any edits, go ahead, you have the powah!\n. Looks good.\n. Merged into #594.\n. Thanks for this fix!\n. This is intentional, because those parameters are related. In what way does it display poorly?\n. Yeah, I'm okay with that. Maybe now there's a better replacement for the jQuery UI slider? It's a bit long in the teeth.\n. Makes sense. JSDOM is still a bit underpowered for SVG, so I'd be mostly imagining using the non-DOM stuff within Node (such as d3.time.format, or a d3.layout). But I don't see much harm in including Sizzle.\n. Staged in #606 for 2.9.0.\n. Seems like we should set this in all cases, not just if a mime-type is specified?\n. Staged in #606 for 2.9.0.\n. When you say \"may\", does this mean that X-Requested-With breaks all cross-origin requests that have Access-Control-Allow-Origin: *, but no Access-Control-Allow-Headers? If that's the case, we should pull this change from 2.9.0 and only enable it optionally.\n. Never! JSONP is evil.\n. \n. I still want the ability to set arbitrary headers on requests. That would allow you to set X-Requested-With if necessary, without it interfering by default.\n. That pointer-events all is needed for the invisible resizers (on the four sides of the extent). Is IE9 not inheriting pointer-events: all from the parent g?\n. I don't understand why this is necessary for the background but not the resizers. Shouldn't they behave the same way? They're both fill: none, visibility: hidden rects.\n. Display: none on the background while dragging? Yeah, that sounds good.\n. OK, looks good. :) IE9, I am disappoint.\n. Staged in #606 for 2.9.0.\n. Fixes #583.\n. This approach has a bug, which is that it doesn't preserve the index (i) of the original data. I need to change the implementation slightly, and probably not use d3.split.\n. Staged in #606 for 2.9.0.\n. Thank you for investigating this. However, I think it's appropriate for d3.ascending to return NaN if the inputs cannot be ordered, as is the case with undefined or NaN. The correct place to handle this would be in an alternative sorting routine that handles NaN specially. The behavior of d3.ascending should be equivalent to:\njs\n[1, 5, NaN, 3, 2].sort(function(a, b) { return a - b; })\nwhich also returns [1, 5, NaN, 3, 2].\n. Thanks for this fix!\n. Looks good.\n. Staged in #606 for 2.9.0.\n. Hmm. I'm not sure this is a good idea; the brush makes more sense with quantitative scales. There's an example using a brush with an ordinal scale, but normally I think of toggling individual values rather than selecting a range.\n. Yep, thanks!\n. Staged in #606 for 2.9.0.\n. Staged in #606 for 2.9.0.\n. Staged in #606 for 2.9.0.\n. Staged in #606 for 2.9.0.\n. Many thanks!\n. Staged in #606 for 2.9.0.\n. Thanks for doing this. This may seem trivial, but I would prefer it to match the convention in the issue description exactly. So, width and height instead of innerWidth and innerHeight. Likewise, for multi-line statements, I always break them out into separate blocks. For example:\n``` js\nvar x = d3.scale.linear()\n    .domain([.05, .95])\n    .range([0, width]);\nvar y = d3.scale.linear()\n    .range([height, 0]);\n```\nI find this easier to read than using two levels of indentation with a var list. Thanks!\n. Wowsa. That's a lot of fixes! Thank you.\n. What about unregistering the events after applying the zoom behavior? For example, you can disable touch and double-click events like so:\n``` js\nvar zoom = d3.behavior.zoom()\n    .translate(projection.translate())\n    .scale(projection.scale())\n    .scaleExtent([100, 800])\n    .on(\"zoom\", zoommove);\nvar svg = d3.select(\"body\").append(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .call(zoom)\n    .on(\"dblclick.zoom\", null)\n    .on(\"touchstart.zoom\", null);\n```\n. It's a bit of a hack, but another option is to have two zoom behaviors on nested  elements:\nxml\n<g class=\"scale\">\n  <g class=\"translate\">\n  </g>\n</g>\nThen you bind an inner zoom behavior and an outer zoom behavior, and delete the event listeners as needed. The stop propagation should allow you to use both zoom behaviors independently.\nBut really I think the simpler solution here is to add a flag to the zoom behavior that says whether mousewheel zooming should zoom on the origin or zoom on the mouse location. I'd support that change. In fact, I implemented exactly that feature for Polymaps; see Wheel.js.\n. Superseded by #1352.\n. It annoys me to have browser-specific workarounds sprinkled throughout the code, so I'm going to close this and wait until I hear more complaints. In the meantime, hopefully people will upgrade to IE10. ;)\n. I think we should delete the make install rule entirely. That only existed because older versions of NPM installed into a global node_modules directory if you forgot to create a local one. Now that npm install does the right thing, we shouldn't duplicate it in the Makefile. (That's why I recently changed the Wiki to recommend npm install instead of make install.)\nI like the change to src/package.js, though! Much simpler.\n. It was named make install for parity with npm install. I don't want two ways of doing something. People should just use npm install directly, as is standard practice with every other node module.\n. Hmm, I'm not sure this is a good idea. Wouldn't a stacked bar chart be a better way of comparing the entities' ratios? Grouping things by curved paths is a fairly weak association compared to proximity (gestalt). Also, there's a lot of duplicate code here, so I think it would be a lot of work to merge this in. It'd be better to release this as a standalone plugin.\n. @Nathanaela is correct, and I apologize for not realizing this sooner. The current implementation of the pack layout is operating as intended, in that the leaf nodes are comparable but the internal nodes are not. I misspoke in the documentation when I described the intended behavior. If you want to compare across levels of the hierarchy, a treemap is probably the better choice (though padding introduces the same distortion).\nIt would be possible to have children of the same depth comparable, rather than designing for leaf nodes to be comparable. But this would need to be a configurable option, as it necessarily prevents accurate comparison of leaf nodes. \n. Hi Ger,\nThanks for the pull request, but I'd prefer to leave the code as-is.\nMike\n. When you say \"causing issues\", what do you mean? Couldn't a custom line generator also handle the case where the array has a single element? If you're going to check if the start and end are the same in a custom interpolator, couldn't you more easily check if the input array has length one?\nOn the other hand, if we think of links as [start, middle*, end], then it does make sense that bundle should return [start, end] when start and end are the same node.\n. Oh, that's interesting. I'd love to see what that looks like.\n. Actually I think that works pretty well. And arguably, you can't be your own ancestor, so the least common ancestor of foo and foo is foo.parent. The alternative would be to not show self-loops, or show self-loops as a generic circle. I like the idea of showing self-loops (if you don't want them, then filter them from your data). And showing self-loops as circles would likely require additional parameterization (the radius of the circle). So I like this approach. What do you think?\n. It's obvious now, but I didn't realize you'd have to synthesize an additional control point to create a loop. I was thinking somehow the interpolator would automatically create a loop by having the appropriate tangents, but of course it doesn't work that way with basis interpolation.\nI like what this code is trying to do, but it feels like too special a case, and the synthesized control point is arbitrary. I'm tempted to go back to #642 as the simplest correct solution. What do you think? Is this worth it? Is this appropriately general? Should there be a way to configure the behavior?\nAlso, I looked at Wikipedia's definition of lowest common ancestor, and it disagrees with my earlier statement (\"arguably, you can't be your own ancestor, so the least common ancestor of foo and foo is foo.parent\").\n. OK, then inverting the open state of these two requests. :)\n. Ha, I made the same exact change earlier today. :) Thanks, though!\n. Yeah, this looks good.\n. I think this is replaced by #640?\n. Thanks.\n. If the data is bad, then the code should fail. It's too much work to consider all of the ways that data could be bad. Instead, we document what's expected of the data, and fail if those expectations are not met.\n. Please see #277.\n. Looks good!\n. Looks good.\n. This is needed for IE8 and below, correct? Because IE9 shouldn't need Sizzle.\n. Merged into 2.9.3.\n. My beef with this is that modern browsers pay a cost to support older browsers. That cost is probably negligible, but creating elements is something that happens fairly often. I prefer the shim approach:\njs\nif (!document.createElementNS) document.createElementNS = function(uri, name) {\n  return document.createElement(name);\n};\nWhy do you consider this overkill? It centralizes the patch, it's faster for modern browsers, and it's less code.\n. Yes, that's the cost. I don't know if document.createElement is faster than document.createElementNS, but if it is, that might swing my opinion the other way. Let me know! :)\n. I'm in favor of the shim. I don't like having to write code that knows about old browsers.\nIf you want to reopen with a shim that works in IE8, let me know. I'd also be grateful if you could look into the CSSStyleDeclaration issue. People seem to get errors on that being undefined, but at the same time, other people are suggesting extending it's prototype to support IE8. So I don't know what to fix.\n. Excellent, I'll add a link to Aight (hilarious) from the wiki.\n. Can you run make test and add the generated files to this pull request?\n. FYI, functionality similar to that proposed here is planned for D3 4.0 in d3-force. I\u2019m planning on exposing simulation.alphaDecay which sets the exponential decay constant such that the alpha for tick i is equal to e^(-lambda * i) where lambda is the decay constant. This is a bit more precise than multiplying the alpha value every iteration. There\u2019s also a simulation.alphaMin threshold to determine when the force layout stops iterating.\nSorry that it took me a few years! Related d3/d3-force#5.\n. Related #675\n. Merged into #683.\n. Fixes #661.\n. This would make an excellent d3 plugin. Would you mind adding it here?\nhttps://github.com/d3/d3-plugins\n. Merged into #756; staged for 2.10.0.\n. Merged into #756; staged for 2.10.0.\n. Merged into #756; staged for 2.10.0.\n. Merged into #756; staged for 2.10.0.\n. Duplicate of #592, which was reverted.\n. Ah, excellent work! I verified that this fixed the bug in a variety of spinning examples. :)\nIt seems like in the case where none of the points are clipped, this introduces a duplicate point at the end? Is that correct? (I haven't verified.) That would be harmless but it might be nice to avoid.\nI think the next part will be to decouple clipping from resampling. This way, we can do the resampling once up-front rather than after clipping. Alternatively, we could introduce different clipping modes that allow you to customize the resampling behavior (no resampling, resample all, resample only clipped paths). But that's a separate feature request.\nThanks for the prompt fix!\n. I think I found another bug. Here's the example: http://bl.ocks.org/3034693\nThe horizontal arc is drawn twice. If you change the origin's latitude to -40\u00ba (which should be equivalent), the horizontal arc is only drawn once. The path when there is a bug (prior to resampling) is:\n\n-180,0 -175,0 -170,0 -165,0 -161.04331008999756,0 18.98280503795921,0 20,0 25,0 30,0 35,0 40,0 45,0 50,0 55,0 60,0 65,0 70,0 75,0 80,0 85,0 90,0 95,0 100,0 105,0 110,0 115,0 120,0 125,0 130,0 135,0 140,0 145,0 150,0 155,0 160,0 165,0 170,0 175,0 180,0 \n\nThe path without the bug:\n\n-161.01719496204078,0 -160,0 -155,0 -150,0 -145,0 -140,0 -135,0 -130,0 -125,0 -120,0 -115,0 -110,0 -105,0 -100,0 -95,0 -90,0 -85,0 -80,0 -75,0 -70,0 -65,0 -60,0 -55,0 -50,0 -45,0 -40,0 -35,0 -30,0 -25,0 -20,0 -15,0 -10,0 -5,0 0,0 5,0 10,0 15,0 18.956689910002417,0 \n\nSo, as you can see, in the first case the path is being drawn from -180\u00ba to 180\u00ba, which means it's not being clipped correctly. I think this is the case where the line needs to be split into two segments.\n. Actually, this brings up a related question, and I'm not sure this is fixable. If you have a set of coordinates in a Polygon that represents the equator, does that fill the northern hemisphere or the southern hemisphere? I'm not actually sure what the correct behavior is here.\n. Folded into #696.\n. Yeah, I think there's more thought needed here as to what the desired behavior is. I haven't thought about it too much yet, so be careful I don't lead you down the wrong path!\n. /cc @jasondavies \nFirst cut at a slight optimization to clipping in 54b0dcb. Let me know what you think. Still thinking about resampling.\n. Agreed; the default behavior (and perhaps the only behavior) for Polygons should be to resample only the clipped edges. For LineStrings, we should break into a MultiLineString as necessary. Points are already handled separately by using a distance filter rather than clipping.\n. @logical42 The clipping code is in src/geo/circle.js.\n. Merged into #733.\n. Merged into #733.\n. Looks good.\n. Merged into #733.\n. Great examples!\n. This seems significantly more sane than JavaScript, though it might not strictly be considered backwards-compatible. Still, probably a reasonably safe change to include.\n. Although, I will point out that my code would work better in the year 3000.\n. Merged into #712.\n. Merged into #733.\n. Merged into #733.\n. Seems reasonable.\n. Merged into #733.\n. Looks good.\n. Pretty sure that since we know cv is a string, we can say if (cv) rather than if (cv.length).\n. Merged into #733.\n. Wise. Looks good.\n. Merged into #733.\n. Append returns the added nodes; your implementation returns the parent nodes. Also, you can implement this functionality already using select(function). For example:\njs\nselection.select(function(d, i) {\n  return this.appendChild(\u2026);\n});\nOr as part of the core library:\n``` diff\ndiff --git a/src/core/selection-append.js b/src/core/selection-append.js\nindex 1c57da1..4a1dc20 100644\n--- a/src/core/selection-append.js\n+++ b/src/core/selection-append.js\n@@ -1,7 +1,5 @@\n // TODO append(node)?\n-// TODO append(function)?\n d3_selectionPrototype.append = function(name) {\n-  name = d3.ns.qualify(name);\nfunction append() {\n     return this.appendChild(document.createElementNS(this.namespaceURI, name));\n@@ -11,5 +9,11 @@ d3_selectionPrototype.append = function(name) {\n     return this.appendChild(document.createElementNS(name.space, name.local));\n   }\n\nreturn this.select(name.local ? appendNS : append);\nfunction appendFunction() {\nreturn this.appendChild(name.apply(this, arguments));\n}\n+\nreturn this.select(typeof name === \"function\" ? appendFunction\n: ((name = d3.ns.qualify(name)).local ? appendNS\n: append));\n };\n```\n\nYou haven't said why you want this functionality, so I'd err on the side of leaving it out. If you want to argue for this being useful, feel free to reopen.\nRelated #4 #311 \n. Can we do this without adding new public methods to d3.transform?\n. This still changes the behavior of d3.transform, though, right? Because now it has a \"transforms\" array rather than implicitly decomposing the transform? Perhaps the first step should be to create an array of transforms, and the second step to decompose it into a single d3.transform. That way we can make this change without affecting the public API.\n. This has a bug where it no longer supports shortest-path interpolation for rotations. For example, d3.interpolateTransform(\"rotate(-170)\", \"rotate(170)\") goes the long way around.\n. Merged into #733. If you want to help with the fix, please submit a pull request for the 2.9.7 branch. Thanks!\n. I'm actually not totally sure now whether we want to use the shortest-path interpolate for same-type transitions. Do you think the transition from \"rotate(0)\" to \"rotate(360)\" should be a no-op, or should it spin around? On the other hand, it'd be a shame for the behavior to be inconsistent (e.g., \"rotate(0)\" to \"rotate(360)translate(0,0)\" doesn't spin because the two transforms are not the similar).\n. OK, I'll revert the shortest path check when using same-type transforms.\n. Forgot to add transition-filter.js? :)\nAlso, take a look at transition-select.js for inspiration. You should be able to say:\njs\nreturn d3_transition(subgroups, this.id, this.time).ease(this.ease());\n. Does this work? Sorry for the blunt question, but there aren't any tests. :) Looking at the code, I think it wouldn't because transitions are arrays of {node, delay, duration} objects, whereas selections are arrays of nodes. Ignoring DRY for a second, I think this is what you want:\n``` js\nd3_transitionPrototype.filter = function(filter) {\n  var subgroups = [],\n      subgroup,\n      group,\n      node;\nif (typeof filter !== \"function\") filter = d3_selection_filter(filter);\nfor (var j = -1, m = this.length; ++j < m;) {\n    subgroups.push(subgroup = []);\n    for (var group = this[j], i = -1, n = group.length; ++i < n;) {\n      if ((node = group[i]) && filter.call(node.node, node.node.data, i)) {\n        subgroup.push(node);\n      }\n    }\n  }\nreturn d3_transition(subgroups, this.id, this.time).ease(this.ease());\n};\n```\nSo, a few differences from selection.filter:\n- filter.call(node.node, node.node.__data__, i)\n- not populating subgroup.parentNode (since transitions don't support append)\n- propagating the id, time and easing to the filtered transition\nIf we were really clever, there'd probably be some way to reuse code slightly. (Perhaps using d3_selection_each, or perhaps by wrapping the filter function passed to d3_selectionPrototype.filter to adapt it for transition filtering.) But maybe it's clearer to have two different implementations?\n. Merged into #733.\n. Merged into #733.\n. I\u2019d prefer using timezone strings; the names are standardized by IANA and used fairly widely.\n. Alright, that's fair. Thanks for the extra effort! :)\n. Hmm, the new dayOfYear-test fails because it still says \"America/Santiago\", and I'm not sure what the correct offset is. -240?\n. Merged into #733.\n. Nice. Thank you for this! Would you mind fixing a couple things?\n- dp is an undeclared variable; you can add it to the var list.\n- Rather than editing the generated file, edit src/svg/line.js and then run make all tests to verify your change.\n. Taking care of a newborn, so I might not be especially prompt on the review. The code looks fine but I need to walk through the math.\n. I reverted your improvement to the algorithm because it can cause the curve to go backwards. See this example: http://bl.ocks.org/3310187 However, I've integrated your other fix, so thank you! If you can think of a different way to preserve monotonicity and local maxima / minima without this side-effect, let me know.\n. Merged into #756 for 2.10.0.\n. Related #4 #311 #724\n. I'd like to see more discussion about how this would be used.\n. Seems like selection.clone(node) would be a closer fit to what you want, so as to support templating. But even then, you might want selection.appendClone and selection.insertClone, or at least allow an optional argument to selection.clone(node, before) (essentially making clone equivalent to insertClone).\nI'm hesitant to allow selection.append(function), since there's no convenient way to use it\u2014your function gets called multiple times, so you need to carefully return the correct node each time the function is called. A selection.clone(node) method is safer since it can create new nodes for you automatically. Though there's still the awkwardness that you need to specify a reference to the node to clone (perhaps var node = d3.select(selector).remove().node()).\nAnother possibility might be selection.clone(selector). For example, say you had some HTML:\nhtml\n<ul>\n  <li class=\"template\">\n    <span class=\"price\"></span>\n    <span class=\"index\"></span>\n  </li>\n</ul>\nYou might say:\njs\nvar item = d3.select(\"ul\").selectAll(\".item\").data(items).enter().clone(\".template\");\nitem.select(\".price\").text(\u2026);\nitem.select(\".index\").text(\u2026);\nSo, the node matching the selector \".template\" is first removed from the DOM, and then clones are appended for each element in the enter selection. Here's how you could extend the enter prototype to do that:\njs\nd3.selection.enter.prototype.clone = function(selector) {\n  var template, parent;\n  return this.select(function() {\n    if (parent !== this) template = d3.select(parent = this).select(selector).remove().node();\n    return this.appendChild(template.cloneNode(true));\n  });\n};\nThis isn't perfect because the original selector \".item\" doesn't match the template selector \".template\"; you'd want to remove the \"template\" class and add the \"item\" class. It'd be better to use \".item\" as the selector for both, but then the first datum will match the template node and end up in the update selection rather than the enter selection, throwing the whole thing off. I suppose selectAll(\".item:not(.template)\") would work, but that's fairly awkward (and all the cloned nodes will still have the class \"template\").\nNote that you can pretty much do this already using enter.select:\n``` js\nvar item = d3.select(\"ul\").selectAll(\".item\").data(items).enter().select(clone(\".template\"));\nitem.select(\".price\").text(\u2026);\nitem.select(\".index\").text(\u2026);\nfunction clone(template) {\n  template = d3.select(template).remove().node();\n  return function() {\n    return this.appendChild(template.cloneNode(true));\n  };\n}\n```\nHere \".template\" is found globally, though the better solution (as in selection.clone) would only select within the each group's parentNode, i.e., within the previously-selected UL element.\n. You\u2019re correct that many methods in D3 accept both constants and functions are arguments. When a function is accepted, its return value is typically the same type as the accepted constant. For example, with selection.attr(name, value), the value can be specified as a string or a function that returns a string (computing the value from data).\nNote, however, that the attribute name cannot be specified as a function. This would be possible to implement, but I think there is a practical limit to what should be defined as a function. While restrictive, it is rare that you would need to compute the attribute name dynamically, as commonly only attribute values need to be computed from data. It is for the same reason that selection.append and selection.insert accept only strings rather than functions that return strings; it is rare that you need to compute the element name dynamically.\nThat selection.select and selection.selectAll also accept a function is somewhat of a special-case to allow extensibility. I would guess that most people don\u2019t know that these methods accept functions, since they are almost always used with selector strings; so, I disagree that most people are genuinely surprised that selection.append and selection.insert do not accept functions.\nStrictly speaking, if you wanted selection.select and selection.selectAll to be consistent with other function usage in D3, the input function should return a string (the selector string computed dynamically from data) rather than a node or an array of nodes. But this would make them significantly less powerful for extension; for example, you could no longer select via XPath functions. You could allow both types of return values and use type inference to determine whether the function returned a string or a node, but that introduces complexity and a performance cost; furthermore, I don't see computing a selector dynamically especially useful. I definitely want to preserve selection.select and selection.selectAll accepting functions that return nodes because this provides a fantastic building block (or escape-hatch, if you will) for extensibility.\nSo, should selection.append and selection.insert accept a function that returns a string? I would say no, for the same reason that the name passed to selection.attr need not be a function that returns a string. But should selection.append and selection.insert accept a function that returns a raw node? That seems more plausible to me\u2014which is why there has been a long-standing TODO comment to this effect. Though I\u2019m not totally convinced that such functionality is significantly more useful than passing a function to selection.select. And while you are correct that most people wouldn\u2019t think of using selection.select to select elements that are created (or appended) dynamically, this seems like a power feature anyway, so I\u2019m less worried about minimizing surprise. (Plus, it might be empowering to teach people that selection.append and selection.insert are thin wrappers on top of selection.select.)\nIt seems moderately useful and consistent to allow the before argument for selection.insert to be a function which returns a node (probably using d3_selection_selector). I expect this has a performance cost for the common case where the before argument is a selector string, but it\u2019s probably negligible.\n. You can append bare nodes, but you have to pass a function to selection.select or selection.each, basically dropping down to the DOM API. For example:\n``` js\nvar node = document.createElement(\"span\");\nd3.select(\"body\").select(function() { return this.appendChild(node); });\n```\nYou could also use selection.each, of course:\njs\nd3.select(\"body\")\n    .each(function() { this.appendChild(document.createElement(\"h1\")); })\n    .each(function() { this.appendChild(document.createElement(\"span\")); });\nOne issue with append taking a function is whether this function should return a string (representing the name of the node to create, such as \"span\" or \"g\") or a node, or both. For selection.select(function), the function must return a node (not a selector string; that could be supported, but I think it would be rarely used).\nAlso, selection.select(node) or selection.append(node) only works when the selection has a single element, so I don\u2019t think this is appropriate to add to the API.\n. The append behavior you describe is nearly identical to selection.select(function). The only difference is that with selection.select, you also have to append the node yourself (not just create it).\n. Superseded by #1354.\n. Released.\n. Thanks for the contribution. We're still hashing out the API, so I'm going to close this to consolidate the discussion. See #732 (and #4 #311 #724).\n. Append and insert will be consistent, so whatever we decide for append will also apply to insert.\n. Merged into #733. I modified the code slightly so as to better encapsulate the special case of interpolating from or to \"none\":\njs\nfunction d3_interpolateTransformIdentity(a) {\n  return {\n    getItem: function(i) {\n      return {\n        type: a.getItem(i).type,\n        angle: 0,\n        matrix: d3_transformIdentity\n      };\n    }\n  };\n}\nThis eliminates the need for a swap flag.\n. I don't understand the rationale described in the html5rocks article. I can see this being useful if you want to measure short durations (e.g., page load performance). I can maybe see this being useful to avoid temporal aliasing during animations, but I can't imagine it's noticeable in practice. Are there any live demonstrations of this being useful?\n. Closing this for now, but if we have a good demo of how this improves animation, or if this has broader browser support we can add it back.\n. Merged into #743.\n. Interesting; that seems inconsistent with the specification, which says:\n\nThe operation represents the equivalent of the following specification: translate(cx, cy) rotate(rotate-angle) translate(-cx, -cy).\n\nSo I would have thought that \"rotate(0 1,2)\" would have been transformed into \"translate(1,2)rotate(0)translate(-1,-2)\". To which we could then apply the normal rules. But the SVGTransformList would need to be expanded for us.\n. Merged into #743.\n. Merged into #756; staged for 2.10.0.\n. Funny, I implemented this about a year ago, but unfortunately I\u2019ve lost the commit now. It's a tempting feature.\nIf we include it, it probably makes sense to just have this be the default behavior for enter.append; I don\u2019t think there\u2019s enough weight to merit two separate methods. The performance cost looks negligible.\nThe big negative is that there is no guarantee (even with this change) that the resulting enter+update selection is in order: that\u2019s because the update selection may not be in order if a key function was used to compute the data join. Hence the need for selection.order, which guarantees that the order of elements will match the data.\nI\u2019ll also point out that selection.order is efficient; if the selection is mostly in-order, it does very little work. So typically the performance cost of using selection.order is negligible. Has that been the case in your experience, or if not, could you provide numbers and test cases to guide this discussion?\n. Here\u2019s a simple example to illustrate how insertInOrder won\u2019t guarantee the correct order if the updating elements change order. Let\u2019s say this is our general update pattern:\n``` js\nfunction update(fruits) {\n  var fruit = d3.select(\"body\").selectAll(\".fruit\")\n      .data(fruits, function(d) { return d; });\nfruit.exit().remove();\nfruit.enter().insertInOrder(\"div\")\n      .attr(\"class\", \"fruit\")\n      .text(function(d) { return d; });\n}\n```\nFirst we enter two fruits:\njs\nupdate([\"apple\", \"orange\"]);\nThe resulting DOM:\nhtml\n<body>\n  <div class=\"fruit\">apple</div>\n  <div class=\"fruit\">orange</div>\n</body>\nNow change the data, adding banana and swapping apple and orange:\njs\nupdate([\"banana\", \"orange\", \"apple\"]);\nIn the resulting DOM, banana is inserted before orange because orange is the next-following element previously in the DOM. However, since insertInOrder only applies to entering elements, orange and apple are not in the correct order with respect to the data:\nhtml\n<body>\n  <div class=\"fruit\">apple</div>\n  <div class=\"fruit\">banana</div>\n  <div class=\"fruit\">orange</div>\n</body>\nFor comparison, here\u2019s the general update using selection.order:\n``` js\nfunction update(fruits) {\n  var fruit = d3.select(\"body\").selectAll(\".fruit\")\n      .data(fruits, function(d) { return d; });\nfruit.exit().remove();\nfruit.enter().append(\"div\")\n      .attr(\"class\", \"fruit\")\n      .text(function(d) { return d; });\nfruit.order();\n}\n```\nThis always produces the correct order, even if updating elements get reordered, even if there are no entering elements:\nhtml\n<body>\n  <div class=\"fruit\">banana</div>\n  <div class=\"fruit\">orange</div>\n  <div class=\"fruit\">apple</div>\n</body>\nOf course, there are many cases where insertInOrder is sufficient; any case where you can guarantee that updating elements are in the same order, and only entering elements need to be inserted into place.\n. Here\u2019s another way to achieve the same result as insertInOrder by passing a function as the second argument to selection.insert. (It\u2019s currently limited to selections with only a single group, but that could be fixed.)\n``` js\nfunction update(fruits) {\n  var fruit = d3.select(\"body\").selectAll(\".fruit\")\n      .data(fruits, function(d) { return d; });\nfruit.exit().remove();\nfruit.enter().insert(\"div\", sibling)\n      .attr(\"class\", \"fruit\")\n      .text(function(d) { return d; });\n// Find the following updating sibling.\n  function sibling(d, i) {\n    var n = fruit[0].length, e;\n    while (++i < n && !(e = fruit[0][i]));\n    return e;\n  }\n}\n```\n. Superseded by #1358 which implements this as the default behavior for enter.insert(name).\n. Yep, fixed.\n. Merged into #756; staged for 2.10.0.\n. It was already the case in the previous version that the abbreviations had to be three characters long; see the substring call in time/format.js.\nI think it would be possible to rewrite the code to allow arbitrary abbreviations. Trying to decide whether I should require the length of the abbreviations to be identical or allow variable length.\n. Merged into #756; staged for 2.10.0.\n. I think I've fixed this in 3d4d679. I've also added a locale file for ru_RU, but I don't speak Russian so feel free to correct it if I made any typos!\n. Yes, it landed in 2.10; see the multi-value map demo. The thing you\u2019re looking for that never landed in master is the function-that-returns-a-map variant; I felt it introduced too many overloaded method variations and wasn\u2019t worth the extra complexity.\n. Also, this should be backwards-compatible for d3.text, d3.json, etc., rather than requiring a call to send().\n. I have folded your suggestions and combined them with @ZJONSSON's #811 into a new pull request #813. Please let me know what you think, and feel free to send a new pull request to the xhr2 branch.\n. The fact that the elements have associated properties should not prevent the browser from garbage collection; modern browsers deal correctly with circular references. As long as the elements and their associated properties are unreachable, they will be discarded. This wasn't the case with older browsers (particularly older IE), but there's no reason to complicate our code for more recent browsers.\nAs for the second change, that would make the comparison of leaf nodes inaccurate. Try this example: http://bl.ocks.org/3315291 You might be able to solve this problem a different way by inserting dummy sibling nodes, for example: http://bl.ocks.org/3315318\nAnd yeah, you'll need to create separate branches (git checkout -b foo) to send separate pull requests.\n. Sure, I could see making it easier to do the dummy node trick by just changing the algorithm slightly internally. I'm not sure what the API should look like. Maybe a second value for pack.padding?\n. Sorry, I'm busy with work at the moment, so I probably won't get a chance to look at this for a while. I'm not sure I fully understand the arguments in favor of switching to polynomial splines, and without having a good argument, I'll tend to be conservative and avoid changing the current behavior.\n. I'm averse to changing the behavior for the existing interpolators. There needs to be a high bar, such the obviously broken behavior of the monotone interpolator, in order to change the behavior. Otherwise we risk surprising developers who upgrade. We can introduce a new interpolator if there is sufficient value to justify the incremental complexity.\nMy specific concern here is that cardinal splines are not intended for use in the context of a graph with a dependent variable y and independent variable x, so there is no pressing need to \"fix\" them. An appropriate use of cardinal interpolation is the clustered force layout example where a closed cardinal spline is used to draw the bounding convex hull of each cluster.\nYour fix is an improvement when using cardinal splines in graphs, but the monotone interpolator is still greatly preferred. (Or, under some conditions, the basis or linear interpolators are also suitable.) The monotone interpolator outperforms the cardinal interpolator here because it is explicitly designed for use in graphs; the other interpolators are not. (Related: I don't recall if it's possible to use the monotone interpolator correctly for graphs that are oriented in other directions.)\nSo rather than change cardinal interpolation or introduce a new interpolator, shouldn't we encourage people to monotone interpolation instead? Which, thanks to you, is now fixed? :grin:\n. Here\u2019s a test case for the monotone bug: http://bl.ocks.org/mbostock/89cf75990724fd7657fd\nBut the screenshot looks like cardinal interpolation rather than monotone, and that would be the expected behavior for cardinal interpolation. Also, I\u2019m not sure how well cardinal or monotone interpolation will work if the points are not uniformly-spaced along the x-axis. In this case there are two points around 1962 that are almost on top of each other.\n. This has been fixed with the new d3.curveMonotoneX and d3.curveMonotoneY in d3-shape for D3 4.0. Here\u2019s an updated version of Jason\u2019s test:\nhttp://bl.ocks.org/mbostock/972e360a214dc778b6d1c6245af7dc12\nThe new d3-shape module also implements Yuksel et al.\u2019s parameterized Catmull\u2013Rom curves, defaulting to centripetal splines, which do not form loops or cusps within a curve segment.\n. Thanks for working on this! Unfortunately I don't think this solution is flexible enough. You might have a string which has multiple missing numbers with different values, for example, treating \"translate(1) scale(2) rotate(3)\" as \"translate(1 0)scale(2 2)rotate(3 0 0)\" requires a substitute 0, 2, 0, and 0. You could allow multiple substitution values, but then it feels to me like you are implicitly specifying part of the initial value with the destination value, in which case you might as well specify the full tween:\njs\nselection.transition().attrTween(\"transform\", function() {\n  return d3.interpolateString(\"translate(1,0)\", \"translate(100,100)\");\n});\nIdeally Firefox/IE would distinguish between user-set values and computed values, and then we wouldn't have this problem.\n. Another option could be separate targets per-locale, e.g., make d3.v2-en_US.min.js. That's a long name, though. :)\n. What's the expected behavior for the decimal point when you format without a group separator (i.e., comma is false)? Seems to me that you should still get the localized decimal point, but I could be wrong. Might be useful to see how Python does it.\n. Merged into 3.0.\n. I tried this with fr_FR and got unexpected results:\nbash\n$ LC_NUMERIC=fr_FR locale -ck LC_NUMERIC\nLC_NUMERIC\ndecimal_point=\",\"\nthousands_sep=\ngrouping=\"127\"\nI think the problem is that the thousands separator is the space character, rather than the empty string.\n. Actually maybe that's the desired behavior? Weird that a locale would disable grouping entirely.\n. As another example, for pt_PT I get:\njs\nd3.format(\",.2f\")(1234.56) // \".56\"\nAnd that I'm pretty sure is a bug. :)\n. I think it's best to reserve mon_thousands for currency formatting. I checked in a fix that detects for a reported grouping \"0\" and disables grouping.\n. Weird. It must be broken locale specifications in Mac OS X, then? The thing is, Mac OS X clearly understands the fr_FR locale correctly, because if you go to System Preferences > Languages & Text > Region, check Show all regions, and then select France > France (French) from the drop-down menu (phew!) it will display something sensible:\n\n. Sure, that sounds reasonable. I haven\u2019t closely examined this pull request, but as a skim read, it looks good.\n. Merged into #846.\n. As far as I can tell, this has been fixed in current browsers. However, it is related to d3/d3-selection#67.\n. Merged into 3.0.\n. Merged into 3.0.\n. I have implemented a similar polyfill for 3.0 in 2eeb2057b2a058a15f9b4d155a4650dcab4ef070. Give it a try and let me know if it works for you?\n. I thought it was only a problem with \"dx\" and \"x\". Is it a problem with \"dx\" and \"transform\", too?\n. Yes, that's right. Only an issue when text-anchor is not start, and dx is non-zero, and either x or transform is set.\n. This is generated from the tree.js in the master branch, FYI.\n. Can I see an example of how this would be used? Thanks.\n. Interesting. You're also discarding the return value of dsv.parseRows, because you're using asynchronous callbacks. Seems like if we want a streaming API, there are other things that should probably change slightly, too.\n. Oh, heh. Right you are! Pretty good. :grin:\n. Tracking #875.\n. This seems like a useful enhancement. Thanks!\n. The new d3.stack for 4.0 outputs [y0, y1].\n. Thank you, and thank you for adding tests!\n. Hmm, I get the following error:\nbash\n$ git pull git://github.com/habeanf/d3.git 5b078e0\nfatal: Couldn't find remote ref 5b078e0\nHowever, I can reimplement your fix easily, so I'll do that.\n. Fixed in 2.10.1.\n. d3.select() would return a single-element selection, where the element is null, which is slightly different than say d3.selectAll([]) which returns a zero-element selection.\nAlso, it would be more performant to define these statically rather than on each selection instance, say:\n``` js\nvar d3_selectionEmpty = d3_selection([]);\nd3_selectionPrototype.enter = function() {\n  return d3_selectionEmpty;\n};\nd3_selectionPrototype.exit = function() {\n  return d3_selectionEmpty;\n};\n```\nBut, I\u2019m not sure it\u2019s a great idea to reuse a singleton empty selection for all default selection.enter and selection.exit methods, since that selection could be modified and then cause unexpected behavior.\nAt any rate, code that\u2019s trying to access the enter and exit selection on a selection that is not the result of a data-join seems like a bad thing, and I don\u2019t seem a compelling need to make that behavior fail silently with noop selections. I have never needed this behavior in practice since the code that access the enter & exit selections is always immediately preceded by the data join. And that seems like a practice we should encourage.\nThank you, though, for the pull request!\n. Examples have been moved to bl.ocks.org, but thank you for this.\n. Related #813. I should make the same change over there, and then we'll release it together.\n. Merged into #813.\n. Looks good.\n. Sorry for the delay. Lost track in a deluge of issues and pull requests. Trying to organize them now.\n. Folded into #1062.\n. Yes.\n. Folded into #1062.\n. Thanks for this pull request, too.\nDisabling the construction of the quadtree when no charge force is specified is an important feature for improving performance when using custom forces. And likewise, I prefer to have faster code paths when the charge is defined as a constant (and friction is currently always a constant), rather than upcasting to functors. Another reason is that the upcast to functor should not be exposed externally; see #895 for example.\nIn general I recommend using the \"tick\" event if you want to implement custom forces, as in the collision detection example. Alternatively, if you want to customize the behavior completely, I recommend forking the entire force layout and rebuilding it from scratch since it\u2019s not too big. :)\n. Merged into 3.0.\n. I don't see a strong reason to support this over the existing d3.timer(function), which you can use to run once by having the callback function return true. Using the native method would be slightly faster, but outside of D3's API, so it's not D3's responsibility to expose the polyfill.\nI suppose one way we could do this is to move requestAnimationFrame to the compat directory (as we do with Date.now), and then you could just rely on window.requestAnimationFrame being polyfilled by D3, and use that directly.\n. Sorry, I thought you were trying to get the requestAnimationFrame function, not set it.\n. > I'd like to be able to overwrite \"d3_timer_frame\" function\nSorry for my imprecise wording, but that's what I meant.\nIs this an issue for all browsers? Or is it primarily an issue for browsers that don't support requestAnimationFrame? Because browsers that do support requestAnimationFrame tend to be fairly efficient. (For example, they never callback more frequently than 60Hz, and they pause animation when in background tabs.)\nI guess my related question would be: how are you going to change the implementation of requestAnimationFrame to slow down the animation? You can't request a slower callback, but I suppose you could drop every other frame? Or are you going to replace requestAnimationFrame with a slower setTimeout? (In which case you could achieve this by patching requestAnimationFrame rather than D3, though I could see that being undesirable in certain circumstances.)\n. Also, related, if it helps: sometimes in the extreme cases (rendering thousands of nodes) I find it helpful to use a mixture of Canvas and SVG. For example, you can use Canvas to render shapes, and then have an SVG overlay for interaction and axes where D3's data-joins are helpful.\n. Thanks for the pull request and sorry for taking so long to respond. I see this one has picked up quite a few merges. :)\nd3.layout.hierarchy is abstract and isn\u2019t intended to be used directly, which is why the nodes method is not exposed; it doesn\u2019t define a layout. It might be possible to expose the links method, but since the layout is not intended to be used directly there is no compelling reason to do so.\n. Supporting NPM, Bower, Browserify, and now Jam? And all of them require patches to index.js or their own file. :\\\n. I would prefer some standardization (or at least collaboration) between the different parties working on browser-side package management. I know this is an easy change to incorporate, but why not instead send a pull request to Jamjs to read Bower's component.json file etc.?\n. Also, this change should be made to src/package.js, which is used to generate package.json with the correct version number.\n. Thanks for filing the issue with jam!\n. Sure, I'll do that.\n. I think this was fixed by f1c87d7e3a02074287326faa46e748543e25a219; see example: http://bl.ocks.org/3892928.\n. I have folded your suggestions into #813. Please let me know what you think. Feel free to also send me a pull request to that branch directly.\n. That's correct; xhr.mimeType just calls overrideMimeType, since there is now a separate xhr.header method for setting custom request headers. However, it's still the case that when you use a convenience constructor (e.g., d3.csv(\"foo.csv\", callback)), both overrideMimeType is called and the Accept header is set.\n. Backwards-compatibility is easier when you start from minimalist APIs. :)\n. Hmm, I was expecting that to throw an IllegalStateException. I need tests. :) The intended way to post is:\njs\nd3.csv().open(\"POST\", \"http://localhost/test\")\n    .header(\"Content-Type\", \"application/x-www-form-url-encoded\")\n    .send(\"a=2&b=3\")\n    .on(\"error\", function(request) { console.warn(request.status); })\n    .on(\"load\", function(data) { console.log(data); });\nAs you can see from the code, d3.csv(url, callback) is equivalent to:\njs\nreturn d3.xhr().open(\"GET\", url)\n    .mimeType(\"text/csv\")\n    .header(\"Accept\", \"text/csv,*/*\")\n    .on(\"load\", function() { callback(null, request); })\n    .on(\"abort\", function() { callback(request, null); })\n    .on(\"error\", function() { callback(request, null); })\n    .send(null);\nSo, you can change a few things after that (for example, you could chain a progress event listener), but nearly everything else is already implied by the convenience constructor.\n. Yes, I just noticed that creating a progress events demo. The current implementation requires the url and callback for the type-specific methods. The returned xhr doesn't have a special wrapper for the load event, so on(\"load\") gives you a request rather than the data as you expect.\nI think I can fix this by making the d3.xhr class support a content function which is invoked to convert the request object into its associated content. This only happens if the request is successful. Then the convenience methods d3.csv etc. will just be simple wrappers on d3.xhr that specify a content function.\n. Ah, hrm. Thanks for the bug report. I need to think a little bit more about how to fix that. Quite obnoxious how stateful the XMLHttpRequest API is.\n. OK, I pushed a fix. I don't allow clearing headers by passing a null value, although maybe I should.\n. Actually, yeah, I think it's good as-is. You don't want to encourage xhr.header(name, null), because if the request is already open, then the previous value for that header has already been added and it's too late to remove it. Unless, of course, we want to defer everything until xhr.send (and in which case we should replace xhr.open with xhr.method).\n. Here's what deferring everything to xhr.send would look like:\njs\nd3.csv(\"/path/to/file\")\n    .method(\"POST\")\n    .header(\"Content-Type\", \"application/x-www-form-url-encoded\")\n    .on(\"error\", function(request) { console.warn(request.status); })\n    .on(\"load\", function(data) { console.log(data); })\n    .send(\"a=2&b=3\");\nI kind of like it better. Plus this would allow get-and-set for the method, headers, and mimeType.\nIf we do this, perhaps we should also add a data method, rather than passing data to send. This could have an optional contentType argument which could allow us to do the conversion automatically. For example:\njs\nd3.csv(\"/path/to/file\")\n    .method(\"POST\")\n    .data({a: 2, b: 3}, \"application/x-www-form-url-encoded\")\n    .on(\"error\", function(request) { console.warn(request.status); })\n    .on(\"load\", function(data) { console.log(data); })\n    .send();\nAlthough I'm not sure I totally want to sign-up for converting JSON objects to x-www-form-url-encoded values, since that requires a whole bunch of Rails-esque logic to flatten objects and arrays into a top-level namespace. And plus typing out \"application/x-www-form-url-encoded\" whenever you want to encode an object negates most of the convenience.\n. Lastly, with the declarative style described above, you could use the same d3.xhr object to create multiple requests (to the same URL).\n. OK, updated to be more declarative. Though I opted to avoid automatic encoding, still. Example:\njs\nd3.csv(\"/path/to/file\")\n    .method(\"POST\")\n    .header(\"Content-Type\", \"application/x-www-form-url-encoded\")\n    .data(\"a=2&b=3\")\n    .on(\"error\", function(request) { console.warn(request.status); })\n    .on(\"load\", function(data) { console.log(data); })\n    .send();\nI was also wrong about being able to reuse a single d3.xhr instance for multiple requests. That's a bad idea because then the xhr.abort method is ambiguous (which request?). We could have an xhr.copy method if you wanted to derive a new request from an existing one, but that seems like a somewhat obscure use-case, since you could just write your own method to create a duplicate request.\n. Right, and really it should be \"application/x-www-form-url-encoded;charset=utf-8\".\n. OK, I changed it so that when you call xhr.data, it will set a default Content-Type header if you haven't set one already. That seems safe, at least, and you can always change the behavior by setting the header explicitly.\n. Now we're down to:\njs\nd3.csv(\"/path/to/file\")\n    .method(\"POST\")\n    .data(\"a=2&b=3\")\n    .on(\"error\", function(request) { console.warn(request.status); })\n    .on(\"load\", function(data) { console.log(data); })\n    .send();\nThis looks pretty good to me. :grin:\n. I had a thought on another API variation:\njs\nd3.csv(\"/path/to/file\").post(\"a=2&b=3\", function(error, data) {\n  // callback\n});\nAnd likewise\njs\nd3.csv(\"/path/to/file\").get(function(error, data) {\n  // callback\n});\nYou could still chain between the d3.xhr constructor and xhr.get (or xhr.post etc.) to set headers, add listeners, etc. The downsides I see are:\n- We need to know HTTP request methods. The vast majority of requests are GET, POST and HEAD. But we'd want to provide a generic way to specify a different method, which adds complexity.\n- We're assuming that only POST requests get a content body.\n- It's less declarative because there's no way to get the method or data.\n. Actually, I looked again at the XMLHttpRequest 2 specification and apparently there is already default behavior for the Content-Type header when posting data:\n\n\nIf data is a Blob, If the object's type attribute is not the empty string let mime type be its value.\nIf data is a Document, Let mime type be \"application/xml\" or \"text/html\" if Document is an HTML document, followed by \";charset=\", followed by encoding.\nIf data is a string, Let encoding be UTF-8. Let mime type be \"text/plain;charset=UTF-8\".\nIf data is a FormData, Let the request entity body be the result of running the multipart/form-data encoding algorithm with data as form data set and with UTF-8 as the explicit character encoding. Let mime type be the concatenation of \"multipart/form-data;\", a U+0020 SPACE character, \"boundary=\", and the multipart/form-data boundary string generated by the multipart/form-data encoding algorithm.\n\n\nSo it would seem that setting a default Content-Type header to \"application/x-www-form-urlencoded;charset=utf-8\" is divergent from the specification, which defaults to \"text/plain;charset=utf-8\". Therefore I'm going to remove this behavior. I'll think some more if there is a better way to post parameters easily.\n. Here's the proposal with the new d3.urlencode:\njs\nd3.xhr(\"/path/to/file\")\n    .post(d3.urlencode(\"a\", 2).and(\"b\", 3), function(error, data) { console.log(error, data); });\nThe implementation of d3.urlencode is a bit more code than I wanted (given that it's probably better to use the standard FormData, or the much simpler \"application/json\" and JSON.stringify), but in theory d3.urlencode is useful for making query strings too. Though there's no symmetric d3.urldecode method. I guess there should be\u2026\n. Merged into #829.\n. Responding to each suggestion:\n1. xhr.post convenience function\nHere's how I intended POST to work:\njs\n   d3.csv().open(\"POST\", \"http://localhost/test\")\n   .header(\"Content-Type\", \"application/x-www-form-url-encoded\")\n   .send(\"a=2&b=3\")\n   .on(\"error\", function(request) { console.warn(request.status); })\n   .on(\"load\", function(data) { console.log(data); });\nI like the idea of doing automatic encoding of JSON objects. For example, this could perform automatic encoding to application/x-www-form-url-encoded (perhaps using FormData, but I don't know if that's supported in IE9):\njs\n   d3.csv().open(\"POST\", \"http://localhost/test\")\n   .send({a: 2, b: 3})\n   .on(\"error\", function(request) { console.warn(request.status); })\n   .on(\"load\", function(data) { console.log(data); });\nThough, perhaps it would be better for that to use application/json encoding by default? (In particular that would avoid needing a strategy to convert hierarchical JSON objects to a flat namespace of form parameters, and not require FormData.) On the other hand if someone sets the Content-Type header to something other than application/json, it would be weird for send(data) to do the wrong thing. So perhaps it's simpler to not do anything automatic data conversion.\n2. Accept Header moved to xhr.open\nThe convenience constructor arguments should take effect immediately and then be discarded. I don't want to keep them around and apply them later; having methods take effect immediately makes things easier to understand and debug.\n3. sendTimeout\nAs I said before, I'm against this for performance and usability reasons.\n4. xhr.open username/password\nThis seems reasonable to me, though I'm also hesitant to add them because people shouldn't be using HTTP basic auth. :)\n. I can't decide how to have send(object) automatically call JSON.stringify and set the Content-Type header to \"application/json\". Clearly, one way of doing it this:\njs\nif (!(data instanceof ArrayBuffer\n    || data instanceof Blob\n    || data instanceof Document\n    || data instanceof FormData\n    || data instanceof String\n    || typeof data === \"string\")) {\n  request.setRequestHeader(\"Content-Type\", \"application/json\");\n  data = JSON.stringify(data);\n}\nBut I don't like this for several reasons: it's verbose; it's not forwards-compatible if XMLHttpRequest accepts another argument type in the future; it crashes on browsers such as IE9 that don't support one of those specific types. It's just clunky.\nYou could do something more strict and require object literals:\njs\nif (data.constructor === Object) {\n  request.setRequestHeader(\"Content-Type\", \"application/json\");\n  data = JSON.stringify(data);\n}\nBut I'm not too happy with that, either. I suppose we could go with a sendJson method, but that seems ugly too.\n. > If we didn't add a convenience-mechanism, the request would fail anyway\nUnfortunately, this is false; in fact our code can cause successful requests to fail. For example, you could create an object like so:\njs\nvar data = {\n  toString: function() {\n    return \"a=2&b=3\";\n  }\n};\nRather than calling your toString method as you might expect, the convenience code above would call JSON.stringify, returning \"{}\" and dropping the \"a\" and \"b\" parameters.\n. Agreed. But we should try to minimize surprise. If the caller doesn't know that xhr.send() performs automatic encoding, they might be surprised when it doesn't coerce to a string.\n. I've incorporated a variant of your xhr.post suggestion into #813. I'd like to punt on automatic encoding, so I think that about wraps everything up. Let me know if you have any more suggestions! And thank you!\n. Thanks for the pull request. Currently, the layout\u2019s size directly determines the gravitational center, and that\u2019s pretty much it\u2019s only purpose (aside from initializing node positions). Thus I don\u2019t see a compelling need to add a separate gravitational center, especially since you can also apply a transform to the G element that contains the force layout if you like.\n. Doing this is harder that it appears. The problem is that you can have newlines embedded within values (e.g., \"foo\\nbar\" in a CSV file), and so you need to parse the row properly to detect when a line ends; you can't callback a row until you read a true EOL.\nThis in turn means that you can't distinguish between the last row in a file that lacks a trailing newline, and the last row in an unfinished chunk that continues (has more columns) in the next chunk. To fix this, you'd need to indicate to the streaming parser when the last chunk has arrived and therefore it is safe to report the last row, even if the last row lacks a trailing newline.\nI could imagine an API as follows:\n``` js\nvar parser = d3.tsv.parser(callback);\nwhile (hasMoreChunks) {\n  parser.read(nextChunk());\n}\nparser.end();\nfunction callback(d, i) {\n  // d is the row data (array of column values)\n  // i is the line number (row index)\n}\n``\n. Although I 'spose you could replaceparser.end()withparser.read(\"\\n\")`, and it would always work for valid DSV files. But I think that's a somewhat awkward API.\n. Closing this pull request, but tracking the feature with #875. Feel free to re-open if you want to make something more like the above suggested API.\n. @jasondavies I found some anomalies in the antemeridian cutting demo. The coordinates are:\njs\nprojection.rotate([210.5, 62.5, 0]);\nprojection.rotate([349, -62.5, 0]);\nprojection.rotate([30.5, 52, 0]);\n. Nicely done!\n. Merged into #846.\n. Yup, this looks like a good start! But we should see how it looks like with clipping / resampling / cutting implemented before we know whether the API works as desired.\n. Maybe it would be faster to have a projectLine(input, output) signature, similar to memcpy? I guess that would be (destination, source).\n. If that would improve performance, that sounds like a good idea. :) My sense is that resampling is more expensive than cutting, but I'm not sure?\n. I took some measurements. Out of 1,852,674 line segments being examined during interaction with the antemeridian cutting demo:\n- 0.65% (12,037) passed both distance checks\n- 29.5% (546,646) failed both distance checks\n- 69.8% (1,293,991) passed the linear distance check but failed the perpendicular distance check\n- 0% (0) passed the perpendicular distance check but failed the linear distance check\nSo, if I interpret this correctly, the linear distance check that you added does not change the behavior of the algorithm, but does avoid additional computation for 29.5% of segments. And since there is no additional computation required beyond an if statement for the 69.8% of segments, I think it's probably safe to leave this check in.\n. This would apply to d3.hcl, too. But I left this out because only RGB and HSL are supported natively by browsers, and also I was worried about the cost of too many instanceof's. I suppose if there were a d3_Color base class that was an abstract super class of d3_Rgb, d3_Hsl and the other colors, that might enable automatic interpolation for any color that is convertible to RGB (which should be all of them).\n. As in #828?\n. Hmm. Makes me think transition.style should coerce to a string before creating the interpolator, too?\n. Yeah, this is actually just a problem when you specify the transition as a function rather than a constant. In the constant case, we coerce the b value to a string. But I forgot to do that in the function case. For example, this works:\njs\nd3.select(\"body\").transition().style(\"background\", d3.lab(\"#f00\"));\nBut if you reload, this doesn't:\njs\nd3.select(\"body\").transition().style(\"background\", function() { return d3.lab(\"#f00\"); })\n. OK, folded into #828. Nice job with one feature improvement and one core bug!\n. Merged into #829.\n. FWIW, you can avoid this problem by interpolating HSL colors rather than converting RGB to HSL. For example:\njs\nd3.interpolateHsl(d3.hsl(0, 1, .5), d3.hsl(0, 1, 0))(.5) // \"#800000\"\nd3.interpolateHsl(\"hsl(0,100%,50%)\", \"hsl(0,100%,0%)\")(.5) // \"#800000\"\nHowever, since not all browsers support HSL colors, D3 converts to RGB when setting styles and attributes. (Also, browsers may munge attributes, thereby converting HSL to RGB.) So this technique requires using an attrTween or styleTween so that you can specify an explicit starting value for the transition, rather than using the computed current value from the element.\n. You typed in a hue of zero, so it interpolated the hue from 240\u00ba to 0\u00ba. Try this:\njs\nd3.interpolateHsl(d3.hsl(240, 1, 0.5), d3.hsl(240, 1, 0))(.5) // \"#000080\"\nThe point being, if you specify HSL colors for the start and end, you can control the interpolation of the hue rather than it always being zero.\n. In general, I like having control over the behavior. With the current API you get a default behavior (H=0\u00ba, S=0) by specifying RGB colors, or you can control the behavior by specifying HSL colors. If we change the interpolator to inherit hue and saturation from the other color as appropriate, then we also remove control because the interpolator cannot distinguish between when H or S is undefined (coming from an RGB color) and when H or S is zero.\nI suppose we could change d3.hsl so that h and s are undefined when you converted from black RGB. But I suspect that might break other things.\n. Specifying an additional argument to the interpolator isn't very useful; you don't have that option when you use transition.attr or transition.style, for example. Also, it's not self-describing, which means you have to go search the documentation to figure out what the argument true indicates.\nI think changing d3.interpolateHsl to not interpolate H or S if undefined would work. Something like:\njs\nd3.interpolateHsl = function(a, b) {\n  a = d3.hsl(a);\n  b = d3.hsl(b);\n  var h0 = isNaN(a.h) ? b.h : a.h,\n      s0 = isNaN(a.s) ? b.s : a.s,\n      l0 = a.l,\n      h1 = isNaN(b.h) ? 0 : b.h - h0,\n      s1 = isNaN(b.s) ? 0 : b.s - s0,\n      l1 = b.l - l0;\n  if (h1 > 180) h1 -= 360; else if (h1 < -180) h1 += 360; // shortest path\n  return function(t) {\n    return d3_hsl_rgb(h0 + h1 * t, s0 + s1 * t, l0 + l1 * t) + \"\";\n  };\n};\nThen you could say:\njs\nd3.interpolateHsl(d3.hsl(240, 1, 0.5), d3.hsl(undefined, undefined, 0))(1)\nYou could take this one step further and also change d3_rgb_hsl to leave H and S undefined when converting from a monochrome color, simply by deleting two lines:\njs\nfunction d3_rgb_hsl(r, g, b) {\n  var min = Math.min(r /= 255, g /= 255, b /= 255),\n      max = Math.max(r, g, b),\n      d = max - min,\n      h,\n      s,\n      l = (max + min) / 2;\n  if (d) {\n    s = l < .5 ? d / (max + min) : d / (2 - max - min);\n    if (r == max) h = (g - b) / d + (g < b ? 6 : 0);\n    else if (g == max) h = (b - r) / d + 2;\n    else h = (r - g) / d + 4;\n    h *= 60;\n  }\n  return d3_hsl(h, s, l);\n}\nI think you'd also need to fix d3_hsl_rgb to handle H and S being undefined, so that when you convert back to RGB  you get a valid gray of the appropriate lightness. I think if (isNaN(s)) s = 0 would be sufficient to fix that.\n. Sorry, haven't had time to address this issue lately. I assume this change would also need to affect HCL colors for consistency. I'm not sure yet about Lab*.\n. Superseded by #1205.\n. The children accessor is evaluated by the parent class, d3.layout.hierarchy. The resulting data is then normalized into a standard format so that it's easier to work with; therefore there is no need to subsequently re-evaluate the children accessor.\n. It's a little confusing to me that now x0, y0 and \u03bb0, \u03c60 no longer refer to the same point. I think I understand why you've done this\u2014so that, effectively, you can interpolate spherical coordinates at t other than 0.5, But it's a bit confusing. :) I haven't had quality time this week to see if I can suggest a better alternative, though. I'll try to make some time soon!\n. Merged into #846.\n. Typically using transition.each:\njs\ntransition.each(function() {\n  d3.select(\"path\").transition()\u2026\n});\n. Candidates for removal:\n- ~~d3.first~~\n- ~~d3.last~~\n- ~~d3.geom.contour~~ (moved to d3-plugins)\n- ~~d3.geo.azimuthal~~ (replaced by d3.geo.orthographic et al.)\n- ~~d3.geo.greatCircle~~ (replaced by d3.geo.circle)\n- ~~d3.split~~ (replaced by line.defined and area.defined)\n- ~~selection.map~~ (replaced by selection.datum)\n- ~~d3.svg.mouse~~ (replaced by d3.mouse)\n- ~~d3.svg.touches~~ (replaced by d3.touches)\n- ~~d3.xhr deprecated callback~~ (replaced by node-style callback)\n- d3.layout.hierarchy deprecated inlined data (replaced by wrapped data)\n- d3.geom.quadtree deprecated array input (replaced by x-y object input)\n. Blocking issues:\n- Use spherical coordinates for more robust polygon winding order detection in d3.geo.path (#950).\n- Should we expose d3.geo.projectionMutator? I'm not sure I like it.\n- Can we minimize the d3.geo.projection interface, or support automatic promotion from point-function to projection?\n- Move d3.geom.hull to a d3 plugin?\nNice-to-have:\n- ~~Use spherical coordinates for d3.geo.centroid and d3.geo.area (#941).~~\n- ~~Expose d3_geo_greatArcInterpolate.~~\n- Expose d3.geo.type (#945)?\n- Performance improvements; running benchmark on commit history.\n- Code reuse?\n. So, the internals of d3.geo.projection are kind of a mess. Considering only projection of points, we have the following public methods:\n- projection - accepts {[degrees, degrees]}, returns [pixel, pixel]. Calls projectRotate which calls rotate and project by way of d3_geo_compose.\n- projection.point - accepts {[degrees, degrees], context}, returns void. Calls clip.point which calls resample.point which is an alias for point, which calls context.point. point calls projectPoint, which calls project.\nAnd the following private methods:\n- rotate - accepts {radians, radians}, returns [radians, radians].\n- project - accepts {radians, radians}, returns [pixel, pixel].\n- projectRotate - accepts {radians, radians}, returns [pixel, pixel]. Calls rotate and project via d3_geo_compose.\n- point - accepts {radians, radians}, returns void. Calls context.point and projectPoint. projectPoint calls project.\n- projectPoint - accepts {radians, radians}, returns [pixel, pixel]. Calls project.\n- rotatePoint - accepts {[degrees, degrees]}, returns [radians, radians]. Calls rotate.\n- clip.point - accepts {degrees, degrees}, returns void. Calls context.point and projectPoint. projectPoint calls project.\n- resample.point - alias for point.\n- context.point - accepts {degrees, degrees}, and returns void.\n. Decided we should revert c3635192d87c3c8ad573224283185c1b01c6b69b and keep backwards-compatibility for old-style d3.xhr callback, since there hasn't been enough advance warning for this backwards-incompatible change.\n. This looks interesting! However, I would suggest a standalone library rather than part of core D3. If you like, you could implement this as a d3 plugin. However, I don't see any dependencies on other parts of D3, so it would be more flexible as a standalone library with no dependencies.\nAlso, you might be interested in JSLINQ.\n. Transforming the scale domains (\"axes\" have a different connotation in D3) when changing the translate and scale makes sense. However, I'm pretty sure the change to zoom.x and zoom.y is backwards-incompatible, because now you don't have a reference to the input scales so the changes are never propagated back.\nI think it would make sense to set translate to the origin [0, 0] and scale to 1 whenever the x- and y-scales are reset. And likewise to transform the scales whenever the translate or scale are set. So this way you could set either programmatically, and the other would be consistent. That would eliminate the need to set the translate and scale in this example: http://bl.ocks.org/3892928\n. OK, my take on a fix is in f1c87d7e3a02074287326faa46e748543e25a219 and slated for 3.0. Let me know if that works for you and thank you for the pull request!\n. In 3.0, you can build this automatically by saying LOCALE=sv_SE make clean all!\n. I'm not sure I understand how you are using the pack layout in those screenshots. That looks more like a directed or undirected graph than a hierarchy. Are you sure you don't want to use the force layout, or a directed graph layout algorithm (such as Sugiyama / graphvis / dot) instead?\n. Thanks for this pull request. I decided to implement a slightly different solution in 3.2, allowing a custom radius function to replace the default automatic scaling; see a895218.\n. I'm curious why you want this behavior. A scale with a degenerate domain isn\u2019t particularly useful, since it maps every value to the start of the range. So displaying any tick values would probably be misleading, or at any rate, also not very useful. :)\n. Yeah, I think it'd probably be best to detect a degenerate domain in this case, and then pad it by some fixed value on both sides, and in that case request only 1 tick rather than 5 or whatever you normally use.\nUnrelated, but I just visited your website and found your WebGL contours map, and I thought it was really cool. :) I liked the satellite visualization hooked up to crossfilter too!\n. This will be supported automatically in 3.0 (see commit 51b2e678d25d34ed58a20751394ba5853712491d). You can build a localized italian build as follows:\nbash\nLOCALE=it_IT make clean all\nOn my machine, this produces:\n``` js\nvar d3_format_decimalPoint = \",\",\n    d3_format_thousandsSeparator = \". \",\n    d3_format_grouping = null;\n// The date and time format (%c), date format (%x) and time format (%X).\nvar d3_time_formatDateTime = \"%a %e %b %X %Y\",\n    d3_time_formatDate = \"%d.%m.%Y\",\n    d3_time_formatTime = \"%H:%M:%S\";\n// The weekday and month names.\nvar d3_time_days = [\"Domenica\", \"Luned\u00ec\", \"Marted\u00ec\", \"Mercoled\u00ec\", \"Gioved\u00ec\", \"Venerd\u00ec\", \"Sabato\"],\n    d3_time_dayAbbreviations = [\"Dom\", \"Lun\", \"Mar\", \"Mer\", \"Gio\", \"Ven\", \"Sab\"],\n    d3_time_months = [\"Gennaio\", \"Febbraio\", \"Marzo\", \"Aprile\", \"Maggio\", \"Giugno\", \"Luglio\", \"Agosto\", \"Settembre\", \"Ottobre\", \"Novembre\", \"Dicembre\"],\n    d3_time_monthAbbreviations = [\"Gen\", \"Feb\", \"Mar\", \"Apr\", \"Mag\", \"Giu\", \"Lug\", \"Ago\", \"Set\", \"Ott\", \"Nov\", \"Dic\"];\n``\n. Sorry for not responding to this pull request. The repository structure is changing for D3 4.0 (see https://github.com/d3), so this work would need to be modified for the new repositories\u2026 but perhaps it\u2019s a good idea. Perhaps using [Istanbul](https://github.com/gotwarlost/istanbul)?\n. Sounds good! :)\n. azimuthal.origin, like most getter-setter methods in D3, returns the object when called with arguments. So, azimuthal.origin([0, 0]) returns azimuthal. Your code doesn't appear to change anything, sinceazimuthal = azimuthal.origin([0, 0])is identical toazimuthal.origin([0, 0])`.\nIf you are having trouble using this class, you might post your code to Stack Overflow for help.\n. Nope, that's how the getter works. If you call azimuthal.origin() with no arguments, it returns the origin, rather than the projection.\n. On second thought, I'm not sure this is the appropriate fix. It's possible that a hierarchical layout could handle negative leaf values, despite that not being true of the current implementations. Also, this could mask problems with data where people think what they are seeing is accurate, but the negative values are ignored.\n. Probably the more idiomatic behavior is to convert to the default orient when set, if the orient specified isn't one of the known values. (This is similar to CSS, where if you set a style property such as the background-color to an invalid value, the rule is ignored.)\n. Thanks for the pull request. I have pushed a slightly different fix in #1064.\n. Great! I would love to see some benchmarks next so that we can optimize this code. For inspiration take a look at Crossfilter's benchmarks.\n. It shouldn't ever be necessary to check endpoints for equality because polygons in GeoJSON are required to have the last point be equal to the first point. And, when rendering a polygon, we call projection.polygon (rather than projection.line), so we know whether it's a closed polygon or an open line string.\n. Thanks. This partially fixes an immediate issue I've noticed with TopoJSON, though it's likely that it's also a bug in my reconstruction of features. You can see the problem here:\nhttp://bl.ocks.org/4122298\n. The latest commit appears to break one of the tests. Let me know when it's ready to look again.\n. I fixed my bug, too. :)\n. I have reverted this pull request using a force push to the 3.0 branch. Unfortunately, GitHub doesn't appear to let me reopen the pull request, but you should be able to send a new one along when your fix is ready.\n. Lovely! Thank you for doing this.\nOne concern with the optimization is that there's now a memory leak since the projection retains a reference to the context after {point,line,polygon}. A quick obvious fix is to reset the context to null after projecting, but I wonder if there's a tweak to either the API or implementation that be more elegant.\n. Hmm, might be worth going a step further and requiring button === 1.\n. I noticed that control-clicking has the same problem as right-clicking on Mac OS X, and would require detection separately from !d3.event.button (looking at d3.event.ctrlKey). For comparison (FWIW) Bing Maps also doesn't do anything special to prevent this. Google does, but only because it disables the context menu entirely. I'm half-inclined to leave this as-is and allow people to override the behavior by registering their own mousedown listeners to specify desired behavior.\n. Use a capturing listener: http://bl.ocks.org/mbostock/6140181\n. If you are listening to the SVG element, you only get events if you click on something within the SVG element. Clicking on the background will go to the body or some other element on the page. So often you need a transparent (fill: none, pointer-events: all) rect to capture events like this.\n. I\u2019ve updated the No Zoom on Context Menu example to use stopImmediatePropagation (and to not disable the context menu, but to instead disable zooming when the context menu is opened).\n. d3.xhr in 3.0 already works directly with queue.js, right?\n. Sorry, I mean, it does work with d3.xhr already in 3.0. What I meant was whether you were aware of this fact. :smile: Here's an example:\n``` js\nqueue()\n     .defer(d3.csv, \"fileA.csv\")\n     .defer(d3.csv, \"fileB.csv\")\n     .await(ready);\nfunction ready(error, fileA, fileB) {\n  console.log(\"ready!\");\n}\n```\nAnd here's a live example: http://bl.ocks.org/4060606\n. FYI, this broke the world tour example, which was relying on using simple projections to compute the centroid:\njs\nvar centroid = d3.geo.path()\n    .projection(function(d) { return d; })\n    .centroid;\nThis crashes because path.centroid now requires a true projection (with a polygon method, in particular). So, I fixed it by borrowing the code from d3/d3-plugins#22, and added a temporary d3.geo.centroid implementation that I hope you will replace with something better. :smile: But, it irks me that we can't automatically promote simple point-to-point projections to proper interpolating / clipping projections. We use the same implementation for every projection, so why can't it happen automatically?\n. This looks great! Should I merge this in now, or should I wait until you tackle d3.geo.area and fix winding order detection to use spherical coordinates?\n. Also, wondering if there is any chance of code reuse between this and d3_geo_greatArcInterpolator? And also between d3_geo_circle and d3_geo_greatArc?\n. Awesome, looking forward to it!\n. I rebased the merge accidentally, but it's in!\n. Great! I expect we'll want a simplified / optimized code path for winding order detection if that's possible, anyway.\n. Should this line:\njs\nif (Math.abs(\u03c60 - \u03c0 / 2) < \u03b5) {\nread instead\njs\nif (Math.abs(Math.abs(\u03c60) - \u03c0 / 2) < \u03b5) {\nOtherwise, it seems like you're only checking if \u03c60 is at the north pole, and not the south pole. In fact, you could probably combine this check with the polar check two lines earlier. Something like:\njs\nif (Math.abs(Math.abs(\u03c60) - \u03c0 / 2) < \u03b5) {\n  if (Math.abs(Math.abs(\u03c6) - \u03c0 / 2) < \u03b5) continue;\n  area += (\u03bb - \u03bb00) * 2;\n} else {\n  cos\u03c6 = Math.cos(\u03c6), sin\u03c6 = Math.sin(\u03c6), cosd\u03bb = Math.cos(d\u03bb = \u03bb - \u03bb0);\n  \u2026\n}\n. Hmm, changing that caused the tests to break, so I'm probably not understanding this code yet!\n. Thanks for the info. If you feel inspired after the release, I bet some visual explanation of how this algorithm works would be interesting to folks!\n. This is great! Looking forward to the winding order optimization too, that sounds like a nice win. Thanks for taking care all my suggestions while I was asleep. :sleeping:\nI still want to look at alternatives to method reassignment today. Probably finite state machine sort of stuff\u2026 not sure if it will be faster but the benchmark should tell us!\nThe other thing I was thinking was better names for \"stream\" and \"listener\". Well, maybe every where we currently say \"listener\", we should say \"stream\" instead, for consistency. But I also thought that \"visitor\" might be a better name for \"stream\" (and \"listener\"), and then we could have d3.geo.visit instead of d3.geo.stream. The name \"stream\" perhaps implies asynchronicity too strongly, and also is ambiguous between noun and verb. But \"stream\" is a pretty name, so I'd be okay with sticking with it.\n. Hi Edwin,\nThanks for the pull request. Since there are multiple components to this request I will address them separately.\nI'd rather not use a variable time step for the force simulation. In addition to being more complicated, it also means that the simulation will perform worse, albeit at the same rate, on slower machines. Since there is no expectation that the force layout be performed at the same rate across machines, it seems preferable that it perform with the same quality, or at least chose the simpler of the two approaches. In other words the force layout is not time-based but iteration-based, and on slower machines there will be fewer iterations per time interval.\nAs for user-defined forces, that is typically done by listening to tick events. For example, the collision detection example uses the tick event to apply a custom geometric constraint. There are more examples of custom forces in the gallery.\nThis same technique could be used to apply a custom drag force. I didn't look too closely at the exact type of drag force you implemented, but one subtle issue here is the stability of the forces. Forces that are derived from the particle\u2019s velocity are typically much less stable when using position Verlet integration, since this type of integration has higher error in velocity (in favor of making it easier to apply geometric constraints).\nThanks,\nMike\n. Awesome!\n. I think errors are fine, right? I mean, the stream doesn't support spheres, and while we could treat them as a noop, it seems like an error and a noop are both acceptable responses to unsupported input. I suppose slightly more consistent to use a noop, though, since we tend to favor ignoring invalid input.\nAlso, what about disabling resampling for the fallback stream, too? That's still a good idea, right? And I don't think we need resampling for albersUsa, anyway.\n. Result of chat:\n- Fallback projection will continue to resample.\n- To use an identity projection, say path.projection(null), which internally sets projectStream to d3_identity.\n. Added path.projection(null). So I think we can close this one now. Thanks!\n. Thanks for this! Isn't the centroid of a sphere undefined, since it covers the entire sphere? I mean, yes, you can pick an arbitrary point on the sphere and call it the centroid, but I'm not sure if that helps.\n. Sorry, I was just misreading the code. I agree that the sphere's centroid should be undefined, but a cursory look at the code suggested it was being set to \u27e80,0,0\u27e9. But of course d3_geo_centroidZ is zero, too, so that's undefined. My mistake!\n. Looks good.\n. I think you may have your coordinate system confused. In SVG (and Canvas et al.), the origin is in the top-left corner. Positive x is rightwards, and positive y is downwards. Taking the first example of a closed counterclockwise unit square, [[0, 0], [0, 1], [1, 1], [1, 0], [0, 0]], it looks like this:\n\nAs you can see this is counterclockwise. I'm guessing from your changes you are assuming an origin in the bottom-left corner, with positive y going up?\n. Lat-lon isn\u2019t Cartesian, unless you\u2019re referring to a cylindrical projection. Latitude and longitude are spherical coordinates, so you need to use steradians to determine the winding order of a geographic polygon. See d3.geo.area for an example.\n. (But of course in most cases you can treat lat-lon as Cartesian and get the same answer\u2026)\n. This would suggest that you are trying to run the D3 tests without the test environment. Hence why the tests require(\"../env\") rather than require(\"d3\").\n. Thanks, Isaac. Will include in 3.0.3.\n. Bah, this pull request is borked. Replaced by #999.\n. Hi Andrew,\nThanks for the pull request. However, I think the simplicity of the mapping from method calls to string here means this class isn't needed.\nAs a general rule, I favor parsimony (one way of doing things) and exposing the underlying standard (here SVG, but shared with CSS) wherever possible. The cases where you see helpers for computing SVG attributes, such as d3.geo.path and d3.svg.area, exist primarily to encapsulate the math rather than to hide the representation. It would be tedious to force everyone to doing basis-interpolation by hand, whereas using string concatenation to specify a transform is not especially onerous.\nYou could argue that D3 as a whole exists to provide a more convenient replacement for the W3C DOM API. However, I don't see this API as being a significant improvement over string concatenation. The litmus test is that it\u2019s not shorter to write. :) Also, since there isn\u2019t compile-time validation in JavaScript, using code rather than string concatenation doesn\u2019t buy additional security.\nAnother issue with this particular subject is that there\u2019s already a d3.transform class that exists to produce the canonical representation of transforms for the purposes of interpolation. Introducing a d3.svg.transform class would be confusing. (The existing d3.transform is not in d3.svg because CSS uses nearly the same syntax, and both support 2D transforms.)\nThanks,\nMike\n. Hmm, it'd be nice to fix Linux, but I'd rather not lose those cursors for everyone else. What about having multiple fallback cursors?\n. I think you can have multiple cursor rules. For example, this sort of thing is common:\ncss\ncursor: -webkit-zoom-in;\ncursor: -moz-zoom-in;\ncursor: zoom-in;\nComplicates the code a bit, though.\n. The epsilons here are a little questionable. Need to double-check that we have them set correctly before merging.\n. Here's an example:\n\n. Folded into #1120.\n. I think you should merge #1040 into this pull request, or alternatively, we should create a 3.2 release branch and put both in there, along with other ready pull requests.\n. Update: I\u2019ve created #1285 for 3.2, so please merge this into the 3.2 branch when you\u2019re ready.\n. Folded into #1065.\n. Thank you for the suggestion, but I'd rather not expose this internal method. The counter argument to readability is that readers unfamiliar with d3.identity will need to go look it up in the API reference, rather than simply being able to read what it does. (If you want to make the code as short as possible, you can often use Object or String as the identity function, but I don't generally recommend that anymore either because it's uncommon to use these functions bare rather than as constructors.)\n. Folded into #1065.\n. Thanks for the pull request. Yet this is not a typo; you are editing a generated file. In JavaScript property names in object literals do not need to be quoted if they are valid JavaScript identifiers. The name \"in\" is a JavaScript keyword and thus must be quoted, and \"in-out\" and \"out-in\" have a dash (the subtraction operator) and must also be quoted. However \"out\" is a valid JavaScript identifier, and thus does not require quoting, and is therefore not quoted when UglifyJS beautifies the source.\n. Thanks for looking at this. It would be very helpful to incorporate type-conversion into loading DSV files, for two reasons:\nFirst, by coupling it to the load call, it\u2019s easier to remember to do, rather than requiring a second pass over the data after it\u2019s loaded (as in the forEach loops here and here). Related to this, it\u2019s important that we find a way to incorporate this into d3_dsv(url), since limiting it to d3_dsv.parse requires that people first load DSV files via d3.text, which is awkward. I think we can add an optional argument after the first URL argument, as d3_dsv(url[, types][, callback]); there\u2019s not currently any ambiguity with the optional mime-type argument that is used in some of the other xhr methods (e.g., d3.xml).\nSecond, doing the conversion greedily substantially reduces memory overhead when converting strings to dates and numbers. Yet the performance improvement is only noticeable when loading very large (>100MB) files, so it\u2019s not likely to be noticeable in common usage (in a browser), but likely still worth doing.\n(Side note: parseInt et al. are substantially slower than coercing to number (+d or d | 0).)\nThere are a variety of ways we could implement this, so we should probably consider the merits of various approaches before committing to one. Here are a few I can think of:\n1. Including optional type information in the header row of the file, similar to ActionScript type declarations. For example, if the header is \"updated_at:date\" or \"count:number\", the field would be coerced to a Date or Number respectively. The downside of this approach is that it\u2019s a nonstandard extension of DSV, since normally the \":date\" and \":number\" would be part of the column name. Also, how do you enumerate all possible types? Are there separate types for floats vs. numbers, and dates of different representations, etc.? And this approach is useless when you don\u2019t control the source file (such as a cross-domain CSV request).\n2. A registry of type-conversion functions by column name or number, as you\u2019ve implemented in this pull request. I\u2019m wary about using the callback signature {value, name, index} since the more common pattern in D3 is {value, index}. (I\u2019d probably remove the name argument.)\n3. A more general approach using a map function rather than a registry of functions. This function has the standard D3 signature {datum, index}, where the datum represents a row in the DSV file (either an object whose property names are the column names, or an array whose elements are the column values). The function could then return the converted value for the row, as in:\njs\nd3.csv.parse(string, function(d) {\n  return {\n    a: parseDate(d.a),\n    b: +d.b\n  };\n});\nThis last approach is very similar to the native array.map, except that it is applied incrementally as the file is generated, improving performance. This is consistent with some of D3\u2019s other uses of accessor methods, such as d3.sum and d3.extent. This approach could also be generalized to allow filtering, removing rows when the map function returns a falsey value (though perhaps null / undefined would be better than falsey).\nThe last approach also starts to get into the domain of #875 #819 #783. In fact d3_dsv.parseRows already accepts an optional map and filter function, skipping falsey values. This is exactly what is used by d3_dsv.parse to convert rows to objects with named properties. So in effect all you need to do is compose the function that d3_dsv.parse generates with another function that the user specifies:\njs\ndsv.parse = function(text, f) {\n  var o;\n  return dsv.parseRows(text, function(row) {\n    if (o) return o(row);\n    var a = new Function(\"d\", \"return {\" + row.map(function(name, i) {\n      return JSON.stringify(name) + \": d[\" + i + \"]\";\n    }).join(\",\") + \"}\");\n    o = f ? function(row, i) { return f(a(row), i); } : a;\n  });\n};\nIn the above, a converts the array of column values to an object with named properties corresponding to the column names, and f is an optional user-specified function which converts this object to whatever representation the user desires. The function o is the composition f \u25cb a, equivalent to a when f is not specified.\nI think this last approach is also useful when you want to convert away from the array representation entirely, as in the choropleth where you want to create a map from id to value. In this case the map function f could return undefined, but have a side-effect of populating the map, say:\n``` js\nvar rateById = {};\nd3.tsv(\"unemployment.tsv\", function(d) {\n  rateById[d.id] = +d.rate;\n}, function(error) {\n  // render choropleth here\n});\n```\nAlthough, now that I look at it, it\u2019s unfortunately obvious that we can\u2019t distinguish between two overloaded forms of d3.tsv: d3.tsv(url, conversionFunction) which returns a request that has not yet been sent, and d3.tsv(url, callbackFunction) which returns a request that has been sent and has no conversion function. So perhaps we need to hook into the xhr.response function to compose f \u25cb a. Maybe:\n``` js\nvar rateById = {};\nd3.tsv(\"unemployment.tsv\")\n    .convert(function(d) { rateById[d.id] = +d.rate; })\n    .get(function(error) {\n      // render choropleth here\n    });\n```\nAnd the downside of this is that it doesn\u2019t fit into the shorthand Queue API (queue.defer), since it requires chaining methods to construct the request function, rather than a single function call with multiple arguments. Plus it requires patching a method into d3.xhr, which isn\u2019t horrible but is slightly undesirable. (Wrapping xhr.response would also be possible, though arguably more confusing.)\nCome to think of it, if d3_dsv exposed the default conversion method, then there\u2019s at least an awkward way you could cobble together this functionality with minimal changes to the API:\njs\ndsv.converter = function(f) {\n  var o;\n  return function(row) {\n    if (o) return o(row);\n    var a = new Function(\"d\", \"return {\" + row.map(function(name, i) {\n      return JSON.stringify(name) + \": d[\" + i + \"]\";\n    }).join(\",\") + \"}\");\n    o = f ? function(row, i) { return f(a(row), i); } : a;\n  });\n};\nHere, a converter is a function that assumes it will first be called on a header row, and then for subsequent rows changes behavior to convert an array of column values into an object with named properties according to the columns. This could be used in conjunction with d3.xhr as follows:\n``` js\nvar rateById = {};\nd3.xhr(\"unemployment.tsv\")\n    .mimeType(\"text/tab-separated-values\")\n    .response(d3.tsv.converter(function(d) { rateById[d.id] = +d.rate; }))\n    .get(function(error) {\n      // render choropleth here\n    });\n```\nBut of course that\u2019s awkward because you have to specify the mime type. Or you could use d3.tsv, but then you\u2019re reassigning the response function. And it\u2019s still not compatible with the Queue.js shorthand.\n. I don't want to start using objects as named arguments. I've always found that awkward.\nI think we could interpret d3.tsv(url, function) as d3.tsv(url, callbackFunction) and d3.tsv(url, function, function) as d3.tsv(url, rowFunction, callbackFunction). And then, expose tsv.row(function) as an alternate method of specifying the row function. This way, you could use a row function in conjunction with Queue.js, or you could use it with d3.tsv directly via method chaining.\nAlso, we'd need to allow the row function to be passed to dsv.parse(text, function), as described above.\n. The callback should always be the last argument for asynchronous functions per JavaScript (well, Node.js) convention. This offers compatibility with Queue.js, for one.\n. I took a crack at my proposal in #1107; take a look and let me know what you think?\n. The reason this has not yet been implemented yet is because we have not yet decided whether the function passed to append should return a string indicating the name of the element to create, or the element itself. The former is what you\u2019ve implemented, and arguably the more obvious behavior. The latter is what selection.select supports, and allows more flexibility. Although it\u2019s already possible to append a specific element by using selection.select(function), so arguably a selection.append(function) where the function returns an element is less useful.\n. Superseded by #1354.\n. Merged into #1285 for 3.2.\n. For posterity, could you point me to the reference for this equation? Spherical law of cosines?\n. Oh man, that's lovely! Thank you so much for the illustrated explanation. :) Although I admit I am still slightly confused because the wikipedia page describes Vincenty\u2019s formulae as iterative, whereas your d3.geo.distance is closed form?\n. Excellent, thanks!\n. Sorry, but it's intentional that D3 does not expose the JSDOM globals. Calling require(\"d3\") only returns the loaded D3 module, and does not pollute the global namespace. If you want to use a DOM inside Node, you\u2019ll have to create that DOM yourself. \n. OK, I see what's happening. The recent change to remove the globals has caused an inconsistency: in some places (such as the definition of d3_selectionRoot in selection-root.js) D3 captures a reference to the global document on initialization, while in other places (such as in selection.append) it depends on the current global document.\nYour code is failing because d3.select(\"body\") selects from the captured document, while selection.append attempts to attempt to the new document that you created. You can avoid this problem by selecting from your new document explicitly, rather than selecting from the default document that is captured when D3 is loaded:\n``` js\nvar d3 = require(\"d3\");\nglobal.document = require(\"jsdom\").jsdom(\"\");\nd3.select(document).select(\"body\").append(\"div\");\n```\nThe reason that D3 exists as a Node module is primarily so that you can use the non-DOM related features, such as d3.geo, d3.scale, and d3.layout. I don't want to restore the old behavior where D3 pollutes the global namespace with its dependent DOM functionality because that makes it incompatible with applications that already have their own (potentially different) functionality.\nI think the solution here is probably to disable d3.select(string) and d3.selectAll(string) in the Node environment, and instead require d3.select(document) first. In other words, to cut off access to d3_selectionRoot, which only makes sense in a browser where there is a primary document visible to the JavaScript runtime.\n. It would probably be a good idea for D3 to refer to captured variables for the document and window, rather than referencing the globals, so that at least it\u2019s always consistent. This would also mean that you could use D3\u2019s DOM directly without needing to re-initializing JSDOM.\n. @arunkjn I have filed a separate issue #1533 to track that.\n. Unfortunately, I don\u2019t think this is quite right either, because it fails on these examples:\njs\nassert.strictEqual(format(\".1r\")(.949), \"0.9\");\nassert.strictEqual(format(\".1r\")(.0949), \"0.09\");\n. Ah, interesting, interesting. I took an alternate two-pass approach in #1046. Which one do you think is better?\n. OK, closed in favor of #1046.\n. Folded into #1065.\n. This should be filed as a separate issue with more detail:\n\nThe system of re-dispatching mousewheel events to a hidden div does not appear to be active on Safari/Chrome/Firefox - fails with a DOM Exception in all on my machine.\n\nI'm unable to reproduce this error, so you'll need to provide more information, preferably including an example that demonstrates the breakage. But at the very least the exact error details and stack trace, and the browser versions. Here\u2019s an example that works for me in all browsers:\nhttp://bl.ocks.org/d/3681006/\nI tested against both V2 and V3, even though there has been no change to the zoom behavior recently. Furthermore, Firefox uses the hidden div for scroll events. It's a bit rusty now, but I think the only browser that didn't support re-dispatching the scroll event to a different target was IE9. Although I 'spose it could have been Firefox 3.6, which was also pretty buggy.\nAs for the mousewheel.detail multiplier, which should in general never been used except on ancient browsers but is in this case due to the above error which needs more detail to investigate, it does look a little low on input devices with discrete wheels (e.g., Naga Razer). On the other hand, it feels perfectly tuned for analog devices (e.g., Magic Trackpad), so whatever number you change it to is simply going to trade-off between those two devices. You might think you could apply a heuristic to distinguish these two types of devices, but I tried that for a long time with Polymaps and it never worked, hence the switch to using scrolling in a hidden div. I'm more concerned about the hidden div failing than I am tweaking this fallback mechanism.\n. Folded into #1065.\n. Folded into #1065.\n. I prefer the other solution in the linked question. Why doesn\u2019t that work for you? You say \"my data is bound below [the] g-node I want to transform\", but it\u2019s not clear why you can\u2019t bind the data on the same level you are transforming.\n. I appreciate the effort but I'm not sure this is the right solution. This ends up loading large chunks of code that are unusable in a non-DOM environment. And I'm not wild about the idea of needing to protect every use of d3_document and d3_window in the future.\nI think a better solution would be to extract DOM-related code from d3.core.js and move it to d3.dom.js (likely moving src/compat/style.js to src/dom/compat.js, too). Then you could build a version of d3 that just has the parts you need, say d3.core + d3.scale + d3.time, with no DOM dependencies.\nAlthough the downside there is that you have to build a custom version of D3 for use within a web worker, or we have to provide multiple releases. And moving all the files is disruptive, so I'd probably prefer not doing it soon.\n. Thanks for the request. I've implemented a slightly different fix (46a586d) in the capture-globals branch.\n. This is already fixed by #799, which exposes the drag behavior instance. You can then register an additional dragmove listener or replace the force layout's.\n. It's true that you can get the document from element.ownerDocument, and the window from document.defaultView. However, there are a number of places where D3 needs access to a top-level document (such as d3.transform(string), d3.select(string), d3.html). Also, I'm slightly wary of whether this would have a performance impact on a very common operation. I think it makes more sense to bind the top-level d3 instance to a top-level document or window, and instantiate multiple d3 instances if you want to manage multiple documents or windows. For example, I don't think we should try to support a selection that spans multiple documents or windows.\n. Folded into #1065.\n. Folded into #1065.\n. Folded into #1065.\n. Folded into #1065.\n. I think I'd probably do one or the other, so if we switch to value === source, then use that exclusively instead of the arguments.length check. It seems reasonable, although it would help to have a concrete (code) example of why you want this functionality. I can't think of any places in the D3 API where this would change the behavior.\n. Looks good.\n. This looks good. Was wondering if we should support an accessor, as in d3.set(array, function), similar to what we do for d3.sum and d3.extent. But since you can also do that using d3.set(array.map(function)), I think it's fine not to provide this functionality. Also, d3.set isn't number-specific, unlike those other d3 methods that accept accessor functions.\n. Let's stick with remove for compatibility with d3.map. (I forget the reason exactly, but I think having a method named delete caused problems with some parsers.) Also, these aren't exact polyfills for the ES6 equivalents because they require string coercion.\n. The problem I anticipate with binding the accessor function to the set is that there will be times when you just want to check the key explicitly, and other times when you want to check against a candidate element. So in your example, in addition to saying s.has({key: \"a\", value: \"foo\"}), you might want to say s.hasKey(\"a\"). Of course you could do the same by synthesizing a candidate element, as in s.has({key: \"a\"}), but neither are ideal.\nAnyway, I am currently inclined to keep your first version as-is for simplicity\u2019s sake.\n. Folded into #1120.\n. My issue with this proposal is that it\u2019s a bit limiting to restrict the insertion point to a specific element; selections have multiple elements (which may not be siblings), and selectors work well because they will work provided the structure of the DOM you are inserting into is symmetric.\nSo really, you'd probably also want to allow the reference element to be specified as a function. In which case there is additional confusion as to whether that function can only return an element, or whether it can also return a selector. I think having it only return an element would be okay, and consistent with selection.select(function).\n. The way I would do this would be to use selection.attr(\"class\", function) rather than selection.classed. For example:\njs\nselection.attr(\"class\", function(d) { return d.status; });\nOr if you had two classes:\njs\nselection.attr(\"class\", function(d) { return d.status + \" country-\" + d.country_id; });\nAlso, selection.classed(name) returns whether or not the first node in the selection has the class name. We shouldn\u2019t change that behavior; all of D3\u2019s DOM methods have both setter methods (two arguments) and getter modes (one argument). So, if we were to allow functions to specify class names, it would need to be selection.classed(function, true) to set a dynamic class, and selection.classed(function, false) to remove a dynamic class.\nI\u2019m inclined at the moment to not support this functionality for the sake of parsimony and simplicity.\n. Your implementation needs a few tweaks, but I appreciate your suggestion. I'd probably name it d3.deviation rather than d3.sd, also.\nFWIW, there\u2019s also Jason Davies\u2019 science.js, which includes a variance implementation:\njs\n// Unbiased estimate of a sample's variance.\n// Also known as the sample variance, where the denominator is n - 1.\nscience.stats.variance = function(x) {\n  var n = x.length;\n  if (n < 1) return NaN;\n  if (n === 1) return 0;\n  var mean = science.stats.mean(x),\n      i = -1,\n      s = 0;\n  while (++i < n) {\n    var v = x[i] - mean;\n    s += v * v;\n  }\n  return s / (n - 1);\n};\n. For consistency with d3.mean etc., we should ignore any elements with NaN values (and null and undefined). Also, your implementation assigns to the input array, rather than creating a temporary value used for the variance computation, which is both slow and has a strongly undesirable side-effect of clobbering the input. :) Take a look at how d3.mean is implemented, and model your code after that, and it should adhere closer to D3\u2019s conventions.\n. Can I ask you to sign the CLA, per D3\u2019s CONTRIBUTING guidelines?\n. Better! If you wouldn\u2019t mind changing the tab indents to two spaces, that would help, or I can do it when it\u2019s merged.\n. I add methods to the API reference when they are released (and not before, so as to avoid confusion).\n. Merged into #2118 (with a handful of fixes) and staged for 3.5.\n. Folded into #1120.\n. Derp. Thank you!\n. Excellent!\n. Folded into #1120.\n. This has been implemented as zoom.extent and zoom.translateExtent in d3-zoom for D3 4.0.\n. I can't help but wonder what it would look like to reimplement albersUsa as a composite of raw projections, rather than a composite of full projections. I might take a crack at it and see if it simplifies things. (It could be a bad idea.)\n. Folded into #1120.\n. Although, a much simpler way of doing this would be to change projection.center() to specify non-rotated coordinates. Which is probably what we should have done in 3.0, but to change that behavior now would be backwards-incompatible.\ndiff\n-    var center = project(\u03bb, \u03c6);\n+    var center = projectRotate(\u03bb, \u03c6);\nI can maybe still see it as useful to expose a rotation API, but it's not a very concise way of specifying the projection's center in pre-rotated coordinates. You end up with something like this:\n``` js\nvar projection = d3.geo.azimuthalEqualArea()\n    .scale(width)\n    .translate([53, 437])\n    .rotate([100, -45])\n    .scale(2159);\nprojection.center(projection.rotation()([-122.4183, 37.7750]));\n```\nOr like this, which is even worse:\n``` js\nvar rotation = d3.geo.rotation([100, -45]);\nvar projection = d3.geo.azimuthalEqualArea()\n    .scale(width)\n    .translate([53, 437])\n    .center(rotation([-122.4183, 37.7750]))\n    .rotate(rotation.rotate())\n    .scale(2159);\n```\nWhereas ideally we would have something like this as a single statement:\njs\nvar projection = d3.geo.azimuthalEqualArea()\n    .scale(width)\n    .center([-122.4183, 37.7750])\n    .translate([53, 437])\n    .rotate([100, -45])\n    .scale(2159);\nA few options:\n- An additional boolean parameter to either projection.rotate or projection.center indicating whether or not rotation should affect the projection center. This is concise but obtuse.\n- A separate-but-similar replacement center method which uses non-rotated coordinates. \"nonRotatedCenter\" is too verbose, \"origin\" is similarly obtuse.\n- Break backwards-compatibility by changing the behavior of projection.center. This would only change the behavior when used in conjunction with projection.rotate. Built-in projections that use this functionality (e.g., d3.geo.albers) would have backwards-compatible default settings. \n. Self-contained rotation definition:\n``` js\nfunction rotation(rotate) {\n  var degrees = 180 / Math.PI,\n      radians = Math.PI / 180,\n      \u03b4\u03bb = rotate[0] * radians,\n      \u03b4\u03c6 = rotate[1] * radians,\n      \u03b4\u03b3 = rotate.length > 2 ? rotate[2] * radians : 0,\n      cos\u03b4\u03c6 = Math.cos(\u03b4\u03c6),\n      sin\u03b4\u03c6 = Math.sin(\u03b4\u03c6),\n      cos\u03b4\u03b3 = Math.cos(\u03b4\u03b3),\n      sin\u03b4\u03b3 = Math.sin(\u03b4\u03b3);\nreturn function(coordinates) {\n    var \u03bb = coordinates[0] * radians + \u03b4\u03bb,\n        \u03c6 = coordinates[1] * radians,\n        cos\u03c6 = Math.cos(\u03c6),\n        x = Math.cos(\u03bb) * cos\u03c6,\n        y = Math.sin(\u03bb) * cos\u03c6,\n        z = Math.sin(\u03c6),\n        k = z * cos\u03b4\u03c6 + x * sin\u03b4\u03c6;\n    return [\n      Math.atan2(y * cos\u03b4\u03b3 - k * sin\u03b4\u03b3, x * cos\u03b4\u03c6 - z * sin\u03b4\u03c6) * degrees,\n      Math.asin(Math.max(-1, Math.min(1, k * cos\u03b4\u03b3 + y * sin\u03b4\u03b3))) * degrees\n    ];\n  };\n}\n```\n. Folded into #1120.\n. I was thinking that d3.geo.length would return the circumference for polygons. What do you think?\n. (FYI, I'm merging this into a local branch to add tests\u2026)\n. Folded into #1104.\n. Fixes #1101.\n. Folded into #1120.\n. Folded into #1120.\n. Superseded by fe09bb0. Thanks for the help!\n. I don't think it needs to so event-like. I'd write your example as:\njs\nd3.csv(\"test/data/sample.csv\")\n    .row(function(d) { d.Hello = -d.Hello; })\n    .get(callback);\nOr, if you prefer:\njs\nd3.csv(\"test/data/sample.csv\", callback)\n    .row(function(d) { d.Hello = -d.Hello; });\n. Also, I think it would be more difficult to hook into d3.xhr's internal event dispatch, rather than simply overriding the already-exposed xhr.response function. Also, since you can have multiple listeners for the same event, it's not clear how you would combine multiple \"row\" listeners (successive mapping of data? stopping when the first listener returns null?). I think a dedicated function is appropriate in this case.\n. Folded into #1120.\n. Folded into #1120.\n. Staged in #1120.\n. Makes me happy that you were able to use this simply by patching projection.stream. :) Good job!\n. Folded into #1120.\nI think it would be nice to expose this as projection.clipExtent, taking an object compatible with d3.geo.path's extent function: [[xmin, ymin], [xmax, ymax]]. It probably wouldn't hurt to still expose d3.geo.clipView, but I think projection.clipExtent would be more convenient for common usage.\n. Looks amazing!\n\n. Although, I found a new bug when I tried to apply projection.clipExtent to a sphere. The sphere is inverted; rather than covering the globe, it covers the rest of the viewport, i.e., background space.\nhttp://bl.ocks.org/mbostock/fde1a65845aef4fe33d1\n. Folded into #1120.\n. Hmm. We have d3.layout.voronoi now, but no d3.layout.delaunay.\n. You can do this in 3.0 using xhr.response and parseRows. For example:\njs\nd3.tsv(\"file.tsv\")\n    .response(function(request) { return d3.tsv.parseRows(request.responseText); })\n    .get(callback);\nOr equivalently:\njs\nd3.tsv(\"file.tsv\", callback).response(function(request) {\n  return d3.tsv.parseRows(request.responseText);\n});\nYou can also pass an optional row function to parseRows that would let you convert it to the desired format:\njs\nd3.tsv(\"file.tsv\", callback).response(function(request) {\n  return d3.tsv.parseRows(request.responseText, function(fields) {\n    return {foo: fields[0], bar: fields[1]};\n  });\n});\nIn 3.1 you will be able to specify a row function for d3.dsv.parse, as well. This would still require a header, but allows you to do type-conversion and filtering as the file is parsed:\njs\nd3.tsv(\"file.tsv\", callback).row(function(d) {\n  d.value = +d.value;\n  return d.value > .1 ? d : null;\n});\nSee #1107 for more details.\n. Excellent.\n. Can I ask you to sign the CLA, per D3\u2019s CONTRIBUTING guidelines?\n. Finally looking at this now for 3.5. I love the diagram you made illustrating the different approaches. I think I\u2019m inclined to approach B \u2014 truncating the radius if the arc is too thin\u00a0\u2014 based on it being similar to how SVG treats rx and ry for rounded rects (per @deanmalmgren\u2019s comment).\nAlso for backwards-compatibility (and based on expected usage), I think it makes sense to have the cornerRadius default to zero rather than default to an accessor like the other properties.\nI plan on working on integrating this in the next few days.\n. Fixed in #2118 for 3.5.\n. We should change the behavior of selection.on and dispatch.on simultaneously so they're consistent. The implementation of selection.on will be different because there's not an explicitly registry of the supported event types.\nI like it when the inputs and outputs are symmetric. If we decide to support selection.on(\".foo\"), it should probably return only the first matching listener, rather than the array of all listeners. This is consistent with selection.on(\"click.foo\") only considering the first non-null node in the selection.\nAs for selection.on(\".foo\", listener) reassigning multiple listeners, and being the more general form of selection.on(\".foo\", null), I guess I'm okay with that. But I can't think of when I would ever use such functionality.\nIt does seem a bit weird that selection.on(\".foo\", null) removes all listeners with the name \"foo\", but selection.on(\"click\", null) only removes the non-named listener for the event type \"click\". In other words we support removing all listeners by name, but not removing all listeners by event type. And should selection.on(\"\", null) remove all listeners of all types and names? Heh.\nIt's tempting to require \".foo\" rather than \".foo\", and then use \"click.\" if you want to remove all click listeners, or \"*\" for all listeners; then \"click\" would refer to the non-named listener for click events, rather than all click listeners. But of course, this deviates from jQuery and is less CSS-like. I suppose \"click.\" could refer to the non-named listener for \"click\" events, but that sounds confusing.\nSo, hrm. I'm not sure what to do yet.\n. > Hmm, it seems impossible to support selection.on(\".foo\", listener) as we don\u2019t necessarily know all of the supported event types.\nI was imagining that selection.on(\".foo\", listener) would replace any current listener named \"foo\" with the specified listener, rather than registering a listener named \"foo\" for all known event types. (It would have no effect if no current listeners had the name \"foo\".) But that would require changing the behavior of d3.dispatch as well. And, as I said, I can't think of when I would ever use such functionality, other than to remove a set of listeners.\n\nPerhaps selection.on(\"click\", null) should remove all named listeners too for the click event, to be more CSS-like?\n\nThat would not be backwards-compatible, and so would require waiting until 4.0. And, I think, confusing. Presumably you'd also change selection.on(\"click\", listener) to replace all click listeners with the specified listener (removing all other click listeners). Which means if you wanted multiple listeners, you now must specify a name for every listener, rather than the current behavior which allows a single non-named listener in addition to any number of named listeners.\nCurrently we support the following modes:\n- selection.on(\"type\") - returns the unnamed listener for the specified event type, or null\n- selection.on(\"type\", null) - removes the unnamed listener for the specified event type, if any\n- selection.on(\"type\", listener) - adds or replaces the unnamed listener for the specified event type\n- selection.on(\"type.name\") - returns the named listener for the specified event type, if any\n- selection.on(\"type.name\", null) - removes the named listener for the specified event type, if any\n- selection.on(\"type.name\", listener) - adds or replaces the named listener for the specified event type\nIn #590, there is talk of supporting setting multiple listeners simultaneously:\n- selection.on(\"type1 type2\") - returns any listener for the specified event types (order undefined), or null\n- selection.on(\"type1 type2\", null) - removes any unnamed listeners for the specified event types\n- selection.on(\"type1 type2\", listener) - adds or replaces unnamed listeners for the specified event types\n- selection.on(\"type1.name1 type2.name2\") - like above, but for named listeners\n- selection.on(\"type1.name1 type2.name2\", null) - like above, but for named listeners\n- selection.on(\"type1.name1 type2.name2\", listener) - like above, but for named listeners\nThe above additions do not need to be included in this pull request, but it's worth thinking about how this change can be consistent with the proposed change above.\nIn this thread we are suggesting three new modes:\n- selection.on(\".name\") - returns any listener with the specified name (order undefined), or null\n- selection.on(\".name\", null) - removes any listeners with the specified name\n- selection.on(\".name\", listener) - replaces any listeners with the specified name\nI think this is okay, but selection.on(\".name\") and selection.on(\".name\", listener) don't seem very useful. (And likewise, selection.on(\"type1 type2\"), selection.on(\"type1.name1 type2.name2\"), selection.on(\"type1 type2\", listener) and selection.on(\"type1.name1 type2.name2\", listener) don't seem particularly useful.)\nIf you did only handle selection.on(\".name\", null), what would you do if someone tried selection.on(\".name\") or selection.on(\".name\", listener)?\n. You can use d3.scale.ordinal:\njs\nd3.unique = function(array) {\n  return d3.scale.ordinal().domain(array).domain();\n};\nIn 3.1, you can use d3.nest and d3.map, which would also allow an accessor:\njs\nd3.unique = function(array, f) {\n  return d3.nest().key(f || String).map(array, d3.map).keys();\n};\nIn earlier versions you can do the same thing with an extra map:\njs\nd3.unique = function(array, f) {\n  return d3.nest().key(f || String).entries(array).map(function(d) { return d.key; });\n};\n. D3 3.1 added d3.set, which is what I would recommend now for computing distinct values:\njs\nd3.set([\"foo\", \"bar\", \"foo\"]).keys(); // \"foo\", \"bar\"\n. I changed [^\\\\.] to [^.], since I think you meant to only match not-period, rather than not-period-or-blackslash. (Within the square brackets, period means a literal period rather than any character.)\n. Looks good. Thanks for the fix!\n. Staged in #1120.\n. This looks good!\n. Sure, as long as it stays private that\u2019s fine. d3/geom/point sounds reasonable, and d3_geom_pointX and d3_geom_pointY.\n. How about calling it simply \"step\"?\n. Merged into #1285 for 3.2.\n. Typically this is achieved by listening for brush events and then modifying the brush extent as necessary, rather than implementing it directly in the brush. This way, you can define whatever behavior you want.\n. Yeah, sorry, I forgot how the brush uses the scale\u2019s range to limit the extent. I could see adding a flag to limit this behavior, such that the brush extent is allowed to go outside the scale range. But I think it would just be a binary flag\u2014either observe the range, or don\u2019t\u2014rather than the four conditions you proposed. Although, there is a related question as to whether this should be controlled for x and y separately (probably). It also seems related to the concept of scale clamping, but probably deserves a separate API.\n. I think if I had to pick an API off the top of my head (that I might regret later), I\u2019d probably expose a brush.clamp method. The behavior could be similar to brush.extent: if both an x and y scale are set, then the clamp is a two-element array of booleans; if only one of x or y is set then clamp is just a boolean. \n. To apply a similar implementation strategy as to brush.extent, I would store the internal state in the general form: a two-element array of booleans. Then do the conversion between the single-boolean and array-form only in brush.extent, depending on whether the x and y scales have been set. Something like:\njs\nbrush.clamp = function(_) {\n  if (!arguments.length) return x && y ? clamp : clamp[+!x];\n  if (x && y) clamp = [!!_[0], !!_[1]]; else clamp[+!x] = !!_;\n  return brush;\n};\nA bit clever I suppose; you could use x ? 0 : 1 instead.\n. Looks good. Will be part of 3.2 release. If you feel like rebasing against the current master to ease my subsequent merge (and then force-push to your repo) that would be helpful but not required.\n. Merged into #1285 for 3.2.\n. You appear to be using an old version of D3; this feature was added in 3.1. See 873db8d8930998ef92141f200dc967e9358d39c9, #1071, #1105.\n. Looks good. My only thought is regarding code duplication\u2014perhaps there's a way to reduce it here.\n. (Didn't mean to close, sorry.)\n. I have incorporated my suggestions and it will be part of the next patch release. Thank you!\n. Thanks for this fix. Yeah, I don\u2019t want to add a module.exports to d3.js since it\u2019s not used by vanilla script tags and it adds clutter. Also, the top-level d3.js you edited is a generated file so your edits would get rewritten.\nThe globals.js is only intended for the Node.js environment which does not provide a DOM; parts of D3 depend on some DOM globals (namely window and document), so those are provided by globals.js when D3 is loaded via index.js. In a browser, d3.js is used directly, and so does not load globals.js.\nFor Browserify, I created an index-browserify.js that simply requires the vanilla d3.js (which has the side-effect of defining the d3 global) and then adds the module.exports statement. Would that work for component, too?\n. Within index-browserify.js, window and document must exist (or else vanilla d3.js would crash), so you shouldn\u2019t need to check for their existence. \nMy guess is that the most accurate way to delete the global would be delete this.d3;, but I haven\u2019t tested.\n. Well, I suppose you could always\njs\n(function() { delete this.d3; })();\n. A slightly more robust option would be delete self.d3;, since that works in Web Worker contexts as well. (Although currently using D3 in a Web Worker context requires a custom build via SMASH that removes the parts that depends on the DOM being available.)\n. Sounds good; you could rebase and squash into a single commit if you\u2019re feeling tidy.\n. I realized your edits needed to be on src/component.js, since component.json is generated to avoid duplicate definition of d3.version. So I did that.\n. Excellent, thank you!\n. This seems like an exceptionally special case that can be easily handled by the caller calling force.stop; there is no need to do this in the default implementation.\n. Thanks, @clkao!\n. This seems much more aggressive (and less adaptive) than our previous approach:\n\nI imagine that there\u2019s a corresponding performance penalty. It\u2019s always going to be the case the adaptive resampling won\u2019t detect some types of distortion. Another technique we could apply here, perhaps, is looking at the finite derivative around the candidate sample point, although I\u2019m not sure if that would be any better.\nAnyway, I guess I\u2019m asking: Can we do better? And, is this the right trade-off, or are we penalizing performance in the common case to handle a special one?\n. I think user control and sensible defaults are important here, too. The default should be fast but reasonably accurate (a compromise). The user can then fine-tune resampling if greater accuracy or speed is needed.\n. \nSeems like you fixed the problem.\n. Merged into #1285 for 3.2.\n. While Chrome should be using BST, I don\u2019t think Firefox is correct here, either, since the date is not in midnight local time. I noticed some weird behavior:\n```\n\nnew Date(1970, 0)\nThu Jan 01 1970 01:00:00 GMT+0100 (BST)\nnew Date(1970, 0, 0)\nWed Dec 31 1969 00:00:00 GMT+0000 (BST)\nnew Date(1970, 0, 1)\nThu Jan 01 1970 01:00:00 GMT+0100 (BST)\nnew Date(1970, 0, 2)\nFri Jan 02 1970 00:00:00 GMT+0100 (BST)\n```\n\nNot to mention:\n```\n\nvar d = new Date(1970, 0, 1);\nThu Jan 01 1970 01:00:00 GMT+0100 (BST)\nd.getHours();\n1\nd.setHours(0);\n0\nd.getHours();\n1\n```\n\nSo your code works, but only because the year you\u2019re setting isn\u2019t 1970. If you were to call d3.time.day on a 1970 date, you\u2019d still get the wrong answer (at 1 AM local rather than midnight).\n```\n\nvar d = new Date(0);\nThu Jan 01 1970 01:00:00 GMT+0100 (BST)\nd.setFullYear(2000, 0, 1);\n946688400000\nd\nSat Jan 01 2000 01:00:00 GMT+0000 (GMT)\nd.setHours(0, 0, 0, 0);\n946684800000\nd\nSat Jan 01 2000 00:00:00 GMT+0000 (GMT)\n```\n\nHere\u2019s it not working:\n```\n\nvar d = new Date(0);\nThu Jan 01 1970 01:00:00 GMT+0100 (BST)\nd.setFullYear(1970, 0, 1);\n0\nd.setHours(0, 0, 0, 0);\n0\nd\nThu Jan 01 1970 01:00:00 GMT+0100 (BST)\n``\n. So what about a simpler fix that avoids the summer time weirdness: constructing the date asnew Date(2000, 0)rather thannew Date(1970, 0)`? That would still have the bug for dates in 1970, but that would be Firefox\u2019s fault, and we would at least avoid Firefox\u2019s bug in the common case.\n. > So day.floor should return the smallest Date object for that particular day, which could have a non-midnight time.\n\nThat\u2019s already the case, is it not? So you\u2019re saying that the current behavior of d3.time.day.floor is correct (Thu Jan 01 1970 01:00:00 GMT+0100 (BST)), it\u2019s just that d3_time_scaleLocalFormats isn\u2019t detecting this as a day boundary because date.getHours returns a non-zero value.\nAnother way of checking if a given date is a boundary is by comparing it to the floored value, since floor is idempotent. For example, d3.time.day(d) >= d. (Note: you can\u2019t use == to test dates for equality.) But I expect your suggestion of decrementing the time by one millisecond and seeing if the field changes is more efficient.\n. Can we have tests for this, both for d3.time.day and d3.time.days?\n. Also, d3.time.day.ceil is still broken, since, like d3.time.days it depends on the current day step implementation, which doesn\u2019t advance in a way that is consistent with the fixed d3.time.day:\njs\nfunction(date, offset) {\n  date.setDate(date.getDate() + offset);\n}\nFor example, in TZ=Asia/Amman node, you can see how setDate doesn\u2019t advance correctly to the next day:\n``` js\n\nd = d3.time.day(new Date(2014, 2, 27, 5, 0, 0))\nThu Mar 27 2014 00:00:00 GMT+0200 (EET)\nd.getDate()\n27\nd.setDate(28)\n1395954000000\nd\nThu Mar 27 2014 23:00:00 GMT+0200 (EET)\nd.getDate()\n27\n```\n\nAnd likewise for d3.time.days, the current behavior is:\n``` js\n\nd3.time.days(new Date(2014, 2, 26, 12), new Date(2014, 2, 31, 12))\n[ Thu Mar 27 2014 00:00:00 GMT+0200 (EET),\n  Thu Mar 27 2014 23:00:00 GMT+0200 (EET),\n  Fri Mar 28 2014 23:00:00 GMT+0300 (EEST),\n  Sat Mar 29 2014 23:00:00 GMT+0300 (EEST),\n  Sun Mar 30 2014 23:00:00 GMT+0300 (EEST) ]\n```\n\nThe desired behavior is:\n``` js\n\nd3.time.days(new Date(2014, 2, 26), new Date(2014, 2, 31))\n[ Thu Mar 27 2014 00:00:00 GMT+0200 (EET),\n  Fri Mar 28 2014 01:00:00 GMT+0300 (EEST),\n  Sat Mar 29 2014 00:00:00 GMT+0300 (EEST),\n  Sun Mar 30 2014 00:00:00 GMT+0300 (EEST) ]\n```\n. If there are cases where the DST change coincides with a week, month or year boundary, then would this same bug apply to those larger intervals?\n\nI have to say, this is turning into quite a complicated fix! It seems like JavaScript runtimes could do a better job of this rather than us having to employ elaborate workarounds.\n. I opted for the simpler solution for now, since I\u2019m not sure we\u2019re likely to encounter the other issues in practice.\n. > Sorry for being dim but what's the simple fix you recommend for displaying the year and not 1am on the axis?\nThe other way to fix this is to explicitly specify an axis.tickFormat (using d3.format(\"%Y\"), for example), rather than relying on the default multi-scale time format and dates that are precisely aligned with time interval boundaries.\n. Resurrecting a thread here because I\u2019m starting work on the new d3-time-interval module\u2026\nIt seems like the main cause of the pain here is (ironically) caused by an earlier fix 83b5f459979a062a1da38d4675be746788697883 for #711, which changed the day method to workaround the abysmal behavior of the Date constructor regarding two-digit years. Before it was:\njs\nfunction day(date) {\n  return new Date(date.getFullYear(), date.getMonth(), date.getDate());\n}\nAnd after the fix:\njs\nfunction day(date) {\n  var day = new Date(0, date.getMonth(), date.getDate());\n  day.setFullYear(date.getFullYear());\n  return day;\n}\nThis introduced the new bug where the wrong date could be returned if the timezone changed between 1900 (and later, after 3847172c6f1199acfb94715064eaf027298c4958, 2000) and the current date\u2019s year. So the current code is:\njs\nfunction day(date) {\n  var day = new Date(2000, date.getMonth(), date.getDate());\n  day.setFullYear(date.getFullYear());\n  return day;\n}\nBut this has the same problem if the definition of DST changes between 2000 and the current year, correct? Although, now I\u2019m not really sure how this intersects with the ES spec you quoted:\n\nThe implementation of ECMAScript should not try to determine whether the exact time was subject to daylight saving time, but just whether daylight saving time would have been in effect if the current daylight saving time algorithm had been used at the time. This avoids complications such as taking into account the years that the locale observed daylight saving time year round.\n\nThat seems to imply that the current approach is the best you can do.\nThe alternative I was considering, rather than the search method proposed in this pull request, was to do as little as possible to avoid the Date constructor\u2019s broken handling of two-digit years:\njs\nfunction day(date) {\n  var y = date.getFullYear(),\n      m = date.getMonth(),\n      d = date.getDate();\n  if (0 <= y && y <= 99) {\n    date = new Date(-1, m, d);\n    date.setFullYear(y);\n  } else {\n    date = new Date(y, m, d);\n  }\n  return date;\n}\n(I think you proposed this previously, but I can\u2019t find it now.) This assumes that the year -1 (1 B.C.) has the same daylight savings behavior as years in the range [0,99], but I think that\u2019s a safe assumption.\n(We still need to change the predicates to fix the non-midnight boundary issue, but this should at least return what the browser thinks is the correct definition of a day.)\n. Another solution?\njs\nfunction day(date) {\n  date = new Date(+date);\n  date.setHours(0, 0, 0, 0);\n  return date;\n}\n. This code has been completely rewritten in d3-time for 4.0.\n. This is closely-related to #1088, and the proposed solution there was:\n\nhave scale.nice(m) where m is the same argument that scale.ticks takes\n\nIn addition to being consistent with scale.ticks, the previous proposal is more flexible for varying domains. Also, it\u2019s pretty easy already to nice a domain to a specific interval:\njs\nvar domain = scale.domain();\nscale.domain([Math.floor(domain[0] / step) * step, Math.ceil(domain[1] / step) * step]);\n. This seems useful; however, I think it would be best to not name this method scale.invert, as scale.invert(y) is not symmetric with scale(x). Perhaps the name scale.invertDomain, to imply that it returns a slice of the domain?\nImplementation-wise, this needs test. And I wouldn\u2019t implement this using d3.scale.ordinal, since that is heavyweight and requires mapping the range value to a string. I think you want to use d3.bisect to find the index of the input value in the range, and then use that to compute the appropriate slice of the domain.\n. Or perhaps scale.invertExtent.\n. You\u2019re right about the range being unsorted; sorry about that. The point about strings is that when using JavaScript objects as maps, the keys must be coerced to strings. So with d3.scale.ordinal, the domain values are coerced to strings; this happens as a side-effect of the domain being stored in a d3_Map (see map.js).\nPrior to this change, there has not been a requirement that the quantize scale support only range values that are coercible to a string. For example, you could say:\n``` js\nvar small = {},\n    medium = {},\n    large = {};\nvar x = d3.scale.quantize()\n    .domain([0, 10])\n    .range([small, medium, large]);\nx(2); // returns small\n```\nThe only way to invert in this case would be to use Array.indexOf. This is a linear scan, so it\u2019s slower, but in practice the number of quantized outputs is typically small so this cost likely doesn\u2019t matter (and coercing to a string has some cost, besides):\njs\nx.range().indexOf(medium); // returns 1\n. I think if the range has duplicate values it\u2019s sufficient to return the first match, and then document it as such.\n. One thing missing I see is when the input value is outside the range. In this case, the invertExtent should probably return null (since we can\u2019t make any assumptions about the input).\n. The design requirement is that scale and scale.invert are the inverse of each other. So if a scale supports inversion, then scale(scale.invert(y)) returns y and scale.invert(scale(x)) returns x for valid values of y and x.\nThis pull request originally proposed a method named scale.invert which did not meet this requirement, so I suggested renaming the method to something else. An alternate proposal would be to keep the name but to change the behavior to satisfy the requirement, say by having scale.invert(y) return the lowest corresponding value in the domain (rather than a range of values), or perhaps the midpoint (average) matching value.\nI suppose either approach might be okay, but no one has yet to express a compelling use case (a real-world example) for either of these methods; this discussion has been abstract. I can\u2019t think of a situation where I would use either.\n. > As for invertExtent, I suggested a use case when I first posted this pull request, and I am actually using it in my project.\nYou described the usage by giving an example of arguments and corresponding return values, but I don\u2019t consider a use case because you haven\u2019t explained how the method might be used this in a \u201creal-world\u201d example. If you could elaborate on how you are using it in your project, that would help me ascertain how useful this method is (say in comparison with other approaches). For example, does your project require mouse-based interaction while using a quantize scale for position encoding?\n. Sorry! I can\u2019t believe I missed that\u2026\nWhat if the scale has a method that returns the quantized domain values, similar to quantile.quantiles? It would return the thresholds within the domain that are used to divide the domain into discrete values in the range. The default quantile scale would return [.5], for example. I feel like that would be more similar to the threshold scale as well.\n. Would you mind posting an example to bl.ocks.org that uses the proposed method in a visualization? Then it would be easier to consider alternatives. Another possibility that comes to mind is a domainIntervals method that would be amenable to a data-join (and could potentially be extended to the quantile scale to improve that API as well):\n``` js\nvar q = d3.scale.quantize()\n  .domain([0, 10])\n  .range(d3.range(5));\nq.domainIntervals(); // => [[0, 2], [2, 4], [4, 6], [6, 8], [8, 10]]\n```\n. Though I guess it\u2019s equally convenient to use the scale.range for the data join and then map to invertExtent:\njs\nq.range().map(q.invertExtent); // => [[0, 2], [2, 4], [4, 6], [6, 8], [8, 10]]\n. I implemented a similar method for the threshold scale, which changes the code for the threshold key:\njs\nthreshold.range().map(function(d, i) {\n  var extent = threshold.invertExtent(d);\n  return {\n    x0: extent[0] == null ? x.range()[0] : x(extent[0]),\n    x1: extent[1] == null ? x.range()[1] : x(extent[1]),\n    z: d\n  };\n})\nI think it\u2019s an improvement; at the least, it no longer hard-codes the number of elements in the domain because it can detect the undefined upper or lower bound in the extent.\n. Merged into #1285 for 3.2. I changed invertExtent to return [NaN, NaN] when the specified value is not in the range; this is more consistent with d3.extent.\n. Merged into #1285.\n. Merged into #1285 for 3.2.\n. I see, so if string is null, then t is undefined and we get the identity transform. Looks good.\n. Merged into #1249.\n. This relies on a globally-installed copy of Vows, rather than using the version of Vows that is required by D3. This is undesirable because it means the user will have to install Vows manually (as npm install -g vows) rather than the standard method using package.json (npm install). Also, this approach won't work if the user\u2019s globally-installed version of Vows is different from the one D3 depends on.\nI'm not familiar with Cygwin, but I'm afraid you'll need to solve this error a different way.\n. This is still undesirable because it assumes that the vows binary is a JavaScript binary rather than an arbitrary executable. (I admit this is probably a safe assumption for a node module, but it\u2019s not a requirement.)\nDoes ./node_modules/.bin/vows work?\n. Sorry, but this seems like a bug (or fundamental shortcoming) of Cygwin rather than something we should fix in D3. If Cygwin doesn\u2019t work for you, I recommend using a more development-friendly operating system such as Ubuntu or OS X.\n. Beautiful. Nice job testing.\n. Merged into #1249.\n. There would be one fewer moving part if we autogenerated src/start.js rather than creating a new src/version.js. Also, src/version.js has to be at the start, anyway, because it not only defines the version field but also the d3 namespace. So how about a script to generate src/start.js, instead?\n. I noticed another issue (prior to your latest change) which is a circular dependency in the Makefile. If you delete the generated src/start.js, then prerequisite determination $(shell node_modules/.bin/smash --list src/d3.js) fails because src/start.js does not exist, which is imported by src/d3.js. I suppose this isn't a big problem as long as src/start.js is not removed by make clean, despite it being a generated file.\n. Also, I was thinking that we should put all of our binaries in a bin folder (rather than src) and use the #!/usr/bin/env node line to make them executable.\n. (The three binaries are start-version, component and locale, for now.)\n. Can you rename bin/start-version to bin/start now?\nAlso, I think bin/start is sufficient; you don\u2019t need ./bin/start. Pretty sure you only need ./ when the executable is in the current directory, to disambiguate it from being on the $PATH.\nI still get an error if src/start.js is missing:\n``` bash\n$ rm -f src/start.js && make\n/Users/mbostock/Development/d3/node_modules/smash/smash:46\n  if (error) throw error;\n                   ^\nError: ENOENT, open 'src/start.js'\n./bin/start-version > src/start.js\nnode_modules/.bin/smash src/d3.js | node_modules/.bin/uglifyjs - -b indent-level=2 -o d3.js\nnode_modules/.bin/uglifyjs d3.js -c -m -o d3.min.js\n./bin/component > component.json\n```\nIt continues because Make ignores the error in generating the prerequisites, and because src/start.js is an explicit dependency it continues to rebuild, but still the error is undesirable.\n. Looks good. Feel free to merge to master since this doesn't affect the built d3.js.\n. This looks excellent!\n. Merged into #1249.\n. A user could certainly define their own global.window and global.document before requiring d3. Those loops exist to stash the original global values while loading d3, and then restore them after d3 is loaded. Deleting them also ensures that d3 does not leak anything into the global namespace, and only exports the d3 object.\n. Merged into #1249.\n. This and related issues were discussed at some length in #1145. The result of the discussion was essentially status quo: to favor accessor methods to convert input to a standard representation. So it\u2019s intentional that the children property of each node represents the computed children (in standard form) after running the layout. If you want to preserve the original children, you must use a name other than children, which is reserved by the layout.\n. I agree; we should expose d3.dsv.\n. Exposure of d3.dsv is now staged in #1285 for 3.2.\n. Merged into #1249.\n. This adds an extra layer of closures on all of d3, so has a performance cost in the common case where only the current window is needed. I see it as being valuable to support this use case, but I\u2019d greatly prefer to do it in a way that doesn\u2019t cost other use cases (particularly the main one, where D3 is loaded in a browser).\nFor example, perhaps there\u2019s something we can do with d3_document and d3_window (in document.js).\n. Eh, that seems complicated (and duplicates src/d3.js), sorry. There\u2019s already a node-specific \u201cbuild\u201d of D3, in the sense of the index.js that is only used in a Node (require) environment. Also, you might take a look at test/load.js, which uses SMASH to load a separate minimal copy of D3 for each test. That might not be the ideal API for your use case, but I mention it to point out there are already ways of accomplishing what you desire.\n. Right, that\u2019s because it\u2019s loading a minimal instance of D3 to verify that all the required import statements are there.\n. This looks promising. What about if the name of the argument was d3_window rather than win, and you changed src/end.js to pass in window?\n. (Also, src/start.js is a generated file because it contains the version number, so you\u2019ll need to remake your edits in bin/start.)\n. Right, the issue with the tests is that large parts of D3 don\u2019t depend on having a window or document available. If you change the wrapper function to take a window as its argument, then you now require all tests to have a sandbox with a defined window, whereas previously that only applied to a subset of tests.\nOf course, to compile that symbol needs to be defined, but it can still be null. I pushed my edits to an environment branch.\n. Well, in a sense that\u2019s already possible because you can d3.select(document.documentElement).select(\"foo\"). But besides d3.select and d3.selectAll, there are a few other places that depend on a global window or document, such as d3.mouse and d3.behavior. Although I think it would be possible even there to use element.ownerDocument.defaultView to go from the element to its containing window.\n. Fixed in #2225; D3 no longer assumes a global window or document. So, if there\u2019s no global window or document, you must call d3.select(node).select(string) to first specify the root node of a selection rather than calling d3.select(string) which tries to use the global document.documentElement.\n. There\u2019s already a component.json file. Do we need both? Also, the version number is wrong, and would need to be updated automatically as we do with the other files.\n. Thanks, I appreciate the help. I\u2019m just not familiar with either Bower or Component. I don\u2019t even know if the existing component.json is intended to support Bower (in which case we should delete it with this pull request) or if it\u2019s designed for Component (in which case we should ensure that it actually works).\n. Related #824.\n. Merged into #1285 for 3.2.\n. \n. \nUsing sphere to draw viewport outlines.\n. \n. Whoah, cool. Even better if you clipped to the land outlines!\n. Stunning!\n. I was thinking, we could avoid the overlap by extending clip-view.js to clip the lower48 projection outside the alaska and hawaii projections. But that doesn\u2019t seem essential for now.\n. I decided to adopt more standard projections for Alaska and Hawaii. Here\u2019s the adjusted projection at 960\u00d7600, scale 1285.\n\n. Having the vertical 141\u00b0W parallel was pretty, but it feels wrong to rotate gamma just to achieve the vertical edge. I suppose it wouldn\u2019t be completely wrong as an alternative to use Mercator for Alaska, since we\u2019re already sacrificing equal-area to fit Alaska in the display. But since there\u2019s a standard Albers projection for Alaska, I\u2019m somewhat inclined to stick with it.\n. Also noticed this significantly improves behavior when you render something outside the U.S. Before:\n\nAfter:\n\nIt\u2019s still not perfect since the lower 48 aren\u2019t excluded from overlapping Alaska and Hawaii, but as we\u2019ve discussed we could do that in the future.\nThis doesn\u2019t apply to the raw projection function, which still uses the old branching strategy and thus may behave inconsistently. It might yet be worth using the dummy context to project the point using the real projections and see what happens.\n. Fixes #1159.\n. I wasn\u2019t planning on it; the vast majority of U.S. maps don\u2019t include territories. If you want it back, I\u2019d recommend copying the code for d3.geo.albersUsa and adding in a new projection for PR.\n. @nani3105 Please use Stack Overflow tag d3.js to ask for help. Although I make an effort to assist everyone that asks, I am not always available to provide help promptly or directly. Stack Overflow provides a better collaborative forum for self-help: tens of thousands of D3-related questions have already been asked there, and some answered questions may be relevant to you. If you have a question about D3\u2019s behavior and want to discuss it with other users, also consider the d3-js Google Group or joining the d3-js Slack. Thank you! \ud83e\udd17\n. Thanks for the pull request.\nThe name \u201capply\u201d is inherited by all functions as function.apply, so I wouldn\u2019t use that name here. The name \u201ceach\u201d seems more appropriate, since this method iterates over each entry in the nested map.\nThere are unrelated changes to the Makefile.\nImplementation feedback aside, I\u2019m not sure if this method is worth its weight, given that it\u2019s not to hard to iterate over the entries after they are computed. This is very often done as part of displaying the nested data. Also, if you want to iterate over the leaf entries, you can do that already using nest.rollup (although you just get passed the values array, but you can assign additional properties to the values array).\n. Thanks for the pull request, but I\u2019ve decided to not include this for now in favor of keeping the API smaller.\n. Merged into #1285 for 3.2.\n. JavaScript is single-threaded, and as far as I\u2019m aware, XMLHttpRequest never issues a synchronous callback when send is called, provided the request was configured as asynchronous. Is there something I\u2019m missing here? How were you able to trigger a synchronous callback?\n. Yes, for this failure pattern, the \"load\" event (or possibly the \"readystatechange\" event; I\u2019m not sure what IE9 is using here) is being dispatched synchronously during the call to xhr.send, before d3.xhr has returned. Hence the response function not yet being set.\nChanging the public API as a workaround for IE9 isn\u2019t necessary if we create a private d3_xhr function that takes the response function directly:\njs\nfunction d3_xhr(url, mimeType, response, callback) {\n  \u2026\n}\nAnd then, d3.xhr changes to:\njs\nd3.xhr = function(url, mimeType, callback) {\n  return d3_xhr(url, mimeType, d3_identity, callback);\n};\nWhile d3.json changes to:\njs\nd3.json = function(url, callback) {\n  return d3_xhr(url, \"application/json\", d3_json, callback);\n};\netc.\n. Folded into #1276 with my modifications. If you want to submit any further changes, please post them to that branch. Thank you!\n. Fixed in 3.1.10.\n. I like the API you\u2019ve designed here; it feels very similar to d3.svg.line and d3.geo.path, where you\u2019ve created a useful adapter from data to some SVG string microlanguage. The implementation seems a little bit heavy on the use of arguments and function.apply, but it\u2019s also quite concise and I don\u2019t have any immediate counterproposals.\nMy main reservation here is whether the need is common enough (and painful enough) to justify the additional API. In comparison to d3.svg.line and d3.geo.path, the transform language is much simpler and really we\u2019re talking only about string concatenation. To use your example, the original is four lines and 212 characters:\njs\nd3.select(\"svg\").selectAll(\"g\")\n    .data([{size: 5}, {size: 10}])\n  .enter().append(\"g\")\n    .attr(\"transform\", function(d) { return \"translate(20,\" + d.size * 10 + \")rotate(40)scale(\" + (d.size + 2) + \")\"); });\nVersus with d3.svg.transform, 7 lines and 260 characters, albeit arguably more readable:\njs\nd3.select(\"svg\").selectAll(\"g\")\n    .data([{size: 5}, {size: 10}])\n  .enter().append(\"g\")\n    .attr(\"transform\", d3.svg.transform()\n      .translate(function(d) { return [20, d.size * 10]; })\n      .rotate(40)\n      .scale(function(d) { return d.size + 2; }));\n(Related: this discussion makes me think of CoffeeScript\u2019s string interpolation, which is quite concise.) In practice, I feel like most transforms tend to be fairly simple, such as the use of a translate in D3\u2019s margin convention. I think using d3.svg.transform would be overkill there:\njs\nvar svg = d3.select(\"body\").append(\"svg\")\n    .attr(\"width\", width + margin.left + margin.right)\n    .attr(\"height\", height + margin.top + margin.bottom)\n  .append(\"g\")\n    .attr(\"transform\", d3.svg.transform().translate([margin.left, margin.top]));\nThat\u2019s not to say there might still be a use for d3.svg.transform; after all sometimes I make a line simply by saying \"M\" + coordinates.join(\"L\") rather than using d3.svg.line. But at this point I\u2019m more inclined to make d3.svg.transform available as a D3 plugin and see what the public response is to it. If there\u2019s a lot of demand for it, then I could be convinced to make it a core feature.\n. In 4.0, the d3.transform class becomes private, internal to interpolateTransform. It should be possible to make a d3-transform plugin (module) that exposes a convenience API for specifying SVG transforms.\nThough, I still think ES6 string templates are nice, too:\njs\nd3.select(\"svg\").selectAll(\"g\")\n    .data([{size: 5}, {size: 10}])\n  .enter().append(\"g\")\n    .attr(\"transform\", function(d) { return `translate(20,{d.size * 10})rotate(40)scale({d.size + 2})`); });\n. Looks good. Should we look into automated detection of dangling globals? I think jshint should do it, but we probably want to squash some of its other warnings.\n. Nice!\n. Related  #4 #311 #724 #732 #734 #961 #1031.\n. Superseded by #1354.\n. These two changes are unrelated, so I would prefer to evaluate them separately. The responseType request would need to go in 3.2, while the XDomainRequest feature could go in 3.1.x, for example. Could you resubmit this as two requests from separate branches?\nI like the idea of switching to the standard XMLHttpRequest for IE10, even for cross-domain requests. Although it seems wasteful that the recommended pattern discards an XMLHttpRequest object in the case that it later decides to use XDomainRequest. It seems like you could make this check once the first time d3.xhr is used, and then remember the decision\u2026 Although maybe it\u2019s negligible next to the cost of making an external request, so who cares?\nAlso, my guess is assigning the responseType field to an XDomainRequest will have no effect, but also not throw an error, so it seems like it would be okay to do that even for XDomainRequest.\n. Merged into #1285 with edits for 3.2.\n. Yep, that looks good. Would be great if you would add a test also, but I can do that if you prefer.\n. Thank you! Merged into #1281 with my edits. If you have further edits, please send a new pull request to the fix-voronoi-points branch.\n. Merged into #1285 for 3.2.\n. Merged into #1285 for 3.2.\n. Merged into #1285 for 3.2.\n. Looks good, thank you.\n. Merged into #1285 for 3.2.\n. Merged into #1285 for 3.2.\n. It\u2019s my understanding that putting code inside a try-finally block can disable some types of optimizations. Can you test without using the try-finally block? Maybe they\u2019re canceling each other out.\n. A variation on your idea.\nWhat if a projection stream had an invalid flag? So, d3.geo.projection would cache the last return value from projection.stream:\njs\nprojection.stream = function(output) {\n  return stream = d3_geo_projectionRadiansRotate(rotate, preclip(projectResample(postclip(output))));\n};\nAnd any operations on the projection could invalidate the previously-returned stream, e.g.:\njs\nfunction reset() {\n  if (stream) { stream.invalid = true; delete stream; }\n  projectRotate = d3_geo_compose(rotate = d3_geo_rotation(\u03b4\u03bb, \u03b4\u03c6, \u03b4\u03b3), project);\n  var center = project(\u03bb, \u03c6);\n  \u03b4x = x - center[0] * k;\n  \u03b4y = y + center[1] * k;\n  return projection;\n}\nThen in d3.geo.path, it could likewise cache the result of projectStream, but throw it away if it were invalid:\njs\nfunction path(object) {\n  if (object) {\n    if (typeof pointRadius === \"function\") contextStream.pointRadius(+pointRadius.apply(this, arguments));\n    if (!cacheStream || cacheStream.invalid) cacheStream = projectStream(contextStream);\n    d3.geo.stream(object, cacheStream);\n  }\n  return contextStream.result();\n}\n(And also changing path.pointRadius to set contextStream.pointRadius if the point radius is a constant, and likewise in path.context.)\n. Also curious to see a benchmark on drawing U.S. counties (as separate features).\n. I pushed my edit in c7507b60133d2701028e5ffcbe456c7114ceec7a to the cache-projection-stream branch, to test. It seems ever-so-slightly faster, but it\u2019s probably not statistically significant.\nI\u2019m not too worried about the circular reference between path and projection.\n. One problem with my approach is that I\u2019m only handling stream invalidation with d3.geo.projection, so stream caching may break existing custom projection streams (if there are any) by not detecting invalidation. Furthermore, my change introduces new public API (or least visible API) to control invalidation of the cached projection stream. By limiting caching to only d3.geo.projection, yours is more limited but also safer without introducing public API.\n. Also, I think with yours there\u2019s no guarantee that the id is unique across projections, so I think it\u2019s possible that if you had two projections whose internal id had the same value, then projection.stream would return the globally-cached stream for the wrong projection. Globals make me nervous that way. :)\n. Yes. I fixed the problem with custom streams by using !cacheStream.valid rather than cacheStream.invalid; in effect, only streams that advertise themselves as cacheable will now be cached. So there\u2019s still new public API, but it won\u2019t break custom projection streams because they won\u2019t be cached by default now.\n. > the global is only set temporarily in path(object) during the call to projection.stream(\u2026)\nTrue, that lessens the risk. However, since the d3.geo.path instance calls methods on the context stream and the projection stream, it could be evaluating arbitrary code while the global is set. This could cause a reentrancy problem.\n. Merged into #1285 for 3.2.\n. Merged into #1285 for 3.2.\n. The projection stream caching broke the adaptive resampling demo. Investigating.\n. Hmm, also broke the interactive orthographic example, since the rotation isn\u2019t propagating to the cached stream!\n. Well, try it and see.\n. Amazing work, Jason. Thanks so much for the fast fix!\n. One final thing. I\u2019m guessing the minified code would be slightly shorter if you stashed a local variable to d3_document.body.style? If it is, then do that, otherwise, it looks good.\n. Hmmm. I\u2019m not wild about either of those workarounds. Another hacky way (but not an improvement) is ::selection { background: transparent; }, but I don\u2019t think there\u2019s a way to do that via JavaScript short of creating a dynamic rule, since it\u2019s a psuedo-element.\nI dunno. How bad would it be to let Firefox fix the bug for themselves?\n. Bene bene bene. Looks good.\n. Nice idea, and the implementation looks good, but this doesn\u2019t sound like something that will be commonly used. I think it\u2019d be better to leave this outside of core for now.\n. Related #1084.\n. Related #1087.\n. Merging into #2019.\n. This has been implemented as zoom.extent and zoom.translateExtent in d3-zoom for D3 4.0.\n. Oops, wrong target.\n. This isn\u2019t the desired behavior. If I ask for d3.time.months with a step of 3, then I expect the returned months to only contain January, April, July and October (standard quarters or the calendar). With your implementation, the behavior is dependent on the start date, and so will return different months of the year for the same step interval depending on the month of the start date.\nUnder the current implementation it doesn\u2019t make sense to use a step interval greater than or equal to the cardinality of the time unit, so using a step of 12 or greater for months isn\u2019t meaningful; you should use years for that.\nIf you want to use an offset relative to the start date, rather than at regular fixed intervals based on the value of the time unit, you\u2019d need to propose a different API for supporting that rather than changing the current behavior. Or you can post-filter, e.g., d3.time.months(a, b).filter(function(d, i) { return !(i % 3); }).\n. As I said, it\u2019s designed to return the same set of months regardless of start date. So a step interval of 5 doesn\u2019t make much sense because it\u2019s not a divisor of 12. The only ones that makes sense are 1 (every month), 2 (odd months), 3 (quarters), 4 (thirds) and 6 (halves).\nIf you want every fifth month starting on the start date, then you either need to use post-filtering as I described in my previous comment or propose new API for doing similar. But making a backwards-incompatible change the current behavior is not acceptable.\n. We can\u2019t change the current behavior in a backwards-incompatible way. This is not a bug fix. If you want different behavior then you should instead propose new API that is backwards-compatible, i.e., that adds new methods rather than changes the behavior of current ones.\nThere are many cases where the current behavior is desirable. For example, when rendering ticks every 10 years, rendering decades is better than picking offsets from the start year which is typically arbitrary. Likewise rendering ticks every 15 minutes, you expect :00, :15, :30, :45.\nMore generally, when you have dynamic visualizations where the domain of the time scale can change due to transitions or animations, a stable algorithm for picking \u201csignificant\u201d tick times is desirable over simply offsetting from the domain\u2019s minimum value. This gives you object constancy for ticks, rather than constantly changing which ticks are displayed whenever the domain changes slightly.\n\nI agree that it makes sense to just use a filter, but then why have these functions built into d3 at all?\n\nBecause date math is hard and filtering by index is not. No API can cover every possible use case. Instead APIs are evaluated based on power-to-weight ratio, and compared to the next best alternative. How frequently is the satisfied functionality needed? How hard is it to implement yourself, using existing methods or vanilla JavaScript? How complex would the implementation be, to test, maintain, document, and support? etc.\n. Documentation is a great place to start. The documentation for interval.range is quite terse at the moment. If you have some time and willingness, it\u2019d be great if you could expand the documentation to include more examples of the current behavior, including examples of post-filtering for the use cases you had in mind.\n\nE.g. suppose they want 100 weeks - we need to be able to subdivide that into (say) 10 major ticks (labelled with dates) with 9 minor ticks in between each.\n\nActually, you might not want to use a d3.time.scale and time intervals here at all. Weeks are variable length\u2014for example with daylight savings time, weeks can be 167, 168 or 169 hours long. Using d3.time.scale when you are aggregating by week can cause your weeks to be displayed at corresponding irregular intervals. If you had a major tick at every 10 weeks, 10 weeks is likewise a (slightly) irregular interval and the 9 minor ticks would not be uniformly-spaced. You usually want d3.time.scale only for precise display of continuous time, not discrete calendar units.\nIt might make more sense for you to use the simpler d3.scale.linear, encoding week numbers rather than dates. (Or perhaps d3.scale.ordinal with rangeBands.) This way you would display weeks at exact regular intervals, ignoring irregularity, and use the generic tick algorithm for linear scales to determine which weeks to show.\n. Yep, good catch. Looks good.\n. Ugh, this logic is becoming frustratingly complex. Why is it okay to preventDefault on mousemove and mouseup, but not on mousedown? Would it be simpler to revert all this extra logic for suppressing selectstart events and just cancel the mousedown event, but focus the window? Do we still want a d3_eventCancel method if most of the places we use it, we just mean to stopPropagation? Should d3_eventCancel be replaced with two methods, d3_eventStopPropagation and d3_eventPreventDefault to shave a few bytes?\n. I\u2019ve written code in the past to find the first \"focusable parent\" of a clicked on element. The polymaps drag mousedown handler:\njs\nfunction mousedown(e) {\n  if (e.shiftKey) return;\n  dragging = {\n    x: e.clientX,\n    y: e.clientY\n  };\n  map.focusableParent().focus();\n  e.preventDefault();\n  document.body.style.setProperty(\"cursor\", \"move\", null);\n}\nWhere:\njs\nmap.focusableParent = function() {\n  for (var p = container; p; p = p.parentNode) {\n    if (p.tabIndex >= 0) return p;\n  }\n  return window;\n};\nNot sure if that really helps in this case, though.\n. Do you have any opinion on the desired behavior, @jfirebaugh? FWIW, Leaflet also seems to preventDefault and stopPropagation on mousedown (see Draggable.js), and so by extension I assume that\u2019s what the MapBox JavaScript API does as a Leaflet plugin. As much as it\u2019s nice to have mouseup work outside an iframe, I think given the other issues this is raising, I\u2019m inclined to restore the previous behavior.\n. Actually, it looks like Leaflet solves this problem by adding a tabindex attribute to the container div, along with an outline:0 style, so that even though Leaflet uses preventDefault and stopPropagation, it focuses this container so that clicking on a draggable element causes the focus to move. (It doesn\u2019t work outside an iframe, though.)\nOf course D3\u2019s behaviors are typically bound to G elements within an SVG, so the behavior would probably need to grab the owner SVG element to apply this technique.\n. If we don\u2019t preventDefault on mousedown, then clicking and dragging will allow text selection, image dragging and link dragging as default behaviors, which can interfere with D3\u2019s behavior. Jason\u2019s previous implementation explicitly suppressed the selectstart event so as to prevent text selection, but this didn\u2019t prevent image dragging (hence the need to add pointer-events: none to the d3.geo.tile example). The point is that if we don\u2019t prevent the browser\u2019s default behavior on mousedown, then unknown things will happen that may conflict with D3\u2019s behavior. We can explicitly disable the ones we know about, but that seems more complex than just preventing the default behavior.\n. It\u2019s easy to verify that Leaflet doesn\u2019t currently pan well inside an iframe\u2014see this example.\n. > In general, it's easier to work around specific problems caused by not preventing default, either in d3 or in client code, than to work around problems caused by preventing default.\nDo you think there are cases where a user would want different behavior than what D3 provides, and if so, can you give an example? In your case of iD, it seems to me you were fixing a bug in D3, not that you wanted different behavior. In other words, D3 tried to provide the \u201ccorrect\u201d behavior, but had a bug.\nI\u2019m happy for people to fork D3 to fix bugs, but I agree if users will want to override this behavior, then allowing default behaviors will make it easier. Or if you think it\u2019s infeasible for D3 to ever implement this behavior correctly for all applications, that would be another argument to err on shifting the burden to users.\n. It is nice that this approach works in an iframe, so maybe that\u2019s enough of an argument to continue with this approach even though it still feels (to me at least) more complex than preventing default behaviors.\nPerhaps what\u2019s missing here is finding a good way to unify the behaviors\u2019 implementations. After all, brushing, dragging and zooming all involve the same basic mode of interaction: mousedown, mousemove*, mouseup (or the touch equivalents). Could we abstract this into a higher level gesture handler, and thereby consolidate the logic that deals with assigning the appropriate listeners and browser quirks?\n. After discussion with Jason, closing this pull request. Will update #1321 with a description of the resolved strategy.\n. Interestingly, this came up in the threshold choropleth example. At some point I regenerated the us.json file from TopoJSON, which inadvertently restored the non-land counties in the Great Lakes and Puget Sound. The unemployment rate for these counties was undefined, since no people (at least on record) live in the water. However, the undefined value was being passed through the threshold scale which then returned the darkest color, rather than returning undefined which would have allowed the counties to inherit the default fill style (\"none\").\nI\u2019ve since fixed the us.json file to remove the watery counties for consistency with the states, but I think it\u2019s still correct to have d3.scale.threshold return undefined for undefined (or more generally non-orderable input). And then it occurred to me we have a similar condition on d3.min, d3.max and d3.extent where we are not correctly handling non-orderable input.\n. Here\u2019s another example of where the previous implementation failed:\njs\nd3.min([new Date(NaN), new Date, new Date(2000, 1)]) // Invalid Date\nd3.min([new Date, new Date(NaN), new Date(2000, 1)]) // Tue Feb 01 2000 00:00:00 GMT-0800 (PST)\nI think if we ignore primitive NaNs, and non-primitive NaNs that occur later in the array (implicitly, because the comparison is always false), then we should ignore non-primitive NaNs at the beginning of the array, too. This is easy to implement and more consistent.\nYour edge case is interesting, but it\u2019s more difficult than detecting singular unorderable values; it requires detecting inconsistent transitive comparisons. This is not a recoverable error if by the time you detect an inconsistency, you\u2019ve already discarded some inputs. You could do two passes to determine the type of comparison (numeric or lexicographic) and then force that type for all comparisons rather than rely on the comparison operators\u2019 built-in coercion, but that seems onerous and slow.\nFor bisection, it\u2019s a requirement that the array is already sorted, and since unorderable values cannot (by definition) be sorted, it seems reasonable to document that bisection requires all array elements to be orderable. It would be onerous to have bisection ignore unorderable values in the array. But for the search value, we have the option of either requiring the caller to check that the search value is orderable (not undefined or NaN), or we can have bisection define the behavior explicitly, as I did in this pull request.\nIt was already the case that d3.scale.quantile coerced the search value to a number and detected NaN. So, perhaps it would be simpler to leave the current behavior of d3.bisect, and change d3.scale.threshold to likewise detect NaN. (Although the threshold scale would need to use the self-comparison check, rather than isNaN, because unlike a quantile scale a threshold scale only requires comparable, not necessarily numeric, domain values.)\nI think it\u2019s reasonable to document that d3.min, d3.max and d3.extent require consistent comparisons between all elements in the array, with the exception of unorderable values which are ignored. And likewise d3.bisect requires consistent comparisons between all elements and the search value, and has undefined behavior if any input is unorderable.\nBut I think for quantile and threshold scales, if the input is unorderable, then the return value should be undefined, explicitly.\n. Right, but I think returning undefined is less useful than extending the algorithm used by JavaScript\u2019s comparison operator for two values to n values, such as returning the lowest number from d3.min if any value in the array is a number. But anyway, I don\u2019t think either are worth the trouble of implementing, since the right thing to do is to coerce inputs to specific types before analyzing.\nI don\u2019t think the goal here is to return the \u201cbest\u201d result in all conceivable cases, because the corresponding implementation would be complex and so would the corresponding documentation. I think it\u2019s easier to just define some strict expectations, and only meet those. So, the threshold and quantile scales should return undefined for undefined or NaN input. If you pass a string to a threshold scale when it expects a number, you\u2019re on your own; I don\u2019t think we need to protect against that because it feels less common than undefined.\nAnd also, checking against the first value only goes so far\u2014other values in the domain might have different types, and so should check all of them and return undefined (or throw an error) then? It feels like there\u2019s a slippery slope of things we can protect against, so we have to be pragmatic in identifying things that are common and easy to protect against. In the general case we can\u2019t protect against everything, so it seems safer to document our assumptions than to enforce them rigorously with asserts or returning sentinel values.\n. Feel free to push commits to this branch. But I\u2019m still ruminating over @jfirebaugh\u2019s comments and haven\u2019t decided yet whether I agree. However I am weighing his arguments against the precedent set by other libraries, which seem to favor preventDefault. (Not that we have to agree with every other library, but it\u2019s empirical evidence to consider at least.)\n. Closing in favor of preventDefault approach.\n. Thanks! I\u2019ve added tests and merged this into the add-transition-size branch. If you want to make any further changes please post a new pull request to that branch. :thumbsup: \n. Isn\u2019t this identical to csv.format(rows.map(\u2026)) (not formatRows)?\nThe main reason you want the accessor passed to csv.parse is to convert objects greedily to more efficient representations (e.g., to convert strings to Dates or numbers). In the case of csv.format, the data is already materialized, so while I agree this is perhaps more consistent, I think it\u2019s probably not necessary since you can filter / map the data before formatting.\n. You\u2019ll also need to rename bin/component to bin/bower, since that\u2019s the file that generates bower.json from package.json. And you\u2019ll need to rename the corresponding rules in the Makefile.\n. Related #1251.\n. I don\u2019t think you need the d3.event.defaultPrevented check; it\u2019s still the case that the drag behavior will suppress clicks when the node is dragged.\nBut you are correct that we no longer preventDefault on touchstart\u2026 We decided we didn\u2019t want to disable the browser behaviors by default, since it\u2019s impossible to undo the effect of preventing the default behavior, but it\u2019s always possible to prevent it in your own code. On the other hand, we do prevent selectstart and dragstart events, so I do wonder whether there\u2019s a way to disable scrolling here.\nUgh, browser events.\n. Ah, you\u2019re right. We just preventDefault on that click, not stopPropagation.\n. Thanks for this pull request. This is a cool feature. It feels a bit too opinionated to include as default behavior though, and I\u2019m not sure how commonly this functionality is needed. I might be tempted to implement this as a D3 plugin first (d3/d3-plugins).\n. I bulk-closed all pull requests in this repository because the code was moved to separate repositories as part of the D3 4.0 launch (and thus no pull requests here could be merged). See d3/d3-drag#27 and d3/d3-zoom#67 for the new issues.\n. On the other hand, it might be better to standardize on closed polygons since that\u2019s what GeoJSON uses\u2026\n. The clip method isn\u2019t bound to the polygon instance. You need to either use function.bind, as in .map(bounds.clip.bind(bounds)), or do the same thing \u201cby hand\u201d, as in .map(function(cell) { return bounds.clip(cell); }).\nBut, the even better fix is to use voronoi.clipExtent, which obviates the need for you to use d3.geom.polygon at all.\n. Hey, thanks for this. It would be great if you could copy the bin/bower script and adapt it for Component. In particular, it needs to copy the relevant fields out of package.json, because I don\u2019t want to edit this file every time I release a new version. Thanks!\n. Better. Still needs to be added to the Makefile. Also please match the indentation style in bin/bower.\nI\u2019m curious if you need index-browserify.js? Does Component require modules to be defined using require-style module.exports? Or does it work with standard libraries that export a global.\n. I made the suggested edits and merged this into master. Thanks!\n. Yep, I left that part in. Thanks for confirming.\n. Here\u2019s an example of ggplot2-style axes without needing explicit axis support: \n\n. In general, D3 properties (such as axis.ticks) only accept a single argument. This is because functions in JavaScript can only return a single value, so for symmetry between setting and getting, the setter form of the property method should only accept a single value.\nThus, D3 favors multiple named properties (ticks, majorTicks, minorTicks) rather than accepting multiple arguments (ticks\u2026). There are a few exceptions to this rule, such as axis.tickSize. However, these exceptions should ideally be fixed in 4.0 or before (I just filed #1394); as you\u2019ll note axis.tickSize only returns the major tick size when called with no arguments, and so the minor and end tick size are not inspectable.\nI also like named properties because it makes the code more self-evident: the name of the method being called tells you what\u2019s being done, rather than needing to look it up in the API reference. Obviously there are always tradeoffs between verbosity and conciseness, and there are plenty of places where a D3 function accepts more than one argument\u2026 but I think in this case, if we do want to support minor ticks, I\u2019m strongly in favor of having separate named properties for minorTicks and majorTicks, similar to what we do with d3.geo.graticule\u2019s majorExtent & minorExtent and majorStep & minorStep.\nAccepting an array of arguments for axis.ticks also raises the question of whether the axis.ticks function should return an array of arrays as its return value. And furthermore it would introduce ambiguity as to whether a single array of arguments is being based (the current behavior) or an array of arrays. There are already some ambiguous cases where D3 needs to check whether the argument is a function or a constant; for example, with axis.tickFormat, you can\u2019t specify separate tick format functions if you are creating multiple axes. Likewise the axis currently does not inspect the array of tick arguments; it simply passes them along to the scale. In the case of d3.time.scale, the argument is a time interval (or an array of time intervals in your suggested case); for quantitative scales, the ticks function accepts numbers.\nBecause the ticks arguments are opaque from the perspective of the axis, looking at the number of arguments being passed is also not a good indication that you want multiple levels of ticks. The ticks arguments are also passed to the scale\u2019s tickFormat method, and for example with log scales, log.tickFormat takes multiple arguments.\n\nI think that the concept of ticks should not be restricted, on the long term, to just major and minor ones, but allow arbitrary levels of ticks.\n\nThis, to me, is a strong argument to not include this functionality in the axis component, and to defer this behavior to the client using post selection as proposed in #1351.\n\nPost-selection is simple and works, but breaks the encapsulation of the axis component.\n\nThe structure of the DOM that the axis component generates is not encapsulated. For one, you have to apply CSS styles to those elements in order for the axis to render correctly. I think every example I\u2019ve ever made that uses the axis component does this, so there\u2019s never been a case where the axis component is strongly encapsulated. And that\u2019s intentional: D3\u2019s philosophy is representational transparency, which means that you use D3 to manipulate the DOM, but not abstract the DOM. So, you should always know what the structure of the DOM is, even if you\u2019re using a component to help you create it.\nI know post-selection is not as convenient as including functionality in the component directly, but the goal is to support what is commonly needed while leaving flexibility for those that want to do something custom. It\u2019s always tempting to include support for additional features, but if we did that with everything D3 would get bloated very quickly. To me, the ggplot2-style axis using post-selection is still a very concise implementation, so I don\u2019t think removing support for minor ticks would place a big burden on users, while keeping it mean and lean for those that don\u2019t need this feature.\n. Thanks for the feedback. :)\n. Closing in favor of #1351.\n. Merged into #1458.\n. Merged into #1458.\n. This pull request also propagates the group index j to the selector functions.\n. This was definitely not the case in the past; see eaed6b880bc5550ad0a6b3a4542f6f8534a6a6da. What version of Sizzle adds this guarantee?\n. Well, it was buggy in the past\u2026 that\u2019s why I made that commit.\n. Merged into #1762.\n. This was fixed in 3.3.0, most likely by 36e5526feb45227f9778682b110f52c620c4527b.\n. Related: #1373. (GitHub only crosslinks references in the body, not the title, apparently.)\n. I believe D3\u2019s implementation is the intended behavior. If you have a color like rgb(0,128,128) and you want it brighter, you only want to increment the green and blue channels to preserve (weakly) the hue. If you also increment the red channel, then you are effectively blending with white rather than increasing the brightness of the color. There is a special case for pure black because it has an undefined hue.\nOf course\u2026 you\u2019ll probably have better results if use a perceptual colorspace such as d3.lab or d3.hcl.\n. Related discussion in #1030. Although, the only issue here is string coercion since separate instances are returned for each value in the range (no interpolation).\n. Superseded by #1409; favoring strings per discussion in #1030.\n. This was the purpose of 6ef0eda53f4f70fc8c0b38a5b1b1f1505bcbf22e / #1381. Are you sure this still needs fixing?\n. Ah, that\u2019s a bug. It should be removing the mousemove listener from this (rather than d3_window) on touchstart.\n. Argh, I vaguely recall introducing that bug\u2026 anyway, #1405 removes them from the intended target this rather than d3_window. That should fix this, right?\n. OK, fixes pushed in e89b278.\n. I think that\u2019s right\u2014in the case of zooming, there\u2019s only a single gesture occurring, regardless of the number of touches. (Unlike dragging, where each drag gesture is independent.) Would be great if you could take a crack at it.\n. Correct me if I\u2019m wrong, but I don\u2019t think this solves the problem because new closures are still generated in touchstarted, replacing the old touchmove and touchend listeners?\n. I see, so you\u2019re temporarily overriding the touchstart listener while a gesture is active, too. That\u2019s a bit clever but now that I understand what\u2019s going on, it feels quite clean. It might be worth adding a brief comment just above the declaration of the touchstarted function saying that the closures persist for as long as at least one touch is active.\nI\u2019m confused by calling started() on touchend. What\u2019s the purpose of this? That seems like the code that we had before that was likewise confusing and caused a bug where a touchend could be interpreted as a dbltap. My only guess is that you\u2019re updating the state of the locations hash, but I don\u2019t think there would be any negative effect of keeping the expired touch in the hash (until the next touchstart, which likewise causes it to be recreated). Or if you just want to remove the ending touch from the hash, couldn\u2019t you look at changedTouches and remove those touches?\n. Correct me if I\u2019m wrong, but it seems that because touchtime is local to touchstarted, dbltap detection no longer works. A dbltap is one tap (touchstart, touchend) immediately followed by a second tap (touchstart, touchend). So at the touchend of the first tap, d3.event.touches.length is zero, so the touchstart event listener is reassigned to touchstarted, and thus at the start of the second tap touchtime is reinitialized as undefined in the new closure.\n. Also, even if this does work, I think it would be cleaner to separate the code you want to run on touchend from what\u2019s run on touchstart, because (at a high level) they aren\u2019t the same event and shouldn\u2019t be treated as such. I think it would be cleaner to extract recalculating of the touch locations to a shared function, and then call that function from both started and ended, rather than having ended call started and risk inadvertent dbltap.\n. This looks good to me too.\n. Merged into #1450 with added tests.\n. Like #1428, I\u2019d prefer this to be folded into #1423 rather than sent as a separate pull request.\n. Would be easier if you incorporated these into your original pull request rather than sending them separately. Any reason not to do that?\n. All you need to do is edit the files in your master branch (which your outstanding pull request in #1423) and it will update that pull request. Since you created separate patches for them, the edits are in separate branches and thus aren\u2019t updating the original pull request.\nYou should really edit these files locally rather than using GitHub\u2019s online editor: there\u2019s no way to run the tests and verify your changes if you\u2019ve only edited them online.\n. You are editing a generated file: the source for this line is in src/selection/on.js. You need to edit this file and then run make to make a change, and use make tests to verify the correct behavior.\nMore importantly, though, D3 doesn\u2019t support browsers that don\u2019t support web standards, meaning it does not support IE8. So the correct way to fix this problem is to patch IE8 with a polyfill that supports web standards. See shawnbot/aight for just such a shim.\n. That\u2019s a good idea. (I was lazy.) I\u2019d also like to do some microbenchmarks to compare the speed of clipping here versus clipping with canvas / SVG.\n. Merged into #1458.\n. Related #1439.\n. This is probably superseded by #2547.\n. Merged into #1458.\n. Merged into #1458.\n. Merged into #1458.\n. Merged into #1458.\n. (This pull request breaks a few tests; I\u2019m hoping Jason will help me fix them.)\n. (This now contains #1448.)\n. Merged into #1458.\n. Re. d3.geo.simplify vs. d3_geo_streamTransform. You could implement simplification without d3.geo.simplify by implementing your own custom stream, as we\u2019ve done in earlier examples:\njs\nvar area = 1, simplify = {\n  stream: function(stream) {\n    return {\n      point: function(x, y, z) { if (z >= area) stream.point(x, y); },\n      sphere: function() { stream.sphere(); },\n      lineStart: function() { stream.lineStart(); },\n      lineEnd: function() { stream.lineEnd(); },\n      polygonStart: function() { stream.polygonStart(); },\n      polygonEnd: function() { stream.polygonEnd(); }\n    };\n  }\n};\nThe first option is that we could expose d3.geo.streamTransform and allow arbitrary overrides. However, this doesn\u2019t really save that much over the above:\njs\nvar area = 1, simplify = {\n  stream: function(stream) {\n    return d3.geo.streamTransform(stream, {\n      point: function(x, y, z) {\n        if (z >= area) stream.point(x, y);\n      }\n    });\n  }\n};\nIf d3.geo.streamTransform is strictly point-based, it could be reduced slightly at the cost of flexibility:\njs\nvar area = 1, simplify = {\n  stream: function(stream) {\n    return d3.geo.streamTransform(stream, function(x, y, z) {\n      if (z >= area) stream.point(x, y);\n    });\n  }\n};\nAbove, d3.geo.streamTransform takes a stream and returns a transformed stream. But a slightly different approach is that d3.geo.streamTransform is an abstract factory for stream transforms; this way the user doesn\u2019t need to expose the stream method because it is inherited from d3.geo.streamTransform. The resulting code is quite a bit shorter:\njs\nvar area = 1, simplify = d3.geo.streamTransform({\n  point: function(x, y, z) {\n    if (z >= area) this.stream.point(x, y);\n  }\n});\nThe downside is the output stream probably needs to be captured as a property of the stream transform since it is no longer accessible via closure. However another option would be to use a different interface for the streamTransform where the output stream is the first argument to the stream methods, although I wonder if this would introduce overhead due to additional function invocation:\njs\nvar area = 1, simplify = d3.geo.streamTransform({\n  point: function(stream, x, y, z) {\n    if (z >= area) stream.point(x, y);\n  }\n});\nWe could even rename it to d3.geo.transform for a geometry transformation rather than a stream transformation, and just leave the stream-based nature of it even shorter.\njs\nvar area = 1, simplify = d3.geo.transform({\n  point: function(stream, x, y, z) {\n    if (z >= area) stream.point(x, y);\n  }\n});\nLastly we have d3.geo.simplify, which is the least amount of code for the user, but does not generalize to other types of custom stream transformations.\njs\nvar simplify = d3.geo.simplify()\n    .importance(1);\n. I went ahead with the d3.geo.transform design which I think strikes the best balance of simplicity and generality. You can see it in the updated dynamic simplification demo.\n. Oh, there was one other idea I had, which felt more D3-idiomatic but I wasn\u2019t sure if it was really an improvement:\njs\nvar area = 1, simplify = d3.geo.transform()\n    .point(function(x, y, z) { if (z >= area) this.stream.point(x, y); });\nIn other words, rather creating a d3.geo.transform with a methods hash, a d3.geo.transform would expose accessors to set (or get) those methods using chaining. It feels a little overkill to me, though.\n. Here\u2019s that implementation for posterity, but I think I\u2019m happier sticking with the object-based constructor:\n``` js\nd3.geo.transform = function() {\n  var proto = transformed.prototype = Object.create(d3_geo_transform.prototype),\n      transform = {stream: function(stream) { return new transformed(stream); }};\nfunction transformed(stream) {\n    this.stream = stream;\n  }\nfunction method(k) {\n    return function() {\n      if (!arguments.length) return proto[k];\n      proto[k] = ;\n      return transform;\n    };\n  }\nfor (var k in proto) transform[k] = method(k);\n  return transform;\n};\n```\nAs for returning a point, I think it\u2019s probably better to preserve the same interface as existing geometry streams; it avoids an additional layer of function invocation.\n. I have an example of composing geometry streams (6287633). Simplification has to go first because d3_geo_clipView drops the z-coordinate as a side-effect of clipping. But I expect simplification is cheaper than clipping, since it\u2019s just a threshold check with no trigonometric operations, so it makes sense for it go first. (Also, you can approximate viewport clipping by just doing rough simplification outside the viewport area, as in 6252418.)\nThe two stream transforms are combined as:\njs\nvar simplifyThenClip = {\n  stream: function(stream) {\n    return simplify.stream(clip.stream(stream));\n  }\n};\nYou could imagine instead saying:\njs\nvar simplifyThenClip = d3.geo.compose(simplify, clip);\nWhere:\njs\nd3.geo.compose = function() {\n  var transforms = arguments, n = transforms.length;\n  return {\n    stream: function(stream) {\n      var i = n;\n      while (--i >= 0) stream = transform.stream(stream);\n      return stream;\n    }\n  };\n};\nI guess that\u2019s pretty simple\u2026 just not sure it\u2019s totally needed. And there is already a d3_geo_compose for composing point-based transformations (only rotations, at the moment).\n. Thanks for the help! Take a look at 24f9f2cd6910d71a73344a487cd21545d2abe529 and let me know if you want to revisit this.\n. Yep, good idea. Fixed in 5c64c23f8076db2ed08875d785fbb227f8ee5638.\n. Also, it still feels a bit weird to re-apply the zoom behavior to trigger a programmatic change (either immediately via selection.call or over time via transition.call). I mean, for one thing, there\u2019s no reason for the zoom behavior to recreate all the event listeners, if the goal of the application is just to dispatch zoom events.\n. A fourth option is to have components expose a different application point solely for emitting events, say zoom.notify. In the case of brush.notify on a transition, it would interpolate the brush domain and dispatch brush events. So if you wanted to interpolate the display of the brush and its state, you could say:\njs\nd3.select(this).transition()\n    .duration(brush.empty() ? 0 : 750)\n    .call(brush.extent(defaultExtent))\n    .call(brush.notify);\nThis seems to solve the problem of unexpected events on initialization quite nicely.\n. Looks good.\n. Merged into #1487 for 3.3.1.\n. Folded into #1690.\n. Looks good.\n. Merged into #1487 for 3.3.1.\n. The bower.json file is for Bower. The component.json file is for Component. Since there\u2019s a bower.json file, Bower should be ignoring the component.json file.\nRelated: it seems like you\u2019re checking out version 3.1.10, but the latest version is 3.3.1. Maybe that\u2019s the issue here? When I bower install d3, I don\u2019t get any warnings:\n```\nbower d3#                  not-cached git://github.com/mbostock/d3.git#\nbower d3#                     resolve git://github.com/mbostock/d3.git#\nbower d3#                    download https://github.com/mbostock/d3/archive/v3.3.1.tar.gz\nbower d3#                     extract archive.tar.gz\nbower d3#*                    resolved git://github.com/mbostock/d3.git#3.3.1\nbower d3#~3.3.1                install d3#3.3.1\nd3#3.3.1 bower_components/d3\n```\n. Thanks for the help!\nCurious how you tested this. I tested my fix on a physical iPhone because the iOS Simulator doesn\u2019t let you put a second touch down to switch from panning to zooming. And I noticed that even when the touchmove listener is limited to the targeted element, you still receive touchmove events from the second touch outside the targeted element (because the first touch is still considered \u201cmoving\u201d when the second touch is moving). Hence the original crash.\nHow does this fix compare to #1499, and which should we use? My approach was to have the current gesture take over the window, so that once you start zooming on a given element, you can\u2019t simultaneously start zooming on another element.\n(Although I suspect there might be a bug in my implementation where it only works with a single zoomable element, because I deregister the touchstart listener on the targeted element, but not all other zoomable elements, so I think a different zoomable element might still be able to receive the touchstart event. But I didn\u2019t want to stopPropagation on touchstart events since that would preclude other listeners from receiving the event. So, hmm\u2026)\nI feel like maybe what we need to do is record which touches are zooming the current target by recording them on touchstart. Then, we ignore any touches (filtering d3.event.touches) on touchmove so that we only consider touches that started on our target.\nActually that seems to be exactly what you are doing\u2026\u00a0so I\u2019m going to test your branch now and we\u2019ll use that if it works on my iPhone. :)\n. Why not delete each changedTouch from locations0 on touchend?\n. Closing in favor of #1498.\n. What inputs were you using that generated an n=1 polygon? Please include them so that we can create a corresponding unit test.\n. The easiest thing is to jitter the points a tiny bit, although that has some drawbacks. Merged this request into #1503.\n. As I said in #1501, please provide some inputs for testing so that I can verify this fix.\n. See #1503 for related feature request.\n. Oh, phooey, wish we had caught this before I released 3.3.3. :)\n. Looks good.\n. Merged into 3.3.4.\n. d3.format(\"d\") is inappropriate if you want to force rounding to integers; use d3.format(\".0f\") instead. Or use the tick format that the scale provides for you, as it will automatically compute the precision that is appropriate to the tick step size.\nIt\u2019s impossible to guarantee that scale.ticks will return exact integers due to the limits of floating point precision arithmetic. And exact fractions of ten, such as 1e-1, are impossible to represent with IEEE 754, since it is a binary (base two) format. [1] For example, 0.1 + 0.2 = 0.30000000000000004.\nThere are a few places where we try to perform integer arithmetic when possible. We do not currently do that with the Math.pow(10, \u2026) call, which could mean that a non-integer is returned even when the exponent is positive and it would be possible to use an integer. Or, if the exponent is -1 and then we decide to multiply by ten, you could also get a non-integer.\nI\u2019d be tempted to apply the following fix to d3_scale_linearTickRange:\n``` js\nvar extent = d3_scaleExtent(domain),\n    span = extent[1] - extent[0],\n    exponent = Math.floor(Math.log(span / m) / Math.LN10),\n    step = Math.pow(10, exponent),\n    err = m / span * step;\n// Filter ticks to get closer to the desired count.\nif (err <= .15) step = Math.pow(10, exponent + 1);\nelse if (err <= .35) step = 5;\nelse if (err <= .75) step = 2;\n```\nThis make it more likely (but not guarantee) that step is an integer if exponent = -1 and err <= .15. Though since I don\u2019t have a windows phone and I\u2019m not aware of another JavaScript engine for which Math.pow(10, -1) * 10 !== 1, I have no way of testing to verify this behavior.\nIf it fixes this problem for you, I don\u2019t mind including the patch, but it\u2019s still the case that you should use a different tick format, regardless.\n[1] http://www.yuiblog.com/blog/2009/03/10/when-you-cant-count-on-your-numbers/\n. Hmm, maybe this is a good idea, though I vaguely recall wanting \u201cd\u201d to do nothing on non-integer input in the past. (You could use \u201c.0f\u201d instead of \u201cd\u201d to output rounded values.)\n. Also, since Python is typed, I get:\n```\n\n\n\n'{:d}'.format(1.2)\nTraceback (most recent call last):\n  File \"\", line 1, in \nValueError: Unknown format code 'd' for object of type 'float'\n```\n\n\n\nIs that what you tried?\n. I think we should probably leave the behavior as-is. I added a few comments on #1512 regarding a possible alternate fix, but I think the main problem there was that \"d\" is an unsafe format, and it\u2019s safer to use \".0f\" to force integers or use the scale to generate a format with automatic precision.\n. Sorry for the delay, I\u2019ve fallen behind.\nThis seems like a reasonable feature; you lose some accuracy in your ability to evaluate a proportion relative to the whole, but relative comparisons between arcs are still valid and perhaps you gain something in being able to identify little arcs. It\u2019s definitely better than using strokes, I grant you. (I did an approximation of this technique in the bilevel partition example by just subtracting a small amount from the arc.endAngle.)\nI\u2019d probably name it \u201cpadding\u201d \u2014\u00a0rather than \u201cspacing\u201d \u2014 since that\u2019s the term we use for similar things in other contexts, like in d3.layout.pack (also treemaps, chord diagrams, axis ticks, etc.).\n. Can I ask you to sign the CLA, per D3\u2019s CONTRIBUTING guidelines?\n. I wondering if it wouldn\u2019t make more sense to specify the padding in pixels rather than in radians. The difference is not noticeable when the inner and outer radii are similar (as in the top post), but when the inner radius approaches zero it becomes obvious:\n\nMy inclination is that you want the sides of adjacent arcs to be parallel, rather than simply changing the angular extent of the arc. This makes the math slightly more complicated because the start and end angle of the arc will now be different between the inner and outer radii, but I think it\u2019s what we want. I\u2019m going to look into implementing pixel-based padding next.\n. Updated implementation in #2122:\n\nThere are still some kinks to work out \u2014\u00a0I\u2019m not 100% sure my math is correct \u2014 but seems close! I also renamed padding to padAngle to make it clear that it\u2019s in radians and for consistency with startAngle and endAngle; this seems especially important given that the pie layout needs to export the padAngle on the generated datum so that it can be used by the arc generator.\n. Cheers. Thank you, @sebastianseilund.\n. Hmm. d3.nest also handles the case where there are multiple elements with the same value for the given key function, such as [{foo: \"a\"}, {foo: \"a\"}]. So this is really a unique index, rather than a general index.\nAlso, maps are tricky in JavaScript because objects are not hashes; that\u2019s why we added d3.map (and because ES6 maps are not yet widely available).\nYou can implement this using array.reduce as a single statement:\njs\n[{foo: \"a\"}, {foo: \"b\"}].reduce(function(p, v) { p.set(v.foo, v); return p; }, d3.map())\n. This is implemented as d3.map(array, accessor) in 3.5. For example:\njs\nvar m = d3.map([{foo: \"a\"}, {foo: \"b\"}], function(d) { return d.foo; });\nm.get(\"a\"); // {foo: \"a\"}\nm.get(\"b\"); // {foo: \"b\"}\nm.get(\"c\"); // undefined\n. Hooray! Thanks for looking at this. I don\u2019t understand this code well enough to comment on the correctness of the fix, but at least superficially it looks good!\n. Merged into 3.3.4.\n. Merged into 3.3.4.\n. Merged into 3.3.4.\n. Merged into #1573 for 3.3.7.\n. I recommend doing this by adding a capturing mousewheel listener on the zoomable element and then calling d3.event.stopPropagation if you don\u2019t want the zoom behavior to handle it.\n. Excellent!\n. Merged into #1547.\n. This seems somewhat slower (+30-40% on U.S. counties) than before. Before:\nU.S. counties (separate): 49ms/op.\nU.S. counties: 47ms/op.\nAfter:\nU.S. counties (separate): 64ms/op.\nU.S. counties: 66ms/op.\nI\u2019m going to investigate whether we can make any other performance gains to cancel out the losses while retaining the fix.\n. Yeah, I think that earlier commit where I removed d3_geo_identityRotation was a mistake. Oops!\n. Performance seems equivalent to me now. Not sure whether it was our changes or upgrading to Node 0.10.19.\nBefore:\nU.S. counties (separate): 58ms/op.\nU.S. counties: 54ms/op.\nAfter:\nU.S. counties (separate): 54ms/op.\nU.S. counties: 52ms/op.\n. Merged into #1547.\n. Merged into #1547. Filed #1551 separately.\n. The d3.js file is automatically generated, so this is the wrong place to make this edit. Also, while I suppose moving the function in question to the top-level is truer to the behavior of the code, the resulting code is equivalent so I\u2019m not sure it\u2019s worth imposing strict mode.\n. This optimization is largely adopted in the new D3 modules. Since the code has been almost completely rewritten (and moved to new repositories!), there\u2019s no way to merge this pull request. But if you find any more slow code in the new modules please let me know!\n. Potential minor optimizations I learned from the rhill-voronoi branch. Would need to microbenchmark (test/geo/benchmark is probably sufficient?) to ascertain their efficacy:\n- Consider using a constructor rather than an object literal for the segments (point / points / other / visited / etc.). The JavaScript engine might optimize these more aggressively.\n- Always pre-allocate any used fields in the constructor to avoid adding fields post-construction (e.g., prev / next). This would apply independently of whether a constructor or object literal is used.\n- Consider using single-character field names rather than human-readable names. (Mostly for code size, but might actually affect performance slightly.) I used some uppercase characters in mine, for better or for worse. :\\\n. Merged into #1573 for 3.3.7.\n. Merged into #1573 for 3.3.7.\n. Merged into #1573 for 3.3.7.\n. Yeah, I noticed this when we upgraded UglifyJS (to 2.4.0 I believe) but I didn\u2019t investigate why.\n. Merged into #1573 for 3.3.7.\n. Seems like this pull request reverses the order of polygons returned by d3.geom.voronoi, such that now d3.geom.polygon area returns negative values. I think while the inconsistent with d3.geo.path area is also desirable, given that d3.geom.polygon already does it the other way, we should strive for backwards-compatibility with the old API.\n. Thanks for this pull request. I agree with the gist of your fix. Here are two related issues:\n1. We\u2019ll probably need a similar fix for the \"p\" format (like \"s\" but for percentages).\n2. Use d3_format_re to figure out the type of the specified format.\nThe second issue is why the replacer function looks at the variable j\u2014that\u2019s the type of the specified format (used currently to check for the \"%\" format type). I think you\u2019ll need to move the code into the replacer so that you can use this parsed type format, and leave the code outside the replacer to only handle the default \",.\" + precision + \"f\" format.\n. I made some formatting changes and merged this into a new pull request, #1590. If you want to make any further changes, please submit them to the fix-tick-format-precision branch. Thank you for your contribution!\n. Thanks for fixing this!\n. FWIW I added the import abs to trigonometry so that it was implied in most of the existing places that do math. Maybe that was lazy of me but it was concise. :)\n. Nice. Good idea!\nI wonder if it would be possible (& worthwhile) to short-circuit one level higher. The project within d3_geo_resample is actually project + translate + scale. In geo/projection.js, it\u2019s something like:\njs\nvar projectResample = d3_geo_resample(function projectTransform(x, y) {\n  var p = project(x, y);\n  return [p[0] * k + \u03b4x, \u03b4y - p[1] * k];\n});\nThen that projectTransform function becomes the project within d3_geo_resample.\nBut you could instead implement project + translate + scale without resampling as a stream transform, replacing d3_geo_resample (and projectResample) entirely:\njs\nvar projectTransform = d3.geo.transform({\n  point: function(\u03bb, \u03c6) {\n    var p = project(\u03bb, \u03c6);\n    this.stream.point(p[0] * k + \u03b4x, \u03b4y - p[1] * k);\n  }\n}).stream;\nI believe this would cut out one level of function invocation, since it would combine the project & transform into one transform rather than having separate stream transforms for project & transform. I think? I could test.\nWe could then restructure d3_geo_resample so that the precision isn\u2019t configurable, but instead set by a closure. Or something. Since the projectTransform wouldn\u2019t have a precision method, obviously.\nAnyway maybe I\u2019m not thinking straight, or maybe there\u2019s an opportunity to tweak the projection pipeline slightly for the no-resampling case.\n. Maybe it\u2019d be possible to write the pipeline like this:\njs\nstream = radiansStream(preclipStream(rotateStream(projectStream(resampleStream(postclipStream(output)))));\nWhere preclipStream, rotateStream, resampleStream, postclipStream could all be d3_identity if those steps are not desired in the pipeline.\n. But, I guess since clipping inverts the rotation that\u2019s not really possible. Anyway. :\\\n. Alright. Thanks for investigating!\n. Speaking of stream and this.stream, it seems a bit strange to me to use d3_geo_transform, but then invoke the wrapped stream using a closure (stream) rather than the member (this.stream), since the latter is what\u2019s used for all the inherited methods. I\u2019m considering just defining a stream transform the hard way for this.\n. There are two forms of clipping: preclip and postclip. Pre-clipping happens in spherical coordinates before the projection. Post-clipping happens in Cartesian coordinates after the projection.\nCurrently postclip defaults to d3_identity which means that if you don\u2019t specify a projection.clipExtent, post-clipping is a no-op with no overhead.\nWe don\u2019t currently allow you to disable pre-clipping completely in d3.geo.projection: it\u2019s either antimeridian clipping (d3_geo_clipAntimeridian) if projection.clipAngle(null) is used or small circle clipping (d3_geo_clipCircle) if projection.clipAngle(angle) is used.\nThat said, you can implement your own custom projection stream without using d3.geo.projection as in the No Antimeridian Cutting example.\nI can imagine it might be nice to disable antimeridian cutting in some situations, but someone needs to suggest an API for enabling it, given that projection.clipAngle(null) currently implies antimeridian cutting. We talked about this previously but couldn\u2019t agree on a good API.\n. Yes, that\u2019s necessary for d3.geo.mercator since the coordinates must be clipped outside of \u00b185.05113\u00b0 latitude, lest they become unreasonable large.\n. This might be okay. In general, I prefer to use arguments.length checking because it\u2019s more obvious what is going to happen: you know statically how the code will behave (outside of function.apply, of course). Type-checking on the other hand is necessarily dynamic. Still, there are plenty of cases in D3 where type-checked branches are a necessary evil, so it might be okay to use here. But I expect this isn\u2019t the only place where you\u2019d need to patch some changes for easier higher-order programming.\n. Thank you for the suggestion. Although D3 doesn\u2019t support IE8 and below, given the risk of breakage to existing users and the apparently negligible benefit of this change, I am inclined to leave things as-is. On the other hand if there\u2019s a real-world use case where you notice the performance difference, let me know and I may change my mind!\n. My issue with defensive programming is that I find it difficult to know where to draw the line: once you start, it\u2019s easy to become increasingly paranoid by considering every way the input might be malformed and code against it. Then your code balloons with complexity, making it harder to maintain and slower for the common cases.\nSo, while this may be a reasonable common case to defend against, I\u2019m still inclined to leave the training wheels off and have the whole thing fly apart if the inputs are invalid. The stack layout requires uniform inputs: every layer must have the same number of values at the same x-coordinates.\n. Thanks for the suggestion. However, as this is not a backwards-compatible change and we\u2019ve already committed to the existing API, this change would need to be deferred to the next major release (4.0.0). The motivation for the current behavior is that the accessor functions are conceptually methods of the stack operator (well, to the degree that methods exist in a hydrid-classical/functional programming paradigm), which is why the stack operator is the context. I can see how it might be useful to change it but it doesn\u2019t seem like a huge win so I\u2019m inclined to be conservative and leave things as-is.\n. selection.children\nI\u2019ve done this in the past using >, the child combinator. So, your example:\njs\nd3.select(\".foo\")\n  .children(\".bar\")\n    .classed(\"baz\", true);\nWould be expressed as (option A):\njs\nd3.select(\".foo\")\n  .selectAll(\".foo > .bar\")\n    .classed(\"baz\", true);\nOr, more likely, as (option B):\njs\nd3.selectAll(\".foo > .bar\")\n    .classed(\"baz\", true);\nOf course this isn\u2019t exactly the same as the functionality you specified. In option A, there could be other elements with class \u201cfoo\u201d within the first element matching the selector \u201c.foo\u201d, so this could potentially select more elements than the selection.children operator. This is why Selectors Level 4 introduces a \u201c:scope\u201d selector. Using this feature you could reproduce your original code exactly (option C):\njs\nd3.select(\".foo\")\n  .selectAll(\":scope > .bar\")\n    .classed(\"baz\", true);\nOption B is likewise slightly different because there could be multiple elements with the class \u201cfoo\u201d, and so selecting all bar-classed elements within foo-classed elements is more relaxed than selecting just the bar-classed children of the first foo-classed elements.\nStill, even though options A & B aren\u2019t exact equivalents, in practice you can almost always adjust the selectors to do what you want my making them more specific.\nAnother approach, option D, to selecting children that reproduces the original example exactly:\njs\nd3.select(\".foo\")\n  .selectAll(function() { return this.childNodes; })\n  .filter(\".bar\")\n    .classed(\"baz\", true);\nUgh, okay, even this isn\u2019t exactly what you want because node.childNodes includes non-element children such as comment and text nodes. But often you can assume the children are elements (for example, when the elements were created in JavaScript).\nSo, a few thoughts:\nIf we were to add this method, I would name it selection.selectChildren. The \u201cselect\u201d prefix ties it more closely to the other select methods. Another possibility is \u201cselectAllChildren\u201d but that seems redundant since \u201cchildren\u201d is plural.\nI\u2019m not sure whether we need to support passing a selector, given that you can easily chain with selection.filter. But maybe. Your reuse of selection.selectAll and selection.filter is good because it ensures consistency. (For example, your implementation correctly allows the selector to be specified either as a string or as a test function.) I\u2019ll send you a few inline comments on smaller issues.\nBut at a higher-level, I\u2019m not convinced that this functionality is essential, or that it gives enough value to justify the implementation. The implementation is fairly small and easy to explain, which is nice, but it\u2019s still new API surface area. The difference between select and selectAll is important, too, since selectAll regroups the selection; people would need to understand that selectChildren is a selectAll-type operator. (Potentially this is a reason to use the name \u201cselectAllChildren\u201d despite its verbosity.) And as described above, there are many ways to achieve similar functionality. I\u2019d like to see some real-world examples to advocate the inclusion of this functionality. Are there any existing examples that would be simplified using this new feature?\n(I will comment separately on the other functions.)\n. Another possibility would be to polyfill support for Selectors Level 4\u2019s :scope selector. That would be lovely, but I don\u2019t have a good sense of how much code would be involved in implementing the polyfill on top of Selectors Level 3 for just that feature.\n. selection.parent\nselection.ancestor\nThe main problem with these methods are data-inheritance and grouping as described in How Selections Work. (Related #350.)\nI\u2019m fairly sure you would never want to inherit data going up the DOM hierarchy. Since the DOM is a hierarchy (not a directed graph) each non-root element has exactly one parent element. Thus, selection.parent and selection.ancestor would be select-type methods rather than selectAll-type methods, and if built on top of select would propagate the descendant\u2019s data to the selected ancestor element. However, in the likely case that the descendant was previously bound to different data than the ancestor, this would unexpectedly overwrite the ancestor\u2019s data.\nWhile not an issue with single-element selections, the other issue with selecting an ascendant is that it wouldn\u2019t regroup the selection in the same way that descending into the DOM does. For example, if you d3.selectAll(\".grandparent\"), then grandparent.selectAll(\".parent\") and then parent.selectAll(\".child\"), the parent elements are grouped by grandparent element, and the child elements are grouped by their parent element. But if you d3.selectAll(\".child\") and then child.selectAncestor(\".parent\"), you still have a flat selection. Without a bunch of magic you don\u2019t have sufficient information to reconstruct the equivalent grouping. Maybe this isn\u2019t a huge issue since you would also get a flat selection if you said d3.selectAll(\".parent\"), but it seems to open a can of worms to allow people to have bidirectional traversal of the hierarchy.\nMaybe not the most robust solution, but I often use element.parentNode to achieve similar functionality:\njs\nd3.selectAll(\".item\")\n  .selectAll(\"a.action\")\n    .on(\"click\", function(d) {\n      d3.select(this.parentNode)\n          .classed(\"active\", d.active = !d.active);\n    });\nThis might also be something that is solved by Selectors Level 4\u2019s selector subjects, but it seems like that specification isn\u2019t complete yet so I\u2019m not totally sure how it works.\nOne potential approach to avoid the selection problems while addressing the described use case would be a static method, d3.selectAncestor(element, selector).\njs\nd3.selectAll(\".item\")\n  .selectAll(\"a.action\")\n    .on(\"click\", function(d) {\n      d3.selectAncestor(this, \".item\")\n          .classed(\"active\", d.active = !d.active);\n    });\nThat feels a bit weird to me since it\u2019s limited to selecting a single element, so why tie it to creating a selection? You could have something like this:\njs\nd3.selectAll(\".item\")\n  .selectAll(\"a.action\")\n    .on(\"click\", function(d) {\n      d3.select(this.querySelectorAncestor(\".item\"))\n          .classed(\"active\", d.active = !d.active);\n    });\nBut that feels weird since it\u2019s so verbose and would require patching the Element interface, so I definitely wouldn\u2019t want to build that into D3. So I\u2019m not sure what the answer is here besides element.parentNode. :)\n. The assumption with the old code was that you didn\u2019t change the type of scale, because it doesn\u2019t really make sense to transition from an ordinal scale to a quantitative scale (the former is discrete while the latter is continuous).\nAnyway, I suppose it wouldn\u2019t hurt to make this change, but it would need tests. And we\u2019d need to verify the transition from quantitative -> ordinal as well, because the old comment that\u2019s in there currently is no longer valid if you are allowed to change scale types. (\u201cFor ordinal scales: - any entering ticks are undefined in the old scale\u2026\")\n. I simplified the code a bit and tested in-browser.\n. Is this standard practice? Seems like a pain to update this file whenever a new release comes out, and so it\u2019s just going to diverge anyway.\n. OK.\n. Thanks for looking into this! I think we should go with #1636 for now. I used the debugger and stepped through the code in Stable & Canary in parallel and was able to identify where the behavior diverged. If we can identify these points of instability, fixing them should be more robust than relying on epsilons. But of course this is hard to do in general;\u00a0we\u00a0were a bit lucky in the case of bisection during resampling.\n. Would you mind signing D3\u2019s CLA and building the generated files, as described in the new contributing guidelines?\n. Thank you.\n. Folded into #1690.\n. Thanks for tackling this problem. How about using this seeded psuedorandom number generator, just for this test? https://github.com/davidbau/seedrandom\n. Merged to master. I added a teardown to restore the native Math.random.\n. I replied to this pull request but the comment was lost when I inadvertently navigated away. So instead I just implemented the proposed changes in #1653 and then adapted your new tests. Please review and submit any additional changes to the map-size-empty branch. Thank you!\n. Merged.\n. There\u2019s been some discussion of this at #750. Please see the proposed API there \u2014\u00a0I\u2019m about to flesh it out a bit in the description.\n. js\nvar russian = d3.locale({\n  decimal: \",\",\n  thousands: \" \",\n  grouping: [3, 3],\n  currency: [\"\", \" \u0440\u0443\u0431.\"],\n  dateTime: \"%A, %e %B %Y \u0433. %X\",\n  date: \"%d.%m.%Y\",\n  time: \"%H:%M:%S\",\n  periods: [\"AM\", \"PM\"],\n  days: [\"\u0432\u043e\u0441\u043a\u0440\u0435\u0441\u0435\u043d\u044c\u0435\", \"\u043f\u043e\u043d\u0435\u0434\u0435\u043b\u044c\u043d\u0438\u043a\", \"\u0432\u0442\u043e\u0440\u043d\u0438\u043a\", \"\u0441\u0440\u0435\u0434\u0430\", \"\u0447\u0435\u0442\u0432\u0435\u0440\u0433\", \"\u043f\u044f\u0442\u043d\u0438\u0446\u0430\", \"\u0441\u0443\u0431\u0431\u043e\u0442\u0430\"],\n  shortDays: [\"\u0432\u0441\", \"\u043f\u043d\", \"\u0432\u0442\", \"\u0441\u0440\", \"\u0447\u0442\", \"\u043f\u0442\", \"\u0441\u0431\"],\n  months: [\"\u044f\u043d\u0432\u0430\u0440\u044f\", \"\u0444\u0435\u0432\u0440\u0430\u043b\u044f\", \"\u043c\u0430\u0440\u0442\u0430\", \"\u0430\u043f\u0440\u0435\u043b\u044f\", \"\u043c\u0430\u044f\", \"\u0438\u044e\u043d\u044f\", \"\u0438\u044e\u043b\u044f\", \"\u0430\u0432\u0433\u0443\u0441\u0442\u0430\", \"\u0441\u0435\u043d\u0442\u044f\u0431\u0440\u044f\", \"\u043e\u043a\u0442\u044f\u0431\u0440\u044f\", \"\u043d\u043e\u044f\u0431\u0440\u044f\", \"\u0434\u0435\u043a\u0430\u0431\u0440\u044f\"],\n  shortMonths: [\"\u044f\u043d\u0432\", \"\u0444\u0435\u0432\", \"\u043c\u0430\u0440\", \"\u0430\u043f\u0440\", \"\u043c\u0430\u0439\", \"\u0438\u044e\u043d\", \"\u0438\u044e\u043b\", \"\u0430\u0432\u0433\", \"\u0441\u0435\u043d\", \"\u043e\u043a\u0442\", \"\u043d\u043e\u044f\", \"\u0434\u0435\u043a\"]\n});\nThen:\njs\nrussian.numberFormat(\"$,.2f\")(1234567.89); // \"1 234 567,89 \u0440\u0443\u0431.\"\nNote that this doesn\u2019t affect the behavior of the default d3.format:\njs\nd3.format(\"$,.2f\")(1234567.89) // \"$1,234,567.89\"\nEdit: this also demonstrates that the currency formatter is now smart enough to put the currency symbol after the number when desired.\n. @rbu If you are pulling in Globalize.js already, wouldn\u2019t you just use Globalize.js to do the number and time formatting? What would be the benefit of creating a d3.locale object from that, given that Globalize.js already provides number and date formatters?\nFor the U.S.-centric default implementation of locale.timeScaleFormat, I\u2019m not sure what the best solution is here. If you want different behavior, it probably makes more sense to just define your own time format, as in the custom time format example. So by that argument I think I\u2019ll remove the locale.timeScaleFormat, since it\u2019s not properly localized anyway.\n. Can use \"\\xa0\" for that (or embed a non-breaking space directly, and it will get escaped by the build).\n. Folded into #1690.\n. (In practice I think it might be preferable to use white-space: nowrap rather than hard-coding this behavior into the locale, but maybe either is okay.)\n. It\u2019s true that map.empty and map.size are constant-time operations when you precompute their return values, but effectively the cost is amortized by making add and remove slower. So, the overall performance of the map class will depend on usage: if you call size or empty frequently, then it might make sense to precompute the value, whereas if you call it infrequently, then it might make sense to compute it lazily by iterating.\nIn any case, I wasn\u2019t primarily concerned about performance here. I think exposing the field _size is ugly, and I don\u2019t want to do it, and implementing size and empty this way seemed better than making the other methods privileged so that they can access the internal size field.\n. (Also, map.empty is still constant-time because it returns true on the first matching key, and we only expect a constant number of non-matching iterable properties.)\n. Folded into #1690.\n. OK, I\u2019m much more confident in the new d3_geo_transverse implementation, and it fixes the tests, so this should be ready to go now. This pull request doesn\u2019t expose the generic functionality, but we could enable it in 3.4.\n. Thank you! Fixed in 3.3.13.\n. It\u2019s probably worth extracting \u03c0\u00a0/ 4 as a constant quarter\u03c0 and putting that in math/trigonometry. (There\u2019s already a half\u03c0 there.) And making the same edit in geo/transverse-mercator.\nThere\u2019s a benchmark in test/geo/path-benchmark if you want to evaluate this change in context, though you might need to edit the benchmark to use the Mercator projection as it mostly uses the stereographic projection at the moment. I think the cost of this divide is likely negligible compared to the much more expensive trigonometric operations (and garbage collecting temporary objects), but since it\u2019s an easy change to make, why not? :)\n. I hate that boilerplate that checks for module.exports. I know, it\u2019s only a few bytes, but it just feels like pollution. The reason I had index-browserify.js before was expressly to avoid polluting the standard release (d3.v3.js) for browsers with special cases for one of JavaScript\u2019s many incompatible packaging systems. So if there\u2019s a problem with index-browserify.js, I\u2019d rather fix it there (say by caching the global and then restoring it) rather than putting this logic in the main library.\nOn the other hand\u2026\nNYT recently standardized on using RequireJS to load modules. Then again RequireJS provides a shim config which allows it to require \u201colder, traditional\u201d libraries (a.k.a. STANDARD JAVASCRIPT) that expose globals, so we probably don\u2019t need to do anything for D3 to work in that environment.\nIf we want to look at jQuery for precedent, we could do something like this:\n``` js\nif (typeof module === \"object\" && module && module.exports) {\n  module.exports = d3;\n} else if (typeof define === \"function\" && define.amd) {\n  define(\"d3\", [], function () { return d3; });\n}\nif (typeof window === \"object\" && window.document) {\n  window.d3 = d3;\n}\n```\n. Thanks, @sheppard.\nThe other case to consider is within a WebWorker environment. I wonder whether we should use self or this instead of window for better compatibility in the last case. For example:\njs\nif (typeof define === \"function\" && define.amd) {\n  define(d3);\n} else if (typeof module === \"object\" && module.exports) {\n  module.exports = d3;\n} else {\n  this.d3 = d3;\n}\n. Superseded by #1689.\n. Wouldn\u2019t this break require(\"d3\") in the case where the optional dependency isn\u2019t satisfied? I understand you want a solution for a browser environment, but it seems first and foremost npm install d3 and require should work in a Node environment, given NPM is the Node Package Manager.\nD3 already supports a cornucopia of browser dependency managers (which decently reflects the mess of options there), including Jam, Browserify, Bower, and Component.\n. So what\u2019s the benefit of deferring the failure to the require stage rather than the install stage?\n. Thanks. I think that\u2019s probably the best course for now.\n. Related #1672.\n. Superseded by #1689.\n. The only effective difference is using typeof exports === 'object' rather than our current longer typeof module === \"object\" && module.exports, right? I feel like the latter is more robust, but then again this whole thing seems like a  cludge anyway. :)\n. Obligatory XKCD reference: :grin:\n\n. Folded into #1690.\n. Superseded by #1708. But my question is whether this information is used by Bower for anything? According to the Bower documentation, the only supported properties in the bower.json are:\n- name\n- version\n- main\n- ignore\n- dependencies\n- devDependencies\n- private\n. Closing as no one has provided additional input.\n. Yep, this looks like a bug. Thanks for the report. I\u2019ll probably make a few tweaks to the implementation per my style.\n. Fix merged into #1762 for 3.4.4.\n. This looks good. Would you mind signing the Individual Contributor License Agreement, per the contributing guidelines?\n. Merged into #1762 (but please sign the CLI).\n. Nice catch! I will add a test.\n. Would you mind signing the D3.js Contributor License Agreement, per the contributing guidelines? Thank you.\n. On second thought, I see you already have. Excellent!\n. Released in 3.4.2.\n. Thank you for the pull request. However, I don\u2019t see a big benefit to computing the domain greedily (automatically) in the stack layout, and so in favor of parsimony and keeping the API as small as possible, I think we should retain the existing API and users can compute the domain using d3.extent (or d3.min / d3.max) as needed.\n. I think there are enough ways to do this already:\n- You can implement a custom projection using d3.geo.projection (see the d3.geo.equirectangular implementation for example).\n- You can implement a custom geometry stream using d3.geo.transform (see bl.ocks.org/5663666 for example).\n- For SVG, you can use viewBox,  or apply a transform attribute to a containing  element.\n- For Canvas, you can likewise apply a transform.\nI don\u2019t think it\u2019s necessary to support this explicitly in d3.geo.projection, and it complicates (albeit in a fairly small way) the API and implementation, so I\u2019d rather leave it out. Also, as Jason pointed out, some projections lose their good properties (e.g., conformity) if you stretch them asymmetrically.\n. > Features provided by d3 projection, such as the London example aforementioned, become useless.\nI think you might be overstating. :) For example, if you apply a transform to a G element, and you use d3.mouse to get the pixel position of the mouse, this takes the transform into consideration so the coordinates returned will be in the same space as the projection and can be used by projection.invert.\nLikewise if you want to place an element on top of London, putting it in the same transformed G element would make it consistent with the projection. The only issue is that element would be stretched according to the transform, so a circle would become an ellipse, or stroke widths would be distorted, etc.\nAnd if you don\u2019t want to use an SVG or Canvas transform, you can still stretch a projection by implementing a custom projection or geometry stream. I agree your proposed change doesn\u2019t break the existing API, but it does add complexity which is always my first concern with any change.\nLet me experiment by implementing my own suggestion and seeing how awkward it is.\n. Yeah, I feel like using d3.geo.projection to create a custom projection is entirely reasonable. Here is a stretched equirectangular:\n\nAnd you could reuse any existing raw projection if you don\u2019t want to duplicate the implementation. (I didn\u2019t bother with d3.geo.equirectangular.raw since it\u2019s simply the identity function.)\n. I think it\u2019s semantically preferable to return null here, and that preserves the existing API (albeit one that was not explicitly documented).\nAlso, this isn\u2019t really the right place to fix this bug, because it\u2019s perfectly valid for someone to remove the \"d\" attribute from a path element in other contexts, such as by saying d3.select(\"path\").attr(\"d\", null), in which case you\u2019ll trigger the same IE bug. Or as another example d3.geo.path might return a null path string. And people can write their own path generators which can return null and aren\u2019t under our control.\nAdd to that, this \u201cfix\u201d for IE reintroduces problems for older WebKit browsers, as you mentioned. (See also 1c2546050f91cc93dcd6960a4d317e3176b5b8aa.) So it\u2019s kind of shifting the problem around rather than solving it precisely.\nAs I said in #1737, a better solution might be to patch IE\u2019s broken SVGPathElement prototype. Or, do nothing, under the philosophy that D3 is not a compatibility layer, and just expect people to workaround this issue on their own or wait for wider IE11 adoption. I think if this isn\u2019t a particularly widespread problem it might be okay to ignore it in favor of simplicity.\n. I think I\u2019d probably rename this to \u201cclockwise\u201d rather than \u201cnegativeSweep\u201d, but the functionality sounds reasonable.\n. I have found a simpler solution to this problem, which is to not implicitly swap the start and end angles when the start angle is greater than the end angle; instead, we now draw a counter-clockwise arc in this case. This obviates the need for an explicit flag, and ensures that the start of the textPath is always at the specified startAngle.\nhttp://bl.ocks.org/mbostock/57d620285395dae5a2ff\n. I like a better motivating example before adding new functionality. Wouldn\u2019t it be simpler to implement your example like this?\njs\nvar formats = {\n  year: d3.time.format(\"%Y\"),\n  month: d3.time.format(\"%b, %Y\"),\n  day: d3.time.format(\"%-d %b, %Y\")\n};\nformats.month(date);\n. Equivalent to this?\njs\nvar formats = {\n  year: d3.time.format(\"in %Y\"),\n  month: d3.time.format.multi([\n    [\"in %b\", thisYear],\n    [\"in %b, %Y\", function() { return true; }]\n  ]),\n  day: d3.time.format.multi([\n    [\"on %-d %b\", thisYear],\n    [\"on %-d %b, %Y\", function() { return true; }]\n  ])\n};\nformats.month(date);\nI guess it seems clearer to me to keep the time formats separate and branch externally, than to merge the formats into a single format with branching. Especially since, in this example, none of the formats are shared across the format type (\"year\", \"month\" or \"day\").\nI know this seems like a small change, but it still complicates the API and requires explanation in the documentation. (And precludes us from adding other arguments to the predicate function in the future.)\n. It would be nice if the function() { return true; } at the end were done automatically. Then it would be more concise:\njs\nvar formats = {\n  year: d3.time.format(\"in %Y\"),\n  month: d3.time.format.multi([[\"in %b\", thisYear], [\"in %b, %Y\"]]),\n  day: d3.time.format.multi([[\"on %-d %b\", thisYear], [\"on %-d %b, %Y\"]])\n};\nAlthough it\u2019s a bit weird that the last element is a single-element array. It seems like you might be tempted to just put the string in there instead, which leads to ambiguity.\n. Merged into #1762.\n. If we wanted to be stricter, we could say typeof b.interpolate === \"function\" ? b.interpolate : \u2026 instead of b.interpolate || \u2026. Though I can\u2019t imagine it\u2019s likely that someone is trying to interpolate an object with an interpolate property on it.\n. Something has been bothering me about this pull request for a while, and I think I\u2019ve put a finger on it.\nFirst, there\u2019s already a way to extend the set of interpolators used by d3.interpolate: add a new interpolator to d3.interpolators. Having d3.interpolate check for an interpolate property is a different way of accomplishing this same objective, which violates the principle of parsimony. Also, there could be a false positive when checking the interpolate property (JavaScript has no \"implements d3.interpolatable\" equivalent; so we must rely on duck typing).\nSecond, the net impact of this change is that color interpolation depends on the type of the destination color, whereas before RGB interpolation was always used. While this may be desirable in some scenarios, there\u2019s no reason the colorspace in which the color is specified and the colorspace in which the colors are interpolated need to be the same. Sometimes you want to use d3.hcl to specify a color more intuitively, for example, but you might still want to use RGB colorspace to interpolate during a transition. This change makes it slightly easier to specify the interpolation colorspace, but only if you understand that the colorspace of the destination color controls the behavior; a more explicit method would be to specify the interpolator explicitly (e.g., scale.interpolate or transition.attrTween).\n. I don\u2019t understand. I thought the recommended pattern was to define D3 as an anonymous module, with the name being specified by the client that loads the module? Will adding a name break current users?\n. Hmm, emphasis added:\n\nYou can explicitly name modules yourself, but it makes the modules less portable -- if you move the file to another directory you will need to change the name. It is normally best to avoid coding in a name for the module and just let the optimization tool burn in the module names.\n\nI do see that jQuery specifies the name \"jquery\" (see exports/amd.js). So, I suppose I should test it and see what happens.\n. I tested and learned a few things.\nWhen d3 is included as a script tag on a page that has AMD, and require is subsequently called, it  no longer throws an error (\u201cMismatched anonymous define() module\u201d). In addition, although it is still the case that d3 is not exported as a global when there is AMD, it is now possible to access the loaded d3 via a require(\"d3\", \u2026). For example:\n``` html\n\n</p>\n<p>require([\"d3\"], function(d3) {\n  console.log(d3);\n});</p>\n<p>\n```\nOf course, it still makes more sense to load D3 via require and omit the script tag entirely. In the example above the script tag is entirely superfluous because the name of the module (\"d3\") matches the name of the file (\"d3.js\").\nHowever, the downside is that it is no longer possible to load D3 under a different module name than \"d3\". For example, assuming a d3.js in the same directory, the recommended require pattern still works:\njs\nrequire([\"d3\"], function(d3) {\n  console.log(d3.version); // \"3.4.3\"\n});\nHOWEVER, if you configure a different name for D3, this no longer works \u2014 even though it successfully loads the script \u2014\u00a0because the configured name (e.g., \u201cd3/3\u201d) doesn\u2019t match the name (\u201cd3\u201d) baked into D3:\n``` js\nrequire.config({\n  paths: {\n    \"d3/3\": \"d3\"\n  }\n});\nrequire([\"d3/3\"], function(d3) {\n  console.log(d3); // undefined!\n});\n```\nIn fact, this is the only reason why the NYT version of jQuery differs from the official distribution \u2014\u00a0it has been edited to remove the name \"jquery\" from the module definition, so that we can define names that are more suitable to our application.\nSo, given that this is not backwards compatible, and that the documentation seems to suggest anonymous modules are preferred, I am inclined to close this request.\n. Yep, that\u2019s true. You\u2019ll need to change how you SMASH them together if you want to use SMASH and require. For example, you could pipe it through sed to add a module name to the define.\n. Strictly speaking this is backwards-incompatible because it does not preserve the context (the array object) and the index that was previously being passed to the bisect accessor. However, I think it\u2019s unlikely that an accessor would depend on the index argument (though surely possible). And this behavior while consistent with our other array accessor methods is not documented.\nI also wonder whether we should deprecate d3.bisector or support both methods.\n. Merged into #1762 for 3.4.4.\n. Looks good, thanks.\n. Interesting. Seems reasonable, although I\u2019d favor using +date instead of date.valueOf().\nBut I\u2019m curious what the application is. When do you need to interpolate dates? It\u2019s much more common to interpolate display values, such as pixel positions, colors, styles, path data strings. In what scenarios do you need to interpolate dates?\n. Interestingly, in previous versions of D3 this worked. It appears to have been broken by 359546c80c2a07edd8b526b2956091eb35119767. There is even an example, Manual Axis Interpolation, of the suggested use case of interpolating the domain of a time scale!\nThe commit was first included in release 3.1.5. As the release notes say:\n\nFix d3.interpolate such that objects that are coercible to numbers (such as [0]) are still interpolated using d3.interpolateArray or d3.interpolateObject as appropriate.\n\nThe commit fixed #1176, but also affected Date interpolation: dates were previously coerced to numbers and interpolated using interpolateNumber, but in 3.1.5 and later they were interpolated as objects (somewhat uselessly).\nIt definitely makes sense that interpolating single-element arrays of numbers should return an array. But perhaps for objects that are coercible to numbers, it still makes sense to interpolate them as numbers rather than as objects? Using d3.interpolate for Number instances is also useless right now. I\u2019ve created a separated pull request to fix this, #1780.\nOf course it could still also be good to support Dates explicitly, rather than coercing them to numbers. But it\u2019s not strictly necessary as d3.time.scale will coerce numbers back to Dates when you set the domain.\n(This is slightly related to #1763, which removes the instanceof check for d3_Color and instead checks if the object exposes an interpolate property. But obviously the built-in Date type doesn\u2019t do that, nor should we extend it to do so.)\n. (I also fixed the example by coercing explicitly.)\n. Yeah, I think we should go with #1780 for now (more conservative, more general, though slightly less convenient), and we can consider adding date interpolation in the future if we think it\u2019s still worth it.\n. Thanks. Merged into #1762 for 3.4.4.\n. Great! Thank you.\n. This also introduces a d3.touch method and changes the drag behavior to listen to the target element of the touchstart event rather than the window, avoiding a crash when a DOM element is removed while dragging. You can now temporarily remove a DOM element while dragging, and later add it back while still dragging, and it will be in the right place.\nI might consider leaving the d3.touch method private for now so that we can roll this out as a 3.4.x, and making d3_touch public in the 3.5 release.\n. So far, these fixes only apply to d3.behavior.drag. There\u2019s a small fix we could make to d3.behavior.zoom. And major changes that we could make to d3.svg.brush if we wanted to support multitouch brushing (not multiple brushes, but just being able to drag handles independently, say). Though I think adding multitouch support to the brush component might be too large of an undertaking for 3.4.4.\n. Merged into #1762 for 3.4.4.\n. Can you rebase this onto the fix-drag-touchend branch and redirect the pull request there, #1792?\n. Replaced with #1799 (pull request to the fix-drag-touchend branch rather than master).\n. Lack of time, at the moment.\n. Related #2556.\n. Superseded by #2403.\n. Thanks!\n. Replaced by #1804.\n. http://bl.ocks.org/mbostock/8cd70315d7d66b3ee039/fd2bc5afa14c0953be8f122af7c3e619f980f239\n. Merged in #1762.\n. There\u2019s no other code on this page, so I don\u2019t see any reason to wrap this code in a self-executing function to prevent the variables from being globals. If you want to reuse this code in some other context, that other context would be where you should wrap the code in a self-executing function.\n. Merged into #1762 for 3.4.4.\n. I pushed a tweak which I think is more explicit. What do you think?\n. Ha, I wondered about that! This reinforces the importance of testing projections against real-world data (literally, heh) and the limitations of our unit tests to detect such changes. I almost wonder about having reference images for each projection, rendering to canvas to tests, and then doing image diffs to compare the results.\n. Moving to icebox for now, but if you think you still have a better fix, please let me know.\n. The bug appears to be in voronoi.topology. It looks like I\u2019m not stitching together the clipped edges correctly. Here\u2019s a version just using non-topological polygons:\n\n. Actually, it might even be in topojson.merge. Because this still appears to work correctly:\njs\nsvg.append(\"path\")\n    .datum(topojson.feature(topology, {type: \"GeometryCollection\", geometries: topology.objects.voronoi.geometries.filter(function(d, i) { return i & 1; })}))\n    .attr(\"class\", \"voronoi-cell\")\n    .attr(\"d\", d3.geo.path().projection(null));\n. Fixed in b1284d48e5558e34ff4c7d99bacea61d2b805884.\n\nThe topojson.merge algorithm requires exact matches between the starting and closing coordinate of each polygon ring (in order to stitch them together). Normally this happens with quantized integer coordinates so small precision problems don\u2019t occur. Here we\u2019re doing the merging in non-quantized coordinates so I made sure that the first & last coordinate are exactly the same.\n. > You beat me to it! :)\n5 points to Gryffindor!\n. I\u2019m unsure whether to add this as a new method, though it does seem nice to piggy-back off of TopoJSON\u2019s representation of topologies. My main concern is whether the d3.geom.voronoi API is sufficient doing things with Voronoi diagrams, or if we need to expose the lower-level concepts of edges & half-edges.\n. I\u2019d still love to ship this feature for 3.5, but I think the API needs further thought.\n. I\u2019m thinking about the new API over in the d3-voronoi module; see d3/d3-voronoi#1 and d3/d3-voronoi#2.\n. Although I opted not to build this functionality into d3-voronoi directly, the latest release 0.3 of d3-voronoi makes the underlying Voronoi diagram available, so it\u2019s now possible to do this in \u201cuser land\u201d without touching the d3-voronoi implementation. For example:\n\nIf there\u2019s demand, I\u2019ll consider adding this to d3-voronoi, but I think it makes sense as an optional extension to d3-voronoi at the moment.\n. Looks good.\n. Numbers from the optimize-interpolate-string branch:\n| branch | n | p | time |\n| --- | --- | --- | --- |\n| optimize-interpolate-string | 12,000 | 0 | 11.3ms |\n| ChALkeR-master | 12,000 | 0 | 12.5ms |\n| master | 12,000 | 0 | 275ms |\n| optimize-interpolate-string | 12,000 | .5 | 17.2ms |\n| ChALkeR-master | 12,000 | .5 | 17.6ms |\n| master | 12,000 | .5 | 159ms |\n| optimize-interpolate-string | 12,000 | 1 | 21.4ms |\n| ChALkeR-master | 12,000 | 1 | 21.4ms |\n| master | 12,000 | 1 | 19.9ms |\n| optimize-interpolate-string | 60,000 | 0 | 78.1ms |\n| ChALkeR-master | 60,000 | 0 | 103ms |\n| master | 60,000 | 0 | DNF |\n| optimize-interpolate-string | 60,000 | .5 | 121ms |\n| ChALkeR-master | 60,000 | .5 | 122ms |\n| master | 60,000 | .5 | DNF |\n| optimize-interpolate-string | 60,000 | 1 | 140ms |\n| ChALkeR-master | 60,000 | 1 | 145ms |\n| master | 60,000 | 1 | 143ms |\n| optimize-interpolate-string | 300,000 | 0 | 491ms |\n| ChALkeR-master | 300,000 | 0 | 596ms |\n| master | 300,000 | 0 | DNF |\n| optimize-interpolate-string | 300,000 | .5 | 749ms |\n| ChALkeR-master | 300,000 | .5 | 775ms |\n| master | 300,000 | .5 | DNF |\n| optimize-interpolate-string | 300,000 | 1 | 833ms |\n| ChALkeR-master | 300,000 | 1 | 920ms |\n| master | 300,000 | 1 | 807ms |\n| optimize-interpolate-string | 1,500,000 | 0 | 2.40s |\n| ChALkeR-master | 1,500,000 | 0 | 2.95s |\n| master | 1,500,000 | 0 | DNF |\n| optimize-interpolate-string | 1,500,000 | .5 | 3.63s |\n| ChALkeR-master | 1,500,000 | .5 | 4.05s |\n| master | 1,500,000 | .5 | DNF |\n| optimize-interpolate-string | 1,500,000 | 1 | 4.25s |\n| ChALkeR-master | 1,500,000 | 1 | 4.80s |\n| master | 1,500,000 | 1 | 4.25s |\n. ChALkeR, this is fantastic.\nThank you for bringing this to my attention and for doing the benchmarks. I knew that the string coalescing logic was a bit messy, and I was essentially relying on numbers being mostly-different across strings. But in practice there are many cases where some numbers are the same\u2014such as the common case when interpolating two paths where only the y-values have changed.\nI wrote a micro-benchmark to reproduce the tests you used (to the best of my ability). I then used it to verify your findings and performance improvements.\nLooking at your implementation and the one in master, I decided to rewrite interpolateString from scratch, using a shared loop over matching pairs of numbers in a and b. (See the new interpolate/string.js.) This new implementation is approximately as fast as yours, and is much simpler to boot.\nSo, I\u2019m going to close this pull request in favor of #1830, but I\u2019m very thankful for the work you\u2019ve done. If you identify any other performance improvements here, please open a new pull request to the optimize-interpolate-string branch. Or if you see other things in D3 you\u2019d like to optimize, please open pull requests for those, too!\nThank you very much!\n. Yes, I can publish a patch release this week.\n. Hmm. I\u2019d probably wait on this to see if there\u2019s more interest. The original request seemed to want to clear all listeners on an element, including ones which could have been registered outside of D3? (Which I don\u2019t think is possible.) But in any case it feels a bit messy to me to remove all listeners, even within D3 \u2014\u00a0if the application code is cleanly structured I feel like you should at least know the namespaces of the listeners you want to remove. \n. @burner986 Please use Stack Overflow to ask for help, and don\u2019t cross-post here. You can retrieve a named event listener using selection.on like so:\njs\nvar listener = selection.on(\"mousedown.drag\");\nSo, here\u2019s how you could remove it, and then add it back:\njs\nvar listener = selection.on(\"mousedown.drag\");\nselection.on(\"mousedown.drag\", null); // removed\nselection.on(\"mousedown.drag\", listener); // re-added\n. This looks good, though I think for testing it\u2019d be best to use a seeded random number generator (as done in test/math/random.js). Then the tests for d3.shuffle can be deterministic.\n. I rewrote the tests to use seedrandom and merged into #2118 for 3.5.\n. Thanks for helping. Any temporary variables needed for traversal or layout must be scoped on the _tree property, to avoid name collisions with existing properties on the data, and to facilitate subsequent clean-up.\nEven better would be to avoid temporary properties entirely (including _tree), though it would be more work to change this. Probably would require creating wrapper nodes that point to the original data nodes, with the wrapper nodes containing the extra temporary properties needed for layout.\nI might take a crack at this myself\u2026\n. I found some time. I ended up writing it from scratch, but I appreciate the offer to help. If you\u2019re still interested, please review #1876. Thank you!\n. I\u2019d feel a little more at-ease if you\u2019d be willing to sign the CLA. But you\u2019re right that the words for the weeks and months after obviously public domain, so if necessary I could verify that this pull request is merely a find-and-replace from the pre-existing locale code.\n. OK, I\u2019m willing to waive the CLA for this since the words themselves are public domain, and the code is just find-and-replace from the existing code. Thanks for the contribution!\n. Fixes #1868.\n. Thanks for the review. I agree the abbreviated internal variables are harder to read. But it saves quite a few bytes in the minified JavaScript, and since these are internal variables, I am okay with that trade-off.\n. Thanks for the fix.\nIt shouldn\u2019t be necessary to delete the children array \u2014\u00a0we\u2019re not recomputing the children, so they should have been deleted (if necessary) from the previous pass of the layout. So checking for the presence of the children array should be sufficient. If it\u2019s present, it should be non-empty.\n. The code intentionally treats null and undefined equivalently.\n. I\u2019ve implemented tests using the Flare dataset in d3-hierarchy for 4.0.\n. Need to make the change in the source rather than the generated file, but this looks good.\n. Merged into #2118 and staged for 3.5.\n. Thanks for the pull request. If you want custom gravity, the recommended solution is to apply custom forces in the \u201ctick\u201d event listener, e.g., http://bl.ocks.org/mbostock/1021953. The built-in forces are just simple default ones.\n. I think we should do some microbenchmarks to compare the three strategies we have so far:\n1. Ternary expressions, as in 2a7f582.\n2. Bounds arrays, as in wenchaojiang/d3@ab1aaf84c942beda4e6e976623dc2574ad10a7ed.\n3. Switch statement, as in 1652ba8.\n. Perf test: http://jsperf.com/quadtree-find\n. Merged into #2118 for 3.5. Still some potential enhancements to the API, but seems fine for a minor release. Test here: http://bl.ocks.org/mbostock/9078690\n. Definitely think the error should be deferred until parse time rather than load time, if we take this approach.\nI wonder, does it help at all if we create a separate \u201cclass\u201d (function prototype) rather than creating each row as an object literal? Something like the dsv-parse-type branch.\n. I wrote a simple benchmark and it seems that using a prototype is faster than a bare object, but using an object literal is substantially faster than both. :\\\n. I\u2019m not convinced yet whether it\u2019s worth supporting CSP. It seems like an arbitrary restriction (your code gets to run, but you can only use a subset of JavaScript) with no demonstrable security benefit in this case (because the \u201cunsafe\u201d code we are evaluating is in fact safe). Also, the workaround is easy to apply (using parseRows, and optionally a custom row transformation function), and so far we only have a single request for support.\nIf JavaScript had a better way of defining types that are faster to instantiate without using new Function / eval, we should switch to that, but then that would only work on new browsers so we\u2019d still have multiple paths. :\\\n. I think I\u2019m inclined to use something more obscure than __value__, since I wouldn\u2019t want anyone depending on this property directly (meaning, it\u2019s part of the private API, not the public API as __data__ is). For example in selection.on, we have to wrap the listener, and so the original listener function is stored as l.$. I think $ would be okay here, too, and is shorter than __value__ besides.\n. I suppose transition.text should similarly support getting?\n. This implementation looks good, but I don\u2019t feel strongly that we need this functionality. I think in most cases if you want to query the DOM, you\u2019d use a selection. What do you think? Is it a good idea to support this?\n. Decided to not support this in the 4.0 API because there\u2019s no way to disambiguate between null meaning \u201ctransitions to the default value\u201d and \u201cno transition is defined for this attribute\u201d. You can however using transition.attrTween and transition.tween in getter mode.\n. Man, AMD support really opened up a can of worms, and I wonder if I regret it.\nIt seems to me like the main benefit of D3 supporting AMD is that it doesn\u2019t define the global. If you don\u2019t care about defining the global, then why support AMD at all? Just let people configure a shim and load D3 like every other JavaScript library.\nRelated discussion:\nhttps://github.com/jrburke/requirejs/wiki/Updating-existing-libraries\nMy take away is that jQuery is \u201cspecial\u201d, but I don\u2019t know whether D3 is special in the same way that jQuery is special.\nLike jQuery, D3 is also a \u201cfoundation of other third party libraries that all assume a global is available\u201d. So should D3 provide a global? The problem with D3 not providing a global is that every D3 plugin (also see d3/d3-geo-projection#9) must support AMD, or the plugin breaks because of a ReferenceError on the d3 global, or you force the user to jump through some tedious RequireJS config hoops to export the d3 global manually.\nLike jQuery, D3 is \u201ccommonly used as a dependency by other libraries\u201d and D3 \u201cis also the defacto implementation of the module interface implied by that name\u201d. So should D3 register as a named module, too? I have no idea. The discussion suggests that in the future jQuery will switch to an anonymous module.\nSo I guess our options are:\n1. Do nothing, and recommend that users specify whatever elaborate config is required to export the d3 global before loading a plugin. This is a documentation-only change, so perhaps we should do this regardless before we do anything else.\n2. Do nothing, and recommend that all D3 plugins adopt AMD. This is the most pro-AMD, but also will inflict the most pain on the user, since there\u2019s no practical way to get every D3 plugin to add AMD support. And it\u2019s tedious for developers. I\u2019ve done this for some of my other libraries (queue and topojson), but I haven\u2019t implemented AMD support for all D3 plugins. (Again, see d3/d3-geo-projection#9 for an example.)\n3. Remove AMD support from the default build. This would break everyone loading d3.v3[.min].js via AMD, so it\u2019d probably need to be done as part of the 4.x release. We could still provide a separate build with AMD support (say d3.v4.amd.js) that is identical but provides whatever magic incantation is preferred by AMD. (We could also remove support for module.exports, since that is trivially supported using package.json or browserify.json and a wrapper script, as we were doing previously\u2026)\n4. Export the d3 global. This is unlikely to cause additional harm, although it\u2019s conceivable that it could clobber something in the global namespace (such as an earlier version of D3 on the same page). This would just make any D3 plugins that do not support AMD start working again, with no fuss for the user. But it is the most unclean approach since we would dirty the global namespace, even though we claim to support AMD.\nOptions 1 & 2 aren\u2019t exclusive, and would be most in continuing with our existing approach.\nOption 3 would keep AMD separate from the main library and allow different options tailored to whatever people need, and perhaps I could stop wasting so much time thinking about how to load a JavaScript file. :imp: \nOption 4 is arguably the best for users, regardless of whether they are using AMD, though it\u2019s a weak compromise that doesn\u2019t establish a clear policy for other libraries. (Should queue and topojson export a global too?) Also, it\u2019s still possible for advanced users to create their own custom build if they don\u2019t want the global, or if they want to load D3 as a named module.\nSo I guess I\u2019ve convinced myself to agree with you and export a global. And I\u2019ll probably change my other libraries to do the same. For one thing, this will make me happy on nytimes.com because d3 will finally work in the console again\u2026\n. Technically this introduces a new public symbol, d3.color, which was previously private (d3_Color).\n. Thank you!\n. Hi. Thank you for the pull request. However, I\u2019m inclined to not special case this error for a few reasons:\n- The error is only thrown when the style property is invalid. For example, if you try to set the width property and you forget to specify the units. (\u201c42\u201d is invalid CSS but treated as \u201c42px\u201d in most browsers besides IE9.) It is relatively easy to find and fix these using IE9\u2019s debugger, and more importantly it is desirable to fix them rather than failing silently by default.\n- IE9 has a relatively small market share thanks to the adoption of IE10 and IE11+. This combined with the above means it should hopefully be affecting only a small number of users.\n- D3 is not a compatibility layer [1], so I\u2019d prefer to keep the number of browser workarounds to an absolute minimum. In this case, I think the right thing is to have the caller specify the appropriate units (or otherwise specify a valid style property value), rather than failing silently or trying to correct the value automatically.\n. Hello and thank you for the pull request!\nI don\u2019t see a strong reason to allow the structure of the entries object to be overridable. If you specify the name of the \u201ckey\u201d property, wouldn\u2019t you also want to be able to specify the name of the \u201cvalues\u201d property? We also don\u2019t allow other objects that are generated by D3 to be similarly customizable. For example, the nodes generated by the tree layout always have the same property structure.\nWe do allow input objects to be transformed implicitly by accessors. But output objects all have the same standard form. For one thing, this simplifies the documentation and makes the API behave more consistently.\nIf you want to transform these objects, I\u2019d recommend using array.map to do it yourself after the entries objects are constructed. If necessary, you could implement array.map recursively. Or, as in the example you\u2019ve included in the description, you could simply do a top-level pass.\njs\nvar entries = d3.nest()\n    .key(function(d) { return d[0]; })\n    .sortKeys(d3.descending)\n    .entries([[\"AL\", 1999, 200], [\"CA\", 1999, 350], [\"CA\", 2009, 550], [\"AL\", 2009, 250]])\n    .map(function(d) { return {state: d.key, values: d.values; });\n. I\u2019m not sure this is a desirable change. On devices that support two dimensional scrolling (such as Apple\u2019s Magic Mouse and Magic Trackpad), this will cause irregular behavior when horizontal scrolling: if the scroll is exactly horizontal, then deltaX is used, whereas if the scroll is not exactly horizontal, then deltaY is used.\nAlso, I can\u2019t reproduce this behavior in Chrome. Are you on Windows? When I use the SHIFT key it doesn\u2019t seem to have any effect on the scroll behavior.\n. It makes sense that this requires an input device with a proper wheel rather than a 2D touch input. Unfortunately, there\u2019s no explicit API for detecting the type of input device, and differentiating between input devices without an API is difficult. It\u2019s easier to differentiate them after listening to many events: touch devices will have various delta sizes in both directions, whereas wheel devices will typically have consistent delta sizes in only a single direction. But it\u2019s hard to differentiate them when only a single event has been received (or when the user has multiple input devices and switches between them, say a USB mouse with a wheel and a touchpad on the laptop).\nI\u2019m also not entirely sure why we want to zoom if the SHIFT key is down. For example, if you\u2019re on a tall and narrow web page where you can only scroll vertically, wouldn\u2019t holding down SHIFT similarly cause the page not to respond to mousewheel events (since horizontal scrolling is disabled)? The zoom behavior is similarly one-dimensional.\n. Excellent. Thank you.\n. Merged into #2053.\n. Looks good.\n. Merged into #2053.\n. Merged, thank you!\n. Hi Jon! Thanks for the pull request. It looks like the previous pull request #1866 is closer to the implementation I imagined in #1865, so I\u2019m going to close this request, but I appreciate your contribution. As far as tests go, it\u2019s hard to write tests for randomized behavior, but I think in this case it\u2019d be best to use a seeded random number generator (e.g., seedrandom) and then at least the tests for d3.shuffle can be deterministic.\n. Moved to d3/d3-arrays#11 for 4.0.\n. Looks good.\n. Merged into #2053.\n. Is there a mirror problem with entering ticks? In which case, there\u2019s no sensible entering position (at infinity), so no transition is possible?\nThis code feels a little complicated, but I don\u2019t have any great ideas on how to fix it since it presumably needs to handle both the transition and non-transition case. But I feel like the transition case is the one that\u2019s causing the problem, so maybe an attrTween would there? I\u2019m worried about this change doing more than addressing the specific issue.\n. Rather than re-setting the transform to its current value, how about not setting the value at all when the scaled tick value is infinite? #2054\n. I pushed a slightly shorter but equivalent implementation. Looks good to me.\n. Merged into #2075.\n. Thanks for the pull request. I do think this would be better as a plugin rather than an addition to core.\n. >  Is there a specific reason all the other localizations are against dialects of their specific languages?\nThere\u2019s no enforcement of how the locales are named at the moment; D3 doesn\u2019t have any automatic fallback logic to determine which locale to use. Instead, you tell D3 specifically which locale you want. The name of the locale is completely up to you.\nI think for convention\u2019s sake it makes sense to use language-county as the name of the locale definition in the repo, especially since parts of the locale definition are typically country- and not language-specific (such as using \u20ac for the currency). Then if someone wants to use fr-FR as a generic locale for French, that\u2019s fine too. I think just it\u2019s more obvious if we have the country in the name, since it would give you a hint that if you try to use this for fr-CA you might want to double-check the definition first.\n. Merged into master.\n. Merged into #2118 and staged for 3.5.\n. The new d3-quadtree module supports quadtree.remove and will be part of D3 4.0.\n. Looks good.\n. Merged into #2075.\n. Merged into #2118 and staged for 3.5.\n. I agree with that the one-argument version is better than the two-argument version, mostly due to confusion with insert, but also I think the one-argument version is clearer.\nI\u2019d probably worry a bit the edge cases in the syntax. (Like, should you be able to escape a . in a class name? And why does the ID have to come first?) Should we also allow arbitrary attributes to the specified, too, like \"div[foo=bar]\"? I might even go so far as to specify a BNF to formalize what the allowed inputs are, though it\u2019s probably simple enough to not need code generation to parse.\nMy other, broader, concern is parsimony. There\u2019s already a way to append elements, set ids, and set classes. This feature adds more convenient syntax, but the cost is both in maintaining the implementation and adding to the API. (We have to document it; people have to read it or skip over it in the documentation; people may be confused when they see the alternate syntax in examples; etc.)\nThis is somewhat similar to the multi-value maps added in 2.10. I never use that feature (okay, maybe once); it always feels like such a tiny win over doing it the normal way. I\u2019m not sure it was really a good idea to support it, in retrospect. The same may be true here, and this syntax also precludes data-driven generated ids and class names, so it\u2019s more limited.\n(Probably not much of a consolation, but I\u2019ll also add you could implement this as a d3 plugin by extending d3.selection.prototype. But that would probably outweigh the added convenience!)\n. Also, regarding the similarity with implicit namespaces: the win there was reducing confusion, not just convenience. Many web developers find SVG\u2019s need for namespaces to be pretty confusing, especially because HTML5 makes them optional in markup, and they are often hidden in the DOM inspector. So, it wasn\u2019t just a matter of saving a few characters when typing \"svg\" instead of \"svg:svg\", but getting to brush over the entire concept of namespaces for new users.\nThere is something to be said for convenience, though. It\u2019s just hard to draw the line, and I\u2019m a bit tired at the moment so I might not be the best judge.\n. > And I actually use the multi-value maps quite often, especially when setting a bunch of static attributes.\nFair enough. :)\n. Superseded by #2059, but thank you for the contribution!\n. Looks good.\n. Merged into #2053.\n. As with #2605 this feels to me like something that should probably be fixed internally, rather than exposed as a new public API.\nRelated #2426 #2589.\n. This is a duplicate of #2605, and probably not related to just fixing mousewheel events on Windows, since it\u2019s more about adding greater control over the zoom behavior.\nMy first concern with both of these proposals is whether it\u2019s better to intercept the input events yourself and then change the scale of the zoom behavior, rather than letting the zoom behavior handle the input events while exposing hooks for how the zoom behavior computes the new zoom level.\nFor example, maybe it makes sense to change the behavior of dblclick, since the default of doubling or halving is arbitrary. But it\u2019s not hard for you to intercept the dblclick event and trigger a zoom transition instead of letting the zoom behavior handle it.\nAnd, it probably doesn\u2019t make sense to override the interpretation of touch gestures; those are designed such that the touch point coordinates remain consistent under pinch and pan.\nSimilarly, it\u2019s questionable to change the behavior of mousewheel, since consistency is good for usability (aside from it being broken on Windows in some cases)\u2026 but sure, maybe it makes sense to override in some contexts for slower or faster zooming. You could also intercept the mousewheel events and do this outside the zoom behavior, though admittedly this is a bit harder to do than intercepting dblclick because a sequence of mousewheel events is typically aggregated into a zoom gesture (zoomstart, zoom+, zoomend) using a timer.\n. That sounds like a reasonable approach for discrete input events like dblclick, but I\u2019m not sure it\u2019s appropriate for mousewheel, which is a continuous gesture on some platforms (and some input devices), such as OS X with a Magic Mouse or a MacBook trackpad.\nYou can, of course, group a sequence of mousewheel events into a single discrete gesture, and this is exactly what Google Maps did before the great switch from raster to vector tiles. But we\u2019d need to change how the zoom behavior interprets the sequence of mousewheel events if you want it to snap to specific zoom levels.\nIt sounds like maybe the API you want is the ability to specify specific allowed zoom levels, rather than allowing continuous zooming between any zoom level (within the scaleExtent).\nAlso, I wonder whether you\u2019d want to temporarily allow being between the specified zoom levels, so as to make the transition between allowed zoom levels smooth and continuous.\n. Looks good.\n. Merged into #2053.\n. Looks good. I verified that the tests pass.\n. Merged into #2053.\n. This feels a bit awkward to me. The current API is designed such that the caller calls the zoom behavior on either a selection or a transition. In the case of a transition, the zoom behavior updates smoothly over time per the transition parameters. That looks something like this:\njs\nselection.transition().call(zoom.event);\nImportantly, the transition is specified by the caller, and used by the zoom behavior.\nWhat we\u2019re describing here is the zoom behavior specifying the transition, or at least overriding part of it: the duration and easing. Do we always want the behavior overriding these parameters? Would it make more sense to allow the zoom behavior to create the transition, rather than overriding parameters of a transition that was previously created by the caller? That might look something like this:\njs\nselection.call(zoom.transition);\nThis isn\u2019t quite perfect because selection.call returns the selection, so you can\u2019t subsequently modify the transition. And maybe it\u2019s still not perfect because you might want to modify some other transition parameters on creation \u2014\u00a0crucially, the transition name. So, needs a bit more thought\u2026\n. Maybe there\u2019s another way of doing this:\njs\nselection.transition()\n    .duration(zoom.duration)\n    .call(zoom.event);\nWouldn\u2019t that allow the caller to specify the transition duration based on the zoom behavior\u2019s logic? (Where zoom.duration is a magic function that computers the appropriate duration from the change in viewport.)\n. There\u2019s a somewhat-related issue here with #1985, where the zoom behavior creates a transition on dblclick / dbltap. The user might want to customize the duration of the transition created on dblclick, or prevent it entirely and keep the instantaneous change.\nOne way to do that would be to expose a new property on the zoom behavior (e.g., zoom.transitionDuration, duration, dblclickDuration?). Another way to do that would be for the caller to listen to dblclick events and override the duration of the transition created by the behavior. But there\u2019s no dbltap event to listen for, so maybe the caller would need to listen to something else? Ehhh.\n. Sounds good. Merged into 3.5.\n. I\u2019ve also added a zoom.duration property for 3.5 so as to customize (or disable) the dblclick zoom transition. We can extend this in 3.5.x to take a function whose input argument is the length of the uw-curve.\n. Looks good.\n. Merged into #2053.\n. Pretty sure this would break D3 in a web worker environment where there is no window.\n. Assuming this is superseded by #2060.\n. ~~Strangely, I can\u2019t see that bug.~~ Oops, it was the chained transition that was preventing the exit from removing the tick, so I wasn\u2019t testing enter and exit properly. Fixed test case:\nhttp://bl.ocks.org/mbostock/219e9a38d8de73f3f9f7/c0b1a1b0b99d9a2b2d0608b870e0a7ba04ac20a8\n. OK, I take it back. It\u2019s better to set the value than rely on it being set previously.\n. I\u2019m tempted to rewrite uninterpolate as:\n``` js\nfunction d3_uninterpolateNumber(a, b) {\n  var k = b - a;\n  return k ? function(x) { return (x - a) / k; } : d3_zero;\n}\nfunction d3_zero() {\n  return 0;\n}\n```\n. d3_functor causes an additional level of closure so it\u2019s better to just have one hard-coded.\n. See also d3_true.\n. Is it worth changing any other place we do numeric interpolation, such as color interpolation? We probably don\u2019t care in RGB space because everything is integers, but we might care in other color spaces. :\\\n. selection.transition guarantees that t >= 1 on the last tick (unless the transition is interrupted), and ease(t) for t >= 1 should be guaranteed to be 1 for the built-in easing functions (see d3_ease_clamp).\n. Looking at the code, I think the NaN complication outweighs the benefit of returning the constant function. Also, I don\u2019t think we really need to optimize for that case, since it should be very rare. I think the previous version is better, and I apologize for wasting your time! :grin:\njs\nfunction d3_uninterpolateNumber(a, b) {\n  b = b - (a = +a) || Infinity;\n  return function(x) { return (x - a) / b; };\n}\n. I think so, yeah. It\u2019s a few bytes shorter.\n. Merged into #2075.\n. Looks good.\n. Merged into #2075.\n. Merged into #2075.\n. Merged into #2075.\n. Merged into #2075.\n. FWIW, this appears slower to me (3.4 GHz iMac, OS X 10.9.5). On optimize-data:\nselection.data(values, key) (enter) 3.8ms/op.\nselection.data(values, key) (update) 5.7ms/op.\nOn master:\nselection.data(values, key) (enter) 3.2ms/op.\nselection.data(values, key) (update) 2.3ms/op.\nLooking at the code, I can\u2019t really tell if this optimization should be faster. :\\\n. I propose a different fix in #2065.\nselection.data(values, key) (enter) 0.57ms/op.\nselection.data(values, key) (update) 0.79ms/op.\n. Interesting. Yes, the merged optimization is faster for me as well.\nselection.data(values, key) (enter) 0.36ms/op.\nselection.data(values, key) (update) 0.60ms/op.\n. Out of curiosity, is this a bottleneck that you observed in practice? Or is this strictly a microbenchmark optimization?\n. Closing in favor of #2074.\n. I should mention that this does not handle modifying built-in object prototypes within the lifetime of a map instance. For example:\n``` js\nvar map = d3.map();\nmap.set(\"foo\", 42);\nmap.get(\"foo\"); // 42\nObject.prototype.foo = \"foo\";\n\"foo\" in {}; // true\nmap.get(\"foo\"); // undefined\nvar map = d3.map();\nmap.set(\"foo\", 42);\nmap.get(\"foo\"); // 42\n```\nIn this scenario, \"foo\" is added to the Object.prototype and thus the set of special keys.\nWhen the map is first created and the key \"foo\" is assigned the value 42, the key \"foo\" is not considered special and thus not escaped. However, after the Object.prototype is modified, the key \"foo\" is special and therefore it is escaped to \"\\0foo\" on retrieval, and thus the associated value is undefined.\nCreating a new map after Object.prototype is modified restores the correct behavior because when the key \"foo\" is set on the second map, it is considered special. So the only problem is when the set of special keys changes within the lifetime of a map instance.\nThere are JavaScript libraries that modify Object.prototype. And it\u2019s conceivable to have a long-lived d3_Map instance. (For example, d3 creates several d3_Map instances in d3_time_format, and one in d3.dispatch.) So, if you create a map before the prototype is augmented, you\u2019ll effectively lose any data associated with that key.\nI hope in practice that Object.prototype happens rarely\u2014when a library is loaded, hopefully before D3. If that\u2019s true then this built-in check will be safe.\nAnother possibility, now that Set and Map implementations are somewhat available, is that we rewrite d3_Map and d3_Set to use those when available. That\u2019s probably the best option\u2026\n. I experimented with native collections in the native-map branch. However, I didn\u2019t implement a fallback for when native maps are not available, so it\u2019s not really usable, especially because node --harmony is missing Map.forEach and Set.forEach.\nAlso Map and Set aren\u2019t drop-in replacements because the API is slightly different and because d3.map and d3.set require string keys or values, respectively. So I\u2019m not sure how we should handle the transition to native collections. It seems rather difficult to do in a backwards-compatible way without a lot of baggage.\n. Using Object.create(null) is an interesting suggestion. I just tried it. It performs very well with the merged optimization:\nselection.data(values, key) (enter) 0.16ms/op.\nselection.data(values, key) (update) 0.16ms/op.\nUnfortunately, it seems that Node and Chrome behave differently in regards to proto:\n\"proto\" in Object.create(null) // false in Chrome, Safari, Firefox\n\"proto\" in Object.create(null) // true in Node\nHowever, it would be fairly easy to detect this shortcoming and workaround it in Node.\n. It\u2019s kind of a ton of code to protect against \"proto\" in Object.create(null) being true on Node. Plus, using Object.create on initialization means that d3 will crash on IE8 on load, rather than deferring until use (in selection.transition).\n. Closing in favor of #2074.\n. I think we\u2019ll probably want to coerce to numbers when setting the domain of a quantile scale, as well.\n. Merged into #2075.\n. Merged into #2118 and staged for 3.5.\n. Merged into #2075.\n. Benchmark:\nselection.data(values, key) (enter) 0.25ms/op.\nselection.data(values, key) (update) 0.35ms/op.\nI expect a native Map or Set would be faster still, but I think we\u2019ll have to wait on those. This change further abandons IE8, but I think I\u2019m okay with that.\n. Merged into #2075.\n. Thanks for the pull request, but I think it\u2019s overly burdensome to defend against such broken code in userland. (For example, you could argue we should provide our own implementations of all built-in JavaScript functions so as to protect from libraries redefining them. Though to be fair, I did make an exception for exactly this in the past:\u00a0@45ca793083b69820c3ebb4bed3969ee385a73ae0.)\nIf we did want to protect against this, a simpler and more efficient implementation would be to add var undefined; in src/start.js.\n. Thanks for the fix.\n. Merged into #2118 and staged for 3.5.\n. \n. Merged into #2118 and staged for 3.5.\n. Sounds good.\n. Are we doing this or not? Up to you. If it saves bytes or improves performance I\u2019m okay with it.\n. Merged into #2118 and staged for 3.5.\n. Merged into #2118 and staged for 3.5.\n. Merged into #2118 and staged for 3.5.\n. Sorry it\u2019s taken me so long to look at this, and thanks for the suggested performance improvement.\nThere\u2019s a subtle issue here in that you can\u2019t just call Object.getPrototypeOf once\u2014you have to crawl up the entire prototype chain to pick up all the inherited properties that would be enumerated by for\u2026in. That still appears 30% faster, at least for this one test case (that may not be representative of real-world usage).\nBut, the bigger issue for me is that the code is certainly more complicated. I can\u2019t see this code being a performance bottleneck, so I\u2019d favor the simpler code.\n. This fix doesn\u2019t handle the case where only one of s or t has a zero weight (it treats the zero weight as one), but that\u2019s easy enough to fix. :grin:\n. Merged into #2591 for 3.5.7.\n. Looks good. Moving all 3.4.x changes to 3.5 due to imminent minor release.\n. Merged into #2118 and staged for 3.5.\n. I like this idea. It\u2019d be nice to extend it to include default styles for the ticks and domain path:\n``` css\n.axis line {\n  stroke: #000;\n}\n.axis path {\n  fill: none;\n  stroke: #000;\n}\n```\n(I\u2019m not 100% certain crispEdges should be included by default, yet.)\nIt pains me when I see someone forget to style the axis:\n\nHowever, these changes are not backwards-compatible, since it changes the default appearance. So this will be part of D3 4.0; see d3/d3-axis#7.\n. Fixed for D3 4.0.\n. Looks fine.\n. Merged into #2118 and staged for 3.5.\n. Merged into #2118 and staged for 3.5.\n. I recently merged a slightly different ja-JP locale in 28acd11a242245b8bd32cfcdaaa8d7d382c6272f. If that\u2019s not correct, please let me know and I will make the necessary edits. Thank you!\n. Before:\n\nAfter:\n\n. Would you mind making this edit directly on the wiki? It is publicly-editable. (I had to lock it temporarily due to spam, but it\u2019s public once again.)\n. Merged into #2591 for 3.5.7.\n. Fixed in 3.5.\n. Hi there. Happy to do what I can to make d3 easier to use for Meteor folks. I\u2019ve created an mbostock account.\nThat said, please allow me to voice my objection to supporting yet another packaging system. It pains me to add to the list of supported packaging systems:\n- NPM (Node.js)\n- Bower\n- Browserify\n- Component\n- Jam\n- Composer / Packagist (PHP)\n- SPM\n- JSPM\n- NuGet (.Net)\n- AMD (e.g., RequireJS).\nAs a library developer, I\u2019d rather just push a new release (vx.y.z tag) to GitHub, and have all my users receive a notification to update their packages. Or packaging systems could periodically poll GitHub for new releases. Or, more simply, packaging systems could simply maintain aliases to GitHub URLs that don\u2019t require updating on every release.\nI especially object to maintaining and running custom shell scripts (meteor/publish.sh) in order to publish. And shell scripts that include curl \u2026\u00a0| sh are a nonstarter; there\u2019s no way I\u2019m running that every time I need to publish a new release. (That\u2019s an unnecessary security risk given it\u2019s only there if I don\u2019t already have meteor installed.) If I must explicitly publish to Meteor, it should be no more complex than running npm publish to publish to NPM. Is there no meteor publish command, or equivalent?\n. (Looking at your script, it seems like I just need to run meteor publish --create once, followed by meteor publish on subsequent updates\u2026 so I\u2019d much rather you confirm the sequence of commands I should run than to bake that into a shell script.)\n. Also, what happens to the meteor/d3 package if d3js/d3 becomes the official one? Can we make meteor add d3 an alias to install the latest official release? Or does it simply stop working when Meteor deprecates the D3 core package?\n. I understand why you might want a meteor/package.js as a Meteor-equivalent to package.json, bower.json, etc. It\u2019s regrettable but fairly painless, especially if someone like you contributes one!\n(That said, it seems like you should still be able to use the standard package.json in the simplest case, or follow the jspm / browserify / jam / spm route and decorate the package.json with a few Meteor-specific fields if necessary. It\u2019s surprising to me that Meteor\u2019s package description is executable code rather than declarative.)\nYet I still don\u2019t like that I need to run meteor publish to notify Meteor of a new release. The explanations you linked describe benefits that could also be achieved without burdening me \u2014 by using a GitHub API to receive a notification of a new release, or by polling a URL. (Note: I have the same objection to running npm publish, which I also view as an unnecessary evil!)\nI understand that you often want built files to be available only on the packaging system and not in the git repository, but at least for me personally, I have found it easier for users to include built JavaScript in the repository. So, there\u2019s no reason the repository can\u2019t serve as the canonical source for these files.  And even if I didn\u2019t want to include built files in my git repository, I\u2019d still rather publish those built files to GitHub as downloads attached to the release (e.g., v3.4.13\u2019s d3.zip).\nMy dream is that whatever new package system comes along can slurp up the official releases I publish on the internet, and redistribute them in their desired form without me needing to do anything beyond providing a declarative description of the code (i.e., the package.json or equivalent) and a URL.\n. It\u2019s simple enough that I would remove the script entirely and just put it in the Makefile. Maybe like this:\nmeteor:\n    cp meteor/package.js .\n    meteor publish\n    rm -rf -- .build.d3js:d3 versions.json package.js\nI\u2019d also add the meteor target to the .PHONY prerequisites.\n. Also, what\u2019s the reason for the meteor/export.js? Does the Meteor package system require us to export a global?\n. I think we can remove the spacejam part. What\u2019s that doing exactly? (Also, if you were to use spacejam here, you\u2019d use node_modules/.bin/spacejam to refer to the locally-installed copy referenced by the package.json dependency. But I think it\u2019s better to eliminate this part entirely.)\n. Sorry, but I haven\u2019t had any time to work on this.\n. Hi @splendido. Thanks for the update. The pull request looks good, but I\u2019m not comfortable giving autopublish.meteor.com permissions to \u201cread and write all public repo data\u201d. If that means I just run meteor publish instead, I guess that\u2019s okay.\n. Yeah, I\u2019m afraid I would not be comfortable giving an untrusted party full write permissions to all my public repositories, even temporarily. :tinhat:\n. You want the Release event, no?\n. OK, merged. Thank you!\n. Question: where does Meteor pull the generated d3.js file from? I\u2019m planning on removing this file from the git repository in the future (#2226). It\u2019ll only be available in the d3.zip attached to the release or the published NPM package.\n. > But if it will be still generated with the build process we might trigger the build soon after the repo is cloned on the build machine and before running meteor publish.\nI don\u2019t think you want to run my build process on your machine. That would be insecure for you. And bad for me, since it does not guarantee that the published file you build is the same as my official release.\nSo, I guess we\u2019re back to me running meteor publish. That\u2019s fine, I guess. Looks like I won\u2019t be able to delete the generated files until Bower supports its own registry, anyway.\n. So, now that this was merged, can we make meteor add d3 an alias for meteor add d3js:d3? The old built-in is deprecated and out-of-date, but still referred to documentation. It\u2019d be nice if it now pointed to the official release.\n. > ...and there's no way to get an alias for the new name.\nSure there is! It\u2019s just code, right? :grin: I mean, it\u2019s up to the Meteor team as to whether it\u2019s better to have meteor add d3\n(A) not work at all,\n(B) to install an old release, or\n(C) to install the latest release.\nI\u2019m merely suggesting that installing the latest release (C) might be the best option.\nIf you want to make it not work (A), that sounds fine, too. But silently installing an old release (B) seems like the worst of the three. There\u2019s not even any information on the meteor/d3 package about it being deprecated and out-of-date.\n. I setup a publish target in the Makefile, so I\u2019m planning on just doing manual publishes (at the same time I publish to NPM). I\u2019ll remove the Webhook.\n. I am no longer supporting any publishing systems beyond npm and GitHub, but anyone else is welcome to make D3 available on other systems.\n. Superseded by bdbeec9e58735a9164adb52d59f952237c785dc0 in 3.5.\n. This is fixed already in d3-timer (see timer.js) for 4.0. It\u2019s probably not worth fixing for 3.x. Even though it\u2019s a strict violation of the API, setTimeout(undefined) is a no-op in every supported environment, as far as I am aware.\nThen again, it\u2019s a trivial change, so it probably wouldn\u2019t hurt to fix, either.\n. Filed d3/d3-time-format#8.\n. Thanks!\n. Merged the earlier #2152. Thank you!\n. Merged into #2227 for 3.5.4.\n. Thanks for the context. I had forgotten\u2026\u00a0Basically this is just a revert of 31ea7dc0f1ff553c446d91591826ec2731fadff1.\nI am happy putting this in the icebox. I want to think about some larger things for 4.0 besides.\n. Thank you! Merged into #2227 for 3.5.4.\n. Related d3/d3-arrays#10. Will consider something like this for 4.0.\n. Thanks. This is fixed in #2227 for 3.5.4.\n. Great, thank you!\n. A different fix is merged into #2591.\n. Not that it matters, but does IE8 log __proto__ with Object.create(null) rather than Object.create({})?\nFor 4.0, I am currently planning on ditching the Object.create(null) for d3.map, and instead go back to the simpler prefixed properties; see src/map.js in d3-arrays. In addition to the __proto__ issue (which also existed on Node 0.10), non-prefixed keys that happened to look like numbers sometimes caused maps to behave like arrays, and then triggered large memory allocations. So forcing the keys to always look like strings rather than numbers seems like a safe choice. And the code is simpler.\nSo with apologies to Shawn (who I have neglected for months by not replying to this pull request), but I\u2019m trying to minimize the amount of changes to 3.x and focus most of my effort getting 4.0 released.\n. :+1: \n. Thank you. Merged into #2227 for 3.5.4.\n. Interesting. Can you elaborate a bit on why you need this functionality?\n. Yes. But why do you need multiple drag behaviors on the same element?\n. Thanks for this suggestion. However, I\u2019ve subsequently re-implemented the pack layout for D3 4.0 in d3-hierarchy. There were some bugs due to a misunderstanding (and / or poor wording) of the Wang et al. paper\u2014which is also paywalled. You can find the new circle-packing code here:\nhttps://github.com/d3/d3-hierarchy/blob/master/src/pack/siblings.js\nThere are a few comments, but I tend to be fairly frugal with comments, favoring essays, examples, and documentation over in-code comments. I\u2019m planning on writing up a better visual explanation of the algorithm, but I need to work on getting D3 4.0 released first. Thanks!\n. Thank you. Merged into #2227 for 3.5.4.\n. Merged into #2227 for 3.5.4.\n. Coincidentally I made a similar change in #2225. I think it\u2019s actually confusing that d3.selection() returns the same instance every time, especially given that d3.transition() returns a new instance for each invocation. So I changed it to always call d3.select(document.documentElement).\n. Fixed in #2227 for 3.5.4.\n. It wasn\u2019t explicitly specified that this was supported, and given the difficulties users were seeing installing D3 on Windows (and io.js), I wanted to make the change now rather than wait until the next major release.\nYou can fix your code as follows:\n``` js\nvar d3 = require(\"d3\"),\n    jsdom = require(\"jsdom\");\nvar document = jsdom.jsdom(),\n    svg = d3.select(document.body).append(\"svg\");\n```\nSee the JSDOM README for additional examples. You are also now free to use a different DOM implementation.\n. Thank you!\n. Merged into #2591.\n. @awelch83 I\u2019ve merged hundreds of d3-related pull requests.\n. I made the corresponding to http://d3js.org as well.\n. :+1: \n. I took a stab at this for 4.0 in d3/d3-shape#42. Before:\n\nAfter:\n\nThere\u2019s still some work to-do, and I need to think through whether this is the right API. Also, there\u2019s the issue that applying constant padding to arcs disproportionately penalizes small arcs, so it makes me wonder if the partition layout should support padding so as to preserve relative areas. (See d3/d3-hierarchy#19 for a description of a similar problem with the treemap layout.)\n. Merging into d3/d3-shape#42.\n. Looks like it chokes in d3_geom_voronoiHalfEdge, but yeah. Needs further investigation.\n. Thanks for the contribution, but I prefer managing the release descriptions by hand.\n. Do we need a /i flag on the rgb/hsl regular expression, too?\n. Thank you! Merged as 3b22a96dc86a542e6a42144851d0ec4b8da645b4.\n. Merged into #2591.\n. Interesting. That sounds correct. I should think a bit about whether this is an alternative solution but your approach seems reasonable.\n. This is related to d3/d3-timer#5 (and d3/d3-transition#9, #2189), in that if we greedily canceled transitions\u2014rather than waiting for them to self-terminate on start\u2014then the count check would be safe.\n. Fixed in #2600, merged into #2591 for 3.5.7.\n. Moving to d3/d3-hierarchy#9. I feel like padding (d3/d3-hierarchy#7) is a better solution than internal node value, given the issues with trying to show internal node value meaningfully.\n. It\u2019s bold because it\u2019s the first use of the alternative, shorter form of \u201cD3.js\u201d.\n. Replacing backslash with \u20a9 (presuming intent) and merging. Thank you!\n. I don\u2019t plan on undertaking this change for 3.x, but I\u2019ve filed d3/d3-shape#13 for 4.0.\n. Sorry, but this feels like unnecessary baggage and I do not think it is appropriate to put it in the D3 repository. If people are using web components with D3, they should create their own import.html as needed.\n. Relying on ordering and side effects in the tick format function seems fragile. The behavior isn\u2019t explicitly documented, but I wouldn\u2019t rely on the tick format function having the text element as the this context: it\u2019s better if the format function relies only on the passed-in value and returns a string.\nIf you want to modify the styling of the generated ticks, the recommended pattern is to post-process the axis after it\u2019s rendered: select the ticks, and then modify them. See the axis styling example.\n. Also, sorry it took me so long to reply, and thank you for submitting this pull request (even if it wasn\u2019t accepted).\n. Fixes #2556.\n. All functions are now consistent in D3 4.0, for both selections and transitions. I\u2019ve standardized on the current datum d, the index i, and the group nodes array, making the D3 signature similar to array methods such as array.forEach.\n. One reason I didn\u2019t do this is fear of performance degradation. I believe try-catch can disable certain optimizations by popular JavaScript engines. And this is the most performance-sensitive part of D3.\nNow, I do use try-finally inside event dispatching (see src/event/event.js and src/selection/on.js), so I\u2019m not sure if those optimizations are already precluded, or if it\u2019s better to put the try-catch higher up the stack to allow the inner loop to be optimized. This is all kind of black magic because most of what matters is touching the DOM, unless you have lots of timers.\nI haven\u2019t had time to think this through but I also wonder whether it would be possible for the exception to be thrown \u201cnaturally\u201d, which could prevent some timers from being called back during that iteration, and to change the code so that any exception would not affect subsequent timer callbacks\u2014those would resume normally on the next animation frame. That way, an exception could cause localized damage, but not permanently break d3.timer or selection.transition.\n. I filed d3/d3-timer#4 to track this for 4.0, but I\u2019m guessing we probably won\u2019t make this proposed change to 3.x. I\u2019ll leave open #2415 for now.\n. I appreciate that some may disagree, but it is our local style convention to omit the parens with no-argument constructors.\n. Merged into #2591 for 3.5.7.\n. I feel the existing row accessor function is sufficient for renaming columns. For example, to lower-case column names:\njs\nvar rows = d3.csv.parse(csv, function(d) {\n  return {\n    a: d.A,\n    b: d.B,\n    c: d.C\n  };\n});\nIt\u2019s easiest if you know the column names, but you could, I suppose, write the code generically (at the cost of performance and complexity). Or you could replicate the approach taken by dsv.parse and wrap dsv.parseRows.\nI agree that having a dedicated function for remapping columns is simpler, but I think the existing API is sufficient and we should endeavor to keep the API small.\n. Thanks for the pull request. I think a plugin does sound more appropriate given than D3 is primarily focused on 2D visualization.\n. Somewhat humorously, this automatic find-and-replace in this pull request breaks SI-prefix formatting (the s type in d3.format), because \u00b5 is the SI prefix for micro, 10\u207b\u2076. At any rate, there\u2019s no way to merge this pull request now that the code has been broken into separate modules for D3 4.0. I do plan on replacing the Greek variable names with ASCII, however; see d3/d3-geo#8.\n. Duplicate of #2436.\n. Related d3/d3-hierarchy#7.\nThere\u2019s a proposed solution to that in d3/d3-hierarchy#8 now, so I want to compare these solutions.\n. This has been implemented in 4.0.\n. Fixed in d3-time-format for 4.0.\n. Closing in favor of the existing selection.classed(name, true) and selection.classed(name, false) for adding and removing.\n. This is already supported in the new d3-scale module, which will be the basis of the 4.0 API; see time.ticks. For example:\njs\ns.ticks(\"milliseconds\", 100);\nI\u2019ve also added a millisecond time interval to d3-time for completeness.\n. Closing since this is implemented in d3-time.\n. This will be implemented in the d3/d3-selection-multi module for D3 4.0, so you should probably take a look over there.\n. Thank you for this pull request. The line and area interpolators (now called \u201ccurves\u201d) are being completely re-written for 4.0; see d3-shape. @jviide has contributed a lovely new cubic monotone implementation based on A Simple Method for Monotonic Interpolation in One Dimension by M. Steffen.\n. Thanks. Glad to hear this will be fixed in 4.0. Sorry for the confusion; it should be temporary.\n. I think you want \"\\xa0\" here instead of \"\\0xa0\"; the latter is the character NULL followed by \u201cxa0\u201d. I can merge and then fix.\n. Thanks for the pull request. I think it\u2019s probably not worth doing this. It might be a tiny improvement here, but it\u2019d be a fair amount of work to change all of the code to adopt this pattern. And moreover, this pattern doesn\u2019t allow you to have custom code for side-effects or validation when a property is set, so you\u2019d end up with some properties than can use the generic getter-setter and others written the \u201clong\u201d way because they need to do something special.\n. Moved to d3/d3-hierarchy#7 for 4.0.\n. Thanks for the pull request. SMASH is going away in 4.0 with the adoption of Rollup, so it\u2019s probably not worth further effort to fix this in 3.x; Rollup uses ES6 imports and will be much more robust.\n. Fixes #1439. Related #2403.\n. This fix is trivial, which I like, so this seems reasonable even though I\u2019m focused on D3 4.0. I\u2019ll try to get it out this week.\n. Released in 3.5.15. Thank you!\n. It\u2019d probably be better to fix this in d3_event_dragSuppress rather than in the drag behavior, since it\u2019s only there where the code depends on the event target having a style property. I\u2019ll try to do that for 4.0.\n. The only reason I closed the issue is that this pull request is sufficient to track the request.\nConcerns with this change:\n- A mousewheel event could initiate a change from an allowed scale extent to a disallowed scale extent, and in that case, we want to clamp the new scale extent to the minimum or maximum allowed value and still prevent default on the extent. (Your implementation appears to only check the new value, and not whether it is different from the current value.) For example, if the scale is clamped in [1, 10], and a mousewheel would change the scale from 8 to 12, then we want to change it to 10 and prevent default.\n- I\u2019m not totally sure the logic is right. For example, this still sets the mousewheelTimer even when the mousewheel event is going to be ignored. The zoom behavior event handling logic is complicated, so it\u2019ll require some thought.\n- I haven\u2019t decided whether the zoom behavior should always behave this way, or whether it should be something that the user can enable. Probably it would be reasonable to just make it always behave this way, and consider it a bug fix.\n. This has been implemented in d3-zoom for D3 4.0.\n. Looks like #2420 is probably a better fix.\n. This adds the --comments argument after the -o argument, causing an error. But more importantly, the --comments argument isn\u2019t passed to UglifyJS because of our custom wrapper script. The correct fix is probably something like this in bin/uglify:\ndiff\n-    output = uglify.OutputStream({ascii_only: true}),\n+    output = uglify.OutputStream({ascii_only: true, comments: true}),\nThat didn\u2019t seem to do anything, though, and I\u2019m not going to investigate it any further at the moment. Because\u2026\nD3 4.0 has a new build process using Rollup. This preserves comments and formatting (for the most part) in the generated file.\n. Adding map.clear and set.clear methods seems reasonable, but I think it\u2019s a losing battle to try to make these closer to ES6. For example: D3\u2019s map.set returns the set value, not the map instance; D3\u2019s map.forEach passes arguments {key, value, map} rather than {value, key, map}. Also, map keys and set values are coerced to strings.\nI want these classes to go away in the future, when it\u2019s reasonable for D3 to only support ES6 runtimes. I don\u2019t think we\u2019re ready for that yet, and because of the nature of the ES6 Map and Set APIs, polyfilling is not a great transitional solution.\n. If we do modify the map & set API, I\u2019d prefer to do it in d3-arrays for 4.0 rather than for 3.x. I\u2019ve opened an issue d3/d3-arrays#9 to track that request.\n. Why not release this as a D3 plugin for 4.0?\n. Thanks, @Klortho. Let me know if I can answer any questions related to creating a new D3 plugin / module. My Let\u2019s Make a (D3) Plugin guide should still be up-to-date, if it helps.\n. Sounds reasonable, though I expect you should still be able to design an API that is compatible with the hierarchy nodes returned by d3.hierarchy and d3.stratify, and otherwise reuse the relevant parts of d3-hierarchy while suiting it to your needs.\n. :+1: \n. Related #2377 #2189.\n. Related #2468, in that the new internal d3_timer API should provide a mechanism for the force layout to cancel its timer and avoid starting it twice.\n. I worry that a better fix would be to make mousewheel handling more reliable across browsers.\nIn the past we went to elaborate measures to ensure consistent behavior by redispatching the mousewheel event to an invisible scroll area, and then measuring how much the scroll offset changed. (Scrolling is much more consistent than mousewheel events.) We later removed that hack because it was, as you can imagine, quite elaborate just to receive a correct delta amount and it appeared that most modern browsers were now better behaved. See #1048.\nBut judging from the issues I\u2019m seeing, maybe mousewheel is broken again, at least on some platforms?\nRelated #2605 #2589 #2022.\nAside from that, a quick observation on this implementation: it breaks the intended behavior of dblclick snapping to round zoom levels. This is less important these days with the increased prevalence of vector map tiles but it\u2019s a big deal if you\u2019re using the zoom behavior with raster tiles (such as bl.ocks.org/4132797).\nThe idea is that if you use mousewheel to go to a fractional zoom (by which I mean the scale is an integer power of the zoom factor, so a zoom of 1.5 is a scale of 2^1.5 = 2.8284\u2026) then a dblclick would take you to the smallest greater round zoom (2) and a shift-dblclick takes you to the largest lesser round zoom (1). If you are already on a round zoom level, then it just increments or decrements the zoom level as appropriate.\n. We can\u2019t make this change in 3.x, and d3-arrays would be to make this change for 4.0+, so closing this pull request. Will respond over in d3/d3-arrays#12.\n. Merged into #2638 for 3.5.9.\n. Works for me? \u00af_(\u30c4)_/\u00af\nhttp://bl.ocks.org/mbostock/a84aeb78fea81e1ad806\n. Still works for me with zoom? \u00af_(\u30c4)_/\u00af\nhttp://bl.ocks.org/mbostock/35964711079355050ff1\n. That sounds like the expected behavior for that example; I\u2019ve just renamed it Zoom vs. Click to make the intent clearer. It is not intended to allow dragging of individual circles; it is intended to demonstrate how to allow clicks on a zoomable element.\nHere\u2019s a zooming and dragging example in D3 3.x.\nHere\u2019s a zooming and dragging example in D3 4.0.\n. It only flashes if you click on the background. Clicking on any circle initiates a drag gesture. Furthermore, if you move the mouse at all between mousedown and mouseup, it won\u2019t count as a click because it is interpreted as a (tiny) zoom gesture. If you have a particularly sensitive mouse, it\u2019s possible that you\u2019re seeing a tiny bit of mouse movement just in a normal mousedown and mouseup. This is one reason not to try to support both clicking and zooming: it\u2019s inherently ambiguous.\nRight-clicking is probably an unrelated issue. The zoom behavior doesn\u2019t ignore right clicks by default in 3.x; it does in 4.0.\n. Did you consider using a quantize scale? Quantize scales don\u2019t (yet) support log and power transforms, but they achieve a similar effect. The main difference is that they will only output the discrete values in your range (e.g., the six colorbrewer blues), rather than interpolating continuously in-between.\n. Closing in favor of d3/d3-scale#45, as any future API changes will happen in d3-scale.\n. My guess is that the new continuous sequential color scales derived from ColorBrewer in d3-scale-chromatic will be more appropriate for this use case, but there\u2019s still the issue that you can\u2019t easily apply a log or pow transform to a sequential scale (d3/d3-scale#62).\n. Are you sure there\u2019s a bug here? I don\u2019t see it from just looking at your change. There are four cases to consider with this logic:\n1. The simulation is active (alpha > 0) and the new alpha is positive (x > 0). The timer is already running, so just set alpha.\n2. The simulation is active (alpha > 0) and the new alpha is not positive (x <= 0). The timer is running and we want to stop the simulation, so stop the timer.\n3. The simulation is inactive (alpha = 0) and the new alpha is positive (x > 0). The timer is not running and we want to start the simulation, so start the timer.\n4. The simulation is inactive (alpha = 0) and the new alpha is not positive (x <= 0). The timer is not running, so do nothing.\nTo illustrate in the code:\njs\nif (alpha) { // Cases 1 & 2.\n  if (x > 0) { // Case 1. Set alpha.\n    alpha = x;\n  } else { // Case 2. Stop the timer.\n    timer.c = null, timer.t = NaN, timer = null;\n    event.start({type: \"end\", alpha: alpha = 0});\n  }\n} else if (x > 0) { // Case 3. Start the timer.\n  event.start({type: \"start\", alpha: alpha = x});\n  timer = d3_timer(force.tick);\n} else { // Case 4. Do nothing.\n}\nAlso, for your fix, note that setting the timer to null doesn\u2019t have the intended effect: it\u2019s still in the timer queue, so it will still receive callbacks. It just means you\u2019ve lost the reference to the timer. The way to stop the timer is to set its callback (timer.c) to null. (In 4.0, there will be a public API for this, timer.stop; for now, the force layout uses a private API.)\nThat said, there is a bug in that we\u2019re dispatching a start event when the force layout ends manually (albeit with the event type of \u201cend\u201d), when we should be dispatching an end event. I\u2019ll commit this fix:\ndiff\n--- a/src/layout/force.js\n+++ b/src/layout/force.js\n@@ -202,7 +202,7 @@ d3.layout.force = function() {\n         alpha = x;\n       } else { // or we might stop\n         timer.c = null, timer.t = NaN, timer = null;\n-        event.start({type: \"end\", alpha: alpha = 0});\n+        event.end({type: \"end\", alpha: alpha = 0});\n       }\n     } else if (x > 0) { // otherwise, fire it up!\n       event.start({type: \"start\", alpha: alpha = x});\n. Eh, I don\u2019t see much harm in leaving it in. In D3 4.0, the src folder will contain ES6 modules (rather than D3 3.x\u2019s ES6-like SMASH files). There will still be a prebuilt UMD module for CommonJS and other non-ES6 environments, but it\u2019s my plan to include the ES6 source for future compatibility and because many people use npm as a simple package manager outside of a strict CommonJS environment.\n. This looks like a duplicate of #2650 (which was retracted by the author\u2026\u00a0I haven\u2019t had time to investigate why). Appears to be a fix for #2646, also.\n. I\u2019ve pushed a slightly simpler fix in d3/d3-hierarchy@68055b9d22b2b1f002fd2cc1995238cbb778f644 for 4.0. In the case of a single-branch tree, the left- and right-most node is always the root, and I think it\u2019s best to avoid invoking the separation function when a and b are the same node (the root); in that case, we can simply center the tree within the layout area.\nI\u2019m probably not going to back-port the fix to 3.x. A simple workaround is to not return Infinity from the separation function:\njs\nfunction separation(a, b) {\n  return (a.parent === b.parent ? 1 : 2) / Math.max(1, a.depth);\n}\n. The fix looks good.\n(If your values weren\u2019t numbers, I would say to use d3.format when displaying the sum, but this fix seems totally reasonable.)\n. The recommended way of implementing this feature is post-selection, as in the custom axis example. After calling the axis, select the first tick (or whatever else you want to customize) and then apply the desired changes. For example:\njs\nsvg.append(\"g\")\n    .call(axis)\n  .select(\".tick\")\n    .text(\"First!\");\nIf you just want to modify the tick text, another way to implement this feature is with a custom tick format, and then use the tick value (d) or the index (i). For example:\njs\naxis.tickFormat(function(d, i) { return i ? d.toFixed(2) : \"First!\"; });\n. Thanks for the suggestion. I suspect that this is not a noticeable performance improvement, but it\u2019s probably worth adopting this type of change D3-wide regardless. I\u2019m not sure I\u2019m willing to find and fix all of these places in D3 3.x, but I\u2019d be willing to survey the new d3 modules for 4.0 and adopt this optimization.\n. Yep, anything that touches the DOM is typically expensive; it should be much more expensive than re-assigning to an argument.\n. The array subclassing is going away in 4.0; it\u2019s not a backwards-compatible change so it has to wait until the next major release. See the d3-selection repo.\nI don\u2019t plan on merging this into 3.x, but I was going to keep this issue around as a reminder to go through the new 4.0 repositories and look for similar problems.\n. The good news is that D3 4.0 is written in ES2015 modules and strict mode, thus this is no longer an optimization killer. \n. See https://github.com/petkaantonov/bluebird/wiki/Optimization-killers#3-managing-arguments\n. Also, d3-selection generally avoids re-assigning to arguments. See the new selection.attr implementation, for example.\n. I have added these to d3-format and d3-time-format and they will be published to npmcdn.com on the next patch releases.\n. Thank you for the contribution, but this would be better as an example (as you have already published on bl.ocks.org) rather than added to the git repository. Cheers!\n. Examples are added to the gallery by anyone editing the wiki: it\u2019s publicly editable. You don\u2019t need to submit examples as pull requests.\nThat said, I\u2019m not convinced this is an effective design for visualization. The large rounded corners subtract more from the larger arcs than the smaller arcs. I don\u2019t see why this is better than a standard pie or donut chart.\n. Duplicate of #2391.\n. Fascinating. I wonder if this has been broken since #629 in May 2012.\n. Published 3.5.13.\n. I\u2019ll probably be rewriting this code for D3 4.0, so it doesn\u2019t feel worth it to me to apply this change, sorry. Also, those comments are sentence fragments rather than sentences; complete sentences should be capitalized and have punctuation, but sentence fragments or single words are often done lowercase and without punctuation.\n. See #2665, #2645, #1921 and #1693. To summarize: this was done because many D3 plugins assumed the existence of a global d3, so when AMD support was added and removed the global, those plugins broke.\nThe d3 global will go away in 4.0 when everyone switches to the D3 module pattern. This not a backwards-compatible change and thus requires being tied to the next major version.\n. See d3-selection-multi for 4.0, in particular selection.styles. It\u2019s still a work-in-progress and I haven\u2019t written the documentation yet, but if you\u2019d like help, please send a pull request over there.\nThe new API is almost exactly what you describe, though it has a distinct name to disambiguate from the single-value case. For example:\njs\nselection.styles({\"fill\": \"red\", \"stroke\": \"blue\"});\nselection.styles(function() { return {\"fill\": \"red\", \"stroke\": \"blue\"}; });\nI\u2019m probably not going to include d3-selection-multi in the default build of 4.0, for the sake of parsimony and keeping things small, but it should be available if people want to add it in.\n. I appreciate the suggestion, but I think this longer material is better suited to the publicly-editable wiki rather than the README. Thanks.\n. Thanks for the suggestion; however, I prefer the current text.\n. This code has already been rewritten for D3 4.0 (see d3-color) so I will not be accepting style-only changes.\n. Apologies for the terse response; I was distracted by my three-year-old. I appreciate your offer to make the code clearer and I\u2019m sorry I\u2019m not able to accept your request.\nCode clarity is a matter of taste, and I don\u2019t feel that these changes are universal improvements. I prefer shorter variable names when the meaning is already apparent from context, such as the R, G and B channels of the RGB color space.\nThat said, I know that sometimes I try too hard to make the code concise and that can make it harder to follow, and there could be some improvements I would accept. I\u2019ve implemented a few changes in d3-color for 4.0 to make it more readable already, such as separating color space conversion, as in hslConvert(color), from the color specification, as in hsl(h, s, l, a).\nIf there are other changes you think might improve readability, please let me know. Although it may be best to smart small and discuss it early. Thank you.\n. This code has been completely rewritten for D3 4.0; see d3-transition. I thank you for the request, but I\u2019m not willing to accept such small changes for 3.x.\nIn 4.0, all the code is strict mode, which eliminates the optimization killer of reassigning to arguments in functions that also reference arguments.length. Also, the multi-value map methods have been extracted into separate functions to reduce ambiguity; see d3-selection-multi. I haven\u2019t written a d3-transition-multi yet, though.\n. The new d3-drag behavior for 4.0 now handles the touchcancel event.\n. This looks fixed in 4.0.\nhttps://tonicdev.com/56c79a2c9b27fc0c00ea757a/5787e92e6ebb1c140083a7d9\n. Why is this metadata needed? https://github.com/mbostock/d3/pull/1707#issuecomment-33182865\n. I\u2019m not planning on adding major new features to D3 3.x now that D3 4.0 is well underway. If you\u2019d like to submit this for D3 4.0, please re-file this pull request over in the d3-voronoi repository. Thank you.\n. This code has been completely rewritten for D3 4.0 in d3-selection. The multi-value map methods have been extracted into a separate repository, d3-selection-multi, which will be an optional plugin. The new selection.attrs (the new multi-value map method) supports taking a function.\n(Also, a change like this have a huge ripple effect, since there are many similar methods (such as selection.style and transition.attr) that should be kept consistent.)\n. The math here is extremely nuanced and reviewing this change, albeit a tiny one, is deceptively difficult. I\u2019d love @jasondavies input here, but I haven\u2019t heard from him recently. I\u2019d like to review this change but I have a lot of work already on my plate trying to get D3 4.0 released ASAP, so I\u2019m not sure when I\u2019ll be able to dive into it.\n. Can you share the data that led to the winding-order problem? That would help me test this change.\nI just fixed a related bug #2024 which turned out to be in topojson.merge: it was selecting the wrong exterior arc after merging the polygons. That arc happened to be degenerate, with the wrong winding order. I\u2019ve fixed topojson in 1.6.26 and I\u2019ve pushed new data files to bl.ock 4090846 which is used by many of my D3 examples.\n. Can you also post how you made municipios.json?\n. Strangely, I\u2019m not able to reproduce the bounding box or rendering problem with the data you provided. It seems to work fine?\n\nThe bounding box returned by d3.geo.bounds is:\njson\n[\n  [-18.161305014722235, 27.637839000751285],\n  [4.3277847236038625, 43.79237956913792]\n]\nThis seems reasonable. It looks like when rendered it\u2019s not exactly capturing all of the Canary Islands, and it extends a bit too far to the North, so I suppose there could be a small bug in d3.geo.bounds. But it looks approximately correct.\n. Okay, I think I\u2019ve figured out the discrepancy here: when reproducing your example, I removed the call to topojson.presimplify, so it seems like that\u2019s still introducing artifacts.\n. Well, more precisely, it isn\u2019t that topojson.presimplify is introducing artifacts, it\u2019s that this enables dynamic simplification in the client using your simplify transform (which is presumably based on my dynamic simplification example):\njs\nvar simplify = d3.geo.transform({\n  point: function(x, y, z) {\n    if (!z || z >= settings.area) {\n      this.stream.point(x, y);\n    }\n  }\n});\nSo I assume what\u2019s happening is that the dynamic simplification is introducing degenerate polygons, some of which are interpreted having the wrong winding order.\n. The other thing is that dynamic simplification is really designed to operate on projected (planar) geometry, not spherical geometry. The idea is that you project the non-simplified geometry down to the plane, and then filter the planar geometry to the desired simplification. Your code does it in the opposite order: it filters the spherical geometry and then projects down to the plane. My guess is that\u2019s more likely to introduce degenerate polygons like this (and it\u2019s also a lot more expensive).\n. So yeah, this is definitely the same as #2025. This is an example of a dynamically simplified polygon I extracted from your dataset:\nvar feature = {\n  type: \"Polygon\",\n  coordinates: [[\n    [-13.487800541155952, 29.40322484792305],\n    [-13.487125861717008, 29.40322484792305],\n    [-13.486900968570694, 29.40322484792305],\n    [-13.487800541155952, 29.40322484792305]\n  ]]\n};\nThe latitudes are identical, so this has obviously collapsed to a straight line. (Well, this is spherical coordinates, so it\u2019s more appropriate to say great arc or geodesic.)\n. Okay, I\u2019ve tested your change and it looks good! Will release shortly.\n. I recommend loading different pre-projected data if you need it. Projection\nis especially slow on mobile devices\u2014I can\u2019t imagine a 12MB unprotected\ndataset displaying, although maybe the latest devices are fast enough these\ndays.\nAnother consideration is that presimplify assumes planar geometry by\ndefault: it uses planar triangles for Visvalingam simplification. If you\ngive it spherical geometry the math is wrong. You need to pass the\nspherical triangle area function as the second argument rather than using\nthe default planar area. (This happens automatically on the command line.)\nThe difference may not be huge depending on the size of your dataset\nrelative to the size of the Earth though, but it just exacerbates the\nproblem of simplifying before projecting.\n. I\u2019m pretty sure you can use custom projections from the command-line, but\nyou need to require them (and npm install them) first. The projection\ndefinition is just JavaScript that gets evaluated and returns the\nprojection object, so anything that can be run in Node should be available\nfor you to use. You can even define the projection definition in a separate\nJavaScript file and require that if escaping it through the command-line is\na pain.\nThat said this needs better documentation and the design of the\ncommand-line tools needs work (specifically decoupling into smaller UNIX-y\ntools). It\u2019s on my long list of things to do after I finish D3 4.0.\n. These have been added to d3-format and d3-time-format.\n. Two things.\nOne is a benchmark demonstrating the degree of performance improvement. I normally suggest JSPerf but that appears to be down due to spam. So something that runs in the browser would be sufficient.\nTwo is that D3 3.x is basically frozen at this point as I am working on releasing D3 4.0 in the next few months. So this pull request should really be re-targeted at the d3-time-format repository.\n. I wrote a benchmark for this over in d3-time-format\u2019s match-not-exec branch. However, I don\u2019t see any impact on performance. If you still see a performance improvement using string.match instead of regex.exec, please let me know how to reproduce that gain and I will consider merging the match-not-exec branch (or implementing other optimizations!). Thanks.\n. D3 3.x is basically frozen at this point as I am focused on releasing D3 4.0 in the next few months. Also, D3 is not a compatibility layer, and I am increasingly inclined to remove patches like this and focus my efforts on modern browsers. So a fix like this is probably best implemented as a shim, either for D3 or for IE9 more generally.\n. The only case where this is undefined is if you enable strict mode. Are you building your own d3.js file or concatenating multiple files together? At any rate, D3 3.x is basically frozen as I am working on releasing D3 4.0 in the next few months. D3 4.0 is implemented using ES2015 modules and uses Rollup to produce a UMD bundle.\n. Thanks. I\u2019ll port this to d3-time-format for 4.0.\n. D3 3.x is basically frozen as I work on D3 4.0 which will be released in the next few months. If you want to propose changes to the selections API, please file an issue over in d3-selection. However, I\u2019m extremely conservative about adding new API methods, and I\u2019m not inclined to add these methods as-is, especially without discussion. Thanks!\n. Superseded by d3/d3-format#21.\n. Go to https://gist.github.com and create a Gist with an index.html file, and then it will show up on https://bl.ocks.org/caravinden.\n. Thanks!\n. Thanks! I will take a look at this soon.\n. Thank you!\n. Thank you!\n. Thanks!\n. Not sure if this was an intentional PR, but it applies to 3.x code which was moved in 4.0. Also due to a desire to remain compatible with older platforms that do not yet support native collections, I decided not to use include these commits in the 4.0 release.\n. Thanks for the suggestion, but I feel the existing link is sufficient.\n. Do you mind changing it to \u201ca Y shape\u201d instead of \u201can Y-shape symbol\u201d? I would, but I am on mobile.\n. My thanks!\n. Nah, that README looks fine. The text here is abbreviated.\n. Merged. Thanks.. With apologies but I am not accepting pull requests for D3 3.x.. Thank you!. Thanks, but I\u2019ll take care of this.. Great, thank you!. Thanks for the suggestion, but I prefer the original formatting.. This isn\u2019t a typo, but there are several typos in the d3-scale README that should have name=\"_pow\" instead of name=\"pow\" etc.. @arielbk No worries\u2014the convention is neither obvious nor documented. Thank you for proposing a fix to the documentation. (I also wouldn\u2019t worry about the style of your commit message. It seems fine to me!). Does this flag apply only to the source code in this repository (i.e., index.js), or does it apply recursively to the D3 dependencies?\nIf it only affect webpack\u2019s consumption of this repository and not transitive dependencies, then I would be happy to merge this.\nIf it affects consumption of dependencies, then the problem (as discussed in earlier issues) is that some D3 code has side-effects. For example, d3-transition adds selection.interrupt and selection.transition to the Selection prototype:\nhttps://github.com/d3/d3-transition/blob/master/src/selection/index.js\nI\u2019m therefore hesitant to add this flag because it\u2019s likely to cause breakages (if this flag affects dependencies).\n. If you want transition methods, you need to import d3-transition explicitly. E.g.,\njs\nimport {select} from \"d3-selection\";\nimport \"d3-transition\";. Removing this side effect would require folding d3-transition into d3-selection, which would make d3-selection\u2019s dependency graph much bigger:\n\nAlso, this is only an example, albeit a pretty stiff one because the side effect is necessary by design. There are other side effects that could be avoided by using lazy initialization. For example, d3-time-format initializes the default locale as a side effect:\nhttps://github.com/d3/d3-time-format/blob/master/src/defaultLocale.js. I would say \"for every element in the selection\"; you don't have to have bound data, and in some cases the cardinality of the data does not match the selection. The index of the bound data is correct, but if there's no data, it is equivalently the index of the element within its group. (A selectionis a grouped array of nodes.)\n. I would say \"null\" rather than \"empty\" here. You can also call attr(name) and it will return the value of the specified attribute for the first element in the selection.\n. Might want to say that names and values will be coerced to strings. So, you're allowed to set the value as a number, but the value will be implicitly converted to a string.\n. \"on the selected DOM node\" -> \"on the selected elements\"\n. Oh, and the function will be evaluated for each element in the selection.\n. Oh, I see. You're creating separate layouts with different orientations. I was confused for a bit. So, ya, an easy way to create a selection from the current node is d3.select(this):\nvar bullet = function(vis) {\n  vis.each(function(orient) {\n    d3.select(this).selectAll(\"g.bullet\")\n        .call(d3.chart.bullet()\n        .orient(orient)\n        .duration(1000));\n  });\n};\nAlternatively, you could just change the call on L37 to vis.each(bullet), in which case:\nvar bullet = function(orient) {\n  d3.select(this).selectAll(\"g.bullet\")\n      .call(d3.chart.bullet()\n      .orient(orient)\n      .duration(1000));\n};\n. I use the prefix d3_{module}_{class} to avoid naming collisions. It's a bit verbose, but it gets minimized anyway. :)\n. Since there's only one title per multiple, you can use g.select('text.title') here. As an additional benefit, you don't have to specify a data operator when you use select, since you'll automatically inherit the data from the parent node. That means you don't need to define the title attribute as an array on L36\u2014you can just use a single property.\n. If you use select rather than selectAll, then d3_chart_identity would be replaced with d3_chart_title (or d3_chart_bulletTitle).\nAlso, I often use String as shorthand for the identity function, as in text(String).\n. Can use select for the chart and subtitle, too.\n. If you want to reverse the scale, I would recommend something like this:\nx1.domain([0, max]).range(reversed ? [width, 0] : [0, width]);\nThat way, you won't need your startpos or pos functions. Also, it means that if you flip the orientation, the bullet chart should do the correct transition from the old scale to the new scale! (You'll need to update x0 at the end in the same way. Another possibility is to create a new scale and then use assignment, x0 = x1.)\n. You can shorten this slightly:\nfunction scale(x) {\n  x = (x - x0) * kx;\n  return i(clamp ? Math.max(0, Math.min(1, x)) : x);\n}\n. Interpolate between two strings with embedded numbers. The output is a string. This interpolator is useful for font sizes, color strings, SVG path data, and all sorts of other uses. Numbers are detected in the start and end string using a regular expression. These are used to create numeric interpolators, the output of which are embedded in a templatized version of the end string.\nd3.interpolateString(\"10px sans-serif\", \"20px sans-serif\")(0.5) == \"15px sans-serif\"\n. Interpolate between two arbitrary arrays. For each value in the start and end array, a generic interpolator is constructed using d3.interpolate. The array interpolator returns an array containing the result of evaluating the nested interpolators.\nd3.interpolateArray([0,1,2], [1,2,3])(0.5) == [0.5,1.5,2.5]\n. Interpolate between two arbitrary objects. For each value in the start and end object, a generic interpolator is constructed using d3.interpolate. The object interpolator returns an object containing the result of evaluating the nested interpolators.\nd3.interpolateObject({foo: 0, bar: 1}, {foo: 1, bar: 2})(0.5) == {foo: 0.5, bar: 1.5}\n. I'd say this.nodeType == 3. 3 is the same as Node.TEXT_NODE, but shorter.\n. And here, you can say this.nodeValue = value.\n. You'll need to fix the textFunction implementation, too.\nfunction textFunction() {\n  var x = value.apply(this, arguments);\n  if (this.nodeType == 3) this.nodeValue = x;\n  else if (x != null) this.appendChild(document.createTextNode(x));\n}\n. It'd be nice to allow the domain to be specified as a function, if we want to implement different domains across multiple box plots. You'd evaluate it as domain.call(this, d, i), and you could wrap it on assignment using d3_functor. The function could be null, or return null, to have the default behavior:\n.domain(domain && domain.call(this, d, i) || [min, max])\n. Should we get rid of this file? Python's SimpleHTTPServer does directory listing, and this would be one less thing to worry about. :)\n. Might as well add the i argument to the function call?\n. I'd recommend stroke-width: 1.5px here, rather than 2px.\n. Is this title svg:g used for anything, or should we delete it?\n. Elsewhere in D3, I use ~~q as an optimization of parseInt(q).\n. I'd probably rewrite this as a ternary expression:\nreturn ~~q == q ? (d[q] + d[q + 1]) / 2 : d[Math.round(q)];\nAlso, you had a typo on L232, where you say q[q + 1] rather than d[q + 1].\n. Do you want to use d3.select(window).on(\"mousemove\", \u2026) to capture mousemove events more reliably?\n. Since there's always exactly one path element, I'd probably just create the path element up-front, outside of update. Then you just need to say path.attr(\"d\", line) and you don't need to join with data and deal with enter/exit.\n. Fun trick: you can use Object instead of function(d) { return d; }. But the identity function is probably more readable. :)\n. I'd probably call this chart or div rather than \"wrapper\".\n. I'd probably use the window's mouseup here, too.\n. This is risky; orient could be specified as something that is coercible to string, such as [\"right\"]. \n. This is risky; type could be specified as something that is coercible to string, such as [\"zoom\"]. \n. I wonder if it's time to switch to a prototype for this? Say:\n```\nfunction d3_rgb(r, g, b) {\n  return new d3_Rgb(r, g, b);\n}\nfunction d3_Rgb(r, g, b) {\n  this.r = r;\n  this.g = g;\n  this.b = b;\n}\nd3_Rgb.prototype.toString = d3_rgb_format;\nd3_Rgb.prototype.brighter = d3_rgb_brighter;\nd3_Rgb.prototype.darker = d3_rgb_darker;\n```\nAlternatively, we could have static constructors, d3.rgb.brighter(color) and d3.rgb.darker(color). Which is also how we convert between rgb and hsl, e.g., d3.rgb(hsl) or d3.hsl(rgb). The main reason that I added a toString method is that you want to be able to use one of these color objects as the value for a style or attribute, in which case the object must be coercible to a string. Otherwise, I thought it would be fastest and simplest to use simple structs to describe colors (since they are created every tick of animations).\nI don't think I'm opposed to making these bonafide classes (perhaps with hsl and rgb methods). I know it's a little different than the selection object (where everything uses closures), but we're already reusing methods and this. I should probably micro-benchmark to see if it's faster. What do you think?\n. I think you mean .rgb = here.\n. Can we add a brighter/darker to HSL? Say by modifying the lightness channel using the same Math.pow?\n. I'd rename this to node. Even though the each method is defined on the groups object (which is actually the selection object\u2014a nested array of nodes), the callback is invoked for each node.\n. No, I don't think that's a requirement. I was thinking of doing the simpler thing where saying hsl.darker() would just affect the lightness channel in some reasonable way. It should be similar to rgb.darker(), but it needn't be identical.\n. You can fold this into a single search routine. You can even fold the min/max on L822 into the search by initializing low and high accordingly. See commit @e67e7d7d8b9a8b0d3e0c27cafae5bf1fd8028274 for an example.\n. Yeah, there are a few variants of binary search, so I opted to customize the binary search for the polylinear scales rather than expose a public method. Perhaps we could build a more generic search factory that lets you specify precisely the behavior you want\u2026 but that might be overkill.\n. I think we need to wrap the input data so that we store the result on invoking the value accessor. This way, you can have a non-deterministic value accessor (such as returning a random number). Also, this way we don't overwrite any fields in the current data by setting parent and offset. I'm thinking a similar model to the hierarchy layouts, there the data is converted into a standard format:\n{parent: \u2026, offset: \u2026, value: \u2026, data: d}\n. Calling d.value here assumes that the value accessor is function(d) { return d.value; }. However, if we wrap the data in a standard format as described above then this code is perfect. Same with the \"height\" attr below.\n. Nice extension of the design here.\nNit: you'll want trailing semicolons as this is an assignment statement. (They're added automatically by the compiler, but I find using semicolons consistently makes the code more readable.)\n. This is another very minor nit, but I'd probably restructure this output to be a bit more compact:\nnice().domain():\n    [1.100, 10.900] -> [1, 11]\n    [10.900, 1.100] -> [11, 1]\n    [0.700, 11.001] -> [0, 12]\n    etc.\n. This typeof check is a bit ambiguous. For example, today I can say selection.attr(new String(\"fill\"), \"white\"), and the name argument is automatically coerced from an object to a string. This isn't a particularly strong counterexample, but I prefer to use the arguments.length check for method overloading as the behavior is more predictable.\nAh, wait. That won't work, because we already support a single-argument form for returning the value: selection.attr(name). So now I'm back to thinking we should have a separate attrs method that takes a map so as to avoid any ambiguity. I'm not sure whether it would be more or less confusing to have a different name for the method, though.\n. Rather than this, I would use groups here, so that we continue to have all instance methods bound to the selection rather than bound to the context of the caller.\n. Needs an accessor function, like d3.min and d3.max. \n. Should probably ignore undefined & NaN for consistency with min & max, too? Actually, since isNaN(undefined) is true, and +null is 0, I think you can say:\njavascript\nwhile (++i < n) if (!isNaN(v = x[i])) s += v;\n. Think we can delete this now.\n. I'd probably just say distances = [] here. See http://jsperf.com/new-array-vs-literal/8.\n. This should take the same form as the other hierarchy function calls, which would make it padding.call(treemap, node, node.depth).\nRelated: The hierarchy layout exposes the hierarchy instance to callers, when in fact this should be subclass, treemap. This is one of the things I don't like about subclassing functions: you can only wrap the parent function, resulting in two objects. :\\ I can't think of any place where we care what the this context is for these function calls, but I'd like to be consistent.\nUnfortunately, fixing this problem is a pain, because it means the subclass can't just call hierarchy(\u2026); it also needs to pass in the wrapping instance (treemap). Blech. At any rate, this refers to the containing window here; saying treemap is probably the right context for now.\n. Don't you want to scale root.children here, rather than all nodes?\n. If you wanted, you could be clever here and redefine the nodeRect function rather than the padding function. That way, we can be smart about how the padding is computed, rather than doing the lazy thing and upcasting constants to functions. Something like:\n``` javascript\nfunction padFunction(n) {\n  var p = x.call(treemap, n, n.depth);\n  return {x: n.x + p[3], y: n.y + p[0], dx: n.dx - p[1] - p[3], dy: n.dy - p[0] - p[2]};\n}\nfunction padNull(n) {\n  return {x: n.x, y: n.y, dx: n.dx, dy: n.dy; };\n}\nfunction padArray(n) {\n  return {x: n.x + x[3], y: n.y + x[0], dx: n.dx - x[1] - x[3], dy: n.dy - x[0] - x[2]; };\n}\nnodeRect = typeof x === \"function\" ? padFunction\n    : x == null ? padNull\n    : padArray\n```\nThis is the same technique used by selections. I guess you could support numbers instead of arrays, too, though I'm not sure whether it's better to typeof check for number, instanceof check for Array, or use Array.isArray (which isn't supported on all browsers).\n. It should not be possible for the area to be negative or NaN, given that we check for this on L21 and assign to 0.\n. No need to change this, but I think it's slightly clearer if you used the names x and y rather than lon and lat. These aren't longitude and latitude as you've defined them (though the projection is linearly separable in that lon is defined exclusively in terms of x and lat in terms of y).\nThe terminology we use in ModestMaps and Polymaps is: point -> coordinates -> location. (I'm using the word \"coordinates\" loosely in the code in part because D3 uses a simple array of numbers to represent all three types, and in part because that's what GeoJSON calls locations.) The input to the invert method is a point that specifies pixel positions. We first convert to normalized coordinates in the range [0,1]; the top-left corner of the world is \u27e80,0\u27e9 and the bottom-right is \u27e81,1\u27e9. Equivalently, this is the world tile at zoom level 0. The conversion between points and coordinates is always just translate + scale and independent of projection. Lastly, these normalized coordinates are converted to longitude and latitude according to the projection.\nThis was also the approach used by Protovis, though I think I used the range [-1,+1] rather than [0,1]. All the projections converted between locations and normalized coordinates; then the geo scale converted between normalized coordinates and points (pixels). See Projections.js and GeoScale.js.\nAnyway, I like that D3's geo projections have scale and translate built-in, and [0,1] is more convenient. You can use them to produce normalized coordinates by setting translate to [0,0] and scale to 1. (This would fit the whole world in a single pixel.)\nIf we want to make the code slightly more clear, then, I might consider standardizing the conversion between points and normalized coordinates at the beginning of the method:\njavascript\nvar x = (xy[0] - translate[0]) / scale,\n    y = (xy[1] - translate[1]) / scale;\nNot necessary, though. I'm sure you understand all this stuff; I just figured I'd write it down for posterity!\n. If you convert to strict equals here, you'll need to string-coerce the input to the mode function. Which is probably a good idea, anyway. mode = x + \"\";\n. I tend to use full words (for clarity) or single characters (for brevity, as in mathematical functions) and try to avoid abbreviations. I say we should call everything coordinates and leave it generic.\n. The crazy thing is, you can leave the var n declared here, and then define it before it's declared. JavaScript hoists var declarations (but not definitions) to the front of the method, which is what allows this to work. But this version is fine too. Just sharing a crazy trick. :)\n. You'll want to replace the existing force.charge method, rather than making a duplicate one.\n. The var i here doesn't have the meaning you intend. (It could be undefined.) Also, stashing the result of the array lookup is slightly more efficient. So use the code I gave you in the earlier response:\njavascript\nvar k = charges[quad.point.index];\nquad.count += k;\ncx += quad.point.x * k;\ncy += quad.point.y * k;\n. Oh, and you'll need to pass charges to the d3_layout_forceAccumulatemethod now.\n. Alpha is always non-zero, but it might still be worth checking if charge is 0 here. That way, we don't pay the cost of computing charge forces if the charge is set to the constant zero. (We\u2019d still compute forces if the charge was set to a function that returned all zeroes, but that seems reasonable.) So I\u2018d sayif (charge) here, and then probablyrepulse(o) since the repulse function already has access to the current alpha.\n. I\u2018d leave this as count. I mean, you could call it charge if you wanted to, but you forgot to also update the repulse function where this is used. And since this is only used internally I don\u2019t see a big impetus to change the name.\n. We can short-circuit this so it exits early:\njavascript\nwhile (++i < n) if (!d3_selection_classed.call(this, names[i])) return false;\nreturn true;\n. Seems like you don't actually need this check. I mean, it doesn't hurt, but it's not necessary either. Ya? (Sorry, I should have seen this last time around!)\n. This requires checking the return value of f(t) for every tick, whereas what we want is to remove the attribute when the transition starts and not set a tween. The implementation should be similar to transition.text, where the tween does the work and returns undefined so that no work is done on tick.\nThe implementation is a bit complicated if we want to support this for transition.attrTween, but I think we only need to support it for transition.attr. And of course we have to distinguish between the case where no tween should be run because the values are equal (a == v) and the case where no tween should be run because the destination value is null (b == null). And we need to support this both for constant nulls (transition.attr(\"foo\", null)) and function nulls (transition.attr(\"foo\", function() { return null; })).\n. I'd write this using the ternary operator:\njavascript\nreturn f === d3_transitionRemove ? this.removeAttribute(name)\n    : f && function(t) { this.setAttribute(name, f(t)));\n. Oh, I see! You could use the comma operator (return this.style.removeProperty(name), null), but that's not ideal so I'll leave you to decide which one you prefer!\n. This might be slightly cleaner if we broke out the different functions, similar to what we do in transition.attrTween:\n``` javascript\nfunction d3_transitionTween(b) {\nfunction transitionFunction() {\n    var v = b.call(this, d, i);\n    return v == null\n        ? a != \"\" && d3_transitionRemove\n        : a != v && d3.interpolate(a, v);\n  }\nfunction transitionString(d, i, a) {\n    return a != b && d3.interpolate(a, b);\n  }\nreturn typeof b === \"function\" ? transitionFunction\n      : b == null ? d3_transitionNull\n      : (b = b + \"\", transitionString);\n}\n```\nI found another excuse for the ternary operator, too. :)\n. Nice catch.\n. Can you refactor this to reduce code duplication? It looks like you could say something like this:\njavascript\nfunction matrix(angle, a, b) {\n    var c = Math.cos(angle *= d3_geo_radians),\n        s = Math.sin(angle),\n        my = m[1],\n        mz = m[2],\n        a0 = a[0],\n        a1 = a[1],\n        a2 = a[2],\n        b0 = b[0],\n        b1 = b[1],\n        b2 = b[2];\n    a[0] = c * a0 - s * b0;\n    a[1] = c * a1 - s * b1;\n    a[2] = c * a2 - s * b2;\n    b[0] = s * a0 + c * b0;\n    b[1] = s * a1 + c * b1;\n    b[2] = s * a2 + c * b2;\n}\nThen you'd say something like:\njavascript\nrotate.x = function(angle) {\n  matrix(angle, my, mz);\n  return rotate;\n};\n. I'm surprised that this represents relative rather than absolute rotation. Can we change it to represent absolute rotation? Meaning, if we rotate.x(10) and then rotate.x(-10), the second call supersedes the first, being equivalent to a single rotate.x(-10). Is there a strong reason to favor relative rather than absolute?\n. If I'm understanding correctly, this zAngle is an optimization for when only the zAngle is set. Is that correct? If so, I say we leave it out for now for the sake of implementation simplicity. It doesn't look like we'll be doing a lot of z-only rotations in the immediate future, though we can always add it back if we are.\n. I think it'd be slightly clearer to initialize zoom as d3.geo.zoom().scale(1000), rather than doing it here.\n. Should this be initialized with scale(200)? I believe the default d3.geo.zoom scale is 500.\n. I'd probably extract this into a reusable d3_geo_zoomRebind:\njavascript\nfunction d3_geo_zoomRebind(projection, zoom) {\n  projection.scale = d3.rebind(projection, zoom.scale);\n  projection.translate = d3.rebind(projection, zoom.translate);\n}\n. Leaking global y here.\n. This should probably be Math.atan2(dy, dx) (and below).\n. I would use f instead of arguments[1] here. I just used arguments[1] for clarity when I was describing the approach.\n. According to http://www.quirksmode.org/dom/w3c_cssom.html, pageX and pageY are only broken on IE8 and below. Since D3 supports only IE9 and above, we can greatly simplify this code to use pageX and pageY.\njs\nvar rect = container.getBoundingClientRect();\nreturn [e.pageX - rect.left, e.pageY - rect.top];\n. Would something like this work?\njs\nstart *= h, step *= h, stop *= h;\nif (step < 0) while ((j = start + step * ++i) > stop) range.push(j / h);\nelse while ((j = start + step * ++i) < stop) range.push(j / h);\n. Seems like you could also write this as:\njs\nvar low = n < m ? n : m, fix = 1;\nwhile (fix * low % 1) fix *= 10;\nreturn fix;\nIf low is NaN, then the while loop clause will be falsey, so it should break automatically. Likewise if the clause is !== 0; truthy. I think that means you'd return 1 rather than low if low is NaN, but I think that's still valid.\n. (I think your implementation returns 10 when n and m are integers, rather than 1.)\n. Actually, why not this?\njs\nreturn Math.pow(10, -Math.floor(Math.log(Math.min(n, m)) / Math.LN10));\n. I need to think about this a little bit more, but I'm not sure getBoundingClientRect is the right frame of reference in HTML speak. The returned coordinates should be consistent with absolute positioning numbers (for parity with the SVG behavior, which is in the \"current user coordinates\"). So, I think this code may have to looking at offsetParent, offsetTop, and offsetLeft?\nFor that matter, it appears that mouse events have an offsetX and offsetY property, which might be what we need, which could mean something as simple as return [e.offsetX, e.offsetY], but I haven't confirmed that yet.\n. I might reduce this like follows:\n``` js\nvar d3_time_suffixes = [\"th\", \"st\", \"nd\", \"rd\"];\nfunction d3_time_suffix(number) {\n  var tail = number % 100;\n  return d3_time_suffixes[tail < 11 || tail > 13 && tail % 10] || d3_time_suffixes[0];\n}\n``\n. I wonder if a slightly more concise check here would beif (svg.createSVGPoint)? This is fine too, though; probably doesn't matter.\n. I think since we use scrollX and scrollY above, we should use those here too, since they are equivalent to pageXOffset and pageYOffset. http://www.w3.org/TR/cssom-view/#extensions-to-the-window-interface\n. Wait, for that matter, isn'te.pageX - window.pageXOffsetequivalent toe.clientX`? Or is that buggy?\njs\nreturn [e.clientX - rect.left - container.clientLeft, e.clientY - rect.top - container.clientTop];\n. I think this is overly strict. For example:\njs\nvar a = {foo: 42};\nvar b = Object.create(a);\nb.foo; // 42\nb.propertyIsEnumerable(\"foo\"); // false\n\"foo\" in b; // true\nfor (var key in b) console.log(key); // \"foo\"\nPhilosophically, I want to iterate over inherited properties here; if you want to derive a new object from a prototype object, that should be transparent.\n. I think I'd probably fix this by declaring d3_rgb_names as Object.create(null) rather than switching to hasOwnProperty here.\n. Again, o = Object.create(null) is a more concise solution.\n. Seems like initializing d3_nsPrefix = Object.create(null) also fixes this one. ;)\n. Yep, nodeByKey = Object.create(null) should work here too. ;)\n. Or /-closed$/.test(x)?\n. You don't need the valueOf() here; isNaN will automatically coerce the date to a number.\n. Why did you change this? I reverted it to fix the tests previously. I think I understand what you're doing here, but it seems more complicated and prone to false negatives.\n. OK, I think I understand. The d3.transform call canonicalizes the result of interpolation (e.g., mapping rotate(780) to rotate(60)). Should be fine either way.\n. Does this work correctly with daylight savings because we later call setHours?\n. Forgot to remove attr(\"dx\") here?\n. I prefer arguments.length checks to argument truthiness, since arity is more explicit and predictable.\n. I'd rather leave out the d3.xhr.get and d3.xhr.post aliases for now, and favor parsimony until there is sufficient evidence these convenience functions are needed.\n. We should favor the standard event names, rather than mapping them to different names for the D3 API. This includes using \"load\" instead of \"success\".\n. Rename to d3_xhr_send.\n. Unused sent property.\n. I don't like exposing these as public attributes; better to hide them via privileged methods.\n. I prefer to check if \"mimeType\" in opts, and then to delete options[method] if value == null on set. (The double-equals catches both null and undefined.)\n. Also, it might be a good idea to decouple the overrideMimeType call from setting the Accept header, now that we can support APIs for both. Speaking of which, we need a xhr.header(name, value) method.\n. This should be subsumed by xhr.header(\"Content-Type\", \u2026).\n. Thanks, nice catch!\n. If squarify is the default, then it should be the default here, too. I'll fix it in the merge.\n. I'd rather this be called rotate and the other one be called rotateObject\u2026.\n. If we wanted to be clear we could say \"projectScaleCenterTranslate\". ;)\n. Heh. This is a nice temporary fix. We should probably rewrite d3_geo_albersUsa as a raw projection, and then wrap it in d3.geo.projection.\n. There are quite a few places we convert from cartesian to spherical coordinates without using d3_geo_spherical. I guess maybe they're each different enough to not merit code reuse, but I wonder if there's a more flexible form (say spherical(x, y, z) rather than spherical([x, y, z])) that would encourage more reuse?\n. I think you need to reassign d3_geo_centroid.lineEnd to d3_geo_centroidLineEnd on ringEnd?\n. ~~Also, doesn't this reassign \u03bb00 = \u03bb, \u03c600 = \u03c6 for every point, not just the first point as implied by the comment above?~~ Oh, no, because d3_geo_centroid.point reassigns itself on the first point. Ha! Yikes, need to investigate doing this without method reassignment.\n. Probably need type coercion here for number (+), when not a function, and above, when a function.\n. Ah, I see you've done the type coercion here, but you'll want it in d3.geo.path so that calling path.pointRadius() returns a number. In general, type coercion should happen in the public interfaces, and then we rely on correct types for private interfaces such as d3_geo_pathContext.\n. See d3_geo_pathContext comment re. type coercion.\n. Yeah, great point.\n. If we remove the invisible argument, the two places that call this method can drop the +1 and -1, respectively.\n. n should be a string at this point, so n.local should always be undefined. That only gets set after the name is qualified using d3.ns.qualify.\n. I would recycle these from d3_map_prefix and d3_map_prefixCode, rather than duplicating.\n. Since x1 is outside the scope of this function, it will be preserved across calls to quadtree(data), which isn't what you want. I guess you'll need local variables for the computed bounds?\n. Let's simplify this by limiting the size to [width, height], rather than specifying an extent. (If you wanted [[x0, y0], [x1, y1]], that would be called an extent rather than the size.) We could support an extent, too, but I think at the moment we only need to support extents that start at [0,0] so a size is sufficient and compatible with other layouts.\n. This method doesn't appear to set size. Test?\n. Rename vertex to point here, for consistency?\n. Rename vertices to points for consistency?\n. If x === d3_svg_lineX and y === d3_svg_lineY, it might be worth short-circuiting this, so that the input data is used as the points directly. This avoids creating a duplicate array of points in the common case where you're using the default accessor.\n. I thought about that, but I think you don't actually need to expose quadtree.extent, since you can set x1, y1, x2 and y2 from the d3.geom.quadtree; in effect the deprecated API has access to the private fields.\n. If x === d3_geom_quadtreeCompatX and y === d3_geom_quadtreeCompatY, it might be worth short-circuiting this, so that the input data is used as the points directly. This avoids creating a duplicate array of points in the common case of the force layout.\n. Same comment as above re. optimizing special case of d3_geom_quadtreeCompat{X,Y}.\n. This will store the derived point in the quadtree, rather than the input data. This is tricky. You need the computed _x and y location of the node to insert new nodes, but the node\u2019s point should refer to the input data, not the derived point. I think you could fix this by storing the computed x and y on the node directly (as n.x and n.y rather than n.point.x and n.point.y).\nYou could also change the signature of insert to insert(n, d, x, y, x1, y1, x2, y2), where d is the datum and x and y are its location. The cool thing about that is what you could represent the computed points more efficiently as two parallel arrays of x- and y-coordinates, rather than creating point objects (since you don't ever need to save the derived point objects).\n. This method should take a datum as input, and derive the associated x- and y-coordinates using the accessors, rather than expecting a point as input.\n. You'll want to pass i as the second argument to fx and fy.\n. Golf it!\njs\nx2_ = y2_ = -(x1_ = y1_ = Infinity);\n. You'll want to pass i to fx and fy here, where i is the number of nodes previously added (for consistency with the constructor behavior).\n. Also, why don't we drop the fx.call(this, \u2026) and just use fx(\u2026) instead. I don't see a compelling need to preserve the this context, especially since we don't in root.add below.\n. Oh, and you'll want to coerce the return values to numbers as you do above.\n. I think we could safely do this in all cases, rather than only in non-deprecated mode. Then you could get rid of the compat field, too!\n. You could short-circuit this when fx === d3_svg_lineX and fy === d3_svg_lineY, too. Or just leave a // TODO comment to this effect.\n. This one could likewise be optimized when fx === d3_svg_lineX and fy === d3_svg_lineY; you can just call d3.geom.delaunay directly!\n. Oops, I didn't mean to add i to the public signature; I was thinking more like this:\n``` js\nroot.add = function(d) {\n  insert(root, d, +fx(d, ++i), +fy(d, i), x1_, y1_, x2_, y2_);\n};\ni = -1;\npoints.forEach(root.add);\nreturn root;\n```\n. And lastly, discard some captured fields:\njs\nxs = ys = data = null;\nMaybe others?\n. Even simpler, use x and y instead of fx and fy, and then move this to first line of the function.\n. I would format this a bit differently. If you don't mind:\njs\nfunction d3_svg_lineStep(points) {\n  var i = 0, n = points.length, p0, p1 = points[0], path = [p1[0], \",\", p1[1]];\n  while (++i < n) {\n    p0 = p1, p1 = points[i];\n    path.push(\"H\", (p0[0] + p1[0]) / 2, \"V\", p1[1], \"H\", p1[0]);\n  }\n  return path.join(\"\");\n}\n. I don\u2019t think you want the !dragging here\u2014this behavior should only be controlled by the clamp setting.\n. Also that means you can use another ternary:\njs\nmin = clamp[i] ? Math.max(r0, Math.min(r1, point[i])) : point[i];\n. Even though this is only temporary, I don\u2019t like the use of the \".suppress\" name here. The caller should pass in the appropriate name and it should not be altered by this method. So, the drag behavior would d3_eventSuppress(\"click.drag\"), etc.\n. Double-quotes, if you please!\n. This shouldn\u2019t be necessary; the return value of m should be floored already. If that\u2019s not the case, then we should fix it in m\u2014that is, fix d3.time.days rather than flooring all ticks.\n. new Date would work too, right? Since this date instance\u2019s time should always be set before being used.\n. Wouldn\u2019t it be better to fix this in src/time/day.js? It feels to me like this is applying the work-around to all intervals, when the only one that actually needs the interval fix is d3.time.day. Although, I guess any interval larger than d3.time.day has the same problem\u2026\n. Using array.forEach would be more appropriate here.\n. You should use nest as the this context, rather than this. Within the context of array.map or array.forEach, the this context is the global object (such as the window), unless you specify the optional thisArg. Also, typically it would be appropriate to pass the second argument of the index i to the function. (Or perhaps depth, based on your initial description.)\n. This won\u2019t work because d3_xhr checks the number of arguments that are passed to disambiguate between various overloaded forms:\n- d3_xhr(url)\n- d3_xhr(url, callback)\n- d3_xhr(url, mimeType)\n- d3_xhr(url, mimeType, callback)\nSee the API reference for details.\nYou could splice the d3_text response function into the arguments (creating a copy of the arguments array first using d3_array, since it\u2019s not a real array). Or you might move the fancy argument logic out of d3_xhr and into the new public function, d3.xhr, and therefore require that d3_xhr always be called with all four arguments, some of which may be null. That might require duplicating a bit of logic between d3.xhr and d3.text, but it\u2019s probably the cleanest approach.\n. If you could leave this in its original location (below d3_xhr), it will make the diff easier to read.\n. You don\u2019t need to declare response as a var now that it\u2019s an argument; you can delete this line.\n. Same comment re. d3.text.\n. You could use d3_selectRoot here instead of creating a new element.\n. Should we restore whatever value was previously set? Note: not the computed value, but the assigned value, element.style.webkitUserSelect.\n. Would vanilla JS be simpler here? d3_document.body.style.webkitUserSelect = \"none\";\n. I wonder if it\u2019s worth detecting the vendor prefix globally, rather than making it specific to d3_selection_style. Then you might be able to shorten some other vendor-specific checks, e.g.,\njs\nvar d3_timer_frame = d3_window.requestAnimationFrame\n    || d3_window[d3_vendor + \"RequestAnimationFrame\"]\n    || function(callback) { setTimeout(callback, 17); };\n. The body should exist by the time the behavior receives any input events.\n. I feel like it\u2019s safe to assume that the body exists if you\u2019re receiving user input events. No?\n. I think now that we\u2019re not canceling the mousedown event, we don\u2019t need to re-focus the window.\n. Should use d3_selectRoot instead of d3_document.documentElement.\n. Likewise, d3_selectRoot here. (Rename that global if you don\u2019t want it to be selection-specific.)\n. I\u2019m not wild about this API. It\u2019s just internal, so it doesn\u2019t have to be perfect, but a few thoughts:\n- d3_behavior_select sounds like a behavior for selecting (something), whereas the implementation is a mechanism to disable selection and then later reenable it.\n- The behavior is a no-op for browsers other than Firefox, so this API doesn\u2019t encapsulate the above behavior. It would be better (assuming it\u2019s possible to design elegantly) if the API encapsulated disabling selection temporarily. That is, it prevents the default behavior on selectstart events on browsers that support it, and otherwise applies the user-select: none style. That way callers can just use this API, rather than using this API + selectstart, which feels like a leaky abstraction.\n- Alternatively this should be renamed to make it clear that it only applies the user-select style on browsers that support it. But I think encapsulating both APIs into one probably be cleaner.\n. Sure, that\u2019s fine.\n. Could we use \"onselectstart\" in d3_document and if that\u2019s true, suppress the selectstart event, and otherwise use the user-select style? More generally: can we make this less browser-specific?\n. I\u2019m tempted to use the name \"suppress\" rather than \"disable\" for consistency with d3_eventSuppress. I\u2019m also tempted to move this to the event folder rather than here in the behavior folder. But it\u2019s probably fine in either. Any preference?\n. I guess a non-vendor specific check would look like:\njs\nvar d3_behavior_selectProperty = \"userSelect\" in d3_documentElement.style ? \"userSelect\"\n    : d3_vendor + \"UserSelect\" in d3_documentElement.style ? d3_vendor + \"UserSelect\"\n    : null;\nThen\njs\nvar d3_behavior_selectDisable = d3_behavior_selectProperty ? \u2026\nAnd\njs\nvar style = d3_document.body.style,\n    selectValue = style[d3_behavior_selectProperty];\nstyle[d3_behavior_selectProperty] = \"none\";\nreturn function() { style[d3_behavior_selectProperty] = selectValue; };\n. This isn\u2019t equivalent. The >= is necessary because it coerces the objects a and b to comparable values, whereas === uses strict equality. For example, if you have two Date objects a and b that represent the same time, then a >= b is true but a === b is false.\n. I know they\u2019re equivalent, but if you could write this as new Array(i) rather than Array(i) that would be more readable. (The new is automatically dropped during minification anyway.)\n. Since you\u2019re in this file already, would you mind changing new d3_Set() to new d3_Set and using n rather than l?\n. You\u2019ve got two spaces after the i here; please use one.\n. Perhaps I\u2019m missing something, but I don\u2019t see how this is an optimization.\n. Same comment as d3.ascending.\n. If you include null / undefined values in your test (which is half of the check, here) it seems like a wash. In both Chrome and Safari it\u2019s within the error bounds of test (which probably underestimate actual variance) and on Safari the optimized version is slower (though still within error). http://jsperf.com/this-is-for-mbostock/2\n. (This code is probably going away, but\u2026) Stylistically, I think these comments would look slightly better on the same line as the code:\njs\ntouchtime = null; // prevent spurious dbltap\nstarted(); // recompute touch locations\nAlso, I tend to use lowercase with no terminating period for end-of-line comments, since these are usually sentence fragments or words so as to limit their length and fit them on the same line.\n. Just noticed this, but isn\u2019t location(touches[0]) more efficiently defined as locations[p.identifier]?\n. Maybe rephrase this test as \"ignores optional padding modifier, skipping zeroes and spaces\"?\n. Use t in d3_time_formatPads rather than t === \"0\" || t === \"_\" || t === \"-\"?\n. Checking that I understand this code correctly: the timezone offset (%Z) is always relative to UTC time. However, in some cases d3_date is already equal to d3_date_utc (specifically: inside format.parse for a UTC time format). Therefore, we only need to temporarily override d3_date to d3_date_utc if it is not already d3_date_utc.\n. If utcZone is true, then date is necessarily an instance of d3_date_utc but we want to return a local Date. In which case you can say date._ here to convert back to local time.\n. It\u2019s probably worth structuring this a bit differently:\njs\nif (inside || visible) {\n  listener.polygonStart();\n  if (inside) { \u2026 }\n  if (visible) { \u2026 }\n  listener.polygonEnd();\n}\n. Would it be possible (and worthwhile) to cache the rotation, since the point is always [-\u03c0, 0]?\n. I wonder if it\u2019s worth writing a different rotation implementation that calls through to a stream listener rather than returning a new array. For example:\njs\nvar transform = new d3_geo_transform(stream);\ntransform.point = function(\u03bb, \u03c6) {\n  stream.point((\u03bb += \u03b4\u03bb) > \u03c0 ? \u03bb - 2 * \u03c0 : \u03bb < -\u03c0 ? \u03bb + 2 * \u03c0, \u03c6);\n};\nreturn transform;\nWe could rewrite all the projections to do this, too, of course, but that\u2019s a lot more difficult since the projection API is public. And it\u2019s only worth doing this if it\u2019s faster on the benchmarks.\n. Forgive me if I\u2019m missing something, but isn\u2019t the \u03bb wraparound already handled by d3_geo_forwardRotation\u03bb? Why is it necessary to do it again here?\n. So, if I understand correctly, this fixes a problem with the input longitude being outside the range \u00b1\u03c0 radians? I think it\u2019d be reasonable to fix that by replacing the use of d3_geo_equirectangular with a new d3_geo_rotationIdentity that just does the wraparound check on longitude. (Also, I guess we\u2019re not concerned with wraparound on \u03c6?)\n. (And to be fair I see we were doing this before, and you just moved it to a new location!)\n. Yeah, I think it would require a fair number of contortions\u2026\n. The if (i) here is redundant. The post-decrement operator returns the value of i before decrementing, so the first test of the while loop fails. You could create an infinite loop by constructing malformed input (e.g., indexes = {length: Infinity}) but that should never happen for an actual array input.\n. The variable node here is undefined.\n. Post-decrement is generally slower than pre-decrement.\n. This doesn\u2019t look like an optimization to me; I expect the performance is nearly identical. And the benchmark you linked to applies to an earlier change (to preallocate the array rather than use push), not to the change you are making.\n. Not sure if it\u2019s worth it, but you could avoid creating a new array with each iteration by assigning the current exterior to a reusable global length-1 array.\n. n = points.length and ++i here?\n. But if the exteriorPolygon is outside the two for loops, it\u2019s still creating a new array for each polygon clipped, right? Which is better than for every ring * exterior, but less than having a single global array that is preallocated. I guess I would consider benchmarking this. If having the global doesn\u2019t improve performance, then I\u2019d probably do what you were doing originally and create the array literal as needed.\n. This doesn\u2019t need to be enclosed inside d3_scale_linearTickFormat, and so could be moved out to a global d3_scale_linearPrecision function.\n. Should be safe to rewrite this as return a[0] - b[0] || a[1] - b[1];.\n. Only one space before the //.\n. Local style convention: please use lowerCamelCase rather than lower_under_score naming.\n. This comparator function should be extracted as a global so that it doesn\u2019t need to be instantiated every time the hull is invoked, say, d3_geom_hullOrder. Also, there should be a space before the || and you don\u2019t need the surrounding parens.\n. These vars should be combined into a single statement. Also, avoid abbreviations for names, and use lowerCamel for functions:\njs\nvar upperHull = d3_geom_hullUpper(points),\n    lowerHull = d3_geom_hullUpper(flippedPoints);\n(Edit: deleted earlier comment from misreading the code.)\n. Style fixes here:\njs\nvar skipLeft = lowerHull[0] === upperHull[0],\n    skipRight = lowerHull[lowerHull.length - 1] === upperHull[upperHull.length - 1],\n    polygon = [];\nFor that matter you could probably drop \"hull\" from lowerHull and upperHull since I think it\u2019s clear enough from the context.\n. Use predecrement --i and spaces around your =.\n. Use preincrement ++i.\n. var i is declared a few times in this function. It\u2019s probably worth consolidating those declarations, declaring it right before n.\n. This is effectively the same function as d3_geo_clipExtent\u2019s isLeft; that should be exposed as a reusable static function, say in math/trigonometry.\n. Strictly speaking it violates semantic versioning because it\u2019s introducing new API surface area. However, it\u2019s just one tiny method, and it was added primarily to fix a bug rather than support dramatic new functionality, so I don\u2019t want to wait until 3.5. (We\u2019ve done this in previous releases, for example when it was reported that d3.random.irwinHall was in fact returning a Bates distribution.) We could make d3.touch private in the interim, but I don\u2019t see a significant risk of releasing it a patch release, so I\u2019m inclined to let it slide.\n. Seems like a shame to set these even when these functions won\u2019t be used. I wonder if there\u2019s a way to restructure the code slightly. (I guess it\u2019s also a shame that these closures are instantiated even though they won\u2019t be used, too, though I\u2019m not sure what the performance implications would be of extracting them.)\n. Pretty sure we want the value returned by transition.attr to be the string-coerced value, not the input value. In other words, f.__value__ = b += \"\".\n. Rename this to d3_xhrHasResponse? Or if you prefer d3_xhrResponseNotEmpty.\n. Please don\u2019t change this. We want to use the locally-installed version (specified in the package.json), not whichever version you happen to have globally-installed.\n. d3.mean checks arguments.length, so passing in f it is undefined will crash. (Which is surprising since you appear to have tests which cover this.)\n. The formatting in this class isn\u2019t consistent with other D3 methods. It should look like this:\n``` js\n  var name1 = value1,\n      name2 = value2,\n      name3 = value;\nif (expression) return statement;\n``\n. Allocating another array and then calling d3.variance recursively is slow, and takes about the same amount of code as just computing the variance directly on the evaluated values, which is what we should be doing here. (See other stats functions for examples.)\n. I believe we should be returning undefined rather than NaN here, based on what we did with d3.mean.\n. In the jsperf you linked, the raw loop is the fastest in Chrome 38.\n. Sure, I\u2019ll restore a specific version for UglifyJS. Unpinning doesn\u2019t really buy us anything since you still have to remember tonpm updateto grab the newer version.\n. I had this exact change in my working tree but I forgot to commit it last night, so thanks!\n. The type offormat` is guaranteed to be a string here, so this check is redundant.\n. ",
    "jasondavies": "Added, thanks! I noticed this when copying the drag code to use in http://www.jasondavies.com/pythagoras-proof/ - D3 worked really nicely for this, especially when inserting the <svg> nodes in between the text.\n. It's definitely NodeList. I have a feeling arguments may work fine, I'm just loading up a VM to check :) I like your approach though, maybe it's still worth having a slow fallback for arguments just in case? Or maybe just ignore it as we want to stay lean?\n. Yep, using Array.prototype.slice for arguments seems to work fine even in IE6.\n. The push version doesn't work for NodeList in IE6 or IE8, so probably no point using it at all?\n. Should I just get rid of d3_arrayArguments as it works fine in IE6+?\n. Cool, thanks.\n. Another note: I'm making simplifying assumptions about the lat/lon coordinates. Do I need to do anything special e.g. consider Earth as an ellipsoid?\nThere's some info here:\n- http://nsidc.org/data/polar_stereo/ps_grids.html\n- http://en.wikipedia.org/wiki/Latitude\nThe Wikipedia link mentions various different ellipsoids e.g. WGS84 is used by all current GPS devices.\n. Okay, this may actually be better named \"azimuthal equidistant projection\".\n. Currently all the geo projections operate on a point-by-point basis, so it's hard to fix the Antarctica problem using that alone. I was thinking of returning null for locations out of bounds, but this doesn't solve the problem of polygons partially out of bounds.\nI suppose a solution could involve adding a new .clip() function that takes a list of coordinates and performs the appropriate interpolation on polygons that overlap partially.\nAlternatively, if we can solve your second point easily, I think it would work to just use overflow: hidden and extend out of bounds points to be outside the projection, as any straight lines out of bounds would become arcs around the circular projection, and partially out of bounds polygons should be clipped properly by SVG without us having to do it.  For Antarctica we may need to add a subpath so it becomes a doughnut though.  It would be nice to have this so the whole world can be displayed at once with this projection, even though no-one would actually want to do this :-)  What I mean is to continue the circular latitude lines outwards all the way to -90\u00b0 (South Pole).\nI think it should be fairly straightforward (!) to replace \"lineto\" commands with the appropriate elliptical arc commands for the polygons to solve your second point.\nI found a nice page about azimuthal projections here: would be nice to make them display using D3 :-)\n. What approach do you suggest for supporting non-linear projections?  Perhaps the projection API could optionally take pairs of points instead of just single points, and this would be used for projecting lines or polygons.\nThe API would need to return sufficient information to construct elliptical arcs, so maybe it could return the same data as required by SVG paths' A command, but as an object e.g. {type: \"arc\", x0: ..., y0: ..., x1: ..., y1: ..., rx: ..., ry: ..., ...}.  Perhaps there's something a bit simpler?  Should C and Q curve commands be supported too?  Maybe it could just return the SVG path string, but it seems a shame to tie it to SVG too much.\n. Note to self: add demo of great circles too.\n. Hurrah, thanks! Looks really cool. I'm also glad I can finally reclaim master for its true purpose now that this is merged :-)\nI have some thoughts about clipping and arcs but I'll open a new pull request when I get round to it.\n. I couldn't resist adding a unit test using the shiny new system. Very nice :-)\n. I wonder if it's worth running all unit tests on both minified and unminified versions?  Maybe another Makefile target tests.min that you run less frequently - you don't want additional guff slowing you down :-)\nOne way of doing it: have a wrapper for require() e.g. require_min() that checks for an environment variable MINIFIED so it knows whether to include the minified version.\nAnyway, just a thought.\n. Done: http://code.google.com/p/closure-compiler/issues/detail?id=378\n. They've fixed this issue now: http://code.google.com/p/closure-compiler/issues/detail?id=378 but I think we're moving to UglifyJS anyway.\n. I wasn't sure if a separate regular expression was necessary, as we need to keep the combined one to search for the end of a field.  The newline check is done for a specific character position, so it seems more efficient to do a check directly. I suppose we could use jsperf to check for sure :-)\n. I noticed this one when testing http://mbostock.github.com/d3/ex/choropleth.html in IE9.\n. Wonderful, thanks! I was wondering how to make it generate small multiples - your idea of relying on bound data sounds great.\n. Okay, I've got bullet multiples working now. I'm a bit unsure about when to refresh the scales, should this be exposed as .refresh() to be called if/when the data changes? Should this also apply some kind of transition, and how should the transition be customisable?\n. Thanks, I've added transitions by default now, but ideally they wouldn't apply the first time round. Maybe the transition delay could be an optional argument, so you could do d3.select('g.bullet').call(bullet, 100) for a 100ms transition duration. Perhaps the default could be 0 (internally it would probably just avoid .transition() until passing 0 results in immediate application).\nI did try variations of d3.select('g.bullet').transition().call(bullet) but this doesn't really work for various reasons, for example you can't really append() new nodes to a transition.\n. Thanks. I've actually changed it to set the fill attribute directly instead now as that's what I've done elsewhere.\n. Hehe :-)  Still need to add the other orientations, and clean up the height computation. I think I should probably add title and subtitle support too like in the Protovis version.\n. Bedtime for me, here are some random thoughts in case I forget:\n- Still wondering about making transitions more flexible. One way would be to expose the internal transition function as a property, so that other easings can be specified. I wonder if people would really need it though. Less is more!\n- Orientations: might be simpler to use a few SVG transforms instead of doing lots of conditionals for each x, y, width, height, etc. attribute.\n- Also need to add other marker types. Another property, specifying a symbol type to pass to d3.svg.symbol()?\nFeel free to hack on it if you want!  I'll probably look at it again tomorrow.\n. I think as it's in the same git repository keeping the same master version number makes sense for anyone who uses github to host particular versions (as you do for bl.ocks.org examples). Unless you're thinking of using a combined version tag of some kind? I think separate versions for all non-core libraries could certainly get a bit confusing. Also, you may then run into dependency issues.\nMaybe it's something to consider if/when the chart library gets a lot bigger: it could then be put into a separate repository with its own version number. This would mean core library development wouldn't be slowed down by having to ensure all the charts are compatible with ever backwards-incompatible change.\nSo yes, a single version number seems best, at least for now.\n. Ah, I wondered why you did that for functions. I'm trying to keep to double quotes for D3, but old habits die hard :-)\n. Do you have any thoughts on the \"top\" and \"bottom\" orientations? My plan is to just use transform=\"rotate(90)\", if I do it right then maybe the transition will even rotate nicely!\n. Sounds fine to me.\n. Hmm, the transitions do seem to work fine at the moment though, I think because they only rely on the new scale, x1 due to no new data being added (aside from the first time round). The x0 scale is only used to create new enter() nodes. So this would only affect the case of adding a new item (e.g. a new measure) and because x0 defaults to a domain of [0, Infinity] it would always appear to transition from zero, rather than from the original scale.\nLet's say we fix this and use the original scale, and add a new measure that's out of bounds in the current scale, then it would immediately appear in the correct (out of bounds) location, and then transition along with the scale resizing to fit in the view box.  With the current behaviour it would transition from zero.  I'm not sure which behaviour is preferable, any thoughts?\nI've come up with a cache example that works, let me know if you want me to push it...\n. Ah, yes, much more obvious at 5000ms! Adding the cache does indeed fix the problem, see my commit ccdbccf5634e65a50928072a9b569419e4482926 above.\n. Looks good to me! I'm undecided on what to do about the chart state, I think the way it works now is good enough though. In some ways, pushing it into the element data seems more correct as it means there is flexibility for the user to set the scale range. In the original Protovis layout, it was exposed as a maximum property. I'll sleep on it, but feel free to merge into master if you want.\nThe only other things are supporting \"top\" and \"bottom\" orientations, and custom marker symbols, but I guess they can be added later too. It's been fun :-)\n. Okay, having slept on it, I do think I prefer storing the chart state in element data, but I think it would be cleaner to store it on an inner svg:g element rather than the outer one. I've implemented this, but I'm using .selectAll even though there's just a single inner svg:g element so that I can set the data. For some reason I couldn't get it to work using .select, maybe I'll have another go or you can give me a hint :-)\nLet me know what you think of using the inner node to store the state, I'm not too bothered but it does make the bullet-multiples example slightly nicer.\n. Awesome, I love the idea of transitioning between chart types!\n. Cool, thanks! I love collaborating in pull requests, it's really fun :-)\nI've started working on the vertical orientations, I'll let you know when it's ready. I'm experimenting with using a rotate transform. Ideally the top-down order should be preserved as left-right order, which means the charts will cross over each other during a transition. Not sure if that'll look good but we'll see.\n. Yeah I'd have to write some code in the example itself to reshuffle the text, so not ideal really. Hopefully using rotate will be simpler than lots of conditionals to switch between width/height and x/y for the chart itself though.\n. Nice fix :-) I think your suggestion sounds good, it's definitely less confusing.\n. Looks great, thanks! I was experimenting with a radial example and I was thinking the labels shouldn't be rotated more than 90\u00b0. That's the only modification I can think of; I think it's ready to merge aside from that.\n. Nice.  Such a helper could be useful in cartesian coordinates too though, maybe that'll help with the naming? :-)  It could have x and y properties to configure scales, but then maybe that's a bit much and it's sufficient to just do something like:\nd3.svg.curvyEdge().from(x0, y0).to(x1, y1)\n. Ah, yes.  I meant that the Cartesian equivalent could be useful e.g. http://bl.ocks.org/915098 for non-radial cases. As I understand it, this is a B\u00e9zier curve with control points at two opposite corners of a rectangle, with the other two corners being the start and end points. This rectangle can be transformed into part of a wedge (not sure what the proper name is for that) by interpreting x and y as r and \u03b8.\nBut you're right that passing in from/to coordinates aren't sufficient for that, it would need some kind of configurable scale(s) or transform that knows about the circle's centre to produce the actual Cartesian coordinates for the SVG path.\n. Ooh, smooth demo :-)  So we could have a helper that gets used like this:\n```\n// Cartesian\nvar p0 = [0, 0], p1 = [100, 100];\nd3.svg.edge().from(p0).to(p1);\n// Polar\nvar p0 = [0, 50], p1 = [45, 150];\nd3.svg.edge().projection(function(p) {\n    var a = (p[0] - 90) / 180 * Math.PI;\n    return [p[1] * Math.cos(a), p[1] * Math.sin(a)];\n}).from(p0).to(p1);\n```\nInternally it would call the projection function in a similar fashion to your demo:\nvar p0 = projection(from),\n    p1 = projection([from[0], (from[1] + to[1]) / 2]),\n    p2 = projection([to[0], (from[1] + to[1]) / 2]),\n    p3 = projection(to);\nThat can probably be cleaner but it's the general idea.  Would that work?  It might be better to just replace projection with cartesian as it's more descriptive.\nAlso, this would create the curve for a hierarchy in the y-axis direction, so the coordinates would need to be swapped for hierarchies in the x-axis direction.\n. Thanks, all updated.\n. Hmm, good points, I think requiring span elements isn't so bad really.  If people occasionally need text nodes it's easy enough to do anyway.  Let's ditch this one then.\n. Ah, very concise indeed!  See latest commit.  Outliers aren't actually displayed, but they're excluded from the quartile calculation.  I'm glad box plots are a bit more complex than I originally thought, it means a reusable D3 chart will be more useful :-)\nAnother thing to consider is that there isn't just one way to compute quartiles.  So I think this should also be a function, but it should return an array of data because I think the quartiles can be in between data.\n. 1. Yep, done!\n2. Yep, done!\n. Might be nice to replicate http://en.wikipedia.org/wiki/File:Michelsonmorley-boxplot.svg for the example. Need to find the original dataset.\n. Thanks, looks excellent! Transitions are certainly tricky, it's good to have these charts as best practice examples as well as being useful as charts.\n. The main ones to keep as == are comparisons with null where you also want them to treat undefined the same as null.\nIt's also worth noting that \"abc\" === new String(\"abc\") will return false, but I'm not sure anyone really uses new String.  Likewise for new Number.  For the sake of correctness perhaps we should keep == to compare any values from outside D3 e.g. an orient property?\n. I think it's worth getting a confirmation of how it would affect performance before continuing.  I found this but the Firefox and Safari results seem a bit counterintuitive.  Either the JIT does something special for non-strict comparisons and they didn't extend the same treatment to strict, or the JIT is compiling the non-strict comparison to a noop :-)  Will come up with a better benchmark when I get a chance.\n. Updated and fixed a bunch of issues (joining data on object identity works a lot better).  Looks like path interpolation is not straightforward, I'll leave it for a future project :-)  Thanks for the pointer about shape interpolation, looks interesting.\n. Updated, thanks for the excellent feedback once again.  I left the use of Object to your discretion as the other examples all seem to use function(d) { return d; }, which I agree is probably more readable.\n. Hmm, just noticed that the mousedown events don't work in Safari (5.0.5). Is there a way to solve it without using a filler <rect>?  The same problem seems to be present in examples/force/force-dynamic.html.\n. In my first attempt I just exposed d3_timer_step as d3.timer.step, but I think only allowing external \"flushing\" of the immediate queue is better.\n. Yeah, I agree it's cheap enough that charts themselves should flush the timer queue if appropriate.  Good call on avoiding overhead in the common case.\n. I thought it might be quite nice to perform the sequential insertions for each merge pair in parallel, so I've added a checkbox to turn this on.\n. Thanks! I've converted the demo on my site to use D3 now, but I need to work on the quicksort one to make it a fair comparison to merge sort. Watch this space\u2026\n. Yeah, perhaps now is the time to add a stats or data module that would contain the IQR stuff used by Q-Q plots too.\n. Sweet, I hadn't heard of Python's bisect until now. Sounds like a good idea.\nI think always returning an insertion point whether a value is found or not is clearer than pv.search's use of negative values, and shouldn't cause any issues.\n. Fantastic, looks great!\n. Looks good; one step closer towards #122!\n. Ah, sorry, I clearly didn't check that thoroughly enough!  Updated with a better implementation; manually tested in Chrome for both SVG and non-SVG elements.\n. Made the property check more precise and added element.classList support.\n. Cool, updated. I've reused the c from the classList check to make this.className[.baseVal] even simpler.\n. It would be nice to unit test the fallbacks too for these kinds of things. I tried delete Object.keys but Node.js relies on it for require().  Perhaps unit tests should have access to the internal namespace so they could test something like d3_keys_fallback, or maybe it's not worth the hassle.\n. Yes, I agree that it's confusing!  As I understand it, the reason they recommend checking hasOwnProperty is in case a third-party framework has added properties to Object.prototype (I think Prototype.js does this) -- you probably know about this already though.  I guess most people will use a .keys() operator for simple hashtable-like objects like {a: 1, b: 2} so they might get confused if additional keys appear in there.  Underscore.js has a similar implementation that excludes the prototype chain.\nUltimately I guess people can just not use a third-party library that messes with Object.prototype.  What do you think?\n. Ah, cool, thanks for the clarification.  I'm happy for this to be closed then, it's a shame we can't use Object.keys but like you say it's easy enough for people to use it if they really want, and adding a comment to d3.keys should help people out in the rare case of other code dangerously modifying Object.prototype.\n. Wow, yeah. It's a bit better in Chrome 12.0.X it seems, but still over 50% slower.\n. Okay, prototype version added.\n. It's a pleasure :-)  Plenty more still to come :-)\n. Very nice!\n. Sorry, I forgot the example relied on d3.layout.histogram when separating out the commit. Looks like you've spotted this already though!\n. Following Python's example sounds sensible.  I've added d3.sum and d3.stats.median too now.\n. Added some more tests and fixed d3.stats.quantiles.\n. Yeah, the implementation of d3.stats.quantiles is slightly different in that it uses linear interpolation for in-between quantiles like R's default quantile algorithm (type=7).  Perhaps we could update d3.scale.quantile to use this algorithm instead?\nAlso, d3.scale.quantile().domain(d).range(quantiles).thresholds() doesn't seem to include the first and last quantiles, if it tracked these as well then we could reuse it.\n. That sounds cool, I'd be up for starting a new library.  I had a look at atoll.js, which looks useful but I guess I'd like to write my own library with more of a D3-inspired coding and API style.  Now I just need to think of a name, which of course is the hardest part.  Any ideas?  :-)  So far I've come up with \"s8s.js\", which is short for \"statistics.js\", but I'm not sure it rolls off the tongue.\n. I've called this science.js for now, as I haven't come up with anything better yet!\n. Maybe d3.svg.touch with a similar implementation would be better?\n. Okay, multitouch support added!\n. Hehe, okay. Yeah, I thought it would be important to be as fast as possible for touchmove events, but actually I think the performance difference is negligible (we're talking microseconds) for a loop vs. using map.\n. Done! You can see it in action at http://www.jasondavies.com/poincare-disc/.\n. Yes, I probably got a bit carried away when doing all of those. :)  I think you're right that more thought needs to be put into making examples work well in iOS e.g. making sure the touchable regions are large enough and so on.  I've only tested in a simulator so I don't have a clear idea of how each example actually performs.\n. You're welcome sir :-)\nI did see a somewhat complicated explanation of how Python chooses between e and f for g, but as far as I can tell it's the same as JavaScript's Number.toPrecision, which mainly uses e aside from limited cases where the exponent is between -4 and precision.\nMaybe we need to invent a new type for significant digits that are always formatted with f?\n. I like it.\n. Wow, looks really good, thanks!  Yep, I think it's good to go.  Transitioning the number of bands can always be done later :)\n. Very nice indeed :)\n. Cool, that's fine with me!  Re touches being misinterpreted as scrolling, I've noticed this when testing on a friend's iPad, and I wonder whether it can always be solved by appropriate use of event.preventDefault() e.g. see Safari Developer Library - Handling Events (scroll down to \"Preventing Default Behavior\").  Having large enough node areas in the force layout would also help alleviate this.\n. Aha, a thick white stroke is a good idea!  Sankey diagrams do look very related, I'm sure there's something we can reuse there.\nI found some more inspiration here, and took this opportunity to try out GitHub's image embedding!\nIt seems some are based on varying widths of actual arrows, that turn 90\u00b0 to give extra space for labelling.  Others are more like Vadim's and GitHub's impact chart.  And wow, that energy conversion chart is epic!  That one looks very much like the impact chart.\nSankey Diagram Generator (with Processing code):\n\nSankeyR:\n\ndrawSankey.m:\n\nSimSankey:\n\n. D'oh, sorry about that, looks like I misread the description about truncation, and it should be j < n in the inner loop instead of j < length. That's what happens when coding without coffee in the morning :-)\n. Hehe. Yes, that could taste interesting :-)\n. Okay, updated with fixes and better unit tests. I wasn't sure if you were already fixing it or not, but here it is anyway :-)\n. Yeah, it does it for us. It's just a style thing really so not important.\n. Agreed, I think this should really be an optional extra as you can achieve exactly the same effect by decomposing manually (well, I think most mortals will think of the decomposed form first before converting to a single matrix!).  Including the matrix stuff by default does indeed seem a bit heavy.  It was fun to write though, I hope someone will find it useful :-)\nI'm thinking I could write an example that allows you to specify the target transform's constituent parts using sliders, and then apply this at the click of a button to a simple box containing some text.  Or perhaps just allowing the matrix to be specified is sufficient?\n. Should d3.{matrix,vector} be renamed to d3.geom.{matrix,vector}, or just be included as they are in d3.geom.js?\n. Done!  d3.vector is now required if d3.interpolate is called on an attribute value containing matrix3d(...).  Perhaps I should add a check for d3.vector to prevent an error if it's not loaded?\n. Ah, awesome, I'll give it a shot, thanks :)\n. Okay, done!\n. Sounds good. Watch this space. :)\n. I must admit, I hadn't really thought about a real use case for this until now.  I just thought it would be fun to implement. :)  Is there really any need for this seeing as people can just interpolate a manually decomposed transform already?  All this really does is decompose matrix3d(\u2026) and then interpolate the decomposed parts individually.\nIn any case I've created a really basic example and fixed a bug.  Ideally I'd like to create a more extensive example that allows all the various 3D operations to be configured.\n. Great, thanks! I've added transitions and wrapped the input data now as you suggested. Hopefully didn't interfere with your weekend plans too much :-)\n. Use treemap.mode(\"slice-dice\"), added in version 3.\n. Loving it!  Just fixed a minor bug by the way: tickFormat was being used instead of format for the data join in d3.chart.axis so it wasn't working for a null tickFormat.  I've also converted d3.chart.bullet to use it now.  Looks great :)\n. Yeah, for me the concept of \"join\" implies unique keys so I'm not sure about the utility of #167.\nI like the idea of subdivided ticks.  It'll be interesting to make them work nicely for log scales.\nJust fixed a silly bug in d3.chart.radar: .variables(x) wasn't setting for non-null x, oops.\n. The main thing remaining for the radar chart is polar-coordinate transitions for paths.  Would this be a good candidate for data-space interpolation?  Finally a use-case for #142 perhaps, for retrieving the old data?\n. Good stuff, thanks!  I will have a think about all of the above :)\n. Yep, reusable bar chart next so I'll have to tackle ordinals for that. :)\nMy original motivation was due to copying and pasting the ticks code between charts and hardly having to change it, so if we end up keeping it private for now it'll still save a lot of duplication.\nThe Archimedean spiral idea sounds cool, there's some Protovis code to make one here but I'm not sure that's the one you meant.\n. Ah, awesome. :)\n. Sweet!  I've now implemented a very basic bar chart along with support for ordinal scales.  At the moment there's a bit of a hack that detects if an ordinal scale is in use and shifts the tick positions along by rangeBand / 2.  \"Sectional\" looks like it could be useful for bar charts but I guess one might still want to have ticks at the centre of bars.\n. I like the idea of a separate d3.chart.grid component, but if layering is the only reason maybe it would be better to use .enter().insert(\u2026) to control layering.  So .enter().insert() would be used for the grid, and .enter().append() for axes.\n. Yep.  Slightly alternative approach to achieve this: perhaps the user should insert their content in a single <g> to avoid issues if they then append further elements after the axes' elements; I suppose an instance of d3.chart.axis could provide such a <g> element?\n. Something like:\njavascript\ng = g.map(d3.chart.axis());\ng.selectAll(\u2026).data(\u2026).append(\u2026)\nIf it was a separate grid component it would be a similar approach I guess, just a couple more lines:\njavascript\ng.call(d3.chart.grid());\nvar layer = g.select(\"g.layer\");\n// append a single <g> here for actual chart rendering\nlayer = layer.empty() ? g.append(\"g\").attr(\"class\", \"layer\") : layer;\n// Do stuff with layer\ng.call(d3.chart.axis());\n. Do you think we should have an extensible way to configure chart axes rather than rebinding a whole load of properties? e.g.\njavascript\nd3.chart.qq().xAxis().mode(\"closed\");\nAlternatively we could require axes to be added separately from charts.  Of course, they can be used separately anyway at the moment, but we could do something like:\njavascript\ng.call(d3.chart.qq());\ng.call(d3.chart.axis().bind(\"x\").orient(\"bottom\"));\ng.call(d3.chart.axis().bind(\"y\").orient(\"left\"));\nThe idea is that bind binds an axis to a particular scale, stashed in __chart__.  For the layering issue, we could always prepend grids and append axes, and perhaps all charts should create their own <g> element in case of interleaving issues.\nActually, for the bind idea to work we'd need to stash both exiting and entering scales in __chart__, so maybe there's an alternative way of doing this.  Perhaps arbitrary axes could be added to a chart, something like:\njavascript\ng.call(d3.chart.qq()\n    .axis(\"x\", d3.chart.axis().orient(\"bottom\"))\n    .axis(\"x\", d3.chart.axis().orient(\"top\"))\n    .axis(\"y\", d3.chart.axis().orient(\"left\"))\n    .axis(\"y\", d3.chart.axis().orient(\"right\")));\n. Wow, smooth! :-)\n. Do you think we need a delay parameter for most charts too, to go with duration?\nFor symbols, colours and sizes, I'm torn between having to add quite a few functions to specify this kind of thing, and just allowing the user to reselect elements.  Perhaps it's okay for the scatter chart to have quite a few functions though, as it's probably one of the more customisable of the charts.  The Mekko chart, by contrast, won't have as many things to customise.\n. Added d3.scale.log().nice() too!  Also fixed a bug in the Protovis implementation for a descending domain.  Hurrah for tests.\n. Done!  Unfortunately we can't just rebind the linear scale's nice for pow scales either as this leads to a fractional pow domain in most cases.  I just used a similar implementation to the log scale and it seems to work fine.\n. Okay, tests updated to be more compact, over to you. :)\n. Sounds great.  I'm quite interested in the function form too, as I think it could simplify code that needs to switch between orientations.\n. This looks like a nice time-saver. I was wondering if the exit selection needed to be considered too e.g. if you want to transition exiting nodes to a new scale before removing them?  This might be too confusing though.\nI don't think this is backwards-incompatible, strictly speaking, as existing code should still work as before, unless someone is doing something strange like affecting external state by passing functions to attr etc.\n. That makes sense.  I'm definitely in favour of this change, I've even started anticipating it by reselecting after appending to the enter selection, so I can set attributes on both enter and update at once!\n. Woop, 2.0!\n. Wow, love the colour-by-area! That sounds sensible; do you want me to move d3.ai.boid to the examples directory for now then?\n. Yes, all of the above sounds great!  I'm warming more to the .radial helpers now, I think it'll make code more readable especially as people start making more radial visualisations.\n. Yes, I was thinking it would be nice to make it layout-independent too. Turns out it was pretty simple to do if we assume the bundle layout takes hierarchical data returned from any hierarchical layout. I've added a treemap example and it seems to work. The radial ones look nicer though. :-)\n. I'm probably missing something, but isn't it possible to project a layout that uses x from 0 to max onto a new scale, min to max, likewise for y?  I suppose you could argue you don't even need size because you can project 0 to 1 onto any scale, so I guess this is more of a convenience than being absolutely necessary?\n. Sweet!  I found a polynomial-based approximation to sin/cos and this makes it a lot faster.  We don't need high precision so maybe we should expose a similar approximation for anyone using radial layouts, just something like d3.fast{Sin,Cos}?\n. This is potentially a better source for an approximation, I will read it thoroughly and report back when I get a chance: http://www.coranac.com/2009/07/sines/.\n. Actually I'm not convinced this approximation is that much faster than the standard functions, benchmarking doesn't show that much of an improvement, so I take back my comment above that it's \"a lot\" faster. :-)  I think I was being misled because Safari doesn't fire the mousemove event if the mouse is over a path (fill area as well as stroke) so it felt jittery.\nI've reverted the sin/cos approximation (we can explore that separately if needed) and added the mousemove listener to window instead, which seems to work better in Safari.  It also makes it continue to respond if you quickly move the mouse away from the area.\n. Cool. I must admit, I don't mind having to use sin and cos, but it does mean one less thing to think about!\n. I like the idea of replacing beta with straightness (or straighten).  A bit longer than beta but a lot more descriptive!\n. Ooh, nice!\n. Not sure how to handle polylinear scales.  How should a given number of ticks be distributed between subscales?\n. Ah, I must have misunderstood #185.  When you said \"the domain could be inverted\" I thought you meant we need to support descending ticks. :-)\n. Hehe. Thanks. :)\n. Note: it turns out the argument.length check only causes the bailout here because k (the argument) is reassigned in the same function.  The bailout trace for V8 says:\n\nassignment to parameter, function uses arguments object\n. Hehe. Nothing that directly benefits (yet!). I was reading through http://s3.mrale.ph/nodecamp.eu/ and was trying out a few things using V8's --trace-opt and --trace-bailout.  I think I picked d3.geom to look at first as I imagined it would contain the most intensive calculations.  To my disappointment, everything's already pretty optimised.  :-)\n\nThat suggestion looks good, I'll have to try out some more benchmarks and get back to you.\n. Yep, I think I checked this one again more recently and couldn't see much of a performance difference; perhaps V8 has improved their JIT since then.\n. Sounds good to me!  I've pushed a couple more commits that implement this.\nWhat's the best way to add collision detection for the Dorling cartogram?  The Protovis version uses Gauss-Seidel with a collision constraint.  Is there a way to reuse the Gauss-Seidel relaxation being performed by the force layout, or should it just be done separately?\n. Maybe we just need a configurable list of constraint functions, that get called in the same way as repulse?\njavascript\n// apply charge forces\nvar kc = alpha * charge;\ni = -1; while (++i < n) {\n  q.visit(repulse(nodes[i], kc));\n}\n. Cool.  Actually I think this Protovis version does use links, which is why I've already gone to the effort of creating a JSON data file of U.S. states mapped to respective borders.  But if I don't need it, that's even better :)  The problem with only using variable-length links is of course that the circles may overlap a bit depending on the data, unless you set a scale specially so they never overlap.\nI've just pushed the initial version of this, which uses variable-length links.\nNext, collision detection!\n. Re configurable constraints, I did experiment just now with a configurable repulse property, whereby if you wanted to customise it you could do something like:\njavascript\nvar repulse = force.repulse();\nforce.repulse(function(node, kc) {\n  var r = repulse(node, kc);\n  return function(quad, x1, y1, x2, y2) {\n    r(quad, x1, y1, x2, y2);\n    // Do other constraint stuff\u2026\n  };\n});\nBut I think that might be a bit confusing.  I'll just leave out the quadtree and do the collision detection in the tick handler for now.\n. Cool, it worked! :)\n. By the way, I appreciated the reference to Wales in your example. :)\n. I've added a Demers cartogram too now, but for some reason it hasn't shown up on GitHub, it might be a caching issue with their Web interface.\n. Oops, thanks for spotting the self-collisions.  Positive charge does work nicely but I feel that centroid gravity would be more accurate, particularly if the same layout is reused for other data like in the Protovis example.  I'll have a go at adding per-node gravity now.\n. I opted to add variable gravity centers rather than arbitrary per-node gravities, what do you think?\n. Agreed, it's actually just a couple of extra lines to add gravity in the \"tick\" handler.  I'm not sure if I'm missing something though, as I had to turn the gravity down quite a bit to stop the circles overlapping.\n. Is it worth adding some tests for this kind of thing?\n. Your new axis branch looks great!  I guess we should figure out how to share scale state first before adding transitions as they go hand-in-hand.\nI feel like the problem of scale state is somewhat analogous to data binding because they are inherently linked.  Whenever new data is bound, that's the point at which the scale state may also change.\nSo, similar to __data__ for data binding, I think storing the scale state in a (parent) node using __chart__ is the analogous approach (as we've done in other axis branches).  The scale state consists of the old scales (if any) and current ones (to be transitioned to).\nI think each chart should have a documented set of named scales that it uses.  For example, a scatter plot would have \"x\" and \"y\" scales.\nIt would be great if an axis instance could be \"bound\" to a particular named scale (as well as being unbound and used separately).  Binding to a named scale would just mean it looks for __chart__ for the old and current scale whenever it is passed to call() on a selection.\nAlso, it would be useful if there was a lightweight API for overriding a particular named scale for any chart.  For example, today when using the horizon chart, I realised there was no way to set a consistent x-scale for multiples of the same chart.  Of course, this could be exposed via separate properties for each chart, but it might be simpler to simply reuse a single .scale(<name>, <scale>) property for all/most charts.  This would stash the scale and set a flag so the chart knows it shouldn't compute its own new scale.\nSo I guess I'm proposing that axes be added to charts separately and we no longer instantiate axes inside charts.  This seems clearer to understand, and easier from an API point of view, as charts don't all need a whole bunch of axis-related properties.  Especially when using multiples, axes tend to be added separately anyway and so having greater control over positioning would be advantageous.\nOh yeah, and layering of grid/axes is an issue, but I think we can get round it by using insert and/or mandating that charts group their plots inside a child <g>?\n. I forgot to mention, I'm assuming that if you haven't overridden any scales, then a particular chart will be responsible for computing any new scales and stashing them, so you would need to call() the chart first before any axes.\nI guess each particular axis should have its own state too, as well as the chart, otherwise it won't know whether a transition to the new scale has taken place or not.  So calling the axis would make it transition from its current scale to the parent chart's current scale, if they differ.\n. Cool, thanks for the quick reply! Scale cloning sounds useful. I see what you mean about rubber stamps vs. separate chart instances. I guess the latter does solve the state issue in a simpler way, so it's worth considering. I do like D3's transformation approach though so it would be nice to keep for charts too if appropriate. I'll let you know when I have something to show.\n. All done, thanks!\n. Seeing a problem when the padding is larger than the available area e.g. try setting padding to 50 in the example SVG treemap I just added, and you'll notice a couple of floating rectangles.\n. It works!\nCSSStyleDeclaration's setProperty requires strings. Patching\u2026\nCSSStyleDeclaration's setProperty now coerces strings. Hooray!\n. I've seen the \"null\" issue occur in other browsers too; it's due to using .transition().style(null).\n. I think there are two issues causing this:\n1. Interpolating from a string to null coerces null to \"null\".\n2. transition().style() calls this.style.setProperty(), even for a value of null.\nIn IE9 specifically, it will complain if you set an invalid style e.g. \"null\". Other browsers will just ignore it.\n. Fixed: #331.\n. Yeah. Bah. :( How about bundling d3.behavior into d3.js? It's ~2kb minified, do you think it'll get much bigger than that?\n. Eek, sorry about that, thanks for fixing it!\n. Cool. I'm attempting to use node-jscoverage (with vows) to get a coverage report.  It's already discovered some invalid octal constants. :D\n. I got partway through writing some tests for this, but JSDOM doesn't yet support SVG's createSVGPoint: tmpvar/jsdom#300 and I had to fix an issue with events not bubbling to the parent window: tmpvar/jsdom#301.\n. Haha. :)\n. Actually, this might be cleaner if it was a little node.js script that dumped some JSON, rather than relying on sed, seeing as it uses node.js to grab the version number anyway.\n. Oh right, sorry for the noise in that case. I'm not sure if it breaks it, but it warns about it. I'll report back when I get a chance.\n. Okay, it doesn't break it, so you can ignore this! Coverage for 2.0.0: http://www.jasondavies.com/tmp/coverage.html\n. The number of lines changed is not indicative of the time spent solving this one! :)\n. Great idea, done!\nI'll see how easy it is to add an intelligent n, I think that would be pretty useful and probably not too hard to get a rough value for a given resolution/precision.\n. Sure, done!\n. I did some work on this about a month ago: https://github.com/jasondavies/d3/tree/map.  In @ba2b1537a18762d8ef4147c27ef3104d622ddc2e I didn't get round to adding tests, that's the next step for transition.attr.  Almost there!\n. Test for residual floating point error added.\n. Thanks!  I found those numbers by trying random numbers until the error occurred, but I agree that the assertions should check for isNaN to make it clear what's being tested. I've updated the test and added a test for coincident circles (for non-zero nodes only): #300.\n. More tests added and bugs fixed.\n. Note: I've added hierarchy.nodes because I think d3_layout_hierarchyInline was not always set depending on the order in which the tests were run.\n. Currently the partition tests use the old API, but the equality tests are only performed on the positional metadata so I don't think it makes a difference whether inlining is turned on or not.  Still, I'll update them to use the new API for consistency.\n. I think it's safe to remove hierarchy.nodes now as the cluster test turns on inlining and it always seems to load before the hierarchy test.\nStrictly speaking we can't guarantee the loading order as the tests are loaded asynchronously, but if we are going to remove the deprecated code anyway at some point I think it's fine.\n. We could potentially call this mode \"centrographic\" instead. This would be more consistent with the other mode names. \"Azimuthal centrographic\" is an alternative name for gnomonic, and is a bit more descriptive.\n. On the other hand, \"gnomonic\" is the more common name for this.\n. It is indeed due to drawing the entire unclipped world. It looks great when clipped to a hemisphere! I'm working on a configurable (input) clipping function for d3.geo.path with built-in support for hemispheres, watch this space!\n. Okay, done!  It could probably do with some cleanup and optimisation, but at least you can see it working.\nSpecifically, I think we could just perform simplistic radial clipping (no insertion of great circles), and then make it easy to transform an arbitrary polygon into a polygon consisting of great circles.  This prevents the situation where you may have a very long polygon edge, which turns into a great circle if clipped, but remains a naive straight line if not clipped.\nIn fact, great circles are straight lines in the gnomonic projection anyway, so the great circles step doesn't even need to be done there.\n. Apologies for introducing a backwards-incompatible change here: I've dropped source/target for d3.geo.greatCircle in favour of processing an array of coordinates all at once.  I initially added this as d3.geo.greatCircle.polyline, but it seemed cleaner like this.  I can add source/target/polyline back in if you want to avoid another major version bump right now.\n. Okay, backwards compatibility reinstated.\n. Oops, need to reinstate greatCircle.n too.  I guess I should ignore it if precision is set, and vice versa.\n. Reinstated.\n. Hurrah, glad you like it! :)\n. Some things I'd still like to add:\n- Make the clipping return multiple subpaths instead of just one.  This will be powerful when combined with the cylindrical type of clipping (e.g. international date line) - so you could clip a straight line crossing the boundary and you would get two subpaths.\n- Related to the previous point: add other common clipping types, maybe just cylindrical is enough.\n- Make sure this plays nice with GeoJSON's MultiPolygon i.e. it doesn't mess up \"holes\".\n- More unit tests!\n. Thanks for taking the time to look into this!\nYes, I stuck with degrees because of the \"geo\" context and latitudes/longitudes being in degrees.  It seemed more intuitive as I was thinking of adding rectangular clipping too, which would ideally take longitudes and latitudes as parameters.  This is why I'd prefer to keep d3.geo.clip if possible, for the rectangular case.  The specific use case I'm thinking of is the ability to \"clip\" at the international date line, so that polylines get split into two subpaths.  Admittedly it's like using a sledgehammer for this particular case, but I think it can be done with the same code without too many changes.\nRe the API surface area: I do see your point, and I've wondered whether this could be rewritten to be more generic and live in d3.geom.  For example, it would be quite cool to take an arbitrary clip function (that returns a boolean) and intersection function.  When I fix this to return multiple subpaths, it'll essentially be a form of Weiler\u2013Atherton, which can handle holes (unlike Sutherland-Hodgman).\nYou're right about the great circle clipping only being correct for a 90\u00b0 angle.  I think it shouldn't be too difficult to extend d3.geo.greatCircle to handle small circles, and great circles as a special case.  In this case I agree d3.geo.circle would be appropriate.  I think small circle clipping is useful because many polar aspect projections seem to clip at some angle below 90\u00b0.  Sadly this means I can no longer just apply d3.geo.greatCircle to the resulting clipped polygons: I have to apply the small circle to the edge separately, probably as part of the clipping operation.\nThere did seem to be a boundary condition that occurred at 90\u00b0 for the gnomonic projection, although it could be an issue with the projection and/or clipping that I need to fix.\n. That makes a lot of sense, thanks.  It would be pretty cool to clip on something like a MultiPolygon, I think Weiler\u2013Atherton could certainly handle it although it might be extra work to handle holes properly.\n. Ooh! I'm already about half-way through, but don't let that stop you if you have the time and inclination. I had to figure out the intersection stuff for small circles, which took some time, and now I'm back to Weiler\u2013Atherton. Now that I've moved it to d3.geo.circle, I can see some of this being exposed as API functionality too if you think it's worth it e.g. circle.intersect and so on.\n. I'm fine with that as long as we don't mind clip being upgraded to return multiple polygons in the future.  Maybe we could future-proof it by making it return a single-element array containing the clipped polygon for now?\n. I'm guessing you're asleep by now, but the confusion is probably due to the naming.  I have d3.geo.path().clip, which performs a generic transformation on polygons (in the upcoming version it will transform an array of polygons at a time).  So \"clip\" is a bit of a misnomer, because you can pass an interpolation function like d3.geo.greatCircle().polyline to it.\nNow, d3.geo.greatCircle().coordinates is just an accessor for producing the interpolation along great circle arcs.  So if we make this the clip function, what's happening when we wire them together is:\n1. d3.geo.path() goes through each GeoJSON feature, and passes each polygon to our custom greatCircle.polyline function.\n2. Our greatCircle.polyline's accessor is our geo clipping function, so the polyline essentially performs clipping first using this, and then does its interpolation.\n. Cool, thanks for the refactoring!  I am reviewing over coffee now. :)\n. > It isn't necessary to create great arcs between coordinates that will not be clipped, though, correct?\nI was interested in performing great arc interpolation on unclipped features to make the projections more accurate.  Admittedly, due to the precision setting and size of the features, it doesn't make that much difference for most of them.  However, I thought it was elegant to be able to perform clipping separately e.g. resulting in some number of points along the great circle boundary, and then I could apply great arc interpolation to the entire thing and it would magically fix these boundaries.\nAs you rightly pointed out though, this isn't correct for small circle clipping, so I'm now doing the correct interpolation in the clip algorithm.\nIn the gnomonic projection, which is what started this off, all great arcs are straight lines, so interpolation on unclipped features doesn't need to happen (hence I turned it off when gnomonic was selected in the example).\n\nOr is it possible that even though neither of two adjacent coordinates are clipped, the points in-between would be clipped, and so we must first create the great arcs and then perform clipping.\n\nI don't think this is possible when clipping against great/small circles.  (And now you've realised that I perform the arc interpolation after clipping anyway!)  However, I've come across a situation where two adjacent points are outside the clip circle, but the great arc connecting them intersects with the clip circle.  My new code handles this case properly, whereas I don't think the old code did.\nSome thoughts on your refactoring branch:\n1. I'd prefer to put circle clipping in d3.geo.circle and just keep d3.geo.greatCircle for backwards compatibility, and then expose the radius parameter when we add small circles support. We can simply set the radius to 90\u00b0 to start with and just say that only great circles are supported for the moment.\n2. I like the idea of handling arbitrary GeoJSON features.  For clipping, this means we can distinguish between polylines and polygons: for the former we don't need to insert interpolated segments along the clip boundary.  It's possible to detect polygons by checking whether the first and last coordinates are equal, but strictly speaking a polyline could have this e.g. imagine a flight path that visits various points on the globe and then ends up where it started!  For great arc interpolation, I'm not sure GeoJSON support is necessary, but perhaps it would be more consistent to support it.  Or alternatively a helper could be used to perform arbitrary interpolation on a set of GeoJSON features.\n3. I like the separation of clipping from d3.geo.path.  This gets around my future-proofing request nicely!\n. By new code, I mean the small circle + Weiler\u2013Atherton clipping that I've been working on over the weekend, and haven't pushed yet.  Instead of resampling entire polygons, I only insert interpolated small circle segments at the intersection points.\nI envisage whole-feature great arc resampling as being a separate operation that will most likely only be used for custom features like flight paths and so on, as the majority of geographic features seem to have a high enough precision already.\nI agree there's probably no need to optimise for gnomonic, so even when clipping against a great circle I'll continue to interpolate the appropriate great arcs.\nI like the greatCircle alias idea.\nI've come across a whole host of various geo operations that could be useful e.g. calculations of rhumb lines and so on, but I think these can wait for another time. :)\n. Cool. :)  In that case I'm happy with the clipping API if we rename to d3.geo.circle and alias as d3.geo.greatCircle, and I assume you're happy for resampling to be removed in a future version.\nWe should also set the radius to 90\u00b0 instead of 89\u00b0 so that it's a true great circle by default.  The issue with gnomonic is that points at 90\u00b0 should be at infinity but the calculation becomes unstable at this point, so you tend to get a huge polygon filling the viewport.\nBasically, gnomonic should be clipped at some radius smaller than 90\u00b0, otherwise it goes crazy, so I suggest we remove it from the example for this release.\nLastly, I noticed warnings in the console about d=\"null\" when transitioning to any projection.  Presumably this occurs when attempting to transition to .attr(\"d\", null).\n. Ah, just noticed you pushed the d3.geo.circle update.  I guess the 89\u00b0/90\u00b0 discrepancy won't hurt, and it's nice to show off the gnomonic projection!\n. In case it wasn't clear, d3.selectAll(\u2026).sort(\u2026) doesn't work at the moment in Chrome, and probably most other browsers too.  I don't like having the array conversion in selectAll, so I'm curious to hear your thoughts on the best approach.\n. Related: I also spotted an issue with JSDOM: tmpvar/jsdom#313 with the use of insertBefore, but I couldn't reproduce it in WebKit, Firefox or Opera so I think it's a JSDOM bug.\n. Array.prototype.sort.call(nodeList, comparator) doesn't actually work in browsers, unfortunately.\nI guess if it turns out there is a performance benefit to avoiding premature slicing, we can always lazily convert, but I agree it's not ideal to have an inconsistency like this, so I'm probably in favour of switching back to arrays unless benchmarks say otherwise.\nI think the sort operator is indeed the only place that relies on array extras at the moment.\n. Yep, correct.  I've just checked and Array.prototype.slice doesn't work on NodeList in IE9, so I think we'd need to bring back d3_array.\n. Ooh, parallel coordinates, cool!\n- I wonder if this would be easy to add if we just add extents support to d3.behavior.drag?  In fact, perhaps d3.behavior.drag should have a simple flag that makes it limit dragging to the bounding box of its parent element?  It already computes positions relative to this.parentNode, so it seems reasonable to use getBBox, although it seems a bit too SVG-specific (even though we already rely on d3.svg.mouse).\n- That would be nice!  Is there a simple way to define the thumb region?  How about relying on the stroked region, and have stroke-opacity set to 0?  I think the cursor could be set dynamically.  If not, we probably need 8 separate paths for a fully resizable rectangle.  If a stroked border is required, we could always have two rectangles inside an svg:g, with the second defining the visible border.  Again, we could rely on getBBox to know which type of drag handle is being clicked.\nI'd definitely be up for d3.svg.selector if it makes things simpler, as I think the vast majority of use cases only need a draggable/resizable rectangle anyway.  This could handle things like setting the cursor dynamically.  I guess there are only really three possible modes: horizontal, vertical and both?\n. Nice! We also probably want a \"move\" cursor for the selection itself.\n. Cool! Unfortunately, at least for me, the cursor flickers between the move, resize and crosshair cursors when dragging (presumably due to latency in updating the rectangle position).  But maybe we can worry about that afterwards!\nThe ability to set the selection might be a neat way to solve the extents issue.  If a position is outside the range, simply clamp it and reset the selection to the clamped position.\n. Ah cool, you're using the scale extents to clamp the selection.\n. Wow, I love it!\n. This is awesome. The faded grid lines in the SPLOM are a nice touch! I'd love to make the dimensions draggable in the parallel coordinates example, what do you think?\nI haven't come up with any particular design issues yet.  I've been thinking we should have something like d3.extent for a while, so that's also nice!  I might submit a pull request for a more efficient (single loop) implementation when I get a chance.\nWe should also modify the zoom example to use d3.svg.brush.\nGreat stuff!\n. Single-loop extent almost done - just need to add tests.\nYes, I must admit I had a go at doing the SPLOM myself before you beat me to it, but I got distracted trying to figure out whether performance could be improved e.g. using d3.timer instead of updating all elements on every mousemove event.  Performance is not actually an issue right now, but perhaps on larger datasets it would be useful to know the best approach.\nI see what you mean about the listeners.  How about only firing a brush event if the extent changes?  I think that would get around the infinite looping issue.\n. Yes, it is a bit weird.  I suppose it makes sense if you think about it in terms of ignoring deleted array elements.  I'm happy with being locally consistent though, and haven't had any issues with this personally.  On the other hand, people might end up thinking Array.map uses the \"D3 way\" if we don't ignore elements.  I'm thinking more of your [,] shortcut - I wonder if that could cause difficult-to-debug issues if it ends up being passed to Array.map?\n. We can add tests for this once this is merged: tmpvar/jsdom#301.\n. The problem is that the browser only fires a click event if mousedown and mouseup occur on the same element.  So if you have a mousedown occurring on one element, and then mouseup on another, no click event is fired.  This could happen in a number of ways e.g. if you clamped the dragged element and mouseup occurred outside the clamp region.\nWe had mistakenly assumed that a click event is always fired after mousedown + mouseup, so we always cancelled the next click event.  In the original bug report, the OP found that he had to double-click on links after dragging a different element, because the next click was always being cancelled.  We only want to cancel the click if it is actually going to be fired as a result of the mousedown + mouseup combination, which isn't always the case.\n. Here is a reference to the click/mouseup/mousedown situation, in case someone needs it in future!\n\nclick: Fires when a mousedown and mouseup event occur on the same element.\n\nFrom http://www.quirksmode.org/dom/events/click.html.\n. I don't think this projects onto the unit [0, 1] square at the moment, I'll need to tweak it a bit.\n. Hmm, albers and azimuthal both don't project within the unit square at the moment, do I need to worry about this?\n. Ah, thanks. Will push a fix in a minute.\n. Cool, I assume y1 is the parallel?  Looks good to me.\n. I've added d3.geo.rotate now, for good measure.  I think we could make it more efficient by special-casing z-axis rotations, which only need a longitudinal add/subtract.\nIn general this will let us do cool things like transverse and oblique versions of any projection, without having to add complicated formulas to each projection.\n. Yes, that's the intention! This should hopefully lead to some awesome demos e.g. transitioning between North/South pole projections. There is of course an overlap here because some projections already allow an arbitrary origin, for example the azimuthal ones, although that's only two dimensions and this provides the third one.  The reason I made the bonne projection use this internally is because I felt it was a bug to ignore the y-origin completely, and I wanted to keep the origin parameter for backwards compatibility.\nI'm open to suggestions about making it easier to use, for instance I think it might be confusing that the order of setting x, y and z angles matters here because setting each angle performs a rotation about an axis, and such rotations don't commute.\n. I've called it d3.geo.zoom in my working copy, to match d3.behavior.zoom. Open to suggestions. :)\n. I like the convenience constructor idea.  In fact, we could just have that for now, and if we need to we can add support for a full matrix-based transform in the future.  Would it be sensible to reverse the order of the arguments i.e. z, y, x, so that you could do d3.geo.rotate(180, -90) for the equivalent to .origin([-180, 90])?\nEdit: fixed sign of rotation arguments. :)\n. Okay, I've refactored d3.geo.rotate, and added d3.geo.zoom.\n. 1. I didn't immediately simplify those projections because I thought they might be slightly more efficient as they are.  I'm happy to simplify them but it might be worth doing a quick benchmark to make sure.\n2. I do check for zero arguments in d3.geo.rotate, but not for all-zero angles. I will update.\n. Yes, that could work.  I guess cylindrical.parallels should be hidden in that case?\nI guess I was hoping that cylindrical and conic projections could be more or less unified, but as you suggested earlier I think we may end up keeping the cylindrical code in d3.geo.cylindrical for simplicity, and simply make d3.geo.conic use d3.geo.cylindrical in the case where the parallels are equidistant from the equator.  So having a slightly different name for setting a single parallel in the cylindrical case makes perfect sense.\nIt turns out the conic code has a lot of n ? checks when I made it handle cylindrical too, because the maths didn't simplify as much as I'd hoped!\n. I've fixed the error in that example for now, and merged with master due to the UglifyJS update.\n. Agreed, I was thinking the same myself particularly as I have a few even more esoteric ones that I'd like to add!  I have a couple of more generic functions e.g. Ramer\u2013Douglas\u2013Peucker line simplification, which may or may not be suitable for core.  Still working on the old Weiler\u2013Atherton clipping, of course\u2026 ;)\nI feel like azimuthal is the most useful of these other projections e.g. for polar views, but I'm happy to move it elsewhere.\n. [Strange, I didn't get a notification for this.]\nI'd be up for that, I'm loving the new d3.geo.projection plugin!\nMy new clipping algorithm should correctly handle splitting of features after rotation. I haven't extended the implementation to handle non-circular clipping but it would be relatively easy to do this for the date line. (You can approximate it by clipping appropriately against two great circles with antipodal centres!)\nIt would be nice to auto-stitch features that have been pre-split in the original GeoJSON, after rotation, although perhaps this should be done beforehand by the user. In theory, if the original features are not split at all, the clipping algorithm should be sufficient after any rotation. But most GeoJSON datasets have features that are split at the boundaries, so I think it's probably worth supporting stitching.\n. Superseded by #820.\n. Thanks, I've added the mode setter along with some tests (and bug fixes!) for equalarea.\nParallel here refers to the latitude (or standard parallel) at which there is no distortion and along which distances match a given scale.  This applies to both the equal-area and equidistant forms of cylindrical projection.\nMercator is indeed also a cylindrical projection.  I originally thought it would be confusing to support it as I thought parallels didn't really apply, however they can be used to set the \"latitude of true scale\" e.g. see here.  I'll have a go at this.\nTo make things potentially even more elegant, we can consider a cylindrical projection as a special case of a conic projection, where the two conic parallels are equidistant from the equator.  So perhaps the implementation would be to keep d3.geo.cylindrical with a single parallel option that would internally call d3.geo.conic and set both parallels accordingly.  Or perhaps we could have parallels(45) be a shorthand for parallels([-45, 45]), assuming there's nothing cylindrical that isn't a special case of a conic.\nSo we could just have two primary types of projections:\n- conic (two parallels, with shorthand for setting both to be equidistant i.e. cylindrical).  Modes: equalarea, equidistant and conformal, the latter gives rise to a Mercator projection in the cylindrical case.\n- azimuthal (origin and vertical distance), with modes as they are now.\nThe Miller projection is a modified Mercator, where the latitude is first scaled by 4/5, projected using Mercator, and then scaled by 5/4.  I'm not sure where that would fit in.  It could of course be a separate projection function, with fairly trivial implementation.\nAnyway, probably best if I bash out the code and see what you think. :)\n. I've merged this into #318 and made d3.geo.conic handle cylindrical as a special case. Unfortunately, things didn't simplify as much as I'd hoped, so I think some kind of subclass would make the code cleaner. I need to go through it again and clean up the code a bit more, but all the tests pass!\nI've also changed the meaning of scale for cylindrical for now as it made the code simpler, but I'll probably change it back to mapping 1\u00b0 to 1/360th of a pixel.\nYou might be amused to hear that I discovered yet another projection, the Tobler hyperelliptical projection (paper), for which various pseudo-cylindrical and cylindrical equal-area projections are special cases.  It requires an iterative numerical technique in the general case, but it might be possible to handle special cases for which we know an analytical solution.  I think I'll save it for another time though. :)\n. Thanks. That was quick! :)\n. This sounds similar to the d3.geo.rotate idea in #318, which performs an arbitrary number of rotations on a set of input coordinates about the x-, y- or z- axes (assuming spherical coordinates).  The difference is that no modifications are needed to individual projections (and it supports an additional rotation axis).\nSo if you want a projection to centre on a specific point, you can rotate the input coordinates such that your point of interest becomes [0, 0].  I think this is same thing, right?\n. Yes, it's a projection from spherical coordinates back onto spherical coordinates, so you can use it to \"preprocess\" points before passing them to a projection that maps onto Cartesian coordinates (at this point you can apply a scaling transformation).\n. That seems to work fine for me, is there something unexpected happening?  Note that d3.geo.rotate takes rotation angles, not coordinates.  So the x-axis is the axis going from the centre of Earth through longitude, latitude: 0, 0.  So rotating about this axis only by 90 degrees will result in the poles being at the left and the right prior to being projected.\nIf you want to rotate the Earth to particular coordinates, you'll want to rotate about the z-axis (longitude) and y-axis (latitude).\n. Ah, I don't think geo rotations will help you.  Apologies for misunderstanding what you were trying to do!\n. Yes, that's because a z-axis rotation is simply a longitudinal translation. :)  I don't see any particular reason to merge the functionality as 3D rotations using matrices are quite different from what you're doing.\nIt sounds like you were producing an oblique equirectangular projection, so it's not a completely new projection per se.  The whole point of d3.geo.rotate is to produce oblique versions of an arbitrary projection, which I think is quite fun!\n. Converting from Mercator to equirectangular isn't possible using only rotational transformations.  Even though they look similar, they're actually quite different!  Azimuthal projections are even more different, and you can't just obtain one by rotations alone.\nThe idea of d3.geo.rotate is that you can take any projection that maps [lon, lat] -> [x, y] (typically with [0, 0] as the origin, at the centre) and convert it to an oblique projection by first rotating the globe arbitrarily such that some other location is at [0, 0], and optionally, it can be rotated around the x-axis too.  So it does indeed save having to do this for each individual projection (although for azimuthal ones it's more efficient to use the azimuthal formulas directly).\n. I think we are mixing three different types of operations here:\n1. Operations that map spherical coordinates -> spherical coordinates e.g. d3.geo.rotate.\n2. Geographic projections that map spherical coordinates -> Cartesian coordinates in pixel space e.g. d3.geo.mercator.\n3. Transformations in pixel space, mapping Cartesian coordinates -> Cartesian coordinates e.g. scaling and translations.\nYour \"geotranslate\" operation falls under no. 3, as it's a way to set a translation offset in pixels (even though you allow the offset to be specified in spherical coordinates -- note that the translation is applied after the projection has occurred).  Instead of modifying each projection to support this, you can also just do:\njavascript\nvar w = 960,\n    h = 500;\nxy.translate([0, 0]);\nvar centre = xy([0, 52]);\nxy.translate([w/2 - centre[0], h/2 - centre[1]]);\nThis will place the UK at the centre of the resulting projection.  You could do something similar to place [-180, 90] at the top-left corner.\nI think defining new projections is already fairly simple, as all you need to do is define the projection function itself, and an invert function.  Admittedly the code for setting scale and translate could all be separated into a reusable helper, to make it even easier.\n. Both geotranslate and translate perform a translation after the projection to Cartesian coordinates, that's why they are both the same type of operation.\nThere is an issue with your example where your first operation is:\njavascript\nfunction(c) { return [c[0] + 180, c[1] - 90]; }\nFor example, consider what happens when you project the South pole, [0, -90].  You get [180, -180], which is outside the usual latitude range for spherical coordinates (it's still technically valid, but you'll get strange results i.e. the Southern hemisphere will be flipped and overlay the Northern hemisphere, which will be shifted to the Southern).\nThen you apply your mercator projection (resulting in Cartesian coordinates), and then apply a rotation, treating these as spherical coordinates!  Rotating about the z-axis is going to be fairly benign, but depending on the range of the Cartesian coordinates, a more complex rotation will result in something strange, with potentially overlapping coordinates (because it maps from spherical to spherical and you're giving it Cartesian).\nBy the way, I think it might be confusing to use the equirectangular projection as an example, because it is a linear transformation something like f(\u03bb, \u03d5) = (\u03bb/360, \u03d5/180), so it's easy to confuse spherical with Cartesian coordinates.  It might be easy to think you can just chain different geographic projections if you start with equirectangular.  But we have to remember that geo projections operate on spherical coordinates (angles), and not Cartesian coordinates, so while you can technically chain them together, it doesn't mean you should. :)\nHaving a chain of operations (in the right order!) certainly does sound appealing, but I think it's straightforward to do so by composing functions in the usual way.  So if you wanted some kind of magnifying operation, this sounds like it would operate in pixel space, so you could do:\njavascript\nvar magnify = \u2026,\n    mercator = d3.geo.mercator(),\n    rotate = d3.geo.rotate().x(\u2026).z(\u2026);\nfunction(d) { return magnify(mercator(rotate(d))); }\nAnd if your map could be panned, you would just call mercator.translate(\u2026) and the magnifier would be kept in the middle, say, with no extra work.  Likewise for geo rotations, etc.\nI think we both agree that cool things can be created by composing various operations together, but I think it only makes sense if you do them in the right order i.e. (spherical coordinates -> \u2026) -> (Cartesian coordinates -> \u2026).  Unless of course you're trying to create art! :)\n. I like it. It's a shame that attr and style both return \"\" instead of null (in accordance with the spec), as it means I had to compare with \"\" to see if a removal is needed or not.\n. Okay, I found a bug in JSDOM: tmpvar/jsdom#326, and also a bug in D3 when transitioning multiple namespaced attributes due to the name being coerced to \"[object Object]\".  So I've used the comma operator to work around the JSDOM bug for now, but strictly speaking it's not necessary in a correct implementation.\nI suppose it would be less brittle if we didn't rely on implementations of removeAttribute[NS] having a falsey return value, what do you think?\n. Thanks!\n. This fixes #329.\n. Good point. :)\n. Hmm, it's quite likely we don't need origin any more.  The origin accessor was an implementation of my idea in this comment.  Essentially it provided a way to retrieve the element's current position on dragstart.  Previously the zoom behaviour stored the origin internally, but if you clamped it externally, the origin would have the wrong position (which matters when zooming).\n- Yes, this really should be [-\u221e, \u221e] but I think I got a bit muddled when clamping the zoom range, so this needs to be corrected.\n- I think this is left over from when I allowed a function to be set as the extent, again it needs correcting I think!\n- It's possible we don't need it at all, if we just set it to [0, 0] to start with as before, then the new extent clamping should keep it in check.\n. Fixed backwards infinities in @14b8d48.\n. I've corrected the other issues too, I think, apologies if I've caused any merge conflicts!\n. Can you include @070b463ac097079f468253ed17b8d35a5643e163 too, I think it got missed out. Thanks!\n. Ah, it's there now, thanks. :)\n. I'm not sure this is necessarily what we want e.g. if you put one finger down at a time, event.changedTouches will contain one touch for each event, so it could mess up d3.behavior.zoom.  We probably want to patch d3.behavior.drag instead.  I'll need to think about it.\n. Okay, I've added another commit that adds an optional \"touches\" argument to d3.svg.touches.  So d3.behavior.drag can use changedTouches instead as this is all it cares about.\n. Merged with your branch now.\n. I shortened the regex a bit too, with no performance impact.\n. Okay, convention wins then!  It wasn't a major thing, but I wanted to reverse the parallel coordinates scale for a particular dimension on click, and I found that dragstart was firing and causing the background lines to disappear.  Easy enough to just do this on the first non-zero drag instead.\n. Oops. :)  It's similar but you seem to be flipping ky instead of kx, and only flipping r0[1] (I flip r0[0] as well).  I think this second difference leads to this bug in yours:\n```\nd3.transform(\"rotate(45)scale(1,-1)\")+\"\"\n\n\"translate(0,0)rotate(-45)skewX(0)scale(1,-1)\"\n```\n\nI think you need to flip r0[0] as well to flip both x- and y-coords.  By the way, I based mine on unmatrix.c, which only adjusts scalex (kx), but I can't think of any reason why flipping ky wouldn't work too.  It works the same in my limited testing, just that mine preserves scale(-1,1) and yours preserves scale(1,-1), so pick your favourite. :)\n. Ah, yes, you're right about unmatrix.c.  A browser-based test would be great!  Probably simpler than rolling our own parser to run in Node.js.\n. Cracked it. Fix (and tests) incoming.\n. Fixed in #379.\n. Oops, forgot to set epsilon back to 1e-6. Updated.\n. :)\n. Good point, updated!\n. Hehe, I knew you would come up with something. :)\nUpdated, and as a side-effect of using \"\", the html test now passes in JSDOM (but the text one still needs my fix).\n. Yep, I'm waiting for tmpvar/jsdom#373 to be merged.  Without the patch, jsdom seems to perform a naive if (txt) test before updating textContent so I'm not sure there's any way to work around it.\n. Ah, sorry, not sure how I missed that!  I'm tempted to try the setter/getter route, e.g.\n``` javascript\nd3_selectionPrototype.attr = setget(d3_selection_attr, function(name) {\n  var node = this.node();\n  return (name = d3.ns.qualify(name)).local\n      ? node.getAttributeNS(name.space, name.local)\n      : node.getAttribute(name);\n});\nfunction setget(setter, getter) {\n  return function(name, value) {\n    if (arguments.length < 2) {\n  // map:object\n  if ((value = typeof name) === \"object\") {\n    for (value in name) this.each(setter(value, name[value]));\n    return this;\n  }\n\n  // map:function\n  if (value === \"function\") {\n    return this.each(function() {\n      var x = name.apply(this, arguments);\n      for (value in x) setter(value, x[value]).apply(this, arguments);\n    });\n  }\n\n  // name:string\n  return getter.apply(this, arguments);\n}\n\n// name:string, value:constant\n// name:string, value:null\n// name:string, value:function\nreturn this.each(setter(name, value));\n\n};\n}\n```\n. Here is an initial attempt using the setter/getter approach: https://github.com/jasondavies/d3/tree/map-setget\nStill to do:\n- How to handle 3 arguments instead of the usual 2 e.g. selection.style.  Maybe an optional expected number of arguments: d3_multimap(\u2026, \u2026, 3)?\nAny improvements on \"d3_multimap\" welcomed. :)  And of course, whether or not this approach is worthwhile pursuing.\n. Ah, good point about evaluation order. It's fun (!) to go back and read the discussions way back in #55, #65 and #179 to see the original rationale behind this. One of the things that came up was the ability to conditionally set multiple attributes (or styles etc.) at once:\njavascript\n.attr(function(d, i) {\n  return i & 1 ? {foo: 0, bar: 10}\n      : {foo: 10, bar: 0};\n});\nIn reality though, we can still do this using .each without much extra typing.\njavascript\n.each(function(d, i) {\n  var g = d3.select(this);\n  if (i & 1) g.attr(\"foo\", 0).attr(\"bar\", 10);\n  else g.attr(\"foo\", 10).attr(\"bar\", 0);\n});\nAs for setting many attributes at once using a plain map, I personally find the non-map way of doing things perfectly readable. Judging from the branches and comments so far, implementation seems to have turned out more complex than anticipated, and I agree that having multiple ways of doing the same thing would probably reduce readability overall.\nSo to summarise, I wouldn't mind if you wanted to close this for now and come back to it if a more compelling reason is raised (although I think it unlikely as we seem to have discussed this one a fair bit!).\n. Thanks, updated!\n. I'd be fine with shorter names, particularly as behavior is now longer to type!\n. I'm trying to digest the various caveats of using offset{X,Y}. I think there are a couple of potential problems:\n1. The coordinates are relative to the current target of the event's target, and there is apparently a bug in Safari where a text node can be the target.\n2. IE9 computes it relative to the padding box (which, is actually the correct way according to the spec!)\n. Yeah. :(\n\n. It's a shame the offsetParent chain doesn't work, I just tried that too but can't figure out where the extra few pixels are coming from.\n. This works for me in Chrome and IE9: http://bl.ocks.org/1854606\n. And Safari, FF and Opera.\n. By the way, older Firefox versions (3?) may return floating point values for the bounding rect, so Math.round should be used if we care about that e.g. see here for an example bug report about this for Sencha.\nI don't know whether it's just 3.0, or later versions of 3.x too.\n. Updated!\n. Hehe, sure! Should get a chance in a bit. Watch this space. :)\n. It works! I even managed to get the links working using CSS3!\n. I have a very rudimentary drag'n'drop <li> reordering example working.  This is something I've always wanted to do in D3 (rather than jQuery UI, for instance).  It turns out that jQuery UI's sortable also automatically scrolls the container if you drag something outside it, which seems fairly important.  I'm guessing auto-scrolling is a bit out of scope for the drag behaviour though?  It seems a bit specific to the drag'n'drop use case.\nI also need to give some thought to what effect the reordering should have.  It could update the bound data to be in the same order as the reordered elements (a bit like the reverse of .order).  But usually data (and its order) is state elsewhere in the application, rather than only bound to a selection.  So it's probably better to have an event to signal that data has been reordered, and pass the reordered data for the application to update its state, so that next time data is bound, it will be in the right order.\n. Ah, cool, thanks for the thorough explanation, that makes perfect sense!\nFor # 2, my point was more that you can't sensibly transition measurements that aren't in pixel units e.g. `.style(\"font-size\", \"1em\").transition().style(\"font-size\", \"2em\") would attempt to interpolate something like \"14px\" \u21a6 \"2em\", because the starting value is always coerced to pixels.  Of course, a custom tween would do the trick here.  I don't think people typically use non-pixel measurements with SVG anyway, which is probably why I haven't come across the issue before.\nI only discovered this because I was using full-page zooming, so the second issue doesn't really bother me.  I don't see any particular need to support a version of transition.style that uses .style.getPropertyValue, for instance.  Less is more. :)\nI've added a note to the Wiki documentation, too.\n. Looks great!\n. Thanks for the quick response, too. :)\n. Looks great!  Much simpler API, and I like how the zoom extent is expressed as a scale factor for consistency.\nI don't actually need translation extents for anything at the moment, but it might be nice to have an example of doing this outside the zoom behaviour (assuming it's straightforward enough).  When the scale transform functionality is in use, perhaps a wrapper would be needed to clamp a scale's domain when it's set?  Otherwise, limiting the translate certainly looks possible as the mouse starting position is computed afresh for each zoom operation.\n. Hurrah! Thanks. :)\n. Ah yes, thanks!\n. Merged!\nSounds like a reasonable interpretation.  What happens when three fingers are detected?  Just pick the two that are furthest apart?\n. Another idea: pinching an existing brush could make it resize from the pinch centre (a bit like Polymaps zooming).\n. The other important case is d3.nest.\n. Ah, it's a shame about \"__proto__\".  I tried this in Firefox 10 and it returned false, but I guess it's still there in WebKit for legacy reasons.  In terms of compatibility, I think Object.create only works in Firefox >= 4, which cuts out 3.x.  But I think \"__proto__\" returning true swings it in favour of Object.hasOwnProperty.  I was thinking we might have d3_hasOwnProperty or d3_hasOwn to make it a little less painful. :)\n. FWIW, Opera also returns true for \"__proto__\" in Object.create(null).\n. Awesome. :)\n. Very nice! Converting my code now and checking that it passes all tests.\n. Hmm, we're only intending to use this to avoid Object.hasOwnProperty.call, right?  It seems overkill for cases like d3_rgb_names, where .hasOwnProperty suffices.\n. Passed all tests! :)\n. Yeah, I originally had d3_nsPrefixMap = d3.map(d3_nsPrefix) to get around that, but then thought it might be simpler to stick with d3_nsPrefix.hasOwnProperty.\n. Pushed to a branch: https://github.com/jasondavies/d3/tree/builtin-properties-map\n. I stuck with hasOwnProperty for other internal objects too: d3_rgb_names, d3_time_weekdayAbbrevLookup and d3_geo_boundsTypes, as I wasn't sure there was much of an advantage.\n. Wow, this is very thorough, great job.\nI concur with your d3.interpolateObject comment, I felt uncomfortable about the overhead for this too.\nRe __proto__ in d3.dispatch, is it worth detecting and providing a more useful error message?  I really don't care either, but it just seems like good practice.\n. Epic, thanks!\n. Cool! I guess my only reservation is the way inheriting depends on the context in which d3.transition is called. Wouldn't the \"transitioner\" concept allow you to inherit from a parent transition too, but without depending on context?\njavascript\ng.each(function() {\n  // \u2026\n  tick.exit().transition(g).style(\"opacity\", 1e-6).remove();\n});\nI like how it elegantly handles the no-transition case. I guess you could have .transition(selection) do a similar thing.\n. Ah! Yes, you're right. I forgot about variable delays and durations!\nIt's growing on me. :) I guess what I really want to do is be explicit and have tick.exit().transition(this) within transition.each, but this isn't possible of course with this being the DOM node.\nSince d3.transition(\u2026) for inheritance only really makes sense in the context of .each (because .each is the only way to do something per each element of a selection or transition), I guess using the context like this is fine.\nThe only way to do what I'm suggesting really would be to pass the current D3 node (either as this, or something else) and then inheriting could be more explicit. In the past I've wondered whether it would be more natural to have this automatically be a singleton selection, to save you having to say d3.select(this). But I'm guessing this is not done for efficiency reasons. If it was done, I guess it could automatically inherit transition properties if appropriate, but this would clearly be backwards-incompatible anyway.\nAnyway, LGTM. :)\n. Just a minor note: if you're using CORS you may find that the server rejects your request due to additional headers like this due to lack of an appropriate Access-Control-Allow-Headers header.\nOne possibility is to retry without this header if an exception occurs. Perhaps an overhaul is in order though e.g. make d3.xhr a configurable function such that X-Requested-With can be turned off. Something for version 3, perhaps, along with POST support?\n. Yep, that's right. I'm guessing most servers are just not set up to handle Access-Control-Request-Headers appropriately, and I can't see a clean way to set the X-Requested-With header conditionally.\n. jQuery no longer sets X-Requested-With for cross-domain requests as of 1.5.2 for a similar reason. We could do something similar and detect cross-domain requests.\n. That sounds like a good approach.\n. Ah, sorry, I tested it and the invisible resizers still worked fine, but now I realise the pointer-events: all is being reset on the g later in the code, so I'll reinstate it on initialisation.\nIE9 appears to have a bug, because the first mousedown creates the brush just fine, but thereafter I'm guessing the parent g is incorrectly ignoring the visibility: hidden rect, perhaps when programmatically switching pointer-events between none and all?\n. Strangely, manually switching pointer-events to none and then back to all via the IE9 Developer Tools fixes it.  But it doesn't work when doing it programmatically. I'm guessing I need to do the all/none switch for the background rect during brushstart/brushend for consistency with the parent g?\n. There, that should do the trick\u2026\n. I think the difference is that the resizers have display: none/null set on them. In fact, I just tried doing the equivalent for the background rect and that seems to fix it for IE9 too.\n. Seems slightly cleaner to use display: none actually. Let me know and I'll update it. In a twisted sort of way, it's more understandable that switching the display style will work around the bug. ;)\n. Yep, done and tested.\n. Hehe. I also noticed shape-rendering: crispEdges is not respected, but I don't know it it's worth offsetting all examples by 0.5px just for IE9. :)\n. Hmm, good point.  Closing for now, in that case.\n. Hehe, nice. :) This workaround could actually be implemented by listening for brushstart and brushend, so people wouldn't need a custom build. I'll leave the branch up for now and put some alternative code up here if someone asks.\n. Hurrah! :)\n. This is what happens at the moment:\n``` javascript\nvar d = [0, 0],\n    line = d3.svg.line().interpolate(\"bundle\"),\n    bundle = d3.layout.bundle();\nline(bundle([{source: d, target: d}])[0]) \u21a6 \"MNaN,NaN\"\n```\nHowever, it looks like the other interpolators handle this without any problem, so perhaps just the \"bundle\" interpolator should be fixed.\nI was thinking of links as [start, middle*, end]. But if the other interpolators handle [d] without any issue, perhaps keeping the existing behaviour is simpler (and like you say we can just check for length one to generate a loop if we want).\n. Another idea could be to return a.parent (if it exists) for LCA(a, a). So the bundle interpolator would know how to orient the loop.\nAt the moment the interpolator just draws a straight line to the parent and back, but it could be modified to produce a modest loop to the parent and back. It would require a bit of extra effort to detect [a, b, a] though. \n. Hmm, I'm not sure it works all that well:\n\nSmaller tension:\n\nI feel the \u00e6sthetic would be improved if the loops were all the same size and oriented towards the centre.  But then that's not really edge bundling. :)\nI don't actually care too much about loops for this data anyway, I just wanted to fix the warning about MNaN,NaN in the console.\n. I cleaned up the code a bit more and it looks a bit better (I wasn't computing the width of the loops correctly, plus I was short-cutting the main bundle interpolation so the loops were a bit too large).\n\nAgreed on all your points. It seems better to show the loops rather than not, otherwise information is lost. Hurrah! :)\nIt would be nice if the interpolator detected simple loops of the form [a, b, a] anywhere in the input array. At the moment it just checks for the simple 3-element case.\n. Ah, interesting about the LCA, I guess that makes sense if you use it as a distance metric (distance(a, a) == 0).\nI'd be happy to stick with #642 in that case. It's really simple to detect d.length == 1 and use a custom self-loop handler using d.parent if you so wish.\nThe synthesised control point is meant to depend on the tension, and not be entirely arbitrary. :) But if we go with the \"correct\" LCA definition, we can no longer do the trick of placing either side of the parent, and I agree it's a bit too special detecting this particular 3-element array.\n. Actually, I agree the synthesised points are arbitrary because the width of the self-loop should ideally be independent from the tension.\n. :+1:\n. Great minds\u2026 :)\n. Yes, it's merged into #640.\n. Yes, you were right about the duplicate point, thanks! I added a couple of simple unit tests, too.\n. Ah yes, I see, good catch! Let's switch to returning segments in that case (we'll need to anyway for Weiler-Atherton, which can return multiple polygons). I'll see if I can come up with a fix soon.\nHmm, I don't know the answer to north/south fill question either! It seems more right to treat it like the North Pole (\u22650\u00b0), but that's just my personal feeling. :)\nThat brings up another point, which is that we should handle clipping of LineStrings differently, because unlike polygons, they don't need an interpolated segment inserted along the clip region edge.\n. Nice work!\nAs for resampling, I don't think it's necessary to automatically resample all points when the input is a true geographic feature. I think it's safe to assume the input data is at a sufficiently high resolution to be projected in all manner of ways.\nResampling was only ever really needed to insert an appropriately shaped line segment along the clip edge (in our case, the circle). Without interpolating along the clip edge, you get an ugly straight line, because the clip points may be quite far apart compared to the original input resolution.\nSo I don't think we need to worry so much about resampling all points. The clipping algorithm should automatically interpolate along any inserted clip edges, but leave other points as they are. Ideally we'd want a precision parameter.\nIn the case of the azimuthal grid, we can already use d3.geo.greatArc to generate interpolated points between A and B. It could be a nice addition to allow resampling of an arbitrary number of points, rather than just two. Perhaps it could interpret an array as a list of coordinates, if source and target are null?\n. Some fun examples:\nHoles: http://bl.ocks.org/3076312\nSpiral: http://bl.ocks.org/3076420\nIcosahedron: http://bl.ocks.org/3072830\nSpinny Globe: http://bl.ocks.org/3076432\n. Note: the spiral example currently shows a brief flicker at around [-87, -87] as it fills the outside instead of the inside of the spiral. Not sure if this is a bug or not.\n. Okay, I know what's causing the spiral flicker. It's due to the great arc interpolation along the edge always choosing the shortest route. This can be a problem if we have:\n1. Antipodal points (since such a route is undefined without a third point).\n2. Two points that are further apart than \u03c0 in a clockwise direction. I think this is occurring briefly in the spiral.\nI would say these are relatively minor (not blocking), since they're unlikely to occur in most geographic features. But I'll fix them all the same. It's also a good opportunity to interpolate correctly along a circle, rather than a great circle, since the clip path may not be a great circle (e.g. when the angle is less than \u03c0/2).\n. All fixed!\n. Superseded by #820.\n. Y3K-compatible. :)\n. Agreed. Thanks!\n. This is backwards-incompatible for anyone relying on interpolation occurring on a reordered decomposed transform list for \"same type\" transforms, but I'm guessing that's unlikely!\n. Good idea. Coming soon!\n. Done!\n. Ah, I see what you mean: you want to retain the decomposition behaviour of d3.transform.\nI guess I wanted to reuse the same  element for retrieving the SVGTransformList, to save having to set it twice if the transforms have different types. But this is probably premature optimisation, since this only occurs when initialising an interpolator.\nWatch this space!\n. Done! I didn't have to set the transform attribute twice, since I can create new d3_transform objects directly.\n. I think it should spin around. Firstly, this is consistent with CSS3, e.g. 0\u00b0 \u2192 360\u00b0 will spin around in CSS3, and your \u00b1170\u00b0 example will go the \u201clong way\u201d around:\ncss\n-webkit-transform: rotate(-170deg);\nAnd:\ncss\n-webkit-transform: rotate(360deg);\n-webkit-transition: -webkit-transform 2s ease-in;\nSecondly, it seems more intuitive since it is closer to what d3.interpolateString would do given the same strings. There are sometimes situations where the \u201clong path\u201d is preferable, and always choosing the shortest-path means this can no longer be supported.\n. Regarding the inconsistency, I think there is a way out!\nFrom the CSS3 spec.:\n\nIf one of the \u2018from\u2019 or \u2018to\u2019 transforms is \"none\"\nThe \u2018none\u2019 is replaced by an equivalent identity function list for the corresponding transform function list.\n\nI'll submit a pull request for the 2.9.7 branch shortly.\n. Oh, never mind, I misunderstood that bit. I tested your example in CSS3 and rotate(0deg) \u2192 rotate(360deg)translate(0,0) is indeed a no-op. I'm still inclined to be consistent with CSS3 though.\n. Ah, thanks!\n. Thanks so much for the detailed explanation! Apologies for not adding tests, I'm adding them now\u2026 :) I did test it manually but clearly not thoroughly enough!\nI guess I'd prefer to reuse code if possible, I'll see how it goes.\n. Yep, definitely simpler to have different implementations due to different handling of parentNode.\n. Admittedly, the second commit probably obfuscates things much more, and is also probably vulnerable to loss of significance due to subtraction of larger numbers. Maybe I'll come back to this later\u2026\nAnother rather pleasing possibility is:\njs\ny = Math.sqrt((b + c - a) * (a + c - b) * (a + b - c) * (a + b + c)) / (2 * c * c);\nClamping is not so bad really, I guess I was just curious about ways of avoiding it.\n. This is also marginally safer than relying on timezone strings, since I guess their meaning is subject to change depending on the current timezone database in use.\n. I spent a while trying to make the tests work using node-time but didn't get anywhere, hence this fix that involves testing based on hacking the timezone offset directly. I'm not sure the process.env.TZ trick will work again anytime soon, see joyent/node#3286.\nMy comment about the timezone strings was just to point out that the timezone database changes all the time, so the tests are marginally \"safer\" in testing based on the numerical offsets. Of course, in reality the particular timezone \u21a6 offset being tested may not ever actually change in the near future. :)\n. I see you fixed it. Thanks!\n. Epic. Thank you!\n. Updated to support \"same type\" matrix transforms too.\n. Ha, I had exactly the same approach in the first commit, ed131d2374bffd67f4ef4df9b2e652a9f0b3a70b, then I think I got sidetracked with premature optimisation. :) Thanks.\n. I originally thought the increased precision would be useful to avoid temporal aliasing. But I agree in hindsight that it's hardly going to be noticeable! I can't think of an actual example that would be perceptibly improved by this.\nThere is another benefit though, which is that performance.now() is guaranteed to be monotonic, and so is resilient against clock skew e.g. due to time synchronisation. I imagine this is rare, but could potentially cause animations to run slower or faster than they should do.\nThe only other use I can think of is for ensuring that audio is accurately synchronised to an animation. :)\n. It does seem like there\u2019s a still bug in the monotone cubic interpolation implementation.  I think it should be possible to fix within the existing Hermite spline implementation though.\n. I tested my own test case against this branch and it seems to fix it.  I think perhaps there\u2019s a problem with the normalised tangent computation.\n. Not sure why you\u2019re using that version.  The fix that I tested is the patch in this pull request (which is quite old as it\u2019s for version 2.x).\n. Ah, of course, I forgot about scale! Let's continue the discussion in #746 about the other options. :)\n. Okay, I've improved handling of intermediate locale files so they aren't left lying around. I think it's safe to assume people should run make clean if they want to change locale.\n. Yes, and I was thinking we may want to allow bundling of multiple locales in future, too. :)\n. Updated to use LC_NUMERIC for d3.format.\n. Well spotted!\nsh\n$ python -c 'import locale\nlocale.setlocale(locale.LC_ALL, \"de_DE\")\nprint locale.format_string(\"%g\", 1234.5)'\n1234,5\n. Could be a bug in OS X for fr_FR; here\u2019s what I get in Ubuntu:\nsh\n$ LC_NUMERIC=fr_FR locale -ck LC_NUMERIC\nLC_NUMERIC\ndecimal_point=\",\"\nthousands_sep=\" \"\ngrouping=3\nnumeric-decimal-point-wc=44\nnumeric-thousands-sep-wc=32\nnumeric-codeset=\"ISO-8859-1\"\n. This Debian bug report from 2004 might help, but I\u2019d expect OS X to have pretty good locale support in 2012!  Need to investigate further and compare with Python.\nThat pt_PT example does look like a bug. :)\n. Python 2.7.2 on OS X 10.8.2:\nsh\n$ python -c 'import json, locale; locale.setlocale(locale.LC_ALL, \"fr_FR\"); print json.dumps(locale.localeconv(), indent=2)'\n{\n  \"mon_decimal_point\": \",\", \n  \"int_frac_digits\": 2, \n  \"p_sep_by_space\": 1, \n  \"frac_digits\": 2, \n  \"thousands_sep\": \"\", \n  \"n_sign_posn\": 2, \n  \"decimal_point\": \",\", \n  \"int_curr_symbol\": \"EUR \", \n  \"n_cs_precedes\": 0, \n  \"p_sign_posn\": 1, \n  \"mon_thousands_sep\": \" \", \n  \"negative_sign\": \"-\", \n  \"currency_symbol\": \"Eu\", \n  \"n_sep_by_space\": 1, \n  \"mon_grouping\": [\n    3, \n    3, \n    0\n  ], \n  \"p_cs_precedes\": 0, \n  \"positive_sign\": \"\", \n  \"grouping\": [\n    127\n  ]\n}\n. Related: #777.  Perhaps we could use mon_thousands_sep in that case.\n. Yes, using it for currency only is what I meant. The fix looks good!\n. Yes, everywhere I\u2019ve checked, the space seems pretty standard for French number formatting (although sometimes a period is used as in some other European countries). So it seems to be broken (although I think locale definitions often vary across platforms in subtle ways anyway).\nDjango appears to bundle number formats along with their i18n translation files; I guess that avoids relying on third-party locale information.\nPerhaps we\u2019d be better off making format string generation a separate standalone step, so that the results can be easily overridden afterwards.\n. Rebased against version 3.1.6.\n. Can we include this in 3.2?  It seems like a simple enough change.\n. Excellent, thanks.  Staged in #1285 for 3.2.\n. Note that a GeometryCollection containing only empty geometries of its highest dimension will result in a null centroid. Not sure if it's more useful to drop to the lowest non-empty dimension here. Probably worth seeing what PostGIS does.\n. GDAL appears to return a null centroid for a GeometryCollection with an empty MultiLineString and non-empty lower dimensions. Likewise for a zero-length LineString, hence I've reverted the last commit. This seems more correct anyway, since something with a zero weight shouldn't contribute anything to the result.\n. Heh, I\u2019d forgotten about this one. Almost finished merging the tests and proper handling of GeometryCollection. Expect another pull request tomorrow!\n. Yes, unfortunately.\n. Upon further investigation, I think it's actually due to the use of \"text-anchor\". When it's not \"start\", the \"dx\" attribute is ignored.\n. It occurs even without x or transform for me, in both Opera and Firefox.\n. Ah, but the parent  had a transform attribute, so I guess that affected it.\n. For use with Node.js: https://gist.github.com/3802532.\n. Yes, but if you pass a function for dsv.parseRows and it returns falsey, it doesn't buffer any rows. So maybe it should return null instead of [] in that case, but it should be quite efficient.\n. I agree we could do with a better API though. Maybe we should figure that out instead of adding this, as it's a bit of a hack. :)\n. Closing in favour of parsing a chunk into lines first and running d3.dsv.parseRows on a chunk of lines at a time.\n. I suppose it\u2019s still useful since newlines can appear within fields, so you need to make sure you track field delimiters too if you want to parse chunks. But there are already Node.js libraries for streaming CSV anyway, so I think having a proper API for streaming CSV via XHR is more useful.\n. Note: this only happens if the mouse hasn't moved after a mousewheel event or if you are in the middle of a touch gesture, and you reset the translate/scale.\n. Yes.  Thanks!\n. Looks great!\nI noticed that d3.xhr(\u2026).mimeType(\u2026) doesn't set the Accept header. Since we now allow arbitrary headers to be set I guess there might be a conflict if the Accept header is set elsewhere. I don't think setting Accept is necessary, or maybe it is for IE9 since it doesn't support overrideMimeType?\n. Yep, that seems reasonable. Impressive how it's still backwards-compatible. :)\n. Related: #783.\n. Thanks. All fixed in 768685693ee2f70090b3433eed5b60ab55df4e8b.\n. Cool. Will add a wrapper in d3-plugins in that case. It feels really clean to use, although I'm curious about the performance impact of the way that we now have to buffer points on a per-lineString or per-polygon basis. I'm guessing it's fairly negligible assuming these individual geometries aren't enormous.\n. Hmm, that could work. Should probably benchmark to make sure it's worth it. :) I've spotted at least one place that I can optimise internally anyway (in d3-plugins):\njs\np.line = function(lineString) {\n  return project.line(rotateLineString(lineString)).map(transformLineString);\n};\nThe transformLineString step can operate in-place, since it's operating on a copy already.\n. Note: this doesn't properly handle polygons yet e.g. we want path(graticule.outline) to work correctly for all rotations.\n. This may not really be possible since we only project on a per-LineString or per-LinearRing basis at the moment, but I was thinking we could bypass cutting altogether for some GeoJSON objects by checking the optional \"bbox\" GeoJSON property to see if it crosses the antemeridian.\nJust an idea; it may not be worth it if projections have to support all GeoJSON types (you can have a bbox defined for a FeatureCollection, for example). On the other hand, it may guide our API design choices e.g. perhaps rotate+cut should happen in d3.geo.path.\n. Excellent. Thanks!\n. I ran into this because I was inadvertently saying:\njs\nvar c = color(\u2026); // returns an RGB string.\n.transition().style(\"fill\", foo ? d3.lab(c).darker(\u2026) : c);\nIt was easy to fix by adding + \"\", but it took some strange intermittent behaviour in Firefox to realise there was something wrong. Here's an example:\njs\nd3.interpolate(\"#886633\", d3.lab(1,3,4))(.4);\n'#531979.8f0100'\n. Yes, I think that would be sensible. I don't see how you would ever want to set anything else. The spec. says style.setProperty takes a DOMString.\n. Looks good!\n. Note that d3_geo_circleClipPolygon should be sufficiently generic to handle tilted perspective clipping, when we get to it. :)\nAll it needs is a function to convert LinearRings into visible segments, a function to specify the ordering of the segment endpoints around the clip edge, and finally an interpolation function to interpolate clockwise around the clip edge. The ordering function can probably be dropped.\n. We now pass the stress test!\n. Agreed, the code could definitely be more intuitive. :)\nRather than use recursion, I\u2019d probably try different values of t in a loop, and that should make more sense. I also want to see if the current distance at t can be used to estimate a better t. At the moment, it \u201cedges\u201d slowly towards a better t, but I think some kind of binary search would be faster.\nI\u2019ll try and come up with something better soon, if you don\u2019t beat me to it. :)\n. Nice!\nNote that although physical circles work well in most cases, they may not produce ellipses in areas of extreme distortion so they\u2019re not always the same as the \u201ctrue\u201d Tissot Indicatrix.  I have some old code somewhere that does a more accurate approximation of the distortion at the circle centres using finite differences.  I plan on sharing it as a plugin when I fix any bugs. :)  One approach could be to use a very small physical circle and then inflate the result.\nBut this is all just musings about the general case, and yours looks great for the orthographic!\n. You should! :)\n. See also: #873.\n. Note: the resampling fix seems to reintroduce artefacts in the Albers cutting test, but I'll look into those again soon.\n. Okay, I understand how to fix the Albers artefacts now. The problem occurs when we have a line that goes through a pole. For example, in the test case I have [0, 88] \u2192 [180, 89]. During resampling, we recursively find the mid-point of this great circle arc. However, the mid-points all lie exactly on the meridians at [0, ] and [180, ].\nNow, consider the Albers projection (this applies to any conic/cylindrical projection). The poles themselves are ambiguous, in the sense that you can have multiple points at different \"latitudes\" at [*, \u00b190], and they will be projected to different positions, even though they are in the same place on the sphere.\nTo remove the artefacts, when the line goes through the pole we need to resample \"along\" the polar edge to get the Albers curve, which represents a single pole on the sphere. I already detect points on the poles by testing for zero x- and y- 3D coordinates. But when resampling we don't necessarily get far enough to land on a pole due to passing the perpendicular distance tests.\nSince this involves detecting when something goes through a pole, I believe it would be simpler to effectively extend the antemeridian cut by a small \u03b5 so it goes through both poles. This should effectively force resampling towards the antemeridian at the poles.\nWatch this space! In the meantime, feel free to merge these commits as they fix more serious problems.\n. I implemented it a little differently: instead of extending the meridian cut line, I simply added a check for all lines that go through the poles, and insert appropriate points. I also removed the distortion check for resampling since it no longer seems necessary.\n. Okay, I think it\u2019s occurring due to \u03bb=180.000000000000142 in the data, so resampling interpolation is probably flipping over to \u03bb=-180.  I will find a better fix soon, e.g. resampled mid-point should be checked to ensure it has not flipped.\n. See also: mailing list thread.\n. True. The primary motivation is really to avoid weird errors mentioned in the thread: Uncaught TypeError: Cannot set property 'z' of undefined. Perhaps this is better solved in d3.layout.treemap directly.\n. Actually, this is more of an issue with clipping, since it does an exact comparison to reconnect Polygon endpoints.  Better fix incoming.\n. Hmm, I think I need to improve the case where coincident intersections are found.  I think I should keep the winding number here in case it interpolates in the wrong direction.  I'll create some tests and fix it shortly.\n. Fixed.  More to come with winding number checks for antemeridian cutting, but this passes all my checks for circle clipping.\n. Major updates!\n. Good point. How about setting context = null after calling clip.*(coordinates, resample)?\n. Done.  More elegant solutions welcome! :)\n. Ready for review.\n. Promotion does happen automatically if you use the d3.geo.projection constructor, or do you mean it would be more intuitive if it happened in d3.geo.path?\nI think you would get a similar result to your use of an identity function if you use:\njs\nd3.geo.path()\n    .projection(d3.geo.equirectangular()\n      .scale(180 / Math.PI)\n      .translate([0, 0])).centroid\nI'll push the d3.geo.centroid work today, perhaps with a placeholder for polygons since they seem to be more tricky than line centroids.  I can use the line centroid as a stopgap for now.\n. Feel free to merge now as it should be more accurate than the current d3.geo.centroid.  Area weighting should make it even better, but still working on it.\nNearly there with d3.geo.area (pesky hemispheres!), which will help with both accurate winding order detection for projections, and the aforementioned area weighting for centroids.\nI'm sure there'll be opportunities for code reuse here.  In particular, I'm thinking we can have some reusable functions that perform spherical interpolation in 3D coordinates, so both d3_geo_circle and d3_geo_greatArc could share this, while caching 3D coordinates (e.g. for source/target) for performance.\n. Hehe. No, it\u2019s only needed for the North Pole because the area is computed by decomposing into triangles relative to the South Pole. That is, each segment is connected to the South Pole to make a triangle. This works great except when you have one or both of the segment points are at the North Pole. This effectively creates a spherical lune and the usual triangle calculation fails. So this case is detected and the (simple) lune area calculation is used instead.\nRelated to this, any repeated points at the North Pole are ignored, e.g. as generated by a graticule outline, since they don\u2019t contribute anything to the area, and break the lune area calculation.\n. Good idea!\n. The winding order calculation is a bottleneck when there are no intersections: removing it doubles the speed of the counties benchmark (80ms \u2192 40ms).\nI have a speedy alternative that works in most cases where a known outside point can be easily found, e.g. where the longitude and latitude ranges are smaller than 360\u00b0.  So that will be coming next.\n. Hmm yeah, I guess an error is also acceptable; I'd be happy to close this unless you'd prefer the noop in this case.\nI think we should definitely disable resampling for the fallback if we intend to use it for things like the identity projection, where the input data is not in spherical coordinates.\nAre you sure we don't want resampling for albersUsa?  For example, resampling allows you to draw a two-point LineString from East coast to West coast and intermediate points should be adaptively resampled along the great-circle arc.\nSo I'd be in favour of dropping resampling for the fallback, but adding it back for albersUsa.\n. Yes, all ambiguous cases should return undefined, so that the user can choose their own arbitrary point if they want to.  For example, another ambiguous case is an equatorial LineString, whose centre of mass is at the sphere\u2019s origin, so again you could pick an arbitrary point on the sphere as its centroid.  We return undefined for ambiguous cases at the moment.\nI think you are suggesting that the combination of an undefined centroid (e.g. sphere) and geometries of lower dimensions (e.g. points) should fall back to the centroid of the lower-dimension geometries.  But if we do this, it should apply to other undefined centroids too e.g. centroid([equatorial lineString, point]) \u2192 point.\nI suppose you could think of {no polygons} or {sphere} as having zero weight, and the centroid is defined as that of the largest dimension with non-zero weight.  If all three weights are zero, then we return undefined.\nThis would mean tracking centroids separately for each dimension e.g. d3_geo_centroid{X,Y,Z,W}{0,1,2}, but I\u2019d be okay with doing that if we want to go this route.\nOn the other hand, it might be better to always let the user figure out the best centroid if their highest-dimension geometries are ambiguous.\nEither way, centroid([sphere, point]) should be the same as centroid([N hemisphere, S hemisphere, point]) for consistency, and this pull request fixes that inconsistency by setting dimension=2 for spheres (sorry, I should have made that clearer in the commit!)\nEdited \"on the other hand\u2026\" for clarity.\n. Aha, cool. :)\n. The response was jittery because the scale should be computed in screen coordinates, not in transformed coordinates (which change when you zoom, causing the jitteriness).  See #1298 for a fix.\n. :+1:\nI wonder if we should also consider making extents inclusive to avoid having to add \u03b5 every time:\njs\nd3.geo.graticule()\n    .minorExtent([[-180, -75], [180, 75 + \u03b5]])\n    .minorStep([15, 15]);\nUnfortunately coincident edges/points may cause clipping issues, so I don\u2019t know if we should just leave it, or maybe treat the poles/antimeridian as special cases.\n. I\u2019ve updated my demos and it works great!\n. Hmm, this needs some more thorough tests for MultiPolygons before it should be merged.  Watch this space.\n. OK, more tests added.\n. Fair enough, but you should open a new issue if you want to make a feature request. :)\n. Great-circle distance on Wikipedia. The spherical law of cosines is problematic because the cosine of a small angle is close to 1, so floating point bits are wasted e.g. 0.99999999\u2026.\nI also made a small demo comparing the three formul\u00e6, and admittedly the error is pretty small!\n. You\u2019re welcome! :) I found the closed form here.\n. Good catch!  I\u2019ve pushed another fix that handles these examples too.\n. No problem, it wasn\u2019t much effort. ;)  Your solution sounds better.  I think Web Workers are sufficiently rare at the moment for custom builds to be reasonable, and I don\u2019t mind if we do this (move files to src/dom) later when it\u2019s more convenient.\n. Should probably adjust the forward projection so it respects the same extents as the inverse.\nIt might be nice to stream points to each sub-projection and use clipExtent when have support for it, so projecting the whole world and graticule will just work (although of course separate graticules are probably advisable due to differences in scale).\n. I look forward to it. :)\n(As for clipExtent, this isn\u2019t necessarily what people will want because most composite U.S. maps have rectangular extents in pixel-space, and clipExtent will produce arcs for albers.  But clipping could be done in pixel-space too.  Anyway, just an idea at the moment.)\n. Hmm. I think it\u2019s reasonable to expect center to refer to rotated coordinates, so that for most projections this would be true:\njs\nprojection(projection.center()) == projection.translate()\nBut of course it would break backwards-compatibility to change this now, and I think it\u2019s quite likely that people are already combining .rotate and .center e.g. for Albers.\nI don't have much in the way of suggestions other than something like projection.rotateCenter, which would simply behave like projection.center, except it would refer to rotated coordinates (so it wouldn't matter if a rotation was specified afterwards).  Not ideal, of course!\n. Yes, that seems reasonable.\nI was following the definition of ST_Length but I think they\u2019re just complying with various SQL specifications: they have a separate ST_Perimeter for polygons.\n. (Interestingly, it seems ST_Length used to return the perimeter in older versions).\n. Excellent, thanks. :)\n. See #1114.\n. Agreed about exposing this as projection.clipExtent.  If we ever want to clip against an extent in spherical coordinates we can always come with an alternative name, or simply interpolate and use projection.clipPolygon.\n. It could be worth updating the JSDOM dependency to point to a specific git:// URL (with commit ID) otherwise some tests will fail for people installing 0.5.2.  We should do the same for UglifyJS for good measure, and this means we can also drop .tmp files!\n. Fixes http://bl.ocks.org/mbostock/fde1a65845aef4fe33d1. :)\n. Hmm. That last fix broke your satellite \"sphere\" test. But it works great for the orthographic with world-50m.json.  I believe the problem is the satellite projection doing crazy things with points >90\u00b0 from the observer, but may be fixed by additional spherical clipping.\n. Retrieval might be better as a map of type\u2192listener as the order is not defined otherwise.\n. Perhaps selection.on(\"click\", null) should remove all named listeners too for the click event, to be more CSS-like?\nThe only issue with returning the first matching listener is how to determine which is first.  I guess we could retain the order in which event types were declared for d3.dispatch, but I don\u2019t think this is necessarily possible for selections.\n. Maybe it's a good reason to avoid retrieval of listeners by name altogether. :)\n. Hmm, it seems impossible to support selection.on(\".foo\", listener) as we don\u2019t necessarily know all of the supported event types.  Maybe we should just stick to removal only in that case.\n. Agreed, I think these additional two modes are not useful enough to warrant inclusion at the moment.  So I think we should have:\n- selection.on(\".name\") - returns undefined.\n- selection.on(\".name\", listener) - no-op, and returns the selection for consistency.\nThis is similar to the current behaviour, except that \".name\" is currently treated as a type so you can actually set a listener using selection.on(\".name\", listener).\nFor d3.dispatch, the analogous behaviour to the above.  Currently, errors are thrown if there is no matching type but it seems simpler to maintain consistency with selection.on rather than start throwing our own errors for these cases.\n. OK, selection.on(\".name\", null) is now implemented too, and I\u2019ve removed the add/retrieve behaviour for \".name\" for d3.dispatch.\n. Superseded by #1140.\n. Ah, yes.  Thanks!\n. Not perfect as there\u2019s still an issue when drawing {type: \"Sphere\"}.  Working on a fix.\n. OK, force-pushed a better fix.  I think this is actually more robust than special-casing \u221e values, because I tried clamping to larger values such as 1e200 and this didn\u2019t work.  Even clamping to a value as low as 1e20 still led to a slanted line in when drawing {type: \"Sphere\"} using Mercator (probably due to loss of precision because IEEE double can only represent around 16 significant decimal digits).\n. Closed in @7306ad091a84ae885dc5f235de307f42b530e739.\n. Also, quadtree\u2019s node.point is still structured {x, y}, so ideally this should be changed to [x, y] too.\n. All done.  Thanks for the excellent review!  The only things remaining are:\n- Should accessors have a signature of (d, i)?  This would mean root.add(d, i), which I don\u2019t see an inherent problem with.\n- Use parallel point arrays for efficiency.\n. What do you think, @mbostock?  Maybe geom/point would be better than core/point?  It is currently used by d3.svg.{line,area} and d3.geom.{hull,quadtree,voronoi}.\n. Thanks for this!  I implemented a similar fix in #1298, hopefully it\u2019ll make it in an upcoming release.\n. I\u2019ve adjusted the fix slightly now to use one sqrt call instead of two.\n. Looks good to me, except that you should edit src/package.json since it generates package.json.\n. This has been in action for some time now at https://www.jasondavies.com/maps/transition/ due to the graticule meridian problems that occur without this.  Would be nice to avoid generating redundant points though.\n. Yeah, this is what I meant about redundant points.  Ideally we\u2019d want some additional code to avoid generating these points if subsequent Douglas\u2013Peucker checks fail.  Of course, there is still a performance impact due to the additional resampling (even if no extra points are generated).\nThe finite derivative could work.  We probably still want a minimum sampling interval though, since the finite derivative check may not catch all cases.\nIn general, I suppose real-world geographic features should be sampled at a sufficiently good resolution such that resampling is not necessary the majority of the time anyway, because the points are close enough together.  So really this only affects:\n- Generated geographic shapes such as graticules, small circles, and of course \u201clow resolution\u201d LineStrings (flight paths etc.)\n- Real-world geographic shapes that are highly distorted in areas of a projection.\n. Agreed.  I\u2019ll have a go at avoiding redundant points when I get a chance.\n. Redundant points are now avoided.  I think there\u2019s still room for improvement, but this fixes the issue for now.\n. Related: Firefox bug 718175 and 487897 (unresolved, unfortunately).\nI think the problem is that there is no such thing as a local time of midnight, from the point of view of Firefox:\n``` js\n\nnew Date(-1)\nWed Dec 31 1969 23:59:59 GMT+0000 (BST)\nnew Date(0)\nThu Jan 01 1970 01:00:00 GMT+0100 (BST)\n```\n\nPerhaps it's a valid question of how to handle a local timezone that has no midnight e.g. due to a DST change.  One possibility is to detect the beginning of a day by subtracting a single millisecond and checking for a change in getDate.\n. I\u2019m thinking we may need the boundary detection fix because I think there\u2019s a general issue with any local timezones that don\u2019t have a midnight due to the DST boundary, e.g. TZ=Asia/Amman node:\n``` js\n\nnew Date(2014, 2, 28, 0, 0, 0)\nThu Mar 27 2014 23:00:00 GMT+0200 (EET)\n```\n\nThere is effectively no local midnight, because it jumps to 01:00:00 when you would otherwise expect 00:00:00.  So the problem is twofold: firstly generating a date object with the right fields set (e.g. day=28 in the above example), and secondly detecting a boundary date for the purposes of formatting.\nThere is also the possibility of days being skipped entirely. :)\n. So, I\u2019m proposing:\n1. We modify the definition of a time interval to take into account non-midnight boundaries between days (and possibly even weirder situations such as a missing 1st day for a month). So day.floor should return the smallest Date object for that particular day, which could have a non-midnight time.\n2. The simple checks e.g. in d3_time_scaleLocalFormats should check for a boundary instead, e.g. subtract one millisecond and see if the field in question changes.  A single Date object could be reused for efficiency.\n. > That\u2019s already the case, is it not? So you\u2019re saying that the current behavior of d3.time.day.floor is correct (Thu Jan 01 1970 01:00:00 GMT+0100 (BST))\nIt is correct for this case, yes, but not for the Asia/Amman example, e.g.\nsh\n$ TZ=Asia/Amman node -p 'require(\"./\").time.day(new Date(2014, 2, 28, 5, 0, 0))'\nThu Mar 27 2014 23:00:00 GMT+0200 (EET)\nSolving this is a bit trickier, but I imagine it can be done efficiently for the common case.  If the boundary check below fails, then some kind of binary search might be necessary.  It would be nice to handle the case of missing days too; maybe test for these weird cases using a mock Date class.\n\nit\u2019s just that d3_time_scaleLocalFormats isn\u2019t detecting this as a day boundary because date.getHours returns a non-zero value.\n\nYes, this is the second issue.  I like the use of floor but it probably is more efficient to decrement milliseconds (at least this avoids creating a new Date object).\n. OK, force-pushed a fix for all of the above.  Binary search could probably be made more efficient, but on the other hand it's going to be very rarely used.\n. I\u2019ve added a time.dst helper for testing, which defines a DST change where date0 becomes date1, and adjusts all internal fields accordingly.\nNow we just need to fix interval.ceil.  This is now used by interval.range, which is why d3.time.days(new Date(2014, 2, 26, 12), new Date(2014, 2, 31, 12)) still fails for Asia/Amman.\nI think it\u2019s okay that day.offset may not necessarily increment the day field, since this is already the case for hour during DST.\n. Rebased against master.\n. All tests pass, but probably want to give it another check over and add more tests before merging.\n. In theory yes.  I don\u2019t know if this occurs in practice for any time zones at the moment, but if it\u2019s simple to be future-proof, we may as well.\nOne interesting thing that I found out when researching the Firefox bug, is that ECMAScript only expects the current DST rules to be applied to all previous years:\n\nThe implementation of ECMAScript should not try to determine whether the exact time was subject to daylight saving time, but just whether daylight saving time would have been in effect if the current daylight saving time algorithm had been used at the time. This avoids complications such as taking into account the years that the locale observed daylight saving time year round.\n\nSo Firefox does seem to be a deviation from the spec. for the 1970 date.  But that\u2019s just an aside, as there is a real issue for DST changes that occur at midnight, e.g. Asia/Amman.\nWe could always temporarily apply your new Date(2000, 0) fix for Firefox+England/London, while we cogitate on this patch.  I\u2019m not 100% sure about the way I\u2019ve implemented ceil, but it seems to work fine.\n. I\u2019d like to add more tests too, e.g. for DST changes occurring on a year boundary etc.\n. I don\u2019t think you\u2019re doing anything wrong, since Firefox deems 1970-01-01T00:00:00Z (UTC) to be 1am local time in the UK.  So it\u2019s expected that local time formatting may not result in a midnight.  Note that the patch in this pull request was not released, and a simpler fix for the problem of 1am appearing everywhere in Firefox/GB was used.\nThis pull request modified time scale formatting so that non-midnight day boundaries were detected and formatted as days instead of times, so perhaps that\u2019s what you\u2019re referring to?\nAs an aside, I can\u2019t work out why Firefox would think 1965-01-01T00:00:00Z (UTC) is 1am, since British Standard Time (all year BST) was not in effect that year.\n. Well, the patch in this pull request should solve that issue.  Are you saying you tried it and it didn\u2019t work?  It didn\u2019t make it into an official release as the whole approach was a bit complicated.\nThe issue of DST boundaries occurring at midnight is still a problem in official D3 releases for the moment.  This will manifest in Firefox/GB 1970, which seems to be a Firefox bug according to ECMA, but other countries currently do this e.g. Asia/Amman, which is not a browser bug as it is a current DST rule.\n. The fix in #1277 that made it to an official release fixed a more serious issue in Firefox/GB, whereby all day boundaries were at 1am, even though the majority should be at midnight. :)\n. The patch is the branch for this pull request.\n. I just rebased it against master (v3.2.8) for you (force-pushed).\n. Good idea.  Force-pushed a better fix, which generates src/start.js.  For consistency with generation of locale formats, I also changed the Makefile to run it using node (and moved the file to src/start-version.js so the main directory doesn\u2019t get cluttered).\n. Done!  I managed to fix the dependency issue by adding src/start.js (and other generated files) after the smash call.\n. Ah, yes, it was simply due to the ordering of targets that make clean all worked.  I\u2019ve renamed start-version now, and removed those extra files that I had added to GENERATED_FILES.\n. This approach might be preferable to adding assert.dateEqual, since it\u2019s likely we\u2019d want to override the Date prototype to add tests for weird timezones in #1197.\n. This is not a bug in D3 itself.  For some reason IE9 doesn\u2019t clip against the SVG element\u2019s boundary by default, so the fix is to use a stylesheet with:\ncss\nsvg { overflow: hidden; }\nD3 aims to provide a thin layer for the DOM, so such an invasive change (automatically setting the overflow style) is not acceptable.  But thanks for the pull request, all the same!\n. Perhaps it\u2019s time we exposed d3_dsv as d3.dsv?  Another one that I\u2019ve encountered is d3_dsv(\"|\").\n. \n. \n. One more\u2026 :)\n\n. I\u2019ve added a short note about the multi-projection stream and when it will work, in case anyone wants to create their own for other regions.\n. Yeah, d3_geo_clipView could be modified to exclude a rectangular region relatively easily (use it twice to exclude two regions), but we can always do this in future.\nNice work on Alaska, I think that\u2019s an improvement.\n. I discovered one way to do it is to add \"use strict\" to src/start.js (inside the closure) and run all tests.  This only catches undeclared variables that are covered by the tests though.\n. Actually, it looks like UglifyJS can warn about it, using the --lint option, but along with other warnings that can\u2019t be turned off.  Perhaps we could grep for \"Accidental global\"?\n. Even better, here\u2019s a custom script that uses the UglifyJS API directly.  Perhaps we could even make it generate two files at once for performance.\n. Related: UglifyJS has started tagging releases again (2.3.6 at the time of writing), so we should probably update for the next release.\n. Yes, that\u2019s the one.\n. Looks good.\n. Possible tweaks:\n- Rather than have projection depend on path, create a shared dependency, cache.js.\n- Use two globals instead of an object, e.g. d3_geo_cacheId and d3_geo_cacheStream.\n. I added it after my initial benchmark, and it didn\u2019t change anything. I\u2019d be happy to drop it in case it affects other VMs.\n. Nice suggestion, will give it a try in a bit.  Just checked, and the current optimisation seems to have a greater effect for separate counties:\nOld: 88ms/op.\nNew: 62ms/op.\n. I think I was slightly worried about maintaining a reference to output in projection (as it would prevent garbage collection of a path\u2019s context stream even if the path is garbage collected), hence the futzing around with IDs.  What do you think?\n(Edited for clarity.)\n. Hmm, I\u2019d prefer not to break custom streams if possible.\nI don\u2019t think there\u2019s an issue with id conflicts, because the global is only set temporarily in path(object) during the call to projection.stream(\u2026), and the cache itself is in the path (and it\u2019s invalidated if a different projection is set on the path).  So in effect, the id doesn\u2019t need to be unique across projections.\n. For your approach, I suppose you could turn off caching if the invalid flag doesn\u2019t exist.\n. Excellent. :)  Well, I think your approach is more elegant, and I don\u2019t mind the additional public API as it could be useful.\n. Ah, good point, I hadn\u2019t thought of that.  Good call. :)\n. Need to think about the area \u2192 length \u2192 point fallbacks a bit more.  I\u2019ll merge when I\u2019m happy.\n. Improvements pushed.\n. Managed to shorten the only other vendor-specific check, for matchesSelector. :)\n. Updated.\n. I\u2019ve tested this in Firefox, and discovered that body { -moz-user-select: none; } does not affect absolutely-positioned elements.\nAn alternative fix could be to call window.getSelection().removeAllRanges() on mousemove/touchmove for Firefox, although this seems less optimal.  Note that the selectstart event appears to be supported by Chrome/WebKit/IE9+, so we could potentially remove user-select altogether in favour of a hybrid of selectstart and removeAllRanges.\n. It would be something like:\njs\nvar s = window.getSelection();\nif (s.rangeCount) s.removeAllRanges();\n. Another idea: temporarily insert a stylesheet rule, * { -moz-user-select: none; }.\n. I guess it\u2019s reasonable, as the bug only affects absolutely-positioned elements, so developers can include their own workaround if needed.\n. Tested in Chrome, Safari, Firefox (with caveat) and IE9.  OK to merge?\n. Hmm, I\u2019m thinking it might be better to stick with selectstart suppression for all browsers except for Firefox, as it\u2019s overkill to set the user-select style too for these browsers.  I\u2019ve added a commit that does this, let me know what you think.\n. I\u2019ve implemented your suggestions.  The use of selectstart vs. -moz-user-select is now encapsulated.  However, should Firefox add support for selectstart in future, it will now not be used.\n. OK, updated.  I also discovered that you need to set -moz-user-select on d3_documentElement for it to truly work properly, since Firefox allows you to select the <body> element otherwise!\n. OK to merge?\n. Just a minor note in case anyone else encounters this.  There is a catastrophic WebKit bug that occurs if you shift-click with -webkit-user-select: none (crashes the whole tab).  This affects both Chrome and Safari.\nWe could consider relying only on selectstart suppression for WebKit as a workaround within D3.  A workaround for users is to wrap everything in a wrapper div with -webkit-user-select: all, which effectively undoes D3\u2019s use of -webkit-user-select: none on the body (quite unappealing, of course).\nYou can reproduce using this example: select some of the text on the axis, and with the shift key depressed, drag on the brush.  It should crash the tab in Chrome.\n. Note that it might already have been fixed via a linked WebKit bug, but it looks like it hasn\u2019t landed even in Chrome Canary yet.\n. Cool.  What\u2019s multi-finger zoom?  We already support double-tap for zooming in.  Rotation would be nice.\n. This should only affect the case where d3.event.scale is undefined during a multi-touch event (n \u2265 2), which currently causes an error in browsers that don\u2019t set this property, so it seems like a pretty safe change (and will make Android users happy).\n. Also suppresses user-select for brush.\n. Yeah, I\u2019m also concerned that having no preventDefault on mousedown makes us brittle to arbitrary browser defaults that may be added in future (or exist already, like the image dragstart issue).  For example, touch-and-hold seems to be blocked by the user-select approach, but I could imagine touch-enabled devices coming up with other default behaviour that we haven\u2019t thought of.\nFor @jfirebaugh\u2019s specific issue, I think window.focus() would be fine.  Even if we didn\u2019t have window.focus(), he could add a mousedown listener of his own quite easily.\nIt is a shame that preventDefault makes dragging problematic within iframes, because it seems to block mousemove when the mouse moves outside of the iframe.  This is one of the things that persuaded me to go for this approach in the first place.  I tried to find an alternative that works with preventDefault, but no luck so far.\nIf there was a way to revert to the preventDefault approach, but fix dragging in iframes, that would be perfect.  Otherwise, I\u2019m a bit torn, but I think reverting is probably safer on balance.\n. document.activeElement.blur() seems to work.  It seems a bit invasive for the drag behaviour to do this though.\n. Unfortunately, that\u2019s not a fix for the same issue.  See Leaflet/Leaflet#1277.\n. Looks great.\n. Here\u2019s an edge case for you (I don\u2019t necessarily think we need to address this at all, other than document it):\njs\nd3.max([0, \"a\"]) // 0\nd3.max([\"a\", 0]); // \"a\"\nThis works because \"a\" >= \"a\", but !(\"a\" > 0 || \"a\" < 0) since comparing with numbers coerces strings to numbers (resulting in NaN).\nNot sure what should be done: maybe returning NaN in both cases would be consistent and simpler than attempting to ignore strings if there are numbers, or we should just document that the methods only apply to arrays with values of a consistent type.\n. Sounds good.  Regarding my edge case, I think it\u2019s possible to return undefined in a single pass if inconsistent comparisons are detected, but it would still be more complex so probably not worth it.  It would need to detect the case where a value is orderable (b <= b), but incomparable with the current max. or min., so !(a <= b || a >= b), and return undefined at this point.  I don\u2019t see how this is useful in practice anyway.\nFor threshold, I like the change to disallow searching for an unorderable value.  However, do we also want to return undefined for a search value which is incomparable with the domain type?  Something like:\njs\nvar y = domain[0];\nif (x >= y || x < y) return range[d3.bisect(domain, x)];\nx <= x is no longer needed since unorderable values will always fail x >= y || x < y.\n. OK, makes sense.\n. We should also only bind mouse events for brush on mousedown (not on touchstart), like in #1322.  I checked and the same problem happens with this branch (with preventDefault turned back on).  I can put it in a separate request if you prefer!\n. Ah, good point!  I\u2019d prefer to keep the API simple in that case.\n. Looks good.\n. Yes, that fixed duplicate events on d3_window, but note that there\u2019s also this.on(mousemove, mousewheelreset).\nUsing a local variable to capture initial touch positions seems more consistent with the mouse handler, as opposed to adding and removing the mousemove/mousewheelreset handler on touchstart/touchend.\n. Ah, I didn\u2019t notice this bug. :)  Yes, this should work.  How about restoring the mouse listeners on touchend, for systems that have both touch and mouse support?\nWe should also set translate0 = null on touchend otherwise mouse wheel scrolling will break in the case of {touchend, mousewheel} (no mousemove in between).  Or, we could use a local variable for touch positions like in #1403, and add a touchmove\u2192mousewheelreset handler.\n. Looks great.\n. Unfortunately we still have a problem here if separate touchstart events are fired, because we end up with two touchmove listeners (one with ID 0, another with ID 1), each with their own locations variable.  The first touchmove listener will attempt to handle it as a pinch, even though locations only contains one ID, so the lookup l1 = locations[p1.identifier] will fail.\nHow about dispensing with ID-based touch listeners, and instead only remove the touchmove/touchend (and restore mousedown) when all touches have gone?\n. Done in #1418.\n. This also fixes the following: a two-finger zoom followed by removing one finger, which should continue panning.\n. It works because the new closures take a snapshot of all current touches on touchstart, including touches that may have been \"touchstarted\" previously.  Replacing the old touchmove/touchend listeners is necessary to ensure the new state is used instead of the old.\nHowever, there is a slight issue due to d3_event_dragSuppress() being called more than once, with only one dragRestore() due to touchend being overwritten.  This means that a document\u2019s user-select style could be lost.\nI\u2019ve pushed a fix for this that creates touchstart/touchmove/touchend closures once on touchstart, and only restores everything if touchend happens with empty d3.event.touches.\n. I\u2019ve added a few comments!  The call to started() on touchend is necessary to recompute the locations, because the scale might have changed when pinching.  (This also updates scale0 for future pinches.)  Hopefully the comments explain what\u2019s going on here now.  I also set touchtime to null to avoid a spurious dbltap.\n. Hmm, you\u2019re right, I\u2019ll look into it\u2026\n. Looks good!\nHow about making the stream cacheable (only really necessary for non-null clipExtent)?  It would make the code slightly longer though. :)\n. I don\u2019t think this is correct as it breaks the case where a counterclockwise polygon (hole) is completely inside the viewport and therefore requires interpolation.  The point-in-polygon test is used to determine whether or not this is the case.\n. That\u2019s nice; I like the use of this.stream to simplify further.\n. Another idea could be to return a point instead of calling this.stream.point (or null to skip that point), but I felt that would be too restrictive as it would prevent generation of multiple points.\njs\nd3.geo.transform({\n  point: function(x, y, z) { if (z >= area) return [x, y]; }\n});\n. Looks great!  I still think we might want to remove floor, though, to avoid the brush edge inconsistency.  This really comes down to shape-rendering: crispEdges being used for the ticks, and Math.floor being used for the brush.  Ideally crispEdges should be used for both.  Unless you can think of another reason why floor is necessary. :)\n\nThis screenshot is for March, 2013, using the 3.3 branch with your latest fix.\n. Exactly. I\u2019m essentially filtering the touches so that each gesture only handles those touches that started on the target element.  I\u2019m assuming that d3.event.changedTouches on touchstart will only be those touches that started on the target element.  These identifiers are used to initialise locations0, and relocate() only updates existing locations in locations0, ignoring any touches that aren\u2019t present.\nThinking about it, I think there could still be problem because nothing is ever removed from locations0 on touchend.  So an identifier might be reused in a different zoom gesture, and create a conflict because it will be handled by the old zoom gesture on touchmove.\nI wonder if it would be more robust to filter based on touch.target, and restore the old behaviour of resetting locations0 on relocate?\n. Done.\n(Aside: only reproduced on Chrome/Android, which appears to reuse identifiers starting from 0.  Safari and Chrome on iOS both seem to have monotonically-increasing identifiers, though I assume they\u2019d eventually get reused.)\n. One more issue: on iOS we use d3.event.scale, but if you try and pinch-zoom and hold it still while simultaneously panning on another target, the panning gesture will affect d3.event.scale and update the pinch-zoom target.  Using the distance fallback that we have there for Android fixes the problem, because this is computed using the filtered touches only.\n. Can you give an example where the ticks are not being displayed at all?  While this Windows/IE10 bug is annoying, it should still produce a step size that\u2019s within 1e-17 of the expected step size, so should still produce reasonable ticks.  They should be formatted using an appropriate format function, though.\n. Interesting.  I think we should adjust %d formatting to truncate non-integer floats, as this is what Python does.  See #1513.\n. This is backwards-incompatible if the previous behaviour of ignoring non-integer numbers was being relied upon, but I think that\u2019s unlikely.\n. Ah, I was using the older string format operator:\n```\n\n\n\n'%d' % 1.2\n'1'\n```\n\n\n\nI guess doing nothing for non-integer output is useful if you want to filter out non-integers, such as in #1512.  Maybe we should just close this then, as it doesn\u2019t really help with #1512, where only integer ticks were desired, and the change could well affect anyone that was relying on the integer-filtering behaviour.\n. Strange, I\u2019m getting similar results for both:\nBefore:\nSingle circle: 0.098ms/op.\nU.S. counties (separate): 56ms/op.\nU.S. counties: 53ms/op.\nDense graticule: 68ms/op.\nCircle polygons: 66ms/op.\nSpiral polygons: 47ms/op.\nAfter:\nSingle circle: 0.096ms/op.\nU.S. counties (separate): 55ms/op.\nU.S. counties: 52ms/op.\nDense graticule: 66ms/op.\nCircle polygons: 71ms/op.\nSpiral polygons: 46ms/op.\n. I added d3_geo_identityRotation, and performance is slightly improved for the \u201ccircle polygons\u201d benchmark (67ms).\n. I was able to drop a field (subject = true | false), which helped a bit.  The switch to a constructor doesn\u2019t seem to speed it up (even when allocating next/prev) but the code feels clearer.\n. d3.js is actually generated by UglifyJS, so I think it would be better to fix UglifyJS.\n. /cc @jfirebaugh\n. I see what you mean, but resampling requires both spherical and projected coordinates, so it would have to do additional gymnastics to capture both pre- and post-projected coordinates.\nI tried benchmarking something equivalent to your suggestion, where the projection switches to a special projectResample stream that doesn\u2019t do any resampling, but it actually seemed slightly slower!  240ms/op \u2192 250ms/op.  It turns out the same happens if I replace stream.point with this.stream.point in this patch, so I guess avoiding that additional function invocation doesn\u2019t buy us anything, at least in V8 (my guess is it gets inlined quite quickly).\n. (Note: I meant slower when compared with this patch, for the World countries precision(0) benchmark.)\n. @mbostock I suppose you might want to do the same for d3_geo_projectionRadians in that case. :D\n. Also, note that d3.geo.clipExtent is now a public API, so for high performance you probably want to: a) pre-project all features so that zoom and pan doesn\u2019t need to reproject, and b) use d3.geo.clipExtent to improve rendering of things like roads (you could potentially not use it for buildings if that was an issue, but 2D clipping should be much faster than spherical clipping).\n. Merged in v3.3.10.\n. This is a great fix: it preserves the ability to distinguish between longitudes at \u00b1180\u00b0 for antimeridian clipping, so I\u2019d be inclined to choose it over mine.\nWe may need mine in future for clip-polygon to avoid coincident points (unless I can think of a better way to handle them), but either will work for now.\n. Merged in e9033c5938b89ef4b8defd85d70eaae537f743df (v3.3.10).\n. Works for me, e.g. http://bl.ocks.org/mbostock/4149176.\n. d3.locale was added in version 3.4.\n. Looks good!\n. Actually, I think it\u2019s safe for me to push this to master and NPM, as it doesn\u2019t affect the build\u2026\n. Can you explain why this might be necessary?  Map projections typically have particular mathematical properties: true scale along particular lines, angular distortion, areal distortion, etc.  These properties hold if the output coordinates are scaled by a single scalar factor (projection.scale).  If we allow independent scaling of x- and y-coordinates, these properties will no longer hold in general.\n. Will add a test at some point. :)\n. Hmm, actually your original clamped latitudes fix has a definite advantage at the moment, which is that the outline is correctly resampled:\n\nAlthough infinities are mathematically pleasing, they don\u2019t play so nicely with resampling:\n\nYour tweak to this branch isn\u2019t quite correct, because we also need to handle the projection of [\u00b1180\u00b0, -90\u00b0], which are the two corners of the projected \u201csector\u201d, and these would be [\u00b1\u221e, +\u221e], with the midpoint at [0, -\u221e].  But we also need to tweak resampling to handle points projected at infinity before merging this.  I also have a feeling I should have said (F - \u03c1 * Math.cos(n * \u03bb)) || 0 to handle (\u221e - \u221e) (will add a test for this case).\n. I\u2019m guessing it\u2019s unrelated to the topology, but I noticed a clipping bug the first time I viewed your example.  Here\u2019s a reproducible example:\n\n. You beat me to it! :)\n. Looks good!\n. Accidental pull request?\n. I\u2019m not sure I like the * syntax either, but it seems consistent with CSS selectors.\n. You can already do that using .on(\".drag\", null) to remove all listeners within the \"drag\" namespace.\n. Ah, good point.  I\u2019ll remove that commit, thanks!\n. I think this has been fixed in version 2.1.0 of AMDClean (see gfranko/amdclean#48)  Can you close this issue if that's the case?\n. Please reopen if there\u2019s still an issue.\n. I\u2019ve pushed a couple of simplifications, mainly aimed at reducing branching.  The first commit simplifies using a loop.  (I also renamed bottom to below elsewhere in the code, and changed > to >= for consistency.)  The second commit uses a switch statement aimed at reducing branching further, plus I think it might slightly more readable.\nI\u2019ve added a test but it doesn\u2019t check to see that find searches the nearest nodes first, as this is a bit difficult.  Perhaps a callback should be added to the private API?\n. The use of new Function(string) is there for performance reasons (around 2x faster in V8).  See commit 2358fd0fb43d74cb72ddc4dd2218ab9153d0af02.  Any untrusted input is first encoded as JSON before being compiled, so it should be safe.\n. That\u2019s much slower, because it\u2019s now calling JSON.parse, JSON.stringify and row.map for every row.  The advantage of the precompiled function is that you end up with something that\u2019s equivalent to:\njs\na = function(d) { return {foo: d[0], bar: d[1], baz: d[2]}; };\nYou can see my benchmark code and try it for yourself.  I can\u2019t see any other way around this issue other than switching to the slower version (around 2-3x slower according to my benchmark) if the strict CSP is detected; see my fix in #1910.\n. To do:\n- [x] Consider moving the unsafe-eval check to be inside d3.dsv so the warning only appears when d3.dsv.parse is used.\n- [x] Add tests for the slower parsing code.\n- [ ] And of course: consider whether it\u2019s worth having two code paths and extra detection code for this.\n. I tried something similar but to no avail.  I\u2019ve rebased against master, moved eval detection to occur on first use, and added a test for the no-eval parsing case now.  All that remains is to decide whether it\u2019s worth including at all!\n. Thanks!  I\u2019ve added the transition.text getter too.\n. I implemented it because I wanted to see how it might be done, but I\u2019ve never actually needed it thus far.  I get the impression the original report in #866 was motivated by \u00e6sthetics and wanting transitions to behave more like selections, rather than a real-world use-case, so maybe we should Icebox this.\n. I suppose the original report mentioned methods that accept either a selection or a transition, and the desire to use getters on transitions for this reason.\n. It sounds like the minifier is broken.  Which one are you using?\nIf the original code is valid JavaScript, I don\u2019t see any reason to change it to comply with bugs in minifiers.\n(Also, since we use UglifyJS with \u201cbeautify\u201d turned on to generate d3.js, your change above is actually dropped anyway after beautification.)\n. LGTM\n. Thanks!  I tried a few different tests in various browsers and I think my fix is a bit more general as it should handle non-text local files too: #1956.  Various caveats still apply, but it avoids the InvalidStateError.\n. Just to be clear, d3.shuffle already exists.  This issue is about adding parameters to allow shuffling a subset of an array, as requested in #1865.\n. I think i0 \u2265 i1 should be a noop.  For negative indices, I think the behaviour should simply be undefined.  One could imagine negative indices implying a position relative to the end of the array; perhaps this could be added in future, hence I\u2019d prefer to leave the behaviour undefined rather than committing to a specific interpretation.\n. This is not backwards compatible and I think it\u2019s unlikely we would want to change the API even in 4.0, as these functions are quite widely used.  I can see the utility of retrieving the largest element according to some value function, but I'm not sure how it should be supported (other than adding an optional boolean argument, which feels ugly).\nNote that d3.extent is also affected.\n. There are problems with this approach (data-inheritance and grouping), discussed here, so I don't think we would want this.\nFWIW, I find the version with a variable more readable.\n. Can you provide a reproducible example, e.g. on http://jsfiddle.net or http://bl.ocks.org?\n. OK, I think I managed to reproduce it.  The issue is similar to the one reported in #1940.  Essentially the problem is due to calling transition methods on a stale transition:\njs\nvar s = d3.select(\"body\").transition().duration(0);\nsetTimeout(function() { s.transition(); }, 0); // fails\nsetTimeout(function() { s.each(function() {}); }, 0); // fails\nIn your case, you're attempting to create a chained transition for a stale transition (probably because you have a reference to the transition and you are using it in an event handler).  This isn't going to work, because the methods on a transition are designed to be called prior to the transition starting (prior to the first timer tick).\n(Strictly speaking, you can call methods as long as the transition hasn't completed yet, but you can't necessarily guarantee that unless you're careful.)\nYou might want to read Working with Transitions, or if you're feeling adventurous, read the source for d3.svg.brush to see how reusable components can be designed with transitions in mind.\n. > Is there a mirror problem with entering ticks?\nRight.  If you switch from a logarithmic scale to a linear scale (let\u2019s say the linear scale has a tick at 0, or a negative tick value), then yes, this code will cause an invalid transform attribute to be set:\njs\ntickEnter.call(tickTransform, scale0);\nNote that there isn\u2019t actually a functional problem at the moment as far as I can tell; the author of #1968 was probably misattributing their problem to this error being shown in the console, when actually I think they just hadn\u2019t reset the positions of their <text> elements correctly.\nPerhaps a cleaner fix would be to call the tickTransform setters with a special \u201cfallback\u201d scale:\n``` js\nfunction d3_svg_axisFiniteScale(scale, scale0) {\n  return function(d) {\n    var value = scale(d);\n    return isFinite(value) ? value : scale0(d);\n  };\n}\ntickExit.call(tickTransform, d3_svg_axisFiniteScale(scale1, scale0));\ntickEnter.call(tickTransform, d3_svg_axisFiniteScale(scale0, scale1));\ntickUpdate.call(tickTransform, scale1);\n```\n. Updated the patch to reflect this change as I think it\u2019s cleaner.  Of course, it still means that some exiting/entering ticks will move and others will fade out/in in-place, which might not be ideal.\nAnother idea could be that movement of ticks should only happen between two scales of the same type {linear, linear}, {log, log}, etc.  We already do a check for ordinal scales, in which case all ticks are treated the same, so that all fade in/out in-place.\n. I suppose you could say there is a functional problem, in that some ticks will be transitioned, and others will fade in-place, which probably isn\u2019t the best approach.  I suppose we could check first to see if all the ticks are finite in a particular scale, before transitioning using that scale, as I think detecting different scale types isn\u2019t that simple.\n. Your demo has convinced me that mixed moving and in-place transitions look fine for quantitative scales though.\n. Excellent, thanks!\n. Actually, I was thinking more that if JavaScript's default string coercion resulted in exponent notation, this should be detected and grouping disabled, for all types, not just e.\n. Thanks!  This is superseded by #2000.  We still need grouping for exponent notation, e.g. if 0-padding is enabled, or if the thousands grouping is 1 or 2.\n. Edit: ignore this, I had a bug in my implementation and I wasn\u2019t tracking zooming for mouse events!\nPreviously, if a zoom transition was interrupted, no zoomend would be triggered.  I found it quite pleasant to use .on(\"zoomend\", transition) for endlessly looping zoom transitions, because interrupting via user input (mouse gesture) would not trigger a new zoom transition until the gesture is finished.\n~~I feel like adding a zoominterrupt event isn\u2019t necessarily the best solution, because it seems preferable to maintain the consistency of {zoomstart, zoom, zoomend} always occurring, but it would be nice to distinguish between an interrupted zoom transition and one that has reached its desired endpoint.  Perhaps an additional property should be included in d3.event to indicate the type of zoomend that has occurred?~~\n. Thanks for the patch, but this is working as expected; selection.on has a signature of:\n- selection.on(type[, listener[, capture]])\n- selection.on(object[, capture]), where object is of the form `{typeA: listenerA, typeB: listenerB, \u2026}.\nI can\u2019t see any reason to pass an array instead of an object; if you want to set multiple types of event listeners at once you can use an object.\n. Thanks for the contribution!  This is now superseded by #2000.  I don\u2019t think you needed to use such a general regular expression to detect exponent notation; it should always be a lowercase \"e\".  I\u2019d welcome any further feedback.\n. Ah, I hadn\u2019t thought about Infinity, thanks. :)  I think it\u2019s reasonable that d3.format should only expect numbers, though.\n. Sorry, I meant \u201cfloating point numbers\u201d, which includes \u00b1Infinity and NaN.  You mentioned:\n\ncustom types (value formatters) which may output something other than 'e'\n\nPerhaps I was confused by that, thinking that you were trying pass strings instead?  Anyway, I agree that any floating point numbers should be supported.\n. Superseded by #2000, which no longer adjusts the width before the switch statement.  This is because the width depends on the thousands grouping being used; previously it assumed a grouping of [3], so instead I modified formatGroup so it auto-truncates to the right width where appropriate.\n. This addresses the common use case of appending new elements and setting a class attribute, but I feel like `.append(\"div\").attr(\"class\", \"foo\") is clearer; in your proposal it\u2019s not immediately clear that the second argument is the class attribute.\nNote that you would also want to make selection.insert consistent and accept a class too, which gets a bit tricky because it already accepts two arguments and the second is optional.\n. Yes, I think I prefer this approach, and the #id syntax is useful too.  It would certainly reduce the amount of code required for these common cases.  For setting multiple classes and an ID, they could simply be concatenated, e.g. name#id.class1.class2.  I\u2019m not sure if any order should be supported, or perhaps the ID should always come first.\nI\u2019m still a bit cautious about doing multiple things within selection.append, but at least this syntax is clearer.\n. See also #2023.\n. Related #824.  Mike explains why exposing .each on the enter selection is undesirable:\n\nvalid but may be surprising since this is a placeholder node\n\nSo I think this probably isn\u2019t the right fix as it\u2019s an API change.  I\u2019ve pushed an alternative fix for the enter.size error in #2046.\n. Thanks for the contribution, but I\u2019m closing as I don\u2019t think we want to add .each to enter selections for the reasons given above.  However, feel free to discuss further if you think there\u2019s a good reason to include it!\n. > I could see potentially wanting to iterate over the enter selection for debugging purposes, to inspect the entering data before elements are appended, on a per-item basis.\nYou can call .each on the appended selection if you need to inspect the entering data.\n. It would be nice to decide on the most appropriate way to adjust the zoom.event duration if we go this route.  I\u2019ve tested something like:\njs\nvar transition = d3.select(this).transition()\n    .tween(\"zoom:zoom\", function() {\n      transition.duration(S * transition.duration()); // S is van Wijk path length\n    });\nHowever, it seems like a bit of a hack to rely on the existing transition\u2019s duration, so perhaps it should be an explicit parameter, perhaps:\njs\nzoom.duration(function(S) { return S * 1000; }); // or zoom.duration(null)\nUsing zoom.duration(null) would fall back to relying on the existing transition duration.\n. Similarly it would be nice to set an arbitrary ease function for the zoom behaviour.\n. I agree about the awkwardness.  Let me attempt to rephrase the issue a bit.\nIn \u201csmooth and efficient zooming and panning\u201d, we have a curve in (u, w) space.  The idea is that moving along this curve at a constant velocity results in a constant rate of perceived change.\nIgnoring delay, D3\u2019s transitions take a duration, and an easing function.  Suppose we choose linear easing, and suppose we want to animate at a constant velocity along our (u, w) curve, which varies in length depending on the view state before/after.  Hence the transition duration varies depending on length of the curve.\nThe zoom behaviour computes the length of the curve, but this is not done until the tween factory generates the tweening function.  I\u2019m not sure it\u2019s possible to reliably compute this curve length any earlier: the tween factory takes the pre-transition state on the first tick of the timer, whereas if we had something like your second example, transition.duration(zoom.duration), the duration would be set immediately and the pre-transition state might change later, prior to the first tick, thus changing the length of the curve.\nNote that for non-linear easing, you might still want the duration to depend on the length of the curve, but in a more complex manner e.g. you might want to specify a constant acceleration, or something else depending on the easing function used.\nIn d3.geo.zoom, I experimented with adding an optional duration parameter, which can be a function or a constant.  If it\u2019s a function, it takes the arc length S, and overrides the transition duration when the tween factory is called (hence this patch):\njs\nselection.call(zoom.duration(function(S) { return 1000 * S; }).event);\n. By the way, in my experimental zoom.duration implementation, the default is not to override the existing transition duration: zoom.duration(null).\n. How about something like the following, which is a slight extension of your selection.call(zoom.transition) idea:\njs\nzoom\n    .duration(function(S) { return \u2026; })\n  .transition(selection[, name]) // returns a transition\n    // .duration is deleted\n    .delay(\u2026);\nYou could also still use selection.call(zoom.transition) if you don\u2019t need to modify any transition parameters.\nOne of the nice things about the current zoom.event is that it is polymorphic and can be used on both selections and transitions; selections cause an immediate zoom{start,,end}.  With this proposal the behaviour always creates a transition, so the events will not fire until the next tick of the timer.\n. An explanation for the change would be nice!  Is this the same issue as #2006?\n. Nice!  Works well for tickExit.  Perhaps it\u2019s an edge case, but the only issue here is that tickEnter implicitly has transform=\"translate(0)\" when nothing is set (from the point of view of d3.interpolateTransform), so the tickUpdate transition will always go from zero to the position in the new scale.\nA bit odd, but you could work around this by saying:\njs\ntickEnter.call(tickTransform, scale1).call(tickTransform, scale0);\ntickUpdate.call(tickTransform, scale1);\n. Thanks, I opted to rebase my branch against master instead to keep the patch cleaner. :)\n. I think I swapped the order in that commit while debugging the general change to use slice instead of substring where possible.  That particular block is the only case where substring is actually better.  I marginally prefer checking i > 0 before g > 0; it\u2019s mainly aesthetics at this point though. :)\n. How about:\njs\nvar d3_zero = d3_functor(0);\n. Hmm, OK.\n. I\u2019m not sure, it feels like a lot of work!  It\u2019s kind of nice to have interpolate(a, b)(1) === b, but I don\u2019t know if it\u2019s really necessary.  We don\u2019t have a real-world example of someone relying on this, other than the brief report in #2039.  (Perhaps they were aesthetically motivated!)\nFor example, selection.transition doesn\u2019t guarantee that t === 1 on the last tick as far as I can see (it computes elapsed / duration, so it does feel a bit superfluous.\nWe\u2019d also want to check the various easing functions too\u2026\n. Ah, so the use of d3_ease_clamp for the built-in easing functions ensures that t === 1 on the last tick.  Maybe it would be a useful change in that case, since it would guarantee that the target value would be set exactly for a completed transition.\n. Unfortunately I\u2019ve just noticed a subtle change in behaviour with my original commit.  (Test added!)\nThe problem occurs when a is numeric and b is NaN, in which case b becomes Infinity.  My function then computes (x - a) / b, which will always return 0 for numeric x, when we would rather it returned NaN.  So I think we always need the === 0 check, and my version would need to be a bit longer:\njs\nfunction d3_uninterpolateNumber(a, b) {\n  if ((b -= a = +a) === 0) b = Infinity;\n  return function(x) { return (x - a) / b; };\n}\nCompare:\njs\nfunction d3_uninterpolateNumber(a, b) {\n return (b -= a = +a) === 0\n     ? d3_zero\n     : function(x) { return (x - a) / b; };\n}\nDo you still prefer mine? :)\n. Looks good.\n. Looks good.\n. Ouch.  Looks good.\n. Note that UglifyJS replaces undefined with void 0 anyway, so this only really applies to the unminified version.\n. Let\u2019s do it.  We save 11 bytes when gzipped+minified.  Performance is unaffected.\n. LGTM\n. Already fixed in #2115.  Will be part of the 3.5 release.\n. We are staging the 3.5 release in #2118.  No definitive release date, but you can follow the progress there!\n. I\u2019m happy with this in principle, but the original reason for the coupling was that rotation of a degenerate polygon might cause it to be treated differently for winding order detection: #1453.  In other words, if we clip unrotated polygons, at least we are consistent with the winding order detection used by TopoJSON.\nI\u2019m optimistic that we can eventually rotate any polygons prior to clipping, when I finally finish my improved clipping/point-in-polygon implementation; it might be better to move this to the 4.0 milestone!\n. Looks great!\n. Fix added for d3.select(window) bug.\n. Sorry, there\u2019s not enough information here to understand what error this is fixing.  It sounds like the issue should be fixed outside of D3, i.e. you shouldn\u2019t be setting an attribute to NaN on resize.\n. Are you sure you\u2019re testing the patch?  It hasn\u2019t made it to a release yet.  The call to translateTo is on line 1564 in master, but 1563 in the fix-zoom branch.  Your error message seems to indicate you\u2019re testing master.\n. Great, thanks.  I\u2019ve pushed a fix for that issue too now.  The issue was that interrupting an in-progress transition caused center0 to be reset, so it needed to be assigned after the interruption.\n. I can\u2019t see any browser exceptions when using element.setAttribute(\"foo\", NaN).  Which browser are you using?\n. OK, I see.  This is not an exception per se, but more of a warning, which is logged to the console if an invalid SVG attribute is set.  In fact, I think it\u2019s actually a good thing, because it\u2019s easier to figure out why things are not working.  In other words, we know that the chart is not displaying properly, because some values are NaN, which probably means a parsing issue.\nThe fact that null is treated specially (it means removal of attributes) doesn\u2019t necessarily mean we should extend this special treatment to other values, such as NaN.  In fact, .attr(<name>, null) is part of the API, and I don\u2019t think it would be sensible to make the API more complicated by making other values do the same thing.\n. Duplicate of #1916.  The file d3.js is actually automatically generated by UglifyJS, so the proposed patch wouldn\u2019t help, in any case.  But I think it would be better to fix the minifier, rather than include workarounds.\n. Yes, good point.  I\u2019ve updated the patch to support case-insensitive RGB/HSL functional notation as defined in the CSS spec.\n. We don\u2019t bundle examples with D3; you should put this on http://bl.ocks.org instead and perhaps add it to the gallery.\n. Ah thanks, I prefer the latter, I'll add it now...\n. Hehe, hadn't quite grokked that, thanks :-)\n. How do you add the initial title though? Or maybe you just detect if g.select(...) is empty?\n. Never mind, I think I'm confusing .select() with .filter() :-)\n. Okay I was right, but detecting emptiness is simple!  See what you think.\n. Yeah, I originally went the way of reversing the scale like that, but you can't have negative widths for rect so this minor setback made me create the *pos functions. Transitioning the flip sounds cool though, that's persuaded me to try it and work around the negative widths a different way :-)\n. I wasn't sure what to use as this here, any ideas?\n. Hehe, good idea.\n. Nice. Should I change d3_functor to d3.functor as I can't access it from d3.charts.js?\n. Well, just need to add d3.functor = d3_functor below it I should think.\n. Actually, renaming it seems more consistent. Sorry for the noise :)\n. Thanks, added in latest commit.\n. Done; should the dashed central line also be 1.5px?\n. Deleted.\n. Ah, cool :-)\n. I did this originally but I wasn't sure how to handle the zero-node case (WebKit would show a warning about d=\"\" in the console: Error: Problem parsing d=\"\").\nSVG Tiny 1.2 does explicitly mention allowing d=\"\" though, and as far as I can tell other SVG specs also allow it to be empty, so perhaps this is just a WebKit issue.  Firefox seems to handle it without any warnings.\nI'll do some more research and I'll probably just ignore this warning unless d=\"\" is actually invalid.  I can always do path.attr(\"d\", null) to remove the attribute if it turns out to be invalid.\n. Nice, less typing is always welcome :-)\n. Yep, the same thought crossed my mind about using a prototype!\nHere's a quick micro-benchmark: http://jsperf.com/structs-vs-objects\nStrangely, prototypes appear to be faster than structs in Chrome.  I'll see if I can test in other browsers too.\n. Updated version for Firefox: http://jsperf.com/structs-vs-objects/2.\nPrototypes win in all browsers so far except for IE.\n. D'oh, thanks!\n. Sure. Do we want rgb.darker() to produce the same as rgb.hsl().darker().rgb()?\n. Added; they turn out pretty close anyway.\n. Done!\n. Cool.  Do you think it's worth using a shared implementation for this and polylinear scales?  Or even make it public e.g. as d3.search?\nI added d3.search in 1a83029485aea399ade3c34a0a8225b952624af7 but it's the same as pv.search.  I'm not sure if the \"negative result\" behaviour will be useful in another scenario.\n. Okay, simplified.  It's essentially the same as the one used by polylinear scales.\n. Ah, yes.  I do try and keep to that as I've noticed you do that elsewhere.  Done in aeb1212f2537ed13b15f6e3ad600716caa0c42b6.\n. Yeah, I had it like this to start off with but I got carried away trying to make everything line up nicely. :)  I'll put it back how it was and see what you think.\n. Thanks, removed.\n. Interesting, thanks. :)\n. Oops, I actually just wanted to scale [root] here, for consistency, even though root.area isn't actually used.  Or do you think root.area should just be dropped altogether?\n. Excellent points, thanks!  Do you think it's worth renaming coordinates to latlng too?  I think xy is probably clearer than point for inversions.\nI'd forgotten Protovis had an implementation of these, it would have saved me deriving them from MathWorld!  Looks like there are a few more we should port from Protovis.  Fun times. :)\n. Note to self: need to add a unit test for this, this is required to handle floating point errors creeping in e.g. Math.acos(1.000000000004).\n. Neat.  I wouldn't pass up the opportunity to use a crazy trick!  :)\n. I could just reuse cc here to save on a variable, but then it wouldn't always mean \"cos c\".  I guess I could explain in a comment. :)\n. Ah yes, nice catch. I originally had it calling this.classed so the check was necessary, but not any more.\n. That sounds reasonable.  We can't do this for styleTween though because removeProperty returns the value of the property that was removed.  I've also just noticed that I haven't updated attrTweenNS to handle d3_transitionRemove.  Will push a fix shortly.\n. I added this to test for +null becoming 0 and affecting the maximum.\n. With hindsight, I agree that absolute is more useful.  Relative seemed natural when implementing as a sequence of matrix multiplications.  If we have absolute rotations, we probably need a standard order of axes.  I will think about this and update the branch soon!\n. That's correct.  I figured that longitudinal rotations would be fairly common, but this optimisation may become obsolete if we have a standard order in which to apply rotations anyway e.g. z, y, x.\n. Oops, good catch. I'll add a test too.\n. That worked perfectly, thanks!\n. I thought it might be slightly less brittle to check for createSVGPoint (perhaps something like JSDOM might implement in a strange way?), so I made this change anyway.\n. Ah, I thought propertyIsEnumerable would be consistent with for \u2026 in!  How about creating two temporary objects with {}, and copy both a and b's truly enumerable properties so that our friend hasOwnProperty can be used instead?\n. Fixed in bb61f88aaf9c6a6226a0a35034fc963536e857bd.\n. node.delay and node.duration might be better here?\n. Yeah, I had that to start off with. :) On second thoughts, it's nicer to keep this future-compatible with *-closed interpolators (as well as being shorter) so I've updated it.\n. Yes, I guess I wanted to test \"same type\" interpolation here instead of the decomposed version, but I guess it's better to stick to the original purpose of the test after all.\n. I removed this final clause, since the decomposed parts are not actually recombined at the moment.\n. I modified this slightly for clarity since it's actually the decomposed transform functions that are interpolated numerically.\n. Good point! It turns out this is error-prone for some time zones e.g.:\njs\nvar d = new Date(0);\nd.setFullYear(2012, 0, 1);\nd.setTime(+d + 100 * 864e5);\nconsole.log(d);\nsh\n$ node tz.js \nTue Apr 10 2012 01:00:00 GMT+0100 (BST)\n$ TZ=America/Scoresbysund node tz.js \nWed Apr 11 2012 00:00:00 GMT+0000 (EGST)\nRather than fiddling with offsets directly, it turns out there's an elegant solution: simply pass the full day-of-year to setFullYear and it will automatically wrap to the correct month and day.\n. I've fixed a similar issue for week-of-year/day-of-week parsing too.\n. Oops, yes, thanks!\n. value |= 0\n. Thanks, good catch!\n. Should it have \"radians\" somewhere in it, too?\n. \"upsampleProjectScaleCenterTranslate\". :)\n. Yeah, I was thinking of adding a fallback as per your comment in d3.geo.path, but then I wasn't sure whether to enable clipping or not.  It seems reasonable not to have clipping or rotation for d3.geo.albersUsa, at least for the moment, since you wouldn't use it for anything other than the US.\n. Good point.  Perhaps I should just reuse it where possible now, even if it involves passing an array.  We can then convert to the most common usage pattern.\n. Well spotted.  It wasn\u2019t actually necessary since .lineStart always reassigned it anyway, but it\u2019s cleaner and more efficient to only reassign on ringEnd.\nFixed in @623b594cf5d9e413da78e20cadbc00726521718e.\n. Fixed in @b085292ea82e21bab44aa38c6573f33a72f14461 and @ee2e784e3fd383a79520883e06ca78d16edbf68e.\n. The .map(Number) isn't necessary, strictly speaking, but makes it slightly more robust against weird inputs.  Perhaps it should just fallback to null if there's a NaN.\n. Sounds good.  I guess we still need an extent internally for backwards-compatibility with quadtree(points, x1, y1, x2, y2) though.\n. Oops. Copied from d3.layout.voronoi without checking. Fixed. :)\n. Perfect!  Done.\n. Done.\n. Should the signature be (d, i)?\n. This would be simple to add.  If an extent is set then we should return null for the size.  If a size is set then we can always compute an extent.\n. Yes, I removed it as I was thinking the signature root.add(d, i) might be confusing.  I think it\u2019s fine though, so I\u2019ll add it back everywhere. :)\n. LOL!\n. I discarded d, too.  Also, now we only precompute points if there are no bounds.  If we already have bounds we can just points.forEach(root.add) as before.\n. I believe new Date(0) is slightly faster (almost 2x; I guess it doesn\u2019t need to grab the current time).\n. Although speed doesn\u2019t really matter for this line!\n. Fixed.\n. Fixed.\n. Yeah, I was thinking other intervals could have issues too, e.g. a DST change occurring at 00:00:00 on New Year\u2019s Day!  So in theory, using setFullYear would not be sufficient, because it would \u201croll back\u201d to the previous year because 00:00:00 is actually 23:00:00 in local time (in the previous year).\n. I was thinking we should apply this to intervals smaller than a day for consistency, but I don\u2019t know if that\u2019s necessary.\n. I need access to .style though, which isn\u2019t available on d3_selectRoot.  I can\u2019t use d3_selectRoot.body either as it might not exist yet.  A similar creation of a new element is used in src/compat/style.js.\n. Yes, although we\u2019d need to ensure that d3_document.body is not null to be fully robust.\n. Nice idea!\n. Good point.\n. Hmm, just realised the case is different here e.g. window.mozRequestAnimationFrame.\n. Oops, d3_selectRoot is document.documentElement, so this should work.\n. Yeah, I think there was a cyclic dependency due to it being selection-specific.  Would d3_documentElement be appropriate?\n. Good idea!  That means we\u2019d be future-proof if Firefox ever add onselectstart, which makes me happy.\nI marginally prefer event, I think, as this seems more lightweight than behaviours (even though it\u2019s only used by behaviours at the moment).\n. Looks good.  This prefers user-select over onselectstart, but that's fine by me.  What should I call it if I move to the events folder?  Perhaps user-select would be better?\n. Yes, much more descriptive.  Done!\n. Beautiful. :)\n. Correct.\n. Nice!\n. Done.\n. It is currently not handled correctly in the identity rotation case, because d3_geo_equirectangular is used for this case (which doesn\u2019t perform the wraparound).  Would be nice to fix in d3_geo_rotation and remove these wrappers, assuming it doesn\u2019t affect anything else.\n. I did consider using a stream listener, but found it simpler to use a single point\u21a6point (rotate) function because an inverse was also required.\n. Yes, I think you originally made this change here.\n. I think we don\u2019t need to worry so much about \u03c6 as it should never be outside the expected range of [-\u03c0/2, \u03c0/2], i.e. we can consider it to be erroneous for this to happen.\nThe reason we need to wrap \u03bb is that it can often be outside [-\u03c0, \u03c0] in some real-world data, especially as some GIS software does this to work around the \u201cantimeridian problem\u201d.  So wrapping in the identity rotation case keeps everything consistent.  Looks like I added the wrapping in @514cdcf9 and @f9f4e265.\nIn summary, I think replacing d3_geo_equirectangular with d3_geo_rotationIdentity would be a good idea. :)\n. The performance impact is negligible but I did this anyway as it makes the code clearer.\n. Seems reasonable.  Rather than a true global (d3_geo_*) I went for a local variable for reuse in the two nested loops.\n. Done!\n. OK, I benchmarked and it seems negligible so I removed it.\n. Do we want to keep d3.touch private for 3.4.4?\n. Done.\n. Would it be better to pin to a specific UglifyJS patch version, since changes in the patch version can cause d3.min.js to change?  For example, I had to update to 2.4.16 to get d3.min.js to match the build in this pull request.  On the other hand, not pinning to a patch version means less maintenance. :)\n. I appreciate this might be for performance, but should d3_window(node) be used here instead of node.ownerDocument.defaultView?\n. ",
    "NelsonMinar": "I've updated the docs based on your comments. I've probably made a mess of git, sorry, still learning how to use it properly. Just gonna keep committing in my fork for now, when I get tired of it I'll figure out how to patch up a pull for you.\nA few responses to your comments:\n- The index of the bound data is correct, but if there's no data, it is equivalently the index of the element within its group.\n  Would it be more correct to say \"the index of the element in the selection\"? I don't understand data joins in D3 yet, so not sure which applies.\n- There's going to be a lot of repeated boilerplate: for instance explaining \"The function is invoked with two arguments: the bound data for the element and the index of the bound data.\" I'm not sure what to do about it yet.\n- There's a blurry line between \"reference docs for casual users of API\" and \"reference docs that are a specification for exactly how the system works\". I'm only capable of writing the former. I'm going to leave out specification details like the fact that attr coerces value to string if they don't seem necessary for a casual user like myself. I can't get the spec aspects of things right.\nMy goal right now is breadth, not depth.\n. I wrote a bunch more docs for selection methods for all the ones I think I understand. I'm done for now. If you like this, I'll try to document some other libraries (svg, scale, etc) as time allows. \n. I substituted your shorter implementation.\nIn issue 82 you suggested using interpolate() as a way to add clamping. I didn't do that as the library implementation of clamp() because it would mean no other user of the scale could use d3.scale.interpolate. \n. I've done the rename and think it's ready to go.\nI've also made a mess out of git, but I think it's all good now; changes 24de130 and 9889915 are fixing messes I made. If that screws up your pull let me know and I'll figure out how to get you a clean pull request.\n. I've added docs to the three interpolate methods.\n. ",
    "kmiyashiro": "Thanks Nelson! Need more docs.\n. ",
    "fridek": "This is more complete benchmark:\nhttp://jsperf.com/2equals-vs-3equals/3\nIn my work I tend to leave == where I'm absolutely sure that type will match.\nI think you should benchmark it with actual use of d3. == seems to be faster, but both are quite fast anyway.\n. ",
    "jfirebaugh": "Prototype.js hasn't been augmenting Object.prototype for quite some time (see here). As far as I know all major frameworks regard that as a strict no-no these days.\n. Hmm, am I supposed to include updates to d3[.chart].js and d3[.chart].min.js with every change?\n. The deferred semantics are certainly useful and preferable in some scenarios. Could we implement them as an option?\nd3.behavior.drag()\n  .deferredStart()\n  .on('dragstart', function () { // called on first move })\n  .on('dragend', function () { // not called if no move occurs })\n. We could provide both objects-as-values and an optional stringification accessor:\n// {'\\0a': {key: 'a', value: 'foo'}} internally:\nvar s = d3.set([{key: 'a', value: 'foo'}],\n               function(o) { return o.key });\ns.has({key: 'a', value: 'foo'}); // true\ns.has({key: 'a', value: 'bar'}); // true (!)\ns.values(); // [{key: 'a', value: 'foo'}]\nThis gets close to d3.map territory, but still I think useful for clarity of intent. And the typical use will be with scalar strings or numbers.\n. There was a window.focus() there prior to removing preventDefault. It didn't work. According to MDN window.focus() is for (maybe) bringing a window to the foreground, not for changing document.activeElement.\n. What exactly are the issues with never using preventDefault? @jasondavies raised the issue of future-proofedness, but it seems to me that could just as easily go the other way, with future default behavior being added that we would want to be triggered.\nI haven't encountered any issues with stopPropagation, and in general that is easier to customize externally to the behavior by capturing or using bubble or callback binding order, so liberal use of stopPropagation seems less problematic.\n. It looks like Leaflet has a workaround for the stuck iframe pan issue as well.\n. I still come down on the side of not preventing default.\n- Not preventing default requires that we find some way to prevent the specific default behaviors of text selection, image dragging and link dragging. It seems like we have a pretty good handle on this via canceling selectstart and dragstart.\n- Preventing default causes focus problems, which perhaps can be worked around, and problems with dragging in iframes, which as far as we know cannot.\n- We don't know the complete set of default behaviors. There may be existing default behaviors we haven't yet stumbled on, or additional default behaviors added in the future. Like selecting and dragging, some may be desirable to prevent. Conversely, like iframes and focus, some may be desirable to preserve. Overall, it's a wash.\n- In general, it's easier to work around specific problems caused by not preventing default, either in d3 or in client code, than to work around problems caused by preventing default. If preventing default is problematic for a specific use case, the only recourse is to fork a copy of the behavior (which is what I've done in iD). But if preventing default is necessary for a specific use case, it's trivial to add externally.\n- The relative complexity of canceling selectstart and dragstart vs. finding a focusable parent element seems like a wash to me.\n. Good question. I don't have any specific examples of differing user needs with respect to any of the default behaviors we're aware of, so I suppose that part of the argument is more about the the potential for unknown or future default behaviors. If we leave preventing default up to the user, and it turns out there's a default behavior that's important to suppress, it's as feasible for the user to do so as it is for D3 -- feasibility here being dependent on relevant DOM APIs. But if D3 prevents default, and there's a default behavior that's important to preserve, than forking is necessary, at least until such time as D3 stops preventing default or makes it configurable.\nThe latter is the situation that iD is in with respect to zoom behavior in an iframe. On openstreetmap.org, iD is presented in an embedded iframe, so it's fairly important that panning behaves nicely when the cursor leaves the iframe bounds. If D3 goes back to preventing default, but we don't find a workaround for iframe drag behavior, I'll continue to bear the (modest) cost of maintaining a patched version in order to preserve the desired behavior.\n. Are there any performance gains to be had in a similar change for d3_geo_clip? In iD, I'd like to just disable clipping entirely for (e.g.) buildings. Because buildings are so dense and mostly within the viewport extent at typical zoom levels, clipping them is a pessimization. For roads it's a different story -- they sometimes extend way off into the distance, and I see big improvements when they are clipped.\n. I'm seeing d3_geo_clipExtent being used even with clipExtent(null) -- looks like d3.geo.mercator does some kind of auto-clipping that can't be disabled.\n. Ok, am I doing it right? This gives a nice performance boost, though I suppose it means that iD will have (more) artifacts when editing along the antimeridian or at extreme latitudes.\n. Here's the benchmark results I get for various branches (MacBook Air, 10.9.5, node v0.10.29, v8 3.14.5.9):\nmaster:\nselection.data(values, key) (enter) 1.4ms/op.\nselection.data(values, key) (update) 1.8ms/op.\noptimize-map:\nselection.data(values, key) (enter) 0.70ms/op.\nselection.data(values, key) (update) 0.91ms/op.\noptimize-data:\nselection.data(values, key) (enter) 0.83ms/op.\nselection.data(values, key) (update) 1.1ms/op.\noptimize-data + optimize-map:\nselection.data(values, key) (enter) 0.40ms/op.\nselection.data(values, key) (update) 0.68ms/op.\nSo combining both optimization is faster on my machine. This make sense to me; the middle data loop has one unconditional get, one conditional has, one unconditional set, one unconditional remove (master) vs one unconditional get and one unconditional set (optimize-data).\nAny idea why the results show a pessimization for you?\n. selection.data is showing up in iD profiles. It's not a huge contributor, but I'm getting to the point where micro-optimizations, in accumulation, start to matter.\n. Too bad about native collections. I had hopes for those as well.\nDid you consider an Object.create(null) approach for avoiding any Object.prototype gotchas?\n. ",
    "capitalist": "I could use it in d3.inlog. Although, there are other ways to see the data. Either you retrieved it, created it with something like range, or generated it with something like a partition layout.\nOn the other hand. Consider the scenario where a user generates nodes in the document by interacting with the graph. If an event handler were adding/changing nodes based on the user's interaction, it may be useful to extract the resulting data.\n. ",
    "marcrichter": "May I ask what happened to this reusable chart initiative? I'm looking into using a Mekko / Mosaic chart in a crossfilter context, and I'd rather not implement this from scratch. Thanks!\n. Excellent, thanks! :+1: \n. ",
    "grawlee": "you guys are amazing!\n. ",
    "biovisualize": "It's not mine but from  kforeman. But my pull request closely followed \nwith a Superformula you modified that included a heart shape. And I'm \nglad it's referenced in the API and in the examples. Thanks!\nChristophe\nOn 10/28/2011 6:46 PM, Mike Bostock wrote:\n\nI decided not to pull this in, for the sake of keeping the code size small. But thank you for submitting anyway! And feel free to link your heart example from the wiki.\n. Good idea. But I will need help since I'm new to javascript. And I think my example using it is poorly coded. Can you give me a better working example using d3.svg.symbols?\nI added some shapes on the commit and on the example. I also added rotation so shapes like the drop, the butterfly and the heart can be upright. But I have to fix the tweening rotation that occurs between rotated shapes.\n\n. Wow, the code is pretty neat now! Even the shape list is in alphabetical order. I just added rotation (rot) to the parameter. I use a circular shifting on the point list instead of a computed rotation to keep the tweening smooth.\n. It's just to set the default orientation and to avoid rotation in the tweening. The user could as well ignore it and use rotate(). Don't you think?\n. Good job, thanks a lot!\n. I didn't realized that. Interesting.\n. Here is a working fork of your example (using rawgit.com) http://bl.ocks.org/biovisualize/e2fc77559c84c579761a\n. \n",
    "kforeman": "no worries, I actually agree now that the super formulas and such are\nso well fleshed out in examples!\nOn Fri, Oct 28, 2011 at 11:46 PM, Mike Bostock\nreply@reply.github.com\nwrote:\n\nI decided not to pull this in, for the sake of keeping the code size small. But thank you for submitting anyway! And feel free to link your heart example from the wiki.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/mbostock/d3/pull/172#issuecomment-2562147\n. \n",
    "syntagmatic": "Agree style and on would benefit from this syntax. I'll  implement something similar to jQuery's access function, which abstracts the overloading to a separate function and optionally executes values which are functions.\n. This change has been applied to style, on, and property. Those functions also return this if an object is passed in, so they can be chained (previous version broke this).\nYou can check out the new syntax in chord.js\nI interpreted the \"function form\" you both mentioned as passing in anonymous functions as values in the map, but delaying their execution until mapped to data. That should be the current behavior. Is this correct?\nOptional execution of function values was not implemented. A self-executing function, function () {}() can be used for this purpose.\nThere is a new function, d3.each, which is a general-purpose each for objects (but not lists) which can take a single extra argument.\n. Added basic support for the function form .attr( function() {return map} ), but evaluation of the returned map is fragile.\nThe issue is attrNull and attrFunction depend on name and value in the attr namespace. I re-implemented part of attrFunction to support functions within the map, such as cx and cy in the following:\njavascript\n.attr( function(d) {\n  return {\n    \"cx\": function() { return 100 + Math.random() * 800; },\n    \"cy\": function() { return 100 + Math.random() * 800; },\n    \"r\": 50 * d,\n    \"fill\": \"hsl(\" + (100*d+100) + \", 70%, 50%)\"\n  }\n});\nFind the above code in action on hello sort.\n. I agree that a function that a returns a map that contains functions isn't useful. My code snippet could be equivalently written:\njavascript\n.attr( function(d) {\n  return {\n    \"cx\": 100 + Math.random() * 800,\n    \"cy\": 100 + Math.random() * 800,\n    \"r\": 50 * d,\n    \"fill\": \"hsl(\" + (100*d+100) + \", 70%, 50%)\"\n  }\n});\nWhat about attrNull. If the function returns a map with null values, should those attributes be removed?\nThe rest is bikeshedding\nI disagree on a map that contains functions, which is cheap in complexity with a recursive call to attr and does improve consistency. Performance cost seems minimal.\nIt's a more straightforward translation from existing code, especially when only one attribute is a function of d:\n``` javascript\n// chained attrs\n.attr(\"y\", y1)\n.attr(\"height\", function(d) { return y0(d) - y1(d); })\n// map contains a function (the bikeshed)\n.attr({\n  \"y\": y1,\n  \"height\": function(d) { return y0(d) - y1(d); }\n});\n// function returns a map\n.attr(function(d) {\n  return {\n    \"y\": y1,\n    \"height\": y0(d) - y1(d)\n  };\n})\n```\nTMTOWTDI. They all look nice to me.\n. I'll give the return mapping of defined attributes a shot. attrs will actually return a list of maps in this case? Will this affect function chaining?\nI do strongly support overloading attr. I'm attracted to d3 in large part because of its use of SVG attributes and strings. Raphael's attr also uses SVG conventions, and can take a map. The two APIs are so similar, it would be very satisfying to me if they behaved identically when possible.\nThe function-which-returns-a-map form is a great addition though, since d3's attr always works on collections of data.\n. The implementation looks great! I'll take a look at how style, etc differ from attr next week. Been learning other parts of the API the past few days.\n. What's the status of this update? Has the attr change been merged into the main branch?\n. Great. This is the list of other operators required?\nstyle, classed, property, on, attr, attrTween, style, styleTween\n. My first attempt at styleTween is here:\nhttps://github.com/syntagmatic/d3/commit/afdebfc87745197dd10bd3c79da8a39b188ef6fa\nDoesn't work at all. Got hung up on: window.getComputedStyle(this, null).getPropertyValue(name). I see that d3.interpolate can do objects and tried this strategy:\n- Get keys of object in function (pass in dummy variable and throw away the values)\n- Create computed styles object (this seems to work)\n- Pass the computed style object into tween.call as the last argument\n- In styleTween (the one that gets added to tweens), loop over the result of tween.call, just like groups.style\nhttps://github.com/syntagmatic/d3/commit/8d74655987b791b013a44ab7216276254cfaaaf4\nUnfortunately this still doesn't work, but there are several functions I'm unclear on at this point. Next time I'll take a more detailed look at the interpolation functions.\n. If transition.style was implemented without transition.styleTween-- does that mean all style transitions with a multi-value would happen instantaneously?\n. I initially preferred the last variant (function returning a map of constants) over the second-to-last (map of functions), but after thinking on it for a few minutes I think this is a good compromise.\nUsing selection.each initially seems like a kludge, but within that function you can construct a map of constants for not only .attr(), but also .style(), .on(), etc. It would be quite verbose though.\nThe function returning a map of constants does look very pretty in coffeescript.\ncoffeescript\nselection.attr (d) ->\n  cx: x(d)\n  cy: y(d)\n  fill: color(d)\njavascript\nselection.attr(function(d) {\n  return {\n    cx: x(d),\n    cy: y(d),\n    fill: color(d)\n  };\n});\nvs the map of functions\ncoffeescript\nselection.attr\n  cx: (d) -> x(d)\n  cy: (d) -> y(d)\n  fill: (d) -> color(d)\njavascript\nselection.attr({\n  cx: function(d) { return x(d); },\n  cy: function(d) { return y(d); },\n  fill: function(d) { return color(d); }\n});\n. Ahh, very concise!\n. This is a decent workaround for now:\njavascript\nvar set_attrs = function(selection, obj) {                                                                                                             \n  for (var key in obj) {\n   selection.attr(key, obj[key]);\n }\n};\nExample:\nhttp://bl.ocks.org/2005817\nDiscussion:\nhttp://groups.google.com/group/d3-js/browse_thread/thread/0c293b88212a7e4d/440940a088052e27\n. typeof isn't ideal for detecting objects, especially since typeof null === 'object' is true.\nThough, jQuery uses this exact check in its access helper function for overloading attr, and I've never hit this issue in practice.\n. ",
    "jheer": "Note that I have since pushed a small update to the color library that fixes a typo bug in CIE76 and CIE94 color difference formulas.\n. Nice, @jrus. I appreciate Chromatist's inclusion of CIECAM02. I've considered implementing this also, but haven't had the time. Do you plan to also include other color difference calculations (e.g., CIEDE2000)? If so, I found a collection of test cases that you might find helpful; they are in my (currently out of date) D3 repo clone.\nThat said, one other thing I do like about my LAB color conversion code is that it follows the model of D3's existing color support, for example enabling color objects to plug right in to attribute definitions.\n. ",
    "jrus": "This may be useful:\nhttps://github.com/jrus/chromatist\n. Yeah, I\u2019m not suggesting you rely on my code directly, necessarily. Only that having existing an existing CIECAM02 implementation might be helpful, if you\u2019re interested in making one.\nI do plan on adding things like color difference calculations, though I don't have too much use for them myself. (For what it\u2019s worth, CIEDE2000 also seems to me to be a dramatically more complex model than is supported by any data or data + theory).\nI also want to add a Munsell lookup table & some kind of interpolation code for that, a lookup of ISCC\u2013NBS color names for  a given Munsell color, some more chromatic adaptation routines, and so forth.\nThe immediate use case for my CIECAM02 implementation: I need to do quite a bit more work on this thing, but it's at least vaguely interesting in this state:\nhttp://www.hcs.harvard.edu/~jrus/colortheory/javascript/colorpicker.html\nI think D3 (and protovis before) is totally great, so many thanks to you fellows. I've been meaning to write some sort of philosophical blog essays (on a not-yet-existing blog) for some time about them, as grokking protovis took me substantially longer than it would have if I\u2019d been able to see a more conceptual overview explaining the ideas behind the abstractions in addition to just the API reference and a bunch of examples. It looks like the D3 story is a bit better there, but of course the more the merrier when it comes to explanations of things. I'll let you know if I do \u2013 plenty of other projects too. :)\nJeff: your \"color spaces\" example is pretty silly, if I do say so, rendering every pixel as its own DOM square. Even if just rendering pixels in canvas image data arrays wouldn't show off D3 as much, it'd be orders of magnitude faster.\nCheers,\nJacob\n. What\u2019s the status of this? Does the current d3 now support passing an object into .attr? If not, can anything be done to help that along? Especially when using CoffeeScript, passing maps makes for much nicer syntax than several repeated .attrs, and matches the kinds of APIs I like to make for other purposes. Undefined evaluation order doesn\u2019t seem likely to ever matter in practice.\n. @syntagmatic, you saw this thread, right?\n. @syntagmatic that's an interesting one. I take it that d3_selection.call(func, arg1, ...) does roughly the same thing that func.call(window, d3_selection, arg1, ...) would do? That (i.e. call) seems like a potentially confusing method, but I suppose fairly useful. Is a similar API used in any other JS projects?\n. @mbostock I\u2019d argue it\u2019s a fairly big improvement in flexibility over the current API. Allowing the set-of-attributes-to-change to be passed around as its own object means that it can be created by extending a default object, can have its parameters easily switched based on some condition, can be passed through directly from a function input parameter, etc.\nIt\u2019s designing an API around using a JavaScript language construct (objects) for what it\u2019s made for, instead of creating a new ad-hoc construct (repeated method calls w/ (k, v) arguments against methods which return the original object back) to do essentially the same thing as the built-in construct already does, more elegantly, and justifying the choice based on \u201cwell, people are familiar with this from their experience with jQuery &c.\u201d, even though many existing libraries support both versions.\nIn CoffeeScript especially the common-case code ends up extremely clean and elegant. [speaking of which, did people see @raganwald\u2019s proposed whitespace-based CS chaining?]\nSupporting the d3_selection.attr(function() { return obj_of_attrs; }) version also would be nice, but isn\u2019t strictly necessary, and isn\u2019t quite as commonly useful as the d3_selection.attr(obj_of_attrs) version. If the former variant is too hard to implement cleanly, the latter alone would still be very nice to have.\n. It\u2019s quite helpful to be able to interpolate in terms of both LCh and Lab*. The former is useful when it\u2019s a desirable feature to keep chroma high (for instance, when interpolating from red to blue, it might be nice to go through a colorful purple instead of a dull purplish-gray). As a precedent, ArcGIS allows the use of either in its \u201ccolor ramp\u201d pickers.\nRegardless of which are supported, CIELAB \u2192 RGB transformations have to have some knowledge of gamut and some gamut mapping algorithm for out-of-gamut colors. The most obvious choices are (a) the nearest in-gamut point between a color and the grey of the same lightness, and (b) the nearest in-gamut point between a color and middle gray (L* = 50).\nHSL/HSV/RGB are quite perniciously bad tools for visualizations (and anything with human input involved, really), and the documentation should clearly recommend against them.\nChroma (C) should scale the same as a/b*, or else it\u2019s entirely confusing what it means. CIELAB has no \u201cmaximum\u201d chroma, and 100 is not in any way special. It should not accept percentages.\nYou might be right that CIECAM02 is more complex than necessary for many D3 applications.\n. One more thing that should really be clarified: I assume the CIELAB here is relative to a reference D65 white point? This is fine, but it should be pointed out in the docs that this makes for different output than Photoshop, which uses a chromatic adaptation transform (the Bradford CAT) to adapt XYZ colors from a source color space\u2019s white point (e.g. sRGB\u2019s D65) to D50, and then computes CIELAB coordinates based on that D50-adapted XYZ.\n. Main thing that would be very helpful if people plan to start using this is some kind of gamut mapping algorithm. Otherwise, they\u2019re going to do LCh interpolation from one bright color to another, and end up with all kinds of weird artifacts along the way. Otherwise, it\u2019s nice that D3 is trying to put some better color spaces in. :-)\n. ",
    "akre54": "Might be worth revisiting this. Any function that leaks arguments or reassigns a var based on arguments is a target for deoptimization (no JIT'ing).\nD3 does this all over the place so I'd be curious to see what perf improvements could be gained by a switch.\n. Building elements from a selector string works beautifully in templating languages like haml and jade, but I think trying to shoehorn support into d3 is ugly and fraught with peril (and edge cases!), and would only really be good for simple strings. -1 from me.\n. Wouldn't Object.keys be faster here for enumerating own properties?\n. I just retested it. It was showing 1.7m for sparse array vs 1m for raw loop. Will look into it :)\n. Large values is where this really makes a difference (see Underscore discussion)\nhttp://jsperf.com/underscore-vals/3\n. ",
    "natevw": "Ah, yes, it is a case-sensitive issue \u2014 both for the computer and my debugging! I'm running on HFS+ with the case-sensitive option on. I didn't quite realize what was going on and the comment about making a symlink only further confused me.\nAnyway...all of the following work:\nrequire(\"../../uglifyjs\")\nrequire(\"../index.js\")\nrequire(\"../\")\nNow that I'm a bit less of a \"modern CommonJS\" newb, I would say require(\"../\") makes the most sense for this kind of self-reference.\n. Although a bit more complicated to implement, I really liked the second version. While it may be subtle, I think it actually helps with both issues: putting only the array to the left of the accessor strengthens the suggestion that it does not apply to the search value.\nUpdated, with unittests this time (after the existing ones proved invaluable in spotting some issues with my first conversion :-)\n. You didn't happen to do any performance testing on using an accessor for comparison, did you? I've got a situation where I have an array of non-primitive values that have a well-defined order but won't compare correctly using JavaScript's < operator (basically, a collection of sub-arrays that each represent an ePub CFI reference).\nI suppose either way this should be it's own issue/pull-request\u2026kind of a rush job atm though so will have to followup later.\n. Looks like you've got the basics going. I wrote an implementation of touch recognition for Polymaps a while ago that I've been meaning to port to a D3 behaviour: https://github.com/natevw/polymaps/blob/a7b0f2a55594d93bd53c1f1679f0a7b09fce74ad/src/Touch.js\nMight be helpful as it detects multi-finger zoom and also 2-finger rotation. Was meaning to add double tap zoom in/out support as well but that hasn't happened.\n. IIRC it allows you to pan and zoom with any number of fingers, not just two. This tends to work a bit better especially for children who don't notice extra fingers grasping the device. Rotation could probably be sorted out I think I just didn't want to do a full parametric fit and left it out.\nDouble-tap for zooming in great, would love to see two-finger single tap for zooming out. (IMO none of this needs to block what you already have ready to merge.)\n\nDe: Jason Davies notifications@github.com\nPara: mbostock/d3 d3@noreply.github.com \nCC: Nathan Vander Wilt natevw@yahoo.com \nEnviado: Martes, 11 de junio, 2013 12:25 A.M.\nAsunto: Re: [d3] Add pinch-to-zoom support for Android. (#1298)\nCool.  What\u2019s multi-finger zoom?  We already support double-tap for zooming in.  Rotation would be nice.\n\u2014\nReply to this email directly or view it on GitHub.\n. +1 for landing this as-is, can always be extended later if desired. Didn't want to derail this pull request, just point out some similar work in case it's relevant for future improvements.\n. I'd find this handy too, of course maybe not needed in D3. I usually just add a helper function that reduces into Object.create(null) since I like the ES5 builtin way better than d3.map with string keys. Didn't think to repurpose nest for this case, though, nice idea.\n. I manually re-applied this work to the other branch. Wasn't sure how to \"join\" the #1792 pull request so the combined patch is at #1798. Closing this as it's replaced by the latter.\n. Any particular feedback why this was \"iceboxed\"? I need to review more fully \u2014 and figure out whether this patch still applies cleanly \u2014 but it's looking like a feature in an app I maintain may have relied on some of these fixes (and of course for IE support) after I switched to a different custom-patched D3 build that neglected this work. Ideally it would all just be in trunk at some point if possible.\n. xref as I pick this back up: http://bl.ocks.org/mbostock/9631744 is the nice little playground used for trying out d3.drag tweaks last round.\n. This patch definitely does not rebase cleanly, and most of its multitouch-related fixes were applied separately in the meantime.\nI've re-done the Win8 (i.e. Pointer Events) work as https://github.com/mbostock/d3/pull/2403 \u2014 @mbostock perhaps you could close this and review that instead?\n. @nikoloas Sorry I missed your questions earlier. Have you found a solution? If not, be warned this patch is probably way out of date.\nThe new d3-drag is even more like pointer events, although unfortunately pointer events are still not supported: https://github.com/d3/d3-drag/issues/25\nHopefully this work here could be ported over, I haven't taken a look at what that would involve yet.\n. Glad to see someone else working on Pointer Event support!\nI wonder on this patch, though, if it couldn't be combined more with the existing touch code? This seems to duplicate a lot of the calculations and logic separately for pointer events. I think ideally, a lot of that could be shared with the touch events.\nIt actually seems to me the zoom behavior might even use d3.behavior.drag internally to unify even more handling:\nd3.behavior.drag().origin(function () {\n    // avoid default parent-relative drag positions\n    var pt = d3.mouse(this);\n    return {x:pt[0], y:pt[1]};\n})/* now you have cross-platform pointer tracking via drag{start|move|end} events */;\nAs I mentioned in https://github.com/mbostock/d3/pull/2403 there might need a few little tweaks to the drag behavior to expose a bit more, but then it could abstract out the cross-platform stuff so zoom could do less itself.\n. Ah, good point with the exception handling (at least in V8, \"functions containing try/catch are not optimized\").\nI think what you're saying about letting exceptions be thrown naturally, is the same as I meant by \"overhaul to be more robust\". That does seem the way to go, then, though I can't really volunteer myself \u2014\u00a0after diving in this far, I decided the right fix for my client was a trivial change to stop a particular bit of app code from throwing in the first place ;-)\n. ",
    "jonfrost": "Right on to both of you.  The solution I started hacking up yesterday tested for .style.setProperty, which is wanted because IE10 will likely (hopefully) finally support setProperty like the MSDN docs state that it does.  Thanks!\n. ",
    "chrisgemignani": "Here are a few improvements, also looked at ticket #199. Can't use\nvar ie = !document.body.style.setProperty;\nsince the document.body is null.\n. Sure, I'll take a look. By the way, did a little more digging and here's the set of examples this fixes in IE9.\n- bubble/\n- box/\n- cartogram/\n- force/force.html\n- force/force-multi-foci.html\n- qq/\n. I've explored the document.createElement(\"div\").style.setProperty approach. \nApparently IE9 didn't have setProperty late in beta (http://www.quirksmode.org/blog/archives/2010/06/more_ie9_goodne.html). IE9 does have setProperty now but it's implemented slightly differently from the other browsers. Here's the scoop:\nIE9:  setProperty(name, value, priority) => value must be a string or you get an invalid argument runtime error\nOthers: setProperty(name, value, priority) => value is handled even if it is a number\nSo to handle this difference, I think we have to do IE detection again, unless you have another idea.\n.  Yup. I'll pull it together and hopefully get this closed out. \n\nChris Gemignani\nSent with Sparrow (http://www.sparrowmailapp.com)\nOn Friday, July 29, 2011 at 3:39 PM, mbostock wrote:\n\nArgh, that's annoying. Thanks, IE. Still, I could see branching three implementations based on calling setProperty on a trial element. If there's no such method, we fallback to direct-set; if the method throws a TypeError, we use a string-coercing setProperty; otherwise, we use the default on all standard browsers.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/mbostock/d3/pull/231#issuecomment-1684021\n. \n",
    "toofishes": "This isn't working when I test it with actual d3 code and should be reopened. I see the following in the IE 9 developer console:\nSCRIPT87: Invalid argument\nd3.js, line 10 character 5\nThis holds true for both the 2.3.0 release and current git HEAD (fe6128180e8). It appears returning null from a .style() call easily triggers this (background-color in my case), as well as returning null from a .html() function, which causes the literal \"null\" text to appear in objects.\n. It gets overridden correctly with the function from the error block.\nI can add a console logger in there and see it trying to call the real set property with either null + \"\" (which equals \"null\") in the .html() case or \"null\" + \"\" in the background-color case.\nI made my .html() function return \"\" instead of null, but the background-color problem still holds (and it is broken in IE9) if you navigate here: http://www.archlinux.org/visualize/\n. Correct, transition() is involved here, and somewhere along the way null is getting coerced to \"null\".\n. ",
    "XULA96": "I am using version 2.9.6 of d3 and whenever I am using IE9 in compatibility mode I get the following error:\nSCRIPT5009: 'CSSStyleDeclaration' is undefined \nd3.v2.js, line 7 character 3\nAny assistance with this would be greatly appreciated!\n. I would love to not test in compatibility mode....I'm doing some R&D on bullet graphs to add to the product I work on for my employer.  Unfortunately many of our clients are still using IE8 and we have to make sure all of our screens with in IE8, IE9, and IE9 in compatibility mode.  If there is no workaround or fix for this, then I will move on in my R&D and see what other option are other.\nThanks\n. ",
    "joshlangner": "@XULA96 For clarification, by default, switching IE9 to \"compatibility mode\" generally throws IE9 into an IE7 mode - not even IE8. That said, D3 does NOT work in IE8 and below due to a significant number of issues. \n. ",
    "futuraprime": "Incidentally, they're based around the format notations already built in to the time system (%Y, %B, etc), so to get ticks by month you'd call\nscale.interval( '%B' )\nscale.intervalFormat( '%B' )\n. ",
    "lynaghk": "I had similar thoughts---in this case the issue was small enough I thought\nit'd be easier to ask you via pull request.\nIt definitely felt a bit gross to kludge around to determine if the elements\nwere svg or html.\nThe road to hell is paved with special cases, eh?\nD3 is great because it is so close to the DOM, but it would be nice to have\nsome things that patch up inconsistencies and unintuitive behavior in the\nDOM.\nI don't know if there are any existing JavaScript \"mixin helpers\" for D3,\nbut I've been putting together my own set of macros in Clojure /\nClojureScript for use with D3 (attr and style accepting maps and being\nexpanded into multiple calls during compilation, for instance).\nI'll let the mailing list know if anything useful comes out of that.\nThanks Mike!\nOn Fri, Aug 5, 2011 at 4:14 PM, mbostock \nreply@reply.github.comwrote:\n\nNeat idea! However, I'm against adding methods to the core selection class\nthat change the behavior of the underlying representation.\nThe D3 kernel is intended to be \"transparent\", in the sense that each\noperator is a direct pass-through to the underlying W3C DOM method. For\nexample, style(\"foo\") sets the \"foo\" style property, and attr(\"bar\") sets\nthe \"bar\" attribute, even though D3 doesn't know what the \"foo\" style or\n\"bar\" attribute mean. In other words, there are no special-cases or\nassumptions about what the attributes or styles mean, or even whether\nthey're supported.\nThis is also why I say D3 is not a compatibility layer. For example, in\ntheory, you might be able to silently transform SVG elements to VML under\nthe hood, but that's a ton of work and breaks the simplicity of the design,\nand the ability to inspect the DOM using the browser's developer tools.\nThis is all a long way of saying, I'm happy using the existing sort and\nstyle(\"z-index\") attributes, rather than creating a helper method that\ntries to choose between them intelligently. You're of course welcome to use\nsuch a helper in your own code, but it shouldn't be part of the kernel.\nThanks again for the contribution. I hope my response is reasonable even\nthough I closed the request! :)\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/mbostock/d3/pull/242#issuecomment-1739842\n. Yeah, I'm still thinking this one through; to give you a bit more context, my need for this functionality came up while I was using ClojureScript to handle the actual looping across the data---I was just using D3 to manipulate the DOM.\nI'm trying to factor out my code into reusable components by writing functions that use D3 to create and return <g> nodes, which get thrown into an <svg> higher up.\n(Similar to the components in d3.svg, but with raw nodes instead of D3 selections)\n\nIn any case, all of my thoughts about this have been for non-data-driven fiddling with singleton nodes like mouseover-popups and stuff like that---I'm not sure how useful being able to handle raw DOM nodes would be outside of that. \n. Sounds good; that's what I typically end up doing in any case (in JS or Clojure).\nHave a good weekend.\n. ",
    "mhalle": "Would it be possible to do this merge at this time?\n. ",
    "dandean": "Any idea if this will be merged in?\nI'm working on my own much simpler attrs implementation which basically iterates a map and calls attr. But, if there are plans to merge this pull request in, I'd love to take advantage of its enhanced functionality.\nHere's my branch, for reference:\nhttps://github.com/dandean/d3/commit/a0754f6da6e035c7eb804253b42579713703a7d1\n. Cool - thanks @mbostock !\n. ",
    "mattsacks": ":+1:\nThis would be great to see in 2.9\n. ",
    "idibidiart": "selection.attr({\n  cx: x,\n  cy: y,\n  fill: color\n});\nFor the new user, reading the above, it's hard to tell that x, y and color are in-line declared functions because it's more typical to see a function declaration in this type of situation or else the assumption is that it's a function expression defined elsewhere or just a variable. Ugh, a little mind bending but any say I can't say I don't love it..\n. in-line declared was meant to read: implicitly declared\n. @mbostock \nI didn't know that because I didn't expect it \nThe more I get into D3 the more my mind opens up to Design As Magic and further away from Design As Commodity\nNot to be dramatic or anything but it certainly appeals to the magician/mathematician in me (in terms of its style) more than the typical \"end user\" The Principle Of Least Surprise appears far less important in the design of D3 than its non-trivial, almost magical design patterns :)\nSorry to go off topic. I just wanted to relay my subjective experience of the medium (D3) as I'm getting to know it\n:)\nMarc F\n. ",
    "dribnet": "\nI\u2019d like to kill support for the single-function signatures.\n\n:cry:\nI get it. \nNevertheless replacing wasteful code like:\njs\n      .enter().append(\"line\")\n        .attr(\"x1\", function(d) { var p = project([d.lon, d.lat]); return p[0]; })\n        .attr(\"y1\", function(d) { var p = project([d.lon, d.lat]); return p[1]; })\n        .attr(\"x2\", function(d) { var p = project([d.lon, d.lat]); return p[0]+10; })\n        .attr(\"y2\", function(d) { var p = project([d.lon, d.lat]); return p[1]+10; });\nwith\njs\n      .enter().append(\"line\")\n        .each(function(d) {\n            var p = project([d.lon, d.lat]);\n            d3.select(this)\n                .attr({ x1:p[0], y1:p[1], x2:(p[0]+10) y2:(p[1]+10) });\n        });\ninstead of\njs\n      .enter().append(\"line\")\n        .attr(function(d) { \n            var p = project([d.lon, d.lat]);\n            return { x1:p[0], y1:p[1], x2:(p[0]+10) y2:(p[1]+10) }; \n        });\nmakes me shed one tear... but maybe combinatorial explosion of method signatures would have made me shed two.\n. ",
    "coli": "I really wish this is supported..\nselection.attr(function() { return {foo: 42}; });\n. Thanks! \nUsing each + select as a workaround just turns functional code back to being procedural code again.\nEdit: it breaks animation too.\n. ",
    "enjalot": "I see your reasoning and I can agree with it. My main thing was the problem with arc.centroid returning NaN, it happened because I did not set the innerRadius to 0 (but did set an outerRadius for the arc).\nThe reason I see this as a bug is that the pie chart was still drawn as expected, because not setting the innerRadius of an arc assumes a default of 0 when drawing, but is undefined when calculating the centroid. \nPerhaps the solution to the bug without changing the API would be to give a default value of 0 for innerRadius of an arc when it is not set?\nHere is an example of the behavior (I log the arc.centroid calculation to the console)\nhttp://bl.ocks.org/1225877\n. ",
    "boothead": "I've update my gh-pages to give  a quick demo of the differences here: http://boothead.github.com/d3/ex/bullet.html. I tend to agree with you that it would be nicer to have a consistent api across the different modules. This one is just a first stab at something that would meet my (possibly quite narrow) needs. Mine also looks pretty messy if you get lots of markers close together.\nBTW - the changes I've made to bullet.js aren't showing up in the \"Source code\" section... Any idea why?\n. Sure thing, I'll keep my open for it. Do you think you'll want this feature in the new lib? If so I'll port it over.\n. ",
    "yasirs": "You are right, I have changed the structure in keeping with the architecture used for the link properties. It is also backward compatible. The use case would be if certain nodes are \"bigger\" or supposed to be better separated in some way. Do you mean a visualization illustrating something like this?\n. Thanks! I think it should work now.\n. there!\n. ",
    "AWinterman": "I found pretty big error in my code, so it should probably just be ignored.\n. ",
    "pjjw": "also- in cube, the result looks like this:\n\n. ",
    "larskotthoff": "I've changed the length test to instanceof Array and am also checking whether exactly one argument has been given now. Unless a ticks function accepts exactly one argument that is an array, it should be fine.\nThis should also take care of the case when tickArguments_ is empty.\n. I've added a separate variable and function. I'm wondering though if there should also be something to keep ticks and tickValues in sync. At the moment, the two are completely separate. I could use tickValues to set the ticks to [1,2,3] and then call ticks() to get the default value of [10] when there are really just 3 ticks.\nDo you think that on setting tickValues tickArguments_ should be updated to tickValues.length? Anything else to take into account?\n. Thanks Mike.\n. Not sure if there's a github way of linking to issues, but this fixes the problem discovered by Jason in https://github.com/mbostock/d3/issues/251\n. Well technically += only has a side effect (the value of x changes), so I'm guessing that using its return value is not well defined. The operator itself is executed correctly, but the return value happens to be different from other browsers.\nSee http://rx4ajax-jscore.com/resource/glossary/glossc.html#compound_assignment_operator\n. Ah. Looks like Opera has implemented it incorrectly then :)\n. Well.\nd3%js: Makefile\n    @rm -f $@\n    cat $(filter %js,$^) > $@\n    @chmod a-w $@\nThis works as well. Maybe a bit hacky without the dots?\n. Sure. To display a world map that always starts at the top left corner, you would do\njavascript\nproj.geotranslate([-180, 90]);\nYou could do the same for a country by extracting the min x and the max y coordinates and doing\njavascript\nproj.geotranslate([xmin, ymax]);\nOr you could center a feature with\njavascript\nproj.geotranslate([x, y]);\nproj.translate([width/2, height/2]);\n. Yes, that does look very similar! I actually like that better because it doesn't require two internal arrays. This would be scale-independent as well by the looks of it?\n. I've had a closer look at #318, but I can't figure out how it should be used. So d3.geo.rotate() takes coordinates (that you can adjust by calling .x etc), but how do I pass it to a projection? I have tried things like\nJavascript\nvar proj = d3.geo.equirectangular(),\n      rot = d3.geo.rotate(),\n      path = d3.geo.path().projection(function(d) { return proj(rot(d)); });\nrot.x(90);\nbut that doesn't seem to work for values other than 0.\n. Ah ok. I didn't get the meaning of the dimensions :)\nWhat I'm trying to do as a hello world like thing is to simply put -180, 90 in the upper left corner, like I did with my changes. rot.z(180) works as expected, but I can't get the latitude right. rot.y(value) rotates the projection, but doesn't really move it. How would I do a vertical translation of the projection?\n. There should be some common functionality though. At least rotating the z-axis does exactly what I want to do for the longitude (if no rotation is applied along the other axes). I'll have a look if this can be merged somehow.\nAnother random thought -- I played around with this and the equirectangular projection. After some rotations, it wasn't an equirectangular projection anymore. Maybe this funtionality could extended and used to derive new projections by rotation and/or transformation matrices?\n. Well, my point was that to get from e.g. a Mercator projection to an equirectangular projection, you can apply a transformation to the latitudinal coordinates. You can use a transformation of the same kind to shift the projection though to center a location. Similarly, you can get to an azimuthal projection by rotation.\nSo my idea was to define all the projections in terms of a basic projection. The same methods used to define these projections could then be used to center locations, rotate, etc. The advantage would be that new projections could be defined with far less code. This should definitely be a separate pull request though (and would probably require quite some work to get it right).\n. Let me try to clarify with some code. Assume I have something like\nJavascript\nvar proj = d3.geo.equirectangular().scale(1).translate([0,0]),\n            f = function(c) { return c; },\n            path = d3.geo.path().projection(function(d) { return proj(f(d)); });\nIf I define f as\nJavascript\nf = function(c) { return [c[0] + 180, c[1] - 90]; };\nI get my translation of the projection. If I define it as\nJavascript\nf = function(c) {\n                var d3_geo_radians = Math.PI / 180,\n                    x = c[0],\n                    y = (Math.log(Math.tan(Math.PI / 4 + c[1] *\n                                d3_geo_radians / 2)) / d3_geo_radians);\n                return [x, Math.max(-180, Math.min(180, y))];\n            };\nI get a Mercator projection instead of the equirectangular one. Similarly, if I define it as\nJavascript\nf = function(c) {\n                var d3_geo_radians = Math.PI / 180,\n                    x1 = c[0] * d3_geo_radians,\n                    y1 = c[1] * d3_geo_radians,\n                    cx1 = Math.cos(x1),\n                    sx1 = Math.sin(x1),\n                    cy1 = Math.cos(y1),\n                    sy1 = Math.sin(y1),\n                    cc = null,\n                    k = 1,\n                    x = k * cy1 * sx1,\n                    y = k * (cy1 * cx1 - sy1);\n                return [x, y];\n            };\nI get an azimuthal projection. You could also define functions to do rotations etc. It seems to me that this would make it easier to define new projections, as less code needs to be written. It also provides a uniform interface for translation, rotation, other projections etc.\n. I think that's probably where we disagree. All the 3 types of operations you've mentioned are the same to me -- they transform coordinates. For example, translate and geotranslate are fundamentally the same. The only difference is that one is applied before a projection and the other one after. Similar for projections themselves. There's no reason why you couldn't chain them to achieve weird and wonderful effects.\nI agree that everything can be done already, but maybe we could make it easier to use. Remember when I asked the question about making a specific part of the world fullscreen? With something like geotranslate this would have been a lot more straightforward.\nI think essentially my idea boils down to this. Instead of the current API where you create projections, set parameters and maybe combine them with rotations, why not have a chain of functions that are applied one after the other? Something like\nJavascript\nvar p = d3.geo.projectionChain();\np.push(function(c) { return [c[0] + 180, c[1] - 90]; });\np.push(d3.geo.mercator());\np.push(d3.geo.rotate().z(10));\np.push(function(c) { return [c[0] - 640, c[1] + 480]; });\nThis might make it more difficult to get started, but it would certainly allow for more flexibility. For example, one could have a map with a section of it magnified by just adding an item to the queue for the magnified bit. If the other elements are the same, panning and zooming the original map would also change the magnified bit without any additional code.\n. Yes, I think we're agreed on that :) The way to break things in interesting ways would certainly be increased by the composing functions approach. My main motivation for bringing this up is that it would remove the amount of duplicate code. The scale and translate functions in all projections are virtually identical. And the geotranslate stuff introduces even more duplication, and that's apart from having to maintain a weird auxiliary array of projected offsets!\nThere are certainly issues with translating things that then go out of bounds. I'm not entirely sure what we could do about that, but I tend to think that documenting it and not adding any safeguards to the code would be best. After all, you can mess up projections already by calling functions with unexpected values.\n. Sure, no problem.\n. ",
    "johan": "Confusing looks of this pull request caused by rebasing in you master branch, and accidentally force-pushing that back to my github fork again. The only commit really related is 4b239274262515ccbe52275eb2bd0070706f9541.\nSomewhat impressive of github to not fail more miserably than above.\n. (More a simplification of the example; it's not used.)\n. ",
    "stepheneb": "This app: http://stepheneb.github.com/avalanche2d-js/avalanche2d.html now uses your zoom-extent branch and a bug I was having with the scale being cached is fixed.\nSee: https://github.com/stepheneb/avalanche2d-js/commit/86a8aa8f4 for more details about what behavior in my app was fixed by this pull request.\n. ",
    "ganeumann": "I'm having a little trouble understanding why the extents clamping is written the way it it. I might not understand the expected syntax? Assuming that .extent([a,b],[c,d],[e,f]) is meant to limit a<=x<=b, c<=y<=d, e<=zoom scale<=f, then shouldn't the function d3_behavior_zoomExtentClamp read:\njavascript\nfunction d3_behavior_zoomExtentClamp(x, i, k) {\n  var range = d3_behavior_zoomExtent[i],\n      r0 = range[0],\n      r1 = range[1];\n  return arguments.length === 3\n      ? Math.max((r0 === -Infinity ? -Infinity : r0),\n                 Math.min(r1 === Infinity ? Infinity : r1, x ))*k\n      : Math.max(r0, Math.min(r1, x));\nThe change is to the return value of the 3 argument version. \n. ",
    "sampumon": "Origin support is missing from API documentation, and as such, I'm confused about what it means for many dragging examples setting d3.behavior.drag().origin(Object).\nAPI: https://github.com/mbostock/d3/wiki/Drag-Behavior\nDrag example: http://bl.ocks.org/1629464\n. ",
    "mizzao": "I am also confused about this - would appreciate some clarification! Also it seems that many drag functions are passed in a mystery parameter, but when trying to log this, it's undefined!\n. Yes, I believe I read that page about 10 times. I had no idea what \"origin accessor\" was and I didn't figure out that I needed to bind data to my element until I found someone else's example:\nhttps://gist.github.com/1629464\n. Hmm, I just saw this appear today: https://atmospherejs.com/d3js/d3\nDoes this have anything to do with your PR? Or did someone do this already?\n. Hey guys - did you decide anything on this? Are we making something to slurp up the d3 releases as they come out, or is d3 just going to make meteor?\n@mbostock - one important reason to have a single package is to avoid having a large number of poorly maintained third-party d3 wrapper packages in the Meteor ecosystem. Meteor's built-in version of d3 is pegged to 3.1.4 and won't ever be updated - it's been deprecated in favor of the community releasing their own, and we (the community) are trying to do it the canonical way instead of having irregular, manually updated releases.\n. ",
    "ajcollins": "Hi Mike,\nThat's exactly what I do to serve locally (a useful single-liner that I'd not come across before): except I wanted to jump straight to the HTML pages, rather than a listing of files. One click to view, rather than two.\nAlex\nOn 13 Nov 2011, at 01:51, Mike Bostock wrote:\n\nIf you use python -m SimpleHTTPServer 8888 & (as explained in the readme), it will generate this for you automatically.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/mbostock/d3/pull/374#issuecomment-2720433\n. \n",
    "GerHobbelt": "Interesting... I was all the time wondering how this one could be.\nAnyway, here it happens across the board: sample screenshots for Safari, Opera, IE9 below: note that each year outline has the same horizontal 1-day-wide line for its 1st of January and assumed last day of December, which is indicative of the error as 365/266 isn't divisible by 7. Also note that the day squares /do/ render correctly.\nPondering how this may be, the best answer I can come up with right now is 'timezone': when you don't nuke the time part of the Date object and make sure it's all in UTC, it might explain why yours is 'good' and mine is 'wrong'. I'm living at GMT+1 (DST) i.e. 'Amsterdam Time'.\nStill makes me wonder why some of the drawing errors are /2/ days long at the end of December - see year 1992 for and example - as the little brainfart above doesn't cater for that one, on first inspection.\nAnyhow, whichever way we turn this, given your response, my fix surely isn't correct/complete either as I bet it'll break yours while 'fixing' mine.  :-(\n(And to answer the next question you're bound to ask: nope, it's not machine specific, as I've observed the exact same behaviour on a Win7/64 box at another place, plus both my machines (Win7/64 and XP64) show the very same mistake in every browser that's able to plot SVG.)\nThe screenshots:\nhttp://imgur.com/a/ATAce\n. 266->366 == typo\n. Bingo!\nIt's a timezone issue.\nQuickly changed my box' timezone to AZ, USA (Why AZ? First thought right now of USA was Arizona, sorry. Last time I came to the US, it felt exactly like the third image, the impression must've lingered. :-) )\nAnyway, top image (imgur.com isn't putting them in the order of upload, alas) is a render of my 'fix' (yech!) when done in AZ/USA time, so my fix is WRONG - see the jan/feb month outline failures. The 'fix' is just replacing the error for another.\nThe second image is the official d3 calendar demo, now re-rendered in AZ/USA time, no other change since the previous snap: it matches your (correct) snapshot: it shows a correct calendar rendering.\nWhich means that my hunch is on the dot or at least close enough; now I need to make my code behave as desired, no matter where you reside on our globe. At least I'm confident again that the existing calendar example has the reported bug.\nhttp://imgur.com/a/CFDk1\n. Thanks for the feedback, BTW; without it, I wouldn't have realized the clumsiness of my original edit. +2 instead of +1. Ahem.\nThe new commit is a real fix. Also tested now with different timezones (Fiji, ...) around the globe.\nThe point being that all parsing and calculus should be done in 'local time' or UTC across the board, as mixing them introduces unwanted locale-dependent offsets.\n. If you could send me the edited example files, I'd be much obliged. Your code has been backported into chord.js - see https://github.com/GerHobbelt/d3/tree/chord-layout-explicit-rel-pullreq-617 (commit 5f09b7f5b35fe064f732d052478cdbb0ca8cc2c7 )\n. Thanks for the reply, but two things:\n(1) be aware that I'm not Mike, I just want the pull request to go\nthrough and to make that an easier process it should be synced to HEAD.\n(2) Didn't see anything at this end, so I guess you attached the example\nand github comments don't allow attachments.\nHence there's a couple of ways to proceed from this point:\n- add the example in your own branch which is related to this pull request\n- if git is still an issue over at yours, send the example file(s) to me\n  via direct email (ger at hobbelt dot com) and I'll drop them into my pull\n  branch and we can take it from there (either re-issue the pull req or you\n  pull that branch into yours so github appends the changes to this pull\n  request #617\nMet vriendelijke groeten / Best regards,\nGer Hobbelt\n\nweb:    http://www.hobbelt.com/\n        http://www.hebbut.net/\nmail:   ger@hobbelt.com\nmobile: +31-6-11 120 978\nOn Mon, May 14, 2012 at 3:50 PM, Dave Porter <\nreply@reply.github.com\n\nwrote:\nThat's great, thanks!  Here's my example page - it's obviously quite\nheavily derivative of your existing chord demo.  The relationships code is\nat the top of the chord.js page (which I've also heavily annotated with\nnotes for myself on how the existing demo works).  Also, I never quite\nfigured out how to rotate the text properly; the labels are all very\nslightly off.  (I believe I'd need to add a bit that rotated the label by\ndifferent amounts based on the length of the label's text.)  Please let me\nknow if you need anything else from me at this time.\nBest,\nDave\nOn Mon, May 7, 2012 at 1:30 AM, Ger Hobbelt <\nreply@reply.github.com\n\nwrote:\nIf you could send me the edited example files, I'd be much obliged. Your\ncode has been backported into chord.js - see\nhttps://github.com/GerHobbelt/d3/tree/chord-layout-explicit-rel-pullreq-617(commit5f09b7f5b35fe064f732d052478cdbb0ca8cc2c7 )\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/mbostock/d3/pull/617#issuecomment-5544171\n\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/mbostock/d3/pull/617#issuecomment-5690599\n. !@#$%^&* shouldn't have merged but cherrypicked instead. Ignore. I will re-issue the request with a cherrypicked copy of the edit that's relevant here.\n. bump ?\n. Hi Mike,\n\nThanks for the follow-up! It's much appreciated and sorry to add to that to\nthe deluge. ;-)\nI hope to add to another deluge in due time, but I know how it is, being\ncompletely swamped myself right now.\nMet vriendelijke groeten / Best regards,\nGer Hobbelt\n\nweb:    http://www.hobbelt.com/\n        http://www.hebbut.net/\nmail:   ger@hobbelt.com\nmobile: +31-6-11 120 978\nOn Wed, Jan 23, 2013 at 8:50 PM, Mike Bostock notifications@github.comwrote:\n\nSorry for the delay. Lost track in a deluge of issues and pull requests.\nTrying to organize them now.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/mbostock/d3/pull/798#issuecomment-12618621.\n. Mike said:\nI think it would be best to not name this method scale.invert, as\nscale.invert(y) is not symmetric with scale(x). Perhaps the name\nscale.invertDomain, to imply that it returns a slice of the domain?\n\nPlease don't do that.\nI have a D3 clone (unfinished business...) which gives this scale the\n.invert() method: the argument to keep the API function name the same is to\nmake all scales' interfaces as interchangeable as possible so that you\ncan 'jack in' an arbitrary scale and still be sure you can call (almost)\nall scale methods.\nThe fact that your 'invert' operation is not \"exact\" in guessing your\noriginal input is of little importance: the information lost in the\ninversion process is just the quantization effect of the used scale. All\nthat .invert() should guarantee is that for the given scale the following\nsequence should produce an identity: input == output for range -> domain ->\nrange transformations. Quantizing scales of course will 'loose detail', but\nthey do that in the scale() itself; the .invert() is not 'at fault' here,\nso this should hold:\n// range --> domain --> range: F(F_inv(y)) == y\n   var input = rangevalue;\n   var output = scale(scale.invert(input));\n   assert(output === input);\nFor quantizing scales of any kind an additional .invertEx() method is\nsuggested which does not just produce a 'domain value' but rather a 'domain\nrange' [start, end> of domain values which all map to the same range value.\n(start is inclusive, end is exclusive for the produced band in order to\nkeep things doable and sound)\nWhat I call '.invertEx()' (too much MS API coding in my past, I guess)\ncould be done by your suggested .invertDomain() though that name also\ndoesn't really convey the sense that a band rather than a single return\nvalue is to be expected either. Maybe a better name could be found in the\ndirection of '.invertWithAccuracy' as techno-savvy people will expect a\nmin/max band or 'sigma-something' with such a name instead. And here we\nhave a known 'inaccuracy' in guessing the original user-fed domain value\nfor the given range value. ('.invertExtent' also sounds good to me,\nincidentally)\nIMO this goes for each 'quantizing' scale, i.e. scale.ordinal,\nscale.quantize and the extreme cases: scale.quantile and scale.threshold:\nall fitted with an .invert() at least and for users who care about\ntechnical accuracy of statements there's .invertWithAccuracy() which\nproduces a min/max domain value set instead.\nThe above would then guarantee that every scale has the ability to go back\n& forth between domain and range values using scale() and scale.invert(),\namong other scale API methods, making for a very flexible approach for\ncoding arbitrary-input charting components when using D3.\nI take the 'lossy behaviour' of the scale in scale(scale.invert()) loops\nfor granted; as an analogy, a scale is like a JPEG picture: I feed it a\npicture and later I want to see that picture again. Even when I can see\nit's been fed through a 'lossy' transform+inverse transform process, I'll\nstill be happy.\nMet vriendelijke groeten / Best regards,\nGer Hobbelt\n\nweb:    http://www.hobbelt.com/\n        http://www.hebbut.net/\nmail:   ger@hobbelt.com\nmobile: +31-6-11 120 978\nOn Tue, Apr 16, 2013 at 6:47 PM, Mike Bostock notifications@github.comwrote:\n\nThis seems useful; however, I think it would be best to not name this\nmethod scale.invert, as scale.invert(y) is not symmetric with scale(x).\nPerhaps the name scale.invertDomain, to imply that it returns a slice of\nthe domain?\nImplementation-wise, this needs test. And I wouldn\u2019t implement this using\nd3.scale.ordinal, since that is heavyweight and requires mapping the range\nvalue to a string. I think you want to use d3.bisect to find the index of\nthe input value in the range, and then use that to compute the appropriate\nslice of the domain.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/mbostock/d3/pull/1201#issuecomment-16456470\n.\n. On Thu, Apr 18, 2013 at 1:38 AM, Mike Bostock notifications@github.comwrote:\nThe design requirement is that scale and scale.invert are the inverse of\neach other. So if a scale supports inversion, then scale(scale.invert(y))returns\ny and scale.invert(scale(x)) returns x for valid values of y and x.\nI understand. The point I was trying to make (badly) here is that I\nslightly rephrase the design requirement, where the last bit reads: \"and\nscale.invert(scale(x)) returns x' for valid values of x such that scale(x)\n=== scale(x')\".\n\nRephrasing the requirement that way I get away scott-free with trivial\ninversion logic for all scales, both 'exact' ones like scale.linear and\nscale.log and 'lossy' a.k.a. quantizing ones such as scale.quantize.\nThen I also don't complicate matters for myself by having to fix things\nsuch as a 'midpoint' approach as you mention: the fastest/simplest\nimplementation can be used as x' does not /have/ to equal x in my rephrased\nrequirement; for 'exact' scales such as scale.linear and scale.log, this x\n=== x' happens to be fact and can be states as an artifact of these scales,\nbut the minimum any scale will guarantee is scale(x) === scale(x')\nI don't have a demo for this yet as I'm still working on the scales\nthemselves (there's other stuff that takes all my time); I expect to run\ninto this when I start coding backpropagation using the D3 components.\n(Yes, sounds nuts. I know. It's just that I see a visual D3 sitting right\non top of the complex number crunching bits. Part of the plan is to have a\nscale.sigmoid() too, so you can probably guess where that one is going ;-))\n)\nBottom line is that I value a 'best effort' .invert() above a 'guaranteed\nexact predictor' .invert() when it means I can now use any scale and always\nexpect .invert() to be available to me.\nAnd if I need more intel, I should always ask for the accuracy estimate\nanyway: invertExtent(). (If you nitpick, there's an issue with the min/max\nin the extent being inclusive or exclusive, but alas...)\nMet vriendelijke groeten / Best regards,\nGer Hobbelt\n\nweb:    http://www.hobbelt.com/\n        http://www.hebbut.net/\nmail:   ger@hobbelt.com\nmobile: +31-6-11 120 978\n. Hi Jason, I chose to use the general 'catch-em-all' expression as I was working with custom types (value formatters) which may output something other than 'e', hence the tail of the string was not guaranteed to start with 'e' or be empty. This way of coding it makes it more robust against further work in that direction. \n(Think of it like this: add API to register your own 'types' to be used in d3.format.)\nMore relevant for you: it also happens to catch 'oddities' such as printing '+Infinity', e.g. d3.format(',g')(Infinity) as the regex will catch on the initial 'I' -- sorry, forgot to add NaN and Infinity printing tests, should've done those too.\n. And there's also NaN, but that one is really fringe case as it will only\nkick in when you use a locale where the 'thousands separator' (comma) is\ninstead set up to be a 'hundreds separator. (Yes, I've got a nasty mind.\n;-) )\nAnd d3.format() should be able to print anything that can 'legally fit in a\nfloating point type' IMHO, so +/-Inf and NaN are real 'numbers' from my\nperspective. It makes userland code much easier (and smaller) because you\ndon't have to bother about what you feed d3.format after you've run some\ncalculations, e.g. flows such as\n``` [oversimplified sample]\nvar v = Math.tan(some_input);\n...\nd3.format(',g')(v);\n```\nthus do not need to check (and 'patch') 'v' before you call this one as\nit'll handle NaN (div-by-0) and +/-Infinity without a hitch, for a very\nlarge range of locale configurations.\nPersonally, I may lean towards more inside a library rather than outside\nit, I don't know. Anyway, it's your call to decide what you consider 'a\nnumber' in this context.\nThanks for the discussion, helps me sharpen my brain!\nMet vriendelijke groeten / Best regards,\nGer Hobbelt\n\nweb:    http://www.hobbelt.com/\n        http://www.hebbut.net/\nmail:   ger@hobbelt.com\nmobile: +31-6-11 120 978\n\nOn Fri, Aug 29, 2014 at 2:03 AM, Jason Davies notifications@github.com\nwrote:\n\nAh, I hadn\u2019t thought about Infinity, thanks. :) I think it\u2019s reasonable\nthat d3.format should only expect numbers, though.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/mbostock/d3/pull/1997#issuecomment-53822737.\n```\n. \n",
    "bbroeksema": "Bump.\nAny comments on possible acceptation of this patch (or required improvements for acceptation)?\n. I do agree that my approach indeed smells like white-box inheritance, actually it is. For my project I namely just copied the edgehandling code and added the bits and pieces I needed. This is related to your above comments, namely I do so because determining the neighbors of a voronoi site is done during voronoi tessellation. At the point of adding an edge to a cell, the algorithm has information about the start and end points of the edge, the cell to which the edge belongs and to which other cell the edge is connected.\nSo the point is that I don't necessary myself want to annotate the polygons with neighbors, it is information I expect to be available after I did a voronoi layout (in order to prevent the costly calculation as a separate step). I might misunderstand your current proposal, but I don't see how this would deliver me the information (or give me the possibility to get it during the layout process).\nAn alternative might be to just store the neighbors in the .data section of vertices as part of the layout algorithm. But then a next requirement could become (not something I need), that one would be able to tell which neighbor reside at which edge. Something you don't solve in a comfortable way when annotating the neighbor at the vertices as each vertex will have two neighbors (except for those at the borders of the image).\nYet another alternative would be to return a list of \"Cell\" objects. Similar to the approach Raymond Hill has in his implementation (http://www.raymondhill.net/voronoi/rhill-voronoi-core.js). But that might be too heavy for d3.\n. Quick note: I do like the idea to make the algorithm more flexible with respect to the data it expects. Actually, one additional extension of your proposal would solve my problem:\njavascript\nvar voronoi = d3.geom.voronoi()\n    .x(function(d) { return d.x; })\n    .y(function(d) { return d.y; });\n    .edge(function(e) { e.d1.neighbor = e.d2; e.d2.neighbor = e.d1; })\nThe edge function would be called for every edge added to the layout and would allow me to register neighbors (or build whatever structure one needs). The argument passed to edge would contain the two data objects the edge is separating. Besides that it should of course contain the start and end vertex of the edge.\n. I implemented a spatial merging algorithm that works as follows:\n- Take the voronoi tessellation of a set of points.\n- Sort the cells by size\n- Start from the smallest and merge it with all direct neighbors for which the site lies within merging distance D.\n  repeat until no further merges occur.\nbeing able to get the neighbors of a given cell is the crucial point here. Of course I keep track which original points fall in a merged cell. It has various applications, can't go into much detail further as I'm working on a paper.\nHope this explains enough what I need and why.\n. I'd still really like to have a solution for this problem. Currently I'm using my own version of the voronoi implementation with the extension as attached to this report.\nSo, why did I choose to export the internals? The current voronoi implementation calculates the diagram and forces the user to clip the cells if necessary. For this it is not needed to know the bounding box on forehand. However, when calculating the neighbors, it can happen that two cells are connected outside the boundingbox. Obviously, when I know the boundingbox on forehand I don't want these neighbours to be added. So by making some of the internals public I was able to implement my own EdgeHandler, which looks like this:\n``` javascript\nfunction EdgeHandler(vertices, w, h) {\n    var polygons   = vertices.map(function() { return []; });\n    var neighbours = vertices.map(function() { return []; });\nthis.handle = function (e) {\n  var s1,\n      s2,\n      x1,\n      x2,\n      y1,\n      y2;\n\n  if (e.a === 1 && e.b >= 0) {\n    s1 = e.ep.r;\n    s2 = e.ep.l;\n  } else {\n    s1 = e.ep.l;\n    s2 = e.ep.r;\n  }\n  if (e.a === 1) {\n    y1 = s1 ? s1.y : -1e6;\n    x1 = e.c - e.b * y1;\n    y2 = s2 ? s2.y : 1e6;\n    x2 = e.c - e.b * y2;\n  } else {\n    x1 = s1 ? s1.x : -1e6;\n    y1 = e.c - e.a * x1;\n    x2 = s2 ? s2.x : 1e6;\n    y2 = e.c - e.a * x2;\n  }\n\n  var v1 = [x1, y1],\n      v2 = [x2, y2];\n\n  polygons[e.region.l.index].push(v1, v2);\n  polygons[e.region.r.index].push(v1, v2);\n\n  var v1Inside = !(x1 < 0 || x1 > w || y1 < 0 || y1 > h);\n  var v2Inside = !(x2 < 0 || x2 > w || y2 < 0 || y2 > h);\n\n  if (v1Inside || v2Inside) {\n    // Only record a neighbour when one of the vertices is within the \n    // bounding box: [0,0,w,h].\n    neighbours[e.region.l.index].push(e.region.r.index);\n    neighbours[e.region.r.index].push(e.region.l.index);\n  }\n};\n\n```\nObviously, this does some extra work (and needs additional information) compared to the original implementation. I don't see how I could reach the same goal though. If you have suggestions to take a different approach I'm more than happy to implement and try it out.\n. Okay, retry. I still added a(n optional) callback. Differences: this time it is optional, that is, d3.geom.voronoi can still be called with just one argument and will return the same result as before. When the callback is set, this callback will be called for each edge that is encountered and nothing will be returned once the tessellation is finished. This allows for creating a custom data structure during tessellation (e.g. in my case I want to keep track of neighbours of a particular cell).\nplease let me know what you think of this (improved?!) approach.\n. ",
    "christophermanning": "I like the idea of adding x and y methods on the Voronoi object. Now I have to transform the data like this: .data(d3.geom.voronoi(vertices.map(function(o){return [o.x,  o.y]})))\nI was just researching how to get neighboring Voronoi cells and it doesn't seem possible since the neighbors aren't exposed from the voronoi object. I ended up using a Delaunay triangulation to connect nodes in cells that neighbored each other: http://bl.ocks.org/1734663 but that requires a Delaunay calculation during each update. If the edges were exposed, this could probably be simplified.\n. I agree, but it seems like fallback cursors only work with image cursors. This might have to be won't-fix.\n. ",
    "ryanthejuggler": "This issue could be closed; the .links() method exposes this information now.\n. ",
    "arestov": "Will this be merged?\n. ",
    "asuth": "ah - i just did some quick testing on the console and saw this:\n> [,]\n[]\nBut makes sense. Could also do new Array(1).\n. ",
    "twooster": "I was wondering if I might be missing something with that. It's a bit confusing to differentiate between when the code operates on the values-as-labeled versus when it's operating on the variables as temporary storage. I feel like I'm treading in dangerous territory here, because I'm a bit out of my element, but I've tried the reversal technique -- applying forces to .px and .py -- and it seems to work reasonably. I'll push in a moment.\n. Didn't even see that! New to the whole pull-request thing...\n. ",
    "conorbranagan": "Makes sense to me. Updated.\n. Yeah I understand, that makes sense. Ideally one wouldn't have to know to set the other dimension when using the Brush but it would be difficult to determine the correct size, like you said. I'll look into it a bit more to see if there is a decent solution, but it seems unlikely. I appreciate your comments and help.\n. ",
    "Fresheyeball": "(pssst.. your example is broken)\n. ",
    "dwt": "Is there a way to reopen this? As far as I understand things, all countries that support AM/PM also understand 24H formats, which isn't the case the other way around. So indeed 24H formatting seems more universal. And AM/PM formatting should/ could go into the en_US locale.\n. On a related note: Is there a specific reason all the other localizations are against dialects of their specific languages?\nI would think that it would be much more useful (for those languages where that is possible) to first create a  base locale (en, es, pt, fr, etc.) and then add specific dialects (en_US, en_GB) later for those where the data is available.\n. Fixed it for you. :)\n. ",
    "trevnorris": "Sorry, not sure you mean by \"convert start, stop and step to integers, and then rescale to floats when calling range.push?\"\ncalcRdx() tells you by what amount you need to multiply the larger value to make it have exactly 18 digits (which is just enough to leave out any decimal error from either values). For example:\njavascript\ncalcRdx( 1e-17, 1e-15 ) === 1e+31\nSo by multiplying start and step, they are converted to integers. Addition then happens in integer space. Afterwards they are converted back to their original values by dividing by the same value.\nWhile this doesn't fix the issue for all cases, it does for the majority.\n. I've just updated the source with a better method of calculating the error fix. This should compensate for error in all values that can be displayed using IEEE 754 (e.g. 9999999999999999 === 10000000000000000, and there's nothing that can be done about that).\nHad been researching this method for a while, but took some time to hammer down just right.\n. I've updated the step/increment calculation to match what you suggested above, and realized that I should have been passing start and step to calcRdx(). Not stop.\nAs far as the calculation goes in calcRdx(), it's actually meant to introduce error that will be corrected in the end calculation. Output of the following will demonstrate what I mean:\njavascript\nvar i = 1, h = 10;\nwhile( i < 100 ) {\n    console.log( eval( '1e' + ++i ) - ( h *= 10 ))\n};\nWhile you would expect to see a bunch of 0's, that doesn't happen. Multiplying (or dividing) by increments of 10 generates a small error value which cancels out properly in the end calculation. If you want to see what I mean, replace my method with the one you've suggested above and run range-test.js.\nI haven't had a chance to verify the method for all values +/- 2^53, but so far it hasn't failed. Though when calculations reach beyond those limits there exist some issues that can't be resolved.\n. ",
    "minikomi": ":+1: I agree with this addition!\n. %d\u65e5 is accurate for Japanese also\nOn Sunday, February 2, 2014, bollwyvl notifications@github.com wrote:\n\nJust poking around: moment.js handles this with a set of tokens for\nspecific date components with ordinals: Mo, Do, etc. This goes beyond the\napproach of a \"date suffix\" token pretty significantly, so may not be\nentirely applicable. Due to this complexity, they accept either function(number,\nperiod) or a %-formatted string.\nHere is a PR that solves some of these issues around Chinesehttps://github.com/moment/moment/pull/750which leads to one for Russian\nand Ukrainian https://github.com/moment/moment/pull/825.\nPerusing their lang files around the 8 languages mentioned above, here's\nwhat i can extract for day-of-month:\n- French: function (number) { return number + (number === 1 ? 'er' :\n  ''); }\n- Italian: %d\u00ba\n- German: %d.\n- Chinese: %d\u65e5\n- Japanese: N/A\n- Korean: %d\uc77c\n- Russian: %d-\u0433\u043e\nHope this helps!\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/mbostock/d3/pull/495#issuecomment-33876109\n.\n. \n",
    "langdonx": "+1\n. This is a great approach to this problem.  How difficult is it to port the pull request into a plugin?\n. @mbostock No chance for this or is there an existing solution?\n. +1\n. I am certainly still interested.  I've been using a patched version of d3 that includes this.\n. ",
    "zacwitte": "Yes please. Any update on this?\n. ",
    "ghost": "Well I just asked some Russians in ##russian on freenode... they don't use date suffixes.  Don't know if that helps.\n. I really wish we could just get this into d3.  It is common in other libraries, and I'm sure lots of you have managers/designers that require your date to be something like \"April 2nd, 2014\" not \"April 2, 2014.\"\nI feel like this has been held back for way too long, especially if its functioning, and we have other languages chiming in.  And from what I here, the other languages may just not even have this, so could easily just have it be replaced with nothing, if not in a language that supports this.\n. Sorry - this was an unknown commit. Please go ahead and close this. \n. ",
    "bollwyvl": "Just poking around: moment.js handles this with a set of tokens for specific date components with ordinals: Mo, Do, etc. This goes beyond the approach of a \"date suffix\" token pretty significantly, so may not be entirely applicable. Due to this complexity, they accept either function(number, period) or a %-formatted string.\nHere is a PR that solves some of these issues around Chinese which leads to one for Russian and Ukrainian.\nPerusing their lang files around the 8 languages mentioned above, here's what i can extract for day-of-month:\n- French: function (number) { return number + (number === 1 ? 'er' : ''); }\n- Italian: %d\u00ba\n- German: %d.\n- Chinese: %d\u65e5\n- Japanese: N/A\n- Korean: %d\uc77c\n- Russian: %d-\u0433\u043e\nHope this helps!\n. ",
    "indec": "Given that this is my first pull request ever, do let me know if I screwed things up royally....\n. Related #461\n. I added resume for a couple of reasons:\n- Completeness - the existence of \"stop\" suggested that \"resume\" should exist. This isn't necessarily a good reason....\n- The drag event's automatic restart, as you mentioned.\n- More generally, it seemed right to be able to put your logic for what happens when motion resumes in one place and not have to write your own wrapper for force.resume() that does all the stuff you want to do when you resume.\nI don't have a specific personal requirement for a resume event. I have no real objection to removing it (YAGNI does rear its ugly head here). It just seems like it should be present, and doesn't add terribly to the complexity of the code. Equally, it'd be trivial to add it in in the future if needed.\nAs to names, I'll defer to you as to your preferred house style. (I wrote this before I saw #459 and so didn't see your preferences there.) Personally, I'd go for \"start\", \"move\", and \"end\" since they're events on the force layout and therefore the \"force\" seems redundant. But, consistency would then suggest renaming the brush events too....\nThat aside, I can update this with a patch to change the names, and I can include \"forcemove\" (retaining a deprecated \"tick\" event for backwards compatibility) and update the various examples to use the new event name if that's what you would like. (Equally, I can do a rename job on the brush events if that takes your fancy.)\n. OK. I'll start work on this tonight. Did you want to keep the \"resume\" event for the force layout too, or shall I remove it?\n. My assumption was that you could still fire the old events - anyone using the old ones would get the old ones, and anyone who updated to the new event names would get the new ones. There'd be some small overhead of course, but otherwise you'd probably have to keep track of which events had been registered, which doesn't seem to be the pattern currently.\nAnd yes, feel free to do the work :)\n. https://gist.github.com/1886287 is about as efficient as I could make it, I think. It's a bit of an ugly hack :(\n. Hurrah! Thanks for D3 :)\n. ",
    "alex": "I've added support for interpolating HSV colors.\n. ",
    "ZeeAgency": "Like I said, it would just be a \"helper\" so no, not needed, but useful to avoid writing something like d3.selection.prototype.myPluginName = d3.selection.enter.prototype.myPluginName = function() {... which is pretty long... jQuery solves this by using an alias, but this is still a bit long d3.selection.fn.myPluginName = d3.selection.enter.fn.myPluginName = function() {.\nPlaying with prototype inheritance seems also weird to me in this case, let's just forget about this feature for now ;-)\n. ",
    "mjackson": "I'm afraid that would defeat the point of the pull request. :) Feel free to close if you don't like it.\n. ",
    "g2010a": "I would love to but I can't reproduce the issue anymore myself... Best kind\nof bug :)\n[Sent from some mobile device]\nOn Feb 23, 2012 5:28 PM, \"Mike Bostock\" \nreply@reply.github.com\nwrote:\n\nWorks fine for me:\n``` js\n\nd3.csv.parse(\"%foo,%bar\\n1,2\\n\")\n[ { '%foo': '1',\n   '%bar': '2' } ]\n```\n\nI'm guessing your problem is elsewhere. You can't use the column name\n\"proto\", but that should be about the only restriction. Can you give me\na reproducible test case?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/mbostock/d3/pull/567#issuecomment-4139575\n. \n",
    "OliverEgli": "Hi,\nI am interested in this feature. Any news about that?\n. Can you provide a minimal working example, using JSON? How do I have to define the internal value in the JSON object? \nWhat would I need to change, if I just like to overwrite the \"value\" as soon as an internal_value is defined?\n. ",
    "loganlinn": "It is working in my branch. I suppose it could use some extra documentation to be more merge-worthy, but I have not gotten any feedback from the maintainers...\n. Take, for example, the Sunburst demo: http://mbostock.github.com/d3/ex/sunburst.html\nThe data for that graph is: http://mbostock.github.com/d3/data/flare.json\nInstead, consider it being something like:\njson\n{\n \"name\": \"flare\",\n \"children\": [\n  {\n   \"name\": \"analytics\",\n   \"size\": 5000,\n   \"children\": [\n    {\n     \"name\": \"cluster\",\n     \"size\": 5000,\n     \"children\": [\n      {\"name\": \"AgglomerativeCluster\", \"size\": 3938},\n      {\"name\": \"CommunityStructure\", \"size\": 3812},\n      {\"name\": \"HierarchicalCluster\", \"size\": 6714},\n      {\"name\": \"MergeEdge\", \"size\": 743}\n     ]\n    },\n    {\n     \"name\": \"graph\",\n     \"size\": 5000,\n     \"children\": [\n      {\"name\": \"BetweennessCentrality\", \"size\": 3534},\n      {\"name\": \"LinkDistance\", \"size\": 5731},\n      {\"name\": \"MaxFlowMinCut\", \"size\": 7840},\n      {\"name\": \"ShortestPaths\", \"size\": 5914},\n      {\"name\": \"SpanningTree\", \"size\": 3416}\n     ]\n    },\n    {\n     \"name\": \"optimization\",\n     \"size\": 5000,\n     \"children\": [\n      {\"name\": \"AspectRatioBanker\", \"size\": 7074}\n     ]\n    }\n   ]\n  },\nNotice: nodes that had children now also have a  size (an internal value).\nTo include those values in the calculated value of the internal node, you'd would do something like:\njs\nvar nodeSize = function(d) { return d.size; };\nvar partition = d3.layout.partition()\n    .sort(null)\n    .size([2 * Math.PI, radius * radius])\n    .value(nodeSize)           // include leaf node values\n    .internal_value(nodeSize); // include internal node values\n. > One potential issue is the the likelihood of collision between the node\u2019s internal value and the node\u2019s aggregate value computed by the layout\nAh, that's unfortunate. Storring the aggregate value at node.value further constricts the design to not allow internal nodes to have their own value. Unless this is the intent of node design, it would seem reasonable to store the aggregate value under a different property; it's a caching mechanism, correct?\nThanks for the great library btw!\n. ",
    "evenwestvang": "+1 for supporting something like this. Much needed when stuck with a data set where not only leaf nodes carry values.\n. ",
    "eparejatobes": "+1 here too!\n. is this in 3.0?\n. ",
    "Kallin": "This would be hugely valuable! Currently it seems I'm forced to fill in the blanks on leaf nodes with an 'other' category so that things add up. I'd prefer to simply specify the value of each node, and have it error out if a node happens to have children who's sum exceed it's own value. Working on an icicle chart, something like this: http://codepen.io/Kallin/debug/vzgnF. Cheers!\n. ",
    "justincormack": "Ah I just saw that there is a pull request for HSV too... will add interpolators as per the comment there.\n. XYZ was only really there as CIELab is defined as a transform from it. I don't think there is much of a use case for it directly, so will remove it.\nThe other two are just the linear and cylindrical versions of the same space. Some operations only really make sense in the linear CIELab, like interpolation, but other things like changing hue make more sense in cylindrical coordinates. One option would be to have one type but expose the cylindrical operations on it too. I think this is probably the nicest to work with, so will give it a try. \n. Ok so now XYZ is gone. CIELab now has hue() and chroma() methods that can return or set the hue and chroma, which is the only reason I had CIELch, so that is gone too. Added Lab interpolator. It is pretty small, so doesn't look too much like bloat in the core.\n. Some thoughts at this point:\n1. For compatibility with existing hsl, I should probably switch the chroma() function to scale as 0..1 not 0..100, and accept percentages. But then the lightness probably ought to be changed, or add a lightness() function. Will think about this a bit more.\n2. If you take the view that HSL and HSV are not colour spaces, just representations of RGB, then adding hue(), saturation(), lightness() and value() functions to d3.rgb would be an option, and then d3.hsl could just be a constructor for rgb objects and not an object of its own. This would simplify the situation to just two spaces, one device space and one perceptual, with a small amount of backwards compatibility breakage.\n3. Chromatist seems a bit complex for most use cases in d3.\n. Thanks for those comments they are very helpful. Will work on the issues raised, should be able to add both interpolators for example.\n. Having used this as is for a bit, it is annoying not to have a way to do LCh initialization. Not sure whether to do an \"lch(...)\" style one like rgb has or go back to having an LCh colourspace. Doing interpolation across LCh will be a little slower without a colourspace for it too.\n. Yeah sure that looks good, will see how it works out but certainly makes sense.\n. Will find some time to look at this soon! Been tied up in other projects but its not forgotten!\n. ",
    "RichMorin": "\nThis is intentional, because those parameters are related.\nIn what way does it display poorly?\n\nOn Google Chrome, the lower origin and translate sliders\npartially obscure the upper ones:\n-r\n-- \nhttp://www.cfcl.com/rdm            Rich Morin\nhttp://www.cfcl.com/rdm/resume     rdm@cfcl.com\nhttp://www.cfcl.com/rdm/weblog     +1 650-873-7841\nSoftware system design, development, and documentation\n. On Mar 15, 2012, at 09:28, Mike Bostock wrote:\n\nYeah, I'm okay with that. Maybe now there's a better replacement\nfor the jQuery UI slider?  It's a bit long in the teeth.\n\nThe slider looks OK to me, but I'm not a designer.  It might be\nworth asking on the D3 list, to see if anyone has a suggestion.\n-r\n-- \nhttp://www.cfcl.com/rdm            Rich Morin\nhttp://www.cfcl.com/rdm/resume     rdm@cfcl.com\nhttp://www.cfcl.com/rdm/weblog     +1 650-873-7841\nSoftware system design, development, and documentation\n. ",
    "kitmonisit": "Yes, thanks for pointing that out. There's the new commit.\n. @jasondavies If that's the case with CORS, how do prototype, jQuery, Mochikit, etc. handle this problem?\n. Excellent :) Took me a while to figure out how to use .defined. It should be a function that, if it returns a truthy value, the datum d will be included in the dataset to be rendered. Else, that datum d will be ignored and will not be rendered by the line or area generator. Thank you!\n. Oops, sorry. Sure, fix coming up!\n. Shall I also breakout the axis definitions to multiline statements, or just keep them to one line?\njs\nvar xAxis = d3.svg.axis()\n    .scale(x)\n    .orient(\"bottom\")\n    .tickSize(6, 0);\n. Done with updating examples according to spec in #565 :) For the following examples, I did not find anything to update according to the conventions, or are already up-to-date:\nalbers\nazimuthal\nbonne\nbubble\ncartogram\nchoropleth\ncontour\nhello-world\nhistogram\nmercator\nmouse\nnode-canvas\nsizzle\nsymbol-map\ntouch\nzoom-pan\n. I can squash them all into one big commit if you'd like, to keep your logs clean and easy to browse. Just let me know.\n. null values for y inserted at every 5th element including the zeroth element\n. nulls don't come out well when drawing individual SVG elements, so I filtered them out.\n. ",
    "shawnbot": "I'd also like to suggest that d3 eventually support JSON-P, which basically does away with this issue for any JSON endpoint that supports a callback parameter.\n. Fine, I'll put in my fork! :trollface:\n. I just want to clarify: the cost you're referring to is the tertiary statement, right? Could it be that document.createElement() is actually faster without the namespace URI?\nEither way, I guess the onus is on me to jsperf it and see if it's any slower. Or I could just bite the bullet and shim document.createElementNS() in IE8, since I'm doing that in so many other cases anyway... Thanks, Mike :)\n. Okay, so I took a look at your test that just times the calling of both functions with literal arguments. That one shows a slight performance edge for document.createElement() over its NS counterpart in Safari 5.1.7 (by kind of a lot, in fact), as in Chrome 20 and 21. The NS version is apparently faster in Chrome 19, though.\nI also made one that more closely mimics d3's selection.append(), and the results are similar: Safari 5's createElement() is much faster, and Chrome 19 only slightly.\nLooks like my hunch might be right?\n. Hmmm... turns out it's a bit more complicated than that. Here's another test that simulates the difference between the current d3 approach (calling document.createElementNS() with a null namespace URI) and the one I've proposed (conditionally calling document.createElement() or the NS counterpart based on whether the element has a namespace URI).\nThe test results are inconclusive so far, though. Safari and Mobile Safari are slightly faster with my approach, and Chrome 21 (Canary) is slightly faster with createElementNS().\n. Cool. I'm bundling all of the IE8-specific stuff into aight, which now includes a createElementNS() shim that throws an exception if you give it a namespace URI.\nIt looks like all of the CSSStyleDeclaration issues were addressed by a combination of the DTD-less DOCTYPE, <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">, and this shim. If CSSStyleDeclaration is undefined in IE, that very likely means that the document is running in quirks mode.\nAight includes the CSSStyleDeclaration shim and a bunch of other ones necessary to get IE8 most of the way there with HTML, assuming you've forced the document into standards mode. So feel free to point people here if any similar issues crop up.\n. @tcha-tcho: This is great! I don't think that it belongs in d3 core, though. You should consider forking d3-plugins and adding it there instead.\n. I still think that the child selection interface makes sense, particularly in contexts where you're working with a selection (in a selection.call callback, for instance) that you don't know anything about, and can't use descendent selectors. I called it children() because that's what jQuery calls it (maybe not the best rationale, but it would be more intuitive for jQuery users) and because d3 seems to favor conciseness over descriptiveness. But it's your call, of course.\nAfter considering the data inheritance issues with ancestor() some more, though, I think it's probably best to just BYO ascendent selection function. I think what I'm most drawn to is the usefulness of the CSS selector/function duality, and how it makes so much sense in these contexts. #1619 would make it much more straightforward to implement these methods outside of the d3 internals. E.g.:\n``` js\nd3.selection.prototype.children = function(selector) {\n  var children = this.selectAll(function() {\n    return [].filter.call(this.childNodes, isElementNode);\n  });\n  return selector\n    ? children.filter(selection_selector(selector))\n    : children;\n};\nfunction selection_selector(selector) {\n  return (typeof selector === \"function\")\n    ? selector\n    : function() { return d3.matches(this, selector); };\n}\nfunction isElementNode(node) {\n  return node.nodeType === 1;\n}\n```\nAnd I'd leave the ancestor function out of the selection prototype so that I could use it similarly to how I've described above, which came into play for me recently when I was building up a DOM structure in which the depth of the link that performs an action affecting its container might vary from one node to the next:\n``` js\nd3.selectAll(\"a.action\")\n  .on(\"click\", function(d) {\n    selectAncestor(this, \".item\")\n      .classed(\"active\", d.active = !d.active);\n  });\nfunction selectAncestor(node, selector) {\n  var parent = node.parentNode,\n      selector = selection_selector(selector);\n  while (parent) {\n    if (selector.call(parent, parent.data)) break;\n    parent = parent.parentNode;\n  }\n  return d3.select(parent);\n}\n``\n. The idea of polyfilling:scope` is super interesting. Another candidate for #1619, perhaps?\njs\nvar supportsScopeSelector = (function() {\n  var div = document.createElement(\"div\"),\n      span1 = div.appendChild(document.createElement(\"span\")),\n      span2 = span1.appendChild(document.createElement(\"span\")),\n      spans = div.querySelectorAll(\":scope > span\");\n  return spans.length === 1 && spans[0] === span1;\n});\n. Correction: calling this.has(key) would only work if the has() method used hasOwnProperty().\n. I noticed that a lot more discussion about this has taken place in #2099, and that that issue was closed. I know that IE8 isn't exactly at the top of your list, but this is a pretty simple fix. I'd be happy to even refactor this a bit so that IE8 (using feature detection, of course) gets a different/slower version of the functions, so that this compatibility fix doesn't affect performance in modern browsers.\n. FWIW, @sylvinus, aight now ships with an aight CLI tool that you can use to prevent the errant for..in iterations over __proto__ in any JS file. The included d3.ie8.js is v3.5.3, but you should be able to create an up-to-date build with:\nsh\nnpm install -g aight\ncurl -s http://d3js.org/d3.v3.js | aight >  d3.v3.ie8.js\n. No worries, Mike! IE8 support is basically off my radar now that global and government site usage is <2%. I'm also going to use custom 4.0 bundles from now on to save precious kb's, so :+1: \n. ",
    "dbrgn": "I just ran across this issue and still think that setting X-Requested-With by default for all non cross-domain requests would be great. Django's request.is_ajax() is also affected. In the meantime, adding the header manually is a good workaround.\n. ",
    "benjchristensen": "This is a great feature and exactly handles \"missing data\" use cases. \nThank you kitmonisit and Mike.\n.defined(function(d) {\n                // handle missing data gracefully (-1 is used for missing data)\n                return d >= 0;\n            });\n. ",
    "gon": "Indeed this feature is actually more advanced and far simpler than what most charting libraries can handle. The doc item https://github.com/mbostock/d3/wiki/SVG-Shapes#wiki-area_defined clearly states what to do: \narea.defined(function(d) { return !isNaN(d[1]); });\nYou basically make sure to return false when you need to according to your data array's d object attributes. For example I need to check whether a date has a non-null amount of video streamed, it looks like so:\nvar areaThisWeek = d3.svg.area()\n  .defined(function(d) { return (d.this_week_streams != null); })\n  .interpolate(\"cardinal\")\n  .x(function(d) { return x(d.last_week_date); }) // plotted as a (comparative) cohort analysis to last week\n  .y0(height)\n  .y1(function(d) { return y(d.this_week_streams); });\nMy data array's d object is set up in such a way to have null values where no data is available yet, but you are free to check against any condition you like. Thanks Mike :)\n. ",
    "mmeisel": "Oops, I didn't realize this pull request was still open -- the most recent commit is meant to fix issue #603.\n. ",
    "BenMakesGames": "ordinal scale inversion is exactly what I need for mouse interaction with bar charts.  I'll definitely add this little patch to the copy of d3 we're using for our project.\n. ",
    "cherdarchuk": "Ordinal scales where this would be really handy: \nlow, medium, high\nbottom, middle, top\nalpha, bravo, charlie, delta, echo\n. ",
    "deanmalmgren": "I was just making a parallel coordinates chart like this one and to look at correlations between ordinal data sets. Was a little disappointed that this feature didn't move forward as scale inversion would have made this much easier.\n@mbostock Is there an example for 'toggling distinct values'? I haven't run across this example yet and it would be pretty helpful in this case. [now that I've declared that I haven't seen this example yet, I will almost certainly find it soon and update this thread accordingly]\n. The more I thought about it, the less the accessor seemed to make sense as the behavior of the function might change. I'm not sure what your philosophy is on these sorts of things, but if others request it we can always add later.\nI attached some code and also edited \"my version\" of the wiki to add some documentation. Should I just edit the official version and let you accept the documentation or is it possible for you to merge in my changes to the wiki. Forgive me as I'm a little new to this and I don't know the best way to do it.\n. v nice! thanks for putting that in there (and telling me about it).\n. ",
    "SalahAdDin": "What's about this man?\n. ",
    "curran": "This issue has been superceded by this other one https://github.com/d3/d3-scale/pull/60 There you can find an active effort towards this by @jheer and @mbostock .\nIt looks like ordinal scale inversion will land in D3 4.0.\n. Also here's an example that pretty much does invert an ordinal scale:\nhttp://bl.ocks.org/mbostock/4349509\n. @tracycollins I think what you need here is the General Update Pattern, taking advantage of the key function to specify which DOM nodes should associate with which data elements.\nIf you have a constant number of nodes all the time, it should be possible to keep track of the key values of the graph nodes that get removed, then use those same values for the new graph nodes. This way, the DOM element for the aged out graph node will be immediately reused for the new graph node, and the DOM element will never get garbage collected.. Perhaps this is better suited to post as an example on bl.ocks.org?\n. These changes look good to me.. @sixwolves This is a strange PR. What does it mean?. It may make sense to disable the Windows builds. It looks like the \"failing\" suites are only failing on Windows.. Nice additions! A few notes:\n\nThe \"on the specified window\" doesn't really make sense, without the context of the argument. Maybe best to leave it out.\nThe other blurbs use things like \"set\" and \"listen\", rather than \"sets\" and \"listens\", so for consistency, I'd suggest making it start with \"prevent\".\n\nSo my final suggested wording would be:\n\n\"prevent native drag-and-drop and text selection\"\n\"enable native drag-and-drop and text selection\". \n",
    "jonseymour": "Apologies for not including a test - I need to fix an issue with my installation of node that is preventing me from running \"make test\".\n. ",
    "marcneuwirth": "That will work for cases where you just want to just disable the handler, but not separate handling of the events to different functions.\nThe real problem is in the way scale is coupled with translate in the mousewheel function. This works fantastically in the basic use case, but makes it impossible to decouple them if you want to zoom straight ahead instead of to the mouse. This is also problem if you want to use zoom on a azimuthal projection, where you want to change the origin and not translate.\nMaybe there is a better way to prevent mousewheel from changing translate when necessary\n. I agree, that seems like a much better solution\n. ",
    "dcporter": "That's great, thanks!  Here's my example page - it's obviously quite\nheavily derivative of your existing chord demo.  The relationships code is\nat the top of the chord.js page (which I've also heavily annotated with\nnotes for myself on how the existing demo works).  Also, I never quite\nfigured out how to rotate the text properly; the labels are all very\nslightly off.  (I believe I'd need to add a bit that rotated the label by\ndifferent amounts based on the length of the label's text.)  Please let me\nknow if you need anything else from me at this time.\nBest,\nDave\nOn Mon, May 7, 2012 at 1:30 AM, Ger Hobbelt <\nreply@reply.github.com\n\nwrote:\nIf you could send me the edited example files, I'd be much obliged. Your\ncode has been backported into chord.js - see\nhttps://github.com/GerHobbelt/d3/tree/chord-layout-explicit-rel-pullreq-617(commit 5f09b7f5b35fe064f732d052478cdbb0ca8cc2c7 )\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/mbostock/d3/pull/617#issuecomment-5544171\n. I'm obviously not paying very close attention. Apologies. I'll get the\nexample files up on my branch ASAP or email them. Thanks!\n\nOn May 15, 2012, at 4:21 AM, Ger Hobbelt\nreply@reply.github.com\nwrote:\n\nThanks for the reply, but two things:\n(1) be aware that I'm not Mike, I just want the pull request to go\nthrough and to make that an easier process it should be synced to HEAD.\n(2) Didn't see anything at this end, so I guess you attached the example\nand github comments don't allow attachments.\nHence there's a couple of ways to proceed from this point:\n- add the example in your own branch which is related to this pull request\n- if git is still an issue over at yours, send the example file(s) to me\n  via direct email (ger at hobbelt dot com) and I'll drop them into my pull\n  branch and we can take it from there (either re-issue the pull req or you\n  pull that branch into yours so github appends the changes to this pull\n  request #617\nMet vriendelijke groeten / Best regards,\nGer Hobbelt\n\nweb:    http://www.hobbelt.com/\n       http://www.hebbut.net/\nmail:   ger@hobbelt.com\nmobile: +31-6-11 120 978\nOn Mon, May 14, 2012 at 3:50 PM, Dave Porter <\nreply@reply.github.com\n\nwrote:\nThat's great, thanks!  Here's my example page - it's obviously quite\nheavily derivative of your existing chord demo.  The relationships code is\nat the top of the chord.js page (which I've also heavily annotated with\nnotes for myself on how the existing demo works).  Also, I never quite\nfigured out how to rotate the text properly; the labels are all very\nslightly off.  (I believe I'd need to add a bit that rotated the label by\ndifferent amounts based on the length of the label's text.)  Please let me\nknow if you need anything else from me at this time.\nBest,\nDave\nOn Mon, May 7, 2012 at 1:30 AM, Ger Hobbelt <\nreply@reply.github.com\n\nwrote:\nIf you could send me the edited example files, I'd be much obliged. Your\ncode has been backported into chord.js - see\nhttps://github.com/GerHobbelt/d3/tree/chord-layout-explicit-rel-pullreq-617(commit5f09b7f5b35fe064f732d052478cdbb0ca8cc2c7 )\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/mbostock/d3/pull/617#issuecomment-5544171\n\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/mbostock/d3/pull/617#issuecomment-5690599\n\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/mbostock/d3/pull/617#issuecomment-5710779\n. \n",
    "webmonarch": "Yeah, I think the package.js change is a no-brainer.  Done and done.  Also just committed the change to the Makefile to remove the make package.json dep on d3.v2.js as well, closing the loop.\nThe changes in make install/make prepare are more a mater of taste...and their value comes into to play when (a) a person doesn't have d3 dependencies installed, and (b) they don't have a pre-compiled package.json.  We can say this is a corner case we don't care about, and I will remove it.  But, if anyone does care about it, then make prepare eases things a little because it implicitly calls make package.json.\nSo, bootstrap build from nothing:\n``` bash\nwith make prepare\nmake prepare\nmake\nmake test\n```\nvs.\n``` bash\nwithout make prepare\nmake package.json\nnpm install\nmake\nmake install\n``\n. np, I think it is a matter of taste.  I don't have an argument worth the time of the argument, so I've removed themake install/make preparetargets from this pull request.  The remaining changes are for thesrc/package.js` dependency improvements discussed.\n. ",
    "gigadude": "This is a supported variant in Circos, very useful for comparing the output of various clustering algorithms when grouping genomic data (in fact I think this may have been the first application for Circos). I can merge the code back into the chord layout but I was worried about the performance implications of doing so (assuming code duplication is the real worry).\n. ",
    "geowa4": "+1 on the concept, and the code looks like it'll do the job.\n. Basically, yes. Sizzle is in the codebase for supporting IE8 and below as much as possible. I noticed the API inconsistency when it was causing the issue I mentioned in my commit message. I was using IE9 when I found it.\n. ",
    "NathanaelA": "This appears to cause children of children to be smaller than the children of the very main circle even if all the child sizes are the same number. \n. Read your reason, I can see your point.    However, in my case -- this is a bad change.  :)    We are working on building a specific chart and the leaf node needs to be all the same relative size.  As they give a visualization of time required for a piece of the project.  If the leaf nodes change size then a leaf one level deep will look like it takes longer than a leaf several layers deep even if our \"size\" number is the same.  The parent nodes are just so we can see how many items it wraps.   So for us the Leaf is the critical that it stays the same relative size no matter where in the tree it is...   :-)\nMaybe make this a configurable option?\n. Sorry, not sure how to separate the pull requests properly.  :)    The second one fixes dom leaks.   When svg objects are removed; because they have data, chart and sometimes handlers attached to them; the browser is unable to clean them up and they stay around.    This clears any added properties to the dom elements; and removes all handlers so that the browser can free up the memory used by them, the data and the handlers.\n. Issue 1 (Leaf Nodes) -- I see your point; would you be willing to accept a patch with a optional option added to the packtree that would do this  (i.e. a  growSingleChildParentsBy = 1 variable, which I would set to be 1.5) -- Adding (a lot) of bogus records to a large dataset is not a good solution.  For our case we don't compare leaf node sizes.     If not, then I'll just maintain our own branch with this change.  :-)\n. Issue 2  (Dom Leaks) -- Interesting, something was fixed between 2.91 and 2.97; if I use 2.91 as the source code base -- I can duplicate the dom leak every time with a simple chart from the examples (the entire svg tree is leaked).   In 2.97, I only see it leak (very) rarely on a simple chart.  \n. ",
    "tpreusse": "Yes this is true.\nSee http://groups.google.com/group/d3-js/browse_thread/thread/31dd64b9657e8551 for explanation of the issue & proposed patch. Also note that the current documentation already indicates that circle size is only comparable to other nodes at the same depth in the hierarchy.\n. this change broke common, documented usage of force.drag\nnode\n    .on('click', function(d) {\n        // do something\n    })\n    .call(force.drag);\nnow needs to be:\nnode\n    .on('touchstart', function(d) {\n        d3.event.preventDefault(); // no scrolling\n    })\n    .on('click', function(d) {\n        if(!d3.event.defaultPrevented) {\n            // do something\n        }\n    })\n    .call(force.drag);\nHowever I do like the change. Not sure about the right approach to patching this: patch layout/force.js (at least touchstart would seem reasonable) and or create some awareness for the breaking change - update docu, examples etc.\n. !d3.event.defaultPrevented is needed because default gets prevented but propagation still happens - my click listener gets called with a default prevented event.\n. yeah it's quite tricky but checking for d3.event.defaultPrevented is not a major hassle and gives you full control - just needs to be documented (if desired). Btw.: I upgraded specifically to get the touchend with force.drag for a tooltip - which is nice and was really hard before.\n. ",
    "eghm": "I ran into this while throwing a lot of data into flare-imports.json.  Maybe it would be better if a node that has been imported but not named were created, but I think that is beyond my understanding at this point.  Another option which I found useful was to change the start.parent and end.parent to just start and end, then unnamed nodes are dropped, though a whole host of Problem parsing d messages.  Not ideal, was more useful to me than nothing.\n. ",
    "beccles": "+1\n. ",
    "javonharper": "+1\n. ",
    "sindilevich": "+1\nSince the no-Sizzle version of d3_select will return null when no element was found, the Sizzle version of the method should behave the same.\n. ",
    "bdon": "Done, amended into the last one.\n. Yeah, handling a useless scale is precisely what I need because I'm creating scales dynamically based on the min/max values from database queries. \nHere's an example for a single chart using a fixed number of ticks and different data. http://bl.ocks.org/4617865 notice when there is one domain value, no labels appear. In my application the charts need to handle arbitrary data so locking them to a fixed scale is not an option. \nIt seems like the best solution for correctly labeling the domain when n=1 is to pad the min and max values e.g.\nvar xScale = d3.scale.linear()\n    .domain([d3.min(data, xSelector) - 0.01, d3.max(data, xSelector) + 0.01])\n    .range([0,300]);\n. Glad you like them! Make sure you check out the bike map too: http://bdon.org/bicycle.html . My site does not have nearly as many epic demos as yours yet, but I'm working on it :)\n. ",
    "willzeng": "Has this been incorporated in any way? It would be a great addition.\n. ",
    "sj26": "@mbostock I'm assuming you're not interested in this patch; closing.\n. ",
    "logicalhan": "Excuse me, but where exactly is the code for the distance filter? I believe the Point clipping is still a bit buggy and I'd like to take a lot into it. Thank you for the framework, by the way. It's pretty great.\n. ",
    "tcha-tcho": "Yeap I made this mod to the built file rather than to the source. Sorry about that. At my work I cannot made GIT calls due to a firewall issues. So I did use github website to generate the commit. Could someone generate the src changes for me?\n. Thank you @shawnbot and @phoebebright ! I turned this suggestion into a independent js code. Thus it can be used in other circumstances too. http://tcha-tcho.github.com/tableconn/\n. ",
    "phoebebright": "Tried your version and worked perfectly first time, importing google doc as csv.  Thanks!\nIf you can point to a instruction on how to generate src change am happy to do so.\n. ",
    "snoble": "one error that seems probably unrelated\n\"\"\"\n    timer with no delay \n      \u2717 first calls after 17 ms or less \n        \u00bb expected 61 to be in within 20 of 17 // timer-test.js:16 \n  \u2717 Broken \u00bb 1638 honored \u2219 1 broken (2.308s) \n  make: *** [test] Error 1\n\"\"\"\n. now it passes... I should probably try to run a timer tests a few times before I accept defeat\n. just checking if you need anything more from me here. no rush\n. cool. just wanted to make sure you weren't waiting on me. let me know if there's anything I can add or clarify. (And congrats)\n. Oh, my apologies for that. When I had played with stuff prior (see https://github.com/snoble/smoothcurvesjs) I had written my own cubic spline function that generated regular cubic polynomials instead of using the more correct Hermit spline which generates parametric polynomials. I didn't realize my method fails when using proper splines.\nFor what it's worth I wrote up a quick modified d3 that has a function that generates the bezier curves for the regular cubic polynomials (https://gist.github.com/e8e1c7e95e9431fa8cfd). You can see it corrects the backwards curve http://bl.ocks.org/3310362\nThe downside to this method is that the control vector for the right side of a point is no longer just the negative of the control vector for the left side. They still have the same slope but their lengths are different.\nHowever this method still guarantees that the cubics meet at the same slope, a monotonic curve, and respect for local minima and maxima. And since it generates a regular cubic polynomial it will never go backwards.\nLet me know if you would like me to investigate this further.\nThanks,\nSteven\n. Oh, I think this might be a more general bug. I'm submitting a pull request.\n. Are there any questions or comments surrounding this?\n. I think I may have confused things by saying (and thinking) that HermiteSplines and CubicPolynomialSplines are different things. All I've done is implemented http://en.wikipedia.org/wiki/Cubic_Hermite_spline#Representations (see from line starting \"Using this connection you can express...\"). \nThe current implementation of connecting a series of bezier curves with only one control vectors per point results in reversing along the x-axis as above.\n. hey, just my regular nag for this pull request.\nlet me know if there's anything I can do to help with it. Personally I do think this bug is real (see http://bl.ocks.org/3315490) and I do think this is the right approach to fix it. I'm not sure this is the best implementation of that approach though.\nIf there's a test you'd like to look at to determine if this is the right approach but you don't have time to write it let me know and I can write it for you (though I appreciate describing a test to someone else can be just as time consuming as writing the test in the first place).\n. Ah, now I understand. Sorry for the confusion. I hadn't realised that the\nother interpolaters weren't for graphs.\nIn that case I think there is still a bug in monotone. The fix I submitted\nbefore fixes how the slopes are selected. But the reversing is still there\n(as you discovered and as you can see in the 2nd link above). I'm pretty\nsure that's due to the spline function.\nOn Aug 25, 2012 1:55 PM, \"Mike Bostock\" notifications@github.com wrote:\n\nI'm averse to changing the behavior for the existing interpolators. There\nneeds to be a high bar, such the obviously broken behavior of the monotone\ninterpolator, in order to change the behavior. Otherwise we risk surprising\ndevelopers who upgrade. We can introduce a new interpolator if there is\nsufficient value to justify the incremental complexity.\nMy specific concern here is that cardinal splines are not intended for use\nin the context of a graph with a dependent variable y and independent\nvariable x, so there is no pressing need to \"fix\" them. An appropriate\nuse of cardinal interpolation is the clustered force layout examplehttps://github.com/mbostock/d3/blob/master/examples/force/force-cluster.htmlwhere a closed cardinal spline is used to draw the bounding convex hull of\neach cluster.\nYour fix is an improvement when using cardinal splines in graphs, but the\nmonotone interpolator is still greatly preferred. (Or, under some\nconditions, the basis or linear interpolators are also suitable.) The\nmonotone interpolator outperforms the cardinal interpolator here because it\nis explicitly designed for use in graphs; the other interpolators are not.\n(Related: I don't recall if it's possible to use the monotone interpolator\ncorrectly for graphs that are oriented in other directions.)\nSo rather than change cardinal interpolation or introduce a new\ninterpolator, shouldn't we encourage people to monotone interpolation\ninstead? Which, thanks to you, is now fixed? [image: :grin:]\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/mbostock/d3/pull/759#issuecomment-8025717.\n. Does the pr even still merge? If so does it actually solve your example?\n. I updated my patch. I'm not super happy with it at the moment and when I have more time I should describe why the fix more closely follows the original paper. But try the branch at https://github.com/mbostock/d3 and see if that fixes your problem (or makes it much worse).\n. hmm... I should think more about that scenario\n. Thanks @mbostock!\n. \n",
    "gabrielmontagne": "I've implemented this because it was needed at work:   We're building a generic component that takes an unknown container (can be a list, or a div, etc) for which we define a \"prototype\" renderer in markup.  This renderer can be an arbitrary chunk of html that has been styled, etc..   Our component pulls that node from the component and caches it.  When we join the data we append a new clone of  the for each of the data items and we then update each with the datum.    \nA simplified example would go along these lines.  Given the markup, \nhtml\n  <html>\n  ...\n  <li class=\"prototype\"> <!-- or \".template\", etc. -->\n    <span class=\"price\">Price</span>\n    ::\n    <span class=\"index\">Index</span>\n    <p>... other stuff</p>\n  </li>\nWe do something along the lines of \n``` javascript\n;requirejs.config({ shim: { 'd3': {exports: 'd3'}} })\nrequire([\"d3\", \"jquery\"], function(d3, $) {\nvar $prototype = $(\".prototype\").remove(), format = d3.format(\"+3.3f\")\nul = d3.select(\"body\").append(\"ul\")\n  li = ul.selectAll(\"*\").data(d3.range(10).map(format))\n  li.enter().append(function(d, i) { return $prototype.clone().get(0)  })\n  li.select(\".price\").text(function(d, i) { return d; })\n  li.select(\".index\").text(function(d, i) { return i; })\n});\n```\nWe \"managed\" to implement this without appending the raw node by appending stub \"span\" nodes, then on an each we actually replace them using $.replace()... but we have to set the datum again by hand and re-calculate the data join.   Not nice at all.\n. ... We're also expecting to be able to select among various data renderers based on the data type... We wish to have certain markup structures that can render certain kinds of articles, for example, and some other configuration for other kinds of research, etc. and be able to decide at the moment of appending the nodes.  Hopefully from some markup chunk written (and styled) as html and not have to reconstruct them using javscript as they can get pretty complex.   \nWe're using d3 to build all our data-driven components.  Not only charts but mixed activity feeds for publications, selectors, typeaheads which mix text and images, etc.\n. ... and even if just to be able to do things like, \njavascript\ndiv.enter().append(function(d, i) { return Math.random() > 0.5 ? $(\"<p>something\" + d + \"</p>\").get(0) : $(\"<h2>other\" + i + \"</h2>\").get(0) })\nand get\nhtml\n<div><p>something+0.000</p><p>something+1.000</p><p>something+2.000</p><h2>other3</h2><h2>other4</h2><p>something+5.000</p><p>something+6.000</p><p>something+7.000</p><h2>other8</h2><p>something+9.000</p><p>something+10.000</p><h2>other11</h2><p>something+12.000</p><h2>other13</h2><p>something+14.000</p><p>something+15.000</p><p>something+16.000</p><p>something+17.000</p><p>something+18.000</p><p>something+19.000</p><h2>other20</h2></div>\n:^)\n. Thanks for the reply.  And I agree, clone (and insertClone) do sound like a good idea.  Although in my mind, if you read it too quickly, it might read like you could be cloning the selection.\nI understand that in order to use selection.append(function) one needs to understand that the function will be called several times and that one must return a fresh object every time...  but I don't think that that is significally harder to grasp than the other functions one can provide for the different methods like attr(), style(), etc. for which one also needs to be aware that the method is called time and time again for each of the elements.\nThe arguments of the append function would be the same so I think it can even feel intuitive for the users.\nWith the patch the current functionality of selection.append() wouldn't be affected.  One can use the name string just as before; the use of a function can be thought of as a slightly more advance use.  ---The function can even return the element name as a String, \"p\", for example, and it will still work---\nWe do have one (for us very important) use case which couldn't be fulfilled by the clone method.  This is being able to decide which node to return based on the datum item.   It is in this context that I find the function argument quite convenient: \njavascript\nenter.append(function(d, i) {\n  return  d.type == \"publication\" ? publicationRenderer.cloneNode(true)\n        : d.type == \"research\"    ? researchRenderer.cloneNode(true)\n        : \"p\"  // default?\n});\n... as illustrated on this very  toyish example (which also shows how the nodes can be easily plucked and potentially prepared for rendering):\nhttps://gist.github.com/3215903#file_index.html\nhttp://bl.ocks.org/3215903\nI like the manual selection / attachment you suggest on your last example and we can use this approach on our project.   But I don't see how that's more intuitive than just allowing the function as argument for append / insert.\n. I also now agree... but only after having first done my own implementation of append for function that returns a raw node and after trying out the \"select\" direct way of creating and appending the node by hand. \nTrying both, one realizes that the functions you pass to either are very very similar, the only difference is the actual attaching the node you create before returning it on the select route.\nSo now I know how little value the append(function--for raw node) provides.\nBut before, just by going through the API and the documentation, that was not visible.\nIf only for this, I wish there had been either a note on the selection.select documentation about this technique (which is not intuitive, I have to say) or the friendlier, thin, but welcomed sugar nicety of allowing the function that returns the node.\n. Yes, once one realizes that if you pass a function to select or selectAll one can return whatever elements\none wants, then it's easy to appreciate how flexible but terse the API is.  \nOne can then build all sorts of components to plug in there.  At work we've built components that clone from other nodes or that build nodes from html snippets.\nBut one can do many different things as well: selection functions that return objects from a pool, components that do subselections based on characteristics of the data or the nodes, components that return nodes that already live somewhere else on the DOM or even creating nodes that are not yet attached because we want to asynchronously build them before showing them... etc.\nFor example, this great new library, https://github.com/sammyt/see , https://groups.google.com/forum/?fromgroups=#!topic/d3-js/dNemrm3UF1M which can make sure a certain DOM structure---described in a simple expression---is in place, building whatever elements are missing, and returning a new\nselection with whatever nodes one has marked as targets.\nI think Mike is right in trying to keep the API small; it'd be hard to cater for all these different uses without overly complicating the calls.   And it the most straightforward things one would like built are easy to express.\n. This is very useful.   \nI'm also using D3 with domino server side, to not only construct HTML documents but also to query and process long and deeply nested XML documents; D3 is very useful in this context. \nWouldn't it be better if there were no default document/window objects on D3 when running server side?  Client side, of course, there's no reason not to have them, but server side the use cases are more diverse and the explicit configuration of the document might not be felt as a burden.\nAt work we don't need jsdom at all but still we run into problems with it because jsdom is a D3 dependency but it won't easily build on our windows machines.\n. ",
    "nevir": "To me, there's several issues being surfaced by this:\nConsistency\nPractically everything else supports functions, I'm guessing that most people would be genuinely surprised that selection.append() & selection.insert() do not.\nSimilarly, while select() can handle all of the desired behaviors, you certainly won't think to use it for a mutation.  Tweaking the docs might mitigate that, but I suspect that you'll continue to see pull requests like this.\nNode Confusion\n@mbostock It seems like your primary concern here is around inserting raw nodes (and screwups from re-inserting existing nodes).  What about:\n- Only allowing string values (or function calls that return strings)\nor:\n- Throwing (or silent failing?) if you attempt to insert a node that already is in the DOM, or has __data__.  (I'm less of a fan of this)\nIt is, however, tremendously useful to be able to synthesize nodes via whatever framework you're comfortable using (say, a Backbone view) - you also avoid having to create wrapper elements or modify the DOM multiple times...\nDOM Mutations\nDOM insertions are pretty heavy (and you especially feel the pain on a mobile device), cutting them to a minimum has been a great performance boon for my projects so far.  I think we can get to a pretty comfortable world where those are cut down to a reasonable level while also producing clear & concise D3 code.\nFor example, the main thing I'm using (via #734) is to pass a function for the before argument of selection.insert - so that I can easily insert elements in the order that they are specified by data, regardless of what's already in the DOM.  This avoids shuffling things around after the fact via order() - Is there a better, already-existing, approach that I'm missing?\n. Awesome, thanks for the thorough response and rationale!  I think I'm pretty well in line with your thinking now.\nFor my specific problem, would a selection.insertInOrder(name) be even more appropriate here?\n. My main motivation is the insert functionality;  Is that a separate discussion?  (the other requests are all about append)\n. I'm seeing a pretty dramatic speed up with this (particularly on iOS, which is where I'm focused): http://jsperf.com/d3-dom-interleaved-insert-performance (edit: I had the benchmark goofed for append/clone - it's closer, but still ~15-20% faster on iOS 6)\nI'm not sure I understand the ordering issue you're describing, though.  Is that if your key function changes behavior between updates?  (all the tests in this pull request use a key func w/ data sorted by key)\n. Also, this would probably need a bit more tweaking to be a good append substitute (it's definitely going to be slower for that case since it's currently walking the data & building that lookup array; I could make it a bit lazier about the memoization)\n. Bump; I'm using this successfully so far in my own projects - do you want me to address anything else as part of this pull request?  (better memoization for the append case?)\n. 10-15% or so is pretty significant, especially for large sets of nodes.  (And I was seeing wins of 20% or so on iOS)\n. @campersau interesting approach!\n. ",
    "gorhill": "If selection.append() supported functions, this sure would simplify code.\nTake this very simple case: a bar chart, where each bar is a filled \"rect\" and a \"text\" used as a tip for the datum, both sitting within a common parent \"g\".\nI want to benefit from the power of CSS, so I can create a CSS rule for when the user hover over the parent \"g\", the child \"text\" become visible (i.e.: \"svg.barchart g.bar text.tip { display: none }\" then \"svg.barchart g.bar:hover text.tip { display: block }\"). No javascript required.\nI can do that right now, but I need three consecutive select.append(), while in my opinion it would makes more sense to call select.append() once and let the user create whatever composite (or not) node he wants. Whenever the composite node grows in complexity, more append() calls are required.\nBut then, I admit I am new to d3, so I might be overlooking the optimal way to do this.\n. The each() you propose is no different than what I see as a workaround now: multiple iterations are required in order to join data and composite DOM elements.\nWhether this function should return a string is really a non issue in my view, as you said somewhere above, that make no sense, this I agree.\nI do not understand your last sentence. I define a composite element as a single element, but with one or more children. So append() would be returned the single top element of the hierarchical ensemble. In the example I was giving, the function given to append() as an argument would instantiate and assemble <g><rect /><text>...</text></g> in memory, and return a reference to the \"g\" element. This would allow for a single iteration, and for whatever needs to be computed, to be computed once per datum.\nThe issue to me is that the current API to join data to DOM element is less friendly toward elements which are composite, which I believe is not an uncommon occurrence, as we are dealing here with objects which are inherently hierarchical, \"g\" or \"div\" elements are rather useless on their own.\nLets have this CSS:\n```\n.d3BarChart .plotArea .bar text {\n    display: none;\n    }\n.d3BarChart .plotArea .bar:hover text {\n    display: block;\n    }\n```\nWith current API:\nvar bars = plotArea.selectAll(\".bar\")\n        .data(d3FriendlyData)\n        .enter()\n        .append(\"g\")\n            .attr(\"class\", \"bar\")\n            [other attributes stuff]\n        ;\n    bars\n        .append(\"rect\")\n            [attributes stuff]\n        ;\n    bars\n        .append(\"text\")\n            [attributes stuff]\n        ;\nWhile if append() accepted a function as an argument:\n```\n    [...]\nvar bars = plotArea.selectAll(\".bar\")\n    .data(d3FriendlyData)\n    .enter()\n    .append(function(d, i) {\n        var g = [create g (with convenient d3 API to create SVG elements?)]\n        var rect = [create rect]\n        var text = [create text]\n        [append rect to g]\n        [append text to g]\n        [attributes stuff for all]\n        return g;\n        })\n\n```\nObviously, this is a simple example, and the former form doesn't appear too much of a burden with this simple example. But I do believe supporting a function as an argument would remove a constraint from the current API which assume that whatever needs to represent a datum is a leaf DOM element.\nThis new form of append() has also nice side effects\n- Ability to reuse values which are computed on the fly from the datum for all elements in the composite element, thus compute once, use more than once.\n- Ability to reuse elements which are already instantiated but now marked as unused component. Say some elements are removed because no longer used, I could place them in a recycling bin for later reuse, thus skipping the (costly from what I understand) instantiation from scratch, all with the attribute settings stuff which does not depend on the datum. Example:\n```\n    var bars = plotArea.selectAll(\".bar\")\n        .data(d3FriendlyData)\n        .enter()\n        .append(function(d, i) {\n            var g = RecyclingBin.pop();\n            if (!g) {\n                g = [create g]\n                var rect = [create rect]\n                var text = [create text]\n                [append rect to g]\n                [append text to g]\n                [attributes stuff which does not depend on datum]\n                }\n            [attributes stuff which depends on datum]\n            return g;\n            })\n``\n. Ah I see. I tried it and I can indeed do the above usingplotArea.selectAll(\".bar\").data(d3FriendlyData).enter().select()`. Never mind then, I am new to D3, I still need to wrap my head around it. Sorry for the noise.\n. ",
    "baumandm": "FYI I'm using this feature successfully as well.  It is very useful for updating an HTML tree where nodes are arranged by their document order rather than absolute positioning.\n. ",
    "AlexGalays": "According to the JsPerf above, isn't the performance gain negligible? Or does it heavily depend on the platform?\n. ",
    "campersau": "If I understand it right you want something like this http://bl.ocks.org/campersau/5274509 don't you?\n. ",
    "gregsymons": "Should this go into the 2.9.8 branch instead?\n. ",
    "ferz": "Thank you for this improvement. I hope to find it in main d3.js distro soon.\n. ",
    "rfink": "Any update on this?\n. ",
    "jeffrose": "Would it make more sense to just use the amdWeb pattern from umdjs? That way AMD is used if it's present and browser globals are used if it's not.\n. ",
    "sheppard": "+1 on having d3 utilize the amdWeb pattern in the default build.  \nI'd go further and suggest that d3 itself might benefit from a transition to AMD modules internally (with r.js or similar to build the output file).\n. Thanks for the link, though it appears that the referenced components (including the D3 component) are based on CommonJS rather than AMD.  As I understand it, a key benefit of AMD over CommonJS is the ability to use & debug individual module files directly within the browser before building the singled minified file for deployment.\n. To clarify - given its dependency on the CommonJS module syntax, it seems unlikely that Component can automatically load source modules directly into the browser as-is, a key feature of AMD.  AMD was created specifically to address the lack of asynchronous module loading in CommonJS, and thus requires a different module definition syntax (see http://requirejs.org/docs/whyamd.html for more information).\nMore to the point, since the AMD module format is not directly compatible with CommonJS, Component is not a useful option for those of us who are already using AMD.  FWIW, a number of libraries (jQuery Mobile and Dojo being two prominent examples) have already or are in the process of migrating to AMD.\nIn order to use d3 in their projects, AMD developers have three main options:\n- Use the \"shim\" capability in RequireJS (http://requirejs.org/docs/api.html#config-shim) - a stopgap measure at best.\n- Maintain a custom version of d3 with AMD support added (a couple of lines of code, but still less than ideal)\n- Work with the d3 community to add AMD support to the library. This pull request is just to add it to the final built file, which will be a great start.  I also think there would be a benefit to converting all of the d3 source modules to the AMD format - but let's defer that discussion to a later time.\nThe amdWeb pattern provides a nice compromise between AMD and the traditional \"browser global\" approach.  The nice thing is that it should not break any existing functionality. @gregsymons and others, would you be interested in updating this pull request (or creating a new one) with an amdWeb-based solution?\n. This is fixed in 3.4\n. For the AMD/RequireJS definition, all you need is\njavascript\ndefine(d3);\nThe module name, dependency list, and wrapper function to return d3 are not needed in this case.  jQuery uses a named module for historical reasons, and uses a wrapper function because the jQuery object is itself a function.\nThe other thing that's commonly done is to avoid setting the window global at all if either Node or AMD is detected, and to always do it if neither are found (no need to check for window existence).  Finally, certain AMD loaders will define module.exports (EDIT: it's exports that is defined by some loaders, not module.exports), so the AMD definition is typically put first for maximum compatibility.  So, my recommendation for the full universal module wrapper would be something like this:\njavascript\nif (typeof define === \"function\" && define.amd) {\n  define(d3);\n} else if (typeof module === \"object\" && module.exports) {\n  module.exports = d3;\n} else {\n  window.d3 = d3;\n}\n. Good point, I have seen a recent movement toward this rather than window.\n. Cool, thanks!\nI was just about to throw out another option based on this example.\nPros: works with the return from the old closure, and puts all the moduley stuff at the top of the built file.\nCons: a bit more convoluted\njavascript\n(function (root, factory) {\n    if (typeof define === 'function' && define.amd) {\n        // AMD. Register as an anonymous module.\n        define(factory);\n    /* EDIT: instead of this: \n    } else if (typeof exports === 'object') {\n    do this: */\n    } else if (typeof module === \"object\" && module.exports) {\n        // Node. Does not work with strict CommonJS, but\n        // only CommonJS-like enviroments that support module.exports,\n        // like Node.\n        module.exports = factory();\n    } else {\n        // Browser globals (root is window)\n        root.d3 = factory();\n  }\n}(this, function () {\n    var d3 = {};\n    // make d3\n    return d3;\n}));\nI'm fine leaving it as you have it now.\n. Yes, I just noticed that after copying the example.   I agree that typeof module === \"object\" && module.exports is a better test - I meant for the example to be effectively the same.  My main point was just to show the difference in where the cludge actually appears in the file.\n. It'd be less cludgy if everyone would just use AMD :)\nOk I'll stop\n. Related: jquery/jquery#1478\n. Aww, I was hoping for Option 2 to become adopted as a \"standard\" approach so I could stop having to add AMD wrappers to plugins myself.  Oh well, a global d3 isn't the end of the world.  FWIW, even under AMD you could always do a synchronous\njavascript\nwindow.d3=require('d3');\nin the console as long as d3 has already been loaded once asynchronously.\n. ",
    "Trakkasure": "Check the component user @ github: https://github.com/component\nThere is a D3 component created that utilizes the AMD style loading you are asking.\nPlus, after loading all your components, creating a single minified file becomes simple to do.  \n\nBrandon Myers\nOn Monday, January 28, 2013 at 12:45 PM, S. Andrew Sheppard wrote:\n\n+1 on having d3 utilize the amdWeb pattern in the default build.\nI'd go further and suggest that d3 itself might benefit from a transition to AMD modules internally (with r.js (/jrburke/r.js) or similar to build the output file).\n\u2014\nReply to this email directly or view it on GitHub (https://github.com/mbostock/d3/pull/745#issuecomment-12796976).\n. I believe that this system supports just that. The minified version is the additional benefit (with all dependencies) that this system provides.  \n\n\nBrandon Myers\nOn Monday, January 28, 2013 at 2:20 PM, S. Andrew Sheppard wrote:\n\nThanks for the link, though it appears that the referenced components (including the D3 component) are based on CommonJS rather than AMD. As I understand it, a key benefit of AMD over CommonJS is the ability to use & debug individual module files directly within the browser before building the singled minified file for deployment.\n\u2014\nReply to this email directly or view it on GitHub (https://github.com/mbostock/d3/pull/745#issuecomment-12802171).\n. \n",
    "rodionos": "Mike,\nIn en_US: substring(0, 3).toLowerCase() works.\nd3_time_weekdays = [ \"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\" ]\nd3_time_weekdayAbbrevRe = /^(?:sun|mon|tue|wed|thu|fri|sat)/i\nIn ru_RU: substring doesn't work as the abbreviated weekday is based on the first two consonants.\nd3_time_weekdays = [ \"Voskresenie\", \"Ponedelnik\", \"Vtornik\", \"Sreda\", \"Chetverg\", \"Pyatnitsa\", \"Subbota\" ]\nd3_time_weekdayAbbrevRe = /^(?:vs|pn|vt|sr|ct|pt|sb)/i\nWhich is why 'Remove duplicate locale specification.' commit break things.\nThe 2 letter codes can be padded to 3 letters as specified in the locale specification file.\nP.S. I'm using a transliterated Cyrillic to illustrate the issue.\nThanks,\nSergei\n. Hello Mike,\nAnother suggested fix to make the default d3 scale more useful is 24-hour format instead 12 hour (AM/PM) format.\nReason being is that 12 hour format is used only in small set of countries.\nThe following changes need to be introduced into scale.js and scale-utc.js:\nscale.js - var d3_time_scaleLocalFormats = [\nOLD\n  [d3.time.format(\"%I %p\"), function(d) { return d.getHours(); }],\n  [d3.time.format(\"%I:%M\"), function(d) { return d.getMinutes(); }],\nNEW\n[d3.time.format(\"%H\"), function(d) { return d.getHours(); }],\n[d3.time.format(\"%H:%M\"), function(d) { return d.getMinutes(); }],\nscale-utc.js - var d3_time_scaleUTCFormats = [\nOLD\n  [d3.time.format.utc(\"%I %p\"), function(d) { return d.getUTCHours(); }],\n  [d3.time.format.utc(\"%I:%M\"), function(d) { return d.getUTCMinutes(); }],\nNEW\n[d3.time.format.utc(\"%H\"), function(d) { return d.getUTCHours(); }],\n[d3.time.format.utc(\"%H:%M\"), function(d) { return d.getUTCMinutes(); }],\nCould you please add a 12/24 switch into the build file? \nAlternatively, it would be nice to be able to switch formats at runtime. \nThanks,\nSergei \n. ",
    "hlship": "I'm trying to track down if multi-value map support was ever released?  It would appear it is, but I don't see support for it inside 3.1.6. Was it backed out at some point?\n. ",
    "ianjorgensen": "The way i use to get around that limitation is:\n``` js\n.attr('attr', function(d) {\n    var style = {fill:'blue', r:5};\nfor(var attr in style) {\n    $(this).attr(attr, style[attr]);    \n}\nreturn;\n\n});\n```\n. ",
    "tandu": "Faced with this issue today in v3.1.4, monotone is still not fixed. Should I patch d3 for my project or ping mbostock?\n\n. You are right, it is cardinal, sorry for incorrect screenshot but monotone has this issue too.\n\nSo there is no way for splines to not cross x coordinate twice without customizing points in my case?\n. I haven't tried it, I will merge it manually if needed but I'm going to wait for developers response first.\n. I have used @jasondavies version from here https://raw.github.com/jasondavies/d3/master/d3.js. Monotone is broken there.\n. I see. I misread your post so that you have tested test case against your branch.\n. I'm getting \"Error: Problem parsing\" d=\"M1023.8598412263891,82.2C1023.8598412263891,NaN,.....\" when 2 coordinates have the same x position. This is not a problem in my case and everything else works perfectly, thank you.\n. I have used suggested replacement\n\nOn 26 Mar 2015, at 19:04, Ivan Lukashov notifications@github.com> wrote:\nHello. Any updates with that bug?\n https://cloud.githubusercontent.com/assets/975790/6850521/b618721a-d3ea-11e4-835b-da819ed5d585.png\n\u2014\nReply to this email directly or view it on GitHub https://github.com/mbostock/d3/pull/759#issuecomment-86592660.\n. \n",
    "wayx": "Hello. Any updates with that bug?\n\n. ",
    "julienfr112": "can this pull request be merged ?\n. ",
    "frogcherry": "oh~ that's great! i'll try it\n. ",
    "vogievetsky": "Also if you want to try out this but you can not be bothered to get my forked d3 then simply import https://github.com/vogievetsky/KoalasToTheMax/blob/master/d3.mouse.patch.js into your project it is the same code and it will override the regular d3.mouse function with the fixed one. Note that that file might disappear if this pull request goes into d3 (So don't hotlink).\n. ",
    "habeanf": "Weird. Well, at least the bug was fixed :)\n. ",
    "ZJONSSON": "Yup, I get it. I came up with this request on the basis of  a specific pattern I was using (might be considered unconventional).   Let's say you have one routine that (perhaps on an interval) refreshes external data and resets a local selection variable as s=d3.select(\".elements\").data(newdata).   On the other hand you might have a GUI interface that changes individual elements of the data through datum.    By having default enter() and exit() in the selection object you can use the same code to redraw/replace, independent of the type of selection object.\n. A typical request could be as follows:\nSimple GET request (default)\nd3.text(\"localhost/test?a=1&b=2&c=3\",function(d) { console.log(d)})\nPOST request with url-encoded parameters\nd3.text(\"localhost/test\",function(d) { console.log(d)})\n  .method(\"POST\")\n  .setRequestHeader(\"Content-type\", \"application/x-www-form-urlencoded\")\n  .data(\"a=1&b=2&c=3\")\nPOST request with JSON encoding\n```\n  d3.text(\"localhost/test\",function(d) { console.log(d)})\n   .method(\"POST\")\n   .setRequestHeader(\"Content-type\", \"application/json\")\n   .data('{\"a\":1,\"b\":2,\"c\":3}')\n```\nI guess methods PUT / DELETE should work as well as the implementation is quite generic, but still untested.\n. This is very promising, thanks!!\nI had a tiny issue with the type-specific methods:\nArguments.length inside d3.xhr() is positive, even when no arguments are supplied to the type-specific method.  This forces a \"GET\" request being sent, even if custom .open() is supplied in a chained manner.\nFor example:\nd3.csv(null,function(d) { console.log(d)})\n    .open(\"POST\",\"http://localhost/test\")\n    .header(\"Content-Type\",\"application/x-www-form-urlencoded\")\n    .send(\"a=2&b=3\")\nworks but two http requests are fired.  One for url = null and the other for localhost\nI guess a quick check whether (!url) would be sufficient to prevent the initial GET request.  Type-specific methods could also be rewritten to \"preprocess\" the on(\"load\",d) such that:  d3.csv().open(\"POST,'.....').... .on(\"load\",d) would return csv parsed results into d ?\nIn any case, here are few other ideas in the same direction, focusing on POST convenience:\nhttps://github.com/mbostock/d3/pull/814\n. I did not manage to get the type-specific functions (d3.text etc) to work  as described above (hence my earlier pull request).   \nStarting with a simple empty d3.text() I get \"TypeError: Cannot read property 'length' of undefined\"\nReason:  d3_xhr_fixCallback is trying to determine the length of the undefined callback variable.   \nIf we amend with a default empty callback function, I still remain with more than two arguments ( n>2)  in the d3.xhr legacy code (due to mime and callback being specified) and automatically execute a GET request, even if our intention is to chain with a POST \nFinally the adaptor parsing only affect the callback supplied as a parameter, i.e. d3.text(null,callback).  The d3.csv().....on(\"load\",...) returns the XMLHttp object as expected in the load-event, not the parsed data.\n. Yup. Easy to fix, just a question on the optimal bridge between the two worlds :)\n. d3.json() /d3.csv() /d3.tsv() fail when attempting  to set request header (\"Accept\",mime) before request.open()\n. Yes, this is one reason I tracked headers separately and injected them after request.open() here: https://github.com/ZJONSSON/d3/commit/597b7d0bc4c6fd58548d3f15cbca8bbeb8b724b0 (old).  Hopefully there is a more efficient way to do this.\n. Looks great so far, except that \"application/x-www-form-url-encoded\" is still 34 characters etc.   I was hoping we could have very small-size vanilla post capabilities, while retaining full flexibility for detailed specifications.   Maybe we just have a .post(data,\"json\"||\"url\") shortcut that sets \"POST\" method and the appropriate header and submits the data.  I'll take it, even if I have to stringify the data myself :)\n. Thanks Mike, much appreciated.   Here are few thoughts back.\n1) xhr.post convenience function\nI see your point and applaud the \"new approach\", however I feel there is a disconnect with the legacy calls.  My original idea was to create a better bridge i.e. ability to amend a legacy call (with std arguments of url, callback) with chained operators that amend/modify the original query.  But perhaps a clean \"switch\" is for the best (i.e. user either picks legacy approach with GET only or the new chained approach).\nIn any case I would strongly support a convenience post function where the user does not have to bother with Content-Type.  My idea was that the automatic Content-Type assignment + JSON.stringify is only executed if the content type is unspecified.  Otherwise everything is executed exactly as specified with no modification.\n2) Interesting... I Agree.  I put this in there to counteract the \"double open\" problem from the current type-specific functions (i.e. a GET is currently always executed). This issue should be solved at the core, not with a fix.\n3) I use setTimeout(..,0) as we don't have process.nextTick() in the browser.   I would love to learn more about the inefficiency arguments against it, as the benefits are quite real, particularly when you need to execute something \"at the end\" of a chained set.   This trick is discussed in chapter \"1.2 When is Function Async\" in the book Async Javascript by Trevor Burnham (but no mention of overhead /downside / browser differences etc).\n4) This I put in, just because it was there to be exposed.  I see your point.\n. Personally I like the second method best.    I look at it this way:  If we didn't add a convenience-mechanism, the request would fail anyway as the XMLHttpRequest would simply transmit the string \"[Object]\" which is most likely meaningless under the circumstances.  \nI struggled more with whether a \"string\" should be (for convenience) assumed url-encoded if not specified (which I assumed might be common).  My view is that it's better to have effective and clear defaults, than no defaults and being forced to specify.\n. Good point.  But then again, specifying the Content Type is always an option for anything that requires specific handling.   The user would have to do that anyway, if not for the defaults.  We never know in beforehand the type of content a .toString function is returning anyway.\n. Well.. I leave this here as a thought.  It's probably more complicated than I thought.\n. Not directly, to my knowledge.  Queue.defer needs a function as an argument  (d3.xhr is an object, not a function).  \nHere is a demo using 3.0 (see the error in console)\nhttp://bl.ocks.org/4208359\nAnd the same demo with d3.xhr as a function:\nhttp://bl.ocks.org/4208375\n. Ah that makes sense.  I've been supplying queue with factory functions for too long.\nThanks and sorry for the confusion.\n. Excellent!  Pondering further on this subject I wonder if the window / document object can be local variables in each selection object?   If a Dom element is passed to a selector, the selection_root window/document would be set to the element.ownerDocument(), with a default fallback to d3_window / d3_document.  Again, this would allow for a very flexible JSDOM usage on the server side.\n. Thanks Mike.   For what it's worth, my thought process was as follows:\nOnly functions that are based on actual selections (and selections themselves) would be affected.  d3.transform() and other similar functions would therefore not be affected.\nLocal document/window are only set to something else than the globals if (a) selection_root has not already been defined (in this selection / parent selection) and that the supplied element to the selector is a DOM node.  In any other case, locals simply reference the globals.   d3.select(string) would therefore use global default, but d3.select(elem).select(string) would be based of the locals of the parent.    As a selection_root would only only set once for any selection chain, it would be impossible to have selections spanning multiple document.   As before, if you select a DOM from a parent selection that doesn't include that specific node, the result should be empty.\nAs the local variables are simple references to objects that already exist, I was expecting minimal impact on efficiency (even positive as the variables references are in a narrower scope).\n. I have not found a way to open up multiple instances of d3, per your earlier comment.  Any code in require() is executed once (see http://nodejs.org/api/modules.html#modules_caching) and d3 is a global object (see module.exports in index.js) not a prototype object (thankfully not).  Is it worth opening up a separate issue or do you want to box this for now?\n. The particular usage case I had in mind was rebinding action dispatches (such as resize, redraw etc).\nPlease see lines 15-17 of the following file for an example: https://github.com/ZJONSSON/dpl/blob/incorp_set/src/core/frame.js\nIf I use original d3.rebind and call frame.render() without arguments, I get the dispatch object, not the frame object.\n. Excellent!  May I suggest that instead of (key->true) we instead repeat the key on both sides (key->key) and use the object-value\" not the object-key for retrieval functions.  This ensures that the original objects placed into the set are returned, not the string representations.\n. Here is a sample: https://github.com/ZJONSSON/d3/commit/6092a091d81e96ea9c690e9ca20509c862ff86e3\nThis set works with dates without string conversion.   I also suggest we should use delete instead of remove, per ES6?\n. Got you.  My suggestion was mainly aimed at ensuring Date() objects passed into d3.set would return the same Date() objects back.   For regular objects we still will have the problem of an \"[object Object]\" key due to lack of a proper hash.\n. Would it not be more intuitive to implement row-conversion as a stream-like event-dispatch:\njs\n  d3.csv(\"test/data/sample.csv\", callback)\n    .on(\"row\",function(row) {\n       row.Hello = -row.Hello;\n    })\n. I like both versions (chained row or event-dispatch) much better than than using extra argument (seems more d3ish to me).  I guess my personal preference for event-dispatch comes from late nights with node.js, i.e. allowing \"potentially-multiple\" listeners subscribing asynchronously to row information.  If data modification is required it would have to occur in the first defined listener (not returning the data, simply modifying it in place).  But I can see how \"order of listeners\" might be confusing, as there is no explicit chaining. \nAs a practical matter, my key interest in row-processor/emitter is the ability to pipe into crossfilter to reduce overall preparation time.\n. My benchmarks showed a speed increase by internalizing the (static) extents of each quadrant at insert time instead of recalculating on every single visit. See https://github.com/mbostock/d3/pull/1109\nUsage example http://bl.ocks.org/zjonsson/5068952  (Even though I don't use the x1,y1,x2,y2 in visit function they are provided)\n. If I understand this correctly there would be a new complete d3 instance for each additional window. Would it not be better to keep track of local window in the selection prototype, as window is only used in selections?\n. +1 for extent (quadtrees that do not begin at topleft [0,0])\n. ",
    "javisantana": "our main reason is to be able to slow down all the animations. Sometimes you dont need the animations run at 60fps so changing the frame function allows to run slower (and save some CPU). This is basically the use case we have now, we have lots of animations done with transition method and we'd like to slow down.\nI can't see how moving requestAnimationFrame to compat would help, I would have to \"patch\" window.requestAnimationFrame before load D3, I could do the same right now (but it is not very elegant)\n. I do not want to set requestAnimationFrame function, I'd like to be able to overwrite \"d3_timer_frame\" function with some custom function in order to control the animations pace (without having to patch requestAnimationFrame before load d3)\nI put the getter because that pattern is used in d3 code not to use d3_timer_frame function directly which does not make any sense in case you want to do your custom animations (you should use timer as you pointed before) \n. >  guess my related question would be: how are you going to change the implementation of requestAnimationFrame to slow down the animation? You can't request a slower callback, but I suppose you could drop every other frame? Or are you going to replace requestAnimationFrame with a slower setTimeout?\nYes, I'd like to replace requestAnimationFrame with a slower timeout. The animation I'm running does not need to run at 60fps and d3 does not provide a way to control the animations.\nOne way to do that is to replace requestAnimationframe but in my opinion this is not the best way, d3 should provide something like my pull request to control the animations. \nI know i can code my own animation using timer function and skip some frames to archieve the desired FPS but I'd like to use then transition features of d3 but I cant control framerate.\nSo your proposal is to do:\nwindow.requestAnmationFrame = function(c) { setTimeout(c, DESIRED_T) }\n// load d3 library\nIs there another way to do this without doing this hack?\n\nAlso, related, if it helps: sometimes in the extreme cases (rendering thousands of nodes) I find it helpful to use a mixture of Canvas and SVG. For example, you can use Canvas to render shapes, and then have an SVG overlay for interaction and axes where D3's data-joins are helpful.\n\nYep, my problem is not performance here, my \"problem\" is that I dont want to run the animatiom at 60fps (why all the animations need to run at 60fps?) because It does not need to be updated at 60fps and I can save some CPU.\nThanks for your time \n. ",
    "tbranyen": "I hear ya man, but what do you prefer: broken or fixed :-/\n. Also only 6 lines and no actual source changes, this is pretty digestible compared to dropping an entirely new file into the project to maintain.\n. @mbostock I completely agree with taking this to JamJS and seeing if we can't get a priority to component.json if it exists.\n. Ah okay, first time I've seen the package.json dynamically generated, usually its the other way around.\n. @mbostock Thank you for merging =) Hopefully we'll be able to consolidate everything into the component.json for the client-side, I fear Node has pretty much dominated package.json.\n. @mbostock One last thing, just talked to @caolan and he wanted to know if you would take over that package in Jam.  If not, he can ping the current maintainer to force-update.\n. Hey @mbostock thanks for taking the time for a well thought out response.  I'm glad you merged this PR as it will fix a lot of headaches and confusion I've shared.  I have some comments below to address your options:\n1. While documentation certainly helps, libraries should be designed to the least surprise.  If you export for all environments where possible, your tool is available to a wider audience with less fuss.  You mention this as well, so we're on the same page.\n2. I wouldn't recommend making AMD a requirement.  Especially since d3 exports correctly in all major module environments and ES6 may-or-may-not be around the corner.  I believe with this PR merged, you have the library exporting as-good-as-it-gets.\n3. Removing AMD seems like the wrong way to go.  Too much flux and pretty much all mainstream libraries have adopted exporting as d3 does.  Its become a standard expectation.\nThe new ES6 modules specification has almost no momentum, but hopefully it will address the pain in even thinking about this stuff.  I can sympathize too; I've implemented UMD incorrectly several times trying to be clever and hating the whole decoration necessity.\n. ",
    "caolan": "@mbostock thanks, let me know your username on http://jamjs.org and I'll make you the package owner :)\n. ",
    "mjc-gh": "Just looking at all these changes now. Really like how it has all come along seems to be a very flexible API. \nI will try and kick in some tests soon and get as much coverage for the new API possible.\n. ",
    "gunn": "I'm not sure if I've got it right, to me this seems to still have the same problem:\njavascript\nd3.interpolateHsl(d3.hsl(240, 1, 0.5), d3.hsl(0, 0, 0))(.5) // \"#602060\"\nd3.interpolateHsl(\"hsl(240, 100%, 50%)\", \"hsl(0, 0%, 0%)\")(.5) // \"#602060\"\nI guess we can fix it by going to the odd step of giving black a hue and saturation, but that's basically what I think we should be doing in the interpolate methods.\njavascript\nvar black = d3.hsl(240, 1, 0)\nd3.interpolateHsl(d3.hsl(240, 1, 0.5), black)(.5) // \"#000080\"\n. That's exactly what my second example is, and what I think the interpolate methods should be doing internally.\nThe app I'm working on at the moment has users providing RGB values to tween between, so it's not a matter of just entering the colour differently. I'm sure other people are doing similar things.\n. Well it would be a shame to lose that control. I do think that the current behaviour will seem broken to most users who expect the most direct transition between two values though.\nIt is possible to switch to HSL (or whatever colour space) and manipulate the values before creating an interpolator - e.g. for HCL:\n``` javascript\nvar a = d3.hcl(a);\nvar b = d3.hcl(b);\nif (a.c<0.1) a.h = b.h;\nelse if (b.c<0.1) b.h = a.h;\nd3.interpolateHcl(a, b)(0.5)\n```\nOr something more complicated for HSL, but I think that's a lot to ask a casual user to figure out.\nWhat about an optional third argument for enabling this behaviour, treating greys as hueless by default?\njavascript\nd3.interpolateHsl(\"#00f\", \"#000\")(0.5) // \"#000080\"\nd3.interpolateHsl(\"#00f\", \"#000\", true)(0.5) // \"#602060\"\n. I don't particularly like the idea of having an additional mode either. If we can make this approach work, it's far superior.  Also it seems to me to be be more semantically correct to say that #444 has no hue than to say that it's red.\nShall I try to implement this?\n. bump\n. ",
    "j0hnsmith": "If a path element has a transition, how do you reselect the transition?\n. ",
    "muddydixon": "Thank you for review.\nOf couse I know JSLINQ.\nBut I want to use more easily especially on browser.\nI rewrite d3 plugin : )\n. ",
    "gollmann": "Am 15.10.2012 um 17:18 schrieb Mike Bostock:\n\nOK, my take on a fix is in f1c87d7 and slated for 3.0. Let me know if that works for you and thank you for the pull request!\n\nThanks for having a look at my suggestion. I agree that backwards compatibility is an important consideration. I have modified my graph to work with your patch.\nKind regards\nGeorg\n. ",
    "makyo": "Given a collection of services, we're creating a pack layout, then calling nodes({children: services}).\nWe began by using force instead of pack, and the issue we ran into was that we were not able to maintain distance between nodes that were not connected by a link, so while those that were connected remained reasonably far apart, those that weren't tended to overlap, and we'd wind up with a v-shape in smaller deployments.  We'll take a look at the other algorithms, though, and thanks for the suggestions.\n. ",
    "RandomEtc": "Tissot Indicatrices for you: http://bl.ocks.org/4052873\n. I didn't dare try it with other projections!\n. Maybe intended d3_radians here?\n. ",
    "mnmly": "\n@jasondavies \n\nOh, exactly.\nDuplication of #873.\n. ",
    "mrmicjam": "The bug if your code is probably with this line then:\nif (!arguments.length) return origin;\nwhich should be:\nif (!arguments.length) return azimuthal;\n. ",
    "evanworley": "I'd agree, no need to make it work for middle click (or any obscure mouse buttons) either :). Do you want me to update my patch or do you just want to merge in if (button !== 1) return; ?\n. ",
    "notan3xit": "You say that it is possible to override mousedown behavior to achieve this. But how can I override the behavior as a caller? The only thing I seem to be able to find is\n.on(\"mousedown.zoom\", null)\nbut this only works for disabling the behavior altogether. In this event handler, the event for zooming is not yet created. So I cannot check the button and call my zoom handler, because 'scale' and 'translate' will be undefined in the event. Is there any way besides copy-and-pasting and modifying the original handler from d3 (which I honestly also don't know how to do, because it uses lots of internal variables and functions)?\n. Thanks for the hint. Since it took me some while to get it to work, I want to point out that I needed this part to get it to work:\nsvg.append(\"rect\")\n  .attr(\"width\", width)\n  .attr(\"height\", height)\n  .style(\"fill\", \"white\")\n  .style(\"pointer-events\", \"all\");\nI do not know why exactly this is, however. Everything else works with or without it, but events do not get stopped by the capturing listener if the rect is not there.\n. ",
    "vasvir": "I was hit by that. The solution was to reverse the order of addition of event handlers and use stopImmediatePropagation()\nThe capturing listener is an overkill in my opinion and in my case it was creating more problems in later program logic.\nThe proposed patch also handles the case where you have a viewbox defined in your svg. In that case the rect does not fill the whole svg (if aspect ratio is being preserved) meaning it is possible to not cancel click events outside the viewbox\nSo if you want to get rid of the rect (no red blink though) here is the patch that applies to http://bl.ocks.org/mbostock/6140181\n```\n--- d3-prevent-panning-with-non-left-click.html.orig    2014-03-26 14:48:46.164954375 +0200\n+++ d3-prevent-panning-with-non-left-click.html 2014-03-28 16:37:28.196160612 +0200\n@@ -23,17 +23,10 @@\n var svg = d3.select(\"body\").append(\"svg\")\n     .attr(\"width\", width + margin.left + margin.right)\n     .attr(\"height\", height + margin.top + margin.bottom)\n-  .append(\"g\")\n     .attr(\"transform\", \"translate(\" + margin.left + \",\" + margin.right +\n \")\")\n-    .call(zoom)\n-    .on(\"mousedown\", mousedowned, true); // capture, so before zoom\n-\n-var rect = svg.append(\"rect\")\n-    .attr(\"width\", width)\n-    .attr(\"height\", height)\n-    .style(\"fill\", \"white\")\n-    .style(\"pointer-events\", \"all\");\n+    .on(\"mousedown\", mousedowned) // capture is not required\n+    .call(zoom);\nvar container = svg.append(\"g\");\n@@ -64,8 +57,7 @@\nfunction mousedowned() {\n   if (d3.event.button) {\n-    rect.transition().style(\"fill\", \"red\").transition().style(\"fill\",\n-\"white\");\n+    d3.event.stopImmediatePropagation();\n     d3.event.stopPropagation();\n     d3.event.preventDefault();\n   }\n'''\n```\n. ",
    "z0mt3c": "@vasvir thanks! works for me ;-)\n. ",
    "rushton": "incorrect implementation, will reopen at a later date\n. ",
    "gedejong": "Hi Mike,\nI understand you are hesitating to change a core functionality of d3.\nYour arguments make sense, but you might have misinterpreted the change.\nThe new implementation waits for a tick event, but calculates the\ndifference with the previous frame and applies the forces\nproportionally. Therefor, the behaviour of the layout does not change\nwhen the frame rate changes during rendering, giving a stable and\nfriendly appearance. On a slower machine, the layout will be less\nprecise, but will still feel identical to a fast machine. If we miss a\nframe (e.g. because of a calculation), the simulation remains smooth.\nSince the simulation is more true to real world physics, it is simpler\nto understand and extend. Drag forces, for example, can only be\ncalculated correctly in relationship with the speed of the object.\nThe user-defined forces can be extended to allow for a component based\nsystem for the force layout. E.g. the drag, friction, 'gravity', spring\nand static forces could be implemented as a user-defined force. The\ncomponents would work together to deliver similar behaviour as your\nimplementation. This separation of concerns makes the code understandable.\nI've tried the new implementation on relatively complex graphs,\ncontaining hundreds of nodes and thousands of edges with a strong\ncentrality. The simulation is stable, unless the drag forces become very\nhigh. This is easily circumvented by adding a cap on the drag force applied.\nIn any case, I feel you're missing an opportunity to extend the quality\nof the force directed layout. Have you tried my implementation?\nWith kind regards,\nEdwin de Jong\nOn 01/23/2013 08:13 PM, Mike Bostock wrote:\n\nHi Edwin,\nThanks for the pull request. Since there are multiple components to\nthis request I will address them separately.\nI'd rather not use a variable time step for the force simulation. In\naddition to being more complicated, it also means that the simulation\nwill perform worse, albeit at the same rate, on slower machines. Since\nthere is no expectation that the force layout be performed at the same\nrate across machines, it seems preferable that it perform with the\nsame quality, or at least chose the simpler of the two approaches. In\nother words the force layout is not time-based but iteration-based,\nand on slower machines there will be fewer iterations per time interval.\nAs for user-defined forces, that is typically done by listening to\ntick events. For example, the collision detection example\nhttp://bl.ocks.org/3231298 uses the tick event to apply a custom\ngeometric constraint. There are more examples of custom forces in the\ngallery.\nThis same technique could be used to apply a custom drag force. I\ndidn't look too closely at the exact type of drag force you\nimplemented, but one subtle issue here is the stability of the forces.\nForces that are derived from the particle\u2019s velocity are typically\nmuch less stable when using position Verlet integration, since this\ntype of integration has higher error in velocity (in favor of making\nit easier to apply geometric constraints).\nThanks,\nMike\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/mbostock/d3/pull/967#issuecomment-12616621.\n\n\nMet vriendelijke groet,\nEdwin de Jong\nTopicus Onderwijs\nEdwin de Jong\nEdwin.de.Jong@topicus.nl mailto:Edwin.de.Jong@topicus.nl\n+31 (0)6 4869 4147\n. ",
    "sander": "This also introduces pinch-to-zoom in Chrome 29 on Windows 8. The response is very choppy though, resulting in a \u2018shaky\u2019 graph in my case. Any idea what could cause this? Should there maybe be a threshold distance for actually changing the scale?\n. For reference: https://github.com/mbostock/d3/pull/984 seems to be a similar solution.\n. ",
    "dancrumb": "Ugh! Thanks... that's the root of it; In my application, I'm mixing\nLat/Long (which is normal Cartesian), with SVG (which is y-inverted\nCartesian) and so was getting all sorts of weird behaviour and reports on\nthe clockwise (or otherwise) nature of my polygons.\nThanks for your patience with this... that totally clears things up for me\nnow.\nDan\nOn Sun, Jan 6, 2013 at 9:20 PM, Mike Bostock notifications@github.comwrote:\n\nI think you may have your coordinate system confused. In SVG (and Canvas\net al.), the origin is in the top-left corner. Positive x is\nrightwards, and positive y is downwards. Taking the first example of a\nclosed counterclockwise unit square, [[0, 0], [0, 1], [1, 1], [1, 0], [0,\n0]], it looks like this:\n[image: Screen Shot 2013-01-06 at 7 18 47 PM]https://f.cloud.github.com/assets/230541/46604/f89b07c8-5878-11e2-9a6e-dcecefe1fbf1.png\nAs you can see this is counterclockwise. I'm guessing from your changes\nyou are assuming an origin in the bottom-left corner, with positive _y_going up?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/mbostock/d3/pull/994#issuecomment-11939701.\n. At the scale I'm working at (city scale), Cartesian is a reasonable approximation. Makes life a lot simpler too :)\n\nSent from my iPhone\nOn Jan 6, 2013, at 21:35, Mike Bostock notifications@github.com wrote:\n\n(But of course in most cases you can treat lat-lon as Cartesian and get the same answer\u2026)\n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "lukasolson": "Why is it such a bad thing that someone would have to look up what something does in the API reference? It seems to me like the benefits outweigh the drawbacks. Don't you get sick of writing \"function (d) { return d; }\" everywhere? :)\n. ",
    "gghh": "Thank you for the detailed explanation! Actually I am just starting out with javascript, and mine was just an educated guess. Cheers,\n. ",
    "smcgivern": "Thanks for the great response! Clearly there are a lot of considerations I had missed.\nAs I understand it, the main concern is: how to fit a hook for performing type conversion within the existing interface for d3.tsv. Not chaining methods allows Queue.js and similar to be used, as well as being cleaner. The options you have discussed (and rejected?) all fail this test. (Feel free to stop reading here if that's not the case!)\nI am also working under the assumption that the third option is the preferred approach, which I'd agree with. The second does have the advantage that as the converter argument will not be a function, it's possible to switch based on the type of the second argument to d3.tsv, as is done in d3.xhr when no MIME type is passed. However, the other advantages of the map function outweigh this.\nSome potential approaches, then, are:\n1. Expose a second function. Something along the lines of d3.tsvTyped(url, converter, callback). This is less elegant, and would need a better name, but is at least explicit about its and the caller's intentions.\n2. Break existing code by moving the callback to after a converter function. A non-starter for many reasons.\n3. Require an explicit null callback to be passed when using a converter without sending the request. This can't work without modifying d3.xhr, because as far as I can see there is no way to specify a callback after creating the XHR. Calling d3.tsv(url, null, converter) is also ugly.\n4. Force the converter function to have a particular arity, so it can be determined which argument is the converter and which is the callback. Unfortunately, the callback can explicitly have arities 0, 1, and 2 (unary callbacks are corrected after the callback is passed to d3.xhr), and potentially others are in use. Additionally, requiring a particular arity seems non-idiomatic.\n5. Allow a converter to be passed, but only by means of the second argument being an object. So that d3.tsv(url, callback) would work as normal, but d3.tsv(url, {callback: callback, converter: converter}) and d3.tsv(url, {converter: converter}) would use the converter. This also looks pretty ugly and it's not something I've seen elsewhere as a calling convention.\nIs that a fair summary? I am sure I've missed several options - and certainly any good options - but those are the ones that immediately come to mind.\n. Sorry for the late reply. I'm sure I've missed something, but what advantage does d3.tsv(url, rowFunction, callbackFunction) have over d3.tsv(url, callbackFunction, rowFunction) if the two-argument version is interpreted as d3.tsv(url, callbackFunction) anyway? Is it just that it matches D3 conventions better elsewhere? (I see that d3.xhr does something similar.)\nMaybe something like the below would be useful, although the non-callback case is ugly: d3.tsv.row(f).call(this, url).\n``` javascript\nfunction d3_dsv(delimiter, mimeType, rowFunction) {\n  ...\n  dsv.row = function(f) {\n    return d3_dsv(delimiter, mimeType, f);\n  };\ndsv.parse = function(text, f) {\n    var o;\nf = f || rowFunction;\n\n...\n\n};\n  ...\n}\n```\n. ",
    "ubershmekel": "I think this didn't solve the type conversion I'd like to do though you do mention it here.\nI want to save space and include my csv-like json in my script like so\nvar data = [[\"vegetable\", \"color\", \"amount\"], [\"carrot\", \"orange\", 3]];\nand convert that using d3js to something like\nvar d3data = [{vegetable: \"carrot\", color: \"orange\", amount: 3}];\nI think you'd need to extract a part of this function and name it for my use-case to be handled:\nfunction(row, i) {\n      if (o) return o(row, i - 1);\n      var a = new Function(\"d\", \"return {\" + row.map(function(name, i) {\n        return JSON.stringify(name) + \": d[\" + i + \"]\";\n      }).join(\",\") + \"}\");\n      o = f ? function(row, i) { return f(a(row), i); } : a;\n    }\n. ",
    "kriscarle": "No problem, I was going off your post here: https://groups.google.com/d/msg/d3-js/JyldAkWkTvI/n8thanJeGvAJ \nCan you point me to a working example? No matter what I try get a \"wrong document\" error from jsdom.\nHere is my test code:\nvar jsdom = require(\"jsdom\").jsdom; //had to install jsdom at myproject level for this to work\nglobal.document = jsdom(\"<html><body></body></html>\");\nglobal.d3 = require('d3'); //have to make these globals so the d3 code can find them\nd3.select(\"body\").append(\"div\");//causes error\nError Message:\n``` /home/kris/Documents/dev/myproject/node_modules/d3/node_modules/jsdom/lib/jsdom/level1/core.js:501\n      throw new core.DOMException(WRONG_DOCUMENT_ERR);\n            ^\nError: Wrong document\n    at Object.core.Node.insertBefore (/home/kris/Documents/dev/myproject/node_modules/d3/node_modules/jsdom/lib/jsdom/level1/core.js:501:13)\n``````\n. Thanks! That makes sense and v3.0.5 works for me now. \nI probably have a special use case. I was processing huge SVGs in the browser turning things on/off, changing styles etc. To improve performance I'm moving some of it to the server, rendering PNGs with PhantomJS and overlaying everything in Leaflet but I still want the code to work in both places. \n. ",
    "arunkjn": "I tried using global document object with d3.\nup till d3.select(document).select('body') it works fine but breaks with append giving a wrong document error.\nI am using d3 3.3.4\nUpdate\nI downgraded d3 to 3.0.5 and it seems to be working in node REPL. but if the code is inside a js file, then running it with node gives ReferenceError: d3 is not defined. This is caused at d3.js:1655 name = d3.ns.qualify(name);\n. ",
    "pjanik": "I also ran into this problem while testing our code in node.js. We have to use both jQuery and D3, but the problem is that each creates its own document. Ugly workaround is to create manually window, document and finally include browser versions of libraries.\nTake a look at node-jquery module:\nhttps://github.com/coolaj86/node-jquery#examples\nDefault behaviour of .create() is to create own document, like in D3. However you can pass your own instance too. \nWhat about implementing the same thing in D3? It would be more flexible and perhaps would solve some issues that were mentioned here (e.g. developer could decide whether he wants to keep document global or not).\nLooking at the code in index.js:\njavascript\nmodule.exports = (new Function(\"window\", \"document\",\n  \"return \" + fs.readFileSync(path.join(__dirname, \"d3.js\"), \"utf-8\"))\n)(window, document);\nit seems that the solution can be trivial, the same function that is immediately invoked with predefined window and document can be provided as .create().\n. Unfortunately I haven't done it due to lack of time. However it should be reasonably easy to convert this code into a plugin.\n. ",
    "darwin": "Ok, no worries. I will keep my copy of drag behaviour in my client code.\nMaybe there is a better solution of restructuring SVG DOM and binding the data to lower level, but it is non-trivial in my case. At least I didn't find a solution.\nImagine a complex example of WYSIWYG SVG editor:\nhttp://cmx.io/edit\n\nI have a tree hierarchy of editable objects. Each editable object has a gizmo which may contain multiple bones with drag behaviour as children. Bone data structure is represented by datum which is bound to .marker element. I have a \".mov\" bone which should transform whole subtree of gizmos. I have a \".rot\" bone which should rotate whole subtree of gizmos. Those bones need to be effective on .gizmo.entity to move the whole subtree.\nHow can I modify this code to apply data to @\u0394entityGizmo while giving me data granularity per \".marker\"?\nselection = @\u0394entityGizmo.selectAll(\".marker\")\n    .data(@entityMarkers)\n    .enter()\n      .append(\"g\")\n        .attr(\"class\", (marker) -> \"control marker #{marker.kind}\")\n        .on(\"dblclick\", doubleClick)\n        .call(drag)\n  selection.each(render)\n. ",
    "mcallistera": "This code would help me too.. parent element that can be dragged around by dragging on child element, various other drag handles also within the parent. I don't understand how to implement the suggested solution without removing nesting, which will be a pain.\n. ",
    "ebengtso": "I'm having the same problem, and I have a rectangle with resize handles, which i use to resize my rectangle.\n<g>\n<g id=\"rects\" transform=\"translate(x,y)\"><rect></g>\n<g id=\"handles\" transform=\"translate(x,y)\"><rect id=\"handle1\"><rect id=\"handle2\"></g>\n</g>\nI have added a drag listener on each handle, and then I resize the rects group and apply a transform on both rects and handles to reposition the rectangle and handles.\nIf I change the position of the parent during drag I reproduce the problem, and using the origin does not solve the problem.\nThe only workaround to my problem is removing the group of handles and applying a transform on each of them to reposition each handle\nI applied the same solution proposed by Darwin to the latest version of D3 and it works.\nWould you be kind to reopen this issue?\nThanks\n. ",
    "thesamprice": "Ran into this same issue. D3 now has the container function that cleans up jitter.\n```\n        let dragGroup = d3.select('#parentContainerId')\n        let drag = d3.drag()\n        .on(\"start\", this.PieceDragStarted.bind(this))\n        .on(\"drag\",  this.PieceDrag.bind(this))\n        .on(\"end\",   this.PieceDragEnd.bind(this))\n        .container(dragGroup.node().parentNode)\n         g.call(drag)\n```. ",
    "adambom": "I agree that splitting the individual components out into their own files is a good idea. That way I can just embed the parts I need if I want them. It also makes for a more lightweight app. I ALSO like it because then I everything becomes modular. For example, I can imagine taking the scales module and composing some higher level libraries using it.\nI like the way modernizr does their custom build, making it easy to generate a modernizr.custom.js. I haven't been following jquery that closely but I think they're taking that approach with 2.0.\nI could maybe take a crack at pulling off a refactor. Does anyone else think this is a good idea?\n. ",
    "jomido": "That's great - thanks, Mike.\n. ",
    "kevincarrogan": "My specific use case is that I have a force directed graph using semantic zooming that once zoomed in moving doesn't take into account the zoom level so that the node stills moves the same distance it would had there not been a zoom.\nIs this the correct way of doing this, if so then is it possible to allow force.dragmove to be exposed?\n. I had seen this before but I don't want additional listeners (as it completely overwrites what the dragmove does) and I couldn't easily work out how to replace the force layout's.\nIt seems to replace the force layout's I have to completely override the drag function, but there are other functions in the drag function that I still want to use that aren't exposed so I would end up copying over more internal functions from force layout.\nEssentially I want to do this:\nthis.force.dragmove = function (d) {\n    d.px += (d3.event.dx / self.zoom.scale());\n    d.py += (d3.event.dy / self.zoom.scale());\n    self.force.resume();\n};\nand not have to do this.force.drag = function () { doing a whole lot of setup }\n. Actually, ignore me as I now see I can override the namespaced event.\n. ",
    "karmi": "\nThe way I would do this would be to use selection.attr(\"class\", function) rather than selection.classed.\n\nYes, but then you lose the nice thing about classed(), and that is additive/subtractive behaviour. Effectively, you'd need to process all classes like this in a single attr(\"class\", ..) block -- and that's what I'm trying to solve.\n\n(...) it would need to be selection.classed(function, true) ... and selection.classed(function, false) (...)\n\nI think this could be supported well -- see the added [FIX] commit.\n\nD3\u2019s DOM methods have (...) getter modes (one argument)\n\nTrue, sorry for the omission -- I think this could be supported as well, code in the added [FIX] commit. I can't, however, make it work for functions working with the index (function(d,i) { return 'num-'+i }).\n\nI\u2019m inclined at the moment to not support this functionality for the sake of parsimony and simplicity.\n\nI understand that, I know it's a liability. On the other hand, if the use case described is common enough, I think this would make working with CSS classes more expressive. What should I do with the pull request then, should we close it?\n. ",
    "fanktom": "Thanks @mbostock for your feedback. I renamed the standard deviation from d3.sd to d3.deviation now.\nAdditionally I looked into the variance implementation of Jason Davie\u00b4s science.js. I added an additional exit criteria if an empty array is passed in, but otherwise I think that my implementation is more specific on arrays with undefined, null and NaN. Jason`s returns 0 for every array with a single element only. However, if you look at R it returns NaN in those cases:\n```\n\na = c(NaN)\nvar(a)\n[1] NA\na = c(NaN, NaN)\nvar(a)\n[1] NA\na = c(1)\nvar(a)\n[1] NA\n```\n\nI think our implementation should behave like the R implementation. For that I am returning NaN now for every array with none or one element only.\n. I took a look at the d3.mean implementation. We can't adapt the concept exactly and use only temporary values because the computation of the variance needs the mean of the whole evaluated array in every iteration.\nSo now I create a new array that contains the valid evaluated values of the accessor function and call the variance again with that new array. Could you come up with a faster approach? All undefined and NaN values are ignored, to fit D3\u2019s conventions.\n. Hey mbostock, is there any progress on this issue?\n. Of course, thank you very much!\nYou should have received the signed CLA.\n. @mbostock Is there any progress on this? I'm not sure if I should do something?\n. @mbostock Sorry, you're absolutely right - I don't know what happened back then. ;)\nI now reimplemented the variance to using an online algorithm that was developed by Knuth, 1998.\nIt never allocates additional arrays and evaluates everything in place.\nThe implementation could be shortened in source code by checking for the argument.length in every while run - but I decided to go with performance and do the check only once - hence a little duplication in the while loops.\nI also changed the undefined return values to undefined rather then using NaN as you suggested.\nWhat do you think?\nReferences\nDonald E. Knuth (1998). The Art of Computer Programming, volume 2: Seminumerical Algorithms, 3rd edn., p. 232. Boston: Addison-Wesley.\n. Done, thanks!\nIs there anything else I can do e.g. add it to the documentation?\n. Alright, very good  - thanks!\n. ",
    "parkr": "@mbostock Would love to see this :+1: \n. ",
    "lzilioli": "@mbostock ++\n. ",
    "carlsverre": "Throwing in my hat as well!\n. If you do that, the mousewheel event won't fire on the document.\n. After playing with it, your solution is possible.  Thanks for pointing it out.  The only thing I am a little bummed about now is not having access to d3_behavior_zoomWheel.\n. ",
    "d0coat01": "This will be a great addition\n. ",
    "elioscordo": "Yes please!\n. ",
    "yang": "+1\n. ",
    "pkpp1233": "+1\n. ",
    "gwalter": "This would be very handy\n+1\n. ",
    "zpydee": "@mbostock can you indicate a timeline for the release of this functionality?\n. ",
    "daetal-us": "++\n. ",
    "lgrkvst": "Hi,\nI've tested your cornerRadius implementation and it works really good - sleek corners! Thank you for doing this.\nThe oddest little caveat though - I can't seem to do this:\nvar d3hull = d3.geom.hull();\nThis throws the following:\nUncaught TypeError: Cannot read property 'length' of undefined d3.min.bm-w.cornerradius.js:4\nzi.geom.hull d3.min.bm-w.cornerradius.js:4\n(anonymous function) force_with_labels.js:18\nI'm not entiry sure, but it points towards d3.min.bm-w.cornerradius.js as it all works when I change to the \"normal\" d3.v3.min.js.\nIt should be easy to reproduce, otherwise, I'm doing something wrong on my end.\nKeep up the good work!\nBest regards,\nChristian\n. Seconded! :>\n. ",
    "ruphin": "Hi,\nThis pull request adds a useful feature to D3 Arcs. We are currently using the latest version of D3 with these changes added on top, and haven't encountered any issues. Perhaps someone can take a look at this pull request, it would be nice to have it merged so we can use the main release of D3 again.\nWith kind regards,\nGoffert\n. ",
    "chrisvfritz": "This has been very useful in my projects as well and I also have not encountered any issues.\n. :tada: !\n. @mbostock Isn't this a superset of (i.e. improvement over) the existing tree layout?\n. ",
    "terite": ":+1:\n. ",
    "bm-w": "@mbostock Signed. Note that this PR is fairly old. I currently haven't got the time to update, but I'm sure the signature leaves anyone else who is interested free to do so (@o-o-, @ruphin, @chrisvfritz, @terite?).\n. ",
    "vicapow": "To those that come across this post, replace keys with values in @mbostock's example. see: https://github.com/mbostock/d3/wiki/Arrays#wiki-d3_set for more info\ndiff\n- d3.set([\"foo\", \"bar\", \"foo\"]).keys(); // \"foo\", \"bar\"\n+ d3.set([\"foo\", \"bar\", \"foo\"]).values(); // \"foo\", \"bar\"\n. ",
    "blq": "I agree with @jasondavies \"is it a good idea to import ../svg/line?\" I too think it should be moved to a core file.\nNo need to depend on graphics for a datastructure like this.\n. Great! I think the ability to be able to completely separate graph-algorithms from graphics rendering is important. \nThanks.\n. ",
    "iterion": "Fine by me :)\n. thanks for the suggestion - much clearer/cleaner now\n. ",
    "shakiba": "I have the same issue on android.\n. @AndruByrne thanks!\n. ",
    "AndruByrne": "my solution is an open pull request right now. you can grab my working\nd3.js on github/andrubyrneif you need that functionality stat.best-dru\nOn May 9, 2013 4:14 AM, \"Ali Shakiba\" notifications@github.com wrote:\n\nI have the same issue on android.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/mbostock/d3/pull/1169#issuecomment-17659340\n.\n. Depends on how much you like using the sqrt function, but yes. So what\nsupplication is left to us? It's not a pleasant bug, and Androids have\ngained some popularity.\nOn May 10, 2013 6:20 AM, \"Sander Dijkhuis\" notifications@github.com wrote:\nFor reference: #984 https://github.com/mbostock/d3/issues/984 seems to\nbe a similar solution.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/mbostock/d3/pull/1169#issuecomment-17719550\n.\n. Why are there now two proposed fixes for this that use practically twice as\nmuch computing power as they need to? The sqrt function is not addition or\nmodulo, it's trigonometry that only needs to be analyzed once. It's\npuzzling that the js community is so prone to sloppy code given the\nexposure to low powered devices; each Joule matters, you know, and laziness\nhere will hard-wire crappy responsiveness in the library. Please take the\ntime to rewrite your fix Jason, the way I did it was not that much\ndifferent from yours.\n\nBest\n-dru\nOn Jun 7, 2013 2:12 PM, \"Jason Davies\" notifications@github.com wrote:\n\nThanks for this! I implemented a similar fix in #1298https://github.com/mbostock/d3/issues/1298,\nhopefully it\u2019ll make it in an upcoming release.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/mbostock/d3/pull/1169#issuecomment-19133200\n.\n. Thank you so much; I was dreading the fork, but I am that persnickety =]\n\nbest!\nOn Jun 7, 2013 5:40 PM, \"Jason Davies\" notifications@github.com wrote:\n\nI\u2019ve adjusted the fix slightly now to use one sqrt call instead of two.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/mbostock/d3/pull/1169#issuecomment-19140027\n.\n. \n",
    "mila76": "months and months and i have to add manually this patch every new build\ni can't understand why\nsome evil apple design? :D\n. ",
    "jisaacks": "@mbostock I appreciate your response but I don't see how that is possible. I am trying to allow the user to drag the extent beyond the range. I know I can programmatically set the extent to anything. But the brush event is triggered by the user dragging the extent, and the user is not allowed to drag the extent beyond the range. so I do not know how listening to the brush event would help.\nCan you please elaborate or pointing me to an example would be great. Thanks :)\n. So I was able to produce the desired behavior without altering D3 if I gave the brush its own x-scale/domain separate from the main focus and added padding to it. When the brush's domain exceeds the main focus, it can be dragged past the main focus. I have to then recalculate the brushes special domain every time it is resized.\n. That sounds good. I can add 2 methods to the brush, something like brush.xLimitToRange() and brush.yLimitToRange() each would except a single boolean value and default to true.\nI'll work on that.\n. @mbostock yes that does sound much better! I will do that.\n. @mbostock I made the changes we talked about, let me know if anything else needs to be tweaked. Thanks.\n. @mbostock I squashed the commits so it wouldn't muddy up your repo with the original 4 settings stuff that we decided against.\n. It is a bit clever, but I think more readable than a ternary within a ternary would be:\njavascript\nreturn x && y ? clamp : clamp[x ? 0 : 1];\nI will make those changes.\n. @mbostock I made those changes, I also updated the tests as well.\n. @mbostock was there anything else that needed changed?\n. I added that because I thought it didn't make sense to allow resizing beyond the range, but maybe that just make sense in my particular use case and not the general use case. I will remove it then.\n. Yep.\n. ",
    "tillberg": "Good suggestion.  In my new commit (force-pushed over the old one), I rewrote the fix with a new d3_eventSuppress function.  Not sure how \"core\" this sort of function is, or if maybe there's a better way to consolidate.\nI like how clean the existing behavior/event source is, and it's tempting to suggest that maybe this click suppression shouldn't be there at all, lest it get overrun by browser and edge case fixes.\nFor reference, the original fix was appneta@6560b3bffca1cb6a398c126e35c5c9f50b7f0759\n. ",
    "danmilon": "Right, index-browserify.js worked like a charm. I updated the PR.\nOn a side note, any idea how we can prevent the global variable?\n``` javascript\nrequire(\"./d3\");\nmodule.exports = d3;\nif (typeof window !== 'undefined') {\n  delete window.d3;\n}\n```\nmaybe?\n. I believe there's no guarantee that browserify, component or node will always set this to the global scope. (or else, not alter it).\n. Indeed, wrapping it in a function should do it. Should I add a commit?\n. done.\n. gah, sorry about that. BTW, I took the liberty and added mbostock/d3 in the component registry. and @visionmedia removed component/d3.\n```\n$ component search d3\nmbostock/d3\n  url: https://github.com/mbostock/d3\n  desc: \n  \u2605 13941\n```\n. ",
    "clkao": "@jasondavies, thanks for the notes.  PR updated accordingly.\n. ",
    "techjacker": "I'm still encountering this problem even though I'm using the latest code. Maybe I'm just not applying the patch correctly?\nI've tried both of the following:\nJavaScript\nd[year] = d3.time.format.utc(\"%Y\").parse(d[year] + \"\");\nd[year] = new Date(d[year], 0);\nI've also tried creating the scales manually with:\nJavaScript\nvar minMax = d3.extent(d, function(data) {return data[year];})\nd[year] = d3.time.year.utc.range(minMax, step);\nThen later I plug it in using:\nJavaScript\nvar x = d3.time.scale().range([0, graphWidth]).domain(minMax);\nBut I'm still getting 1ams in firefox for 1965 + 1970 in the UK. Where am I going wrong?\n. Thanks for the quick response.\nOkay obviously I got the wrong end of the stick re the patch.\nSorry for being dim but what's the simple fix you recommend for displaying the year and not 1am on the axis?\nIt is a weird bug for ff to have, but then again javascript dates always seem to be able come up with new and interesting ways of frustrating me.\n. Ah I see now it's working perfectly with your patch.\nIs this the best version to use? I tried a few of the previous iterations which also worked.\nIf so I'll create a fork based on this and post the link here.\n. Great stuff, thanks, I'm using that branch now.\n. Great, thanks very much for merging in master.\nI'm using component for package management so I'll be kept up to date with that branch if you make any more changes.\n. ",
    "scottcheng": "Good point about naming. I've changed it to invertExtent.\nI cannot agree with you on using d3.bisect, though, because the range may be unsorted. I am now using d3_Map, which I think could marginally improve performance. Also, after reading the source of d3.scale.ordinal, I am not sure what you mean by it requiring \"mapping the range value to a string\".\n. I see; thanks for the explanation.\nOh I definitely didn't think about whether the range values have to be coercible to strings (sorry). I like using indexOf here, because it won't create any overhead for the quantize scales that never use invertExtent.\nThere is another problem: if the range contains duplicate values (e.g. quantize().range([1, 2, 1])), the \"invert extent\" may be noncontinuous, and more complicated return values will be needed. Such cases should be rare, though. Do you think we should support them?\n. Cool. That's exactly how it works now.\n. Actually I did consider this, and I mentioned in the above documentation that the function behavior is undefined in such cases. Returning null is definitely a better solution. I'll add that tomorrow.\nSent from my iPad\nOn Apr 18, 2013, at 1:20, Mike Bostock notifications@github.com wrote:\n\nOne thing missing I see is when the input value is outside the range. In this case, the invertExtent should probably return null (since we can\u2019t make any assumptions about the input).\n\u2014\nReply to this email directly or view it on GitHub.\n. @GerHobbelt First of all, what you are proposing here does not conflict with this pull request.\n\nSecond, I see where you are going with the universal scale.invert, and I think it will be useful for many types of scales. But in this particular case of scale.quantize, I think mapping a y in the range to an arbitrary x in the domain (start point of extent, mid point, etc) so that quantize(x) === y is true makes more sense in terms of mathematics than practicality. Sure that's how it aligns with all the other non-quantize scales, but I just can't think of a scenario where I'd be using such mapping. As for invertExtent, I suggested a use case when I first posted this pull request, and I am actually using it in my project.\nAgain I am not arguing that invertExtent is better than invert, since this is not a one-or-the-other question.\n. > You described the usage by giving an example of arguments and corresponding return values, but I don\u2019t consider a use case because you haven\u2019t explained how the method might be used this in a \u201creal-world\u201d example.\nI believe you are referring to the \"Usage Example\" I gave, while I'm actually talking about the \"Use Case Scenario\" at the beginning: (Sorry for the confusion here)\n\nIn a visualization, I am using a quantize scale to map a period of time into several segments. The scale gets a Date object, and outputs which segment the date belongs to. Now I want to visually mark the time segments, therefore I have to know when each of the time segments start and end.\n\nAnd the start and end of the time segments will be provided by this invertExtent method. Sure there are other ways around, but I think this is the most direct solution which should be provided.\n. Well returning the domain values surely solves the problem, but in a less direct way (at least for my use case and the likes).\nWhat threshold (or quantile.quantiles) does is it maps the index of a range value to a corresponding threshold in the domain. If I am looking for what invertExtent provides here, I'd need to:\n1. Find out the index of the range value, with something like scale.range().indexOf(y),\n2. Map it to the threshold, and\n3. Convert threshold to an extent.\nStep 2 and 3 is like what you did in the threshold example: \njavascript\nx0: i ? x(threshold.domain()[i - 1]) : x.range()[0],\nx1: i < 4 ? x(threshold.domain()[i]) : x.range()[1],\nIn all, I think this method is evidently less developer-friendly than invertExtent. I'm even thinking about adding invertExtent to quantile and threshold scales.\n. Sorry for the wait... I put together a simple example here: http://bl.ocks.org/scottcheng/5553839\n. ",
    "mcandre": "@mbostock ./node_modules/.bin/vows fails in Cygwin as well as Command Prompt.\n. Actually, dot slashing is provided in Cygwin through bash, but when npm runs scripts, it reverts to cmd, and loses dot slash support.\nPlease reconsider this minor tweak for greater Windows support. It's not my favorite OS, either, but it's amazing when software works in multiple platforms, and sometimes all it takes is a little tweak.\n. ",
    "aprilrd": "Got it. \nI found an example https://groups.google.com/forum/#!msg/d3-js/JyldAkWkTvI/rLUuF22_wW4J where it looked like window object should be accessible outside. But I guess the API has changed since then. Thanks for the quick response.\n. ",
    "fabriciotav": "That's even better than having a bunch of methods for predefined delimiters . I mean, for the common case, you're served.\n. ",
    "sammyt": "That makes total sense, I'll have a think about alternative solutions.  Thanks for getting back to me so quickly.\n. perhaps this change would make more sense?\nIn the above commit I've added a new build specific to node.js.  It adds a little build time overhead but avoids the performance penalty for the common case.\n. no worries, I'm always happy to go back to the drawing board.  The load.js approach is interesting, though it would seem to duplicate a lot of what the build process already does to get a fully fledged d3 out of it.\nI'll give it more thought.\n. That is a really nice solution Nick!\n. Would need to remember to pass in the window object when d3 self invokes.\njavascript\n// src/end.js\n return d3;\n})(window);\n. the same thing could be achieved with a named function expression.  I've put together this branch to demonstrate.\nThe NFE approach (or arguments.callee) provides everything the original pull request does, but without the overhead of the function wrapper.\n. updated this pull request to reflect the NFE approach.\n. I've updated the bin/start script to generate the src/start.js (hadn't spotted that).  \nI tried to pass in the window object through src/end.js but it caused the tests to fail.  I'm guessing a little here but I think it might be because some of the tests run within a sandbox that doesn't contains a document property.  I've added a conditional check to see if d3_window is defined and fallen back to window instead. Is that OK? I could try and fix the tests that break when adding window to end.js if you prefer? :)\n. Splendid stuff, I see what the test harness is doing now. Thank you. \n. Yeah I'm also in the position where the inclusion of jsdom as a dependency, and the creation of the default window is unnecessary.  \nMy aim with this pull request was to add the environments concept without breaking anything that currently depends on that default window.\n\nquery and process long and deeply nested XML documents; D3 is very useful in this context\n\nvery cool.\n. ",
    "nicko": "Hi could you use the arguments.callee property of the constructor function and assign it to the var d3 object created on line 2? For example:\nd3 = function(win) {\n  var d3 = {\n    version: \"3.1.7\",\n    env: arguments.callee\n  };\n  if (!Date.now) Date.now = function() {\n    return +new Date();\n  };\n  var d3_window = win || window, d3_document = d3_window.document;\n. ",
    "moshbitten": "Re component.json, from https://github.com/bower/bower:\n\nNOTE: In versions of Bower before 0.9.0 the package metadata file was called component.json rather than bower.json. This has changed to avoid a name clash with another tool. You can still use component.json for now but it is deprecated and the automatic fallback is likely to be removed in an upcoming release.\n\nRe the version number, my apologies. Not only did I somehow manage to get the version number wrong but didn't even notice the Makefile target. Fixed.\nNo worries if you'd prefer not to merge. Ran across a deprecation warning while adding d3 to a Yeoman project of mine and just wanted to chip in, based on your comment to https://github.com/mbostock/d3/issues/1224\n. ",
    "KimGressens": "I'm installing D3 via bower, so I assume the component.json is for Bower.\n. ",
    "necolas": "The current component.json looks like it was intended for use with Component(1) due to the presence of the scripts property.\nBower doesn't need a manifest file in a repo in order for people to install it. However, including one means that you can specify the main file in the main prop (useful for builds tools) and use the ignore prop to avoid the installation of all the stuff people don't need (bin, test, etc)\u2026making for a much cleaner installation.\nIn a future version of Bower, you'll be able to publish built assets directly to the registry instead (like npm).\n. ",
    "shilad": "My motivation for enter().call(foo) sounds similar to #824. I want to create reusable d3 SVG components. foo immediately appends a \"g\" to the selections and creates the component.\nI can get around this using enter().append(\"g\").call(foo), but it seems right to let foo append its container.\n. ",
    "mdintgrp": "Are you going to add Puerto Rico back into the AlbersUSA projection? \nI was using the projection for a project and the latest update made the poor little island disappear.\n. ",
    "nani3105": "I am new to d3 - geo.\nI to display PR and VIR (Virgin Islands) into the Us map. For this i copied the d3.geo.albersUsa code and for the PR projection i used \nd3.geo.conicEqualArea().rotate([66, 0]).center([0, 18]).parallels([18, 18])\nAs the 18 and 18 is recommended for PR and VIR. (spatial reference) .\nHowever this projection is not working for me as the PR and VIR geoJson point are out of bounds\nHow do i set the clipExtent and also i want to move PR and VIR bellow texas/lousiana. How do i figure out the proper translations. \nhttps://jsbin.com/mubetajere/3/edit?js,console\n. Thanks i will post this question in stackoverflow\n. ",
    "christophe-g": "Thanks a lot for the answer and comments (I'll take them into account and push them to the branch on krikrou). \nI understand the doubts re usefulness of this method. I was looking for a way to shape the structure of the nested data according to a data model imposed by another lib (e.g. a config object for a tree that needed to have id, text and children properties). There is a couple of similar request in d3 groups - but I could not find my way with nest.rollup as :\n- it acts on the value array only\n- the function to be called might not be the same for each key (or depth of the nest). \nAs per post-processing entries after they are computed, I am not a big fan of this approach in the case of deeply nested structure. \nAnyway, I still hope the weight of this new method is not too high to be incorporated - othewise, that's just a sheer pleasure to use this lib !\nCheers \nC.\n. Yep, that makes perfect sense\n. Right, I was not so sure what to include for the scope of this function. \n. ",
    "mrcarlosrendon": "Does the call have to be synchronous for this to occur? onload for the XMLHttpRequest is getting scheduled before response() erratically on IE9 in standards mode. In my code base, I could get it to happen about 40% of the time.\nBasically what happens is I call\n\nd3.json(\"somejson.json\", doSomethingWithJSON);\n\ndoSomethingWithJSON(error, data) gets called with the data set to the XMLHttpRequest.  Afterwards, response(d3_json) is called.\nSo the call chain looks like\nd3.json(\"somejson.json\", doSomethingWithJSON)\nd3.xhr(\"somejson.json\", \"application/json\", doSomethingWithJSON)\nd3.xhr.get(doSomethingWithJSON)\nd3.xhr.send(\"get\", doSomethingWithJSON);\nd3.xhr.respond()\ndoSomethingWithJSON(, XMLHttpRequest) <- instead of doSomethingWithJSON(, JSON object)\nd3.xhr.response(d3_json)\n. Sorry, the previous set of commits were a WIP and I ran out of steam before getting d3.xml and d3.text working. Should have left a message about that. On the other hand your comments were very helpful for coming up with an approach.\nAll unit tests are passing now and I think the method overloading should be working properly as well.\n. ",
    "factormystic": ":+1: this is neat. I hate concatenating transform strings by hand.\n. :clap: :+1: \n. ",
    "trinary": "Same here. The extension seems to have been well received, but making a separate build or adding another script tag is bothersome. I'd love some more feedback on the interface or implementation itself.\n. It could, and my initial implementation went for that approach and worked, but needed further work to function in transitions. @seliopou pointed out here that the order-dependent nature of transforms doesn't conform to either the aggregate (style) or \"last-wins\" (on) behavior of the other selection methods. Having it as its own object is less intrusive, but allows for easier composition and re-use. There was some vigorous debate about how to implement it, and we went with a separate object. I like how it turned out. :smile: \n. ",
    "samselikoff": "I feel like I'm missing something, couldn't this be\njs\nvar svg = d3.select(\"body\").append(\"svg\")\n    .attr(\"width\", width + margin.left + margin.right)\n    .attr(\"height\", height + margin.top + margin.bottom)\n  .append(\"g\")\n    .translate(margin.left, margin.top);  // .translate() is a method on selections, like .style()\n. ",
    "dexygen": "A year and a half later and this still hasn't been merged.  I'm a complete newbie to d3 and it's enough of an uphill climb without the error-prone string concatenations to the point where I am tempted to put my arguments into an array and do the concatenation in one fell swoop with join.  To be clear the following is a method on a custom \"ChartHelper\" object/module I'm using.\ntranslate: function() {\n    return \" translate(\" + $.makeArray(arguments).join(\",\") + \")\";\n}\n. ",
    "mgold": "Turning an array to a string includes the comma but not the brackets. You still need makeArray but not join. Alternatively, throw this in your code:\njs\nd3.selection.prototype.translate = function(a, b) {\n  return arguments.length == 1\n      ? this.attr(\"transform\", \"translate(\" + a + \")\")\n      : this.attr(\"transform\", \"translate(\" + a + \",\" + b + \")\")\n};\nNow you can call anySelection.translate(anX, aY) or anySelection.translate([anX, aY]) with method chaining. Caveats: Does not get the value with 0 arguments, does not accept a function, clobbers any other SVG transforms you may have. So it's definitely not PR-worthy but can help you out if you know what you're doing.\nSee also: d3.transform, which returns a normal object and not the standard method-chainable closure, and trinary/d3-transform, a third-party library which does exactly that, but is IMHO a little too heavyweight for just translate (hence my prototype addition). Arguably, trinary's library should replace the current d3.transform in 4.0.\n. +1\n. Any chance this can make it into 3.5? Otherwise just say you don't want it and close.\n. ua = ua || 1 is a few characters shorter.\n. +1 Minor but correct.\n. What are you trying to gain by !!map? Objects are always truthy, and in fact there is no trivial way to determine if an object is empty.\n. Thanks for the explanation.\n. ",
    "kosiakk": "Oh, it seems to be a hot topic! Although my implementation might be not the most elegant among available, I'll comment about motivation behind the request:\nI want to animate transition between two external SVGs (graphviz layouts).\nTo do so, I load SVG XML, use it as data and call recursive Clone function, which navigates through XML layers and re-creates it in the current document. Therefore, for each level I do something like var selection = selectAll(\" * \").data( targetDOM, matchByIdFunct );\nselection.enter().append( fucnction(d){ return d.nodeName } ); // datum is a DOM element from another document\nselection.exit()....\n. ",
    "notlion": "Added another commit with the points pre-allocated.\n. Sure thing. Suppose I'll add a links section here?\n. ",
    "ramprasathzi": "hi please help below concept \nhttp://stackoverflow.com/questions/19271430/rotate-and-resize-the-image-view-with-single-finger-in-android\nmy email address kbramprasath@gmail.com\n. ",
    "tgabi333": "+1\n. ",
    "medihack": "+1\n. ",
    "jrideout": "@mbostock What is the current state of this PR and the related issues? Is there still a problem here to be addressed or are you satisfied with the current state of things?\n/cc @matthull\n. @Yahasana Do you have some benchmarks that show this speeds up rendering in practice?\n. > In general, I prefer to use arguments.length checking because it\u2019s more obvious what is going to happen: you know statically how the code will behave (outside of function.apply, of course).\nAgreed that this is to be prefered. But in this case, I'm actually trying to hack the case where there are two arguments, and ignore the second argument when it isn't a function. This happens the functions is called with a signature like function(d,i) In that case we don't want to consider i to be an accessor. Would the alternative be something like this:\nif (arguments.length === 1)\n  doNoAccessor stuff\nelse if (typeof f === 'function')\n  doAccessor stuff\nelse \n  ???\n\nBut I expect this isn\u2019t the only place where you\u2019d need to patch some changes for easier higher-order programming.\n\nYeah - there are a number of others. I only had direct use cases for min/max in my project though. I'd be happy to look through the d3 codebase if would prefer I make a broader set changes, or at least take the same approach to all the applicable arrays/* functions.\n. In arrays, the additional three functions that could be modified with this approach are extent, median and sum.\nI'll try to see if there is any utility in doing so.\n. ",
    "ratbeard": "+1, this patch has been really helpful for us.\n. ",
    "emepyc": "+1\n. @tommct I haven't looked much into it but seems that there are bugs in your implementation (see the screenshot attached). I think they are related with the \"zoom by rectangle\" thing (not the panning/zomming limits) though.\n\n. Has anyone been able to merge current src/behavior/zoom.js in the PR code?\nI'm having problems trying to do it\n. ",
    "eigenhombre": "+1\n. ",
    "rberner": "+1\n. ",
    "tommct": "I have implemented the following workaround: http://bl.ocks.org/tommct/5671250.\n. Thanks for the report. While it was not in the \"zoom by rectangle\" code, the bug was only ever exposed when using that function. I've fixed it.\n. ",
    "jonathanpullano": "@emepyc: Were you able to resolve those problems? This patch may be useful to me too.\n. ",
    "staticfloat": "Just chiming in here that I'd love to see this kind of thing in mainline D3.  I would use the version of d3 shown in this PR, but unfortunately it's too old for me now.  ;)\n. ",
    "garrilla": "I don't know if this helps anyone - but I rolled my own, here's a block but should be easily reusable\n. where are we up to with this?\nthe current version on the meteor packagaing system is at 3.5.5, while the offcial repo has advanced to 3.5.8\n. ",
    "behr328": "\"Just chiming in here that I'd love to see this kind of thing in mainline D3. I would use the version of d3 shown in this PR, but unfortunately it's too old for me now. ;)\"\nAgreed, I've tried merging these extent features with the most recent version of d3 to no success. These options should be available in the main version.\n. You guys might want to check out the latest changes @lebolo has made in https://github.com/mbostock/d3/pull/2019. He's merged these changes in the latest version of d3!\n. +1 @lebolo \nI've been trying to merge these changes myself for quite some time. Couldn't quite get it so I stuck @mhsmith's version for a while. Would be great to see these in the main d3.\n. Just smashed together these changes and included it in the app I've been building. So far so good, doesn't seem to have broken anything :D\n. +1\n. ",
    "yorlov": "+1, this patch\n. ",
    "bigsley": "What if you ask for d3.time.months with a step of 5? Does it make sense to return January, June, and November? Then you will be returning two months (November and January) which are 2 months apart. How is the current behavior desirable? How does it make sense to return a set of dates that are not evenly distributed?\nAlso, your explanation that I should use years instead doesn't make sense. How do I display every 15 months, using years?\nI think that a more reasonable way to define the API for range would be to include an (optional) anchor point. This would be strictly more generic than what is currently implemented, and would not result in unexpected behavior (non-uniformly distributed dates).\n. What about weeks? Divisors of 52? I understand the backwards compatibility argument, but as I've said, the behavior that I'm suggesting is strictly more generic. I can't tell whether you think this is true, or whether the changes I'm suggesting are valuable.\nThe real-life situation we're encountering is this (and I don't believe this can be a very uncommon scenario) - We are allowing our users to select a range of dates, and subdividing those dates evenly into a date type they select (weeks, months, quarters, or years). Then we need to reduce the # of labelled ticks. E.g. suppose they want 100 weeks - we need to be able to subdivide that into (say) 10 major ticks (labelled with dates) with 9 minor ticks in between each. This way we will want to have ticks evenly distributed along the axis over a long time period.\nI agree that it makes sense to just use a filter, but then why have these functions built into d3 at all? Or why accept values that will provide weird behavior? I don't think that these functions follow the principle of least surprise...\n. OK, I think your answers make a lot of sense. Thanks for being patient with me! \nDo you think there's some way we can make it so that people will be less confused about this, in the future? Documentation? Comments? Complaining when the # of intervals to be skipped (dt) is greater than the maximum value number can output (I guess that's actually hard to test)? I just ask because I ended up spending a lot of time on this - I expected the function to output uniformly distributed dates, but it did not do this out of the box. \n. Sounds great! I'd definitely like to expand the documentation some.\nI'll take a look at using d3.scale.linear, as you mention, but in our\nexperiments it doesn't look like having slightly irregular intervals causes\nnoticeable visual distortion (which is the main thing we're concerned with).\nThanks again :)\nOn Tue, Jun 11, 2013 at 5:33 PM, Mike Bostock notifications@github.comwrote:\n\nDocumentation is a great place to start. The documentation for\ninterval.rangehttps://github.com/mbostock/d3/wiki/Time-Intervals#wiki-interval_rangeis quite terse at the moment. If you have some time and willingness, it\u2019d\nbe great if you could expand the documentation to include more examples of\nthe current behavior, including examples of post-filtering for the use\ncases you had in mind.\nE.g. suppose they want 100 weeks - we need to be able to subdivide that\ninto (say) 10 major ticks (labelled with dates) with 9 minor ticks in\nbetween each.\nActually, you might not want to use a d3.time.scale and time intervals\nhere at all. Weeks are variable length\u2014for example with daylight savings\ntime, weeks can be 167, 168 or 169 hours long. Using d3.time.scale when you\nare aggregating by week can cause your weeks to be displayed at\ncorresponding irregular intervals. If you had a major tick at every 10\nweeks, 10 weeks is likewise a (slightly) irregular interval and the 9 minor\nticks would also not be uniformly-spaced. You usually want d3.time.scale\nonly for precise display of continuous time, not discrete calendar\nunits.\nIt might make more sense for you to use the simpler d3.scale.linear,\nencoding week numbers rather than dates. (Or perhaps d3.scale.ordinal with\nrangeBands.) This way you would display weeks at exact regular intervals,\nignoring irregularity, and use the generic tick algorithm for linear scales\nto determine which weeks to show.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/mbostock/d3/pull/1310#issuecomment-19301102\n.\n\n\nChris Bisignani\nEngineering | Addepar http://www.addepar.com\n(617) 981-3140\n. ",
    "slessans": "Was this ever wrapped up in a plugin?\n. ",
    "vanquang9387": "I really need this feature. Will this be integrated?\n. ",
    "ashclarke": "I am getting this referring to the window on L4314 of fdd6c62, so a = coordinates[0] and b = coordinates[coordinates.length - 1] on L4345 are undefined.\nMy code looks like this:\n```\nvoronoiData = _.map(data, function (data) {\n    return [x(data.date), y(data.price) + Math.random() - .5];\n});\nsourcesVoronoi = d3.geom.voronoi(voronoiData)\n    .map(bounds.clip) // Error call stack from d3_geom_polygonClosed() originates here.\n    .map(function (data, i) {\n        data.path = \"M\" + data.join(\"L\") + \"Z\";\n    data.data = data[i];\n\n    return data;\n});\n\nsourcesContainer\n    .append(\"g\")\n        .attr(\"class\", \"g-overlay\")\n        .selectAll(\".voronoi\")\n        .data(sourcesVoronoi)\n            .enter()\n                .append(\"path\")\n                .attr(\"d\", function (data) {\n                    return data.path;\n                });\n```\nAny ideas why this is the window?\nEdit: bounds are [[0,0],[0,1107],[2150,1107],[2150,0]]\n. Thanks for the tips!\n. ",
    "jaredly": "Sure thing\n. How does that look?\n. It does need (or at least prefer) the browserified version.\n. ",
    "danse": "I think this is definitively a good idea. About the interface, the most natural way for me would be something like:\naxis.ticks(d3.weeks, d3.days);\nOr into an array. I think that the concept of ticks should not be restricted, on the long term, to just major and minor ones, but allow arbitrary levels of ticks. The current interface allows a counter after the function, this is handy but not flexible. I think that counting could go inside the ticker function for a given level, d3's general approach is to pass functions and it works greatly! This applies also to scale.ticks.\nDoesn't matters if it goes to 4.0, if the interface design is improved. Also tickValues could accept more than one argument, following the same idea.\nWell, also an ordinal scale could generate ticks, but just it has not flexibility in the way these could be generated. I'm not so confident about ordinal scales, i wonder if i ever used them, but i hope i got the idea right. A crazy but yet possible application, would be to apply a regular expression to the scale values, and draw lines on a chart corresponding to a matching pattern.\nI think the concept of ticks is deeply related to that of scales, maybe the step that we are lacking is a functional representation of tick picking, that could apply also to ordinal scales. At the end, it will be something similar to the filter function you use for post selection, but with a cascading (or hierarchical, call it like you want) application rule.\n. Well, now that i understand better the idea about d3's encapsulation and representational transparency, i agree that post selection is quite concise, flexible, and adheres to the interface concept.\n. ",
    "tracycollins": "Hello,\nI found this thread while trying find a solution to avoid javascript garbage collection on a dynamic force directed graph. I have a graph where nodes \"age out\" and are removed from the graph, and new nodes are created dynamically from streaming data.\nI think using a pool of DOM objects (i.e., pool of circles) that are reused on append and recycled on remove is the way to go.  To implement this, I think I'd need to use a function in the append and remove statements that pull elements from the pool on append and recycle to the pool on remove, right?\nIf anyone can point me to implementation examples, that would be great.\nThanks\np.s. Awesome library!. ",
    "scameron": "Works great for my case.  Now all my transitions are friends and everybody appears to be getting along beautifully. Thanks for the quick fix!\n. ",
    "wahlatlas": "Yup, this works, thanks!\n. Mike, in your russian example you have\nthousands: \" \"\nI prefer \"&nbsp;\" for that because of text wrapping but get issues for tickValues as they don't seem to use innerHTML but Text\n. Here's how it works\ne.g. for spanish\nvar ES = d3.locale({\ndecimal: \",\",\nthousands: \".\",\ngrouping: [3],\ncurrency: [\"\", \" \u20ac\"],\ndateTime: \"%A, %e de %B de %Y, %X\",\ndate: \"%d/%m/%Y\",\ntime: \"%H:%M:%S\",\nperiods: [\"AM\", \"PM\"],\ndays: [\"domingo\", \"lunes\", \"martes\", \"mi\u00e9rcoles\", \"jueves\", \"viernes\",\n\"s\u00e1bado\"],\nshortDays: [\"dom\", \"lun\", \"mar\", \"mi\u00e9\", \"jue\", \"vie\", \"s\u00e1b\"],\nmonths: [\"enero\", \"febrero\", \"marzo\", \"abril\", \"mayo\", \"junio\",\n\"julio\", \"agosto\", \"septiembre\", \"octubre\", \"noviembre\", \"diciembre\"],\nshortMonths: [\"ene\", \"feb\", \"mar\", \"abr\", \"may\", \"jun\", \"jul\", \"ago\",\n\"sep\", \"oct\", \"nov\", \"dic\"]\n});\nvar thsd = ES.numberFormat(\"n\");\nthsd(10000);  // 10.000\nsee here for options\nhttps://github.com/mbostock/d3/wiki/Localization\nsee it in action here\nhttps://www.destatis.de/bevoelkerungspyramide/\n. ",
    "timmywil": "Every version, including the one in d3's lib folder two years ago that went along with that commit. Unfortunately, Sizzle hasn't always been versioned, but has had the intention of sorting in document order since version 1.0\n. You can probably punt that to Sizzle. I can't imagine it was broken for long or John would have fixed it in subsequent releases.\n. Did some tests with the latest Sizzle selecting both SVG and other elements and checked all browsers just to be sure: http://jsbin.com/ojedat/2/\nI see a discrepancy in IE8, but that's only that the QSA path doesn't find SVG (IE8 QSA bug) and doesn't actually have to do with sorting. IE6 is fine.\nPrevious releases of Sizzle probably had some edge case bugs in its document sorting, but I don't think that is for d3 to fix.\n. ",
    "tschaub": "Let me know if you think this should be handled in a different way.  I tried a few different approaches, and this felt like the least invasive change.  Also didn't find a similar test to crib from.  Please point me in the right direction if there are tests of similar behavior.\n. Thanks for the update @mbostock.\n. ",
    "leodutra": "Nice. I'll explore more the d3 and send more relevant optimizations.\nThere's always something to polish.\nI really like your creation. \n. I edited online on GitHub. As I could not edit the 1423... \nGitHub generated 2 patches when I saved.\n. As I worked with simple pieces, I downloaded the last version and debugged on Google Chrome tools.\nThe problem is when a function is being used in many forms, as that min and max functions from the \"array module\" (a >= b comparison for Date objects equality test).\n. Right, since it's a generic function.\n. It's a nice opinion.\n. Ok.\n. Was a common optimization on IE. I think we can pass.\n@mbostock is smart about d3. I congratulate your holistic.\n. Right.\n. ",
    "couchand": "Here is my input.  It looks so innocent!\nhttps://gist.github.com/couchand/6415625\n. Now I see that there are two coincident points there.  What's the best practice for filtering those?\n. ",
    "marcuskrahl": "Here is an example of the issue: http://jsbin.com/EVugukU/2/edit\nIt is pretty much the default bar chart example, with a slightly different format function (d3.format(\"d\") to only display integer ticks). So the issue might be there. There is no problem when I change the format function to something like d3.format(\".0%\")\n. I started using d3 only two weeks ago so my knowledge about it is very limited. What I wanted to accomplish is a simple bar chart displaying integer values (just assume persons or something similar where a scale of 0, 0.5, 1, 1.5, ... would not make sense but 1, 2, 3 ... would). \nThe solutions I found were the different axis format specifiers, namely d3.format(\"d\") which does not work in IE for Windows Phone and  d3.format(\".0f\") which also displays integer values for .5 ticks and results in the following scale: 0, 1 (0.5 rounded), 1, 2 (1.5 rounded), 2, .... Not specifying any tick format will also display the .5 ticks which is perfect for most situations, but seems inappropriate for impartible values like a number of persons. \nThe one thing that finally (somehow) worked, even on IE, is to directly specify the number of ticks (say I want to display data in the range of [0,3] so I have to set ticks to 3). \nYour fix does not work in the following scenario:\nI want to display data in the range of [0,3]. The exponent will be -1 which will trigger the imprecise calculation of Math.pow(10,-1). However the error in this case is 0.3333333 so your changed if clause will not be called.\nI certainly do not have a clue if this needs to be fixed framework wise or whether this is something the user has to take care of. Maybe you could incorporate the machine error in the integer check of d3.format(\"d\"). Otherwise maybe the docs should clearly mention these edge cases. Stack Overflow answers like http://stackoverflow.com/questions/12643591/how-to-limit-d3-svg-axis-to-integer-labels often suggest to use d3.format(\"d\") to display only integer values so more people might stumble accross this problem.\n. ",
    "selvagsz": "+1\n. ",
    "Twipped": "Came here while trying to find out how to do this.\n+1\n. ",
    "danimt": "+1\n. ",
    "aesnyder": "@mbostock anything needed for this to get merged? Would love to use this in production and am happy to assist in any way to get it merge worthy.\n. @sebastianseilund do you have interest in changing the name from spacing to padding so that we can get his merged? If not, I'm happy to do it.\n. ",
    "sebastianseilund": "@mbostock Good point. I renamed it to padding now. Let me know if you need me to take a look at anything else.\n. Sure. Done :)\n. @mbostock Do you need more from me to merge this?\n. @tjagusz Sure. I copy-pasted a working version of the circle diagram here http://jsbin.com/nageravebequ/1/edit?html,css,js,output\nThe code might be a bit messy, as I just extracted it from a project that does some other things too. It doesn't work with .spacing() since it's using the current version of d3. The numbers you can position with CSS yourself.\n. #2122 looks great and is a much better solution. Getting adjacent arcs to be parallel is obviously the right way to do it. You can close this one, if you don't need more here.\n. ",
    "erikmunson": "Can we get a weigh-in from @mbostock? I'd really like to make use of this feature without forking the repo...\n. ",
    "Awk34": "Would love to see this merged, thanks @sebastianseilund \n. Cool, nice implementation!\n. ",
    "Misiu": "@sebastianseilund could You provide code example for that pie You shown in initial issue description?\n. @sebastianseilund Thanks for sharing :) This would look a lot better with padding.\n. ",
    "herrstucki": "Yes, I it's a unique index on purpose. My main goal was to have a helper to create objects/hashes/maps for quick lookup (e.g. when dereferencing a graph loaded via JSON).\nI guess d3.map(d3.index(array, accessor)) should work in a case where an object isn't enough.\nOf course this can also be achieved with .reduce() but so can the functionality d3.{min,max,sum}, so I thought it wouldn't be out of order to have a D3-idiomatic function for this :)\nAlso Underscore has something very similar.\nAnyway, thanks for considering.\n. @mbostock Is there a chance that you'll reconsider this? I tried it out and the savings can be quite significant, e.g. for d3-scale. Webpack and Parcel both support the sideEffects property, and Rollup is considering about adding Plugin support for it.\nNote that there isn't only sideEffects: false but also a way to list files which contain side effects (e.g. like sideEffects: [\"./foo.js\", \"./bar.js\"], which could be used in d3-transition, d3-time-format etc.\nAs a sidenote, d3-transition mutating d3.selection has been one of the most weird bugs to track down for me (which stops working when you upgrade packages and you end up with two versions of d3-selection in the dependency tree). I wonder why d3-transition not just re-exports a different version of d3-selection altogether and one could either use d3-selection or d3-transition in their code but not both together. For example:\ndiff\n-import {select} from \"d3-selection\";\n-import \"d3-transition\";\n+import {select} from \"d3-transition\";\nI'd be happy to help out here with more investigation or pull requests \ud83d\ude03 . ",
    "Yahasana": "@mbostock good catch! fixed now\n. @jrideout please see there is banchmark test in this 1bec3a67b commit\n. a use case for this: swap the x,y axises and change the vertical chart to horizontal one.\nwe can rotate the x,y axises separately, but this is a complicated solution.\n. d3.time.format.multi is not public but listed in the API Reference wiki \n. @jasondavies cool, I's using the older d3. thanks\n. it's ok, no need to update for this.\ni change to this as you'd like the  pre-decrement over post-decrement ;-)\n. ",
    "dylanmac": "That did it.  Thanks a lot!\n. ",
    "jaspervdg": "Note that I did not opt for implementing the tangent space projection as a separate projection for the following reasons:\n- In many cases you want both the normal projection and the tangent space projection (for example for drawing both a background map and glyphs). With the current option you don't have to manage having two linked projections around, you just have one projection.\n- There appears to be quite a bit of code that relies on a projection dealing in two-element lists.\nStill, in the future it might be something to consider.\n. ",
    "mathiasbynens": "Agree! I didn\u2019t realize this was an auto-generated file.\n. ",
    "bradens": "1570\n. ",
    "hlvoorhees": "Thanks for the tips. Function d3_scale_linearTickFormat now parses the format specifier and I put most of the precision computation in a helper function which won't be called in the default case. Format types \"r\" and \"p\" are correctly handled now, I think (added a couple more unit tests). \n. ",
    "wagenet": "This fixes the issue in my app, though I'm not qualified to say if it's good otherwise. Thanks!\n. ",
    "yuanchuan": "Well, the syntax is not compatible with with IE7. As far as i know there's an awsome project named r2d3 combining d3 with Rapheal in order to support older IE. See this Line of r2d3's build script. So it would bring problems to projects like this if switched to index lookup.\nWhat's more, It's not a good idea to mix up with array and strings. See this discussion at stackoverflow:\nhttp://stackoverflow.com/questions/5943726/string-charatx-or-stringx\n. ",
    "fudanglp": "These should be well documented. Selecting direct children is not so straight forward. I spent hours to figure it out and still doubt it if its the best practice. It would be good that putting these to #d3.selectAll section.\n. ",
    "guybedford": "Amazing, thank you.\n. ",
    "27359794": "Signed the agreement :)\n. Thanks for your time. All changes have been implemented.\nisLeft in clip-extent.js is badly named. is.. suggests it returns a boolean, but in fact it returns the z component of the cross product vector, which is larger than 0 for a left turn and less than 0 for a right turn. This leads to counterintuitive behaviour:\njs\nif (isLeft(a, b, c)) {\n  // this will execute whether the turn is left or right,\n  // since Boolean(x) == true when x != 0. eek.\n}\nI have refactored out isLeft and d3_geom_hull_CW into trigonometry as you suggested, and named the functions appropriately.\n. y instead of fy is a bug in the old code. rather than conditionally copying the array depending on the accessor function, we should just always copy it (because we are making changes to it -- we don't want to change the original)\n. my algorithm outputs a different 'rotation' of the points, but the points are still in CCW order as required.\n. will this override of Math.random cause problems in other test modules? if so, i can reset Math.random to its original state afterwards:\njavascript\nmathRandom = Math.random\nMath.seedrandom(..)\n..\n..\nMath.random = mathRandom\n. ",
    "rbu": "Mike, thanks for taking a shot at this. I'll haven't played around with the branch yet, but the direction you are going to seems right to me. Can you give a quick example how to register a locale at runtime with this?\nHow do you generate a locale?\nStatically loading a js file after d3 has been loaded would be fine for us (similar to what moment.js is doing), however it would be interesting to see if we could generate a d3 locale object from a Globalize.js culture.\nBy the way, we noticed that d3_time_scaleLocalFormats is not using localized format strings. For example, formatting times as \"%I %p\" is rather US-specific. Is this something you'd rather tackle in this branch, or should I create an independent bug report against master?\n. @mbostock, sorry for dropping the ball earlier. The reason would be that we can still use the d3 api. I assume the time and number formatters are also used internally when creating an axis, for example.\nMy idea was to reuse an existing catalog of locale data so that we do not have to build a custom set of locales just for d3.\n. This should actually be\ndateTime: \"%A, der %e. %B %Y, %X\",\n. ",
    "cheezy2022": "Does anybody have any examples of how to change locales on the fly using the D3 library? Still not clear if this is possible with D3, or if we need a custom solution.\n. ",
    "Monduiz": "I'm tryin to wrap my head around this. Does anyone have an example, say, on how to apply d3.locale to a bar chart to change dot-separated decimals to comma? This would go a long way to help understand how to use it in the most common scenarios.\n. Thank you, wahlatlas! It works beautifully. I implemented it today in my app and it saved me a lot of trouble. Thank you Mike for this wonderful functionality. I use more and more D3 now.\n. ",
    "ChALkeR": "http://jsperf.com/mercator\nMakes no visible difference.\n. Thanks =).\nYour new implementation is much cleaner, I was too lazy to rewrite the algorithm from scratch.\nIs optimize-interpolate-string going to be merged to master soon?\n. Thank you =).\n. ",
    "mourner": "When you do npm install, it will still install jsdom, the only difference with optionalDependencies being that it will tolerate failure on it. So if you use Node and jsdom doesn't compile properly, you won't be able to use require('d3') in both cases (it's just that it will fail later, on require stage), and if it does compile, it will work in both cases too. The trade may be worth it, but your call. I just thought it would be nice to bring up a discussion.\n. The benefit is that people that don't have XCode installed will be able to install d3 using NPM.\n. I think I'll close the issue and instead try to push contextify (dependency of jsdom) to build properly without XCode.\n. OK, found out that the jsdom dependency won't be a problem after Node 0.12 release so we'll just wait for that. :)\n. ",
    "rassie": "Updated, should be correct now. On a connected note: there seems to be no scripts section in bower as opposed to npm, maybe should take it out.\n. ",
    "tcp": "Looking back, it wont work for all cases.\nIf the sum of weights is larger than Number.MAX_VALUE, the sum goes to Infinity and the returned value is incorrect. It returns either NaN (Infinity/Infinity), if Infinity is part of the values; or 0 (n/Infinity), for any -Number.MAX_VALUE <= n <= Number.MAX_VALUE.\nThen, weightedMean([n, n], [n, n]) does not return n, but 0.\n. Hi Jason,\nThis pull request is for the case where I want the map to be 'stretched' in a certain direction and I don't want to include the map inside another <svg>.\nFor instance, I want my map to occupy a whole canvas of width x and height y. In the current state, I would have to place the map inside its own <svg>, with a viewBox and preserveAspectRatio=none, as the map is scaled by a single factor. This is a common task, and I don't want to have to wrap the map inside a svg element.\nCheck this out:\nWithout scaling [x,y]\n\nScaling [x,y]\n\nSo far, in the projections that I have tested, I haven't encountered issues using the new scale. It still supports the 'old' scale, so it won't break d3 for people who are already using projections.\nAlso, can you see a way of achieving what is suggested in this PR without using <svg viewbox=\"0 0 w h\" preserveAspectRatio=\"none\"> or scaling via css?\n. Thanks for the thoughtful reply!\nI think points 3 and 4 are very undesirable. Here at Gapminder, we often stretch maps to fit the viewport, but the extra effort to make those calculations could be prone to errors if you are not careful. I'd rather achieve this with two lines than to spread recalculations of positions, boxes, etc. everywhere.\nEditing projection.scale does not break the current (or future) projections. And it helps in two ways: it shows the map in the way that we want it shown (occupying the whole viewport) and it provides the correct position of mapped 'elements'.\nFor example, if I want to place a pixel on top of London, I can have London's position instantly: projection([London-x,London-y]). By using points 3 and 4, that is not the case. I haven't tried with 1 and 2 and while I think I could probably get the correct result, their implementation is not as straightforward.\nI don't see the projections losing 'good properties' as you do. I see it gaining the freedom of being able to scale in both x and y, if that is what is wanted. What if conformity is not desired? Maybe the shape is not so important :)\nRight now, I'm attached to a singular idea of how a projection should behave: always use the same scale for both coordinates. The positioning is 'lost' as soon as I scale it manually using other attributes (css scaling or viewbox+preserve combo). Features provided by d3 projection, such as the London example aforementioned, become useless. Imagine the mess that can be created by using viewboxes, transforms, etc. I would have to track down every transformation, get what their values are just to make sure I can point a position correctly on the map.\nI was worried that this PR would break some other projection, but I can't see how. I was also worried about the API, and I definitely agree with your point.\nAnyway, I thought it would be nice to share as this helps us to achieve what we want faster and I've seen this question pop up in our internal discussions as well as SO and google-groups. I see changing the scale as a more intuitive way of working with projections than the other options mentioned.\nImplementing point 2 requires a deeper understanding of d3/math. I had no knowledge of 1! Thanks for sharing that option. I'll give it a try, but I still think it will be cumbersome compared to having it already ingrained in the lib.\nAgain, thanks for your reply!\n. ",
    "sudodoki": "Just want to point out that there's already a PR for that: https://github.com/mbostock/d3/pull/1721\n. ",
    "voidstardb": "Signed.\n. ",
    "jbblanchet": "I should have done it. I didn't want to set-up node and all this stuff to run the tests, but anyway there's more changes I want to make in the locale module (localization is a major concern for us), so I'll update the tests and update the pull request.\n. Here you go. Took me 5 hours to set up a Linux VM (well 4 hours to try to get it to work under Windows and 1 for the actual Linux setup), but at least I'll be able to run the tests in the future :).\n. ",
    "musically-ut": "This causes a problem with WebKit browsers:\n\nError: Problem parsing d=\"\"\n\nSo it seems that there is no cross-browser compatible solution for this issue. Pity.\n. This is actually a long standing WebKit bug which seems to have been fixed at least in the Nightly build.\nHowever, there is less hope of it getting fixed on IE9/IE10. Hence, I am keeping this pull request open for now.\n. ",
    "jtwalters": "This is a great improvement for the use case of using the path as a textPath. The bl.ocks example is exactly what I was trying to accomplish. Hope this can get merged in.\n. ",
    "salomvary": "Actually, the context (this) of the predicate function has changed from the [format, predicate] array to the context of the resulting function. As this has never been a tested or documented feature I think it should be fine (might even make more sense).\nAlternatively, can change it to apply(f, arguments) and save three bytes:)\n. Oops, looks like I oversimplified the example. This closer to my real-life problem:\njavascript\n['in %Y',         function(d, r) { return r === 'year'; }],\n['in %b',         function(d, r) { return r === 'month' && thisYear(d); }],\n['in %b, %Y',     function(d, r) { return r === 'month'; }],\n['on %-d %b',     function(d)    { return thisYear(d); }],\n['on %-d %b, %Y', function()     { return true; }]\nI know even this can be achieved in other ways, it just felt like it would be great to have the logic in one place and the cost is very little.\n. > I know this seems like a small change, but it still complicates the API and requires explanation in the documentation. (And precludes us from adding other arguments to the predicate function in the future.)\nOk, nevermind then. Keep it simple!\n. ",
    "regiskuckaertz": "Naming a module is perfectly fine and won't break anything:\nhttp://requirejs.org/docs/api.html#modulename\nNormally r.js gives anonymous modules a name, I admit I could not see why\nit didn't with D3.\nRegis\n. Damn, I should've thought about this. You're absolutely right; I may bring\nanother interesting nugget of information that I had, literally, in my\nsleep: r.js choked on D3 because the file (a build I made myself following\nyour instructions on using SMASH) had multiple anonymous modules, which is\nforbidden:\nhttp://requirejs.org/docs/api.html#modulenotes\nThe file had D3 and queue-async in it, both of which are anonymous. And\nbecause I simply copied the content of the Makefile instead of, well,\nthinking, the two modules were put together in the same file. I just need\nto keep the two separate and feed them into r.js instead of Uglify. I'll\ngive it a shot and, if it works as I expect it will, submit a PR on the\nSMASH project.\nSorry for disturbing you with this, Regis\nOn Wednesday, March 5, 2014, Mike Bostock notifications@github.com wrote:\n\nHmm, emphasis added:\nYou can explicitly name modules yourself, but it makes the modules less\nportable -- if you move the file to another directory you will need to\nchange the name. It is normally best to avoid coding in a name for the\nmodule and just let the optimization tool burn in the module names.\nI do see that jQuery specifies the name \"jquery\" (see exports/amd.jshttps://github.com/jquery/jquery/blob/master/src/exports/amd.js#L13).\nSo, I suppose I should test it and see what happens.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/mbostock/d3/pull/1764#issuecomment-36696949\n.\n. \n",
    "DavidSouther": "It certainly is breaking, especially when you've inherited code like \nif (typeof xAccessor !== 'function') xAccessor = function(d,i) { return d.x;}\nhttps://github.com/novus/nvd3/blob/f1a1b34e117327177414ba7980565bcf4e286cb8/src/interactiveLayer.js#L216\nWe'll be fixing that on our end shortly.\n. ",
    "jakevdp": "It came up in a recent addition to mpld3, in the context of a function which takes new axis limits, and smoothly zooms the figure to those limits.  I originally had written a function that converted the dates into scales, interpolated the scales, and then converted those scales back to dates, but this seems much cleaner.\n. Small update: I switched to using +d rather than d.valueOf().\n. Wanted to add: if you prefer a fix that detects objects which are coercible to numbers and implements interpolation that way, I'd be happy with it.  As long as interpolated dates don't return empty objects!\n. I tried out #1780, and I'm happy with that fix if you'd prefer to go that route.\n. Great, thanks!\n. Tested this on my application mentioned in #1779, and it works. Also, tests pass on my box \u2013 I think this is good to merge!\n. ",
    "esjewett": "This (I think), addresses the request raised and discussed in issue #1782 \n. ",
    "eric-poitras": "Hello !\nI need the formatter for the 1-based week of year so I was about to implement the %V directive as a way to format 1-based Week of Year as specified in the venerable API: http://pubs.opengroup.org/onlinepubs/007908799/xsh/strftime.html\nI see here that you may intend to use the %V for signed year. It may be a good idea to use another directive for signed years and still follow the strftime standard for defined values ?\n. Hi. I was wondering if you plan to give me feedback over this pull request. We use d3 in our product and are very motivated to contribute to the project by fixing issues / adding features directly to the library when appropriate. So I signed the contributor form and I tried to follow as close a possible to the library standards. Is there additional steps I could take to make this merged in the library ? Thanks !\n. Merged back master into my branch, and resolved the conflict. Had to fix the bin/component file that was referencing a non-existent attribute. Also, there is a test that fails in mbostock/master so it fail in my branch as well.\n. ",
    "isaomatsunami": "I wish you expose half-edges so that we can write Marching Squares algorithm (my current concern) upon it.\n. ",
    "sbryfcz": "Is there any update on this? I'd love to be able to run this awesome functionality on a node backend. It seems that the old build that contained this functionality is not node compatible. I get lots of errors. Document not being defined and such. Any suggestions for how I could proceed? I love how D3 and topojson has become very rich with functionality for manipulating topology. Keep up the great work!\n. ",
    "IftachSadeh": "Hey Mike,\nThanks for the awesome work on this project!\nThe  voronoi.topology() functionality is great. Is there any way for one to use it with the current master version of d3? (I see it's not yet part of d3-voronoi either)\nThanks!\n. ",
    "typeofgraphic": "I think i have a use-case for this: dynamic nested group drag events. I have groups which need to be dragged (a node with text) but then given say, a keypress, I want to change which <g> entity i drag  -now I want to drag all circles in the whole group. The solution would be in dynamically setting and unsetting which <g> the .call(drag) is set to, which this issue would solve.\nHTML\n<g>\n   <g> <circle><text> </g>\n   <g> <circle><text> </g>\n</g>\n. ",
    "burner986": "I like that here is a lot of discussion about how to remove listeners. In my case after I remove a listener, i want to later bring it back. How could I achieve that? Using google I came upon this lines: \nvar dragCallback = d3.select('rect#no-drag').property('__onmousedown.drag')['_'\u200c\u200b];\nd3.selectAll('rect#no-drag').on('mousedown.drag', dragCallback);\nBut it doesn't seem to work anymore in d3 v4. I have an open stackoverflow question for this too: http://stackoverflow.com/questions/42245111/dynamically-resize-a-div-when-it-is-used-as-a-node-in-a-d3-force-directed-graph. @mbostock Sorry i won't do that again. And thanks so much that did the trick.. ",
    "kaidjohnson": "Chased down the wrong rabbit hole. May have an update on this in a bit...\n. ",
    "PrajitR": "For a temporary solution, would deleting these properties after computation work? Instead of node._visitedChildren = false, we could do delete node._visitedChildren.\n. Great job Mike! This is a lot cleaner than my attempt at solving the problem. I would, however, disagree with abbreviating the internal variables (ea7b43e). I think it makes it more difficult, not easier, to read the code because the one letter names don't readily map to a concept like the longer names do. I think you should merge the first three commits and not the fourth one.\n. ",
    "ljani": "Np! Sorry for late reply, I've been travelling..\n. I just tried the Zoom vs. Drag example and it doesn't work for me with Chrome 50.0.2661.102 m on Windows 10. I'm only able to zoom and pan.\n~~Updating to Chrome 51.0.2704.63 m seems to fix the issue, but it's very new and not everyone has updated yet.~~\nEDIT: The version does not matter, I'm not sure why it worked right after the update.\n. @mbostock I thought the background was supposed to flash if you clicked it? With Chrome, there are times when it won't flash even if I clicked anywhere. Most of the time it works just fine.\nEDIT: I'm not sure if this is the same bug, but one example is right-clicking and dismissing the menu. It takes two left-clicks to get the background to flash whereas with Firefox it flashes instantly. Anyway, there are times the background won't flash until you close the tab, no matter where or how many times you click. I'll let you know if I figure out how to reproduce this.\n. Yeah, I meant the background. And I agree with your thoughts about clicking and zooming.\nHere's another thing: Tooltips. Consider this example. If you:\n1. Point to a circle so that it'll display a tooltip (= the <title>)\n2. Move your cursor over the white background\n3. Click it, nothing happens on Chrome. On Firefox, the background flashes.\n4. See the console, it should say: defaultPrevented\nEDIT: I haven't tried this with 4.0 yet. Might be the same issue as with right-clicks.\nEDIT2: once again the background became unresponsive. I wanted to take a video capture, but I minimized the window and it started working again. Anyway, all I can say is that I had the tab open for a very long time before it came unresponsive.\n. Here we go: https://gfycat.com/SolidFabulousHorsefly\nEach time I click the background, defaultPrevented is logged to the console. I'm still not sure how to end up here, but it seems that leaving Chrome open and doing other stuff seems to be the key, heh.\n. ",
    "Tiln": "Who r you talkin to\nOn May 18, 2014 11:38 PM, \"Mike Bostock\" notifications@github.com wrote:\n\nOK, I\u2019m willing to waive the CLA for this since the words themselves are\npublic domain, and the code is just find-and-replace from the existing\ncode. Thanks for the contribution!\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/mbostock/d3/pull/1874#issuecomment-43465519\n.\n. \n",
    "duggiefresh": "Good to know, thanks!\n. ",
    "Rich-Harris": "Yep, this is fixed in AMDClean now, thanks\n. ",
    "uu1101": "Hmm, I see...\nThe use of Function(\"string\") prevents d3.js being used in a page with Content-Security-Policy, unless the the 'unsafe-eval' option is activated.\nActivating 'unsafe-eval' lets any other scripts in the page evaluate strings as javascript. This is undesirable, as it might open the door to attacks.\n. Follows an alternative implementation, using JSON.stringify and JSON.parse. Its performance characteristics are uncertain, how is performance assessed?\n``` .diff\ndiff --git a/src/dsv/dsv.js b/src/dsv/dsv.js\nindex 9be0ebf..c599740 100644\n--- a/src/dsv/dsv.js\n+++ b/src/dsv/dsv.js\n@@ -32,9 +32,11 @@ d3.dsv = function(delimiter, mimeType) {\n     var o;\n     return dsv.parseRows(text, function(row, i) {\n       if (o) return o(row, i - 1);\n-      var a = new Function(\"d\", \"return {\" + row.map(function(name, i) {\n-        return JSON.stringify(name) + \": d[\" + i + \"]\";\n-      }).join(\",\") + \"}\");\n+      var a = function(d) {\n+        return JSON.parse(\"{\" + row.map(function(name, i) {\n+          return JSON.stringify(name) + \":\" + JSON.stringify(d[i]);\n+        }).join(\",\") + \"}\");\n+      };\n       o = f ? function(row, i) { return f(a(row), i); } : a;\n     });\n   };\n```\n. ",
    "Vanuan": "\nThe new ES6 modules specification has almost no momentum\n\nIt's no longer the case.. ",
    "otarazan": "Thanks for your detailed answer\nOn Jul 12, 2014 6:48 AM, \"Mike Bostock\" notifications@github.com wrote:\n\nHi. Thank you for the pull request. However, I\u2019m inclined to not special\ncase this error for a few reasons:\n- The error is only thrown when the style property is invalid. For\n  example, if you try to set the width property and you forget to specify the\n  units. (\u201c42\u201d is invalid CSS but treated as \u201c42px\u201d in most browsers besides\n  IE9.) It is relatively easy to find and fix these using IE9\u2019s debugger, and\n  more importantly it is desirable to fix them rather than failing silently\n  by default.\n- IE9 has a relatively small market share thanks to the adoption of\n  IE10 and IE11+. This combined with the above means it should hopefully be\n  affecting only a small number of users.\n- D3 is not a compatibility layer [1]\n  https://github.com/mbostock/d3/wiki, so I\u2019d prefer to keep the\n  number of browser workarounds to an absolute minimum. In this case, I think\n  the right thing is to have the caller specify the appropriate units (or\n  otherwise specify a valid style property value), rather than failing\n  silently or trying to correct the value automatically.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/mbostock/d3/pull/1930#issuecomment-48802354.\n. \n",
    "programmist": "I tested it with Chrome on Linux and the behavior occurs.  I tried my Macbook trackpad and it does not occur, but that's because it's a touch device.  As a test I plugged a (non-Apple) mouse into the Macbook and I also see the behavior.\nI hear what you're saying about the inconsistent behavior.  I hadn't considered touch devices.  A better solution might be something along the lines of getting the hypotenuse (sqrt(deltaY^2 + deltaX^2)) of the 2D delta.  I guess the question is, what should a 100% horizontal scroll do?  If I scroll exactly horizontally should it zoom?\n. The main reason I wanted the Shift-zoom was to provide some modality to the zoom behavior.  I created an Angular directive around the d3 zoom behavior and I've made it optionally modal, so that someone can continue to use the scroll wheel to scroll as usual on the page, but then use shift+scroll when they wish to zoom on an SVG drawing (user feedback indicated that the scroll wheel triggering zooming by default was \"annoying\").  I tried metaKey, altKey, and ctrlKey, but all of these have OS and/or browser bindings that make them difficult to use.  Shift was the one with the least number of overloaded bindings.  Unfortunately Chrome overloads it to trigger horizontal scrolling, which makes it completely useless as it completely disables zooming.  Maybe I can find a work-around for this.\n. ",
    "jonsadka": "Please clarify desired functionality if i0 >= i1, i0 < 0, or i1 < 0. I took my best guess as to how these edge cases would function.  \nOh and BTW, d3 is AMAZING!! Thank you Mike :)\n. Jason, any thoughts on the following edge cases to take into consideration?\nAs a reminder, they are as follows:\n- if i0 >= i\n- if i0 < 0\n- if i1 < 0\n. Thanks Jason.  I went ahead and updated the function to account for the i0 \u2265 i1 noop condition and returning undefined for negative step parameters.\nAlso, I threw in a testing file because TDD = AWESOME...and it's fun seeing the green dots run across the screen.\nAnyway, let me know what you think and if any improvements should be made. Thanks for the quick response.\n. Cool. Thanks Mike!\n. Awesome, great addition :+1:\n. - Returns an empty array for non-objects\n- Delegates to ECMA5+ Object.keys if exists (significant speed improvements)\n- Additional tests of edge cases implemented\n. You are correct in that the double bang is not required and my new commit should remove that redundancy, however this check is required for catching falsey values being passed in, such as null, NaN, etc...\n. ",
    "kayellpeee": "a d3.shuffle method would be quite handy\n. ",
    "cmccloud": "I think this would be a useful addition. \n. ",
    "Anmo": "I fixed the backwards compatibility with that ugly boolean optional argument...\nIf you want you now can merge without break nothing.\n. ",
    "serhalp": "That makes sense.  Currently,\njavascript\nd3.format(',e')(0)\n-> \"0,e+0\"\nbut also,\njavascript\nd3.format(',')(1e30)\n-> \"1e,+30\"\nand\njavascript\nd3.format(',g')(1e30)\n-> \"1e,+30\"\nMy latest commit covers all these cases.\n. ",
    "codedependant": "+1\n. I would of really liked to see this feature merged in. I end up using quite a few class names to style my graphs, especially when using BEM. It would not only save quite a bit of typing, but also look a lot cleaner to simply use a single selector.\n. ",
    "gka": "Another possible (and arguable cleaner) implementation could use a second parameter for setting the class:\njs\nselection.append(\"div\", \"foo\");\nselection.append(\"div\", \"first-class second-class\");\n. If the second parameter is a problem I'm happy to go back to my first proposal which uses the CSS selector-like syntax:\njs\nselector.append(\"div.foo\");\nThis then could also be used in inserts\njs\nselector.insert(\"div.foo\", \"ul\");\nAnd while we're at CSS-selector like syntax we could also address setting the ID:\njs\nselector.append(\"div#foo\"); \n// same as\nselector.append(\"div\").attr(\"id\", \"foo\");\nI agree that, from a library design point of view, those short-cuts only tend to mess up the API. But, given that the append action is probably the most used function in D3, I would argue that the code simplification justifies the cause.\nMy feeling is that I am not the only one who is typing .append(\"g\").attr(\"class\", \"bla\") up to 50 times a day, so why not save us all the typing and go for a simpler solution. After all, this doesn't break the API, so nobody would have to change their code if they don't want to.\nTo throw another argument into the ring, selector.append and selector.insert also support specifying the namespace (append('svg:text')) which is more or less a convenient short-cut to avoid something awkward  like  selector.appendNs(tagName, namespace). So the append(\"div.my-class\") syntax somewhat aligns with this concept.\n.  Changed API back to original proposal which avoids second-argument confusion when used in insert. See pull request message above.\n. I'm pretty sure there is always something that could lead to \"moments of confusion\" for people learning to  use a new powerful library such as D3.js. But those who made it through selection.enter() and selection.exit() will probably get the idea of a short syntax for adding classes and ids to newly appended or inserted DOM elements.\nTo your question, I just tested what happens:\n``` js\n\nd3.select('body').append('.foo');\n// Uncaught DOMException: Failed to execute 'createElementNS' on 'Document':\n// The qualified name provided ('.foo') contains the invalid name-start character '.'.\nd3.select('body').append('div.foo span.bar');\n// executes without error, appended this: \nd3.select('body').append('.foo .bar');\n// Uncaught DOMException: Failed to execute 'createElementNS' on 'Document':\n// The qualified name provided ('.foo .bar') contains the invalid name-start character '.'.\n```\n\nI'm happy to write the extra documentation for the new feature, explaining in detail what you can do with it and what not.\n. As of now, the implementation accepts multiple classes and one ID, and the ID always needs to come first. As @naehrstoff mentioned this should probably be checked for eventual syntax errors, e.g. div.foo#bar.\n. @mbostock did you find some time to look at this? I've been using my forked version with this feature in two projects now, and it's just great. Almost any time I call selection.append() or selection.insert() I either want to set a class or an ID, so simplifying the API makes perfect sense here..\n. I replaced the string-search-based implementation with one that uses regex split. That allows using any order of ids and classes, and also should be a little faster.\nAnd I actually use the multi-value maps quite often, especially when setting a bunch of static attributes.\nBut I'm not particularly interested in heaving time-consuming debates about this. If you don't want to add this, I'm totally fine with just using my fork. \n. Ok, I will close this pull request and instead merge it into my fork at https://github.com/gka/d3. It's just an too amazing feature for not having it, but I'm totally fine with being the only one using it.\n. ",
    "grossbart": "I hate being the party pooper (ok, I sometimes enjoy it :trollface:) but wouldn't this lead to Moments of Confusion because people expect it to do more than it can do thinking it works similarly to selector.selectAll('div.foo').\nselector.append('.foo') // is it a div, is it a g, what should it be?\nselector.append('div.foo span.bar')\nselector.append('.foo .bar')\nThat could be interesting, of course, but it's also a whole different beast!\n. The good thing about yor PR is that it's entirely optional, which is your main point: if you want to use it, you can :smiley:\nI would prefer if the second example threw an error, though, because it's not really a valid form...\n\nAm 29.08.2014 um 07:35 schrieb \"gka\" notifications@github.com:\nI'm pretty sure there is always something that could lead to \"moments of confusion\" for people learning to use a new powerful library such as D3.js. But those who made it through selection.enter() and selection.exit() will probably get the idea of a short syntax for adding classes and ids to newly appended or inserted DOM elements.\nTo your question, I just tested what happens:\n\nd3.select('body').append('.foo');\n// Uncaught DOMException: Failed to execute 'createElementNS' on 'Document':\n// The qualified name provided ('.foo') contains the invalid name-start character '.'.\nd3.select('body').append('div.foo span.bar');\n// executes without error, appended this: \nd3.select('body').append('.foo .bar');\n// Uncaught DOMException: Failed to execute 'createElementNS' on 'Document':\n// The qualified name provided ('.foo .bar') contains the invalid name-start character '.'.\nI'm happy to write the extra documentation for the new feature, explaining in detail what you can do with it and what not.\n\n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "MDCox": "Just throwing my +1 into this conversation.  While it is mainly a convenience thing, I think it's a great feature.  Because CSS selectors are used throughout selections, having them available during appends just feels right, and I think will probably be more intuitive for people who aren't already used to the current way.  Yes it brings debates on exact implementation and will add one more thing to maintain, bu I can definitely see myself happily using this for static elements and the more verbose format for things that will later change.\n. ",
    "lebolo": "Sorry, I should note, make and make test completed successfully, but no new tests were written (unless @mhsmith added them previously).\n. @mbostock Any comment on getting this in? Does it need more work? Based on #1299, it seemed like a popular feature request.\n. Going to bump one more time to see if there's any interest in merging this in =) @mbostock, any feedback?\n. If there's still interest in this, I can take a look at the current merge conflicts.\n. I deleted the fork this Pull Request was based on some time ago =( I'd be happy to re-fork and update the patch to resolve merge conflicts, but that would mean I submit a new PR. And I'm still not sure if this feature will actually be merged - it's been 8 months now.\n@mbostock, @jasondavies, is there any interest in merging this feature in? Any reason why it hasn't yet?\n. This feature has been merged (see #1084)\n. ",
    "rtsao": "Would love this feature!\n. ",
    "pedroteixeira": "+1\n. ",
    "joncursi": "+1 works like a charm!\n. ",
    "c0by": "+1 this would be very cool\n. ",
    "ocombe": "This functionality is a must have, any chance to get it merged ?\n. ",
    "256dpi": "+1 I would love to have that!\n. ",
    "satishwaghela": "+1\n. ",
    "kasiarachwal": "+1\n. ",
    "reppners": "+1\n. ",
    "mmase": "+1\n. ",
    "Lbousa38": "Reply\n. ",
    "xshaka": "@lebolo, will be this feature in some final release? I have tried to add your changes on version 3.5.12 but it doesn't work quite well.\n. ",
    "mariusandra": "+1\n. ",
    "jchlapinski": "Well, this PR was created because I needed precise control of scale factor for one of my projects. My particular use-case was that I charted some financial data on a bar chart with time scale and then used some non-linear aggregations while zooming out or in; When zooming out the scale was represented in months, quarters, 6 months, years, 5 years and decades. I wanted to precisely control consecutive scaling factors especially for mouse-wheel zooming to achieve some nice animations - three month bars would gradually become one quarter bar, etc. The point of adding proposed API was that it currently is not possible to scale for exactly 1/3 after single mouse wheel event, and then scale for 1/2 after another.\nI did not test nor think about using touch gestures. I agree that with pinching this approach might need some more thought.\nIMO zoom behavior should never expose too much of its internals (like event handling), but it could allow for applying custom scaling factors. \nI do feel however, that my proposed API is clumsy and non-elegant as proposed above and I am open to suggestions how this could look like. Perhaps this should be divided into several scaling factor generator functions for different zooming events (mouse wheel zooming vs pinch zooming vs double tap zooming)? That way this clumsy 'usecase' parameter could be removed from the API?\n. I also thought at first about just supplying a discreet array of scaling factors for scaleExtent, however as much as this would more or less suit my particular use-case at the time I thought it is much better to be able to supply a function, since that way one can do some dynamic and continuous calculations dependent on a specific context. Just much more general and also very easy to support discreet values case.\nAlso I indeed used a continuous scaling so that when zoomed out the chart was scaled smoothly to the next aggregation level. It was a matter of controlling what those end-point scaling factors might be depending on the current aggregation level as they were non-linear.\nAs for @mbostock comment above, I do not understand why supplying custom scaling function would not be suitable for continuous mousewheel  gestures? With appropriate context supplied to the scaling function it could always at least behave exactly as the algorithm that is currently implemented, no?.\nIt seems to me that this scaling factor control is sometimes useful for some users (judging from those few PRs), although probably not that often, and if done well it should be absolutely harmless and unobtrusive to all. \nIs it a worthy feature to add to API? I do not know, it is definitely nonessential, but I remember I felt a little bit disappointed that I could not do what I wanted with zoom behavior. You can control almost every computational aspect through this beautiful and simplistic API in d3, why can't You control just that?\n. > My first concern with both of these proposals is whether it\u2019s better to intercept the input events yourself and then change the scale of the zoom behavior, rather than letting the zoom behavior handle the input events while exposing hooks for how the zoom behavior computes the new zoom level.\nWell when I think of it now, it does seem to be relatively easy to intercept input events, if slightly more difficult with the mousewheel, and simply use zoom.scale() to achieve custom scaling... \nThere is quite some code in zoom behavior source that deals exclusively with input events, so re-implementing that is not trivial but one can always reach for the code provided there to speed things up. It just seemed much easier to me at the time to patch d3 instead of re-implementing it altogether but now I am not sure whether this is worth it and whether there is a really good way of customizing scaling algorithms in that manner... After all if one wanted to do some more animation oriented and dynamic zooming it would probably be impossible to do properly without intercepting input events anyway.\nIf Your @mbostock concern is that this feature would bloat the API, which is a very important concern IMO, I will not insist on including it. I will close this PR for now, since the code needed work anyway. Thanks for the discussion and for Your insights.\n. ",
    "Y--": "Thanks a lot!\n. ",
    "jshanley": "It seems that this in the context of the .each() method callback would simply be an object whose __data__ property will be copied to the corresponding element when it is .appended. \nI suppose there might not ever be a reason to alter the data during the enter selection, but I could see potentially wanting to iterate over the enter selection for debugging purposes, to inspect the entering data before elements are appended, on a per-item basis.\n. Of course, that's why I mentioned before elements are appended. Anyhow, adding the .each method was not my primary purpose, and it seems you've found a workaround. Cheers!\n. ",
    "factom": "Agreed that's cleaner assuming you don't care about retaining your one line change in 519f258 from\njs\nwhile (i > 0 && g > 0) {\nto\njs\nwhile (g > 0 && i > 0) {\n. ",
    "martoranod": "Fair enough! Thanks for the reply.\n. ",
    "mLuby": "Looks good to me!\n. ",
    "vsn4ik": ":+1:\n. ",
    "floledermann": "The patch doesn't merge without conflicts any more, but should be trivial to adapt. Let me know if you need an updated version that merges with current master.\nBtw. I signed the contributor agreement when I first submitted the pull request.\n. ",
    "zackd": "+1\n. ",
    "dandv": "To make it as painless as possible for both Meteor devs and the library maintainer to publish packages, I'm creating an organization named after the library, adding myself to it (which is how I published the package), then asking the maintainer to create an MD account, which I'll add to the org as well.\nThere is indeed an assumption that the library maintainer will be willing to work with us. I have no reason to suspect the contrary, but if in some instance that happens, we have as a fallback, for Meteor devs integrating the package, my fork of the library.\n. Hi Mike, thanks for getting back to us. I've added mbostock to the d3js Meteor Developer organization. Let me try to address your objections.\nMeteor's need for a custom packaging system has been challenged a number of times, and the bottom line is that it was developed to support libraries that run on different architectures. More on that in this blog post from MDG and this Quora question, Why does Meteor use its own package system rather than NPM.\nIndeed, the publish script just runs meteor publish --create for the first time, and meteor publish thereafter, then cleans up some temporary files. It was made in order to make it as easy as possible for maintainers to publish, along with the Makefile entry. If you'd like to bypass it, you just need to run those two commands.\n. There's one other reason meteor/publish.sh exists: meteor publish (just like bower) expects a file called package.js to exist in the root of the project. This file is rather unspecifically named and conflicts with Dojo's package.js, though I sent a PR to have it renamed to meteor-package.js.\n@mbostock, thanks for prodding me to simplify the script. The --create flag is necessary only the very first time the package is created on Atmosphere, and that's best left as a task for the Meteor dev who first submits the PR. publish.sh is much cleaner now.\nIf you prefer, I can add another commit to this PR to move package.js to the root dir, remove publish.sh, and replace the Makefile entry with meteor publish. The only problem is that there will be a .build directory and a versions.json file created in the root of the project. The current approach is to clean them up, but we could also add them to .gitignore. Thoughts?\n. Good call. I've removed both .sh files and updated the Makefile. Thanks for the nudge :)\n. @mbostock: eliminated spacejam, since the only CI test was a simple instantiation, and Travis isn't used anyway.\nWant to meteor publish 3.5? :)\n. @bobiblazeski - I've just published the latest version on Atmosphere. Going forward, we're moving packages to an automatic publish framework, http://autopublish.meteor.com.\n@mbostock: please let us know when you have a chance if you'd be open in principle to including make meteor in your build process. If not, no problem - we'll separate the Meteor wrapper into its own repo, and trigger builds using the autopublish framework mentioned above (credits go to @splendido for that).\n. @splendido: added you and meteorpublish as well, even if no longer necessary if Mike will be publishing manually.\n. @mcinano Probably. Though I don't know what the solution is for people who just search Atmosphere for 3rd party libraries and instead of our well-maintained wrapper packages, they find old, unmaintained, thin wrappers. See https://github.com/percolatestudio/atmosphere/issues/403.\n. ",
    "paralin": "You also need to update the version number in your package.js I believe every time you update. It might be good to automate this as well.\nWe are discussing having an automated build system for this.\n. @mbostock We're working on a collaborative effort to do this for existing projects and submit pull requests. We're also working on an automated system like you say to automatically pull.\nMy personal opinion is that for things specifically client side like D3 (although you can use it on the server in some rare cases) should just be pulled through Bower, as it's more widely supported. Meteor's ideology is to have a single package for both server and client code, something that really doesn't need to be applied to something like D3.\n. Doesn't require it, but it's necessary if you actually do have any global\nvariables.\nOn Sat Nov 29 2014 at 3:03:58 PM Mike Bostock notifications@github.com\nwrote:\n\nAlso, what's the reason for the meteor/export.js? Does the Meteor package\nsystem require us to export a global?\n\nReply to this email directly or view it on GitHub\nhttps://github.com/mbostock/d3/pull/2130#issuecomment-64968583.\n. @mbostock @splendido Is it really not possible to make this completely external and not require any repo access?\n. @splendido The new registration through webhook sounds like a good compromise for paranoid repo owners. I'd add that option for sure.\n. Meteor supports npm, use it! :)\n. \n",
    "bobiblazeski": "Any update regarding this? Atmosphere version is outdated, while it claims to be the official version which makes things confusing. \n. @mbostock Thank you for the  great work with d3.\n@dandv Thank you for the update. \n. ",
    "splendido": "Hei @dandv and @mbostock, lets have a look at what we did with Twix,js:\n- we've added a package.js file to the other PM ones\n- and modified the Makefile\nThis would be more than enough to work for autopublish.meteor.com\n...unless there are particular actions to be taken to make the package compatible for Meteor!\n. ...ok, sorry, I've seen only now that bower.json and package.json are generated from the scripts under  bin.\nI guess we could do the same for the pacakge.js file?\nAlso there might be no need to tweak the export, since from the closure this.d3 should already result as a global d3 variable. Hence no need to have a api.export('d3');.\nBut I'd have to confirm this...\n. Hello Mike and Jason,\nfollowing the above discussion I've just updated this PR (and in agreement with @dandv) to make it as lean as possible.\nI plugged in your building process adding one more target to the Makefile so to get a package.js file automatically generate on new builds.\nThe idea is to leverage autopublish.meteor.com so that you won't have to run any additional commands (nor scripts) on your side to get the meteor package updated at every new release.\nAll you'll have to do, after having merged this PR, is going to autopublish.meteor.com sign in with your gitHub account, locate this repository and enable it for autopublish by toggling the checkbox you'll find on the right side of the repository item.\nYou can get an idea about how all this works by having a quick look at this page, but basically it creates a web hook on the repo to let us know when you push new tags. And when you'll release new versions, autopublish.meteor.com will automatically take delivery for publishing the new version also for Meteor!\n...this is exactly what you were asking for in this comment so I hope you'll find this new updated PR well in line with your thinking.\nPlease note that you will not be able to toggle your repository until you'll have the package.js file on your master branch (without it the repo won't be recognized as a meteor package...).\nBesides this, @dandv already did the other part of the job creating the d3jd organization including your mbostock user among the maintainers.\nThanks & best regards,\nLuca & the Meteor integration team\n. Giving permissions away is always something that can create concerns, I know.\nThis is why, in more recent PRs, I've added another paragraph to the instructions:\n\nIn case you're not comfortable with autopublish.meteor.com maintaining access rights to your repos, please head to GitHub Application Settings and revoke permissions for Meteor Autopublish.\n\nThe only thing that autopublish.meteor.com does is creating a new webhook on the repository (for which write permissions are required...) and this is once for all.\n@mbostock the other solution might be manually creating the webhook, but I would have to add some code to autopublish.meteor.com to pick up the first test payload as a new registration (I'll be happy to do it...)\nIf you still have concerns and you don't mind doing it, running meteor publish after the build would be enough (I guess your meteor.com user was already added to the package maintainers).\nAmong the three I'd prefer the second one to get the webhook, but feel free to go for the third (or the first one ;-) ): I'm open to every solution.\nWhat do you think @paralin?\nThanks for the positive feed-back @mbostock !\n. I think @mbostock is doing very well being paranoid about his repos ;-)\nWe should all do the same!\nIf we think creating a new subscription on autopublish.meteor.com when the test trigger for a new hook arrives can be a good solution, I'll try to play with it during the next week.\nLets see what @mbostock think about giving permissions for a few minutes only.\nThanks again,\nLuca\n. Don't worry, it's all fine.\nI appreciate your line about repository protection!\nIf after merging this PR you could cretae a new JSON webhook pointing to:\nhttp://autopublish.meteor.com/publish\nthat would be more than enough and much appreciated!\nEdit: the webhook should be set to trigger on Release: Release published in a repository.\n. \n. Yeah, in your case Release is fine!\n(not all are using releases, someone just push tags...)\n. Thank you @mbostock!\nI really appreciate your collaboration, hopefully we'll not have to bother you again with this :)\n...I'll work on the webhook test trigger on my side: I think this will be useful for other cases as well.\nKeep up the great work!\nLuca\n. mmm, that might become a problem :(\nAt the moment it picks up the d3.js file on the root folder: see this line\nBut if it will be still generated with the build process we might trigger the build soon after the repo is cloned on the build machine and before running meteor publish.\nWe should be warned about this change with a failure on the publish operation ;-)\n. Ok, I'll keep an eye on this.\nPlease feel free to delete the webhook when you'll remove the d3.js file from the repo.\nThank you again!\nLuca\n. I'll try to see whether we can get the older one(s) flagged or set as unmigrated (hidden).\nYou might also go to atmosphere and flag it: the sooner we get enough flags, the sooner the package will be marked as flagged.\n...and there's no way to get an alias for the new name. The meteor add d3 withouth author name was something in use before Meteor@0.9.0 :(\n. Your analysis is totally correct!\nBut I think our best option is to open an issue on the Meteor repository asking MDG to remove they're d3 package since it's no more officially supported and not up to date.\nWould you like me to create the new issue?\n...it might have more weight if you do it yourself though. And I'll be happy to second you!\n. Actually there are already a number of issues about this topic...\nSee this search.\nAnd @dandv pinged them very recently after you merged this.\n. The latest release was correctly signalled to autopublish.meteor.com but the user meteorpublish is still not part of the d3js organization. This is the error that was signalled:\nerror: You are not an authorized maintainer for this package.\n@dandv could you add meteorpublish to d3js so that I can retrigger the publish?\n. Ok, I'm going to remove d3js:d3 from autopublish then.\nNo worries.\nThank you @mbostock for taking the publish process on you!\n. ",
    "mcinano": "Hi everyone\nIs there any plan to update the atmosphere repo to d3 4.x?\n. Thx, I'll use npm package.\nSo should be d3 removed from atmospherejs.com?\n. ",
    "nitram509": "thanks.\n. ",
    "benlesh": "Interesting, so master isn't your latest? Because I just forked this today. When will the release be?\n. ",
    "turbolent": ":+1: Looks good in d3-timer! Looking forward to the modularized 4.0, thanks for the amazing work! \n. ",
    "zefrog": ":+1: This would be a nice feature, as I am using ISO week numbers in tickFormat for some graphs, and starting at zero makes no sense...\n. ",
    "tdc-studio": "I am developing with d3 v4.9.1, can I ask if this very helpful feature of ISO Week numbers is available to me please? If I try and format my ticks using %V it doesn't work, unlike %W which of course does. Have I completely missed something obvious.. ",
    "cvrebert": "X-Ref: #2152\n. ",
    "brett-miller": "@mbostock or @jasondavies, is this a candidate for an upcoming release?\n. ",
    "Jaspur": "Als je echt de Dutch locale aan wilt houden, dan moeten maanden en dagen in lowercase. ;-)\n. ;-)\n. ",
    "arjenvanoostrum": "Die gekke nederlanders ook met hun groene boekje.. ;-) Aangepast! \n. ",
    "Tiagoperes": "Will this be merged into master?\n. ",
    "sylvinus": "+1 for this issue. Would also love a simple fix to avoid breaking at load time, I confirm this works on IE8:\n@@ -8146,6 +8146,7 @@\n     monotone: d3_svg_lineMonotone\n   });\n   d3_svg_lineInterpolators.forEach(function(key, value) {\n+    if (!value) return;\n     value.key = key;\n     value.closed = /-closed$/.test(key);\n   });\n. ",
    "RudolfHattenkofer": "Multiple drag behaviours on the same element won't work, because they all get the same identifier for the mouse events ;) See this example: http://jsfiddle.net/jsnqu5u0/\n. Well, the short answer is: Because modularity :D There is going on a lot in my app (e.g. Panning/Zooming, moving parent elements, moving children, rotating stuff...), I can't just define one single correct behaviour for most elements.\n. ",
    "ryank109": "Any update on this?\nI would want this for modularity as well.  I have a group of elements that the user can drag and resize.  It would be nice if I could break up the functionality for just moving and resizing.\n. ",
    "rhardih": "I've run into another use case, also related to modularity. I've extracted a \"selection box\" a'la http://bl.ocks.org/lgersman/5311083, into it's own component plugin, with a simple interface:\njs\nvar svg = d3.select('svg#foo');\nvar sb = d3.selection_box();\nsvg.call(sb);\nSince the selection box internally has to attach a drag handler to show and update it's representant rectangle, if I ever attach a drag handler to my svg selection from the outside, the one already attached by the selection box get's overwritten, and as such it stops working.\n. ",
    "fent": "Came here for the same use case, modularity. If not able to attach a new drag behavior, where do I get the active behavior?. ",
    "andresgutgon": ":+1: Thank you!\n. ",
    "klokoy": "Should\u00b4t this be considered a braking change? When using d3 in node the following used to work\n```\nvar d3 = require('d3');\nvar svg = d3.select('body')\n            .append('svg');\n```\nAs jsdom is not included in d3 this will no longer work.  It was a very nice way to generate svg on the server.\n. Fair enough.  And thanks for your fix.\nKim\n. ",
    "toolness": "Thanks for this!\nI noticed that the D3 wiki docs on Browser / Platform Support still said JSDOM was included with D3, so I updated them to reflect this change... If you don't like it though, feel free to change it.\n. ",
    "DannyDelott": "+1 for the Oxford comma.\n. ",
    "awelch83": "@mbostock Do pull requests actually get merged here? Or is submitting one mostly a waste of time?\n. ",
    "mrblueblue": "One aspect I really liked about the old readme is that all three sentences started with \"D3.\"\nIn order to preserve this repetitive structure, I've updated my pull request. It now reads:\nD3.js is a JavaScript library for manipulating documents based on data. D3 helps you bring data to life using HTML, SVG, and CSS. D3 emphasizes web standards and combines powerful visualization components and a data-driven approach to DOM manipulation, giving you the full capabilities of modern browsers without tying yourself to a proprietary framework.\n. I really like that change jhamon. The sentence now reads:\n\nand combines powerful visualization components with a data-driven approach to DOM manipulation, giving\n. \n",
    "jhamon": "I'm just passing through but wanted to say I :+1:  these changes.  I would have also changed:\n\nand combines powerful visualization components and a data-driven approach to DOM manipulation, giving  \n\nto\n\nand combines powerful visualization components with a data-driven approach to DOM manipulation, giving  \n\nThe repeated use of and in that sentence doesn't really roll off the tongue.\n. ",
    "amZotti": "Why has this not been merged yet? \n. ",
    "Caster": "Thank you for considering this change!\nIndeed the API could be better, as it was for personal use only I just went with this. Very interesting to see the changes you are making, it looks promising. I agree with the penalizing of small arcs, it would be awesome to have D3 take care of that. At the moment I am kind of busy, but if there is anything I can help with, tinker around a bit, just let me know :-)\n. ",
    "xiashuyan": "Rrr\n. ",
    "portante": "@mbostock, could you take a moment to consider this?  Thanks.\n. ",
    "aubergene": "I'm still getting an issue when using this fix. With this example I get this error. Using Chrome 41 on OSX with an Apple Magic Mouse. I click a state and then scroll slightly whilst it is transitioning, which is very easy to do, since the mouse is very sensitive.\nUncaught TypeError: Cannot read property '0' of nulltranslateTo @ d3.js:1427\nmousewheeled @ d3.js:1564\n(anonymous function) @ d3.js:1120\n. I manually applied the patch to d3 3.5.5. I've made a gist here with the issue using the patch.\n. ",
    "hyunkim9123": "I have checked the exception in developer plugin in both chrome and firefox browser. \nIf you would like to see the exception, please set the data.tsv below and follow the instructions at http://bl.ocks.org/mbostock/3885304. \"data.tsv\" is expected to have \"tab\" as the separator, but I have used \"space\" instead of that, which causes parsing error and NaN exception.\nletter frequency\nA .08167\nB .01492\n. ",
    "hughes": "This is great - hope to see it merged soon.\n. Meanwhile, @mbostock has an example of creating padding with dummy nodes\n. It's not a great workaround honestly... the padding is only on one side and the resulting size can be difficult to predict.\n. ",
    "mgetz": "Thanks for that example, Matt! I had not found that one.\n. ",
    "ikari-pl": "This might seem a stupid question, but how can I currently force the partition layout, based on hiearchy as well, to use size for the parent nodes, without switching to d3-layout? The padding should be doable and is probably the only option for a sunburst, right?\n. ",
    "lubomirov": "Hi, I have a working version of d3.behavior.zoom that fully support MS pointer events. The patch is local to zoom.js file. It's about +100 source lines. It can be compact, I didn't an optimization so far. The minimized js size is about +2Kb to d3.js. Could we join our efforts in the area of support pointer events in D3? Sorry, I'm newbie in streaming patches into public libraries.\n. Better version of this pull request was added\n. Hi, nikolas, I've made rebase and double-checked my patch suggested here. It works in IE11 (particularly in 11.0.25). With this version you can do zoom with two/three/more fingers (there is an algorithm that considers third finger if second one goes out of zoom area). Thank you for downloading and reminding me about this pull request. \n. ",
    "n1cho1as": "Hi I have just gone through the truck load of updates to support touch on win8+IE11 and none of these fixes actually work for me.  All I'd like to have is the pinch zoom and panning that is supported by default on a SVG element and when a zoom behavior is implemented.  I have found that targeting the SVG element with CSS touch-action:none on the SVG element I am able to pan, however the pinch zoom does not work.  Applying this CSS also makes Mike's bubble demo work too.\nI am guessing this CSS isnt required for your fix, so wondering if you could please outline what can I expect to change on my existing diagram by using your branch of d3? Is there something else that I should do?\nMany thanks!\n. Hi, I have just downloaded this version and the pinch zoom/panning is not working for my d3 SVG. Do I need to implement something different to add support for IE11?\n. Many thanks for the heads up, I will download this version and test it tomorrow.\nFrom: lubomirov [mailto:notifications@github.com] \nSent: Friday, 15 April 2016 19:22\nTo: mbostock/d3 d3@noreply.github.com\nCc: nikoloas niko.x@outlook.com\nSubject: Re: [mbostock/d3] Pointer (and MSPointer) events for the zoom behavior. (#2547)\nHi, nikolas, I've made rebase and double-checked my patch suggested here. It works in IE11 (particularly in 11.0.25). With this version you can do zoom with two/three/more fingers (there is an algorithm that considers third finger if second one goes out of zoom area). Thank you for downloading and reminding me about this pull request. \n\u2014\nYou are receiving this because you commented.\nReply to this email directly or view it on GitHub https://github.com/mbostock/d3/pull/2547#issuecomment-210378102   https://github.com/notifications/beacon/ARbkCtzm7yZvU7LLBc1S-zK6xn4vCR9Nks5p31jHgaJpZM4F48YH.gif \n. ",
    "Herst": "@nikoloas \nQuoting myself from https://github.com/d3/d3/issues/1439#issuecomment-338496133:\n\nTouch events are in Edge but disabled per default and the setting hidden at about:flags. With this activated zooming in works but zooming out does not. All-in-all the situation is inadequate which is why there might still be need for the implementation of at least some pointer event stuff.\nFor what it's worth, here is a simple demo of how to support the pinch zooming gesture for triggering a programmatic zoom (not the browser gesture for doing page zooming): https://mdn.github.io/dom-examples/pointerevents/Pinch_zoom_gestures.html\nMaybe I find time for hacking support for this into d3 because pinch-zooming is the only thing in my project which does not work on touch-enabled devices with Windows.. \n",
    "amcdnl": "@kalenedrael did you break this out into its own plugin anywhere?\n. ",
    "trusktr": "Live demo?\n. @kalenedrael Can you please share a link to a plugin version of this? Would be so awesome! :D\n. ",
    "flowercat07": "Add class\nDelete class\ndone?\n. Please rejected\nIt's useless...\n. ",
    "greut": "Okay, thanks for the info!\n. ",
    "andreasplesch": "It took me a while to find the d3/d3-arrays project. The approach in range.js there works much better and makes the commit above obsolete. Perhaps it is useful as a temporary fix until the next major version of d3.\n. Hm, it looks like I spoke to soon. While the new range.js works better, it still has the same issue. I opened a new, crossreferenced issue there: https://github.com/d3/d3-arrays/issues/5\n. ",
    "rubenv": "No wait, this doesn't work, d3_selection_interrupt depends on d3_transitionNamespace.\nShould we add a dependency on the whole of transition from inside behavior/zoom?\n. ",
    "lnollet": "Hi, I'm using d3 to draw and manipulate a map and it works fine, excepted on windows mobile devices (pinch zoom and translations by touch are disabled). Maybe those changes could fix it ? Can it be merged with main project ? \nMany thanks for your work.\nLeo. \n. ",
    "stefwalter": "@abonas @jwforres FYI\n. To reproduce this bug:\n- Use an Internet Explorer appliance from here. IE11 on Win7\n- Clone https://github.com/kubernetes-ui/topology-graph\n- grunt depends\n- grunt serve --hostname=0.0.0.0\n- Access port 9000 of your host with IE\n- Try to drag one of the nodes in the force directed graph\nThis bug will cause an exception to be thrown, seen in the javascript console.\n. Rebased\n. @jwforres Above are relatively simple instructions to reproduce this bug. If you have access to Safari, you can try them out.\n. ",
    "jwforres": "@mbostock this is a relatively small change, what are the chances on getting it merged?\n. Also i'm pretty sure this was an issue with Safari, not just IE\n. @spadgett has faster access to safari than I do :)\nOn Tue, Jan 5, 2016 at 10:37 AM, Stef Walter notifications@github.com\nwrote:\n\n@jwforres https://github.com/jwforres Above are relatively simple\ninstructions to reproduce this bug. If you have access to Safari, you can\ntry them out.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/mbostock/d3/pull/2548#issuecomment-169036526.\n. Thanks for merging!\nOn Feb 11, 2016 3:06 PM, \"Mike Bostock\" notifications@github.com wrote:\nReleased in 3.5.15. Thank you!\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/mbostock/d3/pull/2548#issuecomment-183042444.\n. \n",
    "jakerichan": "@mbostock I notice you closed the issue relating to this PR.  Is there anything I need to update before we merge?\n. ",
    "vp2177": "merged into :patch-1\n. ",
    "Klortho": "Any chance of this getting out of the icebox? I spent a lot of time trying to make sure it's backwards-compatible. One thing I didn't do was performance testing on it, for comparison with the existing. But I could do that if you want.\n. Now that the new version is out, I'll try to find time to turn this into a plugin this week.\n. @mbostock , since this isn't going into \"the trunk\" (if that even exists anymore) I am planning on severing backwards-compatibility with the tree layout. The API is not a good fit. Holler if there's any reason not to do that.\n. ",
    "jakefoster": "Agree with @chrisvfritz completely.  This feels like an enhancement to core, not a plugin.\n. ",
    "eseifert": "Thanks Mike! Actually, the changes aren't intended as a fix to mouse wheel handling.\nMy use case is a story telling application where I use the zoom level to show or hide elements. i want to be able to define a certain number of zooming steps between minimum and maximum scaling for the mouse wheel or double click.\nAt the moment it's hard to change the implemented base-of-2 zoom. I tried to create a modified version of D3's zoom behavior, but i just ended up pulling a lot of internals into my code.\nYou're right, I broke the dblclick snapping. I guess i should fix that. I changed it because it didn't work as intended with non-base-2 zoom for my use case: With zoomFactor=1.25 and scale=0.8, zooming out with dblclick would result in a scale of 0.8 as a result of rounding errors.\nComing to mouse wheel interaction: What particular reason is there for the .002 factor in zoom behavior calculation?\nI did some research on cross-browser mouse wheel handling and I think it will be very hard to get right. All of the existing solutions I've looked at have issues, like React's solution (https://github.com/facebook/fixed-data-table/blob/d6bac3ccc59612d521b29d12d84f5142e5f252cb/dist/fixed-data-table.js#L1947-2113) or the jQuery mousewheel plugin (https://github.com/jquery/jquery-mousewheel/blob/master/jquery.mousewheel.js). My temporary solution is to use Math.sign(wheelDelta) instead of wheelDelta*.002.\n. I reverted the changes to dblclick snapping, so it's just about the zoomFactor now.\n. ",
    "nicksrandall": "see https://github.com/d3/d3-arrays/issues/12\n. Issue also reported here: https://github.com/mbostock/d3/issues/1413#issuecomment-21328564\n. ",
    "JesperWe": "Was this supposed to fix the defaultPrevented problem on Chrome? I use a zoom behaviour with drag for panning, and need to recognize clicks as well. I am on 3.5.16 now, and I still have issues with Chrome always setting defaultPrevented = true, both on drags and clicks, which means I can't tell them apart. Firefox works fine, sets defaultPrevented = false for clicks.\n. OK, my case is different: I have a zoom behavior, where a drag does panning, but a background click should do something else. In this case both a single click and a drag event triggers a 'click', which comes with defaultPrevented=true for both types of operation on Chrome, but defaultPrevented=false for the single click and defaultPrevented=true for the drag on Firefox and Edge. Maybe this is a different issue?\n. Right. I have spent the day investigating this. Before this commit, my app was intermittently buggy. With this patch it stopped being intermittent, so it was easier to debug. I had the .on( 'click' ) on the <svg>, and the .call(zoomBehavior) on a <g> tag inside it. With this setup there is a difference between Chrome and other browsers. When I moved the click to the same tag as the zoom, it starts to work as expected. \n. ",
    "cscheid": "Hey, I don't know if this would be a sufficiently useful feature, but I've found myself reimplementing it a few times when exploring different nonlinear transformations over segmented ranges. I didn't find anything quite like it on the issues browser or documentation, but I apologize if this feature exists somewhere.\n. I did. I agree with you that in many (most, even) cases the quantize scales are the correct ones. But in this case (I'm building a time-varying 2d histogram) I was interested in observing the \"movement\" of the parts that would be \"internal to the bands\" as well.\nBut you're right that it might not be worth the trouble.\n. ",
    "Wombatpm": "Update to base\n. Updates to latest\n. ",
    "vylan": "Thanks KaranLala, for this case it's a nice fix. But I found in the case of the root node having no child, error still occurs, could you provide an improved fix, thanks in advance. (http://plnkr.co/edit/XFZSeY?p=preview)\n. Thanks @jfrickson , I 've tested with your code. I believe it fixed this issue. by the way, please change seq2 to sep2.\n. ",
    "KaranLala": "Hey vylan, I looked into it further and my fix is only useful for this case. I'll try to find a better solution to the bigger problem (root with no child included). For now, this quick fix in the tree.separation function should help avoid the issue - \njs\nfunction(a, b) { \n  if (!a.depth) return 1;\n  return (a.parent == b.parent ? 1 : 2) / a.depth;\n}\n. ",
    "linuss": "You're completely right, I'm sorry for my hasty PR. I encountered this bug (which in retrospect was probably just caused by the 'start' event), and wanted to help out.\n. ",
    "jfrickson": "Ok, I also put in a fix for his and vylan's \"root only node\" problem.\n. Should be good to go!\n. ",
    "vendethiel": "It appeared in my profiler output, that's why I changed it in the first place. We call setAttribute (through attr) very extensively, it seems...\n. Right, but at least it silences the chrome profiler warnings. The second thing I'm the most \"sad\" about is the array subclassing using proto, but I don't really have the time to \"fork\" and change everything for our codebase... Oh well, guess I'm stuck with this in the meantime.\nDo you want me to close this PR, or are you interesting to take it on this repo?\n. Good news, thanks :)\n. Is this confirmed not to trigger perf. warnings in chrome?\n. ",
    "drimacus182": "@ieaglle Why isn't it merged into mbostock:master?\n. @ieaglle It would be nice)\n. ",
    "ieaglle": "@drimacus182 I've found a spelling error, canceled, and forgot about that. I probably should proceed with this.\n. ",
    "lokesh005": "Hey but why not it should be in your galary as this svg is unique\nOn Wed, Dec 30, 2015 at 10:21 PM, Mike Bostock notifications@github.com\nwrote:\n\nClosed #2695 https://github.com/mbostock/d3/pull/2695.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/mbostock/d3/pull/2695#event-502908212.\n. Please answer me\n. Okay thanks\n. \n",
    "jfrazier": "+1\n. @mbostock, do you know when this version will be published to npm? Needed for Browserify to work properly. Thanks!\n. Awesome, thanks Mike!\n. ",
    "ferlores": "Not sure, maybe it worked fine with an older version of browserify. \nPlease let me know when you are publishing a new version with the changes. Thanks!\n. ",
    "alanvanbuuren": "Thnx for the new variable name's\n. ",
    "tvictory": "I appreciate your feedback and will consider taking a look at things in d3-color 4.0 instead then.\n. ",
    "timruffles": "Ok, makes total sense! :)\n. ",
    "martgnz": "@mbostock please can you take a look at this? We are going to release a Canvas-based map library and  don't want to rely on forks.\n. BTW, I just created a new TopoJSON using the latest version and still \"leaks\": http://bl.ocks.org/martgnz/7889428fcad5eb8b43eec7c71ddb90af\nI made this json with:\nbash\ntopojson municipios.shp -o municipios.json\nYou can download the original shapefile here: https://drive.google.com/file/d/0B_UyUs3UduSUNkZiMmdJRlVJTlU/view?usp=sharing\n. ",
    "lukasappelhans": "Okay, unfortunately this doesn't seem to be the issue here. I updated this block to use the latest official topojson and d3 releases. You can see that the bounds are fine now, but at least one polygon \"leaks\".\nhttp://bl.ocks.org/lukasappelhans/967f744f80ff2209ad946570063210f4\n. Yes, d3.geo.bounds is fine with the other PR merged. The rendering also works as long as I keep dynamic simplification disabled. Once I turn it on, it paints everything in one color.\n. Awesome, thank you!\nYes, I agree that projecting the topojson beforehand would be better and faster. However, there is (correct me if I'm wrong) no way to use custom projections (e.g. rveciana/d3-composite-projections) when using the cli client. The other problem I see is responsiveness, since we use different projection parameters for mobile vs desktop. Other than that, I should at least add support for projected topojsons.\nI wonder why the simplification produces a straight polygon though. Shouldn't this be avoided in any case?\n. ",
    "isaacl": "What do I need to do to land this?  It's a small, self-contained change that improves performance in c3 charts (which use d3)\n. ",
    "gunins": "Yes it is in strict mode and bundled by r.js. Will Look forward on version 4.\n. ",
    "tianxuzhang": "nice +1\n. ",
    "caravinden": "May I know how can I push my code to examples\nGet Outlook for Androidhttps://aka.ms/ghei36\nOn Mon, Jun 27, 2016 at 9:08 PM +0530, \"Curran Kelleher\" notifications@github.com<mailto:notifications@github.com> wrote:\nPerhaps this is better suited to post as an example on bl.ocks.org?\n\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHubhttps://github.com/d3/d3/pull/2867#issuecomment-228783197, or mute the threadhttps://github.com/notifications/unsubscribe/AE6eiIET45mtgr5OCFPdmi9c4s7FnMLuks5qP-5RgaJpZM4I_IR4.\n. Thanks a lot Bostock\nGet Outlook for Androidhttps://aka.ms/ghei36\nFrom: Mike Bostock\nSent: Monday 27 June 21:57\nSubject: Re: [d3/d3] D3 slider (#2867)\nTo: d3/d3\nCc: Aravind Cheekkallur, Author\nClosed #2867https://github.com/d3/d3/pull/2867.\n\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on https://github.com/d3/d3/pull/2867#event-705183187 GitHubhttps://github.com/d3/d3/pull/2867#event-705183187, or mute the threadhttps://github.com/notifications/unsubscribe/AE6eiKg9d43I19caZOluooh2Qz_OlBrZks5qP_nigaJpZM4I_IR4.\n. ",
    "piq9117": "this PR is nonsense. sorry\n. ",
    "nolsherry": "@mbostock OK, thanks for your response. :)\n. ",
    "askmike": "done. I got the text from the d3-shape README. Want me to change that as well?\n. ",
    "yach7": "3062.",
    "eglassman": "I'm sorry--one more I missed:\n```\nStreams\nshould be\nStreams\n```. ",
    "Loksly": "Same as #3170 \nMike will change it. Don't worry..  #3288 #3259 and many more.\n. instead of require you may use pkg = JSON.parse(path.resolve(__dirname, '..', 'package.json')); or something like that. Require not only parses but executes. ",
    "oscarmorrison": "No worries @mbostock thanks for your consideration. \nI was mainly try to keep it consistent with this style\nvar x = d3.scaleBand()\n    .domain([\"a\", \"b\", \"c\"])\n    .range([0, width]);. ",
    "ameya98": "If I had an example I wanted to share on the Gallery/Examples, what would I do?. ",
    "ry4nguera": "good. ",
    "rousan": "Hey @arielbk,\nI would like to remind you to follow this thumbs rule to write good commit message e.g. use imperative mood in commit message etc.\nFollow this to get better explanation: Here. ",
    "arielbk": "@mbostock Understood; I should have investigated more thoroughly.\n@rousan Noted and thank you for the resource.. ",
    "willsmythe": "Hi @curran,\nI dug into why the d3-scale tests are failing. It is caused by differences in how the current timezone is determined on Linux vs. Windows. On Linux, timezone can be controlled via the TZ environment variable, which was already being set prior to running the tests (since some tests were coded to assume a Pacific timezone). This variable is not honored on Windows (see https://github.com/nodejs/node/issues/4230).\nTo fix d3-scale, I updated the build script to call tzutil (a Windows-specific command):\nyaml\n- script: |\n    tzutil /s \"Pacific Standard Time\"\n  displayName: 'Set timezone for tests'\nI didn't dig too hard into why the d3-time, d3-timer, and d3-time-format tests are failing (I will), but this is a likely culprit (along with possibly other differences in the way timezone, daylight savings time, etc are dealt with on Linux vs Windows).\nI think this problem highlights the value in running tests across multiple platforms. \nThere could be legitimate problems uncovered (both in the current code and in future code) due to differences in the platform used for development (Linux) and the platforms where these libraries are expected to run.\n. ",
    "stevemao": "@envision thanks!, I'd reword it to: NOTE: This will bundle every module in D3\nTo try to avoid mentioning tree shaking.. should be shell. ",
    "jomaxx": "@mbostock doesn't apply to transitive dependencies. You can also apply it in a sub-directory of a package if you add a package.json to that folder.\n. might be worth considering adding this optimization to some of the other d3 packages this package is re-exporting . @mbostock looking at it again. you are right it would cause issues.\njs\nimport { select } from 'd3';\nwould be the equivalent of \njs\nimport { select } from 'd3-selection';\nwhich would not apply the changes fromd3-transition.\nHow do users handle this today? The README does say first that you can import directly from specific d3 modules.. I see. Then I don\u2019t think this change is right. \nIt would be a breaking change since the behavior of importing select from d3 would be different. \nIn the future would d3 consider removing these side effects? . @mbostock understood. to support this, there would need to be architecture changes and i'm not too familiar with the internals of d3 to understand how each module is coupled together. . ",
    "kitcambridge": "Instead of sniffing for IE, you can use the IE-specific document.documentMode property.\n. ",
    "Swatinem": "Fun fact: this was originally set to 5 but failed with\n\u2717 nices to the given stepsize \n        \u00bb expected [ 0, 5 ], \n    got  [ 0, 5.000000000000001 ] (deepEqual) // sqrt-test.js:192\nDon\u2019t we all love floating point math? :-D\n. ",
    "voronoipotato": "SHRUGS http://jsperf.com/this-is-for-mbostock I dunno it seems to work, make sure I was sane in my test setup though.\n. ",
    "visnup": "don't you want to pass f also to d3.mean?\n. ",
    "gardenamacloc900": "Yes\n. ",
    "alexmacy": "I wasn't sure, so I just went with what it said in the d3-drag docs, but this makes sense. I'll make the change, thanks!. ",
    "fernandaloppes": "?. sim. ",
    "tawanjairew": "https://github.com/d3/d3/pull/3114#discussion_r136388035. ",
    "duttaditya18": "Why this change?. "
}