{
    "jstn": "Thanks! Not a design choice per se, just not something we've needed yet at Tumblr. It's a great idea though, I'll do it.\n. This has been added in 1.0.1\n. fixed\n. All of the \"trim\" methods are already LRU (to make this possible the cache stores an NSDate every time a key is set or read). When you call trimToDate: for instance, the objects are removed in order of least recently updated until it reaches the cutoff date. Setting the \"ageLimit\" property will start a recurring timer to do the trim for you automatically.\n. I'd love to see your code if possible, send me an email? jstn@tumblr.com\n. should be fixed in 1.0.2, let me know if you're still having issues!\n. You're right, it should tell you the total disk use. Are the images definitely coming from the cache? (Maybe it really is empty?)\nAny other code or clues you could share?\n. fvisticot, can you try this for me in place of your log statement?\ndispatch_async([TMDiskCache sharedQueue], ^{\n    NSLog(@\"byte count: %d\", [[[TMCache sharedCache] diskCache] byteCount]);\n});\n. Agreed, I'm going to think of a way to expose this without deadlocking the queue. Thank you!\n. I added a property on TMCache called diskByteCount that basically does this synchronously. byteCount can continue to be accessed safely within blocks run the shared disk cache queue. Look for it in 1.0.3 later this afternoon.\n. I agree, but I don't think it's possible. There's no reliable way to know how much memory an arbitrary object consumes, especially if it's mutable and has the potential to change over time without notice.\nInstead, TMMemoryCache has a setObject:forKey:withCost: method and a costLimit property. The cost is an integer that you define, and if you know the size of your objects this can effectively be a byte limit.\nFor instance, if you know that you only need to store NSData in the cache and want to limit the size to 1 megabyte:\n[[TMMemoryCache sharedCache] setCostLimit:0x100000];\n[[TMMemoryCache sharedCache] setObject:data forKey@\"someData\" withCost:[data length]];\n. Really interesting idea! I hadn't thought of using NSCopying like that, I'll have to think about it some more. Thank you.\nEverything is documented in the header for TMMemoryCache, check out costLimit and trimToCostByDate:\nhttps://github.com/tumblr/TMCache/blob/master/TMCache/TMMemoryCache.h\n. Since lengthOfBytesUsingEncoding: is specific to NSString (and not NSCopying) it's not going to be much help in the general case, unfortunately. I'd still love a way to know the byte size in memory of any arbitrary object, but I don't think it exists.\n. Waiting to hear from the cocoadocs folks on this: https://github.com/CocoaPods/cocoadocs.org/issues/32\nShould be up soon. In the meantime all the docs are included in the repo.\n. I've been thinking about a few ways to do this, ultimately I'm going to add something to let you enumerate all the keys. The cleanest way would just be exposing the keys as a readonly property, but then it's up to the developer to make sure they only read the property on the cache's queue (with a barrier, in the case of TMMemoryCache). Another way would be a method like enumerateKeysWithBlock:, which is safer but more limiting. I'll think about it some more.\n. This has been added in 1.2.0!\n. Here's an idea for how you'd implement your own clearing mechanism:\n```\nself.cache.memoryCache.removeAllObjectsOnMemoryWarning = NO;\nself.cache.memoryCache.didReceiveMemoryWarningBlock = ^(TMMemoryCache cache) {\n    [cache enumerateObjectsWithBlock:^(TMMemoryCache cache, NSString *key, id object) {\n        // do your removals asynchronously here\n    } completionBlock:nil];\n};\n```\n. Great catch, thank you!\nWhat's happening is that GCD is hitting its thread limit (~= 64). Here's some brief discussion:\nhttp://stackoverflow.com/questions/7213845/number-of-threads-created-by-gcd\nBasically, TMCache has been using TMMemoryCache with a synchronous call to objectForKey:, which should theoretically be fine because it's happening on another queue (that is, until it's waiting for more objects than there are threads and they all get blocked).\nThe fix was to switch everything in objectForKey: to asynchronous calls, which is messier but ultimately safer and avoids this problem. I've also added a unit test to hopefully catch this if it happens in the future. Here's the commit: https://github.com/tumblr/TMCache/commit/e44251f0d7e0363c7b625e60e8dc55814b41525f\n. Well that's embarrassing. Update coming today, I will roll this in.\n. Fixed in 1.2.0\n. couldn't reproduce this : /\n. I'm not keeping track of them, use below 5.0 is not recommended\n. fixed as of 8c513c1fd84e2ae366a5f3bdf2fa440c3866ae5d\n. For TMDiskCache you can use fileURLForKey:\nFor TMMemoryCache everything is already in memory, so there's no difference between calling objectForKey: and checking if the object exists.\nFor TMCache, use diskCache or memoryCache and query them directly as needed.\n. EDIT: never mind, see below.\nobjectForKey: is functionally equivalent, treat any non-nil return value as \"object present\". In the end it's just an ordinary NSDictionary lookup (there's no difference between accessing an object and seeing if it exists).\nhttp://stackoverflow.com/questions/2784648/how-to-check-if-an-nsdictionary-or-nsmutabledictionary-contains-a-key\nhttps://github.com/tumblr/TMCache/blob/master/TMCache/TMCache.m#L67\n. @guptakshi16 you're totally right and I agree, thank you. It should be its own method, and TMDiskCache for its part should just check the presence of the file on disk.\nUntil that's added I think you could use TMDiskCache::fileURLForKey:block: and pass a block that manually checks for the file with NSURL::checkResourceIsReachableAndReturnError: followed immediately by a call to TMMemoryCache::objectForKey:block:\n. These are both stylistic preferences, I happen to like the __weak out front.\n. I have no doubt that's Apple preferred style, but if it works as expected and the static analyzer doesn't complain in pedantic mode I consider that \"technically correct\". What do the Clang docs say about it?\n. Each of the basic cache operations has two manifestations, a synchronous method and an asynchronous method. objectForKey: will return the object after some time, objectForKey:block: will return void immediately and you can access the object within the passed block (once it becomes available). If the block is empty nothing will happen and the object lookup is wasted.\nFor methods where the block is optional, like setObject:forKey:block:, you can safely pass nil for the block argument instead of writing out the whole type. The operation still completes asynchronously.\n. ``` objective-c\n[[TMCache sharedCache] setObject:Image forKey:@\"ImageKey\" block:nil];\n[[TMCache sharedCache] objectForKey:@\"ImageKey\"\n    block:^(TMCache cache, NSString key, UIImage *storedImage) {\n        NSLog(@\"your object is here %@\", storedImage);\n}]; // returns immediately\n```\n. The file manager itself can probably deal with reads just fine, but the intention is to maintain cache consistency. We don't want another thread moving or changing a file when there's already a block queued up that will need it. There's also the issue of file sizes and dates being changed on disk without the cache having a chance to update its own metadata.\nIt's also a performance consideration. 10 different caches shouldn't read 10 files in parallel off the disk, serial is a better approach here (hence the shared queue across caches.) A nice side effect of this is that two instances of TMDiskCache can use the same disk area without conflict.\n. The asynchronous methods are the \"real\" methods, the synchronous methods are just convenient sugar to make your code cleaner when you need to wait on a response. Everything has to happen on the queue to keep the cache consistent and prevent contention.\nHowever, in practice you'll rarely need to wait on the queue. Reads are concurrent and extremely fast, and the queue is only blocked when there's a write. \nIf you're not concerned with thread safety you might be better off with vanilla NSDictionary and the file manager. Otherwise, coalescing responses would be a great job for dispatch_group()\n. These declarations are not repeats, although I agree the naming is confusing. The initial weakSelf is to avoid a retain cycle, but to actually use it safely in the block we need to make a strong reference first (otherwise it's possible for weakSelf to be deallocated mid-function from another thread.) The second weakSelf does exactly the same thing, except this time for the inner block, and then we need to make another strong reference for the same reason. In the example you highlight I actually skipped the final nil check since we're only calling one method and it's safe for strongSelf to be nil.\nThe weak/strong dance is ugly but it's functionally necessary. If you have a suggestion to make it more concise I'd love to hear it!\n. Interesting, I didn't know that. So it has to be even uglier : (\nh8 u apple\n. I disagree that it's unnecessary, but I've made my case, it's up to Mr Geddins now. The rest is just a matter of style.\n. This would introduce a deadlock for anything that calls sharedTrashURL from within sharedTrashQueue before it has chance to initialize (e.g., emptyTrash). Creating the trash directory in initializeDiskProperties is probably the best solution.\n. ",
    "fvisticot": "seems OK ! Tx a lot\n. It works fine with this code:\ndispatch_async([TMDiskCache sharedQueue], ^{\nNSLog(@\"byte count: %d\", [[[TMCache sharedCache] diskCache] byteCount]);\n});\nBUT it is really not user friendly :(\nFred\nOn Sat, Apr 27, 2013 at 4:19 AM, Justin Ouellette\nnotifications@github.comwrote:\n\nfvisticot, can you try this for me in place of your log statement?\ndispatch_async([TMDiskCache sharedQueue], ^{\nNSLog(@\"byte count: %d\", [[[TMCache sharedCache] diskCache] byteCount]);\n});\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/tumblr/TMCache/issues/19#issuecomment-17108749\n.\n. \n",
    "CA-Y": "it a time capsule 2T\nOn Fri, Apr 26, 2013 at 7:10 PM, Justin Ouellette\nnotifications@github.comwrote:\n\nYou're right, it should tell you the total disk use. Are the images\ndefinitely coming from the cache? (Maybe it really is empty?)\nAny other code or clues you could share?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/tumblr/TMCache/issues/19#issuecomment-17108613\n.\n. \n",
    "mackoj": "Ok, thanks I understand it better now.\nWhat is the rule when the cost limit has been reached ? Does it remove everything or just the first things added ? How does it select what to remove ?\nMaybe you can make a ring buffer with a size limit. This a naive example with strings but it should work perfectly with a few modification with anything that respond to NSCopying protocol.\n``` objective-c\n@interface NSMutableArray (PseudoRingBuffer)\n- (NSUInteger)sizeInOctet;\n- (void)addString:(NSString*)s;\n@end\n@implementation NSMutableArray (PseudoRingBuffer)\n\n\n(NSUInteger)sizeInOctet {\n    NSUInteger acc = 0;\n    for (NSString *s in self) {\n        acc += [s lengthOfBytesUsingEncoding:NSUTF8StringEncoding];\n    }\n    return acc;\n}\n\n\n(void)addString:(NSString*)s {\n    [self addObject:s];\n    while ([self sizeInOctet] > RINGBUFFERSIZE) {\n        [self removeObjectAtIndex:0];\n    }\n}\n@end\n\n\n```\n. ",
    "sinchan": "Thanks.\n. ",
    "orta": "http://cocoadocs.org/docsets/TMCache/1.1.0/ - it's up!\n. ",
    "prendio2": "Thanks so much @jstn for resolving this so quickly and letting me know what was going wrong. Glad I could help in some small way.\n. ",
    "irace": "@tomtaylor What problem is this solving exactly (sorry, I know this is super old)?\n. > Hah, yeah, it's been a while! I think the point was to allow multiple instances of TMDiskCache, with different prefixes.\nI get that much, but what's the benefit of not using the default prefix?\n. This only seems like it'd be useful for debugging purposes, to be able to uniquely identify different queues that point to the same cache on disk. But since you can already do this based on memory address, I'm going to close for now. \nPlease let me know if there's something that I'm missing.\n. Seems like oddly specific functionality to add. Couldn't this be implemented on top of the existing APIs?\n. Sure \u2013 thanks for the contribution and apologies for the delay.\n. This PR may have a better solution for this problem: https://github.com/tumblr/TMCache/pull/71\n. Closing this in favor of the numerous other issues/pull requests that migrate towards the asynchronous methods being wrappers around the synchronous ones, rather than the other way around. This should reduce thread usage.\n. Nice catch!\n. This pull request might add the functionality that @guptakshi16 is asking for: https://github.com/tumblr/TMCache/pull/29\n. (Sorry for the year-long delay in getting back to you about this)\nI'm going to close this because a design goal of TMCache is to keep its API small. This can very easily be implemented by simply creating a category on or wrapper around TMCache that passes in a default value of your choosing.\n. - (void)enumerateObjectsWithBlock:(TMDiskCacheObjectBlock)block on TMDiskCache.\n. Done, apologies for the crazy long delay.\n. Great find, we'll look into fixing this (sorry for the delay in getting back to you).\n. Done, apologies for the crazy long delay.\n. @wwpp3399 You could do this using enumerateObjectsWithBlock: on TMDiskCache.\n. I think I've wrapped my head mostly around this, and it seems to make sense. @jstn feel free to weigh in if you've got any thoughts.\n. It seems like NSURLFileSizeKey : NSURLTotalFileSizeKey :: NSURLFileAllocatedSizeKey : NSURLTotalFileAllocatedSizeKey \u2013 just making sure you're using the one that makes the most sense.\n. I think so but really not sure TBH\n. Why exactly are you expecting it to be freed? Are you clearing out the TMMemoryCache instance?\n. > Gotcha. In that case, should probably only be #imported in the .ms.\n@digabriel Can you make this change?\n. Thanks for your contribution, this has been released as part of TMCache 1.2.3.\n. I don't know if weak references are needed at all in most of these cases. I'm pretty sure it's fine to refer to self in a block passed to dispatch_sync or dispatch_async, even when the queue that the blocks are being added to is retained by self. The queue releases the block once it executes, meaning you won't end up with a retain cycle.\n. > Retaining self will, however, ensure that the block will be run, which, I believe, is the intended behavior.\n@segiddins This would be another argument (the first being the stylistic one) for not using weak references at all, correct?\n. Sorry for the delay \u2013 I agree that this is probably a good change to implement and will look into doing so shortly.\n. Thanks for your contribution, this has been released as part of TMCache 1.2.3.\n. @kompw What's the specific use case where the existing behavior is problematic for you?\n. @kompw Can't you just unescape the path yourself in your client code?\n. Done\n. Need to look closer but I think this might be a duplicate of https://github.com/tumblr/TMCache/pull/69\n. Thanks for your contribution, this has been released as part of TMCache 1.2.3.\n. @napoapo77 Thanks, we're definitely going to try to be better maintainers going forward.\n. Closing in favor of https://github.com/tumblr/TMCache/pull/68/files\n. @mkauppila Thanks for this! I hope to get around to reviewing this more closely soon.\n. Yeah, we'll see...\n. @garrettmoon Are both 1 and 2 necessary to resolve the deadlocking issues?\n. So basically the semaphore is used to block the main thread but you're then unable to dispatch to the state queue, since there aren't any threads available, meaning the semaphore never gets signaled and the main thread waits forever?\nDo you think there's anything that TMCache is specifically doing that results in threads becoming scarce in the first place?\n. > Basically, it seems unsafe to lock resources with queues.\nWhich is crazy if true considering it's exactly what Apple recommends in the \u201cEliminating Lock-Based Code\u201d section of the Concurrency Programming Guide.\n. @garrettmoon I've talked this over with @jstn and we're definitely in favor of moving over to the synchronous methods being wrapped by the asynchronous ones, instead of the other way around. This should reduce the number of threads used, and as such, the number of deadlocks encountered.\nThat said, we're both not thrilled about potentially using pthread_locks instead of GCD queues. I'd be interested in seeing if simply flipping the asynchronous-sychronous swap would have the desired effect without: \n- Making even broader changes to the codebase\n- Raising the barrier to entry by using a technology that most iOS developers aren't familiar with (and that Apple doesn't even seem to recommend for this purpose)\n(We also noticed a potential race condition in your unit test, since the enumCount variable can be incremented by numerous threads in a non-synchronous manner) \n. @garrettmoon Sorry that you felt the need to close this. I must yet again apologize for having been negligent/busy \u2013 I haven\u2019t had nearly the free time necessary to perform the amount of testing it\u2019d require for me to feel comfortable merging such a large change.\nThat said, I still think it\u2019s the right change to make, and I would certainly like to, but definitely think you should move ahead with a local fork in order to not let us hold you up. This is the beauty of OSS :smile: \nTo clarify, since you\u2019re not using pthreads anymore, you\u2019ve simply moved everything to be synchronous by default, correct? And are using semaphores to implement locking to keep things thread-safe? Do you think there\u2019s much of a difference left between this PR and https://github.com/tumblr/TMCache/pull/37?\n. @garrettmoon Great blog post. I\u2019m thrilled to see the changes hit production and am happy that this approach has been working out for you. As mentioned before, I think this is totally the right approach we just don\u2019t have the resources at the moment.\nThat said, I\u2019m a little disappointed that it isn\u2019t a proper GitHub fork of this repository, and that TMCache isn\u2019t mentioned at all in the README :cry: \n. @garrettmoon Thanks Garrett! Out of curiosity, how come you chose not to make it an \u201cofficial\u201c GitHub fork?\n. @garrettmoon Are all of the changes that you ended up making (related to thread starvation, I know that PINCache has other changes as well) still encompassed in this branch? If so, can I ask you to reopen? If not, would you be able to add them here?\nConsidering putting TMCache into basically a \u201cmaintenance mode\u201d \u2013 and suggesting new users use PINCache or something else under more active development \u2013 but this seems important enough to dedicate the resources towards getting it merged in and released before doing so.\n. @garrettmoon Ping! :smile: \n. > Would you like me to open up a new pull request with them (I can't reopen the old, I removed my repo)?\nIf it\u2019s not too much work, this would be greatly appreciated.\n\nIt seems more prudent to simply point people who are seeing the issue to PINCache and not force others through the change?\n\nWe\u2019re most likely going to do this for folks who would prefer to adopt something that\u2019s going to be more regularly maintained and improved going forward. That said, if we\u2019re going to \u201ccease development\u201d on TMCache I\u2019d prefer it to be with most high-priority known issues having already been addressed. I can see people who already use it upgrading without coming here to read all about it.\n. The cost limit is zero by default, and objects have zero cost by default.\nCost limit used used as follows:\n- Set a non-zero limit like memoryCache.costLimit = 100\n- Calling setObject:forKey:withCost:block: and pass non-zero cost values, e.g.\nobjc\n[memoryCache setObject:foo forKey:@\"foo\" withCost:25 block:nil];\nOnce the cost values that you set for each object accumulate to be greater than the limit, the cache will start trimming.\n. @ljfantin I'm sorry but I don't understand your question. Cost limit only applies to the in-memory component of the cache.\n. Hi, thanks for your contribution. Before I'd be able to merge this I'd need you to fill out and submit the CLA found here.\n. > Anyone looking at this PR?\nNot exactly. To be 100% honest, I\u2019m hesitant to add more functionality to TMCache without having more resources to dedicate towards testing it. It\u2019s intended to be a simple library that can easily be built on top of and extended as needed for various applications.\n. At first glance this doesn\u2019t look like something we\u2019d want to add. Can you explain what problems this fixes?\n. Passing a nil input sounds like programmer error to me. I think it\u2019s something that should be checked for in userspace using assertions, rather than something that the library includes code to explicitly support.\nAdditionally, your example above is a bit too contrived to be compelling, as you wouldn\u2019t use a semaphore to synchronize TMCache\u2019s asynchronous APIs when it already provides synchronous alternatives for you.\n. Fixed: https://github.com/tumblr/TMCache/pull/82\n. TMCache is thread-safe in that it can be accessed from multiple threads. Once you get objects out of TMCache, however, you\u2019re on your own.\nNSArray is not thread-safe so you can't treat it as such just because it came from TMCache.\n. It's outside the scope of this project. I'm sure you could find thread-safe collection classes that you could use in conjunction with TMCache, but they don't belong in TMCache proper.\n. Can you please wrap the if block in curly-braces?\n. Thanks for flagging this up \u2013 I will add release notes tomorrow.\n. Here you go: https://github.com/tumblr/TMCache/releases/tag/2.0.0\n. There are many occurrences that can cause TMMemoryCache to release memory, such as setting a costLimit or calling any of the following methods (or their asynchronous counterparts). But yes, UIApplicationDidReceiveMemoryWarning will no longer have any effect on TMMemoryCache by default. If you want this behavior in 2.0, you will need to add it yourself using the lines of code you pasted above.\n``` objc\n/**\n Removes the object for the specified key. This method blocks the calling thread until the object\n has been removed.\n@param key The key associated with the object to be removed.\n /\n- (void)removeObjectForKey:(NSString )key;\n/**\n Removes all objects from the cache that have not been used since the specified date.\n This method blocks the calling thread until the cache has been trimmed.\n@param date Objects that haven't been accessed since this date are removed from the cache.\n /\n- (void)trimToDate:(NSDate )date;\n/**\n Removes objects from the cache, costliest objects first, until the  is below the specified\n value. This method blocks the calling thread until the cache has been trimmed.\n@param cost The total accumulation allowed to remain after the cache has been trimmed.\n */\n- (void)trimToCost:(NSUInteger)cost;\n/*\n Removes objects from the cache, ordered by date (least recently used first), until the  is below\n the specified value. This method blocks the calling thread until the cache has been trimmed.\n @param cost The total accumulation allowed to remain after the cache has been trimmed.\n /\n- (void)trimToCostByDate:(NSUInteger)cost;\n/*\n Removes all objects from the cache. This method blocks the calling thread until the cache has been cleared.\n /\n- (void)removeAllObjects;\n``\n. The reason it no longer does this is becauseTMCache` can be used in extensions which cannot refer to the shared application. \nI will update the README tomorrow.\n. Yeah, that's true actually. Not sure why I didn't think of that.\nI can put out a new version that adds this back tomorrow. Unfortunately, I guess by semver rules this would mean bumping the library to 3.0 :disappointed: \n. Breaks API compatibility though?\n. I would remove the two new public methods I added in 2.0 for telling the cache that the app was backgrounds or that a memory warning occurred.\n. Fixed in version 2.1.0\n. Yes, TMCache will work fine for this use case.\nPlease keep in mind, however, that TMCache is deprecated. It'll work fine for your needs but it might be worth looking for an alternative for long-term, strategic use.\n. This error isn't used anymore?\n. What's the difference between NSURLTotalFileAllocatedSizeKey and NSURLFileSizeKey?\n. I have no idea.\n. OK, fixed. Nice catch!\n. I can change this, this is just what it always was pre-2.0.\n. Totally agree. I just reverted back to how it always was pre-2.0 but I can change.\n. More :coffee: @paulrehkugler \n. ",
    "tomtaylor": "Hah, yeah, it's been a while! I think the point was to allow multiple instances of TMDiskCache, with different prefixes.\n. ",
    "ejensen": ":+1: +1 for merging\n. +1 I'm also seeing removal failures on older hardware due to this issue.\n. ",
    "exister": "+1\n. ",
    "nirajignited": "+1\n. ",
    "jervine10": "+1... merge it please!\n. ",
    "ChristopherDrum": "How long is \"too long\"? I'm trying to find the root cause of my app's TMCache crash issues, but I'm not finding this to be a problem. I ran a test on TMCache to this effect in which I take the key passed into TMCache and make it 18x longer via\nNSString *key = [NSString stringWithFormat:@\"%@%@%@%@%@%@%@%@%@%@%@%@%@%@%@%@%@%@\", baseKey, baseKey, baseKey, baseKey, baseKey, baseKey, baseKey, baseKey, baseKey, baseKey, baseKey, baseKey, baseKey, baseKey, baseKey, baseKey, baseKey, baseKey];\nThen I logged out the byte size of each key being used. I got the following results, with no failures nor crashing:\n  fetching a 1800 byte long key\n  fetching a 1818 byte long key\n  fetching a 1800 byte long key\n  setting a 1908 byte long key\n  setting a 1710 byte long key\n  setting a 1890 byte long key\n  fetching a 1440 byte long key\n  fetching a 1440 byte long key\n  setting a 1818 byte long key\n  setting a 4986 byte long key\n  setting a 1440 byte long key\n  setting a 1674 byte long key\n  setting a 1818 byte long key\n  setting a 1800 byte long key\n  fetching a 1908 byte long key\n  fetching a 1710 byte long key\nYou can see these are exceptionally long keys, with one that is about 5K, let alone the file path it uses for storage. TMCache didn't flinch on any of these. Testing was done on-device (iPhone 6+, iOS 8.1.2)\n. ",
    "foobra": "I met this problem too. \nThread : Fatal Exception: NSInvalidArgumentException\n0  CoreFoundation                 0x30a2fe83 __exceptionPreprocess + 130\n1  libobjc.A.dylib                0x3ad8c6c7 objc_exception_throw + 38\n2  CoreFoundation                 0x30a2fdc5 -[NSException initWithCoder:]\n3  Foundation                     0x313a622b -[NSKeyedUnarchiver initForReadingWithData:] + 2454\n4  Foundation                     0x313f8493 +[NSKeyedUnarchiver unarchiveObjectWithFile:] + 114\n5  Camera360                      0x003146f3 __34-[TMDiskCache objectForKey:block:]_block_invoke (TMDiskCache.m:408)\n6  libdispatch.dylib              0x3b2710c3 _dispatch_call_block_and_release + 10\n7  libdispatch.dylib              0x3b275e7b _dispatch_queue_drain + 374\n8  libdispatch.dylib              0x3b272f93 _dispatch_queue_invoke + 42\n9  libdispatch.dylib              0x3b276745 _dispatch_root_queue_drain + 76\n10 libdispatch.dylib              0x3b2769c5 _dispatch_worker_thread2 + 56\n11 libsystem_pthread.dylib        0x3b3a0dff _pthread_wqthread + 298\n12 libsystem_pthread.dylib        0x3b3a0cc4 start_wqthread + 8\n. ",
    "rpplusplus": "I met this problem too.\nReason: * Terminating app due to uncaught exception 'NSInvalidArgumentException', reason: '* -[NSKeyedUnarchiver initForReadingWithData:]: incomprehensible archive (0x62, 0x70, 0x6c, 0x69, 0x73, 0x74, 0x30, 0x30)'\nException Type: SIGABRT \n. ",
    "kgiszczak": "I suppose so. Frankly speaking, I created this patch more than year ago and I'm not sure right now what was the purpose of this. You can close this pull.\n. ",
    "satyso": "hi\n\u54e5\u4eec\uff0c\u6211\u4e5f\u8fd9\u4e48\u6253\u7b97\u4e86\u3002\u4f46\u6700\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0cweak\u7528\u4e0d\u4e86\u3002\u6240\u4ee5\u6700\u597d\u8981\u786e\u8ba4\u662f\u5426\u9700\u8981\u4fee\u6539\u3002\n\u53e6\u5916\u4ed6\u7684backgroundtask \u6ca1\u6709\u5b89\u5168\u5224\u65ad\u3002\nsong4@163.com\nAt 2013-08-20 17:23:33,\"\u6731\u5efa\u521a\" notifications@github.com wrote:\nI want to be use it for 4.x compatible, So I want to make sure which apis below iOS 5.0 has been used?\n\u2014\nReply to this email directly or view it on GitHub.\n. ",
    "scutdavy": "you can maintain a request queue, and cancel request if the image is not needed anymore. and limit max request count as 3 or 5~\n. ",
    "bogardon": "thanks sir.\n. ",
    "Broich": "+1\n. ",
    "guptakshi16": "I do not agree on the above.  Currently objectForKey returns the object also.  The object may be in the file system which means an expensive disk read and unarchive just for the presence check.\nImagine a use case where we want to sync a local TMCache with a remote cache on the server.\nServer publishes the current list of files.  Client code iterates over the list sent by server and updates based on the server list.  In this scenario a presence check is required for all files.\n. ",
    "jamesjhu": "You can use the following pod command until a new version has been tagged:\npod 'TMCache', :git => 'https://github.com/tumblr/TMCache.git', :commit => '89c70886dd'\n. ",
    "paulrehkugler": "Nope. See Apple's docs:\n\nYou should decorate variables correctly. When using qualifiers in an object variable declaration, the correct format is:\nClassName * qualifier variableName;\nfor example:\nMyClass * __weak myWeakReference;\nMyClass * __unsafe_unretained myUnsafeReference;\nOther variants are technically incorrect but are \u201cforgiven\u201d by the compiler. (Emphasis mine)\n. shouldn't this be handleMemoryWarning?\n. heh, nevermind, i can't read split diffs apparently\n. line-wrapping. smh\n. \n",
    "ebgraham": "explicit braces are a good idea, though\n. ",
    "KanybekMomukeyev": "Solve the problem:\nUIImage *image = [[TMCache sharedCache] objectForKey:@\"ImageKey\"];\n. Thanks JSTN, \nyes, i understand that (synchronous, asynchronous).\nI editted above issue.\n. ",
    "wwpp3399": "Thanks  i have solve this problem!\ud83d\ude0a\n. ",
    "segiddins": "NSURLTotalFileAllocatedSizeKey:\nKey for the total allocated size of the file in bytes, returned as an NSNumber object (read-only). This includes the size of any file metadata.\nNSURLFileSizeKey:\nKey for the file\u2019s size in bytes, returned as an NSNumber object (read-only).\n. I think in that case that NSURLTotalFileSizeKey might be what we want then?\n. Why is this necessary, @digabriel?\n. Gotcha. In that case, should probably only be #imported in the .ms.\n. They don't belong, as the library does indeed need to enforce its own thread safety via queue confinement.\n. @jstn by default now, the warning for shadow declarations is enabled. While the code right now is functionally correct, it would be nice if it didn't use shadow declarations, if only to silence the warning.\n. @irace is, of course, correct -- presuming the dispatch queue flushes. Retaining self will, however, ensure that the block will be run, which, I believe, is the intended behavior.\n. Yes.\n. Wouldn't a better approach be to figure out what is causing the exception rather than blindly wrapping a call in a try/catch block?\n. If the issue is indeed an incomplete write, it might be better to write out to a temp dir and atomically move the completed archive.\n. Well, I don't think there's been a PR yet?\n. @irace you can still listen for the notification without referencing the shared application?\n. Nah it's a feature, so 2.1 should be sufficient \n-Samuel E. Giddins\nOn May 7, 2015, at 8:53 PM, Bryan Irace notifications@github.com wrote:\nReopened #85.\n\u2014\nReply to this email directly or view it on GitHub.\n. How?\n-Samuel E. Giddins\nsegiddins.me\n\nOn May 7, 2015, at 9:11 PM, Bryan Irace notifications@github.com wrote:\nBreaks API compatibility though?\n\u2014\nReply to this email directly or view it on GitHub.\n. No need to remove them, you can just deprecate them. \n\n-Samuel E. Giddins\nOn May 7, 2015, at 9:24 PM, Bryan Irace notifications@github.com wrote:\nI would remove the two new public methods I added in 2.0 for telling the cache that the app was backgrounds or that a memory warning occurred.\n\u2014\nReply to this email directly or view it on GitHub.\n. This gives us the recursive list of all files\n. find the 'root' directory that this file belongs to, to use for the key\n. Gets the key based upon the root file/folder for this file\n. use the modification date of the topmost directory\n. accumulate file size based upon the root object\n. ",
    "devindoty": "Looks good to me, nice work Sam. \n. ",
    "digabriel": "I have several compile errors when using TMCache on a Swift project. Kind of \"UIApplication not found\"... Is related to the background tasks started on TMDiskCache and TMMemoryCache.\nI believe that is the same kind of error that was solved with this pull request (but for Foundation): https://github.com/tumblr/TMCache/pull/53 \n. Done.\n. ",
    "mglidden": "Sorry, meant to submit this to our fork instead of tumblr. Please ignore.\n. ",
    "plivesey": "This comment also highlights the same issue:\nline 270, TMDiskCache.h\nRetrieves the file URL for the specified key. This method blocks the calling thread until the\n url is available. Do not use this URL anywhere but on the . This method probably\n shouldn't even exist, just use the asynchronous one.\n. The first comment is from line 183 in TMDishCache.h\n. I didn't notice that the disk queue was serial, but that makes a lot of sense and answers some of my other questions on how reliable GCD is for not overloading the disk. Having a shared queue definitely makes sense for this, and it also makes sense that other threads should not use the fileUrl for any reason.\nThanks for your help. Since my questions were answered, I'm going to close the issue.\n. Yeah, so I understand the motivation. But is there a specific reason why the code is not thread safe by default? It seems relatively trivial to make the in-memory cache operations atomic and the disk reading should be thread safe since NSFileManager is thread safe?\nIs it just to make the code easier to write?\n. Thanks for your help btw.\n. Haha. I'm definitely concerned with thread safety...I just was thinking that usually I expect serial methods to give control over the threading to the caller.\nHowever, I think I was wrong to think this was a good idea for a few reasons:\n1. TMCache seems to be as parallel as possible while retaining consistency.\n2. I was worried that there would be a performance hit by lots of dispatch_async calls (spinning up threads is expensive). Turns out this was misguided as dispatch_async does not create a new thread every time you call it but runs off a shared thread pool (from my understanding).\n3. The threading is more complex that I imagined, and as a caller I shouldn't assume that I can do it correctly.\nAnyway, most of this question was motivated by wanting to do batch requests quickly. I could see how the library may be able to handle batch requests in just 'one request'. As in, it doesn't need to dispatch_group and submits less blocks to GCD. The library could also expose an API method that did the grouping logic for the caller for convenience.\nHowever, from what I've read above, this doesn't seem necessary for now. I'll test it out with my use case, and if I find any performance problems that could be solved by smarter batching, I'll open another issue to discuss. I doubt that will be the case though.\nSince my question was answered, I'll close the issue for now.\nThanks.\n. ",
    "JonasGessner": "I am totally aware of the use of the weakSelf/strongSelf pattern. But I would change a few things:\n\u2022 Declaring weakSelf twice is unnecessary. The initial weakSelf is sufficient and declaring another weak reference to self is redundant.\n\u2022 In the case of strongSelf, where it really is necessary to declare it twice I would change the name of the second strongSelf. Simply call it strongSelf_ and all warnings will be gone. It will also make the code cleaner because you will immediately be able to see \"which\" of the declared strongSelf variables is accessed.\n\u2022 Or, instead of declaring strongSelf again, don't declare it again but assign the new value to the existing variable.\n. I would also recommend to use these macros to make things easier:\n```\ndefine weakSelfMake __weak __typeof(self) weakSelf = self\ndefine strongSelfMake __strong __typeof(weakSelf) strongSelf = weakSelf\n```\n. ",
    "leonskywalker": "Yeah, we were also investigating why the file is damaged. The situation is really rare but the crash reports did show up in our system. My best guess is the app might encountered a crash when writing to the disk cache previously. \nWhat makes me think it's necessary to add a try catch block is if the file is damaged, the app will always crash when reading from the cache. In my app, the reading happens right after launch, so affected users can no longer use my app. So I think it is better to at least prevent crash while we trying to discover the true cause of the problem.\n. We are using [TMCache setObject:forKey:block:] to store the data , it already writes the file atomically.\n. ",
    "chadmoone": ":+1:  We're having issues with this as well, and I was about to submit this same PR.  We aren't able to replicate directly, but it shows up in the production crash logs.  An issue was also filed for this, but closed because it couldn't be reproduced (#32).\n1. There could be a number of things that cause the file to be corrupted, and while in a perfect world we can prevent most of them, :hankey: happens.\n2. The only way to know that the data is corrupted is to attempt unarchiving, which causes a crash.\n3. Since TMCache is abstracting this, there is no other way to prevent this crash.\nI think it makes sense to protect against it here.\n. ",
    "RickDT": "Same here. \ud83d\udc4d\n. ",
    "ssoper": "+1 would love to see this implemented\n. ",
    "HardipAtWpost": "+1 that something should be done about this.  \nThe app can decide what to do w/ that \"bad\" data.  This way we aren't blindly failing silently, and the app still has a way to recover.\nThis is the #1 crash in our production app right now, and we can't do anything about it.\n. ",
    "brianmichel": "@kompw can you submit a pull request?\n. @irace this looks good, waiting to see how Travis feels.\n. Hmm, this seems odd, however TMCache is no longer in active maintenance, please see here for an alternative to satisfy your needs.\n. Wording in here is a bit weird, maybe didReceive would be better?\n. Any reason these notifications call the same selector? Seems like it should be broken out into two discreet methods if they are executing different code (which it looks like) in the singular method.\n. ",
    "devxoul": "You can set ageLimit to do this.\n. ",
    "PrideChung": "@devxoul But how can I set the age limit per object?\n. ",
    "todaylover": "Yes, I also seek the feature.  create time and last modify time is needed like mysql orm. thx\n. ",
    "prrane": "I am done with my take on this issue and raised a pull request https://github.com/tumblr/TMCache/pull/77\n. ",
    "emartynov": "+1. You can get some insights from releases tab. But text file is easier to read. As well 1.2.2 release message is \"Version bump\"\n. ",
    "bonebox": "I'm also seeing this error when using the latest AWS iOS SDK 2.0. (2.0.12) which is using TMCache 1.2.2.\n. ",
    "napoapo77": "I guess 69 tries to solve the very same issue, but is prone to deadlock if the calling thread is the same sharedTrashQueue one.\nHere it does not make any difference what calling thread you use to instantiate the sharedTrashURL.\nBTW I have also noticed one more place where object instantiation happens asynchronously and although that might be alright in practice when the object creation is well ahead of first usage and/or the hardware is decent, it eventually bombs for older hardware and/or automated tests.\n. Will find the other place and post a separate pull request for you guys to have a look.\n. Glad I could help and happy TMCache is well supported and maintained!\n. ",
    "mattbischoff": "This seems logical to me.\n. Does TMCache support being compiled with GCC?\n. Since it\u2019s iOS 5+, I\u2019d imagine it does, which means we should probably be using the technique here http://stackoverflow.com/a/9462395/114642 to check for Clang and the ability to use has_feature before using it.\n. ",
    "nzhuk": "@jstn Good point. However, there are class methods (e.g. emptyTrash and moveItemAtURLToTrash: ) which require the trash directory to exist and initializeDiskProperties is an instance method, so there's no guarantee that initializeDiskProperties would ever be executed before sharedTrashURL is accessed.\nSo, maybe calling +[TMDiskCache sharedTrashURL] in + (void)initialize method of TMDiskCache?\n. ",
    "mkauppila": "Thanks @irace. Thumbs up for the code review though I guess this PR makes most of this obsolete :)\n. ",
    "garrettmoon": "Yes, using the dispatch signal / wait methods to create synchronous versions of asynchronous methods seems to be a sure fire way to cause dead locking when threads become scarce.\n. As far as number 2 goes, relying on a queue to guard shared resources has the same issues with thread starvation. I've tried to contact Apple about this, no response.\nI'm open to the idea that I'm missing something.\n. That's correct. It can happen off the main thread too, which locks up TMCache but not the main thread.\nThis is the thing, TMCache isn't doing anything that would necessarily make threads scarce, but it's definitely possible to make threads scarce and cause this by simply calling the synchronous method a couple of times in a dispatch_async. This is obviously a contrived example, but it exposes the issue.\nI'm of the opinion that a library shouldn't expose a way to allow users to shoot themselves in the foot like this. As a developer, I should be able to dispatch as many operations as I want without having to worry about this type of thing. I shouldn't have to marshal the number of things I'm putting on disparate queues in my application. I.e. I could create an operation queue to limit the number of calls I put into TMCache to some arbitrary number, but if I have a library elsewhere that has the same pattern, I'll have to marshal that one in conjunction with TMCache. On top of all of this, grand central doesn't guarantee a number of available threads.\nBasically, it seems unsafe to lock resources with queues.\n. I know. I thought the same thing when I read that.\n. Like I said, I could be wrong about all this, I'm open to that idea. But. Give my integration test a try on the library as is. \n. When you try out testDeadlocks, be sure to pause and check out the stack trace. You'll notice bunches of threads all waiting.\n. Although, rereading the document, it says you should be using dispatch_semaphores, not queues to regulate resources. If, instead of pthread locks a dispatch_semaphore was used, that might not cause this issue. I decided on pthread so that I could use a read/write lock.\n. Thanks for catching that on the test, I updated it :)\nSo, I can tell you that switching to asynchronous methods wrapping synchronous was the first thing I tried (now I wish I hadn't squashed my commits). It may alleviate, but won't fix the issue.\nI can't address the 'making even broader changes to the codebase' issue, I understand this is a frustratingly large change.\nI can address the lack of knowledge about pthreads though, it's very simple to switch to dispatch_semaphores. In fact, I tried that out and it surprisingly seems to perform better than pthreads. With this change, the performance is nearly what it was originally (it performs ~2.65% slower than using queues). This is what the Apple docs actually recommend, not queues. I've pushed this change.\nAnyway, I understand the desire to not rewrite half the library. Let me know what you all decide :)\n. Hmm, it's still significantly different from the PR on #37. Sadly, in our testing, that PR isn't even thread safe. It also won't solve the underlying issue entirely. We've decided that you're right, forking is probably best for all involved. You can read more about it here:\nhttp://engineering.pinterest.com/post/112057905219/open-sourcing-pincache\n. @irace Whoops, I went too far trying to make sure I wasn't treading on existing TM's. New README indicates that it's a fork in the first sentence. Sorry about that!\n. Entirely unintentional. I forked, moved to a private repo to work on internally and published from their. Apparently something got lost in the transition?\n. Sadly, no, it doesn't encompass all the changes because I realized the same issues, while likely encountered less frequently, could affect the disk cache. In making those changes, I was required to modify the public facing APIs.\nSo, the original pull request encompasses most of the changes and would address the issue in probably all but extreme circumstances. It probably also needs a bit of cleanup. Would you like me to open up a new pull request with them (I can't reopen the old, I removed my repo)?\nIt seems more prudent to simply point people who are seeing the issue to PINCache and not force others through the change?\n. I'll speak with my colleagues about prioritizing the work.\n. Hey Bryan,\nSpoke with my colleagues: I'm happy to send you the original patch, but our position is we'd rather contribute to the OS community by working on PINCache. So it will be as is and we'd ask that you all make the effort to review and fix any issues and deal with the pull request. Feel free to send me an email if you'd like to pursue this, I'll reply with the diff.\n. ",
    "liuliu": "Is the underlying problem the GCD has a upper limit on how many threads it manages, therefore, we can reach that limits by dispatch a lot waiting blocks on global concurrent queue?\nIt seems that this suggests everyone to use serial queue throughout their implementations, otherwise if you are loading 1,000 images on the global concurrent queue, you may have a lot problems yourself (and really, why you want to do that?).\n. To be more specific, you can pass the test case @garrettmoon provided:\n```\n- (void)testDeadlocks\n{\n    NSString *key = @\"key\";\n    NSUInteger objectCount = 1000;\n    [self.cache setObject:[self image] forKey:key];\n    dispatch_queue_t testQueue = dispatch_queue_create(\"test queue\", DISPATCH_QUEUE_CONCURRENT);\nNSLock *enumCountLock = [[NSLock alloc] init];\n__block NSUInteger enumCount = 0;\ndispatch_group_t group = dispatch_group_create();\nfor (NSUInteger idx = 0; idx < objectCount; idx++) {\n    dispatch_group_async(group, testQueue, ^{\n        [self.cache objectForKey:key];\n        [enumCountLock lock];\n        enumCount++;\n        [enumCountLock unlock];\n    });\n}\n\ndispatch_group_wait(group, [self timeout]);\nSTAssertTrue(objectCount == enumCount, @\"was not able to fetch 1000 objects, possibly due to deadlock.\");\n\n}\n```\nby doing:\n```\n- (void)testDeadlocks\n{\n    NSString *key = @\"key\";\n    NSUInteger objectCount = 1000;\n    [self.cache setObject:[self image] forKey:key];\n    dispatch_queue_t testQueue = dispatch_queue_create(\"test queue\", DISPATCH_QUEUE_CONCURRENT);\n    dispatch_set_target_queue(testQueue, dispatch_get_global_queue(0, 0x2ull));\nNSLock *enumCountLock = [[NSLock alloc] init];\n__block NSUInteger enumCount = 0;\ndispatch_group_t group = dispatch_group_create();\nfor (NSUInteger idx = 0; idx < objectCount; idx++) {\n    dispatch_group_async(group, testQueue, ^{\n        [self.cache objectForKey:key];\n        [enumCountLock lock];\n        enumCount++;\n        [enumCountLock unlock];\n    });\n}\n\ndispatch_group_wait(group, [self timeout]);\nSTAssertTrue(objectCount == enumCount, @\"was not able to fetch 1000 objects, possibly due to deadlock.\");\n\n}\n```\nWhich will enable the overcommit behavior on the testQueue, and GCD will actually create enough threads to cope this particular situation. I am not sure why OVERCOMMIT (the 0x2ull paramter maps to https://libdispatch.macosforge.org/trac/browser/trunk/private/queue_private.h#L46) is not the default behaviour from GCD designers, but they may have some very good reasons. Can someone file a rdar to get clarification from GCD designers?\n. ",
    "ljfantin": "But, You are using TMCacheMemory in this case\nI want to use TMCache with cost limit.\nIs possible ?\n. ",
    "cyril94440": "It seems that everything is working correctly until I reboot the app. Any clue ?\n. ",
    "medvedNick": "I've encountered the same behavior.\nIf you look at - (id)objectForKey:(NSString *)key method of TMCache which calls - (void)objectForKey:(NSString *)key block:(TMCacheObjectBlock)block, you'll see that the first method sets dispatch_semaphore_t semaphore which is unlocked in the completion of the second method.\nHowever, not every branch of the second method calls completion block. That causes deadlock on the whole thread.\nI am not able to say if it is mistake in my code or in TMCache, but this might be helpful for whoever will be stuck at staring at tons of deadlocked threads in debugger like me.\n. ",
    "akkyie": "I'm sorry for my carelessness. I sent my CLA.\nAnd thank you for your quick response!\n. ",
    "vincentmac": "Anyone looking at this PR?\n. ",
    "xinjixjz": "\nTheoretically, we should call the block in every condition branches, because we should notify caller that the work has been done;\nIf user's some requirements depend on setObject:forKey:block block callback (but object or key is nil), then the block will never be called, which will cause some problems.\nFor example:\n\n``` objective-c\n- (void)deadLockMethod\n{\n    __block id objectForKey = nil;\n    dispatch_semaphore_t semaphore = dispatch_semaphore_create(0);\n// user should wait the signal, but the key is nil and then block will never be called.\n[[TMCache sharedCache] objectForKey:nil block:^(TMCache *cache, NSString *key, id object) {\n    objectForKey = object;\n    dispatch_semaphore_signal(semaphore);\n}];\n\ndispatch_semaphore_wait(semaphore, DISPATCH_TIME_FOREVER);\n\n}\n```\n. It is just a example, my point is library should consider the exception input, and the asynchronous APIs should notify caller in all conditions including exception conditions.\nAdditionally,  in the synchronous  APIs, the key and object will be set to nil in other thread and block will never be called, which will cause deadlock.\nAny way, I think a robust library should consider exception input!\n. ",
    "lhyhsx": "@xinjixjz \u8fd9\u4e2a\u63d0\u4ea4\u633a\u597d\u554a\uff01\u4ed6\u4e0d\u7ed9\u4f60\u5408\u5e76\uff0c\u53ef\u60dc\u4e86\u3002\n. ",
    "SudeepSidhu": "I opened an issue for this (with the fix) a while back, https://github.com/tumblr/TMCache/issues/42\nGuess I should do a PR?\n. Sure thing, done!\n. ",
    "vietstone-ng": "wow, why hasn't that fix been added after a long time? :D\n. ",
    "luoyibu": "Yes, you are right. I know that I should ensure the thread safe of NSArray by myself, and I also know how to get it by GCD.\nBut what I was discussing about is that can we get this for the users who are not familiar with thread safe.   Or, just encapsulate the functionality that keep objects came from TMCache to be thread safe.\nI just want to get some advice if it was possible.\n. ",
    "studentdeng": "Thanks for quick reply. I think handle memory warnings is the default behaviour for Cache  which is 1.0 before. The 2.0 strategy is a bit unusual. I think it would be better if it is noticed in README.md, not only in release change log.\n. ",
    "Pearapps": "This lgtm\n. ",
    "blankyao": "TMCache is a good choice, and with TMCache, you don't need to implement NSCoding protocol by yourself.\n. ",
    "DRosadoYew": "Will do. Thank you\n. ",
    "LiVincent-Zhang": "When dose TMCache generates the .dat.nosync file ?. It caused by long file name.. "
}