{
    "Natim": "Thanks.\n. It depends what default means, for me default are to help the dev to get started. Not default configuration for production.\nMaybe the answer is not the same for kinto and cliquet on this. But IMHO the default should be something easier to setup than postgresql.\n. Btw on defaut Redis configuration, persistence on disk is activated.\n. r+\n. :)\n. r+\n. r+\n. Cool\n. Related to https://github.com/Pylons/waitress/issues/91\nNot sure of how to fix waitress with this.\n. I continued to investigate this issue.\nThe result is that with Python2 is waiting for bytes and with Python3 for unicode strings.\nIt looks like a bug to me since it make us do unwanted conditions to handle both cases. I am not sure of how I can reach out to waitress and webob devs to fix this.\n. For kinto the default backends are postgresql.\nThe documentation explains how this can be changed.\n. Related to #163 \n. Do we want to rename the command first ?\n. > whoever can update a record can change its associated permissions.\nYes\n\nanybody who can read actually can share\n\nIt might be true to add someone but what about read/write and removing someone?\n. # Some use cases\nPayments\nFor the payment use case we have three players involved:\n- The payment app that stores payments for users\n- The selling app that can read records of the given app\n- The user that can read its records\nA record would be stored like that:\n{\"shared_principals\": [\"user:me\", \"app:sellingapp\"],\n \"year\": 2015, ...}\nThe collection would be /buckets/concrete/collections/payments\nPermissions on the collection would be:\n{\n  \"scope:payments\": [\"read_shared_records\"],\n  \"scope:sellingapp\": [\"read_shared_records\"],\n  \"scope:paymentapp\": [\"ALL\"]\n}\nThen,\n- the sellingapp can GET /buckets/concrete/collections/payments/records and will get back all records that are shared with it.\n- the user using the payments scope can  GET /buckets/concrete/collections/payments/records and will get back all records that are shared with her.\n- the paymentapp can access /buckets/concrete/collections/payments/records and will have all the records.\nBlog\nWe can also give them ALL access to the blog collection:\n```\nPATCH /buckets/servicedenuages/collections/blog\n{\n  \"permissions\": {\n    \"user:natim@example.com\": [\"+ALL\"]\n  }\n}\n```\nTwitter\nCollection is isolated, CRUD your own records and ready everyones tweets.\nThe CRUD only if by default because natim is owner of the natim bucket.\nWe can add the Everyone read_all_records permissions:\n```\nPATCH /buckets/natim/collections/tweets\n{\n  \"permissions\": {\n    \"Everyone\": [\"+read_all_records\"]\n  }\n}\n```\nDo we want something like: GET /buckets/*/collections/tweets to read all shared buckets? I am not quite sure about it.\nWiki\n```\nPATCH /buckets/natim/collections/wiki\n{\n  \"permissions\": {\n    \"Everyone\": [\"read_all_records\", \"update_all_records\", \"delete_all_records\", \"create_records\"]\n  }\n}\n```\nCompany Private Wiki\n```\nPATCH /buckets/company/collections/wiki\n{\n  \"permissions\": {\n    \"bucket:company\": [\"ALL\"]\n  }\n}\n```\n. > I don't understand what is the concept of \"shared_principals\" you introduced, and I believe we don't need to have the concept of sharing exposed at all in our APIs.\nThe name is maybe not the right one, but it is the list of principals having access to the record using the collection read_shared_records permissions.\n. > For each record, it's possible to push the associated permissions. If R\u00e9my wants \"Severine\" and \"Alexis\" to edit posts about music, then he needs to add them to all the records that are talking about music to add them to the permissions.\nYes I agree about the group concept, we can add a new category of principals for it.\nWhat I had in mind was to create a bucket musicians with Alexis and Severine in it and add the bucket:musicians to all the records that need it.\n. > Here, \"access\" is not defined enough. What does that mean? Which permissions?\nIt depends of the permissions you've put on the collection containing the record.\nIf you've got {'bucket:musicians': [\"read_shared_records\", \"update_shared_records\"]} and on the record {\"shared_princiapls\": [\"bucket:musicians\"]} then it means having read and update access but not deletion.\n. > Then it means that users can obtain different principals depending on which collection they're acting\nI was thinking having group accross all users and collections but I remember we had policies, in Daybed before, letting us do per collections groups.\nMaybe what we need is bucket's groups as does github with Organization teams.\n. > Rather than defining the relation with \"principal \u2192list of permissions\" we could do it backwards \"permissions \u2192 list of principals\".\nRemember on Daybed we store it as your new format and on the API side it wasn't efficient so that we did the reverse on the API side.\n. > Sorry, I find this API proposal cryptic. \"shared\" should reflect a state and records don't have a \"shared: true/false\" attribute.\nYes please change the wording, is related_principals better/enough?\n. Or even principals maybe?\n. Here is what I summarize about buckets, collections and groups following our discussions: https://github.com/mozilla-services/kinto/pull/36/files\n. What I was thinking is to use the bucket list of user as a principal.\nThe principal bucket:servicedenuages means all people admin of the bucket servicedenuages\n. This have been discussed and implemented.\n. Is the close an answer to the question?\n. git pull\n. Looks good to me. ~~It may also fix: #158~~ (actually it doesn't yet.)\n. Currently the Cliquet Protocol defines object's attributes to be in the data attributes.\nIt is also a vision shared with JSON-API specification.\nIn this implementation, we are just providing a new property to the collection which is the schema.\nOther property may come such as signing, description, title.\nHaving them all in the data attribute makes sense because schema is finally a collection attribute and we do not have to change the protocol to handle it.\n. However, as for permissions we could say that schema is a specific attribute that must not be inside the data attribute and that we should keep data attribute for arbitrary application specific data.\nWhat I like in the implemented solution, is that we do not have to change the protocol and make a special case for that.\n. r? @ametaireau @leplatrem \n. Following our conversation, I think we have:\n- parent_id which is the object_uri of the parent ie: /buckets/<bucket_id/collections/<collection_id>\n- collection_id should be resource_name or object_type and contains the object type ie: record, collection, bucket\n. We will for each release of kinto for now on.\n. Superseeded by #62 \n. I changed the tests to reflect the expected behavior with the cliquet change in mozilla-services/cliquet#397\n. Needs https://github.com/mozilla-services/cliquet/pull/398\n. Ah well as collections:create\n. This has been done already: https://github.com/mozilla-services/kinto/commit/c5e01827f06a5c391615edb3779fa77135c3b395\n. This is something we want at least for the default bucket.\n. Actually we could have both:\n- A default one where everybody could create collection and when looking for /buckets/default/collections will get only its collection\n- A personal one created automatically for him ('~' or 'personal')\n. This is really important for cliquetis.\n. My first go was actually to modify the bucket and collection view to create the bucket and the collection if they didn't exists yet.\nBut this was meaning:\n- Checking the bucket_id and collection_id are correct\n- Adding the correct permissions\nMaybe it worth to try to do it your way anyway.\n. I have uncommented the note in the docs/api/collections\n. IMHO documentation about it could be enough.\n. Fixed with https://github.com/mozilla-services/kinto/pull/81/files\n. - [ ] Introduce notions of principals in the storage backend\nFor the two other point, if the user have the create permission to add thing in the list, we can deduce that he might have created things, and then return an empty list.\n. Yes but in case they have the create permission we want to display an empty list rather than a 403\n. r? @leplatrem \n. I am rebasing, can you add me to your repository?\n. Should we remove test files from coverage?\n. See https://travis-ci.org/mozilla-services/kinto/builds/68545912\n. Refs: https://github.com/schlamar/pytest-cov/issues/56\n. We did something like that for OneCRL: https://github.com/mozilla-services/xml2kinto\nIt could be a start to generalize.\n. I would rather create a script in a distinct repository and with a distinct release workflow because I do not want people to have to install Kinto and all its dependencies just to import/export from kinto.\nI have created https://github.com/Kinto/kinto-setup (We may want to rename it into kinto-dump at some point)\nI'd like to have something that POST on the batch endpoint to setup the kinto service and that can also take a list of resources to generate the export.json file that can then be passed as a BATCH.\nI will keep you posted.\n. This is even more useful with the new kinto-admin.\nWe need to let people create collection with schema, ui-schema and displayFields quite easily. I will start to think about it.\n. I have started a Blueprint here: https://github.com/Kinto/kinto/wiki/Handling-permission-on-a-Kinto-Server\n. r? @magopian \n. https://github.com/mozilla-services/kinto/releases/tag/1.1.0\n. Confirmed with Kinto 1.2\n```\n$ http GET https://kinto.dev.mozaws.net/v1/buckets --auth user:pass\nHTTP/1.1 500 Internal Server Error\nAccess-Control-Expose-Headers: Backoff, Retry-After, Alert, Next-Page, Total-Records, Last-Modified, ETag\nConnection: keep-alive\nContent-Length: 196\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 06 Jul 2015 08:30:11 GMT\nServer: nginx/1.4.6 (Ubuntu)\n{\n    \"code\": 500, \n    \"errno\": 999, \n    \"error\": \"Internal Server Error\", \n    \"info\": \"https://github.com/mozilla-services/cliquet/issues/\", \n    \"message\": \"A programmatic error occured, developers have been informed.\"\n}\n```\n. This commit fixes the 500 but doesn't fix the fact that any user can query the list of buckets.\nMy next commit will make a test fail.\n. I think we should discuss this issue.\nI am pretty sure it is not what we want.\nI think we should deactivate this endpoint by default.\nAlso this lists user buckets and because it is listing the permissions on the bucket GET , it is easy to link a bucket to a user.\n. After discussion what we want to do is to return a 403 by default + add a documentation note to explain how to authorize somebody to call this endpoint.\n. Updated with what we've discussed.\n. r? @ametaireau @leplatrem \n. Fixed with https://github.com/mozilla-services/kinto/commit/84cb825dec791a08eb806fb006feb171361d92ee#diff-2eeaed663bd0d25b7e608891384b7298L18\n. Well for now, cliquet is not able to run without postgresql. See mozilla-services/cliquet#340\n. r? @leplatrem \n. I wanted to write a test for that, but I don't know how to write it.\nSomething like writting a new .ini file?\n. #343 has been merged, restarting tests.\n. Also we should take a decision regarding the memory backend by default.\nIn this PR we are keeping cliquet default.\n. I see this link more as an ID of the official URI of the current resource.\nI don't understand why it bothers you that much but if you really want to remove this link the way forward is to remove the inclusion of the readme in the documentation index. Note that we may have duplicates between the README and the home page.\n. Yes it is much faster.\n. PR Updated.\n. I don't think pytest-xdist is a good idea here since test are instable with it and not that much faster :)\n. Yes see https://github.com/mozilla-services/kinto/pull/98\n. > INFO:venusian:cloud storage 0.2.1 starting.\nI think you are not running the version you think you are.\nCan you try this fix? https://github.com/mozilla-services/kinto/pull/97/files\n. I know how I can fix that :)\n. See https://github.com/mozilla-services/cliquet/pull/341\n. I didn't remove them, I tagged them for the release: https://github.com/mozilla-services/kinto/commit/30faf29432d3c99ad80997f9118a003495c10bbc\n. > about optional dependencies [...] how do we remember to restore that when releasing\nIf we need to restore them, then we should not remove them.\nThe aim is not to force postgresql dependency when installing Kinto.\n. I have restored the dependencies for now.\nhttps://github.com/mozilla-services/kinto/commit/64794fdd11356937fdd551b0d20eaa552a4f031e\n. Discussion can takes place here: https://github.com/mozilla-services/kinto/issues/89\n. It works :)\n. Done :+1: \n. Updated.\n. > Workaround: use two collections: one for the schema, one for the records.\nThis means that you need to create a collection with a JSONSchema validator to validate that the schema you enter in the form list is valid.\n. For now we are using UUID but we plan to let the server administrator configure it with https://github.com/mozilla-services/cliquet/issues/292 in the future.\n. Basically in the code of Kinto we are sometimes building URLs.\n- https://github.com/Kinto/kinto/blob/master/kinto/views/records.py#L35\n- https://github.com/Kinto/kinto/blob/master/kinto/views/records.py#L47-L48\n- https://irccloud.mozilla.com/pastebin/69teBJGJ\n- https://irccloud.mozilla.com/pastebin/1bWBKhLm\nInstead of building this URLs by hand we would like to use route_path to do it.\nYou can have a list of all the URLs and there name by running: .venv/bin/proutes config/kinto.ini (once you've installed Kinto)\nFor instance '/buckets/%s/collections/%s' % (self.bucket_id, self.collection_id) could be written: route_path('collection-record', bucket_id=self.bucket_id, collection_id=self.collection_id)\nroute_path may return the /v1/ prefix in front so we may have to create an helper that will remove it. But that's the idea.\n. Here is my alternative proposal: https://github.com/mozilla-services/kinto/commit/8107941d92066ff346e21e04588b39da801dad0b\n. This is still better that what we had.\n. In Syncto we chose to install monitoring tools as part of the project: https://github.com/mozilla-services/syncto/blob/master/setup.py#L17\nBut it is not as easy for Kinto.\nI think the best way to handle that is to copy the monitoring and postgresql options from cliquet to kinto. (We can also choose to keep them in cliquet as well)\n. r+ with nit (I think we should keep only one value for ETag)\n. I merge and I will update the http calls with 1.2 reality.\n. Thank @andymckay \n. I have updated the server and I don't have any 403 anymore. Please reopen if you still see a problem.\n```\n$ http GET https://kinto.dev.mozaws.net/v1/buckets/default/collections/tasks/records -v --auth 'user:password'\nGET /v1/buckets/default/collections/tasks/records HTTP/1.1\nAccept: /\nAccept-Encoding: gzip, deflate\nAuthorization: Basic dXNlcjpwYXNzd29yZA==\nConnection: keep-alive\nHost: kinto.dev.mozaws.net\nUser-Agent: HTTPie/0.9.2\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Backoff, Retry-After, Alert, Next-Page, Total-Records, Last-Modified, ETag\nBackoff: 10\nConnection: keep-alive\nContent-Length: 11\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 06 Jul 2015 08:21:21 GMT\nETag: \"1436170881918\"\nLast-Modified: Mon, 06 Jul 2015 08:21:21 GMT\nServer: nginx/1.4.6 (Ubuntu)\nTotal-Records: 0\n{\n    \"data\": []\n}\n```\n. you are right, collections list are not ordered. But records are.\n. What we could do is to remove it if present and shouldn't with a 307.\nThe goal was to have only one way to name resources, we chose not to have a trailing slash.\n. Confirmed with Kinto 1.2\n```\nGET /v1/buckets/default/collections/tasks/records?_since=1436172070772 HTTP/1.1\nAccept: /\nAccept-Encoding: gzip, deflate\nAuthorization: Basic dXNlcjpwYXNzd29yZA==\nConnection: keep-alive\nHost: kinto.dev.mozaws.net\nUser-Agent: HTTPie/0.9.2\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Backoff, Retry-After, Alert, Next-Page, Total-Records, Last-Modified, ETag\nBackoff: 10\nConnection: keep-alive\nContent-Length: 182\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 06 Jul 2015 08:49:38 GMT\nETag: \"1436172501156\"\nLast-Modified: Mon, 06 Jul 2015 08:48:21 GMT\nServer: nginx/1.4.6 (Ubuntu)\nTotal-Records: 2\n{\n    \"data\": [\n        {\n            \"id\": \"f90c266f-7425-49b4-b2dc-3b242a3cea99\", \n            \"last_modified\": 1436172070772, \n            \"title\": 2\n        }, \n        {\n            \"id\": \"6c5f255d-65cf-4eec-a0ee-4c1132b19f15\", \n            \"last_modified\": 1436172059952, \n            \"title\": 1\n        }\n    ]\n}\n```\n. I can confirm that the 304 is now returned.\n```\nhttp GET https://kinto.dev.mozaws.net/v1/buckets/default/collections/tasks/records?_sort=title   \"If-None-Match\":'\"1436172501156\"'          -v --auth 'user:password'\nGET /v1/buckets/default/collections/tasks/records?_sort=title HTTP/1.1\nAccept: /\nAccept-Encoding: gzip, deflate\nAuthorization: Basic dXNlcjpwYXNzd29yZA==\nConnection: keep-alive\nHost: kinto.dev.mozaws.net\nIf-None-Match: \"1436172501156\"\nUser-Agent: HTTPie/0.9.2\nHTTP/1.1 304 Not Modified\nConnection: keep-alive\nDate: Mon, 06 Jul 2015 11:38:53 GMT\nETag: \"1436172501156\"\nLast-Modified: Mon, 06 Jul 2015 08:48:21 GMT\nServer: nginx/1.4.6 (Ubuntu)\n```\n. Confirmed with Kinto 1.2\n```\n$ echo '{\n        \"permissions\": {\n            \"read\": [\"basicauth:a103c2e714a04615783de8a03fef1c7fee221214387dd07993bb9aed1f2f2148\"]\n        }\n    }' |     http PATCH https://kinto.dev.mozaws.net/v1/buckets/todo/collections/tasks/records/3cfddb63-4cfc-46fa-96bc-16389a7c1ea3         -v --auth 'alice:alicepassword'\nPATCH /v1/buckets/todo/collections/tasks/records/3cfddb63-4cfc-46fa-96bc-16389a7c1ea3 HTTP/1.1\nAccept: application/json\nAccept-Encoding: gzip, deflate\nAuthorization: Basic YWxpY2U6YWxpY2VwYXNzd29yZA==\nConnection: keep-alive\nContent-Length: 142\nContent-Type: application/json\nHost: kinto.dev.mozaws.net\nUser-Agent: HTTPie/0.9.2\n{\n    \"permissions\": {\n        \"read\": [\n            \"basicauth:a103c2e714a04615783de8a03fef1c7fee221214387dd07993bb9aed1f2f2148\"\n        ]\n    }\n}\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Backoff, Retry-After, Alert\nBackoff: 10\nConnection: keep-alive\nContent-Length: 230\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 06 Jul 2015 08:52:56 GMT\nServer: nginx/1.4.6 (Ubuntu)\n{\n    \"data\": {\n        \"description\": \"Alice task\", \n        \"id\": \"3cfddb63-4cfc-46fa-96bc-16389a7c1ea3\", \n        \"last_modified\": 1436172719862, \n        \"status\": \"todo\"\n    }, \n    \"permissions\": {\n        \"write\": [\n            \"basicauth:9be2b51de8544fbed4539382d0885f8643c0185c90fb23201d7bbe86d70b4a44\"\n        ]\n    }\n}\n```\n. r? @ametaireau @leplatrem \n. It depends what we want to run in stage because the idea is to run test_all in stage.\nAlso I can add a test_simulation and test_tutorial rule in travis if it makes sense.\n. We can run them sequentially. I did in the .travis.yml file also our OPS likes to run a unique loadtest for stage. It helps them, this is the reason why we mix them in test_all The mixin approach is the one I found to be able to split tests in differents files and reuse some of the methods.\n. r? @leplatrem \n. Adding the necessary code.\n. r? @ametaireau @leplatrem \n. I wonder if we shoudn't do the same for 409 Conflict\n. :+1: \n. This is because the tasks list need to be completed after the effective release\n. One thing we had in mind is also to use a kinto interface for storage service providers (such as Box.net/Dropbox, BaiduYun)\n. After discussion the basic idea would be the following:\n- To use your personal bucket, FxA gives you the URL of your personnal storage server (you are always using it)\n- You can create a bucket on any server (could be yours) but when you share it you need to share the full URL (including the server hostname)\nAn idea could be to use a kinto router that gives back HTTP 307 with the right URL for a given personal bucket.\n. :+1: \n. On Kinto side we are not using BrowserId but Bearer Token for FxA.\n. > we might also fallback to a repository (operated by mozilla) where users link to their kinto instance.\nIt is what I had in mind, we could operate this repository using a Kinto server.\n. My take on this, is to be able to talk to any kinto server and access your data.\nOne way to do so would be to use https://ipfs.io/ Read this article\n. r? @n1k0 \n. pip install -Ue .\n. I have updated my test but if you want to try my branch you should not us the kinto.dev instance.\n. ```\n$ http OPTIONS http://localhost:8888/v1/buckets/default/collections/tasks/records Origin:http://0.0.0.0:8080 Access-Control-Request-Method:GET Access-Control-Request-Headers:authorization,content-type\nHTTP/1.1 200 OK\nAccess-Control-Allow-Headers: Retry-After,Last-Modified,Total-Records,ETag,authorization,content-type,Backoff,Next-Page,Alert\nAccess-Control-Allow-Methods: GET,HEAD,POST,DELETE,OPTIONS\nAccess-Control-Allow-Origin: *\nAccess-Control-Max-Age: False\nContent-Length: 4\nContent-Type: application/json; charset=UTF-8\nDate: Wed, 08 Jul 2015 15:31:46 GMT\nServer: waitress\n```\n. - We should add a functional test in the turorial when fixing this. See https://github.com/mozilla-services/kinto/blob/118-test-tutorial/loadtests/loadtest/tutorial.py\n. This has been fixed with Cliquet 2.10.0\n. We have the same problem with the postgresql backend.\nThis PR is probably going to fix this: https://github.com/mozilla-services/cliquet/pull/361\n. - [x] Update the Kinto loadtest when fixing this - https://github.com/mozilla-services/kinto/blob/118-test-tutorial/loadtests/loadtest/tutorial.py#L301\n. Fixed with https://github.com/mozilla-services/cliquet/pull/361 and https://github.com/mozilla-services/cliquet/pull/381\n. r? @n1k0 \n. To review accurately:\n- Drop your venv\n- Checkout the last tag and run make serve\n- Checkout master\n- try to run make serve\nWithout this patch the last point fails. With this patch it should works :)\n. We did it for cliquet (https://github.com/mozilla-services/cliquet/commit/9d050be365ac496c259af8947e7f8ed3c78004cc) but we didn't for Kinto yet.\n. Updated.\n. r? @leplatrem \n. We should use the reapply_cors decorator on the default pyramid view.\n. You can reproduce on 304:\n$ http \"http://0.0.0.0:8888/v1/buckets/default/collections/articles/records?_since=1436524796357\" \\\n    Origin:localhost:8000 --auth=user:pass\n. :+1: \n. Same problem if you:\n- DELETE the bucket\n- Recreate the bucket\n- Recreate the collection\n- check for tombstones (they are presents)\n. Same for collections.\n$ http GET http://localhost:8888/v1/buckets/default/collections/tasks/records?_since=1436786412344 --auth user:pass\n$ http DELETE http://localhost:8888/v1/buckets/default --auth user:pass\n$ echo '{\"data\": {}}' | http PUT http://localhost:8888/v1/buckets/default --auth user:pass\n$ http GET http://localhost:8888/v1/buckets/default/collections?_since=1234 --auth user:pass\n. Needs mozilla-services/cliquet#400 to be merged first.\n. r? @leplatrem @ametaireau \n. We should use a configuration variable here: https://github.com/mozilla-services/cliquet/blob/master/cliquet/views/errors.py#L104\n. Refs: https://github.com/mozilla-services/cliquet/issues/385\n. It has been merged.\n. ping @mostlygeek @Micheletto @deanwilson \n. I just updated the ELB certificate everything should work as expected. Next update in July 2017\n. Could you link the previous discussion issue?\n. If you wish to have a 409 or something telling you that the record already exists, you should use the If-None-Match: * header in that case the record will be created only if it doesn't already exists.\n. This is because you are installing cliquet master with kinto 1.3.1 that should be using cliquet 2.3.1 https://github.com/mozilla-services/kinto/blob/1.3.1/setup.py#L24\n. If you want to use cliquet master, you should use kinto master as well.\n. > from the git tag\n\nI think our dev-requirements.txt is installing cliquet master.\n\nWe should not use install-dev for this tests.\n. I have a fix here: https://github.com/mozilla-services/kinto/pull/143\n. It wont fix the 1.3.1 tag but it will be fixed for next release. We'll also remove the github link in dev-requirements during releases.\n. there are no mention of make serve in the contributing part and this fix a bug in the installation part when using make serve with a tag.\n. IMHO, the good place for deployment request is Bugzilla. I put it here because I wanted @kumar303 and @andymckay to be able to follow.\n. > This felt more like a tutorial than a http reference. \nSo maybe the current tutorial is enough?\n. Or should we move it in a tutorial section?\n. The server restarted and I had to restart uwsgi processes: https://kinto.dev.mozaws.net/v1/\n. This is something that has been fixed in cliquet.\n. There is one in cliquet: https://github.com/mozilla-services/cliquet/blob/master/cliquet/tests/test_views_errors.py#L25-L34\nDo you want me to duplicate it for Kinto? I didn't thought it was useful because Backoff is completly handled on Cliquet side (there are no trace of it in Kinto code.)\n. r+ :+1: \n. LGTM with nit. I like it to be in the configuration section.\n. Tests needs to be restarted after mozilla-services/cliquet#411 merge.\n. Restarting tests now that cliquet PR has been merged.\n. The good thing behind that is that then it is possible to share things with people that doesn't use the application yet.\n. So after having discuss this with @leplatrem I am going to implement it like this:\n- PATCH can let you change some fields of a resource, but the value is immutable\nThis means that the new PATCH will replace the permission list with the new one.\n``` http\n$ echo '{\"permissions\": {\"read\": []} }' | http PATCH http://127.0.0.1:8888/v1/buckets/todo/collections/tasks/records/2b2fd6ad-5521-46d5-8712-5a27e42dd31f -v --auth 'alice:alicepassword'\nPATCH /v1/buckets/todo/collections/tasks/records/2b2fd6ad-5521-46d5-8712-5a27e42dd31f HTTP/1.1\nAccept: application/json\nAccept-Encoding: gzip, deflate\nAuthorization: Basic YWxpY2U6YWxpY2VwYXNzd29yZA==\nConnection: keep-alive\nContent-Length: 31\nContent-Type: application/json\nHost: 127.0.0.1:8888\nUser-Agent: HTTPie/0.9.2\n{\n    \"permissions\": {\n        \"read\": []\n    }\n}\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Backoff, Retry-After, Alert, Content-Length\nContent-Length: 316\nContent-Type: application/json; charset=UTF-8\nDate: Tue, 04 Aug 2015 21:24:32 GMT\nEtag: \"1438722779308\"\nLast-Modified: Tue, 04 Aug 2015 21:12:59 GMT\nServer: waitress\n{\n    \"data\": {\n        \"description\": \"Alice task\",\n        \"id\": \"2b2fd6ad-5521-46d5-8712-5a27e42dd31f\",\n        \"last_modified\": 1438722779308,\n        \"status\": \"todo\"\n    },\n    \"permissions\": {\n        \"write\": [\n            \"basicauth:9be2b51de8544fbed4539382d0885f8643c0185c90fb23201d7bbe86d70b4a44\"\n        ]\n    }\n}\n```\nIt seems to be the behavior @brunobord was expecting.\n. r+\n. > I would have put them in 2 separate places: {data: {}, metadata: {email: \"ilove@pancakes.com\"}. metadata would be a read-only system-managed property container.\nI agree that this should be the path forward for that.\nI would also let people set metadata in their payload for validation.\ni.e, the system-side generated value should be equal to the provided one for the server to accept the payload. (email/signing)\n. Yes I think it is the good time to break the protocol.\nThe validation is orthogonal it was just me having some ideas about the read-only proposal.\nThe question is what about the id?\nOn a PUT should it be on both data and metadata? Or should we add it back on data on server side if we need it (let say for signing for instance)\n. I just realised that this post is about allowing data on buckets and collections I thought this was already the case.\n. ```\n$ echo '{\"data\": {\"signing\": \"hash\"}}' | http PUT https://kinto.dev.mozaws.net/v1/buckets/default/collections/tasks --auth user:pass\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Backoff, Retry-After, Alert, Content-Length\nConnection: keep-alive\nContent-Length: 156\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 24 Aug 2015 13:18:31 GMT\nETag: \"1440422311022\"\nLast-Modified: Mon, 24 Aug 2015 13:18:31 GMT\nServer: nginx/1.4.6 (Ubuntu)\n{\n    \"data\": {\n        \"id\": \"tasks\", \n        \"last_modified\": 1440422311022\n    }, \n    \"permissions\": {\n        \"write\": [\n            \"basicauth:631c2d625ee5726172cf67c6750de10a3e1a04bcd603bc9ad6d6b196fa8257a6\"\n        ]\n    }\n}\n```\nSigning is lost during the operation.\n. Yes :+1: \n. r? @ametaireau \n. ``` http\n$ echo '{\"data\": {\"signing\": \"hash\"}}' | http PUT http://localhost:8888/v1/buckets/default/collections/tasks --auth user:pass -v\nPUT /v1/buckets/default/collections/tasks HTTP/1.1\nAccept: application/json\nAccept-Encoding: gzip, deflate\nAuthorization: Basic dXNlcjpwYXNz\nConnection: keep-alive\nContent-Length: 30\nContent-Type: application/json\nHost: localhost:8888\nUser-Agent: HTTPie/0.9.2\n{\n    \"data\": {\n        \"signing\": \"hash\"\n    }\n}\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Backoff, Retry-After, Alert, Content-Length\nContent-Length: 173\nContent-Type: application/json; charset=UTF-8\nDate: Fri, 28 Aug 2015 12:52:35 GMT\nEtag: \"1440766355961\"\nLast-Modified: Fri, 28 Aug 2015 12:52:35 GMT\nServer: waitress\n{\n    \"data\": {\n        \"id\": \"tasks\", \n        \"last_modified\": 1440766355961, \n        \"signing\": \"hash\"\n    }, \n    \"permissions\": {\n        \"write\": [\n            \"basicauth:631c2d625ee5726172cf67c6750de10a3e1a04bcd603bc9ad6d6b196fa8257a6\"\n        ]\n    }\n}\n```\n. > We hadn't identified the need to store data on buckets so far, but we can add it if you have a use case for it?\nAgreed on my side, but good catch.\n. I totally agree about that. @magopian any ideas?\n. > Step by Step Permission tutorial is given twice after First Steps with kinto tutorial.\nYes I have seen that, any idea of why?\n. r? @tarekziade @greeshmab \n. Cool.\n. Works for me.\n. I closed because your answer answered my question.\nWe can rename the issue to implement Quota in Kinto but as we don't have the use case yet we can also create a new one then.\n. I would go for the per collection quota and then if we want a per bucket quota it can just be the sum of all per collection quota.\n. After discussing that with @tarekziade over IRC, tarek's proposition is to add the value alongside with id and last_modified:\n{\n  \"id\": \"certificates\",\n  \"last_modified\": 1470061473832,\n  \"items_count\": 2,\n  \"storage_size\": 400\n}\n. The solution, is to do the following:\n/usr/bin/pypy setup.py bdist_wheel\nmv cliquet-2.5.0-{py2.py3,pp2-pp3}-none-any.whl\ntwine upload cliquet-2.5.0-pp2.pp3-none-any.whl\n. This is because of: \nhttps://bitbucket.org/pypa/wheel/src/f746a01eab7a673cb628a52f99c129d0d5741bcf/wheel/bdist_wheel.py?at=default#bdist_wheel.py-99\nAnd\nhttps://bitbucket.org/pypa/wheel/src/f746a01eab7a673cb628a52f99c129d0d5741bcf/wheel/bdist_wheel.py?at=default#bdist_wheel.py-135\nMarkers are defined here: https://www.python.org/dev/peps/pep-0425/#python-tag\n. Merci\n. I have created https://github.com/mozilla-services/cliquet/pull/436 but I cannot reproduce. Have we got this fixed in last Cliquet version?\n. Actually we do not plan to land this\n. Shall we go with this solution for a start?\n. Yes great, I like the small diff in code :+1: \n. Looks good to me, I fixed the one flake8 error waiting on travis.\n. But I am wondering if this is dead code or missing tests?\n. I did some manual checking and nothing wrong seems happen.\n. I would rather put this code in cliquet directly and let people enable it with a config.\n. Supplanted by https://github.com/mozilla-services/cliquet/pull/447\n. Why we should not use Slack at all and keep on with IRC: https://twitter.com/amontalenti/status/660849837982674945\n. I do not think IRC backlog is a feature for newcomers. Also facilitating access to IRC is.\nI thought the link to http://chat.mibbit.com/?server=irc.mozilla.org&channel=%23storage in the documentation was actually enough.\n. PouchDB did a link between Slack and IRC, I am not a big fan of using Slack but if it helps people why not.\nAlso I am not sure if I would not worth to help them to use IRC instead since it is an OpenSource protocol rather than a proprietary solution.\n. > How do you help them?\nBy making it as easy to get started and use as Slack seems to be.\n. Here at the coworking space they are using Slack, but the IRC integration works like a charm.\nIt seems slack is really trendy and help people to get in touch so maybe it could be a good alternative.\n. Youpi thanks a lot for that :)\n. Let's do that then :+1: \n. The question you can ask yourself is, when landing on the documentation home page and looking for getting paginated records, what would you like to do to find it really quickly?\n. I tried to do it and I ended-up on the record-get page\nWhere there is nothing about filtering/paginating or anything yet (after 3 clicks)\nAlthough there is a link to resource-endpoints\nBut I think we can add a list of link for direct access from the records-get page\n- Filtering\n- Sorting\n- Counting\n- Polling for changes\n- Paginate\n- List of parameters\nNote that we may also want to change the order.\n. Oh yeah\n. r+\n. r? @phrawzty \n. - What is generating this error?\n  The PostgreSQL driver that cannot activate the JSONbin functionnality not present with old server version.\n- When might this error message be seen?\n  When using a PostgreSQL older than 9.4\n- Can the problem be ignored?\n  Nope the server doesn't run in that case and fails with this error\n- Why does upgrading to pgsql 9.4+ solve the problem?\n  Because after PostgreSQL9.4 server have got JSONBin support\n- Does anything else need to be upgraded?\n  No\n. @phrawzty Based on this new information how shall I rephrase the FAQ answer?\n. >  I wouldn't mix troubleshooting and overview questions.\nYes good point, shall I create troubleshooting file?\n. Updated with your remarks.\n. Updated with Dan rephrasing. Thanks :+1: \n. r+\n. Actually we are using the same configuration parameter to validate and to build the Bearer Token.\nFor instance the fxa-oauth/login can ask for kinto and profile scopes when calling kinto with kinto scope only should work.\nI will add another for the building Bearer token part.\n. The problem is that Kinto 1.4.0 should install Cliquet 2.6.x branch but the setup.py is wrong and it install the 2.7.0 instead.\nSuccessfully installed cliquet-2.7.0 kinto-1.4.0\nWe will try our best in the feature to correctly tag cliquet version numbers in kinto.\n. > Is this tutorial really useful, since we want people to use our JavaScript client, should we drive them to do so, and let the httpie commands come for implementers who needs them?\nI don't agree with that, this is the scope of kinto.js documentation.\nI wish we had something like that: http://www.parse.com/docs on the ecosystem landing page.\n. > Remove the presence of HTTPie command line, it's not useful.\nI am not sure, this makes it reproducible and help remove blockers.\n. If we can link on a bucket/collection/records the event we are subscribing, the user ID as well as the PUSH url, then we are all set.\nOn an event, we can go through impacted notification, get the principal list for each user and then decide if we should do the push according to the permission backend.\nHopefully we can handle that asynchronously.\n. This is only the case when using cliquet_fxa with multiauth.\n. It looks like cliquet_fxa is calling the cliquet.initialize a second time.\n. Fixed with Cliquet-Fxa 1.3.2\n. This is only the case when using cliquet_fxa with multiauth.\n. Fixed with cliquet-fxa 1.3.2\n. r? @leplatrem \n. Fixed with mozilla-services/cliquet#483\n. Thank you for starting that. We will review it shortly :)\n. Note that this settings don't have anything to do we each other.\nThe fact that they have the same values in development is a pure chance.\nhost = 0.0.0.0\nport = 8888\nIs use to serve the app with waitress (which is used in production only)\n[uwsgi]\nsocket = 127.0.0.1:8888\nWe will never have to use such a setup because in production we will use file sockets.\nsocket = /run/wsgi/kinto.sock\nkinto.http_host = localhost:8888\nThis one is the public address when kinto have to name itself.\nSo in production the setup will be:\n```\n[uwsgi]\nsocket = /run/wsgi/kinto.sock\nkinto.http_host = kinto.services.mozilla.com\n```\nAs you can see we need to keep all of this settings.\nkinto.http_host should never ever looks like 0.0.0.0:8000 because 0.0.0.0 is not a correct ip address to name a kinto server.\n. Most of what I think is described in #218. Falling back to WSGI might be a good idea on most setup yes.\n. r+ with nit on the uwsgi config names.\n. Super\n. Could you provide a config example of what you have in mind for this?\n. To reproduce you can run twice this command:\n```\n$ echo '{\"data\": {\"display\": \"tito\"}}' | http PUT https://kinto.dev.mozaws.net/v1/buckets/default/collections/display/records/e3e81724-50e6-4e29-811c-968be1ad346d If-Match:'\"1445523707841\"' --auth user:pass\nHTTP/1.1 412 Precondition Failed\nAccess-Control-Expose-Headers: Backoff,Retry-After,Alert,Content-Length\nConnection: keep-alive\nContent-Length: 321\nContent-Type: application/json; charset=UTF-8\nDate: Thu, 22 Oct 2015 14:22:30 GMT\nETag: \"1445523735194\"\nLast-Modified: Thu, 22 Oct 2015 14:22:15 GMT\nServer: nginx/1.4.6 (Ubuntu)\n{\n    \"code\": 412, \n    \"details\": {\n        \"existing\": {\n            \"permissions\": {\n                \"write\": [\n                    \"basicauth:df93ca0ecaeaa3126595f6785b39c408be2539173c991a7b2e3181a9826a69bc\"\n                ]\n            }, \n            \"display\": \"toto\", \n            \"id\": \"e3e81724-50e6-4e29-811c-968be1ad346d\", \n            \"last_modified\": 1445523735194\n        }\n    }, \n    \"errno\": 114, \n    \"error\": \"Precondition Failed\", \n    \"message\": \"Resource was modified meanwhile\"\n}\n``\n. I'd like to merge https://github.com/Kinto/kinto/pull/214 first.\n. Wait on https://github.com/mozilla-services/cliquet/pull/494\n. #214 was too greedy, this is a fix.\n. The ping method is now externalized and generci for all backends here: https://github.com/mozilla-services/cliquet/blob/master/cliquet/storage/__init__.py#L245-L271\n. About the permission layer I would create the history collection in the same bucket so that we can give permissions to the same groups of the bucket. However we shouldn't automatically detect permissions and just let them be defined in the config as for kinto-changes.\n. Why would you need a new permission? It is a collection like other collections we should have already everything that is needed.\n. Yes that would be theread` permission on the history of changes.\nI can see two plans, either we add the permissions directly on the records (the record permission as well as the collection and bucket permissions to the history record) so that we can see all the history of records we had permissions to see at the time.\nOr we can give read permission to the history collection as we usually do for other collections.\nFor the current use cases we are managing public data so that it shouldn't be a problem.\n. > writes should always be performed by the system\nYes exactly\n. We have started a blueprint about that here: https://github.com/Kinto/kinto/wiki/Kinto-History\n. Actually it is a bit more complex than that, because even when not using default bucket, with regards to the permission, two persons may not have access to the same record list while if not using the Vary header we could give them the same cached list.\n. So as @ametaireau said we will need the Vary header on every bucket.\n. @n1k0 still had a similar bug today on /buckets we need to add the Vary header.\n. This was fixed by https://github.com/mozilla-services/cliquet/commit/eda3be3af48b004b2b5ebfeaf7d4e27e6591d8e9\n. > I don't know how to make it pass on it\nIf you want to do that, you will need to write a test that execute the command.\nSee how we did it with Cliquet: https://github.com/mozilla-services/cliquet/blob/master/cliquet/tests/test_scripts.py\n. It looks really good thanks :+1: \n. Rebased in https://github.com/Kinto/kinto/pull/247\n. Shall we abort this PR and see how it goes with Vary headers?\n. This should already be possible with http://kinto.readthedocs.org/en/latest/configuration/settings.html#enabling-or-disabling-endpoints\nAlso I am wondering if a new setting kinto.read-only = true could help to configure that behavior.\n. So I tried my investigation. The aim I have is to safely let people configure a read-only postgresql user on a read-only kinto.\nI did a cliquet migrate with the postgres rw user\nThen the first error I have doing that when running the server is:\nERROR:venusian:(psycopg2.ProgrammingError) ERREUR:  doit \u00eatre le propri\u00e9taire de la fonction sec2ttl\n [SQL: \"--\\n-- Automated script, we do not need NOTICE and WARNING\\n--\\nSET client_min_messages TO ERROR;\\n\\nCREATE TABLE IF NOT EXISTS cache (\\n    key VARCHAR(256) PRIMARY KEY,\\n    value TEXT NOT NULL,\\n    ttl TIMESTAMP DEFAULT NULL\\n);\\n\\n--\\n-- CREATE INDEX IF NOT EXISTS will be available in PostgreSQL 9.5\\n-- http://www.postgresql.org/docs/9.5/static/sql-createindex.html\\nDO $$\\nBEGIN\\n\\n  IF NOT EXISTS (\\n    SELECT 1 FROM pg_indexes\\n       WHERE indexname = 'idx_cache_ttl'\\n       AND tablename = 'cache'\\n  ) THEN\\n\\n  CREATE INDEX idx_cache_ttl ON cache(ttl);\\n\\n  END IF;\\nEND$$;\\n\\n\\nCREATE OR REPLACE FUNCTION sec2ttl(seconds FLOAT)\\nRETURNS TIMESTAMP AS $$\\nBEGIN\\n    IF seconds IS NULL THEN\\n        RETURN NULL;\\n    END IF;\\n    RETURN now() + (seconds || ' SECOND')::INTERVAL;\\nEND;\\n$$ LANGUAGE plpgsql;\\n\"] \nTraceback (most recent call last):\n  File \".venv/bin/cliquet\", line 9, in <module>\n    load_entry_point('cliquet==2.10.0.dev0', 'console_scripts', 'cliquet')()\n  File \"/home/rhubscher/mozilla/kinto/.venv/local/lib/python2.7/site-packages/cliquet/scripts/cliquet.py\", line 46, in main\n    args.func(env)\n  File \"/home/rhubscher/mozilla/kinto/.venv/local/lib/python2.7/site-packages/cliquet/scripts/cliquet.py\", line 21, in init_schema\n    getattr(registry, backend).initialize_schema()\n  File \"/home/rhubscher/mozilla/kinto/.venv/local/lib/python2.7/site-packages/cliquet/cache/postgresql/__init__.py\", line 66, in initialize_schema\n    conn.execute(schema)\n  File \"/usr/lib/python2.7/contextlib.py\", line 35, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/home/rhubscher/mozilla/kinto/.venv/local/lib/python2.7/site-packages/cliquet/storage/postgresql/client.py\", line 51, in connect\n    raise exceptions.BackendError(original=e)\ncliquet.storage.exceptions.BackendError: ProgrammingError: (psycopg2.ProgrammingError) ERREUR:  doit \u00eatre le propri\u00e9taire de la fonction sec2ttl\n [SQL: \"--\\n-- Automated script, we do not need NOTICE and WARNING\\n--\\nSET client_min_messages TO ERROR;\\n\\nCREATE TABLE IF NOT EXISTS cache (\\n    key VARCHAR(256) PRIMARY KEY,\\n    value TEXT NOT NULL,\\n    ttl TIMESTAMP DEFAULT NULL\\n);\\n\\n--\\n-- CREATE INDEX IF NOT EXISTS will be available in PostgreSQL 9.5\\n-- http://www.postgresql.org/docs/9.5/static/sql-createindex.html\\nDO $$\\nBEGIN\\n\\n  IF NOT EXISTS (\\n    SELECT 1 FROM pg_indexes\\n       WHERE indexname = 'idx_cache_ttl'\\n       AND tablename = 'cache'\\n  ) THEN\\n\\n  CREATE INDEX idx_cache_ttl ON cache(ttl);\\n\\n  END IF;\\nEND$$;\\n\\n\\nCREATE OR REPLACE FUNCTION sec2ttl(seconds FLOAT)\\nRETURNS TIMESTAMP AS $$\\nBEGIN\\n    IF seconds IS NULL THEN\\n        RETURN NULL;\\n    END IF;\\n    RETURN now() + (seconds || ' SECOND')::INTERVAL;\\nEND;\\n$$ LANGUAGE plpgsql;\\n\"]\n. Yes it is because make serve automatically run make migrate first.\n. A get works\n. Fixed in mozilla-services/cliquet#525\n. Related to https://github.com/Kinto/kinto/pull/158/files\n. Rebased.\n. I would probably also uncomment the 201 in the tutoriel loadtest.\n. This is #243\n. Thanks.\n. @leplatrem final r?\n. We should have the config_file parameter for the other command as well.\n. > (don't forget to update the contributors ;))\nIt can be done at release time isn't it?\n. Same problem for Collection and Records:\n```\n$ echo '{\"data\": {\"foo\": \"bar\"}}' | http PUT http://localhost:8888/v1/buckets/test/collections/test/records/a2f771d2-7551-4620-9d81-1e45274e506d  If-None-Match:'\"\"' --auth user: -v\nPUT /v1/buckets/test/collections/test/records/a2f771d2-7551-4620-9d81-1e45274e506d HTTP/1.1\nAccept: application/json\nAccept-Encoding: gzip, deflate\nAuthorization: Basic dXNlcjo=\nConnection: keep-alive\nContent-Length: 25\nContent-Type: application/json\nHost: localhost:8888\nIf-None-Match: \"\"\nUser-Agent: HTTPie/0.9.2\n{\n    \"data\": {\n        \"foo\": \"bar\"\n    }\n}\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 199\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 02 Nov 2015 14:34:08 GMT\nEtag: \"1446474848597\"\nLast-Modified: Mon, 02 Nov 2015 14:34:08 GMT\nServer: waitress\n{\n    \"data\": {\n        \"foo\": \"bar\", \n        \"id\": \"a2f771d2-7551-4620-9d81-1e45274e506d\", \n        \"last_modified\": 1446474848597\n    }, \n    \"permissions\": {\n        \"write\": [\n            \"basicauth:b349ae096cba67e1d03439e1da16f45ee90c1063cdfb0ef8b8d3f201b173ea69\"\n        ]\n    }\n}\n``\n. The test is wrong [here](https://github.com/mozilla-services/cliquet/blob/2.10.0/cliquet/tests/resource/test_preconditions.py#L165) it should beIf-None-Match:'\"*\"'` isn't it?\n. Ok well then it works.\n```\n$ echo '{\"data\": {\"id\": \"test\"}}' | http POST https://kinto.dev.mozaws.net/v1/buckets         If-None-Match:'' --auth user: -v\nPOST /v1/buckets HTTP/1.1\nAccept: application/json\nAccept-Encoding: gzip, deflate\nAuthorization: Basic dXNlcjo=\nConnection: keep-alive\nContent-Length: 25\nContent-Type: application/json\nHost: kinto.dev.mozaws.net\nIf-None-Match: \nUser-Agent: HTTPie/0.9.2\n{\n    \"data\": {\n        \"id\": \"test\"\n    }\n}\nHTTP/1.1 412 Precondition Failed\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nConnection: keep-alive\nContent-Length: 111\nContent-Type: application/json; charset=UTF-8\nDate: Tue, 03 Nov 2015 15:54:08 GMT\nETag: \"1446541685814\"\nLast-Modified: Tue, 03 Nov 2015 09:08:05 GMT\nServer: nginx/1.4.6 (Ubuntu)\n{\n    \"code\": 412, \n    \"details\": {}, \n    \"errno\": 114, \n    \"error\": \"Precondition Failed\", \n    \"message\": \"Resource was modified meanwhile\"\n}\n```\n. r+\n. There is a link to that list in the note here http://kinto.readthedocs.org/en/latest/configuration/production.html#recommended-settings\n. Actually what I understand of your proposal, taking care of @leplatrem concerns, is to rather do:\n{\n  \"data\": {\n      \"id\": \"1234\",\n      \"last_modified\": 123456,\n      \"data\": {\"foo\": \"bar\"}\n    }\n}\nSo adding a new level to put all records data in it.\nThen the collection_get will look like :\n{\n    \"data\": [{\n      \"id\": \"1234\",\n      \"last_modified\": 123456,\n      \"data\": {\"foo\": \"bar\"}\n    }]\n}\nThe question is, will permission be part of this data or not?\n{\n  \"data\": {\n      \"id\": \"1234\",\n      \"last_modified\": 123456,\n      \"data\": {\"foo\": \"bar\"},\n      \"permissions\": {}\n    }\n}\nor \n{\n  \"data\": {\n      \"id\": \"1234\",\n      \"last_modified\": 123456,\n      \"data\": {\"foo\": \"bar\"}\n    },\n    \"permissions\": {}\n}\n. If we go furthermore in the proposal and look at collections, will it look like that:\n{\n    \"data\": {\n        \"id\": \"tasks\",\n        \"last_modified\": 1446646942107,\n        \"data\": {\"fingerprint\": \"1a4089078fda74bc20441f62e621b057a92cffb6ace35ccde0c32b6394949801\"},\n        \"schema\": {\"JSONSchema\": \"in it\"}\n    }\n}\nor like that?\n{\n    \"data\": {\n        \"id\": \"tasks\",\n        \"last_modified\": 1446646942107,\n        \"data\": {\n            \"fingerprint\": \"1a4089078fda74bc20441f62e621b057a92cffb6ace35ccde0c32b6394949801\",\n            \"schema\": {\"JSONSchema\": \"in it\"}\n        }\n    }\n}\nDepending of if we consider the schema being part of the collection attributes (that we want to take into account when signing the collection object).\n. If we want to get closer to what jsonapi is doing, it should probably look like this:\n{\n  \"data\": {\n      \"id\": \"1234\",\n      \"last_modified\": 123456,\n      \"attributes\": {\"foo\": \"bar\"}\n    }\n}\n. WFM.\n. I would rather mention not to use the Memory backend in production.\nBut at least this yes.\nRefs https://github.com/mozilla-services/cliquet/issues/406\n. > kinto start then accesses the kinto.ini right\nYes, the kinto init command generate the file for kinto start and kinto migrate to use\n. I wonder if this list of public exposed settings should not be configurable using the configuration file.\n. Now that we have capabilities it should be exposed as a capability.\nHere is an example of how a capability can be exposed: https://github.com/Kinto/kinto-attachment/blob/master/kinto_attachment/init.py#L19-L22\nHere is the place where we could add the capability: https://github.com/Kinto/kinto/blob/8cc9b87b7776b68da391790f99a9b8b0aa65195f/kinto/init.py#L55\nHere as some example of the two tests that could be written:  https://github.com/Kinto/kinto-attachment/blob/a3b531662b6468dd2585e92a238e99551439703e/kinto_attachment/tests/test_plugin_setup.py\n. @lavish205 said on IRC he wanted to work on this bug.\n. You need to expose the capability if the settings is set to true:\nHere is the way to do it:\nconfig.add_api_capability(\"schema\",\n                          description=\"Enforce a schema for collection records.\",\n                          url=\"http://kinto.readthedocs.org/en/latest/api/1.x/\"\n                              \"collections.html#collection-json-schema\")\n. Why do we have two PR for the same thing ( https://github.com/Kinto/kinto/pull/267 )\nCan we close one of them?\n. Superseeded by https://github.com/Kinto/kinto/pull/278\n. Should we let both 3.4 and 3.5?\n. r+\n. r+\n. I am wondering if we shouldn't put the default_bucket feature in a plugin and let the plugin order handle that current limitation.\n. r? @leplatrem \n. r? @leplatrem \n. Why don't you change the two others too?\n. LGTM :+1: \n. Thanks.\n. For a collection there are two things:\n- The collection update\n- The collection records update.\nThe former is the collection.last_modified value which changes when the collection properties are updated.\nThe later is the collections records.collection_timestamp which is the last record update last_modified value.\nI am wondering if we shouldn't keep both value separated and add a last_updated properties on collection which would contain the /records ETag value.\n. Or we should do what @tarekziade said (ie. update the collection last_modified value when a record is updated) and add schema a a subresource of collection. (with a proper schema last_modified value.)\n. > Is that a specific use case we have?\nToday we have the schema experimental feature that is using this last_modified value as a schema version.\n. r+\n. @tarekziade you should be able to use:\nfrom kinto.config import init\ninit(\"config/kinto.ini\")\n. As you can see it should be the case here: https://github.com/Kinto/kinto/blob/master/Makefile#L43-L47\n. Was fixed with #283 \n. We try to keep up with the \"Explicit is better than implicit\" Python Zen philosophy.\nDoing the chain automatically will add complexity to detect cases.\nFor instance we might generate a new configuration file and run migration whereas the user actually forget to set its configuration file path or didn't run the kinto command from the proper repository.\nAlso letting the user run: kinto --ini config/kinto.ini init migrate start seems to make a lot of sense for me.\n. LGTM\n. > I think we should treat everyone equally by comparing products\n:+1: \n. r+\n. I would go for /admin/ rather than /__admin/ but yeah :+1: \n. This has been handled in https://github.com/kinto/kinto-dist\n. Oh great catch. We should use extra_requires there.\n. Oh yes, we should probably:\n- add a filter to search for list containing something\n- add a filter to search for records having a specific attribute (kinto-telegram-wall text attribute)\n- Filtering on sub-objects properties (kinto-telegram-wall from.first_name for instance)\n. Ok let's do that!\n- #343: list property filtering\n- #344: property existence filtering\n- #345: Filtering on sub-objects properties\n. Actually we cannot really move away from the package because it is really faster. What we could do is to use the ultrajson (fork) package in the mean time.\nhttps://pypi.python.org/pypi/ultrajson\n. It should work yes :)\n. r+wc\n. Thanks a lot :+1: \n. Thanks a lot :)\n. We are using Kinto with Firefox for Android so it will eventually become a SDK.\nAlso if you want to work on that feature, we will be glad to help you in the process.\n. Superseeded by #349 \n. :+1: \n. I think it good to tell people to use the #kinto hashtag when they want to speak about it, isn't it?\n. Then it might be wise to create a kinto-storage account?\n. With some Twitter clients you can :)\n. Oh yeah! r+\n. LGTM\n. This was fixed by #349 \n. Great thanks :+1: \n. We should probably update the doc with the API changelog.\n. Even more clever than I planned to do :+1: \n. Yes much better :+1: \n. Let's go for it then :+1: \n- tags_contains=science,burundi\n. For the postgresql backend we should use jsonb_array_elements(data->'arrayAttribute') as array_element\nRefs: https://stackoverflow.com/a/32360952/186202. Contains would probably already be used by #343 \n. I like defined :+1: \n- text_defined=true\n- text_defined=false\n. I also think . is a good idea for that :+1: \n- author.username=natim\n. Shweta can you fix the PEP8 errors showed here: https://travis-ci.org/Kinto/kinto/jobs/97646030#L134\n. Thanks :+1: \n. > it would be pretty cool if we could use websockets.\nWe are working on it. Could you describe exactly what your use case is with that?\nDid you try the cliquet-pusher plugin that let you do that using Pusher?\n\nmaybe once a new record is added, an email could be sent or something\n\nThis is already doable using Notification. We would love to help you building a cliquet-email-notification plugin.\n. Ok, so yes what you describe is exactly what you can already do with cliquet-pusher.\n. She can file pull-request :+1: \n. > Do you have a Postgresql running locally?\nYes I think that's the way to reproduce it.\n. I did something like that in the readme: https://github.com/Kinto/kinto/pull/465/files\nBut I think we should add requirements in the beginning of all Getting Started paragraph telling what the user needs to install and in which version before going further.\n. Fixed with https://github.com/Kinto/kinto/pull/465/files\n. @msathis do you have an idea of how you would like to access this information?\nYou can already have the number of records in a particular collection doing a head request to it:\n```\nhttp HEAD https://kinto-ota.dev.mozaws.net/v1/buckets/blocklists/collections/certificates/records\nETag: \"1450717104423\"\nLast-Modified: Mon, 21 Dec 2015 16:58:24 GMT\nTotal-Records: 10\n```\n. Thank you for this it is really interesting :+1: \n. The proposition is to add on collection a readonly stats parameter such as permissions and data which contains: \nFor buckets\n{\n    \"collections_count\": 5,\n    \"storage_size\": \"478\"\n}\nFor collections\n{\n    \"records_count\": \"114\",\n    \"storage_size\": \"83\"\n}\n. It is already possible to get the last_write and we can use kinto-changes for that.\nAlso having the creation date can be achieve with the kinto-history plugin that let you have an full audit trail.\n. @almet is it closer to what you had in mind?\n. \n\n. Let's do some A/B testing then :+1: \n. kinto migrate is missing in the Dockerfile I am going to fix that :+1: \n. @almet @leplatrem Here is the fix for #363 does it looks better to you?\n. I put the other one here : https://github.com/Kinto/kinto-docker\nLet me check about this libpq-dev\n. Apparently the image is building without specifying libpq-dev and docker-compose up now works\n. > >  I put the other one here : https://github.com/Kinto/kinto-docker\n\nwhy another repo ?\n\nTo keep it and not break the feature of contineous integration with master while providing a smaller and more reliable docker image (based on the last released tag)\n. We might install the wrong cliquet version.\n. Yes let's do that in anycase it will just try that if dependencies are not installed yet so we should be fine.\n. Oh yeah.\n. :+1: \n. +1\n. Seems good to me.\n. Oh :dancer: \n. I don't think people should include it in the config so IMHO we can let it as it is.\n. As far as I know we don't aim to make it an optional feature do we?\n. r+\n. Great :)\n. I am wondering if we should not also put the code of the working plugins on github somewhere. (kinto/kinto-elasticsearch)\n. The image seems 20MB bigger but I don't understand why :)\n. 16K CHANGELOG.rst\n4.0K    CONTRIBUTORS.rst\n4.0K    Dockerfile\n4.0K    LICENSE\n4.0K    MANIFEST.in\n4.0K    Makefile\n4.0K    README.rst\n4.0K    app.wsgi\n4.0K    dev-requirements.txt\n4.0K    docker-compose.yml\n20K examples\n288K    kinto\n52K kinto.egg-info\n0   kinto.log\n4.0K    requirements.txt\n4.0K    setup.cfg\n4.0K    setup.py\n4.0K    tox.ini\n. But I think it is because we've added some plugins as well we should be good.\n. r+\n. It is because group:brewers is not the right way to name a group in a permissions.\nIf you use /buckets/beers/groups/brewers instead it should work just fine.\n. I couldn't add my commit there so I added it here #388 \nNevertheless I would like to thank you for opening this PR with a test it is really useful for us and it definitely means we need to improve the documentation around that.\n. @aegaas note that we should probably release a version of Kinto quite soon. (Last one is more than a month old now.)\n. @aegaas Your new test is passing right?\n. @aegaas You should probably create new branch for further investigations.\nIf you want to rebase on #388 you can use:\ngit checkout Kinto/master -b kinto_master\ngit pull Kinto master\ngit checkout -b investigating_permissions\ngit cherry-pick 62ca813\ngit push aegaas investigating_permissions -u\nI will close this PR for now since the original problem has been merged.\n. @aegaas Can you join #kinto on IRC I have some questions for you regarding what you are trying to do.\n. @aegaas I tried to create a working scenario, not sure if it is what you are trying to do though, hope this helps:\nInstall HTTPie before running the bash script. (`sudo pip install httpie)\n``` shell\n!/bin/bash -v\nAARONEGAAS_USER_ID=\"basicauth:fdef7420df4f59b98f2dd2fe2c1640a8af9b9e6a8b8946bbf1c102271db04e81\" # aaronegaas:passwordOne\nKELLYEGAAS_USER_ID=\"basicauth:a32037e5f4cba65488401e668deabf2cf02cbf60c4271bb8d7fd731d09593d7c\" # kellyegaas:passwordTwo\nhttp DELETE https://kinto.dev.mozaws.net/v1/buckets/TWuTPMYi --auth \"system:notreallyapassword\"\nBucket Setup\nhttp PUT https://kinto.dev.mozaws.net/v1/buckets/TWuTPMYi --auth \"system:notreallyapassword\"\nGroup Setup\necho '{\"data\": {\"members\": [\"'${AARONEGAAS_USER_ID}'\", \"'${KELLYEGAAS_USER_ID}'\"]}}' | \\\n    http PUT https://kinto.dev.mozaws.net/v1/buckets/TWuTPMYi/groups/egaas --auth \"system:notreallyapassword\"\nCollection setup\n\u2014 Circle collection\nhttp PUT https://kinto.dev.mozaws.net/v1/buckets/TWuTPMYi/collections/circles --auth \"system:notreallyapassword\"\n\u2014 tasks egaas collection\necho '{\"permissions\":{\"write\": [\"/buckets/TWuTPMYi/groups/egaas\"]}}' | \\\n    http PUT https://kinto.dev.mozaws.net/v1/buckets/TWuTPMYi/collections/tasks-egaas --auth \"system:notreallyapassword\"\nRecord setup\n\u2014 Circle record\necho '{\"data\": {\"name\":\"Egaas Family\",\"members\": [\"aaronegaas\", \"kellyegaas\"]},\"permissions\":{\"write\": [\"/buckets/TWuTPMYi/groups/egaas\"]}}' | \\\n    http POST https://kinto.dev.mozaws.net/v1/buckets/TWuTPMYi/collections/circles/records --auth \"system:notreallyapassword\"\n\u2014 Tasks Egaas record\necho '{\"data\":{\"task\":\"milk\",\"done\":false,\"circle\":\"egaas\"}}' | \\\n    http POST https://kinto.dev.mozaws.net/v1/buckets/TWuTPMYi/collections/tasks-egaas/records --auth \"aaronegaas:passwordOne\"\nList egaas circles\nhttp GET https://kinto.dev.mozaws.net/v1/buckets/TWuTPMYi/collections/circles/records --auth \"aaronegaas:passwordOne\"\nhttp GET https://kinto.dev.mozaws.net/v1/buckets/TWuTPMYi/collections/circles/records --auth \"kellyegaas:passwordTwo\"\nList egaas tasks\nhttp GET https://kinto.dev.mozaws.net/v1/buckets/TWuTPMYi/collections/tasks-egaas/records --auth \"aaronegaas:passwordOne\"\nhttp GET https://kinto.dev.mozaws.net/v1/buckets/TWuTPMYi/collections/tasks-egaas/records --auth \"kellyegaas:passwordTwo\"\n``\n. LGTM thanks :+1: \n. r+\n. You are right. Actually we will replace thoseuser:passwordwith an arbitrary string liketoken:my-secret` to avoid confusion when using BasicAuth.\nEvery token is valid with the default configuration that lets anyone authenticated to create a bucket.\nBut using BasicAuth introduces a lot of limitations (you identified one in #394) which should be made explicit in the documentation.\nWe've decided to avoid managing users in Kinto and rely on a third-party to provide tokens. For example, Github tokens can be enabled or any other identity provider (OAuth). We could even imagine implementing a simple service that provides tokens for users (registration/password management).\n. Updated with comments.\n. @davidbgk Do you have any feedback on this? (Especially https://github.com/Kinto/kinto/pull/395/files#diff-18cdd64c21241196fabd3c264269b63d)\n. @leplatrem I have updated the PR with your comments.\n. r+\n. r+\n. I think this already landed. https://github.com/mozilla-services/cliquet/pull/601 and was released with Cliquet 2.14.0\nThe next release of Kinto (which should not be long now will include it)\n. The syntax to use will be: \n/v1/buckets/(bucket_id)/collections/(collection_id)/records?_fields=id,title,last_modified\n. Kinto 1.11.0 has been released with this feature.\nYou can try it on the https://kinto.dev.mozaws.net/v1/ instance or create your's on Heroku\n. LGTM too.\n. That something we may want to do with GCM (Google Cloud Messaging) too: https://www.digitalocean.com/community/tutorials/how-to-create-a-server-to-send-push-notifications-with-gcm-to-android-devices-using-python\n. For me a readonly server cannot be used to sync user data.\nAlso the client will get 405 errors but it was the reason why I though it was a capability.\nIs the server capable of writing user data during sync? Yes ? No ?\nThe capability could be writable\n. Should we then add the readonly capability instead?\n. A public settings seems to be enough here.\n. It might have been fixed since. I think one way to reproduce is to call an endpoint with UTF-8 characters in the URL, while trying to log it with mozlog.\n. But it should have been fixed with https://github.com/mozilla-services/cliquet/commit/28f668476017eea71413b326267b0f54d29f269f\n. I've started a pad here if you want to help: https://public.etherpad-mozilla.org/p/why-do-i-need-a-json-database\n. Thanks a lot man :)\n. r+\n. It seems it has been fixed with https://github.com/Kinto/kinto/pull/474\n. \"Which backend to use\" -> \"Select the backend you would like to use: \"\n. I am currently using HUP with uwsgi can we say that this is a feature of the WSGI workers handler (circus/gunicorn/uwsgi)?\n. Sounds good yes.\n. Also it seems to be using the requirements.txt file while we are not handling dependencies using it.\n. See: https://github.com/Kinto/kinto/pull/437\n. AttributeError: 'Request' object has no attribute 'current_service'\n. Seems related to: https://github.com/mozilla-services/cliquet/commit/1f63dbbfbb558b5649c146ab2dd632b51bb174cc#diff-ad559e2efa2b2e15a7d341a92cadc555R175\n. I think it happens when the request is not linked to any service.\n. This have been fixed.\n. https://github.com/mozilla-services/cliquet/pull/650 / https://travis-ci.org/Kinto/kinto/builds/109648422\n. Yes you can add new commit to your branch and it will automatically update this pull-request.\n. @ayusharma Would you mind adding that in the troubleshooting section?\n. Also thanks a lot for answering with the solution :)\n. > Is it possible to list all users (user ids)?\nIf by list all users you mean, list all user ids that have at list one permission on a resource.\nWe do not have this method to permissions backends yet: https://github.com/mozilla-services/cliquet/blob/master/cliquet/permission/init.py\nCan you elaborate on what would be the use case for that? It could be added if necessary.\n\nHow to delete all records owned by a particular user?\n\nAs an administrator? As the user? At which level (server, bucket, collection)?\nIt is possible to get all the objects for a particular user using https://github.com/mozilla-services/cliquet/blob/master/cliquet/permission/init.py#L89\nThen it is possible to remove all this objects at once.\nAlso that's not a public API.\n. > handling orphaned data (as administrator) e.g. testing records during development or outdated records from since canceled projects.\nFor this you can simply delete the bucket related to the project:\nDELETE /buckets/abandoned_or_test_project_bucket_id\n\nI'd like to clean up records from abandoned users\n\nHow do you detect that a user id has been abandoned?\n. Actually default bucket is a shortcut to distinct bucket id.\nYou can get the bucket id of a user by calling the / endpoint (while being authenticated) or the /buckets/default endpoint and looking at the id:\n``` http\nGET /v1/buckets/default HTTP/1.1\nAccept: /\nAccept-Encoding: gzip, deflate\nAuthorization: Basic dG9rZW46bXktc2VjcmV0\nConnection: keep-alive\nHost: kinto.dev.mozaws.net\nUser-Agent: HTTPie/0.9.2\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, ETag, Pragma, Cache-Control, Backoff\nCache-Control: no-cache\nConnection: keep-alive\nContent-Length: 187\nContent-Type: application/json; charset=UTF-8\nDate: Thu, 18 Feb 2016 08:02:35 GMT\nETag: \"1455782547511\"\nLast-Modified: Thu, 18 Feb 2016 08:02:27 GMT\nServer: nginx\n{\n    \"data\": {\n        \"id\": \"e777874f-2936-11a1-3269-68a6c1648a92\", \n        \"last_modified\": 1455782547511\n    }, \n    \"permissions\": {\n        \"write\": [\n            \"basicauth:c635be9375673027e9b2f357a3955a0a46b58aeface61930838b61e946008ab0\"\n        ]\n    }\n}\n```\n``` http\nGET /v1/ HTTP/1.1\nAccept: /\nAccept-Encoding: gzip, deflate\nAuthorization: Basic dG9rZW46bXktc2VjcmV0\nConnection: keep-alive\nHost: kinto.dev.mozaws.net\nUser-Agent: HTTPie/0.9.2\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nConnection: keep-alive\nContent-Length: 505\nContent-Type: application/json; charset=UTF-8\nDate: Thu, 18 Feb 2016 08:03:00 GMT\nServer: nginx\n{\n    \"capabilities\": {}, \n    \"cliquet_protocol_version\": \"2\", \n    \"http_api_version\": \"1.3\", \n    \"project_docs\": \"https://kinto.readthedocs.org/\", \n    \"project_name\": \"kinto\", \n    \"project_version\": \"1.11.2\", \n    \"settings\": {\n        \"attachment.base_url\": \"https://kinto.dev.mozaws.net/attachments/\", \n        \"batch_max_requests\": 25, \n        \"cliquet.batch_max_requests\": 25, \n        \"readonly\": false\n    }, \n    \"url\": \"https://kinto.dev.mozaws.net/v1/\", \n    \"user\": {\n        \"bucket\": \"e777874f-2936-11a1-3269-68a6c1648a92\", \n        \"id\": \"basicauth:c635be9375673027e9b2f357a3955a0a46b58aeface61930838b61e946008ab0\"\n    }\n}\n```\nYou can notice that the bucket_id for this user is: e777874f-2936-11a1-3269-68a6c1648a92\nNote that a user can add permission on this to share it with other users as if it was normal bucket.\nAn administrator can look at all the existing buckets by calling:\n``` http\nGET /v1/buckets HTTP/1.1\nAccept: /\nAccept-Encoding: gzip, deflate\nAuthorization: Basic dG9rZW46bXktc2VjcmV0\nConnection: keep-alive\nHost: kinto.dev.mozaws.net\nUser-Agent: HTTPie/0.9.2\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, Total-Records, ETag, Pragma, Cache-Control, Backoff, Next-Page\nCache-Control: no-cache\nConnection: keep-alive\nContent-Length: 86\nContent-Type: application/json; charset=UTF-8\nDate: Thu, 18 Feb 2016 08:04:53 GMT\nETag: \"1455782547511\"\nLast-Modified: Thu, 18 Feb 2016 08:02:27 GMT\nServer: nginx\nTotal-Records: 1\n{\n    \"data\": [\n        {\n            \"id\": \"e599a995-92b2-2f26-1027-c1168114592e\", \n            \"last_modified\": 1455782879954\n        }, \n        {\n            \"id\": \"e777874f-2936-11a1-3269-68a6c1648a92\", \n            \"last_modified\": 1455782547511\n        }\n    ]\n}\n```\n. Good catch!\n. Fixed in mozilla-services/cliquet#656\n. Fixed in #660\n. You are right it seems to be a nginx configuration redirection rather than a kinto problem.\nYou can have a look at:\n```\n$ curl -i 'https://kinto.dev.mozaws.net/heartbeat'\nHTTP/1.1 301 Moved Permanently\nContent-Type: text/html\nDate: Fri, 19 Feb 2016 09:44:52 GMT\nLocation: https://kinto.dev.mozaws.net/v1/\nServer: nginx\nContent-Length: 178\nConnection: keep-alive\n\n301 Moved Permanently\n\n301 Moved Permanently\nnginx\n\n\n```\n. I did:\nlocation / {\n        return 301 https://$host/v1$request_uri;\n    }\nIt seems to work.\n. It seems to be because the repository that you defined for the socket parameter of uwsgi doesn't exists or doesn't have the right permissions:\nsocket = /var/run/uwsgi/kinto.sock\nYou may try:\nsudo mkdir -p /var/run/uwsgi\nThen make sure the user that runs uwsgi can access  /var/run/uwsgi and can write in the uwsgi directory.\n. Yes please :)\n. Is it when you want to handle multiple python versions?\nI cannot find something else than this in the UWSGI documentation: http://uwsgi-docs.readthedocs.org/en/latest/WSGIquickstart.html#bonus-multiple-python-versions-for-the-same-uwsgi-binary\n. r+\n. @nocturnalwarz Could you try to upgrade to Kinto 2.0 and give us the new stacktrace?\nIt looks like we are not posting JSON but a string. With Kinto 2.0 you should not be allowed to do that anymore.\n. Actually a user doesn't exists while she doesn't have a permission yet.\nSo the 403 is because she doesn't have any permissions yet.\nA call to the default bucket will create the bucket and change this 403 into a 200.\n. Yes it makes sense :+1: \n. After discussion on this, we propose that getting the list of buckets for a user always return a response which can be an empty list if the user never accessed her default bucket.\n. I can do it today.\n. Feel free to comment. r? @leplatrem \n. Yes it is much better thanks!\n. Seems like a problem with the pip version installed in your virtualenv :(\n. However kinto --version doesn't exists:\n$ ./.venv/bin/kinto --version\nusage: kinto [-h] [--ini INI_FILE] [--backend BACKEND]\n             {init,migrate,start} ...\nkinto: error: too few arguments\n. Apparently the build didn't work: https://hub.docker.com/r/kinto/kinto-server/builds/b6udavocsnvt3vg7vtizzpt/\n. I will try to trigger it again.\n. Yes.\n. It works here.\n. What happens is that every time we push on master an new docker build is triggered. Some of them breaks.\nMaybe we should only build new docker images on tags.\n. I opened https://github.com/Kinto/kinto/issues/654 to address this recuring problem.\n. Which tag are you using?\n. I re-triggered the build for the latest master.\n. Can you try with the last build?\n. It is already closed but it reappears when the docker build fails.\n. Fixed in 55de173\n. Using PATCH you can update one of the permission at the time but it is true that you need to handle the list locally.\nPreviously we could do something like {\"permissions\": {\"read\": [\"+niko\", \"-natim\"}]}} but it wasn't really restful.\nAnother proposal was to let people use this syntax:\n{\"permissions\": {\"read\": {\"add\": [\"niko\"], \"remove\": [\"natim\"]}}}\nBut we ended up saying that the value set to an attribute should be the same as the one that we get when fetching the record:\n{\"permissions\": {\"read\": [\"niko\"]}}\nAdding an endpoint per permission doesn't seems to be consistent with what we currently have in the API. (Being able to upgrade sub objects but naming them in the endpoint)\nAlso I think we should address this nevertheless.\n. Note that we have a similar problem with the group members management.\nIf I want to add Alice as a moderator of my blog articles I would probably want to be able to write a request to add Alice without minding about who is already in the permission/group.\n. A solution could be to follow RFC 6902 which is using something like:\n[\n  { \"op\": \"add\", \"path\": \"/permissions/read\", \"value\": \"niko\" },\n  { \"op\": \"remove\", \"path\": \"/permissions/read\", \"value\": \"natim\" }\n]\n. You are right we should return a 415 Unsupported Media Type error\n. Surprisingly, there are tests about that in cornice: https://github.com/mozilla-services/cornice/blob/master/cornice/tests/test_validation.py#L192-L228\n. I have added failing tests so that we can investigate why cornice doesn't catch the matter.\n. Tests are passing with this branch: https://github.com/mozilla-services/cliquet/pull/667/files\n. Waiting on https://github.com/mozilla-services/cliquet/pull/667 to get merged\n. mozilla-services/cliquet#667 has been merged.\n. Test are passing on cliquet master: https://travis-ci.org/Kinto/kinto/jobs/112033653\nWe need a release before merging this.\n. Updated.\n. Fixed and merged in 55de173\n. Thank you for that :+1: \n. For the question of deletion, something that we had in mind is to mark the record as deleted and put it in a garbage collections (using a listener) and then having a job that remove very old items from the garbage.\n. Thanks.\n. r+\n. It is hard to grasp what got fixed without a test :)\n. I think if we are fixing a bug there we should add one.\n. Let me write one :+1: \n. Yes I would :)\n. WFM\n. LGTM :+1: \n. Thank you for your PR. It looks good.\n. Thank you for that it looks great.\n. Thank you for this it is great. I will let @leplatrem review it for the wording part however the feature and tests seems to be there for me.\nYou may want to tacle #487 which is more or less the same idea. \n. Ok I have pushed my reviews.\n. @lavish205 this is great thank you :+1: \n. config.add_api_capability(\"flush\",\n                          description=\"The __flush__ endpoint can be used to remove all data from all backends.\",\n                          url=\"http://kinto.readthedocs.org/en/latest/configuration/\"\n                              \"settings.html#activating-the-flush-endpoint\")\n. Implemented in https://github.com/Kinto/kinto/pull/496\n. This looks great :+1: \n. Thank you @ayusharma :)\n. This: https://sentry.prod.mozaws.net/operations/kinto-stage/group/241579/\n. Usually I shared them publicly so it should work.\n. ```\nStacktrace (appel le plus r\u00e9cent en dernier) : \nFile \"app.wsgi\", line 23, in \n    application = main(config.items('DEFAULT'), dict(config.items('app:main')))\n  File \"kinto/init.py\", line 43, in main\n    default_settings=DEFAULT_SETTINGS)\n  File \"cliquet/initialization.py\", line 530, in initialize\n    config.include(\"cliquet\", route_prefix=api_version)\n  File \"pyramid/config/init.py\", line 798, in include\n    c(configurator)\n  File \"cliquet/init.py\", line 155, in includeme\n    step_func(config)\n  File \"cliquet/initialization.py\", line 190, in setup_storage\n    backend = storage_mod.load_from_config(config)\n  File \"cliquet/storage/postgresql/init.py\", line 743, in load_from_config\n    client = create_from_config(config, prefix='storage_')\n  File \"cliquet/storage/postgresql/client.py\", line 94, in create_from_config\n    engine = sqlalchemy.engine_from_config(settings, prefix=prefix, url=url)\n  File \"sqlalchemy/engine/init.py\", line 427, in engine_from_config\n    return create_engine(url, options)\n  File \"sqlalchemy/engine/init.py\", line 386, in create_engine\n    return strategy.create(args, *kwargs)\n  File \"sqlalchemy/engine/strategies.py\", line 144, in create\n    engineclass.name))\n```\n. I think it is because the config name is wrong, @phrawzty can you verify that it looks like this? http://kinto.readthedocs.org/en/latest/configuration/production.html#recommended-settings\nOr paste the config here?\n. I wonder if we should add an exclude option rather than just removing the fact that default_bucket is added if not present in kinto.includes.\nWhat you did is is a nice way to not change the behavior and still let people deactivate the default bucket.\nBut I think we shouldn't add the default_bucket if it is not present in the kinto.includes.\n. I have rebased it here: https://github.com/Kinto/kinto/compare/woovar-495?expand=1\n. Tests are there: https://travis-ci.org/Kinto/kinto/builds/114452479\n. Superseeded by #499\n. Thanks you @lavish205 for this. It looks good to me. I will let @leplatrem review it :+1: \n. It works for me if tests passes :+1: \n. r+ (comment should not block this as it is the current behavior)\n. You are not supposed to have all this build files. nor *~ ones\n. @Sayli-Karnik I am closing this PR here and I would be in IRC to help you if you need it to do what @leplatrem said.\n. Fixed in https://github.com/Kinto/kinto/pull/510\n. > Velruse has not received any commit for 3 years.\nDoes it means that we should not use it?\nThe developers behind it are from Mozilla and the project is well tested so it should be usable IMHO.\n. r+\nGreat thanks :+1: \n. The problem have been merged into Cliquet master.\n. Tests are passing with cliquet-master. We can/should wait for a cliquet release before merging.\n. cliquet 3.1.2 have been released with this fix.\n. Tests are now green :+1: \n. @ipsha21 Can you do what @leplatrem suggested?\n. Why don't you use the apt-get install redis-server python2.7 python2.7-dev command instead of compiling Python by hand?\n. This is greatissime\n. > Is cliquet.events.redis in the document wrong?\nYes probably, we need to change that, do you mind filing a pull-request to fix this?\n. > redis.exceptions.ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n\nIf the value of KINTO_EVENT_LISTENERS_REDIS_URL was changed to any value, the same error occurred. \n\nThat's a good point.\nAccording to the code, it should be: KINTO_EVENT_LISTENERS_REDIS_URL so you are right.\nI will investigate why it doesn't work.\n. So using:\nkinto.event_listeners = redis\nkinto.event_listeners.redis.use = cliquet.listeners.redis\nkinto.event_listeners.redis.url = redis://redis:6379/0\nkinto.event_listeners.redis.pool_size = 5\nkinto.event_listeners.redis.listname = queue\nIt seems to work.\n. Using KINTO_EVENT_LISTENERS_REDIS_URL=redis://redis:6739/0 instead it doesn't.\n. No :)\n. Thanks @happy-tanuki :)\n. Hi @chrismbeckett \nIt looks like some database migration didn't run. Did you ran kinto migrate?\n. I can still see ifs like this one here: if [[ $ACTION != loadtest_tutorial && $ACTION != loadtest_simulation ]];\n. Why would you like to do that?\nSince you are describing matrix, you do not need to exclude them because they will be part of the matrix they are related to and not the other ones.\n. I can work on this, @lavish205 can you make sure I have permission to write in your branch?\n. Apparently I have the permission already. Let's see if travis is happy with the changes.\n. r? @leplatrem \n. @vsham20 You could have a look at how @apratti did it here: https://github.com/apratti/kinto/commit/2a6ef036fa7dc4af013095aafc3b897183c39447\n. @apratti feel free to file a PR if you want to help :+1: \n. I will probably do the mandatory changes. I though @vsham20 was going to do it that's why I didn't so far.\n. Revamped in #702 \n. I would rather go for a docker link with nginx so that nginx handles the SSL offload.\n. What you can do is to use a socket file so that only process having access to this file can read and write to it. That is the setup we have with uwsgi: http://kinto.readthedocs.org/en/latest/configuration/production.html#running-with-uwsgi\n. If you use something like that: http://kinto.readthedocs.io/en/stable/configuration/production.html#running-with-uwsgi\nFor instance it looks like that:\n[uwsgi]\nwsgi-file = app.wsgi\nenable-threads = true\nsocket = /home/ubuntu/.run/uwsgi/kinto.sock\nchmod-socket = 666\nprocesses =  3\nmaster = true\nmodule = kinto\nharakiri = 120\nuid = ubuntu\ngid = ubuntu\nvirtualenv = /home/ubuntu/venvs/kinto\nlazy = true\nlazy-apps = true\nsingle-interpreter = true\nbuffer-size = 65535\npost-buffering = 65535\nThen you can run uwsgi and have nginx serve the service in HTTPS with a config like that:\n```\nserver {\n    listen 443 ssl http2;\nserver_name kinto.yourdomain.com;\n\nssl_certificate /etc/nginx/ssl/certificate.crt;\nssl_certificate_key /etc/nginx/ssl/certificate.key;\n\nlocation /attachments {\n    root /home/ubuntu;\n}\n\nlocation /v1 {\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header X-Forwarded-Proto $scheme;\n    proxy_set_header Host $http_host;\n    proxy_redirect off;\n    proxy_intercept_errors on;\n    uwsgi_pass unix:///home/ubuntu/.run/uwsgi/kinto.sock;\n    uwsgi_read_timeout 120;\n    uwsgi_send_timeout 120;\n    include uwsgi_params;\n}\n\nlocation / {\n    return 301 https://$host/v1$request_uri;\n}\n\n}\n```\nIf you need an intermediate certificate chain, you can use this solution: https://scottlinux.com/2013/09/02/how-to-configure-ssl-certificate-chain-for-nginx/\n. You can use this generator to make sure to have a perfect nginx SSL configuration: https://mozilla.github.io/server-side-tls/ssl-config-generator/\n. Not yet but it is something we would like the community to help us build. Last time I spoke at Mozilla London someone was interested in helping make one.\n. r+\n. This appear to be the case with the Postgresql backend but not with the Memory backend.\n. > Yes, just reproduced with postgresql9.4 (but not with the in-memory backend)\nWe shall add a storage test :+1: \n. No all the storage tests are run with all backends, but we do not run all cliquet tests with all backends.\n. > he told me that the storage tests aren't really run on each backend\nThis is not what I said. If you look at test_storage.py you can see that they are run for each backend.\nThis bug wasn't covered by the storage tests.\nWhat I said is that cliquet tests are mostly run with the Redis backend.\nIt could be a great idea to run them with Postgresql in the travis matrix.\n. This have been fixed in Cliquet 3.1.1\n. We ended-up adding a print of clause and params here: https://github.com/zzzeek/sqlalchemy/blob/master/lib/sqlalchemy/orm/session.py#L1039\n. This was because we were using the memory backend for permission kinto.permission_backend = cliquet.permission.memory while using the postgresql backend for storage.\n. r+\n. So far we used a plugin to add the specific route. (blocklist XML for instance)\n. LGTM\n. This should be merged after mozilla-services/cliquet#700 is released in the next cliquet version.\n. I don't think the tempfs is responsible for permission denied. Are you sure the user defined in the config have got the needed permission to write in this folder and that the folder actually exists?\n. r+\n. Apparently dnf is not present on CentOS 6 :confused: \n@enkidulan any idea why you choose dnf rather than yum here?\n. This look great thanks :+1: \n. Please rebase to ease the review :+1: \n. r+\n. Extra requires will look like that:\n[extras]\nsecurity =\n    aleph\n    bet:python_version=='3.2'\n    gimel:python_version=='2.7'\ntesting =\n    quux:python_version=='2.7'\nApparently long_description is using description-file where we cannot concatenate multiple files apparently.\nHowever that's something we could contribute if need be.\n. It is widely used in the OpenStack community but I guess we don't need to change our current way of handling the setup.py. I don't think so.\n. I believe this has been fixed with: https://github.com/mozilla-services/cliquet/pull/698\n. I might be wrong.\n. Is it possible to silently log the timestamp query error?\n. AFAIK, yes.\n. > the Kinto documentation doesn't say you can update the data and permissions of a record at the same time, but the Cliquet documentation does. Which is right?\nBoth are right, yes you can update both at the same time.\n\nI think this is going to make maintenance of Cliquet documentation much more challenging.\n\nFor sure.\n. I am  a bit reluctant doing that. Kinto is a product and we would like its documentation to be as complete as possible without having to go in the cliquet library documentation.\nHowever permissions in Kinto have a lot of specificities that cliquet doesn't have such as inheritance.\nSo I would rather improve the Kinto documentation to make it more specific to Kinto permission handling.\n. Ok\n. LGTM\n. See https://github.com/rtfd/readthedocs.org/issues/1820. Thanks :)\n. What would be the expected behavior? Displaying the help?\n. I couldn't reproduce with Python2.7:\nbash\n$ kinto --ini test/kinto.ini \nusage: kinto [-h] [--ini INI_FILE] [--backend BACKEND] [-v]\n             {init,migrate,start} ...\nkinto: error: too few arguments\n$ kinto --version\n2.1.1\n. I could reproduce with Python 3.5:\nTraceback (most recent call last):\n  File \"./bin/kinto\", line 11, in <module>\n    sys.exit(main())\n  File \"./kinto/__main__.py\", line 58, in main\n    if args['which'] == 'init':\nKeyError: 'which'\n. Really good catch :+1: \n. Apparently we do not have tests for the CLI tool.\n. r? @n1k0\n. > Looks good though many mocks everywhere\nYes I use them to basically validate the interaction with the user.\nI guess it is still better than no tests in that case.\n. Tests are passing locally. (Travis dans les choux)\n. Good point.\n. Let me try :)\n. I can confirm that adding KINTO_FLUSH_ENDPOINT_ENABLED env variable doesn't work.\n. Refs #515 \n. Did we forget to merge this?\n. We need to add a global option to let OPS hide this version information because in production the version information can be used to detect vulnerable deployments if we were to have CVE in the future.\n. Yes then maybe do we need to add a /__versions__ view rather than adding them on the root endpoint (that doesn't contains any __ prefix)\n. It is usually a good practice to ask nginx to hide its version number: http://krischan.eu/index.php/2014/01/11/howto-hide-your-web-server-version-number-apache-lighttpd-nginx/\n. Ok let's make it simple, we can improve it later if need be :+1: \n. - [x] kinto-admin\n- [x] kinto-amo\n- [x] kinto-attachment\n- [x] kinto-changes\n- [x] kinto-fxa\n- [x] kinto-ldap\n- [x] kinto-pusher\n- [x] kinto-signer\n- [x] kinto-webpush\n. cliquet/resource/__init__.py\", line 738, in _raise_304_if_not_modified\n    if current_timestamp <= modified_since:\nUnboundLocalError: local variable \\'modified_since\\' referenced before assignment\n. I filed a fix on Cliquet, however I don't understand what you are trying to do with this request?\n. > Nothing, it was basically a mistake.\nOk then you are totally right that we have to fix it, good catch :)\n. Refs #231 \n. I am in favor of release early/release often :) Also there are no reason we've broke things (optimism)!\n. I don't know why travis-ci doesn't trigger tests for this branch. Do you?\n. Everything is green great :+1: \n. r+\n. This is great thanks :+1: \n. This can probably be considered as a know limitation/bug. And we should fix it.\n. Yes it looks good to me.\n. I though it was already the case do you know for which backend it is not the case?\n. This is something that we definitely want to fix for the kinto webextension stack.\nRefs: https://sentry.prod.mozaws.net/operations/kinto-webextensions-stage/issues/384592/\nKey (id, parent_id, collection_id)=(81d2f645-5b5f-2e53-fc0c-913e938ef2a4, , bucket) already exists.. I agree with your analyse. I guess we are now ok to move out of sequences at some point. It is possible to handle timestamps differently.\nIf think for the default bucket we shouldn't raise a 409 when a conflict on automatic bucket and automatic collection creation occurs because it should be transparent.\nOtherwise I agree with what you said.. #1122 Add an ignore_conflict argument to create for the default_bucket. I don't think it is a great improvment since we can already do the exact same thing with batch requests.\nIt will add a new endpoints with potentially new bugs while in terms of API it won't be more efficient or faster.\nI don't think we should worry about pagination rules but maybe using the batch limits could be important.\nIf we exceed the limit we could have the same error that we have with the batch endpoint.. That's probably why we are discussing it. Do we want to implement it or close it?\n\ud83d\udc4d to implement it\n\ud83d\udc4e to close it and leave it like that.. I think you are right we need to set cache limit somewhere. That's mandatory for cache right?\nThen I have no idea of how we should handle a cache oversize? Should we raise ? Should we delete some old data? How?\n. https://github.com/hynek/structlog/pull/72 have been merged. I asked for a minor release.\n. Do you think we could add a test to validate that?\n. r+\n. Yes it is :dancer: \n. I would rather go for #633 until we've got https://github.com/hynek/structlog/pull/72\n. r+\n. Apparently https://github.com/hynek/structlog/pull/72 have been merged @glasserc I will let you merge this if you want or wait for a release of structlog.\n. Thank you for putting this here.\n. The plan is to make it so that we can deploy Kinto in AlwaysData.\nThe plan is also to makes it a community backend. We started working on this here to make the setup easier (backend tests and stuff) but we will extract it at some point.\nAs you may have seen this is just WIP PR so that we don't loose the work that have been done so far nothing more.\n. What about Cache-Control: private\n. Using authentication aware ETag would break the API.\n. I am so glad you tackled this :+1: \nr+\n. In your example is it:  (min_age=28 & married=false) | children=2 or min_age=28 & (married=false | children=2)\n. See https://github.com/Kinto/kinto-admin/pull/80#issuecomment-221219579\n. Yes we could try to get the email from the profile server if the profile:email scope is available.\n. > No. There is no user part. We have invited our users to use a token:!\nWell does it makes sense with the admin too?\n. Yes: when people are connected on Kinto I want to display their username / email address in the header to inform them about which user they are logged with. (i.e Gmail header)\nI would like to find a way to do it that works regardless of the login method.\n. I think what the doc propose with token:api-key is just a convention.\nWe never choose to prevent people from using username:api-key did we?\n. I feel completly lost with this PR,\nWhy would you revert patches on the Vary header? Why would you prevent the app for catching?\nI think we need to describe what we are trying to achieve:\n- We do not want to serve catched value to another user.\nThat's what the Vary header is for. If it doesn't we need to investigate why. Preventing user from catching is a hack but not really what we are trying to do here.\n. Ok then I read: https://github.com/Kinto/kinto/issues/635#issuecomment-221246471\n. Did you understand why Vary: Authorization doesn't work?\n. According to Google article I would rather add Cache-Control:  private and keep the Vary header.\n. After discussion this is a good solution because:\n- The client (Firefox/Chrome) will not try to handle the cache automatically. (no_store)\n- The cache control of the kinto protocol will continue to work as described in the documentation.\n. To phrase it differently:\nBy default the server explicitly tells clients to not store cache entries for authenticated responses.\nIf you plan on overriding this behavior, your client calls should explicitly send the appropriate cache headers.\n. r+, pair=@Natim,@n1k0\n. Can we also add the fix for Cache-Control: no_store in this release?\n. r+\n. Seems good to me.\n. This is great :+1: \n. I'd like to make it return only bucket and collection by default and records if we ask for it or at least let the ability to select the kind of records we want to list.\n. Ok then.\n. Yes you can even do a core plugin as for default_buckets\n. I agree with your analysis, the main reason why we did that is to let people create IDs on client side without having to worry about conflicts.\nAlso we have a strategy to generate a UUID from another string (using the md5 approach).\nBut I agree with you that we should let people use something else if need be.\n. I personalty like the approach.\n. What about the two other backends ? permissions and cache?\n. r+\n. LGTM\n. r+\n. LGTM\n. We should update to last master and update the changelog. I would be nice to file the release so that stable doc uses the new logo.\n. LGTM\n. You can read it there: http://kinto.readthedocs.io/en/latest/community.html#how-to-contribute\n. r- about removing the regexp from the UUID4 Generator\n. Oh yeah :)\n. r+\n. I am afraid I don't but I think in the meantime we've have upgrade the dev server to kinto 3.1 so it might have been fixed.\n. Actually I did reproduced with the current kinto.dev server:\nIt appears to be a kinto-pusher bug actually.\n```\n  File \"/home/ubuntu/venvs/kinto/local/lib/python2.7/site-packages/kinto_pusher/listener.py\", line 31\n, in call\n    registry.pusher.trigger(channel, action, payload)\n...\n   File \"/home/ubuntu/venvs/kinto/local/lib/python2.7/site-packages/pusher/pusher.py\", line 152, in tr\nigger\n    raise ValueError(\"Too much data\")\nValueError: Too much data\n```\n. Thanks :+1: \nBy the way if you'd like to plug Github authentication with Kinto you might want to have a look at : https://github.com/mozilla-services/kinto-fxa/commit/fe8cd46d8a51cab7268aeb3bb5a87f96805f3c25\n. It looks like that:\n\n. Oh maybe I can change that in the svg: https://kinto.dev.mozaws.net/attachments/badge.svg\n. I have updated the Verdana font (not present on my computer) with the following fallback fonts: DejaVu Sans,Verdana,Geneva,sans-serif\n. As far as I understand the use case it seems that you will also gzip the file on the server side isn't it?\n. Thank you @enguerran for starting this, could you give me the write access on your fork so that I can file a commit with my changes? You can also take them into account directly.\n. I think one commit will do :)\n. No I was thinking that you could just add a commit with my changes and a flag @natim review that is usually what we do. I am not a big fan of rewritting history but your solution is totally fine :)\n. Ok thanks, I will merge it and we can iterate later :+1: \n. @leplatrem question: Do we want that? Why don't we let that to the client?\n. Thanks\n. r+\n. This seems to be a great start indeed.\n. Yes apparently tests are passing it is just a matter of 2 lines missing in the coverage.\n. According to the test coverage results:\n\nThese are the lines that are not tested:\nWe should add a test to try the cache migration in --dry-mode\n- https://github.com/lavish205/kinto/blob/issue_638/kinto/core/cache/postgresql/init.py#L80-L82\nSame thing for the permission backend:\n- https://github.com/lavish205/kinto/blob/issue_638/kinto/core/permission/postgresql/init.py#L74-L76\nSame thing for the storage backend:\n- https://github.com/lavish205/kinto/blob/issue_638/kinto/core/storage/postgresql/init.py#L94-L96\n- https://github.com/lavish205/kinto/blob/issue_638/kinto/core/storage/postgresql/init.py#L125-L127\n. Your test doesn't cover the lines because you are mocking initialize_schema.\nThe missing tests are to actually call the initialize_schema with dry_run.\n. Totally r+ thanks for fixing that :)\n. Isn't it already the ETag header's role?\n. > It needs to be part of the signed response if we wish to prevent replay of signed content.\nOh that is an interesting edge case.\nI am a bit reluctant at changing the Kinto protocol for that.\n- Could we add the ETag value in the signature body before generating it without changing the response body?\n- Should we always return the tombstone records as @almet was suggesting?\n. > e.g. a way to check that the downloaded files are not more than a 2d old?\nThis is not a solution we have cases when the collection is not updated in two days and when users will start Firefox once a month.\n. r+\n. r+\n. Note that even for non Basic Auth backend we are still using the hmac secret to generate the bucket ID of a given authenticated user.\n. Yes the bucket ID generated is the name of the user default bucket \n. After thinking this through the answer to this question is that we shouldn't need to rotate this secret.\nThis means that you should avoid using the default BasicAuth policy in production.\nYou should use #795 or #933 or any other authentication mecanism.. Ahem\n. It looks like we've forget to update it to 1.7 before the previous release, isn't it?\n. r+\n. Great job \\o/\n. GG.\n. r+\n. Shall we rebase?\n. r+\n. :)\n. LGTM\n. r+\n. r? @leplatrem (I know that you will have lots of coding styling review)\n. r+\n. Yes so we would need to have path a string of bytes in Py2 and a string (unicode) in Py3\n. r+\n. The thing is in development (witch is a even more common use case) you need to have http by default.\nMy take would be to let http by default and add a warning if https is not turned on.\n. It will redirect you from http://localhost to https://localhost/v1/ and it will basically fail with a browser connection error.\n. Hello @Prashant-Surya you have an example of how to display warnings in the code.\nWhat you need to do is the same things as when project_name is missing but when the http_scheme is http.\n. r+\n. Interresting :) r+\n. > Should we be concerned about that when we move from record -> object?\nYes\n. Cannot we be concerned and still use it?\n. To elaborate I think that most of the time we will use object_id and if we need to use object we can choose to use obj instead to not override the object Python global variable?\n. Do you need to grab the deleted when doing the * ?\n. After thinking this through I wonder if we cannot simply add a backend method to do : Use deletion and purge by parent_id for bucket deletion rather than changing existing ones.\n. This is going to land soon :+1: \n. I think you are missing the point of having Redis here.\nWe have three backends, Permissions, Cache and Storage.\nThe reason we have implemented the three backends with Postgresql and Redis is to prevent user from having to install both if they want to.\nYou are right that using Redis for the storage backend in production has got some drawbacks but using Postgresql for cache and permission is not a good fit either.\nHaving both is also the guarantee that the interface exposed can work with both NoSQL and SQL databases so that we can use any backends.\nMost of kinto clients will never use filtering or sorting (kinto.js for instance).\nYou are true that we should enable transaction for the Redis storage backend and we will work on it eventually but postgresql backend didn't had transaction either at first.\nThe reason why we have both is not because Alex and R\u00e9my are fans of Redis it is because Redis is currently our best option for the permission and cache backend.\n. I don't mind having redis as a plugin but I would rather keep it for the same reason we have kinto-history and kinto-default-bucket as part as the core.\n. > Why postgresql is not a good fit for cache and permission ?\nFor cache because it doesn't expire data automatically as part as the DB feature.\nFor permissions because the intersection of sets is a killer feature of Redis.\nI will not enter in the war of PostgreSQL is better than Redis, I don't care. For me it is important to have at least two backends implementations as a warrant of choice.\nNote that we user Redis in production for the cache backend.\n. For me https://github.com/Kinto/kinto/pull/711 is a good example of what I mean by \"warrant of choice\", the way it has been implemented in Postgresql makes it difficult to apply to no SQL backends, we should probably add a new storage method rather than to change the existing ones so that we can do the delete all without having to return previous records or to create tombstones for instance.\nWhat you call memory-to-disk is exactly what redis is offering so I would be in favor of keeping Redis rather than replacing it by another backend.\nI don't think we can say that our experience with Hello led us to some problems, we already had more problems with Kinto and Postgresql in 6 months than we had for 2 years of Hello.\n. For sure Redis is not a RDBMS but Kinto doesn't need one to store JSON objects. \n. While implementing Quotas I realized that both MemoryBackend and RedisBackend are currently unable to abort a transaction in the ResourceChanged event.\nBoth the kinto-signer and the quota plugin are using this transaction aborting feature to make the request fails in case of 5XX errors.\nThe redis backend is not suitable in its current state for use with these plugins.\nLet's move the backend to a external repository and let the community support it.\n. The Redis backends moved to https://github.com/Kinto/kinto-redis\n. For me it is the expected behavior yes :+1: \n. Appart from the comment it looks good to me :)\n. I've read the code I understand that rather than using the get_bound_permissions function you prepare it and then you pass its result.\nI think I would need some more explanation but it seems a good refactor to me.\n. r+\n. We should probably add a migration function for Postgresql backend to make sure we remove all existing tombstones that have a valid record.\n. r? @leplatrem \n. @leplatrem Could you validate my migration file too?\n. r+\n. r+\n. :+1: \n. r+ But let's release 3.3.0 so that we can release it on kinto-settings stage tomorrow with kinto-dist 0.7.0\n. > Is that feasible?\nYes it is with setup.py entry_points: http://stackoverflow.com/a/9615473/186202\n. r? @leplatrem @n1k0 \n. I wonder if we want to add this to the kinto command itself. In that case it would be great to add permission removal as well.\n. Where should I put the documentation?\n. Test are failing because we are misisng a bit of coverage:\nkinto/core/scripts.py                             47      7    85%   49-51, 57-59, 65\n. Final r? @leplatrem \n. r+wc\n. r+\n. r+\n. f+\n. r+\n. Yeah ! :+1: \n. Superseeded by https://github.com/Kinto/kinto/pull/764\n. Looks good to me.\n. The complexity comes from the fact that we have a fallback in case the version.json file is not present.\n. The major problem is that you cannot add the commit of the tag inside the file if you didn't commit yet. So it is impossible to actually release with the version.json file.\n. r? @leplatrem \n. I am closing for now since we don't have the use case yet we will come back to it later.\n@msathis feel free to propose an implementation if you need it, we will review it and support you if you need it.\n. r=@natim\n. r=@glasserc in #752 \n. That's not the goal of this PR, we can change that before merging if need be.\nRight now, I am trying to implement the solution proposed by @leplatrem in https://github.com/Kinto/kinto/issues/173#issuecomment-222102623 which seems to me to be cleaner.\nUpdating the bucket on each change in it might have a big impact on the kinto protocol and create a lot of HTTP 412. We had a similar discussion before with kinto-attachment and kinto-history and it seems to be safer not to update user data with plugins.\nBut I will rework this until we find a concensus.\n. > I am not sure why you want to update the bucket on each change.\nI will update this PR with the behavior your are mentioning to show you :)\n. I realized that transaction would only work with the Postgresql backend.\n. Looking at it again, it seems that we need to add additional work:\n- [x] Add documentation\n- [x] Add a test on batch with multiple collection with records delete for instance\n- [x] Give more explanation in the 507 message to explain why the QUOTA is exceeded.\n- ~~[ ] Add tests for the default bucket~~ (Not for this PR because we can do it for all)\n. Final r+ @leplatrem \n. The problem we have right now is that the memory backend is not transaction aware. You cannot run the quota plugin tests for instance with the memory backend same for the kinto-signer tests.\nAlso I we were to make the memory backend to handle transaction, all the tests listed before would fail.\n. I'd like us to be consistent for features based on transaction, so I guess it worth it but right now we don't need it.. r? @leplatrem \n. :+1: \n. Yes it looks like a race condition in the memory backend.\nDo you mind testing with the PostgreSQL or Redis backend if you can reproduce the matter?\n. r+\n. r+\n. I am always a bit reluctant to remove features that are implemented and working.\nThe simple fact that we needed it for readinglist seems important to me.\nHowever this seems to be a edge case that would be implemented using a plugin if we need it again.\n. r+\n. > don't we have to provide a version.json file before uploading to pypi? \nWe probably should yes the problem being to do it after the tag and before uploading to pypi...\n. > resources without permissions (records per user-id)\nFor this one in particular, we are using to store plugin settings (kinto-webpush)\nFor most of these features I don't see the benefit of getting rid of them being really likely to need the feature back again in a near future:\n- Newrelic to investigate webextension stack deployment\n- For readonly fields we might need it to store the authorship of a record (signoff feature) but we can do it in the listener as well.\n- I don't remember how the private permission works and how it is different from the UserResource.\n. Indeed this https://github.com/Kinto/kinto/blob/master/kinto/core/errors.py#L31-L74 is supposed to be present there: http://kinto.readthedocs.io/en/latest/core/errors.html\n. @leplatrem fixed it, thanks for reporting it :)\n. @elelay could you try to run this branch and see if it fixes your problem while importing a lot of records using the memory backend?\n. I am wondering if the problem is not this https://github.com/Kinto/kinto/pull/767/files#diff-bd99c33b2f5771809d6116eb3a96f751R97\nWe should probably configure the lock before everything else.\n. Yes please.\n. > What problem ?\nThe fact that the process hangs\n. So I tried my fix (having self.__lock__ = RLock() definition in the __init__) but it hangs after the first call.\n. Good catch !\n. r+\n. I wish we could prevent IDs from starting with something else than a letter or digit. It makes them easier to read.\n. r+wc\n. f+\n. bucket_id = payload.pop('bucket_id', None)\n. I was not able to reproduce :s\n. ```\n$ http  :8888/v1/permissions --auth user:pass\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 338\nContent-Type: application/json; charset=UTF-8\nDate: Thu, 18 Aug 2016 16:19:34 GMT\nServer: waitress\n{\n    \"data\": [\n        {\n            \"bucket_id\": \"magic\", \n            \"id\": \"magic\", \n            \"permissions\": [\n                \"write\", \n                \"read\", \n                \"collection:create\", \n                \"group:create\"\n            ], \n            \"resource_name\": \"bucket\", \n            \"uri\": \"/buckets/magic\"\n        }, \n        {\n            \"bucket_id\": \"magic\", \n            \"collection_id\": \"system\", \n            \"id\": \"system\", \n            \"permissions\": [\n                \"write\", \n                \"read\", \n                \"record:create\"\n            ], \n            \"resource_name\": \"collection\", \n            \"uri\": \"/buckets/magic/collections/system\"\n        }\n    ]\n}\n``\n. I am not  sure it is a bug rather than a feature. We were consideringsystem.Authenticated` to be a group in itselve and you cannot add a group to a group.\nAs far as I remember, we are just checking that the user_id is in the group not that the group matches the user principal.\n. We might, but we need to be able to detect that the principal we've got is not the user_id.\nOne way to do so is to check that a : is present in the member we add.\n. But maybe system.Authenticated and system.Everyone should be acceptable because they act as wildcard userid\n. Refs #794 \n. LGTM r+\n. r+\n. r+\n. > Find a way to allow GET as anonymous\nI think this is when you have a permission dynamic set on it and that you match on the system.Everyone principal.\n. I am wondering if we should go that way and not just add filtering and sorting to the previous service.\n. After investigation it seems that you are using a UserResource rather than a ShareableResource Data from a UserResource are linked to a user so you cannot link data to a non authenticated user.\nIf we use a ShareableResource it should work.\nApparently it was not enough, I will need to dig a little more, not sure yet where is the authorization_required decorator triggered.\n. Ok I manage to make it works.\n. What would it actually takes to add the last_modified value? Do we need it?\n. I think we can merge #769 too.\n. r+\n. Thanks a lot @Prashant-Surya \n. r+\n. r+\n. I think with this patch it will not be possible anymore to have a dot in the field name, is it?\n. oh ok\n. r+\n. 2 tests failed in py34 + flake8\ntests/core/resource/test_viewset.py:1:1: F401 'colander' imported but unused\ntests/core/resource/test_viewset.py:163:9: E303 too many blank lines (2)\ntests/core/resource/test_viewset.py:202:9: E303 too many blank lines (2)\n. >  it also returns 403 even I have the permission to create new objects\nThis should be only the case for buckets.\n. Yes I agree that it should be consistent and I agree with your proposed solution.\n. Yes go ahead :)\n. I think the next step should be to start a PR adding a test for the behavior we want and the one we don't and then we can elaborate from there.\n. https://github.com/Kinto/kinto/blob/master/tests/test_views_buckets.py#L145-L148\n. Yes, let's do that :)\n. Maybe keeping Kinto user management outside of Kinto is still a good idea. I wish we could colaborate around #933. I guess starting with a tutorial explaining the issue with Authentication and how people can plug the backend they'd like would be great.\nOne thing would be to add an OpenID-Connect compliant authentication backend. (kinto-fxa could be a great start for that).\nAnd of course the accounts plugin, that would allow to create users with their profile, eventually plug multiple authentication mecanisms to them, or create anonymous accounts that they can activate so that you can create things and give permissions to people not having an account on your kinto just yet.\nFew days ago I've started a Blueprint about it It would be nice to review it, improve it and implement a proof of concept.\n@kulshekhar if you feel like driving this we will help you for sure. Do not hesitate to join our slack channel\n\n[ ] Tutorial about authentication with Kinto\n[ ] kinto-openidconnect\n[ ] kinto-accounts. That would be awesome.. I had the same error on Friday. I don't know what changed for it to suddenly appear.\nIt looks like it is not using the correct input function from six. I am planning to work on this today.\n. Ok this commit break it: https://github.com/Kinto/kinto/commit/ab3db80c0a99a88a4430c1c4fa140f991dd5c833#diff-87f3ff0cfd5b39515d0d84446afef901\n. Released in Kinto 4.1.1\n. So if I understand the code correctly it is going to used like that: /records?like_title=Mo\nI thought the plan was to use ?contains_title=Mo in #791 \n. I don't have a strong opinion on this. I guess we can keep like_ for now.\n. > Am I right assuming this change is not classified as a change in HTTP API ?\n\nYes it is a minor change in the HTTP API because we are adding a parameter :)\n. r+\n. I updated the API version with: https://github.com/Kinto/kinto/commit/d08523c0ea0b9ee054a042b30285062369e45d42\n. Refs https://github.com/mozilla-services/cornice/pull/372\n. No he means the link in the home page in the Overview section here: http://kinto.readthedocs.io/en/latest/overview.html#faq\n. Add record:create in the inheritence tree to imply collection:read\n. We want to keep the current behavior which is that you can read only records that you have permission on, when you create a record you can get the administrator right on this record.\n. Because he has got read permission on his records.\n. You can try it it already works.\n. > I think he should be able to list records, but only his own records.\nYes I get it but it is already the case and already included in both @leplatrem proposition and implemented code. So there is nothing to change in the code or @leplatrem proposition to have what you are asking for.\n. The 403 is not to leak any information to not authorized users about the fact that the collection exists or not for them.\n. Looks good to me :) Thanks\n. r+\n. https://github.com/Kinto/kinto/commit/eaac16a0eedad018bbd938764ae49e6f76b8cdd1\n. Good catch r+\n. @leplatrem I would like to talk a bit with you to make sure we are adopting the correct strategy here.\n. your intuition was correct...\n. Let me add the tests in a new PR so that we can see if we still have the issue.. Superseeded by #1253. Right now we used to generate the CSV file on the client side which is not optimal...\n. Should we add a title row? How do you know that rows are in the correct order since items are dicts?. Yes are correct, this is a bug we fixed last week: https://github.com/Kinto/kinto/issues/804\nI am going to release a new version of Kinto so that you can grab a version with the bugfix.\n. Refs https://github.com/Kinto/kinto/pull/820\n. Here you go: https://github.com/Kinto/kinto/releases/tag/4.2.0\nto update your kinto-heroku deploy, you can follow these instructions\n. Apparently there are a lot of edge case to support for that.\n. Try to put a virtualenv absolute path in the ini file.\n. Do you have any site in your config?\n. No I just don't know which site module it is talking about.\n. After a teleconsole session we were able to track the problem down to the uid and gid not being able to access the sourcecode.\n. Maybe @ptgamr you should file a PR to add to the troubleshooting section if you can.\n. Thanks\n. Really useful thanks r+\n. In the redis backend we need to also import: ImportError: cannot import name MemoryStorageTest\n. @n1k0 any thoughts about it?\n. This will help people to use an hosted version of the kinto admin available at http://localhost:8888/v1/admin/\n. @VarnaSuresh yes please do \ud83d\udc4d \n. Fixed with https://github.com/Kinto/kinto/commit/a0ce6b45083fdfbdf70b89bb2a50ca0abf6d7a79\n. I merged it by mistake. \n. I think there have been taken into account, do you see something missing in master?\n. Yes by mistake because some documentation were missing and the test for Python3 were failing.\n. In that case we want a redirection to /buckets/default/collections\n. We can wait for #846 to be merged.\n. Done.\n. OPTIONS should always return a 200.\n. Yes.\n. Any reason why you wanted to close the PR?\n. Do you mind adding a test to make sure it works with your fix?\n. Actually we can iterate on PR so if you add commit in your branch you will be able to update the PR.\n. > Sorry for the mess I've made here. :/\nBtw don't be sorry I don't feel like you made any mess :)\n. After thinking a bit about this issue with @leplatrem over IRC we propose the following:\n- Handle the id field in the storage, a resource id is always a string.\n- Handle collection_id, group_id and record_id in the history plugin.\n. After a reset you can push force your branch remotely.\n. Great work thank :)\n. Updated.\n. @d1ndra yes It is possible that you need to change the three tests you are talking about.\n. That's so great thanks !\nI think the API doc must be updated as well :)\n. Yes let me fix the docs build.\n. @sunakshi96 any update on your side?\n. Could you please update your PR branch, it is easier to follow up on the previous pull-request.\n. This one: https://github.com/Kinto/kinto/pull/864\n. Thanks :)\n. If possible I would rather fix it like that: https://github.com/Kinto/kinto/pull/870\n. And add your name in contributors if it is not already the case.\n. I am not against using JSONSchema for that but rather a bit reluctant.\nHow would it looks like in terms of code separation? Will we create JSON files with the JSONSchema for each kind? (bucket, collection, group, permission, record, history, webpush) and load the file from the Python code?\nAs you said the biggest impact would be the error messages that would be hard to configure.\nI am not sure it worth it to be honest.\n. > Why are we transforming a 403 into a 401 anyway?\nThat's to be consistent with the Kinto protocol. If you are not authenticated you should have a 401 and not a 403.\n. I agree with the fix, I wonder if we can add a test there.\n. How do you detect if the transaction is opened or not?\n. As much as security people want's to use.\nRight now they want to use this command to generate the salt:\ncat /dev/urandom | tr -dc _A-Z-a-z-0-9 | head -c${1:-32}; echo\n. The same way we do for the userHmacSecret I guess. Using the command kinto init to generate it and then we will have something different for kinto-heroku and in the doc we can explain to people how to change it.\n. Yes something like that as well as adding some tests and updating the kinto command.\nsecret = settings.get('default_bucket_ID_salt', settings['userid_hmac_secret']). You shouldn't use the build:gh-pages command.\nIf dist doesn't exist anymore there it is probably a bug of the kinto-admin that removed it.\nThe KINTO_ADMIN_PREFIX is supposed to do the CSS job, also the kinto-admin command is supposed to exists which proves that something went wrong when you ran the command.\n. Apparently the new procedure is there: https://github.com/Kinto/kinto-admin/#installation\nI will update the Makefile accordingly.\n. I guess your fork is outdated: https://github.com/Kinto/kinto/blob/master/setup.py#L29. > Why is it so important? From the Pyramid point of view, it's there!\nActually from Kinto point of view it is not and if it is it is an issue because you could have conflict between two Authorizaton policy that would give the same user_id principal while it shouldn't be possible\nAs you can see it is removed from the permit function you linked.\n. We hit that bug today when trying to remove records from a user default_bucket, they didn't show in the admin. Actually I think this should be part of kinto-http.py rather than the kinto-cli which is to handle local kinto.\n. Creating back the collection and removing it again fixed the issue.\n. Yes, I did, do you want a demo?\n. The same problem occurs with the bucket, but creating them and deleting them doesn't fix the issue.\n. After playing around with the matter, I even get a 500 on the permission endpoint:\nFile \"/home/nelson/kinto/venv/lib/python2.7/site-packages/pyramid/viewderivers.py\", line 147, in _requestonly_view\n    response = view(request)\n  File \"/home/nelson/kinto/venv/lib/python2.7/site-packages/cornice/service.py\", line 571, in wrapper\n    response = view_()\n  File \"/home/nelson/kinto/venv/lib/python2.7/site-packages/kinto/core/resource/__init__.py\", line 270, in collection_get\n    include_deleted=include_deleted)\n  File \"/home/nelson/kinto/venv/lib/python2.7/site-packages/kinto/views/permissions.py\", line 99, in get_records\n    perms_by_object_uri.setdefault(bucket_uri, []).extend(resource_perms)\nAttributeError: 'set' object has no attribute 'extend'\n. ```http\n$ http GET https://kinto.dev.mozaws.net/v1/permissions --auth natim:\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, Total-Records, ETag, Pragma, Cache-Control, Backoff, Next-Page\nCache-Control: no-cache, no-store\nConnection: keep-alive\nContent-Length: 11\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 21 Nov 2016 17:19:12 GMT\nETag: \"1479713513758\"\nLast-Modified: Mon, 21 Nov 2016 07:31:53 GMT\nServer: nginx\nTotal-Records: 0\n{\n    \"data\": []\n}\n$ http GET https://kinto.dev.mozaws.net/v1/buckets/default/collections/toto --auth natim:\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, ETag, Pragma, Cache-Control, Backoff\nCache-Control: no-cache, no-store\nConnection: keep-alive\nContent-Length: 155\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 21 Nov 2016 17:19:27 GMT\nETag: \"1479748767193\"\nLast-Modified: Mon, 21 Nov 2016 17:19:27 GMT\nServer: nginx\n{\n    \"data\": {\n        \"id\": \"toto\", \n        \"last_modified\": 1479748767193\n    }, \n    \"permissions\": {\n        \"write\": [\n            \"basicauth:df93ca0ecaeaa3126595f6785b39c408be2539173c991a7b2e3181a9826a69bc\"\n        ]\n    }\n}\n$ http GET https://kinto.dev.mozaws.net/v1/permissions --auth natim:\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, Total-Records, ETag, Pragma, Cache-Control, Backoff, Next-Page\nCache-Control: no-cache, no-store\nConnection: keep-alive\nContent-Length: 523\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 21 Nov 2016 17:19:29 GMT\nETag: \"1479713513758\"\nLast-Modified: Mon, 21 Nov 2016 07:31:53 GMT\nServer: nginx\nTotal-Records: 2\n{\n    \"data\": [\n        {\n            \"bucket_id\": \"287baf1e-7861-e2e0-b0ed-e38c9fa08b2a\", \n            \"collection_id\": \"toto\", \n            \"id\": \"toto\", \n            \"permissions\": [\n                \"write\", \n                \"read\", \n                \"read:attributes\", \n                \"record:create\"\n            ], \n            \"resource_name\": \"collection\", \n            \"uri\": \"/buckets/287baf1e-7861-e2e0-b0ed-e38c9fa08b2a/collections/toto\"\n        }, \n        {\n            \"bucket_id\": \"287baf1e-7861-e2e0-b0ed-e38c9fa08b2a\", \n            \"id\": \"287baf1e-7861-e2e0-b0ed-e38c9fa08b2a\", \n            \"permissions\": [\n                \"write\", \n                \"collection:create\", \n                \"group:create\", \n                \"read\", \n                \"read:attributes\"\n            ], \n            \"resource_name\": \"bucket\", \n            \"uri\": \"/buckets/287baf1e-7861-e2e0-b0ed-e38c9fa08b2a\"\n        }\n    ]\n}\n$ http DELETE https://kinto.dev.mozaws.net/v1/buckets/default --auth natim:\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nConnection: keep-alive\nContent-Length: 99\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 21 Nov 2016 17:19:42 GMT\nServer: nginx\n{\n    \"data\": {\n        \"deleted\": true, \n        \"id\": \"287baf1e-7861-e2e0-b0ed-e38c9fa08b2a\", \n        \"last_modified\": 1479748782546\n    }\n}\n$ http GET https://kinto.dev.mozaws.net/v1/permissions --auth natim:\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, Total-Records, ETag, Pragma, Cache-Control, Backoff, Next-Page\nCache-Control: no-cache, no-store\nConnection: keep-alive\nContent-Length: 263\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 21 Nov 2016 17:19:45 GMT\nETag: \"1479713513758\"\nLast-Modified: Mon, 21 Nov 2016 07:31:53 GMT\nServer: nginx\nTotal-Records: 1\n{\n    \"data\": [\n        {\n            \"bucket_id\": \"287baf1e-7861-e2e0-b0ed-e38c9fa08b2a\", \n            \"collection_id\": \"toto\", \n            \"id\": \"toto\", \n            \"permissions\": [\n                \"write\", \n                \"read\", \n                \"read:attributes\", \n                \"record:create\"\n            ], \n            \"resource_name\": \"collection\", \n            \"uri\": \"/buckets/287baf1e-7861-e2e0-b0ed-e38c9fa08b2a/collections/toto\"\n        }\n    ]\n}\n```. Other example:\n```http\n$ http GET https://kinto.dev.mozaws.net/v1/permissions --auth natim:other\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, Total-Records, ETag, Pragma, Cache-Control, Backoff, Next-Page\nCache-Control: no-cache, no-store\nConnection: keep-alive\nContent-Length: 11\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 21 Nov 2016 17:20:59 GMT\nETag: \"1479713513758\"\nLast-Modified: Mon, 21 Nov 2016 07:31:53 GMT\nServer: nginx\nTotal-Records: 0\n{\n    \"data\": []\n}\n$ http PUT https://kinto.dev.mozaws.net/v1/buckets/demo --auth natim:other\nHTTP/1.1 201 Created\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nConnection: keep-alive\nContent-Length: 155\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 21 Nov 2016 17:21:10 GMT\nETag: \"1479748870282\"\nLast-Modified: Mon, 21 Nov 2016 17:21:10 GMT\nServer: nginx\n{\n    \"data\": {\n        \"id\": \"demo\", \n        \"last_modified\": 1479748870282\n    }, \n    \"permissions\": {\n        \"write\": [\n            \"basicauth:b6d49dda0843da512f8efb5ecca60c9faf845fed6762b98f4193a824488d0162\"\n        ]\n    }\n}\n$ http GET https://kinto.dev.mozaws.net/v1/permissions --auth natim:other\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, Total-Records, ETag, Pragma, Cache-Control, Backoff, Next-Page\nCache-Control: no-cache, no-store\nConnection: keep-alive\nContent-Length: 174\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 21 Nov 2016 17:21:14 GMT\nETag: \"1479713513758\"\nLast-Modified: Mon, 21 Nov 2016 07:31:53 GMT\nServer: nginx\nTotal-Records: 1\n{\n    \"data\": [\n        {\n            \"bucket_id\": \"demo\", \n            \"id\": \"demo\", \n            \"permissions\": [\n                \"write\", \n                \"collection:create\", \n                \"group:create\", \n                \"read\", \n                \"read:attributes\"\n            ], \n            \"resource_name\": \"bucket\", \n            \"uri\": \"/buckets/demo\"\n        }\n    ]\n}\n$ http DELETE https://kinto.dev.mozaws.net/v1/buckets/demo --auth natim:other\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nConnection: keep-alive\nContent-Length: 67\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 21 Nov 2016 17:21:21 GMT\nServer: nginx\n{\n    \"data\": {\n        \"deleted\": true, \n        \"id\": \"demo\", \n        \"last_modified\": 1479748881249\n    }\n}\n$ http GET https://kinto.dev.mozaws.net/v1/permissions --auth natim:other\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, Total-Records, ETag, Pragma, Cache-Control, Backoff, Next-Page\nCache-Control: no-cache, no-store\nConnection: keep-alive\nContent-Length: 11\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 21 Nov 2016 17:21:23 GMT\nETag: \"1479713513758\"\nLast-Modified: Mon, 21 Nov 2016 07:31:53 GMT\nServer: nginx\nTotal-Records: 0\n{\n    \"data\": []\n}\n$ http PUT https://kinto.dev.mozaws.net/v1/buckets/demo --auth natim:other\nHTTP/1.1 201 Created\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nConnection: keep-alive\nContent-Length: 170\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 21 Nov 2016 17:21:29 GMT\nETag: \"1479748889188\"\nLast-Modified: Mon, 21 Nov 2016 17:21:29 GMT\nServer: nginx\n{\n    \"data\": {\n        \"deleted\": true, \n        \"id\": \"demo\", \n        \"last_modified\": 1479748889188\n    }, \n    \"permissions\": {\n        \"write\": [\n            \"basicauth:b6d49dda0843da512f8efb5ecca60c9faf845fed6762b98f4193a824488d0162\"\n        ]\n    }\n}\n$ http PUT https://kinto.dev.mozaws.net/v1/buckets/demo/collections/test --auth natim:other\nHTTP/1.1 201 Created\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nConnection: keep-alive\nContent-Length: 155\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 21 Nov 2016 17:21:36 GMT\nETag: \"1479748896708\"\nLast-Modified: Mon, 21 Nov 2016 17:21:36 GMT\nServer: nginx\n{\n    \"data\": {\n        \"id\": \"test\", \n        \"last_modified\": 1479748896708\n    }, \n    \"permissions\": {\n        \"write\": [\n            \"basicauth:b6d49dda0843da512f8efb5ecca60c9faf845fed6762b98f4193a824488d0162\"\n        ]\n    }\n}\n$ http DELETE https://kinto.dev.mozaws.net/v1/buckets/demo --auth natim:other\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nConnection: keep-alive\nContent-Length: 67\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 21 Nov 2016 17:21:40 GMT\nServer: nginx\n{\n    \"data\": {\n        \"deleted\": true, \n        \"id\": \"demo\", \n        \"last_modified\": 1479748900469\n    }\n}\n$ http GET https://kinto.dev.mozaws.net/v1/permissions --auth natim:other\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, Total-Records, ETag, Pragma, Cache-Control, Backoff, Next-Page\nCache-Control: no-cache, no-store\nConnection: keep-alive\nContent-Length: 199\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 21 Nov 2016 17:21:44 GMT\nETag: \"1479713513758\"\nLast-Modified: Mon, 21 Nov 2016 07:31:53 GMT\nServer: nginx\nTotal-Records: 1\n{\n    \"data\": [\n        {\n            \"bucket_id\": \"demo\", \n            \"collection_id\": \"test\", \n            \"id\": \"test\", \n            \"permissions\": [\n                \"write\", \n                \"read\", \n                \"read:attributes\", \n                \"record:create\"\n            ], \n            \"resource_name\": \"collection\", \n            \"uri\": \"/buckets/demo/collections/test\"\n        }\n    ]\n}\n```. Great thanks :)\n. How does it works with tombstones?\n. Ok so we recreate it with the same last_modified id, we recreate all the child objects with their ID and last_modified value, we recreate all the permissions and we add tombstones for all the recreated objects. Is that correct?\n. Ok then we should probably allow to rename only bucket / collections but not records because it will break the synchronization mecanism.\n. The context is that the request.path was having a prefix that was not recognized by Kinto so that no route where matching. I fixed the fcgi script\n. When I see your screenshot I remember that we want to be able to remove FxA and to rename Basic auth in LDAP for the kinto-writer.\nI don't know if we can use plugin to handle authorization policies there.\n. It is meant to be like this. If it doesn't exists but you don't have the permission to know it you will have a 403. However if you have the permission to know it you will get a 404.\n. However it is not specific to buckets, if you give permission to anyone to read bucket you will get a 404 as well. Or if you don't have the permission to read the collection or record you will get a 403.\n. Yes I guess the read permission on the parent should be enough to have a 404.\n. Yes we should.\n. Are we going to backport it to Kinto 4.4 too?\n. Apparently tagging transaction < 2 is not sufficient anymore. We need to also pin the pyramid_tm version too.. Yes it is basically FxA authentication policy but for portier :). Can we also add tests to make sure it works with records and groups when you delete the buckets and with records when you delete the collection?. r? @leplatrem . \n. Did you update the setup.py file?. Same question for the documentation version. Image. Oups @EtienneM was faster.. For instance for attachment you need it to know on which record you want to assign the attachment to.\nWe can probably have helper that let us get this information from the URI but I like the idea of having them already there in the payload.\nIf event's are different ones I don't mind having a different payload because a plugin most of the time subscribe to one event at the time, so we won't need different event handling. Also if record_id is not present it probably means that you don't need it, right?. > do those commits automatically get included in this pull request to merge\nYes. I've seen that in the past. Try to change the kinto.ini to use host = 127.0.0.1 rather than 0.0.0.0. Actually the Docker images do but yes I guess it is fine.. I totally agree :). \ud83d\udc4d Go ahead \ud83d\udc83 . It is because of a mock on kinto.core.storage.random.random. I think it is yes. Thanks for telling me about it.. Thanks :). r? @leplatrem . \ud83d\udc4d . Yes exclude works too \ud83d\udc4d . I tried that yesterday not sure it works.. Tests passes \ud83d\udc83 \nCould you add a line in the Changelog in Internal Changes?\nThanks a lot :). Don't apologies :) That's totally normal to break the build! It is there to break actually :). It looks good to me thanks :). I tried to reproduce but cannot.. > We keep capabilities for API features that can be disabled/enabled from settings.\nYes so if this feature lands as a default plugins we should probably have a capability.. We should probably add it.. It is not your fault @leplatrem this thing is shitty.... This command is really too dangerous, for instance you cannot remove tombstones only for record or only for collection.\nI would differentiate between:\n - /buckets/bid/collections/cid\nand\n - /buckets/bid/collections/cid/records\nOr between\n\n/buckets/bid/collections/*\n\nAnd\n\n/buckets/bid/collections/*/records. > If your usage of Kinto does not rely on offline sync, then it is fine to remove the tombstones!\n\nIt is but the usecases we have do rely on it.. I like your suggestion about the Alert header because we don't break any API.\nHowever I am not against raising a 400 because the API starts to be broken with an undefined behavior as soon as people start to use _sort and _limit in their records.. Waiting for #1009 before merging.. Thank you @PeriGK :). Actually this is when in use with pyramid==1.8a1. Related to #1008. _get_credentials was removed and we can use the public extract_http_basic_credentials utility instead. https://github.com/Pylons/pyramid/blob/master/pyramid/authentication.py#L1138-L1175. In production we use 3.5 for webextension and Docker stacks and 2.7 for older stacks.. Apparently tests are not running on Py3.6 yet :). I filled a PR upstream but it seems to be already fixed in master, just not released.\nhttps://github.com/stefankoegl/python-json-patch/pull/58. python-json-patch 1.15 has been released so it should work now. Re launching tests.. The kinto-admin JS is considered as being to some static files dependencies of the admin plugin.\nIf you consider master as being a runnable distribution of Kinto, then we are already doing that.\nWe update it in master for each release of the kinto-admin.\nWe can update the static files to there last version by running make update-kinto-admin\nAfter using this process for few months I find it really robust and easy , why do you think we should change it?\n. I see your point, that something we need to discuss and fix then.. Thanks @windwww :). Apparently there are still 2 tests not passing anymore: https://travis-ci.org/Kinto/kinto/jobs/189584939. Thanks @birdbrained for starting this. I am taking over in #1087 . You can give superuser permissions by adding specific principals in your configuration like that:\n```\nKinto Admins Configuration\nBuckets\nkinto.bucket_create_principals = portier:uid\nkinto.bucket_write_principals = portier:uid\nkinto.bucket_read_principals = portier:uid\nCollections\nkinto.collection_create_principals = portier:uid\nkinto.collection_write_principals = portier:uid\nkinto.collection_read_principals = portier:uid\nGroups\nkinto.group_create_principals = portier:uid\nkinto.group_write_principals = portier:uid\nkinto.group_read_principals = portier:uid\nRecords\nkinto.record_create_principals = portier:uid\nkinto.record_write_principals = portier:uid\nkinto.record_read_principals = portier:uid\n```\nYou can also add permissions for history and other kind of records if need be.. Alternatively we could use a meta namespace:\n{\n  \"data\": [...],\n  \"meta\": {\n    \"last_modified\": \"1480331301530\"\n  }\n}. We could probably do the same thing with all the other meta information:\n{\n    \"meta\": {\n      \"total_records\": 357,\n      \"next_page\": \"https://firefox.settings.services.mozilla.com/v1/buckets/blocklists/collections/certificates/records?_limit=3&_token=eyJvZmZzZXQiOjMsImxhc3RfcmVjb3JkIjp7Imxhc3RfbW9kaWZpZWQiOjE0ODQ3MDQ1ODA4OTR9fQ%3D%3D\",\n      \"last_modified\": 1484704581273,\n      \"date\": \"1484838228331\"\n    }\n}. Yes, maybe that's for the Memory backend. Yes it only works on GET. We need to update docs/conf.py. No I didn't. @leplatrem I have no Idea why the ETag contains twice \"\"\"\" probably I did something wrong but it doesn't looks obvious to me, any idea?. Can we do it in multiple PR?. > There is also the raise from for the backend errors\nCan you elaborate on that?\n. I don't think %s is a deprecated feature of Python3 to be honest :). Things to do to move to the next format calls:\nKinto\n\n[x] kinto/__main__.py\n[x] kinto/authorization.py\n[x] kinto/config/__init__.py\n[x] kinto/core/__init__.py\n[x] kinto/core/authentication.py\n[x] kinto/core/authorization.py\n[x] kinto/core/cache/postgresql/__init__.py\n[x] kinto/core/initialization.py\n[x] kinto/core/logs.py\n[x] kinto/core/permission/memory.py\n[x] kinto/core/permission/postgresql/__init__.py\n[x] kinto/core/resource/__init__.py\n[x] kinto/core/resource/viewset.py\n[x] kinto/core/scripts.py\n[x] kinto/core/statsd.py\n[x] kinto/core/storage/exceptions.py\n[x] kinto/core/storage/memory.py\n[x] kinto/core/storage/postgresql/__init__.py\n[x] kinto/core/storage/postgresql/client.py\n[x] kinto/core/storage/testing.py\n[x] kinto/core/testing.py\n[x] kinto/core/utils.py\n[x] kinto/core/views/batch.py\n[x] kinto/core/views/errors.py\n[x] kinto/core/views/heartbeat.py\n[x] kinto/plugins/admin/views.py\n[x] kinto/plugins/default_bucket/__init__.py\n[x] kinto/plugins/history/listener.py\n[x] kinto/views/permissions.py\n[x] kinto/views/records.py\n\nTests\n\n[x] tests/core/resource/test_events.py\n[x] tests/core/resource/test_filter.py\n[x] tests/core/resource/test_object_permissions.py\n[x] tests/core/resource/test_record.py\n[x] tests/core/support.py\n[x] tests/core/test_authentication.py\n[x] tests/core/test_storage.py\n[x] tests/core/test_utils.py\n[x] tests/core/test_views_batch.py\n[x] tests/core/test_views_hello.py\n[x] tests/plugins/test_default_bucket.py\n[x] tests/plugins/test_history.py\n[x] tests/plugins/test_quotas.py\n[x] tests/support.py\n[x] tests/test_main.py\n[x] tests/test_views_collections.py\n[x] tests/test_views_collections_schema.py\n[x] tests/test_views_records.py\n. Can we do your strategy for 5.3.3 and keep the 9.5+ version only for kinto 6.0?. > Should we rename that PR into Upgrade to PostgreSQL 9.5 ? And change the index creation too?\n\nYes, can I let you update the Index creation?\n. @leplatrem final r+?. I agree with you generally but for this specific case the patch are different between the master 6.X and the 5.X branch. There is a setting to activate the permission endpoint: http://kinto.readthedocs.io/en/stable/configuration/settings.html#activating-the-permissions-endpoint\nTo activate the admin plugin we use: kinto.includes = kinto.plugins.admin\nWhat we want is to automatically activate the permission endpoint if the kinto_admin plugin is configured.. I guess you cannot have this information if you don't have permission to have it so you should probably order them by bucket name/ bucket ID :). > I think we should set the behavior to just ignore it. and process the request anyways. Opinions?\nNo it should raise a 400 because If-Match:* is not a valid nor supported value.. >      If-Match = \"If-Match\" \":\" ( \"*\" | 1#entity-tag )\nYou are right my mistake.. It does follow the spec. If you want to check if the records exists or not your would use If-None-Match: * Here we are talking about If-Match: * which means any value.. That behaviour was never implemented so I guess we can merge this and create a new PR to implement it.. I have created https://github.com/Kinto/kinto/issues/1069. > It would also mean a breaking change on the API.\nYes but it would still be backward compatible I guess.. Fixed with #1086 . Duplicate of #1072 . You are so lagging \ud83d\udde1 . > it tries to compare the If-Match header against the current record's ETag, and fail if the record is newer.\nYes that's because before we used If-Modified-Since and we kept the same behaviour.. Superseeded by #1089 . I think this is a question for the kinto-admin project.. Merge with b910b60. The failing tests are because of https://github.com/Pylons/pyramid/issues/2958. Note: The next release of Pyramid should not alter the incoming settings.. > So wait, finally we're not doing a shallow copy or anything?\nWe don't have to because the last release of Pyramid 1.8 has my patch with a fix there.. After investigation, it seems that --reload call hupper which takes sys.argv instead of the previous argv.. I made a pull-request upstream that should handle the matter: https://github.com/Pylons/pyramid/pull/2962/files. BackendError: ProgrammingError: (psycopg2.ProgrammingError) operator does not exist: text <> numeric\\nLINE 7: ...->\\'receipt\\'->\\'header\\'->>\\'chainpoint_version\\', \\'\\') NOT IN (1....\\n                                                             ^\\nHINT:  No operator matches the given name and argument type(s). You might need to add explicit type casts.\\n [SQL: \"\\\\n        WITH total_filtered AS (\\\\n            SELECT COUNT(id) AS count\\\\n              FROM records\\\\n             WHERE parent_id = %(parent_id)s\\\\n               AND collection_id = %(collection_id)s\\\\n               AND coalesce(data->%(filters_field_0_0)s->%(filters_field_0_1)s->>%(filters_field_0_2)s, \\'\\') NOT IN %(filters_value_0)s\\\\n        ),\\\\n        collection_filtered AS (\\\\n            SELECT id, last_modified, data\\\\n              FROM records\\\\n             WHERE parent_id = %(parent_id)s\\\\n               AND collection_id = %(collection_id)s\\\\n               AND coalesce(data->%(filters_field_0_0)s->%(filters_field_0_1)s->>%(filters_field_0_2)s, \\'\\') NOT IN %(filters_value_0)s\\\\n             LIMIT 10000\\\\n        ),\\\\n        fake_deleted AS (\\\\n            SELECT (%(deleted_field)s)::JSONB AS data\\\\n        ),\\\\n        filtered_deleted AS (\\\\n            SELECT id, last_modified, fake_deleted.data AS data\\\\n              FROM deleted, fake_deleted\\\\n             WHERE parent_id = %(parent_id)s\\\\n               AND collection_id = %(collection_id)s\\\\n               AND coalesce(data->%(filters_field_0_0)s->%(filters_field_0_1)s->>%(filters_field_0_2)s, \\'\\') NOT IN %(filters_value_0)s\\\\n               LIMIT 0\\\\n        ),\\\\n        all_records AS (\\\\n            SELECT * FROM filtered_deleted\\\\n             UNION ALL\\\\n            SELECT * FROM collection_filtered\\\\n        ),\\\\n        paginated_records AS (\\\\n            SELECT DISTINCT id\\\\n              FROM all_records\\\\n              \\\\n        )\\\\n        SELECT total_filtered.count AS count_total,\\\\n               a.id, as_epoch(a.last_modified) AS last_modified, a.data\\\\n          FROM paginated_records AS p JOIN all_records AS a ON (a.id = p.id),\\\\n               total_filtered\\\\n          ORDER BY last_modified DESC\\\\n          ;\\\\n        \"] [parameters: {\\'filters_field_0_1\\': u\\'header\\', \\'filters_field_0_0\\': u\\'receipt\\', \\'filters_field_0_2\\': u\\'chainpoint_version\\', \\'filters_value_0\\': (1.0,), \\'parent_id\\': u\\'/buckets/tweet_blockchain_anchoring/collections/MarCharlott\\', \\'collection_id\\': \\'record\\', \\'deleted_field\\': \\'{\"deleted\":true}\\'}]\\x1b[0m \\x1b[36mlang\\x1b[0m=\\x1b[35mpt-BR,pt;q=0.8,en-US;q=0.5,en;q=0.3\\x1b[0m \\x1b[36muid\\x1b[0m=\\x1b[35mNone\\x1b[0m']. Yes it is a duplicate.. > The fact that the argument order is important seems like a bug; should we report it upstream?\nWe have the exact same issue with kinto and subcommands.\nThe command help explicits it so it doesn't seems like a bug to me.. Yes I have seen this for a while and I quite agree.. Yes I will rename it after :). > I guess it's right on the current master.\nThen I don't understand this diff.... > but I want to merge it just to see what happens...\nSame here :D. Well here is what happenned: https://github.com/Kinto/kinto/commit/71209e2daedac0f6a071230e234841ac085ff725\nAn empty merge commit \\o/. If we want to fix the behaviour we should get rid of ETag's all together I guess because we are not using Etag as OPS understand they should work.\nRefs #1027. > Huh, what?\nWell forget it we will handle that with #1027. I guess that was it: https://github.com/webpush-channels/webpush-channels/commit/f9056c66a67637f3f9bd4772099a85c2579d02ce. Should we implement something like:\n/buckets/<bucket_id>/collections/<collection_id>/records?_version_at=<last_modified>. It should fail if the history plugin is not present.. Maybe it would be easier to use an new view:\n\nBuckets: /v1/buckets/version/1486464958017\nBucket: /v1/buckets/tasks/version/1486464958017\nCollections: /v1/buckets/tasks/collections/version/1486464958017\nCollections: /v1/buckets/tasks/collections/todo/version/1486464958017\nRecords: /v1/buckets/tasks/collections/todo/records/version/1486464958017\nRecord: /v1/buckets/tasks/collections/todo/records/5c7d0e7b-5f05-4118-b2a1-25ccf329905e/version/1486464958017. > Without the permission handling, I would not be in favor of merging.\n\nYes I agree we weren't sure about how permissions where handled on the history endpoint.\n\nI'm sorry that you already wrote so much code :|\n\nWhy are you sorry? Isn't it great? It is just a matter of handling permissions right?. Test are broken because of some swagger specification issue. @gabisurita can you help me out there?. > or we can just leave it out the documentation for now.\nHow can I do that?. >  does it provide ETag etc as if it would be the usual endpoint?\nActually it is not a usual endpoint and it doesn't plan to be one. What would be the use case?. I don't think you need ETag for replication or initial synchronization. Using the last_modified should be enough to get the state before a certain timestamp and then build on top of it or doing three way merge.. Handled on client side on the kinto-admin. Feel free to reopen if this is a feature that you want to push forward on the server side.. The idea is to add pytest-watch as a dev dependency and then add a rule in the Makefile to be able to run py.test with that plugin.. You need to install python-dev. Yes please go ahead, you don't need to ask. Please take the issue and file a pull-request.. Just file a pull-request and you will be fine :). Ok I am going to upgrade to kinto 6 and see if we fixed the issue.. Can you try again with that version?. I could reproduce:\nFile \"/home/ubuntu/venvs/kinto35/lib/python3.5/site-packages/kinto/core/events.py\", line 149, in notify_resource_event\n    impacted.append({'new': new, 'old': old[i]})\nIndexError: list index out of range. ```\n$ http delete https://kinto.dev.mozaws.net/v1/buckets -a test:test\nHTTP/1.1 500 Internal Server Error\nAccess-Control-Expose-Headers: Retry-After, Alert, Backoff, Content-Length\nConnection: keep-alive\nContent-Length: 177\nContent-Type: application/json\nDate: Tue, 07 Mar 2017 07:17:28 GMT\nServer: nginx\nX-Content-Type-Options: nosniff\n{\n    \"code\": 500, \n    \"errno\": 999, \n    \"error\": \"Internal Server Error\", \n    \"info\": \"https://github.com/Kinto/kinto/issues/\", \n    \"message\": \"A programmatic error occured, developers have been informed.\"\n}\n```\nI still can. ```\n  File \"/home/ubuntu/venvs/kinto35/lib/python3.5/site-packages/pyramid/tweens.py\", line 22, in excview_tween\n    response = handler(request)\n  File \"/home/ubuntu/venvs/kinto35/lib/python3.5/site-packages/pyramid_tm/init.py\", line 119, in tm_tween\n    reraise(*exc_info)\n  File \"/home/ubuntu/venvs/kinto35/lib/python3.5/site-packages/pyramid_tm/compat.py\", line 15, in reraise\n    raise value\n  File \"/home/ubuntu/venvs/kinto35/lib/python3.5/site-packages/pyramid_tm/init.py\", line 98, in tm_tween\n    response = handler(request)\n  File \"/home/ubuntu/venvs/kinto35/lib/python3.5/site-packages/pyramid/router.py\", line 155, in handle_request\n    view_name\n  File \"/home/ubuntu/venvs/kinto35/lib/python3.5/site-packages/pyramid/view.py\", line 612, in call_view\n    response = view_callable(context, request)\n  File \"/home/ubuntu/venvs/kinto35/lib/python3.5/site-packages/pyramid/config/views.py\", line 181, in call\n    return view(context, request)\n  File \"/home/ubuntu/venvs/kinto35/lib/python3.5/site-packages/pyramid/viewderivers.py\", line 389, in attr_view\n    return view(context, request)\n  File \"/home/ubuntu/venvs/kinto35/lib/python3.5/site-packages/pyramid/viewderivers.py\", line 367, in predicate_wrapper\n    return view(context, request)\n  File \"/home/ubuntu/venvs/kinto35/lib/python3.5/site-packages/pyramid/viewderivers.py\", line 300, in secured_view\n    return view(context, request)\n  File \"/home/ubuntu/venvs/kinto35/lib/python3.5/site-packages/pyramid/viewderivers.py\", line 438, in rendered_view\n    result = view(context, request)\n  File \"/home/ubuntu/venvs/kinto35/lib/python3.5/site-packages/pyramid/viewderivers.py\", line 147, in _requestonly_view\n    response = view(request)\n  File \"/home/ubuntu/venvs/kinto35/lib/python3.5/site-packages/cornice/service.py\", line 491, in wrapper\n    response = view()\n  File \"/home/ubuntu/venvs/kinto35/lib/python3.5/site-packages/kinto/core/resource/init.py\", line 393, in collection_delete\n    return self.postprocess(deleted, action=action, old=records)\n  File \"/home/ubuntu/venvs/kinto35/lib/python3.5/site-packages/kinto/core/resource/init.py\", line 1196, in postprocess\n    data = super().postprocess(result, action, old)\n  File \"/home/ubuntu/venvs/kinto35/lib/python3.5/site-packages/kinto/core/resource/init.py\", line 710, in postprocess\n    old=old)\n  File \"/home/ubuntu/venvs/kinto35/lib/python3.5/site-packages/kinto/core/events.py\", line 149, in notify_resource_event\n    impacted.append({'new': new, 'old': old[i]})\nIndexError: list index out of range lang=None uid=842ba3f6b700d048458dcdb203805df2df12877819389513352cad3afb92bf0c\n. To be honest I don't know how this can happen...python\n    if action == ACTIONS.DELETE:\n        if not isinstance(data, list):\n            impacted = [{'new': data, 'old': old}]\n        else:\n            impacted = []\n            for i, new in enumerate(data):\n                impacted.append({'new': new, 'old': old[i]})\n``. This might be related to a fix that we did here: https://github.com/Kinto/kinto/pull/1249. I couldn't reproduce anymore with the fix. Feel free to reopen if you see the bug again.. Indeed thedelete: true` shouldn't be kept.. > if a record exists we can change the deleted field to true and it will behave as a deleted record.\nWhat makes you say that? I don't think this is accurate.. > Now tombstones behave like non-existing records.\nActually tombstones should works as non existing record, the record has been deleted so it doesn't exists anymore. The tombstones is just an indication that the record once existed but if you create it again it is a totally brand new record.. Oh now I understand the bug, so we are supporting filtering on nested fields but not sorting on them. It looks reasonable . Superseeded by #1120 . Handled by #1122 and #1125 . Oh we refresh the requirements.txt file on release with the make build-requirements\nYou can read why here: http://www.servicedenuages.fr/en/handling-python-projects-dependencies. That's a good idea yes \ud83d\udc4d . Thanks @mozillazg . Yes let me fix it first.. The thing is even with #1095 fixed, the --reload option won't work until https://github.com/Pylons/pyramid/pull/2962 is fixed.. In the meantime we can remove --reload from the make serve. Thanks a lot @mozillazg . > Are you sure the changes are necessary in the PostgreSQL backend?\nYes because tests are failing without it.\n\nthen the ignore_conflict placeholder might not be necessary anymore no?\n\nThis one is not related directly.\nActually it is still mandatory to handle RaceCondition and IntegrityErrors.. Is it some kinds of PDB?. Yes that was my opinion too. Let's do that then :) Also it might break a bunch of plugins but it doesn't matter.. > an external package is a good long-term plan\nIt is a good plan for me.. Superseeded by https://github.com/Kinto/kinto-changes/issues/34. Refs https://github.com/Kinto/kinto/pull/816 ?. Thanks. Can I let you rebase it?. We have a functional test testing for this: https://github.com/Kinto/kinto/blob/7eaf95c/tests/functional.py#L146\nI just tried on kinto.dev and it seems to work:\n```http\n$ http GET https://kinto.dev.mozaws.net/v1/ --auth principal:B\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Backoff, Alert, Content-Length, Retry-After\nConnection: keep-alive\nContent-Length: 2373\nContent-Type: application/json\nDate: Thu, 16 Mar 2017 10:22:52 GMT\nServer: nginx\nX-Content-Type-Options: nosniff\n{\n    \"user\": {\n        \"bucket\": \"7a4fea2b-228b-72a4-aeda-54b8a9f3cc50\", \n        \"id\": \"basicauth:cacbb620f82ecaded70aaf7a34efc54b1b0a5b6bf451af1e01c1180e39848c47\"\n    }\n}\n$ http PUT https://kinto.dev.mozaws.net/v1/buckets/demo --auth principal:A\nHTTP/1.1 201 Created\nAccess-Control-Expose-Headers: Backoff, Alert, Content-Length, Retry-After\nConnection: keep-alive\nContent-Length: 155\nContent-Type: application/json\nDate: Thu, 16 Mar 2017 10:21:58 GMT\nETag: \"1489659718418\"\nLast-Modified: Thu, 16 Mar 2017 10:21:58 GMT\nServer: nginx\nX-Content-Type-Options: nosniff\n{\n    \"data\": {\n        \"id\": \"demo\", \n        \"last_modified\": 1489659718418\n    }, \n    \"permissions\": {\n        \"write\": [\n            \"basicauth:3225b22125bcf8e3cd3dba5a0c5c2f6b1d1c5589c4fdd8e746adc34bbf2993ff\"\n        ]\n    }\n}\n$ http PUT https://kinto.dev.mozaws.net/v1/buckets/demo/collections/tasks --auth principal:A\nHTTP/1.1 201 Created\nAccess-Control-Expose-Headers: Backoff, Alert, Content-Length, Retry-After\nConnection: keep-alive\nContent-Length: 156\nContent-Type: application/json\nDate: Thu, 16 Mar 2017 10:22:08 GMT\nETag: \"1489659728045\"\nLast-Modified: Thu, 16 Mar 2017 10:22:08 GMT\nServer: nginx\nX-Content-Type-Options: nosniff\n{\n    \"data\": {\n        \"id\": \"tasks\", \n        \"last_modified\": 1489659728045\n    }, \n    \"permissions\": {\n        \"write\": [\n            \"basicauth:3225b22125bcf8e3cd3dba5a0c5c2f6b1d1c5589c4fdd8e746adc34bbf2993ff\"\n        ]\n    }\n}\n$ echo '{\"permissions\": {\"read\": [\"basicauth:cacbb620f82ecaded70aaf7a34efc54b1b0a5b6bf451af1e01c1180e39848c47\"]}}' | http POST https://kinto.dev.mozaws.net/v1/buckets/demo/collections/tasks/records --auth principal:A\nHTTP/1.1 201 Created\nAccess-Control-Expose-Headers: Backoff, Alert, Content-Length, Retry-After\nConnection: keep-alive\nContent-Length: 273\nContent-Type: application/json\nDate: Thu, 16 Mar 2017 10:23:05 GMT\nETag: \"1489659785795\"\nLast-Modified: Thu, 16 Mar 2017 10:23:05 GMT\nServer: nginx\nX-Content-Type-Options: nosniff\n{\n    \"data\": {\n        \"id\": \"19cf8360-479c-4cbf-bfb7-863ac0191fb4\", \n        \"last_modified\": 1489659785795\n    }, \n    \"permissions\": {\n        \"read\": [\n            \"basicauth:cacbb620f82ecaded70aaf7a34efc54b1b0a5b6bf451af1e01c1180e39848c47\"\n        ], \n        \"write\": [\n            \"basicauth:3225b22125bcf8e3cd3dba5a0c5c2f6b1d1c5589c4fdd8e746adc34bbf2993ff\"\n        ]\n    }\n}\n$ http GET https://kinto.dev.mozaws.net/v1/buckets/demo/collections/tasks/records/19cf8360-479c-4cbf-bfb7-863ac0191fb4 --auth principal:B\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Alert, ETag, Pragma, Cache-Control, Backoff, Last-Modified, Retry-After, Content-Length, Expires\nCache-Control: no-cache, no-store\nConnection: keep-alive\nContent-Length: 101\nContent-Type: application/json\nDate: Thu, 16 Mar 2017 10:23:25 GMT\nETag: \"1489659785795\"\nLast-Modified: Thu, 16 Mar 2017 10:23:05 GMT\nServer: nginx\nX-Content-Type-Options: nosniff\n{\n    \"data\": {\n        \"id\": \"19cf8360-479c-4cbf-bfb7-863ac0191fb4\", \n        \"last_modified\": 1489659785795\n    }, \n    \"permissions\": {}\n}\n`. Make sure to take the user ID from the/v1/` page. This userID changes if you change theuser_hmac_secret` config value.. > the auth token that appears at the top on the kinto-admin UI\nCan you do a screenshot of it? It should be the same value.. I'm glad we've got to the root of the problem. No worries, keep using Kinto and doing some noise we actually really appreciate it \ud83d\udc4d . We already talked about that multiple times: https://github.com/Kinto/kinto/issues/140 https://github.com/mozilla-services/cliquet/issues/75 https://github.com/mozilla-services/cliquet/pull/235\nThe 200 doesn't change anything, if you are concerned about getting an error you should use If-None-Match: *. Thanks. This seems to break kinto-signer: https://travis-ci.org/Kinto/kinto-signer/jobs/212165621. So we should release kinto-http.py :). What about the idea of removing the memory backend and using a SQLite3 backend (we can use a temporary file in memory to keep the memory backend feature) plus we gain transaction for free? #754 . The Total-Records count change is concerning.. In that case that is why the pagination is not right.. I guess we could add an expiry to the token to achieve that.\nJust for you to know:\n```pycon\n\n\n\nimport base64\nbase64.b64decode(\"eyJsYXN0X3JlY29yZCI6eyJsYXN0X21vZGlmaWVkIjoxNDkwNTMzNDQ0ODE5fSwib2Zmc2V0IjoxfQ==\")\n'{\"last_record\":{\"last_modified\":1490533444819},\"offset\":1}'\n\n\n\n```. We could even want to sign them using jwt to make them less hackable.. I am puzzle about this feature (paginated delete) what does it means? Maybe we should not have a pagination token on deletes at all?. You can actually use the id of one record as a property of another record. But you won't have ForeignKey constraints or ON DELETE cascade capabilities. In certain cases it might be sufficient.\nYou can use batch request to achieve a similar request of join.. It depends of the use case yes.\nFor the user / posts thing, you might want to just sync all users and all posts so that you have the users in your local state.. Closing for lack of answers. Feel free to reopen if you wish to fix the comments.. Thanks.. Maybe it worth updating the CHANGELOG with a note about which bug got fixed by it.. Refs https://github.com/Pylons/pyramid/pull/2725. Refs https://github.com/Pylons/webob/pull/268. Also\n- https://github.com/Pylons/webob/issues/115\n- https://github.com/Pylons/webob/issues/161. Refs https://sentry.prod.mozaws.net/operations/kinto-webextensions-prod/issues/395349/. Waiting for https://github.com/Kinto/kinto-admin/pull/429. Thank you for debugging that :). https://kinto-ota.dev.mozaws.net/v1/buckets/build-hub/collections/releases/records?build.id=null\nReturns an empty list, so I guess it is not sufficient.. raise exceptions.BackendError(original=e) from e\\nkinto.core.storage.exceptions.BackendError: DataError: (psycopg2.DataError) invalid input syntax for type numeric: \"53.0b4\". Is that a feature we support or a side effect?. I was talking about the fact of adding quotes in the querystring.. Do you think that something we should support?. @glasserc I tried your idea of putting a JSON decoder there. But apparently it doesn't fix any of the issue we have. Because even if we decode the number as a number then if we do a Postgresql request with a numeric value on a row that contains string we still have the issue.. Do we have a case where we mix string and integer in the database? Cannot we use the schema to make sure a fields is always of type string even if that string contains only numbers?. I wish we could avoid querying the cache for that. I we use JWT token, we can add the timestamp and use this value to see if the token expired. Because of the signature nobody can forge a token.. > But how do you prevent using it twice?\nWhy would you want such a thing?. Would you like to file a PR to fix this?. What happens if you delete it and reaccess it?. Does it means that you are in a totally blocked situation?. Ok can you try to remove another one?. Maybe you've reach the max number of collection?. The storage API is supposed to always store unicode and return unicode (str) reason why you need to encode the password before passing it to the hashlib API. (which only supports bytes hashing). >  I think the right way to fix the issue is not in the authentication as I did, but storing the hashed password as string, explicitly calling decode on bcrypt's result, which is base64 anyway. This way, tests and production work.\nYes please \ud83d\udc4d you can force push on your branch if you want.\n\nujson.ensure_ascii to false in postgres backend\n\nThis \ud83d\udc4d \n. Initially, the reason we have a readonly mode is to tell Kinto that the database user configured has only read-only access to the database.\nMy understanding is that readonly should not be used as a maintenance mode feature.\nThe maintenance mode is currently set at the nginx level where access to the Python worker is cut for the duration of the maintenance.\nMaybe you want to add a maintenance mode feature to Kinto, but I don't think we should use readonly for that. However if it is your intention, you can remove the if in your command; the if in the delete-collection one was because in the kinto-settings setup we have both instances with read-only access to the database and instances with write access to the database.. Yes we should prevent them from being defined in the first level required.. Can we rebase with #1249 ?. Hi @delebash welcome. Let me try your config on my end I will get back to you shortly.. Try running:\necho '{\"data\": {\"id\": \"username\", \"password\": \"me\"}}' | http POST http://localhost:8888/v1/accounts. Make sure to remove the spaces before the config values in your ini file. However if kinto.account_create_principals = system.Everyone is set you won't need to authenticate. ```\n\nPlugins\n\nkinto.includes = kinto.plugins.default_bucket\n                 kinto.plugins.accounts\n                 kinto.plugins.admin\n\nAuth configuration.\n\nhttps://kinto.readthedocs.io/en/latest/configuration/settings.html#authentication\n\nmultiauth.policies = account\nmultiauth.policy.account.use = kinto.plugins.accounts.authentication.AccountsAuthenticationPolicy\nAllow anyone to create accounts.\nkinto.account_create_principals = system.Everyone\nSet user 'account:admin' as the administrator.\nkinto.account_write_principals = account:admin\nkinto.account_read_principals = account:admin\n```. Thank you for documenting this with this issue. Hope it will be useful in the future.. > how did you find it?\nI did, when I removed the fennec bucket in stage and that fennec-preview and fennec-staging disappeared.. You will probably say that this is not related to that PR but I find it cumbersome when we have system.Everyone to have to put the ID in the body.\nWe could directly use the Authentication header to grab the user and the password:\nbash\nhttp POST http://localhost:8888/v1/accounts --auth username:password. Refs https://github.com/Kinto/kinto/issues/1251. It doesn't fix #1217 but it is a first step toward. I think the Postgresql issue will be handled by #1220 . I am not sure we should add specific tests to make sure it works I guess.. It was for the memory backend but I don't know if my test are running for the postgresql one.\nEdited: Actually it is for all backends because test are in the basebackend.. No because we are then making sure last_modified value are different. Also the tests are validating that we don't see twice the same record.. > Are we still sure that ujson brings us enough benefit compared to python 3.6 json native module? Maybe we could drop it completely.\nKinto speed benefit heavily from the use of ujson. We should definitely keep it.. > I haven't followed the whole conversation about this\nThe rationale is that PostgreSQL backend is using ujson while the memory backend was not. We discovered that sometime ujson doesn't behave exactly as the json module.\n@elelay upgraded the memory backend to use ujson so that both backend behave the same way with regards to JSON handling.\nTo be honest I would just use ujson everywhere without adding a new setting.. > We should probably confirm that with updated figures.\nSure if you feel like doing so. \n\nI continuously read about python 3.6 super performances.\n\nWe are not using Python 3.6 yet in production as far as I know. But I really doubt JSON handling in Python could be faster than in libc.. >  Would you veto if I wanted to land it?\nNo, go ahead.\n\nThis PR needs a rebase\n\nI am not confident handling the conflicts myself.. This is awesome thank you for tackling it!. > This is especially important for the first run, which initializes the schema :)\nNote that if no migration are necessary this will be really fast, it will also detect error while trying to access the DB. (configuration error between docker components or database stopped, etc...). Thanks that would be awesome !!!. This might be related to https://github.com/Kinto/kinto-admin/issues/436. ```ini\n\nAuth configuration.\n\nkinto.userid_hmac_secret = fcc3...d6b2dfd3f9970b\nPut your user id there instead to only allow the admin to create buckets.\nkinto.bucket_create_principals = account:foo\nmultiauth.policies = account\nmultiauth.policy.account.use = kinto.plugins.accounts.authentication.AccountsAuthenticationPolicy\nkinto.account_create_principals = account:foo\nkinto.account_write_principals = account:foo\nkinto.includes = kinto.plugins.default_bucket\n                 kinto.plugins.admin\n                 kinto.plugins.accounts\n                 kinto.plugins.history\n                 kinto_attachment\n```\necho '{\"data\": {\"id\": \"new_user\", \"password\": \"azerty\"}}' | \\\n    http POST http://localhost:8888/v1/accounts --auth foo:bar. Yeah it makes sense somehow. I added account_create because I didn't want some people to be able to change other people password or delete other people account while they were able to create new people.. I enabled it in #1355 . I like the fact that you encountered a 409, it seems to be a good behavior to me.. See http://kinto.readthedocs.io/en/stable/api/1.x/index.html#comment-3404363198\nhttps://github.com/Kinto/kinto-attachment#using-httpie. It is probably because you are using the memory backend. You should change your config to use the Postgresql or Redis backend instead.. @S2606 I think something like that: http://kinto.readthedocs.io/en/stable/community.html#communication-channels. Yeah don't hesitate to file a PR we will iterate before merging. Collecting zope.interface>=3.8.0 (from pyramid<1.9b1,>1.8->kinto==7.3.2.dev0)\n  Using cached zope.interface-4.4.2-cp35-cp35m-manylinux1_x86_64.whl\nCan you try again? It seems to work from here: https://pypi.python.org/pypi/zope.interface/4.4.2. Yep please try again with latest master.. Thanks @rkleine . Refs https://github.com/Pylons/colander/issues/294. Refs https://bitbucket.org/micktwomey/pyiso8601/issues/27/possible-api-contract-break-in-0112-utc. I keep it open to remember to follow up on this.. Was fixed with colander 1.4.0. I will keep #1301 open to follow up on this.. It seems that we have more information since the sentry upgrade.. Superseeded by #1348 . > I'm not super crazy about this because it reinforces the idea of the accounts API as Basic Auth v2.\nToday that's what it is. What you describe in #1317 achieve another purpose than our current accounts plugin.. > Maybe we should rename it from \"accounts API\" to \"basic auth v2\".\nLet's discuss that in another issue.. This is the next level which is to be able to link to a user multiple auth mecanisms.\nToday we didn't find ourselves needing it but I can definitely see how it could be interesting.\nNote that everything you describe here is already doable using groups. You can create a group and then link all the differents user auth principals to that group.. Thanks.. Sounds really french to me like that :/ I guess the previous version is better english.\nI will let our expert @glasserc decide :). It is actually worst than that because it can come from the release itself:\nIf during the review you didn't noticed: WARNING: cannot find kinto.plugins.admin.release_hook.after_checkout hook: kinto; skipping... then you publish something without the embedded kinto-admin.\nIn order to do the thing properly:\nmake install-dev\n.venv/bin/pip install zest.releaser\n.venv/bin/release\nIf you don't do that, then the hook won't be found.... zest.releaser 6.12.5 was released with a fix. I shouldn't happen again.. Actually this line in the Dockerfile doesn't seems to work: npm run build kinto/plugins/admin; \nnpm ERR! enoent ENOENT: no such file or directory, open '~/kinto/package.json'\nnpm ERR! enoent ENOENT: no such file or directory, open '~/kinto/package.json'. Should be fixed with https://github.com/Kinto/kinto/commit/051c6a92abe1304b18a7d84d7dd0ca93191c0756. This build has it: https://hub.docker.com/r/kinto/kinto-server/builds/b43sueeuaeaqswgnawkt8e5/. Refs https://github.com/kumar303/mohawk/. There are a lot of client library for all kinds of programming languages, on the server side we can use mohawk.. Thanks a lot @TDress for starting that work, I added some comments to your PR.. Isn't it https://github.com/Kinto/kinto/pull/1333/files#diff-84c3e7bada317747370dff2b0c64cfb8R183 ?. I created #1334 and #1335 about that thanks.. The goal is to add a new step to the kinto init command to ask about the cache backend.\nBy default it would use the same as the storage backend but it could also ask to specify other backends (redis, memcached, postgresql, memory)\nWe should probably also add an option to the command to specify the cache backend with --cache-backend memcached for instance.. > Maybe it was only tested on the memory backend?\nIt was also tested with the redis backend but you could really well be right about the postgresql backend error.. >  Is it smaller or something?\nYes a bit smaller.. I guess we can already do: kinto create-user --username \"$USERNAME\" --password \"$PASSWORD\" --ini $KINTO_INI\nWhat variable name would you like to default to for username and password?. I know that both words exists but I will let @glasserc review it.. Thanks, but that's not how we handle requirements in that project you can read this article for more information. @emamurho sure.. Also note that if you can guarantee that the HTTP call to trigger the lambda is really quick you could call the HTTP endpoint directly without relying on redis in between.. Just add a new commit to that branch to update this PR.. Thanks for taking care of this.. Sure you can find the documentation on installing your local env here:\n\nhttp://kinto.readthedocs.io/en/stable/tutorials/install.html#using-the-python-package\n\nAlso the contributing guidelines are here:\n\nhttp://kinto.readthedocs.io/en/stable/community.html#how-to-contribute\n\nIn a nutshell, looks at the issues list and pick one, ask questions if you need more information, then file a PR.. We already do that for encrypted content were we set the status to deleted in an encrypted manner and then kinto.js catches it or in the blocklist with an enabled/disabled field.\nYou can change the metadata to do the same, you can also use the history plugin to retrieve a previous version of a deleted record.\nWhat is your use case for virtually deleted?. Thank you for your responses, really pleasant to read.\n\nThe use case is a fully auditable system where every user's every action (including views) are being logged. A supervisor/administrator must be able to come in at any time and view all records, including deleted ones (with full history such as values changed, dates of change, etc.).\n\nIf your aim is to allow review of actions, then what you want is exactly the history plugin. It is also well integrated with the kinto admin, it allows to see who did what action as well as showing a diff between two dates of what happened.\n\nwhat you mean by deleting the encrypted content in an encrypted manner. Isn't encryption a kinto.js-only concept?\n\nCorrect, encryption always happens on the client side.\nYou use it when you don't want the administrator of the database to be able to read the content stored for privacy reasons.\nIn that setup, you might want to encrypt the fact that a record was deleted to prevent the administrator to know how many records were used and how many were deleted because this information could be sufficient to find out what the user is storing in the collection.\nWhen we do that, we don't use the DELETE verb but we encrypt the {status: deleted} metadata. Kinto.js detects it as a deleted item but in that case we actually don't delete the record.. > I also didn't fully understand what blocklists are\nThe blocklist is yet another use-case we use Kinto for.\nFor instance: https://firefox.settings.services.mozilla.com/v1/buckets/blocklists/collections/certificates/records\nYou can see that records contains a enabled field that allow us to deactivate them without removing them.. You can deactivate some endpoint verbs using: http://kinto.readthedocs.io/en/stable/configuration/settings.html#enabling-or-disabling-endpoints\n```ini\nkinto.collection_bucket_delete_enabled = false\nkinto.record_bucket_delete_enabled = false\nkinto.collection_group_delete_enabled = false\nkinto.record_group_delete_enabled = false\nkinto.collection_collection_delete_enabled = false\nkinto.record_collection_delete_enabled = false\nkinto.collection_record_delete_enabled = false\nkinto.record_record_delete_enabled = false\nkinto.collection_account_delete_enabled = false\nkinto.record_account_delete_enabled = false\n```. Do you mind providing a pull-request to the documentation with your questions and the answer that helped? (Maybe in the FAQ) ?. Shall I merge and release this?. Yes you need to use Python > 3.5\nSee https://unix.stackexchange.com/questions/332641/how-to-install-python-3-6. - [x] flake8 new bare expect rule\n- [x] Docs sphinx update\n. Ok let's do it !!!!. I don't think it does to be honest.. I ran kinto-dist e2e tests with success.. Let's merge it and see how it goes in kinto-signer / kinto-dist / kinto-changes respectives CI. One way of fixing that is to add a ON CONFLICT rule here L360\nquery = \"\"\"\n            WITH deleted_record AS (\n                DELETE\n                FROM records\n                WHERE id = :object_id\n                  AND parent_id = :parent_id\n                  AND collection_id = :collection_id\n                RETURNING id\n            )\n            INSERT INTO deleted (id, parent_id, collection_id, last_modified)\n            SELECT id, :parent_id, :collection_id, from_epoch(:last_modified)\n              FROM deleted_record\n            RETURNING as_epoch(last_modified) AS last_modified;\n            \"\"\". This is because create is called with ignore_conflict=False somewhere which is the default.. resource_create_object for the default_bucket should handle this kind of errors.. Nice catch. I confirm that I have the same issue here.. Forcing kinto-http 4.3.4 fixes the issue. I am going to release 7.6.1 with this patch.. > Should we maybe try to add a statement to the migration to handle cases where the record was both in deleted and records?\nYes I think we should. Isn't it used by the default_bucket?. Ok let me try that.. Yes it worked. I will file PR to all plugins \ud83e\udd15 . Thanks @emamurho for your work on that!. It's not an issue to have backend breaking changes, we already had a number of them.\nAlso we already have features that needs transactions and work in a degraded mode for memory and redis backends (that's why we moved redis out of the scope of kinto because we didn't had time to add transaction support for kinto)\n@ronhanson is having a usecase that might need this exact feature. findAndUpdate, maybe he can have insight about which solution he would take.. > pushing 412s requires some work and some fancy SQL footwork.\nCan we add a WHERE last_modified = 'previous_last_modified' clause for the update or delete part and raise a 412 if no records where updated/deleted?. I thought we were trying to do the insert and in case of conflict handling the update?. Yes, I guess we could as well keep a blacklist but built from a list rather than multiple time the pop statement.\n  . @Stanley thank you for investigating this. Are you willing to take over and fix the tests (basically remove the cache key when changing the password or deleting the account) or should we do it?. Thanks, let me know if you need help or if you want to pair on it. I am really exited by the feature to land \ud83d\udc4d . Can you add a line in the CHANGELOG and your name in the CONTRIBUTORS file?. > if an attacker gain access the cache layer and the HMAC secret, than we can have a password leakage.\nNo because it is a hmac and it is not reversible, however we can rotate the hmac key with this plugin since we can wipe the cache whenever we want.. > The problem isn't about being reversible, but being deterministic.\nOh right, we should use the username hash as the cache key and then have a random salt and a saltedhashed password as the value.\nThanks for detecting this!. I guess we should merge it !!. Thanks a lot @Stanley for starting this !!!. Don't forget to merge it to master too after you released it.. > Well, that depends on whether or not it solves the problem.\nAt least to update the changelog . Yes we could also imagine a kinto purge-deleted command.. > Regarding with_deleted, I think that should be False, as that ensures that deletes the records without leaving a tombstone. It is already with_deleted=False in the surrounding code.\nYes sorry you are right.. Hi @AnthonyGaruccio thank you for your contribution.\nCan you add the changelog entry, your name in the contributor file and a line in the config documentation about that?. > I really think that a Bearer token as proposed is the best as default.\nTo be honest I am not quite sure about that postulate. When using the bearer token with Kinto you still have a to build the Authorization header by hand.\nIf you know that Kinto expect a Bearer+OIDC realm then it doesn't change anything to write Bearer+OIDC rather than Bearer.\nPlus this let you configure Kinto with multiple auth providers without messing around with configuration.. > unless another Token Type has been negotiated with the Client\nThat's my point.\n\nI think, having a non-standard Header like Bearer+OIDC will force 2 implementations\n\nI don't think so.\n\nI as a developer don't like how this sounds, if I need a non-standard solution just implementing an interface and settings in kinto.ini (configuration file) will make me much happier.\n\nI agree with you here.. Everything is the same (Bearer token, JWT). Only the Realm that has got a suffix when you call Kinto.\nYou can use the same lib, you can use everything that already exists around OIDC, grab the access_token and then when the clients call Kinto it will use the proper OIDC plugin realm.\nThat's why I don't think it needs another custom implementation.\n\nI've made the first because I'm writing request in a REST plugin, but when I've made an app to make tests with Angular the tools I used sends standard Bearer token.\n\nThen maybe I am wrong. Can you show me how you use your plugin?. Apparently angular2-jwt let you configure a headerPrefix here: https://github.com/auth0/angular2-jwt#configuration-options\nBut now I understand the confusion. Thanks for letting us know.. I think the authentication documentation already have been revamp to use account rather than the dummy Basic Auth, I don't think it is related to openid anyway but more to the account plugin so another pull-request will be fine.\nI think it is good enough as it is to be merge right away, we should create the issue regarding documentation and scopes management once we know how we are supposed to handle it with Auth0.. Since OpenID is about Authentication and Oauth about Authorization, I believe it is fine not validating scopes here and using the userinfo_endpoint to validate bearer tokens.\nIn the meantime I believe we should remove the custom authentication flow using id_token.. > What if we just define two clients IDs and define two policies?\nThe issue is that in that case the bearer_token will be validated in both case right?. I tried the command but I get this error: Error: [Errno 2] No such file or directory: 'py.test'\n. Thanks!. Can we check the changelog according to https://github.com/Kinto/kinto/compare/8.0.0...master ?\nEdit: I did, seems fine.. How is this different from coveralls?. Thank you for the heads up and the proposal.. Thank you @TDress for starting this work. I started to put together some comment.\nI believe the path forward is:\n\nCreate a hawk plugin in kinto/plugins/hawk/\nUse an Authentication backend (you can see kinto-portier, kinto-fxa or even the account plugin)\n\nI believe for kinto we need to authenticate users, having only one id and secret in the config doesn't allow us to authenticate users but rather give access to the kinto instance.\nWe should tight the Hawk authentication with the account plugin so that we can create users there and then use the user id as the hawk id and grab an API secret that would be used as a Hawk secret that we can also rotate if needed.. Superseeded by #1466 . You need to update the expected version in the SQL file too and the test will pass. Other than that r+. Great catch !!!! I was wondering for a while about why kinto.dev was actually always wrong about that :D. Adding @leplatrem let's try to pair review it tomorrow. I don't think the hawk secret should be returned each time we do a GET to the account.\nIt shouldn't be possible to retrieve a hawk secret that was already retrieved. And it should be possible to have multiple hawk secret at the same time.\nIf we are going this route maybe the ID should be random as well.\nI am sorry i am not really clear because I am still processing the feature and its security capabilities.\nI will write a blueprint about that and keep you posted but the flow I have in mind is the following:\n\n[ ] Create a user account\n[ ] Grab an Hawk session for that account (Is it possible to grab a session without entering the user password?)\n[ ] Hmac the session ID in order to grab an ID and a Secret linked to that user\n\nOpen questions\n\nHow do we expire sessions? I guess we can expire session to a given time and extend that time as soon as the session is used. After a while it will disappear.\nHow do we rotate sessions? Each time we ask for a new one\nHow do we handle multiple concurrent sessions? We keep a list of them all linked to a user.. Here is the Blueprint: https://github.com/Kinto/kinto/wiki/Hawk-authentication-session. > Does the current session = most recently used?\n\nNo the current session means the one we are currently logged in with. It is useful if we want to disconnect the user before the session expires.. > Do you want me to add that to the blueprint?\nYes sure :+1: \n\nhow would we find the session /credentials to use to authenticate the request?\n\nThe session won't be tied to the account record but rather stored in the cache backend.\nWe will use a hmac of the hawk session ID to store the hawk secret and the user ID.\nWhen we receive the Hawk Authorization header we will have the ID in the header.\nWe can then hmac it to find the key in the cache backend.\n\nDo you think we should save the sessions as their own independent records and then also save session tokens on account records when we first create sessions? \n\nYes we should save session as their own indepedent records (I don't think it is necessary to store them in the storage backend) I guess if we store the hawk secret, hawk algorithm and user ID in the session record we will have the mandatory information to link it to the user.\n. I started to take over the PR to address the changes but I agree that we should create an hawk plugin even if we share its database with the account plugin.. I am moving the idea of this PR in https://github.com/Kinto/kinto-hawk\n@TDress be sure that your work will be useful and that I will make you a co-author of every commit that has your code in it.\nAgain, thanks a lot for your help.. Refs https://github.com/Kinto/kinto/commit/71ad7adc86465d062fd073c69f98d9de5c366b77. It was fixed and release in pytest-sugar 0.9.1. Blocked by #1470 . It should be impossible to create a collection without a creation timestamp.. > I'm still a bit confused about the DISTINCT at all. If you ask to get all records in parent_id=\"something*\" why should you only get the first one (sorted by last_modified desc)?\nI don't recall but I am pretty sure if you remove that DISTINCT and run the postgresql storage tests one test will fail and explain it.. If you always rely on the requirements.txt file with constrained version then you never updates your dependencies unless your setup pyup or a process to upgrade your dependencies.\nPreviously we assumed that upgrading a dependency was a wish-able thing that we wanted to do as soon as possible. If it breaks we will detect it at last before doing the release because we run our release pull-request on the CI while tagging the list of dependencies.\nIt is fine to use pyup even if having pull-request every few hour is a bit annoying.\nIn anycase you should never use setup.py to constraint dependencies for a library because you can endup in a project where a lib relies on a version and another lib on another version. (It happens a lot especially requests for instance)\nTo prevent breaking developers environments we took some precautions:\n\nWe have cronjob that run the CI on master periodically to tell us if a dependency failed.\nWe have ci on each pull-request so each time we merge we know that the dependency set is right,\nIf it break for someone contributing, they can file an issue and we handle it.\nEach release comes with a requirements.txt file that can be use to constraint pip dependencies versions and make sure to have reproducible installation (that we use with kinto-dist when releasing)\n\nIn Kinto we now have pyup so the requirements.txt file is always kept up-to-date.\nI know people that use it to install the dependencies and in that case they use the last validated version.. I have this bug often with the Default bucket apparently.\n\n. I wonder if an easy fix in that case wouldn't be to raise a 409 Conflict error.. The last note make me feel that facebook login with Kinto would required a specific plugin.. For reference: https://github.com/Kinto/kinto-facebook\n. Does it means that if we want to override a value with ENV variables we need to define it with a wrong value in the ini file?. > I don't think it's dangerous to leak that information, but maybe I'm wrong.\nIn the case of kinto-signer setup we don't have this issue for sure but globally as a Kinto user, when I am using Kinto on a shared collection I don't want to see the email addresses of people that added things into the collection.\n\nGoogle Drive, for instance, lets anyone with any level of access to an object see who the owner of the object is and who else has permissions on the object.\n\nAre you sure about that?\n\nwhat makes this feel unsafe is the fact that it's an email address rather than a semi-opaque user name\n\nWhen we designed this, we decided it was easier to use a email address when using a shared collection because you could guess the name of the user from it without having to rely on something that would map email addresses and users ID.\nToday we have the account plugin and we could have an endpoint that maps email addresses to user ID.. Thank you for tackling this :+1: . > Sorry, I have a silly question, how do I push my changes here?\nYou can keep committing to your show-bucket-create branch and it will automatically update the PR.\nHowever you shouldn't use commit --amend or if you do, you will need to push force to your branch.\ngit push git@github.com:stloma/kinto.git show-bucket-create -f\n\n. > I'm just not seeing the updated code here.\nI can't see it there too: https://github.com/stloma/kinto/tree/show-bucket-create\nSo I believe your push wasn't successful.. This commit, https://github.com/stloma/kinto/commit/fa9652583cff52233c022cb864f12ef3da8a4466 is the one that is linked to that PR and that you pushed force. (It updated the PR too btw) so we are good. What misled me is the fact that it still has the time of the initial commit. Try to avoid using git commit --amend. You summoned me, you can now start with your first wish :couch_and_lamp: . It should probably return a 404 instead of a 500. I am going to land this and release. Thanks for noticing.. If I remember correctly the pagination flow is the following:\n\nGet the first page and keep the last_modified\nGo through Next-Page header\nAt the end try to get a ?_since=kept-last-modified (it should be empty or something new came by while you where going through pagination)\n. The last step is not automatic it is something the client does.. Another thing I recall is that because of the continuation token, it was not possible to prevent having an empty page at the end if total_number_of_items % _limit == 0. It's at the end because there are no more Next-Page header. Thank you for investigating this. So in case the total number of records % the limit == 0 we may have an empty page at the end but that's a known trade off of continuation tokens. Shall we add a test for this?. Why is 8.2.X diverging from master :scream: ?. Superseeded by #1587 . You can have a 8.2.X branch but don't forget to merge it with master after each release.. If you have any idea why pip is failling, I would be interested in knowing.\n\nEdited: 503 Backend is unhealthy. I am not sure to understand exactly the use case.\nYou can probably do that using the batch endpoint.\nHowever when you update a record you always get its new value.\nIf you know that the object is in the pending state then if you use a PATCH status=running you will retrieve that object.\nIn anycase you can always create a plugin if the usecase differs.\nCan you tell us more about your data flow?. For atomic updates in Kinto we use a CAS mecanism.\nWhen you get the record you will get a unique Etag header.\nIf you do you PATCH with the If-Match: \"EtagValue\" you will get a 412 if another worker already updated the task.\nI would do a get and a patch with the header just after and ignore the task if the worker get a 412 answer on the PATCH.. Note that you might encounter this issue: https://github.com/Kinto/kinto/issues/1407\nAre you sure that Kinto qualifies for a task queuing service? Why not use redis.BLPOP or RabbitMQ instead?\nYou can still use Kinto to store the information mandatory for your task to run and push in redis the task ID. Then BLPOP guarantees that only one job will get the ID.\nAn you could have a job that make sure that all jobs have been taken care of (no job in Kinto still has a pending status while the queue is empty.). > How hard is it to add a storage like MongoDB?\nFor the MongoDB storage backend, all the tests are already written and there is a Python lib for it.\nSo it is a matter of a couple hours I guess. You can give it a try I think.\n\nkinto-redis seems pretty much inactive and not much used at the moment.\n\nWhat makes you think kinto-redis is not used? I know multiple users myself.\nFortunately kinto.core.storage API doesn't change often so we don't need to update kinto-redis often :) However note that the redis storage like the memory storage don't handle transaction rollbacks which might cause issues with some plugins (the quota plugin for instance)\n\nHow hard would you think it would to add a custom rest API request like //findAndUpdate ?\n\nThe issue with /findAndUpdate is that it is not REST anymore but JSON-RPC like.\nHowever you can definitely create a plugin that would expose such a view.\nYou can look at https://github.com/Kinto/kinto-elasticsearch/blob/master/kinto_elasticsearch/views.py or \nhttps://github.com/Kinto/kinto-attachment/blob/master/kinto_attachment/views/services.py examples.\nIn this end it should be as complex as writting a cornice view.\nRegarding your question about adding a storage function while doing this you might need to fix #1407 which would be merged directly at the kinto repository level.. I will close this since this was a question and I guess @ronhanson has got all the answer we can give for it.\nWe can open a new issue about implementing @glasserc suggestion if the use-case arise in the future.. > the Postgres implementation of contains supports object contains object; I would like to see us either support that or note in a comment as to why we don't.\nAs you said we already have another way to do that for object. So I believe we should only handle sequences here.\nAs you mentioned contains_any with objects fails :grin: I don't know how we can detect that.. Thanks @glasserc for pushing me to fix that :+1: \n. There are two things behind that change.\nThe first one is to make sure that the account plugin prefix will always be account: and we can remove the XXX in the code\nThe second rationale is because for Hawk I want to define two authentication backend that gives the same user ID:\n- one for Basic Auth and one for Hawk \nMainly because you need to authenticate to grab an hawk session you need to ask it from a Basic Auth session). > it sounds super complicated when reading this...\nIt's not: https://github.com/Kinto/kinto-hawk/#installation\n```\nmultiauth.policies = account hawk\nEnable Account authenticated policy.\nmultiauth.policy.account.use = kinto.plugins.accounts.authentication.AccountsAuthenticationPolicy\nEnable Hawk authenticated policy.\nmultiauth.policy.hawk.use = kinto_hawk.authentication.HawkAuthenticationPolicy\n```. Thanks!. nice catch. Are you sure it's not a feature that we added to support the quota features?. I also found why I implemented it in the first place:\nhttps://github.com/Kinto/kinto-webpush/pull/4/files#diff-737c25e4e87da6befa4a70fef60cc91aR38. Ok we need to fix that, thanks for investigating :heart: . Ok so the mistake is to use as_epoch rather than the more precise unique value?. I though we were precise at the milliseconds so as_epoch should be unique. Let's prepare a release then :rose: . I never really realized that :fearful: . Usually we tend to let people that have the permission to merge, merge their own PR because sometimes even with an approval the author still wants to add new things before merging.. Feel free to merge at your convenience :dancer: . @alexryabkov if you can figure it out, please do.. @fpiedrah ok I had a look at this issue and I guess you are correct.\nWe could say something like: \"Make sure that two authorization policy matches a given token, because in that case you might have incoherent user ID behaviours\". :+1: . Is this because the new kinto-admin is able to read the capabilities to detect the activated authentication mecanisms?. Will it automatically select the current server with this changes?. With Bionic the last LTS 18.04 it is  Python 3.6.5\nWith the previous artful (17.10)  Python 3.6.3\nWith the previous LTS xenial (16.04) Python 3.5.1 (note that it is totally possible to install Python 3.6 with the deadsnake PPA). Google App Engine is using Python 3.6.4. This means we will drop support for Python 3.5 and start supporting Python 3.6 only. Since we already decided to move to Black I guess we are now fine with the idea. You can probably start the work although we might not merge it right away but we will eventually.. Generally a Python version is supported for 5 years so for Python 3.5 it should be until 22-Sep-2019 the last release of the branch being somewhere in March 2019. > I use Ubuntu 16.04 on my Digital Ocean servers and they only have 3.5 by default.\n@peterbe can you confirm it isn't the case anymore?. Yes git is pretty handy to merge this kinds of conflicts so I wouldn't worry too much about that.. I would use grep to list all the files I need to handle:\n$ grep -R \\\\.format\\( kinto -l\n$ grep -R '\" % ' kinto -l\n$ grep -R \"' % \" kinto -l\n- [ ] kinto/config/__init__.py\n- [ ] kinto/schema_validation.py\n- [ ] kinto/core/scripts.py\n- [ ] kinto/core/openapi.py\n- [ ] kinto/core/__init__.py\n- [ ] kinto/core/events.py\n- [ ] kinto/core/utils.py\n- [ ] kinto/core/cache/postgresql/__init__.py\n- [ ] kinto/core/storage/memory.py\n- [ ] kinto/core/storage/exceptions.py\n- [ ] kinto/core/storage/postgresql/__init__.py\n- [ ] kinto/core/storage/postgresql/client.py\n- [ ] kinto/core/storage/postgresql/migrator.py\n- [ ] kinto/core/storage/testing.py\n- [ ] kinto/core/statsd.py\n- [ ] kinto/core/initialization.py\n- [ ] kinto/core/authentication.py\n- [ ] kinto/core/errors.py\n- [ ] kinto/core/resource/__init__.py\n- [ ] kinto/core/resource/model.py\n- [ ] kinto/core/resource/schema.py\n- [ ] kinto/core/resource/viewset.py\n- [ ] kinto/core/permission/memory.py\n- [ ] kinto/core/permission/postgresql/__init__.py\n- [ ] kinto/core/authorization.py\n- [ ] kinto/core/views/heartbeat.py\n- [ ] kinto/core/views/errors.py\n- [ ] kinto/core/views/batch.py\n- [ ] kinto/core/testing.py\n- [ ] kinto/plugins/quotas/scripts.py\n- [ ] kinto/plugins/quotas/listener.py\n- [ ] kinto/plugins/accounts/scripts.py\n- [ ] kinto/plugins/accounts/__init__.py\n- [ ] kinto/plugins/accounts/views.py\n- [ ] kinto/plugins/accounts/authentication.py\n- [ ] kinto/plugins/openid/__init__.py\n- [ ] kinto/plugins/openid/views.py\n- [ ] kinto/plugins/default_bucket/__init__.py\n- [ ] kinto/plugins/history/listener.py\n- [ ] kinto/authorization.py\n- [ ] kinto/views/records.py\n- [ ] kinto/views/permissions.py\n- [ ] kinto/views/groups.py\n- [ ] kinto/__main__.py\nAnd then tick the checkboxes :dagger: . > Should we drop support for Python 3.5?\nYes that's definitely the question to answer, I don't think it will hurt anyone to do so to be honest.. I guess if someone needs a security backport for Python 3.5 in the future they can file a PR and we will gladly make a release for them. Generaly since Python 3.5+ people are trying to follow along with Python upgrade especially since Python 3.7 adds a bunch of performance improvments.\nI agree with you that it's not a pressing concern also I wouldn't like to be waiting on hypothetical customers that didn't voice in for the past 6 months.\nI believe that if it helps having a sane codebase we should do it, if it doesn't let's reconsider in 6 months :dancer: . > Are there any other backports required that we'd be able to drop in favor of built-ins?\nWe would be able to rely more on async/await but we don't have any ioloop for now.. > Drops support for LTS Linux releases that are stuck on 3.5. E.g. Ubuntu 16.04.\nI wouldn't consider it a blocker since it is really handy to install Python > 3.5 on Ubuntu 16.04 see https://askubuntu.com/a/865569/11333\n. It's definitely feasible and we even considered moving the Memory backend to an in memory SQLIte database in order to support transaction with the memory backend.\nI am wondering if you should start it as an external dependency though like for instance: https://github.com/Kinto/kinto-redis\n. 1. Yes\n2. No you don't need to learn anything about Cornice and Pyramid for this storage implementation. For the middleware maybe a little bit\n3. You should let the user configure where they are planning to store their data. But in both case it should be possible to load it from memory or from a file.. I guess you can load the JSON in memory and use a similar mecanism to the one we use with Redis and the memory backend to do the filtering. (You might be able to inherit from the Memory Base Storage class and just use the existing functions.. The Docker file is suposed to create this kinto ini file: https://github.com/Kinto/kinto/blob/master/Dockerfile#L23\nI assume you are using the lastest image?\nOk I found the error, it is because the cache_backend is asking for its value.\n```\nSelect the cache backend you would like to use: (1 - postgresql, 2 - redis, 3 - memcached, default - memory) \nTraceback (most recent call last): File \"/usr/local/bin/kinto\", line 11, in  load_entry_point('kinto', 'console_scripts', 'kinto')() File \"/app/kinto/main.py\", line 151, in main answer = input(prompt).strip() EOFError: EOF when reading a line`\n```\nThank you for noticing.. Have you tried https://api.login.yahoo.com/ as the issuer?. You are welcome, thank you for using Kinto :heart: . @adebisi-fa Can I let you start a pull-request to add the one you successfully tried?\nI guess a table at the end of this file would be good: http://docs.kinto-storage.org/en/stable/api/1.x/authentication.html#openid-connect. Yes totally, if we have a Authorization header we shouldn't assume Anonymous. However it is not the case on /v1/ : \n$ http GET https://kinto.dev.mozaws.net/v1/ \"Authorization: blabla\"\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Backoff, Retry-After, Content-Length, Alert\nConnection: keep-alive\nContent-Length: 2561\nContent-Type: application/json. It isn't a authentication required endpoint however we might consider supporting it.. In the meantime black work has been merged.. > Does it mean it never worked?\nI don't think so because it used to work for sure.. I am happy to see that the code coverage is still happy, however we shall add a specific test for it.. Except for the test not passing I believe the rationale of this change makes total sense.. I am a bit reluctant to add this for records only, also it is not wishable for buckets and collections because it will conflict with the settings separator between buckets and collections.\nI can understand why it could make sense to use a domain name as an ID.\nUsually what we did in the past is to md5 encode the domain to build a guessable UUID.. As far as I know the kinto admin doesn't let you pick a ID, it is automatically generated when you enter a new record.. @itaisteinherz why did you pick this option rather than adding something to the matrix?. Thank you for your work on this @itaisteinherz . > Avoiding creating additional matrix entries makes the CI faster.\nMaybe but it also makes it more harder to understand what failed.. Waiting on https://github.com/Frozenball/pytest-sugar/pull/160. The PR has been merged, however we are still waiting for its release. It seems that they are trying to merge a bunch of other PR before merging so that the tests are green in master.. A release happened but for some reason with a very strange version number: https://pypi.org/project/pytest-sugar-bugfix159/. To be honest I don't know if this is a joke :confused: . Apparently 3.10 has got bugs so it is better to wait for 3.10.1, also pytest-sugar-bugfix159 is just because the maintainer couldn't release it before.\nAlso a clever one recommend not using pytest-sugar on CI.. Here it seems you've lost your previous commit.... Nice job :+1: \nCan you also add a line in the Changelog since it is a new feature?. No worries, we all started messing around with Git, it gets better with experience. > kinto/core/views/version.py:5:1: F401 'pyramid.httpexceptions' imported but unused\nYou can remove the unused import as well. Hello @zakaluka there is no Kinto specific client for .Net that I know of.\nYou can start one and we will gladly host it in the Kinto organization, as a starting point you can have a look at the kinto-http-java client I guess that the closest we have.\nDepending on your use case you might want to start with HTTP requests.. What I can't close it?. Refs https://github.com/Kinto/kinto-http.py/issues/187. >  tell Travis that we expect 3.5 to fail\nNo we should remove the travis config for py35 altogether.. Thank you for this work. To be honest I didn't expect it to be so much of an improvement.\n :+1: :8ball: . Let's make a quick poll: https://twitter.com/Natim/status/1064904568272764931. I did indeed :dancer: . 10 days later: \n\n. Nope it seems good to me :+1: . Yes it is the normal process, the date is fixed only when we release it.. To answer @fpiedrah question, I guess this would be done at the permission and storage backends level, while the kinto-wizard command can be used at the HTTP API level and also to move collections and records between instances not sharing the same database.. I've got to say that thinking of a path as ascii in 2018 seems rather strange to me.. It helps thanks!\n. Don't we need --pre for them?\nhttps://tox.readthedocs.io/en/latest/config.html#conf-pip_pre. We need to release patch release for this one, it breaks kinto 11.2.0. I eventually rebased because the history wasn't relevant anymore.. You need to install psycopg2-binary and to remove psycopg2 from the venv as well.. Yes you need to double the backslash.. Can you check if it fixed it?. For a one char commit? :joy: . > Is there any need here to update the CHANGELOG?\nYes please. Thanks @peterr101 . This is a requests dependency and apparently current requests release specifically ask for a version below 2.8. Refs https://github.com/Julian/jsonschema/issues/400. Can I let you add a changelog note, please?. Welcome.. We are at a stage were we don't really know yet, since the PyPA is talking a lot about pyproject.toml.\nPackaging in Python has been hard to grasp for years and to be honest I think the best solution is the one that works.\nOur setup.py file currently works well.\nEdit: Ok I missed that : https://github.com/Kinto/kinto/blob/master/pyproject.toml. Can I let you add a changelog?. > Should we fix #1900 here?\nWe could be we can also do it later I believe. Especially since everything is properly pinned here.. Usually in the Kinto org we merge without squashing to keep the history and pace of the pull-request. Here we just need to fix tests I guess. No don't worry about that.. I guess the history was the readinglist project where sharing wasn't a feature.\nI believe this is the way to go.. > would build up too much memory\nIt depends on which Kinto service, but I believe if it does uwsgi will renew the worker automatically.. > really?!\nIf the memory goes wild the harakiri plugin can do that yes.\n\nThat's extremely little memory for a production system running on state-of-the-art hardware.\n\nI totally agree, that's why I wouldn't worry too much about that.. The feature seems to be there. I guess the next step is to add a test to make sure the cache backend is called when we call the command.. The tests seems to be sufficiant, can I let you write a bit of doc about the new kinto command?. What do you mean the cli doesn't work? How do you run it?\n.venv/bin/kinto flush-cache --ini kinto.ini\n~/kinto/kinto$ .venv/bin/kinto flush-cache\n/home/rhubscher/kinto/kinto/kinto/core/initialization.py:555: UserWarning: HTTPS is not enabled\n  warnings.warn(\"HTTPS is not enabled\")\nINFO   Running kinto 12.0.0.dev0.\nINFO   Cache has been cleared.\n~/kinto/kinto$ .venv/bin/kinto start\n/home/rhubscher/kinto/kinto/kinto/core/initialization.py:555: UserWarning: HTTPS is not enabled\n  warnings.warn(\"HTTPS is not enabled\")\nRunning kinto 12.0.0.dev0. \nRunning kinto 12.0.0.dev0. \nStarting server in PID 3983.\nServing on http://localhost:8888. Right now we can fix most thing with # noqa for the main function for instance or lisible part of the code. However it would probably be better to refactor if possible.. Apparently they do inherit from Exception.\n```\n\n\n\nimport requests\nissubclass(requests.exceptions.HTTPError, IOError)\nTrue\nissubclass(requests.exceptions.HTTPError, Exception)\nTrue\n```. Yes it makes sense.. ## A couple of notes\n\n\n\n\n\nThe namespace for the account plugin is accounts, why do you want to create a new namespace? Can't we use /accounts/<email>/reset-password?\n\n\nI like the idea of using the email as a username because it ease the sharing capabilities of Kinto. We can share with account:my.email@tld.com and all it takes for someone to open it would be to use the POST /accounts/<email> endpoint.\n\n\nAlternative proposal\nRegistration\nRather than creating new resources to manage the registration, I would be ok to actually add a activated flag to an account.\n{\"id\": \"email@address.tld\", \"password\": \"bcrypt_key\", \"activated\": false}\nWe can have a settings to activate email validation, that will enforce email as usernames.\nWhen we do a POST on /accounts/<email> it would create the following object:\n{\"id\": \"email@address.tld\", \"password\": \"bcrypt_key\", \"activated\": false}\nWith the bcrypt_key being the generated password for activation.\nTo activate an account we would use:\nhttp POST /accounts/<email> password=\"newpassword\" --auth \"<email>:activation_key\"\nIt is the current procedure to change a password, that would activate the account by authenticating with the generated link and providing a new password.\nWhen an account is deactivated, the only endpoint allowed with the activation_key would be the change password endpoint.\nReset password\nFor the reset password phase, we could use the /accounts/<email>/reset-password endpoint. It might be good to actually use another object for this case since we don't want to erase the user previous password. We can use the cache to store this key with the niceties to automatically get rid of it after a TTL period.\nWe could still use: http POST /accounts/<email> password=\"newpassword\" --auth \"<email>:reset_key\" to apply the change.\nThis would means that for this given endpoint we would accept the reset key from the cache as an alternative password to allow a user to change their password.. > it means there's no way to ask for a username AND password on account creation, which is a somewhat widespread use case.\nFair point.\n\nIf we want a simple link, then we need to validate the account using a simple GET (which means not providing a new password, which means using the alternate method using a validate endpoint)\n\nThis is actually a feature, I don't think one should link to the validation link on the kinto service directly, because you want to present some kind of UI to the user.\nInstead the GET link should link to the APP that will make the POST to the validation endpoint. My understanding is that we might want to ask for the password at this stage as well, so that one could use the same UI for changing the password, resetting the password and setting the first password.. I don't see why it is a problem, because you can hash the one provided to validate it as we currently do with the password.. You generate a key, you hash it you store it hashed in the database, you return it, the user uses it, you hash it then you validate it with the stored hashed one.. If the email is lost you can recreate an account and get an new activation key. If you used the activation key you can use the reset password mechanism to change it again.\nIf you loose the username, well it depends, what that means but I guess you can still create a new account and ask an admin to give you privileges.. I think it is fine not relying on kinto-emailer for that especially because kinto-emailer is a kinto plugin with a focus on notifications regarding resource updates.\n+1 to use pyramid_mailer directly.. > Not sure what you mean with \u00ab email context \u00bb. You mean a template?\nNo the context to render the template aka:\n{ \"first_name\": \"Alexis\", \"email_subject\": \"blah\"}. > we should provide a simple WebApp that does the POSTing automatically, in order to have a easy-to-setup account registration mechanism \nWe could as an example but it is quite orthogonal to the service code.\nI can't see someone using this feature not to wish to integrate it with their software UI.. > Some softwares have UI that are not browsers\nIn that case they might not use links to validate the account.. >  1. A request is made from the CLI to the kinto server to create the account\n\n\nAn email is sent to the user, to confirm the email belongs to her / him\nThe user clicks on the link to validate\nAccount is validated.\n\n\nThis is the case when working with a webapp, but if you are using a software you might want to use the following:\n\nA request is made from the CLI to the kinto server to create the account\nAn email is sent to the user, to confirm the email belongs to her / him\nThe user copy the activation key and use the CLI to validate the account.\nAccount is validated.. I think it is up to the developper to define the flow, I am not against building a little Elm demo webapp if it pleases you. We can even pair on it once this lands.. I agree with you in the scope of Kinto which is an API. As soon as you have front-end facing experience, it is not the place of Kinto to solve it. However we could decide that the kinto-admin has got a built-in page to handle that.. > I would prefer Kinto core not be cluttered with support for all the different possible things some developer might want an accounts system to do.\n\nI agree with you and I guess it is why we decided to put the account code in a plugin.\nAs of why plugins ships with Kinto itself, this is another story.. My first issue was that I had a smtplib connection error. Is there a way to add it to the heartbeat part to make sure emailing is correctly configured?. Second issue is that the accounts doesn't seems to have CORS activated?\nEdit: Actually my kinto service was stopped :confused: . Ok the creation doesn't have a CORS issue but the validation has got one.\nThe CORS header \u00ab Access-Control-Allow-Origin \u00bb is missing.\nI think this might be because we are doing a POST without body, which doesn't call the OPTION endpoint. It might be a CORS issue from Kinto rather than a wrong implementation on your side.\nIf I add a body I get a 405 not allowed on the OPTION call. I made a little UI that you can try here: https://kinto.github.io/kinto-account-demo/index.html. I am deploying it here: http://natim.alwaysdata.net/v1/. I added the reset-password and change-password screen on the kinto-account-demo UI.\nIt seems that the CORS OPTIONS request for the /account/<user-id> returns a 400.\nThis is because I am using the wrong method verb:\n webtest.app.AppError: Bad response: 400 Bad Request (not 200)\nE           b'{\"code\":400,\"errno\":107,\"error\":\"Invalid parameters\",\"message\":\"Access-Control-Request-Method in header: Method not allowed\",\"details\":[{\"location\":\"header\",\"name\":\"Access-Control-Request-Method\",\"description\":\"Method not allowed\"}]}'. > Quick note: it seems the + character (which can be present in an email address) is not allowed in the ID. Maybe we should fix that?\nYes we should probably fix it. Feel free to add a test for it if you want.. This has been updated in kinto-admin 1.23 \nWe shall update the kinto-admin module once it is released there.. Do you have a pip command to do so? . My understanding is that pip doesn't support this feature but pipenv does, does it?. @peterbe can you elaborate on https://github.com/Kinto/kinto/pull/1987/commits/f1ab03115a90dcdf4304b1645b5b885e970380a0 ?\nWhy do we keep a requirements.txt file with all the hashes and versions if we don't use it?\nMy rationale about adding it in the first place.. The extra requirements for dev is a nice addition. I guess we didn't do it like that because it doesn't make sense to install them from pypi but we can get rid of a dev-requirements.txt file so I guess it worth it.. Ok I see what you mean, makes sense, we keep requirements.txt for documentation purpose but in dev we can simply not use it.\nI guess it is a bit of a shame especially since we are using dependabot to allow dependency updates only if tests are passing.. > I should probably drop this PR then, no?\nI think if dependabot updates the hashes accordingly you can keep it. I believe it is still a good thing to document the dependencies Kinto is relying on.. It is not used for the CI only, it is used to build reproductible Docker images or at least if not reproductible having always the same dependencies for a given tag.. Exactly that's why we have setup.py with non pined version and requirements.txt with pinned version.\nThat's also why I liked when we had a makefile rule to refresh the requirements.txt file.. I would be willing to try that, it makes a lot of sense to me.. Thank you for taking the time. It looks like the right fix.. > I notice that the tests are failing due to lack of coverage.  I guess this means the function is never actually called in such a way that the default parameter is used.\nThe default value is not used by our tests. Maybe we should add a test that uses it or shall we remove the default value?. I checked and validate_schema is used in only two places were ignore_fields is always defined.. I am not sure this is our issue, because even filtering doesn't seems to work. I guess this is bypassed somewhere.. What seems crazy to me is that records seems to be by pairs in the same page.\nMaybe a distinct value is missing?\nPage 16\nMeline di bosco\nMeline di bosco\nPandoro Fondue!\nPandoro Fondue!\nNutella Xmas Fondue\nNutella Xmas Fondue\nPicol\u00e9 Passatempo. Fixed with #1999 . It looks like this line doesn't allow for the inline script that get's added in the html build file.. Tested and I was able to load the kinto-admin.. > Me too\nNot since @peterbe removed the constrain...\nWell he did not: https://github.com/Kinto/kinto/blob/master/tox.ini#L12. 1.7.0 is the one in the file: https://github.com/Kinto/kinto/blob/master/requirements.txt#L5. Really strange indeed :confused: . @fbertsch can I let you add your name in the contributors file and a litle line in the Changelog?. Maybe we can give it a try, if someone feels like trying it.. Can you elaborate on why the record:create permission on the collection doesn't meet your requirements?\n. Actually what you said is not entirely true. The write permission will be added only to records that the user created, is that an issue that a user can delete its registration?. For instance:\n\nnewsletter.py\n\n```\nfrom kinto_http import Client\n\nKINTO_SERVICE = \"https://kinto.dev.mozaws.net/v1\"\nADMIN_AUTH = (\"admin\", \"p4ssw0rd\")\nALEXIS_AUTH = (\"alexis\", \"p4ssw0rd\")\nEMILIE_AUTH = (\"emilie\", \"p4ssw0rd\")\n\nadmin_client = Client(server_url=KINTO_SERVICE, bucket=\"newsletter\",\n                      collection=\"registration\", auth=ADMIN_AUTH)\n\nalexis_client = Client(server_url=KINTO_SERVICE, bucket=\"newsletter\",\n                       collection=\"registration\", auth=ALEXIS_AUTH)\n\nemilie_client = Client(server_url=KINTO_SERVICE, bucket=\"newsletter\",\n                       collection=\"registration\", auth=EMILIE_AUTH)\n\nadmin_client.create_bucket(safe=False)\nadmin_client.create_collection(permissions={\"record:create\": [\"system.Authenticated\"]}, safe=False)\n\n# Alexis register\nalexis_client.create_record(data={\"email\": \"alexis@domain.tld\"})\n\n# Emilie register\nemilie_client.create_record(data={\"email\": \"emilie@domain.tld\"})\n\n\n# Alexis registrations\nprint(\"Alexis records\", alexis_client.get_records())\n\n# Emilie registrations\nprint(\"Emilie records\", emilie_client.get_records())\n\n# Admin registrations\nprint(\"Admin records\", admin_client.get_records())\n```\n\n\n```\n$ python newsletter.py \nAlexis records [{'id': '5090b563-6b88-4d2c-9f92-89111d751043', 'email': 'alexis@domain.tld', 'last_modified': 1550565644103}]\nEmilie records [{'id': '22b8615c-7de7-4569-9208-69b3a4d549cd', 'email': 'emilie@domain.tld', 'last_modified': 1550565644955}]\nAdmin records [{'id': '22b8615c-7de7-4569-9208-69b3a4d549cd', 'email': 'emilie@domain.tld', 'last_modified': 1550565644955}, {'id': '5090b563-6b88-4d2c-9f92-89111d751043', 'email': 'alexis@domain.tld', 'last_modified': 1550565644103}]\n```. I missed the fact that people are not authenticated at this stage. I agree that we need to fix that somehow.\nI think what is missing too is a way to give access to authenticated people with a given authentication policy: system.Authenticated:accounts\nWhy? Because if you allow both accounts and basicauth with some collections with system.Authenticated you will allow anyone to use this system.Authenticated permission (with unauthorized basicauth accounts). While if you allow only the one with the accounts policy, then you restrict access to those with basicauth.\nThis allow throw away sessions that will meet this use case.. I think we should rename it to basic_auth_activated since it is not really a backdoor anymore but an Auth feature.\n. refer to cliquet's documentation even if its is right, it is easier to understand I think.\n. Yes\n. You can remove the schema.ResourceSchema.Options here since #47\n. We are missing libpq-dev\n. En fait dans le cas de docker sous linux, installer libpq-dev suffit.\n. I don't think we want fined permissions on the bucket itself, do you have a usecase in mind that needs it?\n. Well having Daybed experience in mind I don't think it helps :) groups carries less meaning than roles. Is musicians a role?\n. A role is a category of people that can do specific actions (administrators, moderators, employees, managers, etc.)\n. Does: To have all permissions on all bucket collections and bucket collections items. works for you?\n. Missing file end line\n. Good point, it should be 403\n. Actually there is no owner list anymore.\n. We've just created the group moderators the line above, I don't understand the question.\n. Ok yes good point :)\n. This is an ACE\n. This is a permission\n. This is the object_type\n. This is the object_id\n. self.collection.collection_id = 'record'\n. Maybe can we get it from the resource_name directly?\n. We add a nice thing in Daybed: https://github.com/spiral-project/daybed/blob/cb5efbf9b2ef326154a638c242d64ae001600ba4/daybed/backends/id_generators.py#L18-L41\n. A blank line is missing in order to render a rst list.\n. missing blank line\n. missing blank line\n. missing blank line\n. missing blank line\n. missing blank line\n. missing blank line\n. Yes systemd restarts uwsgi and uwsgi handles the worker pre-fork model\n. This is not detect as being a list. We should add a dot like: #.\n. missing blank line\n. - Basically use of Postgresql RDS (Consistency/Availability/Durability) are handled by AWS\n- Use of Elasticcache for Redis\n- Use of EC2 Instance with uwsgi and nginx deployed\n- Use of Route53 as a loadbalancer\n. Yes I did that first but then I decided to use process_record instead. In either way if one of the two fails we will be out of sync.\n. We want to add a similar test for patch\n. This was to be able to use redis-cli monitor to debug the permission backend.\nI supose that we should put them all on the memory backend now that tests are passing.\n. Because you don't know if it exists or if you don't have access to it.\nThe permission backend doesn't give you a allowed if the the object doesn't exists.\nSo we should call the storage backend before the permission backend if we wanted a 404 here.\nAlso most security guys will tell you that it is better to return a 403 in that case.\n. More information about this here: http://security.stackexchange.com/questions/46171/is-it-a-good-practice-to-show-403-unauthorized-access-error-to-user\n. > They will actually tell you it's better to return a 404, otherwise you disclose that the resource exists.\nOh yes you are right. I guess returning always 404 or always a 403 is not really a big change. Also I for a webservice I would rather return a 403 in all cases rather than a 404 in all cases.\nWhy ? Because it is important to tell the user that something is wrong with the permission she sets. In the case of unknown it is because an non existing object has no permission sets to it.\nAlso if you've got permissions on the bucket you will get a 404 for a non existing collection.\n. > t also have a disadvantage: It leaks the fact that the resource exists to another user, which could then use this information in many different ways.\nAs I said in this case the resource doesn't exists so it obviously doesn't disclose the fact that it exists :)\n. According to the documentation: \n\nStatus code 403 responses are the result of the web server being configured to deny access, for some reason, to the requested resource by the client.\n\nWhich doesn't implies necessarily that the resource exists. It just implies that the user cannot have any information about the resource.\nI like the idea to return 404 when the user has the right to know that the resource doesn't exists and 403 in case she don't have the right to know either if it exists or not.\n. is not\n. I tried but it seams that it is not populated yet at this time.\n. File \"/home/rhubscher/mozilla/kinto/kinto/authorization.py\", line 139, in groupfinder\n    request.prefixed_userid)\nAttributeError: 'Request' object has no attribute 'prefixed_userid'\n. Now it is basicauth:\n. I prefer to use http://localhost:8888/ rather than :8888/\n. This three links are something we want to keep in the README.\n. Yes I would rather remove the inclusion of the README from the documentation if this bothers you.\nAlso it is a common practice to see the documentation as a read-more of the readme and people may display the documentation on another domain, in that case having a link to the \"official\" documentation is not a problem.\n. I am building the bucket_id of the user using an hmac in order to make sure it is unguessable.\n. Why? Actually 412 is a feature, it means that the bucket already existed.\n. Don't we want monitoring here as well?\n. which means if you restart the server you loose your data and that if you start multiple process, you will have random behaviors.\n. https://kinto.readthedocs.org/\n. Also this cannot be overridded yet, see: https://github.com/mozilla-services/kinto/issues/90\n. We should probably keep that so that we can change the default settings without conflicting with tests.\n. I have updated this: https://github.com/mozilla-services/kinto/pull/86#issue-91756118\nNot sure if we put the template somewhere else.\n. Do we really have to pin the version here?\n. Yes, once to create it if needed (with a 412 if not needed) and once to update the bucket information (data and permission).\n. Oh you means adding a test to make sure two call on the same bucket in a row works?\n. httpdomain is more to document RESTAPI's than showing example of usage of it (even if there are example in the documentation of it)\nI am not sure it is relevant to use it here.\nSee http://pythonhosted.org/sphinxcontrib-httpdomain/#basic-usage\n. Like #XXX: Improvment Avoid doing PUT twice on PUT /buckets/default\n. Actually it was raising a 412 :8ball: \n. Actually I added the code to not do the call twice.\n. This is because the user_hmac_id was not set in the config and is now set.\n. This means I will have to change all the principals again :(\n. It does in case:\n- The bucket already exists: https://github.com/mozilla-services/kinto/pull/71/files#diff-580dee783aeea3c8487d07890dfdbcb9R35\n- The collection already exists: https://github.com/mozilla-services/kinto/pull/71/files#diff-580dee783aeea3c8487d07890dfdbcb9R55\n. The magic is it only works if you use the default endpoint so you cannot create collections for other people.\n. Is test_call_on_default_bucket_when_it_exists_doesnt_raise_412 good enough?\n. No because the creation code is in the /buckets/default endpoint only so that the code won't be executed if you call /buckets/{user_bucket_id}\n. I have created https://github.com/mozilla-services/cliquet/pull/344 for that.\n. bucket_put can be update or creation.\n. collection_put can be update or creation.\n. I wanted to make it optionnal as well in https://github.com/mozilla-services/kinto/pull/100\n. Isn't it CLIQUET_CACHE_* nowadays?\n. Should we put master here to avoid forgetting to update it? Cliquet 2.2 has been released already so this rotted.\n. I think we can now use pip install \"kinto[postgresql]\"\n. No we didn't :)\n. It just doesn't work with .[postgresql] but not with kinto[postgresql]\n. Well apparently you are right. I think we need to fix that.\n. Yes this was fixed in Kinto 1.2, it is related to this bug: https://github.com/mozilla-services/kinto/pull/80\n. This should be true with the current kinto authorization.\n. This should be true with the current kinto authorization, since flush doesn't need any permission (NO_PERMISSION_REQUIRED)\n. Yes I was using '%s' % to be compatible with both Py3 and Py2 but text_type works  :)\n. There is a test for it. I will add a comment. ( https://github.com/mozilla-services/kinto/pull/88/files#diff-78b677143edfdcc21ab2170f88157eacR159 )\n. What I liked with this was the fact to check that a bucket_id is related to the connected user.\n. How would you like to present them?\n. I would do: \n- view.bucket-collection.[GET|POST|PUT|PATCH|DELETE]\n- view.bucket-record.[GET|POST|PUT|PATCH|DELETE]\nOne pattern matching is enough for human brain :)\n. I like this idea, we should try it.\n. Actually it was tasks before and it is here to make sure https://github.com/mozilla-services/kinto/pull/131/files#diff-580dee783aeea3c8487d07890dfdbcb9R76 is tested. One could be tempted to replace default and the test would break if the collection id is replaced.\n. Actually with your fix on cliquet if you don't provide data you'll get a 400 (data should be present and is not defined)\nSee https://github.com/mozilla-services/kinto/issues/63\n. Yes it isn't possible.\n. It doesn't work :(\n. that are currently stored (data is always a plural in english)\n. It doesn't because the read permission is given for the bucket/collections and not on each records.\n. Missing a with_deleted=False\n. All the article (even the one I didn't write)\n. missing with_deleted=False\n. I removed it but apparently, until https://github.com/Kinto/kinto/pull/63 is fixed and merged it is still mandatory.\n. This is missing \"data\"\n. Do we really have to add it, I dislike it visually.\n. Currently, every modification of an object makes sure the user that did it has got the write permission not only creation.\n. This is not what we are trying to say.\nWhat we are trying to say is that in order to share an object you need a way to get the user ID of the person you want to share the object with.\n. :+1: \n. I was just trying to debug, but I suppose you are right. I will had a test that does the right thing (checking for Allow-Control-Expose-Headers)\n. I wouldn't call it default too.\n. These are working credentials for localhost:8888\n. Please do not commit this kind of files.\n. Because you do not need to change the doc URL from the configuration. The default values is the right one in the scope of kinto.\n. This should never look like that, I should be kinto.http_host = localhost:8888\n. In mean the ~ ones. The .py are fine.\n. As far as I know it should be \n```\n[uwsgi]\nwsgi-file = app.wsgi\nenable-threads = true\nsocket = /run/uwsgi/kinto-latest.sock\nchmod-socket = 666\n```\n. I am sure there should be a way to define the PROXY in the ENV. See https://github.com/jkbrzt/httpie#proxies\n. Oh I though you would update the PR.\n. Please consider adding a note stating that:\nPlease `consider reading httpie documentation <https://github.com/jkbrzt/httpie#proxies>`_ for more information If you need to configure a proxy for instance.\n. Please update your greeshmab:patch-1 branch to make this little change so that we can merge it :+1: \n. We should probably add init here too.\n. Shall we default to config/kinto.ini but allow for a file passed as a parameter?\nDo not hesitate to create another ticket linked to this one to handle this suggestion.\n. 2.10\n. We should add a note about implicit creation of both the default bucket and the collection in it, when using default and not when using the bucket id.\n. Well it is explained shortly here: https://github.com/Kinto/kinto/pull/257/files#diff-faad629fc7ad04c55c32e64e7a2d19e8R19\n. :+1: \n. Shall we do that in the init command instead? and tell the person that she need to start kinto init first?\nIn the make file we can also add the CONFIG_FILE as a dependency and run kinto init automatically if the file doesn't exists.\n. I would add the sample in the egg anyway + @oak11 work on the init command to do something like:\nkinto init\nkinto start\n. please remove trailling spaces.\n. Also maybe we should not commit the generated file anymore.\n. nit pick: This could be a constant (HERE in uppercase) defined at the beginning of the file.\n. I think the template.py file should not be in the config folder but in the kinto/ one.\n. Same here:\ndestination = os.path.join(here, '..', '..', 'config', 'kinto.ini')\n. We should probably use codecs.open to handle UTF-8 in this files.\nSee: https://github.com/mozilla-services/cliquet/blob/master/setup.py#L8-L9\n. :+1: \n. Please use six.moves.input to make this code compatible with both Python2 and Python3.\nhttp://pythonhosted.org/six/#module-six.moves\n. I would rather change line 29 into:\nif backend in ('2', ''):\n. What about redis and memory setup?\n. Indentation here is not right, we should put the parenthesis at the end of the previous line\n. please import it like from kinto.config import template\n. Please include kinto/config/kinto.tpl\n. Please remove the kinto.ini file from the version control we do not want to add since it is now generated from the template.\n. Please remove the trailing spaces at the end of lines.\n. It is configuring the memory backend.\n. Ok\n. The idea was to default to memory but we can discuss this if you think otherwise.\n. I think I would keep that check in the input() methods when passing backend=None to the method.\n. the way to interact with Kinto resources\n. I don't understand this definition, I would say: the list of HTTP resources endpoint defined for Kinto.\n. Shouldn't we have the PATCH release number if we say we are following Semantic versioning for our HTTP API?\n. Maybe we can leave it without PATCH and add a note to say that every api change is a minor change but we will not have patch changes at the API level.\n. resources and utility endpoints ?\n. This: https://en.wikipedia.org/wiki/Web_resource\n. Do you think a version of kinto will eventually implement both API version?\n. I was thinking that the package documentation should only show the API that is implemented.\nNote that we are displaying all version of the documentation in ReadTheDocs, so even if a documentation is only showing a version of the API, it will still be possible to read all version of the API.\n. I was thinking that we could have the API implemented in Kinto package documented in the package documentation and only that. If we want to compare different version of APIs, we can do it by comparing documentation packages version as well. (Note that ReadTheDocs keep publishing all the different version of the Kinto packages)\nWe can probably also list the different APIs in another documentation repository (which could import them from the Kinto packages)\n. shall we put the DELETE method in uppercase?\n. Please keep this version with the makedirs and using the HERE variable.\n. Why is this change necessary?\n. Does it means we should not have some here?\n. I don't agree, why would I write:\nrender_template(\"kinto.tpl\", config_file, {\"secret\": \"abc\", \"storage_backend\": \"bla\", ...})\nIsn't it better to write:\nrender_template(\"kinto.tpl\", config_file, secret=\"abc\", storage_backend=\"bla\", ...)\n. I would rephrase the comment, because if old version of pip doesn't includes functools32 and we need it, then it is a kinto dependency right?\n. You probably want to use a temporary file. Using mktemp\n. What is kinto1 here?\n. We should remove this line.\n. It is python 3.5 and libpq-dev is present here :)\n. To build a smaller image.\n. To build a smaller image.\n. That's precisely that that helps building smaller images.\n. I though it was better to actually run the last tag but I think docker-hub already handles that so we can switch back to master.\n. we should add a link here to the edit button of the wiki page on github.\n. This is to be able to use python 3.5\n. To be able to remove the building dependencies and build a smaller image.\n. You just download to build the image but since docker-hub build it for you actually just download a small image.\n. Yes it is part of my rework of the Dockerfile.\n. Note that if the venv is not activated it will fail. Cannot we call pip using a python command?\n. http://stackoverflow.com/a/15950647/186202\n. Should we add a link to the glossary there then?\n. For both libpq5 and python3 it is to mark them as manually installed in order for them not to be uninstalled with removing python3-dev and libpq-dev\n. git is in case there are dependency link\n. And I don't uninstall pip, should I?\n. The file is just committed in the kinto-website repository and gh-pages branch.\n. That's about it:\nFile \"/usr/local/bin/kinto\", line 5, in <module>\n    from pkg_resources import load_entry_point\nImportError: No module named 'pkg_resources'\n. stackbrew/debian    sid                 e560b1d2575a        8 days ago          117.2 MB\ndebian              sid                 e560b1d2575a        8 days ago          117.2 MB\nLook at the IMAGE ID, they are the exact same images :)\n. The name of the listener that you then configure.\nThis is working as for logging configuration in python where you name your handlers before using them and configuring them.\n. I'd like to talk about the Token Server here as an example.\n. going through\n. A client is automatically (we can remove the then I guess)\n. It seems strange to me to add it there if it is already added automatically.\n. Why not tell people to use a virtualenv instead? Would it be easier for them?\n. nit: Python with a capital P.\n. You can use the add_path_to_virtualenv command oh wait it just works with pew - pew add /path/to/folder nevermind.\n. It should probably be Github+Bearer here.\n. Good catch !\n. You should have Github+Bearer here now :)\n. nit: no space before ? in English\n. That's to help readability of the tutorial, would you suggest that:\n- we use some random token?\n- we replace bob with bob-token?\n. nit: PostgreSQL\n. PostgreSQL\n. Why change to ziade.org here?\n. Same question here, why change to notmyidea.org?\n. We should probably tag the cliquet-fxa version as well.\n. :+1: \n. I would have tested 304 only there.\n. You can also use: fuser -k 8888/tcp\n. Make sure that the path you defined for the socket parameter of the uwsgi configuration exists.\n. If possible I would add the exact message returned by postgresql. So that looking for the solution would come up in the search engine.\nAlso it is possible other encoding would raise a similar error.\n. > because it may be that two or more changes happened during the same timestamp\nThis is not possible on server side. Even if two records happens at the same timestamp, they will have different timestamps.\nSee http://kinto.readthedocs.org/en/latest/api/1.x/cliquet/timestamps.html\n. >  in FxSync you sometimes see 1000 records with the exact same timestamp, so you shouldn't discard 950 of them after fetching only the first 50.\nThis is a real problem for syncto because Kinto guarantees that it won't happend. If Sync doesn't it means that we have a problem in syncto.\n. However a default limit can be set in the configuration.\n. > the list until the Next-Page response header is present\nthe list while the Next-Page response header is present ?\n. We probably need to update the start parameter at some point.\n. I can also duplicate this code in groups/buckets and collection if you think it is a good idea to do it.\nSince the code is in Cliquet it is unlikely that they will fail if the other one passes.\nIt is just some functional tests to make sure that what we want for Kinto is working regardless of cornice or cliquet changes.\n. Should we also support the sort '-v' option?\nparser.add_argument('-v', '--version', action='version', ...\n. Yes I can change for publicKey if you prefer.\n. I would rather go for a base64 of os.urandom(9) bytes implementation.\n. ``` python\n\n\n\nimport os, base64\nbase64.b64encode(os.urandom(9))\n'TKmj0DI4wcLh'\nlen(base64.b64encode(os.urandom(9)))\n12\n. To avoid id collisions within the scope of the bucket collection.\n. python\nlen(base64.b64encode(os.urandom(6)))\n8\n``\n. We could even make the number of bytes a settings of the generator.\n. I did a pull request on https://github.com/corpix/shortid/pull/2 about this.\n._sort=-last_modified` isn't it?\n. Yes sorry.\n. If you don't know, just push \"enter\" to choose the default Memory backend, when you will need another one you will know it :)\n. It should be schema right?\n\n\n\nSomething like that maybe:\npython\nconfig.add_api_capability(\"schema\",\n                          description=\"Enforce a schema for collection records.\",\n                          url=\"http://kinto.readthedocs.org/en/latest/api/1.x/\"\n                              \"collections.html#collection-json-schema\")\n. You can ask for a new file creation with:\nkinto --ini new_file.ini init\nOr you can remove the previous config/kinto.ini and restart kinto init\n. Maybe self.assertNotIn('schema', capabilities)\n. With @almet we though of flush, flush_endpoint, flush_endpoint_enabled.\nflush_endpoint seemed more explicit that just flush\nIn the future we should define a way to phrase:\n- The kinto server has got the capability to have attachments\n- The kinto server has got the capability to have schema\n- The kinto server has got the capability to have changes\n- The kinto server has got the capability to have flush_endpoint\n. Should we move that information in the capability itself?\n. Well it has been added as a capability while it wasn't the case before so we can now look for it here.\nFor me it is fine to say the protocol changed.\n. > what's inside the resources, but how to access them, and the mean of access is exactly the same as before.\nI mean the protocol of the home page changed and how we are getting the information of it default_bucket, flush_endpoint and schema`` are activated\n. It doesn't hurt anyone to add this information in the CHANGELOG.\n. I tried to change that and tests were failing.\n. This is part of testing that the current date is correctly passed to the template.\n. What about: https://github.com/Kinto/kinto/commits/master?author=lavish205 ?\n. Why did you removed this lines?\n. Please put this in the pyramid importation block sorted alphabetically \n. Actually it seems that you cannot importroute_path, but that you should be usingrequest.route_path`\n. It doesn't work if you want to upgrade cliquet does it?\n. of objects\n. Do you mean something like:\npython\ndef resource_handling(resource, request, data, resource_name, resource_id):\n    data = {'id': resource_id}\n    obj = resource.model.create_record(data)\n    request.current_resource_name = resource_name\n    resource.postprocess(data, action=ACTIONS.CREATE)\n    return obj\n. I would also validate that the error message give enough feedback for the user to solve the issue.\n. Good catch\n. This is supposed to be tested but I don't know why the coverage is not calculated.\n. @leplatrem If you have feedback on this I would be interested.\n. This is not supposed to happen because parse_args should take care of it.\n. Maybe we don't need this anymore then.\n. Yes, it is hard to test and because we are using entry_points I guess we don't need it anymore.\n. If you use pip install -e . then it should update when updating the file without having to restart pip install in between.\n. Actually by default parse_args use sys.argv automatically.\n. Can I test if the content of the file actually contains the right backend?\n. Yes it was an optimization not to install all the dev dependencies to validate flake8.\n. Yes prune is fine I guess.\n. Maybe there is a better way here so that we don't even bother triggering a storage query since we want an empty list here.\n. It is defined in the core_authorization.RouteFactory\n. Yes it is what I did in the first commit but it makes a query to the storage while we don't want to make one in that case.\n. We need to detect that it was allowed while there were no shared_records.\nIf we don't know that we will endup having all the records as if we had the read permissions on buckets.\n. We thouht about doing that, but it is more the KintoRouteFactory than the BucketRouteFactory.\nI think we shouldn't have multiple RouteFactory for a given project, it makes it harder to follow.\n. Actually I think we should read that from the config.root_factory, I did a hack to get there but I wish we could fix it using the config one.\n. Didn't we say this was stripped during conf loading?\n. Yes it is what I though.\n. Because it is back to default value.\n. This is already describe earlier: https://github.com/Kinto/kinto/pull/637/files/cd2788b4649f3a520c1c0e105e640442c174ac5c#diff-4f31c1e2c9e43e4d6edbcd36ed58f8b8R38\n. I think you should rename kinto_core by kinto and log all kinto errors here.\n. Here we lose the fact that we may want the DEBUG log level for kinto, while the INFO level for other package is fine.\n. Maybe we need to add structlog>=16.1 in setup.py too\n. Can we add a test with the error message displayed to the user?\n. I would probably go for a global timeout as well as a timeout per heartbeat too.\n. I don't get this, cannot we just remove the setting?\n. Cannot we remote it just for the default bucket?\n. This means that we cannot change group permissions if we do not provide also the data with PUT.\nBut is it working fine with PATCH?\n. nit: IDs\n. nit: IDs\n. I don't really like that change :(\nShouldn't we actually inherit from the kinto-core UUID4 generator in kinto to override the regexp with a more general one?\n. We shouldn't talk about clients here, all clients can and should implement the three thing. You can even implement it at the HTTP level.\nWe should rephrase like that:\nThere are three conflict resolution strategies:\n. Redis, PostgreSQL\n. We can rephrase like:\nYou can use both of them: \n- Redis will let you start easily and you will have a database running in memory which means your database should be smaller than your server RAM. It is a good solution for experimentation and you will also be able to use a Redis cluster to scale in production.\n- PostgreSQL is a good solution for a Kinto server and will let you use all the power of PostgreSQL and its tooling.\nDo not hesitate to mix both if you can, for instance you can use PostgreSQL for the storage backend and Redis for the permission and cache backends.\n. We should remove that it is not true.\n. We can add a link to the tutorial: http://kinto.readthedocs.io/en/latest/tutorials/write-plugin.html\n. modifies\n. Actually I am not 100% sure about this one either :)\n. in the documentation\n. Should we add the email address?\n. Shouldn't we remove experimental from config names? It doesn't add any value and we are upgrading the protocol nevertheless... I am not sure it adds any value.\n. I am not sure this would take 1.0.13. Also the requirements.txt file seems to say the contrary so if you built the requirements.txt file after this change just keep it like that. I would probably change it with <1.1.0b1 since 1.0.13 might be the last but we are not sure about it.\n. I think the right fix would be to convert the id as a string rather than raising an error.\n. Because a integer is a valid ID according to the validation RegExp.\n. The ID in the URL will always been seen as a string? If this is just to fix the bug in the body then I misunderstood the scope of this PR and you can discard this comment.\n. Add a comment to explicit why we are building a fakerequest,\n. (#708)\n. Yeah, I am currently blocked there, I have two solutions, either I am finding a way to give collection_id and parent_id to delete, either I am rewritting delete_all\nWould you like to chat a little bit about it with me?\n. I am wondering if we want the list of deleted item at all for that particular use case.\n. Better than keys() :D\n. We could probably use parent_id instead of pid\n. ditto\n. Potential conflict with my other migration in the other PR.\n. Yes it is how I wrote it at first, I can revert :)\n. Can we list here the buckets for which the history is activated?\n. I wish we could select in the config the bucket that we want the history to be kept for as we did for kinto-changes.\n. btw this would be automatic if we used a Listener rather than a subscriber.\n. Could we use a Listener there? https://github.com/Kinto/kinto-changes/blob/master/kinto_changes/listener.py#L11\n. For now that's the purpose of this script.\n. It delete the collection not only its records.\n. No, it should be part of the MVP, if we use a Listener this will be covered.\n. Ok let's create an issue to address that then :'(\n. other plural endpoints \u2192 other endpoints ?\n. Apparently it is not covered by the use of Listener.\n. Would you rather print an error message to the stderr?\n. Why are there 2 events and not 3? We might want to add a comment there.\n. Can we use a skipIf decorator instead?\n. Does it means it doesn't work? :)\n. Shall we use which_command here too?\n. I guess you solved this with your logger configuration?\n. Can we use logger here then.\n. ditto\n. We should use 32 here since 33 is already used for collection.\n. Exchange print by a logger call.\n. Or maybe nothing?\n. Running ?\n. where the collection belongs?\n. Usually jobs runner takes care of this. This command is meant to be run by hand and it wanted to have the most usuful output.\n. I think we should add verbose options then, but the logger config of the server  with the HekaLogger doesn't fit well with running this command.\n. > an addon\na storage/permission or cache backend for it?\n. Missing blank line at the end of the file :)\n. It doesn't looks to be enough.\n. In that case we should get rid of -v or change it for logging.DEBUG\n. Because verbosity contains None\n. Oh we could do that yes. :+1: \n. No it's not, for syncto it is syncto for instance and readinglist, readinglist.\n. This code is really likely to be subject to race conditions. (If two people update records in the same bucket for instance.) @tarekziade was suggesting doing something like Redis CAS or we could maybe do it directly with a PostgreSQL request so that it become a consistent change.\n. It is happening in a transaction thanks to the postgresql backend :)\n. You are right, it is a left over from the history plugin I took the idea from. No need for that here.\n. I see it more as can't happen scenario but I can try to add a test for it.\n. Yes, let me add a test for it then. :+1: \n. You are correct that in case of the bucket we could use the bucket_id but for the collection, because we can have the same collection_id in two distinct buckets we have to use both the bucket_id and the collection id, but then you could also have the same id for a group and a collection the bucket, reason why in kinto (and not kinto,core) we made this convention of using the uri as the record unique id.\n. > how do we protect the user from updating these records?\nWe prevent it because we don't have any API for the user to access it.\nIf we were to add this API we would need to make sure the user cannot modify it.\n. Actually it can happen if the collection is deleted and the plugin wasn't activated before the last change.\n. Yes we should add a test for it.\n. I added tests and it seems that because the quota is removed before there it doesn't trigger the quota on delete already.\n. Tests added.\n. Yes I am adding a test there.\n. Currently it is, but we can change that.\n. It works if kinto_redis is installed in the docs venv builder.\n. Because in case of a bucket you don't have any collection_info but you are using the variable below.\n. You are right that this might not be sufficient and we should probably get the collection_info here too.\nThis is to fix the batch on multiple collections for instance.\n. This is optimization yes.\n. Everything that was in the bucket before the quota is \"free\"\n. > How can you get the records if they were deleted then ?\nThis is because they were not deleted in this yet.\n. Maybe @tarekziade have got a point about this.\n. I did that in order to validate that batch DELETE works properly. It allows to make sure that using batch records within collections are properly deleted and taken into account in the quota.\n. Actually I find it easier to read like that because it removes a level of indirection and make it explicit that it will raise. I don't think creating a level of indirection with only another function call adds much value here.\n. I find it very explicit, how would you like it to be?\n. Is it enough? Don't you need to try to convert it to an integer?\n. Needs a rebase.\n. Don't we want to rather fix the behavior?\nI like the idea that you can configure all id_generators with one config.\n. You can probably remove this as well if you want to use the tox venv. I remember doing this to make it run faster than having to install all the dependencies.\n. :+1: \n. I think since we are not supporting python2.6 anymore we can probably just import unittest here.\n. unittest2 is a backport of the new features added to the unittest testing framework in Python 2.7 \nhttps://pypi.python.org/pypi/unittest2\n. That's not the spec, we should remove it\n. That's not the spec\n. missing _ at the end.\n. Sorry forget this message, you are describing the current behavior and not the one we want :)\n. A test is missing for this case.\nIt is strange since the test you wrote should cover it.\n. Yes I guess it helps.\n. Apparently tests from test_filter never enters postgresql _format_condition, which is probably because tests runs with the Memory backend there.\n. We need to add tests for the storage as well so that we can test that storage backends correctly supports the new operator. See: https://github.com/Kinto/kinto/blob/master/tests/core/test_storage.py#L386\n. > So is covering it in test_storage enough?\nYes I think so.\n. Yes I will be enough and tested for all backends. Including the kinto-redis community one.\n. Please add the test in the global StorageTest rather than the specific PostgreSQL one. All implemented backend should support this feature.\n. Don't you want to commit rather than abort?\n. Don't we want to do that at a upper level? I mean make sure the transaction have been canceled or committed each time a response have been sent?\n. Any idea why we abort rather than committing?\n. Yes i guess it makes sense to make sure the database is writable.\n. You are right, this tests fails with Postgresql :(\n. It doesn't really improve readability because parameters have got the same name as the variable that contains the value.\n(records=records, filters=filters, sorting=None, id_field=id_field, deleted_field=deleted_field)\n. This should be CacheTest I guess.\n. I am a bit puzzle about that.\n. This is supposed to be kinto/plugins/kinto_admin/static/* right?\n. Same here, I think the path is wrong.\n. Same here.\n. I guess we can remove that since we are now in the Kinto directory we will support the current version of Kinto.\n. is this path correct?\n. We should use the test config file instead. You can even create a specific one for the plugin tests. What we want is https://github.com/mozilla-services/kinto-dist/blob/master/config/kinto.ini#L133\nYou can also configure tests like that https://github.com/Kinto/kinto/blob/master/tests/plugins/test_history.py#L29-L32 rather than using a config file.\n. This needs a comment, I don't understand what we are trying to achieve here.\n. Oh yes I do actually, we are trying to get the groups linked to system.Authenticated.\n. Yes we should do that too.\n. We could put that in tests/plugins/kinto_admin/config.ini since it is a test fixture.\n. Please make a simpler config file.\n. We could use kinto.ini also as you said we might move that in the test folder.\n. You mean using the GroupSchema to do that?\n. Updated :D\n. The best fix ever \ud83d\udc83 \n. What is this collection_id field here?\n. I would use if value is not None because we don't want to remove it for False and 0\nYou might to add a test to make sure we don't remove the field with False, 0, \"\" (empty string) etc.\n. Could you put your name in an alphabetic order in the list please?\n. Can you validate the error message here?\n. Actually because we made the choice of using pytest, it is better to use pytest.raises instead of self.assertRaises().\nAnd yes in that case you need to import pytest :)\n. Please don't commit this file.\n. Maybe we should put it at the end rather than at the second position.\n. If you add the following lines of code, Kinto will stop working. We need to rephrase.\n. we should switch the space and the comma console ,first in console, first\n. We should probably keep the slash at the end there.\n. The plugin we are talking about for the kinto-admin is kinto.plugins.admin Maybe we can add it in the list.\n. I don't understand the /0 here, why would we need it?\n. Why do you need to add self here?\n. I think details can be on the same line.\n. \ud83d\udc4d \n. editor maybe?\n. Maybe we can keep build instead off www here.\n. It should be /v1/admin/ see #886 \n. We don't need that anymore.\n. 1.4.1\n. Kinto Web Administration\n. It was to install the last version of the dependencies. In anycase I don't like to have a node_modules folder in a Python software tree \ud83d\udde1\n. Handled here: https://github.com/Kinto/kinto/commit/fb1aa61c4e4fb02fe34e7e1dbd64ad7e157303be\n. Why self.principal.split(':')[1]?\n. It should be something like basicauth:1234 right?\n. I am a bit worried that effective principal doesn't includes it but I guess it is included later.\nIn anycase publicly we should have the prefix in the list of principals.\n. Note that we also remove the other one: https://github.com/Kinto/kinto/blob/master/kinto/core/authorization.py#L64\n. Isn't this supposed to be 1.14 (unreleased)\n. It seems to me that 1.13 have been used already: https://github.com/Kinto/kinto/pull/891/files#diff-2c14b00f3393d6e7355fb480528f38e3R22\n. We need to make sure cors are applied there.\ndef test_redirects_benefits_from_cors_setup(self):\n        app = self.make_app()\n        headers = {\n            'Origin': 'lolnet.org',\n            'Access-Control-Request-Method': 'GET'\n        }\n        resp = app.options('/v0', headers=headers, status=200)\n        self.assertIn('Access-Control-Allow-Origin', resp.headers)\n. Client-side encryption seams confusing to me. I would rephrase so that we can say that storing encrypted records on the server with client-side encryption is optional.\n. I think we used payload instead of ciphertext\n. La configuracion \u2192 configuration\n. Offline\n. 1.5.0?\n. This won't work with Python 3 because it will already be a string. In that case we need to use decode_header from utils.. https://github.com/Kinto/kinto/blob/master/kinto/core/utils.py#L412-L416\nYou may want to create _decoded the same way you did for _encoded. Can we keep this?. We should probably wait for 1.1.1 which will be there shortly now. https://github.com/Pylons/pyramid_tm/pull/52. This should stay 5.0.0. The limitation is if somebody configure another policy with the same name, but it is an edge case we can ignore I guess.. I think you might want to define this using environment variables don't you?. See: https://github.com/Kinto/kinto/blob/master/docker-compose.yml#L13-L18. assert not in. That's a really interesting question, this mean adding it in kinto.plugins as well which doesn't feel right to me, I can see multiple way of activating the include() while disabling it in the multiauth.policies which is why I didn't took that path.. Seems interesting. Oh but you configure the PostgreSQL server with Docker don't you?. Any idea why you want to change the behavior here? Is there a security risk not to have the prefix in the principal here.. Ok I'll trust you on that :). Maybe we can just get rid of this one.. We should add write inheritance too.. Should we add a test for records too?. I think we should allow people to configure the bucket and collection they want to purge, don't you think?. wow powerfull. Shouldn't we remove the previous versions as well?.          :param filters: Optionally filter the records by their attribute.\n             Each filter in this list is a tuple of a field, a value and a\n             comparison (see kinto.core.utils.COMPARISON). All filters\n             are combined using AND.\n         :type filters: list of :class:kinto.core.storage.Filter\n     :param sorting: Optionnally sort the records by attribute.\n         Each sort instruction in this list refers to a field and a\n         direction (negative means descending). All sort instructions are\n         cumulative.\n     :type sorting: list of :class:`kinto.core.storage.Sort`\n\n     :param pagination_rules: Optionnally paginate the list of records.\n         This list of rules aims to reduce the set of records to the current\n         page. A rule is a list of filters (see `filters` parameter),\n         and all rules are combined using *OR*.\n     :type pagination_rules: list of list of\n         :class:`kinto.core.storage.Filter`\n\n     :param int limit: Optionnally limit the number of records to be\n        retrieved.. > OpenAPI 2.0 currently doensn't some features that are present on Kinto API.\n\nDo you mean:\n\nOpenAPI 2.0 currently doesn't support some features that are present on Kinto API.\n\n. Can you add a note on how you choose to handle this limitations in the SWAGGER file?. I would rather have a default plugin then rather than yet another way to activate / deactivate features.. Note that if you can deactivate it we probably need a capability for it.\nAny reason why you want to be able to deactivate it?. We should use ruamel.yaml rather than PyYAML. http://yaml.readthedocs.io/en/latest/pyyaml.html. And also because we had this discussion for kinto-wizard and we made this choice there: https://github.com/Kinto/kinto-wizard/blob/master/setup.py. ruamel.yaml. Please put the logging section at the very end of the file. Should we retry more than once here?. If we put it on the top of the file it will fail in case the psycopg2 driver is not installed.. ```\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 ERROR collecting tests/core/test_cache.py \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\nImportError while importing test module '/home/rhubscher/mozilla/kinto/tests/core/test_cache.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\ntests/core/test_cache.py:6: in \n    from kinto.core.cache import (CacheBase, memory as memory_backend,\nkinto/core/cache/postgresql/init.py:5: in \n    import psycopg2\nE   ImportError: No module named psycopg2\n\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015 ERROR collecting tests/core/test_storage_migrations.py \u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\u2015\nImportError while importing test module '/home/rhubscher/mozilla/kinto/tests/core/test_storage_migrations.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\ntests/core/test_storage_migrations.py:8: in \n    from kinto.core.cache import postgresql as postgresql_cache\nkinto/core/cache/postgresql/init.py:5: in \n    import psycopg2\nE   ImportError: No module named psycopg2\n``. It is nottime.sleep(0)the problem buttime.sleep(-0.5)Because we don't want to wait for the two first retries.. I tried without success and it felt more natural not to use a global state.. Actually the backends are not supposed to raise something else thanBackendErrorbecause we want the user of the cache backend to be able to catch all exceptions regardless of the backend. I think we might have another bug to file about handling this for the cache backend.. Yes ok. That's a way of doing it, we could also recreate an object.. Actually that's the name of the file that is generated byreact-scripts`.. To be honest, I am a bit reluctant to add http://docs.pylonsproject.org/projects/pyramid_beaker/en/latest/ just for that.... Do you want me to move all decorators inside the new file or are you suggesting that we should move this class in the utils file? I put it there because that's an exposed feature of kinto.core rather than an utility for kinto.core. @leplatrem any idea why it was working before?\nApparently:\n./kinto/core/resource/schema.py:\n  245 :     _before = QueryField(colander.Integer()). Do we have a way to check that programatically at the Python level?. I don't think we need to use getattr there because we are always using the pgdialect that will always define it.. How do you get the engine from the client?. Yes but is it a good idea to do that?. woups. Well limit is bound by the config max limit so it shouldn't be a problem, also I don't know if LIMIT is supposed to be a BIGINT or of another kind. I might worth to have a look.. Yes it looks like a bug to me actually.. Do you want it as a CONSTANT uppercase?. Oh no its not a bug because we have the permissions on the beer bucket so it makes sense.. Oh no you are right we should probably say that the ID is wrong even if we are on the collection record endpoint? I don't know.. Yes it is .:). Fixed with 81a86d7. Our default_settings aren't nested so yes I think it is enough.\nMaybe we don't need to update the documentation about it.\nThe bug in Pyramid will probably be merged on Sunday but at first they said it was a feature and not a bug.... We should not add (Permissions, self) here. We changed the API so we should change the changelog.. nit: Can we add the PR reference number in the changelog?. buckets collection which is /buckets/version/1234567890123 we can on the bucket record which is /buckets/test/version/1234567890123. This file is the one from the history plugin which this feature is a part of.. > The history endpoint already handles this, by providing history entries only on data that was readable/writable at the time it was edited.\nIf this is the case it is really great ! We can have the exact same behaviour here.\nAs you can see this is just another simplified view of the history plugin data.. > we should stick to a reduced vocabulary to avoid confusion.\nI agree but kinto collection and collections of records is already really confusing.... > If we do it on the client side, the filtering aspect is out of scope.\nYes the filtering can appen on the client side.. A missing resource return a 404, if it was an invalid parameter we would return a 400 but here the resource just doesn't exists because no route are matching it.. Yes because you don't want to match /buckets/twitter_collections for instance. I can see some use cases where deleted is a property of a record and not a tombstones: \"deleted\": 3. Sure how do you do that?. Because generally you don't want to concat strings with + \nIn that specific case we probably could.\nhttps://waymoot.org/home/python_string/. http://softwareengineering.stackexchange.com/a/304447. Unfortunately it is not as simple because path can contain dots: See what we did there: https://github.com/Kinto/kinto-admin/blob/62553505e3610831b6119780328dede6c0f784da/src/utils.js#L124-L165. I would be in favor of using @n1k0 function there too.. \ud83d\udc4d . Yes fixed with https://github.com/Kinto/kinto/pull/1118. We need somehow to bump_timestamp one more time in case of conflict.. Ok it makes sense. Let's find out how we can create a test to reproduce that. I guess we had one with loadtest simulation before.. You cannot have DO NOTHING and RETURNING last_modified at the same time.. > If it's inserted it will return the inserted value, if there's a conflict it won't return anything\nNot in fact it will never return anything even if it creates it.. Oh so we could use that to detect a conflict :). We could probably use call_args instead of call_args_list.. Why >= rather than ==. Don't you need = something ?. lambda will probably make flake8 to fail .... nit: principals = [request.prefixed_userid].extend(principals). database backends. Wrong handling of merge conflict?. Wrong handling of merge conflict?. Wrong handling of merge conflict?. Wrong handling of merge conflict?. Wrong handling of merge conflict?. Wrong handling of merge conflict?. Wrong handling of merge conflict?. Wrong handling of merge conflict?. Wrong handling of merge conflict?. We also need to update the version in the __init__.py of the package.. Actually we don't it is read automatically \ud83d\udc4d . I don't think we want to keep that log.. Yes sure.. For me the fix is at the storage level not the request level, but if it feels more natural, I can change the description.. I indeed put it in utils first but then I had a recursive import error when using http_error and ERRORS from utils.. The problem is that the logger will raise a UnicodeDecodeError as well :(. I don't think webob let me read the raw bytes of request.GET.. I should be able to log the environ if you think it is a good idea.. We should remove the * at the end.. Does this means that we can store as many data as we want in the collection to get infinite storage quota? Same question for bucket metadata.. After thinking about this a bit more, I think it is fixing the fact that once it exists, it will not keep increasing it. Is that correct?. A comment telling which events are sent there would be great. I guess it is the read event.. I don't think this would be possible, because to know that you would need to read the configuration file which is already a parameter of the CLI tool.... I would be ok to move that function to a scripts module in the quota plugin.. If you are in readonly mode you cannot write on the database, even from a script.\nIt is not the responsibility of this script to turn users in maintenance mode, if need is, it is the OPS that will do it.. I am a bit puzzle by a while True here, can we turn thoose into for bucket in buckets instead?. \ud83d\udc4d thanks. UnicodeDecodeError maybe?. I guess yes.. Because they are not valid JSON values and we don't use it, so I'd like to change the behavior to stick with the JSON spec there.. Why not? The goal is to make sure the JSON used by the history public are serializable. It should not hurt to activate it.. Yes that's what @n1k0 suggested, so it would allow to do *a*b*c requests for instance.. I agree with @glasserc that we should do all this at save time, rejecting the schema or changing it silently if it has internal fields in it.. Nice \ud83d\udc4d . If possible I would keep the Logging configuration at the end of the file because they change the INI sections while all into settings should be in the same [app:main] one.. Be careful that you changed the ini section here... (you are in the [formatter_color] section now). This file is not correct anymore, please update it with the changes that you've made to the other one.. 6f57dfd5. It looks like ReStructuredText to me rather than Markdown.. Check out the [open bugs](https://github.com/Kinto/kinto/issues) - anything tagged with the [**easy-pick**](https://github.com/Kinto/kinto/labels/easy-pick) could be a good choice for newcomers.. Anything tagged with [**enhancement**](https://github.com/Kinto/kinto/labels/enhancement). It is fine to keep lines breaks to 80 characters lines I guess.. [Github](https://github.com/Kinto/kinto/). [reStructuredText](https://en.wikipedia.org/wiki/ReStructuredText). It would be more future proof, but you don't want to have to worry about permission handling I guess.. That's the case if you don't provide any arguments, however OPS will use SOPS and ENV variables so they want to be able to do: kinto create-user --ini /etc/kinto.ini --username $USERNAME --password $PASSWORD. I didn't find one unfortunately :(. The latter.. Maybe we can actually. I will have a look.. Yes I know, apparently there is a way using stats but it doesn't looks as robust as my workaround.. Actually not with the TTL.... You are right I should do that in different PR's. Why are we talking about Atom here?. If it is the default, why do we need to add it in the config?. Please improve the message here.. Is this good enough? https://github.com/Kinto/kinto/blob/master/docs/api/index.rst#118-2017-11-16. Oups. Can we use a DNS to the library/memcached image there?\nKINTO_CACHE_HOSTS: cache:11211 cache:11212. lot of spaces at the end.. Was this change mandatory to be able to use the KINTO_CACHE_HOSTS env variable? It doesn't work with other backends apparently.. Yes I did, it seems to works :). I created https://github.com/Kinto/kinto/issues/1410 to handle that.. Yes sure be you guest. Can you think of a use case for that?. Can you think of a use case for that?. It is our own scheme. We asked ourselves a lot of question about that.\nLooking at the Auth0 documentation is seems that the only way to verify an access_token is to use the id_token. (at_hash value) but it doesn't seems to be the way of doing it with Firefox Account where we would most likely use the /verify endpoint.\n. My understanding of OAuth was that sending the access_token should be enough but then how do you validate it with Auth0? How does services usually work with id_token and access_token ? Do they send the id_token?. Do we need to convert the value to integer?. Well in your test you test with a mock of an integer, the question is did you try it with an actually config file?. This was it: https://auth0.com/docs/api-auth/tutorials/verify-access-token\nBut this is what I also found: https://auth0.com/docs/api-auth/intro#calling-apis-with-access-tokens. So maybe the access_token is also a JWT that self validates?. The problem is that if you look at this table: https://auth0.com/docs/api-auth/intro#how-to-use-the-new-flows\nYou see that tokeninfo is disabled.... Should we rely on userinfo call instead?. Do you mean to install pytest-watch here? In that case you should use $(VENV)/bin/pip install pytest-watch. In that case you should use $(VENV)/bin/ptw. Why not using {k: v for k, v in settings.items() if k not in black_list} instead?. What about going for a simpler algorithm, something like:\nblacklisted_settings = ['backend', 'max_fetch_size', 'max_size_bytes', 'prefix', 'strict_json', 'hosts']\nblacklist = [prefix + setting for setting in blacklisted_settings]\nfiltered_settings = {k: v for k, v in settings.items() if k not in blacklist}\n. Really?. No worries just checking :). I don't think we should put it here since it is already in the setup.py. Arguably this id and secret should be unique per users.. We should reuse code 105 for that.. I believe instead of putting it in core we should create a hawk plugin in the plugins folder.. We should plug it to multiauth so that we can use multiple authentication mecanisms in parallel.. Good catch, do you mind filling a pull-request for this one change only?. > So you think we should use one secret to authenticate all users on a kinto instance?\nNo not at all, that's what you've implemented but that's not what we are aiming at.\n\nSo user ID will be used as client ID and the secret will be defined in settings.\n\nI guess at some point we should have an endpoint to trade the account identifiers with a Hawk secret.\nThe secret will not be defined in the settings, but generated randomly and stored inside the database as a property of the account record.\n\nWhen you say we can \"rotate the secret as needed\"\n\nFor now you can ignore that part, I will try to put together a blueprint to explain that in details.. Oh sorry @gabisurita I missunderstood your comment yeah definitely \ud83d\udc4d . Not accurate anymore.. I guess this test is not only for _since and for other fields it might be useful to be able to search for an empty value.. Remove support for ID_Token (which is used by the frontend), on the backend we want to use access/bearer token . Should we replace oidc by google here?. Is this on purpose? I though we said that we would only send Bearer token and not id_tokens anymore?. I guess you mean that https://github.com/Kinto/kinto/pull/1413/files#diff-2193261fa1533ff793bf90b447434bc8R32 is not sufficient?. I don't understand how setting cache.expire helps here can you elaborate?. Ok got it. URL Indigestion. :+1: . What about:\n{\n  '': { \n    'bucket:create': { \n      '': ['bucket:create']\n    }\n  }\n}. Oh this is because we don't inherit settings permission just yet ok.... BOOM!. :joy: . Instead of using the bcrypt_hashed password in the cache key you can use the password itself (it will be hashed with the USERID_HMAC_SECRET anyway. Shall we keep 30 by default?. I'd like to understand where this [1] comes from it is a bit unclear to me right now.. > do we really need contains_any \nYes I do. > I think this is all way too complicated and I am not crazy about the use of string processing to convert from one type to another.\nThat's the only way I found so far to be able to add it in the WHERE clause.\nWe could use jsonb_to_text_array but it would be have to be a JOIN.\nIf you find another way of doing it, I would be pleased to use it.\nIt was also a bit complex to use the SQLAlchemy execute parameters with an array.. Yeah maybe we should keep it.. If you've got an array of json objects it won't work. The array should be only strings or int.. Yes @jlebunetel is working on the documentation part :+1: . Oh I just understood your remark, I guess we should add a test to make sure of it.. There is one case where current and collection_timestamp are different it is when current is lower than collection_timestamp. So we would have bump_timestamp and _bump_timestamp?. What do you mean it doesn't belong here? It is part of the two places you wanted to remove the _bump_timestamp call and add the new call to bump_timestamp.\nDo you want me to revert and keep _bump_timestamp instead?. Oh yes indeed :/. Yes sure thing.. You can probably use self.get(collection_id, parent_id, object_id) but that's the idea I guess yes.. I guess we should raise a 400 for objects here.. Whould test_contains_with_string_select_records_with_color be better? Any suggestion?. I totally disagree here, most of the time we want to use /collection?contains_any_colors=red and we don't want to have to add /collection?contains_any_colors=[\"red\"]\nKeep in mind that it is a querystring not a document body, we should keep it as short as possible.. IMHO it is not in the scope of this PR, we are trying to support strings and integer. That's something one might want but out of the scope of this PR.. Also for Kinto v1 API we already support it for in_ and exclude_ so I believe one might expect the same behaviour here. That's something we might want to revisit for the v2 of the API.. I am not afraid of order matters, that's how a sieve works. In software all fall through regexp implementation I know work the same way (iptable, urls patterns, etc.). Would this two cases work for you:\n\n/collection?contains_colors=red\n/collection?contains_any_colors=[\"red\", \"blue\"]\n\nMeaning we support one argument or a JSON list but not the comma separated list anymore?. Oh ok I totally missed that, thank you for noticing.. If we agree on https://github.com/Kinto/kinto/pull/1604#discussion_r183651613 maybe we can support this as if it were: querystring['contains_bar'] = '[{\"id\": 1234}]' ?\nWhat do you think?. Please use kinto.core.utils.json. Only two spaces before the #. 'redis://localhost:6379/2'. We should use kwargs here to make it more readable:\nconfig.init('kinto.ini', backend='postgresql', cache_backend='postgresql')\nShould we also default cache_backend to backend if the parameter is None?. We should add a test with postgresql and memcache.. If we don't need to generate the settings from the installed kinto plugins, we don't need to have a python view anymore to render the html page. (except maybe to route between the index.html page and the help page but do we really?). Why is this related to the CSP feature?. There are two things, the CLI tool that use the config.init function and the config.init function that can be use from somewhere else and notably in the tests.\nFor the former, you are right, but one could use the config.init function and I find it better not to have to pass twice the same value.. Move to .format(). :sob: . Any reasons why we need sudo here?. I should have read your issue description, sorry about that.. To test this, you would need to actually create someting and delete it from the test function itself.. I would say that it is good enough for me then. Can you also make sure that the collection permissions is empty?. Why did we need to rollback?. https://github.com/simplejson/simplejson/issues/237. Are those official plugins that we want to ship with Kinto? Why would we want to install them all by default? Should we plan to move them to kinto.plugins?. Should we enforce admin here as the default root user? I believe it would help people but it seems a bit brittle regarding security.. account:admin suggests that the admin account should exists. Also I would rather encourage people to use an email address as username because it simplifies the use of the sharing capabilities (although for the later we might need to verify the address). > But please open another issue, I don't want to let this rot\nI wasn't suggesting that we should make any changes or enforce the email address there, I was just suggesting to use account:your.email@host.tld rather than account:admin. Yes probably, we should investigate that too.. Objects or Items?. Are you sure it is still better like that that with the first commit?. https://github.com/Kinto/kinto/pull/1814/commits/fda8c13690cd2700371d00d488e00149fd5efd6a#diff-77d5feaac7fd094b43cdca245fac1ef4R179. Thank you for your Pull-Request regarding this.\nTravis-CI ran your tests here: https://travis-ci.org/Kinto/kinto/builds/450102518\nAs you can see in the logs here: https://travis-ci.org/Kinto/kinto/jobs/450102519#L581\nThe version tests case are now failing because we changed the behaviour.\nCan you update the test Kinto/kinto/tests/core/test_views_version.py:29 to reflect your changes?. Yes just keep add commit to your branch.. I am really reluctant of merging that because then we might loose sight of the next release of pytest-sugar.. I wish we could come up with a better way of naming this.\nsuggestion\n    \"jsonschema >= 3\",. Yes sir indeed #1900 . Maybe changing from \" to ' would be a better fix?. suggestion\n        self.validated[\"querystring\"] = {\"like_title\": 10}. suggestion\n                        \"name\": \"like_title\",. We do use PRIVATE :dancer: . ./kinto_chefclub/views/devices.py:\n    6 : from kinto.core.authorization import PRIVATE\n   51 : @devices.delete(permission=PRIVATE)\n   68 :     permission=PRIVATE, schema=PayloadSchema(), validators=(colander_body_validator,). Why would you remove this?. suggestion\n        \"flush-cache\",. suggestion\n        elif command == \"flush-cache\":. suggestion\n    elif which_command == \"flush-cache\":. suggestion. I guess we don't need both a command and a subparser.. The cache function has got a implementation per backend. Here we are using the one defined in the cache/__init__.py interface. It is the responsibility of each backend to implement it.. All tests passes, the only thing is that there are no tests yet for the code you wrote:\n/home/travis/build/Kinto/kinto/kinto/__main__.py                                127      2     52      1    97%   243-244, 241->243\nLines 243 and 244 as well as from lines 241 to line 243. Maybe we can add some feedback cache has been flushed ?\nSee https://github.com/django-extensions/django-extensions/blob/master/django_extensions/management/commands/clear_cache.py#L36. What makes you think it does work?. Ok I missed that.\nIf you look at the migrate command you will get a glance of what do to.\nBasically call bootstrap to get the env and then you should be able to call env[\"registry\"].cache.flush(). Do we need that anymore?. Can we merge the two strings?\nsuggestion\n                help=\"The bucket where the collection belongs to.\",. Do you plan on handling dry_run here? If not, please remove the argument.. Storing it in the cache backend seems to be a good idea in that case.. > Or we could generate the activation-key by hashing the record with the server's secret key\nTo make this correctly, the server secret key should be rotqted for each user which means you would still have to store the hash in the cache.\nThe benefit of using the cache is that you can handle expiration seamlessly.. Yep seems good.. > Isn't there something you could configure in the Google settings?\nUnfortunately nope.. I can also add a settings, add_trailing_question_mark or detect that it is Google and remove it :confused: . I am pretty sure Auth0 should add it automatically too.. Could you try it on your end?. > I know that I got this plugin working with Google ID :)\nI do remember that, but it seems to me that they made some changes on their interface :confused: . C'\u00e9tait pour voir si tu suivais :roll_eyes: \n. I don't think it is only coming from the openid plugin, it is something any plugin can define.. Yep that would be great: https://github.com/Kinto/kinto-fxa/blob/master/kinto_fxa/init.py#L65-L68. @leplatrem what do you think about this?\nI my opinion, we should restrict to one capability per plugin and instead add other info in the capability of the plugin.\n\"accounts\": {\n    \"description\": \"Manage user accounts.\",\n    \"url\": \"https://kinto.readthedocs.io/en/latest/api/1.x/accounts.html\",\n    \"validation-enabled\": True,\n    \"reset-password-enabled\": True\n}. Please add conditional view loading for reset password and validation.. Do you know if zest.releaser handle this?. :1st_place_medal: . :heart_decoration: . To be restful, we want this step to be a POST (because it changes a resource), this would also prevent developer to point their user to a JSON API endpoint rather than to an interface.. suggestion\n        config.include(\"pyramid_mailer\" + (f\".{mailer}\" if mailer else \"\")). Here you accept + character. Maybe shall we use the same regex for both?. > I don't think it's the same use case: in one case (no account validation) you want to allow a few set of characters, in the other case you might want to restrict emails to a given sub-domain.\nYeah makes sense :+1: . It's not a left over, in case this test fail we will be happy to have it to debug.. ",
    "almet": "Whoohoo, first external contribution :)\n. Yes, I believe that makes the most sense to have kinto persist on disk by default. Redis / Memory are too volatile to make them defaults here.\n. If we need to differentiate between defaults for the devs and defaults for prod, then we probably should  have two different set of configuration files.\nI don't consider postgres to be something harder than postgres to install (but yes, that's a personal thing I believe). So, even if it is (hard to install), we should document how to install it (with a docker, yo).\nI wasn't aware for redis persisting on disk by default, cool!\n\nThe suggested (and default) policy is to fsync every second. It is both very fast and pretty safe. The always policy is very slow in practice (although it was improved in Redis 2.0) \u2013 there is no way to make fsync faster than it is.\n. thanks!\n. (waiting on cliquet 1.1 to be released)\n. Fixed already. Closing.\n. Ah okay!\n\nCool that we have that. We've changed to use postgres as a default to store everything. So if we want to have docker use postgres, we probably want to pull postgres in addition to redis and create the default table.\n. (I've rebased this PR on top of master)\n. We need to add documentation on this as well.\n. LGTM\n. To run the tests, you should be able to run postgres. I think this needs to stay as a requirement since it's the default database we're using.\n. IMO the default env for devs is to use postgres, since it's the target database.\nInstalling it with docker is a matter of minutes. In case we really want to go down this path, then agree, we should change this, but I don't think that's the path we want to take.\n. Aparently the load tests are hanging. We need to find out what's hapenning.\n. > Unlike Daybed, I propose that each user owns the schema of the collection.\n\nEspecially because the schema endpoint will probably be a resource :)\n\nI don't quite get this. How is that different from daybed? I would propose anyone who can create a collection can also create a schema.\n. >  Is the schema using the resource code of Cliquet ? If so, how do avoid overlap of stored collections ? We could use underscores prefix, and prevent public collections to have a name that starts with underscore :)\nI think this is handled by the \"bucket\" concept.\n\nWhat happen to existing data when schema is changed ? Probably ignore and wait for next PUT or PATCH ?\n\nThat's a good question. I believe in this case it should be possible to iterate on all the records and apply a function to them, maybe?\n\nWhat happen when records are shared between users ? Do we let other users records crash our application when fetching shared records ? We could probably run client-side validation using JSON schema on shared records.\n\nIn case we download data from somewhere, we assume it's already validated by the server, so I don't get where the problem lies here?\n\nDo we want to provide a collection of custom formats or even types ? I'm thinking of recurrent needs for uuid4, geohash, GeoJSON objects, phone, postal codes...\n\nI think we should do that but would need to explore the json schema spec further to understand better how to do that.\nAlso, I think json schema has one big problem: its complexity. It doesn't seem to be simple to use it. As such, we could probably provide a way to create schema in an easy way, which would then map to the standard?\n. > Unlike Daybed, the collections are not global. It means that as a user, I can associate a schema to my todo collection, even if someone else already had set a different schema for her own todo collection.\nThen we agree :-) However, the notion of \"own\" differs a little: with buckets, a resource can have multiple owners.\nGotcha about how we should store the schemas. This should be handled by mozilla-services/cliquet#243 then.\n\nI was wondering what happens if two users have a different schema for the same collection name.\n\nWe need some kind of namespacing here (and I believe this is achieved through buckets). Like on github: leplatrem/cliquet differs from ametaireau/cliquet.\n\nI wouldn't go that way. Maybe if it's too complex, then we can imagine a WYSIWYG JSON schema builder ?\n\nI don't know the json schema spec well enough to make a call, but it seems that it would be harder to do it that way than allowing a simpler format.\n. Thanks for starting this discussion! I've also wrote something on my side that I'm posting it in a first comment before actually comenting on your proposal. I feel doing so before actually reading your proposal specifically could allow us to open up some thoughts.\nFrom yesterday's discussion, we agreed that a good way to approach this problem was to split the discussions into 3 different ones:\n- Define a list of permissions and a list of object on which they can be applied;\n- Define how we want to handle principals (what they are and how to we obtain them);\n- Define what the API should look like at the HTTP level.\nDefine a list of permissions and a list of object on which they can be applied\nList of permissions\nPermissions are the basic rights one can have on any object. I believe they are:\n- read an existing \n- create a new \n- delete \n- update an existing \nI don't think we should have a concept of \"sharing\" defined in the permissions, and I would focus on the real use case: anybody who can read actually can share.\nList of objects on which we can apply permissions\nWe can apply these permissions on:\n- all user's collections (authorize the creation of collections to someone else)\n- a specific user's collection (authorize someone to create new records in my collection)\n- records of a specific user's collection (authorize someone to read all records of the collection)\n- specific collection_records (authorize someone to modify a specific record of the collection)\n- colletion_schema (authorize someone to update the collection schema)\nIn addition to that, I believe we don't need to define an object for the permissions itself: whoever can update a record can change its associated permissions.\nFor each object, some permissions might not make sense and could be removed (for instance, updating or deleting a collection_schema might not make sense).\nI feel the discussion about principals should go in a different issue so I opened #35 \n. An now here is a comment on your proposal!\n\nwe only need permissions on Collections\n\nI also think we need permissions at the root level (so it's possible to have someone share all collections of someone else for instance).\nAbout permissions, we might not need to define an object for the permissions itself by statgin that \"whoever can update a record can change its associated permissions\".\n\nThe collection owner can change permissions and give specific access to some other users\n\nI believe we could have that by just using the \"write\" permission to the \"collection\" object.\nI believe my proposal is along the lines of your 3rd use case: \"Everything is flexible and go through permissions\"\n. Oh, I get where you're coming from. By sharing, I was only thinking about sharing the same access level.\ne.g. if you have the rights to read and write, then you can give anyone else this same right.\n. Wow, this issue tries to cover a lot of different things at once (introducing the bucket concept and defining the exposed APIs for permissions)!\nBuckets\nI do agree that permissions introduce a big shift in how we currently expose our APIs, and I think I like the bucket approach.\nHowever:\n\nIt also means that collection doesn't necessarily belongs to one user only but can have multiple owners.\n\nIt's entirely possible to have the collection belong to one user and have this collection accessible by many different users. It is similar to what github proposes with their repositories: it's mine by I can have others publish information there, even without my consent.\nTo continue the github comparison, buckets seems a lot like what they called \"organisations\". I like the fact to let the meaning open, because as you said \"The benefit from having bucket is that we let the user defines what does the bucket means\".\nPermissions\nI concur with the fact we should continue using the +, -, All and Authenticated concepts we had in Daybed (back in the old times!).\nI think we should define a formalism for all the objects and associated permissions matrixs. For instance, I would say we reuse the objects and permissions defined in #33 and have something like {object}_{permission} for all the combinations.\nThere is still a bunch of shadow spost I would like to get adressed:\nI don't understand what is the concept of \"shared_principals\" you introduced, and I believe we don't need to have the concept of sharing exposed at all in our APIs.\nAnd it's actually where it starts to get complicated. Let me use an example to explain what I feel is painful and what needs resolving here.\nImagine you have a collection where you want to share specific records with specific people. For instance, R\u00e9my has a blog where posts about \"music\" can be edited by \"musicians\" and posts about \"bike\" by \"bikers\".\nFor each record, it's possible to push the associated permissions. If R\u00e9my wants \"Severine\" and \"Alexis\" to edit posts about music, then he needs to add them to all the records that are talking about music to add them to the permissions.\n(I'm aware of the limitatons of this example \u2014 it's possible to create a collection per category \u2014 but I hope you can grasp my concerns out of it)\nHaving a concept of \"groups\" would help solving this, and maybe that's what you tried to bring with the \"shared_principals\"? If so it seems it's not fine grained enough to cover this use case.\nAlso, we need to be aware that's something we tried to solve with daybed in our first iteration and had something way more complex that what we wanted as a result.\n. > The name is maybe not the right one, but it is the list of principals having access to the record using the collection read_shared_records permissions.\nHere, \"access\" is not defined enough. What does that mean? Which permissions?\n. > Yes I agree about the group concept, we can add a new category of principals for it.\nInteresting, I like that. Then it means that users can obtain different principals depending on which collection they're acting (because musicians means something different for me and for other users).\n. Sorry, I find this API proposal cryptic. \"shared\" should reflect a state and records don't have a \"shared: true/false\" attribute.\nOh, I think I got something interesting!\nRather than defining the relation with \"principal \u2192list of permissions\" we could do it backwards \"permissions \u2192 list of principals\".\nOld:\n{'bucket:musicians': [\"read_shared_records\", \"update_shared_records\"]}\nNew:\n{\n  'read_record': [\"group:musicians\"],\n  'update_record': [\"group:musicians\"]\n}\nWhere groups would be defined inside the collection; or if not there, on the bucket.\n. It's interesting to note that these information we can get about our users aren't actually all mandatory. We should have one which is mandatory (and acts as a kind of identifier of the user).\nAlso, I would be more specific about the principals you can get out of this, for instance, if the principal is coming as an uuid, then we should put this information in the principals.\npython\n[\"uuiid:4567\", \"email:natim@example.com\",\n \"bucket:servicedesnuages\", \"scope:payements\", \"scope:profile\"]\n. I don't quite get what \"I have access to the servicedesnuages org\" actually means and if that's something we should support for our first iteration.\n. See #34 for a definition of what buckets are.\n. > ``` js\n\n\"permissions\": {\n   \"groups\": {\n      \"write\": [\"uid:\"]\n   },\n   \"collections\": {\n      \"read\": [ ... ]\n   }\n}\n```\n\nI agree with that but we should add the \"create\" permission.\n. I've updated. We probably should upate the APIs as well, but I think it's wiser to wait for feedback first.\n. OK, I think we're good with this, should we merge?\n. Sorry for the context miss here. This branch has been merged in another temporary one which contains all work related to permissions and buckets. see https://github.com/mozilla-services/kinto/pull/46\n. I'm glad to have this feature ready.\nHowever, I was more thinking about having the schema defined alongside the data attribute (e.g. at the same level).\nIs there any reason why this is not the case?\n. This has been merged in the temporary bucket-permission-api branch.\n. That's pretty cool and I think we should merge it for now. I'll create a new issue to have the permissions deleted on deletion of the collections / buckets.\n. See #57 instead.\n. This is here: https://registry.hub.docker.com/u/mozillastorage/kinto/\nNow all commits to master will build a new docker image. We might change this in the future to only build tags.\n@leplatrem @Natim @tarekziade @n1k0 if you have an account, I can add you to the mozilla-storage organisation.\n. r+ minus the discussion on 403 vs 404.\n. LGTM.\n. r+\n. LGTM with nitpicks.\n. r+ with nits.\n. It's ready to be reviewed.\n. Updated with @Natim 's comments.\n. Updated.\n. Thanks! Didn't updated the version pinning though.\n. Ah okay. This was done in the (unrelated) https://github.com/mozilla-services/kinto/commit/f82c24e962734671330a9bbd427ca87517b97915 commit.\n. LGTM with comments.\n. Let's just remove the inclusion of the readme then. It doesn't bothers me that much, it's just that it's getting in the way of having an easier to follow documentation, that's all.\n. That's indeed useful to have the default authz policy used here!\n. r+ (tests pass)\n. Potential solutions for this are WebFinger or the Mozilla Token Server (which assigns users to a node).\n. We could first try to hit a webfinger URL and fallback on FxA if no webfinger document is found.\n. Kinto itself is not tied to any authentication mechanism. We are currently supporting FxA via OAuth 2.0 bearer tokens, and could also support BrowserID if needed.\nSince the current best practice to connect to FxA is to use OAuth2.0, and this is completely unrelated to how the discovery works, I think we need to find a better way to support that.\nWeb Finger seems an option here, especially because it's defined in an RFC and easy to implement. I have left to find if there are other easy ways to do this. I'm thinking about DNS TXT records or files that an user could deposit on their domain, but that restricts to people who owns some domains.\nIn the case we don't find such document, we might also fallback to a repository (operated by mozilla) where users link to their kinto instance.\n. > It is what I had in mind, we could operate this repository using a Kinto server.\nIn any case, this repository should mimics the semantics we're using for user discovery. e.g. if we use webfinger for discovery, then we should have something with the same semantics that runs on our infrastructure.\n. For completeness, here is the proposal I submitted for an outreachy intern:\nThe Kinto project aims to bring storage instances to everyone,\nattached to their Firefox Accounts. It actually supports multiple\nauthentication schemes, but FxA is integrated with it, and that is\npart of the solution we want to deliver.\nCurrently, Kinto is thought as a centralized server: there is one\ninstance, and everyone authenticates on this instance. Items are\nshared between users of a same instance.\nThis doesn't resonates well with multiple goals we have: scalability\nis harder when there is one endpoint, and it's also not interoperable.\nFor instance, imagine Alice and Bob. Bob is using Mozilla's servers to\nstore his data, whereas Alice deployed her own Kinto instance.\nThere are different use cases:\n- Alice wants to use Routina [0], an application that stores its data\n  inside a Kinto instance. As such, Routina needs a way to discover\n  where it should store its data, and send the requests to this server;\n- Bob and Alice want to collaborate on a set of data (think about a\n  shared expense webapp). There should be a way for Alice to host\n  everything and grant access to Bob to her data. The webapp should be\n  able to use the correct server.\nHere are the different steps that could allow these scenarios:\n- At the moment they authenticate, the client detects the email adress\n  used, and relies on the domain part to do a Web Finger request on the\n  domain ** and for the specified user.\n- In case the identified server doesn't support WebFinger, it uses a\n  central repository to lookup where the Kinto server is located.\n- Once the Kinto server located, all requests should be issued against\n  this server.\n** It is also possible to use the same mechanism to discover the FxA\nendpoints. But as FxA isn't a federated protocol, users from one FxA\nrealm would need to be accepted explicitely by the Kinto server, in\nits configuration.\nIn terms of code changes, here is what it looks like (roughtly step\nbystep):\n- Update the Kinto.js client to find the server location. It should\n  first rely on WebFinger;\n- Create a central repository. This could be contained in the FxA\n  profile server or in a central Kinto collection;\n- Update the Kinto.js client to fallback to this central repository in\n  case no Web Finger exists;\n- Investigate on ways to store this information directly in the web\n  browser. It could also be configurable by the javascript client (with\n  an UX that looks like what Remote Storage proposes).\n- Work on the first user experience: how can client learn they can\n  chose which server to use?\n- Ship it!\n. See @oak11's article about how servers will be discovered. http://www.servicedenuages.fr/en/discovery-of-kinto-servers\n. In order to accomplish this, a new command should be registered.\nSee how entry points are being handled in the Cliquet project.\nYou should be able to do this by registering an entry point for the name \"kinto\". Then, you should use argparse with subparsers in order to handle the different commands.\n. Let it be https://pay-storage.dev.mozaws.net/v1/\n. +1. I added to the trello this afternoon actually. Maybe we should close here and ping them when it's been deployed.\n. We probably should still add a test in kinto for it. (reopening, feel free to close if you feel it's not appropriate)\n. No, the test in cliquet seems enough. I naively thought that it was not testing for specifically the 304 response. Closing.\n. This is so helpful to have someone speaking correct English! <3\n. @leplatrem thoughts?\n. If we want to allow this only for kinto then I think this PR does what it should, but I wonder if we shouldn't do this directly in cliquet.\n. Currently, the only way to remove a permission is to issue a PUT on the associated endpoint. Using a PATCH will only add members.\nThis is not the final API and we are currently working on the semantics to use in order to delete principals.\nOne of the proposal that was done was to keep the endpoint like it is right now, and add new sub-endpoints on which it would be possible to:\n- issue PATCH with {\"remove\": [\"tartenpion\"]} on  e.g. /records/{id}/permissions/read;\n- issue DELETE on e.g. /records/{id}/permissions/read/tartenpion.\n(Discussion is still open on this)\n. @leplatrem yes that would be much appreciated :-)\n. This is now ready to be reviewed. @phrawzty @Natim ?\n. GREEN IT IS!\n. @Natim why not but this is orthogonal to what we're proposing this IMO. \nDoing the rename of the current \"data\" in \"metadata\" will break the protocol, though, so we should issue a new version of it. Since we don't have anything in production just yet that relies on the current version of the protocol, it might be the right timing to change it.\n. That's exactly the scope of the data/metadata thing: metadata is data kinto relies on internally, whereas data is meant to be used by the client.\n. We hadn't identified the need to store data on buckets so far, but we can add it if you have a use case for it?\n. There is this thig in the redis documentation as well. +1\n. Ah! That's where it was previously actually, and we moved it there because it was more a guide to different type of permissions. I honnestly can't chose between the two location: both of them sound okay to me.\n. Thanks!\n. yay! Thanks :-)\n. LGTM. Merging.\n. I think that it is a useful feature to provide for Kinto, if we want to have servers open to the world at some point :-) Reopening for now, we can close it if/once we all agree this feature isn't useful.\n. Thanks for your answer :+1: \nWe had a parallel discussion about the location of id and last_modified (which we named metadata). There are multiple reasons to put them in a different location than the data itself (one of them being that the clients currently need to mutate the returned objects to pass them to their consumers) and we were thinking about putting them in a metadata namespace.\nI was concerned about the complexity it adds to the API, and that's the reason why I like your proposal: it separates the metadata from the data itself, without adding yet another namespace.\nI would propose that we do that by iterations:\n1. Move the schema attribute to the root of the collection object. Leave the schema attribute on records as it is for now;\n2. Move id and last_modified to the root as well;\n3. Move the schema attribute of records to the root.\nThis change would impact both Kinto.js, and Syncto. If we have to break the API, better do it sooner than later: nobody is currently using this protocol for something that shipped. If we want/have to wait, we'll need to think handle backward compatibility, which isn't a concern we have right now.\nAlso, there is something I don't get: why are you saying this is that complex? What do you identify as the potential implementation problems?\n. We should add a note which credits the original authors if we remove them from the logos here.\n. I've identified a few things where having a custom theme would help us move things forward. For instance, it would help to be able to hide the menu on the index page.\nSo, we might fork this theme and add the missing bits ourselves.\n. I like it, but I'm not sure it makes sense to have it on the index page of the documentation.\n. yes, its the best strategy :-)\n. Looks good to me overalls. I'm a bit concerned about some duplication of concerns between the Kinto and the Cliquet documentation, especially about settings, though.\n. Yes that makes sense. r+ :-)\n. Exactly the same story for me, hence the question.\n. Ideally, using IRC would be the preferred way to connect. However, IRC is too complex for newcomers and they don't tend to stay in there. Plus IRC does require you to stay connected to access the backlog (well, it's possible to use hacks, but that's what they are: hacks).\nZulip (zulip.org) seems to be one of the alternatives that it is possible to self-host. However, it unfortunately takes a large amount of memory to run.\nThe other proposed solution, mattermost seems to be a good alternative. We need to try it out!\n. I think we should put IRC aside, as it isn't a great way to be in communication. For instance, none of the Outreachy is currently there, nor any of the occasional contributors.\n. The thing being: how do you help them?\n. I like the idea to keep the canonical way to contact us to be IRC on freenode: it's a network run for projects like us, and it's not baked by a company (which can disappear any time).\nHowever, as slack seems to be a convenient way for people to contact us, it might be a good idea to do a duplex, maybe using https://github.com/hoodiehq/slack-irc-duplex and then proposing the two ways to contact us ?\n. Nice investigation.\n. Ah, too bad to hear this @nikkisquared. Feel free to reach out tu us whenever you can/want about kinto.\n. I would actually find it very nice to have Kinto.js examples integrated with the current Kinto documentation, or at least have pointers there, Kinto.js being the reference JavaScript client.\nI actually agree that the HTTPie commands are useful in order to reproduce a call (I've used them a few times already). But I think it is only useful for the persona who's implementing a Kinto client, and the core devs.\nPublicizing the use of Kinto.js is IMO a good way to move the ecosystem forward, and while reviewing the docs, I was really asking myself why I wasn't seing some JS examples, or mentions of a JavaScript client earlier: I believe we should showcase the JavaScript client as the primary way to integrate with Kinto.\n. I would love to have @n1k0's feedback on this.\nWhat do you think about having the Kinto.js client exposed directly in the Kinto server documentation? It could be just a link to the documentation of Kinto.js, the goal here would be to have the users use our solution with the smallest amount of indirection.\n. sorry if this was unclear. I think we all agree on the fact that we should keep the HTTP API. I'm proposing to add pointers to the JavaScript client, because it's not the case currently and seems to be missing.\n. +1\n. > What does this mean? Remove the commands that demonstrate how to actually make the requests? I think those are useful, so maybe you're talking about something else.\nThat's what I meant, yes. See #502 for more info on this.\n\nI don't see any \"community\" section. Was this renamed to \"Contributing\"? Or should there be a new order?\n\nThere's a big \"Community\" section in the front page, but it's not reflected in the menu on the left: these two should be the same, and in the same order.\n\nResource endpoints are broken\n\nThey're broken in the sense that if you actually navigate to a specific example, the according section should be highlighted on the left menu, but it's currently not the case. At least the \"API\" section should be highlighted.\n\nthe \"hack\" section is broken\n\nI cannot find anymore why it's broken, so let's consider it's ok!\n. Also, it should be possible to have different push urls for one person, depending on the collection.\n. r+\n. @oak11 I'll close this pull request. Please open a new one with just the changes you want.\n. In order to do this, you should, in cliquet:\n1. Add a \"ping\" method to the redis backend. It's as simple as self._client.ping() which should be exposed as a \"ping\" method, and called in the __init__ method. The method should be added here: https://github.com/mozilla-services/cliquet/blob/master/cliquet/storage/redis.py#L51\n2. Add tests that ensure that an exception is raised in case the ping doesn't work.\n3. Do the same for Postgres.\n. Oh! So there is already a ping method to use! Neat. Even simpler then: just call it ;-)\n. Notifications for the win!\n. Good catch @michielbdejong !\nIf I understand the holy spec correctly (link to the caching section), it seems that returning no-cache would make the client issue a request even if there are matching records in the cache. The response could be cached by inbound servers, and as such the problem would remain effective.\nRather, we could use the Vary header (see spec), specifying the header \"Authorization\".\n\nThe \"Vary\" header field in a response describes what parts of a\n request message, aside from the method, Host header field, and\n request target, might influence the origin server's process for\n selecting and representing this response.  The value consists of\n either a single asterisk (\"*\") or a list of header field names\n (case-insensitive).\n. What about adding this Vary header to all the buckets? It seems to be something we want anyways, which would mean the security model would be the same across buckets, nope?\n. They already are in there (in the docs). See in red after the key of the setting?\n. @Natim I don't understand what we get by having two different levels of \"data\" (or data/attributes). Having data alongside the other metadata (last modified etc) seems cleaner to me.\n\nPermissions, schema etc should go alongside the rest. Eg.\njs\n{\n  'id': '1234',\n  'last_modified': 123456,\n  'data': {'foo': 'bar'},\n  'permissions': {},\n  'schema': 'blah'\n}\n. Cool. For the last warning, we probably should find a way to exclude it from the copy, in here https://github.com/mozilla-services/cliquet/blob/master/cliquet_docs/init.py#L6\n. r+ otherwise.\n. Hey. Thanks for the new pull request. However, this includes changes that aren't useful. I suggest you start from scratch, from a new branch, and you import the changes you want there.\nThere are multiple things you need to do, since you commited these changes in your master branch (doing so is considered a bad practice as it prevents you from working on multiple patches at the same time, for instance).\nSo, I would recommend you to remove your clone from github and start again, with a fresh clone (but first, save your work by copying it somewhere else, for instance!)\nThen, we don't want to have a completely empty repository with just your files: we want to have it added. I'll let you figure out how to do so. In the meantime, I'll close the pull request here.\nFrom a fresh clone:\n$ git checkout master\n$ git checkout -b generate-ini-file\nThen add your files, and then:\n$ git add newfile.py\n$ git commit -am \"Commit message\"\n$ git push origin generate-ini-file\nAnd then issue a pull request.\n. You should also add a command line to this, in order to have a \"kinto init\" command.\n. With the kinto init command there is no need to start the server; just create the .ini file!\n. That's not the intention. The intention was implemented in https://github.com/Kinto/kinto/pull/395\n. I've just got the exact same problem locally, with python 3.4. Not sure why this is included since it should be included for python < 3 only.\n. Closing in favor of #528.\n. Okay, great. Now we have to write the tests!\n. Tests for config should go in kinto/tests/test_config.py and don't bother about having tests for kinto.__main__ for now.\n. I would also add:\n- master-master replication\n- creation date\nThen, the problem I see is that this table will be really hard to read (and might take too much space).\nAny idea on how to solve this problem?\n. Well in practice it's useless to me, since I can't subscribe to it.\n. Thanks!\n. Now, that's a good idea!\n. PPPerfect!\n. Thanks for doing this. I'm actually not sure about the results, when looking at them.\n\nIn this example, the table is almost unreadable...\n. Also (and I know this is painful to change again) I wonder if the default value should come at the end (after the explanation and not before) ?\n. Cool :)\n. +1 for contains.\n. contains?\n. defined, exists?\n. I would suppose the \".\" could be a delimiter.\n. Hi, and thanks for your request and comments. In addition to pusher (and cliquet-pusher), one can integrate with any service to notify on new changes. The goal of Kinto is to be easily integrated with all these different services.\n. You're actually completely right, we need to update the documentation to add information about notifications on Kinto. It's hidden in the Cliquet docs, but we didn't spent the needed time to update the Kinto docs. I've opened #353 about this.\n. Thanks, that's useful. It also showcases that we're missing documentations for events, since no docs are to be updated yet :(.\n. Thanks!\n. That's a very good idea, Karl! Do you think a link to the edition form on github for the specific page would work?\n. That's a good idea! Do you want to work on a pull request or would you prefer us to add it?\n. It's all in the installation section. The overview was meant to explain what kinto is, and not to get started with it. We could add a section with a link to the \"installation steps\" if you think it's worth it?\n. How to install postgres is already described. We could add some more information about how to install python and redis in subsequent sections.\n. Thanks!\n. Hi! As I was saying this morning during the standup, I'm not really in favor of having a link to heroku on our landing page.\nHowever, having a \"deploy\" button that links to a section of the documentation where different ways to deploy are listed seems a more acceptable idea to me.\nI can do these changes if you don't want to make them.\n. We need to chose between \"get started\" and \"deploy now\", otherwise the text is too long.\n. ah.\n. LGTM\n. Great idea otherwise! r+wc\n. go go go !\n. Then, how do you remove the feature?\n. I'm adding a few more details.\n. updated the PR with some more info and rephrasing.\n. Adding some more info in the text.\n. updated.\n. Ah, that's cool, didn't know about it :-)\n. Out of curiosity: what's your use case for this? :-)\n. Thanks for the report and the test case :-)\nThis should make the documentation easier to read: https://github.com/Kinto/kinto/pull/389 (credits to @natim). Don't hesitate to add some feedback there.\n. Thanks!\n. Thanks.\n. Hi, thanks for opening this issue.\nThis is not something we currently allow, because we didn't had an use-case for it. It's possible to add this feature, and should be done in cliquet rather than in kinto.\nI personally like the idea of specifying the keys you want in return, with a _keys? argument probably. Do you want to work on a patch for this?\n. Ah yes! Neat, I missed this change in cliquet.\n. I think this should be done as a plugin. From the documentation, I see that one would need to \"send the notification and a device token to the APNs servers\".\nTheir API is full HTTP, so this looks a lot similar to what we're doing in the kinto-webpush extension, and that could be a nice use case for it.\n. That looks good to me!\n. r+\n. This happened when doing what? How can I reproduce?\n. Thanks!\n. r? @leplatrem \n. Let's do that!\n. Hi, thanks for taking the time to add these features to the list on our documentation!\nHere are some general remarks:\nThe tables is malformed and wouldn't render properly. Here's a diff you can apply locally to have it working properly.\nI tried to read a bit the documentation of couchbase mobile, and it's unclear how are provided some of the features you're marking as \"provided\":\n- Pluggable storage / cache: can you point me where I can configure the storage and caching layers to use some different backend that the default one?\n- Fine-grained permissions: same here, I failed to see where fine-grained permissions are provided. Do you have a link to some documentation?\nThanks!\n. By pluggable storage we think more about the database you can use in the backend: postgres, mysql, mongo, etc. Kinto is built around the fact that you can store your data in the backend of your chosing. I believe this is not what Couchbase mobile provides.\n. From the article you pasted:\n\nChannels provide READ access to users between the mobile client and the remote database.\n\nThat's not what we call fine-grained permissions. Kinto proposes a matrix of {bucket,collection,record} x {write,read,create} permissions. You can read more about the limitation of CouchDB regarding permissions on our article. It seems that these points are also applying to Couchbase mobile. I might be wrong here, so don't hesitate to provide some more information about how ACLs are handled so we can update our documentation properly.\n. Hey @WilliamHoang . I've read your article with interest, and I've seen that you've indicated there that couchbase is doing pluggable storage and cache. How couchbase is doing pluggable storage is still unclear to me.\nAlso, it seems you reused the comparison table from here without giving credit. Beware that the content in this repository is released under the Apache license and as such it's better to cite the original authors if possible.\nThanks!\n. @WilliamHoang Did you find the time to fix the issues I raised here? Otherwise I'll close it for now, and you can open another pull request with the correct explanation. Thanks.\n. No news, I'll close this pull request for now. Feel free to re-open if needed.\n. Hi, and thanks for taking the time to write this down.\nBy reading it, however, I feel more confused than before, so I think it's the good time to decide together what we would like to put in there.\nHere is what I would like to put in this:\nWhy do I need a dedicated JSON store where databases such as postgres offer the same thing:\n- Databases don't offer a way to access your data over an HTTP interface.\n- Databases expose a complicated query language.\n- Kinto lets you configure the database you want to use, and exposes a unified API for all the different databases.\n- Databases are not meant to have offline first clients.\n. Could be of some interest \u2014\u00a0http://daybed.readthedocs.org/en/latest/\n. Some comments: you're focusing on what kinto does for the users at first, stating what they want, but this might or might not be the case, depdending who your users are.\nI proposed a few changes (in the pad and here):\n``` rst\nWe believe data belongs to the users, and not to the application authors. When writing an application, data should be made available from any device, connected or offline, and everything should be in sync.\nRather than spending a non-trivial amount of time and expertise on implementing all that (and then maintaining it !), you could use Kinto, that does all that for you:\n- Expose your data over an HTTP interface, unlike a database like PostreSQL\n- Use simple HTTP queries, instead of SQL\n- Use Kinto.js to easily implement offline first clients\n- Choose the database you want from those that Kinto supports, and use a unified API to access its data\n- Administrate your data using the handy admin UI\n- Easily set up live push notifications for live synchronisation\n- Make it possible to  share data between users (using fine-grained permissions)\n- Take advantage of schema validation if you need it\n- Use tools and libraries like Kinto.js that implements encryption so you don't have to\n\n```\nAbout the wording: we try in general in the documentation to avoid using \"you\".\n. Yes, it seems that matrix is the way to go for a better travis integration.\n. Thanks!\n. Thanks for bringing this up. I like the idea of not trying to do too much, and I believe that's why we used lightweight.\n\"Kinto is a lightweight JSON storage service with synchronisation and sharing abilities.\" would then become \"Kinto is a simple JSON storage service with synchronisation and sharing abilities.\", and I don't see a lot of value in \"simple\" in this sentence.\nTwo alternative proposals:\n1. Remove lightweight completely. \"Kinto is a JSON storage service [...]\"\n2. Put a little indicator next to \"lightweight\", with a link explaining what we mean by that.\n. good idea!\n. Thanks, that's easier to understand!\n. That's a good idea.\nThe goals of both documents are not exactly the same, because CONTRIBUTING.md will actually be included at the beginning of each pull request. It could then make sense to have CONTRIBUTING.md contain some basic instructions that are useful in the context of a pull request with for instance a link to our contribute page.\n. Great! Should we change it in cliquet as well?\n. Thanks for taking the time to write this.\nHere is a capture of what I see when clicking on the link and then posting the data to the kinto server. The commercial service hurl.it displays ads.\n.\nThat would probably be beneficial to have our own instance of this service rather than relying on a third party: that would let us remove the ads we don't want.\nAlso, maybe there could be a way to not get the user out of the context of the tutorial each time he/she clicks on a link: that would be great to have the same experience but staying inside the documentation.\nWe were discussing this with @n1k0 last time, and I wonder if users will actually use these features? (I for once would copy the curl/httpie links in my terminal). @magopian for instance, would you use such links if they were present?\n. Thanks for your feedback. That sounds like a good course of actions. I just don't want to point our users to a commercial website if we can avoid it :)\n. Here it is! http://hurl.kinto-storage.org (soon over https)\n. After a quick timelooking around, it seems that the free version of hurl doesn't contain the same features that the closed version has. I wonder if we should look at other potential alternatives.\n. Still the same company, but I like how they provide the command line and next to it a \"send to hurl\" link: https://www.embedcurl.com/\n. After looking a bit more, it seems that this free version of hurl actually proposes to have a bookmark to the requests/responses, but you need to click the \"permalink\" link at the bottom of the page.\nIt seems that this permalink is actually a hash of the parameters.\n. Relevant \u2014 https://twitter.com/ametaireau/status/697129422172897281\n. I think we can close this pull request for now. I created #502 for the idea of having executable examples (that can run from the documentation directly).\nAlso, as per a discussion this morning, it seems that for the documentation, it might make sense to use the docbox project.\n. The problem seems to come from this line in the psql backend, which takes the greatest value between records timestamp and the current datetime.\nWe should take the last_modified value of the collection?\n. Actually, we would need to set the timestamp during the creation of the collection.\n. Thanks a lot for this contribution! I've added a few comments here and there. In addition to them, please try to wrap all the lines to 80 chars.\n. 1. Not sure what you mean with \"list all users\", since we don't have any concept of users.\n2. To delete records owned by a particular user, you need to authenticate as this user and issue a DELETE request on the collection.\n. @Natim explained the technical reason for this answer from the server.\nHowever, I believe the response should be an empty list rather than a 403 for the list of buckets.\n. See https://github.com/mozilla-services/cliquet/pull/636/files for how we did it in cliquet.\n. Yep, this sounds cool!\n. Currently, I've added a --no-test option in debian/rules because it fails with an error:\nrunning build_ext\nTraceback (most recent call last):\n  File \"setup.py\", line 83, in <module>\n    dependency_links=DEPENDENCY_LINKS)\n  File \"/usr/lib/python2.7/distutils/core.py\", line 151, in setup\n    dist.run_commands()\n  File \"/usr/lib/python2.7/distutils/dist.py\", line 953, in run_commands\n    self.run_command(cmd)\n  File \"/usr/lib/python2.7/distutils/dist.py\", line 972, in run_command\n    cmd_obj.run()\n  File \"/home/alexis/dev/kinto/debian/kinto-server/usr/share/python/kinto-server/local/lib/python2.7/site-packages/setuptools/command/test.py\", line 142, in run\n    self.with_project_on_sys_path(self.run_tests)\n  File \"/home/alexis/dev/kinto/debian/kinto-server/usr/share/python/kinto-server/local/lib/python2.7/site-packages/setuptools/command/test.py\", line 122, in with_project_on_sys_path\n    func()\n  File \"/home/alexis/dev/kinto/debian/kinto-server/usr/share/python/kinto-server/local/lib/python2.7/site-packages/setuptools/command/test.py\", line 163, in run_tests\n    testRunner=self._resolve_as_ep(self.test_runner),\n  File \"/usr/lib/python2.7/unittest/main.py\", line 94, in __init__\n    self.parseArgs(argv)\n  File \"/usr/lib/python2.7/unittest/main.py\", line 149, in parseArgs\n    self.createTests()\n  File \"/usr/lib/python2.7/unittest/main.py\", line 158, in createTests\n    self.module)\n  File \"/usr/lib/python2.7/unittest/loader.py\", line 130, in loadTestsFromNames\n    suites = [self.loadTestsFromName(name, module) for name in names]\n  File \"/usr/lib/python2.7/unittest/loader.py\", line 103, in loadTestsFromName\n    return self.loadTestsFromModule(obj)\n  File \"/home/alexis/dev/kinto/debian/kinto-server/usr/share/python/kinto-server/local/lib/python2.7/site-packages/setuptools/command/test.py\", line 37, in loadTestsFromModule\n    tests.append(self.loadTestsFromName(submodule))\n  File \"/usr/lib/python2.7/unittest/loader.py\", line 100, in loadTestsFromName\n    parent, obj = obj, getattr(obj, part)\nAttributeError: 'module' object has no attribute 'test_views_flush'\nTraceback (most recent call last):\n  File \"/usr/bin/dh_virtualenv\", line 106, in <module>\n    sys.exit(main() or 0)\n  File \"/usr/bin/dh_virtualenv\", line 92, in main\n    deploy.run_tests()\n  File \"/usr/lib/python2.7/dist-packages/dh_virtualenv/deployment.py\", line 156, in run_tests\n    subprocess.check_call([python, 'setup.py', 'test'], cwd=self.sourcedirectory)\n  File \"/usr/lib/python2.7/subprocess.py\", line 540, in check_call\n    raise CalledProcessError(retcode, cmd)\n. Might be interesting: https://github.com/nylas/sync-engine/commit/bb4881d876d9a99c42a07ac3d97336c15cc83ee3\n. Thanks, that looks great, you just need to address the little nitpick and we're good to merge!\n. I concur with this: the tutorial should not rely on external dependencies if there is no need to. ShortID could be a great addition, but that's a feature, and out of the scope of this tutorial.\n. General note: does it work with a .rst extension?\n. Either is fine! (a.k.a \"I don't care\")\n. LGTM with nits.\n. Just noted that links do us the markdown format whereas this is rst.\n. That looks good to me! You can land with or without my last nitpick !\n. Thanks!\n. That's a bunch of cool changes! Great.\n. Yes, I think we should merge this (but it needs to be rebased first)\n. Thanks!\n. Let's close this then!\n. That's great I love it :) We should add a few more links and be good to go!\n. That's great!\n. thanks :)\n. Hi, and thanks a lot for taking the time to send these changes to us, they're very welcome :)\nI've added a few comments in the pull request, let me know when you're ready so we can merge!\n. Great, thanks a bunch for this :+1: !\n. looks good to me, added a few nitpicks.\n. @lavish205 that's the same idea, but that's not the same code exactly: one will need to do the same work for exposing this \"flush\" capability.\n. Yes !\n. I would be in favor of flush_endpoint_enabled, which I think conveys more meaning (flush could be just anything)\n. Great idea!\n. So I believe we should close this issue!\n. Thanks !\n. Travis CI is showing the test that fail. You should see this fail also on your machine (when running make test)\n. What's the configuration that was used? How can we reproduce?\n. Hmm, I don't have any access there. Can you copy and paste the stacktrace in this bug (I think that's something we might want to do for these issues anyway, because not all contributors have access to the sentry stack).\n. Thanks for proposing this. It misses tests that show that this is working like it should.\n. Found this very nice toolkit to generate different HTTP calls examples, based on the HAR format for request/response: https://github.com/Mashape/apiembed/\n. Also have a look at https://apiblueprint.org/\n. Which can be used to generate docs like this: https://github.com/danielgtaylor/aglio\n. Thanks!\n. We should add a functional test for this to avoid regressions in the future.\n. Velruse can be used either as a pyramid plugin or as a separate service.\n. What do you think @bbangert ?\n. That sounds like a reasonable thing to do, yes!\n. Refs https://github.com/mozilla-services/cliquet/commit/2c2f0337923272a52caa3a0e32a1bfd23f8e374b\n. Hi!\nA guide on how to install postgres is already provided, I think it could benefit from an addtion about how to have redis started and running.\n. r? @magopian \n. This breaks the links for people who have bookmarks on 1.1 links.\n. @domtallo: What I understand from your previous messages is that you have a setup which is currently working: you have a reverse proxy doing the SSL offload properly, the only remaining problem you have is that the kinto server itself thinks it's running on the 8888 whereas you would like it to be on the 443 (HTTPS) protocol.\nThe message from @natim is proposing a different solution to what you currently have in place (Currently you have a docker container listening to a specific port, and outside the docker a reverse proxy doing the SSL offloading, from what I understand). The setup you have seems to be working, except from the host and port parts.\nIn order to do this, you can configure the kinto server (with the kinto.ini file) telling it the correct host and port.\nHere is the link to the documentation: http://kinto.readthedocs.io/en/latest/configuration/settings.html#scheme-host-and-port, in your case, it means that your kinto.ini file should have the following configuration:\nini\nkinto.http_scheme = https\nkinto.http_host = kinto.yourserver.tld\nHope that helps\n. Also, if you're interested in how I setup haproxy to do SSL offloading, have a look at https://github.com/almet/infra/blob/master/haproxy/haproxy.cfg\n. Currently, there is some Kinto-related Java code inside the Firefox tree, but nothing has been put together as a library. \n@pocmo worked on this. Would you like to work on making this happen?\n. This is because the default bucket plugin doesn't call the postprocess method.\n. Hi @lvictorino and thanks for opening this bug.\nI'm surprised this wasn't tested. While chatting with @natim yesterday, he told me that the storage tests aren't really run on each backend. If this is true, we might want to run all the storage tests for each backend. @Natim, can you confirm, and eventually open a bug about this? Thanks!\n. > No all the storage tests are run with all backends, but we do not run all cliquet tests with all backends.\nI don't understand what you mean. Can you rephrase?\n. Maybe the plugin could inspect the list of resources defined (using cornice.get_services), and register a new view for the service with the specified renderer?\n. Neat! LGTM, r+\n. Great, thanks for the work :)\n. Thanks for the contribution!\n. Thanks for detecting this. I believe we can just link to the english version since the docs are in english. Also there is a note at the very top of the articles when it's available in french, so I believe that should be enough.\n. This makes me wonder: should we host these docs under docs.kinto-storage.org instead?\n. We've actually decided to do this on purpose, to have all the docs in one place without having to lose the user between cliquet and kinto goal was to not talk at all about cliquet in the kinto docs, hence the copy.\nThat being said, I'm not against a change in this. Just wanted to let you know why we made the decision when we did.\n. Hey @glasserc, and thanks for taking the time to advocate your solution !\nI do agree that the current solution has shortcomings, and that we should solve them :)\n\nIt isn't clear which version of this documentation is authoritative.\n\nOur goal then was to not have Kinto users ever exposed to the cliquet documentation. As a result, the Kinto docs should be authoritative.\n\n[...] both have to be maintained.\n\nThis isn't completely true: the process is automatic. The docs are canonically stored in the cliquet documentation, and copied when Kinto documentation is generated.\n\nLinks are broken\n\nThat's a true challenge, and I believe that's where the pain-point really is.\n\nThe main goal we had with doing the copy was to not lose our users between the different documentations, and not have to duplicate the parts of the documentation which are similar between Cliquet and Kinto.\nI've read your argument stating that developers are used to read many different documentation. I believe the problem here isn't related to the number of different documentation, but to the role each documentation has to play.\nThe distinction between Cliquet and Kinto is hard to make even for us developers, so preventing our users from doing it is IMO a sane thing to do.\nChanging the naming from Cliquet to Kinto-Core kinda makes this hassle disappear, so we might consider it.\nBy doing so, I believe the number of concepts we expose to Kinto users are better delimited: we don't care to have them know about cliquet, we want to them to know about buckets, collections, records and permissions.\n. You can use http://www.brokenlinkcheck.com/broken-links.php#status to find broken links\n. This is great, thanks! \n. That's a good idea! For this, we would have to:\n- Add a version parameter in the cliquet add_api_capability method\n- It would show up directly in the hello view\n- Write some tests to test this works as expected\n. That's the case with the current deployment anyway (the kinto version is present).\nWe should open another issue for this. I'm not sure hiding the version will gain us some security? I would love to have mozsec input on this! \n. Related to https://wiki.mozilla.org/Outreachy#Add_support_for_OpenAPI_to_Kinto\n. It is actually possible (and might be a better thing to have) to import the name of the user by asking the profile server. It is also possible to ask for the email address.\nAlso note that the email address that's returned by the account server needs the auth to have the proper token scope.\n. Well, my point was more that it's possible to get the full name of the user :)\n. But that is not the recommendation we're making i' the docs though (where we recommend using token:passwd). \nI believe it would be a good idea to make a decision on this and adapt the docs and admin accordingly (either use app token or something else but  we need to be consistent) \n. Really cool,\nHaving stuff as plugins seems to be a good idea, so that people can disable the stuff really easily, and a proof that our plugin system is extensible enough, so I would say yes, make it a plugin and activate it by default?\n. This looks good to me!\n. We should of course replace \"protocol\" by \"API\" anywhere we can, it would make things easier to grasp for newcomers :)\n. Cool. Just not sure about the color, but that's great :)\n. Oooh yeah!\n. Resources that might be useful https://www.python.org/dev/peps/pep-0440/#handling-of-pre-releases and https://www.python.org/dev/peps/pep-0440/#exclusive-ordered-comparison.\n. I believe this is related to https://github.com/Kinto/kinto/issues/256\n. I understand better, thanks!\nOne other way I can think of that seems to solve this would be to always include the deleted items in the sync and in the collection. In the Kinto server, there is actually a difference between something that exists and something that existed and was removed, thanks to the use of tombstones.\nWould this solve your problem? \nIt doesn't really matters, but note that this issue should probably be handled in the kinto signer.\n. Thinking a bit more about it, it makes me think about another important security feature the signer misses currently. An attacker could prevent an update to be applied in the clients.\nDownloading all the deleted records does not seem to fix this specific issue.\nShould we have a way to have a kind of heartbeat feature between the clients and the server. e.g. a way to check that the downloaded files are not more than a 2d old? How would we accomplish this?\nI'm not sure this is what you have in mind @mozmark , if it isn't I should probably open another issue on the signer for this.\nLet's continue the discussion here for now I think.\n. You need to be sure that your list is up to date, otherwise an attacker can just block the updates by serving an old version.\nWe could have something that updates the collection on a daily basis for instance, and when clients start their browser, it will first download the list I believe, so we are covered. The thing it should check for is that the list it gets from the server is one that is actually not more than X days old (this check is done on the retrieved list and not on the cached list on the client).\nHowever, this is possible only if SSL is broken, so it might not be an issue for Firefox clients which pin their SSL certs ? (but still remains an issue for all other use cases which do not pin the SSL).\n. This would allow a lot more readability, that's a good idea.\n. Hi all,\nThe main reason I see to having at least two backends in the core is to make sure the database APIs stay generic enough to plug new types of storages (which, is left to the community, and we do not have any community implementation so far, apart an intent from @Lothiraldan). Nevertheless, that is the rationale, and as been used as a \"selling\" point for Kinto -- plug with the database you want if the existing ones do not match your needs.\nNow, if I read well, you would like to remove Redis from Kinto core (and put it somewhere else), in order to make things easier to develop, but I do not get how it will be easier as the codebase would still need to be maintained, unless you are thinking about removing Redis entirely from Kinto ?\nSlightly related: I believe having the redis backend as an external plugin would probably make the maintenance experience harder (like what we had with cliquet + kinto), but that might just be a CI issue. In other words, if we can have a Continuous Integration system to test the plugins compatibility before merging features, that would solve this issue.\nAlso slightly related, but might be out of scope: the levelup/leveldown experience might be of interest to us, and I wonder if something similar could be used in Python for Kinto, making it possible to have multiple backends maintained by the community (tm) and used by us for Kinto.\n. Nice, @enguerran just mentioned on IRC this would be useful to him :)\n. So, do we have a plan for shipping this in the next releases?. It is not problematic thats true, but doing so in the backend means less code to maintain. (also, note that the argument for the cost is true on the server and client approach) \n. Because we have one backend and many frontends :) doing it in the backend simplifies the life of clients. \n. I would only return the complete list (probably no pagination). We could propose this feature only if the correction has a schema associated, which would remove the problem you mentioned) \n. In case that helps: https://gist.github.com/almet/04a151035de8a082770b6eaff4060621. I've updated it to reflect your remarks. Thanks.. merci :)\n. Thanks for the info. depending on when we plan to ship #795, it might or might not make sense to document this.. Yes ! Closing . Please test that the required file is now included before releasing. Thanks . Hi Kinto team :-) It's cool to see that things are still moving around here! It's been a long time since I commented on anything, I hope I'm able to help you out.\nFrom what I recall, at some point the kinto-signer was copying records from one collection to another (to update the destination collection records with the recent changes), and it was needed to not modify their last_modified field (because otherwise the serialization would differ, and thus the signature not match).\nAt the same time, I believe it was needed to bump the collection in order to make it clear that there were a change in the records inside the collection.\nHope I'm not too far away from the current question, as I didn't took the time to understand the full context around the discussion.. I believe this is because of this line where we get the records that were updated since the latest signature. If we do not update the timestamp of the collection, then we would also get old records?. Probably this hasn't survived the end of year crazyness :-) Here's a little bump -- what's missing on this to go ahead?. This seems great, thanks for working on it! Being able to use Openid connect will be a lot useful, so we can ditch basic auth default mechanism :-). > Now the question is: should we do the scope filtering feature in this PR as well as revamp the whole authentication documentation? My take is \u00abno\u00bb :)\nThat's the easy way, for sure ! But the risk is that it will stay as it is. I remember that this auth documentation have had to be revamped for some time now and it's still not the case.\nMy take would be to have documentation before merging this ;) (but, it's easy to say when you're not the one doing it!). Or I guess we should issue a minor with this fix (related to https://github.com/Kinto/kinto/issues/1916). > > At first, I had trouble to understand what this activation-form-url was made for, but from what I understand, it's purpose is to add a link in the validation email that is sent to the user.\n\n@almet the idea (discussed in #1973) is that modifying the user record should not be done with a GET, but with a POST (or PATCH). So the activation-form-url is the link to the WebApp, which should display a proper form asking the user to confirm that they want to enable/activate/validate the account (probably a simple \"call to action\" button that will POST to the validate endpoint).\n\nWhy displaying a form if the user clicks on the link already? The Webapp could do the POST directly, saving an extra click, and staying RESTful. If we decide to go this way, we could have a default webapp shipped direclty with kinto-accounts, which will do the POST on behalf of the user, and letting the ability to the developer to specify a different webapp to use.. Not sure what you mean with \u00ab email context \u00bb. You mean a template?\nAlso, In addition to what you've described, I think that if we go with a POST to validate the account, then we should provide a simple WebApp that does the POSTing automatically, in order to have a easy-to-setup account registration mechanism (e.g. as an admin deploying the stack, I want this to be simple enough). As for delaying reset password to another PR, I think it's un-necessary, unless you're in a hurry having this shipped (in which case, do as you prefer!). As for delaying reset password to another PR, I think it's un-necessary, unless you're in a hurry having this shipped (in which case, do as you prefer!)\n\n\nwe should provide a simple WebApp that does the POSTing automatically, in order to have a easy-to-setup account registration mechanism\n\nWe could as an example but it is quite orthogonal to the service code.\nI can't see someone using this feature not to wish to integrate it with their software UI.\n\nSome softwares have UI that are not browsers (e.g. a CLI script), which is why I think this is necessary to have by default.. > > Some softwares have UI that are not browsers\n\nIn that case they might not use links to validate the account.\n\nI think I missed something then. To me, if I register an account with the command line, the workflow is as follows:\n\nA request is made from the CLI to the kinto server to create the account\nAn email is sent to the user, to confirm the email belongs to her / him\n3. The user clicks on the link to validate\nAccount is validated.\n\nUnfortunately, users use links in the emails to validate the accounts, and this happens through HTTP GET requests only.\nWhat other scenario do you have in mind to avoid this webapp?. Ah yes! I haven't thought about this solution. I remember that's what Twitter used to do in the past :-)\nThat being said, I tend to prefer the \u00ab user clicks on the link \u00bb solution, because it's simpler. What's the value of having the user copy a verification code over clicking a link in an email, apart not having to implement an UI?. > I think it is up to the developper to define the flow, I am not against building a little Elm demo webapp if it pleases you. We can even pair on it once this lands.\nI agree, we need to let the possibility for the developer to tweak the flow, if they want it to be different. One major selling point of kinto is \u00ab don't reinvent the wheel each time \u00bb, and as such, I believe we should provide the golden path for everything. Something that makes it easy for everyone to use accounts, without having to implement something special.. I agree, but I believe that if we start solving one problem (here having accounts validation), then we need to do it completely, and painlessly for the devs that want to use it.\nAs a side note, I think we're kinda going in circles with this discussion. I don't really mind disagreeing, but if anyone wants to weight in in order to move forward on this topic that would be beneficial :-) cc @leplatrem @glasserc . I've tried with the demo @natim put together and it worked for me (wrt. CORS). Any way to reproduce the error?. I'm updating the tests to use a non-empty record. \nI'm actually not sure we should support empty records, but I don't see any good reason to not support them.\n. Actually I should remove it from here and put it only in the tests.\n. Created https://github.com/mozilla-services/cliquet/issues/31\n. Yeah, cliquet rocks!\nWe will need a bit more code to handle collections management, plus currently it seems I can only add empty items to the collections (not very handy ;))\n. Neat, I know what's next in line then :)\n. Cool, doing that now.\n. This could even go into cliquet actually.\n. Can we also assert that the configuration has the right value?\n. from cliquet import Service?\n. Which makes me think we should use konfig in our projects, it's already doing this work for us.\n. We should name this kinto-redis\n. 1.3.0\n. This definition doesn't say much. \"Buckets are a group of collections, which can be shared accross users\" seems more close to what I have in mind.\n. Sorry, what?\n. I believe we should have the same set of permissions we have for other objects (read, create, update, delete)\n. Having \"principals\" returned here doesn't make a lot of sense to me, we should probably have a list of permissions and eventually a group \"owners\"\n. I feel this should be handled by more fine grained permissions\n. I don't understand what a role is, but I do with a group. Why are you suggesting we could use \"role\"?\n. fine-grained\n. I still believe we shouldn't go with this solution. We should have permissions associated.\n. administrate doesn't convey a lot of meaning. \"To have all permissions on the collection items\" seems a better description to me.\n. I agree with the schema!\n. +1\n. From this description, I cannot tell how a bucket is different from a collection. My understanding (not when reading this text) is that buckets are a container of collections, but this text kinda says it's like a collection, but open for others.\nSo, what's the right definition? :)\n. the list of principals.\n. admins finally looks like a better option then (yes, I know).\n. I think only admins should be allowed to do that.\n. I would actually differenciate between create and update (which seems to be both in the \"write\" option here).\n. oh ok it's actually here.\n. We're currently changing all the layout of the docs and doing another pass on this proposal. The idea is to have a default bucket for each user.\n. It could be possible to replace, but only if you have the permission to do so ;)\n. We want to introduce the concept of principals, and a group is just one principal.\n. We probably want to have all the combination of object / permission, and probably remove the ones which don't make sense. This would be more future proof than having write / read and then not being able to be more fine grained than that.\n. Well, it's the group of \"seekers\".\n. This doesn't prevent merging of this, but I think the name generation should be pluggable. Having an id generator is something we had in daybed and I think we should continue like this: it helps users to generate whatever they want as a new name. for instance the koremutake generator for daybed @natim pointed.\n. Why not passing the bucket options directly here?\n. (it would use the call arguments syntax, which is easier to follow)\n. When reading this, I see that we're inheriting a bunch of methods. Should we instead add hooks in the BaseResource class?\n. So, we aren't deleting permissions associated with this bucket?\n. So, why everything is in memory but the permission backend?\n. why should unknown raise a 403?\n. They will actually tell you it's better to return a 404, otherwise you disclose that the resource exists.\n. Also, s/guys/folks.\n. The link you pasted doesn't buy us much: it says it's a good practice and it's a bad practice.\nThe HTTP spec states:\n\nIf the server does not wish to make this information available to the client, the status code 404 (Not Found) can be used instead. \n\nI think that's for us to make a choice here: do we want to disclose this information or not?\nA 403 has one advantage over a 404: it's clear that the resource isn't accessible by the connected user, so for instance, if she's not connected with the right account she can find it out and act properly.\nIt also have a disadvantage:  It leaks the fact that the resource exists to another user, which could then use this information in many different ways.\n. Here, we are returning a 403 if the resource doesn't exist. When a resource doesn't exist, a 404 should be returned. 403 means that the resource exists but that you cannot access it.\n. Are you okay?\n. test_old_group_is_replaced_on_put\n. test_old_group_is_modified_on_patch\n. buckets\n. Buckets\n. A list of records\n. Are now\n. Link to http://cliquet.readthedocs.org/en/latest/reference/configuration.html#basic-auth\n. tutorial\n. We should link the pull request from @magopian here (and thank him)\n. I would say \"data storage, synchronization and sharing\".\n. IMO people reading the documentation already know where the documentation is.\n. yeah, and this probably is the reason why we have these links here. Maybe it's time to split the README and the actual doc.\n. postponing until we have a proper agreement. See #92\n. It's just a shortcut and the point is not actually showcasing that the thing is hapenning on localhost but what comes after the domain. I would rather keep it like that to avoid adding more information that seems less useful than the rest to the user, if you agree.\n. Cool, we need to make sure we update this file each time we do a release (if we had templates of what we should do for a release, we could include this step)\n. \"A storage service for storage\" sounds weird to me. The fact that we have fine grained permissions is IMO too much detailed information. I would rephrase this with \"A remote storage service with syncing and sharing abilities\"?\n. we could put that in a function named read_file.\n. \"users are assigned a bucket\"\n. Why is the principal changing here?\n. I would rather use a secret which explicitly says it's not secret (this is not secret)\n. And I guess this is why the principal has been changed :)\n. Why would it raise a 412 ?\n. Can you explicit that in the tests?\n. Well, is it possible if you share the bucket:read permission with someone else?\n. bucket_creation?\n. nit: already exists\n. collection_creation?\n. We could put the bucket check+creation and collection check+creation in separate functions to ease readability and have a smaller function.\n. nit: I would do str() rather than formatting like that.\n. ah yes, I'm always doing this error :x\n. I removed the \"that is\" ;)\n. So we fix it only for kinto and not for all cliquet resources?\n. I was thinking about that, but actually it would mean to put the symbol next to almost all resources. Maybe it's still worth it.\n. Good catch, I added them (and actually the collection get on groups was missing \u2014 now fixed)\n. Why removing this information? When explaining what a bucket is, I find it very useful to say it's a namespace. Even yesterday, when working with Quentin, the first thing he said was \"oh, okay, it's a namespace\", without me saying it.\n. I put these at the end of the listing on purpose: the table already mentions all the endpoints which are here.\n. but let sync :)\n. reference implementation\n. Sorry, what?\n. Ah, we're on the API page, didn't notice! You're correct then :-) We should link to the concept then to make it easier to follow, probably.\n. A permission is the action itself. an ACE tells if you have the right or not to perform the action.\n. We could think about renaming this, but just not now (out of scope for this PR I believe)\n. It's still the case in the \"concepts\" page.\n. The permission names are prefixed by their children. \nI replaced in the doc: In the case of a creation, since an object can have several kinds of children, the\npermission is prefixed by the type of child (for instance groups:create,\ncollections:create).\n. I don't understand your comment :-)\n. I replaced with \"There is no delete permission. Anyone with the write permission on an\n  object can delete it.\"\n. \"system.Authenticated: All users that are authenticated, no matter how they authenticated.\"\n. Rephrased with Alice and Bob:\n\nIf Alice wants to share objects with Bob, Bob will need to give Alice his user ID - this is an easy way to obtain that ID.\n. It's currently hardcoded.\n. The sentence terminates the line just after :)\n. authorization is a special one, since it's used like that in the standards. (the name of the HTTP header). I'll update the description to be with an \"s\" and let the name of the settings with the z.\n. The thing is that it's the most asked question, and that there is an entry for only the FAQ from the index page, so people could miss the comparison.\n. So, schema is inside the data attribute?\n. This section remembers me that I duplicated the documentation in kinto and formatted it as a table. We might backport this change directly in cliquet instead, otherwise we would need to update the kinto documentation each time a setting is changed on cliquet.\n. Oh sorry, this is in Kinto! I though we were in Cliquet. My bad.\n. This probably shouldn't go in this section but in the \"recipes\" for deployment instead. We could link there from here.\n. nit: test_expires_and_cache_control_headers_are_set\n. should this go in another test case? The setup isn't necessary here if I read correctly.\n. Why don't we test the value of the returned Cache-Control header here?\n. I don't understand what is the fundamental difference between this class and the latter one.\n. consider: \"if the [...] setting is defined\"\n. It's acceptable but not ideal. Let it be ;)\n. This is normal: when no filter is specified it means that it's field=test. See the kinto documentation about filtering.\n. Consider this string as what's prefixed to the name of the field.\n. nitpick: remove the trailing space here\n. here as well.\n. You should let this commented I believe.\n. You can let these commented, they are just examples of values that could be turned on.\n. Rather than moving the existing kinto.ini file somewhere else, let it where it is currently and create a new kinto.tpl file, like you did.\n. Of course, it's missing the other options here :)\n\nI would build a dictionary depending the answers that are given to the answers. Eg. start with a clean one options={}\nAnd then, depending the answer to the questions, add the correct values in there.\n. I don't think we need the 1.0 folder here, since the docs are versionned.\n. Is Hoodie really Node.js? I thought it was Erlang as well (for Couch)\n. Why do you need to specify the kinto prefix here?\n. I believe that's actually the behaviour we want: the \"kinto\" folder is the one where all the kinto files are contained, and you shouldn't temper it. Rather, creating a \"config\" folder where you run the command seems to make more sense.\n. Please remove this empty line :)\n. We thought it was actually better to pass the variables as a dict rather than as parameters.\n. yes, the only think you might want to change here is the mode which should be \"w\" instead of \"w+\".\n. Both solutions work for me, and I don't consider this really important. I've see with Shweta that the version without the kwargs would make more sense (be more explicit), but we can reverse it to the previous behaviour if you want.\n. We probably don't want to print out here. Just let the \"if not os.path.exists(folder)\", and add a test :-)\n. Is there too much spaces there? (should be 4 I think)\n. You need to import with absolute locations. from kinto.config import render_template. You don't need to import it as origin.\n. Please define the comments from inside the method, and not on top of it. eg.\n``` python\ndef test_values_is_not_empty(self):\n    # Your comment here.\n```\nThat being said, your comment here just repeats the name of the method, so your don't need to add one.\n. It's not clear to me what the intent is here. What are you trying to test?\n. We probably should check here that the event is of the right type.\n. This should go in a kinto.events module (to be created)\n. Switching back to master is a feature. It allows to test the docker integration before making a tag.\n. We could also switch to debian release instead? unstable is... well, unstable.\n. +1.\n. you can also look at\n. synchronising?\n. This doesn't link to the tutorial, the link can be more precise.\n. Consider adding that's what we call \"offline first\": the data is also available locally, and can be synced when a connection is available.\n. heh.\n. I think the differentiator here isn't that it's vanilla JS, it's more that the data isn't stored locally: this is raw requests to the server.\n. s ?\n. @oak11 will like this :)\n. @oak11 will like this :)\n. What is an alias?\n. Should we issue a warning and ask for it to be included in the configuration explicitely now?\n. I removed it because I think it just adds some pointers to a mozilla specific tool. We can add it as an example, though. Updating the docs accordingly.\n. updated.\n. I think it's \"route them\" (without s)\n. Thanks for the fix :)\n. \"bob\" looks a lot like a user to me (and not a token) :)\n. You probably need to remove the latest >.\n. Since nothing was changed in the code, I don't understand why you actually need a new version?\n. Ah yeah sorry, missed it as it wasn't in the diff :)\n. nit: missing the \".\" at the end of the sentence.\n. you are missing a \"=\" here.\n. nit: Add a blank line after the title\n. You could add a way to solve this: \"Make sure sure the postgres server is running properly\".\n. updated.\n. flake8 reports that kinto/__main__.py:34:29: E127 continuation line over-indented for visual indent\n. I believe this will do it by default. In which case it could be good to define it explicitely here, you're right.\n. nit: buckets\n. to store\n. While reading this I found that it makes actually little sense for \"beers\" to have a \"fingerprint\". We might want to do another pass on the examples here to use something that actually makes more sense to the reader. This could be done in another issue.\n. That's two times \"please\" :)\n. I believe we don't need to add a specific header here.\n. nor a link :)\n. That could be neat to add a short sentence saying \"Thanks for considering submitting a pull request, we really appreciate that. Before doing so, here are a few guidelines\"\n. We could quickly extract the most important things from this doc, put them here and add a link to \"see you to contribute in more details\"?\n. We could quickly extract the most important things from this doc, put them here and add a link to \"see you to contribute in more details\"?\n. nit: an exclamation mark could add some more energy in the phrasing?\n. I believe we don't really need to point that out. \n. All pull requests should include tests, they help us avoiding regressions in our code.\n. If you're interested, you can also [...]\n. nit: Add a line break between the two lines?\n. should also update the documentation accordingly\n. It's just another way to phrase it (docs vs documentation)\n. \"by to\"\n. even if the\n. s/now/thus\n. These two are already listed in the protocol changes. Not sure we should repeat them here.\n. I'm not sure we should add this level of detail in the CHANGELOG. What about linking to the documentation instead?\n. \"REST\", \"API\" ?\n. (We might want to have a few more keywords here in order to have people discover us by the use of these, maybe) \u2014 Also thinking about \"database\".\n. We probably should just remove this right now, and fix it in Kinto.js, so we can support encryption there :)\n. Why what ? Why are we building kinto ? Why should you use kinto ?\n. s/an application/applications\n. unlike databases\n. the \",\" is superfluous here. Should we replace \"instead\" by \"rather than\"?\n. Add a link to Kinto.js\n. link to the admin UI\n. link to the section about this in the docs\n. link to the docs\n. ditto\n. I'm not sure we should add mozilla's specific doc here (this should probably leave in syncto instead)\n. We should say \"During the installation\", because this might not be at the end at some point :)\n. With restructured text, the way to have a code block is by either using :: or by using the code-block directive, like this:\n``` rst\n.. code-block:: bash\nsome code here\n```\n. nitpick: try to wrap the lines to 80 chars max.\n. If you don't know what to select, just push \"enter\" to choose the [...].\nAlso, consider replacing \"when you will need another one you will know it :)\" by \"You can always change your backend selection later on\" ?\n. I confirm that this should be \"schema\" (or maybe \"experimental.schema\" ?)\n. I believe this link is incorrect. rest links needs to end with an underscore. Something like:\nrst\n`later on <https://kinto.readthedocs.org/en/latest/configuration/settings.html#backends>`_\nYou also have an extra backtick there (at the end of the line).\n. Add some validation to pushed records using a json schema\n. this should be aligned with the line before it.\n. apparently, @leplatrem is saying that we don't need to convert to bool here since this was done already.\n. The spaces are actually legitimate here: in python, you:\n- first import standard library modules (hint: time is one)\n- then import 3rd party library modules\n- then import the modules from you project (here kinto).\nBetween each block you need an empty line.\n. consider: \"Restart the kinto server on code or configuration changes\"\n. does this really speedup the startup time? If yes, do you know why? (importing pip shouldn't take that long!)\n. I would assign the key you're looking for into a variable first, and then use it in the comparisons.\n. I'm not sure this is part of the protocol (the protocol keeps unchanged here, just more capabilities have been added to it)\n. ditto.\n. But it hasn't! The protocol isn't about what's inside the resources, but how to access them, and the mean of access is exactly the same as before.\n. I agree, but It's just not in the right section: the protocol is unchanged.\n. Can you be a bit more explicit ? Why should we consider this a protocol change?\n. nit: \"on debian and ubuntu\"\n. why are you installing python this way rather than relying on the system packaged version?\n. redis is packaged as \"redis-server\" in debian/ubuntu. Please use that instead.\n. I don't understand where this method is called?\n. Rather than duplicating, we should factorize this code.\n. I see twice the same code here in this file, so having a helper for it should make it easier to maintain.\n. That's what I mean, yes!\n. For those who don't know what DNF is:\n\nDNF was introduced in Fedora 18, and it has been the default package manager for Fedora since version 22\n\u2014 Wikipedia\n. Can you link to the cornice issue in the tests?\n. I would phrase it a bit differently: \"if you prefer to use slack, head over to https://slack.kinto-storage.org/\"\n. Should this be \"as Basic Auth\"?. Adding examples of third parties could be useful here in order to understand better.. Is it returned on purpose? If yes, what is it and how should I use it? I was naively thinking that this would remain hidden on the server.. Just a question: what happens in case I want to update my pre-\"account-validation\" existing account? Will my userid be rejected? . I would feel more confident if validated accounts were marked as such (with a validated: true|false flag for instance), rather than checking that some keys aren't present.. +1 for having a listener for this :-). \n",
    "leplatrem": "PostgreSQL is a lot more easy to install than Redis (see docs), but since we don't have any other session backend implementation, using psql by default does not prevent us from running Redis!\nWe could consider defaulting to PostgreSQL once we have session backend running on it :)\n. Since the default test database is postgres in cliquet, there is no database creation step\n. @Natim @ametaireau r?\n. @Natim r?\n. https://github.com/mozilla-services/cliquet/issues/124\n. I'm closing this since it might not be relevant anymore. Re-open if you don't agree.\n. @ametaireau @Natim r?\n. Dropped in favor for #27 \n. r?\n. ```\nDuration: 1355.65 seconds\nHits: 28925\nStarted: 2015-06-10 08:47:11.849940\nApproximate Average RPS: 21\nAverage request time: 0.10s\nOpened web sockets: 0\nBytes received via web sockets : 0\nSuccess: 300\nErrors: 0\nFailures: 0\nSlowest URL: http://127.0.0.1:8888/v1/batch     Average Request Time: 0.996720044776\nStats by URLs (10 slowests):\n\n\nhttp://127.0.0.1:8888/v1/batch                                                                                                                                    Average request time: 0.996720044776    Hits success rate: 1.0\n\n\nhttp://127.0.0.1:8888/v1/buckets/b3a35c678e974eb99dd44d87bf276514/collections/articles/records?_since=1433926273898                                               Average request time: 0.66175   Hits success rate: 1.0\n\n\nhttp://localhost:8888/v1/buckets/1e974a01fe96493fb3f2b31d88494d05/collections/articles/records?_limit=20&_token=eyJsYXN0X21vZGlmaWVkIjoxNDMzOTI2NjMzNDEyfQ%3D%3D  Average request time: 0.660035  Hits success rate: 1.0\n\n\nhttp://127.0.0.1:8888/v1/buckets/b3a35c678e974eb99dd44d87bf276514/collections/articles/records?_since=1433926387666                                               Average request time: 0.632717  Hits success rate: 1.0\n\n\nhttp://127.0.0.1:8888/v1/buckets/b3a35c678e974eb99dd44d87bf276514/collections/articles/records?_since=1433926225684                                               Average request time: 0.58516   Hits success rate: 1.0\n\n\nhttp://127.0.0.1:8888/v1/buckets/b3a35c678e974eb99dd44d87bf276514/collections/articles/records?_sort=title                                                        Average request time: 0.573286  Hits success rate: 1.0\n\n\nhttp://127.0.0.1:8888/v1/buckets/1e974a01fe96493fb3f2b31d88494d05/collections/articles/records?_since=1433926881417                                               Average request time: 0.568409  Hits success rate: 1.0\n\n\nhttp://127.0.0.1:8888/v1/buckets/b3a35c678e974eb99dd44d87bf276514/collections/articles/records?_since=1433926070700                                               Average request time: 0.561393  Hits success rate: 1.0\n\n\nhttp://127.0.0.1:8888/v1/buckets/6b97dd79a0114e5ca5ccb52c394b75bb/collections/articles/records?_since=1433926157132                                               Average request time: 0.516797  Hits success rate: 1.0\n\n\nhttp://localhost:8888/v1/buckets/1e974a01fe96493fb3f2b31d88494d05/collections/articles/records?_limit=20&_token=eyJsYXN0X21vZGlmaWVkIjoxNDMzOTI2MjE4MDkyfQ%3D%3D  Average request time: 0.513393  Hits success rate: 1.0\n\n\nCustom metrics:\n\n\nlist_deleted : 24\n\n\nbatch_create : 24\n\n\n200 : 378\n\n\n201 : 21411\n\n\ncreate : 11\n\n\nlist_archived : 13\n\n\nupdate : 44\n\n\nfilter_sort : 45\n\n\nbatch_delete : 5\n\n\n404 : 100\n\n\nbatch_count : 38\n\n\nlist_continuated_pagination : 44\n\n\npoll_changes : 45\n\n\ndelete : 7\n```\n. For example, generate Angular forms from JSON schema http://schemaform.io/\n. > > Unlike Daybed, I propose that each user owns the schema of the collection.\n\n\nEspecially because the schema endpoint will probably be a resource :)\n\nI don't quite get this. How is that different from daybed? I would propose anyone who can create a collection can also create a schema.\n\n\n\nUnlike Daybed, the collections are not global. It means that as a user, I can associate a schema to my todo collection, even if someone else already had set a different schema for her own todo collection.\n\n\nIs the schema using the resource code of Cliquet ? If so, how do avoid overlap of stored\ncollections ? We could use underscores prefix, and prevent public collections to have a name that \nstarts with underscore :)\n\nI think this is handled by the \"bucket\" concept.\n\nNope, what I meant with this was https://github.com/mozilla-services/cliquet/issues/243.\nAnd that the schema endpoint is built using the cliquet.ressource.BaseRessource class (CRUD).\n\n\nWhat happen when records are shared between users ? Do we let other users records crash our \napplication when fetching shared records ? We could probably run client-side validation using JSON \nschema on shared records.\n\nIn case we download data from somewhere, we assume it's already validated by the server, so I \ndon't get where the problem lies here?\n\nI was wondering what happens if two users have a different schema for the same collection name.\n\nAlso, I think json schema has one big problem: its complexity. It doesn't seem to be simple to use it.\nAs such, we could probably provide a way to create schema in an easy way, which would then \nmap to the standard?\n\nI wouldn't go that way. Maybe if it's too complex, then we can imagine a WYSIWYG JSON schema builder ?\n. Some feedback :)\nDocumentation and flow\n- There is a lot of vocabulary\n- We need to always use the same words in order to make it easier to read\n  - owners, administrators, creators, bucket users \u2192 admins\n  - users, principals, user identifiers \u2192 principals (?)\n- In the example part, it is hard to follow because it is not clear where those JSON are located (bucket, collection, records ?)\n- We need a list of principals \"types\" somewhere (e.g. email:, uid:, scope:, ...)\nFeatures\n- We should expose the problem we had in a few lines somewhere.\n- Maybe the notion of group should not be mixed up with the rest, and should be introduced as a \"second-line feature\"\nDesign\n- I would definitely would reduce everything to read and write\njs\n\"permissions\": {\n   \"groups\": {\n      \"write\": [\"uid:<user>\"]\n   },\n   \"collections\": {\n      \"read\": [ ... ]\n   }\n}\n- I would suggest to get rid of Authenticated and Everyone and replace them with a specific principal type  (e.g. status:all, status:authenticated)\n. Ok then, let's go for Create/Read/Update/Delete permissions. But we must find relevant use-cases for them.\nWe could also add : \n- Private todo list\n- Poll (create,read/update/delete own records)\n. I believe we can close this in favor of #48 \n. What difference with https://github.com/mozilla-services/kinto/commit/82d8e18f5582903693a41f48bca28c456fa1dd9d ?\n. @Natim I revamped the pull-request with what we had discussed with @phrawzty.\nCurrently, the schema is a sub-resource of collection where PUT and DELETE are allowed.\nI don't remember if we said that the schema should be a collection optional field instead.\nI like it this way, but looking at the way the resource class is used for the schema, it could be more natural if it was a colllection optional field.\n. Ok, no definitely, it makes a lot more sense if the schema is field of the collection resource. (for managing permissions etc.)\nI'll see if I can get it done before my holidays :)\n. Ok I did it :)\nPlease don't let it rot again :)Take over!\n. @Natim r?\n. @Natim r?\nEspecially one point : \nFor records, is bucket_id the parent_id of records ? and collection_id the collection id as it was implemented here ?\nOr collection_id is the parent_id, and records is the collection_id (i.e. the object type) ?\n. Thanks @Natim for your feedback, I did these in #48 to avoid merging hell :)\n. Even though this is pretty cool and fun, we have no use-case so far for a Kinto storage backend.\nDropping.\n. @Natim I would suggest we skip the integration of permissions for this one. We wait for https://github.com/mozilla-services/cliquet/pull/288 to be merged, and rework another PR\n. r? @ametaireau @Natim :)\nSome parts of the views code is not dry at all ! But I believe we will merge our utils to handle this :) This is now open to review :)\n. Thanks for your feedback ! Will update tomorrow :)\n. I really wonder how you had the courage to write all this without tests! ;))\n. This is currently not possible with current code in cliquet, where error message is hard-coded. Closing, since it does not add much value...\n. Implemented in https://github.com/mozilla-services/cliquet/pull/307\n. +1\n. ```\nKeyError permissions\nFile \"loadtest/tutorial.py\", line 149, in play_user_shared_bucket_tutorial\nself.assertIn('write', record['permissions'])\n\n``\n. Indeed, I didn't write tests forrecords:createandgroups:create`! We should do that!\n. r+ without underscores in object names ;)\n. Is the \u00abdefault bucket\u00bb what I naively called \u00abpersonal bucket\u00bb ?\n. Ok, that's one way to do it indeed :)\nI would have tried (but no thought about it yet) to modify what we had here:\nhttps://github.com/mozilla-services/kinto/blob/master/kinto/views/collections.py#L17-L19\n. I was going to say r+, but I realize that some parts of the docs might deserve an update (ex. docs/api/collections.rst)\n. r+\n. That is something we had in mind for cliquet 2.1 indeed. But it implies several complex points:\n- Introduce notions of principals in the storage backend\n- For collections, let the policy authorize users even if no obvious permission to read ?\n- If no record belongs to Bob in the shared collection, then raise 403 inside the resource view ?\n. It is not only a matter of having the create permission.\nFor example, for the payment tracking use-case:\n- Seller has no right to create receipts\n- Payments creates receipts records with read permission for its seller\n- Seller can list all receipts where it has read permission\n. Since the implementation happens in Cliquet, I created a dedicated issue there https://github.com/mozilla-services/cliquet/issues/354\nSince there might be some efforts of integration into Kinto (ex. write perm implies read), let's keep this issue opened it is released upstream and available here.\n. (didn't finish reviewing, back on wednesday)\n. Ready to be reviewed/merged\n. https://github.com/Kinto/kinto-wizard/ was started :) closing here!\n. Done.\n. As far as I understood, the .ini settings come into the **settings value of the kinto init main function. So it might be possible to test it by calling main() with custom setting values, without having to introduce new .ini files.\n. r- if we change the default backend without a full overview of documentation (like started in #95)\n. Please rename your PR (and thus upcoming merge commit message) if FxA is concerned :)\n. ### Use-case exposed by @almet and @Natim :\nA collection has a schema. A formbuilder needs to read that schema to render the form. In order to read that collection object, we currently need to set read on the collection, which also gives the permissions to read every records! If the form is a poll for example, we only want to give record:create, but certainly not the permission to read every record.\nWorkaround: use two collections: one for the schema, one for the records.\n. Fixed with #367 \n. r+\n. The server was not yet running the last version. I believe we can close this ?\n. I also think so.\nSince the protocol implementation is done in Cliquet, let's track this there https://github.com/mozilla-services/cliquet/issues/352\nI leave the issue opened here, we'll close it when fixed upstream :)\n. Done, available in 1.4.0\n. Records are not either.\n```\nhttp \"https://kinto.dev.mozaws.net/v1/buckets/default/collections/tasks/records?_sort=title\" --auth 'user:password' \nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Backoff, Retry-After, Alert, Next-Page, Total-Records, Last-Modified, ETag\nBackoff: 10\nConnection: keep-alive\nContent-Length: 324\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 06 Jul 2015 08:48:07 GMT\nETag: \"1436172442466\"\nLast-Modified: Mon, 06 Jul 2015 08:47:22 GMT\nServer: nginx/1.4.6 (Ubuntu)\nTotal-Records: 3\n{\n    \"data\": [\n        {\n            \"id\": \"f90c266f-7425-49b4-b2dc-3b242a3cea99\", \n            \"last_modified\": 1436172070772, \n            \"title\": 2\n        }, \n        {\n            \"id\": \"6c5f255d-65cf-4eec-a0ee-4c1132b19f15\", \n            \"last_modified\": 1436172059952, \n            \"title\": 1\n        }, \n        {\n            \"description\": \"Write a tutorial explaining Kinto\", \n            \"id\": \"a5f490b2-218e-4d71-ac5a-f046ae285c55\", \n            \"last_modified\": 1436172442466, \n            \"status\": \"done\"\n        }\n    ]\n}\n``\n.?_since=` is supposed to raise 400. But doesn't.\n```\nhttp \"https://kinto.dev.mozaws.net/v1/buckets/default/collections/tasks/records?_since=toto\" --auth 'user:password'\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Backoff, Retry-After, Alert, Next-Page, Total-Records, Last-Modified, ETag\nBackoff: 10\nConnection: keep-alive\nContent-Length: 11\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 06 Jul 2015 08:32:32 GMT\nETag: \"1436170881918\"\nLast-Modified: Mon, 06 Jul 2015 08:21:21 GMT\nServer: nginx/1.4.6 (Ubuntu)\nTotal-Records: 0\n{\n    \"data\": []\n}\n``\n. Duplicate of #88 \n.self.request.validatedis an empty dict, even thoughself.request.body` contains the payload with permissions.\n~~Would it be a problem of subrequests in the default view?~~ PATCH endpoint has no Cornice schema, thus no validated attribute.\n. Documentation should be updated. Thanks !\n. r+\n. Can you explain why you decided to mix them both ?\nIntuitively, I would have created loadtests/simulation.py and loadtests/tutorial.py, and would have added an entry in Travis. \n. Well, I'm not a big fan of the mixins. If test_all means running both, then why couldn't we run them sequentially ?\n. Another idea to avoid mixins:\n```\nloadtests/Makefile\ntest: simulation tutorial\nsimulation: install\n    $(VENV)/bin/loads-runner --config=./config/test.ini --server-url=$(SERVER_URL) loadtest.TestBasic.test_simulation\ntutorial: install\n    $(VENV)/bin/loads-runner --config=./config/test.ini --server-url=$(SERVER_URL) loadtest.TestBasic.test_tutorial\n```\nRun bench tutorial (rare use case):\nTEST_SUITE=loadtest.TestBasic.test_tutorial make bench -e\n(/me just trying to think) \n. I would vote in favor of consistency, if the cost is not huge\n. We already have a details field in error responses, so it makes sense to use it for 412.\nAFAIK it is already present on 409, see http://cliquet.readthedocs.org/en/latest/api/errors.html#conflict-errors\n\nSince this is something that concerns the protocol, it will be implemented in Cliquet.\n. Good idea @oak11!\n\nI think we have to distinguish the kinto init from the two others. Indeed, for init the user will be prompted for values and options. Whereas for migrate (and serve), it will only consist in cabling the existing pserve and cliquet migrate existing commands.\nThe hardest part of the init command is to implement the prompts with a nice presentation. That's why we can try to find some existing tools that could simplify the task. pcreate and cookiecutter could be some good candidates :)\nFrom what I read, click is a helper to implement a command with options like --count=5. There are many tools that provide this functionnality (see below), including some from the standard python library. As a rule of thumb, when this happens, we shall never choose without list our needs. And so far, in terms of command-line options, I haven't thought of anything special!\n\nTools for CLI parsing:\n- http://docopt.org\n- http://pypi.python.org/pypi/clize\n- http://pypi.python.org/pypi/begins\nToolkits:\n- http://pypi.python.org/pypi/prompt_toolkit\n- http://builtoncement.com\n- https://plumbum.readthedocs.org/en/latest/\n. Done in 1.9.0\n. r+ with nits\nI imagine there are several ways to do it, and this seems like a valid one :)\n. This happens only when going the default bucket view.\nIndeed, when using the \u00ababsolute\u00bb bucket id, the problem disappears.\n. :+1: !\n. I can't reproduce locally:\n```\n$ http \"http://0.0.0.0:8888/v1/buckets/default/collections/articles/records?_since=1234\" Origin:localhost:8000 --auth=user:pass\nHTTP/1.1 200 OK\nAccess-Control-Allow-Origin: *\nAccess-Control-Expose-Headers: Backoff, Retry-After, Alert, Next-Page, Total-Records, Last-Modified, ETag\nContent-Length: 11\nContent-Type: application/json; charset=UTF-8\nDate: Fri, 10 Jul 2015 10:39:56 GMT\nEtag: \"1436524796357\"\nLast-Modified: Fri, 10 Jul 2015 10:39:56 GMT\nServer: waitress\nTotal-Records: 0\n{\n    \"data\": []\n}\n```\nThe header Access-Control-Allow-Origin: * seems to be returned.\n. LGTM !\nJust wondering : why sometimes with_deleted and sometimes not ?\n. r+\n. > The certificate expired on 14/07/2015 14:00. \n:smile: \n. This was already discussed a while ago, and we agreed on returning 200 in this case. Discussion can be reopened, but this is definitely not a bug.\nAs the Cliquet docs say, a 409 is returned when a field unicity is violated. It won't be the case with Kinto, since there is currently no way to specify field unicity (until schema feature is landed)\n. I supposed there is some documentation change for this, at least in the contributing section, no ?\n. r+\n. I guess this could be achieve using #600. It would require some manipulation by the client, but would keep things simple.\n. I am wondering if the Github issues are a good place to track deployment tasks for Mozilla internal stuff.\nOur Trello is probably more appropriate. What do you think ?\n. This documentation gives a good overview of the permissions.\nHowever, it can be improved by refering to other parts of the documentation !\nFor example, it would be nice if it would match one precise example of the use case docs, and link to concepts described elsewhere instead of reexplaining them :)\nAre the other parts of the API docs formatted the same way ? This felt more like a tutorial than a http reference. \n. > speaking correct English\ncorrectly speaking English ? #kiddin\n. r+ with \u00abyou nit\u00bb\n. I don't see any objection in (re)defining the regexp here, along with the generation in call. \nIt would be even better IMO\n. I guess we can close this issue, in favor of Portier #933 #994 . Please reopen if I'm wrong.. Note:\n- Probably ~~re-import~~ redraw some of the schemas removed here : https://github.com/mozilla-services/cliquet/pull/389/files\n. > Taken from #161:\nWhen considering this proposal, @QuentinRoy was suggesting that we use \"metadata\" as a field name for last_modified and other internal properties, and store the collection data in \"data\".\n. Note: This was closed, however it was not implemented on buckets.\nIntentional ?\n. Looks like a duplicate of #158 :)\n. I wish we will fix this. It was not the case with the previous versions. It might come from the fact we changed the tooling for packaging (from zest releaser to twine).\nRegarding documentation, it would be worth just mentioning something like a side-note : \u00ab*it is not bad to have a recent pip installed, run pip install -U pip if yours is a couple of years old\u00bb\n. This was resolved by @Natim and @ametaireau in the last versions of cliquet.\nI could install the stack with pip 1.5.6 :)\nThanks for the feedback !\n. Using --tb=native is not essentially better :|\n\n. This looks like a feature request : add quota management in Kinto !\nIt could be a very relevant feature indeed, especially with public Kinto servers :)\nOnce we have an actual use-case, we could provide some specs here... Should quotas be defined at the collection level, per user, in config, in bucket/collections objects ? \nMeanwhile, for SyncTo, maybe you could just pass the header along. And in see if Kinto.js has an elegant way to introduce failures on custom response attributes like headers...\n. Could you explain why you closed please ?\n. The main question is: is it enough to have it by bucket or per collection? Or should it be a complex combination of both?\nSome insights on how it could work:\n- Add a new built-in plugin (kinto.plugins.quotas)\n- Introduce a new capability with exposed quotas values \n- Register a AfterResourceChanged subscriber that listens to every action on the record resource\n- Use an internal storage dataset to track stats (see example)\n- On create, sum the bytes, on delete subtracts, on update sum the difference between old/new. (note: postgresql internal JSONB is going to be smaller but what counts is API input/output)\n- On create/update, check if the body size exceeds setting size_per_item\n- On every new response provide the current stats in headers (?)\n- On create/update, when one condition fails, raise the appropriate http exception\nThen in a second iteration we can imagine defining the settings in the parent bucket etc.\nRelated #360 \n. First, let's note that there are two locations where the schema attribute was introduced:\n- on the collection object, for the JSON schema definition\n- on records, for the validated schema version\nHow it was done\nRegarding the collection object, I found it consistent to put it in data. As @Natim said:\n\nIn this implementation, we are just providing a new property to the collection which is the schema.\nOther property may come such as signing, description, title.\n\nThe schema is the collection data, it is completely consistent :) Because data is just the name we gave to the main payload of response, and has no further semantics. That's what kinto.js reads when it receives the response. \nPlus it was very easy to implement, since completely in the rails of current cliquet resource code.\nAs for the record, since we wanted to have a way to filter records by schema version, it had to become a record attribute. In cliquet, we store the data content in the storage backend (which allows filtering) and the permissions in the permissions backend.\nRemoving the odd\nNow. I fully understand your concern : keeping the application specific properties in data and every Kinto notion at the root level is a good (new) idea !\nBut IMO, in order to remain consistent, we should then also move id and last_modified ! \nCollection would look like this:\njs\n{\n   \"id\": \"087-7u8097908708\",\n   \"last_modified\": 456789986,\n   \"fingerprint\": \"11:D5:D2:0A:9A:F8:D9:FC:23:6E:5C\",\n   \"data\": {\n       \"author\": \"Bozo the clown\",\n   },\n  \"permissions\": {\n     \"write\": [\"fxa:00567y09\"]\n  },\n  \"schema\": {\n    ....json-schema...\n  }\n}\nSame idea for records:\njs\n{\n   \"id\": \"087-7u8097908708\",\n   \"last_modified\": 78945144,\n   \"fingerprint\": \"11:D5:D2:0A:9A:F8:D9:FC:23:6E:5C\",\n   \"data\": {\n       \"title\": \"F Society\",\n       \"url\": \"http://thefreedictionary.com/decentralize\",\n   },\n  \"permissions\": {\n     \"write\": [\"fxa:00567y09\"]\n  },\n  \"schema\": 456789986\n}\nBut, hey, this is not a minor task. It does not look like one of our priority either. And it would break kinto.js AFAIK. \nEven though I find it attractive, I am not sure I want to put a foot in this energy absorbing swirl :) This is pretty huge.\nPragmatism\nIn order to implement your idea without inverting too much effort, we could : \n- leave id and last_modified as they are\n- leave the schema attribute on records as it is\n- move the schema attribute to the root of collection object\nBut, does it really bring any value ? Will it be fondamentally better ? What are our criterias to evaluate that ?\nPlease note that it would be a lot cleaner if we refactor some part of cliquet resource schema manipulation in order to achieve this. Otherwise payload validation (especially for PATCH request) will have even more ugly parts. I would be motivated to do it though.\n. We talked about this in a meeting. The current implementation has the advantage to keep data content consistent between single record and list of records responses.\nWe came with the following conclusion:\n- We release Kinto with the schema validation feature as experimental and subject to change\n- We keep investigating to find a solution that is consistent and intuitive :)\n. I would vote for closing this issue in favor of #256 \n. r- : I would not spread the same assertions like this everywhere !\nAn assertion in a test should reflect its title.\n. r+\n. Done !\n. Done in kinto 1.6.0 (with cliquet 2.8)\n. There might be some corner cases where this code was useful. But since the tests pass without it, it is dead code :)\nIf we figure out what were the corner cases, we'll add a test and restore it...\n. @tarekziade was it a specific requirement to be able to set cache duration \u00abglobally on bucket\u00bb for every underlying collections ?\nOtherwise this PR is ready :) @Natim @ametaireau @tarekziade r?\n. > duplication of concerns between the Kinto and the Cliquet documentation\nFor this particular case, I don't see any alternative. Especially because the setting name contains the name of the resource, which is generic in Cliquet, and limited to bucket, group, collection, record in Kinto.\n. I would be in favor of enabling Slack with two-ways sync with IRC. Even though I am not delighted with that proprietary drain :]\n. Note for later:\n- http://www.mattermost.org\n- https://zulip.org\nAnd @n1k0 was mentioning something like \u00abdistort\u00bb :)\n. Slack was setup, closing\n. r+\nI confirm that it fixes the issue :)\nThanks!!!\n\n. Following up on this: I changed from default to a specific bucket in the load tests. And went from  35 to 75 RPS. \nThat means the default bucket is currently 55% slower than other buckets.\nI start a PR to tackle this step by step.\n. Note: This was landed in cliquet master (2.11.dev).\n. Done in 1.9.0\n. Made a wip for the second point. It is tricky, unless, we transform the default bucket id into a hash from the authorization code.\nhttps://github.com/Kinto/kinto/commit/cb71b528e014d193c596da87118ae65ffeb812c5\n@Natim I know every tests fail, but early feedback is welcomed :) Thanks!\n. Some feedback about this after a couple of hours:\n1.  It is not trivial at all.\n2. The authorization policy must know about the target bucket_id\n3. Using collection.create_record() is not enough. Because associated permissions have to be created too (ie. write to owner).\n4. Using a resource instance and calling put() is not trivial either. Especially because the request and context have to be prepared accordingly. Whereas we would have to do it during context instanciation (see point 2)\n5. The cliquet RouteFactory instantiate the current resource to determine if the PUT requires write or create. This means that the default bucket logics should happen before relying on Cliquet factory.\nI tried different things but mainly have been trying to add a custom routefactory in Kinto where we would create the default bucket and collections.\nIn vain so far :)\n. With memory backend:\nDuration: 60.08 seconds\nHits: 5517\nStarted: 2015-09-22 13:50:53.098524\nApproximate Average RPS: 91\n. Closing because there is now a paginate entry in docs. http://kinto.readthedocs.io/en/stable/api/1.x/pagination.html\n. Also, ideally I wouldn't mix troubleshooting and overview questions.\n. Oh yes, good idea :)\nr+\n. I propose that we close this meta issue and re-spawn scoped dedicated issues for the remaining items.\n. Just to get some inspiration... The Pusher ecosystem is really simple to setup ! \nhttps://github.com/pusher/pusher-http-python#triggering-events\n. https://github.com/Kinto/kinto-webpush/ was implemented \\o/\n. On other buckets\necho '{\"data\": {\"id\": \"blog\"}}' | http POST http://localhost:8888/v1/buckets/b8f3fa97-3e0a-00ae-7f07-ce8ce05ce0e5 --auth=\"bob:\" --verbose\nit works as expected:\n```\nHTTP/1.1 405 Method Not Allowed\nAllow: GET, HEAD, PUT, PATCH, DELETE, OPTIONS\nContent-Length: 102\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 19 Oct 2015 10:34:44 GMT\nServer: waitress\n{\n    \"code\": 405, \n    \"errno\": 115, \n    \"error\": \"Method Not Allowed\", \n    \"message\": \"Method not allowed on this endpoint.\"\n}\n```\n. If tests pass, this look like a sane change! r+\n. Cannot reproduce with kinto master, memory backend, cliquet 2.9.0dev0\necho '{\"permissions\":    \n    {\"write\": [\"/buckets/46524be8-0ad7-3ac6-e260-71f8993feffa/groups/moderators\",\n               \"basicauth:631c2d625ee5726172cf67c6750de10a3e1a04bcd603bc9ad6d6b196fa8257a6\"]}}'| http PUT http://localhost:8888/v1/buckets/default/collections/bookmarks --auth user:pass -v\nreturns\n```\nPUT /v1/buckets/default/collections/bookmarks HTTP/1.1\nAccept: application/json\nAccept-Encoding: gzip, deflate\nAuthorization: Basic dXNlcjpwYXNz\nConnection: keep-alive\nContent-Length: 195\nContent-Type: application/json; charset=utf-8\nHost: localhost:8888\nUser-Agent: HTTPie/0.8.0\n{\n    \"permissions\": {\n        \"write\": [\n            \"/buckets/46524be8-0ad7-3ac6-e260-71f8993feffa/groups/moderators\", \n            \"basicauth:631c2d625ee5726172cf67c6750de10a3e1a04bcd603bc9ad6d6b196fa8257a6\"\n        ]\n    }\n}\nHTTP/1.1 201 Created\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 348\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 19 Oct 2015 10:38:53 GMT\nEtag: \"1445251133832\"\nLast-Modified: Mon, 19 Oct 2015 10:38:53 GMT\nServer: waitress\n{\n    \"data\": {\n        \"id\": \"bookmarks\", \n        \"last_modified\": 1445251133832, \n        \"schema\": {}\n    }, \n    \"permissions\": {\n        \"read\": [], \n        \"record:create\": [], \n        \"write\": [\n            \"basicauth:6de355038fd943a2dc91405063b91018bb5dd97a08d1beb95713d23c2909748f\", \n            \"basicauth:631c2d625ee5726172cf67c6750de10a3e1a04bcd603bc9ad6d6b196fa8257a6\", \n            \"/buckets/46524be8-0ad7-3ac6-e260-71f8993feffa/groups/moderators\"\n        ]\n    }\n}\n```\n. ~~Somehow more preoccupying, with postgres backend, I get another behaviour (current user is not added):~~    Update: Everything is fine with postgres backend. The difference with previous comment, is just that I changed the hmac_secret and the resulting user id differs from the one passed in the request body.\necho '{\"permissions\": \n    {\"write\": [\"/buckets/46524be8-0ad7-3ac6-e260-71f8993feffa/groups/moderators\",\n               \"basicauth:631c2d625ee5726172cf67c6750de10a3e1a04bcd603bc9ad6d6b196fa8257a6\"]}}'| http PUT http://localhost:8888/v1/buckets/default/collections/bookmarks --auth user:pass -v\n```\nPUT /v1/buckets/default/collections/bookmarks HTTP/1.1\nAccept: application/json\nAccept-Encoding: gzip, deflate\nAuthorization: Basic dXNlcjpwYXNz\nConnection: keep-alive\nContent-Length: 195\nContent-Type: application/json; charset=utf-8\nHost: localhost:8888\nUser-Agent: HTTPie/0.8.0\n{\n    \"permissions\": {\n        \"write\": [\n            \"/buckets/46524be8-0ad7-3ac6-e260-71f8993feffa/groups/moderators\", \n            \"basicauth:631c2d625ee5726172cf67c6750de10a3e1a04bcd603bc9ad6d6b196fa8257a6\"\n        ]\n    }\n}\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 242\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 19 Oct 2015 10:42:05 GMT\nEtag: \"1445251325575\"\nLast-Modified: Mon, 19 Oct 2015 10:42:05 GMT\nServer: waitress\n{\n    \"data\": {\n        \"id\": \"bookmarks\", \n        \"last_modified\": 1445251325575, \n        \"schema\": {}\n    }, \n    \"permissions\": {\n        \"write\": [\n            \"basicauth:631c2d625ee5726172cf67c6750de10a3e1a04bcd603bc9ad6d6b196fa8257a6\", \n            \"/buckets/46524be8-0ad7-3ac6-e260-71f8993feffa/groups/moderators\"\n        ]\n    }\n}\n```\n. Festival ! :tada: \nWith the redis backend, I have a 500 :)\n```\n2015-10-19 12:46:06,925 ERROR [venusian][waitress] \"PUT   /v1/buckets/b928fd92-4832-bca4-b56e-d647c573204d/collections/bookmarks\" ? (? ms) u'create' lang=None; exception=Traceback (most recent call last):\n  File \"/home/mathieu/Code/Mozilla/kinto/.venv/local/lib/python2.7/site-packages/pyramid/tweens.py\", line 21, in excview_tween\n    response = handler(request)\n  File \"/home/mathieu/Code/Mozilla/kinto/.venv/local/lib/python2.7/site-packages/pyramid/router.py\", line 163, in handle_request\n    response = view_callable(context, request)\n  File \"/home/mathieu/Code/Mozilla/kinto/.venv/local/lib/python2.7/site-packages/pyramid/config/views.py\", line 385, in viewresult_to_response\n    result = view(context, request)\n  File \"/home/mathieu/Code/Mozilla/kinto/.venv/local/lib/python2.7/site-packages/pyramid/config/views.py\", line 501, in requestonly_view\n    response = view(request)\n  File \"/home/mathieu/Code/Mozilla/kinto/kinto/views/buckets.py\", line 165, in default_bucket\n    response = request.invoke_subrequest(subrequest)\n  File \"/home/mathieu/Code/Mozilla/kinto/.venv/local/lib/python2.7/site-packages/pyramid/router.py\", line 217, in invoke_subrequest\n    response = handle_request(request)\n  File \"/home/mathieu/Code/Mozilla/kinto/.venv/local/lib/python2.7/site-packages/pyramid/router.py\", line 163, in handle_request\n    response = view_callable(context, request)\n  File \"/home/mathieu/Code/Mozilla/kinto/.venv/local/lib/python2.7/site-packages/pyramid/config/views.py\", line 596, in call\n    return view(context, request)\n  File \"/home/mathieu/Code/Mozilla/kinto/.venv/local/lib/python2.7/site-packages/pyramid/config/views.py\", line 329, in attr_view\n    return view(context, request)\n  File \"/home/mathieu/Code/Mozilla/kinto/.venv/local/lib/python2.7/site-packages/pyramid/config/views.py\", line 305, in predicate_wrapper\n    return view(context, request)\n  File \"/home/mathieu/Code/Mozilla/kinto/.venv/local/lib/python2.7/site-packages/pyramid/config/views.py\", line 245, in _secured_view\n    return view(context, request)\n  File \"/home/mathieu/Code/Mozilla/kinto/.venv/local/lib/python2.7/site-packages/pyramid/config/views.py\", line 355, in rendered_view\n    result = view(context, request)\n  File \"/home/mathieu/Code/Mozilla/kinto/.venv/local/lib/python2.7/site-packages/pyramid/config/views.py\", line 501, in _requestonly_view\n    response = view(request)\n  File \"/home/mathieu/Code/Mozilla/kinto/.venv/local/lib/python2.7/site-packages/cornice/service.py\", line 571, in wrapper\n    response = view()\n  File \"/home/mathieu/Code/Mozilla/cliquet/cliquet/resource.py\", line 361, in put\n    unique_fields=unique)\n  File \"/home/mathieu/Code/Mozilla/cliquet/cliquet/collection.py\", line 290, in create_record\n    self.permission.replace_object_permissions(perm_object_id, permissions)\n  File \"/home/mathieu/Code/Mozilla/cliquet/cliquet/storage/redis.py\", line 18, in wrapped\n    return func(args, *kwargs)\n  File \"/home/mathieu/Code/Mozilla/cliquet/cliquet/permission/redis.py\", line 151, in replace_object_permissions\n    principals = permissions[permission]\nKeyError: u'create'; uid=6de355038fd943a2dc91405063b91018bb5dd97a08d1beb95713d23c2909748f; errno=110; agent=HTTPie/0.8.0; authn_type=BasicAuth; collection_id=collection; collection_timestamp=1445251566921\n```\n. Thanks for starting to tackle this !\nAs a general remark, I don't understand why it is necessary to duplicate __init__.py and kinto.ini into the scripts folder.\nFrom what I understand from your script, I would instead:\n- use relative path to kinto/config/kinto.ini\n- prompt the user for a couple of settings (something like storage engine ? [postgresql] as a first version) \n- replace the appropriate values of the config\n- output the file as you did :)\nTell us what you think !\nEnjoy and good luck :)\n. Great !\nI think we can make it even simpler. If we want a command to get started quickly, then we don't need to ask for advanced stuff like uwsgi.\nIf some settings are not defined in the .ini file, then Kinto will use the default values automatically. So as a start, we can output the bare minimum.\nSee, for example, the one we use to run the load tests here : https://github.com/Kinto/kinto/blob/master/loadtests/server.ini\nI also suggest that we ask for the backend only once, and use the same for all of them. For example, if I say that I want postgresql then postgresql is used for storage cache and permission. This way we don't prompt for so many things, and it helps to get started quickly !\nIn order to guide you, I propose this list of small tasks:\n- [ ] Remove the files ending with ~\n- [ ] Remove the duplicated __init__.py and kinto.ini files in scripts/ folder\n- [ ] Remove prompts for advanced configuration values to keep it to the bare minimum (like the one in load tests)\n- [ ] Ask for the backend values only once and use the same in all of them\nAfter that, we will make sure it works, we will improve it to be able to run with commandline arguments, we will document it, add more settings and advanced stuff etc. But first we have to reduce it the bare minimum that works and make it look shiny :)\nGood luck !\n. Here are some answers, I hope my answers will guide you a bit :)\n\n-So, uwsgi is default right?I don't ask if uwsgi should be enabled or not?\n\nuwsgi is not necessary for Kinto to run locally. It is more like a production setup, when the server should handle hundreds of requests per second. It is out of scope for the first version.\n(See the minimalistic ini file I pointed in my previous comment)\n\n-Also, for the backends, I only ask if the user wants postgresql at the backend or not? what happens when another platform is to be used at the backend?\n\nAs a first step, I would suggest something like : \n```\n\nWhich backend to use ? (1 - in-memory, 2 - postgresql, 3 - redis) [1]: \n2\n\nOK, Kinto will be configured with backend \u00abpostgresql\u00bb.\n```\nThis is not an award-winning user interface, but it could work as a first version in my opinion!\n\n-for multiauth policies, should there be an option for basicauth and fxa auth? If there is an option, fxa_auth will need client id and client secret correct?\n\nAuthentication configuration can be complicated. I suggest that you leave it\nwith the defaults (i.e. basic authentication only). Users that need to configure that will still be able to edit the ini file manually anyway.\nHowever, the client secret is used at several parts of the Kinto code as \u00aba seed\u00bb to encrypt some sensitive data. This one is mandatory :)\n\n-also, what does the socket file contain?\n\nForget about socket, it is only used by uwsgi...\n. As a side note...\nWe may want to investigate the relevance of existing tools that provide such templating/prompts. @ametaireau pointed https://github.com/audreyr/cookiecutter which lead me to something available with Pyramid : pcreate. http://docs.pylonsproject.org/projects/pyramid/en/latest/narr/scaffolding.html\nThe documentation does not say much and it might not be obvious to get started. However, in the end, this could save us some efforts on raw input parsing and configuration templating...\nIt may be interesting to at least give it a try and look for examples to mimic them !\n. Oh, you went fast !\nWhat feedback do you have on cookiecutter ? Is it nice to use as a user ? You chose it over pcreate for a particular reason ?\nDon't worry if you don't commit while you do some investigations ! We can take our time and see if it fits well our needs :)\n. Great ! Indeed, cookiecutter is not a bad choice. It just installs a fair amount of additionnal tools and libraries where pcreate already comes installed with Kinto.\nFor example, if you run pcreate -l you'll see every available templates.\nSome scaffolds examples in the wild:\n- https://github.com/mozilla-services/cornice/tree/master/cornice/scaffolds\n- https://github.com/Pylons/pyramid/tree/master/pyramid/scaffolds\n- https://github.com/Pylons/pyramid_jqm/tree/master/pyramid_jqm\n- https://github.com/Pylons/pyramid_jinja2/tree/master/pyramid_jinja2/scaffolds\nHowever, I don't know if any of those will prompt the user for configuration values... I don't even know if pcreate has this feature :))\nThere are more tools listed here too : https://github.com/audreyr/cookiecutter#similar-projects\n. Thanks @Natim for the detailed explanation :) Now that you said it I feel dumb :D \nI updated it !\n. I am globally seduced by that. But I have a mixed feeling in regards to the Pyramid ecosystem conventions...\n- We should probably replace pserve with something that runs the app.wsgi file no?\n- It looks like prefixing settings name is a common pattern in Pyramid applications. This would contrast with the ecosystem, no?\n- I wish this could apply to every cliquet applications, without having to copy/paste this global_config line)\n. Unlikely to happen. Been here for too long.. Thanks for this contribution :)\n. This line in Kinto.js is responsible for storing it in the local database:\nhttps://github.com/Kinto/kinto.js/blob/e6aa1023c467ddc733d7e514b62ae5e3fa7a6d11/src/api.js#L249\n. @n1k0 r?\n. That's a great use case for writing a kinto plugin indeed :)\n. The implementation of history tracking itself is very simple, it is very similar to what was done in kinto-changes (BTW I think this feature should land there).\nWe could even store a diff between old and new on update etc. \nAmong the use-cases we have in mind, there is:\n- What was changed in this collection since last time?\n- When was this record created?\n- What is the history of the collection json schema?\nHistory must thus track and allow filtering/sorting by:\n- resource_name: every kind of object (bucket, collection, records, ...)\n- prefixed_userid: userid prefixed by authentication policy\n- action: create/update/delete\n- uri: object URI without version prefix\nThe history is actually a resource whose records are the notifications payloads, that can be filtered, sorted etc. like any other resource but readonly.\nBut while I was thinking about the implementation, I realized the main challenge was about permissions (especially if we store diffs).\n- Minimalist: use a setting to specify which principals are allowed to read\n- Per bucket/collection: readable if read on bucket/collection\n- Filtered per permission: show only the history entries where the related object is readable. This would probably give the best experience, but would be relatively complex to implement ('cuz of perfs, reminder: permissions can be in redis, history records in postgresql)\nDo you have any feedback on the preferred approach? I personnally like the second one as a first step.\n. > Ideally it would be nice to have the previous data and the new data\nYes, this is trivial to implement.\nThe only concern is about permissions: we have to be sure that those who can read the history would have been allowed to read the affected records.\n. Merged in #694 !\n. Thanks Michiel for initiating this! \n\ndon't use a \"default\" bucket\n\nWe are replacing the default bucket with a redirection in #233 \n\nSend a \"Cache-Control\": \"no-cache\" header on each response\n\nThis would indeed be a no-brainer. And we would restrict the client cache headers feature to anonymous requests (like @Natim suggested in https://github.com/mozilla-services/cliquet/issues/449)\n. Closing as I think this was resolved. Please re-open if I'm mistaken\n. Excellent, thank you for your contribution !\nAs you may have noticed, @oak11 started to investigate around the init command in #216. Do not hesitate to get in contact and share the efforts, especially about choosing a tool that could handle the prompts and templating...\n. Apparently @Natim merged your code in another pull-request :) Congratz !\n. Current status on this:\n- Good news: kinto.js follows automatically the redirection, so we can consider that we don't break the API, and thus keep it as /v1/\n- Bad news: currently it only works with cors disabled in the browser :) the redirection is rejected.\nAs a note:\ndiff\ndiff --git a/cliquet/utils.py b/cliquet/utils.py\nindex 917ad80..1b1a86d 100644\n--- a/cliquet/utils.py\n+++ b/cliquet/utils.py\n@@ -178,7 +178,10 @@ def reapply_cors(request, response):\n         from cliquet import Service\n         if Service.default_cors_headers:\n             headers = ','.join(Service.default_cors_headers)\n            response.headers['Access-Control-Expose-Headers'] = headers\n+        response.headers['Access-Control-Allow-Headers'] = 'accept, authorization, content-type, if-none-match'\n+        response.headers['Access-Control-Allow-Method'] = 'GET'\n+        response.headers['Access-Control-Allow-Credentials'] = 'true'\n     return response\n```\n$ http options http://localhost:8888/v1/buckets/default Origin:http://localhost:3000 'Access-Control-Request-Headers: accept, authorization, content-type, if-none-match'  'Access-Control-Request-Method: GET' \nHTTP/1.1 200 OK\nAccess-Control-Allow-Headers: Content-Length,Expires,accept,Alert,Retry-After,Last-Modified,ETag,Pragma,Cache-Control,if-none-match,Backoff,content-type,authorization\nAccess-Control-Allow-Methods: GET,HEAD,PUT,PATCH,DELETE,OPTIONS\nAccess-Control-Allow-Origin: *\nAccess-Control-Max-Age: 3600\nContent-Length: 4\nContent-Type: application/json; charset=UTF-8\nDate: Fri, 30 Oct 2015 09:56:41 GMT\nServer: waitress\nnull\n```\n```\n$ http get http://localhost:8888/v1/buckets/default Origin:http://localhost:3000 --auth='bob:'\nHTTP/1.1 307 Temporary Redirect\nAccess-Control-Allow-Origin: http://localhost:3000\nAccess-Control-Expose-Headers: Backoff,Retry-After,Alert,Content-Length\nContent-Length: 53\nContent-Type: application/json; charset=UTF-8\nDate: Fri, 30 Oct 2015 09:58:23 GMT\nLocation: http://localhost:8888/v1/buckets/b8f3fa97-3e0a-00ae-7f07-ce8ce05ce0e5\nServer: waitress\n{\n    \"code\": 307, \n    \"errno\": 999, \n    \"error\": \"Temporary Redirect\"\n}\n```\nReject by browser:\nBlocage d'une requ\u00eate multi-origines (Cross-Origin Request) : la politique \u00ab Same Origin \u00bb ne permet pas de consulter la ressource distante situ\u00e9e sur http://localhost:8888/v1/buckets/default/collections/items/records?_since=1445873606766. Raison : \u00e9chec de la requ\u00eate CORS.\nFetch API cannot load http://localhost:8888/v1/buckets/default/collections/items/records?_since=1446136656546. The request was redirected to 'http://localhost:8888/v1/buckets/45f48187-a63b-2c1c-1019-28e5505d0cab/collections/items/records?_since=1446136656546', which is disallowed for cross-origin requests that require preflight.\n. From our last conversations, it looks like using the Vary header could solve the client caching problems we have for the default bucket.\nShould I drop this PR then ?\nShould I revamp the part about putting the bucket id in the user field on the hello page ?\n. Giving up with this, given last discoveries about cache-control and vary headers\n. I would suggest to replace collection attributes on resource by model (i.e. check for deprecation warnings)\n. r+ :+1: thanks for your patience ;)\n. As said somewhere else :\n- The most efficient way to make sure that Kinto does not write to the database is to configure it with a PostgreSQL user that has only readonly privileges\n- The inconvenient is that every requests PUT/POST/PATCH/DELETE will be responded with a 503, and will trigger Sentry errors.\nWe have thus to limit the requests on collections to GET.\nThis can happen at several levels:\n- Reverse proxy (or CDN) - ie. Nginx\n- At the software level (during view registration)\n- At the wsgi middleware level (in kinto init)\nThe higher the better. So I would be in favor of doing it in Nginx + PostgreSQL of course. But as we say, we can take \u00aba belt and braces approach\u00bb and do something in the Kinto codebase :)\nWith the middleware approach, we have to be careful because this will restrist the batch requests. Even though every subrequest is readonly.\nWith the view registration approach (as suggested by Remy), we are sure that it applies to REST resources views only (responding a 405).\nWith a kinto.read_only_mode setting, that populates the other ones, we can make sure that the list of disabled resources (buckets, collections, groups, records) is exhaustive...\nMy 2 cents...\n. > I guess this can be detected in the middleware by introspecting the request body ? \nYes I guess we can just introspect the path (request.path.startswith('/batch'))\n\nthis POST-is-a-bunch-of-GET feature\n\nNope. This is a very specific usage of the batch endpoint, for which we don't have any use-case currently. (There used to be one for readinglist, where the UI would want to populate several menu entries by article read status using only one request)\nSo, for sec settings, at the CDN level we can go for the easiest way : only GET.\nBut in Kinto, in order to remain consistent, I suggest we allow POST on batch. (or we only disable resource verbs using available settings, as suggested by Remy)\n. After quick conversation with @tarekziade, the approach suggested by @Natim is the way to go. There is no code to write, just manipulate setttings at startup when readonly is set, and the views won't be registered in Pyramid (405 responses when accessed)\n. Of course, you won't touch the schema with a readonly user :) cliquet migrate is irrelevant here no ?\n. Related #64 \n. It is here but totally unclear indeed http://kinto.readthedocs.org/en/latest/api/cliquet/resource.html#delete-collection\n. r+\n. Rebased\n. r+\n. (don't forget to update the contributors ;))\n. Side note: tested here : https://github.com/mozilla-services/cliquet/blob/2.10.0/cliquet/tests/resource/test_preconditions.py#L163-L168\n. > The test is wrong here it should be If-None-Match:'\"*\"' isn't it?\nNope, it should be just *.\nRef spec (see last example) : http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.26\n. I would vote for closing this then :)\n. Tests fail because of #252 \n. Yes, adding a column for default values was already suggested in #208 \n. Very related to #174 \n. > The question is, will permission be part of this data or not?\nFrom what I understand I guess it should. Like schema and other metadata.\n\nOne of the challenges with this approach is that record lists should also contain the associated metadata. \n\nIn terms of implementation, this would probably mean to get rid of the multiple backends and put everything into one. Otherwise, joining data and permissions during the list construction might not be efficient at all. Especially if we want stuff like #123 \n\nI'll let @leplatrem expend on this as I don't see clearly where the problem lies.\n\nAs I said privately, this could be quite a change for the whole ecosystem, and I see no emergency in doing this. I personally would rather keep metadata mixed up with data and put the efforts into other challenges that bring more value to the end users (docs, install, demos, integrity, ...)\n. @almet r?\n. This was implemented using template in #278 \n. Sounds rather obvious that memory backend is suboptimal for production...\n. Hi Janine,\nAre trying to fix #238 ?\nI don't understand what you did here. 238 should just consists in mentioning DELETE operation for the list of records, that's just it :)\n. Thanks again for your contribution!\nI will close this for now. But don't hesitate to open another one with just the missing line in docs!\n. Thanks!\n. Added as suggested :)\n. @Natim  final r?\n. Cannot reproduce.\n. Ok great ! Let's go through some missing parts:\n- [x] Add a rule in Makefile to run init when config file is missing (like in #261)\n- [x] Add default config/kinto.ini to .gitignore\n- [x] Update documentation to remove wget of remote ini files\n- [x] Update quickstart to mention this command\n- [x] Remove cp config/kinto.ini config/dev.ini from documentation\n- [x] Warn (or create backup or whatever) when destination file already exists\n. r+\n. Yes, we still have a problem regarding documentation.\nThe trick we used to include the cliquet resource docs isn't working very well. \nSee here, we have status code listed http://kinto.readthedocs.org/en/latest/api/cliquet/resource.html#delete-collection\nBTW, 401 and 403 aren't mentionned :D \nWe have to find a way to document that the buckets/groups/collections/records all share a common set of properties. And those properties are the one described in the documentation of cliquet resource (above link).\nI fully agree that the current situation isn't very much engaging\n. Related #196 \n. Since a lot of things have changed in Cliquet, I think we should put some efforts to make it crystal clear for anyone witshing to update. As for example:\n- [x] Mention new settings in changelog\n- [x] Copy/paste protocol changes of cliquet\n- [x] Copy/paste breaking changes of cliquet\n- [x] Say something about transactions and integrity of requests\n- [x] Say something about sqlalchemy\n- [x] Add link to cliquet release ?\nAnd also:\n- [x] Update documentation with new settings (postgresql pooling)\n- [x] Remove groupfinder from Kinto\nWe'll do together tomorrow! \n. Oops! Done. Thanks!\n. Closing. Not a good idea.\n. settings['userid_hmac_secret'] returns a value of <class 'bytes'> !\n. Also, these lines are not necessary:\nhttps://github.com/Kinto/kinto/blob/master/kinto/config/init.py#L48\nAnd this: https://github.com/Kinto/kinto/blob/master/kinto/config/init.py#L55-L61\ncould be simplified to **values\n. Unlikely to happen (been here for too long). @n1k0 r?\n. Thank your @scottinet for the feedback !\n\nOffline-first client and Decentralised discovery?\n\nThe offline-first client allows application developers to implement an application that works offline. The developers would just create/update/delete records, and the library takes care of synchronizing the local database with the remote server. See kinto.js or PouchDB\nDecentralized discovery is the ability for the application to store the data at a specific location automatically. Most likely that depends on the authenticated user. When I use an application and say that I am mathieu@mydomain.com then the application knows that my Kinto instance is hosted at https://kinto.framasoft.net. See remotestorage for example.\n\nConflict resolution\n\nDo you have any details to provide ? This is a very wide topic and if you do something in particular I think it would be great to mention it in our docs :) \nI realize that Kinto does not really perform any automatic conflict resolution. It's more about concurrency control, using Etag.\n\nBulk operations \n\nNoted. From what I read, Kuzzle does only bulk create (import) though.\n\nValidation, through pipe plugins\n\nNoted ! \nI think we should probably distinguish what is available via code, and via HTTP API. In for example Kinto you defined a JSON Schema on the collection via the HTTP API, and created/updated records will be validated for this collection.\n\nFine-grained permissions\n\nGreat!\nI read the documentation (and almost the whole pull-request) and from what I understood (may be wrong), the permissions are set via configuration (or code), but not via HTTP API.\n\nPluggable authentication\n\nNoted :)\nAgain, thanks a lot for your feedback!\n\nWe couldn't manage to come to #OSSPARIS15, but I'm sure we'll be able to meet soon and exchange about our respective visions and roadmaps!\n. Great, thank you!\n\nI hadn't seen the SDK documentation yet. Neat! \nIt looks like Kuzzle and Kinto columns will be pretty similar then :)\n. yes!\nI will give it a try. Thanks for your feedback!\n. What about a built-in plugin specified in .ini instead of CLI arg ?\n. According to what was done in kinto, this will simple be a built-in plugin :) specified or not in the kinto.includes setting !\n. Works for me!\n. r+ but better if sphinx warnings can be fixed :) \n. In the tutorial we decided to go with Github+Bearer.\n. Could reproduce:\n```\nvirtualenv .venv34 --python=python3.4\nRunning virtualenv with interpreter /usr/bin/python3.4\nUsing base prefix '/usr'\nNew python executable in .venv34/bin/python3.4\nAlso creating executable in .venv34/bin/python\nInstalling setuptools, pip...done.\n$ source .venv34/bin/activate\n$  pip install kinto\nDownloading/unpacking kinto\n  Downloading kinto-1.11.0-py2.py3-none-any.whl (47kB): 47kB downloaded\n  Storing download in cache at /home/mathieu/Downloads/pip/https%3A%2F%2Fpypi.python.org%2Fpackages%2Fpy2.py3%2Fk%2Fkinto%2Fkinto-1.11.0-py2.py3-none-any.whl\nDownloading/unpacking waitress (from kinto)\n  Using download cache from /home/mathieu/Downloads/pip/https%3A%2F%2Fpypi.python.org%2Fpackages%2Fsource%2Fw%2Fwaitress%2Fwaitress-0.8.10.tar.gz\n  Running setup.py (path:/tmp/pip-build-8iw7z7ci/waitress/setup.py) egg_info for package waitress\nDownloading/unpacking jsonschema (from kinto)\n  Using download cache from /home/mathieu/Downloads/pip/https%3A%2F%2Fpypi.python.org%2Fpackages%2Fpy2.py3%2Fj%2Fjsonschema%2Fjsonschema-2.5.1-py2.py3-none-any.whl\nDownloading/unpacking cliquet<3,>=2.15 (from kinto)\n  Using download cache from /home/mathieu/Downloads/pip/https%3A%2F%2Fpypi.python.org%2Fpackages%2Fcp2.cp3%2Fc%2Fcliquet%2Fcliquet-2.15.0-cp2.cp3-none-any.whl\nDownloading/unpacking functools32 (from kinto)\n  Using download cache from /home/mathieu/Downloads/pip/https%3A%2F%2Fpypi.python.org%2Fpackages%2Fsource%2Ff%2Ffunctools32%2Ffunctools32-3.2.3-2.tar.gz\n  Running setup.py (path:/tmp/pip-build-8iw7z7ci/functools32/setup.py) egg_info for package functools32\n    This backport is for Python 2.7 only.\n    Complete output from command python setup.py egg_info:\n    This backport is for Python 2.7 only.\n```\n. This was related the universal wheel published on Pypi.\nUntil we find a proper fix for this, we replaced the wheel by python sources (.tar.gz) on Pypi.\n. Appart from the 500 which is of course unacceptable, I think there is a misunderstanding here: if tags is a list attribute in the records, then ?in_tags=burundi is not exactly what we expect here.\nWe made the in operator to filter against multiple values (e.g. in_status=read,unread), but not as a contains operator.\n. I suggest that you open 3 different issues for that :)\n. We had doubts about that. Especially because Kinto and Kinto.js are mentionned explicitly here, whereas in Cliquet we tried to keep a generic doc that can work for any project.\nBut I'm ok with that if you are too :) \nr+\n. I remember that we had found some difference with Readinglist. But it could be worth to re-run some benchmarks, since some comments say it's not faster for every usecase :) \n. ujson 1.35 was just released \\o/\n. r+wc :)\n. Done in #354 \n. Fixed by https://github.com/Kinto/kinto/pull/351, thanks @conlini!\n. That is just excellent!\nIt would point to the Run kinto page ?\nWe'd be delighted to merge that! Thank you very much! \n. @Natim r?\n. This looks valid to me. @n1k0 @almet any feedback ?\nI think we might want to precise that Hoodie is using PouchDB (and thus CouchBD)\n. Your pull request contains a lot code that's already in the repo, and this makes it hard to outline and merge.  Can you try to merge the current master in your branch? Please update the changelog also to help us understand which issue is being fixed :)\nThanks !\n. Thanks for taking the time to contribute :) \n. Thanks @hansent for reporting this bug!\nIt looks like a consequence of #302, which was fixed and released recently.\nCould you please try to pull the last version of the kinto-server container?\n. Thanks for your feedback!\nI could find the problem in the Dockerfile :)\n. Thanks @chartjes @hansent and @saidimu for bringing this up!\nI just pulled and tested with the lastest container version and it is now fixed.\n$ sudo docker pull kinto/kinto-server\nUsing default tag: latest\nlatest: Pulling from kinto/kinto-server\ne7c6ac28919b: Pull complete \n1f32f6b0a215: Pull complete \n79efb74cdc69: Pull complete \n3a706ce797fa: Pull complete \n837c720db103: Pull complete \n5a9e9f07dab2: Pull complete \nDigest: sha256:cbd4264f9851c368664d0f542f54618f63404b7378f7a8165656e4845ff48ca6\nStatus: Downloaded newer image for kinto/kinto-server:latest\n$ sudo docker run -p 8888:8888 kinto/kinto-server\n2015-12-16 11:08:43,716 INFO  [venusian][MainThread] kinto 1.11.0.dev0 starting. \n...\n. We can put A lightweight JSON storage service with synchronisation and sharing abilities. like for the GH repo description.\n. r+\n. Currently we have:\n- Offline-first client\n- Fine-grained permissions\n- Easy query mechanism\n- Conflict resolution\n- Validation\n- Revision history\n- File storage\n- Batch/bulk operations\n- Changes stream\n- Pluggable authentication\n- Pluggable storage / cache \n- Self-hostable\n- Decentralised discovery\n- Open source\n- Language  \nI suggest that we also add: \n- API (WebSocket, REST)\n- Peer-to-peer\nAnd rename Changes stream to Push notifications, Validation to Schema validation.\nWe might have to get rid of hoodie since it relies on Pouch/Couch. \n. Duplicate of #331\n. > API changelog.\n:+1: \n. Updated\n. That's not so complicated with modern editors...\n\nBut I think I prefer the default next to the setting name.\nI will try to do something in CSS to set a max-width on the second column\n. \n. - ?has_attr=true\n- ?has_attr=false\n. We use the dot notation for partial responses (_fields=a.b) so it seems the best option. \n. The Kinto server is an HTTP service, it works with every browser.\nThe kinto.js client is absolutely not necessary to use Kinto in a JavaScript application. Using Angular or pure XmlHttpRequest would also work perfectly! \nkinto.js is relevant to provide offline/sync, and relies on IndexedDB, promises etc. to do it. Since it provides the polyfills to run on not-so-modern browsers, it should be ok with IE11. If you have a particular problem with kinto.js on the browser you mention, I suggest that you open an issue on the kinto.js repo instead.\nI'm closing this, but feel free to re-open if you still have some doubts !\n. Would you create a new page Notifications ? Where we can imagine opening to sending emails etc, or do we refactor (and move) the existing synchronisation page with a new section focused on live sync ?\n. Closing now that tutorials about notifications have landed\n. Excellent, I need this for my kinto-attachments plugin !\n. I can't reproduce it. How did you resolve it?\nDo you have a Postgresql running locally?\n@karlht how do you know that a lot of users have encountered that problem ? :) I'm curious and wonder why we were not aware of it!\n. We should also probably mention minimum python version :)\nFrom IRC: \n\nbefore going further, is there a required python version?\n. :+1: \n\nNo there isn't, but it's a good idea.\nRelated #173 \n. What's the status of this ? Does the built-in plugin kinto.plugins.quotas covers this already?\nBTW created date was later reported in issue #679 \n. I also vote for two buttons, even if they point to the same page :) but my opinion may not represent most of our users\n. We could also just leave \u00abGet started\u00bb, and then the \u00abDeploy on heroku\u00bb paragraph becomes very obvious on the first look\n. already merged #341 :dancer: \n. Okay, do not throw the previous one away then!\nNo need for libpq-dev?\n. > I put the other one here : https://github.com/Kinto/kinto-docker\nwhy another repo ?\n. ok then, got it! I'm a bit worried that too much choice can be puzzling though\n. But that command is what we suggest to do in the docs :/\n. \\o/\n. > adding in that case specific events before the data is saved into the DB\nGood idea, but it's another scope IMO. Please open an other issue to describe what you have in mind! \nFor naming ideas : https://docs.djangoproject.com/es/1.9/ref/signals/ :)\n. @n1k0 r?\n. - Run kinto is not hidden in the tutorials section\n- Get started shows how to run and points to tutorials\n- Tutorials now mention API in title\n. r+!\n. from what I understand we can delete the kinto-docker repo after that\n. Take this as a yes :)\n. Code now works :) Ready to review/merge!\n. > I don't think people should include it in the config so IMHO we can let it as it is.\nBut that's the only way to have default bucket work with kinto-attachment ! And that's the main reason  we put the default bucket as a plugin :) See #277 \n\nShould we issue a warning and ask for it to be included in the configuration explicitely now?\n\nyes, I think so \n. > Then, how do you remove the feature?\nWe cannot at this stage.\nCurrently the client of v1 expects the default bucket to create collections implicitly.\nBeing able to remove the default bucket could be part of the API v2. \n. Ready to review/merge!\n. Should I take over on the branch ?\n. Ready to review/merge!\n. Thanks.\nBy the way, don't take it yet, I didn't even tested it! \n. Ok, I went through the whole thing and could make it work :)\nNow ready to review/merge!\n. the ADD commands can now be simplified then\n. r+\n. Excellent ! Thanks for your contribution !\nBefore we merge, could you please : \n- Add yourself to the contributors files\n- Bump the HTTP_API_VERSION to 1.2 (new feature)\n- Add an entry in API changelog docs/api/index.rst\n. > HTTP_API_VERSION is already 1.2. Should I just add the changes to the changelog under v1.2?\nGood point! Yes I guess since 1.2 was added in the current master and not released yet. So forget what I said about bumping :)\nThanks !\n. Excellent! Thank you again! \n. Thank you for this report!\nThis is very (very) pleasant to receive a test case as a bug report!\nFrom what I see it looks like you're using the username instead of the user id in the group definition.\nThe user id can be obtained from the root URL when authenticated.\nWe'll double check all this tomorrow but the documentation probably deserves a good clarification on this!\n. Excellent, thank you! I I will spend some time on it, that indeed look very much like a bug!\n. r+, Aaron should be added to contribs :)\n. r+wc \n. Having it in the \u00abPython path\u00bb should be enough. Did you try leaving it in the current folder for example?\nYou can also use the PYTHONPATH environment variable for example:\n- $ export PYTHONPATH=/home/your/path:$PYTHONPATH\n- $ kinto start\nLet us know! (please continue mentioning my nick so that I get the notification more easily)\n. As we explained in #393, there is no notion of password in Kinto (we'll rework the documentation).\nBasic Auth has a bunch of limitations. We are aware of them but the documentation does not make them explicit (yet! Thank you for this feedback, we opened #395 to start addressing this issue.).\nAs a workaround, it's possible to change the permissions of the records for a specific user, by authenticating with the old user:pass1 and adding the userid of the new user:pass2 pair.\nIt is also possible to use groups to handle permissions for multiple users on multiple objects at the same time.\nBut ideally, for long term storage of personal data, we'd recommend using another authentication method... (see tutorial custom auth)\n. Don't forget that most tutorials have things like user:password, \"public:notsecret\", alice: or \"alice:secret\"\n. I confirm: this will be available in Kinto 1.11\n. r+\n. @Natim @n1k0 please review the changelog with care r?\n. Pusher rolled out mobile push notifications :) https://pusher.com/push-notifications\n. I really see the capabilities as a list of extra-features that are not built-in.\nThe readonly is exposed in settings. Its value has an impact on the behaviour of the API (like max_batch_requests) but I don't see it as a \u00abcapability\u00bb.\nFor example, the default bucket could (once activation is not forced on startup) will become a capability.\nBut I may be wrong, please argue a bit :)\n. > The capability could be writable\n:+1: \n. > The capability could be writable\nAfter thinking about this, I believe we should keep capabilities for extra features.\nIn this case, the writable capability seems a bit obvious and basically expected. \n. I am still convinced that readonly can remain a public setting.\nA capability could be something that expresses an additional property: cdn-friendly ?\n. See https://github.com/mozilla-services/cliquet/issues/631#issuecomment-176761484\n. @almet r?\n. No idea. That was a stacktrace on Sentry a while ago :(\n. Closing, we'll reopen if comes back.\n. @Natim created a tool here: https://github.com/Kinto/parse2kinto\nLet's continue the discussion there ;)\n. I'd r+!\nBut I haven't tested it locally. Do we merge and release 1.11.1 ?\n. That is an excellent question which forces us to write a proper summary of the purpose of Kinto.\nI suggest that we add it somewhere in the overview/faq :)\n. Looks good!\nWhere would we put this ? FAQ ?\n. Thanks for your contribution!\nI checked Travis and it worked well.\nI just wonder if we should do the same for py27, py34 and pypy now :) What do you think ?\n. I agree to merge it like this. Let's iterate if we can do better!\nThanks again!\n. r+wc :)\n. what about minimalist ?\n. This is awesome thanks!\n. > This is typically what we want to do asynchronously :) \nYes indeed. Although relying on a fast local server that behaves as relay is a very common approach. \nIn the tutorial we mention: \n\nTo run this in production, we would rely on a local email server acting as a relay in order to avoid bottlenecks. Or use the asynchronous approach otherwise.\n\nIf you are willing to improve the tutorials please don't hesitate!\n\ndo the e-mail example in the second part (async)\n\nYes why not, if it does not make it too long.\n\na piece of code that modifies data in the response\n\nAltering records on the fly can be a bit hacky, I have no idea how'd it look.\nOtherwise, we could do something else, like pushing messages to crossbar.io for example.\nNo other feedback apart from this :) \\o/ ?\n. > If there's any issue sending e-mails out, you now have to deal with an HTTP service that fails to return responses \nNo because the exceptions raised by listeners are catched.\n\nIf the triggered notification has zero impact on the request/response flow, what would we ever want it to be synchronously executed ? just to slow down the user for no reason ?\n\nThe default listener that deposits messages in the redis queue is synchronuous. \nA listener that sends messages to a crossbar server would be synchronuous too IMO.\nFor example, the listener that sends to Pusher is synchronuous in the current implementation (I don't say it's the best way to do it though).\nIn brief:\n- if we can alter the response in a simple and clean manner, let's do that! That's indeed the best illustration.\n- otherwise let's find another example! (Some ideas: populate a \u00abhistory\u00bb collection to track changes, or implement a listener for an alternative third-party to pusher.)\n. It sounds good!\nRegarding the config example, with what you propose it seems complicated to give extra parameters to functions or filter events by resource/actions.\nAn alternative is to move every listeners to this async implementation. The configuration of listeners does not change, expect that they are now always async.\nIf, for some reason, we need to run code synchronuously then we can still implement something that subscribes to the low-level Pyramid event and run code.\nConfiguring the worker class and number of processes now becomes another parameter along existing ones (use, actions, resources) and can have default (memory and # of CPU)\n``` ini\nkinto.event_listeners = redis send_email\nkinto.event_listeners.redis.use = cliquet.listeners.redis\nkinto.event_listeners.redis.workers = cliquet.workers.memory\nkinto.event_listeners.redis.processes = 1\nkinto.event_listeners.send_email.use = myproject.mymodule.send_email\nkinto.event_listeners.send_email.workers = cliquet_celery.workers\nkinto.event_listeners.send_email.processes = 4\nkinto.event_listeners.send_email.resources = bucket collection\nkinto.event_listeners.send_email.actions = create delete\nkinto.event_listeners.send_email.from = jeanlouis94@voila.fr\n```\n. > Great! Should we change it in cliquet as well?\nWhy not\n. No need for now.\n. This is now open for review/merge! \n@magopian, FYI this PR switches from inherited method in the resource class to event subscribers. \n@Natim r?\n. The formatted response is not showing well, any idea?\n\n. Are you still willing to merge this?\n. That's an excellent idea!\nI can work on this using pen and paper, and post scanned diagrams here so that someone can contribute nice ones :)\n. I started this:\n\nWhat do you think ?\n(forget about aesthetic :))\nRegarding sequence diagrams, I still have to think :) (e.g. scenario, level of details)\n. related to https://github.com/Kinto/kinto/issues/288 ?\n. Please define \"change phrasing\" :)\n. Bug confirmed implicit sort order -last_modified is not enabled\nCreate batch of records:\necho '{\"defaults\":{\"headers\":{\"Authorization\":\"Basic dXNlcjpwYXNz\"}},\"requests\":[{\"method\":\"PUT\",\"headers\":{\"If-None-Match\":\"*\"},\"path\":\"/v1/buckets/default/collections/blog/records/d914797f-1e55-4dde-ac92-51f4d06ba990\",\"body\":{\"data\":{\"id\":\"d914797f-1e55-4dde-ac92-51f4d06ba990\",\"title\":\"art1\"}}},{\"method\":\"PUT\",\"headers\":{\"If-None-Match\":\"*\"},\"path\":\"/v1/buckets/default/collections/blog/records/8aadb4d4-c107-4335-a119-81027143cf22\",\"body\":{\"data\":{\"id\":\"8aadb4d4-c107-4335-a119-81027143cf22\",\"title\":\"art2\"}}},{\"method\":\"PUT\",\"headers\":{\"If-None-Match\":\"*\"},\"path\":\"/v1/buckets/default/collections/blog/records/8712d6c9-8caf-43d3-b70d-7c82d672a1bc\",\"body\":{\"data\":{\"id\":\"8712d6c9-8caf-43d3-b70d-7c82d672a1bc\",\"title\":\"art3\"}}}]}' | http POST http://localhost:8888/v1/batch\nRetrieve:\n```\nhttp GET \":8888/v1/buckets/default/collections/blog/records\" --auth user:pass\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, Total-Records, ETag, Pragma, Cache-Control, Backoff, Next-Page\nCache-Control: no-cache\nContent-Length: 283\nContent-Type: application/json; charset=UTF-8\nDate: Wed, 10 Feb 2016 14:53:32 GMT\nEtag: \"1455115734732\"\nLast-Modified: Wed, 10 Feb 2016 14:48:54 GMT\nServer: waitress\nTotal-Records: 3\n{\n    \"data\": [\n        {\n            \"id\": \"8aadb4d4-c107-4335-a119-81027143cf22\", \n            \"last_modified\": 1455115734728, \n            \"title\": \"art2\"\n        }, \n        {\n            \"id\": \"d914797f-1e55-4dde-ac92-51f4d06ba990\", \n            \"last_modified\": 1455115734725, \n            \"title\": \"art1\"\n        }, \n        {\n            \"id\": \"8712d6c9-8caf-43d3-b70d-7c82d672a1bc\", \n            \"last_modified\": 1455115734732, \n            \"title\": \"art3\"\n        }\n    ]\n}\n```\nWith order:\n```\nhttp GET \":8888/v1/buckets/default/collections/blog/records?_sort=-last_modified\" --auth user:pass\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, Total-Records, ETag, Pragma, Cache-Control, Backoff, Next-Page\nCache-Control: no-cache\nContent-Length: 283\nContent-Type: application/json; charset=UTF-8\nDate: Wed, 10 Feb 2016 14:54:03 GMT\nEtag: \"1455115734732\"\nLast-Modified: Wed, 10 Feb 2016 14:48:54 GMT\nServer: waitress\nTotal-Records: 3\n{\n    \"data\": [\n        {\n            \"id\": \"8712d6c9-8caf-43d3-b70d-7c82d672a1bc\", \n            \"last_modified\": 1455115734732, \n            \"title\": \"art3\"\n        }, \n        {\n            \"id\": \"8aadb4d4-c107-4335-a119-81027143cf22\", \n            \"last_modified\": 1455115734728, \n            \"title\": \"art2\"\n        }, \n        {\n            \"id\": \"d914797f-1e55-4dde-ac92-51f4d06ba990\", \n            \"last_modified\": 1455115734725, \n            \"title\": \"art1\"\n        }\n    ]\n}\n```\n. Sounds good!\nAlthough I would put it in a setup_signals function in cliquet/initialization.py\n. > can we say that this is a feature of the WSGI workers handler (circus/gunicorn/uwsgi)?\nYes.. What is the status of this ? Is it done already ?\n. Looks like it's done.\n\n. No risky change. Merging.\n. Excellent!\nThanks!\n. Raw Python internals might not be the most convenient way :)\n@floomy would you expect something like a shell script to purge, or your need would a priviledged HTTP API to be manipulated from the app?\n. Indeed in NGinx there is:\n```\nserver {\n    listen                80;\nlocation /v1 {\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header X-Forwarded-Proto $scheme;\n    proxy_set_header Host $http_host;\n    proxy_redirect off;\n    proxy_intercept_errors on;\n    uwsgi_pass unix:///run/uwsgi/kinto-latest.sock;\n    uwsgi_read_timeout 120;\n    uwsgi_send_timeout 120;\n    include uwsgi_params;\n}\n\n...\n...\n\nlocation / {\n    return 301 https://$host/v1/;\n}\n\n}\n```\n. Thanks !\n. Thanks !\n. > why would you do it this way instead of just keep going in reverse chronological order?\nYeah, I changed it. In the third approach, they both go backwards. One fetches the old records with _before=MIN(...) and the other one fetches the new records with _since=MAX()\n. Good catch!\nFrom what I see with the stacktrace, it looks like there is an existing record whose JSON data is just a string and not an object.\nCould you try to reproduce and send us the step-by-step please ?\nThanks for taking the time to report it !\n. Without more feedback, it is going be hard to tackle...\nAny news @nocturnalwarz ?\nThanks !\n. Closing for lack of feedback.\n. The current behaviour comes from this line of code : https://github.com/mozilla-services/cliquet/blob/2.15.0/cliquet/authorization.py#L86\n. We should work on this patch to simplify the approache/remove indirections...\n. @Natim, I reworked your PR here https://github.com/Kinto/kinto/commit/cbcb9bb02f8c3909866a75b1ff633b61f9208080\nIf you agree with the approach, I can push it here :)\n. pair=@Natim\n. Can we close this ?\n. Great!\nYou can indeed follow the approach you took in #859, but the algorithm to merge is a lot more challenging :) I suggest that you implement all 16 tests provided to make sure we behave as expected. \n\nYou can raise ValueError from the utils module, and then in resource/__init__.py transform them to 400 responses with raise_invalid().\n\nIn a second time, we'll want to make sure that the provided \u00abpatch body\u00bb is valid against the RFC (eg. specified op cannot be dance etc).\nEnjoy! Thanks for your enthusiasm!\n. I would be in favor of moving this to the kinto-dist repo\n. You should still probably: \n- [x] update changelog (easier release process)\n- [x] update API changelog\n- [x] update the API docs\n- [x] increment http protocol version\n. r+\n. This is a client thing I guess. If one walks away with some data, what could do the server? Re-open if relevant :)\n. I marked this as a duplicate of #101 \n. See an example of implementation (for buckets): https://github.com/Kinto/kinto/pull/462/files\n. Since no test existed for that part, I felt lazy to start them :]\n. Will do.\n. no test but r+ :)\n. @magopian your super powers of newcomer could be required here ;) \n. Thanks for your positive feedback! I'll take your comments into account.\n. r+wc :)\n. > is that ok?\nyup!\nyou can merge IMO\n. I can't reproduce locally the timestamp constraint errors of the loadtest_simulation.\nThey seem to always occur on current bucket and collection creation, on the timestamps_pkey constraint.\nThis could be related to this code:\nhttps://github.com/mozilla-services/cliquet/blob/3.0.0/cliquet/storage/postgresql/schema.sql#L154-L158\nwhich inserts a timestamp when could not find one. Unicity can be violated with concurrent transactions.\n\nPS: good news, load tests have approximately 15% more RPS from cliquet 2.15 to cliquet 3\n\n```\nBackendError: IntegrityError: (psycopg2.IntegrityError) duplicate key value violates unique constraint \"timestamps_pkey\"\nDETAIL:  Key (parent_id, collection_id)=(/buckets/blocklist, collection) already exists.\nCONTEXT:  SQL statement \"INSERT INTO timestamps (parent_id, collection_id, last_modified)\n  VALUES (uid, resource, ts)\"\n\nPL/pgSQL function collection_timestamp(character varying,character varying) line 14 at SQL statement\n[SQL: '\\n        SELECT as_epoch(collection_timestamp(%(parent_id)s, %(collection_id)s))\\n            AS last_modified;\\n        '] [parameters: {'parent_id': u'/buckets/blocklist', 'collection_id': 'collection'}]; uid=None; errno=None; agent=python-requests/2.9.1; authn_type=None\nCRITICAL:venusian:\"PUT   /v1/buckets/blocklist/collections/addons\" ? (? ms) (psycopg2.IntegrityError) duplicate key value violates unique constraint \"timestamps_pkey\"\nDETAIL:  Key (parent_id, collection_id)=(/buckets/blocklist, collection) already exists.\n```\n. Would you be willing to merge it like this and go forward ?\n. Since the thread on bugzilla is pretty big, I suggest to read this instead : https://github.com/mozilla-services/docs/pull/60/files\n. :+1: \n. Thanks @lavish205 for your patience!\n. The fix was merged in cliquet https://github.com/mozilla-services/cliquet/pull/675\n. @almet r?\n. Please use this template for the configuration:\nhttps://github.com/Kinto/kinto-dist/blob/master/config/kinto.ini\n. Great! Closing this.\n. Thanks @woovar !\nIndeed, as @Natim  said, that's the best way to keep backward compatibility for users who expect the default bucket to work without having it in their configuration.\nBut since the plugin is present in the default configuration file (output with kinto init) I think we can even get rid of these lines and avoid the exclude setting.\nIt would require to add a breaking changes entry in the changelog, to invite users to check that the kinto.plugins.default_bucket is present in the includes setting if they expect it.\n. Great ! Thanks a lot for this contribution !\nThere is a conflict in the README file. I can merge and rebase this branch for you if you don't want to bother with that. Let me know :)\n. Good catch!\nr+\n. - [x] wait for Cliquet release\n- [x] update changelog\n. @Sayli-Karnik, if you want to implement this issue: https://github.com/Kinto/kinto-changes/issues/6, you should contribute it to the repository there!\nIt is generally a good practice to keep repositories uncoupled and independant :)\nYour changes are mostly valid, it's just they belong there ;)\n. FWIW @ptgamr did https://github.com/ptgamr/kinto-github-token ;) . Velruse has not received any commit for 3 years.\n. We went for OpenID Connect support only. It's enough for now :). Done in #519\n. I could fix the problem easily :)\n. Thanks! This step by step guide for installing python might be useful for some users!\nHowever I am not sure we'd like to grow the get started documentation that much, especially with platform specific stuff.\nI suggested that we put it in a wiki page as we did for PostgreSQL : https://github.com/Kinto/kinto/wiki/How-to-run-a-PostgreSQL-server%3F and link it from there :)\n. Closing for lack of feedback. Don't hesitate to re-open if you like!\n. Is this fixed (as by #516) ?\n. Note: This also applies to authentication settings (e.g multiauth.policy.ipauth1.use)\n. :+1: \nRegarding notifications do you think it would be worth adding a mention in the documentation ?\n. The No handlers could be found for logger message is just a warning.\nIf you say that you still have the error after running the migrate command, it is preoccupying.\nWhich version did you have before upgrading? I'll try to reproduce.\n. Thanks for this contribution! This is ready to merge!\n. @lavish205 do you need help on this ?\n. Me neither to be honest !\nLet's close this and let's see if somebody is comfortable with that :)\nThanks for your patience, keep up!\n. What is the error that you have when you run the tests locally ?\n. If you scroll further you should be able to find some details about the original error\n. @vsham20 can we help on this ?\n. Closing for lack of activity..\nThanks everyone involved!\nFeel free to reopen and revamp the work on this! \n. From your branch:\n$ sudo docker build .\n...\nStep 6 : CMD kinto --ini $KINTO_INI migrate && kinto --ini $KINTO_INI start\n ---> Running in 6c86618684bf\n ---> 766361468fef\nRemoving intermediate container 6c86618684bf\nSuccessfully built 766361468fef\n$ sudo docker run 766361468fef\n2016-03-30 15:44:52,416 INFO  [venusian][MainThread] kinto 2.1.0.dev0 starting.\nr+\n. > This breaks the links \nIt only breaks the anchor right?\n. FYI, I cannot reproduce, at least with the PostgreSQL backend. Undefined values are at the end with ascending sort, and at the beginning with descending sort (-score).\n. Fixed http://kinto.readthedocs.org/en/latest/api/1.x/cliquet/batch.html \n. Currently the Docker container uses pserve which does not support https.\nShould we use uwsgi instead?\n. @domtallo do you have a conclusion to share ? Maybe to put in the FAQ ?\nThanks for your feedback !\n. Related #327 #402 \n. See Android client https://github.com/intesens/kinto-http-java :)\n. Oh, very nice catch!\n. Yep\n. @magopian Thanks for taking care of this :)\nSomething crucial is missing: a call to migrate in case the db schema was changed. Maybe a mention about semver idea of breaking changes would be a plus: like read changelog... ;)\nAlso, a nit, but should the upgrade docs be in get started ? Maybe production ?\n/cc @Natim\n. Something like this would work (with a minimal piece of code in cliquet): \npython\n@resource.register(name='record',\n                   collection_path=_parent_path + '/records',\n                   record_path=_parent_path + '/records/{{id}}',\n                   renderers=[('geojson', 'application/vnd.geo+json'), ('rss', 'application/rss+xml')])\nBut it is not pluggable, external plugins cannot register new mimetypes.\nWe could read them from settings though:\nini\nkinto.record_renderers = geojson:application/vnd.geo+json\n                         rss:application/rss+xml\nThoughts?\n. No concrete use-case right now, closing.\n. The issue #454 was transformed into a pull-request. Closing this.\n. good catch!\nI believe we can add it to the MANIFEST.in at least. But you're right the paths can be tedious to find within the pip site-packages folders...\nMentionning the file URL online also makes sense.\nAs a stretch goal, we could also run uwsgi in the Dockerfile to make sure the app.wsgi runs properly there\n. It should redirect to /v1/ I guess.\n. @almet r?\n. Removed easy-pick label since I could not reproduce.\n. Closing until we reproduce.\n. Removed easy-pick since I could not reproduce in a test\n. Closing until we reproduce.\n. @Natim r?\n. @Natim r?\n. Done\n. How do you do extra_requires ? Or this long_description=README + \"\\n\\n\" + CHANGELOG + \"\\n\\n\" + CONTRIBUTORS,\n. Is this a popular solution in the Python community? \n. r+wc\n. 'cuz of this: https://github.com/mozilla-services/cliquet/blob/3.1.2/cliquet/storage/postgresql/schema.sql#L154-L157\n. @Natim @tarekziade @phrawzty  was it 1.8 ?\n. I could reproduce:\n$ psql -h localhost -p 5432 -U postgres\nsql\nCREATE DATABASE kinto18;\nCREATE USER kinto18 WITH PASSWORD 'postgres';\nGRANT ALL PRIVILEGES ON DATABASE kinto18 TO kinto18;\ngit clone git@github.com:Kinto/kinto.git\ncd kinto\ngit co 1.8.0\ndiff\ndiff --git a/config/kinto.ini b/config/kinto.ini\nindex a19006e..e4aa1ed 100644\n--- a/config/kinto.ini\n+++ b/config/kinto.ini\n@@ -12,12 +12,12 @@ use = egg:kinto\n #\n # http://kinto.readthedocs.org/en/latest/configuration/settings.html#storage\n #\n-# kinto.storage_backend = cliquet.storage.postgresql\n-# kinto.storage_url = postgres://postgres:postgres@localhost/postgres\n-# kinto.cache_backend = cliquet.cache.postgresql\n-# kinto.cache_url = postgres://postgres:postgres@localhost/postgres\n-# kinto.permission_backend = cliquet.permission.postgresql\n-# kinto.permission_url = postgres://postgres:postgres@localhost/postgres\n+kinto.storage_backend = cliquet.storage.postgresql\n+kinto.storage_url = postgres://kinto18:postgres@localhost/kinto18\n+kinto.cache_backend = cliquet.cache.postgresql\n+kinto.cache_url = postgres://kinto18:postgres@localhost/kinto18\n+kinto.permission_backend = cliquet.permission.postgresql\n+kinto.permission_url = postgres://kinto18:postgres@localhost/kinto18\nWe didn't have the kinto command at the time:\n$ virtualenv env\n$ source env/bin/activate\n$ pip install \"cliquet[postgresql]\"\n$ python setup.py install\n$ cliquet --ini config/kinto.ini migrate\n$ pserve config/kinto.ini\nFill with some records:\ngit clone git@github.com:mozilla-services/xml2kinto.git\ncd xml2kinto\ngit co onecrl-stable\nKINTO_SERVER=http://localhost:8888 make sync -e\nUpgrade kinto and migrate the database:\npip install -U \"cliquet[postgresql]\"\npip install -U kinto==2.0\nkinto --ini config/kinto.ini migrate\npserve config/kinto.ini\nAnd :bomb: : \nhttp PUT http://0.0.0.0:8888/v1/buckets/staging --auth user:pass\n2016-04-28 23:57:58,123 DEBUG [cliquet.storage.postgresql.pool.QueuePoolWithMaxBacklog][waitress] Connection <connection object at 0x7fc55bb14050; dsn: 'dbname=kinto18 user=kinto18 password=xxxxxxxx host=localhost', closed: 0> checked out from pool\n2016-04-28 23:57:58,129 ERROR [venusian][waitress] \"PUT   /v1/buckets/staging\" ? (? ms) (psycopg2.IntegrityError) null value in column \"last_modified\" violates not-null constraint\nDETAIL:  Failing row contains (staging, , bucket, null, {\"id\": \"staging\"}).\n [SQL: '\\n        WITH delete_potential_tombstone AS (\\n            DELETE FROM deleted\\n             WHERE id = %(object_id)s\\n               AND parent_id = %(parent_id)s\\n               AND collection_id = %(collection_id)s\\n        )\\n        INSERT INTO records (id, parent_id, collection_id, data, last_modified)\\n        VALUES (%(object_id)s, %(parent_id)s,\\n                %(collection_id)s, (%(data)s)::JSONB,\\n                from_epoch(%(last_modified)s))\\n        RETURNING id, as_epoch(last_modified) AS last_modified;\\n        '] [parameters: {'collection_id': 'bucket', 'last_modified': None, 'data': '{\"id\":\"staging\"}', 'object_id': u'staging', 'parent_id': ''}] agent=HTTPie/0.9.2 authn_type=basicauth collection_id=bucket collection_timestamp=1461886924717 errno=110 lang=None uid=6de355038fd943a2dc91405063b91018bb5dd97a08d1beb95713d23c2909748f\n2016-04-28 23:57:58,129 DEBUG [cliquet.storage.postgresql.pool.QueuePoolWithMaxBacklog][waitress] Connection <connection object at 0x7fc55bb14050; dsn: 'dbname=kinto18 user=kinto18 password=xxxxxxxx host=localhost', closed: 0> being returned to pool\n2016-04-28 23:57:58,129 DEBUG [cliquet.storage.postgresql.pool.QueuePoolWithMaxBacklog][waitress] Connection <connection object at 0x7fc55bb14050; dsn: 'dbname=kinto18 user=kinto18 password=xxxxxxxx host=localhost', closed: 0> rollback-on-return, via agent\n2016-04-28 23:57:58,130 CRITI [venusian][waitress] \"PUT   /v1/buckets/staging\" ? (? ms) (psycopg2.IntegrityError) null value in column \"last_modified\" violates not-null constraint\nDETAIL:  Failing row contains (staging, , bucket, null, {\"id\": \"staging\"}).\n [SQL: '\\n        WITH delete_potential_tombstone AS (\\n            DELETE FROM deleted\\n             WHERE id = %(object_id)s\\n               AND parent_id = %(parent_id)s\\n               AND collection_id = %(collection_id)s\\n        )\\n        INSERT INTO records (id, parent_id, collection_id, data, last_modified)\\n        VALUES (%(object_id)s, %(parent_id)s,\\n                %(collection_id)s, (%(data)s)::JSONB,\\n                from_epoch(%(last_modified)s))\\n        RETURNING id, as_epoch(last_modified) AS last_modified;\\n        '] [parameters: {'collection_id': 'bucket', 'last_modified': None, 'data': '{\"id\":\"staging\"}', 'object_id': u'staging', 'parent_id': ''}] agent=HTTPie/0.9.2 authn_type=basicauth collection_id=bucket collection_timestamp=1461886924717 errno=110 exception=Traceback (most recent call last):\n  File \"/home/mathieu/tmp/kinto/env/local/lib/python2.7/site-packages/pyramid/tweens.py\", line 20, in excview_tween\n    response = handler(request)\n  File \"/home/mathieu/tmp/kinto/env/local/lib/python2.7/site-packages/pyramid_tm/__init__.py\", line 101, in tm_tween\n    reraise(*exc_info)\n  File \"/home/mathieu/tmp/kinto/env/local/lib/python2.7/site-packages/pyramid_tm/__init__.py\", line 83, in tm_tween\n    response = handler(request)\n  File \"/home/mathieu/tmp/kinto/env/local/lib/python2.7/site-packages/pyramid/router.py\", line 145, in handle_request\n    view_name\n  File \"/home/mathieu/tmp/kinto/env/local/lib/python2.7/site-packages/pyramid/view.py\", line 541, in _call_view\n    response = view_callable(context, request)\n  File \"/home/mathieu/tmp/kinto/env/local/lib/python2.7/site-packages/pyramid/config/views.py\", line 602, in __call__\n    return view(context, request)\n  File \"/home/mathieu/tmp/kinto/env/local/lib/python2.7/site-packages/pyramid/config/views.py\", line 328, in attr_view\n    return view(context, request)\n  File \"/home/mathieu/tmp/kinto/env/local/lib/python2.7/site-packages/pyramid/config/views.py\", line 304, in predicate_wrapper\n    return view(context, request)\n  File \"/home/mathieu/tmp/kinto/env/local/lib/python2.7/site-packages/pyramid/config/views.py\", line 244, in _secured_view\n    return view(context, request)\n  File \"/home/mathieu/tmp/kinto/env/local/lib/python2.7/site-packages/pyramid/config/views.py\", line 353, in rendered_view\n    result = view(context, request)\n  File \"/home/mathieu/tmp/kinto/env/local/lib/python2.7/site-packages/pyramid/config/views.py\", line 507, in _requestonly_view\n    response = view(request)\n  File \"/home/mathieu/tmp/kinto/env/local/lib/python2.7/site-packages/cornice/service.py\", line 571, in wrapper\n    response = view_()\n  File \"/home/mathieu/tmp/kinto/env/local/lib/python2.7/site-packages/cliquet/resource/__init__.py\", line 404, in put\n    unique_fields=unique)\n  File \"/home/mathieu/tmp/kinto/env/local/lib/python2.7/site-packages/cliquet/resource/model.py\", line 294, in create_record\n    unique_fields)\n  File \"/home/mathieu/tmp/kinto/env/local/lib/python2.7/site-packages/cliquet/resource/model.py\", line 177, in create_record\n    auth=self.auth)\n  File \"/home/mathieu/tmp/kinto/env/local/lib/python2.7/site-packages/cliquet/storage/postgresql/__init__.py\", line 237, in create\n    inserted = result.fetchone()\n  File \"/usr/lib/python2.7/contextlib.py\", line 35, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/home/mathieu/tmp/kinto/env/local/lib/python2.7/site-packages/cliquet/storage/postgresql/client.py\", line 53, in connect\n    raise exceptions.BackendError(original=e)\nBackendError: IntegrityError: (psycopg2.IntegrityError) null value in column \"last_modified\" violates not-null constraint\nDETAIL:  Failing row contains (staging, , bucket, null, {\"id\": \"staging\"}).\n [SQL: '\n         WITH delete_potential_tombstone AS (\n             DELETE FROM deleted\n              WHERE id = %(object_id)s\n                AND parent_id = %(parent_id)s\n                AND collection_id = %(collection_id)s\n         )\n         INSERT INTO records (id, parent_id, collection_id, data, last_modified)\n         VALUES (%(object_id)s, %(parent_id)s,\n                 %(collection_id)s, (%(data)s)::JSONB,\n                 from_epoch(%(last_modified)s))\n         RETURNING id, as_epoch(last_modified) AS last_modified;\n         '] [parameters: {'collection_id': 'bucket', 'last_modified': None, 'data': '{\"id\":\"staging\"}', 'object_id': u'staging', 'parent_id': ''}] lang=None uid=6de355038fd943a2dc91405063b91018bb5dd97a08d1beb95713d23c2909748f\n. Problem found: no triggers are defined, they must have been lost during migration. This means the migrations test suite misses some expectations !\nProblem, no triggers:\n``` sql\nSELECT tgname FROM pg_trigger;\n tgname \n\n(0 rows)\n```\nRun the full SQL definition of the final schema using psql to fix the migrated one. It is idempotent and does no harm. \nwget https://raw.githubusercontent.com/mozilla-services/cliquet/3.1.2/cliquet/storage/postgresql/schema.sql -O schema-3.1.2.sql\n$ psql -h localhost -p 5432 -U postgres\n\\c kinto18;\n\\i schema-3.1.2.sql\n...\n...\nThe triggers are back:\n```\nSELECT tgname FROM pg_trigger;\n      tgname\n\n\ntgr_records_last_modified\n tgr_deleted_last_modified\n(2 rows)\nTime: 0,303 ms\n```\nThe creation now works \\o/ \n```\nhttp PUT http://0.0.0.0:8888/v1/buckets/staging --auth user:pass\nHTTP/1.1 201 Created\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 158\nContent-Type: application/json; charset=UTF-8\nDate: Thu, 28 Apr 2016 22:06:39 GMT\nEtag: \"1461888399161\"\nLast-Modified: Fri, 29 Apr 2016 00:06:39 GMT\nServer: waitress\n{\n    \"data\": {\n        \"id\": \"staging\", \n        \"last_modified\": 1461888399161\n    }, \n    \"permissions\": {\n        \"write\": [\n            \"basicauth:6de355038fd943a2dc91405063b91018bb5dd97a08d1beb95713d23c2909748f\"\n        ]\n    }\n}\n```\nThe previous records are here:\nhttp GET http://0.0.0.0:8888/v1/buckets/blocklists/collections/certificates/records --auth user:pass\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=UTF-8\nEtag: \"1461886924753\"\n...\nTotal-Records: 10\nThe blocklist update works:\nmake update-blocklist-file\nKINTO_SERVER=http://localhost:8888 make sync -e\n.venv-python2.7/bin/xml2kinto -s http://localhost:8888\nWorking on 'http://localhost:8888'\nReading data from '/home/mathieu/tmp/xml2kinto/blocklist.xml'\nSyncing to http://localhost:8888certificates/records\n- 104 records to create.\n- 0 records to delete.\n- 0 records to update.\nDone!\nNew records are here:\nhttp GET http://0.0.0.0:8888/v1/buckets/staging/collections/certificates/records --          \nHTTP/1.1 200 OK\nContent-Length: 32020\nContent-Type: application/json; charset=UTF-8\n...\nTotal-Records: 113\n:smile: \n. Looks like we're done with this ;) Cliquet now became kinto.core!\n. done!\n\u279c  ~ curl -I https://kinto.readthedocs.io\nHTTP/1.1 302 FOUND\nServer: nginx/1.4.6 (Ubuntu)\nDate: Fri, 29 Apr 2016 09:29:55 GMT\nContent-Type: text/html; charset=utf-8\nContent-Length: 229\nConnection: keep-alive\nLocation: https://kinto.readthedocs.io/en/stable/\n. Thanks! :+1: \n. Resolved upstream. A new fix was proposed upstream https://github.com/rtfd/readthedocs.org/pull/3302. Bug still there ;) . Awesome! thanks !\nr+ : my concerns are mostly nitpicks that you can choose to ignore or address\n. Glad you tackled this! Thanks!\nThe tests are a bit indigest, but I can't see any better way.\nLGTM\n. Unfortunately not yet. But I can start to write a few lines.... Closing because the order matches more or less:\n\n. Mago on fire \ud83c\udf89 \ud83d\udc4f \n. Your PR was merged. Please close once deployed ;) GG!. Bug is still there.... OMG this is fixed :tada: :tada: !. r+wc\n. > I started to wonder if a more useful \"first steps\" document might use a client library and hide this complexity from the user.\nYes good idea!\n\n[...] perhaps for client implementors\n\nI don't think client implementors are the first target. (Well, actually they would if this doc would be focused on the server itself and if we had some eco-system docs elsewhere.).\nAn idea would be to focus on front-end/mobtile devs that don't want to bother with the server just yet. Maybe some recipes for some common use-cases ?\n. r+ for me, if I'm not the only one to agree on the renaming of get started to install you can merge ;)\nThanks a lot!\n. r+\n. Closing because the bug could not be reproduced.\n. >  If we want to avoid any leakage of information, we should firewall the access to those /__VIEWS \nApparently this is not going to be the case: https://bugzilla.mozilla.org/show_bug.cgi?id=1268823#c2\n. Maybe we could add a specify \u00abtag\u00bb in setup.py in order to mark this release as alpha/beta/release candidate? Or maybe not, release, get early feedback, release fix :)\n. Here https://github.com/Kinto/kinto/blob/master/kinto/core/initialization.py#L441-L483 is where we already tinker with settings...\nNot an emergency, but we may have to at least make it super clear here: \nhttps://github.com/Kinto/kinto/releases/tag/3.0.0\n. Oh, but you forgot kinto.logging_renderer and kinto.event_listeners !\nNot a big deal :)\n. If you have some bandwidth you can do logging_renderer and we release a minor. For the other one it only applies to the default redis listener, which I don't think it's is massively used... No need to spend energy on this!\n. > considered as a know limitation/bug\nI don't think it's a bug. A limitation yes. See #442 for a related discussion.\nIndeed, with our current permission tree, if the client has not the permission to read the parent object, it cannot see its attributes. Although it can obtain a list of the children (full or partial) that it can read/write.\n\nMaybe we need a new enumerate permission type?\n\nWhat would be the difference with read?\n\nallowing to retrieve the tree of available resources for a given authenticated user\n\nThat sounds acceptable and useful ! The only detail is that we would not be able to obtain attributes of parent object for which we have no read permission.\n$ http http://kinto/v1/access\n{\n  \"buckets\": [\n    {\n      url: \"/buckets/buck\",\n      data: {\n          id: \"buck\",\n      },\n      permissions: {\n        write: [...], read: [...]\n      },\n      collections: [],\n   }, {\n      url: \"/buckets/buck\",\n      collections:  [{\n          id: \"coll\",\n          permissions: {\n            write: [...], read: [...]\n          }\n        },\n        ...\n      ]\n    },\n    ...\n  ]\n}\n. Actually an export of the permission backend will be useful: a tree of {parentURI, URI, id}\n. One idea: GET /permissions --auth user:pass\njs\n{\n    buckets: [\n        {\n            id: \"certificates\",\n            uri: \"/buckets/certificates\",\n            permissions: [\"read\", \"write\", \"collection:create\"]\n        },\n        {\n            id: \"blog\",\n            uri: \"/buckets/blog\",\n            permissions: []\n            collections: [\n                {\n                    id: \"articles\",\n                    uri: \"/buckets/blog/collections/articles\",\n                    permissions: [],\n                    records: [\n                        {\n                            id: \"3c6cd52c-75ba-46da-8bf3-d658ddb204a0\",\n                            uri: \"/buckets/blog/collections/articles/records/3c6cd52c-75ba-46da-8bf3-d658ddb204a0\",\n                            permissions: [\"read\"]\n                        }\n                    ]\n                },\n                {\n                    id: \"comment\",\n                    uri: \"/buckets/blog/collections/comments\",\n                    permissions: [\"record:create\"],\n                    records: [\n                        {\n                            id: \"f6b4efaf-4cea-4fae-99b8-07fa876aee92\",\n                            uri: \"/buckets/blog/collections/articles/records/f6b4efaf-4cea-4fae-99b8-07fa876aee92\",\n                            permissions: [\"read\", \"write\"]\n                        }\n                    ]\n                }\n            ]\n        }\n    ]\n}\nCons:\n- Can dump millions of entries (Idea: strip children if permission on parent)\n- Query to permission backend can be resource greedy\n- Must explicit whole list of permission (eg. write gives read and <child>:create\n. After discussing with @n1k0, we realized that it would not very convenient to have it as a tree.\nSomething flat like this would do it:\n```\nGET /permissions\n{\n    \"data\": [\n        {\n            \"uri\": \"/buckets/toto\",\n            \"resource\": \"bucket\",\n            \"bucket_id\": \"toto\",\n            \"permissions\": [\"read\", \"write\"]\n        },\n        {\n            \"uri\": \"/buckets/tata\",\n            \"resource\": \"bucket\",\n            \"bucket_id\": \"tata\",\n            \"permissions\": [\"collection:create\"]\n        },\n        {\n            \"uri\": \"/buckets/toto/collections/test\",\n            \"resource\": \"collection\",\n            \"bucket_id\": \"toto\",\n            \"collection_id\": \"test\",\n            \"permissions\": [\"record:create\"]\n        },\n        {\n            \"uri\": \"/buckets/toto/collections/test/records/d5db6e57-2c10-43e2-96c8-56602ef01435\",\n            \"resource\": \"record\",\n            \"bucket_id\": \"toto\",\n            \"collection_id\": \"test\",\n            \"record_id\": \"d5db6e57-2c10-43e2-96c8-56602ef01435\"\n            \"permissions\": [\"write\"]\n        }\n    ]\n}\n```\nIn a second step, to reduce the load, it could even be filtrable:\n- For bucket and collection only :  /permissions?in_resource=bucket,collection\n- Every writable record in this bucket: /permissions?bucket_id=test&permission=write&resource=record\nWhat do you think?\n. The only way to get of this is to rely on a SEQUENCE to build timestamps. I suggest that we get rid of the fact that timestamps are based on clock and make them fully opaque (hence the label protocol:v2)\n. The records_pkey error that we can see in the mentioned Sentry error is indeed easy to catch, since it's a conflict on (id, parent_id, collection_id), and not on timestamp unicity (idx_records_parent_id_collection_id_last_modified).\nHowever, how should we react to it? If it is the same user on both ends, then do nothing or overwrite is fine. But if it's two different users, then the second one should probably receive a unicity error. edit: raising a unicity error seems fine in both case actually, but may not be technically feasible since ON CONFLICT RAISE ERROR is not available :). Yes, there are mainly two scenarios:\n two overlapping requests trying to create the same object (records_pkey)\n two overlapping requests (same millisec) creating/updating/deleting objects within the same parent (idx_records_parent_id_collection_id_last_modified)\nThe constraint error is not raised when the operation is performed but when the transaction is committed \u2014 just before serving the response.\nThe approach we took in #1120 does not seem right. Not only that it only fixes the first one, but also mainly because it tries to catch and handle an error that is necessary to maintain a consistent DB state. For example, a rejected insertion in storage rollbacks the changes that were made in permissions. If we swallow it, what do we do with permissions? And why would we merge the attributes of the rejected object into the one that was concurrently committed?\nFor the second constraint, one approach (as suggested on SO) is to rely on PG sequences. But that breaks our protocol since timestamps would not be epoch anymore. \nCurrently, I don't see any obvious way to magically handle these situations and prevent error responses. IMO one of the concurrent requests has to be accepted, and the other ones rejected as conflict. \nSo maybe, we should simply just rework our error response semantics. When a database error occurs, we return a 503 Service Unavailable \u2014 why not. But what if we would return a 409 Conflict when an integrity constraint occurs? In the end, that's exactly what is happening. And QA wouldn't have the impression to break the service with concurrent requests.... Closing for lack of interest. I would be in favor of moving them outside (if possible), and let test helpers in something like kinto.testing.\nI don't know if it could help us decide but we currently specify the test suite in setup.py https://github.com/Kinto/kinto/blob/master/setup.py#L105 \n. The original issue is more than a year old, I close. Feel free to reopen if you think this is still relevant...\n. Ok, let's close it then? . Closing until we have a concrete use-case.. > into process growing indefinitely in memory ?\nWe use postgresql on stage AFAIK so no problem about crashing the web head I believe\n. Limiting cache size applies to every backend I think. Writing to cache could prune the oldest data until the total size is bigger than a limit. \n. This requires:\n- Generalize storage migration mecanism to cache backend\n- Add a hits attribute to track calls to cached entries\n- Add a created attribute to track insertion/refresh\n- Compute size of value and denormalize total\n- Before inserting: if total > max_size then sorte entries by hits+created and delete keys until total < max_size\n. r+\n. r+with nit :)\n. Thanks Ethan for going further with this!\nCan you explicit the changes you made to the resources docs please?\nAlso, I would be in favor of hiding the kinto-core docs until they are not ready. I read them quickly and I think they bring more confusion than clarity. So as you said this will have to be tackled later\n. r+ on this. We could always go further, but this is a huge step forward! Thanks Ethan!\n. Nice!\nThanks for taking the time!\nSeems like you're doing something cool ;)\n. Fixed by #650 \n. Also applies to default bucket subrequests. \u2192 implement https://tools.ietf.org/html/rfc7396\n. Unlikely to happen. Leaving #621 . Fixed!\n. Closing because I'm pretty sure the current behaviour is fine:\nhttp://kinto.readthedocs.io/en/stable/api/1.x/buckets.html#delete-all-buckets\n@n1k0 please reopen if you remember why we had opened that.\n. > Do you think we could add a test to validate that?\nAlthough we have generic tests in kinto.core for the load_default_settings() mecanism, I don't think we have tests for its usage on particular kinto settings (each one defined in kinto.__init__:DEFAULT_SETTINGS)\n. https://larlet.fr/david/blog/2016/specifications-apis/\n. Some notes/ideas:\nInstead of generating the Swagger from the source code, which seems very hard based on the services definitions only. We could edit it by hand and then make sure it remains up-to-date with a plugin like pyramid-swagger\nEditing it by hand can be tedious in our case since we have many properties that are repeated accross the API.\nWe can imagine to edit by hand several small pieces of yaml/json and have a way to assemble them towards a final big spec file. Also, depending on settings or what plugins are installed the list of endpoints may change... I wonder how that should come into play.\n. :+1: \nWe can merge like this and add a dedicated issue Remove structlog initialization hack when new version is released\n. Hey guyz! Cool to see you here ;)\nBefore you start implementing the bodies of this scaffold, can you detail a bit the value added by this new backend?\nFor example, I remember a while ago that AlwaysData was stuck with an old Postgresql version, and Mongo was mentioned.\nSince it will add some setup/integration \u00aboverhead\u00bb we can list pros/cons and see if it is relevant to put it in the core or as a community-plugin!\nThanks for starting this!\n. The browser automatically adds If-None-Match and If-Modified-Since based on the first responses. The server returns 304 and the client reuses the former response.\nI could fix the fiddle with this hack:\njs\n  return fetch(base + path, {\n    headers: {\n      Authorization: \"Basic \" + btoa(`${user}:${pass}`),\n      \"If-None-Match\": \"\",\n      \"If-Modified-Since\": \"\",\n    }\n  })\nI read the specs:\n- 13.4 Response Cacheability \n  https://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html#sec13.4\n- 14.9.1 What is Cacheable\n  https://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.8\nI felt dumb, I don't understand 100% of it.\nAs @almet recommended, I digged in Gecko source code. And found the piece of code that is responsible for the behaviour that we see\nI could understand that the client tries to \u00abvalidate\u00bb its cache with those If-Last-Modified and If-None-Match. In our case, the server returns 304 (ie. no new object created meanwhile) , so the client thinks it can re-use its cache!\nCache-Control: no-store should do it.\nThen, when my eyes had burnt, I found a very useful page, by Google, which makes it very clear:\nhttps://developers.google.com/web/fundamentals/performance/optimizing-content-efficiency/http-caching\n\n\u201cno-cache\u201d indicates that the returned response cannot be used to satisfy a subsequent request to the same URL without first checking with the server if the response has changed. As a result, if a proper validation token (ETag) is present, no-cache will incur a roundtrip to validate the cached response, but can eliminate the download if the resource has not changed.\nBy contrast, \u201cno-store\u201d is much simpler, as it simply disallows the browser and all intermediate caches to store any version of the returned response - e.g. one containing private personal or banking data. Everytime the user requests this asset, a request is sent to the server and a full response is downloaded each and every time.\n\nI came back to the spec. This is still... opaque.\n\n14.9.2 What May be Stored by Caches\nno-store\n   The purpose of the no-store directive is to prevent the inadvertent release or retention of sensitive information (for example, on backup tapes). [...]\n\n\n. r+\n. Fixed in #685\n. > Using basic auth we could return the user part.\nNo. There is no user part. We have invited our users to use a token:!\n. Actually, I fear that this introduces some confusion with the user id to be used in permissions definitions...\nWe could let the client do these calls no? \nI put a -1 on the idea, but I may be wrong, please explain why it makes sense to do on the server side :) \n. > > No. There is no user part. We have invited our users to use a token:!\n\nWell does it makes sense with the admin too?\n\nIn theory, the kinto-admin should adapt to the notions of the protocol. Even if it means replacing the username and password fields of basic auth by a single \u00abtoken\u00bb field.\nMaybe this is not possible in practice...\n(Related  #297 and #395)\n\nI would like to find a way to do it that works regardless of the login method.\n\nYes, I think that is the main argument in favor of doing this on the server side.\n. > We never choose to prevent people from using username:api-key did we?\nIndeed :)\n. Closing...\nFeel free to reopen if you have some opinion on this :)\n. Final approval ?\n. ~~Did not~~ COULD reproduce with current master and memory backend:\n```\necho '{\"permissions\": {\"collection:create\": [\"system.Everyone\"]}}' | http PUT :8888/v1/buckets/toto --auth demo:\nHTTP/1.1 201 Created\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Vary, Backoff\nContent-Length: 223\nContent-Type: application/json; charset=UTF-8\nDate: Tue, 24 May 2016 12:55:57 GMT\nEtag: \"1464094557039\"\nLast-Modified: Tue, 24 May 2016 12:55:57 GMT\nServer: waitress\nVary: Authorization\n{\n    \"data\": {\n        \"id\": \"toto\", \n        \"last_modified\": 1464094557039\n    }, \n    \"permissions\": {\n        \"collection:create\": [\n            \"system.Everyone\"\n        ], \n        \"group:create\": [], \n        \"read\": [], \n        \"write\": [\n            \"basicauth:0dee39e8946c74dd57d7e63987200f62365d7b96a5974e5f5f2dd68ec78af599\"\n        ]\n    }\n}\n```\n```\nhttp PUT :8888/v1/buckets/titi/collections/titi\nHTTP/1.1 201 Created\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Vary, Backoff\nContent-Length: 95\nContent-Type: application/json; charset=UTF-8\nDate: Tue, 24 May 2016 12:58:44 GMT\nEtag: \"1464094724551\"\nLast-Modified: Tue, 24 May 2016 12:58:44 GMT\nServer: waitress\nVary: Authorization\n{\n    \"data\": {\n        \"id\": \"titi\", \n        \"last_modified\": 1464094724551, \n        \"schema\": {}\n    }, \n    \"permissions\": {\n        \"write\": [\n            null\n        ]\n    }\n}\n```\n. r+\n. r+ with feature version bump\n. r+\n. r+!\n. I think we should still document it somewhere in the API docs, no ?\n. @Natim r?\n@n1k0 feedback?\n. > feedback+++\nSo far it's behind an experimental_ setting that is false by default. I suggest that we wait for the implementation to be done in kinto-admin to enable it officially (since we may discover flaws...)\n. > I'd like to make it return only bucket and collection by default and records if we ask for it or at least let the ability to select the kind of records we want to list.\nI guess your concern is optimization. Let's keep filtering and optimization for another issue/PR and keep this experimental feature small and subject to breaking changes (hence the name experimental)\n. final r+ ?\n. Would you prefer to put in a plugin while it is not used in kinto-admin (like kinto.plugins.permissions_endpoint) ?\n/cc @n1k0 \n. I was sure that it was the case... :(\n. It is the case as far as I understand\n. > I personalty like the approach.\nToo bad: \n$ kinto start\n...\nFile \"/home/mathieu/Code/Mozilla/kinto/.venv/local/lib/python2.7/site-packages/timeoutcontext-1.0.0-py2.7.egg/timeoutcontext/_timeout.py\", line 68, in _replace_alarm_handler\n    raise_timeout)\nValueError: signal only works in main thread lang=None uid=None\n2016-05-27 12:05:03,265 INFO  [kinto.core.initialization][waitress] \"GET   /v1/__heartbeat__\" 500 (2 ms) request.summary agent=HTTPie/0.9.2 authn_type=None errno=999 lang=None time=2016-05-27T12:05:03 uid=None\n. From what I could study, in order to fix this bug, we need to remove the hacks in Cornice. \nEspecially the part that rebuilds the Colander schema from scratch there. It prevents us to define a custom validator at the resource level that could make sure that at least one of data or permission is provided in body.\n. +1 for API\n. r+\n. Updated. I also added some tests about posting with existing id. I was sure we had some! \n. Duplicate of #345 ? \n. I could not reproduce locally with the memory, redis nor postgresql backends :(\necho '{\"permissions\": {\"write\": [\"system.Everyone\"]}}' | http -v PUT :8888/v1/buckets/file-demo --auth user:pass\necho '{\"permissions\": {\"write\": [\"system.Everyone\"]}}' | http -v PUT :8888/v1/buckets/file-demo/collections/attachments --auth user:pass\n{\"responses\":[{\"status\":201,\"path\":\"/v1/buckets/file-demo/collections/attachments/records\",\"body\":{\"data\":{\"field1\":\"bulk1\",\"__attachment__\":\"data:image/png;name=ama.png;base64,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\",\"last_modified\":1465483065175,\"id\":\"fcce9869-7329-479c-9730-f51955637bc3\"},\"permissions\":{\"write\":[\"basicauth:33975331adc14b6cf6655d1a3dc342a75299c4d76ca81ff098ebd1f4ade2d6e3\"]}},\"headers\":{\"Access-Control-Allow-Origin\":\"*\",\"Content-Type\":\"application/json; charset=UTF-8\",\"Content-Length\":\"5027\",\"Access-Control-Expose-Headers\":\"Retry-After, Content-Length, Alert, Backoff\"}},{\"status\":201,\"path\":\"/v1/buckets/file-demo/collections/attachments/records\",\"body\":{\"data\":{\"field1\":\"bulk2\",\"__attachment__\":\"data:image/svg+xml;name=kinto4.svg;base64,<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!-- Created with Inkscape (http://www.inkscape.org/) -->

<svg
   xmlns:dc="http://purl.org/dc/elements/1.1/"
   xmlns:cc="http://creativecommons.org/ns#"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:svg="http://www.w3.org/2000/svg"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:xlink="http://www.w3.org/1999/xlink"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   width="210mm"
   height="297mm"
   viewBox="0 0 744.09448819 1052.3622047"
   id="svg2"
   version="1.1"
   inkscape:version="0.91 r13725"
   sodipodi:docname="kinto4.svg">
  <defs
     id="defs4">
    <linearGradient
       id="linearGradient4885"
       inkscape:collect="always">
      <stop
         id="stop4887"
         offset="0"
         style="stop-color:#ffdd55;stop-opacity:1;" />
      <stop
         id="stop4889"
         offset="1"
         style="stop-color:#ffdd55;stop-opacity:0.42941177" />
    </linearGradient>
    <linearGradient
       inkscape:collect="always"
       xlink:href="#linearGradient4242"
       id="linearGradient4622-5"
       gradientUnits="userSpaceOnUse"
       gradientTransform="matrix(0.61370533,0,0,0.48783313,-329.02764,503.67443)"
       x1="-252.11148"
       y1="-370.70154"
       x2="-145.7482"
       y2="-388.2449" />
    <linearGradient
       inkscape:collect="always"
       id="linearGradient4242">
      <stop
         style="stop-color:#ffdd55;stop-opacity:1;"
         offset="0"
         id="stop4244" />
      <stop
         style="stop-color:#ffdd55;stop-opacity:0;"
         offset="1"
         id="stop4246" />
    </linearGradient>
    <linearGradient
       inkscape:collect="always"
       xlink:href="#linearGradient4242"
       id="linearGradient4624-1"
       gradientUnits="userSpaceOnUse"
       gradientTransform="matrix(0.61370533,0,0,0.48783313,-338.5355,504.18575)"
       x1="-252.11148"
       y1="-370.70154"
       x2="-145.7482"
       y2="-388.2449" />
    <linearGradient
       inkscape:collect="always"
       xlink:href="#linearGradient4242"
       id="linearGradient4620-8"
       gradientUnits="userSpaceOnUse"
       gradientTransform="matrix(0.61370533,0,0,0.48783313,-317.17967,503.03289)"
       x1="-252.11148"
       y1="-370.70154"
       x2="-145.7482"
       y2="-388.2449" />
    <radialGradient
       inkscape:collect="always"
       xlink:href="#linearGradient4885"
       id="radialGradient4883"
       cx="488.17834"
       cy="308.56741"
       fx="488.17834"
       fy="308.56741"
       r="85.670303"
       gradientTransform="matrix(7.920429,-2.6488595,1.6919624,5.0591841,-3897.7267,76.716583)"
       gradientUnits="userSpaceOnUse" />
  </defs>
  <sodipodi:namedview
     id="base"
     pagecolor="#ffffff"
     bordercolor="#666666"
     borderopacity="1.0"
     inkscape:pageopacity="0.0"
     inkscape:pageshadow="2"
     inkscape:zoom="0.7"
     inkscape:cx="400.26903"
     inkscape:cy="952.02956"
     inkscape:document-units="px"
     inkscape:current-layer="layer1"
     showgrid="false"
     showguides="true"
     inkscape:guide-bbox="true"
     inkscape:window-width="1920"
     inkscape:window-height="1016"
     inkscape:window-x="72"
     inkscape:window-y="27"
     inkscape:window-maximized="1" />
  <metadata
     id="metadata7">
    <rdf:RDF>
      <cc:Work
         rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type
           rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
        <dc:title></dc:title>
      </cc:Work>
    </rdf:RDF>
  </metadata>
  <g
     inkscape:label="Layer 1"
     inkscape:groupmode="layer"
     id="layer1">
    <text
       xml:space="preserve"
       style="font-style:normal;font-weight:normal;font-size:158.06756592px;line-height:125%;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#333333;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;"
       x="74.834732"
       y="367.14319"
       id="text4865"
       sodipodi:linespacing="125%"><tspan
         sodipodi:role="line"
         id="tspan4867"
         x="74.834732"
         y="367.14319"
         style="-inkscape-font-specification:Ubuntu;font-family:Ubuntu;font-weight:normal;font-style:normal;font-stretch:normal;font-variant:normal;fill:#333333;">Kinto</tspan></text>
    <path
       style="opacity:1;fill:url(#radialGradient4883);fill-opacity:1;fill-rule:nonzero;stroke:none;stroke-width:0;stroke-miterlimit:4;stroke-dasharray:none;stroke-opacity:1"
       d="m 595.39812,320.41527 c -5.66538,8.72485 1.80285,20.99114 11.82602,21.2912 9.99981,-0.48339 19.43445,-6.44616 25.50811,-14.25569 5.24131,-6.83345 8.49353,-18.59017 0.8777,-24.95315 -8.53528,-6.04863 -20.42286,-2.00988 -27.76945,4.1385 -4.42289,3.76932 -8.29463,8.31992 -10.44238,13.77914 z m -78.0627,-19.00759 c -7.1305,11.27686 1.80642,27.63038 14.94202,28.35923 15.23773,-0.53658 29.94143,-9.62977 37.74466,-22.70705 4.69338,-8.24962 7.60215,-20.1016 0.53671,-27.91085 -8.55008,-8.35501 -22.26487,-6.2822 -31.97459,-1.19484 -9.07948,5.54138 -17.23959,13.41549 -21.2488,23.45351 z m 102.56769,46.03065 -115.14237,0 -8.59464,21.66491 58.51026,0 56.63212,0 z M 478.901,335.5299 c -7.84981,12.89461 0.97084,32.4054 16.34343,33.81341 20.96067,0.17601 41.37164,-13.6708 49.31999,-33.03912 3.6388,-8.93352 5.17659,-21.00584 -2.77137,-28.15139 -10.1455,-8.63219 -25.99217,-7.70864 -36.81835,-0.81903 -11.36003,6.33158 -21.16416,15.99973 -26.0737,28.19613 z m 41.32722,-27.08113 c -5.5677,8.57441 1.77175,20.62921 11.62211,20.9241 10.25853,-0.53349 19.94839,-6.80323 25.83952,-15.0921 4.87651,-6.84853 7.33956,-18.6512 -0.8058,-24.09815 -9.50654,-5.36268 -21.56444,-0.38226 -28.6834,6.81327 -3.39881,3.21872 -6.22697,7.09311 -7.97243,11.45288 z m 19.23527,13.25206 c -8.24639,14.21437 -0.69756,35.88218 15.97779,39.50046 16.42414,2.16514 33.12928,-4.8222 45.3875,-15.52363 11.94287,-10.61423 20.8263,-26.10893 20.36558,-42.41417 -1.45778,-14.27408 -16.85542,-23.00748 -30.23803,-21.74663 -14.20667,2.17824 -27.60516,9.36504 -37.70637,19.57024 -5.83573,5.9215 -10.60625,12.92222 -13.78647,20.61373 z m 59.84185,24.84205 c -5.43234,8.60662 0.89897,20.20957 10.30617,22.35432 8.67752,2.15756 17.34356,-2.66137 24.36075,-7.30687 8.85374,-6.37324 16.17848,-18.0973 12.27115,-29.1712 -4.55229,-9.74988 -17.42783,-9.88312 -26.0625,-6.15436 -9.13333,3.67471 -17.04817,11.16461 -20.87557,20.27811 z"
       id="path4180"
       inkscape:connector-curvature="0"
       sodipodi:nodetypes="ccccccccccccccccccccccccccccccccccccccccccc" />
    <rect
       transform="matrix(-0.99999552,0.00299217,0.00473552,0.99998879,0,0)"
       y="346.55457"
       x="-499.66916"
       height="10.105114"
       width="190.68703"
       id="rect4606-8"
       style="fill:url(#linearGradient4620-8);fill-opacity:1;stroke:#000000;stroke-width:0;stroke-miterlimit:4;stroke-dasharray:none;stroke-opacity:1" />
    <rect
       transform="matrix(-0.99999552,0.00299217,0.00473552,0.99998879,0,0)"
       y="332.10812"
       x="-510.85962"
       height="10.105114"
       width="190.68703"
       id="rect4608-1"
       style="fill:url(#linearGradient4622-5);fill-opacity:1;stroke:#000000;stroke-width:0;stroke-miterlimit:4;stroke-dasharray:none;stroke-opacity:1" />
    <rect
       transform="matrix(-0.99999552,0.00299217,0.00473552,0.99998879,0,0)"
       y="317.63599"
       x="-519.9292"
       height="10.105114"
       width="190.68703"
       id="rect4610-5"
       style="fill:url(#linearGradient4624-1);fill-opacity:1;stroke:#000000;stroke-width:0;stroke-miterlimit:4;stroke-dasharray:none;stroke-opacity:1" />
  </g>
</svg>
\",\"last_modified\":1465483065179,\"id\":\"bda6eb60-4c78-42cd-b3fe-fc9fc7c66924\"},\"permissions\":{\"write\":[\"basicauth:33975331adc14b6cf6655d1a3dc342a75299c4d76ca81ff098ebd1f4ade2d6e3\"]}},\"headers\":{\"Access-Control-Allow-Origin\":\"*\",\"Content-Type\":\"application/json; charset=UTF-8\",\"Content-Length\":\"10574\",\"Access-Control-Expose-Headers\":\"Retry-After, Content-Length, Alert, Backoff\"}}]}\n@Natim do you have any stacktrace from the dev server?\n. Closing here :)\n. With the history plugin, we can obtain the creation date history?uri={uri}&action=create\n. not unanimous feedback on this. Let's wait for Aymeric feedback :) \n. https://img.shields.io/badge/slack-kinto-e01865.svg\n. > Do i need to modify test cases as well?\nI guess the tests will fail since the code coverage won't be 100%.\nYou'll have to at least add a new test that calls the migration methods with is_dry=True\n. >   leplatrem, what to do next for that issue? (--dry-run one)\nFirst, the tests should pass. \nThen, you need to add a couple of tests where you call initialize_schema with is_dry=True.\n. @lavish205 Are you stuck ? Do you wish we'd take over ? Don't hesitate to tell us :)\n. As I said above, you should leverage the code you've changed, using the tests cases (the coverage results give you the lines that were not executed).\nSome lines will be very easy to reach, some others will not be trivial because you'll have to go through each step of the code to go through every \u00abif\u00bb.\nWe can help for the hardest ones, but I'm sure you can do some of them :)\nBut if you feel discouraged, just tell us, most of the work is done already, it would be awesome to have this feature in version 3.4 ;)\nGood luck!\n. I merged it and added the couple of necessary tests :)\nThanks Lavish for your work on this! This is a really useful feature for production stacks.\n. @Natim do you have an idea why it installs SQLAlchemy==1.1.0b1 with <1.1 in setup?\n. I may not grasp everything that is at stake here, but as Natim suggested: why don't we add the Etag to the body before signing?\nOn the server, it may require a minor change in kinto-signer, and in the client, we have it at hand (see http client and in sync incoming hooks)\nSince you mention the idea of a signed heartbeat, I guess that the above proposition is not enough :)\n. This was implemented in the kinto-signer plugin v.0.7.0.\nClosing :)\n. nice one!\n. > generate the bucket ID of a given authenticated user\nOh. Well this is restricted to the default_bucket plugin...\n. Agree.. Okay my friends! The code is ready! You can review it @Natim !\nMeanwhile I'll update the docs.\n. Final r+ ?\n. \n. Indeed, if you leave %(http_port)s it will be possible to specify the port from the command line with kinto start --port 1234.\nOtherwise, you can set any forced value there.\n. Closing for lack of feedback :)\n. @Natim I just rebased.\n. \n. @glasserc r?\n. Instead of duplicating the imports and the call to strip prefix, it would be a lot nicer to have something like:\n``` py\nfrom kinto.core.utils import instance_uri, list_uri\ninstance_uri(request, 'collection', bucket_id='test', id='toto')\nlist_uri(request, 'record', bucket_id='test', collection_id='tutu')\n```\n. r+\n. Also, the resource_name is the same when bucket and collection are created implicitly in the same request:\n{'resource_name': 'collection', 'user_id': 'basicauth:3a0c56d278def4113f38d0cfff6db1b06b84fcc4384ee890cf7bbaa772317e10', 'action': 'create', 'timestamp': 1467730856639, 'subpath': u'collections/articles/records', 'uri': u'/buckets/default/collections/articles/records'}\n{'resource_name': 'collection', 'user_id': 'basicauth:3a0c56d278def4113f38d0cfff6db1b06b84fcc4384ee890cf7bbaa772317e10', 'action': 'create', 'timestamp': 1467730856639, 'subpath': u'collections/articles/records', 'uri': u'/buckets/default/collections/articles/records'}\n. Fixed in #705\n. @Natim r? \n. You were right, with Python 3:\n```\n  File \"/home/travis/build/Kinto/kinto/kinto/plugins/default_bucket/init.py\", line 35, in create_bucket\nuri=bucket_uri)\n\nFile \"/home/travis/build/Kinto/kinto/kinto/plugins/default_bucket/init.py\", line 74, in resource_create_object\nresource_name, matchdict = view_lookup(request, uri)\n\nFile \"/home/travis/build/Kinto/kinto/kinto/core/utils.py\", line 383, in view_lookup\nfakerequest = Request.blank(path=path)\n\nFile \"/home/travis/build/Kinto/kinto/.tox/py34/lib/python3.4/site-packages/webob/request.py\", line 1332, in blank\nenv = environ_from_url(path)\n\nFile \"/home/travis/build/Kinto/kinto/.tox/py34/lib/python3.4/site-packages/webob/request.py\", line 1409, in environ_from_url\nif SCHEME_RE.search(path):\n\nTypeError: can't use a string pattern on a bytes-like object lang=None uid=3a0c56d278def4113f38d0cfff6db1b06b84fcc4384ee890cf7bbaa772317e10\ninitialization.py          353 INFO     \"POST  /v1/buckets/default/collections/tasks\" 500 (5 ms) request.summary agent=None authn_type=basicauth errno=999 lang=None time=2016-07-06T09:19:23.727999 uid=3a0c56d278def4113f38d0cfff6db1b06b84fcc4384ee890cf7bbaa772317e10\n```\n. > The thing is in development (witch is a even more common use case) you need to have http by default.\nWhat happens if you set kinto.http_scheme to https in development (with kinto start) ?\n. @Prashant-Surya, let's follow natim advice and just make a logger.warning() if the setting was not set to https\n. Hello @Prashant-Surya !\nI saw that you committed a fix for this issue, do you mind opening a pull-request ?\nThanks a lot!\n. Closed by #1078 . - impacted_records \u2192 impacted_objects\n. -  Total-Records -> Total-Objects\n. * Collection endpoint \u2192 Plural endpoint\n* Record endpoint \u2192 Object endpoint. with_deleted=False \u2192 leave_tombstones=False\ninclude_deleted=False \u2192 with_tombstones=False. process_record() \u2192 process_object(). Nope, because in this case records is not a \u00abcore notion\u00bb. Now core has the notion of objects, and buckets, collections, groups, records and accounts leverage it.\nBefore it was confusing because there were the terms records and collections in kinto.core.... @Natim I haven't touched the Redis backend... I think I need your support :) Don't hesitate to push commits, I won't force push...\n\n. > Do you need to grab the deleted when doing the * ?\nThere is a with_deleted parameter.\nDeleting the tombstones is done with purge_deleted\n. > we should probably add a new storage method rather than to change the existing ones so that we can do the delete all without having to return previous records or to create tombstones for instance.\n\nI wonder if we cannot simply add a backend method\n\nThe current implementation of delete_all() in Redis is really poor, especially in terms of performance. Let's first try to improve it, I don't see it as impossible!\nWe can pair and take the time necessary, there is no hurry anyway!\n. > The reason we have implemented the three backends with Postgresql and Redis is to prevent user from having to install both if they want to.\n~~to allow users you mean ?~~  edit: Oh, I see, you mean to prevent redis users to install postgres ?\n\nYou are right that using Redis for the storage backend in production has got some drawbacks but using Postgresql for cache and permission is not a good fit either.\n\nWhy postgresql is not a good fit for cache and permission ?\n\nHaving both is also the guarantee that the interface exposed can work with both NoSQL and SQL database\n\nIntellectual purpose as I mentioned.\n\nMost of kinto clients will never use filtering or sorting (kinto.js for instance).\n\nNot true. They use massively ?_since=<>\n\nYou are true that we should enable transaction for the Redis storage backend and we will work on it eventually but postgresql backend didn't had transaction either at first.\n\nPlease admit that this is a huge amount of work :)\n\nRedis it is because Redis is currently our best option for the permission and cache backend.\n\nNo, not without transactions :)\n. The idea was not to challenge the relevance of Redis versus PostgreSQL in general. Redis is a really fast key value store, and does cool stuff others technologies don't do. However, our usage of Redis in Kinto (where we deserialize json in python to filter for example) is not optimal, and as far as I can remember the resulting performance from the API point of view was not better than PostgreSQL. Some further investigation/metrics could help here, but that's not the main issue.\nWe want to keep Kinto backend agnostic. We believe that it's a valuable property for the product, and potentially an advantage for community adoption. But maybe we are wrong, maybe the memory backend for dev and postgresql for production are enough. Keep those two only would still require a layer of abstraction for the backends, but we wouldn't have to maintain 3x3 backends ourselves each time the API evolves. We could just ask the community and adjust our vision based on the feedback!\n\nNote that we user Redis in production for the cache backend.\n\nThat's not what I see in the puppet files, but indeed, as I said in the issue description, that's a valid usage: redis for cache, postgresql for permission and storage to leverage the per-request transactions.\n\nsame reason we have kinto-history and kinto-default-bucket as part as the core.\n\nTrue, having those in the core allows to make sure our changes in the python core API is usable and relevant when used in concrete plugins. However, they don't introduce new system dependencies. Would we want to have kinto-elasticsearch plugin in core for example?\n\nFor cache because it doesn't expire data automatically as part as the DB feature.\n\nTrue, our approach in the postgresql backend can be costly because we do an index-scan to delete expired items before selecting the keys. But sometimes our intuition regarding performance can be wrong, some metrics would help. We all agree that Redis as a cache backend, without transactions, is fantastic.\n\nFor permissions because the intersection of sets is a killer feature of Redis.\n\nAgain, postgresql is very efficient on selecting indexed table fields, so only some miserable metrics on postgres could become a strong argument in favor of Redis here.\n\nthe way it has been implemented in Postgresql makes it difficult to apply to noSQL backends\n\nIn Redis maybe, but would it be true with RethinkDB, MongoDB or CouchDB ?\nAs I mentionned in the description, the current implementation of delete_all() in Redis is very limited, we can improve it and see if it's still a block (let's discuss that in #711)\nConcretely, we can reformulate and say something like: the \u00absets\u00bb feature of Redis makes it relevant for the permission backend in addition to the cache backend, however some work has to be done on plugging transactions with two-phase commit (in order to use it along postgresql as storage). Does the community want that redis+postgresql setup? Is worth the investment? Or shall we just keep it as an option for the cache backend only ?\n- Related #45\n. Yes, that's what I meant: I suggest that we move the redis backends to a separate repo, and that we stop maintaining them officially along Kinto. \nThe Redis aficionados would maintain the repo at their pace, implement stuff carefully, and would have the right to complain or suggest API changes when something is not done correctly in Kinto core (signatures, changelog, ...). But currently, keeping Redis like that in core does not guarantee anything and is counterproductive \u2014 since methods are implemented poorly \u2014 and making it suitable for production requires a lot of time/energy \u2014 since it has no migrations, no transactions, a lot of re-entrancies, is sub-optimized. \nAn investment in kinto core that I personally don't see worth making right now since Redis is not the recommended stack for production.\n\nNote: In parallel, I opened a few questions for the next kinto-monthly meeting.\n. @Natim feedback?\n. > using the get_bound_permissions function you prepare it and then you pass its result.\n\nyes, that is it! actually, each backend implementation was resolving the result of this callback the same way! so it makes much more sense to call it before leveraging the backends. It makes the code simpler to read IMO.\nPlus, it gives us a consistent way of fetching the permissions for several objects, necessary for #653 and #694 :) Win-Win :)\n. \n. I could have sworn it was the case !\nGG r+\n. r+\n. @Natim ready to review/merge!\n. We don't.\nBut it may be a remaining sequel of #740 ... \nTrying to find a URL path that matches (ucs < 0x80) with ucs = ((in & 0x1f00) >> 2) | (in & 0x3f); :)\nI feel like I'm in front of this:\n\nI know I could get it with a lot of efforts, but my brain gets on strike.\nSo I would vote to close now that we have #740 and see if it appears again.\n. > when installed in the venv\nIs that feasible?\n. r+wc\nYou used resource instead of object. Let's keep resource for the REST notion. See http://kinto.readthedocs.io/en/stable/concepts.html\n. Neat !\n. r+ with nits\n. r+\n. Related https://github.com/mozilla-services/cliquet/issues/583 \u00abthat'll come back later through the CLI and kinto-admin\u00bb \ud83d\ude04 \n. It could be kinto delete-collection --bucket=\"bid\" collection=\"cid\" :)\n. We can start a page for the kinto CLI ? Don't we have the output of --help somewhere already ?\n. f+ :)\n. @Natim final r+ ?\n\n\n. r+\n. Tests fail because of pep8 coding style. Will be fixed in #736  https://github.com/Kinto/kinto/pull/736/commits/10bb3b53c9073821c536a802c3048c569e32a9d9\n. https://github.com/mozilla-services/cliquet/issues/623\n. \n. There are two jobs: one with the merge on the targetted branch, and one for the branch.\nThe current version of the patch removes pypi on one of them only.\n. I'm a bit suprised by the complexity of the view code, compared to https://github.com/mozilla-services/shavar/commit/cebd41f123d83d2198eef67d6a7da923873cd136\nAlso, consider:\n- Update the release docs if there is anything new to do\n- Reify the view result since it runs many commands that will never have different results within the same run\n. Apart from missing details about the breaking changes, it looks very good to me!\n. Why would we want to switch from memory to postgresql to run tests ? There are gonna be slower ! \nWhat is the use case ?\n. Making the memory backend transaction aware requires to implement the transaction managers (see https://github.com/zopefoundation/transaction/blob/master/transaction/tests/examples.py)\nDo you think it is worth it?\n. r+\n. Thanks for this feedback! It's a bug indeed, we should either support the former setting or make this breaking change explicit (would lead to kinto 4.0)\n. Good catch ! Thanks !\n. kinto start relies on waitress which uses threads. We thus might have to introduce some mutex in the memory backend...\n. @n1k0  made this script to load 10000 records : https://gist.github.com/n1k0/684c2b7e3150b101376b2bd429b7b19f\n. Ready for review :) @Natim r?\n. Nope, just pop it out of the dict that is stored in the data column!\n. \\o/ \nI was wondering: don't we have to provide a version.json file before uploading to pypi? shouldn't we add a note about this in the releasing docs/PR tasks?\n. nits:\n- Fix Redis get_accessible_object implementation (#725) \u2192 Remove?\n- typo: kinto.core resources are now schemaless\n. r+\n. Related https://github.com/Kinto/kinto/pull/763. BTW I'm +1 on removing readonly fields. /cc @gabisurita . > I am wondering if the problem is not this\nWhat problem ?\n. The new version of this branch fixes the problem.\nI could reproduce the errors (concurrency + hang) initially and fixed it.\nTo run n1k0 script:\n. ~/.nvm/nvm.sh && nvm use 6.3.0\n  npm install kinto-http\n  npm install btoa\n  node batch-create.js\n. I merged to include it in the next release. If you have feedback I'll take them in another PR\n. It's reproduced on TravisCI : https://travis-ci.org/Kinto/kinto-http.js/jobs/153325171\n\n. Its probably related to the history plugin, I'll have a look\n. We might want to raise a 400 when it's put in the members of a group then.\n. This bug is still valid as far as I understand, as #794 only applies to group URLs and system.Everyone\n. > I think with this patch it will not be possible anymore to have a dot in the field name, is it?\nThis patch only applies to strict schema resources (only history basically). Kinto resources are schemaless (preserve_unknown=True), thus any field is considered as \u00abknown\u00bb.\n. r+\n. Note: also add how to set your database to UTC\n. Ok, so here is some insights about this cryptic ticket :)\n- Our target are the users who have played with the local in-memory backend, configured their plugins and stuff, and now want to go to production.\n- I don't think they'll be happy to restart configuration from scratch with kinto init (but I may be wrong)\n- Some Python packages will be missing, because we install those only during kinto init\n- I don't think we should go into the details of installing PostgreSQL for a particular distro/version of Linux/Ubuntu, we should link to external official docs, which will be maintained and up-to-date for sure. Our wiki page may also be improved but we don't want it in the docs, a link at most.\n- We want to give every instructions that are specific to Kinto, the following are enough I believe:\n  - PostgreSQL 9.4+ is required (link to external docs)\n  - Install python dependencies with pip install -Ue \"kinto[postgresql]\"\n  - create a specific database like mydatabase with UTF8 encoding\n  - set your database to UTC timezone (ALTER DATABASE mydatabase SET timezone TO 'UTC';)\n  - change your backend settings to kinto.core.storage.postgresql (see settings docs)\n  - change your backend url to something like postgresql://scott:tiger@localhost:5432/mydatabase\n  - run kinto migrate\n  - restart kinto\nThe best to succeed the resolution of this ticket is to do the exercice in a blank environment (like a container or a virtual machine), start with the memory backend with kinto init and switch to postgresql following the improved documentation :)  \nGood luck!\n. This is ready to be reviewed/merged :) \n@Natim r?\n. Thanks for opening the issue! \nThe in_ operator is already used for multiple values filtering (eg. in_status=closed,opened), we have to come up with a new one I guess (e.g. contains_). \nAlso maybe we should accept patterns like (contains_url=http(s?)).\n. Oh, I forgot to ask : would be willing to work on this feature (we can help) ?\n. Implement a test case where:\n- alice creates a bucket with group:create: [Authenticated]\n- alice creates a group abc\n- bob cannot read groups of buckets (including abc)\n- bob tries to create a group abc with If-None-Match: *. It should return 412 and not 403 since he is authorized to create groups.\nImplement another test case:\n- alice creates a bucket with write: [Authenticated]\n- alice creates a group abc\n- bob tries to create a group abc with If-None-Match: *. It should return 412 since he is authorized to create groups\nImplement another test case:\n- alice creates a bucket with read: [Authenticated]\n- alice creates a group abc\n- bob tries to create a group abc with If-None-Match: *. It should return 403since he is not authorized to create groups\n. @anna-liao would you need help to get started?\n. As magopian said:\n\nLet's go with the trivial solution (at least for now): add a default value...\n\nSo basically, all you need to do is allowing to create groups with a PUT request that has no body. For that you'll have to change the group validation schema in views files for groups, and add a default value for the members attribute (empty list []).\nYou'll have to update the group views tests to reflect that change if any test fails, and a add a new one that specifies the behavior.\nFrom the tests the following operation should work:\npy\nself.app.put(\"/buckets/bid\", headers=self.headers, status=201)\nself.app.put(\"/buckets/bid/groups/atest\", headers=self.headers, status=201)\nAnd from the command-line, with httpie installed:\n$ http PUT :8888/v1/buckets/bid --auth token:blah\n$ http PUT :8888/v1/buckets/bid/groups/atest --auth token:blah\nWith the current code, you'll that it complains because members is not provided.\n. Oh...\nI don't see any default value for members : https://github.com/Kinto/kinto/blob/master/kinto/views/groups.py#L13-L16\nSo this means that the upgrade to Cornice 2 ( #790 ) changed something here. \nThere is still something to fix. The group should always have a members attribute, with an empty list if not specified.\nThanks for catching this!\n. @anna-liao I don't have the same behaviour with a PUT and an empty body:\n```\nhttp PUT :8888/v1/buckets/t/groups/g --auth t:t\nHTTP/1.1 400 Bad Request\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 159\nContent-Type: application/json; charset=UTF-8\nDate: Thu, 01 Dec 2016 15:40:34 GMT\nServer: waitress\n{\n    \"code\": 400, \n    \"details\": [\n        {\n            \"description\": \"data is missing\", \n            \"location\": \"body\", \n            \"name\": \"data\"\n        }\n    ], \n    \"errno\": 107, \n    \"error\": \"Invalid parameters\", \n    \"message\": \"data is missing\"\n}\n```\nAre you still interested to look into it?. Please, no, don't be sorry! \nFirst, there is no emergency :) Second I suppose that you would do that on your personal free time, so it should never be a burden! \nI was asking because sometimes our interests change over time, and someone would be glad to take over. \nSo, please, it's all yours, take your time, and I hope you'll enjoy hacking on it :). You have to add \u00e0 custom validator on the group schema members field, and everything will be taken care of by kinto.core\nI advise you to start by writing a group view test that will fail at first, and then make the changes so that the validator comes in the game :)\n. The PR is still WIP, if anyone wants to give a hand, more than welcome! It's mainly a matter of documentation now :). Before broadening the scope of this too much and adding new things on the pile, let's go back to the accounts API feature.\nThe code of this PR was ready. I was thinking that we could rewrite the whole project documentation to rely on it instead of basic auth. And that last part never happened because it represents a lot of documentation effort. \nFrom here, we can imagine several strategies (add yours!):\n Merge it as an hidden/experimental feature (ie. just code, no docs)\n Merge it and document it as an extra feature (ie. without rewriting every docs)\n Merge it once the whole documentation is ready (ie. requires lots of efforts)\n Move it to a separate repo for less friction and keep the core repo as small as possible\n* Drop this PR (which has hackish parts) and rely on a more solid solution like Portier by default (see #994) \n\n\nI guess starting with a tutorial explaining the issue with Authentication and how people can plug the backend they'd like would be great.\n\nThis requires a good knowledge of Kinto. I don't know if that's an easy start at all. We never wrote it, and the current docs were never super clear about auth (ex. #976).   \n\nOne thing would be to add an OpenID-Connect compliant authentication backend. (kinto-fxa could be a great start for that).\n\nThis is another topic. See #939 and #508 \n\neventually plug multiple authentication mecanisms to them\n\nThis would deserve a dedicated issue.\n\ncreate anonymous accounts that they can activate so that you can create things and give permissions to people not having an account on your kinto just yet.\n\nThis would deserve a dedicated issue. \n. I don't think this is a bug.\nIt's a matter of compability with cornice master / v2 AFAIK\n. Closing as Cornice 2 was not released yet, and #790 will cover the changes.\n. Duplicating the test file accross repos may not be a problem... otherwise we could have something like kinto.core.storage.testing \n. Move CacheTest to kinto/core/cache/testing.py, and move PermissionTest to kinto/core/permission/testing.py.\nBut I would leave their inherited implementations  MemoryStorageTest, PostgreSQLStorageTest in tests/core/test_storage.py\n. > A quick fix would be to allow to read the schema\nCould you elaborate ?\n. Ok I think I get it. When a user has record:create we allow to read the collection metadata but not the list of records. I like it!\nNote that for consistency we shall probably apply the same strategy for bucket metadata and collection:create and group:create\n. So, let me try to sum it up: the idea is to make the necessary changes so that record:create would implicitly allow to read the collection object.\nIn terms of specs (and thus unit tests to implement), it becomes:\nIf Alice has no permission to read the collection but has record:create\n- she can read the collection object\n- she obtains a 403 if she created no record in that collection (current behaviour)\n- she can obtain the list of her own records (current behaviour)\n- records of other users do not come up in the list  (current behaviour)\n- she cannot read individual records of other users  (current behaviour)\nIf Alice has the permission to read the collection, she can read the collection object, and every records, but cannot create records (current behaviour).\n. > I think it's ok for who got the record:create permission knows that the collection exists?\nOk I think I see what you mean. Maybe we could change the current behaviour when the user has record:create: instead of returning a 403 when no record was created, we could return an empty list.\n. Oh I realized this is a duplicate of #101 \\o/ :)\n. Is that as easy as described to reproduce ?\n. I could reproduce on Travis with kinto-dist https://travis-ci.org/mozilla-services/kinto-dist/jobs/158134738\n. @juhieta I couldn't reproduce locally :( Do you have a concrete list of steps that reproduce the problem?\nThanks!\n. Hi @juhieta! Could you have a look in the end?\nWe couldn't reproduce so far, but we don't want to miss it. Maybe you had the problem with an old version?\n. I'll merge the PR as those tests don't harm.\n. @Natim @tarekziade r?\n. r+ with green build :)\n. The fix looks good in apparence indeed. I'm ok to merge.\nWe could go further and try to setup a test where this would have an impact. For example, make sure that no record is skipped not duplicated when going through pagination when the last record of a page has not the field used in the filter or sort...\n. What's the status of this now that #1116 was merged?. Related #539 \n\non the client side which is not optimal\n\nConverting from JSON to CSV in the client-side is not problematic IMO.\nThe main concern are the columns. Doing the union of every existing fields in the records can be costly, and might lead to some disparities from one page to another.\n. > in the backend means less code to maintain.\nWhy ?\n\nMy main concern is the list of columns.\nThe client can agregate every pages and build the list of columns from the whole list of records.\nOn the server we don't fetch the whole list of records from the storage backend, thus we might fall in a situation where two pages have different columns. What about headers? Should they be repeated on every page?\nFootnote: I wouldn't say it's an easy pick :)\n. We must improve the way we raise 404 errors\nHere https://github.com/Kinto/kinto/blob/2f0ba5e/kinto/views/init.py#L24-L32\nAnd https://github.com/Kinto/kinto/blob/2f0ba5e/kinto/core/resource/init.py#L664-L679\nin order to provide some additional details in the 404 response JSON body.\nSee also what was done in #748 \nDon't hesitate to ask questions if something does not seem feasible or clear!\n. Is raven installed ? Maybe logging fails silently if no sentry client is installed ? I just looked at kinto-heroku and it seems that Kinto is not installed with optional monitoring requirements kinto[monitoring]...\n. I recently ran into problems of loggin configuration too... and we're not the only ones :)\n\nI could get it behave as expected by setting explicitly a kinto logger:\n``` diff\ndiff --git a/config/kinto.ini b/config/kinto.ini\nindex 4fbd156..fb5c5c3 100644\n--- a/config/kinto.ini\n+++ b/config/kinto.ini\n@@ -212,7 +212,7 @@ kinto.logging_renderer = kinto.core.logs.MozillaHekaRenderer\n[loggers]\n # keys = root, sentry\n-keys = root\n+keys = root, kinto\n[handlers]\n keys = console, sentry\n@@ -225,6 +225,11 @@ level = INFO\n handlers = console, sentry\n formatter = heka\n+[logger_kinto]\n+level = DEBUG\n+handlers =\n+qualname = kinto\n+\n [logger_sentry]\n level = WARN\n handlers = console\n```\nI have no idea why the root does not include kinto logger :/\n. Closing for lack of feedback :) I assume everything is good!. @magopian r?\n. I applied the same logics to bucket metadata (collection:create and group:create gives access to (parent) bucket metadata).\nMaybe we shouldn't and keep it for record+collection metadata only?\nWhat do you think @enguerran / @magopian ?\n. > Do you think it could be a security issue or something? \nI wouldn't say a security issue, but it makes the impact of the change bigger.\n. This cannot be reviewed without going through each commit. I'm very confident in the code and the test suite though.\nI changed and simplified a lot of code. Basically:\n- I renamed many variables and method names in the authorization code. It is now more consistent with what it does.\n- I added a level of keys in the inheritance tree of permissions. Before it used to have some concat and join strings for the keys.\n- There is now a read:attributes permission in the inheritance tree of permissions. It is not exposed yet to the HTTP API but we could eventually. It gives the finer grain we need (#110) to allow reading attributes and not the whole list of records.\n- I changed the way the authorization code relies on settings. This paves the way for #350 \n- I removed the specific case we had for allowing listing buckets. It now behaves as other: if you can create buckets, you can receive an empty list on /buckets if none are accessible to you.\nDon't hesitate to ping me for questions!\n@magopian r?\n\n. Final r+ my friends?\n. \\o/\n. Thanks a lot!\n. Thanks for catching the merge errors @Natim !\nI restored the backup I had before rebasing and merged origin/master into the branch instead.. Thanks for this contribution!\nWe should also do it for update().\nSince this applies to the postgresql backend internals, it would exceptionnally acceptable to merge it without tests. But maybe it would be relevant to have a test in storage/testing.py that asserts that the specified record object is not altered (that's why you added the line with .copy() I suppose). What do you think ?\n. The current code looks great and seems to do the job! Adding a test would make it perfect :)\n(do not hesitate to ask for help if you're stuck)\n. Well, it's always better to be able to run the tests locally... \nI pulled the branch, and the whole test suite is green indeed. And you're right there is a test called test_create_copies_the_record_before_modifying_it in the storage tests.\nSo I think we're good to merge!\nThanks for the good work!\n(Please merge your branch with the current master using git fetch origin and git merge origin/master)\n. I'm very sorry to say that, but unfortunatly nope, that was not the idea of #788 :((\nFrom what I can see, this PR copies the wiki page to the Running in production docs. I'd like to keep the Kinto docs focused on what is specific to Kinto+postgresql.\nUsers which are familiar with PostgreSQL do not miss any crucial information while being bored :)\nUsers that are not familiar should first get their server running (possibly with external/up-to-date/official docs) and then come back to Kinto.\nI added some details in #788 \nSorry about the time lost here :(\n. I'm closing in favor of #839 :(\n\n. @n1k0+@magopian r?\n. \ud83d\udc4d \nYes, you could mention the packages why not: Kinto PostgreSQL backends rely on specific Python packages (like SQLAlchemy and psycopg2)\n. Nice, thanks a lot! Merging \ud83c\udf89 \n. If we really can't figure what's wrong, since it got broken from one day to another, I find it acceptable to add a @skip_if_pypy decorator on this single test with a comment...\nWe shouldn't spend too much efforts on Pypy, especially if related to mocking in tests :)\n. Yes in this build you can see it was working on 4th of August:\nhttps://travis-ci.org/Kinto/kinto/jobs/149744279\nWith the following versions:\n```\npypy installed: alabaster==0.7.9,apipkg==1.4,args==0.1.0,Babel==2.3.4,beautifulsoup4==4.5.1,cffi==1.3.0,clint==0.5.1,colander==1.3.1,colorama==0.3.7,configparser==3.5.0,contextlib2==0.5.4,cornice==1.2.1,coverage==4.2,docutils==0.12,enum34==1.1.6,execnet==1.4.1,flake8==3.0.3,funcsigs==1.0.2,functools32==3.2.3.post2,futures==3.0.5,greenlet==0.4.7,imagesize==0.7.1,iso8601==0.1.11,Jinja2==2.8,jsonschema==2.5.1,kinto==3.4.0.dev0,linecache2==1.0.0,MarkupSafe==0.23,mccabe==0.5.2,mock==2.0.0,newrelic==2.68.0.50,PasteDeploy==1.5.2,pbr==1.10.0,pkginfo==1.3.2,pluggy==0.3.1,psycopg2cffi==2.7.4,py==1.4.31,pycodestyle==2.0.0,pyflakes==1.2.3,Pygments==2.1.3,pyramid==1.7,pyramid-multiauth==0.8.0,pyramid-tm==0.12.1,pytest==2.9.2,pytest-cache==1.0,pytest-capturelog==0.7,pytest-cov==2.3.0,pytest-cover==3.0.0,pytest-sugar==0.7.1,python-dateutil==2.5.3,pytz==2016.6.1,raven==5.23.0,readline==6.2.4.1,redis==2.10.5,repoze.lru==0.6,requests==2.10.0,requests-toolbelt==0.7.0,simplejson==3.8.2,six==1.10.0,snowballstemmer==1.2.1,Sphinx==1.4.5,sphinx-rtd-theme==0.1.10a0,sphinxcontrib-httpdomain==1.5.0,SQLAlchemy==1.1.0b3,statsd==3.2.1,structlog==16.1.0,termcolor==1.1.0,tox==2.3.1,traceback2==1.4.0,transaction==1.6.1,translationstring==1.3,twine==1.7.4,unittest2==1.1.0,venusian==1.0,virtualenv==15.0.2,waitress==1.0a2,WebOb==1.6.1,WebTest==2.0.23,Werkzeug==0.11.10,zest.releaser==6.6.4,zope.deprecation==4.1.2,zope.interface==4.2.0,zope.sqlalchemy==0.7.7\npypy runtests: PYTHONHASHSEED='3491541475'\npypy runtests: commands[0] | python --version\nPython 2.7.10 (f3ad1e1e1d62, Aug 28 2015, 10:45:29)\n[PyPy 2.6.1 with GCC 4.8.4]\n```\nIt started to fail with PR #756 here : https://travis-ci.org/Kinto/kinto/builds/152618090\n```\nalabaster==0.7.9,apipkg==1.4,args==0.1.0,Babel==2.3.4,beautifulsoup4==4.5.1,cffi==1.7.0,clint==0.5.1,colander==1.3.1,colorama==0.3.7,configparser==3.5.0,contextlib2==0.5.4,cornice==1.2.1,coverage==4.2,docutils==0.12,enum34==1.1.6,execnet==1.4.1,flake8==3.0.4,funcsigs==1.0.2,functools32==3.2.3.post2,futures==3.0.5,greenlet==0.4.9,imagesize==0.7.1,iso8601==0.1.11,Jinja2==2.8,jsonschema==2.5.1,kinto==3.4.0.dev0,linecache2==1.0.0,MarkupSafe==0.23,mccabe==0.5.2,mock==2.0.0,newrelic==2.68.0.50,PasteDeploy==1.5.2,pbr==1.10.0,pkginfo==1.3.2,pluggy==0.3.1,psycopg2cffi==2.7.4,py==1.4.31,pycodestyle==2.0.0,pyflakes==1.2.3,Pygments==2.1.3,pyramid==1.7.1,pyramid-multiauth==0.8.0,pyramid-tm==0.12.1,pytest==2.9.2,pytest-cache==1.0,pytest-capturelog==0.7,pytest-cov==2.3.1,pytest-cover==3.0.0,pytest-sugar==0.7.1,python-dateutil==2.5.3,pytz==2016.6.1,raven==5.24.3,readline==6.2.4.1,redis==2.10.5,repoze.lru==0.6,requests==2.11.0,requests-toolbelt==0.7.0,simplejson==3.8.2,six==1.10.0,snowballstemmer==1.2.1,Sphinx==1.4.5,sphinx-rtd-theme==0.1.10a0,sphinxcontrib-httpdomain==1.5.0,SQLAlchemy==1.1.0b3,statsd==3.2.1,structlog==16.1.0,termcolor==1.1.0,tox==2.3.1,traceback2==1.4.0,transaction==1.6.1,translationstring==1.3,twine==1.8.1,unittest2==1.1.0,venusian==1.0,virtualenv==15.0.3,waitress==1.0a2,WebOb==1.6.1,WebTest==2.0.23,Werkzeug==0.11.10,zest.releaser==6.6.4,zope.deprecation==4.1.2,zope.interface==4.2.0,zope.sqlalchemy==0.7.7\npypy runtests: PYTHONHASHSEED='629183249'\npypy runtests: commands[0] | python --version\nPython 2.7.10 (7e8df3df9641, Jun 14 2016, 13:58:02)\n[PyPy 5.3.1 with GCC 4.8.2]\n```\nmock and transaction are at the same version. But Pypy went from 2.6.1 to 5.3.1 ! \nTo be honest, I don't know why we were running such an old (working) version!\n. \\o/ GG ! \nr+ but don't forget to add a Internal changes entry in changelog\n. yes!\n. Cannot reproduce with memory backend locally.\n. Cannot reproduce with postgresql backend locally either :/ Running kinto-dist config with every plugins enabled :(\nhttps://travis-ci.org/mozilla-services/kinto-dist/jobs/163976422\n. I thought we already had automatic redirect for Django users :)\n. You can rebase now that #746 and #850 were merged\n. r+ !\n. Nice catch @gabisurita !\nThe problem comes indeed that we interpolate the field value as a native python value (which is integer) and then compare it with a string (id).\nI remember also that we don't want to compare with string if the store value is an integer.\nThe fix might not be so easy actually, since we don't always have the schema of the data.\nWe could maybe filter with something like field IN (\"0\", 0) but I find it very ugly... \n. This code is very old, but statsd was never enabled in prod, which explains why we haven't seen it before. Matched route is None when no service matches the URL I guess...\n. I'll try to give you some insights: \n- You can add a filtering test with numeric id here: https://github.com/Kinto/kinto/blob/f8d52232aa717f0829e50f4b0728abdfe8b28e3e/kinto/core/storage/testing.py#L312-L313\n- You can cast id to string here: https://github.com/Kinto/kinto/blob/f8d52232aa717f0829e50f4b0728abdfe8b28e3e/kinto/core/storage/postgresql/init.py#L642-L643\n- You can override the method _extract_filters() method in the history resource here: https://github.com/Kinto/kinto/blob/f8d52232aa717f0829e50f4b0728abdfe8b28e3e/kinto/plugins/history/views.py#L30 and cast to string the collection_id, group_id, record_id there if one is specified \nThe fix is spread over the code base, but this way every component is aware what to do with its own stuff. \nModifying code is usually hard to get it right at the first time :)  If you feel like you're not feeling like doing it, don't hesitate to step back, that would be completely understandable!\nGood luck!\n. Great!\nAs you can see here: https://github.com/Kinto/kinto/blob/4.3.1/kinto/core/statsd.py#L19-L28, we already use the classname (here storage). Since we specify the prefix during initialization: https://github.com/Kinto/kinto/blob/4.3.1/kinto/core/initialization.py#L247-L249, the key ends up being storage.storage\nI believe we'd want to keep the current approach, just that the prefix could just be backend so that we have kinto.backend.storage.get (and kinto.backend.cache.get etc. for example)\n. > Let me know if I got it wrong or there's something missing!\nNothing wrong! But yes some stuff is missing from the spec\n- Only use this behaviour when the specific Content-Type is used\n- Merge recursively the objects (see a pseudo code example is given in the RFC)\nI believe you should move this to core.utils and run some of the tests specified in the specs (especially the last one).\nI know it would be better if we would have this new behaviour by default, but we can't break existing clients, so we better leave behind the request header Content-Type: application/merge-patch+json as the spec says.\n\nObs: Should this increase API_VERSION or be included on the API entry docs?\n\nYes it should be incremented!\n. This is just excellent! Awesome job, definitely not easy!\nWe'll probably put that header by default in our official python/js clients.\n@Natim I'm in favor of merging. You're still listed as requested changes\n. Thanks for starting this!\nI think you could put it in kinto/core/utils.py. It should also have some tests to make sure it behaves as expected.\nDon't hesitate to ask specific questions here if you're stuck!\n. > is it possible that there's a problem with the build process with the docs job?\nYes you are totally right! I can't spend time on this right now unfortunately.\nFor the tests, why didn't you just copy https://github.com/Kinto/kinto-signer/blob/06f790cc57ad3b53db090d62a5318df96e320fdd/tests/test_utils.py#L9-L130 ?\nSince you copied the code of the parse_resource() it would make sense to copy the tests too no?\n. > do you think it's necessary to have source;dest format?\nOH I'm very sorry! I hadn't caught that! \n. This is good and ready to be merged!\nThe failing test is unrelated to this PR:\n```\ngenerating indices... genindex http-routingtable py-modindex\nwriting additional pages... index\nException occurred:\nFile \"/home/travis/build/Kinto/kinto/.tox/docs/lib/python2.7/site-packages/sphinx/jinja2glue.py\", line 179, in get_source\nraise TemplateNotFound(template)\n\nTemplateNotFound: defindex.html\nThe full traceback has been saved in /tmp/sphinx-err-F2OoKS.log, if you want to report the issue to the developers.\nPlease also report this if it was a user error, so that a better error message can be provided next time.\nA bug report can be filed in the tracker at https://github.com/sphinx-doc/sphinx/issues. Thanks!\n```\n. Great! Congratz!\n. Do you need help to get started with the tests?\n. You can start small. I suggest that you make a backup of all this code that you have here, and restart from scratch with very little code.\nFor example, you start a test that inherits from HistoryWebTest in test_history.py.\nIn the setUpof this new test, you perform some operations:\n- create a bucket\n- create a collection\n- create 1 record\n- delete 1 record\n(see examples in the FilteringTest setup)\nThen your first assertion will be simple: test that you can revert the delete operation.\npy\ndef test_can_revert_record_deletion(self):\n    # assert that the record is missing\n    self.app.get(record_url, headers=self.headers, status=404)\n    # call the revert endpoint\n    self.app.post(revert_url, headers=self.headers)\n    # assert that the record is back\n    self.app.get(record_url, headers=self.headers, status=200)\nOnce you get that simple bit working, you can iterate like this:\n- add a new test that will fail because the code does not handle the new case\n- make the test pass with some new code\n- git add -A\n- refactor and clean-up if necessary\n- git commit -m \"feature X\"\n- go to step 1\nIf our contributions docs do not allow to get started, please let us know and open dedicated issues, even if it's just a question! It is very important that no particular knownledge is necessary to get started!\nGood luck and enjoy!\n. Closing for lack of response. Feel free to reopen, we'd be happy to see all this resumed!. @sunakshi96 I just tried and it worked with:\n``` ini\n\nPlugins\n\nkinto.includes = kinto.plugins.default_bucket\n                 kinto.plugins.history\n                 kinto.plugins.admin\n```\nAdmin is there at http://0.0.0.0:8888/v1/admin/\n. Looks like the new documentation page is gone \ud83d\ude28\n. Do you need help to recover the files? There might be a way (using git reflog)\n. Closing for lack of feedback.\nDo not hesitate to re-open if things move on your side!\n. The tests are broken of the release of cornice 2.0. We'll make our best to merge #790 ASAP\n\n. I can help, I'm the one who merged #790 and introduced some additional work on validation. I'd be glad to merge the PR myself providing the last bit of effort! You've done an amazing job here, and I wouldn't want you to get discouraged...\n. I'll merge the PR myself please. You've provided a tremendous amount of work here, and you should now lean back for a while :)\n. - psycopg 2.6.2 (7th July 2016) is supposed to have a fix for that. But that's the version we run in prod and we still have the error. https://github.com/psycopg/psycopg2/issues/443\nIn this thread on AWS https://forums.aws.amazon.com/message.jspa?messageID=443924 it says it could come from the node running out of memory.\nOn the Heroku above link, it says it can come from Abrupt client (application side) disconnections, but I can't see any event around the same time in Sentry. I consider the root cause about threads to be already managed by SqlAlchemy, but I may be wrong...\nI opened a PR to enable connection recycling after 1H on production. It does not harm and may help maintain a pool of fresh connections in case the problem comes from the server and not the client.\nWe've had the error 118 times in 24 days, with an average of 40 requests per seconds.\nLet's see...\n. Small note: sqlalchemy behaves well and invalidates the connection from the pool:\njson\n      {\n        \"category\": \"kinto.core.storage.postgresql.pool.QueuePoolWithMaxBacklog\",\n        \"level\": \"info\",\n        \"timestamp\": 1478204174.971706,\n        \"type\": \"default\",\n        \"message\": \"Invalidate connection <connection object at 0x45e8cc0; dsn: 'dbname=kinto user=xxxxxxx password=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx host=xxxxxxxxxxm port=5432', closed: 1> (reason: OperationalError:SSL SYSCALL error: EOF detected\\n)\",\n        \"data\": {}\n      },\n      {\n        \"category\": \"kinto.core.storage.postgresql.pool.QueuePoolWithMaxBacklog\",\n        \"level\": \"debug\",\n        \"timestamp\": 1478204174.971844,\n        \"type\": \"default\",\n        \"message\": \"Closing connection <connection object at 0x45e8cc0; dsn: 'dbname=kinto user=xxxxxxx password=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx host=xxxxxxxxxxm port=5432', closed: 1>\",\n        \"data\": {}\n      },\n      {\n        \"category\": \"kinto.core.storage.postgresql.client\",\n        \"level\": \"error\",\n        \"timestamp\": 1478204174.971996,\n        \"type\": \"default\",\n        \"message\": \"{\\\"Pid\\\":3109,\\\"EnvVersion\\\":\\\"2.0\\\",\\\"Hostname\\\":\\\"ip-xxxxxxx\\\",\\\"Timestamp\\\":1478204174971000000,\\\"Fields\\\":{\\\"lang\\\":null,\\\"uid\\\":null,\\\"errno\\\":null,\\\"querystring\\\":\\\"{}\\\",\\\"agent\\\":\\\"xxx\\\",\\\"method\\\":\\\"GET\\\",\\\"path\\\":\\\"xxx\\\",\\\"authn_type\\\":null},\\\"Logger\\\":\\\"kinto\\\",\\\"Type\\\":[\\\"(psycopg2.OperationalError) SSL SYSCALL error: EOF detected\\\\n\\\"],\\\"Severity\\\":2}\",\n        \"data\": {}\n      },\n. Using the connection recycling seems to help a lot. Oh sorry, I forgot to mention: you should update the CHANGELOG too\n. Thanks!\n. > How would it looks like in terms of code separation? \nInstead of having Colander classes, we would have simple dicts in the source code (not JSON files)\n\nI am not sure it worth it to be honest.\n\n+1. \\o/\nYes, everything returned by request.effective_principals is just fine :)\n. Shouldn't this be reported to pyramid-tm instead?\nOr couldn't we prevent to do smart stuff in the 403 view? Like why are we transforming a 403 into a 401 anyway?\n. Tracked upstream: https://github.com/Pylons/pyramid_tm/issues/40\n. I suggest that we close this, and make sure the code we put in those error views do not hit the backends. Good catch!\nI think that the transaction is opened by this line: https://github.com/Kinto/kinto/blob/master/kinto/core/authorization.py#L35\nMaybe we could put the fix there (something like: if no transaction is opened before the call on the backend, then close it just after there)\n. > How do you detect if the transaction is opened or not?\nMaybe with that ? https://github.com/zopefoundation/transaction/blob/master/transaction/_transaction.py#L85\nMaybe the current patch is the best way to go after all :)\n. After some investigation, we realized that kinto-fxa was not implemented properly. We'll propose a fix there. \nLet's keep #877 and #879 open, it does not hurt to fix them some day, but the root cause is fxa in this case (accessing request.effective_principals several times in the request cycle shouldn't induce several hits to auth server and cache backend)\nThanks for spotting the bug !! I close this but remain open to any objection ;)\n. AFAIK there's always a transaction (isolation) for every operation. Nevertheless, a transaction does not necessary last more than one instruction.\nSo yes, I agree the cache operations could be decorrelated from the transactions managed (ie. opened/committed/rolledback) along the request cycle!\n. As @Natim noted, it would also allow to use the cache in AfterResourceChanged hooks, that are executed once the request transaction is committed.\n. Related #691 . Note: the problem only exists for buckets, since it's (currently) the only object that has two types of children.\nThe chain of implicit permissions would then have two steps: create groups \u2192 read bucket attributes \u2192 read collections list. Maybe we should step back and find out something simpler?  (can't think of anything now).\n. Reported upstream https://github.com/Pylons/pyramid/issues/2800\n. Hi @noisedispatch! \nI'm very glad you chose Kinto for your first PR! \nThe amount of code to write for the feature itself is very small, so you'll probably have to be prepared for other kinds of obstacles like handling Git and writing a test that controls the expected behaviour.\nBut don't worry, we can help you!\nEnjoy! ...and thanks again for proposing your help!. Yeah Python dependencies and cache can be tricky when incompatible version ranges are modified. Let us know if you could get back on tracks!. The setting would be set by an administrator. Then in the Python code, we generate a random number, if it is below the percentage, we set the header, otherwise we don't. If we consider that the random number distribution is linear, then we know we'll have a certain percentage of hits to receive the header.. Hi @jvce92 !\nThanks for your interested in the project! welcome on board!\nIndeed, you'll have to introduce a new settings like kinto.backoff_percentage and if it is defined, then put the header only if random is below the specified value (which is could also be understood as \u00abbackoff probability\u00bb ;)). Sorry for the delay, your message got lost in my pile of notifications :(\nYou would use a library called mock that could force the value of random :)\nSomething like that`(untested code):\n```py\ninitialization.py\nimport random\n...\nif random.random() > setting:\n    response.headers[\"Backoff\"] = ...\n```\n```py\ntests.py\nimport mock\nwith mock.patch('kinto.core.initialization.random.random', return_value=0.6):\n    resp = self.app.get(\"/\")\n    self.assertIn(\"Backoff\", resp.headers())\n```. Could you add an entry in the API changelog please?\nThanks :)\n. > Please at least remove the principal without the prefix from the list of principals.\nWhy is it so important? From the Pyramid point of view, it's there!\n. Related #892. Yes, I think it's beneficial to have every options \u00abexposed\u00bb in the config file (commented out, with nice sectioning etc.)\n. > how much changing around the structure of a file is acceptable in this instance where I'm new to a project.\nThe sky is the limit! As long as you find it better than the current one ;) Don't spend too much time on it before submitting a first version, so that we can give you feedback ASAP\n\nmy plan was to go through the configuration file and copy the general structure of that to try and [...]\n\nThat sounds like a good idea!\n\nIn situations like this, should I move the settings to their own sections (kinto.http_host and kinto.http_scheme for example) or keep them where they are?\n\nI don't understand this... If you refer to INI sections (like [production]) unfortunately we can't do that easily (see #220), that's why we stick to these ascii art sections :D \n. Hi @heron182 ! Yes, you can! Thanks for your interest!. Can you reproduce locally?\n. Can you please give the set of HTTP requests that reproduce the problem?\n. Very very very good catch. See #935. Thanks :)\n\n. From the client point of view, this would just look like as if the bucket/collection/record was deleted (eg. 404)\n. oh no, I would just do something like:\n- UPDATE records SET id=$newid WHERE id=$oldid\n- UPDATE deleted SET id=$newid WHERE id=$oldid\n- UPDATE records SET parent_id=/uri/$newid WHERE ...\n- UPDATE deleted SET parent_id=/uri/$newid WHERE ...\n- UPDATE permissions SET object_id=/uri/$newid WHERE ...\n. This PR passes a schema as instance instead of a class. Related to https://github.com/Cornices/cornice/pull/415\n. Don't have more context?\nFrom what I see in the code, this could happen in get_accessible_objects() when bound_permissions is an empty list.\n. I think this is covered by the permissions endpoint :) Please re-open if I'm wrong!. I agree, this is quick and dirty fix.\nBut we don't have much context about the error :/  I would welcome any help to figure that out better ;)\n. \n. Please open an issue in kinto-admin to see what can be done there\n. @Natim for this patch to work efficiently we would need to scan every objects parent id (the same as webpush?).\nFor example:\n- Give collection_read_principals = system.Authenticated\n- Query the /permissions endpoint as any authenticated user\n- You would expect to have the read permission on every collections (in every buckets)\nFor retrieving the list of every collections, if we use get_all() we don't know in which bucket they are (ie. we don't know the value of parent_id). We still can first iterate on buckets and then on their collections, but this is sub-optimal (that's the current implementation of this patch).\n. r=me\n. This is a backport of pull-requests that were merged on master to the 4.3.X branch\n. I can't reproduce :( Look:\nGet user ids of a and b:\n```\n$ http GET :8888/v1/ --auth a:             \nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 3368\nContent-Type: application/json; charset=UTF-8\nDate: Thu, 17 Nov 2016 08:56:44 GMT\nServer: waitress\n{\n    ...\n    \"user\": {\n        \"bucket\": \"58c9d725-1dc9-e496-dcd8-593b1c3901c0\", \n        \"id\": \"basicauth:8d89e624473bb4e9af5a59f370aba3e621fa513456f56cbe3b9903f566e6527d\"\n    }\n}\n```\n```\n$ http GET :8888/v1/ --auth b:\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 3368\nContent-Type: application/json; charset=UTF-8\nDate: Thu, 17 Nov 2016 08:56:47 GMT\nServer: waitress\n{\n    ...\n    \"user\": {\n        \"bucket\": \"ad4074ae-d913-75c8-bcd7-0b51a1098f38\", \n        \"id\": \"basicauth:54daaac37654444616c0ecf2c2ee363ae7baa2e6f761120dafe5c86f076766eb\"\n    }\n}\n```\nCreate groups with those user ids:\n```\n$ http PUT :8888/v1/buckets/test --auth user:pass\n$ echo '{\"data\":{\"members\":[\"basicauth:54daaac37654444616c0ecf2c2ee363ae7baa2e6f761120dafe5c86f076766eb\",\"basicauth:8d89e624473bb4e9af5a59f370aba3e621fa513456f56cbe3b9903f566e6527d\"]}}' | http PUT :8888/v1/buckets/test/groups/test --auth user:pass \n$ echo '{\"data\":{\"members\":[\"basicauth:54daaac37654444616c0ecf2c2ee363ae7baa2e6f761120dafe5c86f076766eb\"]}}' | http PUT :8888/v1/buckets/test/groups/test1 --auth user:pass\n$ echo '{\"data\":{\"members\":[\"basicauth:8d89e624473bb4e9af5a59f370aba3e621fa513456f56cbe3b9903f566e6527d\"]}}' | http PUT :8888/v1/buckets/test/groups/test2 --auth user:pass \n```\na and b can't read the groups, since they don't have any permissions on the bucket:\n```\n$  http GET :8888/v1/buckets/test/groups/test --auth a:\nHTTP/1.1 403 Forbidden\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, ETag, Pragma, Cache-Control, Backoff\nContent-Length: 95\nContent-Type: application/json; charset=UTF-8\nDate: Thu, 17 Nov 2016 08:58:01 GMT\nServer: waitress\n{\n    \"code\": 403, \n    \"errno\": 121, \n    \"error\": \"Forbidden\", \n    \"message\": \"This user cannot access this resource.\"\n}\n$  http GET :8888/v1/buckets/test/groups/test --auth b:\nHTTP/1.1 403 Forbidden\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, ETag, Pragma, Cache-Control, Backoff\nContent-Length: 95\nContent-Type: application/json; charset=UTF-8\nDate: Thu, 17 Nov 2016 08:58:04 GMT\nServer: waitress\n{\n    \"code\": 403, \n    \"errno\": 121, \n    \"error\": \"Forbidden\", \n    \"message\": \"This user cannot access this resource.\"\n}\n```\nAdd them with write perm on the bucket:\n$ echo '{\"permissions\":{\"write\":[\"/buckets/test/groups/test\"]}}' | http PUT :8888/v1/buckets/test --auth user:pass\nNow they can read them, all 3:\n```\n$ http GET :8888/v1/buckets/test/groups --auth a:   \nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, Total-Records, ETag, Pragma, Cache-Control, Backoff, Next-Page\nCache-Control: no-cache, no-store\nContent-Length: 488\nContent-Type: application/json; charset=UTF-8\nDate: Thu, 17 Nov 2016 09:18:13 GMT\nEtag: \"1479374287462\"\nLast-Modified: Thu, 17 Nov 2016 09:18:07 GMT\nServer: waitress\nTotal-Records: 3\n{\n    \"data\": [\n        {\n            \"id\": \"test2\", \n            \"last_modified\": 1479374287462, \n            \"members\": [\n                \"basicauth:8d89e624473bb4e9af5a59f370aba3e621fa513456f56cbe3b9903f566e6527d\"\n            ]\n        }, \n        {\n            \"id\": \"test1\", \n            \"last_modified\": 1479374269675, \n            \"members\": [\n                \"basicauth:54daaac37654444616c0ecf2c2ee363ae7baa2e6f761120dafe5c86f076766eb\"\n            ]\n        }, \n        {\n            \"id\": \"test\", \n            \"last_modified\": 1479373059020, \n            \"members\": [\n                \"basicauth:54daaac37654444616c0ecf2c2ee363ae7baa2e6f761120dafe5c86f076766eb\", \n                \"basicauth:8d89e624473bb4e9af5a59f370aba3e621fa513456f56cbe3b9903f566e6527d\"\n            ]\n        }\n    ]\n}\n$ http GET :8888/v1/buckets/test/groups --auth b:\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, Total-Records, ETag, Pragma, Cache-Control, Backoff, Next-Page\nCache-Control: no-cache, no-store\nContent-Length: 488\nContent-Type: application/json; charset=UTF-8\nDate: Thu, 17 Nov 2016 09:18:16 GMT\nEtag: \"1479374287462\"\nLast-Modified: Thu, 17 Nov 2016 09:18:07 GMT\nServer: waitress\nTotal-Records: 3\n{\n    \"data\": [\n        {\n            \"id\": \"test2\", \n            \"last_modified\": 1479374287462, \n            \"members\": [\n                \"basicauth:8d89e624473bb4e9af5a59f370aba3e621fa513456f56cbe3b9903f566e6527d\"\n            ]\n        }, \n        {\n            \"id\": \"test1\", \n            \"last_modified\": 1479374269675, \n            \"members\": [\n                \"basicauth:54daaac37654444616c0ecf2c2ee363ae7baa2e6f761120dafe5c86f076766eb\"\n            ]\n        }, \n        {\n            \"id\": \"test\", \n            \"last_modified\": 1479373059020, \n            \"members\": [\n                \"basicauth:54daaac37654444616c0ecf2c2ee363ae7baa2e6f761120dafe5c86f076766eb\", \n                \"basicauth:8d89e624473bb4e9af5a59f370aba3e621fa513456f56cbe3b9903f566e6527d\"\n            ]\n        }\n    ]\n}\n```\n. Same without the group in common between the two:\nCreate bucket:\n```\n$ echo '{\"permissions\":{\"write\":[\"/buckets/n1k0/groups/a\", \"/buckets/n1k0/groups/b\"]}}' | http PUT :8888/v1/buckets/n1k0 --auth user:pass\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 205\nContent-Type: application/json; charset=UTF-8\nDate: Thu, 17 Nov 2016 09:25:27 GMT\nEtag: \"1479374727123\"\nLast-Modified: Thu, 17 Nov 2016 09:25:27 GMT\nServer: waitress\n{\n    \"data\": {\n        \"id\": \"n1k0\", \n        \"last_modified\": 1479374727123\n    }, \n    \"permissions\": {\n        \"write\": [\n            \"/buckets/n1k0/groups/b\", \n            \"/buckets/n1k0/groups/a\", \n            \"basicauth:cbd3731f18c97ebe1d31d9846b5f1b95cf8eeeae586e201277263434041e99d1\"\n        ]\n    }\n}\n```\nCreate two groups with a and b:\n$ echo '{\"data\":{\"members\":[\"basicauth:54daaac37654444616c0ecf2c2ee363ae7baa2e6f761120dafe5c86f076766eb\"]}}' | http PUT :8888/v1/buckets/n1k0/groups/a --auth user:pass \n$ echo '{\"data\":{\"members\":[\"basicauth:8d89e624473bb4e9af5a59f370aba3e621fa513456f56cbe3b9903f566e6527d\"]}}' | http PUT :8888/v1/buckets/n1k0/groups/b --auth user:pass\nList groups:\n```\n$ http GET :8888/v1/buckets/n1k0/groups --auth a:\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, Total-Records, ETag, Pragma, Cache-Control, Backoff, Next-Page\nCache-Control: no-cache, no-store\nContent-Length: 270\nContent-Type: application/json; charset=UTF-8\nDate: Thu, 17 Nov 2016 09:26:24 GMT\nEtag: \"1479374770617\"\nLast-Modified: Thu, 17 Nov 2016 09:26:10 GMT\nServer: waitress\nTotal-Records: 2\n{\n    \"data\": [\n        {\n            \"id\": \"a\", \n            \"last_modified\": 1479374770617, \n            \"members\": [\n                \"basicauth:54daaac37654444616c0ecf2c2ee363ae7baa2e6f761120dafe5c86f076766eb\"\n            ]\n        }, \n        {\n            \"id\": \"b\", \n            \"last_modified\": 1479374756259, \n            \"members\": [\n                \"basicauth:8d89e624473bb4e9af5a59f370aba3e621fa513456f56cbe3b9903f566e6527d\"\n            ]\n        }\n    ]\n}\n$ http GET :8888/v1/buckets/n1k0/groups --auth b:\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, Total-Records, ETag, Pragma, Cache-Control, Backoff, Next-Page\nCache-Control: no-cache, no-store\nContent-Length: 270\nContent-Type: application/json; charset=UTF-8\nDate: Thu, 17 Nov 2016 09:26:29 GMT\nEtag: \"1479374770617\"\nLast-Modified: Thu, 17 Nov 2016 09:26:10 GMT\nServer: waitress\nTotal-Records: 2\n{\n    \"data\": [\n        {\n            \"id\": \"a\", \n            \"last_modified\": 1479374770617, \n            \"members\": [\n                \"basicauth:54daaac37654444616c0ecf2c2ee363ae7baa2e6f761120dafe5c86f076766eb\"\n            ]\n        }, \n        {\n            \"id\": \"b\", \n            \"last_modified\": 1479374756259, \n            \"members\": [\n                \"basicauth:8d89e624473bb4e9af5a59f370aba3e621fa513456f56cbe3b9903f566e6527d\"\n            ]\n        }\n    ]\n}\n```\n. Thanks for reporting!\nI confirm :|\n```\n$ echo '{\"data\": {\"a\": {\"b\": {\"c1\":1, \"c2\":2}}}}' | http :8888/v1/buckets/default/collections/test/records --auth user:pass\nHTTP/1.1 201 Created\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 213\nContent-Type: application/json; charset=UTF-8\nDate: Thu, 17 Nov 2016 10:11:26 GMT\nServer: waitress\n{\n    \"data\": {\n        \"a\": {\n            \"b\": {\n                \"c1\": 1, \n                \"c2\": 2\n            }\n        }, \n        \"id\": \"26ca2cc8-1cff-4d73-88a8-5cde5da05546\", \n        \"last_modified\": 1479377486159\n    }, \n    \"permissions\": {\n        \"write\": [\n            \"basicauth:cbd3731f18c97ebe1d31d9846b5f1b95cf8eeeae586e201277263434041e99d1\"\n        ]\n    }\n}\n```\n```\n$ http :8888/v1/buckets/default/collections/test/records?_fields=a.b.c1,a.b.c2 --auth user:pass\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, Total-Records, ETag, Pragma, Cache-Control, Backoff, Next-Page\nCache-Control: no-cache, no-store\nContent-Length: 105\nContent-Type: application/json; charset=UTF-8\nDate: Thu, 17 Nov 2016 10:13:01 GMT\nEtag: \"1479377486159\"\nLast-Modified: Thu, 17 Nov 2016 10:11:26 GMT\nServer: waitress\nTotal-Records: 1\n{\n    \"data\": [\n        {\n            \"a\": {\n                \"b\": {\n                    \"c2\": 2\n                }\n            }, \n            \"id\": \"26ca2cc8-1cff-4d73-88a8-5cde5da05546\", \n            \"last_modified\": 1479377486159\n        }\n    ]\n}\n```\nBut do you think the behaviour changed in recent versions? How critical is it?\n. I submitted a PR with the fix. If everything goes extremely fast, we could tag, QA and release this afternoon, but tomorrow or monday would be more realistic I suppose. \n. I'll backport it\n. Thanks for the precision!\n. See https://github.com/zopefoundation/transaction/blob/master/CHANGES.rst#201-2016-11-11\n. See issue upstream https://github.com/Pylons/pyramid_tm/issues/49\n. See Pylons/pyramid_tm#52. Fixed upstream. Just updated, take over if you don't want to wait until monday ;)\n. Are you sure it's an easy-pick? I don't see it as such.... As @Natim said somewhere: everything that can be (un)plugged from settings should be mentionned as a capability.  Thanks!. Related: #508 . What's present in event.payload is not totally consistent with the fact that we're doing a BATCH request contained 3 patch operations:\n```\n\n\n\nevent.payload\n\n\n\n{ 'action': 'update',\n  'bucket_id': u'staging',\n  'collection_id': u'gfx',\n  'record_id': u'fd6a9531-af10-79a0-e645-4249218dbf4f',\n  'resource_name': 'record',\n  'timestamp': 1479999631700L,\n  'uri': u'/buckets/staging/collections/gfx/records/fd6a9531-af10-79a0-e645-4249218dbf4f',\n  'user_id': 'basicauth:cbd3731f18c97ebe1d31d9846b5f1b95cf8eeeae586e201277263434041e99d1'}\n```\n```\n\n\n\nevent.impacted_records\n\n\n\n[ { 'new': { u'blockID': u'g1057',\n             u'details': { u'bug': u'https://bugzilla.mozilla.org/show_bug.cgi?id=951422',\n                           u'created': u'2015-11-18T12:52:47Z',\n                           u'name': u'Intel driver < 6.14.10.5216 for DIRECT3D_9_LAYERS on XP',\n                           u'who': u'.',\n                           u'why': u'.'},\n             u'devices': [],\n             u'driverVersion': u'6.14.10.5218',\n             u'driverVersionComparator': u'LESS_THAN',\n             u'enabled': True,\n             u'feature': u'WEBGL_ANGLE',\n             u'featureStatus': u'BLOCKED_DRIVER_VERSION',\n             'id': u'fd6a9531-af10-79a0-e645-4249218dbf4f',\n             'last_modified': 1480064809393L,\n             u'os': u'WINNT 5.1',\n             u'schema': 1479999632223L,\n             u'vendor': u'0x8086'},\n    'old': { u'blockID': u'g1057',\n             u'details': { u'bug': u'https://bugzilla.mozilla.org/show_bug.cgi?id=951422',\n                           u'created': u'2015-11-18T12:52:47Z',\n                           u'name': u'Intel driver < 6.14.10.5216 for DIRECT3D_9_LAYERS on XP',\n                           u'who': u'.',\n                           u'why': u'.'},\n             u'devices': [],\n             u'driverVersion': u'6.14.10.5218',\n             u'driverVersionComparator': u'LESS_THAN',\n             u'enabled': True,\n             u'feature': u'WEBGL_ANGLE',\n             u'featureStatus': u'BLOCKED_DRIVER_VERSION',\n             'id': u'fd6a9531-af10-79a0-e645-4249218dbf4f',\n             'last_modified': 1479999631630L,\n             u'os': u'WINNT 5.1',\n             u'schema': 1479999211622,\n             u'vendor': u'0x8086'}},\n  { 'new': { u'blockID': u'g1249',\n             u'details': { u'bug': u'https://github.com/mozilla/addons-server/issues/3787',\n                           u'created': u'2016-10-20T11:51:45Z',\n                           u'name': u'GFX-blocklist-test',\n                           u'who': u'test',\n                           u'why': u'test'},\n             u'devices': [u'0x9616'],\n             u'driverVersion': u'8.723.0.0',\n             u'driverVersionComparator': u'EQUAL',\n             u'enabled': True,\n             u'feature': u'DIRECT3D_11_LAYERS',\n             u'featureStatus': u'BLOCKED_DRIVER_VERSION',\n             'id': u'5bbd4751-5616-a3cc-e31c-1d04ade888bf',\n             'last_modified': 1480064809430L,\n             u'os': u'All',\n             u'schema': 1479999632223L,\n             u'vendor': u'0x1002'},\n    'old': { u'blockID': u'g1249',\n             u'details': { u'bug': u'https://github.com/mozilla/addons-server/issues/3787',\n                           u'created': u'2016-10-20T11:51:45Z',\n                           u'name': u'GFX-blocklist-test',\n                           u'who': u'test',\n                           u'why': u'test'},\n             u'devices': [u'0x9616'],\n             u'driverVersion': u'8.723.0.0',\n             u'driverVersionComparator': u'EQUAL',\n             u'enabled': True,\n             u'feature': u'DIRECT3D_11_LAYERS',\n             u'featureStatus': u'BLOCKED_DRIVER_VERSION',\n             'id': u'5bbd4751-5616-a3cc-e31c-1d04ade888bf',\n             'last_modified': 1479999631664L,\n             u'os': u'All',\n             u'schema': 1479999211622,\n             u'vendor': u'0x1002'}},\n  { 'new': { u'blockID': u'g1239',\n             u'details': { u'bug': u'https://bugzilla.mozilla.org/show_bug.cgi?id=838845',\n                           u'created': u'2016-10-18T09:29:16Z',\n                           u'name': u'GFX1-Val',\n                           u'who': u'test',\n                           u'why': u'test'},\n             u'devices': [u'0x4396'],\n             u'driverVersion': u'6.1.7601.18328',\n             u'driverVersionComparator': u'LESS_THAN_OR_EQUAL',\n             u'enabled': True,\n             u'feature': u'DIRECT3D_10_LAYERS',\n             u'featureStatus': u'BLOCKED_DRIVER_VERSION',\n             'id': u'cf217981-2c42-76bf-df19-4324a194a075',\n             'last_modified': 1480064809477L,\n             u'os': u'All',\n             u'schema': 1479999632223L,\n             u'vendor': u'0x1002'},\n    'old': { u'blockID': u'g1239',\n             u'details': { u'bug': u'https://bugzilla.mozilla.org/show_bug.cgi?id=838845',\n                           u'created': u'2016-10-18T09:29:16Z',\n                           u'name': u'GFX1-Val',\n                           u'who': u'test',\n                           u'why': u'test'},\n             u'devices': [u'0x4396'],\n             u'driverVersion': u'6.1.7601.18328',\n             u'driverVersionComparator': u'LESS_THAN_OR_EQUAL',\n             u'enabled': True,\n             u'feature': u'DIRECT3D_10_LAYERS',\n             u'featureStatus': u'BLOCKED_DRIVER_VERSION',\n             'id': u'cf217981-2c42-76bf-df19-4324a194a075',\n             'last_modified': 1479999631700L,\n             u'os': u'All',\n             u'schema': 1479999211622,\n             u'vendor': u'0x1002'}}]\n``. Just putauthMethods: ['basicauth']here https://github.com/Kinto/kinto/blob/master/kinto/plugins/admin/src/index.js#L9. We could remove${resource_name}_idand leaveuriwith the value of the plural endpoint for example.. I think there is some confusion here. The problem concerns the events that have several impacted records.\nFor example, a batch request that \u00abputs\u00bb 3 records on the same collection. You'll see thatrecord_idanduriin the event payload don't make sense. I suggest that we remove${resource_name}_idand leaveuri` with the value of the plural endpoint when there is more than one impacted record.\n. r=me. Yes! exactly that's the way it works! it's pretty awesome once you figure out the workflow :)\nWe'll wait for the tests to pass, and you'll have your code integrated once merged :). Is there any good reason to keep 0.0.0.0 instead of 127.0.0.1 since it is rather unlikely that users will serve their kinto publicly with pserve?. Hi!\nAwesome if you're willing to contribute the change!\nThere isn't much you can centralize I'm afraid :/ \nThe docs reflect what the command output shows, and the configuration test will assert your change in the template.\nThe only exception is the loadtest where I think we can leave 0.0.0.0 since we may load test via a real network...\nThanks!\n. Oh, interesting!\nThat may be related to the PYTHONPATH, which wouldn't contain the appropriate path to the source code. We do some black magic here:\nhttps://github.com/Kinto/kinto/blob/master/docs/conf.py#L33\nMaybe we should improve that.... @Natim r?. I'd rather go with exclude on this one.\nIf I start a new project, I don't want to ask an administrator to change the server configuration to enable something like history on a collection...\nFor the signer plugin we could have:\nini\nkinto.history.exclude_resources = /buckets/blocklists-preview /buckets/blocklists\nAnd I don't think the kinto-changes generates any event, so it might not be tracked in the history. We can also consider getting rid of the ResourceChanged events in the  kinto-signer if that makes sense.. Note: this is due to:\n https://github.com/Kinto/kinto/blob/master/kinto/core/authorization.py#L136 (* instead of [^/]+)\n https://github.com/Kinto/kinto/blob/master/kinto/core/permission/postgresql/init.py#L224 which does not surround the pattern with ^$. . I realized that real pattern matching (~) is very slow compared to LIKE in Postgres.\nThe need of pattern matching is limited to:\nPermission backend:\n delete every access control entries that starts with a parent id /parent/%\n obtain accessible objects in a plural endpoint ^/object/uri/([a-Z0-9-_])+$\nStorage backend:\n delete all and purge deleted with parent id that starts with /parent/%\n get_all  with parent id that starts with /parent/%\nSo the only use case we have for pattern matching is the get_accessible_objects() where we cannot use LIKE /parents/% because we don't want to include children (see bug #965). Using SIMILAR TO in PostgreSQL appears to be more efficient than POSIX regexps, but does not support the whole range of regexp operators. \nSo finally, I suggest that we stick to * instead of being able to pass POSIX regexps, since it would imply a big loss of performance. See #974.\nClosing, please reopen if you think I miss a point!. We could stick to LIKE and have more perf gain:\n```\n[dbname] # SELECT COUNT(*) FROM access_control_entries WHERE object_id SIMILAR TO '/buckets/[a-zA-Z-_]+';\n count \n\n 6\n\n(1 row)\nTime: 30,519 ms\n```\n```\n[dbname] # SELECT COUNT(*) FROM access_control_entries WHERE object_id LIKE '/buckets/%' AND object_id NOT LIKE '/buckets/%/%';\n count \n\n 6\n\n(1 row)\nTime: 4,435 ms\n``. Side note: we'll probably drop that weirdbasicauth` authentication once #795 will land.\n. We'll drop basic auth in #1736 \nClosing as won't fix :) . >> 1. How should responses be documented?\n\n\nI think currently cornice does not support that @leplatrem ? Maybe this can be added as docstrings and extracted from there?\n\n\n\nIndeed, there's nothing in Cornice right now. We could add extra attributes on Cornice services to specify the responses schemas.\nAs you noted already, in Kinto we still have some custom validation that should be moved to Colander schemas (see #873 #880).\n\nIf it makes sense to use cornice_swagger, then go ahead, but if it doesn't suit our use cases, then I don't want to spend a lot of time trying to force it to fit.\n\nWe can keep this as a long term goal indeed, and use that use-case to help the library improve until we obtain an output that is good enough. (Be aware that some do not agree on the automated approach: https://larlet.fr/david/blog/2016/specifications-apis/)\n\n@gabisurita proposed making Swagger stuff into a plugin.\n\nI would strongly suggested to keep it in the same repo. Especially because the spec must evolve very closely with the code. And the tests should break if the spec does not match the resulting API (and vice-versa :)). It could be built-in plugin but what are the arguments in favor of running the API without it?\n\nIf we come up with some way of generating it automatically, it could live in kinto.core so that projects \"inheriting\" from kinto.core could get Swagger support too. \n\nGenerating would be the goal of cornice_swagger I guess. The view itself does not contain anything specific to kinto. The .yml file does. So it's basically like GET /__version__. A project made with kinto.core can provide a swagger definition and the view serves it. So I don't have any objection with having it in kinto.core, but it may require extra efforts to have a clean separation with regards to testing (or maybe not you already did everything the right way)\nI don't remember its name, but there's a Pyramid project that makes sure your requests/responses match the specifications you expose. That's something we could investigate to make sure our spec remains up-to-date with the code...\nAwesome contribution again :) \ud83d\udc4f \n. > Also, should we show it as a capability?\nWe keep capabilities for API features that can be disabled/enabled from settings. So, I would say that no capability would be required (like for GET __version__)\n\nimaging an use case like this we could also split the current spec into kinto.core and kinto specs and merge them during generation. What do you think?\n\nThat's a nice idea! We could also apply the same strategy when plugins are included (e.g config.add_openapi_entry(...)). But let's keep that for another round, the scope of this PR is good enough IMO\n\nThe one I'm aware of is pyramid_swagger. Unfortunately it's not suitable for some use cases because of limitations on the spec.\n\nTake it easy, you'll even have time to contribute to the spec ;)\n. I'm in favor of merging it too!\nThere's one little detail that we discussed recently: the URL /swagger.json. We don't have this .json suffix in any of the other endpoints, and since the spec is evolving to Open API, maybe we should not insist too much on the former name swagger. \nIn Shavar @tarekziade used the URL /__api__ which is agnostic and consistent with the other ones like /__version__ or /__heartbeat__.  https://github.com/mozilla-services/shavar/pull/78/\nI don't want to delay the merging of this PR, but if you agree we can create an issue and think about it before we release the next Kinto version :)\nCongrats!. . Thanks for taking the time to fix that!. Thanks for reporting! \nIt is strange that no test was broken oO. I must say that beyond the elegance of this patch, I'm really pleased by the quality of the pull-request (tests notably etc.) \ud83d\udc4d . > This may be a cornice/colander issue\nYes, this can be fixed in cornice. By adding a cornice >= 2.3 in setup.py, the tests should pass now :). :huge thanks:. You know what, I'm done with this. Life is too beautiful to ruin it with crazy sh$\u00a4 like UnicodeDecodeError and bytes-like object required.\n. I was wrong about webob, at least regarding request.path (some other issues exist with parameters like https://github.com/Pylons/webob/issues/161).\nThe request.matchdict (Pyramid url dispatch) has unicode, whereas request.path hasn't.\nHence the great simplification.\n. I suppose that the returned entries should match the deleted objects.\nFor consistency, we can consider that _limit should limit the number of objects to delete.. I don't understand how would that be used? As filters like _min & _max? \nMy first reaction would be to avoid having those in core since ElasticSearch provides those features already, and the tutorial makes it easy for someone to start implementing it :). I'm tented to close it, since we currently don't have the notion of operation on the data, only filters for returning partial data.\nFeel free to reopen if you have a clear view on how it would look like :) . > This command is really too dangerous\nThis command purges tombstones. That's it! If this is dangerous, then let's not provide the feature, especially now that #991 was merged.\n\nI would differentiate between [...]\n\nHow? With an additional CLI parameter?\n\n/buckets/bid/collections/*/records\n\nBTW there is not such parent. Only parent_id='/buckets/bid/collections/*', collection_id='record'\n. I realize that my previous was very straight to the point, and can be read with a very serious tone :| Sorry if it came out that way, didn't mean to be violent :]. > This command is really too dangerous\nBTW if your usage of Kinto does not rely on offline sync, then it is fine to remove the tombstones!. Closing then!. Does not harm, merging.. THanks! I just pushed your suggestions to master ;). @gabisurita so it should return the total records that will deleted accross all pages right?. could you open an issue please :) ?\nI think it's trivial because we do a get_all() just before performing the deletion.... https://github.com/mozilla-services/kinto-fxa/pull/38/commits/8849ef7db8e553126821d6ff959eb6af62bb2167. seems like a misusage of the Cache class and not an API bug.. Thousand \\o/\n. \ud83d\ude4f . :) \nIndeed... I wouldn't be against raising a 400 when a record uses a reserved word, but that may be a bit radical I don't know!. Runnable means make serve just works. We could add a Makefile entry to fix that.\nI agree that it is very annoying to have to files (eg. git grep). I just found that zest.releaser has the notion of hooks:\nhttps://github.com/zestsoftware/zest.releaser/blob/6.8.1/zest/releaser/tests/functional-with-hooks.txt\nSo that means we could have a release hook that builds the admin before pushing it to pypi. \nFrom a git clone, a make command would be enough.. Tests fail because Pyramid 1.7 is used. @birdbrained could you rebase/update the pull-request please?. Related to #350 \nSolving it would be an easier answer to this question. In the meantime, this could be added to the FAQ. Cannot reproduce :/. The remaining changes to do are nice to have. You can merge as soon as you feel good about the code :)\nGG ! . (are you sure you added a changelog entry?). Thanks for starting this! There are still some things to improve, but at least it is very good to have an exhaustive list of possible settings!. Closing for lack of activity :| Feel free to re-open if you want to continue working on it! Thanks again!. Agree. \nThis is what JSONApi recommands too: http://jsonapi.org/format/#document-meta\nMaybe, the next_page could go to \"links\": {\"next\": \"https://\"} so that we stick to their spec too: http://jsonapi.org/format/#document-links. Just for the reference: we used to rely on If-Modified-Since/If-Unmodified-Since but got rid of them because they are not opaque, in the sense that they should contain an HTTP date, with a precision to second. . Does not seem useful anymore. > Do you have any idea why?\nIt seems related to requests. There was a release 3 hours ago, we can try to downgrade it maybe?\n```\n    AttributeError: 'module' object has no attribute 'epoll'    Traceback: \nFile \"/opt/python/2.7.9/lib/python2.7/unittest/case.py\", line 329, in run\ntestMethod()\n\nFile \"loadtest/tutorial.py\", line 21, in test_tutorial\nself.play_user_default_bucket_tutorial()\n\nFile \"loadtest/tutorial.py\", line 27, in play_user_default_bucket_tutorial\ncollection_url = self.collection_url('default', collection_id)\n\nFile \"loadtest/init.py\", line 85, in collection_url\nheaders={'If-None-Match': '*'})\n\nFile \"/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/requests/sessions.py\", line 546, in put\nreturn self.request('PUT', url, data=data, **kwargs)\n\nFile \"/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/loads/measure.py\", line 82, in request\nmethod, url, headers=headers, **kwargs)\n\nFile \"/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/requests/sessions.py\", line 488, in request\nresp = self.send(prep, **send_kwargs)\n\nFile \"/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/loads/measure.py\", line 90, in send\nres = _Session.send(self, request, **kwargs)\n\nFile \"/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/requests/sessions.py\", line 609, in send\nr = adapter.send(request, **kwargs)\n\nFile \"/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/requests/adapters.py\", line 423, in send\ntimeout=timeout\n\nFile \"/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/requests/packages/urllib3/connectionpool.py\", line 588, in urlopen\nconn = self._get_conn(timeout=pool_timeout)\n\nFile \"/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/requests/packages/urllib3/connectionpool.py\", line 241, in _get_conn\nif conn and is_connection_dropped(conn):\n\nFile \"/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/requests/packages/urllib3/util/connection.py\", line 27, in is_connection_dropped\nreturn bool(wait_for_read(sock, timeout=0.0))\n\nFile \"/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/requests/packages/urllib3/util/wait.py\", line 33, in wait_for_read\nreturn _wait_for_io_events(socks, EVENT_READ, timeout)\n\nFile \"/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/requests/packages/urllib3/util/wait.py\", line 22, in _wait_for_io_events\nwith DefaultSelector() as selector:\n\nFile \"/home/travis/virtualenv/python2.7.9/lib/python2.7/site-packages/requests/packages/urllib3/util/selectors.py\", line 364, in init\nself._epoll = select.epoll()\n\n1 occurrences of: \nAttributeError: 'module' object has no attribute 'epoll'    Traceback:\n\nFile \"/opt/python/2.7.9/lib/python2.7/unittest/case.py\", line 329, in run\ntestMethod()\n\n```\n. Is this still valid?. Are you sure it's not the case? \nIs this only for Memory?\nI can see that we catch all SQLAlchemy errors in the PostgreSQL client already?\nNote: see https://github.com/Kinto/kinto-redis/blob/master/kinto_redis/storage.py#L14-L22. What error can happen with the memory cache backend?. > better to make this explicit.\nWorks for me!\n\nkeep SimpleSchema, PartialSchema and StrictSchema on the viewset?\n\nIf not used, and not mentionned in docs, I'm not again removing them :) \n. This is excellent work. You never stop raising the bar \ud83d\udc4d \ud83d\udc4d . In many places we do something like that:\npy\nheaders = self.headers.copy()\nheaders.update({'Etag': '\"123\"'})\nWith Python3, now we can do:\npy\nheaders = {**self.headers, 'Etag': '\"123\"'}\nor\npy\nheaders = {**self.headers, **get_user_headers('mat')}. We could also remove deprecated stuff like:\n class Toto(object)\n super(Toto, self).__init__(*args, **kwargs)\n* String formatting with %\n. > Can we do it in multiple PR?\nWhy not!\nThere is also the raise from for the backend errors. >>    There is also the raise from for the backend errors\n\nCan you elaborate on that?\n\nI think we can do raise BackendError(original=e) from e  instead of just raise BackendError(original=e) to keep a proper stacktrace. Nice! \nAre there some flake8 options to prevent us from using deprecated features of python 3? (like \"hello %s\" % name?. > I don't think %s is a deprecated feature of Python3 to be honest :)\nSaw that here:\nHowever, the % operator is still supported; it will be deprecated in Python 3.1 and removed from the language at some later time.)\n https://docs.python.org/3/whatsnew/3.0.html#pep-3101-a-new-approach-to-string-formatting . Tracking of this will happen in kinto-admin repo. Thanks for the feedback!. My proposition (instead of breaking compatibility with 9.4) would be to:\n Take your fix using ON CONFLICT when running PostgreSQL 9.5\n Remove the retry decorator?\n Keep an issue opened and mention the known problem with cache and 9.4 in the docs\n Later, when releasing version 6.0 we can drop 9.4 support (there are other things to change, like create index if not exists etc.). Should we rename that PR into Upgrade to PostgreSQL 9.5 ? And change the index creation too?. > @leplatrem final r+?\nI would just improve the CHANGELOG a bit with a sentence instead of just Postgresql 9.5, no? This is not a blocker though, so r+ :). Quick note on maintainance: I'd rather continue to submit patches to the master branch. Then, when we want to release 5.3.X, we backport the pull-request (usually with a simple git cherry-pick -m 1 <merge-commit>). Duplicating the PRs like this and #1056 can end-up being confusing IMO. > patch are different between the master 6.X and the 5.X branch\nGotcha, but maybe we can handle the situation in the content of the commit that backports the change? (not sure what's best, let's see next time...). . See https://github.com/Kinto/kinto/blob/master/kinto/init.py#L82-L84. Yup, by design this information is not available. I'm closing, feel free to reopen with protest signs if necessary :D . Yes indeed it is official:\n```\nThe meaning of \"If-Match: *\" is that the method SHOULD be performed\n   if the representation selected by the origin server (or by a cache,\n   possibly using the Vary mechanism, see section 14.44) exists, and\n   MUST NOT be performed if the representation does not exist.\n```\nThis spec is so hard to grasp...\n. You can see that we received a request with ?_since=1.0979741403836703e+248 :) . Thanks for looking at this!\nDon't worry, you're not off the track. logs.py is the place where the logger are instantiated. They are then use throughout the application.\nIn this issue, we'd like to log access control failures with warn. It means we want to log something when:\n a user authentication is not valid\n a user tries to access/modify an object without permissions.\nThe first part is more complex and can be done in a second step/ticket, but the second happens here in the authorization code:\nhttps://github.com/Kinto/kinto/blob/5.3.5/kinto/core/authorization.py#L53\nBasically we'd like to log warn something when the permits method returns False\nLet's know! Don't hesitate to submit a draft ;)\nThanks again!. > Is there an actual permits method, or did you mean permission?\nI sent you a link that points to it ;)\n\nadd on log statements in logs.py to facilitate logging\n\nI don't follow you. Wouldn't something like that be sufficient ?\npy\nif not allowed:\n    logger.warn(\"{userid} is not allowed to {permission} {object_id}\".format(...))\n. Thanks for your feedback!\nAccording to what I read here, the POST data should be logged too no?\nI guess it makes sense to have this endpoint in Kinto if the Content-Security-Policy header is set here too (to assure report-uri value consistency). \nSo at least we can document the nginx configuration in the production docs, so let's keep this issue opened :)\n. We should get the respective validators from request.registry.id_generators and makes sure it matches.\nNote: this also applies to groups and collections.. Nice! Thanks! \nI guess the best way would be to contribute the appropriate changes to your branch. Let's hunt those black holes!. This is definitely a bug. Good catch!. No.. We track kinto-admin issues there, closing ;) . Current status\n----------- coverage: platform linux, python 3.5.3-final-0 -----------\nName                                           Stmts   Miss Branch BrPart  Cover   Missing\n------------------------------------------------------------------------------------------\nkinto/__init__.py                                 32      0      8      0   100%\nkinto/__main__.py                                 86      0     30      0   100%\nkinto/authorization.py                            43      0     16      0   100%\nkinto/config/__init__.py                          44      0      6      0   100%\nkinto/core/__init__.py                            54      0      8      0   100%\nkinto/core/api.py                                 50      0     12      1    98%   108->113\nkinto/core/authentication.py                      24      0      4      0   100%\nkinto/core/authorization.py                      124      0     46      1    99%   29->33\nkinto/core/cache/__init__.py                      34      0      2      0   100%\nkinto/core/cache/memory.py                        59      0     15      0   100%\nkinto/core/cache/postgresql/__init__.py           65      0     10      0   100%\nkinto/core/cache/testing.py                      133      0      4      0   100%\nkinto/core/decorators.py                          29      0      4      0   100%\nkinto/core/errors.py                              68      0     12      0   100%\nkinto/core/events.py                              92      0     32      0   100%\nkinto/core/initialization.py                     324      0     88      0   100%\nkinto/core/listeners/__init__.py                   5      0      0      0   100%\nkinto/core/logs.py                                55      0     21      0   100%\nkinto/core/permission/__init__.py                 52      0      2      0   100%\nkinto/core/permission/memory.py                  116      0     50      0   100%\nkinto/core/permission/postgresql/__init__.py     176      0     52      0   100%\nkinto/core/permission/testing.py                 314      0      8      0   100%\nkinto/core/resource/__init__.py                  521      0    182      1    99%   702->705\nkinto/core/resource/model.py                      84      0      6      0   100%\nkinto/core/resource/schema.py                    191      0     30      0   100%\nkinto/core/resource/viewset.py                   111      0     14      0   100%\nkinto/core/schema.py                              52      0     10      0   100%\nkinto/core/scripts.py                             46      0     12      0   100%\nkinto/core/statsd.py                              40      0     12      0   100%\nkinto/core/storage/__init__.py                    52      0      4      0   100%\nkinto/core/storage/exceptions.py                  16      0      2      0   100%\nkinto/core/storage/generators.py                  20      0      4      0   100%\nkinto/core/storage/memory.py                     201      0     89      1    99%   368->372\nkinto/core/storage/postgresql/__init__.py        323      0     98      1    99%   124->111\nkinto/core/storage/postgresql/client.py           63      0     16      0   100%\nkinto/core/storage/postgresql/pool.py             25      0      4      0   100%\nkinto/core/storage/testing.py                    751      0     48      0   100%\nkinto/core/testing.py                            105      0      6      0   100%\nkinto/core/utils.py                              237      0     80      2    99%   166->160, 221->224\nkinto/core/views/__init__.py                       0      0      0      0   100%\nkinto/core/views/batch.py                         79      0     21      0   100%\nkinto/core/views/errors.py                        66      0     24      0   100%\nkinto/core/views/heartbeat.py                     45      0     12      0   100%\nkinto/core/views/hello.py                         25      0      6      0   100%\nkinto/core/views/swagger.py                       15      0      0      0   100%\nkinto/core/views/version.py                       26      0      4      0   100%\nkinto/events.py                                    3      0      0      0   100%\nkinto/plugins/__init__.py                          0      0      0      0   100%\nkinto/plugins/admin/__init__.py                   14      0      0      0   100%\nkinto/plugins/admin/views.py                      10      0      0      0   100%\nkinto/plugins/default_bucket/__init__.py         104      0     20      0   100%\nkinto/plugins/history/__init__.py                 12      0      2      0   100%\nkinto/plugins/history/listener.py                 71      0     24      0   100%\nkinto/plugins/history/views.py                    37      0      8      0   100%\nkinto/plugins/quotas/__init__.py                   9      0      2      0   100%\nkinto/plugins/quotas/listener.py                 128      0     54      1    99%   160->133\nkinto/plugins/quotas/utils.py                      4      0      0      0   100%\nkinto/views/__init__.py                           22      0      2      0   100%\nkinto/views/buckets.py                            19      0      4      0   100%\nkinto/views/collections.py                        39      0      6      0   100%\nkinto/views/contribute.py                          9      0      0      0   100%\nkinto/views/flush.py                              12      0      0      0   100%\nkinto/views/groups.py                             38      0     14      0   100%\nkinto/views/permissions.py                        90      0     38      0   100%\nkinto/views/records.py                            68      0     12      0   100%\n------------------------------------------------------------------------------------------\nTOTAL                                           5762      0   1300      8    99%. I remember that we removed id and last_modified from the schemas in the early weeks of Cliquet. \nSee it was there https://github.com/mozilla-services/cliquet/blob/1.3.0/cliquet/schema.py#L31\nLike an old grandpa, I don't always remember the details of the stories... but with some git bisect and grep black magic you could find the commit/PR that removed it and possibly find some explanation! It does mean that what you'll find will still be relevant ;)\nNow, I see no objection for moving the id generation/validation to the schema instead of resource. That's the purpose of schemas.. TBH I don't know. \nEven last_modified could be present with a missing=drop. Currently what happens when last_modified is specified with \"abc\" ?\nDo not hesitate to restore them if it solves your issues ;). Do we have that feature? Isn't this a duplicate of https://github.com/Kinto/kinto/issues/344 ?. Gabi, could you give us a summary about the current state of this PR so that we can go forward please? Thanks!. The destination branch should be 5.X then :) . awright. https://twitter.com/ThePracticalDev/status/833770687940669441\n. > If we want to fix the behaviour we should get rid of ETag's all together I guess because we are not using Etag as OPS understand they should work.\nHuh, what?. If you set the project_name to webpush_channels, then this is a bug. I assigned you as a way to ping, nothing else ;)\nLe 23 f\u00e9vr. 2017 18:06, \"Gabriela Surita\" notifications@github.com a\n\u00e9crit :\n\nFrom the API perceptive, I like the idea of making it a filter (e.g.\nrecords/id?_at=), but I'm not sure if this is feasible in\na plugin (it probably is, but will be ugly) and I also don't think this\nshould be part of the core.\nI think a new view is the easiest approach if we are doing it on the\nserver and want to keep it as a plugin.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/Kinto/kinto/issues/1104#issuecomment-282055020, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAhXhNXgE_cdpTUEOEhzVWq4Vo1ttYUcks5rfbyAgaJpZM4MKCp9\n.\n. I've got another idea: we do it on the client side \ud83d\ude07. This was successfully implemented in kinto-http.js, the code is straightforward.\nSee https://github.com/Kinto/kinto-http.js/pull/161. >> I'm sorry that you already wrote so much code :|\nWhy are you sorry? Isn't it great? It is just a matter of handling permissions right?\n\nYeah \u00abjust\u00bb :) \nAlso, does it provide ETag etc as if it would be the usual endpoint?. >>  does it provide ETag etc as if it would be the usual endpoint?\n\nActually it is not a usual endpoint and it doesn't plan to be one. What would be the use case?\n\n'cuz @n1k0 mentioned use-cases like initial synchronization or replication, but appart from building a diff from a list of changes I don't have any use-case for this endpoint anyway :D\n. > So we should probably give a shot at a client side implementation of the feature in kinto-http.js.\nYes, at least give it a try \ud83c\udf89 \n\nYou mentioned it was trivial, while I feel some complexity here, so my question is, do you want to pair on this? \ud83d\ude0a\n\nIf I'm not wrong, it's just a matter of writing this part in JS, which replays the history from the start:\n```py\n    # We want to get the record at a certain time.\n    filters = [Filter('target.data.last_modified', last_modified, COMPARISON.MAX),\n               Filter('resource_name', resource_name, COMPARISON.EQ),\n               Filter('uri', parent_id, COMPARISON.LIKE)]\n    sorting = [Sort('last_modified', -1)]\nrecords, count = request.registry.storage.get_all(\n    collection_id='history', parent_id=bucket_uri,\n    filters=filters, sorting=sorting)\n\n# Only process records once\nalready_processed = set()\nresults = []\nfor record in records:\n    record_id = record['target']['data']['id']\n    if record_id not in already_processed:\n        already_processed.add(record_id)\n        if record['target']['data'].get('deleted') is not True:\n            results.append(record['target']['data'])\n\nreturn {\"data\": results}\n\n```\nWhich would give something like that:\n```js\nconst entries = yield client.listHistory({\n  'max_target.data.last_modified': timestamp,\n  resource_name: \"record\",\n  collection_id: cid,\n  bucket_id: bid\n})\nconst recordsById = entries.reduce((entry, acc) => {\n  const {target: {data}} = entry;\n  const {id, deleted} = data;\n  if (id in acc) {\n    if (deleted) {\n      delete acc[id];\n    }\n    return acc;\n  }\n  acc[id] = data;\n  return acc;\n}, {});\nconst results = Object.values(recordsById)\n  .sort(({last_modified: a}, {last_modified: b}) => a - b);\n```\nThere is another approach, which consist in applying the history backwards. The code would be a bit more complex, but it would be cheaper in resources (especially on collections with frequent changes). edit: going backwards also solve the problem when the history plugin was not enabled from the beginning.\nNote: In our use case, we don't have to deal with permissions since the obtained history entries already take them into account. \nWe can pair on this on Monday, but I always feel bad when lots of code/efforts are at stake :| . It could be a make tdd that runs the ptw command with the appropriate parameters. Would that mean going away from structlog?\nI'm +0 :). I'll try to drop the built-in Heka renderer and use https://github.com/mozilla/mozilla-cloud-services-logger in Kinto-dist. If the output is alright, we'll get rid of code \\o/. We're doing something wrong, we should get rid of our logging_renderer setting.\nWe could get rid of structlog custom initialization I think.. ```\nhttp put https://kinto.dev.mozaws.net/v1/buckets/a -a a:a\nHTTP/1.1 201 Created\nAccess-Control-Expose-Headers: Content-Length, Retry-After, Backoff, Alert\nConnection: keep-alive\nContent-Length: 152\nContent-Type: application/json\nDate: Tue, 07 Mar 2017 12:58:50 GMT\nETag: \"1488891530236\"\nLast-Modified: Tue, 07 Mar 2017 12:58:50 GMT\nServer: nginx\nX-Content-Type-Options: nosniff\n{\n    \"data\": {\n        \"id\": \"a\", \n        \"last_modified\": 1488891530236\n    }, \n    \"permissions\": {\n        \"write\": [\n            \"basicauth:cec4ef00dfaac462ae18c78f53798e1ee0bb25b583a6f9056e8d001d58e0f56d\"\n        ]\n    }\n}\n```\n```\n\u279c  ~ http delete https://kinto.dev.mozaws.net/v1/buckets -a a:a\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Retry-After, Backoff, Alert\nConnection: keep-alive\nContent-Length: 66\nContent-Type: application/json\nDate: Tue, 07 Mar 2017 12:58:52 GMT\nETag: \"1488891532818\"\nLast-Modified: Tue, 07 Mar 2017 12:58:52 GMT\nServer: nginx\nTotal-Records: 1\nX-Content-Type-Options: nosniff\n{\n    \"data\": [\n        {\n            \"deleted\": true, \n            \"id\": \"a\", \n            \"last_modified\": 1488891532818\n        }\n    ]\n}\n```\nShall we close?. When the provided old does not have the same length as the new. So in the resource view collection_delete(), when the delete_records() does not return the same length as get_all() ?. In the resource code, in collection_delete() we do:\n1. records = get_all()\n1. deleted = delete_all()\n1. notify(deleted, action=action, old=records)\nThere can be a race condition between 1. and 2.\nWith #1386 we could have only one call to delete_all()\n/cc @glasserc \nhttps://github.com/Kinto/kinto/blob/5426bbde435970bf9c1bd70b48b84f4d6e3e2ebb/kinto/core/resource/init.py#L372-L379. Nice, thanks! . > Should we wait for #1095?\nIt was marked as WIP so I didn't bother... What do you think?. \n. Are you sure the changes are necessary in the PostgreSQL backend?\nIf yes, then the ignore_conflict placeholder might not be necessary anymore no?. Both changes are related and would probably require a test. BRB. There's a problem with Travis tests that I can't explain. I'd rather raise when trying to cache bytes, so that we have clean signature in the interface.\nBut if you have good reason to cast, please do!. > it might break a bunch of plugins\nWe can bump a major, no problem. #1144 also introduces breaking changes in kinto.core.testing. Results (158.43s):\n    1715 passed. On Travis, the total time goes from 37 min to 11 min.. > if we are moving flush maybe it also makes sense to move the permission endpoint.\n+1. Thanks!. Thanks for noticing!\nI'm on it. The project was configured with Python 2.7 and was failing to install. It should be back soon!\n. Done, thanks again! . The default configuration with make serve does not output (sub)request summaries. We should fix that before merging.. The fact that (sub)request logs are swallowed is to due to https://github.com/Pylons/pyramid/issues/2975 \nI will see if I can fix it by limiting import side effects in kinto/core/__init__.py and kinto/__init__.py. The only way I could achieve what I desired was to move the formatter out of the package.\nOtherwise Python logging module will import the parents modules of the formatter (hence kinto, kinto.core), and pserve will then get rid of our loggers if not explicit defined in .ini. \nIt is now fixed using an external package :) . you're welcome :). It is a good plan mainly because we could have the same problem in app.wsgi too. \nThe piece of code that recursively imports the parent modules of the specified formatter is in Python logging stdlib. Thanks!. +1 to forbid them explicitly. I wonder why we had for that.. Excellent ! Thanks! . I agree, this would be the cleanest strategy.\nHowever the dump/load idea can be implemented in less than 50 lines, whereas the sqlite requires a lot more efforts (sql queries, migrations, ...). It was mainly done for huge collections, since the tombstones are returned in the response. \nIf the server defines a limit of 100 records per response to keep response payloads small. Why would it return 25K records when deleting a huge collection?. Hi!\nWelcome on board!\nI will try to answer your questions, let us know what you think and we can drill down into details :)\n\ncan we use PostGIS with Kinto ?\n\nIn short: you can use PostGIS in the Kinto database but the provided backend code does not use PostGIS.\nYou can enhance the default DB schema with your custom tables, views, columns, triggers or whatever, but our backend code won't be aware of it. Of course, you could implement your own geospatial backend, and even publish it as a package for the community if you like :)\nMay I ask: do you really need PostGIS or you just want to do geospatial queries on your data? For the latter, the ElasticSearch approach would really be the most efficient IMO :)\n\ncould use a custom PostgreSQL schema ?\n\nThere are two strategies:\n\nyou keep the provided Postgresql backend, and you define a trigger that will spread the JSON field into your typed fields\nyou define your own Postgresql backend, and you store the data the way you want from the dict objects you'll receive in the Python code\n\nHope it clarifies a bit :) \n. Closing, please re-open if you have more questions on the same topic!. In theory we should be able to use both (I mean for consistency). I suggest that we keep this open and investigate what we can do (fix bug, document limitation, raise configurationerror ... ). > How would that work? Check if an account exist and use it otherwise generate a basicauth principal?\nWe rely on Pyramid Multiauth. It iterates on every auth methods until one is successful.\nI agree this can be very confusing. For example in prod, we once had ldap+basicauth and when users entered wrong ldap credentials they would end up authenticated as basicauth:* instead of receiving 401.. Good catch! Thanks!. Fixed now. https://online.swagger.io/validator?url=https://settings.stage.mozaws.net/v1/api. I'm ok to close. We can re-open if it happens again on the 6.X version (deployed in prod at https://firefox.settings.services.mozilla.com/v1/). I updated the changelog, thanks Gabi!. Looks like tests are broken :(. Could you try with https://unpkg.com/kinto-http@4.2.0/dist/kinto-http.min.js ?\nThere seems to be a packaging issue in kinto-http.js 4.3.X (released yesterday). > First pass at a Thimble project using Kinto for storage, and works great!\n\nhttps://thimbleprojects.org/flukeout/250660/\n\nThis is awesome! Yeah! . Problem comes from here: https://github.com/Kinto/kinto/blob/6.0.5/kinto/core/storage/postgresql/init.py#L703\nWhere all([is_numeric(v) for v in value]) is True for empty strings/lists. Related https://github.com/Kinto/kinto/issues/344. Unfortunately I couldn't find it. It looks like our logger crashed when trying to output the JSON #DoubleFail\nAnd I couldn't access Kibana either :( . This occurred on a request on the records of the crypto collection (/v1/buckets/default/collections/storage-sync-crypto/records) while creating the underlying bucket: \n```\nWITH delete_potential_tombstone AS (\n            DELETE FROM deleted\n             WHERE id = '448cfa42-e013-a3f2-657b-XXXXXXXXXXX'\n               AND parent_id = ''\n               AND collection_id = 'bucket'\n        )\n        INSERT INTO records (id, parent_id, collection_id, data, last_modified)\n        VALUES ('448cfa42-e013-a3f2-657b-XXXXXXXXXXX', '',\n                'bucket', ('{}')::JSONB,\n                from_epoch(NULL))\n        ON CONFLICT (id, parent_id, collection_id) DO UPDATE\n        SET last_modified = EXCLUDED.last_modified\n\n    RETURNING id, as_epoch(last_modified) AS last_modified;\n\n```\n\nIsn't it supposed to be the goal of the ON CONFLICT close to handle duplicate key value violates unique constraint errors ?\nAre there concurrent requests on the client that may cause situations like this where two requests on non-existing bucket would overlap? /cc @glasserc . Related #602 . > After the keyring is synced, every extension's collection is synced (in parallel).\n\nStrange then that we ended up with overlaping requests. Let's see if it appears again :). Needs rebase with latests bug fixes. Seems to occur quite often on prod. In storage.update() we first select the record to determine if we'll perform an update or an insert. \nIf a deletion occurs concurrently, then \u2014 when the lock is released \u2014 the UPDATE query will not affect any row, and updated = result.fetchone() will return None. Is it the same as #573 ?. \ud83d\udc4d thanks!. >  I assumed that only the one request would fail, similarly to how it would if I had put a nonmatching If-Match on a single request.\nExactly, that is supposed to be the behaviour with 4XX responses. See #624 \n\nOn the other hand, maybe the entire batch has to fail because I'm rejecting the transaction?\n\nYes, I guess so... but as stated in #624 we must make a decision about consistency there.\nAlso, I'm surprised the message is not You may not delete the storage-sync-crypto collection\nI was thinking, we already have settings to restricts principals for a specific operation. Wouldn't it be easier to extend them with something like like collection_<your-id>_delete_principals = nobody? http://kinto.readthedocs.io/en/stable/configuration/settings.html#bypass-permissions-with-configuration \n. Some failing tests because of #1208 . Now that you found the root cause of our misery (#1211), I'll merge this one :) . This infamous \"where id in\"... \nr+ and huge GG!! I owe you one dude.. r+. Usually we cherry-pick the merge commits. I'll close this and prepare a new 6.X version then.. The failing build on the functional test is very interesting :) We have a edge case that is not covered by unit tests !. Related #343 #344. Related #343 #344. Work around: put quotes around 53:  /records?min_target.version=\"53\". > Is that a feature we support or a side effect?\nWhat?\nWe want to use numeric comparison if both field and filter values are numeric, textual otherwise.. It is not properly documented, so I guess we can classify as side effect :))\n. > Cannot we use the schema to make sure a fields is always of type string even if that string contains only numbers?\nThe storage is not aware of the data schema. But how do you prevent using it twice?. > > But how do you prevent using it twice?\n\nWhy would you want such a thing?\n\nSee original issue description.. Now requires #1232  for tests to pass. Replaced by #1258 . Closing this now that the only remaining one is #1229 (duplicated #360).\nDon't hesitate to re-open if this is inappropriate.. This is a duplicate of https://github.com/Kinto/kinto/issues/360 I believe. @glasserc in you have some bandwidth, I'd gladly ask for help here please...\nI don't explain why the returned value of purge_deleted() has changed with my last changes... It is supposed the number of tombstones that were deleted, and I don't explain why it's not behaving as expected :/ \nThanks!. > Isn't it because your query now returns the deleted tombstones UNION the deleted timestamps and returns the rowcount as the number of deleted things?\nOops, sorry I had an uncommitted local change that was reading the value of SELECT COUNT(*) FROM delete_tombstones... But still it didn't work as expected.\nI reverted the hack to have two delete in a single query. Thanks a lot for helping :] . You can also include #1207 #1214 #1222 #1223 no ?. strange I could reproduce locally with build-hub stuff but not from tests with the exact same data:\n```diff\ndiff --git a/tests/test_views_collections_schema.py b/tests/test_views_collections_schema.py\nindex c88c5a8f..a66a4615 100644\n--- a/tests/test_views_collections_schema.py\n+++ b/tests/test_views_collections_schema.py\n@@ -180,6 +180,169 @@ class RecordsValidationTest(BaseWebTestWithSchema, unittest.TestCase):\n         self.assertEqual(len(resp.json['data']), 1)\n+class RequiredProperties(BaseWebTestWithSchema, unittest.TestCase):\n+\n+    def setUp(self):\n+        super().setUp()\n+        schema = {\n+            \"additionalProperties\": False,\n+            \"description\": \"Mozilla software releases.\",\n+            \"properties\": {\n+                \"build\": {\n+                    \"additionalProperties\": False,\n+                    \"properties\": {\n+                        \"date\": {\n+                            \"description\": \"i.e: 2017-04-13T21:49:00Z\",\n+                            \"format\": \"date-time\",\n+                            \"title\": \"Build date\",\n+                            \"type\": \"string\"\n+                        },\n+                        \"id\": {\n+                            \"description\": \"Build ID\",\n+                            \"title\": \"Build ID\",\n+                            \"type\": \"string\"\n+                        }\n+                    },\n+                    \"type\": \"object\"\n+                },\n+                \"download\": {\n+                    \"additionalProperties\": False,\n+                    \"properties\": {\n+                        \"date\": {\n+                            \"description\": \"Date of the archive\",\n+                            \"format\": \"date-time\",\n+                            \"title\": \"Date\",\n+                            \"type\": \"string\"\n+                        },\n+                        \"mimetype\": {\n+                            \"title\": \"Archive's mimetype\",\n+                            \"type\": \"string\"\n+                        },\n+                        \"size\": {\n+                            \"description\": \"Size of the archive in bytes\",\n+                            \"title\": \"Size\",\n+                            \"type\": \"integer\"\n+                        },\n+                        \"url\": {\n+                            \"description\": \"URL of the archive\",\n+                            \"title\": \"URL\",\n+                            \"type\": \"string\"\n+                        }\n+                    },\n+                    \"required\": [\n+                        \"url\",\n+                        \"mimetype\",\n+                        \"size\",\n+                        \"date\"\n+                    ],\n+                    \"type\": \"object\"\n+                },\n+                \"source\": {\n+                    \"additionalProperties\": False,\n+                    \"properties\": {\n+                        \"product\": {\n+                            \"description\": \"Product name\",\n+                            \"title\": \"Product\",\n+                            \"type\": \"string\"\n+                        },\n+                        \"repository\": {\n+                            \"title\": \"Repository\",\n+                            \"type\": \"string\"\n+                        },\n+                        \"revision\": {\n+                            \"title\": \"Revision number in the tree\",\n+                            \"type\": \"string\"\n+                        },\n+                        \"tree\": {\n+                            \"description\": \"i.e mozilla-central\",\n+                            \"title\": \"Tree\",\n+                            \"type\": \"string\"\n+                        }\n+                    },\n+                    \"required\": [\n+                        \"product\"\n+                    ],\n+                    \"type\": \"object\"\n+                },\n+                \"systemaddons\": {\n+                    \"items\": {\n+                        \"additionalProperties\": False,\n+                        \"properties\": {\n+                            \"builtin\": {\n+                                \"description\": \"Version in release\",\n+                                \"title\": \"Built in version\",\n+                                \"type\": \"string\"\n+                            },\n+                            \"id\": {\n+                                \"title\": \"ID\",\n+                                \"type\": \"string\"\n+                            },\n+                            \"updated\": {\n+                                \"description\": \"Last update version\",\n+                                \"title\": \"Updated version\",\n+                                \"type\": \"string\"\n+                            }\n+                        },\n+                        \"required\": [\n+                            \"id\",\n+                            \"builtin\",\n+                            \"updated\"\n+                        ],\n+                        \"type\": \"object\"\n+                    },\n+                    \"title\": \"Systemaddons\",\n+                    \"type\": \"array\"\n+                },\n+                \"target\": {\n+                    \"additionalProperties\": False,\n+                    \"properties\": {\n+                        \"channel\": {\n+                            \"title\": \"Update channel\",\n+                            \"type\": \"string\"\n+                        },\n+                        \"locale\": {\n+                            \"title\": \"Locale\",\n+                            \"type\": \"string\"\n+                        },\n+                        \"platform\": {\n+                            \"description\": \"Operating system and Architecture\",\n+                            \"title\": \"Platform\",\n+                            \"type\": \"string\"\n+                        },\n+                        \"version\": {\n+                            \"title\": \"Version\",\n+                            \"type\": \"string\"\n+                        }\n+                    },\n+                    \"required\": [\n+                        \"platform\",\n+                        \"locale\",\n+                        \"version\",\n+                        \"channel\"\n+                    ],\n+                    \"type\": \"object\"\n+                }\n+            },\n+            \"required\": [\n+                \"id\",\n+                \"source\",\n+                \"download\",\n+                \"target\"\n+            ],\n+            \"title\": \"Release\",\n+            \"type\": \"object\"\n+        }\n+        resp = self.app.put_json(COLLECTION_URL,\n+                                 {'data': {'schema': schema}},\n+                                 headers=self.headers)\n+\n+    def test_reproduce_1243(self):\n+        record  = {'download': {'size': 35420548, 'url': 'https://archive.mozilla.org/pub/mobile/nightly/2017/05/2017-05-02-10-02-40-mozilla-central-android-api-15-l10n/fennec-55.0a1.gl.android-arm.apk', 'date': '2017-05-02T12:01:11Z', 'mimetype': 'application/vnd.android.package-archive'}, 'id': 'fennec_2017-05-02-10-02-40_55-0a1_android-arm_gl', 'target': {'version': '55.0a1', 'platform': 'android-arm', 'locale': 'gl', 'channel': 'nightly'}, 'source': {'product': 'fennec'}}\n+        self.app.put_json(COLLECTION_URL + \"/records/\" + record[\"id\"],\n+                          {'data': record},\n+                          headers=self.headers)\n+\n+\n class ExtraPropertiesValidationTest(BaseWebTestWithSchema, unittest.TestCase):\n     def setUp(self):\n         super().setUp()\n```. Tests fail because of https://github.com/pypa/setuptools/issues/1042. Thank you very much for this detailed bug report! \nThe account resource contains some hacks to be able to allow anonymous creation and still have a parent_id that makes its content private to each user. We'll look into it :). > We could directly use the Authentication header to grab the user and the password:\nYes, please open an issue, and somebody could work on it :) . Be careful with the over optimism here :) It's not an easy-pick IMO. > Kinto speed is due to the use of ujson. We should definitely keep it.\nDo we have numbers? We did benchmarks 2 years ago with Python 2.7. I continuously read about python 3.6 super performances. We should probably confirm that with updated figures.\n\nTo be honest I would just use ujson everywhere without adding a new setting.\n\n+1  (all or nothing)\n. Related #816  #1157  #1253. > I'm not sure whether this qualifies as a major version and/or API version.\nThe way I see it:\n\nYou fixed inconsistencies and bugs\nThose fixes deserve a mention in the API changelog, so we should bump its version\nI don't think it requires a major dump for the API version ( #1252 didn't :) )\nIt doesn't break anything on the Python side, so major dump in the package version either\n. > We break the technique shown in #344 \n\nWith all due respect, it was very hacky.\n\nWe implicitly discourage the use of fields with the name has_foo\n\nWell, I agree, but acceptable IMO since that's also true for other fields as shown in #1004 . Please open an issue if you think that we should refactor this. . It's already the case (pyramid > 1.8) :). Ideally, if we could have multiple commands in kinto CLI, we should do:\nENTRYPOINT kinto\nCMD migrate start --ini=$INI --port=$PORT. Thanks for your feedback on this!\nI'd like to recall that the Dockerfile of this repo is not the one that is used by ops at Mozilla (we use a distribution of various plugins: kinto-dist).\nI personally find it super convenient to be able to do docker run kinto and get an instance running. But since we use the memory backend by default, we don't need migrate by default.\nSo we can put kinto as the entrypoint, and let the commands be start, migrate etc. as for the CLI.\nThat means if someone wants to run the container with a postgres database, it will be necessary to run migrate and start as separate commands. After giving it some thoughts, it makes sense.\nWe'll still probably need a run.sh file, since we'll want to set --ini $KINTO_INI as a default argument for every command.\n. Thanks for your efforts on this :) . Excellent! If it's the right way, let's do this! I have always found it hard to pick the appropriate pattern with Pyramid :) . Issue introduced in https://github.com/mozilla-services/cliquet/pull/130 . >  It isn't clear exactly why; the commit message just says \"Simplify and fix coverage\"\nThere was a piece of code that was never executed. Since no test was failing without it, I just removed it :) \n. Since #1245 was released, we'll need a changelog entry. Duplicate of #939 \nRelated #508 . Last month, we could make authentication work with Auth0 using the code of this PR #1425.\nIt should be enough to get started on your side. We are tracking Auth0 support via OpenID in #939.. I revamped the little pizzerias example that we had a couple of years ago: \nhttps://github.com/Kinto/kinto-elasticsearch/pull/52/files\nIt just works, I will clean it up and make a blog post out of it.... http://www.servicedenuages.fr/en/kinto-elasticsearch. Can you send config and request please?\nThis is explictly tested so I'm surprised.... Caused by colon in unique key counter, here https://github.com/DataDog/dd-agent/blob/5.14.1/aggregator.py#L446. https://github.com/mozilla-services/foxsec/issues/383. Hooray! Thaaanks!. In Cache, get() that deletes and reads in two different instructions\nhttps://github.com/Kinto/kinto/blob/7.3.1/kinto/core/cache/postgresql/init.py#L142-L150. @glasserc can we close this?. @TaoufikBouabid for Docker with Postgresql the best way to go is docker-compose: docs.kinto-storage.org/en/stable/tutorials/install.html#using-docker-compose\nIf you encounter problems or documentation is not clear, please let us know! Good luck!. Note: \nSince we are pining a precise version here, we should create an issue to remember to get rid of it when upstream is fixed. Thanks for your interest!\nI'm trying to reproduce this and I can't :(\nMaybe it was fixed with #1305 ?\nIn order to be sure, it would be interesting to reproduce the bug.\nFor example, you can try to run Kinto 7.3.1 with a PostgreSQL database. \nOnce you're done with that, you can:\n- create a bucket, a collection and a few records\n- query the list of records with ?query=u0000 in the URL (eg. /buckets/a/collections/b/records?query=u0000)\n- it should crash :) \nIf doing the same thing with the latest master doesn't crash, then we're done, we can close this issue :) \n. @hiteshramani could you look at it?. Alright, so I guess we can close this... Thanks everyone!. (psycopg2.DataError) invalid input syntax for integer: \"\"\nLINE 7: ...onfirm(65534)' = '[\"\",\"\"]') AND as_epoch(last_modified) > ''\n                                                                     ^\n [SQL: '\\n        WITH total_filtered AS (\\n            SELECT COUNT(id) AS count\\n              FROM records\\n             WHERE parent_id = %(parent_id)s\\n               AND collection_id = %(collection_id)s\\n               AND (data->%(filters_field_0_0)s IS NOT NULL AND data->%(filters_field_0_0)s = %(filters_value_0)s) AND as_epoch(last_modified) > %(filters_value_1)s\\n        ),\\n        collection_filtered AS (\\n            SELECT id, last_modified, data\\n              FROM records\\n             WHERE parent_id = %(parent_id)s\\n               AND collection_id = %(collection_id)s\\n               AND (data->%(filters_field_0_0)s IS NOT NULL AND data->%(filters_field_0_0)s = %(filters_value_0)s) AND as_epoch(last_modified) > %(filters_value_1)s\\n        ),\\n        fake_deleted AS (\\n            SELECT (%(deleted_field)s)::JSONB AS data\\n        ),\\n        filtered_deleted AS (\\n            SELECT id, last_modified, fake_deleted.data AS data\\n              FROM deleted, fake_deleted\\n             WHERE parent_id = %(parent_id)s\\n               AND collection_id = %(collection_id)s\\n               AND (data->%(filters_field_0_0)s IS NOT NULL AND data->%(filters_field_0_0)s = %(filters_value_0)s) AND as_epoch(last_modified) > %(filters_value_1)s\\n               \\n        ),\\n        all_records AS (\\n            SELECT * FROM filtered_deleted\\n             UNION ALL\\n            SELECT * FROM collection_filtered\\n        ),\\n        paginated_records AS (\\n            SELECT DISTINCT id\\n              FROM all_records\\n              \\n        )\\n        SELECT total_filtered.count AS count_total,\\n               a.id, as_epoch(a.last_modified) AS last_modified, a.data\\n          FROM paginated_records AS p JOIN all_records AS a ON (a.id = p.id),\\n               total_filtered\\n          ORDER BY last_modified DESC\\n          LIMIT %(pagination_limit)s;\\n        '] [parameters: {'collection_id': 'record', 'filters_field_0_0': 'confirm(65534)', 'pagination_limit': 10000, 'parent_id': '/buckets/blocklists/collections/plugins', 'filters_value_1': '', 'filters_value_0': '[\"\",\"\"]', 'deleted_field': '{\"deleted\":true}'}]. I'm looking at Sentry 8.17.0 but don't know where to find request path/querystring for example\n\n. \n. From what I understand about deadlocks in the official documentation, this happens when two transactions acquire locks on different objects in different order. \nThings that might be worth looking at:\n where is cache.get() used? Appart from pyfxa?\n In the cache backend code, the deletion of expired rows and the select are done in two separate instructions (both are executed in the same transaction, since in the same with connect())\nJust to check the kind of lock, in one terminal I ran:\n```\n[dbname] # BEGIN;\nBEGIN\nTime: 0,823 ms\n[dbname] # DELETE FROM cache WHERE ttl IS NOT NULL AND now() > ttl;\nDELETE 0\nTime: 23,002 ms\n[dbname] # \n```\nAnd in the other one (source)\nsql\n SELECT a.datname,\n         c.relname,\n         l.transactionid,\n         l.mode,\n         l.GRANTED,\n         a.usename,\n         a.query, \n         a.query_start,\n         age(now(), a.query_start) AS \"age\", \n         a.pid \n    FROM  pg_stat_activity AS a\n     JOIN pg_locks         l ON l.pid = a.pid\n     JOIN pg_class         c ON c.oid = l.relation\n    ORDER BY a.query_start;\nAnd we can see that the DELETE FROM cache takes a table level lock:\n```\n-[ RECORD 1 ]-+---------------------------------------------------------\ndatname       | dbname\nrelname       | idx_cache_ttl\ntransactionid | \u00a4\nmode          | RowExclusiveLock\ngranted       | t\nusename       | postgres\nquery         | DELETE FROM cache WHERE ttl IS NOT NULL AND now() > ttl;\nquery_start   | 2017-08-08 09:08:47.311075+00\nage           | 00:02:04.741193\npid           | 29603\n-[ RECORD 2 ]-+---------------------------------------------------------\ndatname       | dbname\nrelname       | cache_pkey\ntransactionid | \u00a4\nmode          | RowExclusiveLock\ngranted       | t\nusename       | postgres\nquery         | DELETE FROM cache WHERE ttl IS NOT NULL AND now() > ttl;\nquery_start   | 2017-08-08 09:08:47.311075+00\nage           | 00:02:04.741193\npid           | 29603\n-[ RECORD 3 ]-+---------------------------------------------------------\ndatname       | dbname\nrelname       | cache\ntransactionid | \u00a4\nmode          | RowExclusiveLock\ngranted       | t\nusename       | postgres\nquery         | DELETE FROM cache WHERE ttl IS NOT NULL AND now() > ttl;\nquery_start   | 2017-08-08 09:08:47.311075+00\nage           | 00:02:04.741193\npid           | 29603\n```\n. It looks like you're making progress, at least in the understanding of the lock and transactions subtleties ;)\nThe order of rows in the delete was a very good catch! \nIndeed, the cache index on ttl is not created on a specific order (could be CREATE INDEX ON cache(ttl ASC) for example) like the last_modified in the records table. And the DELETE query is not ordered either (could be DELETE FROM cache WHERE key IN (SELECT key FROM cache ORDER BY ttl ASC for example). \n\nIt seems like writing an automated test for this would be quite difficult?\n\nYes I agree\n\nTo preserve correctness, we could add a AND now() < ttl to the SELECT statement to ensure we only get cache entries that haven't expired yet, and move the DELETE someplace else\n\nYes we could keep the get() as read-only, and delete old entries before adding new ones (from the set() method).\n\nThis time around, the two transactions that deadlocked started (and issued their DELETE statements) before two previous DELETE statements committed. \n\nSince we use SQLAlchemy sessions in the with client.connect() context manager, there is always an ongoing transaction during the execution of the context manager. In the current code of cache.get(), a transaction covers the two operations (delete+select) which can overlap with another request.\nAlso, our with_transaction=False only means the transaction will be committed when the context manager exists, and not when the http request is served successfully.  Appart from the terrible naming of this parameter, I believe there must be a way to change that so that with_transaction=False would mean autocommit each client.execute() query. This way we would avoid this overlap of transactions for atomic operations for example.. Apparently we do build it though:\nhttps://github.com/Kinto/kinto/blob/master/Dockerfile#L20-L21. I submitted a patch to make hooks fail when they can't be imported : https://github.com/zestsoftware/zest.releaser/pull/236. I don't think this is super easy to implement, but I may be wrong.\nHawk involves crypto, keys etc. I remember implementing something years ago for Daybed.\nhttps://github.com/spiral-project/daybed/blob/6850c766886074e5d6b590a45f985a171efe6339/daybed/tokens.py\nAlso, how easy is it to introduce Hawk in client libraries?. See kinto-hawk https://github.com/Kinto/kinto-hawk\nClosing here :) . I think we should also mention the pip install kinto[memcached] somewhere. Hi @furquan1993 :)\nWelcome here!\nFirst, you should have a local environment working (ie. tests should be all green). You can follow these steps:\nhttps://kinto.readthedocs.io/en/stable/community.html#hack\nThen, before starting to code, you need to make sure the goal of the issue is clear to you. As Natim said, the objective here is to prompt the user when running kinto init. We already do it for the the storage backend, but we now want to do it for the cache, since we added the support of Memcached recently. \nDon't hesitate to ask any question! \u00abAny\u00bb means: even those you believe to be stupid :)\nEnjoy!\n. > some information regarding project details?\nWhat do you mean? \nFirst, do you grasp the scope of this new feature?\n@furquan1993 you didn't ask question nor commented back. How are you doing? . > Goal here is to add other backend (redis,postgresql, memory) rather than default (storage backend).\nWell, the memcache backend is already implemented in the project. But it is not shown among the available choices for the cache backend when running kinto init. The storage backend is something else.\nI suggest that you spend some time running Kinto locally and play with it, you'll probably find it easier later to implement this ;)\n. Kinto should theorically work fine on both.\nBut we won't be able to assist you much on Windows to get your setup working (python, postgresql, memcache etc.). So I would slightly recommend Linux :) . It's not clear at all in the docs, but you should create and activate the virtualenv if you want to run it locally without root privileges...\nOtherwise, since you are about to modify the code, you'll find easier to follow the from sources instructions :). @skepticleo do you need help? should someone else take over?. @aimanparvaiz yep! go ahead :) . Thanks for your interest!\nActually, adding memcache as an extra dependency here: https://github.com/Kinto/kinto/blob/master/Dockerfile#L21\nAnd add the necessary changes in the yml file to add a link to a memcache container and add the configuration values so that it would be the configured cache backend. Hi @mayurvadhavana !\nThanks for your interest in the project!\nI don't know if @emamurho is still working on this :) \nPlease note also that this precise issue is more about Docker than Python. \nYou could look into #1334 otherwise :)\nEnjoy!. One possible flaw is that the command does not run current_transaction.commit() (see https://github.com/Kinto/kinto/blob/master/kinto/core/scripts.py#L89) and maybe it was only tested on the memory backend ?. This is trivial to implement inefficiently :) i.e. within the request/response cycle. But it would be rather inconvenient if the remote webservice is slow or does not respond.\nUsing a Redis queue, as specified here http://kinto.readthedocs.io/en/stable/tutorials/notifications-custom.html would be the best way to go IMO :)\nSee also #420 . Hi! Welcome here! And thanks for the kind words ;)\nYou are right, currently we can only filter events by action / resource (http://docs.kinto-storage.org/en/stable/configuration/settings.html?highlight=listeners#filtering). \nIn that case we would need a object_ids filter or something like that, to be able to do:\nini\nkinto.event_listeners.redis.actions = create\nkinto.event_listeners.redis.resources = bucket collection\nkinto.event_listeners.redis.buckets_ids = blocklists blog\nkinto.event_listeners.redis.collection_ids = articles\n(a little bit like we do in kinto-emailer settings)\nOr maybe be able to specify URIs in resources: \nini\nkinto.event_listeners.redis.actions = create\nkinto.event_listeners.redis.resources = /buckets/blocklists /buckets/blog/collections/articles\n(a little bit like we do in kinto-changes settings\nI think that could be a very good starting point: design an intuitive/flexible set of settings and implement this new filtering feature! \nWhat do you think?. > Question though, would we want to hold off on this issue? If we plan to proceed with this issue first then can you please point me to the lambda details\nWell, whatever direction we take for this issue (either Redis or synchronous call within the request/response cycle), we'll need the filtering feature. We can split and open another issue, but I don't think it's super necesssary.\nPlus, if you go with the Redis listener, then there is nothing else to do in this repo beyond the filtering feature. \n\ncan you please point me to the lambda details\n\nI don't think there's much to say. A lambda is a piece of code that is executed when a HTTP request is sent to a specific URL.\nIt could be anything, any server, any webhook, it does not have to be a lambda actually.\nHere, we'll just want to do a POST on the configured URL with the event as JSON. \n\nOne more thing, I did try and look in to where we can put some logic for filtering based on object_ids etc and with what ever little understanding I have of the code base\n\nIt should be something like that:\nhttps://github.com/Kinto/kinto/blob/a9c8c356742a7ff15f52f310267545a389e43b69/kinto/core/initialization.py#L390-L412\nMaybe first we should design the settings names/format (depends if you're ready to rework the code afterwards ;))\nEnjoy!. You can start by imagining what would be the most intuitive way to\nconfigure filtering the .ini file. Something natural that you could almost\nguess without looking at the docs.\n(I personally like the {resource_name}_id approach)\n. Thanks! This would be the way to go indeed!\n\nkinto.event_listeners.redis.resources = record\nkinto.event_listeners.redis.resourceId = mybucket mycollection \n\nOne detail: so far we have used underscores instead of camelcase, we should stick to it ;)\nAnd it should be plural since we can specify a list.\nIn your example, you filter by record but specify id values that look like buckets and collections. I suppose you want record events but only from specific bucket/collection.\nIt makes me think of something. Suppose we have the following:\nini\nkinto.event_listeners.redis.resources = record\nkinto.event_listeners.redis.object_ids = blocklist certificates\nWhat happens if the event is triggered on /buckets/certificates/collections/pinning/records/record-id or /buckets/settings/collections/blocklist/records/record-id? It is kept obviously, but what about /buckets/foo/collections/bar/records/blocklist-record-id?  Should we leave the ambiguity of which resource it refers to? Maybe, I don't know...  @Natim f?\nWe could still remove the ambiguity by prefixing the _ids settings with the resource type:\nini\nkinto.event_listeners.redis.resources = record\nkinto.event_listeners.redis.bucket_ids = blocklist catalog\nkinto.event_listeners.redis.collection_ids = certificates addons fennec\nIn this case, the only ambiguity that remains is about the possible combinations of bucket/collections: eg. both blocklist/addons and catalog/addons will be kept. Is the case that becomes a problem, we could still define several listeners like this:\n```ini\nkinto.event_listeners.redis_blocklist.resources = record\nkinto.event_listeners.redis_blocklist.bucket_ids = blocklist\nkinto.event_listeners.redis_blocklist.collection_ids = certificates addons\nkinto.event_listeners.redis_catalog.resources = record\nkinto.event_listeners.redis_catalog.bucket_ids = catalog\nkinto.event_listeners.redis_catalog.collection_ids = fennec\n```\nI'm not saying you should follow my propositions, it's just a way to challenge the idea and come up with a solid plan :) \nWhat do you think?. Yes! I like the idea :) \nA few utils that may become useful:\n```py\nfrom kinto.core import utils as core_utils\nresource_name, matchdict = core_utils.view_lookup(self.request, resource_uri)\nandpy\nresult = core_utils.parse_resource(\"/buckets/bid/collections/cid\")\n```\nthat you would have to extend a bit to support inclusion of records at the end...\nIn any case, don't hesitate to ask for help :) you can start a pull-request even if it's just a draft, we do it all the time!\nEnjoy!. Yes great.\nThe commits will be appended when you push to your branch.\n\nI'll rename its title though :) . Indeed, that's the idea I had in mind too!\n\nCareful, I think the settings should be written like this:\npy\nkinto.event_listeners.redis.resource_ids = /buckets/mybucketname\n                                           /buckets/mybucketname/collections/mycollection\n                                           /buckets/mybucketname/collections/mycollection/records/dasdad-addsa-saddaad\nAlso, I have the intuition that we could avoid taking the special cases into account in the implementation. Not in the specifications of course, what you describe is correct and it's what we should expect from the resulting behaviour.\nSo one little piece of advice, start with a naive implementation, write the tests suite and only add complexity in your code once some test fails :)\nEnjoy ;). > Not sure what you meant in your last comment about how the settings should be written.\nSorry to have confused you! It's just because in your example you repeated the kinto.event_listeners.redis.resource_ids = part. Gabi \\o/ Welcome back :)\nThanks for your \u00abpatch\u00bb (huhu)\nTo be honest, I could not take time to review it thoroughly yet. But the tests look good!\nI think we might have to be a bit more talkative about the changes in the changelog (and API changelog?) with regards to null values. (as well as in the docs on patch endpoints). An alternative would be to have a setting that specifies the \u00absynchronizable\u00bb resources. \nFor the synchronizable resources, we would guarantee timestamp uniqueness and consistent with plural timestamp, for the others, we would just take shortcuts and bypass bottleneck. I'm blocked with two failing tests:\n test_create_ignores_specified_last_modified_if_in_the_past\n test_update_ignores_specified_last_modified_if_in_the_past\nThere is no way I can bump the collection timestamp without a timestamps  table if we allow specifying last_modified field in the past.\nTo be honest, now that I completely forgot the background story behind this specification, I can't figure out why and how it makes sense to bump the collection timestamp when you specify last_modified in the past.  The polling for changes with (?_since=) won't catch the changes anyway :| . The original implementation was done here:\nhttps://github.com/Kinto/kinto/commit/805cf67c2e470579c223664a7e698f040333f612\nApparently to align PostgreSQL with other backends implementations (ie. memory and redis)\nCan someone tell me why it makes sense to support last_modified in the past when the collection is not empty ?. > I don't think it does to be honest.\n@Natim could you please help me rewrite the specs of those two tests?. Before merging this, we should make sure it does not break:\n- [ ] kinto-signer\n- [ ] kinto-changes + kinto-signer (= kinto-dist)\n- [ ] kinto-wizard\n. Yes, now that you mention that, it could be that... We want to keep the records unchanged when copying them, but bump the collection timestamp of records (for kinto-changes etc).\nBut honestly, I can't see why it should be like that, especially because I believe the signature is computed on the final records set. And since we copy the records once the staging collection has been edited, the timestamps on the destination will always be superior :/\nAnd more generally, the kinto-signer thing should not come in the way :) If we look at it as it is, in terms of synchronization, the current code/docs don't seem to make sense :(. Thanks for this very detailed report!\nSome issues come from the lib we use mozilla/mozilla-cloud-services-logger\nSome points are trivial improvements.\nSome are bugs (eg. \"path\": \"/v1/batch\", within a subrequest.summary, no error output with excinfo). 23 records among how many? Would be interesting to see if they appeared while the service was overwhelmed...\n. Cannot happen since #1386 . Thanks a lot!. > Should we maybe try to add a statement to the migration to handle cases where the record was both in deleted and records?\nIt is listed as a task as Thorough migration tests\n. @glasserc The tests are green :) If you can, please add a dedicated storage migration test \ud83d\ude4f . Tests are green, #1402 makes py35-raw fail.\n~~Merging \ud83e\udd47~~  No, we must add changelog / migration documentation first :) . More generally, this is due to the fact that the storage and the permission backends are split.\nWe could investigate about 2-phase commits. It does not anymore. I would have emphasized the schema change, with a special note about running the migrate command no?. Thanks @emamurho \\o/ . I don't know if we want to tackle this here (or if we track it in another issue), but in the resource/__init__ there is also a very ugly storage.get() + if + storage.create() code, whereas we could probably catch UnicityError. Fixed by https://github.com/Kinto/kinto/pull/1439 , right?. We can merge once the following is done:\n\n[x] unit tests that assert a cache key is set (or bcrypt is not called on second attempt)\n[x] unit tests that assert what happens when user/pass is changed/deleted\n[x] the TTL value in settings\n[x] a cache refresh on each request (basically call cache.set())\n\n@Stanley are you still interested in working on this and go through those last steps? Let us know, maybe somebody can help and take over!\nThanks!. Awesome! Thanks \\o/. @cfguimaraes in order to try this branch with Auth0, you can use these settings:\nini\nmultiauth.policies = oidc\nmultiauth.policy.oidc.use = kinto.core.authentication.OpenIDConnectPolicy\noidc.issuer_url = https://{yours}.auth0.com\noidc.audience = {api-id}\n. Thanks @cfguimaraes for your detailed feedback!\nNext step on my side is to write a little single page app demo (with Github auth or something) and update the docs / tutorial...\n\nHowever, the code looks for a Bearer+OIDC Authorization Header, I couldn't find a place where this Header is described, only Bearer token.\n\nWe invented it with @Natim :) Since Kinto can have several authentication policies enabled, with several ones that use bearer tokens, we wanted to have a special one. Maybe we could default it to just Bearer and make it optional in settings to customize it. If you thought that was confusing, it's a sign :) \n\nNotes: \nhttps://developer.github.com/apps/building-oauth-apps/\n. I made some changes to this branch. The tests will fail. The audience setting was renamed to client_id.\n\nI made it work with Google Accounts, this is the frontend demo that I wrote:\nhttps://github.com/leplatrem/kinto-oidc-demo/\nIt's still Work-In-Progress though.. > Plus this let you configure Kinto with multiple auth providers without messing around with configuration.\nHonestly, having multiple authentication policies configured is not the most common use-case. I reworked the settings part, it now supports multiple OpenID policies, and I updated the demo.\nI drafted some docs as well.\nAt this point I would take as much feedback as possible :) . The code is ready to be thoroughly reviewed/merged. \nAlso, I would also really appreciate if someone could test this: https://github.com/leplatrem/kinto-oidc-demo\nNow the question is: should we do the scope filtering feature in this PR as well as revamp the whole authentication documentation? My take is \u00abno\u00bb :) . @Natim final r?. > I think it is good enough as it is to be merge right away\nI'll create the issue once approved and merged :) . > Since OpenID is about Authentication and Oauth about Authorization, I believe it is fine not validating scopes here and using the userinfo_endpoint to validate bearer tokens.\nOur original use case is to obtain different userids depending on scope (to isolate data between apps basically).\nWhat if we just define two clients IDs and define two policies?\n```ini\n    multiauth.policy.notes.issuer = https://accounts.google.com\n    multiauth.policy.notes.client_id = YYYYYYYY.apps.googleusercontent.com\n    multiauth.policy.notes.client_secret = UAlL-YYYYYYYY\nmultiauth.policy.lockbox.issuer = https://accounts.google.com\nmultiauth.policy.lockbox.client_id = XXXXXX.apps.googleusercontent.com\nmultiauth.policy.lockbox.client_secret = UAlL-XXXXXX\n\n``\nThe user ID will benotes:abcon one side, andlockbox:abc` on the other side... The IdP could restrict the access to one or another with the callback/redirect URIs settings.\n\nI believe we should remove the custom authentication flow using id_token.\n\nI don't know, using ID tokens saves a round trip to the IdP. But yes, it would make everything simpler indeed. I wish I had an example of flow where we obtain JWT access tokens, but I don't. Yeah, you're right, let's make it super stupid and simple: just access tokens.. > The issue is that in that case the bearer_token will be validated in both case right?\nIf it's for the second policy, yes. Two round trips to the IdP. It should be 8.1.0 because we have new features.\nAnd since #1439 was reviewed we could include it. v2 is just because of Drop support for EOL Python 2.6 and 3.3. @Natim since you're the one at the initiative of the Hawk support, I call for your help here, review, feedback and approval needed :)\nAlso, since the feature brings a lot of new code for a limited audience, what would you think of moving it to a dedicated package?. What's the status of this?. Close in favor of #1485  ?. @Natim should we merge? failing tests are due to #1470 on Py35. > did this ever used to work back when we wrote everything to timestamps? If so, how?\nYeah it wasn't trying to create if a row was present, so we had the error only when the collection was empty. @mozillazg how are you doing? Are you still interested to work on this?\n. > . Unlike read load, which can often be served using CPU and memory, write load always goes to disk and is therefore more expensive.\nOK I see... The ON CONFLICT is more like a try/except than a IF NOT EXISTS. \n\nThe read would be optimistic -- if it's there, then we don't have to insert, but if it isn't there, we can insert and maybe get a conflict, no big deal\n\n\ud83d\udc4d Yes, let's do that. \nWill it change anything if we do it in one atomic query INSERT ... ON CONFLICT .. WHERE NOT EXISTS (SELECT ... ) ?\n\nsuch behavior is no different from trying the INSERT + ON CONFLICT and then having another thread delete the record just afterwards\n\nYes, BTW we do a self._get_record_or_404() and then delete() :) \n. Warning, treated as error:\n/home/travis/build/Kinto/kinto/kinto/core/openapi.py:docstring of kinto.core.openapi.OpenAPI.generate::py:class reference target not found: dict Full OpenAPI/Swagger compliant specification for the application.\nERROR: InvocationError: '/home/travis/build/Kinto/kinto/.tox/docs/bin/sphinx-build -a -W -n -b html -d docs/_build/doctrees docs docs/_build/html'. Fixed in #1736 . Maybe we could use the parent timestamp as the default value when it's empty.\nOr make a call to collection_timestamp('record') when the collection is created. \n\nIt should be impossible to create a collection without a creation timestamp.\n\nWhat does that mean? The problem here is that the collection timestamp (parent's last_modified) is a different value than the records list timestamp (~max(records' lastmodified)). When the parent is created, we don't initialize the children list timestamp, so listing the records from a read-only node fails.. @aimanparvaiz would you be interested in bringing this to the end? Or should someone take over?\nThanks!. @aimanparvaiz of course that's OK! You can take as much time as you need! I just wanted to check with you that you're still interested with this :) . The diff of this pull-request contains a lot of unrelated changes that are already on master. \nIf you are familiar with git you can try to rebase your work and see if you can only limit the changes to your contribution.\nIf you need help please don't hesitate to ask, there should be a way to start clean without loosing commits!\n. Thanks @aimanparvaiz for your efforts on this! Tests pass which is good news :) \nI don't have the brain lately to dig into the code, but I'll come back to it when I find the energy :). Looks like this PR has stalled..\n@aimanparvaiz are you still interested to pushing it forward? Should someone else take over?\nThanks for everything you've done so far! . > Notes: Maybe related: https://github.com/Pylons/colander/pull/199 https://github.com/Pylons/colander/issues/214\nAlso, if we end-up fixing this, we should remove what was done in #1502 \n. plural endpoint = GET list of records in a collection. Yes! Thanks!. To fix this issue, start by reproducing in a test (in /test_views_schema_collection.py for example)\n- using the schema shown above\n- using a record that does not have minVersion in a targetApplication field (in a list, itself in a list in versionRange)\n- try to validate!\nIntrospect the validation error attributes and see if something consistent can be done :)\n. Did you try what folks suggest on the InternetZ for the flake8 ValueError: bad marshal data (unknown type code) error? (delete pyc files etc). > it looks like the schema is incomplete\nYou're right! Sorry!\nThe full JSON schema would be this one. You can use to try to reproduce the issue and we can simplify it afterwards :) \n```json\n{\n  \"definitions\": {\n    \"minVersion\": {\n      \"type\": \"string\",\n      \"title\": \"Min version\",\n      \"description\": \"The mininum version.\"\n    },\n    \"maxVersion\": {\n      \"type\": \"string\",\n      \"title\": \"Max version\",\n      \"description\": \"The maximum version.\"\n    }\n  },\n  \"title\": \"Add-on\",\n  \"description\": \"Add-on\",\n  \"type\": \"object\",\n  \"additionalProperties\": false,\n  \"required\": [\n    \"guid\"\n  ],\n  \"default\": {\n    \"guid\": \"\",\n    \"prefs\": [\n],\n\"versionRange\": [\n  {\n    \"minVersion\": \"0\",\n    \"maxVersion\": \"*\",\n    \"severity\": 1\n  }\n]\n\n},\n  \"properties\": {\n    \"enabled\": {\n      \"type\": \"boolean\",\n      \"title\": \"Enabled\",\n      \"description\": \"blocking rule is enabled.\",\n      \"default\": true\n    },\n    \"guid\": {\n      \"type\": \"string\",\n      \"title\": \"Add-on id\",\n      \"description\": \"The add-on unique identifier or a regular expression.\",\n      \"minLength\": 1,\n      \"default\": \"\"\n    },\n    \"os\": {\n      \"type\": \"string\",\n      \"title\": \"OS\",\n      \"description\": \"The comma-separated operating system identifiers, eg. Darwin,Linux\",\n      \"pattern\": \"^[^,](,[^,]+)$\"\n    },\n    \"prefs\": {\n      \"type\": \"array\",\n      \"title\": \"Preferences\",\n      \"description\": \"The list of impacted preferences.\",\n      \"uniqueItems\": true,\n      \"default\": [\n  ],\n  \"items\": {\n    \"title\": \"Preference name\",\n    \"description\": \"The browser preference name, eg. browser.startup.homepage\",\n    \"type\": \"string\",\n    \"minLength\": 1,\n    \"default\": \"\"\n  }\n},\n\"versionRange\": {\n  \"type\": \"array\",\n  \"title\": \"Versions\",\n  \"description\": \"The list of impacted versions.\",\n  \"items\": {\n    \"type\": \"object\",\n    \"title\": \"Version range\",\n    \"description\": \"Version range\",\n    \"additionalProperties\": false,\n    \"required\": [\n      \"minVersion\",\n      \"maxVersion\",\n      \"severity\"\n    ],\n    \"default\": {\n      \"minVersion\": \"\",\n      \"maxVersion\": \"\",\n      \"severity\": 1\n    },\n    \"properties\": {\n      \"minVersion\": {\n        \"$ref\": \"#/definitions/minVersion\"\n      },\n      \"maxVersion\": {\n        \"$ref\": \"#/definitions/maxVersion\"\n      },\n      \"severity\": {\n        \"type\": \"integer\",\n        \"title\": \"Severity\",\n        \"description\": \"The severity code number.\",\n        \"enum\": [\n          1,\n          3\n        ],\n        \"enumNames\": [\n          \"1 - Soft block\",\n          \"3 - Hard block\"\n        ],\n        \"default\": 1\n      },\n      \"targetApplication\": {\n        \"type\": \"array\",\n        \"title\": \"Target applications\",\n        \"description\": \"The list of target application information.\",\n        \"default\": [\n\n        ],\n        \"items\": {\n          \"type\": \"object\",\n          \"title\": \"Target application\",\n          \"description\": \"Target application\",\n          \"additionalProperties\": false,\n          \"required\": [\n            \"guid\",\n            \"minVersion\",\n            \"maxVersion\"\n          ],\n          \"properties\": {\n            \"guid\": {\n              \"type\": \"string\",\n              \"title\": \"Application id\",\n              \"description\": \"The application unique identifier.\",\n              \"enum\": [\n                \"{ec8030f7-c20a-464f-9b0e-13a3a9e97384}\",\n                \"{3550f703-e582-4d05-9a08-453d09bdfdc6}\",\n                \"{92650c4d-4b8e-4d2a-b7eb-24ecf4f6b63a}\",\n                \"{aa3c5121-dab2-40e2-81ca-7ea25febc110}\"\n              ],\n              \"enumNames\": [\n                \"Firefox\",\n                \"Thunderbird\",\n                \"Seamonkey\",\n                \"Android\"\n              ]\n            },\n            \"minVersion\": {\n              \"$ref\": \"#/definitions/minVersion\"\n            },\n            \"maxVersion\": {\n              \"$ref\": \"#/definitions/maxVersion\"\n            }\n          }\n        }\n      }\n    }\n  }\n},\n\"details\": {\n  \"type\": \"object\",\n  \"title\": \"Details\",\n  \"required\": [\n    \"name\",\n    \"why\"\n  ],\n  \"properties\": {\n    \"name\": {\n      \"type\": \"string\",\n      \"title\": \"Name\"\n    },\n    \"why\": {\n      \"type\": \"string\",\n      \"title\": \"Why\"\n    },\n    \"who\": {\n      \"type\": \"string\",\n      \"title\": \"Who\"\n    },\n    \"bug\": {\n      \"type\": \"string\",\n      \"title\": \"Bug\"\n    },\n    \"created\": {\n      \"type\": \"string\",\n      \"format\": \"date-time\"\n    }\n  }\n},\n\"blockID\": {\n  \"type\": \"string\",\n  \"title\": \"Internal blocklist id\",\n  \"description\": \"Original block id, eg. i152\",\n  \"pattern\": \"^i[0-9]+$\"\n}\n\n}\n}\n```. Cool! Thanks!\n\nNow it will be something like this: \"0 in body: \\'maxVersion\\' is a required property\"\n\nI'm ok with this! ;) \n. Validation messages are tricky, because we'd have introspect the internal of jsonschema validation... Which is not recommended :/ . Welcome! Yes, of course! Don't hesitate to ask if something is unclear, and don't hesitate to push some draft code as a pull-request if you need early feedback.\nEnjoy!. The capabilities are some metadata shown in the JSON on the root URL http://localhost:8888/v1/\n. As you can see in the faulty code pointed above, we iterate on every settings without looking at the multiauth.policies setting at all. It should be the other way around :). Exactly. Something like (untested):\npy\nfor policy in aslist(settings['multiauth.policies']):\n    v = settings.get('multiauth.policy.%s.use' % policy, '')\n    if v.endswith('OpenIDConnectPolicy'): \n        ..... @bhaveshpoddar94 Do you need any help?. @bhaveshpoddar94 ping :) Let us know if we can help or if someone should take over!. I don't think it's resolved, and seeing the lack of activity I believe you can take it!. Thanks for your interest in the project!\nThe issue is just for the creation, it should just add the entry with permissions create that I put in my comment.\nSo what we want is to check that the current user has a least one principals in common with the ones mentioned in the kinto.bucket_create_principals setting.\nIf I understand the current code correctly, the function allowed_from_settings() already returns an entry when this is the case: ({\"\":  [\"bucket:create\"]}).\nBut then when we build the perms_by_object_uri we never look at it :(\nhttps://github.com/Kinto/kinto/blob/110ace2ea0688c3abfdec8e8f471a540a502fba1/kinto/views/permissions.py#L87-L91\nSo it should be enough to do something like this (untested):\n```py\nbucket_creation = from_settings.get(\"\")\nif bucket_creation:\n     perms_by_object_uri[\"/buckets\"] = bucket_creation\nallowed_resources = {'bucket', 'collection', 'group'} & set(from_settings.keys())\nif allowed_resources:\n   ....\n```\nYou should a write a unit test in test_views_permissions and make sure you obtain the desired behaviour:\n$ py.test tests/test_views_permissions.py. > It looks like allowed_resources in the following snippet will always evaluate to false as from_settings is {'': 'bucket:create'}, so there will be no intersection.\nYes that's why I was proposing to put it before looking at allowed_resources (bucket creation is not linked to any parent resource, as opposed to records creation, collections, groups... etc.)\n\nI've been digging through the permissions a bit and don't see a bucket:create key in perms_descending_tree, which seems like it would fix the problem.\n\nYes indeed, and if I look at PERMISSIONS_INHERITANCE_TREE (where the perms_descending_tree is built from) there seems to be everything we need:\nhttps://github.com/Kinto/kinto/blob/110ace2ea0688c3abfdec8e8f471a540a502fba1/kinto/authorization.py#L26-L28\nEnjoy!. I think you already went far enough for me to get lost :) \nFirst, let's agree on how it should look like.\nCurrently, this is how it comes out on GET /permissions for a single bucket:\njs        \n        {\n            \"bucket_id\": \"bid\",\n            \"id\": \"bid\",\n            \"permissions\": [\n                \"write\",\n                \"read\",\n                \"collection:create\",\n                \"group:create\"\n            ],\n            \"resource_name\": \"bucket\",\n            \"uri\": \"/buckets/bid\"\n        }\nSo we can see that we have \"uri\": \"/buckets/bid\" and the perm collection:create. \nWe don't have \"uri\": \"/buckets/bid/collections\" and the perm create.\nSo I think it would be consistent to have \"uri\": \"/\" and the perm bucket:create, instead of \"uri\": \"/buckets\" and the perm create or \"uri\": \"/buckets\" and the perm bucket:create.\nWhat do you think?\nOnce you define well what we expect, you may have to touch several unit tests to match the new behavior yes :)\nAlso, don't hesitate to open a pull-request with your work-in-progress, so that we can iterate on real code ;)\nThanks for being so thorough!. 1. We should use the requirements.txt everwhere (local dev, travis, Dockerfile)\nAnd probably switch to some recent stuff like Pipfile (+Pipfile.lock)\n2. We get rid of that build-requrirements command and let pyup be the main source of updates. A developer can still contribute a PR that upgrades to a particular release out of the current range (tech debt, new required feature, etc.)\nActually, bulk upgrading requirements during the release PR is not the main issue here, since we have a very good code coverage (but we need 1. !!)\n@Natim if you could see this, I'd love to read your thoughts :pray: ! . Thanks for your feedback! \nI think we should still consider that these points are problematic:\n- undesired upgrades in pull-requests (see my comment above)\n- contributors might not run the same set of versions \n- local dev and CI might not run the same set of versions\n\nIf you always rely on the requirements.txt file with constrained version then you never updates your dependencies unless your setup pyup or a process to upgrade your dependencies.\n\nYes, that would be the plan. Since we already have pyup by the way.\nIt wouldn't be very different than today. Except that we would not run this make build-requirements right before releasing, that introduces changes at the last moment. \n\nIn anycase you should never use setup.py to constraint dependencies for a library \n\nAgree, not planned to do that.\n\n(that we use with kinto-dist when releasing)\n\nNo entirely true actually, we don't use the requirements.txt from the Kinto repo to build the one from kinto-dist\nhttps://github.com/mozilla-services/kinto-dist/blob/ea1ac50c2c1b9c983c81843f1a421c964b63db3e/Makefile#L37-L38\nSo technically, our only seatbelt in kinto-dist before launching to prod is the end-to-end/functional test there.\nWe never had problems of that sort so far, but we can still do better than the current situation.. Blocked by the fact that Pyup does not update Pipfile.lock: https://github.com/pyupio/pyup/issues/197\nhttps://github.com/mozilla-services/socorro/pull/4333#issuecomment-368543736. @peterbe could you please confirm that switching to Renovate instead of Pyup would allow us to use pipenv?. Note: Dependabot supports Pipenv :)  . How does Pipenv play with tox?\n. ~~FYI I haven't tested building the container, and haven't double checked that tox actually takes constraints into account~~ Done. Works :)\nWaiting for @Natim approval before merging!. @Natim do read your notifications between 2 snorkeling sessions?. > Why is this a minor version? The release notes don't describe anything that I would consider a \"new feature\", even within our loose application of semver.\nThe OpenID plugin no?. inserted can be None when:\n- none of the 2 requests in the union returns a record \n- the cursor is consumed twice\nI cannot reproduce, but I don't think UNION/UNION ALL is the problem here\n. > It concerns me what this can happen.\nMe too! I spent quite a while on this today and could not come up with a clear path that would lead to this kind of situation either. According to Sentry it happened like 100 times on Testpilot and almost 500 times on buildhub. This is far from being paranormal!\n\nPerhaps we can work together to audit how the transactions are committed\n\nThe transactions are bound to the request lifecycle using pyramid_tm and this SQLAlchemy binding:\nhttps://github.com/Kinto/kinto/blob/4c033067d46330049cc4ab51a439db89019887de/kinto/core/storage/postgresql/client.py#L105-L107\nCommit or rollbacks are done just before the response is served.\nIn buildhub we use kinto-elasticsearch which introduces a round-trip to an ES server in the response cycle. It could make the transactions last a lot longer than normal. \n\nI really think there are better patterns to insert something\n\n:) \n. Wao thanks! Excellent :) \n\nMeaning, if it's true that two concurrent clients attempt the same .create() (with possibly different JSON!) it would be weird to \"correct\" the second client's call.\n\nDefinitely, if we know that when inserted is None we are in a conflict situation, we can raise a python exception. The client should probably get a 409 Conflict (that will be retried). Unfortunately I can't see the request body on the Sentry error :( . We iterate on the settings defined in the .ini + the defaults:\nhttps://github.com/Kinto/kinto/blob/86a9943b428b8e7fab53190bf840222f5c833225/kinto/core/initialization.py#L480-L497\nWhat would we be your suggestion? \nNote that the plugin include happens after the initialization phase:\nhttps://github.com/Kinto/kinto/blob/86a9943b428b8e7fab53190bf840222f5c833225/kinto/core/init.py#L202-L205. According to my understanding of the code, it seems like a workaround yes. Unless we add a helper like request.get_setting(\"key\", 128) and use it instead of request.registry.settings.get() I don't see how we could fix this.. Ok, we can add an additional initialization step that does that.\nBut I think the input list should be settings names because I'm not sure we can reverse (SIGNER_CID_PATH should be signer.cid.path or signer_cid.path?)\n. I like the idea of a helper like request.config() with options similar to python-decouple. @Natim  proposed this in https://github.com/Kinto/kinto/issues/123 and I implemented it :) . Maybe because we didn't want to expose the blocklist permissions to the whole world? Expose which emails are allowed to modify certicates blocklist entries for example.\nhttps://firefox.settings.services.mozilla.com/v1/buckets/blocklists/collections/certificates. @ssWitcher I'm sorry I hadn't seen your comment :( I needed this for something we have in production and jumped on it!\nI hoped you hadn't spent too much energy on it :(  . Thanks Sebastien for your help!\nI don't know when we'll take the time to work on this though :sweat: . \n. > It should probably return a 404 instead of a 500\nIt looks like it's already returning 404\n```\nhttp PUT :8888/v1/buckets/default/collections/a/records/1 -a user:pass\nHTTP/1.1 201 Created\nAccess-Control-Expose-Headers: Backoff, Retry-After, Alert, Content-Length\nContent-Length: 152\nContent-Type: application/json\nDate: Thu, 29 Mar 2018 16:12:01 GMT\nEtag: \"1522339921768\"\nLast-Modified: Thu, 29 Mar 2018 16:12:01 GMT\nServer: waitress\nX-Content-Type-Options: nosniff\n{\n    \"data\": {\n        \"id\": \"1\",\n        \"last_modified\": 1522339921768\n    },\n    \"permissions\": {\n        \"write\": [\n            \"basicauth:7afa16e9e220bdca1f8fa1839c9cb7dc29cffbd148756908894ed8add8d1ced8\"\n        ]\n    }\n}\n\u279c  kinto git:(master) \u2717 http DELETE :8888/v1/buckets/default/collections/a/records/1 -a user:pass\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Backoff, Retry-After, Alert, Content-Length\nContent-Length: 64\nContent-Type: application/json\nDate: Thu, 29 Mar 2018 16:12:07 GMT\nEtag: \"1522339927516\"\nLast-Modified: Thu, 29 Mar 2018 16:12:07 GMT\nServer: waitress\nX-Content-Type-Options: nosniff\n{\n    \"data\": {\n        \"deleted\": true,\n        \"id\": \"1\",\n        \"last_modified\": 1522339927516\n    }\n}\n\u279c  kinto git:(master) \u2717 http DELETE :8888/v1/buckets/default/collections/a/records/1 -a user:pass\nHTTP/1.1 404 Not Found\nAccess-Control-Expose-Headers: Backoff, Retry-After, Alert, Content-Length\nContent-Length: 90\nContent-Type: application/json\nDate: Thu, 29 Mar 2018 16:12:08 GMT\nServer: waitress\nX-Content-Type-Options: nosniff\n{\n    \"code\": 404,\n    \"details\": {\n        \"id\": \"1\",\n        \"resource_name\": \"record\"\n    },\n    \"errno\": 110,\n    \"error\": \"Not Found\"\n}\n```. Interesting...\nI was playing with the batch endpoint too, but it seems fine.\n```\n$ echo '{\"requests\":[{\"method\":\"DELETE\",\"path\":\"/v1/buckets/default/collections/a/records/2\"},{\"method\":\"DELETE\",\"path\":\"/v1/buckets/default/collections/a/records/2\"}]}' | http POST :8888/v1/batch -a user:pass\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Backoff, Retry-After, Alert, Content-Length\nContent-Length: 758\nContent-Type: application/json\nDate: Thu, 29 Mar 2018 16:16:23 GMT\nServer: waitress\nX-Content-Type-Options: nosniff\n{\n    \"responses\": [\n        {\n            \"body\": {\n                \"data\": {\n                    \"deleted\": true,\n                    \"id\": \"2\",\n                    \"last_modified\": 1522340183528\n                }\n            },\n            \"headers\": {\n                \"Access-Control-Expose-Headers\": \"Backoff, Retry-After, Alert, Content-Length\",\n                \"Content-Length\": \"64\",\n                \"Content-Type\": \"application/json\",\n                \"ETag\": \"\\\"1522340183528\\\"\",\n                \"Last-Modified\": \"Thu, 29 Mar 2018 16:16:23 GMT\",\n                \"X-Content-Type-Options\": \"nosniff\"\n            },\n            \"path\": \"/v1/buckets/default/collections/a/records/2\",\n            \"status\": 200\n        },\n        {\n            \"body\": {\n                \"code\": 404,\n                \"details\": {\n                    \"id\": \"2\",\n                    \"resource_name\": \"record\"\n                },\n                \"errno\": 110,\n                \"error\": \"Not Found\"\n            },\n            \"headers\": {\n                \"Access-Control-Expose-Headers\": \"Backoff, Retry-After, Alert, Content-Length\",\n                \"Content-Length\": \"90\",\n                \"Content-Type\": \"application/json\",\n                \"X-Content-Type-Options\": \"nosniff\"\n            },\n            \"path\": \"/v1/buckets/default/collections/a/records/2\",\n            \"status\": 404\n        }\n    ]\n}\n```\nSo you run the same delete request twice? And sometimes the second one fails. That might be related to #1407 \nWe should catch ResourceNotFound here:\nhttps://github.com/Kinto/kinto/blob/c6cc7bba094aed6897d0157dc78b1731ac12c8db/kinto/core/resource/init.py#L573-L583\n. Maybe we could also automate stuff like:\n- replace the version number in the link to default settings in production.rst\n- post the entry on the Github releases page when running postrelease\n\nNote:  we did some zest.releaser hooks in #1133 . @Natim r?. Nice catch :) . Excellent, thanks for taking the time to investigate this!\nIt may only happen with the PostgreSQL backend actually... . > When I turn history plugin on I get a 503.\n\nNice one!\n. That's exactly it.\nWe need to show whether the user has the permission to create root level objects (buckets, accounts so far). Since they don't have any parent object, there is no field we could use as id.\nWe could put a \"id\": \"\" in the payload on those if you think that's more consistent for consuming clients.. OK, after having chatted with @glasserc this fix won't work, cause it will squash the accounts and buckets root permissions (both with \"id\": \"\")\nI propose that we set \"id\": \"root-{resource_name}\" instead (eg. \"id\": \"root-bucket\") and avoid safety checks around id.\nIt would have to be done in a else here:\nhttps://github.com/Kinto/kinto/blob/71fed133948d18f8c423ef4319e2c231a9580f6e/kinto/views/permissions.py#L125-L128\n. I had never heard of subTest()! Nice!. Thanks! \nI think we'll follow the approach in #1581 \nWe'll leave this open until we make a final decision :) \nSorry for the confusion! That was definitely an interesting patch :)). Apparently the key changes were introduced by this innocent commit: https://github.com/Stanley/kinto/commit/00ef4bf2e3fcccf94b1a0cbd9e45364d074d6378#diff-ba2d1b0729b3d63fcf9111d377936b47\n@Natim  @Stanley I really need your insights here, but it looks like a hole.\nOn our side we don't have any Kinto 8.2.0 running with the account plugin in production, but I would advise those who do to downgrade to 8.1.X until a fix is released.. Some changelog entries may miss on master. It should also be 8.3.0 because we upgraded a bunch of dependencies :). What's the status of this? Is it a \u00abwon't fix\u00bb?. > Not sure where to add a test or even what should happen.\nWe have 2 places for storage tests:\n- kinto/core/storage/testing.py for tests that apply to every implementations of storage backends\n- tests/core/test_storage:PostgreSQLStorageTest for postgres specific tests\nSo a test along this one would work:\nhttps://github.com/Kinto/kinto/blob/9e22784dc57291c8f93624f8c1175cabd9b7f080/tests/core/test_storage.py#L259-L271\nYou can setup all the threading / raw pyscopg you need, let me know if you can't figure out how to transpose your snippet to the kinto ecosystem\nAlso, I realize that when the storage backend raises a UnicityError we don't automatically transform it into a 409 like we do for IntegrityError here:\nhttps://github.com/Kinto/kinto/blob/9e22784dc57291c8f93624f8c1175cabd9b7f080/kinto/core/views/errors.py#L112\nMaybe we should also change that so that unicity errors are returned as 409. Either in the global error view as above for any uncaught exception, or add a try/except in the resource code:\nhttps://github.com/Kinto/kinto/blob/9e22784dc57291c8f93624f8c1175cabd9b7f080/kinto/core/resource/init.py#L345\nhttps://github.com/Kinto/kinto/blob/9e22784dc57291c8f93624f8c1175cabd9b7f080/kinto/core/resource/init.py#L468\n\nNote: This is slightly related to #1407 . What's the status of this?. Closing in favor #1919 . Hmm. Can you explain why do we need this?\n\nWhy can't we stick with the current behaviour:\nini\nmultiauth.policy.account.use = kinto_hawk.authentication.HawkAuthenticationPolicy. I'm usually -1 on introducing numerous internal tweaking customizations that give users many options/strategies to choose from...  Unless we're really really stuck, I'd prefer to keep the current approach : auth policy name \u2192 user prefix.. > The second rationale is because for Hawk I want to define two authentication backend that gives the same user ID: for Basic Auth and one for Hawk\nHmm, it sounds super complicated when reading this.... Would be easier to have\nini\nmultiauth.policies = account \nmultiauth.policy.account.use = kinto_hawk.authentication.HawkAuthenticationPolicy. Some stuff is missing on the kinto-admin release page, I'll add them. > Or, are you referring to it as a risk of getting wrong numbers between the two queries? I.e.\nYes, I'm pretty sure it's this one! Ethan has worked a lot on race conditions / TOCTOU stuff ;). > One culprit might be the rounding error of rounding the last_modified up to the nearest second. Note that each two pairs of last_modified is different but their as_epoch is the same. :(\nOMG, this is dreadful... it's unrelated to this PR indeed, which has to assume that epoch timestamps are unique. Let's create a bug around that, we should at least have a DB constraint to avoid this situation. > Although this issue seemed like a P5 previously, maybe it's a P3 or P2. @leplatrem , @mostlygeek ?\nThere are many aspects that made this issue more important recently:\n- It now has a proposed solution in a PR where tests pass. It's always nice to avoid letting it rot and keep conversations alive.\n- In buildhub, everytime a new version is deployed, a job fetches the 1 million records from Kinto. Recently there had been many new releases and the whole thing slows down.\n- Some users were trying to do some queries and got 504 https://github.com/mozilla-services/buildhub/issues/350 The workaround is to use the ElasticSearch endpoint of course, but it'd be nice to avoid it. As Ethan said, #1622 was a first step and we can do better. Especially when we figure out a strategy for #1624.. My position on stuff like this has always been: tests are specifications. If tests don't fail you can remove whatever you want :) . Can you give us pointers to the tests?\nWhich PR / blame ? Any mention in CHANGELOG? Are those tests present in the original cliquet repo?. OK, I grep the usage of get_all and found this in the CHANGELOG:\nThe storage backend now allows ``parent_id`` pattern matching in ``kinto.core.storage.get_all``. (#821)\n@Natim implemented it and I approved it in https://github.com/Kinto/kinto/pull/821 \n. I found its usage by searching \"pattern matching\" :) \nhttps://github.com/Kinto/kinto/blob/5904085b9ce87ea8772fe2fb19cf4b8c00db03a8/kinto/plugins/accounts/views.py#L82-L83\nI remember now that we suffered when implementing the accounts parent id stuff. Each account entry is isolated using parent_id=user_id. As admin, I can see every entries, thus parent_id=*. \nThere might other ways to implement this, and I don't think the \u00abaccount admin\u00bb feature is important enough to justify having lower perfs on get_all(). In case you wonder:\nhttps://github.com/Kinto/kinto/blob/382adcdc2dccff7151798bc7d250769dc818d83e/kinto/core/storage/postgresql/schema.sql#L5-L13. > It isn't really clear what the scalability characteristics of Kinto are or should be. Is Kinto meant to store 10m records? I would say probably not. What about 1m records, but all in one collection? I'm not certain.\n10m records accross several collections, I would say yes. \n1m records in one collection, it should support it, but maybe not in optimal conditions. Since synchronization is going to be painful anyway (especially on the first time).\n\nIt isn't really clear (to me, at least) what queries Kinto should support as \"first-class\" and which are \"gravy\", i.e. added bonuses that we threw in because they were easy to implement but are not as well-loved, performant etc. as others. Na\u00efvely I would say syncing collections is more important than supporting arbitrary filters, but then again, if that's what you want, CouchDB is available and may be a better fit for you.\n\nI definitely agree that syncing is more important than arbitrary filters (for which we have the ElasticSearch plugin)\n\nIt isn't really clear to me what the relative priorities are in the Kinto ecosystem. As an example, in order to produce a Total-Records header, we have to add a COUNT to our queries, which means enumerating all the matching records rather than just the ones that we're going to render in the response. In other distributed systems, you might just paginate until you get an empty page. Is the ease-of-use/sanity checking provided by the Total-Records header worth the performance cost?\n\nThat was a naive choice at the beginning of the project. The Total-Records is not even exposed in our clients API...\nOn the server side, the total count is just used to figure out whether we have a next page. Which, as you say, could be managed differently (ie. paginate until empty page).\n. @glasserc could you add a CHANGELOG entry please?. So this will work for anynomous users too?. Great!\nThe problem seems to be this line:\nhttps://github.com/Kinto/kinto/blob/a7f94773610566ec91f2d6172da910fb73fa84ef/kinto/views/collections.py#L59\nWhich does not contain a *, and thus does not delete children rows.\nThe starting point is http://kinto.readthedocs.io/en/stable/community.html#hack let us know if you need help!. Unfortunately, as awkward as it would look, it is not :( (because of #710)\nThe notion of collection in Kinto core is different, and so is the related test in kinto/tests/core/resource/test_object_permissions.py. I'm sorry, I know this is confusing.\nInstead you should add a new test in CollectionDeletionTest in tests/test_views_collections.py\nYou can run this individual test with py.test -k test_permissions_are_removed...\nHave fun ;) . What is the status of this @glasserc ? How far is it from being done?. Yes, so that our community users can deploy it during the weekend :) . The following seems to happen: \n\nuser authenticates on Auth0 with Google identity\nuser obtains an Access Token that has openid scope, and thus allows to fetch user info\nuser sends access token to obtain user id from root URL\nkinto iterates the configured policies to validate the access token, and tries to fetch the user info for that\nsince access token obtained from Auth0 allows to fetch profile from Google, kinto identifies the user with the google policy\nkinto admin sees that user tried to identify with auth0 but obtains a user id prefixed with google and considers that something is wrong\n\nSince Auth0 is a kind of bridge to Google (and other identity providers), I don't think it makes sense to have both configured, and we could consider it a limitation of the server.\nWhat do you think?. I think the documentation changes that @fpiedrah submitted were enough and that we can close this. Do you all agree? . @Natim final r?. I generalized to collections and groups.\nMaybe we improve the current code, which repeats a lot of lines between record / collection / bucket.\nAlso I still have to update the documentation. . @glasserc I completely changed the organization of the code. There's less repetition, IMO it's better but I can change my mind.. > Is this because the new kinto-admin is able to read the capabilities to detect the activated authentication mecanisms?\nYes!. > Will it automatically select the current server with this changes?\nYes, it's done in index.js. What are the python versions on ubuntu distributions?. The question remains: should we drop support for Python 3.5?. . > What's the procedure for merging etc.?\nOnce you have r+, and if you have permissions you can press the merge button :) We never took the time to setup bors or equivalent.... @peterbe r?. > Is it documented that developers have to remember update this if they upgrade anything in package.json?\nYeah I think we should do that. . I'll write it while upgrading to 1.19. Can we vote? Am I the only one to be hesitant?. Please add the underscores to the keywords ;) \nWhat you describe might come from this:\nhttps://github.com/Kinto/kinto/blob/0ebe2f3aaaefe41db58d8fc51aae46fd00aff773/kinto/core/resource/schema.py#L230-L231\nAnd indeed, we should probably only allow it for fields related to timestamps (I like the idea to take the value from the ETag header and pass it as it is to _since). For those who want to have a look at this, this could be avoided by adding some safety check here for example:\nhttps://github.com/Kinto/kinto/blob/21bac9b787639da76b38f535aa34e1f0391e48e9/kinto/core/utils.py#L106-L117\n. > Hey, if this is still open I would like to work on this\nGreat!\n\nwhere would be the best place to put a test for this?\n\nI guess that somewhere around here:\nhttps://github.com/Kinto/kinto/blob/f9e3c6ea2c2a44e855c16cf2969dd73200ac94ac/tests/core/test_views_errors.py#L114\n\nAnd to add to this, what would the expected result be?\n\nIf the querystring contains a bad character, the view should return 400. Opened  https://github.com/Kinto/kinto/issues/1707 as you suggested. Thanks for the report!\n\nBut, the error should be caught in the assert statement. This just causes the test to fail because the record is added twice.\n\nI didn't understand that part :( What do you mean by caught in the assert statement ? . Yeah true. There is still need to specify xenial though.. But this issue was not fully clear in terms of scope.\nThanks for pointing it out!. Also, I don't think it's a good pattern to have the ability to mix code and settings :)\n. Upstream issues:\n- https://github.com/Kinto/kinto-admin/issues/540\n- https://github.com/Kinto/kinto-admin/issues/577. @n1k0 I wrote a startup guide dedicated to remote settings here : https://remote-settings.readthedocs.io/en/latest/tutorial-local-server.html\nI think it would make sense that running the docker would be as easy as the first steps there. Most of the issues described here were fixed :) \nWe could still always improve things of course, but we should re-open focused issues where relevant!\nThanks @n1k0 for setting the cat amongst the pigeons*\n(*okay I admit, I looked it up on wordreference)\n. You are right this is not supposed to happen! \nSo, basically the issue here is:\n the account capability is exposed since the plugin was enabled\n the configured policies don't mention account in the multiauth.policies \n* the Kinto Admin thinks the server can authenticate users with account, where it can't.\nI think the solution to this is would be to raise a configuration error if the account plugin is included but the policy is not enabled in multiauth.policies setting as described in the docs https://kinto.readthedocs.io//en/stable/api/1.x/accounts.html\n. Some progress made here. I'm glad I found the motivation and time to tackle this :smile: . Tests are green \\o/\nr+ anyone ?. Hmm, I don't reproduce this on the dev server. https://kinto.dev.mozaws.net/v1/admin/\nAny error in the console? \n\n. Now that I spent some time on the kinto-admin code, I can get back of this issue :)\nThe fact that the auth form posts to the root URL is expected: we use the root URL response to check if the user field is present.\nAs for the Error compiling schema error, I'll reopen the issue on the kinto-admin repo if it pops up again.\nI'll close this ;). > Shouldn't this return be a continue?\nExcellent catch! It should be a continue! It's a buuuug :)\n\nActually I don't really find the code very easy to read..\n\nOh yeah I agree!. I would agree with changing that indeed: use the current timestamp before serving the response instead of the one when the request kicks in.\nWe should still be able to have individual or intermediate timestamps in the impact_records attribute I believe.\nMore generally, we should tackle #945, the semantics of the \u00abglobal\u00bb fields of an event are wrong. \n\nNote: if someone reads this, the terms collection and records in this issue represents the internal notion of kinto.core, and applies to buckets, groups, collections, records, accounts... in kinto. See #710 . > Running the test suite with @reify on my laptop finishes in 225-235 seconds. Running with @property finishes in 240-255. So I guess we should probably keep the @reify.\n\nI'm not sure it's a clear indicator, since most of the test use the memory backend. Some load test maybe more accurate, but again with PG on the same machine I don't know if the difference will be huge. . Hello https://github.com/property and https://github.com/reify :hand: . I don't think so, look at this job on Travis with python 3.5:\nhttps://travis-ci.org/Kinto/kinto/jobs/435094504\n. https://github.com/Pylons/webob/blame/master/src/webob/acceptparse.py#L1005-L1010 ?. > Thanks, I will pick this one up\nAwesome!\nApparently you're right, Pyramid might be affected.\nBut we could start with cornice (we own the repo):\nhttps://github.com/Cornices/cornice/search?q=best_match&unscoped_q=best_match\n\nAlso using iPython3 (or jupyter) is there a way to see this warning?\n(Basically trying to recreate, apply a fix and unit test before I implement\nthe code for Kinto)\n\nI see them when I run the tests tox -e py36. Don't bother about unit tests for that case. We can also see them on TraviCI jobs output\n. If I understand well what is said here : https://github.com/Pylons/webob/blame/master/src/webob/acceptparse.py\nWe should use .acceptable_offers(). > How do I unit-test to make sure my changes are fine?\nIn that case I don't think we really need unit-tests. The tests coverage in Cornice is 100% I think.. See https://github.com/Cornices/cornice/pull/493. Yes! please do! Welcome on board ;). Yes, you can work on it!\nBasically, when you run the tests, you will see some deprecations like the one I pasted above.\nThe idea is to fix the code to get of rid of them :). Actually I may have been confused, here is what we have:\n```\n\u279c  ~ http PUT https://kinto.dev.mozaws.net/v1/buckets/bam \"Authorization: blabla\"\nHTTP/1.1 401 Unauthorized\nAccess-Control-Expose-Headers: Backoff, Retry-After, Content-Length, Alert\nConnection: keep-alive\nContent-Length: 110\nContent-Type: application/json\nDate: Thu, 27 Sep 2018 12:59:49 GMT\nServer: nginx\nWWW-Authenticate: Basic realm=\"Realm\"\nWWW-Authenticate: Bearer realm=\"Realm\"\nWWW-Authenticate: Basic realm=\"Realm\"\nWWW-Authenticate: Portier realm=\"Realm\"\nX-Content-Type-Options: nosniff\n{\n    \"code\": 401,\n    \"errno\": 104,\n    \"error\": \"Unauthorized\",\n    \"message\": \"Please authenticate yourself to use this endpoint.\"\n}\n```. Ok, the test case would be this then:\n```\n\u279c  ~ echo '{\"permissions\":{\"collection:create\":[\"system.Everyone\"]}}' | http PUT https://kinto.dev.mozaws.net/v1/buckets/bam -a admin:s3cret\nHTTP/1.1 201 Created\nAccess-Control-Expose-Headers: Backoff, Retry-After, Content-Length, Alert\nConnection: keep-alive\nContent-Length: 194\nContent-Type: application/json\nDate: Thu, 27 Sep 2018 13:06:28 GMT\nETag: \"1538053588434\"\nLast-Modified: Thu, 27 Sep 2018 13:06:28 GMT\nServer: nginx\nX-Content-Type-Options: nosniff\n{\n    \"data\": {\n        \"id\": \"bam\",\n        \"last_modified\": 1538053588434\n    },\n    \"permissions\": {\n        \"collection:create\": [\n            \"system.Everyone\"\n        ],\n        \"write\": [\n            \"basicauth:cd075adfa24e28743a8435d594a8353132465e23eaeabfe4142e465e088c2ffa\"\n        ]\n    }\n}\n```\n```\n\u279c  ~ http PUT https://kinto.dev.mozaws.net/v1/buckets/bam/collections/bim \"Authorization: blabla\"                                         \nHTTP/1.1 201 Created\nAccess-Control-Expose-Headers: Backoff, Retry-After, Content-Length, Alert\nConnection: keep-alive\nContent-Length: 95\nContent-Type: application/json\nDate: Thu, 27 Sep 2018 13:06:39 GMT\nETag: \"1538053599860\"\nLast-Modified: Thu, 27 Sep 2018 13:06:39 GMT\nServer: nginx\nX-Content-Type-Options: nosniff\n{\n    \"data\": {\n        \"id\": \"bim\",\n        \"last_modified\": 1538053599860\n    },\n    \"permissions\": {\n        \"write\": [\n            \"system.Everyone\"\n        ]\n    }\n}\n```. Great thanks!\nThe idea is to get rid of all the deprecation warnings, so replace it everywhere.\nAlso, could you please add a line in the CHANGELOG file please?\nIf you run tox -e flake8 it should show no error (cf. https://travis-ci.org/Kinto/kinto/jobs/434615685). Great thanks! I'v just checked the test output on Travis, and those deprecations are gone ;)\n. you absolutely can!. I would suggest adding a flush-cache command, that would call the .flush() method of the cache backend.\nIt should not be too hard to get it working. For testing, you can look at:\nhttps://github.com/Kinto/kinto/blob/e19ff82e38dd263d5f6480652d4ed2d02ff50557/tests/core/test_scripts.py#L13-L14\nDon't hesitate to open a pull-request very early in the process, this way it's easier to help :)\nEnjoy! . Great !\nThe warning is not here anymore (https://api.travis-ci.org/v3/job/436097314/log.txt). Thanks!\nIf you are interesting in more easy-picks, don't hesitate to look throughout the https://github.com/Kinto org ;). Yes, I would be in favor of adding type definitions! Don't hesitate to start, even if we don't do everything we keep track here of what's remaining to cover :) \n. > I will work on it shortly, the aim is to stay compatible with 3.5 for now right?\nYes, mainly because it is a common python version on several distributions. It's kind of tricky to fix, because we register a route with the explicit name default:\nhttps://github.com/Kinto/kinto/blob/cd6bb4f0416265ca05fe52a7a05a42cdf46bad8f/kinto/plugins/default_bucket/init.py#L202-L203. Thanks for starting this :) \n@Natim would be happy if we would enable Black here ;) \nI have one feedback: I don't think having that kind of annotations are helpful: List[Dict[str, Union[int, str]]]:. If we could have something like List[StoredObject] and somewhere have StoredObject defined to be a dict with at least an id, last_modified... it would be better ;)\nIs it possible?. @Cnidarias should we keep this PR open? \nNow that we have black, and that the core is a bit more polished (#1827  #1932), we could get back to this :)  . @Natim @glasserc  ?. Note: @peterbe recommends therapist https://github.com/peterbe/hashin/pull/80/files. Be careful commit edbf3b8  should not be part of this PR. Excellent! Let's get the documentation part updated for developers in the community section and then we can iterate :) We should probably add the necessary deps in the dev-requirements.txt right?\nThe diff is hard to review :sweat_smile: \n. Almost there! :tada: \n\nI would like to avoid configuration of black if possible. Double quotes are fine.\nSince python 3.5 is still officially supported, we have to adapt. Suggesting its installation manually in the dev docs is fine IMO\n\nThanks :pray: . Let me know if you need help or support ;) \nActually I would be very interested with this PR, because I started to work on #710 using xargs sed like an animal :). :) here we go :) thanks again ;). Hi @anshvyas !\nFirst, you can try to setup the project development environment locally:\nhttps://kinto.readthedocs.io/en/stable/community.html#hack\nOnce you have that, you can try to execute the test suite related to schema validation:\nThe following command should be successful:\n$ py.test tests/test_views_schema_record.py\nThen you introduce some changes and verify that the tests still pass :) \nDon't wait for your code to be perfect/done before submitting a pull-request though. . > Can you explain to me how the schema_validation.py gets executed in the following line\nIn this particular case, you will be executing the validation of a collection creation/modification (in kinto/views/collections.py)\n. > More interestingly would be to file a new issue that measures how often the JSON Schema validation happens on a busy environment\nThe JSON schema validation is called everytime a record is modified in a collection that has a schema.\n\nif it'd be possible to use something like a module level cache of reusable instances.\n\nSounds like a good idea!\nedit: And thanks a lot Peter for your inputs!\n. Yes sure!. Does it mean it never worked?\nI'm surprised, I'm pretty sure that not put account_create_principals = system.Everyone in settings does not allow to create accounts...\n. We have to figure out what is going on during this 1 second. It's far too much for a couple of DB lookups.. How long does it take if given password is wrong for ethan? . > Usually what we did in the past is to md5 encode the domain to build a guessable UUID.\nIndeed, if they use a script to upload record, they can just do:\npy\nrecord = {\"id\": domain.replace(\".\", \"-\"), \"domain\": domain}\nAnd do the same when looking it up: \njs\nRemoteSettings(\"tippytop\").get({filters: {id: domain.replace(\".\", \"-\")}});\nAnd we can set a disabled widget in Kinto-Admin so that user can't change the domain value in order to maintain consistence between the id and domain fields\n. > Do we make them md5 the domain name themselves? Do we add kinto-admin support for this kind of ID generation?\nFor this particular use-case we're good, they use a Python script to upload their data :) \n\nAs far as I know the kinto admin doesn't let you pick a ID\n\nYes it can if it's mentioned in the schema. . ```\n$ therapist run --fix kinto tests                              \nblack ............................................................... [SUCCESS]\nflake8 .............................................................. [SUCCESS]\n\nCompleted in: 43.26s\n```. . @glasserc what do you think of all this? Objects vs. Items, I thought we agreed on Objects. What about the \"plural\" things here and there?. I've just ~~rebased~~ merged master\nThat late debate around objects versus items versus resources really killed my motivation TBH. This is ready for merge :) . > hopefully you didn't rebase any changes into an earlier file.\nNope I didn't. I force-pushed because I amended the merge commit from master.\nThanks for your reviews! It's ready to land! Since this touches many files, I'm tempted to squash the commits before merging.... Traceback:\ntests/core/test_scripts.py:3: in <module>\n    from kinto.core import scripts\nkinto/core/scripts.py:10: in <module>\n    from kinto.plugins.quotas import scripts as quotas\nkinto/plugins/quotas/__init__.py:3: in <module>\n    from .listener import on_resource_changed\nkinto/plugins/quotas/listener.py:5: in <module>\n    from kinto.core.storage.exceptions import RecordNotFoundError\nE   ImportError: cannot import name 'RecordNotFoundError'. 2.2.1 fixed it thanks!. Pyramid has the same ConfigurationError :). > wouldn't something like raise VersionNotFound do the trick?\nWhatever, we just need to raise an exception with a clear message that the server administrators would receive when a client tries to access this endpoint if the file does not exist.... Why do we need hupper? :) . Draft7 is available is jsonschema v3, you should upgrade it ;) https://github.com/Julian/jsonschema/blob/master/CHANGELOG.rst . @peterr101 some new versions of bravado core were released... could you please have a look?. Could you please explain this pull-request?. Well you submitted a change to a file that lists the contributors of this repo :)  You usually do this after having changed some code!\nIf you're interested by Kinto and some its good first bugs, let's discuss in the issues directly ;)\nHave fun!. > we don't test a lot on Edge.\nI never had the chance to try this browser :) . Should we close this? Since it looks like #1850 ?. Thanks for starting this!\nThis seems to work from what I see in the Travis CI log.\nBut that's a pity, the command is ran for every environment, even like docs or linting...  I think the admin build should have a dedicated entry in the matrix instead. \nIs that what you say that fails?\n. > Travis CI seems to still be failing, I'm looking at it now. \nyou should run this locally before relying on TravisCI:  \n$ py.test tests/core/test_views_version.py\n\nBut can someone please advise me on how to update this pull request instead of spamming with more new ones?\n\nJust push more commits to your master branch and it will update this PR automatically. Close the ones that you want to ignore ;)\n. > Regarding the changelog, should I just add the change 11.2.0 (unreleased)?\nAdd a line in the paragraph on top, mentioning your change :) And you can yourself to the list of contributors ;)\nThanks! . Thanks a lot! Welcome in the game ;). See  #579. I don't understand this issue, how is it different than #1659?. I think it makes sense to have this exact post as a comment in the issue there, or as the description of a pull-request that starts the work. We are open to suggestions!. I don't understand what this issue means. \nSSH does this:\n```\n$ ssh user@server.org\nuser@server.org's password: \n....\n```\nPlease re-open with more details if relevant ;)\n. It looks to me! Thanks for taking the time to do this!\n\nPerhaps it is correct for the functional build to fail as it runs on 3.5?\n\nThis PR will drop support of Python 3.5.\nThe TravisCI configuration and CHANGELOG should also be updated to reflect that ;)\nIt looks like you should run black to format your changes (see TravisCI job py36) . Could you please update your branch, we'll merge ;). Related #903. Thanks for your contribution!!. Those were @Natim favorites :D \nThis happens in the batch endpoint which is a bit specific. Some more safety checks might be necessary.\nOtherwise, this should help greatly https://github.com/Pylons/webob/pull/390\n. Please, go on!\nNot much more to add to the instructions given in the message :). Yes it did:\nhttps://travis-ci.org/Kinto/kinto/jobs/461791830#L606\nThe tests output a loooot of warnings (https, postgresql config...). There is Flit as well... https://flit.readthedocs.io/en/latest/ which says no need for setup.py and setup.cfg ...\n. thanks :) . Workaround is to install the jsonschema lib with --pre option. This should be ok now with 11.2.1. @peterbe, don't worry about the conflicts, I can do it and try to push a merge on your branch.. I have one major question though: what do we do about our clients:\nhttps://github.com/Kinto/kinto-http.js/blob/27737b9e62df2aff6adc32523708cd7e66131282/src/base.js#L540 --> Nan\nhttps://github.com/Kinto/elm-kinto/blob/d5b5337166f23d130322858ace30c0a80abdca28/src/Kinto.elm#L299-L301 --> 0\nMaybe we should first release of kinto-http.js where the totalRecords is obtained via a HEAD? \n(I don't know, truely asking..). The wacky diffs come from some mistakes I made during the painful merge I guess. \n. @peterbe, I merged and repaired the merge :) Tests now pass.\nI believe what remains is:\n- [x] be extremely clear about the removal of the header in GET in changelog\n- [ ] ~~Maybe we could have a server setting to maintain the header if set to True (default: false) for situations where clients rely on this info~~\n- [x] document that the header can be obtained with HEAD\n- [ ] figure out a way to nicely document that we Total-Records is now deprecated in favor of Total-Objects because of #710\n- [x] improve the models code (eg. two methods instead of count_only param)\n- [ ] squash could be a good idea (didn't want to force push on your branch ;))\n- [x] kinto/core/storage/testing.py still uses objects, total_count = self.storage.get_all(params) and that causes deprecation warnings. . Yeah, I'm ok with whatever ;) . > Could you elaborate on the changed behavior of PATCH operations that don't change anything? Is this a changed API behavior? What was the justification for the old behavior?\nIn user resource, when a PATCH didn't change anything we wouldn't hit storage. In shareable resources (ie. whole kinto), it does. \nIf I remember correctly, in ReadingList we had some code that wouldn't change the existing \u00abreading position\u00bb if it was inferior to the current one or something like that.\n\nWe do use PRIVATE :dancer: \n\nI guess that returning self.request.get_prefixed_userid() in the get_parent_id() method should be enough.\nWe can keep the PRIVATE permission and bypass the permission backend entirely.\nThe only different with the old code is that the responses payloads will contain a permissions field.. @glasserc @Natim r?. > I'm (still....) sad about the loss of the docstrings which (in my mind) communicate a bit about what Resource is \"for\" and how you might use it in a plugin.\nSorry I didn't get back to that, true, I will then.\nI was very surprised by the amount of docs we have for kinto.core though :D . The route is now called collection-object, this is due to #710 \nThat means we need a fix in kinto-attachment :) . I released a new version kinto-attachment. > ...and they don't really care about implementation details within.\nYou're right, let's merge!. Thanks for the hard work!. Nice! Thanks!\nAre you motivated to refactor the failing parts?. I had to complexify a bit the original patch, in order to have consistency WRT schemas defined at bucket level (record:schema, collection:schema ...etc)\nMay deserve a second look. . `````\n1.8.5 (2019-01-03)\nWarnings\nFixed one last remaining invalid escape sequence in a docstring.\n\n```\n. Welcome onboard! Go ahead ;) \nIn brief..\n- remove the code itself\n- remove the tests\n- remove the docs\n- add a CHANGELOG entry :). > We can have a settings to activate email validation, that will enforce email as usernames.\nI like the idea of extending the accounts plugin with email/registration features.\nIt would require pyramid_mailer (or Kinto emailer?) to be installed though.\nThe field \"activated\": false could work, but we need it to be read-only when modified via the HTTP API\nI think that using the cache backend for activation/reset tokens would work. If users take too much time to activate the account, and they must revisit the activation/reset endpoint... > I'd like a different resource schema for the Account class if the 'account activation' option is enabled in the settings, is that possible?\nYes there must be way with colander defer, or pyramid views scanning.. I wouldn't bother with that for now ;) . +1 to use pyramid_mailer directly.. This is interesting too: the timestamp in the header is not the latest timestamp...\n```\nhttp DELETE $SERVER/buckets/main/collections/fxmonitor-breaches/records -a admin:s3cr3t \nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Alert, Retry-After, Content-Length, Backoff\nContent-Length: 283\nContent-Type: application/json\nDate: Fri, 18 Jan 2019 09:59:06 GMT\nEtag: \"1547805531452\"\nLast-Modified: Fri, 18 Jan 2019 09:58:51 GMT\nServer: waitress\nX-Content-Type-Options: nosniff\n{\n    \"data\": [\n        {\n            \"deleted\": true,\n            \"id\": \"ad1557d4-5c78-4e87-810a-394076f87d41\",\n            \"last_modified\": 1547805546445\n        },\n        {\n            \"deleted\": true,\n            \"id\": \"61ea1a61-fe57-4417-a0a3-c4d6e22abfcb\",\n            \"last_modified\": 1547805532615\n        },\n        {\n            \"deleted\": true,\n            \"id\": \"b3adfaf8-32e5-4df4-a033-801674e12740\",\n            \"last_modified\": 1547805531452\n        }\n    ]\n}\n```. Another service? I don't remember it :(. @Natim could you r+ me please? I need to send in prod ASAP :pray: . Thanks!\n. When? How? What are the steps?\nWe use the Admin with OpenID successfully everyday :) . > Do you have a pip command to do so?\nI initialized it with hashin but now dependabot is going to update them automatically . > My understanding is that pip doesn't support this feature but pipenv does, does it?\npip does! we use it in kinto-dist already. > Why are tox and wheel and setuptools in dev-requirements.txt? Is legacy or a good reason?\nI presume that they are necessary to release Kinto and publish on pypi. We would consider as dev requirements anything a dev uses ;). I should probably drop this PR then, no?. the user field in the root URL would be nice, but probably not as easy as the other option ;). Can you please update CHANGELOG + CONTRIBUTORS files?. I'm surprised, this was supposed to do the job no?\nhttps://github.com/Kinto/kinto/blob/322139b774b356cf024c553affa28548cb3aa694/kinto/core/resource/init.py#L1160-L1164. I could not reproduce locally :( \nThis is what I did:\nhttps://gist.github.com/leplatrem/af47241da55693e1c75479b2d1e92f48\n. So the easiest wasy I can suggest is to create another account, give it privileges via the .ini file.\n```ini\nAllow anyone to create accounts.\nkinto.account_create_principals = system.Everyone\nSet user 'account:admin' and 'account:recover' as the administrator.\nkinto.account_write_principals = account:admin account:recover\nCreate the `recover` account (using `httpie`):\n$ echo '{\"data\": {\"password\": \"secret\"}}' | http PUT :8888/v1/accounts/recover -v\n``\nOverwrite theadmin` password:\n$ echo '{\"data\": {\"password\": \"new-password\"}}' | http PUT :8888/v1/accounts/admin -a recover:secret\nDelete the recover account:\n$ http DELETE :8888/v1/accounts/recover -a admin:new-password \nRemove account:recover from the .ini file :)\nLet me know how it goes!\n. hmm.. \nhttps://github.com/Kinto/kinto/blob/8455861294cf35963e24946d301e5c04daa6f3f7/kinto/plugins/admin/public/index.html#L6-L7. @dependabot rebase. Me too... :face_with_thermometer: \n\n. @dependabot rebase. > Not since @peterbe removed the constrain...\nWhere? And look at the screenshot.... > 1.7.0 is the one in the file: https://github.com/Kinto/kinto/blob/master/requirements.txt#L5\nYes because I've just merged #2020 \nBut not in 1bfa4217f1c00fb2ff7e26e75b75d17a38db57fc. > Really strange indeed confused\ntox creates a sdist archive and installs from it.\nSome implicit shit. Never liked tox. I'll look into it to fix that\n```\nusing tox-2.9.1 from /home/mathieu/.local/lib/python2.7/site-packages/tox/init.pyc\nGLOB sdist-make: /home/mathieu/Code/Mozilla/kinto/setup.py\n  /home/mathieu/Code/Mozilla/kinto$ /usr/bin/python /home/mathieu/Code/Mozilla/kinto/setup.py sdist --formats=zip --dist-dir /home/mathieu/Code/Mozilla/kinto/.tox/dist >/home/mathieu/Code/Mozilla/kinto/.tox/log/tox-0.log\npy36 create: /home/mathieu/Code/Mozilla/kinto/.tox/py36\n  /home/mathieu/Code/Mozilla/kinto/.tox$ /usr/bin/python -m virtualenv --python /home/mathieu/Code/Mozilla/kinto/venv-test/bin/python3.6 py36 >/home/mathieu/Code/Mozilla/kinto/.tox/py36/log/py36-0.log\npy36 installdeps: -r/home/mathieu/Code/Mozilla/kinto/dev-requirements.txt, -c/home/mathieu/Code/Mozilla/kinto/requirements.txt, psycopg2, newrelic, raven, statsd\n  /home/mathieu/Code/Mozilla/kinto$ /home/mathieu/Code/Mozilla/kinto/.tox/py36/bin/pip install -r/home/mathieu/Code/Mozilla/kinto/dev-requirements.txt -c/home/mathieu/Code/Mozilla/kinto/requirements.txt psycopg2 newrelic raven statsd >/home/mathieu/Code/Mozilla/kinto/.tox/py36/log/py36-1.log\npy36 inst: /home/mathieu/Code/Mozilla/kinto/.tox/dist/kinto-13.1.0.dev0.zip\n  /home/mathieu/Code/Mozilla/kinto$ /home/mathieu/Code/Mozilla/kinto/.tox/py36/bin/pip install /home/mathieu/Code/Mozilla/kinto/.tox/dist/kinto-13.1.0.dev0.zip >/home/mathieu/Code/Mozilla/kinto/.tox/py36/log/py36-2.log\n  /home/mathieu/Code/Mozilla/kinto$ /home/mathieu/Code/Mozilla/kinto/.tox/py36/bin/pip freeze >/home/mathieu/Code/Mozilla/kinto/.tox/py36/log/py36-3.log\npy36 installed: apipkg==1.5,appdirs==1.4.3,argh==0.26.2,atomicwrites==1.3.0,attrs==18.2.0,bcrypt==3.1.6,beautifulsoup4==4.7.1,black==18.9b0,bleach==3.1.0,bravado-core==5.10.1,certifi==2018.11.29,cffi==1.11.5,chardet==3.0.4,Click==7.0,colander==1.7.0,colorama==0.4.1,cornice==3.5.1,cornice-swagger==0.7.0,coverage==4.5.2,dockerflow==2018.4.0,docopt==0.6.2,docutils==0.14,entrypoints==0.3,execnet==1.5.0,filelock==3.0.10,flake8==3.7.4,hupper==1.4.2,idna==2.8,iso8601==0.1.12,jsonpatch==1.23,jsonpointer==2.0,jsonref==0.2,jsonschema==2.6.0,kinto==13.1.0.dev0,logging-color-formatter==1.0.2,mccabe==0.6.1,more-itertools==5.0.0,msgpack-python==0.5.6,newrelic==4.12.0.113,packaging==19.0,PasteDeploy==2.0.1,pathtools==0.1.2,pkg-resources==0.0.0,pkginfo==1.5.0.1,plaster==1.0,plaster-pastedeploy==0.6,pluggy==0.8.1,psycopg2==2.7.7,py==1.7.0,pycodestyle==2.5.0,pycparser==2.19,pyflakes==2.1.0,Pygments==2.3.1,pyparsing==2.3.1,pyramid==1.10.2,pyramid-multiauth==0.9.0,pyramid-tm==2.2.1,pytest==4.2.0,pytest-cache==1.0,pytest-cov==2.6.1,pytest-sugar==0.9.2,pytest-watch==4.2.0,python-dateutil==2.7.5,python-memcached==1.59,pytz==2018.9,PyYAML==3.13,raven==6.10.0,readme-renderer==24.0,requests==2.21.0,requests-toolbelt==0.9.1,rfc3987==1.3.8,simplejson==3.16.0,six==1.12.0,soupsieve==1.7.3,SQLAlchemy==1.2.17,statsd==3.3.0,strict-rfc3339==0.7,swagger-spec-validator==2.4.3,termcolor==1.1.0,toml==0.10.0,tox==3.7.0,tqdm==4.30.0,transaction==2.4.0,translationstring==1.3,twine==1.12.1,ujson==1.35,urllib3==1.24.1,venusian==1.2.0,virtualenv==16.3.0,waitress==1.2.1,watchdog==0.9.0,webcolors==1.8.1,webencodings==0.5.1,WebOb==1.8.5,WebTest==2.0.32,Werkzeug==0.14.1,zest.releaser==6.16.0,zope.deprecation==4.4.0,zope.interface==4.6.0,zope.sqlalchemy==1.1\n``. See #2024 . > This might be a dumb question, but what is the value of arequirements.txt` file?\nPin the known good set of dependencies.\n\nDo we expect our users to retrieve this file and pass it when doing pip install kinto?\n\nI don't think so, although they could.\nAt least we want to make sure that the proper dependencies are pulled when we build the Docker container for example.\n. I don't think we'll add newsletter features to kinto, but using this use-case to rethink permissions or options makes sense ;) \nI would like to have finer-grained permissions :) see #1550 and #368 for example.\nSomething like...\n{\n   \"write\": [\"admin\"]\n   \"record:create\": [\"system.Everyone\"],\n   \"record:read: [],\n   \"record:write\": [],\n}\n. > Is this a good opportunity to remove this wacky import and just depend on jsonschema 3.0.0?\nYes! And also remove the mentions of pre-releases #1900 . commit this ?\n. Hard to believe : this is cloud storage :)\n. yes, ok, seen the tests\n. @Natim : fully agree!\n. Ah yes, that's because of https://github.com/mozilla-services/cliquet/issues/30\ncollections management is definitely not a requirement :)\n. you mean : \n\nas such, please refer to cliquet's documentation regarding API and endpoints.\n. I believe the scheme is mandatory for urlparse to parse this uri correctly :/\n. that makes Redis available on localhost:6379 ? No change needed in app conf ? \n. only connect\n. XXX\n. 1.7.0\n. I believe it makes more sense to talk about \"roles\" instead of \"groups\"\n. Principals is weird word. We probably don't want to use it.\n. With the bucket name as prefix, the collection name becomes unique.  (?)\n. Why not replace ?\n. error response.\n. allows to add or remove\n. PUT can be used to override the set.\n. same set of records\n. anymore?\n. Here I would just say the write permission in plain english\n. first apparition of groups ?\n. This endpoint defines the bucket resource:\n* its owners\n* its permissions\n. What if we only keep write and read ?\n\nIf in the future we have specific use cases, we'll extend them! For example, collections:write, groups:write... considering write means all of them for retro-compat'...\n. information\n. Typo GET\n. endpoint \n. anymore ?\n. enables\n. eases\n. group:seekers \u2190 singular\n. rights ? \u2192 permissions\n. kinds\n. *Kinto*\n. any authenticated user can create buckets.\n. record\n. we have \u2192 consider the following diagram\n. has got.\nWhere is it stored ?\n. Where is it stored ?\n. But, should it be 409 when permission to replace is denied ?\n. yes, group is singular\n. enable\n. By default, the bucket of the current user is used.\n(the second part between parenthesis could not be processed by my brain at this time of the day)\n. collections can have the same name across different buckets\n. groups appear out of the blue here\n. ~~anymore~~\n. Do mention that notion of permission here. It comes after.\n. The part after In any case is not clear at all. It should be put above, after the optionnally specifying....\n. user principals come out of the blue here\n. administration permissions  come out of the blue here (it was mentioned as owner before)\n. here those braces bring confusion. Better put some random UUID\n. I would have prefered something like that : \n```\n    \"permissions\": {\n        \"admins\": [\"uid:basicauth_5d127220922673e346c0ebee46c23e6739dfa756\"],\n        \"groups\": {\n            \"create\": []\n        },\n        \"collections\": {\n            \"create\": []\n        },\n    }\n\n``\n. This is useless here, better put it above in the introduction\n. Creating a collection inside a bucket enables [..] on all buckets collections ? \u2192 not clear :) \n. what is this ?\n.group:moderators` ?\n. acls is not suitable IMO :)\npermissions is a lot better, and consistent with buckets\n. Same here, I would have liked this layout:\n\"permissions\": {\n   \"records\": {\n       \"read\": [\"userid:<buyer-id>\", \"appid:<seller-appid>\"]\n   }\n}\n. rights --> permissions\n. A twitter bucket is created\n. group: singular.\n. Note: this is not collision-proof. IHMO it shouldn't prevent merging, but could deserve an enhancement ticket :)\n. This should be removed.\n. Oops to be done !\n. This should be removed.\n. To be done !\n. collection_id comes from internal Cliquet, and should be explicit : \n``` python\nfrom kinto.views.buckets import Bucket\ncollection_id = Bucket(self.request).collection.collection_id\n```\n??\nor explicit : \n``` python\nclass Bucket(resource.BaseResource):\nname = 'bucket'\n\ndef __init__(self, *args, **kwargs):\n   super(...)\n   self.collection.collection_id = self.name\n\n```\nAnd then : \n``` python\nfrom kinto.views.buckets import Bucket\ncollection_id = Bucket.name\n```\n. Object URI building is not DRY.\n. yes good point !\n. Created issue in Cliquet https://github.com/mozilla-services/cliquet/issues/292\n. What do you have in mind ?\nI would go for https://github.com/mozilla-services/cliquet/issues/32 instead of resource hooks :)\n. I believe it's the contrary :)\n. I think that should happen after the storage update was performed. \nEven if using process_record() is more elegant, I guess that with the existing code (and no event system), we would have to override every endpoint post/put/patch in order to run this code after the storage operation was executed :|\n. I wouldn't put underscores here :)\n(first time I say this!! :D)\n. You chose not to add it to the bullet list ?\n. Now we have request.prefixed_userid :)\n. existing_record_members = set(old.get('members', []))\n. works ?\n. And would also suggest to re-run pip install -r dev-requirements for those who have an existing setup\n. Probably useless :)\n. getattr(obj, 'prefixed_user_id', None)\n. Can you explain what you do here ?\nI don't see any spec for this in the tests :)\n. If we do PUT on /buckets/default/ then it's done twice ?\n. We probably want to test that it does not raise a 412 on the second request\n. all collections\n. See #71 \n. I would add something like for buckets:\nA collection is the parent object of records. It can be viewed as a container where records permissions are assigned globally.\n. are defined (?) in buckets\n. ~~has the rights~~ --> is allowed\n. bucket group (?)\nAFAIK 's will express possession, not sure it works here\n. and its id will be assigned automatically (?)\n. You used singlular present elsewhere (i.e. Creates)\n. ditto\n. I would suggest articles titles, todo list status, ...\n. ditto\n. of applications where *Kinto* is particularly relevant\n. - Sync user...\n. You can get rid of this IMO\n. Let's\n. personal bucket\n. Looks like @ametaireau introduced some sphinx tooling for this\n. (e.g. todo, ...)\n. previous call above\n. In case you want to use the Server wins behaviour, you must sent the ...\n. we obtained while fetching the collection\n. rejects\n. In order to merge both version, we can fetch the last version of this single record \n. list of changes that occured since we have fetched the collection\n. records\n. I would say ETag here\n. If you want to obtain the list of records that were deleted\n. Exactly, add a test to verify that the 412 is not exposed to the user on the second request\n. Yes, it makes sense.\nDon't you think we could add a small comment here to remember that we could do some optimization if needed later ?\n. +1 (and collection ?)\n. monitoring came already with setup.py develop since Kinto is supposed to already have it in setup.\n. Oh great !\n. ``` python\nis_put_collection = (request.method.lower() == 'put' and request.path.endswith(collection_id))\nif not is_put_collection:\n    ....\n```\n. The collection already existed\n. When I read this, I realize that I missed a big part of the spec: objects are created on access.\nI don't want to retain the merge of this, but we may want to open an issue and restrict the creation of objects to \"PUT/POST\" requests.\nOtherwise, once I know the bucket id of someone, I can fill it with millions of collections, just by trying to reach them with GET. \n. maybe move this to cliquet.utils then\n. OH very good point !\n. merged!\n. Please remove this changes from this PR (out of scope), it will be adressed in #90 or #95 \n. ditto\n. I think it requires quotes\n. This does not install postgresql deps in Travis\nhttps://travis-ci.org/mozilla-services/kinto/jobs/69301205#L244\n. @Natim I left it because we've seen that it does not work\n. Indeed it was in the past, when UUIDs were generated on the DB side.\n. I would have expected them to be equal. Created an issue, discussion happens there: https://github.com/mozilla-services/cliquet/issues/356\n. +1 for six.text_type() :)\n. Instead of copying the code of the view to compute the bucket id in the test, it would make more sense to compare to an actual value (by forcing hmac_secret to a specific value for example)\n. Please add a comment (and a test?) for this if\n. By default, nobody can read...\n. Why not leave that in SimulationLoadTestMixin ?\n. Why those intermediary   ~~functions~~ methods ?\n. Should be fixed now ?\n. I don't see where this is used\n. Useless ?\n. nit: indentation is not consistent with previous self.session.get\n. Wouldn't we want to store collection_url and record_url in a variable ? (it seems repeated a lot)\n. I think you can set this header on the session object instead of repeating it at each request\n. Same for auth http://docs.python-requests.org/en/latest/user/advanced/\n. Here I would use an intermediary variable to present the permissions object nicely\n. ditto\n. nit: I guess we can omit this (unless you had a reason to specify it)\n. nit\u00b2: the fact the collection id is default here does not bring too much value, and it is somehow confusing to understand the test\n. I guess you tried to add the route with the same name :) \n. Now that I see this, I wonder: it could have been possible to define an optional group starting with / in the regexp ?\nex. /bucket/default{subpath:^(/.*)?$} \n. Careful, double quotes are parts of the value\n. ~~manipulated~~\n. By default, the write permission is given to the creator of an object.\n. The currently authenticated user id can be obtained  of the root url.\n. This is unclear, and probably not relevant here \n. This was explained elsewhere, and I'm not sure that this sentence is clear.\n. also explained elsewhere\n. You ? We ? \n. personal bucket ?\n. Similarly, the permissions of a collection can be obtained with a GET:\n. The user that updates the permissions is always given the write permission, in order to prevent loosing ownership on the object.\n. Permissions can be specified during the creation of an object, and can later be updated ...\n. This sentence is unclear. What is the comments collection ?\n. Ah ok.\nNow, it will be possible to create two collections (articles and comments) in this bucket. Users will be able to read their own records.\nSee - link to use case doc - \n. Still mandatory ?\n. PATCH the permissions of the comments collection\n. As described in the use case page, let us create a new group writers. \n. articles\nCould you be more explicit here ? Does it rely on https://github.com/mozilla-services/cliquet/issues/354 ?\n. What are we supposed to see here ?\n. -you\nThen, a POST request [...] flushes all the data\n. We could add like a symbol or something\n. note: groups endpoints are missing\n. Should re-explain the concepts in the API page ?\n. nit: prefer intermediary variable for nicer indentation\n. Ok thanks I will clarify this. (one tests cache_expires from settings, the other one from json api)\n. Well, it is acceptable that one test method doesn't rely on setUp, as long as it is not half of all methods.\n. > Note: Without the fix, call_count equals to 75. Now 27.\n. I would prefer a link to communication channels http://kinto.readthedocs.org/en/latest/contributing.html#communication-channels\n. yes, or something like replace-by-a-secret\n. This mean that you open the file with write mode. We probably don't want to erase it since it is under git control. Every time we will pull the changes with git, it will be overwritten.\nI suggest that we read it but write to another one (like config/dev.ini)\n. I would like to see this in **Bug fixes** :)\n. The leading / in the path here, migth be the source of your trouble\n. In ini files the sections are those strings between brackets (e.g. 'app:main')\n. I kind of agree, but I followed advices from #208 \nIt is not totally at the end though, it is below in the table:\n\n. Both /run and /var/run are valid on debian. If /var/run is more cross-platform, let's go for it :)\n. Small remark : I believe you could look into this pyramid/scripts/pserve.py and see if can call a function instead of running a subcommand. \n. I may be wrong, but I think you could use the cliquet_migrate function here (in cliquet/scripts) \n. Add a link more details to here https://github.com/mozilla-services/cliquet/releases/tag/2.9.0 ?\n. micronit: since Cache-Control may contain other strings, assertIn() could be safer\n. I would suggest to use a local variable config_file everywhere.\nFrom what I read here, migrate is always executed with config/kinto.ini\n. We could just put the sample in the egg and suggest to run kinto start only :)\n. good idead!\n. we could probably put a sample hostname here (e.g.  cdn.firefox.com). It would help to know if the value should contain protocol scheme or not\n. I would put this URI in a variable instead of repeating it 3 times\n. What happen if user types 3 :) ?\n. We don't complain?\n. default when empty string is seized yes, but surrounding the input with a while True: ... if backend in ('', '1', '2'): break would not change much\n. you mean prompting in the init() method ?\nI found it more consistent to have interaction with user along the CLI code rather than along templating.\nDo you have any strong argument?\n. Careful with this then, there is now two documents about versioning. I suggest you get rid of this one.\n. nit: If we plan on having .. added-on:: 1.10 in the doc, then the folder could be named 1.X instead of 1.0 :)\n. In the docs, we use several time the word enpoint (=verb + URL). It would be great to mention it somewhere around here\n. I'm ok with that.\nI wish we'd have endpoint like in Cliquet glossary (http://cliquet.readthedocs.org/en/latest/reference/glossary.html)\n. I think it endpoints should be defined in the glossary too then :)\n. nit: old revisions ?\n. Now that I see this... This is a fun answer, but I wonder if it serves our cause here :)\n. We can add a link to https://github.com/Kinto/kinto-attachment/ and mention that is already usable but not stabilized ? What do you think ?\n. I first wanted to keep a list of featured apps, but then thought it could conceal the wiki page...\n. We usually don't compare with boolean values, but use negation like if not os.path.exists(folder)\n. why switch to debian unstable?\n. why not python:3.5 + libpq-dev ?\n. why unsinstall ?\n. I think it's better to put several RUN to avoid re-running everything\n. So you don't build the container from the current code anymore. This is a big change! What advantage do you see?\n. I meant why not use the python:3.5 image and just apt-get install libpq\n. :+1: please add a comment then :)\n. the size is virtual AFAIK\nthat means if I already have the python image, then I will only download the new layer of kinto. Whereas if the container is built from a raw debian I download everything\n. wrong comment\n. in order to keep a consistency between the .ini mentionned in the RUN phase and this commands here, you should probably either:\n- put the WORKDIR command on top and remove explicit paths in RUN\n- use explicit paths to .ini in CMD\n. nit: make is part of build-essential\nwhy git ?\n. nit: why venv ? (ran as root, and isolated)\n. nit: libpq5 is not necessary if libpq-dev is installed\n. what is that?\n. I thought also, but then realize there were inconvenients: \n- the global index is bypassed (and can give some info to get started)\n- the link has to be maintained and can be broken more easily\n. How is this file published ? Updated ?\n. Good catch!\n. nit: make is already in build-essential\nnit2: why git ?\n. nit: libpq5 is redundant with libpq-dev\n. nit2: python3 is redundant with python3-dev\n. Add a comment like: Uninstall from container every packages that are used for installation only\n. micronit: you don't uninstall setuptools :)\n. From what I understand we can leave the \u00abofficial\u00bb docker compose\n. (once #376 is merged)\n. ah oh ok :)\nnanonit: you can put it on the same line as python3 and libpq5 then :)\n. should probably be replaced by httpie like elsewhere\n. typo: singular notification\n. ~~one~~\n. nit: unless the node becomes unreachable ?\n. routes them to different nodes\n. node~~s~~\n. nit: forcing the routing of a particular request to a specific node (?)\n. Could we write a test here to assert the value of id ?\n. We could write a test to specify the behaviour when a collection with this id already exists (returns 200 instead of 201 with existing object) \n. Yes, check that is contains something like uuid (does it? if it does just check the length for ex.)\n. The load balancer is the piece of software that takes\nThe load balancer is the piece of software that routes \nno ?\n. But it does not save you the step of adding to Python path ?\n. So that adding it automatically could be removed in 2.X, whereas config files can stay\n. Looks like you forget these two\n. Good catch!\n. token:my-secret ?\n. yes or bob-token, like we had my-secret\n. user management\n. There is no such thing as user sign-up, password modification, etc.\n. However, since Kinto handle permissions on objects, users are uniquely identified.\n. In this tutorial we will use a Basic Authentication, which computes a user id based on the token provided in the request.\nThis method has many limitations but has the advantage to avoid specific setup or third-party services to get started immediately.\n. This page has to be contrasted with api/cliquet/authentication.rst.\nIMO we should remove its inclusion and duplicate its content here.\n. cf. reformulated version in first-steps.rst\n. typo: plural?\n. this is redondant with http://kinto.readthedocs.org/en/latest/api/1.x/cliquet/authentication.html#basic-auth\n. nit: use :term:user id. _We recommend_\n. bytes digested \u2192 scary :)\n. where does crypto come from ?\n. nit: indentation\n. nit: Writeusing Nodeandusing Python` above each paragraph\n. nit: in JS you did hex first\n. +and observe the user id in the JSON response.\n. :+1: \n. your app \u2192 your use case\n. remove extra comma after changing the token\n. use emphasize-line to highlight the id\n. JWT is a popular one.\n. Basic Tokens \u2192 Basic Auth tokens\n. Not sure what you want to explicit here.\n. Where? In the tutorial! \u2192 Obsolete ?\n. `\nYou can generate new tokens and give thewrite`` permission to their respective user id.\nYou can also create a group per \u00abuser\u00bb whose members are the different user ids obtained from tokens. And then use this group in permission definitions on objects.\nMost likely, you would use an identity provider which will be in charge of user and token management (generate, refresh, validate, ...). See this example with Django <http://django-oauth-toolkit.readthedocs.org/en/latest/tutorial/tutorial_01.html>.\n```\n. that's what git log gave me. I'll put it back\n. This seems to have introduced a problem with the wheel for Python 3 (reopened #303).\n. nit: ref to issue :)\n. this should probably be removed\n. micronit: Python (uppercase P)\n. We fixed mozilla-services/cliquet#631\n. I would add a note here to say that _currently the configuration of the custom generator applies to every resources\nIt's a tiny limitation and could easily be fixed\n. There is something important I guess: the id generator should be random enough to avoid id collisions\n. I don't think we need this -1, since the _since and _before are both exclusive\n. In Kinto the timestamps are guaranteed to be unique at each write operation. So there will never be two records with the same timestamp! (there is a database constraint for that by the way)\n. No problem, thanks for reviewing this thoroughly!\n\nI had hundreds of records with identical timestamp, because the FxSync sets the first sync time as the timestamp for pre-existing bookmarks).\n\n@Natim we've got a problem then! :) I opened issue https://github.com/mozilla-services/syncto/issues/82\n. Why repeat supported ?\nI would suggest something as simple as:\n* **Python**: 2.7, 3.4+\n* **Backends**: In-memory, Redis or Postgresql 9.4+\n. Apache actually ;)\n. destination no?\n. The comments for the sequence diagram are only visible in the source. It is just to be able to edit the sequence diagram on the website. For architecture, it's an SVG so we can edit it directly in Inkscape\n. typo: PostgreSQL\n. queries ? requests ?\n. I'm bit embarassed by this since Kinto.js does not provide anything specific for encryption :)\n. Yep, I think you're right :)\n. I wouldn't mention experimental here\n. inconsistent indentation with test below\n. instead of having two tests suite to vary the setting value, you can do:\npython\napp = self.make_app(settings={...})\nresp = app.get('/')\n. nit: since default settings are loaded, you can do  settings['experimental...]\n. \u00abValidates collection records with JSON schemas\u00bb\n. nope it is not converted :)\n. Yes, you're right, I moved everything from inheritance to events \n. erf we should, but not only here...\nhttp://makina-corpus.com/blog/metier/the-worlds-simplest-python-template-engine :)\n. nitpick: I wonder if we should name it flush only (?)\n. nitpick: for the tests you can use a hard-coded value if you don't test its output\n. Why do you have this config_file_timestamp string here ? I thought the file content was compared somewhere else, no ?\n. Makes sense.\n. This can now be removed :)\n. you don't need to override setUp, tearDown, _get_test_app or get_app_settings since you don't change their behaviour\n. nitpick : use ```` around setting names and values\n. It is not a bad idea, but it would be a protocol breaking change. #lazy \n. As @almet said, and if I understood correctly, this might not be mentioned as a protocol change but as a new feature!\n. apparently @n1k0 does not agree with what we said here. So I will update the CHANGELOG in the release and keep a mention in the protocol changes.\n. collection-record ?\n. typo\n. nit: use infinitive everywhere for consistency\n. We may want to set help as the default target ?\n. monitoring features like StatsD and Newrelic\n. I just said that because of the trailing s in builds.\nAdding leading to seems superfluous\n. nit: 200 is superfluous\n. The group is not created in setup, so you should create it before deleting it.\n. route_path() is a method. It means it has to be called on an instance of the class. Not the class itself.\nIn this case:\npython\nbucket_uri = request.route_path('bucket-record', id=bucket_id)\ncontext.get_permission_object_id = lambda r, i: bucket_uri\n. You mean here in this file ? \n. You should not mention 2.7 since in the title you wrote 2.7/3.4+.\npython is installed by default on ubuntu/debian.\npython-dev is already mentionned below in the system requirements section.\n. orphan title\n. Redis is not mandatory so I don't think we should mention it here before all without context nor explanation\n. the vertical bars might deserve some horizontal adjustment \n. Should be 2.1.1\n. Should be 2.1.1\n. Note: I wonder if we should not reorder them (ex. errors and deprecation after main objects buckets, collections...)\n. nitpick: for code use double backtick\n. Good catch :+1: \n. wao I had no idea we could do that for bold words within links :)  Awesome!\n. question: should we add link to the FAQ ?\n. nit: use constant\n. nit: rename psycopg2_missing\n. nit: installs\n. nit: asks\n. nit: generates\n. shouldn't the no cover go to the except block ?\n. typo: No redirections ... or is made\n. instead of hello page I think we use root URL endpoint \n. Since we have a tox rule for this, the script might not be necessary\n. Is this a mistake or do you think the sync docs are not relevant ? https://github.com/Kinto/kinto/blob/master/docs/api/1.x/synchronisation.rst\n. Ok got it. We could move the file in the tutorials folder then\n. This fixes #543, we could add it to the changelog\n. Since those are not generated files, shouldn't we use recursive-exclude ?\n. This attribute is not defined if the condition is not met.\nInstead, you could define another RouteFactory (e.g.  BucketRouteFactory with a class attribute like allow_empty_list)\n. Why do you mute the context here?\n. I would have preferred to keep this close to the existing (and only) link between context and resource : https://github.com/Kinto/kinto/blob/master/kinto/core/resource/init.py#L1122-L1135\nFor example, extract_filters could return something like (last_modified == -1) to return 0 records.\n. force is allow here\n. Oh I see, you have force and forced... hum, we should be able to simplify that\n. from kinto.authorization import BucketRouteFactory\n. :+1: \n. > we shouldn't have multiple RouteFactory for a given project\nThat's not a problem if their code is small. Having tests like if self.resource_name == 'bucket' bothers me.\nLook nothing says here that we shouldn't have one per route:\nhttp://docs.pylonsproject.org/projects/pyramid/en/latest/narr/urldispatch.html#route-factories\n. Yes, but it seems that in order to save a query we introduce some additional indirection :(\n. Oh maybe that's the other way around, remove the prefix above\n. ``` py\ndef test_no_anonymous_can_list_buckets_by_default(self):\n    self.app.get(self.collection_url, status=403)\n\ndef test_anybody_can_list_buckets_by_default(self):\n    resp = self.app.get(self.collection_url,\n                        headers=get_user_headers('alice'))\n    # But it contains no record if no read permission.\n    self.assertEqual(len(resp.json['data']), 0)\n\n``\n. nitpick: We usually add a reference to the original PR/issue for each entry in the changelog\n. I'm not sure the resource docs are ready to be exposed so much :)\n. Why did you choose to remove this?\n. We could repeat the formulaePlural endpoints (such as collections) support XXX`\n. For example: Plural endpoints (such as collections) support limitation of number returned objects\n. This may be too much, one level could help to shrink the full reference TOC\n\n. Why this change ?\n. Or if you start kinto in two different terminals\n. For example, with postgresql, ...\n. I am truely sorry if you had explained it already :( I usually review from the github UI and don't read the commit messages... my fault.\nRegarding the change itself, shouldn't we add link like For more info about timestamps behaviour, check out... ? (genuine question, too much links can sometimes be confusing)\n. > My hope is that we will feel embarrassed by their exposure and that will make us fix them :) \nThat can be a strategy indeed! ... audacious but it may work :)\n. @n1k0 : \nthis (consistent with notifications payload format):\n``` js\n{\n    \"data\": [\n        {\n            \"bucket_id\": \"2f9b1aaa-552d-48e8-1b78-371dd08688b3\", \n            \"collection_id\": \"test\", \n            \"permissions\": [\n                \"write\", \n                \"read\", \n                \"record:create\"\n            ], \n            \"resource_name\": \"collection\", \n            \"uri\": \"/buckets/2f9b1aaa-552d-48e8-1b78-371dd08688b3/collections/test\"\n        }, \n        {\n            \"bucket_id\": \"2f9b1aaa-552d-48e8-1b78-371dd08688b3\", \n            \"permissions\": [\n                \"write\", \n                \"read\", \n                \"collection:create\", \n                \"group:create\"\n            ], \n            \"resource_name\": \"bucket\", \n            \"uri\": \"/buckets/2f9b1aaa-552d-48e8-1b78-371dd08688b3\"\n        }\n    ]\n}\n```\nor that (always an id attribute, whatever the resource type):\n``` js\n{\n    \"data\": [\n        {\n            \"bucket_id\": \"2f9b1aaa-552d-48e8-1b78-371dd08688b3\", \n            \"id\": \"test\", \n            \"permissions\": [\n                \"write\", \n                \"read\", \n                \"record:create\"\n            ], \n            \"resource_name\": \"collection\", \n            \"uri\": \"/buckets/2f9b1aaa-552d-48e8-1b78-371dd08688b3/collections/test\"\n        }, \n        {\n            \"id\": \"2f9b1aaa-552d-48e8-1b78-371dd08688b3\", \n            \"permissions\": [\n                \"write\", \n                \"read\", \n                \"collection:create\", \n                \"group:create\"\n            ], \n            \"resource_name\": \"bucket\", \n            \"uri\": \"/buckets/2f9b1aaa-552d-48e8-1b78-371dd08688b3\"\n        }\n    ]\n}\n``\n. @n1k0resource_name(consistent with notifications payloads) or justresource?\n. I think we can consider the new protocol a new feature and bump to3.1.0. nit: missing comment that it could raise TimeoutException\n. That would be reimplementing harakiri :(\n. That's the waypserveworks, c.f. changelog\n. You're talking aboutid? You'd prefer to remove it if equal todefault?\n. Hum, I don't think so. The callable starts running when it is submitted to the pool, that's why I have two loops!\n. Ok, sorry, I think I know what you mean. Will rework.\n. Yes, I did not change the previous behaviour regarding heartbeats (thetry/exceptis managed there)\n. aaah that's why you used%r! :/\n. I like the fact that it warns the user that its enabling an experimental feature. Let's remove that when kinto-admin pull-request is ready\n. Help would be better likeSimulate the migration operations and show information. missing%s`\n. nitpick: choose between single quote or double quote but not both mixed\n. Can you explain why you think that?\n. Hum, I don't like that implicit stuff. Should we document it? And then what about booleans, arrays...\nIMO if an integer ends up here in the id field, it's a client mistake, that can easily be fixed, no?\n. I believe that this message should not be within is_dry but always in output instead\n. typo: record\n. I don't think you can do it via get_all(), since for each deleted record you'll need to figure out which parent_id and collection_id it was stored into. We might have to rewrite delete_all() :/ for the good, since it is currently rather unoptimized\n. oups: leftover\n. You need to update the schema attribute on the storage backend :)\n. This should work, it can also be written like that:\nsql\nDELETE \nFROM deleted d \nUSING records r\nWHERE d.id = r.id AND d.parent_id = r.parent_id AND d.collection_id = r.collection_id\n. nit: move above\n. Although this was move from every permission backend implementation to here, I believe it is not properly tested / specified\n. a new /permissions endpoint [...] list of objects (buckets, collections, groups, records) on which they have read or write permission.\n?\n. ressources \u2192 objects\n. It enables\n. what the current user is allowed to do\n. rst requires double back ticks\n. \u00b5nit: ? list_permissions ?\n. objects\n. forget about it (just saw  flush_endpoint)\n. nit: If you changed the HTTP API, update the API_VERSION constant and add an API changelog entry in the docs\n. Fixes #??\n. nit: Other last names are capitalized but not upercase\n. .. when the kinto.experimental... setting is set to true ?\n. hum, no :)\n. Maybe not \u00abcleanup\u00bb, but delete records ?\n. The history is activated for every buckets. Spawn an issue to add a setting in order to limit the buckets where it's enabled ?\n. Interesting, I'll look into that.\n. Actually listeners can setup for certain kinds of objects, but not for a list of buckets/collections ids. Let's keep that for another issue. Because we might prefer have a blacklist instead etc.\nFrom the point of view of kinto-admin, it makes it harder to implement if the tracked buckets are limited. Let's start simple.\n. Well actually, I've look and it makes the configuration more verbose for users (plugin+listener), and does not bring anything concrete... So I might want to leave it like that.\n. @glasserc how would you say that in colloquial english?\n. genuine question: Are warnings always shown, no matter how python was compiled/ran ?\n. What happens if you call instance_uri with Request.blank() ?\n. There is a skip if already, but the test is instanciated anyway\n. Here you go:\n```\n(.venv) \u279c  kinto git:(master) \u2717 python\nPython 2.7.12 (default, Jul  1 2016, 15:12:24) \n[GCC 5.4.0 20160609] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n\n\n\nfrom webob.request import Request\nfrom kinto.core.utils import instance_uri\nr = Request.blank(path=\"/\")\ninstance_uri(r, \"bucket\", id=\"toto\")\nTraceback (most recent call last):\n  File \"\", line 1, in \n  File \"kinto/core/utils.py\", line 397, in instance_uri\n    return strip_uri_prefix(request.route_path('%s-record' % resource_name,\n  File \"/home/mathieu/Code/Mozilla/kinto/.venv/local/lib/python2.7/site-packages/webob/request.py\", line 1395, in getattr\n    raise AttributeError(attr)\nAttributeError: route_path\n\n\n\n``\n. Not ideal... \u00abLoading ?\u00bb\n. Why did you remove the time? It can be useful if some actions are ran in jobs?\n. I think we should keep the logging from .ini. For example, it allows to turn-on debug during migrations \n. Maybe a matter of taste but I think--debugis enough.-D` is not common right?\n. This deserves a note in the changelog\n. Why not:\npy\nlevel = parsed_args.get('verbosity', DEFAULT_LOG_LEVEL)\nlogging.basicConfig(level=level, format=DEFAULT_LOG_FORMAT)\n. I don't think this test is necessary, info by default is fine no? logging default is warning btw\n. set to unreleased until it's released (unless we release 1.9 now)\n. Mention it in a Protocol changes like other versions\n. typo: has\n. nitpick: identation\n. note: in shavar it was the git remote url I think \n. Why not just SOURCE = $(shell git config remote.origin.url)\n. Why not in Makefile ?\n. nit: \u00abhas\u00bb\n. nitpick: move that to except ? (not sure)\n. project_name is always kinto. We use that for settings prefixes if I remember well\n. This is weird, it would deserve some comments and some safety checks maybe\n. Why don't you give the git remote url ? \n. Oh I think I get it: ssh vs. https. Then no need to strip the trailing .git https://shavar.services.mozilla.com/version\n. - Note: this is a breaking change (would lead to kinto 4.0).\n- I suggest that we give some details. For example In settings, replace kinto.core.cache.redis by kinto_redis.cache\n- I don't think we use the term backend for the listener, so some details about that would be required too I think\n- typo : are not part of\n. Does this work ?\n. - rSt requires double back ticks\n- Wouldn't it be better to have this note on top ?\n. me thinking out loud: Since those settings values are given as examples, I think we could give a fully qualified postgres config instead? \n. nitpick: added a built-in plugin that allows to define quotas per bucket or collection...\n. sync storage? canonical json?\n. in INI settings file\n. typo: each bucket \u2192 every bucket ?\n. nitpick: I think we use bucket id elsewhere ?\n. nitpick: I think it's e.g. instead of i.e.\n. nitpick: and collections\n. This doesn't seem to be relevant anymore\n. typo: overrides: But, isn't exceed or go over instead of override?\n. I don't understand this comment\n. Would be better to add explicitly parameter names like above\n. Why not follow the same approach as above for bucket_info, put this in except ?\n. Why this ? (please add comment, collection_uri is defined far away)\n. Maybe we should not compute these if no *bytes* setting is defined\n. What happens if the plugin is enabled once the bucket already has some data?\n. We may list that limitation in the docs\n. - Add explicit argument names (collection_id, parent_id)\n- How can you get the records if they were deleted then ?\n. Those upercase constants look weird (taken from storage.sync isn't it ?) Why don't they all start with QUOTA ? Why using them after all ? \n. I don't think we should keep the use of those upercase constants here. Plus, it's QUOTA_BYTES_PER_ITEM\n. nitpick: use a small helper raise_insufficient\n. use constants for quota and bucket_info values?\n. typo: does not exist\n. Why do you create a collection and a record here ?\n. I guess that those upercase strings refer to the ones in the docs ? QUOTA_BYTES_PER_ITEM or QUOTA_BYTES ? But you used MAX_BYTES_PER_ITEM and MAX_BYTES. Why not just something like Maximum bytes size per item exceeded (%d > %d Bytes) ? (not crucial, but while we're at it..)\n. Note: add mention of handling of existing data when plugin is enabled\n. Those uppercase strings come from https://developer.chrome.com/apps/storage. Not sure if they bring anything compared to simple bold string (Maximum total bytes, Maximum bytes per object, Maximum number of objects...).\nI realize that we use objects in Kinto and not items\n. We could indeed try to convert strings/float/bool to int, but the value isn't supposed to be anything else than integer :)\n. I spent some time but gave up. Don't hesitate to try but I think it's harder than expected :) \n. I was thinking maybe it's useful for not sending reports to coverals ?\n. https://github.com/mozilla-services/cornice/issues/378\n. Why not... it will leave a useless trace in the DB, but we delete it on each call anyway.\nYour call!\n. The commit would have the same result (ie. ending the transaction), except that something would be left in the database between two calls.\nWould you prefer ?\n. nit: The storage backend now allows [...] in kinto.core.storage.get_all().\n. I would suggest to add a test without parent matching to make sure that we kept the strict comparison behaviour when two parent_ids are similar (eg. parent_id: xabcx should not be returned with parent_id=abc)\nBy the way, maybe we should have it for delete_all() also...\n. nit: since this method has many parameters, I suggest that we provide the kwargs names \n. nit: those two blocks of code are very similar. Maybe we could reuse a small helper function shared with delete_all() ?\n. Maybe it should be plugins.history here instead of listeners.X, since we use those for listeners configured via .ini files?\n. \ud83d\udc4d \nYou could even make it shorter like this:\nquery_record.pop(id_field, None)\nquery_record.pop(modified_field, None)\n. Yes, but this client is instantiated only if statsd_url is specified in the settings (cf. initialization.py)\n. I believe test_list_can_be_obtained_if_allowed_to_create and test_list_is_denied_if_not_allowed_to_create cover this (?)\n. the barley collection was created by Bob (and Alice is allowed to create records). But you're right, the current version of the patch is not correct. I added a failing test that shows that users should only see their own records in this particular case.\n. Creation of tables and indices maybe ?\n. We could add a ..important:: paragraph here to mention that this command should be ran every time Kinto is upgraded.\n. nitpick: for kinto is superfluous here I think\n. - typo: backends\n- I would say Python packages\n. Do not mention sudo here. Even though it may work, it installs the Python libraries globally on the system, which is not recomended.\nAlso, I think -U is enough.\n. nitpick: in other titles, only the first word is capitalized\n. - or create a new one\n- config/kinto.ini (Unix path style)\n- another filename\n. nitpicks: use intermediary variables to avoid folding if conditions (ex. is_number = (....))\n. This takes the first object URI of the bound perms. \nBut the first is not always the parent! (Ex. record \u2192 collection \u2192 bucket)\nSo I guess this is wrong for records, because it will check that the user has the permission record:create on /buckets/test which will never be the case.\n. nit: we usually do that in the prepare-X-X-X branch\n. I think we should define a colander validator on members instead.\n. In the original issue, we found this bug by filtering the history with ?collection_id.\nBut this actually applies to group_id or record_id too.\nWe could do a quick fix like this one with field.endswith('id'). This will solve the history filtering problem.\nBut the issue is wider and applies to any field. And that's what makes it hard to fix: ?toto=123 -> {\"toto\": \"123\"} or {\"toto\": 123}. I think it's more at the storage level to take care of this.\nMy 2 cents :)\n. looks like it is not the right command ;)\n. idea: Link to releases page on Github could be useful\n. Although this is absolutely correct, I would recommend to avoid the mutation of the original list, and build a new list instead. It is generally considered as a good practice to avoid side-effects on the input variables received.\npy\nfilters = super(...)\nfilters_str_id = []\nfor filt in filters:\n    if filt.field in (...):\n        filt = Filter(..., str(filt.value), ...)\n    filters_str_id.append(filt)       \nreturn filters_str_id\n. nitpick: you can use a tuple instead of a list: ('record_id', ...)\n. Better \u00abwhen filtering on id with numeric values\u00bb or something like that, no ?\n. You can use self.assertNotIn('field', result)\n. Theses should be moved to self.apply_changes() I think\n. Here \"id\" should have value of object_id and resource_name value of collection_id (ref #710)\n. I don't think the test should be removed from here though ;)\nAs Ethan suggested, you can add more tests in tests/test_views_*.py instead\n. nitpick: add reference to original issue.\nAlso, this change belongs to the protocol section of changes, and requires a line in the API changelog (docs/api/index.rst)\n. nitpick: you can name this variable just details\n. Here resource_name should have value of self.request.current_resource_name\n. Well indeed, you could modify this test a bit, but not too much. It would be complementary with the new ones in test_views_*.py\n. The resource name is one of bucket, collection, group, record. Here by using collection_id it would work as expected. The name of this parameter is very bad I know, because it seems related to collections only, but it actually represent the resource id/name. In #710 we would fix that naming problem.\n. nitpick: superfluous parenthesis\n. nitpick: leave blank lines ;)\n. nitpick: something looks wrong with the indentation here\n. Usually we only keep the assertions that are relevant to the specification (ie. the test title).\nFor example, the test on the values of id and details is not properly relevant for the spec \u00abcollections are isolated by bucket\u00bb.\nI suggest that you only keep the assertions regarding details in dedicated tests similar to test_unknown_collection_raises_404 from test_views_records.py, but for each of bucket, group, collection and record in the other test_views_ files. \n. If we follow the URL endpoint approach (which is better indeed), then the command-line is probably useless.\n. I'm not sure that we need this\n. These are available in the ACTIONS enum in kinto.core.events\n. I think this does not bring much value\n. I think the revert operation should be at the same level as history. Thus /buckets/{bucket_id}/revert.\n. nitpick: else is superfluous since we raise otherwise\n. Yes you can using the storage backed.\nSomething like that (untested):\npy\nstorage = request.registry.storage\nfilters = [Filter('collection_id', collection_id, COMPARISON.EQ)]\nentries, total_count = storage.get_all(parent_id='/buckets/%s' % bucket_id,\n                                       collection_id='history',\n                                       filters=filters)\n. Here we don't need the assertion on the details fields. It's unrelated to the specs of this test:  \u00abtest_unknown_collection_does_not_query_timestamp\u00bb\n. We already covered this in test_unknown_collection_raises_404 from test_views_collections. The assertion is not necessary here.\n. These assertions should be moved to a specific test in test_views_record.py that says test_unknown_record_raises_404\n. The indentation should be like the one you did in  kinto/core/resource/__init__.py\n. Why the parse_resource() would be documented differently? This is not necessary IMO\n. - Nitpick: capital Extract\n- What is resource here? \u2192 It's a URI\n- What are bucket and collection \u2192 they are bucket id and collection id\n- What does the function return? A tuple? A dict ?\n. You could just take the tests from here: https://github.com/Kinto/kinto-signer/blob/06f790cc57ad3b53db090d62a5318df96e320fdd/tests/test_utils.py#L9-L130\n. Didn't you forget to include this image?\n. A good practice is to keep main page anchor in sync with file name (here kinto-admin instead of admin-ui)\n. nitpick: superfluous capital D\n. This is too big to be included like that.\nI suggest that we rely on an external library instead (like https://github.com/stefankoegl/python-json-patch) and here keep a small helper only.\n. Why StopIteration ?\nI think we can merge the 2 excepts \n. Usually catch all are a bad practice, it's better to specify at least one exception type\n. This looks like you're applying the operations here, whereas we have a apply_changes() method.\nI suggest that you keep the flow, here I would see something like:\npy\nif content_type == 'application/json-patch+json':\n    changes = self.request.json\nelse:\n    try:\n        changes = self.request.json.get('data', {})\n        # ...\n. This could be moved on top, before iterating on changes (see previous comment about current flow).\nWith a new dedicated helper:\npy\nif content_type == 'application/json-patch+json':\n    try:\n        updated  = apply_json_patch(updated, changes)\n    except ValueError as e:\n        raise_invalid(...)\n. It's usually better if we don't store such intermediary values on the resource instance. Using small functions that take an input and return a result instead is one good practice (easy to test, composable etc.)\n. I know this part is a bit messy. It will be better with #790, but in the meantime if you can keep thenotion of permissions to the children class ShareableResource it would be better :) Didn't look in details if feasible for this case though\n. I don't think we should have this here. Do you remember why?\n. This could deserve a dedicated test suite, no? class JsonPatchTest(...)\n. With a dedicated test suite, you could move this a to setUp()\n. This means the client will receive a 500 Internal Error instead of a clean 400 error response\n. I suggest that you keep only one group of assertions per test. For example, you could split into two:\n- test_json_patch_test_success\n- test_json_patch_test_failure\nAlso, here we don't know if it failed because of the remove or the test\n. There is something with this test, I can't suggest easily a better way, but it can be improved IMO :)\n. I'd rather catch those to utils.py and raise a simple ValueError from them. From the resource point of view, these are details of implementation\n. why not do this in the apply_changes() method instead ?\n. here I would do a else/else if for the rest of this method, since what's coming below does not apply to json patch. \nplus, it would reduce the complexity for the reader, where each block applies to a particular case\n. since this is repeated several time it could go to a computed @property or be initialized as private attribute in constructor (like if self._is_json_patch). What do you think?\n. I think it's acceptable to return result here. We give an input and a patch, we receive an output. If you need to keep them separate, then you could also take two separate arguments as input\n. I believe that the easiest cast for set are lists, no?  {k: list(v) for k, v ...}\n. why not something like (roughly): resource = {'data': record.copy(), 'permissions': record.pop('__permissions__', {}) ?\n. Let keep the readonly fields with json-patch appart for now if it makes the code look bad (open another issue for example)\n. if you give pop() a second argument, it's becomes a default value.\npy\ndata = record.copy()\npermissions = record.pop('__permissions__', {})\nresource = {'data': data, 'permissions': permissions}\n. Oh, very interesting! Please add all those comments regarding removing by value along the code :) \n. Why did you add an additional data level here?\n. nitpick: use *JSON-Patch* notation instead of back ticks (for code)\n. I wouldn't provide so much details here, but just a link to a record PATCH for example.\n. to use *JSON Patch* with the request header ``Content-Type: application/json-patch+json`` instead of just ``Content-Type: application/json``\n. When using this request header, the body should contain a list of operations. For example:\n. typo: please refer to\n. This is very useful when altering permissions since there is no need to get the current value before adding some principal to the list.\n. Sorry but I don't get why we couldn't use the changes object to pass the operations here? \n. Why do we delete this folder each time?\n. 1.4.1 ;)\n. Yes, this is case. \nSo, if we want we can put request.effective_principals + [request.prefixed_userid] in the hello view instead?\nWe do some similar black magics here: https://github.com/Kinto/kinto/blob/master/kinto/core/authorization.py#L59\n. I think it's alright since we already have prefixed_userid in hello[user]\n. 1.13 unreleased, but that's acceptable\n. @glasserc suggested to remove them, unless I did not understand correctly. Couldn't we have includeme(config) function in the authentication module instead? \nSee https://github.com/mozilla-services/pyramid_multiauth/blob/master/pyramid_multiauth/init.py#L220. I'm not super fan about the duplication of the basic auth capability here.\nI guess we could just set multiauth.policies to an empty value for this test. You're right having to activate it with two settings is not right.\nWhat if we remove the policy.basicauth.use setting and do something like (just thinking out loud heh):\n```py\ninit.py ?\nsettings['multiauth.policies']  = ['kinto.authentication.basicauth' if p == 'basicauth' for p in settings['multiauth.policies']]\n```\nThen pyramid multiauth will include the module and we'll be able to keep everything related to basicauth there...\nNo?\n. Hmm, but then the policy name (userid prefix) won't be basicauth . just \npy\nif 'basicauth' in policies:\n    config.include('kinto.authentication')\nto at least keep the description along the implementation?. typo: lets you (?). .. code-block:: yaml \n    :emphasize-lines: 12,13\n?. Note that with the above example, config/kinto.ini must define.... nit: PostgreSQL service. This is not completely related to settings customization and also applies when the yml file is download with wget. What do you think if we move it above?. . The above downloaded docker-compose.yml file can be adjusted this way:. Maybe this is not a problem after all. I didn't see any test for this for example :). If you inherit from UserResource just to access that private method, then we should refactor that. We could have a extract_filters function in kinto.core.resource instead, that both places would call. Maybe we should use _since like for filtering resources plural endpoints?. nitpick: indentation. the revert is on the bucket, so it would be Revert a bucket... . nit: objects instead of records, since groups and collections are concerned. Can you explain this passed_since boolean in comments? I see that you look-up some entries in the history, that you reconciliate later, but this is not easy to grasp. please store the second part of this condition to help reading and give some meaning . nit: operation \u2192 request. I think the code could be greatly simplified if this method would be in charge of building the requests from a list of data structures like tuples or dicts. This would prevent to have those self.create_revert_operation() everywhere\n. The code would be simpler if the if passed_since that you have in insert_rec_to_revert_lists would be put here. This part deserves some comments, it's quite hard to follow :) . you can use rec1['permissions'].setdefault('read', []). if this is used only once, then maybe it can be inlined in the test directly. self is not used \u2192 function? . This effective_principals value truely respects what Pyramid would return. The previous list was wrong, there was no way we could obtain a prefixed_userid in the principals with the previous code.\n. Both settings should be kept!. done. There's no reason it wouldn't work as groups, no?. Here basically the code does the same, but is not limited to particular patterns.. Same here, the idea is to avoid limiting this function to a set of known resource names. This is fix. But since the history resource was relying on the bug to work, I had to do some changes regarding the history entries (eg. explicit declare that the permissions inherit from bucket)\n. Note: according to docs (and performance obtained locally), LIKE behaves exactly like = if the values do not contain % character. account ID. data.id ?. raise something ? 403 for get ? 400 for post ?. Lookup in settings for AccountsAuthenticationPolicy. We can probably move this to core.resource.viewset (and handle a global refactor later with Kinto/kinto#880)\nOr, better, contribute the fix to Cornice: https://github.com/Cornices/cornice/blob/master/cornice/validators/init.py#L36\n(i.e. re.match() on the content_type header instead of equality). If you want to instantiate the spec only once for the whole test suite, you can try to use setUpClass() instead of setup() https://docs.python.org/2/library/unittest.html#unittest.TestCase.setUpClass. nit: superfluous parenthesis. Do we have a use case :) ?. It's done automatically apparently. header (singular). I don't think this should go in the model tests, since it is done in the resource. PaginatedDeleteTest seems more appropriate. yep!\n. I would rephrase this in a less technical manner, like When admin is enabled, /v1/admin does not return 404 anymore but now redirects to /v1/admin/ (trailing slash). When does it happen that validated doesn't have a header entry? See https://github.com/Cornices/cornice/blob/9b73c5ae8dfbebede6413a007ffac7fe28e76401/cornice/validators/init.py#L60-L62. \u2764\ufe0f . Ditto: could this happen that querystring is missing? If it's for the test, we could fix the test setUp instead I believe.. What do you think of FieldList or StringList instead ?. nit: superfluous else. I think there is the notion of preparer in Colander that could split, and then the notion of Sequence. In a second iteration, we can try to leverage that if possible. except UnicodeDecodeError ?. Is decode_header not necessary for this one? Maybe we could run decode_header here before deserailize each sub-node so that we have it one place only? Or do it in Cornice instead.... I see that you repeat missing=drop, maybe we can remove it from each schema then!. One was Partial and the other one Simple. Is that ok to now give the same behaviour to both?. I can't remember why we had that, but if I remember well it's because of Webob (/cc @Natim). Ok then!. I don't think those lines are necessary. This filtering section may be a bit confusing. A very simple example of notification can be useful though (see maybe https://github.com/Kinto/kinto-changes/blob/master/README.rst). I think those go to the features section. redundant ?. production settings should go relatively on top, since they are more useful than profiling etc.. Why couldn't we set missing in HeaderField class instead? (like FieldList). Me neither, well done!\nI have one remark though: the above comment could be more explicit about filters (field filters?) to help understand what the code does. A couple of minimalist examples with boolean or list value could help for example (?deleted=true -> {\"deleted\": True}). please move this list elsewhere (or whole validator) to improve indentation ;) #IndentationFreak. shouldn't we allow value only instead ?. cherry on cake: you could have a regex to make sure those look valid :). Technically we don't support as many querystring values for a patch. But maybe we can keep it simple as it is, they don't harm.\nYour call!. Just check its presence in deserialize maybe then. Yeah something like ^(/\\w)+$ ? .. As a step 1, what we have here is fine. If you struggle with that when working on #1006 then you can do a second round.. nit: this could be imported from the top of file. We could retry 10 times with a small increasing delay between each call after the second call. cache PostgreSQL backend. I think that 0.005 is enough. What's wrong with time.sleep(0) ? The if seems unnecessary. why not use a variable in the closure instead of changing kwargs ? \n(please add comment if particular reason). Why don't we raise the original exception? (please add comment if particular reason). Please add a comment.. Hum, I suggest that we either fix it everywhere or wait for another PR no?. nitpick: http verbs are usually written upercase. I had never seen this :) Interesting... It took me a while to figure out why _fields was not listed in CollectionQuerySchema!\nMaybe there is a matter of wording or comments to really distinguish : general (both endpoints), plural and single enpoints. With all the explicit declarations that we do elsewhere, I wish those few lines become extremely simple. superfluous elif 'cuz of the return above. Why is this necessary if we have unknown: raise ?. Why missing: drop ?\nIt's better if you instantiate the schema once out of the loop IMO. Don't we need to check that cstruct is iterable?. Are we sure here that cstruct is a mapping?. Yes, it would be a lot nicer with a decorator (that may already exist in pyramid). nit: activated sounds superfluous here. Maybe we should rename index.html into index.tpl or _index.html, otherwise it can be confusing. note: we had the synchronized decorator in kinto.core.utils. Seeing the level of care here, I assume you want to introduce this as part of the core API. You could hence add it the API docs of kinto.core. . No, in comments at least. Don't hesitate to add as many comments as you can for this kind of details :) . I didn't understand your proposition :(. I would list those as Breaking changes. nitpick: validated fields --> schema. ditto. ditto. nitpick: binded -> bound. \ud83d\udc4d . nitpick: prefer an intermediary variable to avoid indentation. Add a comment to explain that we decide later what to put in data based on the resource schema?. Do we really want to support that .bind(**kwargs). I find it cool and flexible, but it looks like we don't use it and it does not ease the understanding of the code.. Why are they not deferred in this case?. This is a breaking change. I suggest that we keep two queries depending on the version of postgresql being used instead of breaking compat. I remember we had that before, and we changed... What does the docs say? Will the old location still be accesible? deprecated?. Yes, see https://github.com/mozilla-services/cliquet/blob/master/cliquet/schema.py. > Do you know why we have them there?\nOriginally (archeology) they were in core because we thought they were common types of fields. They're just used in third parties or plugins. We can deprecated them, no worries.. If we look at the logs, a part of the code already introspects it (see select version()).\nI'll loook into SQLAlchemy.... engine.server_version_info\nhttps://github.com/zzzeek/sqlalchemy/blob/bc4a96836d5bfb911da26f7e77119f3a7b356f2e/lib/sqlalchemy/engine/default.py#L244-L245. nitpick: here https://github.com/zzzeek/sqlalchemy/blob/bc4a96836d5bfb911da26f7e77119f3a7b356f2e/lib/sqlalchemy/testing/exclusions.py#L384 they use getattr so maybe we should use it too and compare version >= (9, 5). Shouldn't we be more explicit like PostgreSQL 9.5 is now required for the cache backend?. This one is technically a bug fix ;). We could remove the retry decorator I think, because it hasn't proven to be useful.... When there's only one you can do \"/records/{}\".format(record_id). For that particular case I guess it is (may have to judge them one by one). Are these deletions expected?. Instantiate this validator only once (e.g. positiveInteger). 2**64 / 2. interesting difference that would a deserve a comment or XXX : ). It shouldn't be camel case no ? I'm sorry to have suggested that name :( . Hum, now I don't know anymore :D \nA constant seems weird for a reusable instance no ? \nMaybe like a class name ? Like colander.Length ? Or just positive_integer like a variable?. This is bikeshed, it's fine whatever way. We can add a comment for mental health of the reader. This is a big breaking change!. leftover? loadtests -> functional ?. nit: shouldn't these go to the service definition ?. left over or useful info?. should we add this only if our verbose option is set?. If that helps we could make self.model lazy, ie. instantiate at first use. Which should be late enough to let colander path validation happen before? (#justWondering, not sure heh). I think there is something wrong with this sentence, since we contrast exactly the same with newer or older, and that sounds weird. In other words, how \u00abnewer or older\u00bb is not equivalent to \u00abnot exactly the same\u00bb?\nBy the way, personnally, I would change the behaviour to match the spec. I don't see any implication in the synchronization process. The clients are not supposed to have timestamps that are superior to the server ones, so I wouldn't even consider this a breaking change.. I would adjust the comment, your explanation on the PR description was a lot better: for example, something like collection is a resource that always exists\". nit: we could specify the keyword record=. nit: useless upercase on tombstone. nit: elif is not necessary since we return above. nit: exists. nit: doesn't. should we have the tests on collection get/delete that always succeed with If-Match:* or If-None-Match: * ?. We could mention those changes in the API changelog (and increment the HTTP API number maybe). nit: buckets collection \u2192 buckets plural endpoint. a previous state of [...] \u2192 of objects*. \u00abstate\u00bb \u2192 \u00abversion\u00bb ? . snapshot list resource \u2192 what is this? we were talking about state then version...  we should stick to a reduced vocabulary to avoid confusion.. \u00b5nit: collections and records ;). Does this make every snapshot public?\nThe permission aspect is crucial.\nExample scenario: I have access to a collection, then I am removed the perm, then some data is created. Can I access a snapshot of some data that was edited after I was removed the permission?\nIt's not impossible to handle, but not trivial.\nThe history endpoint already handles this, by providing history entries only on data that was readable/writable at the time it was edited. That's why I suggested to do this reconciliation on the client side. . Why all of this instead of putting /buckets/{bucket_id}/{subpath:.*} in the path?. This is not idiomatic, use any(). You said above that \u00abwe cannot provide a version history on the buckets collection\u00bb. The filename test_history_at does not match the vocabulary elsewhere (version, state, snapshot, ...). Those tests look like huge copy-paste of the same steps. Plus the test methods are long and contains several steps. It's usually easier to have short well-scoped test methods. If we do it on the client side, the filtering aspect is out of scope.. nit: .endswith('/{}s'). why not endswith('{}s') like above?. nit: why not + ?. Is adding the / necessary?. Maybe add a test where you have an unknown resource name? /buckets/abc/labels/12/version/1234 ?. Why not use an ordered dict to deduplicate instead of set + list?. nit: why is not True and not just not ?. > Because generally you don't want to concat strings with +\nWhy ?. Using dict.values() no?. Interesting, ok. Good point! Please add some comments to the code, the conversations on github don't last. In storage/memory:apply_filters() and apply_sorting() we had just this:\npy\n            left = record\n            subfields = f.field.split('.')\n            for subfield in subfields:\n                if not isinstance(left, dict):\n                    break\n                left = left.get(subfield)\nIt might be worth unifying both :) The simpler the better IMO (unless there's a reason hehe). What happens if last_value is None ? There is no pagination ? Would that solve #816 ?. Ahhh that's why... Hmm no strong opinion. we don't mention last_modified here?. I'm not sure, but if last_modified is not provided and there is a conflict, then this could fail (last_modified can not be null, but maybe the trigger will initialize it to a new value (newer timestamp), we have to check). If tests pass, this is cool :). nit: This could be rewritten using ON CONFLICT. \u00b5nit: indentation. \u00b5nit: identation. This comment is not really in-sync anymore (eg. we don't bump here). If I'm not wrong, previous_collection_ts will never be NULL because it would have been set during the first operation before the conflict occured.\nAlso, if I understand correctly, this will re-run the trigger with record.last_modified = collection_ts, which will re-bump the timestamp (as if a user would have had specified it in a normal PUT). Hence, shouldn't we compare with as_epoch(ts) <= as_epoch(previous_collection_ts))\n. Here we are resolving only one kind of conflict: two users trying to create objects with the same id in overlapping transactions.\nWhat we face in #602 is different IMO: we create objects with different ids, but when we fail in assigning unique timestamps. And I don't think this ON CONFLICT will catch it.\n. You can basically run two python scripts in parallel that calls 10000 times storage.create(). Or do what I did here with two psql in parallel http://stackoverflow.com/questions/34817760/how-to-generate-unique-timestamps-in-postgresql\n. I just read that EXCLUDED.last_modified would give us access to the rejected inserted value. nit: Elsewhere we just add a trailing inline comment # not raising  :) . Instead of concatenating, elsewhere in the code base we use a safeholder, like %(on_conflict)s. Here providing an empty string by default for example.. nit: don't worry too much about query indentation, I would prioritize python identation. \ud83d\udc4d . don't forget to add it in the docstring. Why not? If it's inserted it will return the inserted value, if there's a conflict it won't return anything. That's why I did an UNION after to do like create or get. Humm, that's not the behaviour I have, look:\n```\n[testdb] # INSERT INTO timestamps (parent_id, collection_id, last_modified)\n      VALUES ('haha', 'hoho', NOW())\n      ON CONFLICT (parent_id, collection_id) DO NOTHING\n      RETURNING last_modified;\n       last_modified        \n\n2017-03-02 16:45:25.445502\n(1 row)\nINSERT 0 1\nTime: 5,195 ms\n[testdb] # INSERT INTO timestamps (parent_id, collection_id, last_modified)\n      VALUES ('haha', 'hoho', NOW())\n      ON CONFLICT (parent_id, collection_id) DO NOTHING\n      RETURNING last_modified;\n last_modified \n\n(0 rows)\nINSERT 0 0\nTime: 0,282 ms\n```. XXX: wrong test title. Why two parameters?. We should still remove the tombstone in that case.\nWhat about:\ndiff\ndiff --git a/kinto/core/storage/memory.py b/kinto/core/storage/memory.py\nindex f86f10d..0650955 100644\n--- a/kinto/core/storage/memory.py\n+++ b/kinto/core/storage/memory.py\n@@ -135,22 +135,23 @@ class Storage(MemoryBasedStorage):\n                modified_field=DEFAULT_MODIFIED_FIELD, auth=None, ignore_conflict=False):\n         id_generator = id_generator or self.id_generator\n         record = {**record}\n         if id_field in record:\n-            if not ignore_conflict:\n-                # Raise unicity error if record with same id already exists.\n-                try:\n-                    existing = self.get(collection_id, parent_id, record[id_field])\n-                    raise exceptions.UnicityError(id_field, existing)\n-                except exceptions.RecordNotFoundError:\n-                    pass\n+            # Raise unicity error if record with same id already exists.\n+            try:\n+                record = self.get(collection_id, parent_id, record[id_field])\n+                if not ignore_conflict:\n+                    raise exceptions.UnicityError(id_field, record)\n+            except exceptions.RecordNotFoundError:\n+                pass\nThe storage tests on ignore_conflict=True should be more explicit regarding:\n removing the tombstone or not\n bumping the collection timestamp or not. I guess that your concern comes from this https://github.com/Kinto/kinto-http.js/blob/3d4069b29b675bbe61d2ce5465abb996f883169a/src/collection.js#L355  \nBut the right way would be to do entry.action == delete instead of entry.target.data.deleted == true.\nI find the breaking change acceptable though, but open to conversation. Adding deleted: true doesn't seem a good idea though :/. leftover: test title does not match. nit: Here I would mention Adds an endpoint to completely... no ?. We should mention the dropped env variable here. Thx, but it's only when a lambda is assigned to a variable AFAIK. humm bof :)\n```\n\n\n\nl = [1].extend([2])\nl is None\nTrue\n. Py3. Py3. Not sure these defaults are taken into account :) . Here I would mention that Kinto is not coupled to any authentication mecanism or provider. And then in another paragraph mention there's an `account` built-in plugin that provide user sign-up, ... etc with a link to the docs :ref:link <api-accounts> ``. That is not supported, I updated the tests.. Trying toPUT /accounts/{id}can also leak information about existing accounts. Do you think this is a problem?. It's the bcrypted password string. Currently I know no way to hide it.. Here I would rather put a link to a Kinto plugin or documentation page. The webpush-channels project seems to be an independant project, no? (yes, using kinto.core but how does it integrate with kinto in the end?). Ok, if webpush-channels replace kinto-webpush, then we need a documentation page that explains how to receive push notifications when some record is changed in Kinto. nitpick: I would leave the link to the roadmap here. Also, please use the:github:shortcut like other links!. \u2192 When specifying empty values in querystring filters. Why not \ud83d\udc4d  :) But we could also writeif value and (is_numeric(value) or all([...]))no?. Please link to bug in webob and make it explicit that we clean shit here.... \u2192 Return 400 bad request instead of crashing when querystring contains bad characters ?. I would have intuitively put inutilswith all other request utilities. Any good argument forerrors?. In kinto 6.X, shouldn't we use thekinto.core.loggerinstance ?. no breaking changes here?. Nit: i think we put AND on line start elsewhere. Yes, a pity that the delete method does not return anything.... nit: we have aget_user_headers()helper.with_deletedis not part ofpurge_deleted()` (?). Unless I am completely confused at this time of the day, the second query does not depend on the result of the first one, so we can safely execute those two queries separately. They will be executed in the same transaction anyway.. Indeed, the tombstones are the last bit of info that we keep about a resource. Once we delete the tombstones, we can wipe out timestamps.\n\n\n\nI agree that changing the name would be the best option.\n. I'll write it as a single op, it does not harm :) . Oh, and thanks for the detailed explanation \ud83d\ude0a . nitpick: we could add rebuild-quotas only if plugin is included? \n. I would have put this script in the plugins/quotas/ module. Indeed but then isn't it the opposite? Can't rebuild if server is writable ?. I would pass storage backend instead of env. nit: put record_pagination closer to the loop where it gets updated. why not return a tuple instead ?. LGTM.\nI'm not super convinced about the utilty of the assertions on the series of calls to storage, but they may help a lot when fixing potential bugs.. Maybe in this one we can just assert about the output and not individual calls to get_all() ?. generator would be nicer indeed. I don't think it's overkill if put into small helpers. nit: bug #1226 <https://github.com/Kinto/kinto/issues/1226>_. If that's possible it would be cool, but not crucial. If it has new features, it's 6.1.0. nitpick: Use (capitalized). I don't think it's necessary to change this for the history plugin tests?. If it is meant to be used in tests only I don't think it's necessary to document it here. No?. Why not /like_field=*foo* ?\nFor example, if like operator contains * then respect it, otherwise do *<keyword>* like currently.. As @n1k0  pointed out, we should add tests when stored objects contain integers, lists etc. We've seen numerous bugs (in PG) when relying implicit casts.... This could be an API breaking change (although off and no were not documented...). cool, did not know about this name :) \nbtw, on wikipedia it's called schwartzian transform. \u00b5nit:  boolean values usually start with is_ or has_... what about is_like_operator ?. \u00b5nit: in python multi-lines if are not recommended. Would it be better to have two intermediary variables like null_comparable_ops and null_incomparable_ops ?. \u00b5nit: I don't think it's necessary to have uppercase here. This approach has some advantages:\n it avoids breaking with existing collection metadata\n we strip record and schema at the same place (stripping record fields will still be necessary if the users don't allow additional props on their schemas)\n we are in a resource class, where self.model.id_field etc. are available. It's not the case within the colander validator for collection schema\n it is fairly similar to what there were before this PR, so I'm not chocked by those changes\nPlease expose your whys :) . > I don't think we need to go to this lengths to avoid putting an empty required field\nThe empty array gives me an error in jsonschema library that we use: \n```\nFailed validating 'minItems' in schema['properties']['required']:\n    {'items': {'type': 'string'},\n     'minItems': 1,\n     'type': 'array',\n     'uniqueItems': True}\nOn instance['required']:\n    []\n```\nOpened https://github.com/Julian/jsonschema/issues/339. \ud83d\udc4d . Shouldn't this be on top of everything?. I think an empty value should do it here. This is super advanced configuration, we could move it at the end in a dedicated section. I think it would be more readable with a line per resource. Plus, the default id generator is something like kinto.views.NameGenerator. This shouldn't be necessary with Kinto 7+. We have to choose between: no value, empty string'' or None, and use the same everywhere. (I have a preference for no value). I think we could get rid of Firefox Accounts since its usage on any server is not opened to the public.\n. We could add kinto-portier instead. These settings are already at the end. And I don't think most users will change them, so leave them at the end :). I don't think this deserves a dedicated \u00absection/title\u00bb. It should be moved along configuration example. missing = 3. This plugins section is often used. I would suggest to move it after Feature settings. Or like that:\n```\nkinto.eos =\n``. Leftover? It's now on top.. Those are already in production settings paragraph :) . I suggest that you put the production settings just right below this section. They are not used immediately by someone trying the project, so no need to have them on top. \nPlus, the following settings (cross, backoff, end of service) are all production settings too. leave empty value. Sometimes you addedTrueandFalse(capitalized) sometimes it's lowercase. Please make it consistent accross the whole file. Missing = a the end of lines. You have twice this link. I realize this won't work in Kinto itself. Indeed, the resources names in Kinto are onlybucket,group,collection,record`.\nI know this is very confusing ( see #710 ) because the endpoint types are also named collection (plural) and record (instance) :( :(\nSo the examples are like kinto.collection_bucket_delete_enabled = false or kinto.record_record_delete_enabled = false.\nIt is so confusing that maybe we could even skip this section.... please decide :) your call! . I wonder if we should repeat the setting name. The danger is that someone would just uncomment this line, and it will override the kinto.includes that we gave above.\nMaybe, instead we could just add a sentence instead:\n```\nAdd kinto.plugins.accounts to kinto.includes setting\n```\nWhat do you think?. Same doubt as for kinto.includes, should we repeat the setting in the file or just add a sentence?. Let's skip that part. I'll adjust the documentation examples. They are not incorrect but very confusing.. Sorry for the delay, I had troubles going through the pile of Github notifications.\nI'll update the documentation and you'll decide if you leave it in the .tpl or not :) . Should we add an example? Or put pusher.cluster = eu ?. These are already present a little below!. These are already in the logging section. nitpick: missing spaces around =. nitpick: add blank line here :) . You could also call the POST view with a fake request instead no? (just wondering...). nit: displays. nitto. nit: a valid. In this test, the titlle suggests that it will fail to create it (compared to the next test below). nit: with valid. I think the most common way is to rely on prompt for password no?. nit: superflous parenthesis. nitto. nit: http://sametmax.com/alternative-au-do-while-en-python/. nit: this identation does not match the instruction above at line 51. Memcached . Memcached. This should probably be documented in the install/settings section. Looks like you are also fixing #1339 . Not necessarily, those are tiny fixes, but don't forget to update CHANGELOG\n. I didn't understand this question. The protocol part is not detailed enough, we have to make explicit (and in api/docs also) that something changes:\n* if a record is pushed with an older timestamp, the collection timestamps is not dumped anymore. this won't work I think, since we need https://github.com/mozilla-services/python-dockerflow/pull/21. > Fix raise conditions regarding the collection_timestamp. As a side-effect when adding a record in the past, the collection_timestamp is not bumped anymore.\nIt was not about race conditions, but bottleneck. Just keep what you wrote in the README , it's enough/great. I would write it as user id instead of user_id. URL (uppercase). nit: ins \u2192 create_record. Why dummy? . \ud83d\udc4d . \ud83d\udc4d . Now that I see this, maybe a whitelist of supported settings would make more sense.... No, don't worry we can open another issue and handle that later :) . @emamurho please fix this and we're good to go!\n@Natim did you try the changes locally?. I agree with @Natim, an explicit cast to int or float would not harm here. nitpick: I wouldn't split this line like this. Can we leave the way it was?. Instead of having a function, you could just define a constant EXCLUDE_SETTINGS = ('prefix', 'hosts', ...) somewhere on top.. a more idiomatic (and shorter) way of writing these 3 lines would be:\npython\nfiltered_settings = {k: v for k, v in settings.items()\n                     if k not in EXCLUDE_SETTINGS}. nit: I don't think the `` are rendered within italic blocks. the default sort order ?. ``delete_all``. (suggestion) Maybe a link to a Postgresql reference that mentions why the C collation will leverage the index could be useful\n  . nit: share credentials \u2192 share the same database ?. So this fixes #1460 . You might want to add a row in metadata here.. \ud83d\ude2e \nInteresting PG bug!\nGood catch mate... must have been painful :| . Sorry @cfguimaraes for the delay...\nBasically you should be able to apply the fork with:\n$ cd kinto/\n$ source .venv/bin/activate\n$ pip install -e <path-to-python-jose-fork>\nBut according to the code above if you provide a JWT but no access token, then this hash is not verified.\nThe status of this branch is still very rough, I want to land it ASAP, we'll need it in our production stacks at Mozilla :) . nitpick: I think it could be just hawk since the underlying library may change overtime :) . What about Hawk Authentication as the title?. authenticate requests.\nThe rest of the sentence from your application backend to Kinto. is not really helpful. Note: Why would someone be interested in checking these implementations from the settings docs?. Hawk authentication can be enabled by .... And also Kinto must be installed with [hawk] optional dep. ?. use absolute imports from kinto.plugins.hawk. you can import HawkAuth here, so that we can have from kinto.plugins.hawk import HawkAuth. using mohawk is an implementation detail that we don't need to expose here. why not merge _test_credentials and _get_account_hawk_creds methods?. leftover. Also the account plugin must be enabled as far as I understand. 90 should be a setting (comment says 60 BTW :)). I agree.\nThere is already a if param == '_since' a little below BTW . I think it's better for readability and style, but in this case, it's mainly for consistency with the rest of the codebase. I think we only have relative imports in tests :). Good catch!\nThen you could do something like:\npy\nfor f in filters:\n    if f.field == self.model.modified_field and f.value == '':\n        raise...    . The thing is that we can have access tokens in JWT format. I haven't looked at those yet. \nAlso, using id tokens saves a round-trip to the Identity Provider. With the inconvenient that their validity remains unquestioned until they expire.. \u00b5nit: mention #1487 . This setting should be documented and could be added to settings template IMO. I don't think is correct applies here. It would probably be was already verified. Add a comment to say we refresh the cache ttl on each request?. Shouldn't it be request.matchdict['id'] instead ? Since we make sure they match in the resource code?. nit: checks. We should not slow the tests by two seconds here, we can do better like call .cache.expire(cache_key, 1) first and then make sure it's >1 or whatever. Method? Hmm, I would say verification. call it resource_ids_setting for consistency. for_resource_ids for consistency. You should do this only once in the filter constructor (__init__). else should be enough here. you can put those matchdict.get() and returned_resource_ids.get() above the if to ease reading. Those are not really names but URIs. nitpick: this could be a single line comment . nit: session time and for the session does not sound super clear in the same sentence :). Are you sure you need to mock these?. I wouldn't touch these tests and just add new ones. Why this change?. id_generator does not match empty strings so this is useless. nitpick: elif is useless since the previous if ends with a return. same as above. don't you have these already in the event.payload or attributes?. Maybe you would not need to mock the requests attributes in the other tests that are unrelated to resource ids if utils.view_lookup() does not get called when self.resource_ids is falsy (empty list). You could add if not self.resource_ids: return on top and this way this filter is completely bypassed when unused.\n(my 2 cents)\n. Yes I was tempted to decode them, what do you think?. I'm curious now, how would it reach log files? If the token is sent as hash location the browser does not put it in the http request AFAIK. Good catch. It's OAuth, but it's confusing anyway, we should simply put \u00ablogin dance\u00bb. I knew it thanks to ZeroBin :) https://news.ycombinator.com/item?id=3832269. I'm pretty sure view_lookup(request, '/buckets') should already work as expected, ie. return \"bucket\", {}\nIf it does not, then we can fix it. You could add a unit test in test_utils to assert that BTW. this would be simpler like this:\npy\nif \"id\" in matchdict:\n     matchdict[resource_name + '_id'] = matchdict['id']. this would not be necessary if view_lookup() would return the right value. Are you sure this is necessary? I would say that the code in from_settings() is enough.. You don't need that class, you can just put the test into PermissionsUnauthenticatedViewTest. leftover. There needs to be a test somewhere that asserts the content of the bucket creation entry. syntax error?. Ok, I get it.\nSo we should keep the view_lookup() consistent with what it does. /buckets is the bucket resource, so it should return this.\nNow, what we want is that to read perms_descending_tree[\"\"][\"bucket:create\"]. So we should manage this corner here, and not in view_lookup().\nFor example:\npy\nif resource == \"bucket\" and permission == \"create\":\n    obtained = perms_descending_tree[\"\"][\"bucket:create\"]\nThat way we don't have to change kinto.authorization.PERMISSIONS_INHERITANCE_TREE, and we dont' change the semantics of view_lookup() for that particular case. Just imagine that view_lookup() can be used by any other component and would not expect this \"\", {\"id\": False} response\n. No, I don't think this PERMISSIONS_INHERITANCE_TREE dict should be touched in this PR. \nThis dict gives the permission inheritance, and there is permission that is above bucket:create since it can only be given via settings.\nHowever in the permissions endpoint code, we can manipulate the perms_descending_tree and adjust the from_settings() function.. Why not do perms_descending_tree['bucket'] = {'bucket:create': {'bucket': {'bucket:create'}}} here and remove the if below ?. yep!. Oh! Very good catch!\nI think we'll have to do the same thing for accounts, I'm pretty sure the permission to create and write account does not appear in the permission endpoint. We should open an issue and fix it in another PR.. typo if it. :+1: . micronit: I'm not sure it is the way we ident stuff elsewhere. And accounts ;). This should probably be renamed root_perms now.\nAnd I guess it can be simplified:\npy\nfor root_perm in from_settings.get('', []):\n    resource_name, _ = .... This will work, but if we want to be completely safe here, it should be: (can't have guessed don't worry)\npy\nuri = core_utils.strip_uri_prefix(self.request.route_path(f'{resource_name}-collection')). Why account singular if it is for /accounts?. Here you test the number of keys, I think it would be just easier to compare the dict directly:\npy\nself.assertEqual(account, {\n    'permissions': ['read', 'write'],\n    'resource_name', ...\n    ...\n}). Same here, I think you can compare dicts. Compare dicts here as well?. ok I get it ! leave it like that sorry :). Ideally, I'd like the /buckets perm to come out first, could you please check that? (I never know whether None comes first or not). could be x.get(id_field, \"\") too ;). I think this comment should go below close to the ?sort={} request. I think it is better to use pytest parametrize function for this (better failure messages etc). You're right, leave it like this.... But then I don't have it in the on_account_changed event to delete the cache entries.\nIn that case we could introduce a new feature in the cache backend to delete multiple keys with * (account:alice:*:verified). What does it mean \"won't work\" ? \"will always be false\" ?. Could you please add them to https://github.com/Kinto/kinto/blob/master/docs/api/1.x/filtering.rst ?. nitpick: usually when we add new features to the HTTP API we highlight it as such (see older entries) :) . If you expose it, it should not start with _, and probably have a doctstring with expected parameters and returned value ;). nit: name the arguments, it's easier to read/refactor. nit: modified_field could be last ;). this does not belong here apparently ;) maybe it's not as easy as it seemed :|. self._timestamps is not defined in MemoryBased so it should not be used here. leftover ;). If the MemoryBasedStorage relies on  a self._bump_and_store_timestamp(), then every child class will have to implement it. So it should not be prefixed with _. And should raise NotImplementedError etc. :) . :+1: . If this code has to remain, please use intermediary variable. Can't we do this in native_value() ?. nit: nicer with {field} in the string and .format(field=sql_field). Authentication policies can now hard code and override the name specified in settings. comment is wrong. Add a small comment :  If the authn policy has anameattribute, we ignore the name specified in settings. \u00b5-nit: indentation of WHERE :blush: . The variables are not named correctly in the tests, instead it could be:\n```py\nrecords_and_tombstones, records_count = self.storage.get_all(parent_id='abc',\n                                                             collection_id='c',\n                                                             include_deleted=True)\nself.assertEqual(records_count, 0)\nself.assertEqual(len(records_and_tombstones), 2)\n```\nThe returned count is the number of records, excluding tombstones. Tombstones are returned when ?_since is in querystring, they are not real records....\nThe parameter include_deleted is not named correctly, it should be with_tombstones. We identified the issue a while ago #710 . nit: superfluous since safeholders is a default dict ;). nit: it only applies to PostgreSQL ;)\nAnd also, I think it would make sense to mention the performance gain!. I think it needs to check the resp.status (eg. if 5XX) like does the commit veto (see https://github.com/Pylons/pyramid_tm/blob/ffed3d3e352b800064dbe9e1f0270f11fdda63ff/pyramid_tm/init.py#L50) \nAlso, why should it only apply to exception with content-type JSON ? And why should we .begin() again?\nIf you want to add some new tests, you'll find some in core/test_views_transaction.py\n. nit: superfluous parenthesis. Maybe add a comment that what happens in reality:\nhttps://github.com/Kinto/kinto/blob/master/kinto/core/resource/init.py#L1055-L1057. I know it makes no sense to redo that at each loop iteration, but I would have had less trouble reading all this if order_field and pagination_direction would have been define right along the pagination rules below :) . Please add a comment like Create records with different parent ids. index by memory address? I realize I don't understand why we don't just build a list :) . Are you sure the 500 is necessary here? I'm really not sure, since the final batch response status will be 5XX, the classic pyramid_tm commit veto is going to play its role.\n(also don't hesitate to add this as a comment..). Here we are in kinto.core, there is no notion of buckets. Try with /mushrooms. Can you please add a link to this issue please : #624. I opened #1658 :). not contains because we only delete objects where the user is the only writer?. :tada: . there might be a location key to set to querystring if I'm not wrong. and I think you could even check that at the schema level actually. I think we wrote query string in one word elsewhere.... If you still have some energy we could mention how to use this in the openid docs section ? :) :) . something like String(validator=colander.Regex(\"none\"), missing=colander.drop) . What do you mean?\nThat it's a pity to reserve the field collection:schema when the feature is disabled?\n. That kind of change is a no go for me :) :trollface: . \u00abThat must be a bug, that can't possibly be intentional\u00bb says my neighboor. Why don't call it matchdict? I'm against resource_data but it sounds like it's going to represent real data like record attributes etc.. Note: this will require a major bump. It is a breaking change :) \nWe use this thing in kinto-signer where we raise event from event listeners. I didn't check if what we do there is feasible with the \u00abdrain\u00bb approach :)\nhttps://github.com/Kinto/kinto-signer/blob/20fb9a014537aa6dc7c838da79d6b4755dc10084/kinto_signer/utils.py#L200-L212. if after_event is None maybe. .get(key, None) is equivalent to .get(key). Isn't this supposed to be left indented? like executed when after_event is not None?. maybe add a comment here :) . kinto.core.events.notify_resource_event() now supports.... Should it be added to http://kinto.readthedocs.io/en/stable/core/index.html ?. leftover?. what's resource_changed_events[0].impacted_records[0]['new']['name'] here?. it is recommended to use aslist() from pyramid.settings. I took the ones that were not coupled to any brand or commercial service. what do you mean by default root user?. > account:admin suggests that the admin account should exists.\nYes maybe there are some place in the getting started docs that don't mention creating the admin. I added mentions in the install docs\n\nAlso I would rather encourage people to use an email address as username because it simplifies the use of the sharing capabilities (although for the later we might need to verify the address)\n\nWe could have a regex for account ids, whose default would be an email adress for example. But please open another issue, I don't want to let this rot ;). You are right I'll rephrase this!. For the sake of simplicity I think I prefer account:admin :/ . what about value ?. Since the fix happens at the resource level I would prefer not to involve PostgreSQL here.\nCould you reproduce the original issue with that test?\n. would be great with ?field=\"\\x00\" too ;). instead of having one test method that tests two things, it's better to have two methods:\n\ntest_400_when_query_field_contains_nul_character\ntest_400_when_query_value_contains_nul_character. Ok I see.\n\nThe thing is that now we have a safety check / fix (and some tests that assert the proper behavior) at the resource level. We don't have to imply PostgreSQL anymore. BaseWebTest should be enough :wink: . Oh interesting! I forgot about that :) \nIt's more about this I think:\nhttps://github.com/Kinto/kinto/blob/48d58f0fefe5c89218fb756616426c1efe06e05c/kinto/core/init.py#L94-L95\nI'll remove it from the CHANGELOG then. Does it apply to collection_create_principal  to? :open_mouth: . I would suggest to install black only and run it via tox -e lint  (tox and therapist will be installed via dev-requirements). this line can be omitted since already in dev-requirements. Maybe we could add:\nflake8\n    setuptools<36\nBTW @Natim do you remember why setuptools<36? . looks like an extra line. if it's mentioned in travis, we should keep it flake8 (py35).\nBut I would in favor of removing it in travis too instead :) . blank line sorry :) \n. Could there be a unit test for this change deep in core.intiatlization? . could you please add a unit test for this? . I used objects everywhere. Apparently, we can only have jsonschema==3.0.0a3 https://pypi.org/project/jsonschema/#history :) . Now that you say it... one or the other I'm fine. Maybe we could help by showing the location we've looked:  Version file missing from %s % files.join(\",\"). I would say thatf\"{credentials[0]}:{credentials[1]\"` is fine. Or leave the format() call. This is probably better to leave it with format(). with other auth policies that overlap with the ones it supports.\n...or something like that.  Because it is perfectly fine to use Auth0 with accounts etc.\n. Could you please move this to the top? and mention the issue number also.\nThere is no need to list the dependencies updates.... you will need to add this line to tox.ini in the deps section of [testenv:py35-raw] in the tox.ini file. Unfortunately I don't have a strong tip to give you... I looked at the failing test and saw that it was relying on a specific list of deps.... This should go in 11.2.0 (unreleased). Indeed, >=2.9.9 will match >=2.10.0. Can we add a comment and open an issue to remove it when jsonschema 3 is released officially please?\nLike we did for #1727 . Warnings are gone but tests fail :) . I don't know what we have in other regexp... single quotes are fine IMO. We should remove the deprecated fallback too, no just remove the warning message :) \nIn other words, we should stop supporting the .mapping attribute on the resource class. Well, in theory I left the old methods with deprecation warnings. I'm not shocked by self.object, but apparently you are, so I'll change it...\n. Right, for the storage backend it's true indeed. We should probably have a _details-head-list.rst where we mention that the header can be obtained with HEAD. I'm not a big fan of this pattern. I don't think the return type of a method should differ based on a parameter value. What do you think?. to fix (post-merge). to fix (post-merge). nit: upercase HEAD ?. side note: In theory, this applies to every resources (buckets, collections, groups, etc.) but I'm fine if we only document it for records.... We are not supposed to have deprecate stuff for methods that were just introduced. I guess there is a path somewhere that makes a call to this count_all method with the wrong parameter...  \nIMO the caller should be in charge of rebinding the old collection_id parameter to resource_name, but I guess we could avoid having this here!. :+1: . :+1: . According to this, there should be no call to .list_all() and .count_all() with the parameter collection_id. . yep. I saw what you did, perfect!. in the resource?. I know this is not your code, but those quotes are weird, could you please remove them?. I don't think we need this argument. kinto flush-cache as @Natim suggested is better I think. In Python 3.6 dict keys are stable right?. plural_methods I guess\nBut plural_delete(self) isn't defined :) . this is for a single object ( object_methods=(\"DELETE\",) ). I'm surprised this works. Should it be given object uris?. Why is that?\nI think what limits storage operations is this setting https://github.com/Kinto/kinto/blob/f1da55010ae7fe4a4be7d2c8378a35d82eecf84c/kinto/core/init.py#L92. I wouldn't mind skipping resource events if that simplifies the code. The only idea that comes into my mind is a call to collection_timestamp() before deleting,... Maybe we could add a comment here to make it clear that this principal is going to be removed from every permission set on every object. Yes it does :wink: . `/user-data/``\n```\n?. Here I would put account:admin instead :) . I think we have something similar in kinto/core/authorization.py. Should we move it to utils?\n. Should it raise 404 if no entry for this user is found?. Doesn't it apply to /buckets? \n. I think it would help if you would briefly explain (here or in setup) what you mean by doomed and safe :). Maybe this doesn't have to be a class attribute IDK. I realized (when refactoring the core notions stuff), that using kwargs explicitly helps a lot. (resource_name=...). system. ?. Assert that we still have self.user_principal ?\n(permissions should not be empty). nitpick: I wouldn't list this change in the internal changes category. Probably breaking changes.... This tests should be kept, since they don't relate to the CLI but the HTTP API . Same here, this is about the API, not the CLI. I would remove usage:, and also write Kinto with lowercase. The cache backend, nothing more. Since it does not have to be memory, for example if memcached is configured...\nAlso add a . before This can..... I think I had a pending review that was never submitted and it got sent when I sent some comments yesterday.\nI'm really sorry for the confusion!. I think I had a pending review that was never submitted and it got sent when I sent some comments yesterday.\nI'm really sorry for the confusion!. Okay, you are right! the usage:  is everywhere! Keep it!. Weird, I'm pretty sure it's here for a reason...  I'm afraid that if we remove it we break Auth0 or something...\nIsn't there something you could configure in the Google settings?. > Could you try it on your end?\nOk I will on Kinto DEV\nI know that I got this plugin working with Google ID :) . We should add a note that this is a breaking change IMO. At least mention the minimum required version of kinto-admin :). I don't explain it...\n$ hashin pyramid-tm\n$ hashin pyramid-multiauth\n$ git status\n$. 1.23. Maybe add a comment that this comes from the openid plugin. > Is this just cleaning up whilst-you're-at-it?\nyes\n\nAlso, why is it not using core.storage.DEFAULT_DELETED_FIELD?\n\nhmm, good point, but the column is hard coded in the schema.sql file anyway. Looks like a merge issue . Here we should probably rephrase in order to make explicit that the default is fine enough.  . This should go in the latest section :) . At this point we should have emailing configured (link to settings section?). Here we should explain why (if any reason, I didn't read the whole thread) it's not a simple link /validate?key=abc. Usually, we try not to mix API docs with configuration docs. It looks like the following section should go to the settings parts. Can't I use this open endpoint to spam bob with reset emails?. account_validation?. that is available. I wouldn't use User creator here, it's confusing. If I create my own account, I'm not responsible for telling myself anything :)\nAdministrator maybe?. ditto: responsability of the administrator?. Double back ticks in RST. ditto : double back ticks. user object data? user data?. the account will need to be activated. Mail configuration?. I wouldn't bloat the config template with every possible option. We are dealing with optional settings of a plugin here... the main ones should be enough IMO. Yes I agree, this is how we did in kinto-signer: one capability and additional options values. Is this documented?. Check 'resource_name == \"account\"' then. or len(keys) > 1 ?. why not catch KeyError above?. validation_enabled. move all code below to a method that will confine the reset logics. . isn't equivalent to user.get(\"validated\", True)?. EmailFormatter?. move compiled regex to module constant. context.validation_enabled. move default email to module constant. move default template to module constant. I think this should go to a listener that listens to ResourceChanged events for the account resource with action=create. default duration should go to module constant. Maybe we shouldn't care about this. It allows me to know that user X is validated or not. I'm pretty sure the kwarg is object and not record. I would suggest to send an event and move all this code to a listener instead (or at least a function). ditto. constant.... I would prefer the email stuff to be confined in one place instead of being spread out in views.... Yes, I tried to run prerelease and it worked :). Thanks, fixed in 80c4a7d18. :woman_facepalming: . You can try this maybe (?)\npy\nresource_name, _ = core_utils.view_lookup(request, request.path)\nhttps://github.com/Kinto/kinto/blob/master/kinto/core/utils.py#L441. This is cool and worth mentioning in the CHANGELOG!. Also double back ticks in RST. Require?  Request?. New (capitalize). New (capitalize). SMTP (upercase). Why no return value here? Deserves a comment IMO. This return value seems to never be used. How is that?. Never KeyError? Deserves a comment IMO. The same way we have get_cached_reset_password()  we should have delete_reset_password() so that both uses of ACCOUNT_RESET_PASSWORD_CACHE_KEY are close to each other. This docs about email-context belong to API docs, settings docs are about configuration not API usage :wink: . Move to utils. Move to utils? (along other cache manipulations?)\n. Ditto about utils and cache read/write/delete :) . move to utils. why this here?. why not use accounts.utils?. I may have said something confusing. \nI think we can consider: API docs are for web developers who interact with the API, and Settings docs are for admins who install and run the service. Good catch! Don't change the whole thing, you're right it's better to track that in a separate issue. ",
    "tarekziade": "It looks like the headers values should be in string, not binary.\nIn https://github.com/mozilla-services/cliquet/blob/master/cliquet/resource.py#L110 and followingm by removing the encoding and keeping the string, it works\ndoes that sound right ? \n. Turns out there are deeper problems with this.\nWe need to:\n1- allow running and launching tests in cliquet w/o postgres.\n2- allow running and launching tests in kinto w/o postgres.\nchange the Tox file so it tries both environement. Then offer the two configs like in my initial PR\n. We have a use case for Webextensions.\nWe need to implement the quotas defined in https://developer.chrome.com/extensions/storage#property-sync  - where Kinto is used as a Key-Value storage (so one collection/addon and one bucket/user I guess)\nOn the server side we should add:\n-  QUOTA_BYTES: The maximum total amount (in bytes) of data that can be stored in sync storage, as measured by the JSON stringification of every value plus every key's length.\n- QUOTA_BYTES_PER_ITEM: The maximum size (in bytes) of each individual item in sync storage, as measured by the JSON stringification of its value plus its key length.\n- MAX_ITEMS:    The maximum number of items that can be stored in sync storage.\n. > Use an internal storage dataset to track stats\nWhy not as a collection metadata ?\n. Yeah, my rationale is that items_count and storage_size will be used by the client (or the quota plugin) like the last_modified field and that it's valuable to have them as a core value alongside last_modified.\n. > was it a specific requirement to be able to set cache duration \u00abglobally on bucket\u00bb for every underlying collections ?\nI don't think we have this use case, but I guess being able to set default values for the whole server can make sense. As long as we have no cache at all by default\n. Yay, looking forward for this feature!\n. side note: once this is implemented, it would be cool to have transaction-level events (start/success/failure) with a transaction number (uuid?) attached\n. in pserve + app.wsgi\n. Right now we have to do this in kinto.ini\n``` ini\n[app:main]\nuse = egg:kinto\nkinto.http_scheme = http\nkinto.http_host = 0.0.0.0:8888\nBackends.\nkinto.storage_backend = cliquet.storage.postgresql\nkinto.storage_url = postgres://postgres:postgres@localhost/postgres\nkinto.cache_backend = cliquet.cache.postgresql\nkinto.cache_url = postgres://postgres:postgres@localhost/postgres\nkinto.permission_backend = cliquet.permission.postgresql\nkinto.permission_url = postgres://postgres:postgres@localhost/postgres\n```\nMy change would allow to do something way less verbose:\n``` ini\n[app:main]\nuse = egg:kinto\nkinto.http_scheme = http\nkinto.http_host = 0.0.0.0:8888\n[storage]\nbackend = cliquet.storage.postgresql\nurl = postgres://postgres:postgres@localhost/postgres\n[cache]\nbackend = cliquet.cache.postgresql\nurl = postgres://postgres:postgres@localhost/postgres\n[permission]\nbackend = cliquet.permission.postgresql\nurl = postgres://postgres:postgres@localhost/postgres\n```\n. The proposed change is straightforward. Example:\n``` diff\n--- a/kinto/init.py\n+++ b/kinto/init.py\n@@ -30,6 +30,8 @@ DEFAULT_SETTINGS = {\ndef main(global_config, **settings):\n+    from konfig import Config\n+    settings['config'] = Config(global_config['file'])\n     config = Configurator(settings=settings, root_factory=RouteFactory)\n # Force project name, since it determines settings prefix.\n\n```\nThen the code can grab the config object. Another option is to pour back the content of the config file into settings, but I think it's less powerful than letting the code interact with the config object.\n. > We should probably replace pserve with something that runs the app.wsgi file no?\nwhy ? I think we can tweak the startup files so pserve is happy\n\nIt looks like prefixing settings name is a common pattern in Pyramid applications. This would contrast with the ecosystem, no?\n\nThe configuration file is used by humans to tweak the app options, so the target is them, not the code.\nI don't really think the configuration file should stick to a pattern if we think it's less explicit and clean, since for the code both ways to load the options can be done.\nThe only consideration imho is: do we like it better with explicit sections or not\n\nI wish this could apply to every cliquet applications, without having to copy/paste this global_config line)\n\nThis step can happen in cliquet during the initialization chain I think\n. +1 - and abort startup if it's not\n. Sounds like the 3rd one can be enforced by default in the Kinto API ?\n. The simplest and fastest way to do it is to create a wsgi middleware that rejects all calls where request.method != 'GET'\n. > So I would be in favor of doing it in Nginx + PostgreSQL of course\nOps are in favour of the app level because it simplifies their puppets deployments if they just create a  custom read-only kinto config.\nIn the final deployement they will block any write calls at the CDN level, but they want a safety net.\n\nWith the middleware approach, we have to be careful because this will restrist the batch requests. Even though every subrequest is readonly.\n\nI guess this can be detected in the middleware by introspecting the request body ? \nThis is also very important to know for the CDN rules. \nbonus question is : are we using this POST-is-a-bunch-of-GET feature for the sec settings ?\n. see https://github.com/mozilla-services/cliquet/blob/master/cliquet/init.py#L27-L88\n. I am here: http://kinto.readthedocs.org/en/latest/configuration/settings.html#storage\nI was reading the list of options for the storage. I think we should somehow mention what are the default values in the settings section.\n. oh! I see what you mean now, \"10\" is the default value. This was not obvious. Maybe we could explicitely write: \ndefault value: 10\n. I would suggest an explicit row in the table called \"default value\" maybe ?\n. That will work only if Kinto runs with a single process, which is not the case most of the time when you deploy with uWSGI\n+1 to just mention that the Memory backend is suboptimal in a real deployment with mutiple processes.\n. One solution would be to extend resource.register() so we can list for each verb the status codes. \nThat'd also be a great way to improve testing by asserting that whatever response goes out of the method, its status is in the list \n. dupe of https://github.com/Kinto/kinto/issues/286 - closing this one since the other one has more info+discussions\n. I consider children to be part of the parent resource content and I think the logical thing is to impact the last_modified of the parent when a child change.\nWhat would be the benefit of not doing it ?\n. > The former is the collection.last_modified value which changes when the collection properties are updated.\nIs that a specific use case we have ? to be able to do something when a collection property has changed but NOT when a record has changed ?\n. by the way, I could not find where init() can be used from the shell. I had to use a main section to run it. Is this somewhere or we should add it?\n. It's even simpler:\nbash\n.venv/bin/kinto --ini config/kinto.ini init\nThere's a bug though when this file does not exists, for some reason \"make serve\" does not re-create it, I;ll open another bug\n. see https://github.com/Kinto/kinto/issues/290\n. dupe of https://github.com/Kinto/kinto/pull/283\n. There's one thing I find unclear in the comparison matrix: some of the contenders are client-server products, and some are just servers.  For instance I don't think we're just comparing Kinto with the Firebase Server only, but rather with the Firebase product.\nIn the same vein, comparing Kinto with CouchDB might not be fair to CouchDB if we don't include PouchDB in the matrix.\nI think we should treat everyone equally by comparing products - and before the matrix, clearly define what is the product we are talking about.\nFor example: \"an offline-first toolkit\" ? and for Kinto, the Kinto+Kinto.js combo ? for CouchDB the PouchDB+CouchDB combo ? etc.\n. I hope that does not mean Kinto can't run without an OAuth provider... If Kinto can run with Basic Auth (or no auth at all), I think the tutorial should use it to KISS. \nWhen I am trying a new storage service and following a tutorial, I don't care about authentication. It's not something I care about until I deploy the service. (or try out stuff around permissions etc)\nIf your tutorial forces me to use Github, Twitter or Facebook - It makes me want to stop right there.\n. one option is to have a composed wsgi app where /__admin is served by a second app (kwak)\n. @leplatrem an option in the ini file sounds cool too\n. I am now importing cliquet glossary so the Kinto doc can use the terms described there. The Kinto has its own glossary for terms that are Kinto-specific. \n@leplatrem let me know if this works for you\n. > last_read - timestamp of last read. (Not sure about this).\nI don't think that one is easy to implement. When you have a stack with several nodes, you would need to have a complex implementation to be able to have that info. What is your use case for this info ?\n. Here are the two items I suggest we add in the collection or bucket metadata (and not used for the signing)\n1. items_count \n2. storage_size - In bytes.\nThose two fields will be useful to implement a quota feature among other things. I don't think it should be added as a plugin. It sounds like a core feature that can be added without having to deal with plugin indirections, in particular if we have to deal with conflict resolutions at some point.\nIf we reach the consensus on how those two fields are stored we can do what @leplatrem suggested:\n- On create, sum the bytes, on delete subtracts, on update sum the difference between old/new. \n@msathis  What is the use case for the created_at field ?\n. Maybe It might worth adding in that case specific events before the data is saved into the DB, so some custom code can alter the data and maybe even reject the change ?\n. I vote for 1. because \"little indicators\" won't stick when the text is copied around\n. Another thing: maybe we should store tutorial scripts in real Python modules, we can run tests against. This is useful to make sure the tutorials are really working when the project changes.\n. >  relying on a fast local server that behaves as relay is a very common approach\n\nTo run this in production, we would rely on a local email server acting as a relay in order to avoid bottlenecks.\n\nNot if you want a robust system.  If there's any issue sending e-mails out, you now have to deal with an HTTP service that fails to return responses to its users because the SMTP service is borked.\nIf it slows down (it happens even on \"very fast\" local SMTP services), you're slowing down all requests to your HTTP service.\nIf I take an example of how Kinto could be deployed at Mozilla : it would use Amazon SES, and I would want to send emails to SES asynchronously.\n\nIf you are willing to improve the tutorials please don't hesitate!\n\nI would not dare changing it until you really feel it's useful !\n\nAltering records on the fly can be a bit hacky, I have no idea how'd it look.\n\nMe neither, but in my mind the only benefit of synchronous notifications is if it impacts what is written in the DB or what gets back to the user. \nIf the triggered notification has zero impact on the request/response flow, what would we ever want it to be synchronously executed ?  just to slow down the user for no reason ?\n. > No because the exceptions raised by listeners are catched.\nBut if the service times out, you still get unacceptable response times.\n\nThe default listener that deposits messages in the redis queue is synchronuous. \n\nYes that's something we've discussed when we added it. In that case we're making the assumption that the redis service is dedicated to Kinto usage and we can push to its queue and for example trigger an exception if it's not operating fast enough. We're under control for this queue hopefully.\nIdeally, we should have workers inside Kinto to deal with this. Example: https://github.com/AcrDijon/henet/blob/master/henet/workers.py\nThat would be an enhancement and handles your not-really-async not-really-sync examples\n. Implementation : \n- add a workers.py module into cliquet, with a Workers class\n- initialize it in cliquet.initialization so the registry gets a \"workers\" new attribute with n processes launched\n- add a listener in cliquet.listeners that dumps event payloads into the workers pool and run asynchronously a function that runs in a separate process.\nAbout the function that's executed asynchronously - I am not 100% sure about what should be the proper design. we could have a simple configuration system where a fully qualified name is declared, and gets the payload. \nConfig example:\nini\nkinto.event_listeners = background\nkinto.event_listeners.background.processes = 4\nkinto.event_listeners.background.functions = \n    myproject.mymodule.send_email\n    myproject.mymodule.do_something_else\nwith send_email(event_payload)\n. :+1: \n. There's one issue with your configuration proposal though: the pool of workers is initialized on startup independently from the listeners we've set up. Processes are also shared among listeners.\nSo \"processes\" should be a separate, global option. e.g.\nProposal:\n``` ini\nkinto.background.processes = 4\nkinto.event_listeners = redis send_email\nkinto.event_listeners.redis.use = cliquet.listeners.redis\nkinto.event_listeners.redis.workers = cliquet.workers.memory\nkinto.event_listeners.send_email.use = myproject.mymodule.send_email\nkinto.event_listeners.send_email.workers = cliquet_celery.workers\nkinto.event_listeners.send_email.resources = bucket collection\nkinto.event_listeners.send_email.actions = create delete\nkinto.event_listeners.send_email.from = jeanlouis94@voila.fr\n```\n. Implementing the feature in https://github.com/mozilla-services/cliquet/pull/647\n. yeah a brief text with a link to the doc sounds perfect\n. We should be cautious, it sounds like a recipe for disasters.  Do you have some use cases in mind ?\n. one minor annoyance is if Kinto is running under mod_wsgi : that web server complains when you register signals, so we need to add something about it in the doc\n. btw @leplatrem : if we add an async flag to all our events, the listener will be able to know which one to run synchronously.  Does that help for what you want to do with in-transaction events ?\n. Yeah let's move it to kinto-dist - https://github.com/mozilla-services/kinto-dist/issues/45\nThanks\n. @Natim That's orthogonal. If we want to avoid any leakage of information, we should firewall the access to those /__VIEWS   \nThat's why I've initially created the __ prefix standard\n. Even though we're not hiding them I am skeptical about the fact that hiding the version numbers is a good practice - apache and nginx don't do it afaik.\nLet's ask Julien\nAlso: let's not add yet another info page, this is getting overkill \n. The signer blocks for 30s. This should be enforced by the whole heartbeat view, not delegated by each backend. Because 30s + 30s + 30s... :)\n. what about other back-ends ? do we care ? or should we state explicitly in our docs they are not suited for production use ?\n. > Should we raise ? \nNo, caching should not impact the result of the web service calls. just speed it. So if the cache is full, it's up to the application to do whatever it wants to optimize it. \nSorting by date is one option, another one could be by hits e.g. getting rid of the least called cached entries.\n. Fixed in https://github.com/Kinto/kinto/commit/0e3880710d4049e2e2fdc013d8d0b46cc7a5b88c\n. I think that's related to the way the structlog factory is initalized to wrap python APIs\n. One thing you can do is initialize the logger with default settings, and revisit them once the settings are loaded. It's a pattern I used in other apps\n. I am -1 on avoiding to use logging before things get initialized, because you can't control what is going to happen. If a underlying lib calls a logging API you might get back the error.\nIt's quite simple to initialize the logging system - with a default  behavior that does like a print()\n. Ok commenting there\n. proposed fix\n``` sh\n$ git diff kinto/core/initialization.py\ndiff --git a/kinto/core/initialization.py b/kinto/core/initialization.py\nindex 26e5028..e08228f 100644\n--- a/kinto/core/initialization.py\n+++ b/kinto/core/initialization.py\n@@ -318,7 +318,8 @@ def setup_logging(config):\n     renderer_klass = config.maybe_dotted(settings['logging_renderer'])\n     renderer = renderer_klass(settings)\n\nstructlog.configure(\nstructlog.wrap_logger(\nlogger,\n         # Share the logger context by thread.\n         context_class=structlog.threadlocal.wrap_dict(dict),\n         # Integrate with Pyramid logging facilities.\n```\n. if @hynek is willing to release your fix soon +1 for the proper fix.\n. I don't think that's the right fix see https://github.com/Kinto/kinto/issues/628#issuecomment-220968779\n. Very nice ! \n\nMaybe we could have this new backend implemented in its own repository ? e.g. kinto-mongodb. \nKeeping kinto as small as possible is making it easier to deploy when you don't use mongodb - and gives us a less complex requirements handling. For instance, no need to add a bunch of Skips in the tests.\n. Closing this, feel free to add a link to a repo in case you start back this work. Thanks\n. > It will ease displaying the username on the kinto-admin.\nI am also confused because ISTM the dashobard has all the info. Can you describe the detailed use case in a user story ?\n. You should do it the other way \n1/ call each heartbeat function into a separate thread. \n2/ a successful result flips a flag\n3/ on timeout (or before) return with the result.\nuse concurrent.futures.ThreadPoolExecutor\nI am making the assumption that each heartbeat function is isolated enough to run in parallel with the other ones\n. also: r-\n. Looks great r+\n. Example of usage:\n``` python\nfrom kinto.core.events import BeforeResourceChanged\ndef zip_attachment(record):\n   filecontent = record['filecontent']\n   gzipped = gzip(filecontent)\n   record['filecontent'] = gzipped\n   record['filename'] += '.gz'\nrecord['original'] = {\n                'filename': record['filename'],\n                'hash': sha256(filecontent),\n                'mimetype': record['mimetype'],\n                'size': len(filecontent),\n            }\ndef on_before_resource_changed(event):\n    for record in event.impacted_records:\n        zip_attachment(record)\nconfig.add_subscriber(on_before_resource_changed, BeforeResourceChanged)\n```\n. This ended up being a core feature on kinto-attachment, so I am closing this bug\n. \"a warrant of choice\"\nthis is not an argument imho. People chose Kinto for its features not the DB it uses.\nHaving to deploy postgresql is just a technical detail. I would argue that if we find some speed bottleneck and Redis makes thing super efficient, let's use it. If it's just to make sure our backend can be implemented with various DBs, I would ask : why? it just sounds like more trouble & more work.\nThat said, for Mac Developrs, it's always a little bit painful to have to deploy postgres. It's not straightforward. So being able to play with Kinto with no DB is kind of nice. I would vote for a memory-to-disk toy implementation though :)\nA cache DB should be optional btw, but it sounds like you want more from Redis - and from experience (Hello) that led us to some problems.\n. > the way it has been implemented in Postgresql makes it difficult to apply to no SQL backends\nWhich leads to the question: why do you want a No SQL backend ?\n\nWhat you call memory-to-disk is exactly what redis is offering so I would be in favor of keeping Redis rather than replacing it by another backend.\n\nWhat I call a memory-to-disk backend is a toy implementation in python so Kinto \"works\" just to try it out on a single process for fun - rather than having to install and run Redis.\n\nI don't think we can say that our experience with Hello led us to some problems, we already had \nmore problem with Kinto and Postgresql than we had for 2 years of Hello.\n\ncough cough   Choosing Redis over a classical database in Hello was a very poor choice. We had to deploy HUGE servers to make sure that we had enough room to fit the whole database in RAM, and then worry a lot about sharding and replication. If we had picked Postgres or MySQL from day one we woud have avoided a lot of trouble. This was just to have the TTL feature, but that cost us a lot more work than if we have had crons to clean up the DB.  We were just lucky the DB did grow more ;)\nRedis is a cache server, not a real RDBMS - I think you need to admit it and stop trying to use it for everything ;)\n. > I suggest that we move the redis backends to a separate repo, and that we stop maintaining them officially along Kinto. \n+1 \n. This is really awesome!! I am wondering if we can use some reSt magic (like a glossary?) to avoid the duplication of the status codes text, so we just type something like :term:400 ?\n. -1 on having a specific stats endpoint. We should store this info in the metadata with the other info. They are metadata like last_modified. \n. Like I said in https://github.com/Kinto/kinto/issues/173#issuecomment-236604658 I am still -1 on having a specific view for holding this information, which is of the same nature than last_modified.\n. > Right now, I am trying to implement the solution proposed by @leplatrem in #173 (comment) which seems to me to be cleaner.\nPlease don't implement any code if we disagree on the design. This is a potential waste of time.\n\nUpdating the bucket on each change in it might have a big impact on the kinto protocol and create a lot of HTTP 412\n\nI am not sure why you want to update the bucket on each change. \nPlease let's pause for a second here until we know exactly what we want. thx\n. I tried to write a test to reproduce it but I can't. But if you run a server it can be reproduced.\n. @leplatrem  Good job! you beat me to it :) \n. @gabisurita note that the swagger validator at swagger.io passes even with this issue, as it seems more relax on this problem for some reason.. Yes that's the default port\n. s/read-only/GET/  requests ?\n. missing string or is this normal ?\n. typo again ;)\n. It seems to me that the docs are not versioned on each HTTP API increment, but on each Python package release, which is different.\nSo how can we have document with:\n- a list of all API versions ?\n- for each new API version a specific document with the diff with the previous API version\n. good point! :+1: \n. sure. \n. I thought it was more than that. For instance \"GET /\" is part of the protocol, as defined in Cliquet docs, and it's not a Resource (according to the definition in the Cliquet glossary)\n. This is the definition from Wikipedia = https://en.wikipedia.org/wiki/Application_programming_interface#Web_APIs\nI am ok to change it, but in \"HTTP resources endpoint\" , I don't understand what the word resource means.\n. why not just \"endpoints\" ?\n. natim: This is the definition of.. Web Resource ;)  For the definition of HTTP API it's closer to https://en.wikipedia.org/wiki/Web_API.\nSo what about:\nmultiple publicly exposed endpoints that accept HTTP requests and respond with the requested data, in the form of JSON.\n. done\n. It's already in the Cliquet glossary. Ideally we should have a unified glossary across the two docs. I guess we can import it like we do for other cliquet docs\n. You mean 1.x and the 2.x line ? I don't see why/how\n. But the docs will need to show all API versions\n. That's the problem with having the HTTP API documentation inside a Python package. The HTTP API documentation should be separated from the implementation. I understand that it's easier to maintain if it's in the Kinto repo, but the kinto package releases should not interfere with the HTTP API versions.\nThe target readership does not care about the implementation. They want the API doc, and they want to be able to see how 1.1 is different from 2.3 for instance.\n. Maybe we could provide our own configure function that includes logger._logger = None because I don't see a use case in kinto for using reset_logger besides configuring the logger.\n. 2 seconds seems very low. Since we're running in parallel I think we can use 10 seconds by default maybe ?\n. I am confused, I've read 2, 3 and 5 seconds in various places\n. shadowing the builtin, let's use function or func or callable_\n. you are running threads, but here you are doing a sequential loop. We're losing the benefits of the threads and making the loop duration dependant on the number of callables.\nThe pattern is to just return after n seconds and let the futures flip the flag. e.g. a general wait with a timeout (see the pool API)\n. there's one thing missing: when one (or several) heartbeat(s) fails, we need to catch the future(s) exception(s) and log them here with logger.exception so we can track down what happens. The future object holds that exception, so we just need to iterate on them and collect the TB\n. another option is to catch them in heartbeat_check and push them in an exceptions list\n. also: make sure you call logger.exception in the main thread sequentially on the collected tracebacks, otherwise you might have mangled exceptions since two functions can fail in parallel at the same instant\n. if we re-raise here we're getting a 500 I think. I think what you want is (not tested):\npython\nfor future in done:\n    exc = future.exception()\n    if exc is not None:\n        logger.error(\"%r failed\" % future.__heartbeat_name)\n        logger.error(exc)\n. ok I see, so there's the convention that the heartbeat functions should catch all errors. But we never know what might happen in external heartbeat functions.\nIs that a behaviour we want to keep ? \ne.g. do we want the global heartbeat to completely fail when one heartbeat is producing an error, or do we want to log that error and flag that backend to false in the result ?\n. nit: you can use %r instead of '%s'\n. ",
    "kumar303": "Awesome, thanks!\n. it seems to be working in my patch here https://github.com/mozilla/payments-env/pull/34\n. Yeah, it's probably better as :ref:. You could do it in two steps. Add this to the target section in get-started.rst \n```\n.. _deploy-an-instance-on-heroku:\nDeploy an instance on Heroku\n...\n```\nThen you can reference it from the other page like:\n:ref:`single-click deployment on Heroku <deploy-an-instance-on-heroku>`\n. ",
    "magopian": "Seems the test failure is linked to the way the tests are launched, because using make tests-once on master doesn't fail anything, while doing it on this PR does fail on test. I'll investigate this asap.\n. r+wc, thanks for picking up the ball :+1: \n. yep, that allows using the --lf (for \"last failed\") to the test run command, which will only re-run the tests that failed. It's awesome, you should use it ;)\nAlso, if you want to give it a try:\n- pip install pytest-xdist\n- py.test --cov-report term-missing --cov-fail-under 100 --cov kinto -n 4 --nosugar\npytest-xdist is not compatible with pytest-sugar I believe, hence the --nosugar.\nThis will run the tests in parallel on 4 workers/cores, which should be much faster ;)\n. I agree. pytest-cache would still be good though\n. r+\n. GO FASTER (travis)\n. It seems the user exists already:\n```\nhttp GET https://kinto.dev.mozaws.net/v1/buckets/todo/collections/tasks/records -v --auth 'user:password'\nGET /v1/buckets/todo/collections/tasks/records HTTP/1.1\nAccept: /\nAccept-Encoding: gzip, deflate\nAuthorization: Basic dXNlcjpwYXNzd29yZA==\nHost: kinto.dev.mozaws.net\nUser-Agent: HTTPie/0.8.0\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Backoff, Retry-After, Alert, Next-Page, Total-Records, Last-Modified, ETag\nBackoff: 10\nConnection: keep-alive\nContent-Length: 129\nContent-Type: application/json; charset=UTF-8\nDate: Sun, 05 Jul 2015 13:16:04 GMT\nETag: \"1436100694561\"\nLast-Modified: Sun, 05 Jul 2015 12:51:34 GMT\nServer: nginx/1.4.6 (Ubuntu)\nTotal-Records: 1\n{\n    \"data\": [\n        {\n            \"description\": \"Alice task\",\n            \"id\": \"42b9f92e-4e00-48a9-b2b2-fe1b0fd9eb49\",\n            \"last_modified\": 1436100694561,\n            \"status\": \"todo\"\n        }\n    ]\n}\n```\nBut GETing the default records returns a 403:\n```\nhttp GET https://kinto.dev.mozaws.net/v1/buckets/default/collections/tasks/records -v --auth 'user:password'\nGET /v1/buckets/default/collections/tasks/records HTTP/1.1\nAccept: /\nAccept-Encoding: gzip, deflate\nAuthorization: Basic dXNlcjpwYXNzd29yZA==\nHost: kinto.dev.mozaws.net\nUser-Agent: HTTPie/0.8.0\nHTTP/1.1 403 Forbidden\nAccess-Control-Expose-Headers: Backoff, Retry-After, Alert, Next-Page, Total-Records, Last-Modified, ETag\nConnection: keep-alive\nContent-Length: 95\nContent-Type: application/json; charset=UTF-8\nDate: Sun, 05 Jul 2015 13:15:05 GMT\nServer: nginx/1.4.6 (Ubuntu)\n{\n    \"code\": 403,\n    \"errno\": 121,\n    \"error\": \"Forbidden\",\n    \"message\": \"This user cannot access this resource.\"\n}\n``\n. Similarly, providing theIf-None-Matchheader never returns a304(which might be \"normal\", as the full list is always returned).\n. The following step in the tutorial is granting thegroup:createpermission to authenticated users, it fails in the same way.\n. The issue is that by default pytest does not capture the logs (only the output). So the logs (giving more information about the failure) were not displayed on test failure. Usingpytest-capturelog` fixes that (see #191)\n. I've added a \"second attempt, different wording\" part on the pad: https://public.etherpad-mozilla.org/p/why-do-i-need-a-json-database\n. I think it would benefit from more visibility, maybe a link from the very first sentence on http://kinto.readthedocs.org/en/latest/index.html?\nMaybe something like \"Why should I use Kinto\" which links to a paragraph in the http://kinto.readthedocs.org/en/latest/overview.html page? (the first paragraph?)\n. From what I understand of the code I read, this looks good to me. If someone else with better knowledge of the codebase could double-check, that would be nice ;)\nThere's a test failure, from the load tests, is it related to what you were discussing with @Natim on irc about cliquet having timestamp unicity issues?\n. @almet I would personally use it, yes, I find it far more convenient and ergonomic to edit params in a web form, than on the command line (think about very long command lines, wrapping over several lines, and you can't position the cursor using your mouse).\nIt would indeed be much better if we had our own instance of hurl, and even better if we could have all that in the context of the page itself (but then, switching to a terminal is also a context switch, maybe even more than switching tabs).\nSo, maybe, just maybe, we could take this in steps?\n1/ add the urls to hurl\n2/ install / use our own instance (and modify the links to point to it)\n3/ study the feasibility of having the forms inline with the docs (maybe use something like swagger? or... the kinto-js lib ;)\n. that was blazingly fast\n. After thinking some more about it, I agree that it doesn't make sense to use a closed service in our official docs.\nThis means there's the following solutions:\n1/ modify the current open source solution to support parsing the url fragment into form inputs, the way it's done on hurl.it\n2/ implement another solution, that could be embedded straight into the documentation: this would be even better and more ergonomic/useful than having to open a new tab for each API call, and could also allow us to \"pipe\" the output of one API call into the form for the next API call (making it dynamic, being able to re-use the IDs, ETags and others). However, this would mean quite a lot of work\n3/ leave the documentation as it is, and maybe add a note about the existence of web services that can be used in place of the command line\n. Fixed in https://github.com/Kinto/kinto/commit/03aad1c1ee7ee87ee6dede784717c789a3707b44\n. It does work with a .rst extension, I double checked, but it could also be a .md file if you'd rather have that, what do you think?\n. @almet I've updated the file, let me know what you think ;)\n. Thanks a lot for the thorough review @almet ! I've updated it, let me know if that still looks good to you\n. Ah, good catch on the link formats :) Changed the file to be a .md\n. I like this, especially the sequence diagram which is pretty clear. The architecture diagram also kind of gives some general information, and \"tags\" (? the bullet points on the right) about what each \"layer\" does.\nThe architecture diagram is a good compromise I guess between something that is general enough (you don't want a detailed explanation of cornice here), but still gives pointers on what each layer is responsible for.\nr+wc from me, thanks for this work!\n. @leplatrem updated the license field, thanks, is that ok?\n. @almet I added your suggestions from https://github.com/Kinto/kinto/pull/478#discussion-diff-54535553\n. I added @leplatrem's wording/typo fixes, and removed the problematic sentence, what do you think @leplatrem @almet ?\n. @almet I added some links, let me know what you think ;)\n. I created a pad with my proposed modifications and some notes: https://public.etherpad-mozilla.org/p/kinto-makefile-documentation\n@ayusharma @leplatrem @almet what do you think?\n. Nobody else answered, and this is 21 days old, I think it's safe to say that you can move forward with that now @ayusharma  ;)\nThanks!\n. r+ thanks!\n. this is awesome, thanks!\nr+\n. Disclaimer: at least locally it seems this fixes the issue, and using this Dockerfile I can launch the kinto server from inside the docker container. However, maybe because of some bad docker configuration, the port forwarding seems to timeout.\nIf somebody could validate that this fixes the issue for them, that would be awesome ;)\nping @almet @Natim \n. excellent, thanks! I'm landing this\n. Data that caused the issue (sorted on the score field):\n{\"data\":[{\"toto\":\"tata\",\"last_modified\":1459420435063,\"score\":4139,\"foo\":\"bar\",\"id\":\"e9896d20-db5c-48d9-9ec6-adb617a1af52\"},{\"toto\":\"tata\",\"last_modified\":1459420433493,\"score\":3913,\"foo\":\"bar\",\"id\":\"0f41cd76-7bff-429c-baa6-1cad78f57caa\"},{\"toto\":\"tata\",\"last_modified\":1459420430201,\"score\":3455,\"foo\":\"bar\",\"id\":\"06742560-77de-45c3-bf6b-f7b3a471ed18\"},{\"toto\":\"tata\",\"last_modified\":1459420431480,\"score\":2959,\"foo\":\"bar\",\"id\":\"29838c12-06f0-46bf-a2c2-dd4c01efcfcf\"},{\"toto\":\"tata\",\"last_modified\":1459418331306,\"foo\":\"bar\",\"id\":\"4f40b498-5ac1-4b4f-a50e-e939f14af7a3\"},{\"toto\":\"tata\",\"last_modified\":1459418331138,\"foo\":\"bar\",\"id\":\"6abf99a6-c5f9-4592-9339-4f46fc5e6546\"},{\"toto\":\"tata\",\"last_modified\":1459418330935,\"foo\":\"bar\",\"id\":\"288af843-2d35-4e6b-b2ea-132249c97ec3\"},{\"toto\":\"tata\",\"last_modified\":1459418330747,\"foo\":\"bar\",\"id\":\"94115077-62c4-48da-ba4b-d792d02f4406\"},{\"toto\":\"tata\",\"last_modified\":1459418330565,\"foo\":\"bar\",\"id\":\"51446599-b3d9-4666-bb78-d9483fcbfc61\"},{\"toto\":\"tata\",\"last_modified\":1459418330227,\"foo\":\"bar\",\"id\":\"928b481a-3be8-4684-9012-00bdb3604d1b\"},{\"toto\":\"tata\",\"last_modified\":1459418329683,\"foo\":\"bar\",\"id\":\"e443266f-12c6-46c6-b457-4175789c381e\"},{\"toto\":\"tata\",\"last_modified\":1459418329484,\"foo\":\"bar\",\"id\":\"b5f01dcc-8fca-4122-9072-5f0cefadcc66\"},{\"toto\":\"tata\",\"last_modified\":1459418329284,\"foo\":\"bar\",\"id\":\"21a04c85-aea9-4ac9-b52c-6ab45c1f8ce9\"},{\"toto\":\"tata\",\"last_modified\":1459418329107,\"foo\":\"bar\",\"id\":\"01033a9f-8887-4a69-b1a2-15fec7295bfe\"},{\"toto\":\"tata\",\"last_modified\":1459418328923,\"foo\":\"bar\",\"id\":\"edb15905-4915-425b-8707-01616be5328b\"},{\"toto\":\"tata\",\"last_modified\":1459418328707,\"foo\":\"bar\",\"id\":\"53c8fb25-7267-443b-af4c-4a17c0dab3c2\"},{\"toto\":\"tata\",\"last_modified\":1459418328534,\"foo\":\"bar\",\"id\":\"a938afc2-4832-4f68-819e-00d8db1caa70\"},{\"toto\":\"tata\",\"last_modified\":1459418328339,\"foo\":\"bar\",\"id\":\"a34b221c-e82b-4da2-9010-2a03912f5bc0\"},{\"toto\":\"tata\",\"last_modified\":1459418328163,\"foo\":\"bar\",\"id\":\"6899ff74-3e15-4319-8575-9943240becca\"},{\"toto\":\"tata\",\"last_modified\":1459418327977,\"foo\":\"bar\",\"id\":\"5bb85a22-c965-4ef5-a2d0-1f09f58c4606\"},{\"toto\":\"tata\",\"last_modified\":1459418327796,\"foo\":\"bar\",\"id\":\"27a86f14-6d9a-4cca-93fd-43243d981bcd\"},{\"toto\":\"tata\",\"last_modified\":1459418327623,\"foo\":\"bar\",\"id\":\"07056637-13cc-49da-962b-77f958e0f059\"},{\"toto\":\"tata\",\"last_modified\":1459418327443,\"foo\":\"bar\",\"id\":\"32551088-ba67-4a07-be87-6b6502f47b92\"},{\"toto\":\"tata\",\"last_modified\":1459418327259,\"foo\":\"bar\",\"id\":\"cac2eb16-24db-4fe7-b258-6a1dfe6bae2a\"},{\"toto\":\"tata\",\"last_modified\":1459418327088,\"foo\":\"bar\",\"id\":\"b32a089d-48d3-47e6-b9be-3c3699c8e463\"},{\"toto\":\"tata\",\"last_modified\":1459418326875,\"foo\":\"bar\",\"id\":\"ad9a7efb-65dc-4e29-ab3b-0e747d4c9d0c\"},{\"toto\":\"tata\",\"last_modified\":1459418326109,\"foo\":\"bar\",\"id\":\"a628882a-c7ee-4300-8d84-1e577d476f8a\"},{\"toto\":\"tata\",\"last_modified\":1459417940577,\"foo\":\"bar\",\"id\":\"ad794d1c-926e-4aa1-b2c5-c25635f40945\"},{\"toto\":\"tata\",\"last_modified\":1459420432815,\"score\":2887,\"foo\":\"bar\",\"id\":\"7becc0e6-95a6-4150-a0d3-a041ca84c177\"},{\"toto\":\"tata\",\"last_modified\":1459420432312,\"score\":2698,\"foo\":\"bar\",\"id\":\"c38bf9d8-4eea-41b1-b370-200f5592ccb5\"},{\"toto\":\"tata\",\"last_modified\":1459420430787,\"score\":2394,\"foo\":\"bar\",\"id\":\"03e65d71-b3a4-4138-9674-e6180dae34f1\"},{\"toto\":\"tata\",\"last_modified\":1459420435285,\"score\":2372,\"foo\":\"bar\",\"id\":\"5d654eb0-1937-46cd-b447-d26ded64184a\"},{\"toto\":\"tata\",\"last_modified\":1459420434839,\"score\":2178,\"foo\":\"bar\",\"id\":\"ed5a2564-ccc3-49bf-b053-8210fc7b0982\"},{\"toto\":\"tata\",\"last_modified\":1459420433039,\"score\":2141,\"foo\":\"bar\",\"id\":\"521315c2-5d3d-49eb-9a92-c88431bdac50\"},{\"toto\":\"tata\",\"last_modified\":1459420432032,\"score\":1990,\"foo\":\"bar\",\"id\":\"e7ba2169-c60b-4236-a625-a289cb10747b\"},{\"toto\":\"tata\",\"last_modified\":1459420431163,\"score\":1975,\"foo\":\"bar\",\"id\":\"a4fdd30a-ce15-444d-b3a1-0931531e47ed\"},{\"toto\":\"tata\",\"last_modified\":1459420495623,\"score\":1822,\"foo\":\"bar\",\"id\":\"4cdbe479-4555-4f3a-9a12-7c9e174636c6\"},{\"toto\":\"tata\",\"last_modified\":1459420434615,\"score\":1175,\"foo\":\"bar\",\"id\":\"4ab97029-3682-46be-95f5-30f6c3091545\"},{\"toto\":\"tata\",\"last_modified\":1459420434409,\"score\":1131,\"foo\":\"bar\",\"id\":\"2ae8643d-7adf-4544-b723-9a4c891bca60\"},{\"toto\":\"tata\",\"last_modified\":1459420434183,\"score\":1066,\"foo\":\"bar\",\"id\":\"3b92bcae-c9ca-4a03-bbf8-14ffd297d01a\"},{\"toto\":\"tata\",\"last_modified\":1459420433952,\"score\":683,\"foo\":\"bar\",\"id\":\"ec9295c0-0735-4a57-8a9c-2e73c99fc2a8\"},{\"toto\":\"tata\",\"last_modified\":1459420433263,\"score\":455,\"foo\":\"bar\",\"id\":\"19971108-4666-4f5c-9103-a63ccffce623\"},{\"toto\":\"tata\",\"last_modified\":1459420433712,\"score\":407,\"foo\":\"bar\",\"id\":\"c122b967-603e-425c-b14d-18d5bac9854a\"},{\"toto\":\"tata\",\"last_modified\":1459420432583,\"score\":386,\"foo\":\"bar\",\"id\":\"f9038545-a4e3-49f9-8430-e69eed3dd9ae\"},{\"toto\":\"tata\",\"last_modified\":1459420431765,\"score\":252,\"foo\":\"bar\",\"id\":\"07357e8f-d1cc-4056-ba64-0c73cba2d1c3\"}]}\nThe PHP code:\nphp\n    $headers = array('Accept' => 'application/json', 'Content-Type' => 'application/json');\n    $options = array('auth' => array('token', 'switch'));\n    $request = Requests::get('http://localhost:8888/v1/buckets/default/collections/bar/records?_sort=-score', $headers, $options);\n. Closing: unable to reproduce using in-memory or postgresql. Will re-open if we can find a way to reproduce this issue.\n. r+, thanks!\n. @natim r?\n. @natim r?\n. Yes, just reproduced with postgresql9.4 (but not with the in-memory backend)\n. Here's the SQL query we're sending to posgresql:\nSELECT total_filtered.count AS count_total,\n               a.id, as_epoch(a.last_modified) AS last_modified, a.data\n          FROM paginated_records AS p JOIN all_records AS a ON (a.id = p.id),\n               total_filtered\n          ORDER BY data->>(:sort_field_0) DESC, last_modified DESC;\nAnd here are the parameters:\n{'sort_field_0': u'score', 'collection_id': 'record', 'deleted_field': '{\"deleted\":true}', 'parent_id': u'/buckets/4ed2d0f8-ba97-9765-af32-d19b001f70d8/collections/foobar'}\nIf we try running the following query straight in psql, we can confirm that the order is coherent with a string sort, not an integer sort.\n. Ok, @Natim found the answer: we should be using data-> (to json value), instead of data->> (to text).\n. Excellent, maybe add a link from the \"get-started\" page to the \"running in production\" one?\nr+wc\n. Submitted a PR to address this issue: https://github.com/rtfd/readthedocs.org/pull/2428\n. Seems the fix in the above PR on readthedocs was reverted, and the current issue tracking it is https://github.com/rtfd/readthedocs.org/pull/3441 (some issue with the git version used on their servers if I understand correctly?). This now seems fixed, see https://github.com/rtfd/readthedocs.org/issues/1820. Created a PR upstream: https://github.com/snide/sphinx_rtd_theme/pull/330\n. Seems the fix in the above PR on readthedocs was reverted, and the current issue tracking it is rtfd/readthedocs.org#3441 (some issue with the git version used on their servers if I understand correctly?). Is there a way to reproduce this issue? Do you have data or a list of steps?\nAs a preliminary investigation, I found out that it might be raised by this line of code in the ujson library: https://github.com/pydata/pandasjson/blob/adcad445673b274728957f20643eb4e0975e79c5/ujson/lib/ultrajsonenc.c#L287\nMaybe relevant, this SO question: http://stackoverflow.com/questions/8422243/overflowerror-unsupported-utf-8-sequence-length-when-encoding-string\n. Agreed, let's close this one, and reopen if needed (and then maybe do something like first safely encode to utf-8, and only then do the json.dumps).\n. For reference, the way to run a single test using tox (running pytest) is as follows:\n.venv/bin/tox -e pypy -- tests/core/test_views_transaction.py::TransactionEventsTest::test_resourcechanged_is_rolledback_with_transaction\n. Let's go with the trivial solution (at least for now): add a default value...\n. Let's follow what Postgresql does on that one.\n. As a side note, this test doesn't fail for the memory backend because there's a min constraint that \"fixes\" the issue.\n. I don't see any drawbacks in having the same behavior. Do you think it could be a security issue or something? \n. I meant \"a minor change is needed to either the docs or to the code and tests\" ;)\n. r+\n. i believe you addressed all the comments (hard to say with the new \"review\" feature of github, code changes don't hide the comments anymore :(\nr+\n. all good it seems, :shipit: !\n. sure. I'll give it a few more tries, because it might be hiding something else, and it's the only symptom visible. I won't spend too much time on it though ;)\n. I can't find when it started failing though, when going through the travis build archive. Do you have a clue? It was before the 12 of august, from what I can tell, but not sure how long before.\n. I believe I have found a solution. Not sure why it's working though ;)\n@leplatrem r?\n. @leplatrem r?\n. @leplatrem better like that? https://github.com/Kinto/kinto/pull/841/files#diff-73e8dd09932ff9ff7ea1678c7a44fc39R333\n. It seems this also happens on other queries: we receive the expected status code... but on the pre-flight request instead of having a 200 on the pre-flight, and then the status code on the request itself.\nEg (note that this should return a 404 because it's asking for collectionss instead of collections):\ncurl 'https://kinto.dev.mozaws.net/v1/buckets/default/collectionss/test-items/records' -X OPTIONS -H 'Host: kinto.dev.mozaws.net' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:50.0) Gecko/20100101 Firefox/50.0' -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8' -H 'Accept-Language: fr,fr-FR;q=0.8,en-US;q=0.5,en;q=0.3' --compressed -H 'Access-Control-Request-Method: GET' -H 'Access-Control-Request-Headers: authorization' -H 'Origin: http://localhost:8000' -H 'Connection: keep-alive' -H 'Cache-Control: max-age=0' --verbose\n. I don't see if there's any use case that would need both configured, indeed. Maybe we could add a note to the documentation about this limitation, and revisit this in the future if needed?. > {\"id\": \"email@address.tld\", \"password\": \"bcrypt_key\", \"activated\": false}\n\nWith the bcrypt_key being the generated password for activation.\nTo activate an account we would use:\nhttp POST /accounts/ password=\"newpassword\" --auth \":activation_key\"\n\nI was wondering about this: it means there's no way to ask for a username AND password on account creation, which is a somewhat widespread use case.\nWould it make sense to instead have the activation key stored in a activation-key field, which, if present, means the account hasn't been activated yet?\nThis way you'd create the account as usual, and the activation_key field would be automatically generated and added to the record. POSTing the activation key to /accounts/<email>/validate would then remove the activation-key field from the user record, activating it.\nA remaining question is: how do we deal with the email? If we want a simple link, then we need to validate the account using a simple GET (which means not providing a new password, which means using the alternate method using a validate endpoint). I believe this wouldn't be a good practice (applying some data change on a GET request).\nWe could also imagine having an optional activation-form-url field in the user record. If this field is provided when creating the user, GETing the /accounts/<email>/validate/<activation key>/ endpoint (with an anonymous user) would redirect to the activation-form-url/<activation key> url, where a custom form could be displayed (allowing for @Natim method using the \"change password\" procedure).. How about that: when the \"account validation\" option is enabled, it requires an extra activation-form-url field to be added to the user.\nWhen the user is created, the activation key is appended to this field, and a mail is sent with the content of this field.\nTo activate the user, this activation key needs to be POSTed to the /accounts/<email>/validate endpoint, which will remove the activation-form-url field from the user record.\nEg:\n1/ echo '{\"data\": {\"password\": \"azerty123\", \"activation-form-url\": \"https://example.com/validate/\"}}' | http PUT http://localhost:8888/v1/accounts/foo@bar.com\n2/ user record is created (user is not active):\njson\n{\"data\": {\n  \"password\": \"azerty123\",\n  \"activation-form-url\": \"https://example.com/validate/123456789abc\"\n}}\n3/ an email is sent with the link https://example.com/validate/123456789abc, following it leads to a custom form that will POST the activation key to kinto\n4/ http POST http://localhost:8888/v1/accounts/foo@bar.com/validate/ activation_key=\"123456789abc\"\n5/ user record is modified (user is active):\njson\n{\"data\": {\n  \"password\": \"azerty123\"\n}}\nHow does that sound? It does feel a bit brittle and bespoke, not sure that API makes sense...\nOther paths to explore:\n- having the activation form url set in the settings (but this means there's only one of those URLs per kinto instance, which might be a limitation to some use cases)\n- go back to @natim's proposition: use the \"change password\" procedure if we believe it's ok to not create a user with a password (and ask the user for the password later on, on the activation form). In that case, the \"temporary/activation\" password is appended to the activation form url link sent by mail.. I just realized: @Natim we can't use the password as the activation key, as it's stored hashed in the record, not in plain text.. How do you pass the activation key (the password) to the user (to the custom validation form)?. and if the user loses the mail or whatever, there's no way to recreate the link? What happens then, the username is \"lost\" to everybody?. Implementation question: is there a way to specify a different resource schema given the settings?\nI'd like a different resource schema for the Account class if the 'account activation' option is enabled in the settings, is that possible?. I've started a WIP in https://github.com/Kinto/kinto/compare/master...magopian:1973-account-validation?expand=1\n\nIt would require pyramid_mailer (or Kinto emailer?) to be installed though.\n\n@leplatrem I believe kinto emailer wouldn't work here out of the box because it's missing:\n1/ a way to send to the user id (the list of recipients can only be an email address or a group URI, it's not accepting a placeholder like {id}\n2/ a way to use random fields as placeholders in the template (in our case the activation-form-url and activation-key fields)\nSo either I can update the kinto-emailer plugin to add those modifications, or use the pyramid_mailer.\nThoughts?. > At first, I had trouble to understand what this activation-form-url was made for, but from what I understand, it's purpose is to add a link in the validation email that is sent to the user.\n@almet the idea (discussed in #1973) is that modifying the user record should not be done with a GET, but with a POST (or PATCH). So the activation-form-url is the link to the WebApp, which should display a proper form asking the user to confirm that they want to enable/activate/validate the account (probably a simple \"call to action\" button that will POST to the validate endpoint).\nThe WebApp should do this POST asynchronously, in the background (everything kinto related should be done this way in a WebApp I believe), so I'm not sure we need a redirection url.\nI'm not arguing against the GET and redirection url though ;). > Why displaying a form if the user clicks on the link already? The Webapp could do the POST directly, saving an extra click, and staying RESTful. If we decide to go this way, we could have a default webapp shipped direclty with kinto-accounts, which will do the POST on behalf of the user, and letting the ability to the developer to specify a different webapp to use.\nIf we're comfortable with modifying a record without a user explicit action (auto-POSTing a form), I'd be ok with going all in and changing the validate endpoint to accept a simple GET.\nIf we do that, then there's no more need for an activation-form-url.\nIn any case, the redirect-url can already be set by modifying the link in the email_body_template setting. We could also accept it as a GET or POST parameter on the validate endpoint.\nMaybe we should discuss this in another issue/PR?. Ok, the current work on the user creation and validation should be done now, and properly documented.\nWhat's left to discuss before this can be merged:\n1/ do we want to get rid of the activation-form-url in favor of validating a user using a simple GET? (see https://github.com/Kinto/kinto/pull/1982#issuecomment-456316544)\n2/ does it make sense to merge this PR as is, without the \"reset password\" functionality, which could be discussed in another issue, and implemented in another PR?. After an out-of-band discussion with @Natim we came to the conclusion that this PR could be slightly modified:\n1/ don't require an activation-form-url field\n2/ allow the user creator to provide some email context when POSTing on the /accounts/ endpoint (that will be used in addition to the user record and the activation-key to render the email template from the settings)\n3/ to validate the user, still require a POST on the /accounts/<user id>/validate/<activation key> endpoint, through whatever means the user creator deems fit (it could be through a form, at a URL that they have provided in the email context in 2/). Here also allow the user creator to provide some email context (to render the \"user successfully activated\" email in 4/)\n4/ when the user is validated, send another mail to confirm its activation. Wow, such long thread.\nHere's a plan:\n1/ I'll continue working on this PR to implement the modifications suggested in https://github.com/Kinto/kinto/pull/1982#issuecomment-456539599\n2/ I'll implement the reset password feature\nOnce this is done, we can decide if it's good enough to land.\nRegarding the \"sample webapp that kinto should provide\": let's discuss this in another issue, I'd like to not delay the landing of this functionality for too long. We can still improve in the future if we want (eg: also allowing a GET to validate an endpoint, providing redirect URL, providing a sample webapp, ...).. I believe the PR as is is good to review on the user creation and validation side. I'm now going to implement the \"reset password\" functionality.. I believe this is now complete (with the password reset) and ready to review.. > Ok the creation doesn't have a CORS issue but the validation has got one.\nI'm not sure why this would happen, do you have an idea? Is there something specific to do when adding the service?\n\nMy first issue was that I had a smtplib connection error.\n\nI added a commit with some documentation on the configuration of pyramid_mailer.\n\nIs there a way to add it to the heartbeat part to make sure emailing is correctly configured?\n\nI'll have a look at how to do that. Ok folks, I hope I have addressed all your comments and reviews, but one thing: the heartbeat request. I've seen @natim PR and would love that they merge it. In any case, I'd love this PR to land as is, and maybe in the future add the heartbeat.\nThere's also this comment I'm not sure how to deal with it.\nWhat do you think @natim @leplatrem @almet? Anything else I'm missing?. Quick note: it seems the + character (which can be present in an email address) is not allowed in the ID. Maybe we should fix that?\n```\n$ echo '{\"data\": {\"id\": \"bob+test@example.com\", \"password\": \"321\"}}' | http POST http://localhost:8888/v1/accounts\nHTTP/1.1 400 Bad Request\nAccess-Control-Expose-Headers: Alert, Backoff, Content-Length, Retry-After\nContent-Length: 167\nContent-Type: application/json\nDate: Tue, 12 Feb 2019 11:03:13 GMT\nServer: waitress\nX-Content-Type-Options: nosniff\n{\n    \"code\": 400,\n    \"details\": [\n        {\n            \"description\": \"Invalid object id\",\n            \"location\": \"path\",\n            \"name\": null\n        }\n    ],\n    \"errno\": 107,\n    \"error\": \"Invalid parameters\",\n    \"message\": \"path: Invalid object id\"\n}\n``. I believe I've addressed all your comments @leplatrem please let me know if I missed anything (in particular, are you happy with the way the docs are organized now?). Whenever a user creates or modifies a record, thewritepermission is automatically added to the record's permission. So unless you create a new random user for each creation (what I'm doing right now for the newsletter registration, but which requires enabling unlimited \"account creation\" using thebasicauth` policy), the user used to create the records will have access to all the records created.\nIs that clearer @Natim ?. I was going to create a plugin for that feature, not modify kinto itself obviously.\nAs I said above:\n\nAs a heads up: the same \"newsletter\" use case could be fixed by having finer grained permissions (eg a \"read-only\" permission that would not give read access to the owner/creator).\n\nWhich is probably the best solution. It might be a lot more involved and a lot more work though, so I might spend some time on the \"newsletter\" plugin in the meanwhile, I'll see.\nClosing this now.. the README is also displayed on the first page of the github repo. It's also used as the pypi page, I believe\n. wow, isn't that needed? Weird, can you confirm @Natim @leplatrem @ametaireau @n1k0 \n. I'm extra polite ;)\n. What do you mean? I took this line from http://kinto.readthedocs.org/en/latest/contributing.html#pull-request-guidelines\n. ah, sorry, I thought you meant I should update the contributing.html documentation file ;) Thanks for the rewording advice, will do that straight away\n. ah, you're right ;)\n. Add a link to cliquet?\n. typo: no \"is\"\n. typo: no \"is\"\n. Add links to cornice and pyramid?\n. Do you plan on adding \"comments\" like you did below for the sequence diagrams? Btw, are those \"comments\" visible somewhere in the final page (in the \"alt\" of the image?)\n. Did you want a <bucket id> here instead of <>?\n. good catch for the collection-post instead of collection-put here ;)\n. Same here, did you want to have <bucket id> instead of <>?\n. ah, of course, I understand now, thanks ;)\n. nit: don't you use the better/faster/stronger .format for string interpolation?\n. Changes in this file aren't related to the PR, are they? You took the opportunity to change the group deletion to using the subscriber too?\n. Should it be reworded to \"Use tools and libraries like Kinto.js that help encrypt your data\"?\n. Or maybe \"Use tools and libraries, like Kinto.js and its remote transformers that make encrypting your data a breeze\"?\n. The very first target in a Makefile is the default target, so help should be the default one here.\n. Yes it does because Cliquet's version isn't pinned. I've double checked by running this command, and it does indeed upgrade all the dependencies that don't have pinned versions.\n. The beginning of this sentence is weird, did you mean something like \"Since there might be some database schema changes, ...\" ?\n. did you mean to write 403 instead of 413?\n. Do you like ending comments with a .?\nI'm not sure why, but this comment sounds a bit confusing to me. Maybe something like\nThe create permission object id is the one for the plural endpoint.?\n. For safe creations, the user needs a create permission (See Kinto/kinto#792).\n. do you want to save those headers on the class so you can simply use self.bob_if_none_match_headers?\n. there's an extra space in front of :ref: that makes the whole cell be displayed as a dt/dl (which displays the text as bold).\n. Also, the api-utilities-version tag is missing from the utilities.rst file (for the very last section iiuc), so the docs don't build.\n. Maybe test the full response?\nassert response.json == \"{'version': '0.8.1'}\"\nThis way, if we have some other code in the future that overrides the version, this test will fail ;)\n. I would highly recommend avoiding writing files (and even more if the files are in \"non test locations\") during a test. This means that the test will overwrite the local version.json file (and the teardown will remove it anyway).\nHow about using mock instead?\n. I would rather make use of self.addCleanup when needed (as you did with the second test), because running this will remove any local version.json file.\n. It would make sense to have this in the setUp too (in case some other parts of the code are exercised before, and thus the memoization already happened).\n. Maybe test the full response?\nassert response.json == \"{'foo': 'lala'}\"\n. Should this only be raised if statsd is configured, as explained in the docs above?\n. How do you like the \"simple assignment before if\" instead? Eg\npython\nlistener = on_resource_changed\nif config.registry.statsd:\n    key = 'plugins.history'\n    listener = config.registry.statsd.timer(key)(on_resource_changed)\nI know some people prefer this, some people despise it ;)\n. Maybe a test that makes sure that the client instantiation doesn't raise if the statsd is not configured and not installed, and neither if statsd is configured and installed?\n. oh, right, it makes sense now ;)\n. But we also need it in the tearDown don't we? So the memoization doesn't stay around for following tests? Or are you going to call self.addCleanup or something?\n. \ud83d\udc4d \n. i'm not saying you should use that (it depends on wether you want conciseness or code coherence), but just so you know, with pytest you can use simple asserts\nassert self.config.registry.statsd == self.mocked.return_value\n. same here, you could do something like assert not self.mock.count.called\n. Do you want to add a note about the fact that GETing the list of records will return an empty list (and not a 403) if the user doesn't have the read permission on the collection, and has not created any records yet? (as discussed in the issue #803)\n. I thought one could only see the list of his own created entries, or is that only for records? Is it expected that Bob can see this collection, while he only has the \"create\" permission on collections, and the 'barley' collection has been created by Alice?\n. Sure, the tests and the code are there, but how was wondering if you wanted to add a note to the changelog about that?\n. somehow this doesn't sound very good... maybe reword to \"if the user does not have the permission to write\"?\n. Why change this?. is this really a \"bug fix\"?. Do you want to add note explaining that http://localhost:3000 is the login page/single page app?. typo: stores. typo: missing \"it\" in Note that it will become.... At this point Kinto should be properly configured?. errr... those are not the debug messages you're looking for. Haha, I just realized while taking my shower: storing this activation key in the account means the user will get it back as a response to the POST. And will thus be able to POST to the validate endpoint without needing the email. Which defeats the whole purpose of validating the email.\nSo this activation-key has to be used straight away while sending the email, but not stored!\nAlso, I want to be paid overtime.. This validation_email_regexp is only used on line 143, which is only in case of a user creation, so no, the userid shouldn't be rejected.. Or we could generate the activation-key by hashing the record with the server's secret key, which means it could be re-generated when needed (when checking the validation key on the validate endpoint, or if the activation link needs to be sent again).. I'll add a test to make sure an account created before enabling the account validation can still authenticate.. What i see from the code in kinto/plugins/accounts/authentication.py is that we're using the server secret to get the cache_key. Could we use the exact same technique with the user record (and not only the username) to generate the activation key?\nI don't understand why we would have to rotate the secret key? Is it because the cache key is not accessible to the end user, but the activation key is, and would thus allow attackers to get enough activation keys to infer the secret key?. I've implemented your suggestion @Natim storing the activation key in the cache, let me know what you think ;)\nhttps://github.com/Kinto/kinto/pull/1982/commits/9dd642ebb038497215dbc0dce7f499aae604d14a. Quick note here: the validation and the reset-password endpoint (services) are available, even if the account validation option isn't enabled in the settings. However, they would not work properly. I'm not sure how to conditionally add a Service?. Indeed you can. What do you recommend? Adding a timer to only resend a mail (and overwrite the reset password) every 30 minutes or something?. I'll add a boolean for validation-enabled (I don't think it's relevant to have a reset-password-enabled boolean as it's tied to the account validation).. There's a link to the settings section a few lines above (line 306 in this div). In the settings section, I moved the \"email configuration\" closer to the beginning of the section instead of the very bottom of it.. @leplatrem where can I find this resource_name? Should I somehow use the \"private\" utility kinto.authorization._resource_endpoint?. I wanted to prevent modifying anything else than the password, and also we don't use the content of the password field in this piece of the code.. It seems it's obj :P. It's done now ;). that's an \"additional restriction\", it doesn't take over/replace what's declared in https://github.com/Kinto/kinto/blob/master/kinto/plugins/accounts/views.py#L33 (if that's the root cause of this issue, not sure yet, I'm investigating). I don't think it's the same use case: in one case (no account validation) you want to allow a few set of characters, in the other case you might want to restrict emails to a given sub-domain.. I pushed a fix. I'll remove it, @Natim added it to debug some test failure that needed some more context.. I believe I forgot to add a return value here, good catch ;). I have no idea how/why this worked... I'll investigate. Ok so https://docs.pylonsproject.org/projects/pyramid/en/latest/api/authentication.html#pyramid.authentication.BasicAuthAuthenticationPolicy says that the function is expected to return either None or a list of principals. In our case (even before this PR) the function was only return None or True, and it was working as expected... because it seems everything is based on the cached password (which must be checked elsewhere).\nIn this PR the reset_password_flow value wasn't used/returned, and so the account_check function was returning None, which worked \"correctly\" because what really matter is the cache.\nWhat do you think should be done here? I'm going to \"fix\" the problem by returning the reset_password_flow function value even though it's useless in our case, but I guess this should be properly fixed (or not? maybe just commented?) in another issue/PR.. I'll add the KeyError. Oh wait, I understood the opposite from one of your previous review, sorry about that will move it back to API. ok, leaving. ",
    "n1k0": "Right. Uninstalled cliquet, reinstalled the whole thing, now the bug is a little different \u2014 though less critical (see updated title and description).\n. I vote for this; imho uuids are opaque, fast when properly indexed, well known and tooled. I could see people wanting us to support key-value-like collections, eg. getting a setting by its name which would be the primary key, though I'm not really sure we want to support/encourage this approach (eg. setting names are much more easily guessable).\nI'm not totally on the fence though. Thoughts?\n. Yes, probably. \n. Side note, it's a little strange the PR being merged while the tasks list not being fully completed.\n. I get that; maybe the post-release bits should be handled in Trello?\n. Looks okay to me. Lemme checkout the branch and tell you.\n. I got this error after switching to that branch, updating deps and running make serve:\n(.venv)\uf8ff niko@n1k0-moz ~/Sites/kinto (126-fix-option-401)\n$ make serve\n/Users/niko/Sites/kinto/.venv/bin/cliquet --ini config/kinto.ini migrate\nTraceback (most recent call last):\n  File \"/Users/niko/Sites/kinto/.venv/bin/cliquet\", line 9, in <module>\n    load_entry_point('cliquet==2.2.2.dev0', 'console_scripts', 'cliquet')()\n  File \"/Users/niko/Sites/kinto/.venv/lib/python2.7/site-packages/cliquet/scripts/cliquet.py\", line 48, in main\n    env = bootstrap(args.ini_file)\n  File \"/Users/niko/Sites/kinto/.venv/lib/python2.7/site-packages/pyramid/paster.py\", line 131, in bootstrap\n    app = get_app(config_uri, options=options)\n  File \"/Users/niko/Sites/kinto/.venv/lib/python2.7/site-packages/pyramid/paster.py\", line 31, in get_app\n    global_conf=options)\n  File \"/Users/niko/Sites/kinto/.venv/lib/python2.7/site-packages/paste/deploy/loadwsgi.py\", line 247, in loadapp\n    return loadobj(APP, uri, name=name, **kw)\n  File \"/Users/niko/Sites/kinto/.venv/lib/python2.7/site-packages/paste/deploy/loadwsgi.py\", line 271, in loadobj\n    global_conf=global_conf)\n  File \"/Users/niko/Sites/kinto/.venv/lib/python2.7/site-packages/paste/deploy/loadwsgi.py\", line 296, in loadcontext\n    global_conf=global_conf)\n  File \"/Users/niko/Sites/kinto/.venv/lib/python2.7/site-packages/paste/deploy/loadwsgi.py\", line 320, in _loadconfig\n    return loader.get_context(object_type, name, global_conf)\n  File \"/Users/niko/Sites/kinto/.venv/lib/python2.7/site-packages/paste/deploy/loadwsgi.py\", line 454, in get_context\n    section)\n  File \"/Users/niko/Sites/kinto/.venv/lib/python2.7/site-packages/paste/deploy/loadwsgi.py\", line 476, in _context_from_use\n    object_type, name=use, global_conf=global_conf)\n  File \"/Users/niko/Sites/kinto/.venv/lib/python2.7/site-packages/paste/deploy/loadwsgi.py\", line 406, in get_context\n    global_conf=global_conf)\n  File \"/Users/niko/Sites/kinto/.venv/lib/python2.7/site-packages/paste/deploy/loadwsgi.py\", line 296, in loadcontext\n    global_conf=global_conf)\n  File \"/Users/niko/Sites/kinto/.venv/lib/python2.7/site-packages/paste/deploy/loadwsgi.py\", line 328, in _loadegg\n    return loader.get_context(object_type, name, global_conf)\n  File \"/Users/niko/Sites/kinto/.venv/lib/python2.7/site-packages/paste/deploy/loadwsgi.py\", line 620, in get_context\n    object_type, name=name)\n  File \"/Users/niko/Sites/kinto/.venv/lib/python2.7/site-packages/paste/deploy/loadwsgi.py\", line 640, in find_egg_entry_point\n    pkg_resources.require(self.spec)\n  File \"/Users/niko/Sites/kinto/.venv/lib/python2.7/site-packages/pkg_resources/__init__.py\", line 952, in require\n    needed = self.resolve(parse_requirements(requirements))\n  File \"/Users/niko/Sites/kinto/.venv/lib/python2.7/site-packages/pkg_resources/__init__.py\", line 844, in resolve\n    raise VersionConflict(dist, req).with_context(dependent_req)\npkg_resources.ContextualVersionConflict: (cliquet 2.2.2.dev0 (/Users/niko/Sites/kinto/.venv/lib/python2.7/site-packages), Requirement.parse('cliquet==2.2.1'), set(['kinto']))\nmake: *** [migrate] Error 1\nHints?\n. Thanks, it worked. Side remark: could this be automated in some way?\nAs for the patch, it didn't fix my issue; I'm still getting a 401 on OPTIONS. Here's the curl equivalent cal made by the browser:\ncurl 'https://kinto.dev.mozaws.net/v1/buckets/default/collections/tasks/records' -X OPTIONS -H 'Host: kinto.dev.mozaws.net' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.10; rv:41.0) Gecko/20100101 Firefox/41.0' -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8' -H 'Accept-Language: en-US,en;q=0.7,fr-FR;q=0.3' --compressed -H 'DNT: 1' -H 'Origin: http://0.0.0.0:8080' -H 'Access-Control-Request-Method: GET' -H 'Access-Control-Request-Headers: authorization,content-type' -H 'Connection: keep-alive'\nReceived response headers are:\nHTTP/1.1 401 Unauthorized\nContent-Type: application/json; charset=UTF-8\nDate: Wed, 08 Jul 2015 15:09:02 GMT\nServer: nginx/1.4.6 (Ubuntu)\nWWW-Authenticate: Bearer realm=\"Realm\"\nBasic realm=\"Realm\"\nContent-Length: 110\nConnection: keep-alive\nNo response body, obviously.\nFor safety, I dropped my .venv, recreated one and reinstalled the whole thing, with the very same results. I feel like I'm missing smthg, but what?\n. > I have updated my test but if you want to try my branch you should not us the kinto.dev instance.\n\n. (r+)\n. I don't have a clue how to review this accurately. Maybe @leplatrem or @ametaireau are better fits here?\n. Still fails for me:\n- on the 1.2.1 tag: https://pastebin.mozilla.org/8838963\n- on the patch branch: https://pastebin.mozilla.org/8838971\n. That fixed it! r+\n. Note: this one was hard to spot as the error is well hidden deep within collapsed sections in travis build reports, eg. this one.\n. Look at the script; I'm just checking out the 1.3.1 tag and make serve. Shouldn't installing the specific cliquet version a given Kinto version requires be handled automatically?\n. > We should not use install-dev for this tests.\nSo could you come with a dedicated Make command I could simply use for tests?\n. I appreciate how it improves the natural navigation flow. For the menu on the homepage, don't waste energy on it. r+wc\n. Nit: Could we left-indent a little texts next to logos? Using CSS not SVG, obviously.\nOther than that, LGTM.\n. https://discordapp.com/ ;)\n. > What do you think about having the Kinto.js client exposed directly in the Kinto server documentation?\nThe thing is Kinto.js doesn't cover the whole Kinto API, and we should definitely keep the lower level HTTP req/rep examples.\nOf course, linking to the client docs wherever applicable would be useful (eg. synchronization, backoff, etc.)\n. First two passes done, looks good. I now need to build the docs and browse them as a real docs reader.\n. r=wc, nits are your call.\n. > The history is actually a resource whose records are the notifications payloads\nJust to be sure, would that mean we could access the resource data itself? Ideally it would be nice to have the previous data (before the action is executed) and the new data (after the action is executed). Maybe this could be rendered conditionally (eg. with ?full=true) to avoid large entries to bloat the output.\n(and yeah this would look a lot like revision handling haha)\n. > The only concern is about permissions: we have to be sure that those who can read the history would have been allowed to read the affected records.\nI wonder how silly would be to create a new dedicated permission for that?\n. Like a superadmin permission, explicitly allowing people having that permission set being able to browse everything in the history they weren't originally allowed to. Just having written that scared me so I'm not super sure if it's a good idea.\n. > Or we can give read permission to the history collection as we usually do for other collections.\nYeah, much simpler, let's do that. We can always heavily document that giving read permission to the history collection is something possibly dangerous, harmful, handle with care, etc. \nWe should probably ensure that no user can write to that collection as well (writes should always be performed by the system). \n. > @n1k0 still had a similar bug today on /buckets we need to add the Vary header.\nNote that it's not only for /buckets but for all urls shared by different authenticated users like /buckets/default and / where the user property varies depending on the auth status as well.\n. After discussing it on IRC, it would be good to have the default bucket listed in a user section, along the user id:\njson\n{\n    \"documentation\": \"https://kinto.readthedocs.org/\", \n    \"hello\": \"kinto\", \n    \"settings\": {\n        \"batch_max_requests\": 25, \n        \"cliquet.batch_max_requests\": 25\n    }, \n    \"url\": \"http://localhost:8888/v1/\", \n    \"user\": {\n        \"id\": \"basicauth:71c5e3dd315eaf28ec38dbba4e11e67ec34892c7f67c6264506957dc92ae6481\",\n        \"bucket\": \"b4f6b878-44c5-dbdc-25e0-66e36e1673d0\"\n    },\n    \"version\": \"1.7.0.dev0\"\n}\nThis is likely to break older clients though; thoughts?\n. Looks good, r+\n. Awesome. r+wc\n. :+1: \n. Makes me think the static web admin webpage will have to load its default settings from a json file if we want it to be ready to consume the running server API. \n. LGTM. Much clearer.\n. Yeah, this looks good.\n. r+, with a side note; we should probably create a proper wiki homepage listing the different topics covered there.\n. Looks good!\n. LGTM\n. Very clear and insightful, answers a bunch of questions I had; r+.\n. > However, I believe the response should be an empty list rather than a 403 for the list of buckets.\nI second that.\n. I'm raising this up again because while implementing the new full-http kinto-admin I need to browse the list of available buckets for users as soon as they authenticate.\nRight now the fix in kinto-admin would be to perform a first unnecessary http request to buckets/default, just in order to allow browsing the list of buckets... \n. Sounds good!\n. Sorry to ask, but is there any ETA for this?\n. o/\n. Right, we can probably close this issue if it doesn't happen to you, so it's related to my messed up env.\nFor the --version option to the kinto executable, I think it would be a worthy addition. Should I file a new issue for this?\n. Filed #457. Closing this one.\n. Ok never mind.\n. That'd be awesome to have if you ask me.\n. r+\n. Note: kinto-client v0.4.1 has been released with an appropriate client-side fix.\n- npm package: https://www.npmjs.com/package/kinto-client\n- release notes: https://github.com/Kinto/kinto-client/releases/tag/v0.4.1\n. Well, kinto-client now performs PUT requests only for creations because of this limitation, though there are stil legit use cases for allowing POST methinks. This should be reopened, but I'm not 100% sure so pinging @leplatrem here. \n. :+1: (please) \n. I'm lacking proper context when it comes to the amount of performance impact this has, though importing pip only when necessary sounds always good to get anyway :)\nr+ \n. To be entirely honest I didn't remember there was a js tutorial in these docs :)\nNow I see it, it seems a little redundant with what kinto-client offers in terms of HTTP API support. kinto-client probably covers most developer needs when it comes to consuming the Kinto HTTP API, and as it's itself a dependency of Kinto.js... we're pretty much safe here I think.\nI'd probably add a link to kinto-client and start thinking about how could look more generic docs for implementing clients (maybe the existing docs are already good enough, I didn't check).\n. Yep!\n. Looks good though many mocks everywhere; I suppose we don't have many alternative choices with argparse?\n. r+!\n. Not very constructive I know, but: Wow. :)\n. >  I don't understand what you are trying to do with this request\nNothing, it was basically a mistake. Though this is a way to explicitly crash the server, which is probably something we don't really want to expose to consumers?\nFeel free to close if this isn't important.\n. > > Maybe we need a new enumerate permission type?\n\n\nWhat would be the difference with read?\n\n\nBasically allowing to list an entry id but not to access its data.\n\nThe only detail is that we would not be able to obtain attributes of parent object for which we have no read permission.\n\nWell, couldn't we easily infer the nested structure here? If we know the url for a collection we have access to, we know the bucket name it's attached to; so we can build the tree. Am I missing smthg?\nNote that we could totally avoid listing the permissions in this tree nodes if we're not allowed to access them.\nEdit: if that's really complicated I agree having at least the list of available resources for the user would be still tremendously useful ;)\n. Looks nice, though I'd limit this to buckets and collections, and maybe add an option for records with a big warning regarding perfs in the docs :)\n. I love it!\n. AFAICR my issue back in the days was that we were receiving a 200 on the flush endpoint even the operation was not finished. tbh I never experienced any trouble with the flush endpoint since I've refactored the test setup strategy in kinto-node-test-server, so it's probably fine to mark this as obsolete.\n. Interesting read & discussion https://bugzilla.mozilla.org/show_bug.cgi?id=269303\nIn this thread I feel we can replace the term \"Cookie\" with \"Authorization\". Excerpts:\n\nAfterall, if the entity depends on the value of the Cookie header, then you really have two (or more) different entities.\nThis is another reason why entity-tags are better than last-modified time stamps\nfor validating cache entries.  If you use last-modified as the cache validator,\nthen you are saying essentially that the URL is enough to uniquely identify the\ncontent.\n\nThis is something that I've been wondering and asking for a while, so here it is again: is there anything preventing us to forge authentication-aware ETag values? eg \"userid-1234567890\" instead of just \"1234567890\".\n. feedback+++\n. >  I suggest that we wait for the implementation to be done in kinto-admin to enable it officially\nwfm :+1: \n. First feedback: we need to enable support for the OPTIONS verb for the /permissions endpoint:\n```\n\u279c  kinto-admin git:(master) \u2717 http OPTIONS :8888/v1/permissions -a toto:toto\nHTTP/1.1 405 Method Not Allowed\nAllow: GET, HEAD\nContent-Length: 102\nContent-Type: application/json; charset=UTF-8\nDate: Tue, 28 Jun 2016 09:06:33 GMT\nServer: waitress\n{\n    \"code\": 405, \n    \"errno\": 115, \n    \"error\": \"Method Not Allowed\", \n    \"message\": \"Method not allowed on this endpoint.\"\n}\n```\n. Successful experiment achieved in kinto-admin here https://github.com/Kinto/kinto-admin/pull/161\n. \\o/\n. +1, too much confusion raised lately about what the kinto protocol precisely is (some people even mentioned they though we exposed a kinto:// uri scheme :D)\n+1 for API.\n. Indeed that's nice to know ;) r+\n. Definitely!\n. \n. Why did they use a serif font for that button? Mystery. \nr+\n. r+ r+ r+ r+ r+ r+ r+ r+ r+ r+ r+ \n. r+\n. \n. > Ahem\n?\n. Ah, woops indeed :D\n. LGTM, I'd tend to say r+ though I'd feel slightly more confident doing so with a go from @leplatrem :)\n. This is brilliant and will greatly improve the developer experience :)\n. Okay looks good to me, r+\n. LGTM :)\n. I think it's a very good idea \ud83d\udc4d \n. Much better! LGTM\n. FYI kinto-admin v1.4.1 has been released.\n. Closing in favor of #886\n. The admin must be built exposing a KINTO_ADMIN_VERSION env var, eg. \n$ KINTO_ADMIN_VERSION=1.8.0 npm run build. Do we want comments attached to single entries, or would we prefer a general comment when submitting changes for review (like the description field when submitting a github PR)?. Well, this is also an issue for Kinto as it impacts the admin plugin and the way Kinto server users may extend the admin plugin capabilities, eg. through plugins with custom widgets. I'm reopening so we can keep track of progress on this.. If I'm assigned to this it'll probably take a long time before the feature sees the light of the day :) but why not.. Just _at would work for me. We discussed this with @Natim and discarded the idea, but the more I think about it, the more I'd be very happy with just records/id?_at=<last_modified>; that would be more intuitive and consistent with other filters. I get that altering core endpoints/features with plugin stuff might sound odd and be harder to maintain though.\nEdit: well, not so intuitive if you consider mixing qs params like _at=123&_before=123 or silly crap like that. Oh well.. > If _at is just for records you can't mix it with _before\nWell that's the thing, we started with records but we'll actually want the same for collections.\nEdit: ok, I'm so confused with all this that I'm just gonna get some sleep instead.. > I've got another idea: we do it on the client side :innocent:\nI said I needed some sleep \ud83d\ude01. > 'cuz @n1k0 mentioned use-cases like initial synchronization or replication, but appart from building a diff from a list of changes I don't have any use-case for this endpoint anyway :D\nOK fair enough, no valid identified use cases apart from what I should be working on. So we should probably give a shot at a client side implementation of the feature in kinto-http.js. You mentioned it was trivial, while I feel some complexity here, so my question is, do you want to pair on this? \ud83d\ude0a. > Yes, at least give it a try :tada:\nhttps://github.com/Kinto/kinto-http.js/pull/161. From the error it seems we're not splitting dotted values to retrieve the matching nested dict, hence the uncaught key error. . Would something like this be enough?\n```diff\ndiff --git a/kinto/core/resource/init.py b/kinto/core/resource/init.py\nindex a4f9c89..237c6fc 100644\n--- a/kinto/core/resource/init.py\n+++ b/kinto/core/resource/init.py\n@@ -1087,7 +1087,7 @@ class UserResource:\n         }\n     for field, _ in sorting:\n\n\ntoken['last_record'][field] = last_record[field]\ntoken['last_record'][field] = dict_subset(last_record, [field]) return encode64(json.dumps(token))\n\n```\n\n\nEdit: no, dict_subset doesn't do what we want it seems.. Fix proposal sent in #1116.. @natim I did my best in https://github.com/Kinto/kinto/pull/1116/commits/8b0ea7e5179013b84861e5b5835fa71243c27b08 and https://github.com/Kinto/kinto/pull/1116/commits/7c8bfbcaf2ae4d19487e2679734c47536f41ef19 to come with something better.. So I'm gonna go crazy and ask for a review. r=? @Natim @leplatrem. It seems like permissions entries don't have a last_modified property, which actually makes sense. Maybe that's an erroneous use of the API by the client, but still, this should not crash the server.. I confirm the server doesn't crash and paginates properly when the _sort parameter on a non existent property is omitted.. Yeah looks a lot like it's the same issue. FWIW the fix in kinto-http.js looks like this https://github.com/Kinto/kinto-http.js/pull/170 (brr)\nEdit: I mean this\n. I see. Well I'd say if we keep getting regularly confused with this behavior ourselves, it may be a bad sign of some sort.\nOkay let me just say that RTFM is the appropriate fix. . FWIW, Travis build failed with this:\n\npyramid.httpexceptions.HTTPInsufficientStorage: There was not enough space to save the resource. This error should be gone with latest kinto-http v4.3.2. Thanks for reporting.. Thank you for tackling this, I think it will benefit everyone eventually :+1: . First thing, https://kinto.dev.mozaws.net/v1/admin/ is not reachable to me atm:\n\n\u279c  ~ curl -I https://kinto.dev.mozaws.net/v1/admin/\nHTTP/1.1 503 Service Unavailable: Back-end server is at capacity\nConnection: keep-alive\nAnd I'm using the latest Kinto docker image, as described in https://github.com/Kinto/kinto-portier/issues/10, with the kinto.ini from the issue description. To reproduce, it's probably a good idea to setup kinto locally? . > Any error in the console?\nYes:\n\nFull log:\nindex.js:150 Error compiling schema, function code: var refVal1 = refVal[1]; var validate =  (function  (data, dataPath, parentData, parentDataProperty, rootData) { 'use strict';  var vErrors = null;  var errors = 0;            var errs_1 = errors;    var errs_2 = errors; if ((typeof data !== \"number\" || (data % 1) || data !== data)) {  var err =  { keyword: 'type' , dataPath: (dataPath || '') + \"\" , schemaPath: '#/definitions/nonNegativeInteger/type' , params: { type: 'integer' }  , message: 'should be integer'  } ;  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++;  }  if (typeof data === \"number\") {    if (  data < 0 || data !== data) {  var err =  { keyword: 'minimum' , dataPath: (dataPath || '') + \"\" , schemaPath: '#/definitions/nonNegativeInteger/minimum' , params: { comparison: '>=', limit: 0, exclusive: false }  , message: 'should be >= 0' } ;  if (vErrors === null) vErrors = [err]; else vErrors.push(err); errors++;  }   }  var valid2 = errors === errs_2;   var valid1 = errors === errs_1;   validate.errors = vErrors;  return errors === 0;        }); return validate;\nw @ index.js:150\nn @ resolve.js:54\nS @ index.js:190\ne.exports @ ref.js:21\ne.exports @ validate.js:271\ne.exports @ properties.js:204\ne.exports @ validate.js:347\nw @ index.js:87\nn @ index.js:56\nv @ ajv.js:358\nc @ ajv.js:214\nl @ ajv.js:198\nu @ ajv.js:172\nm @ ajv.js:317\no @ ajv.js:97\nc @ validate.js:197\ne @ Form.js:175\n(anonymous) @ Form.js:90\nr.onSubmit @ Form.js:103\nn @ ReactErrorUtils.js:24\ni @ EventPluginUtils.js:83\ns @ EventPluginUtils.js:106\np @ EventPluginHub.js:41\nm @ EventPluginHub.js:52\nr @ forEachAccumulated.js:22\nprocessEventQueue @ EventPluginHub.js:252\nn @ ReactEventEmitterMixin.js:15\nhandleTopLevel @ ReactEventEmitterMixin.js:25\na @ ReactEventListener.js:70\nperform @ Transaction.js:141\nbatchedUpdates @ ReactDefaultBatchingStrategy.js:60\na @ ReactUpdates.js:95\ndispatchEvent @ ReactEventListener.js:145\nnotifications.js:80 {message: \"Could not authenticate with Kinto Account Auth\"}message: \"Could not authenticate with Kinto Account Auth\"__proto__: Object\ns @ notifications.js:80\n(anonymous) @ session.js:195\nn @ runtime.js:62\n(anonymous) @ runtime.js:296\ne.(anonymous function) @ runtime.js:114\nl @ proc.js:313\nr @ proc.js:389\ng @ proc.js:357\ne.cont @ proc.js:110\nl @ proc.js:323\nr @ proc.js:389\n(anonymous) @ proc.js:500\nr @ scheduler.js:25\ni @ scheduler.js:66\nn @ scheduler.js:39\nx @ proc.js:487\n_ @ proc.js:436\nl @ proc.js:317\nr @ proc.js:389\nPromise.then (async)\nE @ proc.js:451\nC @ proc.js:518\n_ @ proc.js:436\nl @ proc.js:317\ns @ proc.js:272\nw @ proc.js:457\nC @ proc.js:518\n_ @ proc.js:436\nl @ proc.js:317\ns @ proc.js:272\nk @ proc.js:555\n_ @ proc.js:436\nl @ proc.js:317\nr @ proc.js:389\ni @ proc.js:467\nt @ channel.js:85\n(anonymous) @ channel.js:173\n(anonymous) @ channel.js:198\nr @ scheduler.js:25\ni @ scheduler.js:66\nn @ scheduler.js:39\n(anonymous) @ channel.js:197\nt @ channel.js:38\n(anonymous) @ middleware.js:73\n(anonymous) @ bindActionCreators.js:7\nL.onSubmit @ AuthForm.js:609\nr.onSubmit @ Form.js:112\nn @ ReactErrorUtils.js:24\ni @ EventPluginUtils.js:83\ns @ EventPluginUtils.js:106\np @ EventPluginHub.js:41\nm @ EventPluginHub.js:52\nr @ forEachAccumulated.js:22\nprocessEventQueue @ EventPluginHub.js:252\nn @ ReactEventEmitterMixin.js:15\nhandleTopLevel @ ReactEventEmitterMixin.js:25\na @ ReactEventListener.js:70\nperform @ Transaction.js:141\nbatchedUpdates @ ReactDefaultBatchingStrategy.js:60\na @ ReactUpdates.js:95\ndispatchEvent @ ReactEventListener.js:145. In Kinto.js we use \"Publish\".\n\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Kinto/kinto/pull/156/files#r37865468.\n\n\nNicolas\n. Nit: client (singular)\n. Could we imagine linking the logos to appropriate documentation sections?\n. I wonder if we should create new tests for header checks; here for instance we're mixing querystring and headers. Thoughts?\n. It's a little strange to move the easiest way to get started down the menu\u2026\n. Nit: may become mandatory? How about simply are required?\n. Nit: Some indentation might help reading the nested configuration bits here.\n. Nit: uWSGI (here and in other parts of the existing docs)\n. It may be worth adding a comment explaining what uwsgi_params points at.\n. Nit: It could be useful to specify at what time it's flushed, the UTC way.\n. Nit: We may want to describe further how to actually install it, or at least link to external docs providing this information.\n. I'd actually reassert the dependency to python-virtualenv with an external link to its installation procedure.\n. Don't ever link to head directly, use a frozen commit hash from master history, so we're sure it won't be updated at the time users click that link.\n. Question: Is this path cross-platform compatible? Also, I'd naturally expect it to be /var/run.\n. Nit: Always useful to link Docker to the actual project homepage.\n. Also Nit: Python (cap P)\n. This link isn't formated properly it seems:\n\n. Yeah, so I'd move the Tutorials section before the Community one. Actually to me, a natural section ordering would be:\n1. Overview\n2. Concepts\n3. Tutorials\n4. Configuration\n5. Apis\n6. Community (which could be renamed Community and Support)\nThoughts?\n. Also, I'd probably add a note about the fact that a public Moz demo instance is deployed and already installed/configured, so the reader which would actually just want to quickly toy around with the API doesn't mess with the installation procedure.\n. FWIW /run doesn't exist on OSX.\n. \u00b5Nit: Could we indent the <Files> node as well? :3\n. I'd probably list live notifications/sync support for all solutions, mentioning the feature is upcoming through an upcoming plugin for kinto.\n. Ah, that's part of \"Changes stream\" I guess; maybe you could rename it to \"Real-time\" or \"Live updates\"?\n. Yeah, request messages is vague.\n. If we follow semver, adding a feature without breaking BC still implies bumping a minor - which might happen quite often. Are we okay with this?\n. You mean a heading in the docs, right, not a HTTP header?\n. I'd add it's up to clients to ensure they fully support the HTTP API version provided by the server\n. Nit: the JSON response body contains\n. We should add a note that we'll observe semver only for major and minor, not patch.\n. Nit: Adding links to WebSockets and Redis might help newcomers.\n. Nit: s/some//\n. Nit: s/some/an\n. Might be worth filling this section before landing ;)\n. Same remark.\n. s/to to/to\n. +1\n. Yes, thank you! :heart: \n. Note: /me wonders how it could even work before =)\nNit: Maybe we could create another var instead of overriding the existing args one? eg. parsed_args\n. I'm fine with both of your suggestions with a slight preference for the second option where I appreciate being able to always rely on the id property describing the resource id.\nSide remark: I was thinking of parent_id for parent resource identifiers but it might introduce more confusion/complexity than anything else, so nope. \n. If consistency is a priority (and I think it should) I'm okay to follow existing conventions :)\n. huh! does that mean it was always enabled? edit: ok seen asbool\n. The permissions object\n. nit: leftover?\n. No.\n. This is a trick to set the public asset root path to /admin/.\n. When kinto-admin v1.4.1 is out, we need to add \"kinto-admin\": \"1.4.1\" here.\n. We could remove this and a few other items.\n. Lots of exclamation marks. How about dropping the first one?\n. data is plural I think (@glasserc?)\nAlso, i'd probably nuance this slightly more, as I can see application authors wanting to store application data too :) \nWe believe users data belong to them, not to application authors (@glasserc, halp)\n. Nit: We envision self-hosting and genericity? or reusability maybe\n. Should we mention JSON somewhere here? I think this speaks a lot to Web developers.\n. Nit: lose\n. Makes me think of a tagline so I'm putting this here: the backend for your next single page app is already there\n. It's not obvious to neophytes how this makes things more secure and privacy friendly.\nStore encrypted data at a location users can control, ensuring better privacy and security.\n. stored resources? if object is the official terminology, scratch this comment: consistency matters more\n. Linking to these three things would be useful I think.\nAlso s/or/and\n. s/will leverage/leverages\n. The ecosystem is growing and plugins already provide advanced features\n. s/or// I think\n. In French we use_capitalis\u00e9_, which means accumulating work on something generic. I couldn't find a proper equivalent in English...\n. \u00b5Nit: could we decode the body once and for all?. Nit: it feels like we could factor altering and sending the response in a small reused function. It's been a long time I've not been doing any Python but it's odd we need a global here.... As suggested while pairing, even if slightly less efficient I'd rather use a template here.\n```python\nINDEX_TEMPLATE = open(os.path.join(HERE, 'build/index.html'), 'r').read()\nNote: I don't remember how you close a file pointer in one call, if it's even possible\ndef admin_home_view(request):\n    # ...\n    request.response.write(INDEX_TEMPLATE.replace('<script', globalSettings + '<script'))\n    return request.response\n```\nBy the way, it's really odd to mutate request.response and return it; is it actually how it's supposed to be used?. Really depends if we want to prioritize dotted field key names as my implementation does, or if we don't really care. Probably this is mostly matter of properly documenting the behavior we settle on?. If last_value is None it's most probably because an erroneous sorting field key has been provided. Should we error is such a case, or just ignore it as I did?  We could possibly raise a 400 error properly describing the issue to the consumer, which sounds rather good to me. I can work on that if you want.. Also note that without a JSON schema to validate provided parameters against (in which case all fields are inherently optional), the last record from a chunk might or might not have the field matching the provided key set. In such a case, I don't have any solution in mind, sadly.. The default parameter has None as a default value already, which is consistent with the previous implementation. . Woops, misread the place where you've added that comment, you're totally right! Edit: https://github.com/Kinto/kinto/pull/1118. So we don't have that previously available deleted attribute from the tombstone anymore... should we \"merge\" it ? yeah no that'd be super weird, ok. > Adding deleted: true doesn't seem a good idea though :/\nYeah, definitely not a good option. Let's land it that way.. Nit: s/Fix/Prevent maybe?. Except if I've miread the patch, I'd probably add a warning about the fact that now searching for a field string actually containing the * character is now impossible.. Oh!. Ah.. ",
    "vsham20": "@Natim I am working on this\n. Which all requirements are we supposed to add and where? I mean in Readme or any requirements.txt file?\n. @leplatrem Could you help me out here, i am not getting why test cases are failing?\n. @leplatrem https://www.irccloud.com/pastebin/rWSVtOrd/\n. @leplatrem yes, i tried to find the error but i can't find where its going wrong\n. @leplatrem yes I made Change according to your previous comment but it's terminating with import error.\nAnd currently I am not working on this issue as my semester exams are going on.Will continue after exams are over. Sorry :)\n. ",
    "michielbdejong": "I think discovery in FxA is based on BrowserID? So:\n- the user gives their email address me@example.com to a Kinto client\n- the Kinto client retrieves https://example.com/.well-known/browserid\n- if this resource does not exist for example.com, it falls back to BrowserID's secondary identity provider, from there to Mozilla's default FxA instance, and then to Mozilla's default Kinto instance.\nSo I think what a user has to do to self-host and be entirely free from any hard-coded Mozilla URLs, is to become their own primary identity provider for BrowserID, plus FxA, plus Kinto?\nThere is still a difference between remoteStorage and Kinto in that remoteStorage redirects the user to https://remotestorage.io/get/ which lists multiple options for getting an account on a storage provider somewhere, and I think Kinto currently would default silently to Mozilla's instance. So you could insert a page in the UI saying 'You have no Kinto server linked to me@example.com yet, do you want to link Mozilla's server?', and then that would be a point where multiple options could be offered.\nOf course, the user experience is easier when defaulting to Mozilla-hosted is silent. But I think the difference boils down only to whether this is silent or not; in itself, BrowserId already implements decentralized discovery.\n. Right, BrowserID decentralizes identity, but not service discovery, so we still need something like WebFinger.\nSo WebFinger could announce:\n- The URL of the server\n- The API of the server (would be nice to keep it generic, so the same mechanism can be used for announcing Kinto-compatible as well as remoteStorage-compatible, CouchDB-compatible, *-compatible servers)\n- Any available end-points for getting access through BrowserId/FxA\n- Any available end-points for getting access through OAuth2 implicit grant flow\nWebFinger links need a \"rel\" attribute to indicate what they mean. For remoteStorage discovery, we use this: https://tools.ietf.org/html/draft-dejong-remotestorage-05#section-10 - might serve as a basis for something generic enough to also discover servers with <storage_api> == \"kinto-v1\".\nThe remoteStorage spec currently used the \"http://tools.ietf.org/html/rfc6749#section-4.2\" property for announcing the dialog URL for OAuth2 Implicit Grant, but if we want a \"discover the user's storage server of any kind\" mechanism, we can add a longer list of possible auth mechanisms.\n. Here's an illustration showing why using the default bucket is a bad idea: https://michielbdejong.com/kinto-buckets.html\n. Ah you're right, we probably still need that Vary header, bummer. That makes the security model of the default bucket much more complex than the security model without default bucket.\n. Right, that's true.\n. Update on  https://michielbdejong.com/kinto-buckets.html - it was still failing after Cache-Control: no-cache was added to kinto.dev, but that was because there was a bug in my test script (not setting dbPrefix: userid) which is fixed now. So I think for browser cache (and probably also for shared-cache proxies, because they should also revalidate), it's now safe to use the default bucket on kinto.dev. A revalidate will always be triggered, and then Kinto will do two things:\n- check the Authorization header\n- respond with the ETag for the user corresponding to the Authorization header, so the cache knows which cached data to serve, based on that ETag header, and will never serve the wrong data.\nHope I'm right about this description. ;)\n. Created https://michielbdejong.com/kinto-test2.html to illustrate that the current situation with the kinto.dev default bucket looks safe.\n. Looks like it should link to http://kinto.readthedocs.org/en/latest/get-started.html#deploy-an-instance-on-heroku\n. Fixed in  856ec46\n. Fixes #412.\n. Thanks! Continued in #416.\n. timestamp := MAX(local_records['last_modified'])-1 because it may be that two or more changes happened during the same timestamp, and you did not get all of them during the first sync.\nThis is especially relevant if you combine this with _limit. For instance, in FxSync you sometimes see 1000 records with the exact same timestamp, so you shouldn't discard 950 of them after fetching only the first 50.\n. Next-Page response header will only occur if a limit was set\n. This is not the only reason; it's also because it keeps track of the id of the first record of the next page to fetch, not its index in the list. Suppose you had retrieved records a,b,c,d,e in the first batch, and then record b is changed. If you would then do offset=5, you would skip the first 5 records, including record f (because the list now is a,c,d,e,f). The trick is to not do offset=5 but start_at=f.\n. I think the Next-Page system will take care of that; suppose you retrieved z,y,x,w,v, record b changes, and you continue retrieving records u...,d,c,a. On the next sync run, you'll get only the b record that was updated since you started your initial sync run\n. timestamp := MAX(local_records['last_modified']) - 1 (see above)\n. I don't think this is true?\n. What's the advantage of this?\n. But we need inclusive, right? Say the records have been changes at t=1,2,3 in a sequence 11122 22233 and your fetch limit is 5. Then your first page should be _since=0 and the second page should be _since=1 (so that you don't skip the 222 records in the second page).\n. I still think you'll skip records with this strategy unless you can be sure that each record has a unique lastmodified timestamp. As soon as you have 1 local record with a given timestamp, all other remote records with that same timestamp will be ignored, right?\n. ok, I remember now, sorry. So then it's safe for Kinto. We could add a note saying that for Syncto, this constraint is not true, and records will actually get skipped when using this approach (in my test account, I had hundreds of records with identical timestamp, because the FxSync sets the first sync time as the timestamp for pre-existing bookmarks).\n. ",
    "rektide": "WebFinger scares me a little because it seems to imply to me that the workflow would be a user entering their webfinger identity, and getting back the store for that user. If this interpretation is correct, that may be distributed, but it's very 1:1. What happens when I want to Kinto into some group resource, for example a Shared Calendar?\nIf we used something like Host Meta - 4.2 Resource-Specific information, a service could let a user log in with their- say- email, and then query whatever hosts they wanted to see if there were <Link rel=\"application/kinto\" href=\"...\"/>  (for example) resources on any hosts pertinent to that identity-resource. Multiple resources could be returned. And the host could also enumerate site-level resources available, for discovering group resources.\nI suppose each Kinto \"resource\" could just get it's own WebFinger ID. I'll try to find more time to better consider and understand the proposals above, but I see some mirroring of the concerns I have about tightly coupling identities to Kinto data-pools.\n. ",
    "oak11": "I came across a library click (http://click.pocoo.org/5/) I guess it would be helpful for other commands also.\n. Thats true, For now, I'll continue working on the init command.  Thanks for the tools and toolkits listed above, they seem interesting to use. I'll try working with them once the init command is done.\n. I have committed those changes. \n. I'll make the changes mentioned above. However, I have a few doubts:\n-So, uwsgi is default right?I don't ask if uwsgi should be enabled or not? \n-Also, for the backends, I only ask if the user wants postgresql at the backend or not? what happens when another platform is to be used at the backend?\n-for multiauth policies, should there be an option for basicauth and fxa auth? If there is an option, fxa_auth will need client id and client secret correct?\n-also, what does the socket file contain?\n. That looks interesting! I am not familiar with it, but, I'll give it a shot. I'll try to create a .ini file using the cookiecutter and pcreate and then commit the changes. \n. I have been able to create a .ini file using cookiecutter. However, I was unable to set the 8 bit password for kinto.userid_hmac_secret which is generated as a random string.\n I tried to parse it in\n hook/pre_gen_project.py , I get that the .ini file is not found.\nhook/post_gen_project.py ,  I get the error ConfigParser.NoSectionError: No section: 'authentication_configuration' , which is there in the file.\nplease help. \n. About cookiecutter, its easy to implement. I selected that because, I found more documentation on it, no particular reason as such. I tried creating a template using pcreate, it didnt work out quite well. It would be great if you could suggest a few more resources/ links on it. I guess I would be able to decide on which is better after giving pcreate a fair chance. \nIn the meanwhile, cookiecutter uses Jinja2, how about using Jinja2? However, the parsers will still be used if we use Jinja2. \n. Thanks! I'll try pcreate\n. created a script to generate a .ini file. It prompts for backend choice. What other prompts need to be added?\n. added prompt for backend choice, what other prompts should I add?\n. what changes should I make to this? and what prompts should I add?\n. working on it, regarding the command line, when the user enters kinto init, template.py file should get executed and kinto start then accesses the kinto.ini right?\n. I am closing this pull request since all the recent changes and improvement suggestions are on #271. Please refer to that.\n. The kinto init command code runs template.py to generate a .ini file in config folder\n. what values should the variables be assigned for memory setup for backend? Also, I was unable to remove the kinto.ini file from the config folder as the execution halts at main.py and gives an error: kinto.ini not found. I have made the other changes.\n. I'll check it\n. r+\n. Cool, tell me the locations to put tests for kinto/config/init_.py  and  kinto/__main.py  I'll write the tests and commit them. \n. what should I have done instead?\n. Oh, I'll keep that in mind. Is there anything else I should change/add?\n. I'll try that\n. so that the kinto.ini file is created within the kinto/config folder( where kinto.tpl is present) . If only config/kinto.ini is written, it creates a new config folder in the root directory and kinto.ini is created inside that.\n. oh, okay I'll change it back to config/kinto.ini \n. done\n. I am trying to see if values has elements. If it has elements (is not empty) then it is correct- as it will have elements only if it has passed through the if statements and init function. \nIf it is empty (has no elements), there was a failure somewhere. \n. yeah!\n. ",
    "deanwilson": "The request for a new cert went in yesterday i think. I'll check on the status when the US is awake.\n. ",
    "QuentinRoy": "I am not sure I got what is the inconvenient you talked about. But I don't think the metadataobject/container/property have to be inside data. I would have put them in 2 separate places: {data: {}, metadata: {email: \"ilove@pancakes.com\"}. metadata would be a read-only system-managed property container.\n. IMHO the server should never put, alter, use or rely on any data stored in the data container (if we retain the data/metadata scheme we were talking about). It should be entirely managed by the user and should not cause any action from the server (except recording, pull events and sync stuffs of course).\nIf the server needs an id, even provided by the user at some point, it should be in metadata. If the user wants to use its own id and doesn't want to rely on the server-managed one (in metadata where he may not be able to set it or change it), he can do whatever he wants inside data without any risk of side effects from the server.\n. ",
    "greeshmab": "Step by Step Permission tutorial is given twice after First Steps with kinto tutorial.\n. Yes, This would be more helpful \n. ",
    "guewen": "Sounds good :-)\n. ",
    "k4nar": "The ref should do the trick :) .\n. ",
    "phrawzty": "r+\n. r? anybody\n. While this answer may be technically correct, it leaves me unsatisfied:\n- What is generating this error?\n- When might this error message be seen?\n- Can the problem be ignored?\n- Why does upgrading to pgsql 9.4+ solve the problem?\n- Does anything else need to be upgraded?\netc.\n. If this is really a FAQ it could link to the (hypothetical) troubleshooting page.\n\n@phrawzty Based on this new information how shall I rephrase the FAQ answer?\n\nWith what you just said. :smile: Maybe something like:\n\nKinto uses JSONBin, which is a [quick description], support for which was added to pgsql in version 9.4.  This is a hard requirement a hard requirement for the pgsql backend, therefore you'll either need to use pgsql 9.4 (or greater), or use a different backend entirely.\n. r+\n. > Remove the presence of HTTPie command line, it's not useful.\n\nI have found the HTTPie examples to be highly useful, personally - my vote is to keep them.\n. The ini deployed to stage is legacy - I assume that at one point those maxconn variables were valid. A simple s/maxconn/size/ caused those errors to disappear, as expected. :smile: \n. r+ with nits\n. Agree w/ @ametaireau - referring to it as a namespace made it immediately obvious to me as well. :smile: \n. Either:\n\n[...] interacted with. For example, collections, records, buckets, and groups, are all objects.\n\nOr:\n\n[...] interacted with: collections, records, buckets, and groups.\n. Might we consider \"label\" instead of \"name\" in this instance?\n. Is a permission the action itself, or is it the right to perform an action? Consider:\nA permission is the right to perform an action on an object.\n\nThis would imply another terminology item for action.\n\nAction\nAn action is an operation that can be performed on an object. Examples are \"read\", \"write\", and \"create\".\n\nThat said, if we have truly defined \"permission\" to be the action itself, as well as the right to perform that action, then no problem (though we should be explicit about that).\n. Double-quotes, not guillemets, in English. :wink: \n. > ACL\n\nAccess Control List\n. Double-quotes, not guillemets, in English. :wink:\n. Terminate with a period.\n. (imho) This sentence is out of context - consider moving it to the end of this section, or removing it entirely.\n. The comma is not necessary here.\n. > [...] lists all of the permissions that [...]\n. The prefix \"Ability to\" is implied and can thus be removed from this entire list.\n. Add a serial (Oxford) comma.\n\nKinto \u2014 Store, Sync, Share, and Self-Host.\n                          ^ serial comma\n. Remove the comma and terminate with a period.\n. verview* is used twice here. Consider something like:\n\nA high-level look at Kinto.\nAn introduction to the Kinto universe.\nA high-level introduction.\n\netc.\nOr maybe something more informative:\n\nAn introduction to Kinto, including comparison table and FAQ.\n\n(I like that last one.)\n. For a people that love to put commas everywhere, it's odd that you'd be against one that actually makes grammatical sense. :wink: \n. The description needs to be more descriptive. :smile: Consider something like:\n\nDive into the details: architecture and terminology.\n. We can assume that it's documentation. :smile: Consider something like:\nAn exhaustive look at our HTTP endpoints.\nA deep dive into the HTTP endpoints.\nThe gritty details of the HTTP endpoints.\n. Serial comma. :wink: \n. Vampire Weekend - Oxford Comma\n. I liked comparing it to a namespace - that made things nice and clear, for me.\n. Consider:\nIf the bucket already exists - but you don't have write permission - you will get a 403 [...]\n. In English, \"id\" is a psychoanalysis term (see: Freud). You want ID, which means \"identification\" or \"identifier\". :smile: \n\nYou'll want to verify all of the documentation for this since the word \"id\" surely appears more than once.\n. Remove the comma.\n. I'm honestly not sure what this sentence means. :confused: \n. Remove the comma.\n. https://en.wikipedia.org/wiki/Id,ego_and_super-ego#Id :wink: \n. Is the \u00e0 supposed to be there?\n. replace (singular)\n. > Many of the listed endpoints are _resource endpoints which can be filtered, paginated, and interacted with as described in [...]\n. Consider:\n\nWhoever has this permission can read, update, and delete the object as well.\n\nHowever, I'd go in a totally different direction, personally:\n\nAny listed principal can write the object, which further implies read, update, and delete on the same.\n. I'm confused by this line. Is it the case that all newly created objects will be prefixed in this fashion?\n. Need to add some words. :smile: \n[...] lists all of the permissions [...] be associated with each kind [...]\n. The construct \"Ability to\" doesn't need to be used (or repeated) in this table and should be removed. Consider:\nCreate new buckets.\nRead all objects in the bucket.\nCreate new records in the collection.\netc.\n. In general when one has a series of items which build upon one another, one starts with the base item first. Concretely speaking this means that \"read\" should appear before \"write (and read)\" everywhere in this table.\n. I assume that the write permission is grated to the creator for the object that they created, though this is not stated explicitly. Consider something like:\nBy default, the creator of an object is granted the write permission on that object.\nBy default, newly created objects grant write permission to their creator.\n. Replace the colon with a period.\n. I'm unclear as to the relationship between editing the associated permissions and deleting the object. Are those two concepts the same thing or are they separate (but related)?\n. Remove the comma.\n. What does \"authentication mean\" mean?\n. \"on a the\" is almost certainly a mistake. :smile: If I'm interpreting this phrase properly (and I may not be, heh), consider:\nCollections on the \"default\" bucket are created silently upon first access and therefore don't need to be set beforehand.\n. ID\n. > [...] be obtained from the root URL.\n\nURL is an acronym and should be capitalised. I would recommend checking the rest of the documentation to ensure consistency (just like for ID).\n. This is awkward. Consider:\n\nObjects are shared based on user ID.\n\nThat may be too brief. Two (more verbose) possibilities:\n\nBy granting permissions on an object to another user ID, you can share that object with another user.\nYou can share an object with another user by granting permissions on that object to another user ID.\n. Could this be more concise? Consider:\nAll authenticated users.\n. Consider:\nThe user ID that updates the permissions is always granted the write permission. This is in order to prevent accidental loss of ownership on an object.\n\nOut of curiosity, is this a default behaviour that can be changed, or is this a hardcoded behaviour?\n. Consider:\n\nStore a record in the collection. The ID will be assigned automatically.\n. The synopses in this document (records.rst) use a different voice than those in the other documents (that I've reviewed so far, at least). Consider the following:\nStores a record in the collection.\nvs.\nStore a record in a collection.\n\nThe first statement is in an active voice (imperative) whereas the second is passive. It's a subtle distinction, and I'm not arguing for one or the other - only that we be consistent across the documentation.\nIn other words, the form of the synopses in this document should be changed to match that of the other documents. :smile: \n. > Create or update [...]\n. > Update a record [...]\n. Either replace the comma with a hyphen, or enclose the corollary statement in parentheses.\n\n[...] to be modified - all the rest [...]\nor\n[...] to be modified (all the rest will remain intact).\n. > Retrieve all the [...]\n. Consider:\nRecords can be paginated and filtered, and conflicts can be detected.\n. @natim and I discussed this further on IRC. Consider:\nIf somebody wants to share objects with you, you'll need to give them your user ID - this is an easy way to obtain that ID.\n. > Retreive a [...] its ID.\n. > Delete a [...] its ID.\n. Here we encounter a battle between US English and Commonwealth English. :smile: The important thing is to be consistent; unfortunately, both \"synchronisation\" and \"synchronization\" occur throughout the documentation, which is a no-no. Ultimately we just need to decide which English we're comfortable with and then stick with it.\n\n(Personally, I prefer the Australian English dictionary, but I'm old-fashioned like that.)\n. Consider:\n\nThe basic idea is to keep a local database up to date with the Kinto server.\n. \"Post\" has a number of meanings and, contextually, this is a rough place to employ it.\nConsider:\nUpload creations.\nor\nApply creations remotely.\n. Either:\n[...] every record that was created [...]\n\nor\n\n[...] all records that were created [...]\n\nYour choice. :smile: \n. These list items are sentences and must be terminated with a period.\n. > Delete a record by its ID.\n(So that it matches the form in the previous section.)\n. > [...] server settings, or by using [...]\n. > If the response is 304 Not Modified, then the object is up to date, so there's nothing to do.\n. > If the response is 200 OK, then store the ETAG response header value for the next synchronisation and [...]\n. As with the list above, don't be afraid to be a little more verbose with the contents of this list, too. :smile: \n. > [...] database consists of adding new records, updating changed records, and removing deleted records.\n. > [...] created records are simply records which, based on the ID field, are unknown to the client.\n. > In the case that the record marked for update or deletion has also been modified locally, it will be up to the developer to choose a strategy - for example, merge fields or ignore deletion.\n. Remove the comma.\n. Why?\n. > [...] useful to note that ETags [...]\nI'm unclear on the meaning of \"quoted record last modified value\" - this needs to be re-written, but I need more information.\n. Consider:\n\nPassing a If-None-Match: * request header in the PUT will prevent existing records (with the same ID) from being over-written.\n. Consider:\nPassing a If-Match: \"<record.last_modified>\" request header to the PUT, PATCH, or DELETE request will cause Kinto to reject the request with a 412 Precondition Failed response if the [...]\n. Consider:\nThe server won't be available to assign record identifiers while offline, therefore we recommend generating them on the client in this case.\n\nThat said, \"recommend\" suggests that this is optional - is it? If the record IDs can't be generated, then it doesn't seem like the developer has much of a choice. In that case, perhaps:\n\nThe server won't be available to assign record identifiers while offline, therefore the client must generate them in this case.\n. > Record identifiers are UUIDs: a very common [...]\n. Oxford Comma\n. No space before the colon.\n. Collection, singular.\n. Something something COMMA!\n. Organise vs. organize (English :cry:)\n. While semi-colons can be used in lists, this is generally only the case in \"complex\" lists (i.e. lists where each item is a list in itself). There is another case where lists and semi-colons are used, but this is neither the time nor the place for an excursion deep into the jungle of English grammar. :wink: \n\ntl;dr These list items should be terminated with periods (and start with capital letters).\n. I bet you know what I'm going to say regarding commas (and the serial nature thereof).\n. Consider:\n\nKinto has a concept of groups of users. A group has a list of members and belongs to a bucket.\nPermissions can refer to the group instead of an individual user - this makes it easy to define \"roles\", especially if the same set of permissions is applied to several objects.\n. A haiku by @phrawzty:\n\nSerial commas,\non this line and the next one.\nEnglish is so weird.\n. considers\n. CEREAL KAWMA.\n. Either:\n\n[...] this bucket will become readable.\n\nor:\n\n[...] this bucket will also be readable, as a result of inheritance.\n\nI prefer the latter.\n. Consider:\n\nThe permission to create new buckets, however, is controlled from the server configuration.\n. > In general, the permission to create [...]\n\nThe qualifier is necessary since it's not always true (see the comment directly below).\n. > child objects.\n. Terminate the sentence with a period.\n. Is it necessary to have the plural form of the word here?\n. Double-quotes instead of guillemets.\n. Consider:\n\nAn ACE associates a permission to both objects and principals. This allows you to describe rules like [...]\n. Is a principal not an object? Also, perhaps we should define object in this glossary, too. :smile: \n. Consider:\nCheck out our blog post on permissions in Kinto for more information.\n. Consider:\nKinto is meant to be relatively straightforward to install, and we've provided fairly extensive documentation to get you up and running. That said, some dependencies might make the process harder than it should be - we've got some notes on crypto libraries and PostgreSQL at the end of this page.\n. s/given/provided/;\n. Why?\n. I would suggest explicitly stating the rules for how environment variables get picked up by Kinto. The example below is good, but I'm totally unclear as to whether it's only variables that begin with CLIQUET_ or what...\n. I would also explicitly state the order of operations, which (based on the example below) would appear to be:\nENV > .ini > internal_default.\n. Maximum doesn't need to be capitalised.\n. Remove the comma.\n. Why?\n. Consider:\nWhile there are a number of useful settings to assist in configuring the backend, the most important are {backend_type}_backend and [...]\n. So it does! :eyes: \n. Oxford comma\n. Consider:\nBy default, Kinto relies on WSGI for underlying details like host, port, or request scheme. Tuning these settings may be necessary when the application runs behind proxies or load balancers, but most implementations (such as uWSGI) provide adequate configuration details. That said, if ever these items need to be controlled at the application layer, the following settings are available:\n. Blank description?\n. Blank description?\n. A quick shout-out to Heka might be nice here. :smile: (It could even be lifted right from their docs.)\nConsider:\nHeka is an open source stream processing software system developed by Mozilla. Heka is a \"Swiss Army Knife\" type tool for data processing, and is useful for a wide variety of different tasks. For more information, see https://hekad.readthedocs.org/\n. > Requires either the raven package, or that Cliquet be installed with the optional monitoring package:\npip install cliquet[monitoring]\n. Remove the comma.\n. Either remove the comma and use parentheses:\n[...] startup (mainly for setup check).\n\nor use words:\n\n[...] startup, which is useful chiefly as a setup check.\n\nYour choice. :smile: \n. As above:\n\nRequires either the statsd package, or that Cliquet be installed with the optional monitoring package:\npip install cliquet[monitoring]\n. As above...\n. Middleware, like software, is an uncountable noun and thus has no plural form.\nConsider:\nEnable the middleware as described here.\n\n(We should verify the middleware documentation as well, but that section doesn't appear to be involved in this PR.)\n. Remove the hyphen.\n. The word \"couple\" isn't used this way in English (or, at least, not in common parlance). Instead, you could use \"pair\", like in \"key/value pair\".\nConsider:\n\n[...] be created for each username:password pair.\n. Accounts, plural. https://wiki.mozilla.org/Identity/Firefox_Accounts\n. \"Install and configure\" is really brief - maybe add a bit more of a description here, so that it lines up with the rest of the documentation in terms of verbosity.\n. ID\n. Remove \"of course\".\n. > [...] objects, in order to provide a [...]\n. As above:\nBy default, every login / password pair will be [...]\n\nThat said, do you mean \"every\" or \"any\" here? Every implies that multiple pairs could be passed in a single request, whereas \"any\" means that literally any pair will be accepted (but only one per request).\n. Authorisation vs. authorization...\n. I don't know what this means. :confused: \n. Initialise vs. initialize...\n. Consider:\n\nIn the following example, Basic Auth, Persona, and IP Auth are all enabled:\n. Consider:\nPermission handling and authorisation mechanisms are specified directly via configuration. This allows for customised solutions ranging from very simple to highly complex.\nSince this is all handled via configuration\n. Not sure what \"mentioned among\" means here. Maybe this instead?\nbasicauth is configured via multiauth.policies:\n. Consider:\nBy default an internal Basic Auth policy is used.\n. > to plug in any kind [...]\n. > consists of\n\nhttps://english.stackexchange.com/questions/61600/consist-in-vs-consist-of\n. La virgule d'Oxford.\n. Consider (simply):\n\nSpecific resource operations can be disabled.\n. > For example [...]\n. Consider:\nThe Flush endpoint is used to flush (completely remove) all data from the database backend. While this can be useful during development, it's too dangerous to leave on by default, and must therefore be enabled explicitly.\n. I would replace this with a description of what the profiler will generate, and how that output can be used to debug the app.\n. These instructions are specific to Debuntu and should be clearly marked as such.\n. Consider:\nThis is considered an advanced configuration feature and should be used with caution.\n\nPerhaps add:\n\nProceed at your own risk.\n. Is this an internal TODO? Not sure why we're including it in the doc.\n. Consider:\nThanks for your interest in contributing to Kinto!\n. Consider:\nWe love community feedback and are glad to review contributions of any size - from typos in the documentation to critical bug fixes - so don't be shy!\n. Will the trailing period mess up the URL? Maybe safest just to remove it?\n. Consider:\nCheck out the open bugs - anything tagged with the [easy-pick] label could be a good choice for newcomers.\n. Consider:\nAny issue with the [question] label is open for feedback, so feel free to share your thoughts with us!\n. > The best way to send feedback is to file a new issue on GitHub.\n. > Explain how you envision it working. Try to be as detailed as you can.\n. > Try to keep the scope as narrow as possible. This will help make it easier to implement.\n. I'd go in a slightly different direction with this one. Consider:\nFeel free to include any code you might already have, even if it's just a rough idea.\n. Add a colon.\n. Add a colon.\n. > Check out #Kinto on Twitter. :)\n. s/yor/your/;\n. version, singular.\n\nWhere is the list of supported versions? Perhaps that should be linked from here.\n. Replace the semi-colons in this list with periods (or remove the terminating punctuation entirely, including the period on the final item).\n. Consider:\n\nBefore we started on Yet Another Data Storage Service, we took a look at what was already out there, with a view to extending an existing community project (rather than reinventing the wheel). In the end, the solutions we reviewed didn't quite solve the problems we had - notably regarding fine-grained permission settings.\nWhat follows is a comparison table showing how Kinto stacks up against some other projects in this space.\n. The answer to this question occurs literally 50 lines above - no need to repeat it here. Suggest removing this Q/A entirely.\n. Consider:\nNot yet! That said, we want to make Kinto as easy as possible to install and use, so this is high on our list of priorities.\n\nBe careful when making promises like this, though. If you say \"it's a top priority\", and it sits for a year, then it's obviously not true. It might be safer (and more interesting) to invite the community to help out on this one.\nConsider:\n\nNo, but it's a great idea. Packaging is hard and we're a small team, so if you'd like to help us out by maintaining packages for your favourite OS, we'd be delighted to collaborate with you!\n. Consider:\nThat said, Kinto is easy to install via pip, and we've got an image set up on the Docker hub, too.\n. > [...] simplicity and short learning curve [...]\n. > [...] obvious choice for the development [...]\n. > Operations team at Mozilla is comfortable with deploying and managing Python applications in production.\n. :laughing: \n. Proposal to add /dev/null backend :ghost: \n. Consider:\nNo. Kinto is a JSON storage service and is not designed to store arbitrary files. We'd be open to exploring file storage should a solid use-case present itself in the future; however, at this time, it's not on our roadmap.\n. This... this is super confusing. Also, \"factorised\" isn't a word. :wink: \nConsider (simply):\nCliquet is a toolkit for designing micro-services. Kinto is a server built using that toolkit.\n. > A starter kit for JavaScript applications.\n. > An offline-first demonstration web application.\n. > The servicedenuages-blog bucket will [...]\n. > Let's start by giving everybody read access to the bucket.\n\nThat said, according to docs/api/permissions.rst, the system.Authenticated flag means all authenticated users (not anonymous). Assuming we don't want to change the example, we should be clear about what it means:\n\nLet's start by giving all authenticated users read access to the bucket.\n. > bucket: articles and comments.\n. > Now, with that same user, let's create two collections in this\n. > Thanks to the read permission that we set previously, all authenticated users will be able to read both collections.\n. Is the user string case-sensitive? It's capitalised here, but in the --auth it's not.\n. Remove the comma.\n. > We will create a new group called writers with Natim as a principal member.\n. Let us \u2192 Let's\n. Consider (simply):\nNow we grant the write permission on the blog bucket [...]\n. Consider:\nNow Natim can write new articles!\n. Kinto uses the JSONBin feature of PostgreSQL, which is used to store native JSON objects efficiently. Support for this feature was added in PostgreSQL 9.4.\n. I'm seeing an Exception error - what's wrong?\n. That said, we've included solutions (or at least explanations) for some common problems below.\n. :+1: \n. Why remove .project_docs as an example?\n. The documentaton explicitly states\nBy default, Kinto doesn\u2019t define a secret for you\n\nPerhaps this value should be empty?\n. Remove the extra \"s\" from \"backends\".\n. Remove the extra colon (it breaks the rendering of the code block).\n. It might be worth adding a bit of extra information about why a read-only user still needs write access to something.\n. ",
    "gfortaine": "Did you think about SwellRT ?\nhttp://swellrt.org\n\"This is the only decentralized-federated framework to build collaborative applications.\"\n. ",
    "enguerran": "I saw you were speaking about mattermost and on may 10, framasoft announced an installation on their server called framateam. What do you think about?\nAnd the one more thing, mattermost can connect to IRC channel with matterbridge.\n. same here, I guess you can close the issue.\n. @almet I updated the PR with your comments. See if it's ok.\nMaybe I can add a note about https://github.com/Kinto/kinto/pull/485#discussion_r54877130 to help people changing the configuration file.\n. @glasserc the broken link to the \"documentation contributing\" comes from this page https://github.com/Kinto/kinto/blob/master/CONTRIBUTING.md\n\n. @Natim I am not familiar with PR, I added you as contributor of my fork. Nevertheless I can modify my commits regarding your remarks: may I have to keep one commit by question/answer or may I let modification visible in the PR by creating one new commit for each modification you ask?\n. I updated questions/answers with a beautiful push -f to keep one commit by question.\nBut I see you speak about one commit: do you mean one and only one commit for the PR?\n. Alright, I'll do one commit by review for the next one. Thanks a lot for your patience and your time.\nMy last correction is coming.\n. Sorry, I was out of the Web for vacations ;)\nI'm late but at least it LGTM.\n. I cannot take a decision on this as I am not yet aware enough of kinto permissions system. I do discussed with @Natim. But I cannot understand how my needs are different from formbuilder's.\nExtract from https://github.com/Kinto/formbuilder/blob/master/formbuilder/actions/server.js:\n- bucket: { \"collection:create\": [\"System.Authenticated\"], \"write\": [] }\n- collection (a form): { \"record:create\": [\"System.Authenticated\"], \"read\": [userId] }\nThe extra need is\n\nWe also want to be able to list the collection the user can administrate. It makes it impossible if we give the read permission on the collection.\n\nIn formbuilder, access are controlled by \"encoded\" URL. If you have the admin token, you'll have access to the collection's administration. If you have the user token, you'll have access to the form and can only create a record. As far as I could understand formbuilder's code.\nIf I create a collection of \"url with admin token\" in a specific user's default bucket, I guess an admin could have access to several forms' administration.\nAgain, I am just a beginner user of kinto and maybe I am wrong.\n. I recognize that it is not obvious as usually you need to manage user creation before using it. I don't know another application in which the authentication is made that way.\nSo it may be a good idea to insist and find a beautiful metaphor to illustrate. If I get an idea, I'll let you know.. I guess we need to help the user to \"change it later\".\nI suppose we can change the backends directly in config/kinto.ini (with the help of the doc).\nBut is there a CLI to to get this question back? Select the backend you would like to use: (1 - postgresql, 2 - redis, default - memory) And so have a wizard to setup postgres or redit.\n. What a syntax ;)\nfixed in the next commit.\n. I think it is like if they modify\n. In fact, that is exactly why I created the gist.\nI needed to customize the kinto.ini file and I saw that the kinto.ini generated in the docker container was referencing to memory storage.\nI do not want to set kinto using some options via environment variables and some via a kinto.ini file.\nSo, I changed the docker-compose.yml to exclude the environment variables and set up a docker volume to mount the kinto configuration file into the container.. I do not know rST very well, so I cargo cult-ed the block code syntax. Is it wrong?. The PostgreSQL server is a container started by docker-compose.yml with this configuration: (yes I removed environment variables, but for kinto only as I do not want to have two places for configuration, kinto.ini and environment variables)\nyml\ndb:\n    image: postgres\n    environment:\n        POSTGRES_USER: myusername\n        POSTGRES_PASSWORD: mysecuredpassword. You mean, we should change the docker-compose.yml file in the repository to match this one:\nyml\n    db:\n      image: postgres\n      environment:\n        POSTGRES_USER: postgres\n        POSTGRES_PASSWORD: postgres\n    web:\n      image: kinto/kinto-server\n      links:\n       - db\n      ports:\n       - \"8888:8888\"\n      volumes:\n        - ./config:/etc/kinto. Yeah, that is true, it is some common command lines to control our running containers.. I added a new useful command line, even if kinto-pusher was already installed (I do not know which one we can use as example).. I added another useful command line: https://github.com/Kinto/kinto/pull/936/commits/9cc476182e0085cb18d15d5713d977e7b2ecd4b5#r89494120. fixed wih the new commit. fixed wih the new commit. fixed wih the new commit. ",
    "nikkisquared": "I'd like to work on this. I've looked up the sections on pagination, but I'm not sure how or where they could be better referenced.\n. That helps me a lot. I'll start with adding more to the records-get page, and then see about making better references in previous pages.\n. Sorry, I won't be able to do this. I'm struggling with the time zone between me and the kinto team, I find myself unable to do much without being able to get feedback over irc as I work.\n. ",
    "glasserc": "\n\nThe order of the section matters. It should be Overview, Concepts, Community and then Tutorials, Configuration and APIs;\nThe menu on the left should be in the same order than these sections.\n\n\nI don't see any \"community\" section. Was this renamed to \"Contributing\"? Or should there be a new order?\n\n\nRemove the presence of HTTPie command line, it's not useful.\n\n\nWhat does this mean? Remove the commands that demonstrate how to actually make the requests? I think those are useful, so maybe you're talking about something else.\n\nResource endpoints\n- It seems broken: no menu on le left.\n\nWhat does this mean? The fact that there's no menu for \"Resource endpoints\" subsection titles on the left side? I believe this is just due to the depth of the section (\"Resource endpoints\" is a sub-subsection) since none of its siblings have menus for their titles either.\n\n\nthe \"hack\" section is broken\n\n\nHow is it broken?\nThe remaining tasks are either already done or I just created issues for them (see #562, #563, #564, #565, #566, #567, #568, #569, #570, and possibly others). Please feel free to create issues for the remaining four issues described above, or mention that they've been fixed or aren't valid, so we can close this one :)\n. OK. Since #502 is already open, and I've just created #580 and #581, I'd like to close this issue.\n. This only happens to work due to a quirk of how we handle missing fields as the empty string. I'm going to add a has filter, per @leplatrem.. Added a has_ filter in #1258.. I am implementing something similar to this right now. One difficulty I had was defining objects that are \"owned\" by a user. I guess I can say any object for which the user is the only one to have write permission on it is \"owned\" by that user.\nProbably this endpoint should require that the user authenticate, but often you need an endpoint like this after the user is gone, so that probably means this endpoint needs to be accessible by some \"superuser\". I think I'd require that a PR adding this endpoint should also add a config option for which principals are allowed to access it, defaulting to none. System administrators can turn the feature on by either providing their own user principal, or for instance by allowing system.Everyone and limiting access to the endpoint using nginx or something.\n. Who is the intended audience for the documentation? My guess is that the main people who read Kinto documentation are going to be programmers who are intending to build software using Kinto. In that case, they're probably already going to be looking at documentation in two places: the main Kinto documentation, and the documentation for whatever library they are using in their own programming language. Is three places much worse than two places? It's not like the user would have to exert any extra effort to go to the Cliquet docs -- they would just click a link.\nSoftware developers are normally very good at understanding that software is built on top of other software, and other libraries don't try to hide this (for example, the React tutorial refers to Markdown and the third-party marked library). So I think the conceptual cost is low. I think we would just need a note at the front saying that Kinto was built using the Cliquet protocol or something like that.\nInstead, to avoid this conceptual cost, we're adding a lot of complexity to our documentation. In particular:\n- Our documentation is duplicated across two projects. Both Kinto and Cliquet have information about what API endpoints you can use to set permissions, for example, and both have to be maintained.\n- It isn't clear which version of this documentation is authoritative. For example, the Kinto documentation doesn't say you can update the data and permissions of a record at the same time, but the Cliquet documentation does. Which is right?\n- Cliquet documentation has to be \"relocatable\", so it can be included in other projects. Since we don't include the entire Cliquet documentation into Kinto, some links in the Cliquet documentation (which point to other Cliquet documentation) are broken in the Kinto documentation (because we don't include the targets of those links in the copy). Maintainers of Cliquet documentation will need to always remember that some parts of their documentation serve not just as Cliquet documentation, but documentation of Cliquet-based services. I think this is going to make maintenance of Cliquet documentation much more challenging.\nI believe that on balance, these disadvantages outweigh the advantage of having all the Kinto documentation in one place. I think it's possible to make both Cliquet and Kinto documentation more usable by providing overviews and Kinto-specific notes in the Kinto documentation, while linking to the Cliquet documentation for more details.\n. Re: \"without having to go into the cliquet library documentation\": I wrote my thoughts about that in #560.\nI agree that the Kinto permissions app should cover anything specific to Kinto, such as inheritance. But of the current Kinto permissions documentation, most of it isn't specific to Kinto. The \"formalism\" section defines the set of possible permissions, and there should be something like it in Cliquet (but there isn't). \"Get the current user ID\" is true for any Cliquet app. \"Retrieve/add/modify permissions\" is all generic for any Cliquet app. Nothing covers inheritance. As with the rest of the Kinto documentation, I think this document would be more helpful if it provided a high-level summary and linked to Cliquet for details.\n. This issue doesn't make sense any more since now all the documentation is grouped together automatically.\n. Another alternative is to move it into Kinto.js with a title like \"How to add support for a new Kinto command to Kinto.js\". What do you think @n1k0 ?\n. OK, let's split this task into #578 (removing the JS tutorial that we have), which is easy, and #579 (coming up with a guide for implementors), which is future work.\n. Having reviewed the documentation thoroughly, I don't think we should do this. The FAQ is all architectural and design questions. The Troubleshooting page is about debugging and certain well-known exceptions.\n. This appears to be related to https://github.com/rtfd/readthedocs.org/issues/1820.\n. As far as I can tell, it hasn't yet been.. r+\n. I believe this is related to https://github.com/snide/sphinx_rtd_theme/issues/290.\n. While I was working on this, I started to wonder if a more useful \"first steps\" document might use a client library and hide this complexity from the user. That change was more invasive than what I was looking to do today, so I left it as-is for now, but I'm open to making that kind of change later if it seems like a good idea. (In that case, I guess the \"first steps\" page would become something like a tour of the Kinto API, perhaps for client implementors, and/or maybe a guide for choosing a data model in the face of Kinto's synchronization patterns.)\n. r+\n. No idea..\n. Ah, I think it was, but it was taking a long time. It's checking now.\n. Yeah, I wasn't really sure how to handle this. I'd like to support the configuration values with a deprecation warning if that's possible, but I don't want to go to a lot of effort to make that happen. I'll check to see if there's a way to update the config before invoking the Pyramid configuration stuff.\n. r+\n. r? @leplatrem \n. Do you think I should do those too, or are you merely mentioning them for completeness? logging_renderer could make use of the same logic, but event_listeners will be harder.\n. So this is two different constraint violations, right?. I'll fix this as part of my documentation cleanup PR.\n. The changes I made to resources.rst are all detailed in full detail in the individual commits. I extracted sections of it as sorting, pagination (which includes counting), and selecting_fields. I also made a minor grammatical change to an explanation of what the 304 response means on a GET.\n. Even for requests for a simple resource that isn't in a batch request such as /buckets/abc/collections/plop, we seem to enter the kinto-fxa code about five or six times in a single request. It seems like the call to effective_principals is not cached for a given request, and it calls authenticated_userid, which isn't cached, which calls unauthenticated_userid, which is not cached either (but by then we're in kinto-fxa code and the bug could be said to be in kinto-fxa). All of these methods are in pyramid or pyramid-multiauth. Here's a typical traceback:\n```\n  /usr/lib64/python3.6/threading.py(884)_bootstrap()\n-> self._bootstrap_inner()\n  /usr/lib64/python3.6/threading.py(916)_bootstrap_inner()\n-> self.run()\n  /usr/lib64/python3.6/threading.py(864)run()\n-> self._target(self._args, *self._kwargs)\n  /home/ethan/Jobs/Mozilla/kinto/.venv/lib/python3.6/site-packages/waitress/task.py(78)handler_thread()\n-> task.service()\n  /home/ethan/Jobs/Mozilla/kinto/.venv/lib/python3.6/site-packages/waitress/channel.py(338)service()\n-> task.service()\n  /home/ethan/Jobs/Mozilla/kinto/.venv/lib/python3.6/site-packages/waitress/task.py(169)service()\n-> self.execute()\n  /home/ethan/Jobs/Mozilla/kinto/.venv/lib/python3.6/site-packages/waitress/task.py(399)execute()\n-> app_iter = self.channel.server.application(env, start_response)\n  /home/ethan/Jobs/Mozilla/kinto/.venv/lib/python3.6/site-packages/pyramid/router.py(233)call()\n-> response = self.invoke_subrequest(request, use_tweens=True)\n  /home/ethan/Jobs/Mozilla/kinto/.venv/lib/python3.6/site-packages/pyramid/router.py(208)invoke_subrequest()\n-> response = handle_request(request)\n  /home/ethan/Jobs/Mozilla/kinto/kinto/core/initialization.py(171)eos_tween()\n-> return handler(request)\n  /home/ethan/Jobs/Mozilla/kinto/.venv/lib/python3.6/site-packages/pyramid_tm/init.py(136)tm_tween()\n-> response = handler(request)\n  /home/ethan/Jobs/Mozilla/kinto/.venv/lib/python3.6/site-packages/pyramid/tweens.py(51)excview_tween()\n-> request_iface=request_iface.combined\n  /home/ethan/Jobs/Mozilla/kinto/.venv/lib/python3.6/site-packages/pyramid/view.py(612)_call_view()\n-> response = view_callable(context, request)\n  /home/ethan/Jobs/Mozilla/kinto/.venv/lib/python3.6/site-packages/pyramid/viewderivers.py(410)viewresult_to_response()\n-> result = view(context, request)\n  /home/ethan/Jobs/Mozilla/kinto/kinto/core/views/errors.py(23)authorization_required()\n-> if Authenticated not in request.effective_principals:\n  /home/ethan/Jobs/Mozilla/kinto/.venv/lib/python3.6/site-packages/pyramid/security.py(378)effective_principals()\n-> return policy.effective_principals(self)\n  /home/ethan/Jobs/Mozilla/kinto/.venv/lib/python3.6/site-packages/pyramid_multiauth/init.py(119)effective_principals()\n-> userid = policy.authenticated_userid(request)\n  /home/ethan/Jobs/Mozilla/kinto/.venv/lib/python3.6/site-packages/pyramid/authentication.py(71)authenticated_userid()\n-> userid = self.unauthenticated_userid(request)\n  /home/ethan/Jobs/Mozilla/kinto-fxa/kinto_fxa/authentication.py(57)unauthenticated_userid()\n-> user_id = self._get_credentials(request)\n\n/home/ethan/Jobs/Mozilla/kinto-fxa/kinto_fxa/authentication.py(86)_get_credentials()\n```. https://groups.google.com/forum/#!topic/pylons-discuss/-1Z5N-hhAOw has some information on the subject.. Yes, @Natim and I saw this error a lot when I was adding the warnings/backwards compatibility to the settings stuff in #599. I thought I had put the logs in the right place (after the structlog init), but I guess not. I'll look at it.\n. I'm a little stuck on this issue. We can't set up logging without loading settings, and we can't load settings without having set up logging (for when the settings are old and deprecated). I guess this works in the tests because we set up logging outside the test harness for these tests? I think the most sensible thing to do is to not call logging to print a deprecation warning. This means updating the tests to use some other mocked function, but that might be better anyhow.\n. I have reproduced the behavior using just structlog, so I believe this is partly a structlog bug, and I have opened https://github.com/hynek/structlog/issues/71 to track this issue.\n. So, I've confirmed with upstream that there's a \"bug\" in structlog. I've issued https://github.com/hynek/structlog/pull/72 to try to fix it. We can wait until that gets merged and released, or we can merge one of the workarounds -- #632 or #633 are both equally ugly IMO.\n. I agree with @Natim :)\n. r+\n. Rebased this against current master\n. r+\n. Otherwise, r+\n. Well, Kinto's documentation is very thorough, so I guess so. But I would also understand not documenting it since it isn't part of our public API.\n. Ultimately, you need the client to choose the ID, but I don't think it needs to always be a UUID. I would be :+1: on relaxing the requirement.\n. The \"Edit on Github\" link is a known issue. As far as I can tell, it's a bug in readthedocs. See https://github.com/Kinto/kinto/issues/573.\n\nAs for the URL that you sent, that page got folded into the \"community\" page. Where did you find that link? I opened #666 to try to fix the uses that I could find.\n. LGTM\n. This is only important once #667 gets merged.\n. I think providing the OpenAPI documentation for an endpoint is the easiest way to solve this issue, but I don't think solving this issue is itself the highest priority.. collection_timestamp -> ?? I don't like resource_timestamp. Maybe plural_timestamp, or children_timestamp?. r+. The kinto.core docs need to be proofread for grammar, but that's outside the scope of this PR.\n. r+\n. Awesome! r+\n. r+! :100: \n. r+\n. I don't think we need this; I've already worked around this in ext.storage.sync. (See keyToId in https://reviewboard.mozilla.org/r/55838/diff/22.)\n. I like it too!\n. Sorry, no idea really! But the ones from web.1 seem to be produced by the same process as kinto, even if nothing in the Kinto codebase produces them explicitly. I don't think the router ones are  coming from Kinto. On my local machine, the logs look more like:\n2016-09-26 16:34:49,305 INFO  [kinto.core.initialization][waitress] \"GET   /v1/buckets/default/collections/foo/records?_since=1473771653605&_sort=-last_modified\" 401 (2188 ms) request.summary agent=curl/7.47.1 authn_type=None errno=104 lang=None time=2016-09-26T16:34:49 uid=None\n. @oronsan I don't think anyone is working on this feature, so go for it!\n. This is meant to address #788. r? @leplatrem\n. I think it means the overview page of the Kinto server project, i.e. http://kinto.readthedocs.io/en/stable/overview.html .\n. I was able to run this branch and make the request you posted without any problems. Is it maybe something silly like an outdated version of Cornice in your virtualenv? If you're running make serve, that should take care of it. Can you track down where something is being checked for mapping functionality?\n. I'm not sure if it's a problem with pyramid-tm or if we're using it wrong.\n. This was eventually solved in mozilla-services/kinto-fxa#35.\n. The existing function needs a Request in order to run. From the specific test, it wasn't convenient to create a request so we just duplicated the logic. If you changed the default_bucket_id implementation, probably it's enough to reflect those changes in this test. Otherwise you'll have to change the test to actually use the default_bucket_id logic, either by creating a Request or by extracting a non-Request version which can be used here. Either choice might be the better move long-term anyhow.\nIt also occurs to me that this task might be obsoleted by #1736.. We use flake8 to enforce consistent style on Python code. I don't think we have any style guide for other files (and certainly not for .tpl files).. No strong feelings. How does this work with synchronization?\n. Ah, right. I misread this and thought it was about renaming records. Renaming buckets and collections seems OK to me.\n. I'm not sure about this one -- I think the docs are correct. If you try to delete a bucket that doesn't exist, you get a 403. I think this is so that we don't leak information about things that are there but can't be seen because you don't have permission.\n```\n\nhttp PUT localhost:8888/v1/buckets/abcd -a 'user:pass2'\nHTTP/1.1 201 Created\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 155\nContent-Type: application/json; charset=UTF-8\nDate: Fri, 11 Nov 2016 22:26:32 GMT\nEtag: \"1478903192992\"\nLast-Modified: Fri, 11 Nov 2016 22:26:32 GMT\nServer: waitress\n\n{\n    \"data\": {\n        \"id\": \"abcd\",\n        \"last_modified\": 1478903192992\n    },\n    \"permissions\": {\n        \"write\": [\n            \"basicauth:db446a4e0ffd571c291d2d7e20bfd978a1e92cd5fe566ca796af74c40943c583\"\n        ]\n    }\n}\n\nhttp DELETE localhost:8888/v1/buckets/abcd -a 'user:pass2'\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 67\nContent-Type: application/json; charset=UTF-8\nDate: Fri, 11 Nov 2016 22:26:35 GMT\nServer: waitress\n\n{\n    \"data\": {\n        \"deleted\": true,\n        \"id\": \"abcd\",\n        \"last_modified\": 1478903195786\n    }\n}\n\nhttp DELETE localhost:8888/v1/buckets/abcd -a 'user:pass2'\nHTTP/1.1 403 Forbidden\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 95\nContent-Type: application/json; charset=UTF-8\nDate: Fri, 11 Nov 2016 22:26:36 GMT\nServer: waitress\n\n{\n    \"code\": 403,\n    \"errno\": 121,\n    \"error\": \"Forbidden\",\n    \"message\": \"This user cannot access this resource.\"\n}\n```\n. That's super weird. Maybe @leplatrem or @Natim knows whether these should be consistent or if it's meant to be like this? If it's meant to be like this, I agree we should document it.\n. The build failure is unrelated to these changes -- a fix exists in https://github.com/Kinto/kinto/pull/916, although I'm not sure what its status is.\nI feel like listing so many possible reasons for a 403 is a little overwhelming. I'd rather see a more \"global\" note about Forbidden errors explaining that we sometimes return them instead of 404s if the user doesn't have access to the place where an object would be.\n. Is this going to hit master?\n. Would this mean that some events will have ${resource_name}_id and uri, and others won't, depending on what request triggered them? That sounds bad to me -- I would rather drop them from all events, to have consistent events.. Well, but are the events different ones? It seems like this proposal is to change update events to have certain fields if it was a batch request, and to lack those fields if it wasn't a batch request. Wouldn't a plugin want to subscribe to both of those cases, and handle them similarly?. Well, I'm still confused. Let's consider the following cases:\nhttp -j --auth 'user:pass2' PUT localhost:8888/v1/buckets/default/collections/some-collection/records/some-record data:='{\"my-field\": \"my-value\"}'\nLet's say this generates an event like:\n{ 'action': 'update',\n  'bucket_id': u'default',\n  'collection_id': u'some-collection',\n  'record_id': u'some-record',\n  'resource_name': 'record',\n  'timestamp': 1479999631700L,\n  'uri': u'/buckets/default/collections/some-collection/records/some-record,\n  'user_id': 'basicauth:cbd3731f18c97ebe1d31d9846b5f1b95cf8eeeae586e201277263434041e99d1'}\nNow consider:\nhttp -j --auth 'user:pass2' POST localhost:8888/v1/batch requests:='[{\"method\":\"PUT\",\"path\":\"/buckets/default/collections/my-collection/records/my-record\",\"body\":{\"data\":{\"my-field\": \"my-value2\"}}}]'\nThis request is identical to the first one, so it should generate the same events. Agreed?\nYou're saying that the second one, if and only if it contains two PUT requests, should be missing record_id and should have different semantics for uri. Did I understand that correctly?\nMy argument is that whoever authored the plugin doesn't care whether the events came from someone making a batch request with two PUTs, or someone making two separate PUT requests. The events should be the same, and have the same semantics, in both cases. So if you want to remove the record_id from the second case, you should remove it from the first case too. But maybe I'm missing a point somewhere.\n. In investigating this, I noticed that the timestamp argument to notify_resource_event is only present in the payload, but that doesn't really make any sense (for all the same reasons as the above). Do we need to keep the timestamp? What do we use it for?. OK, never mind that last comment -- I think I confused myself. For a given (resource_name, parent_id, action), the timestamp should correspond to the parent_id's collection_timestamp, so \"must\" be the same for all impacted_records.. Sorry I wasn't able to look at this for so long!\n\nI haven't had a chance to look at the memory issue you encountered. I'm glad you found a workaround. Maybe that's good enough, or maybe we should dig deeper?\nThe tests look very thorough. Testing the definitions in isolation is a great idea.\nAdding a new kind of request means adding a new test to the swagger tests. Maybe it would be cool if there were a way to avoid this? For example, maybe we could have a test that just makes every request possible. Or is it at least possible to verify that all requests in the spec were exercised by the test suite, and fail if one wasn't? (This might not work for error responses, which I think we still have to write out explicitly.)\nIf it makes sense to use cornice_swagger, then go ahead, but if it doesn't suit our use cases, then I don't want to spend a lot of time trying to force it to fit. In our meeting today, you mentioned that our Colander schemae are actually shared, so probably not a good match for a user-facing schema. In addition, some of our API involves custom headers, which I bet aren't captured in any Colander schema. Both of these seem like good reasons why cornice_swagger wouldn't fit.\n@gabisurita proposed making Swagger stuff into a plugin. @Natim didn't have any objections. @leplatrem ? We agreed that we should proceed as-is (i.e. in this repo) for now, since moving it should be easy once it exists. I think it should stay in this repo as long as we're maintaining it manually.\n@gabisurita asked where the Swagger view should live (kinto or kinto.core). I think that as long as it's being maintained manually, it should live in kinto, given that the views that are documented are there too. If we come up with some way of generating it automatically, it could live in kinto.core so that projects \"inheriting\" from kinto.core could get Swagger support too. What do you think @Natim @leplatrem ?\n\nCustom headers like If-Match and If-Not-Match weren't there when I looked at this earlier, but I see that they're now. In a meeting today, @gabisurita said that support for headers has just landed in Swagger 2.0.\n. OK, I'm r+ on this. @Natim @leplatrem ?. \ud83c\udf8a . Ah, I understand now..\nYes, let's keep the tests, I agree they're good and valuable.. \ud83c\udf86 \u2747\ufe0f \ud83d\udca5 . For the same reason that we don't commit .pyc files to master. These files are not the preferred form for modification or even readable. Verifying a PR that modifies these files is therefore impossible. These files are the output of an automatic process and so keeping them around is just wasted space. It probably wouldn't be such a big deal to me except that the kinto-admin plugin is by far the heaviest thing in a git clone, weighing in at 7MB (out of 7.9MB), so doing a git pull is much slower when someone updates these files.\nI agree that master should be \"runnable\", but I don't think that means we need to keep kinto-admin build outputs in source control. We could agree that \"runnable\" means \"runnable without the admin\", or we could agree that \"runnable\" means \"runnable with everything in a non-optimized way\", or we could agree that \"runnable\" means \"runnable once you execute a build step\". Each of these ways could permit kinto-admin build outputs to not be checked in to git, because they don't belong there.. I'm tempted to classify this as a regression, but I think listening on either 127.0.0.1 or 0.0.0.0 are equally \"correct\" in the general case. (See this Pyramid issue for some heated discussion on this point.) And it doesn't seem like pserve respects any environment variables about host, and we don't do anything special with those variables. Given that, I think we should update kinto init to allow the user to specify what address to listen on, and update the Dockerfile to pass 0.0.0.0 to this argument.. Hi! Thanks for the contribution! Sorry nobody has had time to look at this. The change looks OK by itself but the tests are failing, I think because we have a constraint that forces pyramid 1.7. Could you please update that too?. As far as I know, there isn't anything that's exactly like what you say -- there's only one circumstance where there's a special permission, and that's the kinto.bucket_create_principals, which lets you define some user that has permission to create buckets, even if they aren't granted any other permission in the database itself. If you had a fixed set of buckets, you might be able to set something up where you create all the buckets yourself and explicitly list the \"superuser\" among the permissions of that bucket. Because permissions \"cascade\", this would also grant them permissions on buckets and records. But you specifically said \"without being explicitly listed in the permissions lists\", and I don't think there's anything like that.\nYou might be able to implement something as a Kinto plugin which acts as a permission backend by just calling to some other permission backend and adds a \"superuser\" ID on every get_object_permissions. This wouldn't be a complete solution, but it might be good enough depending on your use case.\n. \ud83d\udc4d . Looks OK to me. Maybe I misunderstood what you were saying in our meeting earlier, but it sounded like you needed to fix the JSON thing to fix the build failures, but the build failures don't seem related to the JSON library validation per se. So what's the rationale for fixing the JSON thing in this PR? (Just curious...). Yeah, that's because we \"render\" the template using the str.format method, which doesn't understand comments. You can see that happening at https://github.com/Kinto/kinto/blob/53ddeabd0e7ca68921f5360fd80e2ec3d7ac233b/kinto/config/init.py#L24. I don't think you need to make cache_prefix be a variable in this way -- you can just put a dummy example value.. For those of you following along at home, one specific problem we've seen is that the CDN will gzip a response and then strip the ETag. Since we're using ETags for concurrency control, this breaks syncing and everything else.\nThere's an argument that we're using ETag wrong, since the RFC says an ETag corresponds to a representation rather than the resource itself. That would make the CDN behavior correct, since gzip'ing a response means producing a new representation. There's also the Last-Modified / If-Unmodified-Since headers. We could also perform a test with \"weak\" ETags, which only change if the resource is no longer the same \"semantically\". Maybe the CDN would preserve a \"weak\" ETag, even if it gzips the response. On the other hand, this might break all our existing clients, which assume ETags are just string-encoded integers :(\n@Natim proposed in #1102 getting rid of ETags completely. I'm not crazy about the idea of removing ETag, since it will break our old clients. I'd be in favor of adding new concurrency-control information, whether that's within a meta tag or as Last-Modified or something else.. I don't know what changed that made this test start to fail, but I don't understand why it should have ever worked, and why it doesn't fail in the other non-pypy builds. It's failing because it's trying to get a current_resource_name from a mock to use as details in an HTTP error. current_resource_name produces another mock, which means that the details can't be serialized. I think you can work around it by setting a current_resource_name in the mock (in get_request()).. I didn't have time to do a thorough review, but from what I see, this looks OK to me. I don't have a problem with concentrating fundamental or common schemas in a schemas module. (In Haskell, sometimes projects will have a Types.hs module where all the models are defined but most of the operations they support omitted. This seems like that to me.) On the other hand, I like better how you put e.g. VersionResponseSchema in the same module as the view that serves versions -- it's closer, so it seems to me like it will be more likely to be modified at the same time. So I would say that we should try to do that as much as we can, and fall back to putting things in schemas if we have to. At first I thought you put things in schemas to re-use them, but I see that e.g. CollectionRequestSchema is only used once?\nThe ResourceResponses thing seems a little complicated.. I guess this is to simplify shared error responses? It feels like it's tied too tightly to the different views we support.. I'd love to hear @leplatrem 's thoughts on this!. I think you could argue that it should work on other requests and have the semantics that it affects only the response to the request. This could maybe be useful for large PUT requests made on an asymmetric connection, for example.\nI think you could also argue that the semantics are a little muddled. If someone PUTs to a \"subset\" of a record, I feel like that could be interpreted to mean \"replace the fields I selected, but leave the other fields alone\".\nPersonally, I think it should only work on GET. I think the semantics are clearest and we don't have a use case for having it on other methods.. Per @Natim on IRC, those of you following along at home should do make maintainer-clean in your kinto source tree to rebuild a venv with Python 3.\n. Sorry to ask stupid questions, but does this change follow the spec then? Or is it just to stop a crash and we'll try to conform to the spec later? It seems like just ignores If-Match: * rather than checking whether the record exists or doesn't exist.. Ugh, I guess this got opened by someone else in the meantime... I agree with you: I think If-Match: \"abcd\" should fail if the record is not there.\nWhile I'm here, I should also note that I think the current behavior of the codebase is slightly wrong. If I read the code correctly, it tries to compare the If-Match header against the current record's ETag, and fail if the record is newer. I think this is different from what the spec says, which is that the request should fail unless the record's ETag is exactly the same (neither older nor newer) than the If-Match header, but I don't think it's super important as long as the clients behave properly (because time, and thus our ETags, are monotonic). We assign more meaning to ETags than the standard really requires -- ETags are just opaque cookies representing the version of a document and don't have to behave monotonically or anything.\n. So wait, finally we're not doing a shallow copy or anything?. It seems like pserve had a massive rewrite upstream which breaks us in a couple of ways.\n\n\nIt seems like moving from optparse to argparse (https://github.com/Pylons/pyramid/pull/2864/) changed the semantics of an argument string like ['pserve', 'config.ini', '--reload', 'http_port=8080']. For some reason, the argument parser fails to parse this, but it will parse correctly if --reload comes either before the INI file or after the variable.\n\n\nIt seems like the implementation of pserve used to re-invoke the same command as sys.argv, but now specifically recursively invokes pserve from inside a \"monitored\" reloader process. The second (inner) execution then tries to parse kinto serve arguments with pserve and totally fails.\n\n\nIt seems like we'll have to rewrite our kinto serve code to make it work with Pyramid 1.8. Since master is kind of broken right now, I think we should revert the change until someone has time to do that. In the meantime, @gabisurita points out that if you remove --reload from the Makefile, then everything works OK (but without reloading). We could make that change instead and create an issue to track it.. The fact that the argument order is important seems like a bug; should we report it upstream?. I'm also in favor of fixing the ETag thing, which I'm glad you did.. Very strange! I logged into the server and didn't see anything in the logs. You said you couldn't reproduce this locally, right?. I think this is a good change even disregarding pytest behavior. Repeated initialization isn't really valuable for us.. Nice explanation! If the Pyramid issue gets fixed, will we move the code back into Kinto, or do you think having it as an external package is a good long-term plan?. REST verbs don't exactly match CRUD verbs. In this case, POST doesn't really mean \"create\", and neither does PUT. I think this behavior makes sense in the context of REST.. If we change the memory backend to write to a file and read it on startup, we ought to rename it.\nOf the non-SQLite solutions, I think dumping/loading directly into the memory backend is the cleanest.. I agree that it doesn't really make sense to have paginated delete (i.e. limit). I'd be OK with taking them out.\nOne use case where something like paginated delete might be useful is if you wanted to \"pop\" a random record from a \"queue\" collection. But I'm not sure this would work with READ COMMITTED and probably we shouldn't encourage the use of Kinto as a queue.. OK, that makes sense. Then we should probably fix it as-is then.. No, Kinto doesn't have any concept of relationships or \"foreign keys\". In this, it is much like other document-store technologies like Redis, CouchDB or Mongo. The equivalent of a SQL join is to fetch related things on the client. You could do this in-memory, like you propose; this is easier if you've already \"synced\" the collections locally. If you're just using an HTTP-based client, you could also do it with multiple round-trips to the server.\nI hope this answers your question; if it doesn't, feel free to reopen. This is a fine place to ask questions, but we also list several other places at http://kinto.readthedocs.io/en/stable/community.html :). How would you use a batch request to do a join? It seems like you'd have to get the first response in order to get the IDs to use in the second request.. Thanks!. It led me on a merry chase, but I'm pretty sure that the encoding of the string Mon Apr 10 2017 15:41:28 GMT 0900 (\\x93\\x8c\\x8b\\x9e (\\x95W\\x8f\\x80\\x8e\\x9e)) is cp932, making it Japanese (Mon Apr 10 2017 15:41:28 GMT 0900 (\u6771\u4eac (\u6a19\u6e96\u6642))) (\"Tokyo (Standard Time)\"). Of course, that doesn't tell us why this encoding vs. UTF-8, or where this field was (it doesn't seem like clients usually send Date headers?), or why we seem to fail when parsing GET.... I couldn't reproduce it using requests like this (Python 3):\n```python\nimport requests\nfrom requests.auth import HTTPBasicAuth\nPROD_URL = 'https://firefox.settings.services.mozilla.com/v1/buckets/blocklists/collections/plugins/records?_sort=-last_modified'\nresp = requests.get(PROD_URL, headers={\n    \"Date\": b\"Mon Apr 10 2017 15:41:28 GMT 0900 (\\x93\\x8c\\x8b\\x9e (\\x95W\\x8f\\x80\\x8e\\x9e))\"\n}, auth=HTTPBasicAuth(\"ethan\", \"test\"))\nLOCAL_URL = 'http://localhost:8888/v1/buckets/default/collections/test/records?_sort=-last_modified'\nresp = requests.get(LOCAL_URL, headers={\n    \"Date\": b\"Mon Apr 10 2017 15:41:28 GMT 0900 (\\x93\\x8c\\x8b\\x9e (\\x95W\\x8f\\x80\\x8e\\x9e))\"\n}, auth=HTTPBasicAuth(\"ethan\", \"test\"))\n```\n. Thanks!. Do we have a complete set of request information that triggered this bug?. The behavior of the client is just to do a sync() on this collection, which only has this one record. This happens before any other access of the default bucket. After the keyring is synced, every extension's collection is synced (in parallel).. OK, this seems like it's a duplicate of #624 then, thanks, closing.. In addition to removing deletions which aren't necessary, @leplatrem responded to my confusion about what the heck was going on in the plugin by renaming some variables. Remember, in Cliquet, collection_id meant something more like resource_name (see #710). Also, the IDs are not IDs of buckets and collections, but rather of \"records\" that track bucket and collection quota info respectively.. The actual failure is plaster.exceptions.InvalidURI: Could not determine the loader scheme for the supplied config_uri.. 6.X needs a backport of https://github.com/Kinto/kinto/pull/1208.. Isn't that syntax ambiguous? It's the same to search for any object whose value is the string \"null\". I'd rather be more rigid about what our query syntax is for this case, maybe introducing a new syntax for JSON-y values like is_field.name=null or json_field.name=null.. Should field.name=null match records where the field is missing, or only where it is explicitly present and null? (I would vote for the second option)\n. Fixed by #1252 and #1258.. Fixed by #1252 with tests added in #1258.. Refs #1216 and #1215. I think we're trying too hard to be clever with an ad-hoc string query syntax and IMO we should leave the current syntax in place (\"simple\" syntax, where anything that can be converted to a number is a number and everything else is a string) and add a robust syntax that can encode any value as well as its type. I'd propose JSON (so /records?min_target.version=53 for number, /records?min_target.version=\"53\" for string, /records?min_target.version=null for null, etc.).\nFor comparison order, one reason I don't want to be too clever here is that I'm afraid of inventing an inconsistent order. E.g. 2.0 < 10 but 10 < \"2.0b\". Having a robust syntax doesn't completely avoid this problem because data in different records can be of different types, and we will have to order them somehow (if we get e.g. _sort=different_typed_field). How do we handle that? I don't think throwing an exception in this case is necessarily a bad thing, but if we have to invent an ordering, I think \"all ints are less than all strings\" [i.e. the Python2.7 comparison rules] is fine.\n. There were two parts to this bug and the JSON decoder fixes the first one. Previously, this request would work \"sometimes\" depending on whether the data in the record looked numeric or not. Now, it never works, which is an improvement.\nThe second part of the bug is about how we compare numbers to strings. Like I wrote originally, we already have that problem. You can put record1 = {\"flavor\": \"1\"} and record2 = {\"flavor\": 1} and then _sort=flavor. What order comes out? Does Postgres let you do that? I think the answer to those questions should guide our fix.. It seems that Postgres's sorting order is all strings, followed by all numbers:\n{\n    \"data\": [\n        {\n            \"flavor\": \"1\",\n            \"id\": \"1b210b24-b0e6-44c4-b427-e912a3c94697\",\n            \"last_modified\": 1496695080659,\n            \"null\": null,\n            \"people\": []\n        },\n        {\n            \"flavor\": \"2\",\n            \"id\": \"417fa284-42d0-41ad-a39e-16f40542120c\",\n            \"last_modified\": 1496695076284,\n            \"null\": null,\n            \"people\": []\n        },\n        {\n            \"flavor\": \"strawberry\",\n            \"id\": \"7f163dc4-4aad-4680-bb1d-0c8a4dbcf479\",\n            \"last_modified\": 1496694495121,\n            \"null\": null,\n            \"people\": []\n        },\n        {\n            \"flavor\": 1,\n            \"id\": \"d41694ee-94a5-4f11-93c3-3b3cfee38e5a\",\n            \"last_modified\": 1496695085202,\n            \"null\": null,\n            \"people\": []\n        },\n        {\n            \"flavor\": 2,\n            \"id\": \"83f1952a-5af8-4d98-95f3-93602adc3427\",\n            \"last_modified\": 1496695037864,\n            \"null\": null,\n            \"people\": []\n        }\n    ]\n}\nSo I would say we should compare numbers as different from non-numerics, but compare them earlier.. This is fixed by #1258 (thanks @leplatrem for adding tests to confirm!).. One theory is that the collection doesn't really exist and is being created by the default bucket, but it shows up in the collections list:\n```\n\nhttp GET 'https://webextensions.settings.services.mozilla.com/v1/buckets/default/collections' Authorization:\"Bearer $OAUTH_BEARER_TOKEN\"\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Retry-After, Next-Page, Last-Modified, Pragma, Cache-Control, ETag, Expires, Alert, Backoff, Content-Length, Total-Records\nCache-Control: no-cache, no-store\nConnection: keep-alive\nContent-Length: 591\nContent-Type: application/json\nDate: Mon, 22 May 2017 14:39:20 GMT\nETag: \"1495226961598\"\nLast-Modified: Fri, 19 May 2017 20:49:21 GMT\nTotal-Records: 7\nX-Content-Type-Options: nosniff\n\n{\n    \"data\": [\n        {\n            \"id\": \"ext-kUzzyCxGNwiFvYYi1ZO1MkTOGsoO9jgBZ92WOkbRrJE\",\n            \"last_modified\": 1495226961598\n        },\n        {\n            \"id\": \"storage-sync-crypto\",\n            \"last_modified\": 1495204273593\n        },\n        {\n            \"id\": \"ext-HiBPc2uTndUKhd4YvUw3v9Uz-tSiSh99_th9vaUlfjg\",\n            \"last_modified\": 1493593179857\n        },\n        {\n            \"id\": \"ext-lCLovzdsTMn9wexv1IWrfvv-nl9-zcjqjN6VkzfS_6g\",\n            \"last_modified\": 1493593179648\n        },\n        {\n            \"id\": \"ext-Ccc4rbVqgGSk-K7sUJv_68gQdPlmqiqNkffN4uv9-Jc\",\n            \"last_modified\": 1493386699683\n        },\n        {\n            \"id\": \"ext-XoxmiYy4pv3TApmYW4H3O8-cyUg4itiSKqDOVseaOC8\",\n            \"last_modified\": 1490785806741\n        },\n        {\n            \"id\": \"ext-Y90xoorGgbLBgNeFEapkV_aLf7h4zwd2ns79UeEceYg\",\n            \"last_modified\": 1490785480260\n        }\n    ]\n}\n.\n\nhttp DELETE 'https://webextensions.settings.services.mozilla.com/v1/buckets/default/collections/ext-Ccc4rbVqgGSk-K7sUJv_68gQdPlmqiqNkffN4uv9-Jc' Authorization:\"Bearer $OAUTH_BEARER_TOKEN\"\nHTTP/1.1 507 Insufficient Storage\nAccess-Control-Expose-Headers: Backoff,Retry-After,Alert,Content-Length\nConnection: keep-alive\nContent-Length: 125\nContent-Type: application/json\nDate: Mon, 22 May 2017 14:50:07 GMT\nX-Content-Type-Options: nosniff\n\n{\n    \"code\": 507,\n    \"errno\": 121,\n    \"error\": \"Insufficient Storage\",\n    \"message\": \"Collection maximum size exceeded (102426 > 102400 Bytes).\"\n}\n```\nBut this doesn't really surprise me, because we enforce quotas even on DELETE (see e.g. https://github.com/Kinto/kinto/pull/752#r74076173).. I can GET some collections, including storage-sync-crypto; the ones that I can get are all empty, except for storage-sync-crypto, which:\n```\n\nhttp GET 'https://webextensions.settings.services.mozilla.com/v1/buckets/default/collections/storage-sync-crypto/records?_since=0' Authorization:\"Bearer $OAUTH_BEARER_TOKEN\"| wc\n      0       1    1788\n```\n\n... is certainly no bigger than that. I could always delete the bucket; that ought to work, but I don't really want to try that until I have a better idea what happened.. I was able to delete ext-XoxmiYy4pv3TApmYW4H3O8-cyUg4itiSKqDOVseaOC8, which had been one of the empty ones. The collection which produces the 507 still does, with the same number of bytes. Anything worth doing is worth overdoing, so I tried deleting all the other collections too. The ones that I had previously been able to fetch were successfully deleted, but the ones that I hadn't been able to GET before are also impermeable to DELETE. I now have three remaining collections -- storage-sync-crypto and the two I couldn't delete before.. This is now a tracking bug for #1226, #1229, and #1230.. Thanks for your contribution! The tests you mention don't seem to actually use a mock. Instead I think they just use the memory backend. It's possible that storing a bytes to Postgres makes it come back as str but come back as bytes in the memory backend. If that's true, I wonder how we're storing the \"bytes\" of the hashed password in Postgres? We might be accidentally storing it as a JSON string full of \\uXXXX. If that's true, I think the best fix would be to take the hashed password and encode it as base64 in the Account view (which reduces storage use as well as giving us a consistent type to work with).. When you say decode on bcrypt's result, do you mean base64 => bytes, or do you mean base64 bytes => base64 str? If I understand correctly, the second sounds OK to me.. I feel like there's another larger issue here which is that we should only support storing true JSON records -- meaning, we should have barfed when the hashed password (as bytes) tried to get stored to Postgres. Is there an option for ujson to let us not serialize bytes, but only the usual booleans, integers, floats, strings, lists, dicts, and None?. Great work, solid investigation! Thank you so much for your effort on this!. OK, I guess this was easier to fix than I was worried it would be.. I decided that the tests really belonged on default_bucket, since that's the component that changed. I rewrote the branch and threw away the tests on the quotas plugin.. Sure. Closing in favor of #360.. Isn't it because your query now returns the deleted tombstones UNION the deleted timestamps and returns the rowcount as the number of deleted things?\nTo be honest, I don't think this fixes the problem and I am no longer sure it's worth fixing. I'm not as experienced with SQL stuff as you are but the Postgres documentation says \"UPDATE, DELETE, SELECT FOR UPDATE, and SELECT FOR SHARE commands behave the same as SELECT in terms of searching for target rows: they will only find target rows that were committed as of the command start time.\" My interpretation of this is that if you have two DELETE queries as subqueries of a single SELECT, things can be committed after the first one and before the second one, which is the thing we wanted to avoid.\nI think we should probably just go back to the way the code was before this last commit and (as a follow-up) make the isolation level a Kinto-wide configuration option. Otherwise we're just trying to force transactional semantics by wedging our queries together.. This should be ready for legit review now.. Fantastic, thank you.. This is clearly an improvement, I'm just going to merge as-is. Thanks again for your hard work!. I've opened https://github.com/esnme/ultrajson/issues/264 to see what upstream thinks about disallowing bytes, but I don't really expect that to happen because ujson's approach seems to generally be \"Serialize it all and let Douglas Crockford sort 'em out\". For example:\n```\n\n\n\nujson.dumps({\"hi\": set()})\n'{\"hi\":[]}'\nujson.dumps({\"hi\": object()})\n'{\"hi\":{}}'\nclass MyFoo:\n...   def init(self, a, b):\n...     self.a = a\n...     self.b = b\n... \nujson.dumps(MyFoo(1, 'a'))\n'{\"a\":1,\"b\":\"a\"}'\n```\n\n\n\nCompare this with the built-in json, which is quite conservative about what it will serialize:\n```\n\n\n\njson.dumps({\"hi\": set()})\nTraceback (most recent call last):\n  File \"\", line 1, in \n  File \"/usr/lib64/python3.5/json/init.py\", line 230, in dumps\n    return _default_encoder.encode(obj)\n  File \"/usr/lib64/python3.5/json/encoder.py\", line 198, in encode\n    chunks = self.iterencode(o, _one_shot=True)\n  File \"/usr/lib64/python3.5/json/encoder.py\", line 256, in iterencode\n    return _iterencode(o, 0)\n  File \"/usr/lib64/python3.5/json/encoder.py\", line 179, in default\n    raise TypeError(repr(o) + \" is not JSON serializable\")\nTypeError: set() is not JSON serializable\njson.dumps({\"hi\": object()})\nTraceback (most recent call last):\n  File \"\", line 1, in \n  File \"/usr/lib64/python3.5/json/init.py\", line 230, in dumps\n    return _default_encoder.encode(obj)\n  File \"/usr/lib64/python3.5/json/encoder.py\", line 198, in encode\n    chunks = self.iterencode(o, _one_shot=True)\n  File \"/usr/lib64/python3.5/json/encoder.py\", line 256, in iterencode\n    return _iterencode(o, 0)\n  File \"/usr/lib64/python3.5/json/encoder.py\", line 179, in default\n    raise TypeError(repr(o) + \" is not JSON serializable\")\nTypeError:  is not JSON serializable\n```\n\n\n\nIt might be smart to use the built-in JSON during testing and use ujson for increased performance when in production. That might be more work?. Closing in favor of #1240.. I believe this fixes #1216 and #1215.. The problem is that the behavior of ujson is arguably broken and lets a developer accidentally serialize things that shouldn't be serializable. Any arbitrary object will be serialized by using its __dict__. But what I'm most worried about is that we would serialize a bytestring that seems OK until by chance it contains some non-UTF-8 encoded text and then failing.\nPersonally I don't think this is too much complexity to avoid those kinds of bugs. (The PR only changes ~75ish lines of code.) The only thing that I might consider is trying to localize the complexity to the utils module.. Refs https://github.com/esnme/ultrajson/pull/266.\nI tried \"simplifying\" this by centralizing the logic to dispatch between JSON flavors in utils.json, but that didn't work because there's nothing to dispatch according to. (This isn't flask; I don't have global access to the request or the config.) I think it would be possible to implement @elelay's suggestion of mocking/overriding the utils.json flavor using a monkeypatch, but that seems much uglier to me than just configuring it explicitly (as has been done here).\n@leplatrem @Natim Would you veto if I wanted to land it? I see a +1 for using ujson on everything, but no strong objection against the patch as it stands now. Do you have an alternative implementation in mind that would be cleaner?\nThis PR needs a rebase in the meantime, plus there are a few remaining nits from the review.\n. Thanks for your work and for bearing with us while we sorted this out!. There's also the question of sort order. Postgres documentation says that By default, null values sort as if larger than any non-null value; that is, NULLS FIRST is the default for DESC order, and NULLS LAST otherwise. However, because of our strange coalescing behavior, you can get it to do strange things:\n```\n\nhttp -a 'user:pass' POST localhost:8888/v1/buckets/default/collections/icecream/records data:='{\"flavor\": \"strawberry\"}'\nhttp -a 'user:pass' POST localhost:8888/v1/buckets/default/collections/icecream/records data:='{\"flavor\": \"blueberry\",\"author\": \"Ethan\"}'\nhttp -a 'user:pass' POST localhost:8888/v1/buckets/default/collections/icecream/records data:='{\"flavor\": \"raspberry\",\"author\": null}'\nhttp -a 'user:pass' 'localhost:8888/v1/buckets/default/collections/icecream/records?_sort=author'\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Total-Records, Cache-Control, Content-Length, Alert, ETag, Expires, Pragma, Last-Modified, Retry-After, Next-Page, Backoff\nCache-Control: no-cache, no-store\nContent-Length: 333\nContent-Type: application/json\nDate: Tue, 06 Jun 2017 21:17:07 GMT\nEtag: \"1496783699002\"\nLast-Modified: Tue, 06 Jun 2017 21:14:59 GMT\nServer: waitress\nTotal-Records: 3\nX-Content-Type-Options: nosniff\n\n{\n    \"data\": [\n        {\n            \"author\": null,\n            \"flavor\": \"raspberry\",\n            \"id\": \"265506f9-2a07-4ba4-a548-8b7cd3b9a457\",\n            \"last_modified\": 1496783699002\n        },\n        {\n            \"author\": \"Ethan\",\n            \"flavor\": \"blueberry\",\n            \"id\": \"0a1b92fd-ddf7-460b-aceb-59b5f599c0eb\",\n            \"last_modified\": 1496783688505\n        },\n        {\n            \"flavor\": \"strawberry\",\n            \"id\": \"480f82db-1dc9-4a61-ac02-fefcda8c8928\",\n            \"last_modified\": 1496783673440\n        }\n    ]\n}\nSeems legit. Let's paginate\n\nhttp -a 'user:pass' 'localhost:8888/v1/buckets/default/collections/icecream/records?_sort=author&gt_author=a'\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Total-Records, Cache-Control, Content-Length, Alert, ETag, Expires, Pragma, Last-Modified, Retry-After, Next-Page, Backoff\nCache-Control: no-cache, no-store\nContent-Length: 124\nContent-Type: application/json\nDate: Tue, 06 Jun 2017 21:17:41 GMT\nEtag: \"1496783699002\"\nLast-Modified: Tue, 06 Jun 2017 21:14:59 GMT\nServer: waitress\nTotal-Records: 1\nX-Content-Type-Options: nosniff\n\n{\n    \"data\": [\n        {\n            \"author\": \"Ethan\",\n            \"flavor\": \"blueberry\",\n            \"id\": \"0a1b92fd-ddf7-460b-aceb-59b5f599c0eb\",\n            \"last_modified\": 1496783688505\n        }\n    ]\n}\nWait... what happened to strawberry?\n```. Interestingly, this behavior seems to be even more bonkers for integer fields:\n```\n\nhttp -a 'user:pass' 'localhost:8888/v1/buckets/default/collections/icecream2/records'\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Last-Modified, Total-Records, Retry-After, Pragma, Alert, Cache-Control, ETag, Backoff, Next-Page\nCache-Control: no-cache, no-store\nContent-Length: 327\nContent-Type: application/json\nDate: Wed, 07 Jun 2017 15:55:20 GMT\nEtag: \"1496850665926\"\nLast-Modified: Wed, 07 Jun 2017 15:51:05 GMT\nServer: waitress\nTotal-Records: 3\nX-Content-Type-Options: nosniff\n\n{\n    \"data\": [\n        {\n            \"author\": null,\n            \"flavor\": \"raspberry\",\n            \"id\": \"9b5a421c-8860-4331-8fdb-590c41bb443c\",\n            \"last_modified\": 1496850665926\n        },\n        {\n            \"author\": 1,\n            \"flavor\": \"blueberry\",\n            \"id\": \"23697cff-be13-419e-b6d5-9023b2b09f62\",\n            \"last_modified\": 1496850661019\n        },\n        {\n            \"flavor\": \"strawberry\",\n            \"id\": \"dc70e65a-7835-4b38-a9ca-59de6c7e532a\",\n            \"last_modified\": 1496850653779\n        }\n    ]\n}\n\nhttp -a 'user:pass' 'localhost:8888/v1/buckets/default/collections/icecream2/records?lt_author=2'\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Last-Modified, Total-Records, Retry-After, Pragma, Alert, Cache-Control, ETag, Backoff, Next-Page\nCache-Control: no-cache, no-store\nContent-Length: 118\nContent-Type: application/json\nDate: Wed, 07 Jun 2017 15:55:34 GMT\nEtag: \"1496850665926\"\nLast-Modified: Wed, 07 Jun 2017 15:51:05 GMT\nServer: waitress\nTotal-Records: 1\nX-Content-Type-Options: nosniff\n\n{\n    \"data\": [\n        {\n            \"author\": 1,\n            \"flavor\": \"blueberry\",\n            \"id\": \"23697cff-be13-419e-b6d5-9023b2b09f62\",\n            \"last_modified\": 1496850661019\n        }\n    ]\n}\nHmm, OK, I guess null and missing fields should be greater than?...\n\nhttp -a 'user:pass' 'localhost:8888/v1/buckets/default/collections/icecream2/records?gt_author=2'\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Last-Modified, Total-Records, Retry-After, Pragma, Alert, Cache-Control, ETag, Backoff, Next-Page\nCache-Control: no-cache, no-store\nContent-Length: 11\nContent-Type: application/json\nDate: Wed, 07 Jun 2017 15:55:58 GMT\nEtag: \"1496850665926\"\nLast-Modified: Wed, 07 Jun 2017 15:51:05 GMT\nServer: waitress\nTotal-Records: 0\nX-Content-Type-Options: nosniff\n\n{\n    \"data\": []\n}\n\nhttp -a 'user:pass' 'localhost:8888/v1/buckets/default/collections/icecream2/records?min_author=2'\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Last-Modified, Total-Records, Retry-After, Pragma, Alert, Cache-Control, ETag, Backoff, Next-Page\nCache-Control: no-cache, no-store\nContent-Length: 11\nContent-Type: application/json\nDate: Wed, 07 Jun 2017 15:56:05 GMT\nEtag: \"1496850665926\"\nLast-Modified: Wed, 07 Jun 2017 15:51:05 GMT\nServer: waitress\nTotal-Records: 0\nX-Content-Type-Options: nosniff\n\n{\n    \"data\": []\n}\nwat?\n``. Fixed by #1258.. I've added some commits to implement ahas_operator, addressing #344 directly, since the change in how we handle missing fields breaks a test each intest_views_groupsandtest_views_collections`. I know this is kind of outside the scope of this PR, but it touches a lot of the same code and benefits from the new cleaner implementation. If you'd rather, I can separate out the commits for that feature.. I only have two concerns about HTTP API compatibility:\n\nWe break the technique shown in https://github.com/Kinto/kinto/issues/344 (but that was never documented, so I'm not super worried about it)\n\nWe implicitly discourage the use of fields with the name has_foo. I'm not crazy about the multiple-commands thing. Parsing such a command line sounds kind of crazy (--ini has to apply to both migrate and start, but --port should only apply to start?). Why don't we define a special command migrate-and-start for this use case? Or maybe define a setup.py entrypoint in Python and call it kinto-run-in-docker?. Yes, kinto migrate updates the database schema to bring it up to date with the code that's running against it. This is especially important for the first run, which initializes the schema :). You found a good one. Some additional information:\n\n\nIt changed between pyramid_tm 1.1.1 and pyramid_tm 2.0.\n\nThe transaction.abort() call that you added does not fix anything in pyramid_tm 2.0 -- it only \"works\" in pyramid_tm 2.1.\nIt seems like in all versions of pyramid_tm, the transaction is aborted once an exception is raised.\n\nIs it maybe time that we stop registering ResourceChanged as a pre-commit hook and used it instead as a commit veto hook?\nStill digging... Worked on this a bit more today. The behavior seems to be a bit different in pyramid 2.0 and pyramid 2.1. In pyramid 2.0, I see (from the logs) that the transaction is aborted, but then another transaction is created and that one commits. However, this isn't what fails the test. The test fails because the exception isn't turned into a failing 507 response. That bug gets fixed in 2.1 (I think it's https://github.com/Pylons/pyramid_tm/pull/61). However, now, the transaction doesn't get aborted; it doesn't commit as part of the response, but it does commit later (when it goes out of scope?), which causes subsequent requests to fail. (Actually, we got lucky; the DELETE to clean up is what fails, even though it probably shouldn't.)\nSome of the error handling paths in pyramid_tm cause the transaction to be aborted. It might be a bug that prevents it from being aborted in this case. I'm going to file a bug upstream and see what they think.. Based on my discussions with upstream, using a beforeCommit hook here is not the right choice. beforeCommit hooks are only called once the decision to commit has been made. Instead, we can use a tween to fire ResourceChanged events at the end of the request. If this raises an exception, pyramid_tm will abort the transaction. I've pushed a change demonstrating the technique. What do you think, @leplatrem?. You beat me to this! Good work!. The tests use account_write_principals and account_read_principals, but don't have account_create_principals (which is the setting mentioned in the documentation). Adding account_create_principals breaks everything. (I'll open a PR soon.) Probably we should rerun the tests with a few different valid combinations of settings (create, read+write, create+read+write...).\nEdit: this test failure is not exactly the same as the bug reported... OK, so setting account_create_principals gets you into an interesting bootstrapping problem where you can't create an account without being an admin, but you can't be an admin without creating the account. So that's why all the tests failed. However, what actually happened for me when I reproduced R\u00e9my's problem is that the tests don't consider you an admin unless you also have account_write permission. This makes some sense -- probably anyone should be able to create their own account, so having that permission doesn't make you an admin -- but it's definitely missing from the documentation.. I changed my mind, and decided that it makes more sense to raise a ConfigurationError if someone is allowed to create accounts but isn't themselves an admin, because there doesn't appear to be a valid use case for it yet. We can always undo this restriction later if it turns out to be useful to someone.. I think this is an issue for kinto-admin.. CSV export is covered by https://github.com/Kinto/kinto-admin/issues/438 and https://github.com/Kinto/kinto/issues/817.\nI've opened https://github.com/Kinto/kinto-admin/issues/441 for \"delete by batch\".\nI've opened https://github.com/Kinto/kinto-admin/issues/442 for \"Filter by properties\".\nClosing this.. I believe point 2 (above) may also apply to the Postgres backend.. Let's close it in favor of #1407... I believe this is the aftermath of https://github.com/Kinto/kinto/pull/1271. After some investigation with @jasonthomas, we believe that the script didn't actually run over all of the affected users -- in particular, there appear to be 14 that weren't covered by the second run of the rebuild-quotas script. We think this is due to #1267 not having landed yet. Rerunning rebuild-quotas should fix it (and any other users whose quotas weren't actually rebuilt). Since it's been a month and a half and today is the first occurrence of this, it seems like there's no real urgency, so we're going to wait until Monday to rerun it.. This should be fixed now that we reran the script.. I've been able to reproduce this locally by adding some weird code to the kinto-fxa module and hammering it.\ndiff\ndiff --git a/kinto_fxa/authentication.py b/kinto_fxa/authentication.py\nindex f69c421..941b204 100644\n--- a/kinto_fxa/authentication.py\n+++ b/kinto_fxa/authentication.py\n@@ -81,6 +81,20 @@ class FxAOAuthAuthenticationPolicy(base_auth.CallbackAuthenticationPolicy):\n         auth_cache = self._get_cache(request)\n         auth_client = OAuthClient(server_url=server_url, cache=auth_cache)\n         try:\n+            #print(\"About to verify\")\n+            import random\n+            import time\n+            r1 = random.randint(1, 10000000)\n+            cache = request.registry.cache\n+            for i in range(10):\n+                r1 = random.randint(1, 10000000)\n+                r2 = random.randint(1, 10000000)\n+                cache.set(\"Ethan is testing\" + str(r1), \"hi\" + str(r2), 300)\n+            try:\n+                cache.get(\"Ethan is testing\" + str(r1))\n+            except Exception as e:\n+                print(\"Exception!\", r1, e)\n+                raise e\n             profile = auth_client.verify_token(token=auth, scope=scope)\n             user_id = profile['user']\n         except fxa_errors.OutOfProtocolError as e:\nrace-fxa.py:\n```python\nimport aiohttp\nimport asyncio\nimport async_timeout\nAUTH = \"Bearer ......\"   # some legit bearer token\nURL = 'http://localhost:8888/v1/buckets/default/collections/plop'\nasync def fetch(session):\n    with async_timeout.timeout(10000):\n        async with session.get(URL) as response:\n            resp = await response.json()\n            print(resp)\n            assert response.status == 200\nasync def main():\n    async with aiohttp.ClientSession(headers={\"Authorization\": AUTH}) as session1:\n        await asyncio.gather(*[fetch(session1) for i in range(4)])\nloop = asyncio.get_event_loop()\nloop.run_until_complete(main())\n```\nRun with:\nwhile python race-fxa.py; date; end; date\nThis usually produces the exception, sometimes in as few as 500 seconds, sometimes in as much as 6000 seconds. The magic numbers (ttl=300, 4 threads) seem to be relatively important because trying to change them makes it harder to reproduce (I had no luck with ttl=15 nor with ttl=3000). The exception leaves messages like this in the Postgres log:\nERROR:  deadlock detected\nDETAIL:  Process 20392 waits for ShareLock on transaction 13130988; blocked by process 20391.\n        Process 20391 waits for ShareLock on transaction 13130989; blocked by process 20392.\n        Process 20392: DELETE FROM cache WHERE ttl IS NOT NULL AND now() > ttl;\n        Process 20391: DELETE FROM cache WHERE ttl IS NOT NULL AND now() > ttl;\nHINT:  See server log for query details.\nCONTEXT:  while deleting tuple (482,68) in relation \"cache\"\nSTATEMENT:  DELETE FROM cache WHERE ttl IS NOT NULL AND now() > ttl;\nFinding this unhelpful, I added information to the query to make it clearer which \"get\" query prompted the DELETE:\nERROR:  deadlock detected\nDETAIL:  Process 5119 waits for ShareLock on transaction 13272262; blocked by process 5117.\n        Process 5117 waits for ShareLock on transaction 13272270; blocked by process 5119.\n        Process 5119: DELETE FROM cache WHERE ttl IS NOT NULL AND now() > ttl; -- 'fxa.oauth.verify_token:993e1f0b77d15d1ac958d4f687959eec6620cbce2684c718eaad2a4efa36513a:[''sync:addon_storage'']'\n        Process 5117: DELETE FROM cache WHERE ttl IS NOT NULL AND now() > ttl; -- 'Ethan is testing4822691'\nHINT:  See server log for query details.\nCONTEXT:  while deleting tuple (167,97) in relation \"cache\"\nSTATEMENT:  DELETE FROM cache WHERE ttl IS NOT NULL AND now() > ttl; -- 'fxa.oauth.verify_token:993e1f0b77d15d1ac958d4f687959eec6620cbce2684c718eaad2a4efa36513a:[''sync:addon_storage'']'\nAs the logs indicate, both transactions are blocked on a ShareLock. Mathieu didn't find the ShareLocks for two reasons -- one, the lock doesn't show up in pg_locks until the second transaction is blocked on it, and two, the query he used excludes locks from pg_locks like this one, with relation being NULL. However, here's what it looks like:\ntestdb=# select * from pg_locks;\n   locktype    | database | relation | page | tuple | virtualxid | transactionid | classid | objid | objsubid | virtualtransaction |  pid  |\n        mode         | granted | fastpath \n---------------+----------+----------+------+-------+------------+---------------+---------+-------+----------+--------------------+-------+\n---------------------+---------+----------\n relation      |    16401 |    61705 |      |       |            |               |         |       |          | 14/685             | 16268 |\n RowExclusiveLock    | t       | t\n relation      |    16401 |    61703 |      |       |            |               |         |       |          | 14/685             | 16268 |\n RowExclusiveLock    | t       | t\n relation      |    16401 |    61697 |      |       |            |               |         |       |          | 14/685             | 16268 |\n RowExclusiveLock    | t       | t\n virtualxid    |          |          |      |       | 14/685     |               |         |       |          | 14/685             | 16268 |\n ExclusiveLock       | t       | t\n relation      |    16401 |    11695 |      |       |            |               |         |       |          | 11/1007            | 21622 |\n AccessShareLock     | t       | t\n virtualxid    |          |          |      |       | 11/1007    |               |         |       |          | 11/1007            | 21622 |\n ExclusiveLock       | t       | t\n relation      |    16401 |    61705 |      |       |            |               |         |       |          | 5/2152393          | 19719 |\n RowExclusiveLock    | t       | t\n relation      |    16401 |    61703 |      |       |            |               |         |       |          | 5/2152393          | 19719 |\n RowExclusiveLock    | t       | t\n relation      |    16401 |    61697 |      |       |            |               |         |       |          | 5/2152393          | 19719 |\n RowExclusiveLock    | t       | t\n virtualxid    |          |          |      |       | 5/2152393  |               |         |       |          | 5/2152393          | 19719 |\n ExclusiveLock       | t       | t\n transactionid |          |          |      |       |            |      13272541 |         |       |          | 5/2152393          | 19719 |\n ShareLock           | f       | f       # <-- this one\n transactionid |          |          |      |       |            |      13272541 |         |       |          | 14/685             | 16268 |\n ExclusiveLock       | t       | f\n transactionid |          |          |      |       |            |      13272542 |         |       |          | 5/2152393          | 19719 |\n ExclusiveLock       | t       | f\n tuple         |    16401 |    61697 |    0 |     3 |            |               |         |       |          | 5/2152393          | 19719 |\n AccessExclusiveLock | t       | f\n(14 rows)\nFrom my reading (e.g. this one), the first transaction doesn't generate a lock because it can tell that the row hasn't been modified by any current transaction; instead it just optimistically updates it. The second transaction wants to grab a row lock on some rows, and this turns into a transaction lock.\nIt seems like a ShareLock is the kind of lock that is acquired when trying to determine whether a row matches a WHERE clause in some other query. So the second DELETE query is determining whether it's going to delete the rows deleted by the first query (which could still rollback).\nA deadlock only occurs when two transactions grab locks on objects in a different order. In this case, it seems clear that the objects being locked are rows, and it seems like the queries that are grabbing locks are the DELETE queries. So why are the locks being grabbed in a different order? I don't 100% understand the query plans given, but it seems that the DELETE query is visiting rows in physical order rather than according to the index, because:\n```\ntestdb=# explain (verbose) delete from cache where ttl is not null and '2017-08-08 19:54:06' > ttl;\n                                                        QUERY PLAN                                                        \n\nDelete on public.cache  (cost=234.32..2595.19 rows=4869 width=6)\n   ->  Bitmap Heap Scan on public.cache  (cost=234.32..2595.19 rows=4869 width=6)\n         Output: ctid\n         Recheck Cond: ((cache.ttl IS NOT NULL) AND ('2017-08-08 19:54:06'::timestamp without time zone > cache.ttl))\n         ->  Bitmap Index Scan on idx_cache_ttl  (cost=0.00..233.11 rows=4869 width=0)\n               Index Cond: ((cache.ttl IS NOT NULL) AND ('2017-08-08 19:54:06'::timestamp without time zone > cache.ttl))\n(6 rows)\n```\n(A bitmap index scan is explained a bit here.) Note that it generates different query plans for 'timestamp' < ttl vs. 'timestamp' > ttl, and it also generates different query plans for timestamps that are less than/greater than the entire table.\nIn order to explore this a little better, I've been running DELETE queries using data generated with this function:\nplpgsql\nCREATE OR REPLACE FUNCTION public.insert_junk()\n RETURNS void\n LANGUAGE plpgsql\nAS $function$\nBEGIN\nFOR i in 1 .. 100000 LOOP\n  INSERT INTO cache VALUES ('Ethan is testing ' || random() * 100000, i, sec2ttl(random() * 300 + 45)) ON CONFLICT DO NOTHING;\nEND LOOP;\nEND;\n$function$\nThe value field of the database shows its insert order, which appears to match physical order (doing a SELECT * FROM cache LIMIT 10 shows the ones with value 1..10).\nIf both DELETE queries are locking rows in physical order, then it shouldn't be possible to induce a deadlock with just two DELETE queries. Therefore my suspicion, although I haven't reproduced it yet, is that one UPDATE is happening, then a DELETE is blocking on that UPDATE, and then a series of other UPDATEs are happening which change the physical order of the rows, such that when a second DELETE happens, it manages to grab some rows which weren't grabbed by the first DELETE. Then, when the first UPDATE commits, you get a deadlock.\nI'm still trying to reproduce the thing with a clear set of queries, aided by increasingly verbose logging on my local postgres and the occasional reproduced deadlock. However, the real question is what to do about it. Here is a solution that uses SELECT FOR UPDATE to lock rows according to an ORDER BY (i.e. a deterministic order that doesn't depend on physical order or change between transactions). That's probably the most targeted solution.\nThis is also an opportunity to rethink this part of the code more generally. @leplatrem and I both don't like that this get() operation, which has a very read-only sort of name, does a giant delete. To preserve correctness, we could add a AND now() < ttl to the SELECT statement to ensure we only get cache entries that haven't expired yet, and move the DELETE someplace else -- a \"cron job\" sort of thing that happens only once every N seconds, or once every N requests, or with probability xxx%, or something else entirely. (A database trigger?) Alternately, we could replace the giant DELETE with smaller deletes, perhaps having the get() method only delete outdated entries for its own key. If we can be assured that only one DELETE is running at a time, or that each DELETE only locks one row, then we don't really need to care too much about the order in which the DELETE locks the rows, and we wouldn't have to do the SELECT FOR UPDATE thing. On the other hand, it seems that we can get the error with only a few simultaneous requests, so maybe we should do the SELECT FOR UPDATE thing too.\nIt seems like writing an automated test for this would be quite difficult?\n. This is the most verbose log I've gotten yet (from postgres).\nbroken-sql-2.txt\nThis time around, the two transactions that deadlocked started (and issued their DELETE statements) before two previous DELETE statements committed. I'm not sure if that's relevant per se or if it's just part of the initial condition for the transactions/locks.\n. I still can't figure out how the physical order of the rows might change, and the documentation is pretty thin on the subject. It seems like if you have a series of rows sorted by physical order, removing some of them (by updating them with a later TTL or outright deleting them) would leave you with a set that's still in physical order. https://dba.stackexchange.com/a/95852 says that DELETE can change the physical order of rows, but I don't understand how.\n\nYes we could keep the get() as read-only, and delete old entries before adding new ones (from the set() method).\n\nThis wouldn't by itself address the problem; we'd also need to order the DELETE.\n\nApart from the terrible naming of this parameter, I believe there must be a way to change that so that with_transaction=False would mean autocommit each client.execute() query. This way we would avoid this overlap of transactions for atomic operations for example.\n\nI don't think the existence of a transaction is actually relevant for this bug; it's just two overlapping DELETE queries, both of which happen at the beginning of a transaction.. Based on some comments on my StackOverflow cry for help, it seems like actually, the index is being used, and it's guiding the lock acquisition. In #1310, I tried locking them in ttl order, and that lead to deadlocks. Locking them according to key (key), as suggested by a commenter, leads to no deadlocks. So does locking them according to physical order (ctid).\nI still don't really understand why locking them according to ttl order leads to deadlocks in our application. Any update to a cache entry should remove it from the set that should be about to be deleted. One commenter suggested that ordering by ttl is not well-defined if two entries have the same ttl, but I haven't been able to reproduce it that way either. But at this point I'm running out of patience -- I have two fixes that both seem to work and a vague understanding, so maybe that's good enough.. OK, I did a little bit more investigation this morning. I set the deadlock_timeout parameter to one day, and then when the transactions deadlocked I was able to use SQL queries to investigate what rows had been grabbed by what transactions (using SELECT xmax, * FROM cache ORDER BY ttl limit 10). It seems like the two transactions deadlocked by both grabbing one of two rows that have the same ttl. I guess having equal ttl means that the order is undefined. Even with this information, I still wasn't able to reproduce the deadlock \"by hand\" -- in my tests, it always appears to grab the locks in a deterministic way (I guess by ttl and then physical order, or something like that). Still, #1312 should address the problem.. This didn't seem to work either.... > Today that's what it is.\nMaybe we should rename it from \"accounts API\" to \"basic auth v2\".. Hmm, I think it's OK to disallow it for \"regular\" JSON. I like the solution in your PR.. I'm OK with this, but what's the purpose of it? Is it smaller or something?. As far as I know, there is no word overriden, only overridden is correct. Nice catch!. Thanks!. Also in the documentation is this example, which I think is incorrect: {\"a\": {\"b\":\"c\"}} + {\"a\":{\"d\":\"e\"}} \u2192 {\"a\":{\"b:c\", \"d\":\"e\"}} (because \"b:c\" isn' valid JSON). That might be outside the scope of this PR, but if you're in there anyhow... \ud83d\ude07 \n. The changes look fine to me. The only wrinkle I can think of is emptying an existing collection, but you already thought of that by handling tombstones.\nI'm not 100% sure how to handle updating timestamps that are in the past. If we set last_modified back to the \"new\" old record, then we will re-sync certain records. If we don't update last_modified, there's no way for the client to know about the records in the past. I think we have to accept that putting records in the past is going to break synchronization. Based on that, I would say we should try to keep last_modified monotonic.\nMy opinion, therefore, about the right behavior of the two tests:\n\ntest_create_ignores_specified_last_modified_if_in_the_past: timestamp should be the same as timestamp_before (change assertGreater to assertEqual).\ntest_update_ignores_specified_last_modified_if_in_the_past: timestamp goes backwards here because the last_modified of the only record goes backwards. We could handle this by insert into timestamps on the first record save, which will ensure that the collection's timestamp doesn't go backwards in this case, but still leaves us open to slightly more complicated cases (record A is inserted, followed by record B; timestamp_before is taken; B is put 10 seconds in the past; timestamp is now record A). So I think the right behavior here is to do nothing (let timestamp go backwards). Anyone explicitly setting last_modified had better know what they're doing and might break synchronization.. Thanks for digging into this so much @leplatrem, and thanks for the explanation @almet. I don't claim to 100% understand the factors in play here, but I agree that bumping a collection timestamp with record timestamps in the past doesn't seem to make sense, because follow-up queries with ?_since=... won't match the new records and will generally just confuse the client. (This would probably give you a Server was flushed in kinto.js.) I understand how exact replication of timestamps could be important for kinto-signer use cases, but I don't understand how it could possibly be correct to bump a timestamp while preserving a different one.. Should we try to log any information about the user who hit the error?. Could I get a rereview now that I had to commit to >1.9?. This seems to happen repeatedly for certain IDs. For instance, we noticed that it happens an awful lot for bucket ID 6a1ee6f2-2e10-fa9e-3bc3-25904412946e. Based on this, I suspected it might be due to bad data rather than any kind of race condition. If the client issues a \"delete bucket\" request when there's a record in the deleted table, we could get this kind of error. On the other hand, we should remove the rows from the deleted table when we create or update the bucket, which should happen on almost every request for the default_bucket plugin. Anyhow, I asked Wei to look in the production tables and here's what he found: https://irccloud.mozilla.com/pastebin/hvmDywwh/. It isn't clear to me yet how we are getting into this state. I can't reproduce it easily with simple sequential queries. Maybe there was a race condition at first that got us into a bad state but wasn't logged as an error?. According to a query run in production, there are 23 records appearing in both deleted and records. https://irccloud.mozilla.com/pastebin/HMXMzNFs/. I detailed what I think is actually happening in #1396.. This should be fixed in 8.0.0.. Should we maybe try to add a statement to the migration to handle cases where the record was both in deleted and records?. Speaking about this more, this still leaves the TOCTOU whole in create described by #1388, but we think that's essentially solveable and will go ahead merging/starting the deploy process moving for this PR. I'll take over to write a PR for #1388.. I could be wrong, but I wonder if 2-phase commit would even be helpful here -- the problem isn't that some transactions succeed and some don't, the problem is that with READ COMMITTED we can get changes in the middle of our transactions.. I've also gotten deadlocks from this script. In that case, try uncommenting the put_record call and changing it to delete_bucket.\n\nI've also had this script \"succeed\" from Kinto responses but leave records in both deleted and records.. I'm extracting the \"both deleted and records\" bug as #1396.\nI believe what's happening in this one is something like the following:\n\nThe record in question (the default bucket) is deleted at the top of the request.\nRequest 1 and request 2 both start around the same time.\nBoth requests do self.get() to check if the request exists already. It doesn't.\nBoth try to delete the tombstone and insert into records. One succeeds, the other gets an integrity error.\n\nI don't believe #1386 will fix this one -- we need to stop doing explicit checks for the record using self.get(), because that's a classic TOCTOU error.. This is also a duplicate of #1376. I need to refer to existing bugs more often.. Duplicate of #1375.. Replaced by #1403.. Per https://docs.pytest.org/en/latest/changelog.html#pytest-3-3-0-2017-11-23:\n\nPytest now captures and displays output from the standard logging module. The user can control the logging level to be captured by specifying options in pytest.ini, the command line and also during individual tests using markers. Also, a caplog fixture is available that enables users to test the captured log during specific tests (similar to capsys for example). For more information, please see the logging docs. This feature was introduced by merging the popular pytest-catchlog plugin, thanks to Thomas Hisch. Be advised that during the merging the backward compatibility interface with the defunct pytest-capturelog has been dropped. (#2794)\n\nI believe this means we can just remove the pytest-capturelog plugin and everything will work fine.. No problem, I was just trying to model it off of other existing changelog entries and didn't see anything that looked relevant.. I'm not actually sure how to fix the TOCTOU at the resource level. The reason we do a get first is to enforce 412 concurrency headers. Would we have to do a SELECT FOR UPDATE? If so, that would probably require another break in compatibility with the storage backend, in which case yes maybe we should do it in this PR.. N.B. the TOCTOU bug at the resource level affects put, patch, delete, and collection_post.\nAnother approach might be to have the INSERT/UPDATE/DELETE queries return any replaced rows, and do the 412 afterwards, rolling back if necessary??. Or another option is to push the 412 conditions into the SQL layer somehow. This would also be a breaking change.... I'm going to merge this for now and punt on the TOCTOU at the resource level, which is now #1407. I'll cut a release and at least we can cut down on the Sentry errors... A PUT can be a create or an update. There's no such thing as INSERT ... WHERE last_modified = 'previous_last_modified'.. I think that might be the right approach. Be sure to handle the case of If-Match, which has to fail if there is no record with which to conflict.. I would be curious to see your scripts.. Well, that depends on whether or not it solves the problem.. I'm not really sure how to make a change that would only be kintowe specific, and I'm hesitant to try to devote effort to fixing the problem without being sure that it is, in fact, the problem. Assuming purge_deleted is the actual problem, how would we fix it? Is there a way we can determine that it is the problem for kintowe without changing the kinto code in this invasive way?\nRegarding with_deleted, I think that should be False, as that ensures that deletes the records without leaving a tombstone. It is already with_deleted=False in the surrounding code.. Speaking about this on a voice call, R\u00e9my and I agreed that this hack could be improved by making it conditional on a setting named something like experimental_disable_purge_deleted, so as not to afflict random users who installed this version by accident. Making this change now.. @Natim re-r?. I'm pretty sure the performance characteristics we're seeing are only due to DB migrations and changed queries.. Yeah, I always forget that one. I knew I was going to forget something and was leaving it to the tests to show me where it was. Thanks for fixing it.. /cc @peterbe. If you were interested in getting your hands dirty in the Kinto codebase, this might be a PR to look at.\nI'm not exactly sure what the test failure is about, but some of these tests seem to take a strange attitude about cleaning up after themselves -- looking at it now.. Thanks for the suggestions -- I'll try to clean up the mocking in the test cases tomorrow.. This no longer blocks #1485.. I agree that this is basically the only thing we can do... did this ever used to work back when we wrote everything to timestamps? If so, how?. There's a version number in docs/configuration/production.rst. However it's pretty late in the day so maybe I'll just pick up from here.. Hmm, that's a good point .. Postgres should be smart enough not to have to write a row if one already exists. I should probably post on Stack Overflow or IRC to try to find out whether INSERT ON CONFLICT IGNORE should cause write load, or if not, what else I might be doing wrong.. I asked on IRC in #postgresql and they said that:\n- The INSERT itself optimistically looks for the row in the index and if it finds one is already there, it doesn't try to actually write.\n- Locking a row does a write (because the lock is stored in the row itself as part of the t_xmax field).\nSo probably we can't do much better than this except by going back to a SELECT first. [Edit: And I feel a lot better about doing it because Postgres itself is basically doing it too.] I don't think doing it in the same query is really that much better than doing it as two separate queries. I'll write up a PR.. This might be a stupid question, but why wasn't this caught by https://github.com/Kinto/kinto/blob/master/kinto/core/resource/schema.py#L234, as described in the original bug?. I am skeptical that separating the COUNT into a separate query will be faster. It means scanning the table two times instead of only once. But please feel free to open a PR with some benchmark numbers!. I guess I should also mention that keeping it in one query is probably better for reentrancy, although it may not matter much for this particular use case.. It seems like we're going to discuss this next week when we're all together in Orlando. In the interests of readiness, could we have some information about what the context/use case here is? It seems like these requests are happening in Buildhub, which we know has a ton of records all in one collection. What kinds of requests are being made? What are they used for?\nI want to rule out the risk that we implement a \"fix\" but we end up still slow because of other requests that end up repeatedly filtering a large collection.\nSince we acknowledge that this is largely specific to the pathological use that Buildhub does of Kinto, maybe the right fix is to just add Buildhub-specific indexes to the Buildhub Kinto DB.. Per my comments in https://github.com/Kinto/kinto/issues/1624, I think having two SELECT queries violates abstractions without any real benefit. If the only problem it solves is Buildhub, and if you don't want to use it for Buildhub, I would say no, let's not release it.\nI'm open to trying to optimize Buildhub more generally, which is a broader topic, but in order to know how best to attack it, I'd need to have some information about what the context is. What kinds of requests are being made? What are they used for?. Is this issue still outstanding, or can we close it now that #1931 landed?. I'm a bit surprised to hear that The requirements.txt constraints are not used to initialize the developer local virtualenv. dev-requirements.txt is used by the make install-dev command, but I see that (like you say) the requirements.txt file is essentially completely ignored. Similarly, travis runs make install-dev and tox, and tox depends on dev-requirements.txt, but not requirements.txt. Are we even sure that we deploy kinto with the requirements in the requirements.txt? I'm not sure we do. Compare with e.g. https://github.com/mozilla-services/kinto-dist/blob/master/Dockerfile#L25, which explicitly depends on a set of dependencies set outside this project. I suspect that the requirements.txt file serves no purpose whatsoever.\n\nWhat purpose should requirements.txt serve? My instinct is to make the requirements.txt actually obligatory by putting it in the Makefile, setup.py or whatever. But honestly I'm not an expert at Python packaging in general so I'm willing to go along with whatever the usual thing in this ecosystem is.\nHow should requirements.txt be updated? Personally, I prefer using something like pyup to upgrade one dependency at a time rather than bump a whole bunch of them using make build-requirements just before a release. But I don't have a strong opinion on the subject.. Same error as #1493:\n\nWarning, treated as error:\n/home/travis/build/Kinto/kinto/kinto/core/openapi.py:docstring of kinto.core.openapi.OpenAPI.generate::py:class reference target not found: dict Full OpenAPI/Swagger compliant specification for the application.. Also, this will need to be rebased to pick up #1513.. Why is this a minor version? The release notes don't describe anything that I would consider a \"new feature\", even within our loose application of semver.. > The OpenID plugin no?\nOops, sorry, I guess I didn't actually read the changelog.. Just to recap some of the above:\n\ninserted being none seems impossible because the query has two parts. The first part tries to insert the record and replaces any tombstone; the second part tries to fetch an existing record. inserted being none means it couldn't insert (there's an existing record) but also that it couldn't fetch an existing record, which seems inconsistent.\nLike Peter says, it's probably coming from two different threads both doing create() at once. The first thread is inserting (or maybe updating?) successfully but hasn't committed; the second one is not able to insert but not able to read the other (uncommitted) row.\ncreate() has to raise a UnicityError in case the record already exists. This is important for e.g. default_bucket not running object creation events. This is not exactly the same as raising a 409. Note that the two requests don't actually conflict so a 409 is a little bit wrong.\nUnicityError takes as an argument the already-existing record. Of course, if we get no inserted result, then we don't have any way to get access to the already-existing record.\nThe code links to a StackOverflow answer about how to do a \"SELECT or INSERT\" query, although the answer has been updated since I landed this code. Although the existing code is based on the old answer, the current wisdom is that you can hit the same race condition we do, and that you have to either loop, use a different serialization level, or accept the possibility of the race condition.\n\nThis might be a good time to talk about switching to a stronger serialization level, for example repeatable read. This would at least get us to a place where transactions behave predictably. On the other hand, we'd then have to be ready to handle serialization errors, which might require a lot more work.\nThe Postgres documentation does say (about read committed): \"Because of the above rules, it is possible for an updating command to see an inconsistent snapshot: it can see the effects of concurrent updating commands on the same rows it is trying to update, but it does not see effects of those commands on other rows in the database.\" Indeed, I think that's what we're seeing. This behavior seems to remain in v10 and v11.\n. This might be a stupid question, but why? Can't we just iterate over everything in sys.env and look for things that seem like they could be settings?. Thanks!. Hmmm. This might be an acceptable use case, but I'm not sure it makes sense here. After all, the public bucket is only editable by a very few people in ops -- it's not the staging bucket, for instance. I don't think it's dangerous to leak that information, but maybe I'm wrong. Even with the staging bucket, I kind of wonder what the value is in keeping that information secret. Mozilla \"works in the open\". Anyhow, I think there are lots of use cases where a user who doesn't have write permissions ought to be able to see something about the object's permissions. For example, let's say I'm looking at a record that I have read permissions to -- right now I don't even know what permissions I have on that object. I think it makes sense for me to be able to know whether my friend has read permissions to it as well. Google Drive, for instance, lets anyone with any level of access to an object see who the owner of the object is and who else has permissions on the object.\nI think what makes this feel unsafe is the fact that it's an email address rather than a semi-opaque user name. Maybe this is a good use case for the accounts plugin? Then we could at least hide the email address behind a semi-opaque userid. (Of course, that userid is only one step away from an email address, but still...). Hi @stloma, I can't speak for @leplatrem but I took a few minutes to look through the other tests in the codebase and there seem to be a few in test_object_permissions.py that use sorted() to compare, probably for exactly this reason. I think that's the best approach. It's not exactly a race condition because it doesn't have to do with two processes happening at the same time, just that we use a set() so even within one process, order isn't guaranteed. JSON doesn't have any way to represent a set() except as a JSON Array, so it looks like there's an order when we really don't intend for there to be.\nDon't worry about asking questions or leaving comments on a PR! We like to work collaboratively! Thanks for your continued hard work!. Ah, yes, sorry, I guess I didn't explain it very well in the beginning.\nThe admin plugin is built from the package.json located at kinto/plugins/admin/package.json. As we release new versions of the kinto-admin project (from https://github.com/Kinto/kinto-admin/), we need to ensure that those released versions are the ones used by the admin plugin. However, it's a bit of a tedious chore, and it's possible to mess it up in a way that isn't obvious: in #1560, we bumped the version of the package.json without relying on the new version of kinto-admin in the dependencies, meaning we didn't actually get the new version of kinto-admin.\nIf you have a tedious, error-prone chore, then you should automate it. I don't have a specific suggestion for how exactly what mechanism to use to automate it. I think a minimal solution to this issue would be a command that would update the package.json file correctly. More extravagant solutions are possible (something that finds the latest version from npm? something that happens at release time?).\nWe happen to have other tedious chores that could be automated, which are the ones Mat listed (the manual steps from the release process in community.rst). We've toyed with the idea of automating them using zest.releaser hooks. I think those tasks could be outside the scope of this issue but we would also be happy to merge a PR that did those things.\nHope this helps. Don't hesitate to ask if you get stuck. We're happy to provide early feedback if that's helpful. Good luck and happy hacking!. Yes, just to confirm, with the accounts plugin, the bucket:create permission \"wipes out\" the account:create permission if both are present and we're paginating, except if the pagination border falls between them. Either way, though, the \"total records\" field shows the correct total. However, thinking about this more, I don't think it makes sense for there to be two separate bucket:create and account:create records -- these are both things that can be created under a single root element. Similarly to how bucket permissions can have both group:create and collection:create listed, I think there should be a single record with resource_name root that has both account:create and bucket:create.\nI'm also seeing that sometimes I get permissions lists which include buckets b1 and b10 twice. I think this is related; if the pagination border hits between account:create and bucket:create, the pagination filter is coming in as comparing against Missing, which I bet is random depending on the memory address of Missing vs. other real objects. (We don't handle Missing correctly if it comes on the filter, but only if it comes on the record.) In other words, I bet records without id probably violate a lot of assumptions throughout kinto. I don't love the name root-account or root-bucket, but honestly it doesn't really matter too much what it is as long as there is one.\nHowever, looking at this more closely, we have other problems with this code, which assumes that id is a primary key for each record -- which it normally is, when retrieving a list of some resource such as collections in some bucket, but isn't here. (For example, you can have /buckets/abcd/collections/def and /buckets/abcd/groups/def. Both have id \"def\", and get \"merged\" the same way account:create and bucket:create do.) The actual primary key here is something like (record_name, id), but of course most of the time record_name isn't available. So probably we need to be much smarter here. I think we have two options here -- either we can stop using the memory backend's semi-internal function for this, in which case we need to pick actually-unique IDs (perhaps url?), or we can write another function to handle this somewhat different use case, re-using only the parts that make sense for both. At the moment I'm leaning towards using url as the id, but it feels kind of hacky.\n. To reproduce the groups / collections thing, try doing:\n```\nhttp PUT 'localhost:8888/v1/buckets/abcd' --auth \"user:user\"\nhttp PUT 'localhost:8888/v1/buckets/abcd/groups/def' --auth \"user:user\"\nhttp PUT 'localhost:8888/v1/buckets/abcd/collections/def' --auth \"user:user\"\nhttp PUT 'localhost:8888/v1/buckets/abb' --auth \"user:user\"   # because we need pages of length two, but for both the group and collection to be on a page after the first one\nhttp 'localhost:8888/v1/permissions?_sort=id&_limit=2' --auth \"user:user\"\nThen, take the Next-Page header and request that with the same auth. For me it was:\nhttp 'http://localhost:8888/v1/permissions?_sort=id&_token=eyJvZmZzZXQiOjIsImxhc3RfcmVjb3JkIjp7ImlkIjoiYWJjZCIsInVyaSI6IlwvYnVja2V0c1wvYWJjZCJ9LCJub25jZSI6InBhZ2luYXRpb24tdG9rZW4tODJjZjE0ZjctOTIxNC00ZjMzLThlYjItZWExNzk5Yzc5ZmU4In0%3D&_limit=2' --auth user:user\n```\nLooking at this more, I guess we should probably keep the id available for places where the id is available, but we should probably use uri as the unique field. I think this should be possible with the code as written, but I'm not 100% sure yet.. I've decided to push just this fix. The resource name stuff really ought to get straightened out too, but that can be in a separate PR.. Closing in favor of #1581.. Hmm. This is kind of intertwingled with #1576, so maybe wait until that lands before reviewing this.. I rebased this onto master and I think all the tests are correct now. r? @leplatrem . Yes, I also saw that and wondered the same thing ... it did seem a bit strange to note that the username was \"verified\", without noting how it was verified.. OK. How does the client identify that it's \"at the end\"?. I won't claim to be an expert in this code, but it seems like we only issue a continuation token if there are still some items yet unseen, so we never get an empty page.\n1585 changes the memory backend so that we don't repeat the first page of objects, but I think it's possible to get into a situation where we generate an infinite number of empty pages, each with a Next-Page headers.. I looked more closely at the pagination behavior we have and I no longer believe it's possible to get into an infinite-pagination situation. We only generate a next-page header if we have a completely full page, and each time we have a completely full page, we advance the offset in the next page. I had gotten confused because I thought we would continue until offset + len(records) == total_records, but that isn't the case (we continue until len(records) < limit).\nBecause #1585 has landed, I'm considering this fixed. Closing.. Yes, I agree.. This might fix #581 (but maybe not #573?).. This is kind of bikesheddy, but I think contains_foo=x,y should mean \"the foo attribute contains [\"x\", \"y\"]\" (i.e. what you called contains_all here). If you want to write \"the foo attribute overlaps with [\"x\", \"y\"]\", I think you should write intersect or contains_any.. Pip failing might not be your fault... on https://github.com/mozilla/pyjexl/pull/13 I'm getting \"too many redirects\".. I guess I wouldn't be averse to something like PATCH /v1/buckets/my-bucket/collections/my-collection/records?status=open&_limit=1. But we don't support it now, and I am extremely hesitant to endorse the use of Kinto as a queue. I think using a queue as a queue is going to be better for you than using a database as a queue. I don't know if this is still a problem, but I had a co-worker from a couple jobs ago who worked for a company who had built a queue around MongoDB and constantly ran into issues where the database indices gradually got less and less efficient as records moved forward in time. I think they ended up having to rebuild indices periodically.\nMy personal opinion about kinto-redis is that it doesn't support the level of query you need in order to avoid race conditions. I'd expect the same thing from kinto-mongodb. But maybe for some applications that's OK? I guess if losing your data were a big problem, you wouldn't be using MongoDB anyhow.. I see you've made some drastic changes to this query. Most are probably fine, but separating the SELECT and COUNT into separate queries damages reentrancy. Is it possible to benchmark with and without that change, to see how much it gains us to sacrifice reentrancy like this?. Now that #1616 is clarified, it would be good to add a test to this PR that captures the subtle bug that the old query had when using a wildcard parent_id.\n\nselect id, last_modified, data FROM records WHERE parent_id... collection_id=... ORDER BY last_modified DESC LIMIT 10 is a pure index-level read, it's always going to be fast. It doesn't even need to read the records table.\n\nIt happens to be that way sometimes, but in general this query may not be a pure index-level read, and it may need to read the records table.\n\nAnyway, there is a real way to prevent the len(SELECT) != COUNT across the two executions. You can use REPEATABLE READ\n\nAnother, simpler way is to use a different query. For example, the previous query doesn't have this problem. That's why I asked you to benchmark with and without that change. Even if the risk is small, it's a new risk and I would like to know what the pros and cons are.. No, I don't want you to test using REPEATABLE READ, because I think that change is outside the scope of this PR. Introducing REPEATABLE READ means having to deal with serialization failures and I don't think we're ready to do that yet.\nI want you to test with/without two queries, because it's possible to write a single query that does not suffer from the race condition that you automatically have if you write two queries, and if the performance penalty for that isn't too bad, then I would prefer that.\nYes, with this PR, certain queries are faster. (It turns out that others are slower.) But you have made a lot of different changes to the queries in order to get this result. I would like to look at each change individually rather than the whole package.. Great, thanks!\nFrom your notes in #1507, the SELECT COUNT(*) is able to do a table scan, I guess probably because the vast majority of your DB is buildhub stuff. However, the combined data-and-count is probably doing an index scan so it can output results in the right order, and I bet the index scan adds some overhead. On my machine, the difference is not so drastic -- about a factor of 2x -- but maybe on your machine the table scan is being parallelized in a way that the index scan can't be.\nOne obvious difference between the queries you're benchmarking and the ones in your PR is that the ones in the PR have filters associated with them. Between this and the fact that your broken-down queries are doing a table scan, it might be good to see what happens if you run the query on a collection that makes up a smaller proportion of the database.\nI didn't know about windowing functions. The query I came up with is much closer to the original query:\nWITH collection_filtered AS (\n    SELECT id, last_modified, data, deleted\n      FROM records\n     WHERE parent_id = '/buckets/a/collections/b'\n       AND collection_id = 'record'\n  ORDER BY last_modified DESC\n),\ntotal_filtered AS (\n    SELECT COUNT(*) AS count_total\n      FROM collection_filtered\n     WHERE NOT deleted\n)\n SELECT count_total,\n       a.id, as_epoch(a.last_modified) AS last_modified, a.data\n  FROM collection_filtered as a,\n       total_filtered\n LIMIT 10;\n. 50% is still quite a large slice of your database. I bet it's still doing a table scan. (Some EXPLAIN ANALYZE output would verify it for sure.) How about if it's only 10% or 1% of the total records? How about one of the records from the buildhub docs, using the Kinto records API queries instead of ElasticSearch?. We just talked about this in Vidyo -- for those following along at home:\n\nAlthough this issue seemed like a P5 previously, maybe it's a P3 or P2. @leplatrem , @mostlygeek ?\nI agree that the existing query is bad and needs to be replaced. I'm not excited about replacing it with two queries: this introduces race conditions, and for some requests, it's slower than what we have.\nI think we can do better than what we have without introducing race conditions nor slowing down certain queries. I think that would be a slam dunk easy merge scenario.\nIf we're going to make some requests slower in exchange for making other requests faster, I think we need to have very clear and explicit reasoning about why the requests we're making slower are OK to make slower (less common, less important, etc.).\nAn option might be to introduce heuristics to try to figure out which kind of situation we're in -- maybe in situation A, query q1 is faster, and in situation B, query q2 is faster. (We do have some stuff like this already; see https://github.com/Kinto/kinto/blob/382adcdc2dccff7151798bc7d250769dc818d83e/kinto/core/permission/postgresql/init.py#L482-L493.) But this gets us into the business of trying to outrun the Postgres query planner and I'm not confident that our time is well spent doing that.\n\nIf I understood correctly, @peterbe said he was going to step away from this PR so (assuming it's high priority) maybe I will take a swing at coming up with a query that is better than what we have without slowing down other queries.. > I don't think that's a fair evaluation. When there were only 10 records to be matched, the sum of the SELECT + COUNT query was 10% slower.\nIn fact, your proposed solution can be up to 100% slower because of what I wrote in https://github.com/Kinto/kinto/issues/1507#issuecomment-384395502.\n\nAlso, in terms of priorities I think we're missing a subtle point in that if a READ query takes 15 seconds (not unrealistic at all at the moment on databases like Buildhub) that means the Postgres server is potentially distracted and resource hogging for other queries (read or write) that needs to be dealt with.\n\nIn general, yes, I agree, slow queries are bad. Note that what you are worrying about here is about CPU usage. However, your benchmarks actually measure latency.\n. It turns out there actually are two tests that cover get_all with a wildcard parent_id. But my assertion is that outside of those tests, nobody actually uses it. (The only code path I could see is if someone creates a Model subclass with a parent_id that has a wildcard in it.) What if I delete the functionality and the two tests that cover it, can I still remove it? :grinning: . > Each account entry is isolated using parent_id=user_id. As admin, I can see every entries, thus parent_id=*.\n\nI also found why I implemented it in the first place: [kinto webpush uses it]\n\nThanks for digging this up, I would never have thought to look here.\nIn both of these use cases, the intent is to support some kind of scoping (typically by user) but having some kind of special functionality to which the scoping doesn't apply. In these circumstances you use UserResource instead of ShareableResource.\nNaively, I guess I would have assumed that we use the permission backend to do this kind of scoping, because it seems cleaner and more powerful. But I guess doing that is pretty tricky because permissions are inherited -- if you have read on a collection, you have read on all its children.\nI will open a PR to document this a little better. Thanks!. I think it's clear that we don't have robust tests on the wildcard matching. I think it would be good to add some. I think it would be prudent to figure out what the correct behavior is and write tests that reflect that correct behavior before updating with the query.. Yes, I think we should think about that too. That's why I wrote we should figure out what the correct behavior should be and write tests that reflect that. What do you think the correct behavior should be?. One reason why Total-Records might be nice is to show pagination stuff on the client side. (e.g. if Total-Records is 50, we can show pages 1..5.) We do expose it, not as part of other requests, but as a getTotalRecords call in kinto-http.js. PostgREST handles this by exposing a Content-Range header, but that header doesn't contain a total count unless you add Prefer: count=exact header. They even recommend stripping this header in prod: http://postgrest.org/en/stable/admin.html?highlight=Content-Range#count-header-dos.. We spoke about this online today. Removing the Total-Records header is kind of an API-breaking change, even though to our knowledge, our clients don't actually rely on this header.. Oops, yes, this PR took so long I forgot about the unchecked boxes in the description. I've opened #1635 with a CHANGELOG entry.. Speaking personally now, I feel that the 2nd option (\"best effort\" Total-Records) is the worst of both worlds. We pay the performance penalty, but we don't get an accurate result.\nThinking about this more, Total-Records is essentially always exposed to race conditions, because even if it's accurate now, there's no guarantee that it will be accurate when the client receives it, parses it, or sends another request. In other words, relying on Total-Records to do correct pagination is essentially always wrong; any client that relies on the first request's Total-Records is doomed, and even relying on the most recent request's Total-Records is wrong because new records could have been inserted before or after the current page. So my feeling is that we should scrap the options in category 1.\nI think my current preference is something like category 3, but with a caveat that if a user does a HEAD request, we calculate the Total-Records correctly (this is what kinto-http.js's getTotalRecords function does). There are use cases where category 2 is useful, but I think such cases are better solved by forcing clients to request total records explicitly, and I think category 3 is the closest we can come without actually breaking the API.. I agree that this is a good fix and we should merge it -- why did you close it @stloma ?. Oh, I see, this is on 9.X.. Wow, nice! How did you figure that out?. This should be OK now, right? I got someone to fix it short-term, but long-term there's still some question about where it should live (and how).. Duplicate of #535.. Sorry, let me rephrase... this line contributes nothing to whether this endpoint works for anonymous users or not. That's controlled elsewhere. At present, that setting is for the endpoint to allow anonymous access. If that setting weren't there, then this endpoint wouldn't work for anonymous users, even before this PR.. It's not very close. I think it should be a little easier now that https://github.com/Kinto/kinto/pull/1671/ has landed, because we can just rely on the existing listeners to clean up after we delete a resource, but I haven't confirmed that. The use case I needed this for was already solved by https://github.com/Kinto/kinto-fxa/pull/55 so I felt much less urgency about it. Maybe we should close it until someone else has the energy to pick it up.. I worked on this a little bit to try to clean it up a little bit. I rebased onto current master, which led into porting to the more current event system as well as changing to the new plural/object vocabulary. I ended up squashing the whole series, which really didn't make much sense any more, into a single commit. Sorry if anyone had looked at this recently.\n@leplatrem When I last left this PR, there were several issues I didn't really know how to address, marked with FIXMEs in the code. I can invent solutions to all of them, but I'd really like your input on them before I invent something you hate. There are some other things I could do to move this PR forward -- writing tests being the main one -- but I was holding off to see if any of the issues I found were fatal to this PR.. I think this is now a legitimate PR and should be reviewed accordingly.\nI decided not to put the user-data_delete_principals setting in the kinto.tpl, figuring it wasn't a common enough endpoint to make it worth cluttering things up.. I'm kind of tying myself into knots here. The problem I'm facing is that if you delete a bucket and then a collection from inside that bucket, the event listener for buckets deletes the quota record for the bucket, and then the quotas plugin emits a nonsensical quota record for the bucket (-1 records, -x size). If you do it the other way around, the quota record is correct, and then the event listener for the bucket deletes it. When I see this, I see a dependency on the bucket listener by the quotas plugin, and my view ends up depending on both of them.\nNow, if the buckets event listener doesn't emit events for deleting its children, then you end up with something like the current quotas plugin. When a collection is deleted, it does a get_all to fetch the records that it \"knows\" will be deleted, and takes them into account, and it \"knows\" that it doesn't have to clean up its quota entries because they'll be deleted by the buckets/collections event listeners.\nIf the buckets plugin does emit events for deleting its children, then the quotas plugin gets both simpler and more complicated, because it no longer has to do a get_all to fetch records, but it has to accommodate the fact that when an event shows up for a deleted record, it may be a \"cascade\" from a deleted bucket that it already saw. I can't tell, but this might mean that there's still knowledge \"baked in\" to the quotas plugin that says what kind of objects are children of what other kinds of objects.\nI don't love either of these approaches. I think if you care about record deletion, you shouldn't have to also listen to collection and bucket deletion. My feeling is that the most correct thing to do is to delete the children before deleting the parent, but that can't be made to work with the buckets event listener as it stands today (because it only happens after the bucket was deleted).. Not sure why the coveralls build is taking so long but the builds all succeeded so merging.. Thinking about this further, I am wondering if it makes more sense to just have the caller use Request.blank to gin up a fake request. I could also define instance_uri_registry by using Request.blank, but writing tests for such a silly function almost seems not worth it. What do you think @leplatrem ?. I think we should close this in favor of #1667.. Oh, I didn't realize we had to update our packaging for heroku, but I see that https://github.com/Kinto/kinto-heroku shows a dependency on kinto 6.0. The accounts plugin was introduced in 7.0.0. I'll open a PR on kinto-heroku to bump the version. Sorry about this!. I merged the kinto-heroku PR. As far as I know, that's all I need to do -- I don't have to cut a release or anything like that. Please give it a try and let me know if it works or not!. That looks like it's somehow failing to instantiate the Postgres storage backend. I'm guessing your kinto.storage_url setting is an empty string. Otherwise I'm not sure either... Hi, what's the status on this? Can I close it?. There's also a reference to request.path in this method that should probably get updated.. Actually, because of #945, uri is essentially always wrong, so I'll just leave it alone for now.. I discovered while working on Kinto/kinto-changes#41 that having an event trigger another event doesn't always cause the second event to be fired. I added a commit to handle this by reorganizing the kinto.core.events module, but I'm not really sure that it works and I haven't added tests yet. f? @leplatrem . N.B. This means it's possible to write an event listener that sends another very similar event, which can break the event \"grouping\". I'm not sure if this is something we should support, reject, or merely tolerate.\n. I rebased onto current master and pushed a couple new commits. In particular, I decided that it made sense to extract an EventCollector class which seemed like a reasonable place to keep the logic for how to merge events. This meant unwinding some of the changes I made to move get_resource_events into drain_resource_events -- I kept the existing name/calling convention but it's now a generator rather than returning the events. That's probably OK for the use demonstrated in kinto-signer. I also added a test for an event triggering another event. I am thinking about adding a test to demonstrate that \"cascading\" events are merged the same way as regular events.. Blocked on requests/requests#4681.. Rebased onto current master.. Yes if a URL is permitted then I think it's OK to fail when checking it.. I'm hesitant too. I think what we have already (verification using flake8) is working pretty well. I think we jumped on prettier too early in the JS world with the consequence that periodically we'd get a PR to update prettier and have to reformat everything. I'd like to avoid this mistake here.\nI think if we can articulate exactly what we don't like about the Black style and reflect it in issues upstream, that would put us in a much better position.. Thanks!. Oops, thanks for the reminder. I discovered this a week ago and forgot the exact syntax I had used... According to your description, it sounds OK to have scopes be configurable, if you can figure out a way to make it work!. The specific reason is because we're built on Pyramid, and deployed with pserve, which is configured using a PasteDeploy .ini file. I don't think there's a real architectural reason why it has to be this way, though.. Ugh, Travis has been choking on this PR a lot for reasons that aren't really obvious, but it seems like the tests pass so whatever.. The upgrade to react-scripts seems to have broken stuff. It's now impossible to build with the query-string library. See https://github.com/sindresorhus/query-string/pull/148. I'm not sure exactly how to address this. I guess I have to build another release of kinto-admin?. Thanks for your contribution!. I think 3.16.1 is pretty much dead because of https://github.com/simplejson/simplejson/issues/237... I can help with the travis failures. It looks like it just failed to build docs due to a network error. I restarted the build. I'll keep an eye on it for a little while and let you know if I think any action is required on your part.. Thanks for your contribution!. Thinking about this further, I think that although #1770 is a valid short-term fix, it feels a little odd for me to bless one specific attribute about the resource as \"part of the payload\". Maybe the right fix is for the payload to include the model or resource or something so that the recipient of the event can decide what attributes it wants.. Another approach would be to turn the @reify'd timestamp property into a @property. As far as I can tell, the @reify is a performance optimization -- fewer database round trips. Taking it out doesn't seem to break any tests (except for a few that rely on the ability to set the timestamp of a resource). \nRunning the test suite with @reify on my laptop finishes in 225-235 seconds. Running with @property finishes in 240-255. So I guess we should probably keep the @reify.\n@leplatrem suggested that I add a comment to this change explaining it, which I'll do.. I just added one test (for put) in a section where tests are also present for other verbs. What do you think about this, @leplatrem ? Is this test even in the right place?. OK. I am going to merge just this smaller fix, knowing that perhaps it isn't the best long-term solution, but right now I don't want to untangle the significance of the timestamp property being reifyd. Thanks!. I didn't have to add anything to the CONTRIBUTORS.rst file for #1765 because @schobewankenobi is already in there.. I think this can be closed now that we have the new cornice version.. We still seem to have the warnings and indeed cornice still uses best_match.. Refs #1936, https://github.com/Cornices/cornice/pull/499. This should be OK now.. That probably means you don't have memcached running on your machine. But it's fine as long as you don't touch the kinto.core.cache.memcached code.. Looks like we have an intermittent failure in test_config (when we wrap around a second boundary), but no real failures in this PR.. Blocked on https://github.com/requests/requests/issues/4830.. Rebased onto master now that #1830 has landed. This should unblock this.. The 1 second was when the password was wrong. If it's right, it drops a little bit:\n```\n\ntime http --auth ethan:trustno1 'localhost:8888/v1/buckets?expected=\"123\"'\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Last-Modified, Total-Records, ETag, Retry-After, Backoff, Next-Page, Alert, Pragma, Cache-Control, Expires, Content-Length\nCache-Control: no-cache, no-store\nContent-Length: 11\nContent-Type: application/json\nDate: Wed, 17 Oct 2018 16:13:47 GMT\nEtag: \"1539792827723\"\nLast-Modified: Wed, 17 Oct 2018 16:13:47 GMT\nServer: waitress\nTotal-Records: 0\nX-Content-Type-Options: nosniff\n\n{\n    \"data\": []\n}\n0.34user 0.09system 0:00.58elapsed 75%CPU (0avgtext+0avgdata 35792maxresident)k\n46040inputs+8outputs (113major+11486minor)pagefaults 0swaps\n```\nElapsed: 0.58s.. I think the outstanding issue is about how users actually put data in. Usually they use kinto-admin. Do we make them md5 the domain name themselves? Do we add kinto-admin support for this kind of ID generation?. I spoke about this a little bit with @leplatrem on IRC. I have to say I like \"items\" better, but either one is an improvement on what we have now... Maybe even \"resources\", since it matches resource_name?. The problem is all the tests that break because up until here, everything was being native-valued. For example:\nFile \"/home/travis/build/Kinto/kinto/kinto/plugins/quotas/listener.py\", line 178, in on_resource_changed\n    if bucket_info[\"storage_size\"] > bucket_max_bytes:\nTypeError: '>' not supported between instances of 'int' and 'str'\nLike it or not, I think this would be a breaking change. Again, I wonder if the smart change is just to force http_api_version to be a string.. Closing in favor of #1835.. It seems like pyramid_tm relies on a private method of the underlying transaction library, which is now gone. I have filed https://github.com/Pylons/pyramid_tm/issues/67 to make sure upstream knows about it.. This is failing because of the new transaction release (see #1834).. I rebased to clear up the merge conflict.. https://github.com/Pylons/pyramid/blob/master/setup.py#L29. I'm moving this to https://github.com/Kinto/kinto.js/issues/869. Yes, Kinto is still developed and maintained, but we don't test a lot on Edge.. I've never heard of anyone using Kinto in a .NET stack. I don't have a lot of experience with that stack so I'm afraid I can't really make any recommendations for starting points.. Not sure why.... I spent a little while trying to track down the history here. I think it's just an oversight. The main issue with supporting JSON values was in the storage code rather than the query deserialization code -- see https://github.com/Kinto/kinto/pull/1258. Then, when contains_ and contains_any_ were added in https://github.com/Kinto/kinto/pull/1604, but the behavior of in_ and exclude_ was left as-is.  The code right now:\nhttps://github.com/Kinto/kinto/blob/593abdbc15c358590c799b8d86461563da8efbe2/kinto/core/resource/schema.py#L231-L247\nThis aaaalmost works. A JSON array like [\"a\",\"b\",\"c\"] gets split into [\"a\", \"b\", and \"c\"]. Then we deserialize each element, but since the first and third aren't JSON, only the middle one gets deserialized correctly. That's why the strange behavior @Natim saw in his bug report.\nThe existing behavior can remain as a fallback AFAICT. We should just try native_value first.. It's still unreleased and it's marked as such, so I think it's OK, right?. Refs #1850.. Refs https://github.com/requests/requests/issues/4890.. Refs #1926.. @leplatrem Feel free to review this again if you like and merge whenever you want. This is pretty low priority so I guess it can wait until after #710 lands.. I haven't really paid attention to packaging stuff, but I'm in favor of moving to the future (which is I guess setup.cfg?).. I got this as well. I think you need to install the newest bravado-core (from dev-requirements).. Commandeering this issue because a similar stack trace affected @peterbe. It turns out we don't pin swagger_spec_validator. We probably should.. Should we fix #1900 here?\nThe build failed because of black.. Yeah, my hypothesis is that nobody actually uses the totalRecords field on the paginatedList result, but just pages the results. I think automatically including a call to getTotalRecords (on each page...) would be a prohibitive performance penalty and would rather not do that.. > Do you mean a squash?\nNo, I meant a rebase, meaning moving these comments onto master so that we get fewer wacky diffs like this:\n\n\n. Refs https://github.com/Kinto/kinto-attachment/pull/158.. The build failed at first but I rebased it onto master (with the new pytest-cov) and now I think everything should be copacetic.. I'm not sure you really want to hear my opinion, so I've been trying to stay out of it, but since you asked: I don't think Kinto is a good foundation for the kinds of thing you want to do. I don't like the current Kinto accounts plugin and I would prefer Kinto core not be cluttered with support for all the different possible things some developer might want an accounts system to do.\nI think the PostgREST approach here is pretty solid: don't do any user stuff whatsoever -- delegate that to some other service -- but allow people to present JWTs to prove their identities. I recently saw https://github.com/netlify/gotrue which seems like a pretty nice product, but if you wanted to build something open source I would certainly support that too.. Yikes, I didn't think += mutated the original value. Good catch!. Refs https://github.com/Kinto/kinto-signer/pull/262.. Ouch. Thanks for jumping on this.. @dependabot rebase. It looks like this broke us because a couple tests use incorrect URLs (i.e. URLs that don't conform to the new colander validator).. Could you take a look at this when you get a chance, @leplatrem ? We have a test that asserts support for username:pass@singlename in URL, which seems to suggest that we use that somewhere, but I think the only place the URL field is used is in OpenID, which probably wouldn't be affected. What do you think?\nAre the \"incomplete\" domain names in the tests meant to represent actual use cases or are they just because we were too lazy to type in a plausible domain name? . It looks like this is failing because of the colander upgrade. N.B. should the colander upgrade have broken this? Na\u00efvely I would have thought that the versions in requirements.txt are the ones that get installed.. Thanks! I'm going to wait until we sort out the failing tests (see #2020) before merging, should be sometime tomorrow.. This might be a dumb question, but what is the value of a requirements.txt file? Do we expect our users to retrieve this file and pass it when doing pip install kinto?. @dependabot rebase. Filed #2038 as a follow-up.. Hi @palutlaanirudh, the problem is that the docs make several references to kinto-redis, which is a plugin. This leads to a situation where the generated docs include the Redis backends as though they were first-class, built-in components instead of an optional plugin. See https://kinto.readthedocs.io/en/latest/core/cache.html for an example of what I mean. This also leads to the unfortunate situation where you have to install the kinto-redis plugin to build the docs, instead of just being able to build them from the kinto source. In other words, kinto has a dependency on a plugin, which is bad. A plugin can depend on kinto but not the other way around -- if kinto requires it, it isn't a plugin.\nTo help, I'd like to see a patch that reviews the places where Redis/kinto-redis is mentioned in the Kinto docs (or anywhere else in this repository!). I think any usage of kinto-redis should be changed to a \"link\" -- instead of including kinto-redis in the kinto docs, we should include links to the kinto-redis project for those who are interested. Ideally we would be able to remove kinto-redis from the requirements needed to build the docs.\nTo get started, I'd encourage you to clone the Kinto project and try running the tests and building the docs. Then try making some changes and rebuild the docs to make sure you get the results you expect. Don't hesitate to say something if you get stuck or have problems. We hang out sometimes on IRC or on Slack if you need help.. @dependabot-bot rebase. @dependabot-bot recreate. In py36 and py37 (but not py36-raw) this breaks coverage here: https://github.com/Kinto/kinto/blob/3c919616fca321e3289cba4bcba9cf02017f8366/kinto/schema_validation.py#L8\nIs this a good opportunity to remove this wacky import and just depend on jsonschema 3.0.0?. It looks like this is caused by a bug in the argparse module: http://bugs.python.org/issue9253#msg186387\nThe workaround is to set a dest and set subparsers.required = True. I have done this in https://github.com/Kinto/kinto/pull/576/commits/84f74af1bd32e9cda251e64a38ae51ce813ddc80.\n. I didn't understand the reason that this got added in the first place, so I'm not qualified to comment on that.. isn't this for the purposes of testing or something?\n. Did we intend to remove this?\n. I was using it to test locally using python kinto/__main__.py, which is a little easier than running pip install every time I make a change..\n. Should this test check that the mock actually got called?\n. This is awesome! Thanks!\n. Good catch!\n. Like I wrote in https://github.com/Kinto/kinto/pull/574/commits/e46ba29e2875a6e3c59bdf06d453f12e46d338ff, it's kind of annoying, and I'm not sure it looks good in rendered HTML, but sure :)\n. Personally, I don't think so. The rendered form on Readthedocs has a link to the FAQ on the left side. I think most people look for/go to a FAQ when they have a specific question they want to see answered, which can happen at any point during the document (i.e. not just in the overview, but in concepts, or the tutorial).\n. I ran a link checker like @almet suggested in #564.\n. Done in https://github.com/Kinto/kinto/pull/574/commits/7737ff700a6a8764aae52c2d71fd2df7c4328854.\n. Yes, I did that in https://github.com/Kinto/kinto/pull/585/commits/894f7c18df3abe636bca40bfc0349ec505a2c48a.\n. I'm not clear on the difference between prune and recursive-exclude. The documentation doesn't suggest that there should be any difference between the two commands. The only difference I can see is that recursive-exclude requires that we specify every different kind of file -- for loadtests, this would be .ini files, .py files, .json, and a Makefile. For talks, it would be .rst, .css, a couple stray .cfgs, some .pngs, .jpgs, and .svgs, and another Makefile. It seems to me like prune suggests that no matter what file shows up in talks, we don't want it in the package, but recursive-exclude suggests that we only want to exclude certain kinds of files and other kinds of files in talks would be OK. But I don't know anything at all about this so I'll do whatever you recommend :)\n. This information is already present in the standalone timestamps.rst file. (I had hoped that this would be clear from the commit message in https://github.com/Kinto/kinto/pull/616/commits/42bee8a0b0d4a65f3b7160fabac5639d6af14402.)\n. My hope is that we will feel embarrassed by their exposure and that will make us fix them :) Also, other people looking at them might improve them, but if they're hidden, they probably won't be improved.\n. OK. Since we call configure in initialization.py:setup_logging, I've just moved this code there in 9f83849eb4067c1514abfc91c1afea5306aad7cc.\n. You're a better man than I if you can follow a giant documentation merge just by looking at one diff :)\nThe contents of resource.rst are intentionally general and try to set out principles that all endpoints follow. I think it might be better to just remove the entire file and describe the actual endpoints in buckets, collections and records files. In that case, my goal is to eventually delete this entire file, so I don't want to put a link here. But I'm not sure, and I would be open to the argument that having a generic file like this is valuable. Let's iterate on it.\n. OK, done in 796d6133225865e4150932509a8c483a696fedc0\n. I would probably write that a protocol is \"at\" a version or just \"is version 1.6\". To me, \"in version 1.6\" sounds like it's contained in the version, like a feature of the version.\n. Yes, @enguerran is correct, \"one user modifies\", \"two users modify\"\n. Why not just key.endswith('id_generator')?\n. Oh, never mind, because you want to retrieve the prefix.\n. I would write \"A/B testing\"\n. Also, \"downloading of extra assets\" is kind of confusing to me (what makes an asset extra? why are we downloading it anyhow?). I think Kinto's strongest use case to date is blocklists, so maybe reword to that instead?\n. \"every endpoint that is not\"\n. in the Pyramid ecosystem\n. Is cliquet_fluent a real thing?\n. We discussed this on IRC. \"The bucket the collection is in\" sounds fine to me, but if you don't like it, some other alternatives include \"The bucket where the collection is\", \"The bucket with the collection in it\", \"The bucket containing the collection\", or \"The bucket that contains the collection\".\n. Is it possible for there to be records returned that are then not removed by the delete (i.e. a race condition with another client)? Or is this all happening in a transaction?\n. Why do you copy the payload? Edit: I see you mutate the payload below, but then the question is why do you mutate the payload?\n. Is the \"no cover\" pragma here because it's difficult to test, or because this is a \"can't happen\" scenario?\n. I think this can trigger even on a delete, which seems wrong to me.\n. Same concern about these checks being triggered on deletes -- I think we should always permit deletes, even if you're over quota.\n. Could you tell me a little bit more about what parent_id means? I looked at the StorageBase class and I'm still kind of confused. In normal use, I would have assumed that it's a bucket ID, but here you're using a URL, and below you're using a collection URL. Where/how is this info getting stored? Is it in a special inaccessible Postgres table? Or is it in the same table user records are stored? If so, how do we protect the user from updating these records?\n. This is a clever way to define tests.\n. I guess there's no need to check for 507s on updates?\n. Should we verify that the record didn't get created too?\n. I think a race condition shouldn't be possible, since the ResourceChanged event happens within a transaction.\n. Does this mean that kinto_redis is required to run tests?\n. considers. I would also reword this, something like \"A bucket's quota is a limit on the size of bucket attributes, group attributes, collection attributes, and record attributes.\"\n. Deleted items', with the apostrophe to indicate possession (the size of the deleted items). I'd probably reword this as \"Deleted items are considered to have zero size\" or \"size zero\".\n. look like\n. plugin\n. That can be stored in a collection or bucket?\n. \"work\", because \"it does work\"\n. Try adding a test where the quota is reduced after a bunch of objects have been stored, and then doing a delete.\n. I personally think full-text isn't wrong here, but if we're going to change it, I think we should include a stronger word than \"filtering\". How about \"Add pattern-matching query to filtering on plural endpoints\" or \"Add substring query to filtering on plural endpoints\"?\n. Shouldn't this still be a normal 404? Why are we removing this test?\n. It seems like we don't use this details variable anywhere here. Am I missing something?\n. I see where we define the custom 404 for collections, and for records, but I don't see any place where we define one for buckets. Where is that?\n. I don't think this test is relevant to what you want to change. This looks like a test for the underlying kinto.core resource code and specifically like it's trying to verify that if a resource has an _extract_filters method that raises an exception, that exception gets passed through correctly.\nI think you need tests to verify that getting a non-existent bucket, collection, or record has the correct details attached. You might look for those tests in tests/test_views_*.py.\n. It looks like you're only checking that the attributes are present in the error message, not that they are correct. I think we can add stronger tests that also check that resp.json['details']['id'] is equal to \"barley\", and similarly that the resource_name is \"collection\".\nI'm not sure every single test needs to be updated. Personally, I think it's OK if we leave these tests alone -- they check that we got a 404, and that's good enough. Instead I would add new tests that check that when we make a request that we expect to get a 404, that that 404 comes back with these details.\nSince we expect all 404s to have a certain structure (with id and resource_name having certain attributes), it might be worthwhile to add a method somewhere called something like check404 that enforces this structure. Then, the tests that use this method will look more declarative.\n. I'd probably use neither emphasis or code -- it's a proper noun, so capitals are enough.\nI'd probably use by somewhere here, like:\nIt's possible to use JSON-Patch by sending the request header ``Content-Type: application/json-patch+json``.\nI don't think it's necessary to explain \"instead of (something else)\".\nSorry to bikeshed :)\n. omitted\n. Hmmm. Do I understand this correctly? We mutate changes because later we use changes to find any keys/values in the record that might have changed, which we do so that we know whether the record needs to be saved and also so we can respond with just changed fields.\nIf that's correct, then we're using changes as a strange bidirectional argument -- both passing data in, and getting data out. It seems to me like when it's input, changes is {\"data\": [... list of operations ...]}, but when it's output, it's {\"data\": [... list of operations ...], \"key1\": \"new_value1\", \"key2\": \"new_value2\"}. In other words, both kinds of data are mixed up. Is that true?\nIf I understand correctly, then I'd much rather have some other mechanism for returning the changed fields of the record. Perhaps apply_changes should return (updated, changed_fields). Unfortunately this would be an API-breaking change. At the very least, we should document this behavior of apply_changes if we're going to take advantage of it, and I would say we should clear the old data entry when we update it.\n. Yeah, that's a great insight and one that I wouldn't have realized just from looking at the code :)\n. I think this test is confusing because you're inserting between elements 0 and 1, but you're inserting the same value as element 1. I think this test should use result['b'][1] and its value should be different than bbb. Also, you might put add an assertion about the len here (since you have them in other tests too).\n. And that it should be bbb?\n. Actually, I don't think this really preserves API compatibility. After all, anyone using the old version of this code is probably overriding this function in a subclass, and they probably have the old signature. When we call this method with the new argument, things break.\nI think we should just \"bite the bullet\" and make a breaking change. Have apply_changes take the \"operations\" (I think that's a better name) and have it return (updated, changes). If you really want to try to preserve backwards compatibility, we could try to check if the return value was a tuple of length 2, and if it wasn't, assume that operations are also changes. But I think that's added complexity for no good reason, so if it were me I would just make it be a breaking change.\nI know this is more work but I think it's cleaner to have changes be explicitly returned than have it be a parameter that gets mutated!\n. I don't understand this question. I'd probably replace the second and third bullet points and just add a sentence to the first that says something like\nrst\nFor more details, see `JSON Patch Format <link here>`_.\nAre you asking where the link should point to? I would have it point to the JSON Patch section above, if that's possible.\n. Right, when he said \"a link\" I think he meant a link that points to the API docs, not a \"live\" URL or command to demonstrate the PATCH functionality. So pointing to the API docs sounds fine to me, since this is just an index.\n. I think we should do it for all calls for consistency. This also allows resources to support their own modification syntaxes, although I guess that nobody will actually do that. So I'm proposing the signature def apply_changes(self: Resource, record: Record, requested_changes: object) -> (updated: Record, applied_changes: {FieldName: Value}). (Or maybe applied_changes should just be [FieldName]?)\n. This means that existing resources will have to be updated to return the same requested_changes that they got in their parameters, but I think that's OK for a little more flexibility.\n. be split or get split\n. I think I know what you mean here, but I think this sentence is kind of confusing. How about The assertions should only correspond to the aspect of the specification that this test method is exercising?\n. I think you're trying to propose a TDD-style approach where you write tests before writing code for your feature, but you didn't say that explicitly here? Also, simplest. I think some of these bullet points would be better as a paragraph of prose, or maybe a link to some other blog post?\n. You need to update the :returns: and :rtype:. To be honest, I would love a great description of applied_changes, including what it should look like when some changes are happening to a deeply nested object.\n. I think this is OK. It's pretty clever and probably the best you can do without using something like eval. Of course, you don't need \", \" twice -- you might take it out entirely just to make it clear that we're not comparing against the literal text of the error message. How about something like this?\npython\nself.assert_(resp.json['message'].startswith('Content-Type header should be one of ['))\nself.assert_(resp.json['message'].endswith(']'))\nfor message in messages:\n    self.assertIn(message, resp.json['message'])\n. crave user data\n. getting it into production? deploying to production?\n. capitalized??\n. lose\n. No space before question mark in English\n. How about \"Our JavaScript client for browsers will leverage IndexedDB to work completely offline and synchronize data when online\"? Also, \"synchronize\" is spelled differently here from above (\"synchronise\") -- I prefer the -ize because I'm American, but we should probably be consistent.\n. I don't like a statement like \"Foo is optional\". It sounds like everyone assumes it's required and we're trying to let them know that it isn't, whereas actually client-side encryption is a feature and a strength. How about \"It's even possible for data to be encrypted on the client to keep user data safe even on the server\"?\n. Historically, \"data\" has been the plural of \"datum\", but I personally use it as an \"uncountable\" noun -- \"some data\" -- which typically takes singular verbs. \"The data is clear.\" I think this might be different in British English, but I'm not sure. I think either way is OK.\n. Maybe \"amortized\"? It means to pay for something once and spread its cost out over time, multiple projects, etc. I guess that's the opposite of what you meant here though. Maybe something simpler like \"shared\" or \"focused\"? Maybe something fancier like \"harmonized\" or \"standardized\"?\n. I don't feel strongly about it if @Natim wants to keep them. My real concern is just that I don't understand the workflow for releases on a release branch.. What are these changes about?. Maybe add a comment showing the character that this represents? \u560a. separated. They. Also, maybe validate them on every request, under heavy load.. If you're uncomfortable sharing the spec and its dict across your tests, another thing you could try is to explicitly deallocate them in a tearDown method using self.spec_dict = self.spec = self.resources = None, which might cause them to get GCed sooner.. Ah, this change isn't also part of making the __version__ endpoint fail, right? That's just the changes to the test suite below.. Could you add some documentation, e.g. here or in the commit message, as to how this improves generated code quality? It sounded like adding a tag causes code generators/libraries to generate a new namespace for all Kinto things.. So we are generating one class with a test_resource_foo for each operation? Do resources share operations, or are they distinguished somehow?\nWould it make more sense to define one class per resource? That way the class name could help track down what resource failed.\n. What's the significance of using the __dict__ of self.request? I guess marshal_param updates this dictionary in some way, and that is then used in self.app.request somehow?. Why just the first scope?\n. I don't really understand the value of this change. It seems like in this test, the type would be something that a client might want to know?. Optionally \ud83d\udc11 . I just noticed this.. what's going on here?. So what I was thinking when I suggested this was something a little different:\n```python\ndef operation_test_method(op):\n    def test_method(self):\n        pass   # basically \"validate_request_call\"\n    return test_method\ndef resource_test_class(resource):\n    attrs = {}\n    for op_id, op in resource.operations.items():\n        attrs[\"test_{}\".format(op_id)] = operation_test_method(op)\n    return type(\"{}Test\".format(resource.name), (SwaggerResourceTest,), attrs)\nBucketsTest = resource_test_class(resources['Buckets'])   # or whatever the syntax is\nCollectionsTest = resource_test_class(resources['Collections'])    # etc.\n```\nThis approach means you don't have to explicitly handle metaclasses, which could be easier to read. Another approach might be to use a class decorator:\n```python\ndef operation_test_method(op):\n    def method(self):\n        pass  # again, basically validate_request_call\ndef resource_test_case(resource):\n    def decorator(cls):\n        for op_id, op in resource.operations.items():\n            setattr(cls, \"test_{}\".format(op_id), operation_test_method(op))\n        return cls\nreturn decorator\n\n@resource_test_case(resources['Buckets'])\nclass BucketsTest(SwaggerTest):\n    pass\n```\nBut having reread this a bunch of times, I think the hardest part to read was just the diff. Reading the new file, it isn't that confusing, except for a couple of quirks in how I think you are interfacing with Bravado.. An example might help here. We should at least say something like \"These YAML files are merged recursively with the Kinto swagger.yaml file\".. I think some more comments would be helpful here to readers who don't already know much about the OpenAPI spec. How about: The 'security' field lists all acceptable ways of authenticating, so no plugin should add something to 'securityDefinitions' without it being here too, and then A 'security' requirement is an object of the form {security_mechanism: ['list', 'of', 'oauth2', 'scopes']}  # or an empty list if oauth2 isn't used.. I think we should unify this list of limitations with the ones in the documentation, and provide a link to them.. , and provide request or default in /batch requests\nAlso, I'd like to see a comment about whatever we ended up doing with additionalProperties and what bugs that fixes in what libraries, etc.\n. We should also make a note that this is the ONLY supported way to get the spec, since the running code does some transformations on the data, for example updating the host and listing the accepted security mechanisms.. Something got messed up with your RST here. I think you have an extra backtick before your link. You might also need an underscore after the closing backtick.. Do we have to change this to ruamel.yaml now that we've updated the dependency? Sorry if this is a stupid question, I've never used ruamel.yaml before.... It doesn't look bad by any means IMHO, and I really like having an explicit, formal schema, so I think this is an improvement.. Ouch.. too bad we have to make dozens of changes like this. Maybe we should try to find a few minutes in a subsequent PR to extract this expression as an attribute on the test case, something like self.swagger_resource?. I'm not crazy about seeing exactly the same code to produce a schema that's similar to the one we use in real code. We discussed this on Hangouts, we decided that the best approach would be to change these tests to either be tests of the bind method, or tests of the schema that are actually being used in the viewsets.. Why do we need to put bind() on our mocks?. It seems like validate_schema_for isn't useful any more, but I can't tell if we're removing it in this PR or not. I see a couple places in the tests like this where it's being removed, and I see the class attribute is being removed from ViewSet, but I don't see any code that uses this attribute. Are we removing it?. Why do we need something from mock.sentinel instead of just a MagicMock? (Above, in test_schema_is_added_when_uppercase_method_matches, you turn a sentinel into an ordinary MagicMock.). Sorry, I had misread this test the first time around!. It might be nice to have a module-level docstring explaining what's supposed to go in this file vs. what goes in kinto.core.resource.schema.. I think this will mutate the shared default_schemas dictionary.. Isn't this the same as 2 ** 63 ?. What happens if the method isn't in service.definitions? Or is that supposed to never happen?. I agree with @leplatrem's previous comment about this verbiage. How about If-Match and If-None-Match precondition headers now check the ETag for strict equality. Previous versions would allow requests if they seemed to be more recent than the current version.. Should this be put_if_match ? (Or was that too long?). Shouldn't we pass default here?. Personally, I'd be in favor of forbidding dots in field names. MongoDB does.. ```python\nWe use ignore_conflict here because each user can only ever have one default bucket, and it is created implicitly.\nIf we got a conflict, it's from two requests by the same user, both creating a bucket.\nThis isn't an error since creating the default bucket is idempotent.\n``\n. A quick module-level docstring linking to the zest.releaser docs and explaining how to test changes to this would be nice.. I think you could remove this and replace it with a line or two about \"This hook causes the kinto-admin to be built just before a release is packaged\"..unknown:). Does it maybe make sense to log the raw bytes of the query string to see what kind of madness we're getting?. I do! I'm super curious what kind of request would produce #1182.. Yeah, that changelog entry is my fault, sorry!. Leftovers?. Tangential question: Is this format officially mandated or anything?. Does thedeleteaftergetopen us up to race conditions?. It's still better than what we have and I'd be happy to merge it if there's a FIXME comment explaining the race and why we can't fix it.. Do we need to check thatwith_deletedisFalsetoo?. Should we try to combine these queries into one? Or doesREAD COMMITTEDsomehow protect us from race conditions?. Are the slashes in/abc/apart of why the behavior is different? Can we make them all have slashes?. They're the same create events fromtest_an_event_is_sent_on_implicit_bucket_creationandtest_an_event_is_sent_on_implicit_collection_creation. Since they're already there, I didn't think it was worth rehashing them. But a comment is a good idea.. Oh, oops.. I thought this was being added todelete_all`. Never mind... What I was wondering is:\n\nT1 deletes a collection \"record\".\nT2 inserts a collection \"record\" of the same name and commits. (Because of READ COMMITTED, it doesn't see the collection in T1 anyhow.)\nT3 looks for the records that are children of that collection, causing a timestamps record to be written.\nT1 then does purge_deleted and wipes the timestamps created in T3 (which it sees because of READ COMMITTED).\n\nBut I'm not really sure I understand SQL isolation well enough to know if this is a problem, and even if it is, we may not really be able to do anything about it. By the time we get to purge_deleted, we've already executed the delete query for the collection and deleted all of its records... Thinking about this more, it's a little strange that purging tombstones is the thing that triggers removal from the timestamps collection. If I delete a bucket, surely its \"collection\" timestamps should be deleted before I delete any records that are \"under it\" or purge their tombstones? Maybe the problem is just that purge_deleted is a bad name for this method, and we should change the concept to something like recursive_delete (which is outside the scope of this PR).. I just followed the example of the delete-collection script, although I feel like these scripts don't need to obey the same rules about readonly mode.. This is the record that will be inserted into the DB so I figured I would just return that. But it's really just because I was being lazy.. I have a two-level structure because I'm trying to handle pagination in the correct/natural way. But it's really clumsy. Maybe the right thing to do would be to write a \"paginated\" generator, but maybe that's overkill for this script?. I can add a check to the script to see if it's in includes, how does that sound?. I decided that the FIXME wasn't necessary and instead filed https://github.com/Kinto/kinto/issues/1236.. I decided to keep the wrapper (that checks config parameters and returns exit status codes) in scripts, but move the body of the script into the quota plugin.. Maybe assert that it's still equal to 'hach\u00e9', and not e.g. 'hach\u00c3\u00a9'?. Can we specify a type of exception?. Can we self.assertRaises((OverflowError, UnicodeDecodeError), ...)? Per https://docs.python.org/2/library/unittest.html#unittest.TestCase.assertRaises, it seems like we can.. Oops, I didn't realize we had released a 1.16. You should probably remove the has and JSON-encoded notes from 1.16 (below).. I don't think we need to go to this lengths to avoid putting an empty required field. The JSON Schema Spec says that omitting it is the same as an empty array. Unless you're trying to do this so that we don't confuse users by secretly changing their schema, but I don't think that's valuable, since we're already changing the schema.\nShould we be doing these manipulations to the schema at schema save time?\nShould we be removing definitions of internal fields from schema['properties']?. :+1:. We don't actually need this to be a safeholder any more, we can put LIMIT in the query.. max_fetch_size can get removed from safeholders too.. while not validator.match(username). Or, pull the first input into the while loop.. I think this is fine, but having quoted at the end of the noun phrase feels a little clumsy to me. Normally I'd probably write ETags are the quoted ``last_modified`` value of the record, but I see that the example (``\"<record.last_modified>\"``) being next to the word \"quoted\" is kind of nice too.\nI'd probably also use \"observe\" rather than \"notice\" here, but I think notice is OK.. I'd prefer to change requesting Github to making a request to Github each time.. This isn't true. This sentence should stay the same, along with Memcached is also available as a cache backend.. What is this about? Is there no Memcache-specific exception parent class we can use here?. This might be a silly question, but do we have to worry about reentrancy here (sharing the Memcache client across threads)? Or does uwsgi just spawn multiple threads with their own interpreters?. I guess we use this JSON format so that we can retrieve the TTL in the ttl() method? It's kind of a bummer that there's no ttl command (as in Redis).. A comment explaining why we can't use the touch command would be a good idea.. Typo here?. This is outside the scope of this PR, but I guess this means we can never set the permissions to the empty object.. I think but and though (N.B. typo) are redundant -- either one is fine. I'd probably write note instead of notice. permissions-specific.. Yes, but IMHO passing an empty object should be different from not passing anything.. Wait, maybe I misunderstood, I didn't think that was a consequence. I would have written something like However, using null instead of a set of principals when using other patch types is not valid and will result in an error.. Ah, yes, then I misunderstood. I thought we had logic to only do the preprocess/postprocess null step if we were in a merge patch. In that case, why do we have this preprocess/postprocess step, versus just allowing permissions to be nullable? I'm guessing it's because we want to only allow nulls in certain kinds of operations, but it seems like we added it to the PermissionSchema, so it seems like it's global anyhow?. flake8 complains that this variable is never used. Is a bare execute() call acceptable, or do we have to check the result somehow?. You could shorten this to qs or None. But why not just build a dict of parameters we want to include and only add querystring if there's something here, similar to the way you do in the error view?. Weird spacing around last_modified.. Missing semicolon?. I guess this comment isn't exactly true any more since we update deleted?. This will overwrite any existing record, but (if the current record isn't deleted) it should raise an integrity error. I'm not sure there's a clean way to do this. We can add WHERE deleted = TRUE, and then raise an integrity error if no row was inserted, but we won't be able to retrieve the existing timestamp or whatever. Or I guess we could continue with our current TOCTOU strategy and just defer fixing this to another PR (with tests and everything).. I think we should consider putting a FOR UPDATE here, although I don't really have a strong justification for why. It seems like two different queries could select the same not-yet-deleted rows and delete them simultaneously, although they might want to each delete 10. (But this might be a bigger topic than we want to address in this PR; see this SO discussion.). This prefers to keep the tombstone. Maybe we should prefer the existing record by running a DELETE query first?. Nice cleanup \ud83d\udc4d. Hmm, oops? I just did make build-requirements and committed without really reviewing it. I'll roll it back... Apparently as of Python 3.4, __file__ is almost always an absolute path. I have updated the uses of it in the codebase.. While this is technically true, I believe returning None explicitly in this particular case is a better expression of intent here, since the function is meant to return None when it cannot identify the schema version in play. But I agree with your suggestion in a couple of other places.. This is the original schema, from which I want to verify that migration is possible.. Oops, yeah. Good catch. I hate XUnit-style test cases... Each call is a tuple of arguments. I guess the idea is to make sure that forms such as logger.info(\"Executing migration {}\", \"migrations/migration_003_004.sql\") are still OK?. Rethinking how logging is done in the test suite is outside the scope of this PR, although I agree it needs work.. That would create a schema that was different from the PostgreSQL permission v1 schema.. Yes (as described in the PR description as well as the commit comments).. initiated. Apparently it always came last (per the test just above). None comes first, but Missing comes last to mimic the Postgres backend.. This is a unittest flavored test, which doesn't have any concept of \"parametrization\". I can convert it to a pytest style test, but it seems a bit aggressive of a change. Alternately I can use metaprogramming to generate all the tests, but it seems a bit ugly. In the meantime I used subTest, which is a little bit like parametrize in that it annotates the test failure with the values that were being tested. What do you think?. I think this is all way too complicated and I am not crazy about the use of string processing to convert from one type to another. I think you should be converting the filter value to JSONB. This way we can support checking for fields containing complex objects like [1, 2] (in a field like [[1,2], [5, 9]]). There's no way to do \"overlap\" testing with this type, but I think that's OK -- do we really need contains_any at this point in time or did you just figure it was easy to implement at the same time?. What was this about?. No, that's not right.\nhttp --auth 'user:user' PUT 'http://localhost:8888/v1/buckets/default/collections/def/records/r1' 'data:={\"user\": {\"first\": \"Ethan\", \"id\": 1234}, \"aliases\": [{\"ll\": \"ls -l\"}, {\"gti\": \"git\"}, {\"vi\": \"vim\"}]}'\nhttp --auth 'user:user' 'http://localhost:8888/v1/buckets/default/collections/def/records?contains_any_aliases=[{\"ll\":\"ls -l\"}]'   # matches\nhttp --auth 'user:user' 'http://localhost:8888/v1/buckets/default/collections/def/records?contains_any_aliases=[{\"sl\":\"ls -l\"}]'   #doesn't match\nhttp --auth 'user:user' 'http://localhost:8888/v1/buckets/default/collections/def/records?contains_any_user={\"id\":1234}'   # 503\nCompare with contains:\nhttp --auth 'user:user' 'http://localhost:8888/v1/buckets/default/collections/def/records?contains_aliases=[{\"ll\":\"ls -l\"}]'   # matches\nhttp --auth 'user:user' 'http://localhost:8888/v1/buckets/default/collections/def/records?contains_aliases=[{\"sl\":\"ls -l\"}]'   #doesn't match\nhttp --auth 'user:user' 'http://localhost:8888/v1/buckets/default/collections/def/records?contains_user={\"id\":1234}'  # matches\nN.B. these behaviors may not match in the memory backend.. This doesn't work.\nhttp --auth 'user:user' POST 'http://localhost:8888/v1/buckets/default/collections/def/records' data:='{\"name\": \"Superman\", \"colors\": [\"red\", \"blue\"]}'\nhttp --auth 'user:user' GET 'http://localhost:8888/v1/buckets/default/collections/def/records?contains_colors=[red,blue]'\nDoesn't match... The same problem above is present here.. What happens if field is not an array?\nThis can also match objects, but I guess it doesn't matter because almost any object contains you could consider doing is better expressed as a bunch of equality filters?\n. These tests are inaccurately named.. The UnicityError should use the record that it conflicted with, not the record that was the conflict.. Doing a self.get() leads to a different race condition. What happens if another thread deletes the record in between your insert failing and your get()?. Why do you want to support this syntax? Personally, I consider this format legacy and would push towards using JSON wherever possible. (I understand why the code supports this syntax, but I don't think we should put it into our API.). Why should we add contains or contains_any to this code block? It only pertains to last_modified and id, which (because they are not arrays) should never be used with these operators.. I don't love this solution to this problem. At the very least, you should leave a comment explaining why this order is important.. I don't have a strong opinion about the human-language description of the test, but it shouldn't have contains_any in the name if it doesn't test contains_any.. Same here.. Why shouldn't we support this?. These tests are each trivially passable by returning an empty list. Maybe it would be good to add an assertion counting how many objects are returned, or verifying that any object which wasn't returned didn't have \"red\".. It would be nice to add a test for an object in an array of objects.. nit: I probably would have preferred this to be added to cond rather than conditions.. Well, I just tried building a list and none of the tests failed. Maybe the person who wrote it originally was afraid that different pagination rules would re-match a record twice? In that case, the tests probably won't fail because we don't construct pagination rules in such a way where this could happen (but a pathological user could conceptually find a way if they were motivated). Since none of the tests fail, I'll take it out... I did this so I could control the permission name I wanted to show up in the config. (I wanted user-data_delete instead of user-data_write.) I just noticed this one says user_data instead of user-data, even though my config file says user-data, so I guess I don't 100% understand how this works. There might also be a better way to get this to behave the way I want to, rather than overriding the factory.. There's definitely some bugs here. In particular, the quota plugin fails hilariously to deal with what I'm doing here, and I'm not even sure the buckets / collections listeners are being fired (because they should have deleted the quota records).. This sort() turns out not to be necessary, I misread how the get_objects_permissions function works.. against. I think must is a bit strong here, maybe can is better?. every underlying collection. Aren't the other things you documented new too? Should we put record:schema and group:schema here too?. It seems a little unbeautiful that we have to both pass the internal fields to validate_schema but remove them from the data ourselves.. Maybe we should abstract this validate_or_400 pattern and put it in schema_validation.. It's kind of unfortunate that the schema validation feature doesn't have to be turned on here, because it claims collection:schema as a reserved word... Yes, that.. every underlying collection, group, or record. I'm a little nervous about this. It hard-codes part, but only part, of the containment hierarchy of Kinto. To be honest, I preferred that this logic be part of the Record resource.. Basically, I changed resource_events to be mutated (drained), but this poses a problem because we would no longer be able to fire AfterResourceChanged and AfterResourceRead, so now I keep a second explicit dictionary of those after they've been drained from the first one.. matchdict sounds an awful lot like a dictionary of information describing the URL -- what route it matched, what resource was named, what its ID was, etc. However, by definition, if you are providing this information using this argument, then the data is about some resource different from the one specified by the current URL. This is why I gravitated away from matchdict.. mentioned. Also, shouldn't in docs be in config?. I added it using autofunction to notifications.rst. On the one hand, you could say I was trying to integrate my documentation with what was already there. On the other hand, you could say I was being lazy.... It should match the order of the events, so de Paris (which triggers the de New York).. I guess from the name resource_ids that several can be provided at once, but we don't provide an example of that, which may mean someone reading this will think this is an example of many resource_ids.. Nit: for resource_id in self.resource_ids. I believe @leplatrem's existing comment about doing this only once, during __init__, is outstanding.. I'm a little nervous about tying this to bucket and collection since this is kinto.core, which was designed to support user-defined resources. But I'd be OK with it if this is much easier than the alternative.\nI saw a comment earlier by Mat asking why we couldn't just compare matchdict against the parsed resource_id -- I might have misunderstood what he was asking in which case just say so, but why do we have to go through all these contortions here? Maybe a comment would be helpful?\n. Oh, I didn't realize this was here! Why do we have both this and view_lookup (which is what I used when I wanted to parse URL-y things in kinto-changes)? I'm guessing based on your change that the event filtering stuff uses this code and not view_lookup. This function supports something that is sort of URL-y but also <bid>/<cid> which I think is kind of gross. Since we're introducing a new feature, I think it would be better if it could only parse URLs and not semi-URLs like this function does -- is it possible for this feature to use view_lookup instead of this? If it's difficult, let me know, maybe we can find another approach.. I see that you preserved the extra period at the end of this message, but actually this isn't the end of the message (there's another line afterwards), so let's get rid of the period (assuming we have to use parse_resource at all).. There's a DummyRequest class in kinto.core.testing that provides at least upath_info. Do we still need these mocks if we can use that instead? I'd rather test against a DummyRequest but with real utils methods than a real Request but with mocked utils methods.. Yes, as noted in the commit message.. I'm a bit confused because here it seems like failed authentication should be obvious (401/403) but elsewhere the documentation says to request /v1/ and try to infer that auth has failed because of no principals. Is that specific to /v1/? Does it depend on the auth mechanism?. Is this necessary? We still have https://github.com/Kinto/kinto/blob/48d58f0fefe5c89218fb756616426c1efe06e05c/kinto/core/initialization.py#L111-L112. Maybe update this comment... an object. This isn't really a Kinto record but a Memcached record. I could kind of go either way on this.. Should this be \"plural endpoint\", knowing what we know now?. Should these be and the items not modified in the interim?. Same question here about whether this should be the elements or something.. This should be obj. Shouldn't this be obj too?. Shouldn't this be obj?. obj. obj ?. Am I reading correctly? There are two object params? Also, obj. Shouldn't this be obj?. obj ?. I'm not sure I really understand what these kwargs are and whether I should expect them to have an object or a record.. This should remain record. Same with these.. These too.. an object. Should this be obj?. This should be obj.. I'd suggest changing this to something like contents or stored data or everything.. Should colobjects here be something like resobjects?. These two don't seem quite right to me... More generally, I don't love self.object, especially if we're using obj to avoid the builtin object.. If you move this down a little bit, you can use the parsed operator to check whether it is exactly a like query (and not e.g. a check for a field like likes_pizza).. an object. I still think this qualifies as a breaking change. Anyone who implemented a resource subclass has to update the names of methods (as you did in docs/core/resource.rst). Same for anyone who implemented a storage backend.. obj?. This should remain as it was.. Another place where maybe object is not the greatest?. Another use of self.object.. Another self.object. Another one.. Another one. Another one.. Another one.. Another one.. Another one.. Another one.. I'm not shocked, but I couldn't tell if you left it on purpose or whether it was just another artifact of your search-and-replace.... I don't think that prevents breakage in the case I mentioned.. I think these should remain as they are.. Shouldn't this be resource?. It would (still...) nice to add a note here mentioning that this could break you if you implemented a resource subclass.. Taking some of the text from existing docstrings and putting it here might be nice. Maybe something like This is a hook allowing ...?. Please be sure we don't lose this (still...)!. More merge messiness.. Resolved by @leplatrem in https://github.com/peterbe/kinto/commit/3128691ae1396c796000e88d4ca8d49cd93840d7. I think the link to Docker Hub is OK, but I don't know if we need this here. It's already the third option shown on https://kinto.readthedocs.io/en/latest/tutorials/install.html, which you can get to from clicking the link to \"Online documentation\" above. What do you think?. Right.. Good catch. I bet it doesn't work. Permissions are probably being deleted by cascading event handlers.. Getting resource events right is pretty important. For example, it's how the quota plugin handles adjusting quotas.. That's it, thanks. I was trying to figure out a way to get access to it rather than hard-coding a random number... Maybe we can move this logic into validate_schema and not have to duplicate it in kinto/views/records.py.. That isn't what this function does. Should it?. Good idea, thanks.. I'm a bit leery of doing this because we remove data associated with this user from a lot of different places and I don't want to end early with a 404 when there's other stuff to be removed.. To be honest, I'm not sure. It feels like there's a concept of \"hierarchy\" in Kinto -- what resources are contained by what other resources and at what levels -- but nowhere does there seem to be any kind of formalization of that hierarchy. I feel like the whole concept needs to be structured somewhere, but I think it's outside the scope of this PR. This is a quick-and-dirty hack that responds to what this endpoint needs.. If we try to support /buckets, then we should also try to support /buckets/abcd/collections. The method (as scoped right now) doesn't have to care too much about these kinds of URLs because it only considers actual object IDs.. I was basing this on the code in test_events, although I admit it's a little excessive for this case. There might be a larger solution to cleaning up how we initialize apps in the test suites generally... I guess that means the code isn't necessary.. I'll simplify.. ???. ",
    "s-utsch": "I commited the changes. I didn't know you could call pserve as a function instead of running it with a subcommand, thanks for letting me know.\nAlso, I removed my script from the coverage test, I don't know how to make it pass on it. Does anyone know what I'd need to do to fix it?\n. ",
    "smuriu": "I'm very much in favour of the proposal by @almet. I only just recently came across kinto but already thinking of things I could do with it. One question I have, related to the kinto-attachment plugin, would this proposal if implemented add the attachment attribute as metadata alongside id, permissions, ...? Seems a lot cleaner that way IMO.\nOn a side note, has anyone proposed a related records plugin? In my mind, it would add the key relations which is an array of  a relation objects:\n'relations': [\n  {\n    'relation': {\n      'collection': 'collection_x',\n      'record': 'record_x'\n    }\n  },\n  {\n    'relation': {\n      'collection': 'collection_x',\n      'record': 'record_y'\n    }\n  }\n]\nAgain, this would feel nice if added as metadata alongside id, ...\n. ",
    "lavish205": "@Natim can you assign this bug to me?\n. will solving #270 fix this?\n. \"flush\" capability same as \"schema\" and \"attachments\" right?\n. I am working on this bug.\n. #511 \n. @Natim how to handle two condition like if [[ $ACTION != loadtest_tutorial && $ACTION != loadtest_simulation ]]; in travis?\n. @leplatrem yes, I am unable to figure out how to fix it \n. @leplatrem Do i need to modify test cases as well?\n. @leplatrem @Natim I'm unable to figure out what is missing?\n. @Natim I have added one test case: https://github.com/lavish205/kinto/blob/49b6a50a28bf2a47976e169e21ad3ada8aa83b46/kinto/tests/core/test_scripts.py#L27\nWhere I'm calling storage, cache and permission migration. What else I have to do?\n. Thanks @leplatrem  and @Natim \n. @leplatrem do we need to remove last_modified field from records table?\n. Hi @leplatrem this seems easy, but can you provide little more information regarding where we need to add this check and raise 400?\n. need more information to work on this bug.\n. @mansimarkaur No. You can take this issue. \n. Acc. to idiomatic python, .get() is the best way to access value of any particular key from dict.\n. but we need different settings for both the test cases. It has been discussed with @Natim \n. ",
    "Micheletto": "LGTM\n. ",
    "davidbgk": "Thanks!\n. @Natim way better, thanks!\n. Why not a UUID? There is a nice uuidgen under OSX.\n. :+1: \n. ",
    "nhoizey": "You're welcome! ;-)\n. ",
    "conlini": "It would make sense to tie in dependency chain on commands.\nSo running migrate would ensure init is run if not done previously\nand running start would run init > migrate and then start\nThat would reduce the need for multi step setup/startup\n. hmm yes that does add a level of complexity and branches when there are multiple configurations.\nTrying to work that out would require asking user to chose one of the configs, which would defeat the purpose of a single command starting up the server.\n. ",
    "scottinet": "Hi, and thank you for including Kuzzle in your comparison table!\nAbout Kuzzle, as you may know, we're still in alpha version, and we are working hard to bring our product to beta. Nevertheless, we've already developped some of the features you mention, and I'd like to bring some precisions. :-)\nBut first, can you help me understand these two listed features, to be sure to answer correctly about these: Offline-first client and Decentralised discovery?\nAbout the table itself:\nFunctionalities we already support:\n- Conflict resolution\n- Bulk operations (API documentation). Easy access through our SDK is planned in the next few weeks\n- Validation, through pipe plugins\nFunctionalities in alpha stage:\n- Fine-grained permissions (pull request). We already have a dev documentation, and default roles are available in our configuration file. More documentation and features are currently under development\nUnder development:\n- Pluggable authentication\n. Hi again :)\n- Offline-first: do you mean this? :-)\n- Decentralized discovery: we don't support data zones yet\n- Conflict resolution: we simply expose ElasticSearch Conflict Management. Usually, it's a \"last update wins\" strategy, but several options are available to fine-tune this. For instance, updates on critical documents can be done using the 'version' tag, telling ElasticSearch that we want to update a specific version of the document. If the current document version is greater than the provided one, a conflict error occurs.\n- Bulk: indeed, we support only bulk insert/update/delete for now. Data dumps functionalities are planned for a later time\n- Validation: it seems that you're referring to data _format validation, through a schema. We call them mappings and we support them (and also in our SDK). I thought you were talking about functional validation, which is business-specific. For instance, it's very common for a back-end to allow data to be created by an application only if this data complies to certain conditions. That's why I mentioned plugins\n- Fine-grained permissions: like I said, this functionality is still in alpha-stage. For instance, a new API route has just been submitted in this pull request, allowing to create or update roles through the API. \n. ",
    "kseistrup": "However, functools32 is for Python 2.7 only, so I get this exception when I try to pip install kinto on Python 3.5:\npytb\n$ pip install kinto\nCollecting kinto\n  Downloading kinto-1.11.0-py2.py3-none-any.whl (47kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 49kB 1.3MB/s \nCollecting cliquet<3,>=2.15 (from kinto)\n  Downloading cliquet-2.15.0-cp2.cp3-none-any.whl (315kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 315kB 1.1MB/s \nCollecting jsonschema (from kinto)\n  Downloading jsonschema-2.5.1-py2.py3-none-any.whl\nCollecting functools32 (from kinto)\n  Downloading functools32-3.2.3-2.tar.gz\n    Complete output from command python setup.py egg_info:\n    This backport is for Python 2.7 only\n. ",
    "niraj8": "Something like this?\n\n. Yes, it will point to Run Kinto page. I'll send a pull request right away.\n. :smiley: \n. Yes. \nhttp://docs.hood.ie/en/start/\n. ",
    "saidimu": "The latest build of the Docker image (ID b8ccaa29bb7f) also fails with the same error:\nsudo docker run -p 8888:8888 kinto/kinto-server\nTraceback (most recent call last):\n  File \"/usr/local/bin/kinto\", line 9, in <module>\n    load_entry_point('kinto==1.11.0.dev0', 'console_scripts', 'kinto')()\n  File \"/code/kinto/__main__.py\", line 74, in main\n    pserve.main(pserve_argv)\n  File \"/usr/local/lib/python3.5/site-packages/pyramid/scripts/pserve.py\", line 58, in main\n    return command.run()\n  File \"/usr/local/lib/python3.5/site-packages/pyramid/scripts/pserve.py\", line 325, in run\n    relative_to=base, global_conf=vars)\n  File \"/usr/local/lib/python3.5/site-packages/pyramid/scripts/pserve.py\", line 367, in loadserver\n    server_spec, name=name, relative_to=relative_to, **kw)\n  File \"/usr/local/lib/python3.5/site-packages/paste/deploy/loadwsgi.py\", line 255, in loadserver\n    return loadobj(SERVER, uri, name=name, **kw)\n  File \"/usr/local/lib/python3.5/site-packages/paste/deploy/loadwsgi.py\", line 271, in loadobj\n    global_conf=global_conf)\n  File \"/usr/local/lib/python3.5/site-packages/paste/deploy/loadwsgi.py\", line 296, in loadcontext\n    global_conf=global_conf)\n  File \"/usr/local/lib/python3.5/site-packages/paste/deploy/loadwsgi.py\", line 317, in _loadconfig\n    loader = ConfigLoader(path)\n  File \"/usr/local/lib/python3.5/site-packages/paste/deploy/loadwsgi.py\", line 393, in __init__\n    with open(filename) as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/code/config/kinto.ini'\nStarting subprocess with file monitor\n. Thanks @leplatrem !\n. ",
    "gabisurita": "It's a bit unfriendly, but this is possible via:\n- ?attr  for records not having the attribute\n- ?not_attr for records having the attribute defined\nBut I can work on this if changes are needed. \nAn example:\n```\n$ http GET localhost:8888/v1/buckets/default/collections/c1/records --auth aaa:aaa\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, Total-Records, ETag, Pragma, Cache-Control, Backoff, Next-Page\nCache-Control: no-cache, no-store\nContent-Length: 166\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 10 Oct 2016 22:20:16 GMT\nEtag: \"1476137810045\"\nLast-Modified: Mon, 10 Oct 2016 22:16:50 GMT\nServer: waitress\nTotal-Records: 3\n{\n    \"data\": [\n        {\n            \"id\": \"r3\",\n            \"last_modified\": 1476137810045,\n            \"param\": \"nope\"\n        },\n        {\n            \"id\": \"r2\",\n            \"last_modified\": 1476137797249\n        },\n        {\n            \"id\": \"r1\",\n            \"last_modified\": 1476137764176,\n            \"param\": \"yeap\"\n        }\n    ]\n}\n$ http GET localhost:8888/v1/buckets/default/collections/c1/records?not_param --auth aaa:aaa\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, Total-Records, ETag, Pragma, Cache-Control, Backoff, Next-Page\nCache-Control: no-cache, no-store\nContent-Length: 124\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 10 Oct 2016 22:20:21 GMT\nEtag: \"1476137810045\"\nLast-Modified: Mon, 10 Oct 2016 22:16:50 GMT\nServer: waitress\nTotal-Records: 2\n{\n    \"data\": [\n        {\n            \"id\": \"r3\",\n            \"last_modified\": 1476137810045,\n            \"param\": \"nope\"\n        },\n        {\n            \"id\": \"r1\",\n            \"last_modified\": 1476137764176,\n            \"param\": \"yeap\"\n        }\n    ]\n}\n$ http GET localhost:8888/v1/buckets/default/collections/c1/records?param --auth aaa:aaa\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, Total-Records, ETag, Pragma, Cache-Control, Backoff, Next-Page\nCache-Control: no-cache, no-store\nContent-Length: 52\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 10 Oct 2016 22:20:25 GMT\nEtag: \"1476137810045\"\nLast-Modified: Mon, 10 Oct 2016 22:16:50 GMT\nServer: waitress\nTotal-Records: 1\n{\n    \"data\": [\n        {\n            \"id\": \"r2\",\n            \"last_modified\": 1476137797249\n        }\n    ]\n}\n```\n. I would like to work on this issue.\nAny problem in following the approach used on Json Patch (#859)?\n. How do you fell about this improvement at the moment? My main concern is pagination and batch limits from settings. Should we support these? In case we do, what happens if we exceed the limit?\n@leplatrem @Natim . > I don't think we should worry about pagination rules but maybe using the batch limits could be important. If we exceed the limit we could have the same error that we have with the batch endpoint.\nI don't think we can use the same protocol for batch because batch requests are ordered, but I don't think we can assume the same for collection PATCH.\nIDK. If you think it makes sense I can implement it. While working on the rust client I was thinking that this could be useful to simplify the synchronization protocol but it also brings several related issues (e.g. limits, history entries, logging, performance). Thinking through it maybe it brings more problems than solutions.\nAlso, I don't think this is an easy pick. . I would like to work on this issue. :)\n. Once we get cornice_swagger to work we could provide the OpenAPI documentation for the path at this endpoint with almost no effort, but if we want to support it, it would be a good idea to change a bit the design of #1033. Opinions?. Removing the id field already leads to an error on the insertion, but the removing the timestamp doesn't. I think including a test for it would be a good idea. I'll work on it.\n. Sorry for the delay, I was having some troubles in get the storage tests running locally. Some tests were failing due to the database timezone. This probably should be included on the backend documentation, but I think that's already covered by issue #788. \nLeaving the last_modified field off the record already produce errors on several tests, so I think another test for this is not needed.\nResults (159.86s):\n    1386 passed\n       6 failed\n         - /home/gabi/outreachy/kinto/kinto/core/storage/testing.py:567: AssertionError: 1475004498137L not less than 1475004498124L\n         - /home/gabi/outreachy/kinto/kinto/core/storage/testing.py:548: AssertionError: 1475004498292L != 1448881675541\n         - /home/gabi/outreachy/kinto/kinto/core/storage/testing.py:498: AssertionError: 100 != 200\n         - /home/gabi/outreachy/kinto/kinto/core/storage/testing.py:650: KeyError: 'last_modified'\n         - /home/gabi/outreachy/kinto/kinto/core/storage/testing.py:629: AssertionError: 1475004507708L not less than 1475004507701L\n         - /home/gabi/outreachy/kinto/kinto/core/storage/testing.py:610: KeyError: 'last_modified'\n. I've made a few changes that I think cover all your comments.\nOne more thing, do you think we should mention some of the Python dependencies? Or at least cite the major dependencies, like sqlalchemy and psycopg2?\n. This may not only be related to history entries.\nIf we create the collections with ids 0, 1 and string, the behavior is different when selecting via the id parameter. \n$ echo '{\"data\": {\"description\": \"Collection Zero\"}}' |  http PUT https://kinto.dev.mozaws.net/v1/buckets/default/collections/0 -v --auth 'hey:you'\n$ echo '{\"data\": {\"description\": \"Collection One\"}}' |  http PUT https://kinto.dev.mozaws.net/v1/buckets/default/collections/1 -v --auth 'hey:you'\n$ echo '{\"data\": {\"description\": \"Collection String\"}}' |  http PUT https://kinto.dev.mozaws.net/v1/buckets/default/collections/string -v --auth 'hey:you'\n```\n$ http GET https://kinto.dev.mozaws.net/v1/buckets/default/collections -v --auth 'hey:you'\n{\n    \"data\": [\n        {\n            \"description\": \"Collection String\", \n            \"id\": \"string\", \n            \"last_modified\": 1475731844316\n        }, \n        {\n            \"description\": \"Collection One\", \n            \"id\": \"1\", \n            \"last_modified\": 1475731818775\n        }, \n        {\n            \"description\": \"Collection Zero\", \n            \"id\": \"0\", \n            \"last_modified\": 1475731794491\n        }\n    ]\n}\n```\n```\n$ http GET https://kinto.dev.mozaws.net/v1/buckets/default/collections?id=string -v --auth 'hey:you'\n{\n    \"data\": [\n        {\n            \"description\": \"Collection String\", \n            \"id\": \"string\", \n            \"last_modified\": 1475731844316\n        }\n    ]\n}\n```\n```\n$ http GET https://kinto.dev.mozaws.net/v1/buckets/default/collections?id=0 -v --auth 'hey:you'\n{\n    \"data\": []\n}\n```\n```\n$ http GET https://kinto.dev.mozaws.net/v1/buckets/default/collections?id=1 -v --auth 'hey:you'\n{\n    \"data\": []\n}\n```\n. I've closed the PR because this solves the specific problem for #851, but not the general problem that I mentioned there. I just realized that when building tests to this problem. I thought that I did this pull request too early to keep it. \n. I just wasn't sure if I would actually be able to fix this. Sometimes people don't like to have open pull requests on their repositories that aren't getting close to a solution. \nSorry for the mess I've made here.  :/\n. This actually solves the problem when the filtering by 'id' and 'collection_id'. I've also added some view_tests for this problem. \n```\n$ http GET http://localhost:8888/v1/buckets/default/collections --auth \"aaa:aaa\"\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, Total-Records, ETag, Pragma, Cache-Control, Backoff, Next-Page\nCache-Control: no-cache, no-store\nContent-Length: 230\nContent-Type: application/json; charset=UTF-8\nDate: Fri, 07 Oct 2016 00:33:29 GMT\nEtag: \"1475790719823\"\nLast-Modified: Thu, 06 Oct 2016 21:51:59 GMT\nServer: waitress\nTotal-Records: 3\n{\n    \"data\": [\n        {\n            \"description\": \"Collection 1\", \n            \"id\": \"1\", \n            \"last_modified\": 1475790159895\n        }, \n        {\n            \"description\": \"Collection 0\", \n            \"id\": \"0\", \n            \"last_modified\": 1475790151479\n        }, \n        {\n            \"description\": \"Collection String\", \n            \"id\": \"string\", \n            \"last_modified\": 1475790135228\n        }\n    ]\n}\n$ http GET http://localhost:8888/v1/buckets/default/collections?id=string --auth \"aaa:aaa\"\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, Total-Records, ETag, Pragma, Cache-Control, Backoff, Next-Page\nCache-Control: no-cache, no-store\nContent-Length: 90\nContent-Type: application/json; charset=UTF-8\nDate: Fri, 07 Oct 2016 00:33:32 GMT\nEtag: \"1475790719823\"\nLast-Modified: Thu, 06 Oct 2016 21:51:59 GMT\nServer: waitress\nTotal-Records: 1\n{\n    \"data\": [\n        {\n            \"description\": \"Collection String\", \n            \"id\": \"string\", \n            \"last_modified\": 1475790135228\n        }\n    ]\n}\n$ http GET http://localhost:8888/v1/buckets/default/collections?id=1 --auth \"aaa:aaa\"\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, Total-Records, ETag, Pragma, Cache-Control, Backoff, Next-Page\nCache-Control: no-cache, no-store\nContent-Length: 80\nContent-Type: application/json; charset=UTF-8\nDate: Fri, 07 Oct 2016 00:33:34 GMT\nEtag: \"1475790719823\"\nLast-Modified: Thu, 06 Oct 2016 21:51:59 GMT\nServer: waitress\nTotal-Records: 1\n{\n    \"data\": [\n        {\n            \"description\": \"Collection 1\", \n            \"id\": \"1\", \n            \"last_modified\": 1475790159895\n        }\n    ]\n}\n$ http GET http://localhost:8888/v1/buckets/default/collections?id=0 --auth \"aaa:aaa\"\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Content-Length, Expires, Alert, Retry-After, Last-Modified, Total-Records, ETag, Pragma, Cache-Control, Backoff, Next-Page\nCache-Control: no-cache, no-store\nContent-Length: 80\nContent-Type: application/json; charset=UTF-8\nDate: Fri, 07 Oct 2016 00:33:40 GMT\nEtag: \"1475790719823\"\nLast-Modified: Thu, 06 Oct 2016 21:51:59 GMT\nServer: waitress\nTotal-Records: 1\n{\n    \"data\": [\n        {\n            \"description\": \"Collection 0\", \n            \"id\": \"0\", \n            \"last_modified\": 1475790151479\n        }\n    ]\n}\n```\n. ^ Sorry, I've closed the pull request because GitHub doesn't allow resets on a \"pull requested\" branch. Sorry about that. I'm still getting used to work with pull requests.\n. > After a reset you can push force your branch remotely.\nApparently only if you reset within the the committs on the pull request. I've reseted to a commit before I did any modifications, added more commits and when I pushed it (with --force) the PR was automatically closed. I'm still trying to figure out what happened.\nAnyways, I think now the solution is working both on the regular id and the history plugin filters. Let me know if there is something wrong or missing :)\n. Behaviour:\n```\n$ echo '{\"data\" : {\"touched\": \"yes\" }}' | http PATCH http://localhost:8888/v1/buckets/default/collections/c0/records/r0 --auth aaa:aaa\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 169\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 10 Oct 2016 21:15:54 GMT\nEtag: \"1476134154134\"\nLast-Modified: Mon, 10 Oct 2016 21:15:54 GMT\nServer: waitress\n{\n    \"data\": {\n        \"id\": \"r0\", \n        \"last_modified\": 1476134154134, \n        \"touched\": \"yes\"\n    }, \n    \"permissions\": {\n        \"write\": [\n            \"basicauth:b4a6199b0cbf1363ef8e60c1c26e0358f49f5698c6bb4cb879437732768fcc94\"\n        ]\n    }\n}\n$ echo '{\"data\" : {\"touched\": null }}' | http PATCH http://localhost:8888/v1/buckets/default/collections/c0/records/r0 --auth aaa:aaa\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 153\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 10 Oct 2016 21:16:09 GMT\nEtag: \"1476134169802\"\nLast-Modified: Mon, 10 Oct 2016 21:16:09 GMT\nServer: waitress\n{\n    \"data\": {\n        \"id\": \"r0\", \n        \"last_modified\": 1476134169802\n    }, \n    \"permissions\": {\n        \"write\": [\n            \"basicauth:b4a6199b0cbf1363ef8e60c1c26e0358f49f5698c6bb4cb879437732768fcc94\"\n        ]\n    }\n}\n```\n. > I know it would be better if we would have this new behaviour by default, but we can't break existing clients, so we better leave behind the request header Content-Type: application/merge-patch+json as the spec says.\nThat would include accept application/merge-patch+json as a valid content type on the viewset, right?\nRunning the RFC example over a record: \n```\n$ echo '{\"data\":{ \"title\": \"Goodbye!\", \"author\" : { \"givenName\" : \"John\", \"familyName\" : \"Doe\" }, \"tags\":[ \"example\", \"sample\" ], \"content\": \"This will be unchanged\" }}' |  \\ \nhttp PATCH http://localhost:8888/v1/buckets/default/collections/c0/records/r1 --auth aaa:aaa\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 317\nContent-Type: application/json; charset=UTF-8\nDate: Tue, 11 Oct 2016 15:52:53 GMT\nEtag: \"1476201173217\"\nLast-Modified: Tue, 11 Oct 2016 15:52:53 GMT\nServer: waitress\n{\n    \"data\": {\n        \"author\": {\n            \"familyName\": \"Doe\", \n            \"givenName\": \"John\"\n        }, \n        \"content\": \"This will be unchanged\", \n        \"id\": \"r1\", \n        \"last_modified\": 1476201173217, \n        \"phoneNumber\": \"+01-123-456-7890\", \n        \"tags\": [\n            \"example\", \n            \"sample\"\n        ], \n        \"title\": \"Goodbye!\"\n    }, \n    \"permissions\": {\n        \"write\": [\n            \"basicauth:b4a6199b0cbf1363ef8e60c1c26e0358f49f5698c6bb4cb879437732768fcc94\"\n        ]\n    }\n}\n$ echo '{\"data\":{ \"title\": \"Hello!\", \"phoneNumber\": \"+01-123-456-7890\", \"author\": { \"familyName\": null }, \"tags\": [ \"example\" ] }}' | \\\nhttp PATCH http://localhost:8888/v1/buckets/default/collections/c0/records/r1 Content-Type:application/merge-patch+json --auth aaa:aaa\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 287\nContent-Type: application/json; charset=UTF-8\nDate: Tue, 11 Oct 2016 15:52:54 GMT\nEtag: \"1476201174716\"\nLast-Modified: Tue, 11 Oct 2016 15:52:54 GMT\nServer: waitress\n{\n    \"data\": {\n        \"author\": {\n            \"givenName\": \"John\"\n        }, \n        \"content\": \"This will be unchanged\", \n        \"id\": \"r1\", \n        \"last_modified\": 1476201174716, \n        \"phoneNumber\": \"+01-123-456-7890\", \n        \"tags\": [\n            \"example\"\n        ], \n        \"title\": \"Hello!\"\n    }, \n    \"permissions\": {\n        \"write\": [\n            \"basicauth:b4a6199b0cbf1363ef8e60c1c26e0358f49f5698c6bb4cb879437732768fcc94\"\n        ]\n    }\n}\n```\n. So, here goes a second sketch, using jsonpatch module.\nMy main concern is how to treat permissions. Since there is no support to sets on JSON Object notation. I've choose to treat them as dicts. Permission operations would look like:\n- {\"op\": \"add\", \"path\": \"/permissions/read/alice\", \"value\": \"\"}\n- {\"op\": \"add\", \"path\": \"/permissions/read/alice\"} (I've also add the option to omit value on this case).\n- {\"op\": \"remove\", \"path\": \"/permissions/read/alice\"}\nAnother approach would be to treat permissions as lists, but the remove option would need to be specified as a numeric value, which I think is not consistent with the use case presented.\nI've also wasn't able to remove the read dependency on __permissions__, but permissions are only updated on SharableResource.process_record().\nResponse behaviour is not working as well, I'm not sure how to address this though. \nWe have a much smaller diff now! :)\n. I'm having some problems after merging #790. Do you have any idea what's causing this?\n```\n$ echo '[{\"op\": \"add\", \"path\": \"/data/aaa\", \"value\": \"aaa\"}]' | http PATCH localhost:8888/v1/buckets/b1/collections/c1/records/r1 Content-Type:application/json-patch+json\nHTTP/1.1 400 Bad Request\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 403\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 24 Oct 2016 13:50:37 GMT\nServer: waitress\n{\n    \"code\": 400, \n    \"details\": [\n        {\n            \"description\": \"\\\"[{\\\"op\\\": \\\"add\\\", \\\"path\\\": \\\"/data/aaa\\\", \\\"value\\\": \\\"aaa\\\"}]\\n\\\" is not a mapping type: Does not implement dict-like functionality.\", \n            \"location\": \"body\", \n            \"name\": \"\"\n        }\n    ], \n    \"errno\": 107, \n    \"error\": \"Invalid parameters\", \n    \"message\": \"\\\"[{\\\"op\\\": \\\"add\\\", \\\"path\\\": \\\"/data/aaa\\\", \\\"value\\\": \\\"aaa\\\"}]\\n\\\" is not a mapping type: Does not implement dict-like functionality.\"\n}\n```\n. Great! Please let me know if you need anything else.\n. I would like to work on this one. \nShould the list include the user id or the  system.Authenticated and system.Everyone default principals?\n. The error response is matching 403\n```\n$ echo '{}' | http PUT localhost:8888/v1/buckets/b1 --auth aaa:aaa\nHTTP/1.1 403 Forbidden\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 95\nContent-Type: application/json; charset=UTF-8\nDate: Fri, 11 Nov 2016 00:51:39 GMT\nServer: waitress\n{\n    \"code\": 403,\n    \"errno\": 121,\n    \"error\": \"Forbidden\",\n    \"message\": \"This user cannot access this resource.\"\n}\n```\n. That's is indeed true for buckets (I'm sorry, at first glance I didn't got that) or objects inside non-existing or inaccessible buckets, but not for collections and records on an existing and accessible bucket.\nSome examples:\nDELETE on non-existing bucket\n```\n$ http DELETE localhost:8888/v1/buckets/blah --auth aaa:aaa\nHTTP/1.1 403 Forbidden\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 95\nContent-Type: application/json; charset=UTF-8\nDate: Sat, 12 Nov 2016 00:48:29 GMT\nServer: waitress\n{\n    \"code\": 403,\n    \"errno\": 121,\n    \"error\": \"Forbidden\",\n    \"message\": \"This user cannot access this resource.\"\n}\n```\nDELETE on a collection inside a non-existing bucket\n```\n$ http DELETE localhost:8888/v1/buckets/blah/collections/bleh --auth aaa:aaa\nHTTP/1.1 403 Forbidden\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 95\nContent-Type: application/json; charset=UTF-8\nDate: Sat, 12 Nov 2016 00:48:50 GMT\nServer: waitress\n{\n    \"code\": 403,\n    \"errno\": 121,\n    \"error\": \"Forbidden\",\n    \"message\": \"This user cannot access this resource.\"\n}\n```\nDELETE on a non-existing collection inside an existing bucket\n```\n$ http DELETE localhost:8888/v1/buckets/bbb/collections/c --auth aaa:aaa\nHTTP/1.1 404 Not Found\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 94\nContent-Type: application/json; charset=UTF-8\nDate: Sat, 12 Nov 2016 00:51:17 GMT\nServer: waitress\n{\n    \"code\": 404,\n    \"details\": {\n        \"id\": \"c\",\n        \"resource_name\": \"collection\"\n    },\n    \"errno\": 110,\n    \"error\": \"Not Found\"\n}\n```\nAlso, I've mentioned DELETE first, but the same applies for PATCH.\nPATCH on non-existing bucket\n```\n$ http PATCH localhost:8888/v1/buckets/blah --auth aaa:aaa\nHTTP/1.1 403 Forbidden\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 95\nContent-Type: application/json; charset=UTF-8\nDate: Sat, 12 Nov 2016 00:54:16 GMT\nServer: waitress\n{\n    \"code\": 403,\n    \"errno\": 121,\n    \"error\": \"Forbidden\",\n    \"message\": \"This user cannot access this resource.\"\n}\n```\nPATCH on a collection inside a non-existing bucket\n```\n$ http PATCH localhost:8888/v1/buckets/blah/collections/bleh --auth aaa:aaa\nHTTP/1.1 403 Forbidden\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 95\nContent-Type: application/json; charset=UTF-8\nDate: Sat, 12 Nov 2016 00:54:27 GMT\nServer: waitress\n{\n    \"code\": 403,\n    \"errno\": 121,\n    \"error\": \"Forbidden\",\n    \"message\": \"This user cannot access this resource.\"\n}\n```\nPATCH on a non-existing collection inside an existing bucket\n```\n$ http PATCH localhost:8888/v1/buckets/bbb/collections/c --auth aaa:aaa\nHTTP/1.1 404 Not Found\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 94\nContent-Type: application/json; charset=UTF-8\nDate: Sat, 12 Nov 2016 00:54:35 GMT\nServer: waitress\n{\n    \"code\": 404,\n    \"details\": {\n        \"id\": \"c\",\n        \"resource_name\": \"collection\"\n    },\n    \"errno\": 110,\n    \"error\": \"Not Found\"\n}\n``\n. I'm not sure this is expected in the permissions scope, but if it is, I think we should document the different behaviour forbucket,collectionandrecordobjects separately (which means splitting the_status*.rstfiles), or at least mention404, What do you think?\n. @Natim, got it! So i think that clarifies a bit the behaviour fordeleteandpatch. What do you think?\n. One more thing, the user is expected to havewritepermissions on the parent to get a404instead of403? Wouldn'tread` be enough to prevent leaking information?\n```\n$ echo '{\"permissions\": {\"read\": [\"system.Everyone\"] }}' | http PUT localhost:8888/v1/buckets/b1 -a aaa:aaa\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 221\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 14 Nov 2016 18:22:19 GMT\nEtag: \"1479147739801\"\nLast-Modified: Mon, 14 Nov 2016 18:22:19 GMT\nServer: waitress\n{\n    \"data\": {\n        \"id\": \"b1\",\n        \"last_modified\": 1479147739801\n    },\n    \"permissions\": {\n        \"collection:create\": [],\n        \"group:create\": [],\n        \"read\": [\n            \"system.Everyone\"\n        ],\n        \"write\": [\n            \"basicauth:e786965bf09bdbdff1c9dcb892354d6200439ae98c045515225740ff7709ebef\"\n        ]\n    }\n}\n$ http PATCH localhost:8888/v1/buckets/b1/collections/c2 -a aaa:aaa\nHTTP/1.1 404 Not Found\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 95\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 14 Nov 2016 18:22:37 GMT\nServer: waitress\n{\n    \"code\": 404,\n    \"details\": {\n        \"id\": \"c2\",\n        \"resource_name\": \"collection\"\n    },\n    \"errno\": 110,\n    \"error\": \"Not Found\"\n}\n$ http PATCH localhost:8888/v1/buckets/b1/collections/c2 -a bbb:bbb\nHTTP/1.1 403 Forbidden\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 95\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 14 Nov 2016 18:22:49 GMT\nServer: waitress\n{\n    \"code\": 403,\n    \"errno\": 121,\n    \"error\": \"Forbidden\",\n    \"message\": \"This user cannot access this resource.\"\n}\n$ http DELETE localhost:8888/v1/buckets/b1/collections/c2 -a aaa:aaa\nHTTP/1.1 404 Not Found\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 95\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 14 Nov 2016 18:23:10 GMT\nServer: waitress\n{\n    \"code\": 404,\n    \"details\": {\n        \"id\": \"c2\",\n        \"resource_name\": \"collection\"\n    },\n    \"errno\": 110,\n    \"error\": \"Not Found\"\n}\n$ http DELETE localhost:8888/v1/buckets/b1/collections/c2 -a bbb:bbb\nHTTP/1.1 403 Forbidden\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 95\nContent-Type: application/json; charset=UTF-8\nDate: Mon, 14 Nov 2016 18:23:19 GMT\nServer: waitress\n{\n    \"code\": 403,\n    \"errno\": 121,\n    \"error\": \"Forbidden\",\n    \"message\": \"This user cannot access this resource.\"\n}\n```\n. > Yes I guess the read permission on the parent should be enough to have a 404.\n@Natim, should we open an issue for that? Right now write is required(as on the example above).\n. From what I've worked with this plugin, I couldn't understand why we need the ${resource_name}_id fields. Couldn't we just use only uri all the times? . @delijati, thank you for the feedback!\n1) When you say validation you're talking about validating every request/response against the spec or validating the spec itself? Unfortunately, from what I've tested, pyramid swagger request/response validation isn't suitable for all use cases (ex: extra parameters with any type on an object body). I've just performed validation during tests using bravado_core (which is pyramid swagger validation core). I'm also not sure about adding another validation layer. If you say about validating the spec itself, why not use bravado_core instead of flex or pyramid_swagger?\n2) I'm not sure using cornice.ext.swagger is feasible, but I think it might add considerable complexity to the API code, which was something I want to avoid.\nAbout YAML instead of JSON, I agree. It is listed as pending.. @delijati i've used validation of requests/responses just on tests. I think using it in production doesn't make much sense (as we already validate them using colander). The idea is only to ensure that the spec is correct, not use it for validation.\n. @delijati I've tried the plugin, but got a 500 on GET   /v1/swagger_json. Do you have a branch where you've been testing this? It would be easier to reproduce on my side.\nHere's the traceback:\n2016-12-10 11:00:06,578 ERROR [kinto.core.views.errors][waitress] \"GET   /v1/swagger_json\" ? (? ms) unbound method get() must be called with BatchRequest instance as first argument (got str instance instead) agent=HTTPie/0.9.4 authn_type=None errno=None exception=Traceback (most recent call last):\n  File \"/home/gabi/kinto/.venv/lib/python2.7/site-packages/pyramid/tweens.py\", line 22, in excview_tween\n    response = handler(request)\n  File \"/home/gabi/kinto/.venv/lib/python2.7/site-packages/pyramid_tm/__init__.py\", line 119, in tm_tween\n    reraise(*exc_info)\n  File \"/home/gabi/kinto/.venv/lib/python2.7/site-packages/pyramid_tm/__init__.py\", line 98, in tm_tween\n    response = handler(request)\n  File \"/home/gabi/kinto/.venv/lib/python2.7/site-packages/pyramid/router.py\", line 158, in handle_request\n    view_name\n  File \"/home/gabi/kinto/.venv/lib/python2.7/site-packages/pyramid/view.py\", line 547, in _call_view\n    response = view_callable(context, request)\n  File \"/home/gabi/kinto/.venv/lib/python2.7/site-packages/pyramid/viewderivers.py\", line 442, in rendered_view\n    result = view(context, request)\n  File \"/home/gabi/kinto/.venv/lib/python2.7/site-packages/pyramid/viewderivers.py\", line 147, in _requestonly_view\n    response = view(request)\n  File \"/home/gabi/kinto/.venv/lib/python2.7/site-packages/kinto_swagger/__init__.py\", line 20, in swagger_json\n    base_path=base_path, head=False)\n  File \"/home/gabi/kinto/.venv/lib/python2.7/site-packages/cornice_swagger/swagger.py\", line 174, in generate_swagger_spec\n    parameters, definition = schema_to_parameters(schema, service)\n  File \"/home/gabi/kinto/.venv/lib/python2.7/site-packages/cornice_swagger/swagger.py\", line 22, in schema_to_parameters\n    location_schema = schema.get(location)\nTypeError: unbound method get() must be called with BatchRequest instance as first argument (got str instance instead) lang=None uid=None. Upgrading cornice_swagger did the work.\nThis looks great. Thank you for taking the time to do it. Skimming through the docs I've got a few questions while following this approach:\n\nHow should responses be documented?\nPatch requests should have a body, but that doesn't show on the documentation\nHow to document query strings?\nDoes it allows customizing the tags? I think putting all the operations under the tag buckets may be confusing, specially when using client generators.\nHow to set up authentication?\n\nFinally it doesn't seems to generate valid swagger, but I understand it's just a sketch.. @delijati, great! We may wait for @glasserc, @Natim and @leplatrem to discuss this,but for now my impressions are:\n\n\nI think documenting responses with docstrings might be too much information on them. I think we should find a better option.\n\nI'm not sure about that, it would need proper investigation.\nThe problem is that as far as I know the querystrings are not validated with cornice schemas, but on kinto.core.resource.\nGreat.\nI mean securityDefinitions and /path/{path}/{method}/security fields on the swagger document.\n. > I would strongly suggested to keep it in the same repo. Especially because the spec must evolve very closely with the code. And the tests should break if the spec does not match the resulting API (and vice-versa :)). It could be built-in plugin but what are the arguments in favor of running the API without it?\n\nI agree on keeping it in the same repo and I can't think of an use case were someone would like to get it disabled. On the current implementation if someone really wants to do it, deleting the .yaml file or removing it with pkg_resources (in case of someone using the package) would do the work. I guess it's more a matter of style than usability. Also, should we show it as a capability?\n\nGenerating would be the goal of cornice_swagger I guess. The view itself does not contain anything specific to kinto. The .yml file does. So it's basically like GET /version. A project made with kinto.core can provide a swagger definition and the view serves it. So I don't have any objection with having it in kinto.core, but it may require extra efforts to have a clean separation with regards to testing (or maybe not you already did everything the right way)\n\nKeeping the spec as is I think we could just move test_view_swagger.py to kinto.core and keep tests_swagger on the root of the tests. Also, imaging an use case like this we could also split the current spec into kinto.core and kinto specs and merge them during generation. What do you think?\n\nI don't remember its name, but there's a Pyramid project that makes sure your requests/responses match the specifications you expose. That's something we could investigate to make sure our spec remains up-to-date with the code.\n\nThe one I'm aware of is pyramid_swagger. Unfortunately it's not suitable for some use cases because of limitations on the spec. There's no way to define a schema with additional attributes without a fixed type, which means requests/responses of objects with additional attributes may fail. As I as commenting with @glasserc on our meeting today, we are testing some limits of the OpenAPI documentation. There are also some dubious definitions on the spec that fail bravado_core validation but work with documentation and code generation resources, which means I.M.O we can't trust bravado_core validation as our only source of truth.\nFootnote: pyramid_swagger uses bravado_core for validation. > I don't really understand why turning additionalProperties from {\"description\": \"blah\"} to {} fixes anything.\nIn terms of logic that's super weird, but following the traceback for the error, unmarshal_model, has a special case for empty objects, which skips unmarshal_object, that explicitly checks for type. So there's a indeed a special case to handle empty objects. We may call it a bug on bravado, but at this point I don't really know where the bug is... \u00af\\(\u30c4)/\u00af\n```\n/home/travis/build/gabisurita/kinto/.tox/py34/lib/python3.4/site-packages/bravado_core/unmarshal.py:173: in unmarshal_model\nmodel_as_dict = unmarshal_object(swagger_spec, model_spec, model_value)\n\n/home/travis/build/gabisurita/kinto/.tox/py34/lib/python3.4/site-packages/bravado_core/unmarshal.py:133: in unmarshal_object\nresult[k] = unmarshal_schema_object(swagger_spec, prop_spec, v)\n\n/home/travis/build/gabisurita/kinto/.tox/py34/lib/python3.4/site-packages/bravado_core/unmarshal.py:54: in unmarshal_schema_object\n))))\nE           bravado_core.exception.SwaggerMappingError: The following schema object is missing a type field: {'description': 'Any extra field that applies.'}\n```. > There's one little detail that we discussed recently: the URL /swagger.json. We don't have this .json suffix in any of the other endpoints, and since the spec is evolving to Open API, maybe we should not insist too much on the former name swagger.\nI agree. According to spec, there's still a convention in using swagger.json to refer to OpenAPI description files, but it doesn't say anything about resource paths.. Yes. It is.\nI guess it's because the record tests in the core scope override the validated field, thus skipping deserialization and validation.\nhttps://github.com/Kinto/kinto/blob/master/tests/core/resource/test_record.py\n. The same happens for Last-Modified.. @glasserc \nWhat happens is that the default cornice validator doesn't understand (and thus don't deserialize variations of JSON). This may be a cornice/colander issue, but I'm not sure if it really is, or how to address it there.\nI agree about using a list instead of regular expressions. Notice that we already check for acceptable content-types at viewset.py, so we shouldn't expect nothing there that isn't Merge-Patch, Json-Patch or regular Json. Actually in this solution we don't need validation at all, we just need to cast the Content-Type for validation and store the previous one in an attribute such as the patch method can know it is a merge request.\nhttps://github.com/gabisurita/kinto/blob/25a67356dd6088912a1c3001c0526e2ee04a85e9/kinto/core/resource/viewset.py#L12. So I suggest dropping the patch here (keeping the tests) and fixing it on cornice. We can merge the tests after this has been fixed on cornice.\n@leplatrem Do you think we should keep using regular expressions? There are several types that match +json that i think could be supported.. Thank you @leplatrem ! :). @leplatrem Yes, I think so. It should return the number of buckets that would be deleted without pagination.. Weeeeeeeee   \ud83d\udcaf0. Maybe we could send just a warning. Can we use the Alert header for this?. Note: I'm probably going to address #880 on this PR as well.. > So what's the rationale for fixing the JSON thing in this PR?\nGetting JSON Patch requests to be validated by cornice. We need this because now we are using colander for validating and deserializing other aspects of the request that are also needed on JSON Patch (sync headers, etc). Right now we only trust the external library for validation and ignore cornice validation for this content-type. https://github.com/Kinto/kinto/blob/master/kinto/core/resource/init.py#L101\nThe problem is that I just discovered colander doesn't accept JSON Arrays at the top level, so this may be a bit more tricky than it seems. https://github.com/Cornices/cornice/issues/433. > It may deserve a mention as an internal change?\nI didn't think it was necessary, but when it comes logging more is usually better than less. :P. One of the load tests are failing, but I guess this is probably not related to this change (it was passing before I changed the changelog). Do you have any idea why?. Downgrading fixed loadtests but now pypy is failing. \ud83d\ude1e . > The ResourceResponses thing seems a little complicated.. I guess this is to simplify shared error responses? It feels like it's tied too tightly to the different views we support.\nHmm, these are actually all the responses for the Resource class, and we are actually changing the record schemas (e.g allowed permissions) for each view during initialization here. \nChanging the error responses is not something we would probably do in the server repository, because all storage views have the exactly same error messages. We did the same with the handwritten spec. But there may be some extensions that would like to change it. I just realized we can make responses a Resource attribute rather than a ViewSet attribute, than we could just change the responses messages by setting response_schemas on each Resource derived class.. > So I would say that we should try to do that as much as we can, and fall back to putting things in schemas if we have to. At first I thought you put things in schemas to re-use them, but I see that e.g. CollectionRequestSchema is only used once?\nCollectionRequestSchema is used only on resources, and that's why it's on kinto.core.resource.schema. Any and QueryField are reused, and that's why they are on kinto.core.schema. What I did was to move some non resource specific schemas from kinto.core.resource.schema to kinto.core.schema. IMO CollectionRequestSchema should remain in kinto.core.resource.schema.. Closed in favor of #1078. No, we don't have them anymore.. Sorry, package refers to this repository. \nI've couldn't reproduce the warning here. Can you paste your log?. I've got it. It was included by the reference to kinto.core.resource.schema. Nice catch! :) \nWhat about the rest of the changes? Are they needed? I noticed there are some commented lines and changes in the order. There are some indentation problems on some lines too. Can you fix that? . > Actually I copied the rest of the changes from the #961. Okay I ll fix the indentation. May I know how to reference the new commit on this PR?\nYou already did it. You just need to push it to your branch. :)\nType is still commented. Can you fix that too?. Thank you @sunakshi96! Is you name already on the CONTRIBUTORS.rst file? If not, can you add it please?. > The class declarations seem a bit verbose but I don't have any alternative proposition. Except maybe have some kind of helper\nAn interesting approach for that would be to set the header, query and body on when instantiating a request (setting them on the init method). e.g:\npython\n request_schema = RequestSchema(header=HeaderSchema(), querystring=QuerySchema())\nBut we still would have to do a bunch of imports. But I'm also not sure about that. I tend to think it's probably better to make this explicit.. Also, do we have to keep SimpleSchema, PartialSchema and StrictSchema on the viewset?. @leplatrem, I tried this different approach using schema binding, I think it makes the viewset a bit simpler, what do you think? . > I just don't know if bind() was made for such a use case. Maybe we can ask somewhere?\nI've asked #pyramid channel on IRC and they said that it was, and that there should be an easier way to do it. I've submitted a patch to colander which should be on the next release. https://github.com/Pylons/colander/pull/280. I'm Just curious... Has anyone tried kinto with pypy3?. @Natim Hmm. I don't get it. Why If-Match:* is invalid? It's just a convention used in Kinto? I thought we should accept the valid values for If-Match on RFC 2616.. > but does this change follow the spec then?\nI don't think it does. From my understanding of the following paragraph it just fixes the crash. IMO if we want to follow the spec correctly we should raise 412 on non existing resource, but not only on *, but also on other values of If-Match.\n\nIf none of the entity tags match, or if \"*\" is given and no current entity exists, the server MUST NOT perform the requested method, and MUST return a 412 (Precondition Failed) response.. > That behaviour was never implemented so I guess we can merge this and create a new PR to implement it.\n\nAgree. It would also mean a breaking change on the API.. What about the behavior of If-Match on a numeric value? Should we ignore it when a resource doesn't exists? What does matching on a non-existing resource means?\nI'm not sure how much this would affect the current API, but my feeling is that it should fail on non existing even if the value of If-Match is an ETag.. What about the behavior on plural endpoints? Now we consider If-Match and If-None-Match: * to always succeed on collection gets and deletes. Should we keep this behavior or validate on ALL or ANY clauses?. What is considered a valid id?. Final r? @Natim @leplatrem . First I think it should be. Actually I was trying to make it be part of the schemas for #1077, but the main problem  for this is that the id_generator can be defined at any Resource subclass or at the configuration file, so we can't know at the ViewSet what the id pattern is. One idea I had was to bind the id_generator to the schemas at the register_resource method. . Currently only the resource id is validated by the Resource class https://github.com/Kinto/kinto/blob/master/kinto/core/resource/init.py#L784. I've found the changes here: \nhttps://github.com/mozilla-services/cliquet/commit/6e23e82997d11ab2cad1481553e195f533259f36\nAnd the motivation here:\nhttps://github.com/mozilla-services/readinglist/issues/170\nI agree with removing last_modified from schema as the original issue suggests, but I don't get why id was removed as well. Do you have a clue?. > Currently what happens when last_modified is specified with \"abc\" ?\nNothing. It's just ignored. To be honest I thought this was a feature because there are tests that check if last_modified is properly ignored. I think ids should be in the schema, but I don't have an strong opinion about last_modified. As the issue said, we will set it as a default timestamp anyways.. https://github.com/Pylons/pyramid/blob/master/HISTORY.txt#L45. > Gabi, could you give us a summary about the current state of this PR so that we can go forward please? Thanks!\nThe current status is: the validation works as is but the main problem at the moment is that we fetch the model before validation so we need an auxiliary method to validate the path prior to regular validation. \nI've tried some approaches to make the model lazy (e.g. make it an attribute decorated method), but it looks like it still gets fetched when we access request or context (I don't remember each). This would need some deeper investigation. I still want to fix this at some point, but fell free to finish this earlier if you need it. :). I remember fixing this. https://github.com/Kinto/kinto/commit/c6a8606c6bee58c29246c7e0a63ae89cb028fedd\nI guess it's right on the current master. See https://github.com/Kinto/kinto/blob/master/docs/conf.py#L142. >Then I don't understand this diff... \nMy neither, but I want to merge it just to see what happens.... > I am favor in favor or fixing the ETag comparison too. Let's gather opinions...\nSo let's do it them. If we want to match the spec strong comparison requirements and also keep the current behavior, we could allow specifying week entities as the spec suggests. But in case we don't need it, lets just keep it simple.\nhttps://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html#sec13.3.3. From the API perceptive, I like the idea of making it a filter (e.g. records/id?_at=<last_modified>), but I'm not sure if this is feasible in a plugin (it actually is, but I think it will be ugly) and I also don't think this should be part of the core.\nI think a new view is the easiest approach if we are doing it on the server and want to keep it as a plugin.. > Edit: well, not so intuitive if you consider mixing qs params like _at=123&_before=123 or silly crap like that. Oh well.\nIf _at is just for records you can't mix it with _before, so I guess it still intuitive. . > I assigned you as a way to ping, nothing else ;)\nOK. I'm just having some fun here. haha. > Test are broken because of some swagger specification issue. @gabisurita can you help me out there?\nYeah. Cornice swagger doesn't support the *subpath notation (I didn't know cornice supported it as well). I can try to find a fix for this or we can just leave it out the documentation for now.\nEdit: let me see if I got it right, we are enabling this view for anything under /buckets? Even if we enable plugins? That's pretty scary. . The current master has already been fixed by https://github.com/Kinto/kinto/pull/1078, but it's still unreleased yet. The problem is related with using Json pointers on the response headers. Which pass the editor validator but fail at swagger.io. Closed by #1108 . Yeah. I've tested the deployed version (5.3.2) and it looks fine. I think this might be a broken plugin that's making the whole server fail.. I can't reproduce it anymore.\n@Natim how did you do it?. I can reproduce with @Natim token. WTF?!. Now that we are here I think we have a few problems with the current way we handle preconditions and tombstones:\n\nWe use deleted for precondition checks, but if a record exists we can change the deleted field to true and it will behave as a deleted record.\nBefore #1102 we used to allow checking tombstones with If-Match checks but we also allowed creation with If-None-Match: *. Now tombstones behave like non-existing records. In my opinion tombstones should always have the same behavior of records for precondition checks. . >What makes you say that? I don't think this is accurate.\n\nTake a look at this example, the second query should have failed, but precondition checks look directly for a deleted field.\n```json\ngsurita-30820:kinto gsurita$ echo '{\"data\": {\"deleted\": true}}' | http PUT localhost:8888/v1/buckets/b If-None-Match:* -a a:a\n{\n    \"data\": {\n        \"deleted\": true,\n        \"id\": \"b\",\n        \"last_modified\": 1488202807022\n    },\n    \"permissions\": {\n        \"write\": [\n            \"basicauth:007f513f3cb1622ac923571e17ea0b4512f41d62c51092acec6e2666e6f5d65b\"\n        ]\n    }\n}\ngsurita-30820:kinto gsurita$ echo '{\"data\": {\"deleted\": true}}' | http PUT localhost:8888/v1/buckets/b If-None-Match:* -a a:a\n{\n    \"data\": {\n        \"deleted\": true,\n        \"id\": \"b\",\n        \"last_modified\": 1488202809191\n    },\n    \"permissions\": {\n        \"write\": [\n            \"basicauth:007f513f3cb1622ac923571e17ea0b4512f41d62c51092acec6e2666e6f5d65b\"\n        ]\n    }\n}\n```. > Actually tombstones should works as non existing record, the record has been deleted so it doesn't exists anymore. The tombstones is just an indication that the record once existed but if you create it again it is a totally brand new record.\nActually thinking through it with the changes made on #1102 I agree with that. We can follow this approach and simplify a bit some parts of the code.\nMy main concern for this was what happens if:\n1. At timestamp 1, user A creates a record R.\n2. At timestamp 2, user B fetches and deletes the record R.\n3. At timestamp 3, user A uses put again over the record record R If-Match: \"1\".\nFrom my understanding the expected messages should be.\n1. Create\n2. Delete\n3. Precondition failed \nBoth before and after #1102 we would get the same messages, but from different sources. Before we would raise because we checked tombstones for If-Match, now it will raise because If-Match will always fail on non-existing records.. Should we wait for #1095?. I think we should probably fix the make serve recipe before releasing. I know it's more important for development but I think it's bad to make a release without it working.. Time is not the only issue but specially memory. Pytest design doesn't free the memory from a test after it's completed which can make travis go on swap. That's why the tests were erroring in #1138.\nI had similar issues and discussed this with @glasserc on #977. This should have been partially fixed on https://github.com/pytest-dev/pytest/pull/2046, but apparently they only freed pytest own objects and left test specific objects.\nSome cross referencing:\nhttps://github.com/pytest-dev/pytest/issues/1649\nhttps://github.com/pytest-dev/pytest/pull/2046\nhttp://stackoverflow.com/questions/20900380/py-test-excessive-memory-usage-with-large-number-of-tests. Side note: if we are moving __flush__ maybe it also makes sense to move the permission endpoint. . Related to https://github.com/Kinto/kinto-http.py/issues/115. I don't think this is a problem on kinto-signer itself, but kinto-http that it's used on kinto-sginer testing. This breaks the current release, but it has been fixed on https://github.com/Kinto/kinto-http.py/pull/122 . > So we should release kinto-http.py :)\nWe definitely should. . I don't think total records changing is an issue, as long as the pagination is right. . It should be fixed on kinto>=5.4.1\nhttps://github.com/Kinto/kinto/releases/tag/5.4.1. Ref https://github.com/Kinto/kinto/issues/1106. Just realized basicauth was also enabled. We should maybe clarify in the documentation that's not possible to use both at the same time.\n. > In theory we should be able to use both (I mean for consistency).\nHow would that work? Check if an account exist and use it otherwise generate a basicauth principal? I don't know, this sounds a bit confusing and I can't think of an use case for that besides integration tests on clients. Maybe raising ConfigurationError is an option.\nBut now that we are here, it's probably a good idea to test (and support) integration with portier and other authentication plugins.. Which deploy are you using? The swagger validator seems to pass on the dev server as well as with the 7.0.0dev. Can you give me some details about the deploy you are using? Are there any plugins enabled?\nhttps://online.swagger.io/validator/debug?url=https://kinto.dev.mozaws.net/v1/api\n. The provided Smwogger code example also seems to work with the current master and the dev server. . Is it https://kinto.dev.mozaws.net/ ? It seems to pass swagger validator and I was able to use the smwogger release version with it. Can you confirm the result?\n```python\n\n\n\nimport asyncio\nfrom smwogger import API\nasync def print_operations():\n...     async with API('https://kinto.dev.mozaws.net/v1/api') as api:\n...         print(api.operations)\n... \nloop = asyncio.get_event_loop()\ntry:\n...     loop.run_until_complete(print_operations())\n... finally:\n...     loop.close()\n... \n['heartbeat', 'lbheartbeat', 'version', 'batch', 'contribute', 'create_attachment', 'create_bucket', 'create_collection', 'create_flush', 'create_group', 'create_portier-login', 'create_portier-verify', 'create_record', 'create_stepfunction', 'delete_attachment', 'delete_bucket', 'delete_buckets', 'delete_collection', 'delete_collections', 'delete_group', 'delete_groups', 'delete_history', 'delete_record', 'delete_records', 'get_bucket', 'get_buckets', 'get_changess', 'get_collection', 'get_collections', 'get_fxa-oauth-login', 'get_fxa-oauth-params', 'get_fxa-oauth-token', 'get_group', 'get_groups', 'get_history', 'get_openapi_spec', 'get_permissionss', 'get_record', 'get_records', 'patch_bucket', 'patch_collection', 'patch_group', 'patch_record', 'server_info', 'update_bucket', 'update_collection', 'update_group', 'update_record']\n\n\n\n```. I got it. It's related to the blocklist plugin. I'll investigated it.\nRelated to: https://github.com/Cornices/cornice.ext.swagger/issues/68. You can use kinto attachment, or for small files, you may also base64 encode stuff. What are you trying to store?. @swapnilaga3 Sure! You can pop me (or someone else more involved with the project at the moment) if you need anything. Happy to help :).  Null read permissions is failing colander validation. This is easy to fix if we allow {\"permissions\": {\"read\": null} on PermissionsSchema, but that poses another problem: should we allow permissions to be null on \"regular\" JSON? Which would be the behavior? Do nothing? Or should we add some custom validation to raise an exception?. related to https://github.com/Pylons/colander/issues/299. Hey @leplatrem ! Good to see you! \nI can update the documentation as soon as I have some time or keep the current behavior by not allowing null values using custom validation. What do you think makes more sense? . @glasserc Thanks for the review! I've tried to sketch some minor upgrades on the documentation for this section. What do you think?\n. Flake8 seems to be failing because of this new error \"E722 do not use bare except\". May I just ignore this error and open an issue for it?\n https://travis-ci.org/Kinto/kinto/jobs/297283472. @Natim Sorry, I wasn't clear at this point. We're not leaking raw passwords but since we have a constant key/salt, one can brute force it with a dictionary attack over the hash. The problem isn't about being reversible, but being deterministic. I agree having a rotating secret and wiping out the cache periodically is a nice way to go, but it stills doesn't fix this problem, as an attacker can have access to both the hash and the seed at the same time.\n  . This may help https://github.com/Kinto/kinto-wizard. Hey, looks like the tests are breaking because jsonschema>=3 is yet not supported by bravado_core. I've opened an issue for this matter.\nhttps://github.com/Yelp/bravado-core/issues/303. @peterr101 The issue was already fixed. We probably just need to wait for them to bump a release.\nhttps://github.com/Yelp/bravado-core/pull/304\nMeanwhile, testing with the current bravado_core master may be a good idea just to make sure that everything works well.. Just a small tip: I think you don't need to include pytest here.\nYou can run tests using:\n- pytest tests/path/to/my/test under the virtualenv to run a single test. \n- pytest tests/ under the virtualenv to run all the tests.\n- make tests to run all the tests for all python versions, like travis do.\nHope this helps! :)\n. Oh, I'm really sorry. I didn't get that. :/\nBut why is pytest.raises better than assertRaises?\n. I've tried a few things, but the order of the types differs on the different Python versions and there are 3 or 4 different permutations. we've could list them all (manually or using itertools), but I'm not sure what's uglier. :/\n. The problem with casting as lists is the expected behaviour for lists on jsonpatch. There is no way to remove by value.\nthe easier approach I've found using the jsonpatch package was to cast them as dict.\n. Permissions is not defined on UserResource objects, which are used on tests. I'm not sure if there is a real use case where __permissions__ is not defined, but it does raise exceptions on JsonPatchTests.\n. If I make changes = self.request.json, it becomes a list. I'm not aware if there's a way to update in apply_changes() this way. \n. That's a lot better, but shouldn't we check for read only fields as well? I've moved that part down, is there any problem with that?\n. If it was as list, the operations would look like:\n- {\"op\": \"add\", \"path\": \"permissions/read/0\", \"value\": \"alice\"}\n- {\"op\": \"remove\", \"path\": \"permissions/read/0\"} (which I think is inconsistent with what was presented on the issue)\n. Casting the set as a list makes the package treat it as a JSON array.\nAccording to the RFC specification, to add or remove from an array element, you should specify the array index. Adding can be done using '-' (which corresponds to append), but there's no way to remove an element by it's value.\n. So I can modify changes object on apply_changes, otherwise it will be passed to apply_changes as a list. I've used it to solve the comment:\n\nwhy not do this in the apply_changes() method instead ?\n```\nchanges should be a json object for Response-Behavior processing.\nif content_type == 'application/json-patch+json':\n    changes = updated.copy()\n``\n. Yes. That's correct, and it may be a strange approach, but was the way that I've found to avoid modifyingapply_changessignature, patching arguments early on update, or avoiding updating changes after theapply_changescall. Perhaps we could use a keyword argument to pass something likeoperationsandchanges = {}toapply_changes. It would still be a bidirectional argument, but never on the same call.\n. And where should I include the link?\n. I've added an argument toapply_changesin order to solve the issues related to thechanges` object. Is there a problem with that? \n. By what @leplatrem said, I thought I should include an example like the ones provided for regular patch on api/1.x/records.html. Sorry, my question wasn't clear. So I'll just point to the API docs, is that ok?\n. > I think we should just \"bite the bullet\" and make a breaking change. Have apply_changes take the \"operations\" (I think that's a better name) and have it return (updated, changes).\n\nWe should change the return value only when we have a JSON-Patch, right? Or should we do it also for regular calls? Just to make sure that I've got it right, the approach would be:\n- Keep the signature def apply_changes(self, record, changes)\n- In case of a regular call, return updated\n- If Json Patch, return (updated, changes)\nIs that clear?\n. effective_principals actually omits basicauth prefix. Should the view include basicauth:1234 or just 1234.\n. I just wrapped the Merge Patch tests in a new class, that moved up all the tests that were below. It's really weird on the diff.. Great! Thanks!. At least on the generated Python client, running without this tag implies creating different client instances. e.g\n```python\nimport swagger_client\nbuckets_client = swagger_client.BucketsApi()\ncollections_client = swagger_client.CollectionsApi()\n(...)\nbucket = {...}\nbuckets_client.create_bucket(bucket=bucket) \ncollection = {...}\ncollections_client.create_collection(bucket_id='my_bucket', collection=collection) \n```\nWith it we can do\n```python\nimport swagger_client\nclient = swagger_client.KintoApi()\n(...)\nbucket = {...}\nclient.create_bucket(bucket=bucket) \ncollection = {...}\nclient.create_collection(bucket_id='my_bucket', collection=collection) \n``. I've tried deallocating them in thetearDown()method and leaving it for garbage collecting but it didn't work. Maybe this works different on pytest, but I guess there should be no problems in sharing the spec across the tests. I can't think of a test case we would need to modify these objects.  . Yes, I'm sorry. I should have split this into different commits.. This is the weirdest part, I think. We are forcing pytest to look at the Worker class while running this TestCase. Without it, it would just use the collected version. Which means it doesn't run any test. This is the main motivation to use a metaclass. It took me some time to figure this out. These links may help http://doc.pytest.org/en/latest/example/pythoncollection.html and http://stackoverflow.com/questions/2798956/python-unittest-generate-multiple-tests-programmatically. I will patch this and I think I'll makeself.requestalways a dict. I couldn't understand why, butmarshal_paramexpects the request to be a dict whilevalidate_requestexpects it to be aIncomingRequestobject with attributes matching the fields used onmarshal_paramrequest dict. My guess is thatIncomingRequestwas implemented later to support JSON deserialization onbravadoand they didn't want to change the param handling part of the code. I was usingvalidate_requeston the last version of test resources, but with it we needed to specify where each parameter would go by hand (e.g. body, path, header) now we are using onlymarshal_paramto validate and set the parameters, which actually looks for the param location and set it wherever it should go, raisingValidationErrorif the value doesn't match the spec. . This test case (in comparison to the last one) checks if it's possible to change the default security (which means what the resources require as authentication) by only updating onlysecurityDefinitionson an extension. It matches what happens on [this part](https://github.com/gabisurita/kinto/blob/775b67d6c78ae011286946f53bd99af0602b1e57/kinto/core/views/swagger.py#L67). I didn't test for type in this case because it should be the same fortest_extensions, but I will test forsecurityDefinitionstoo.. It may be unlikely, but I think it possible to have conflicts in plugins. But I think we can drop this keep it as a default, and reintroduce if we need it later. What do you think?. I agree, i've included it there because there's a pretty similar test to checkTotal-Records` on get operations. Maybe we should move both.\nhttps://github.com/gabisurita/kinto/blob/4ba9cb6a5dacc015b39754a4b4f30dc26ec55a5e/tests/core/resource/test_model.py#L11. Yes, we should. This should have raised on tests, but I guess there's another package that imports pyYAML.. Well, I've got why StrictSchema and SimpleSchemawere needed by get_record_schemabut I actually didn't understand why we needed PartialSchema and SimpleSchema on this one, aren't we just setting the request schema here (in contrary to the body schema)? \nAlso, this didn't break any tests and the API behavior looks ok, so I think it's ok to keep the same behavior to both.. I guess handling it on cornice is a good idea. I'm also not sure if it's still needed.. This can definitely be improved but I didn't understand how to use preparer to do it. Thinking through it, maybe defining it as Sequence we can do something as simple as:\n```python\nclass FieldList(colander.SchemaNode):\n    fields = colander.SchemaNode(colander.String(), missing=colander.drop)\ndef deserialize(self, cstruct=colander.null):\n    if isinstance(cstruct, six.string_types):\n        cstruct = cstruct.split(',')\n    return super(FieldList, self).deserialize(cstruct)\n\n``. It does not look very good, but think it's better to handle the filter deserialization here than leave it to theResource._extract_filters` method.\nOpinions?. The problem is that value don't have an specific type, so we can't set it on the schema (or at least I don't know how to do it). Maybe we could check this at deserialize?  . Yeah, that was something I was thinking about earlier... this doesn't apply only for JSON Patch.\nShould we use the same schema for all requests and validate all parameters, even the ones we won't use it, or set individual request schemas for each method with only the expected params? \nI think it's more explicit to have multiple request schemas, and it's better for documentation purposes, but that also means more code to maintain.. Or maybe define a new colander type that deserialize returns ctruct? . That would be cool, but I'm not sure what we can validate here. I know they all have to start with /, but I'm not sure if there's anything else to check here. Maybe if there is anything between two /? IDK. You can probably point to https://kinto.dev.mozaws.net/v1/admin/ instead.. I guess the next sections make more sense if we are developing Kinto Admin. If we are only using the plugin that is shipped with the server, which is already precompiled, I would simply give instructions on how to enable using a config file and a link to kinto admin repository if someone wants to customize or contribute.  . I think kinto-admin isn't that relevant to be in the second position of the documentation. I would probably put in the tutorial section, IDK.. That would be good. I mean, now we are generating it automatically I don't think we should test it this way. We can probably think of something better.. This preserve the error message used previously. e.g:\n\"permissions in body: \\\"foo\\\" is not one of read, write, collection:create, group:create\"\nWithout it we just get an unrecognized fields message. We can set the error massage manually, but then this can override other validation messages.. Yes, we do. I should probably add a test for that too.. With the current implementation it still is, the body field is still added just on the viewset. I've tried to preserve this for backward compatibility, but we can indeed solve this on the schemas.\nEdit: Sorry, I've deleted @leplatrem comment by accident instead of mine, it asked if validate_schema_for was still needed. An interesting approach IMO would be to handle the record_schema binding directly on the schema (instead of the viewset), what do you think?. _fields is not accepted in plural DELETE, so that's why it's not there. I've tried to omit \"General\" and just add the Collection or Record according to each type. Turns out Record was not used. :P. Do you think the verb on the class name should be uppercase as well?. Because they have a default.. This is the return value if we call bind() on a mocked schema. If we want to avoid this, we should also mock patch the bind return value. e.g.\n```python\n\n\n\nm = mock.MagicMock()\nm.method()\n\nAnd a proposed solution:python\nm = mock.MagicMock()\nm.method = lambda: m\nm.method()\n\n``. It failed on the second bind as one call from colander that inserts a node would not accept a mock object, so I've set theResourceSchemamanually. But I'll try to find a better approach.. Yes, we are. It was used to tell if we added a body to the request schema or not, but it doesn't make sense anymore as we split the requests intoRequestSchemaandPayloadRequestSchema`.\n\n\n\nWe could consider this a breaking change because it can be changed from a resource, but I can't see any reason why someone would change this attribute, because probably the requests would fail if it was different.. Anyways, it's not a problem anymore with the new bind implementation.. Hmm, that's interesting. I agree ResourceSchema should be on kinto.core.resource because it's only related to the resource (and I'm keeping it there), but I'm not so sure about other things like Timestamps or Header fields that could be reused in other parts of the core.\nMost of these schemas are imported on kinto.core.resource so they are still accessible. Only Timestamp and URL aren't, and they aren't used anywhere on Kinto. Do you know why we have them there?. > We can deprecated them, no worries.\nOK. I don't have a strong opinion about it. We can keep them too. In case we deprecate or move them, do you think we should add warning messages or we can just make it a breaking change?. About the documentation: I couldn't fond mentions to these schemas anywhere. Also in some parts we use a colander String with url validator to implement an url instead of the URL schema.. I don't see many module-level docstrings on kinto.core (__init__.py is the only exception), that's why I didn't use them, but I agree it would be nice to have this written in the code somewhere.. Yeah, these are unreleased. They probably got there by a problem in some auto merge.. I wouldn't call this record, maybe querystring?. This can sound stupid, but shouldn't we do the same for limit? I don't know how it interacts with the postgresql back-end, but it sounds to me that it should be limited.. Also, with the current implementation we also accept negative values, which can overflow as well. . In other parts of code we used lowercase for validators, but anything is fine, i guess.. The tests are probably failing because Python3 implement default float casting on division. Try 2**64 // 2 or 2**32. Is a shallow copy here enough? Maybe it's a good idea to note with XXX that this is a bug on pyramid.. This is never supposed to happen. The method that is passed to the default_security is actually fetched the same way that is done here (by inspecting service definitions), but the interface for default_xxx calls on cornice swagger is designed to take only service as a parameters (so we can have the same interface for all defaults), but we can change the api to take a method definition as an optional argument.. Tags could be defined on the service, but cornice swagger doesn't support it yet (There's an issue for that https://github.com/Cornices/cornice.ext.swagger/issues/61). Operation ids need to be isolated by method/verb.. Yeah, that's a way to go. My first plan was to set model as a @property, but this lead to several recursions to solve and I just gave up for some time hahaha.. Maybe raise 400?. Shouldn't it be 400 here?. The version here doesn't match the version on the init file (should be 1.16 I guess). Maybe this is stupid, but I think a test to check if we don't overwrite groups on PATCH without groups would be good. I don't remember if we treat this correctly during deserialization.. That's what I've mentioned \ud83d\udc4d . How do we create an admin?. I think it's maybe a bad idea to have includes here again, as it may conflict with the first one.\nEdit: we also do it for fxa so that's probably ok.. Should we allow not providing an account id using the default generator?. What happens if you allow anyone (aka system.Everyone) to create an account? \n```json\ngsurita-30820:~ gsurita$ echo '{\"data\": {\"password\": \"foo\"}}' | http post localhost:8888/v1/accounts \n{\n    \"data\": {\n        \"id\": \"2MKD8dBv\",\n        \"last_modified\": 1490696952189,\n        \"password\": \"$2b$12$Uidm9NDGJU2BZR3NH0zHcuGaF026e97tfqRx5eTnhJt1brLFkBJ5m\"\n    },\n    \"permissions\": {\n        \"write\": [\n            \"account:no_match\"\n        ]\n    }\n}\n``. I'm not sure about 401 here, this can leak information about the account existing. Maybe making it 403?. \ud83d\udc4d . Nit: maybe jump a line here between a code blocks and a comments. I don't like this much because we actually have to create an account, shut down the server, add an account and then start the server back. I would rather have a way to create an admin account during startup, but we can leave this for later.. Actually, this change is meaningful to the fix. Without it a null value on a regular patch would remove permissions as well.. From my understanding what I've described is the implemented behavior. This is what I've tried to explain in the PR by saying \"As a side effect this allows passing null to regular patch operations with no effect\".. I think it would be great to expose the TTL in settings.. One can increase this value to have more cache hits (e.g across periodic requests). Refreshing the TTL at each request would also be a great feature IMO.. I've tried running withsudo: false`, but got that weird bug mentioned on the linked Travis CI issue (https://github.com/travis-ci/travis-ci/issues/9815).  For now this seems to be the only way of using Python 3.7 with Travis.\n```\n3.7 is not installed; attempting download\nDownloading archive: https://s3.amazonaws.com/travis-python-archives/binaries/ubuntu/14.04/x86_64/python-3.7.tar.bz2\n$ curl -sSf -o python-3.7.tar.bz2 ${archive_url}\ncurl: (22) The requested URL returned error: 403 Forbidden\nUnable to download 3.7 archive. The archive may not exist. Please consider a different version.\n```. ",
    "zwhitchcox": "Ah ok, cool, I didn't know about that. And my use case is for a contact form for a marketing website. Ideally, they could automatically have new messages shown and maybe even a live chat. Obviously, you could do that with a long poll, but I thought it might be a little nicer with websockets.\n. I guess I should be more explicit with my websockets request though. So, you could create a hook and add \"listeners\" to the collection. Whenever someone adds a new field, the other party is informed via a websocket.\n. Ok, thanks haha I had no idea.\n. Yeah, that's really cool. I can't wait to use these services. And maybe start creating some of my own if there's on I need and isn't available! Thanks\n. Also, not trying to nitpick or anything, but I read through the whole documentation, and I didn't see anything about that. So, maybe, if it is in there make it a little more prominent? Not complaining at all! Just thought you might want to hear the suggestion.\n. ",
    "johngian": "Fixes #309 \n. @leplatrem HTTP_API_VERSION is already 1.2. Should I just add the changes to the changelog under v1.2?\n. @almet No use case for now :) I just like the idea.\nI have tried some other alternatives but they felt way more complicated for my needs. Kinto has a much more lightweight approach. Plus, I like the stack.\n. @leplatrem PR updated\n. That was my initial take (following cliquet.events paradigm) but I wasn't sure if we needed to create that for just one event. I will move the changes to the new module.\n. You mean here to check that id returned is not empty? Next tests checks explicitly the id.\n. ",
    "anyangocynthia": "Thanks \ud83d\ude00\nOn Wednesday, January 6, 2016, R\u00e9my HUBSCHER notifications@github.com\nwrote:\n\nClosed #355 https://github.com/Kinto/kinto/issues/355.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Kinto/kinto/issues/355#event-506853066.\n\n\nKInd Regards,\nCynthia Anyango\n. You can just add it .\nOn Jan 6, 2016 12:37 PM, \"Alexis Metaireau\" notifications@github.com\nwrote:\n\nThat's a good idea! Do you want to work on a pull request or would you\nprefer us to add it?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Kinto/kinto/issues/357#issuecomment-169277246.\n. I managed to trace the error . I run postgres=$(sudo docker run -e POSTGRES_PASSWORD=postgres -d -p 5432:5432 postgres) and then it gave me that error . \np.s I have postgresql installed and docker too\n. Its Great ! Good job !\n. \n",
    "karlht": "I think I may also need access to put labels on issues.  I was trying to label this one \"documentation\" and \"enhancement.\"\n. > how do you know that a lot of users have encountered that problem ? :) I'm curious and wonder why we were not aware of it!\n@anyangocynthia said that was the case; presumably she and a number of colleagues encountered it.\n. The Location: header above should read https://kinto-ota.dev.mozaws.net/v1/__heartbeat__ -- maybe a regex that doesn't match underscores?\n. This looks good to me.  I don't believe I can merge it; I'll leave that to @Natim.\n. ",
    "ipsha21": "Can we add instructions to install python, Postgresql, redis in the getting started section, or just mention the requirements and not the steps to install them?\n. Is this fine?\nhttps://github.com/ipsha21/kinto/wiki/Step-by-step-guide-for-installing-Python\nOn Tue, Apr 19, 2016 at 2:26 PM, R\u00e9my HUBSCHER notifications@github.com\nwrote:\n\n@ipsha21 https://github.com/ipsha21 Can you do what @leplatrem\nhttps://github.com/leplatrem proposed?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/Kinto/kinto/pull/513#issuecomment-211809254\n. Yes, sure. Made a commit.\n\nOn Thu, Apr 21, 2016 at 5:25 PM, R\u00e9my HUBSCHER notifications@github.com\nwrote:\n\nWhy don't you use the apt-get install redis-server python2.7 python2.7-dev\ncommand instead of compiling Python by hand?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/Kinto/kinto/pull/513#issuecomment-212881529\n. \n",
    "msathis": "@Natim \nRight now\nGET https://kinto-ota.dev.mozaws.net/v1/buckets/mybucket --auth=\"test:test\"\nreturns data, permissions. Additionally it can return one more property \"stats\" as well.\nThe properties i would like to see in stats object\n1. collections_count - (Applicable only for buckets)\n2. records_count - Total records. Not sure whether we need it for bucket stats too.\n2. storage_size - In bytes.\n3. last_write or updated_at - timestamp of last write.\n4. last_read - timestamp of last read. (Not sure about this).\n5. created_at - created timestamp.\n. And the data property in the response contains only last_modified property. It can also return created_at timestamp as well. \n. @tarekziade I agree. GET request of /bucket and /bucket/collection should return the stats as well.\n. ",
    "aegaas": "@leplatrem thanks for getting back to me so quickly! I think maybe I incorrectly assumed that the create_group call would figure out the hashes for me. We have a suite of rspec tests that use these basicauth: keys in groups and the same behavior occurs. \nAbove you can see I've updated the test to use the user's id, and the test will still fail with a 403.\nIf I instead use the keys directly in the permissions hash, everything works alright, but that would quickly become unmanageable with a large dataset. I'd very much prefer to use 'group:' definition in record and collection permission objects.\n. Thank you everyone for jumping on this in record time! The test passes, but unfortunately I have a larger test suite that doesn't seem to be taking the changes as well as I hoped. Its likely I need to figure out how to update kinto on my AWS instance to prove this out.\nI'll take some time today to prove this out and perhaps add more test cases to fit what I'm seeing in the real world.\n. I have added a more complex test case that uses 2 users, aaron and kelly. aaron writes a record to a collection and kelly is able to read it!\n. Thanks @Natim this was very helpful. I have updated my local build and will investigate further.\n. Team,\nWhile the test suite is showing all green, which is great, I've been validating against a real kinto instance which is not showing the same results:\nthe gist linked is showing my debug output where I have a system account, create a group, and then create a collection with write permissions. I then attempt to write to the collection but get a 403. What am I doing wrong?\nhttps://gist.github.com/aegaas/c7c145d39fcade50e3ad\n. Yes this is great! Thank you for updating this\n. ",
    "ptgamr": "@leplatrem if I want to implement it the right way, where should I put the file kinto_github.py ? (sorry I'm not so familiar with Python)\n. +1\n. @leplatrem  @Natim\nIf user has record:create permission, should he be able to list all the records that he created under that collection ?\nOtherwise, he can't list his records. If we give him the collection read permission, he will be able to read all records.\n. But how can user get to that record later again if he doesn't have read permission on the collection? \nFor eg: I like to list all my tasks under tasks collection. (tasks collection is created by admin, and authenticated user is granted record:create permission)\n. I think you haven't got my point.\nI'm trying to address what @leplatrem said ealier:\n\nOk I think I get it. When a user has record:create we allow to read the collection metadata but not the list of records. I like it!\n\nI think he should be able to list records, but only his own records.\n. You mean it's already working like that? Ok, let me verify it again ... The last time I tried to list the collection, I'm able to get all records (because I got a 403, then I give user collection read permission)\n. Thanks @leplatrem . I just verified again and it's working as expected now. Sorry I messed up a bit when receiving the 403 code when user haven't create any record. It make me think that I can't list the records if not granted read permission.\nCould we change 403 to 404 code instead? As I think many applications base on 403 to actually handle Authorization error, sometime log the user out.\n. I think it's ok for who got the record:create permission knows that the collection exists?\n. That could be much better!\n. Then I got this: \n*** Starting uWSGI 2.0.12-debian (64bit) on [Fri Sep 16 14:26:49 2016] ***\ncompiled with version: 5.3.1 20160412 on 13 April 2016 08:36:06\nos: Linux-4.4.0-36-generic #55-Ubuntu SMP Thu Aug 11 18:01:55 UTC 2016\nnodename: ptgamr-private\nmachine: x86_64\nclock source: unix\npcre jit disabled\ndetected number of CPU cores: 1\ncurrent working directory: /root/git/kinto\ndetected binary path: /usr/bin/uwsgi-core\nsetgid() to 1000\nsetuid() to 1000\nyour processes number limit is 3912\nyour memory page size is 4096 bytes\ndetected max file descriptor number: 1024\nlock engine: pthread robust mutexes\nthunder lock: disabled (you can enable it with --thunder-lock)\nuwsgi socket 0 bound to UNIX address /var/uwsgi/kinto.sock fd 3\nPython version: 2.7.12 (default, Jul  1 2016, 15:12:24)  [GCC 5.4.0 20160609]\nSet PythonHome to /root/git/kinto/.venv\nImportError: No module named site\n. Nah. Is it a problem because I'm building from source? I can make serve normally\n. Yeap ;) Thanks @Natim \n. ",
    "WilliamHoang": "Hey Alexis,\nThanks for the quick reply.  Let me provide some details below..\nPluggable storage:  This is regarding OAuth by third party providers and\nalso LDAP -\nhttp://blog.couchbase.com/2016/january/how-to-authorize-users-in-sync-gateway\nFine-grain permissions:  This is regarding Channels and Sync-Gateway -\nhttp://blog.couchbase.com/2016/january/using-channels-in-sync-gateway\nLet me know if there are additional questions and I will look at the DIFF [\nhttps://gist.github.com/almet/0b35d03d945dec341079 ]\nThanks,\nWilliam\nWilliam Hoang\n_| *_Twitter http://bit.ly/sweetiewill | LinkedIn\nhttp://bit.ly/myLinkedIN | Schedule Event / Calendar\nhttp://bit.ly/bookwilliam | *\nOn Fri, Jan 29, 2016 at 3:52 PM, Alexis Metaireau notifications@github.com\nwrote:\n\nHi, thanks for taking the time to add these features to the list on our\ndocumentation!\nHere are some general remarks:\nThe tables is malformed and wouldn't render properly. Here's a diff\nhttps://gist.github.com/0b35d03d945dec341079 you can apply locally to\nhave it working properly.\nI tried to read a bit the documentation of couchbase mobile, and it's\nunclear how are provided some of the features you're marking as \"provided\":\n- Pluggable storage / cache: can you point me where I can configure\n  the storage and caching layers to use some different backend that the\n  default one?\n- Fine-grained permissions: same here, I failed to see where\n  fine-grained permissions are provided. Do you have a link to some\n  documentation?\nThanks!\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Kinto/kinto/pull/409#issuecomment-176965041.\n. @almet \n\nCan add a link too for Couchbase Mobile [ http://developer.couchbase.com/mobile/ ] or I'll open another PR \n. Hey Alexis,\nLet me try to get to this ASAP today!\nThanks,\nWilliam\nWilliam Hoang\n_| *_Twitter http://bit.ly/sweetiewill | LinkedIn\nhttp://bit.ly/myLinkedIN | Schedule Event / Calendar\nhttp://bit.ly/bookwilliam | *\nOn Tue, Feb 9, 2016 at 9:50 AM, Alexis Metaireau notifications@github.com\nwrote:\n\n@WilliamHoang https://github.com/WilliamHoang Did you find the time to\nfix the issues I raised here? Otherwise I'll close it for now, and you can\nopen another pull request with the correct explanation. Thanks.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Kinto/kinto/pull/409#issuecomment-181899825.\n. Hey Alexis,\n\nI will make a new one.  Sorry I am dealing with family event and been MIA\nfor the pass 1-2 weeks.\nThanks,\nWilliam\nWilliam Hoang\n_| *_Twitter http://bit.ly/sweetiewill | LinkedIn\nhttp://bit.ly/myLinkedIN | Schedule Event / Calendar\nhttp://bit.ly/bookwilliam | *\nOn Tue, Feb 23, 2016 at 4:42 PM, Alexis Metaireau notifications@github.com\nwrote:\n\nClosed #409 https://github.com/Kinto/kinto/pull/409.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Kinto/kinto/pull/409#event-561308761.\n. \n",
    "ayusharma": "Why do I need a JSON store?\nLanguage Independent : JSON is a language independent data format as Kinto Stores it. JSON can accept undefined data set in document but for pgsql query we need to define it and in pgsql JSON mostly usage for raw or secondary data.\nSecure: All the data is stored in files/documents so users can not temper it.\nSimple: No need of using ugly SQL Queries, Easy to work - no schema, no indexes, no complex sql but Just objects. More Javascript friendly.\nLightweight : Very small NoSQL and Validation engine as comparison to other databases. No databases processing to convert the JSON data into JSONB, BSON etc. to store it. pgsql has defined type of query natural like select * and JSON based on hstore docs or say collection when we are doing get call we need to write query which is not efficient .\nFile/Document Based: No need to run separate server or Backend Server and Databases Server. All data is to be stored in files as JSON Format. Better portability.\nDoes it seem right ? I want to get review before creating a Pull request. \n. Could we also add about kinto admin here , like:\n- Kinto admin allows to perform admin operations very easily.\n. It is great.  Explaining the architecture. :+1: \n. how could I reproduce this ? I tried python3 kinto init and all worked well\n. I want to work on this bug. I am able to reproduce the situation. Looking forward for suggestion to start. \n. I am getting this error on test cases. I am using  make tests .\n. Could I use the same branch to generate new pull request by hard resetting the old commits ?\n. open pgsql \nand change your database encoding:\nupdate pg_database set encoding = pg_char_to_encoding('UTF8') where datname = '<your db name>';\n. How can I reproduce this ? \nLogic of redirection is working right locally \ndef _redirect_to_version_view(request):\n        path = request.matchdict['path']\n        querystring = request.url[(request.url.rindex(request.path) +\n                                   len(request.path)):]\n        redirect = '/%s/%s%s' % (route_prefix, path, querystring)\n        raise HTTPTemporaryRedirect(redirect)\nOn localmachine :\n```\ncurl -i 'http://localhost:8080/heartbeat'\nHTTP/1.1 307 Temporary Redirect\nServer: nginx/1.8.0\nDate: Fri, 19 Feb 2016 05:43:31 GMT\nContent-Type: text/html; charset=UTF-8\nContent-Length: 216\nConnection: keep-alive\nLocation: http://localhost:8080/v1/heartbeat\nAccess-Control-Expose-Headers: Backoff,Retry-After,Alert,Content-Length\n\n\n307 Temporary Redirect\n\n\n307 Temporary Redirect\n  The resource has been moved to /v1/heartbeat; you should be redirected automatically.\n\n\n``\n. Finally I figured out the problem. Nginx configuration forlocation /` should be like this :\n```\nlocation / {\n                return 301 http://localhost:8080/v1$request_uri;\n        }\n```\nTest Case :\n```\ncurl -i http://localhost:8080/heartbeat\nHTTP/1.1 301 Moved Permanently\nServer: nginx/1.8.0\nDate: Sat, 27 Feb 2016 07:53:16 GMT\nContent-Type: text/html\nContent-Length: 184\nConnection: keep-alive\nLocation: http://localhost:8080/v1/heartbeat\n\n301 Moved Permanently\n\n301 Moved Permanently\nnginx/1.8.0\n\n\n``\n. Should we add this to troubleshooting section ? Took me some time to figure out while deploying kinto on nginx. \n. Yes. You are right. But there is no plugin attribute is mentioned in documentation. It is necessary to mentionplugins = pythoninconfig/kinto.ini` file to keep kinto working. So I added it to doc.\n. I got it working. \nIf we define the content_type while registering a service in cornice, the corince would take it as a default validator.  link : http://cornice.readthedocs.org/en/latest/validation.html#content-type-validation\nso I have changed  code in   https://github.com/mozilla-services/cliquet/blob/master/cliquet/resource/init.py#L70-L79\n```\nservice = Service(name, path, depth=depth,content_type=\"application/json\",\n                          **viewset.get_service_arguments())\n```\nand it gives the response on content-type: text/plain as :\n```\n{\"errno\":107,\"message\":\"Content-Type header should be one of ['application\\/json']\",\"code\":400,\"details\":[{\"location\":\"header\",\"name\":\"Content-Type\",\"description\":\"Content-Type header should be one of ['application\\/json']\"}],\"error\":\"Invalid parameters\"}\n```\nI came across this conversation https://github.com/mozilla-services/cornice/pull/192\n. I am woking on this.  Please provide text for the '##' fields. and check other fields too. \nAfter that I will also document the defined functions. \n```\nhelp:\n    @echo \"Please use 'make ' where  is one of\"\n    @echo \"  all                         to install dependencies and prepare production environment\"\n    @echo \"  install                     to install dependencies and prepare production environment\"\n    @echo \"  install-monitoring          to enable monitoring feature using NewRelic\"\n    @echo \"  install-postgres            to install postgresql support\"\n    @echo \"  install-dev                 to install dependencies and prepare development configuration\"\n    @echo \"  virtualenv                  to setup the python virtual environment\"\n    @echo \"  build-requirements          ##\"\n    @echo \"  serve                       to start the kinto server on default port\"\n    @echo \"  migrate                     to run the migrations with kinto migrate\"\n    @echo \"  tests-once                  ##\"\n    @echo \"  flake8                      to run the flake8 linter\"\n    @echo \"  tests                       to run all the test suite\"\n    @echo \"  clean                       to remove .pyc files and pycache directory\"\n    @echo \"  distclean                   to remove .egg-info files and *.egg, build and dist directories\"\n    @echo \"  maintainer-clean            to remove the .tox and the .venv directories\"\n    @echo \"  loadtest-check-tutorial     ##\"\n    @echo \"  loadtest-check-simulation   to run end-to-end tests on Kinto\"\n    @echo \"  docs                        to builds the docs for sphinx\"\n    @echo \"Check the Makefile to know exactly what each target is doing. If you see a \"\n    @echo \"target using something like $$(SETTINGS), you can make it use another value:\"\n    @echo \"  make SETTINGS=settings_mine docs\"\n```\nwhat is the use of $$(SETTINGS) ? \nThanks \n. @magopian It looks great. \n. Pls take a look.. https://public.etherpad-mozilla.org/p/kinto-makefile-documentation . I tried to made description infinitive. \n. ",
    "cbjadwani": "Matrix is not required for other python versions.  This fix was needed for 3.5 to workaround travis-ci/travis-build#4794\n. ",
    "aurelg": "@almet When browsing the documentation without (the possibility to have) a terminal, such links would probably be very useful. Think mobile devices for instance.\n. ",
    "floomy": "My reasoning was handling orphaned data (as administrator) e.g. testing records during development or outdated records from since canceled projects.\nI'd like to clean up records from abandoned users (without keeping track of every single token). I'm not sure if this could be part of the HTTP API.\n. OK, I will then use multiple buckets (instead of multiple users' default bucket) and delete old \"stuff\" with the /buckets endpoint.\nThanks for your help!\n. ",
    "nocturnalwarz": "Sorry I couldn't even figure why it was doing that and not sure how to reproduce it either. It only happened on my ubuntu box.  I have mutliple CentOS boxes it works just fine on setup exactly the same way.\n. ",
    "abdulsattar": "docker run -p 8888:8888 kinto/kinto-server:1.11.2 works though.\n. ",
    "doplumi": "It's happening again\n```\ndocker run -p 8888:8888 kinto/kinto-server\n/bin/sh: 1: kinto: not found\n```\n. So, I got away but setting up a reverse proxy that handles SSL, which was simpler than I thought. I have Kinto on 8888 and the proxy targeting 8888, listening on 8889 and replying with httpS. And it works: Kinto request on 8889 are not blocked from Chrome anymore.\nNow, the problem with this approach is that insecure Kinto at 8888 is still accessible from everybody.\nAre you by any chance aware of any waitress/pserve options I could use to make Kinto from the docker container (8888) only reply to the proxy (8889) and no one else? \n@almet suggested, over at SO, to use kinto.http_host and kinto.http_port options to solve this issue but have no idea how!\n. @leplatrem: Actually no, I didn't quite understand @Natim advice. \nI am still playing with Kinto so all I need for now is it being accessible from HTTPS, but it would be nice and cleaner to have the server be only accessible via HTTPS, especially for production.\nIf anybody has an easier way to set this up please share.\n. ",
    "gEndelf": "I have the same issue:\ndocker run -p 8888:8888 kinto/kinto-server\n/bin/sh: 1: kinto: not found\n. tag by default  - latest\nit's working now, thx!\n. ",
    "chrismbeckett": "Yeah, that's me :)\n------ Original Message ------\nFrom: \"Alexis Metaireau\" notifications@github.com\nTo: \"Kinto/kinto\" kinto@noreply.github.com\nCc: \"Chris Beckett\" chrisb@arsnebula.com\nSent: 2/25/2016 2:18:36 PM\nSubject: [kinto] Add a custom id generator tutorial. (#464)\n\nr? @chrismbeckett\n\nYou can view, comment on, or merge this pull request online at:\n  https://github.com/Kinto/kinto/pull/464\nCommit SummaryAdd a custom id generator tutorial. File \nChangesAdocs/tutorials/custom-id-generator.rst (82) \nMdocs/tutorials/index.rst (1) Patch \nLinks:https://github.com/Kinto/kinto/pull/464.patchhttps://github.com/Kinto/kinto/pull/464.diff\n\u2014\nReply to this email directly or view it on GitHub.\n. Moving the discussion between @Natim and I here, instead of having it over in the Corpix/shortid.\n\nI am not really sure that the merits of ShortID needed to get pulled into this - the example provided here using urandom() is great for an example. I think people would like to use their own ID generation strategies for all sorts of reasons. The main use case would be they want to use a common ID format and strategy between different systems/services. But, since I was originally asking how to integrate ShortID specifically into Kinto in the original IRC chat, I thought I would elaborate on the requirements I personally use regarding ID generation on my own projects, and why I initiated this request in the first place. Here is what I look for:\n1. Polyglot (works in multiple languages, since I may need to use it across different micro-services)\n2. Isomorphic (works across client and server so I can generate my record ID's anywhere)\n3. Crypto-based strategy that reasonably ensures the required degree of nearly-true randomness\n4. URL friendly (works well across HTTP boundaries)\n5. Popular/Proven (leveraging the wisdom of crowds/proven in production to ensure it is sound)\nThe following are a number of strategies that I have found that fit this bill:\n1. UUID - globally unique, proven, but large and less user friendly if you don't need globally unique\nFor strategies that don't require global uniqueness, for collection ID's I have used the following that fit the above requirements:\n1. ObjectID - strategy taken from MongoDB, and now ported widely. Has the benefit of being time ordered.\n2. FirebaseID - url friendly, scalable, works, and has the benefit of supporting both time and lexigraphic ordered). Not widely ported, but isomorphic in JavaScript available on NPM here Firebase-Auto-Ids.\n3. ShortID - growing in popularity, proven, being ported.\nSorry to keep adding here, but is it worth demonstrating (related to the issue of isomorphic/polyglot), an ID strategy that also works with the custom ID generation client-side with Kinto.js Custom ID Generation? It may also be worth adding a hyperlink to the example here demonstrating that custom ID strategies can work across client and server.\nPersonally, I have gone with ShortID since I can easily use it in my own custom auth services (NodeJS/Koa), in Kinto (with Corpix/shortid), and in the browser with Kinto.js, and it doesn't have any dependencies on a specific crypto library.\n. Gratz :) Thank you both for helping me with this. I think this example will be a big help to many people.\n. No, I didn't run migrate. When I tried to run migrate just now, this is what is logged to console, and the flush endpoint still doesn't work?\nchrismbeckett:~/workspace/server (master) $ kinto --ini config/dev.ini migrate\n/usr/local/lib/python2.7/dist-packages/cliquet/storage/postgresql/client.py:86: UserWarning: Reuse existing PostgreSQL connection. Parameters permission_* will be ignored.\n  warnings.warn(msg)\n/usr/local/lib/python2.7/dist-packages/cliquet/storage/postgresql/client.py:86: UserWarning: Reuse existing PostgreSQL connection. Parameters cache_* will be ignored.\n  warnings.warn(msg)\nNo handlers could be found for logger \"venusian\"\nThis is my dev.ini:\n```\nSERVER\n[server:main]\nuse = egg:waitress#main\nhost = 0.0.0.0\nport = 8080\n[app:main]\nuse = egg:kinto\nBACKENDS\nkinto.storage_backend = cliquet.storage.postgresql\nkinto.cache_backend = cliquet.cache.postgresql\nkinto.permission_backend = cliquet.permission.postgresql\nAUTHENTICATION\nkinto.userid_hmac_secret = 681a433b048c8debc07677835b50045142cc18668082e4016fbd262498173842\nmultiauth.policies = jwt\nmultiauth.policy.jwt.use = kinto_jwt.JwtAuthenticationPolicy\nkinto.bucket_create_principals = system.Authenticated\nkinto.bucket_read_principals = system.Authenticated\nFEATURE SETTINGS\nkinto.id_generator = kinto_shortid.ShortIdGenerator\nkinto.experimental_collection_schema_validation = true\nENDPOINTS\nkinto.flush_endpoint_enabled = true\nkinto.collection_bucket_delete_enabled = false\nkinto.collection_collection_delete_enabled = false\nkinto.collection_group_delete_enabled = false\nkinto.collection_record_delete_enabled = false\nLOGGING\nkinto.logging_renderer = cliquet.logs.MozillaHekaRenderer\n[loggers]\nkeys = root\n[handlers]\nkeys = console\n[formatters]\nkeys = heka\n[logger_root]\nlevel = INFO\nhandlers = console\nformatter = heka\n[handler_console]\nclass = StreamHandler\nargs = (sys.stdout,)\nlevel = NOTSET\n[formatter_heka]\nformat = %(message)s\n```\nTo simulate Heroku, I set the storage URL's through environment variables.\n. It works in my Heroku deployment, so I guess I can just reset my database in dev and chalk this up to not performing the correct upgrade procedure.\n. ",
    "woovar": "@Natim @leplatrem That would be great and is much cleaner. I assumed since those lines were in the code, we absolutely wanted backwards compatibility. But if we can get rid of the requirement, it will become much clearer. Just removing the default bucket plugin from the configuration will stop the default bucket behavior. I can write tests for that and remove the appropriate code in init.py in this PR. \n. @leplatrem If you could do that, that would be great. Thanks!\n. ",
    "Sayli-Karnik": "Oh right, I'll make the changes!\n. ",
    "jmandel": "Fundamentally the challenge is that OAuth is designed as an authorization protocol. You can build an authentication protocol on top, but you have to be careful to get the details right (like OIDC). For details see http://oauth.net/articles/authentication/ by @jricher.\n. ",
    "bbangert": "If velruse hasn't needed a commit in three years, then it hasn't gotten one. :)\nNow, there does seem to be 15 PR's, and some issues. We could fix that up fairly easily, merge the ones that work, and get a new release out. If the desire is to support multiple auth's, that'd be far easier than re-implementing velruse.\n. ",
    "coveralls": "\nCoverage remained the same at 100.0% when pulling 2e24bf18ff52c425ffff33ff69b566473225d12b on ipsha21:documentation-issue-358 into 1c7b94c2980c5aba942b60137c8d7a37534c531a on Kinto:master.\n. ",
    "happy-tanuki": "Thank you for your investigation!\n. @leplatrem according to the document, I could use the custom config file in docker-compose.yml. But it seems kinto.event_listeners parameter was not affected. (no messages in logger and the another redis client cannot subscribe.)\n. @leplatrem It's worked! I misunderstood a event-listener behavior which is not PUBLISH but LPUSH.\nAnd by the redis' default, keyspace events notifications are disabled. http://redis.io/topics/notifications Thanks.\n. No problem. I missed the usage of redis listener in the documentation.\n. ",
    "apratti": "This was for a school project. Glad to help.\n. ",
    "TofPlay": "I can not help for Android. I'm just an iOS developer.\nWork on the iOS part could be fun \ud83d\ude00\nBut unfortunately I have not the time for that. I'm already very busy with my job \ud83d\ude13\n. ",
    "sunakshi96": "Hey \nSo the solution is to upgrade pip right? \n. Hey \nI would like to work on this issue :-)\n. Hey \nI want to ask that the third step:\"Link from overview page\" mentioned above ,does it refer to the main KintoAdmin Page \n. hey\nI added the line kinto.plugins.admin in the kinto file but  the link 0.0.0.0:8888/admin is not running.\n. Hey \nI seems like there is a bug,because the link http://0.0.0.0:8888/admin gives an error (code 404).\n. Okay I will do that\n. Hey \nI I have just opened the another issue. And deleted the kinto-admin.rst file \nThanks gabisurita :-). \nI think we can handle the issue 'Document built-in plugin for kinto-admin\" to describe the enabling and features of plugin. \n.....and the  plugin awaits to be rescued  :-). Hii\nOh the changes are made to fix the warning caused by a python class :'Sequence'. May I please know which package are we referring here?. `\nsunakshi@sunakshi-Inspiron-3542:~/kinto$ make docs\n.venv/bin/sphinx-build -a -W -n -b html -d docs/_build/doctrees docs docs/_build/html\nRunning Sphinx v1.5.2\nloading pickled environment... done\nbuilding [mo]: all of 0 po files\nbuilding [html]: all source files\nupdating environment: 0 added, 0 changed, 0 removed\nlooking for now-outdated files... none found\npreparing documents... done\nwriting output... [100%] tutorials/write-plugin                                                                                 \nWarning, treated as error:\n/home/sunakshi/kinto/docs/core/resource.rst:159: WARNING: py:class reference target not found: Sequence\nMakefile:132: recipe for target 'docs' failed\nmake: *** [docs] Error 1\n`. Hey\nThe Sequence is not mentioned in the documentation. Since the warning mentions the target Sequence is not found so I simply added the ('py:class','Sequence') under nitpick_ignore in conf.py file in /kinto/docs/core folder. . Hey\nActually I copied the rest of the changes from the #961. Okay I ll fix the indentation. May I know how to reference the new commit on this PR?. > Type is still commented. Can you fix that too?\nYes I can!. Thank you @gabisurita . ",
    "enkidulan": "@Natim that is a good point, I guess it may have sense to mention both in docs. But keep in mind that\ndnf will replace yum in all RHEL-derivatives eventually as it is a next generation of yum. Fedora uses it as a default package manager at least for 3 last releases, not sure about other distributives. \n. ",
    "zakaluka": "Have any best practices or guidelines been documented anywhere, by chance?. The use case is a fully auditable system where every user's every action (including views) are being logged.  A supervisor/administrator must be able to come in at any time and view all records, including deleted ones (with full history such as values changed, dates of change, etc.).  A GET on a bucket / collection / record, rather than filtering / aggregating history results, seemed to be a much easier option from a end-user perspective.\nI read about the history plugin (just on the website) but wasn't sure whether it would be sufficient for this purpose.\nTwo questions:\n1. I'm not sure what you mean by deleting the encrypted content in an encrypted manner.  Isn't encryption a kinto.js-only concept?\n    Note: I'm not familiar enough with the Kinto-HTTP interface to know if it supports encryption or not.  I'm making an assumption that any web-service type interface relies on SSL for protection (rather than encrypting the data as well).\n\nI assume you are referring to the bucket/collection/record metadata.  If so, I am leaning towards setting a status as deleted in that metadata (rather than actually running a DELETE command against the database).  However, my concern is about what would happen if a DELETE command ended up being sent to the server.  How do I stop it from performing its default action?  That was my main reason for suggesting that 'write' permissions should be split into 'update' and 'delete' as 2 separate permissions.\n\nEDIT: Sorry, but I also didn't fully understand what blocklists are.  Are you referring to browser blocklists (i.e. how it is used on http://docs.kinto-storage.org/en/stable/overview.html)?. @Natim Thank you for all the detailed answers.  They were extremely informative and also helped show how much more I need to learn about Kinto :).  \n\nYou can deactivate some endpoint verbs using: http://kinto.readthedocs.io/en/stable/configuration/settings.html#enabling-or-disabling-endpoints\n\nI can't believe I missed that section! It is doing precisely what I needed to do (or at least part of it).\n\nFor instance: https://firefox.settings.services.mozilla.com/v1/buckets/blocklists/collections/certificates/records\nYou can see that records contains a enabled field that allow us to deactivate them without removing them.\n\nThis is also an excellent option for what I am interested in doing.  It is also highly preferable because it allows me to have full control over how to treat a record that is disabled / \"deleted\".  \nFrom the information you provided, a combination of disabling the delete endpoints and using a technique similar to Mozilla's use with blocklists will give me exactly what I set out to find.\nThank you again for all your help.  I will close this issue now but I am wondering whether it is worthwhile to add a section to the manual that contains the \"techniques\" you explained with a description / examples of what they do (for someone else who may come looking).. Yes, I will do that.\n. ",
    "stasm": "Hey, thanks for adding this to the docs and for helping me out in IRC!\n. ",
    "jvehent": "We don't hide release versions today. I don't think we need to in the future.\nbash\n$ curl https://shavar.services.mozilla.com/__version__\n{\n    \"commit\": \"a92303b58b9c9cea0b74896a9b6e011e964e51b9\",\n    \"source\": \"https://github.com/mozilla-services/shavar.git\",\n    \"version\": \"0.6.9\"\n}\n. wazzaaa\n. ",
    "mozmark": "Related, yes. In this case, the collection last_modified and the record last_modified communicate different things.\nLet's say we have a collection. Imagine a record is added, then removed.  If a client syncs at the start, then again between the addition and removal and then, finally, syncs again after removal. Currently, the response body containing records will be the same in the first and last case. Also, the last_modified state based on (signed) data the client can see looks the same. but I need to be able to distinguish between the two (and determine the order in which all three responses belong) from signed data.\n. @Natim the ETag does have this data - but it needs to be part of the signed response if we wish to prevent replay of signed content.\n@almet I wasn't sure. Should I close it and file it there?\n. I'm slightly less worried about availability issues than I am integrity issues (since a determined attacker can arrange for other kinds of DoS) but it is a real problem. Especially since an attacker can 'fake' a successful sync (and we use 'last success' as a way to determine certain behaviours in my use-case).\nSome kind of signed heartbeat is what we'd need were we to decide to resolve that, @almet - this would need to be separate from actual collection updates because of what @natim describes. Maybe @jvehent has thoughts on this?\n. ",
    "Prashant-Surya": "Can I work on this issue?\n. @leplatrem can you briefly describe how should I solve this?\n. @Natim okay \n. Thank you @Natim\n. ",
    "mansimarkaur": "I'd love to work on this. \n. object is a global variable in Python. Should we be concerned about that when we move from record -> object?\n. So, what else should we name a record as if not object?\n. Yes, obj seems to be a good option. Thanks!\n. @lavish205 Are you still working on this issue? If not, can I please work on this?\n. @Natim How many characters and base salt do you think should be used?\n. I thought we want to add the details attribute to all 404 errors as in the normal 404 should also contain a details attribute in the response. \n. @glasserc  Even i couldn't find anything for buckets.\n@leplatrem id is to object_id I understood from #710 but what exactly does a resource_name define?\n. Shouldn't the valid format of a 404 error contain the details attribute as well, now? If yes, then  I think this test should be modified to ensure that the error contains details. What do you think?\n. Yes, makes more sense to add another test to check the 404 format. Thanks!\n. ",
    "peterbe": "What about https://kinto.readthedocs.io/en/stable/api/1.x/records.html\nWe renamed the Total-Records header to Total-Objects (but kept both to be gentle). Should the /records (and its documentation) be redirects for /objects now?. Pardon my kinto-juniorness but...\nFeels like this issue is crossing paths with https://github.com/Kinto/kinto/pull/1598 which is about doing inserts.\nIt feels like the bestest way would be to use row-level locking. And for inserts, rely on idx_records_parent_id_collection_id_last_modified. \nThe TOCTOU problem happens because we \"disconnect\" between the client and the database whilst we figure out whether to proceed with the delete/update or whether to raise an error which results in a 419(?) HTTP error. \nBy doing something like:\nsql\nSELECT last_modified FROM records\nWHERE id=:object_id and parent_id=:parent_id and collection_id=:collection_id\nFOR UPDATE NOWAIT\n...first, we can be totally confident how to proceed. If the record existed the row-level locking will protect us from a single process getting access to the UPDATE/DELETE to come. \nIf it didn't exist and it's an insert/upsert, you can't lock the whole table or anything like that but you are also blocked from doing two inserts with the same id|parent_id|collection_id combo. E.g.\nsql\nINSERT INTO records (id, parent_id, collection_id, data, last_modified) VALUES\n(:object_id, :parent_id, :collection_id, (:data)::JSONB, :last_modified)\nand, on the Python level you watch out for an IntegrityError. E.g.\npython\ntry:\n    cursor.execute('INSERT INTO ...')\nexcept IntegrityError as exception:\n    if 'records_pkey' in exception.args[0]:\n        raise TooLateToInsertError('419 for you!')\n    raise\nPerhaps adding proper Postgresql locking is already something we're planning or perhaps there are circumstances I don't (yet) really understand. \nOn the Storage interface, it appears to be create, update and delete only. Right? So we can write one implementation of the upsert-with-locking for each. I'd be happy to volunteer where I can. \n. By the way, the delete case is solvable without a lock using @Natim 's idea of either using WHERE last_modified = 'previous_last_modified' or something like this:\npython\ncur.execute(\"\"\"\n    DELETE FROM records WHERE\n    id=:object_id and parent_id=:object_id and  collection_id=:collection_id\n    and last_modified=from_epoch(:last_modified)\n    RETURNING id\n\"\"\", {...})\nfetched = cur.fetchone()\nif not fetched:\n    raise TooLateToDeleteError('419 for you!')\n. I have prototypes for insert, upsert, update and delete all as python scripts that are pure psycopg2 based. I use a threadpool and some time.sleep() to trigger the race conditions and in all cases I can \"prove\" the prototypes. Is this interesting? \nIn all my prototypes I have not yet worried myself with the complexity of tombstones but I'm sure we can factor it in. \nThe only thing that is a bit stinky is that the interface between Python and Postgres is that you have to rely on the driver to wrap Postgres errors into exception which you then capture and analyze. E.g. this.. I'm trying to collect my thoughts. https://github.com/Kinto/kinto/issues/1525 is all about the create() method. This issue has escalated into a discussion about leveraging proper row-level locks. \nHopefully we can break this up. This issue can be about using row-level locks to do the logical delete. And that other issue can be about using Integrity checks instead of the overly complicated upsert. \nSo, my prototype for row-level locking is really trivial in comparison to \"real kinto\" in that, in kinto, we use SQLAlchemy instead of handcrafted SQL strings. For example, the prototype assumes that you always include, as parameters, the last_modified. Perhaps it needs to be smarter and break that up for with- and without a last_modified. \nIf you think the row-level prototype is sane in theory, I can start attempting a patch. . The SELECT it does looks like this:\n```sql\nWITH collection_filtered AS (\n    SELECT id, last_modified, data, deleted\n      FROM records\n     WHERE parent_id = '/buckets/build-hub/collections/releases'\n       AND collection_id = 'record'\n       AND NOT deleted\n),\ntotal_filtered AS (\n    SELECT COUNT(id) AS count_total\n      FROM collection_filtered\n     WHERE NOT deleted\n),\npaginated_records AS (\n    SELECT DISTINCT id\n      FROM collection_filtered\n)\n SELECT count_total,\n       a.id, as_epoch(a.last_modified) AS last_modified, a.data\n  FROM paginated_records AS p JOIN collection_filtered AS a ON (a.id = p.id),\n       total_filtered\n  ORDER BY last_modified DESC\n LIMIT 10;\n```\nEven though it's limited to the first 10, the whole query becomes a \"beast\" for Postgres:\n```\n                                                                            QUERY PLAN\n\nLimit  (cost=485454.57..485454.60 rows=10 width=80) (actual time=8778.417..8778.419 rows=10 loops=1)\n   CTE collection_filtered\n     ->  Seq Scan on records  (cost=0.00..197338.38 rows=772692 width=1009) (actual time=0.058..965.993 rows=772688 loops=1)\n           Filter: ((NOT deleted) AND (parent_id = '/buckets/build-hub/collections/releases'::text) AND (collection_id = 'record'::text))\n           Rows Removed by Filter: 4\n   CTE total_filtered\n     ->  Aggregate  (cost=16419.71..16419.72 rows=1 width=8) (actual time=2948.909..2948.909 rows=1 loops=1)\n           ->  CTE Scan on collection_filtered  (cost=0.00..15453.84 rows=386346 width=32) (actual time=0.002..2874.297 rows=772688 loops=1)\n                 Filter: (NOT deleted)\n   CTE paginated_records\n     ->  HashAggregate  (cost=17385.57..17387.57 rows=200 width=32) (actual time=712.816..878.339 rows=772688 loops=1)\n           Group Key: collection_filtered_1.id\n           ->  CTE Scan on collection_filtered collection_filtered_1  (cost=0.00..15453.84 rows=772692 width=32) (actual time=0.016..376.150 rows=772688 loops=1)\n   ->  Sort  (cost=254308.91..256240.64 rows=772692 width=80) (actual time=8778.415..8778.417 rows=10 loops=1)\n         Sort Key: (as_epoch(a.last_modified)) DESC\n         Sort Method: top-N heapsort  Memory: 44kB\n         ->  Hash Join  (cost=8.52..237611.31 rows=772692 width=80) (actual time=4539.533..8618.027 rows=772688 loops=1)\n               Hash Cond: (a.id = p.id)\n               ->  CTE Scan on collection_filtered a  (cost=0.00..15453.84 rows=772692 width=72) (actual time=0.060..464.148 rows=772688 loops=1)\n               ->  Hash  (cost=6.02..6.02 rows=200 width=40) (actual time=4537.915..4537.915 rows=772688 loops=1)\n                     Buckets: 65536 (originally 1024)  Batches: 32 (originally 1)  Memory Usage: 3585kB\n                     ->  Nested Loop  (cost=0.00..6.02 rows=200 width=40) (actual time=3661.729..4242.430 rows=772688 loops=1)\n                           ->  CTE Scan on total_filtered  (cost=0.00..0.02 rows=1 width=8) (actual time=2948.910..2948.911 rows=1 loops=1)\n                           ->  CTE Scan on paginated_records p  (cost=0.00..4.00 rows=200 width=32) (actual time=712.817..1192.142 rows=772688 loops=1)\n Planning time: 0.949 ms\n Execution time: 8847.949 ms\n```\n~9 seconds!!\nCompare with...\nsql\nselect id, as_epoch(last_modified) AS last_modified, data\nfrom records\nWHERE parent_id = '/buckets/build-hub/collections/releases'\n  AND collection_id = 'record' and deleted=false\n  order by last_modified desc limit 10;\nwhich looks like this:\n```\n                                                                              QUERY PLAN\n\nLimit  (cost=0.42..11.46 rows=10 width=1008) (actual time=1.887..1.970 rows=10 loops=1)\n   ->  Index Scan Backward using idx_records_last_modified_epoch on records  (cost=0.42..852510.52 rows=772692 width=1008) (actual time=1.886..1.967 rows=10 loops=1)\n         Filter: ((NOT deleted) AND (parent_id = '/buckets/build-hub/collections/releases'::text) AND (collection_id = 'record'::text))\n Planning time: 2.522 ms\n Execution time: 4.152 ms\n```\nThe count is quite expensive. \nsql\nSELECT count(*)\n  FROM records\n WHERE parent_id = '/buckets/build-hub/collections/releases'\n   AND collection_id = 'record'\n   AND NOT deleted;\nThat returns 772,688 here in my database.\nAnd it looks like this explained:\n```\n                                                                     QUERY PLAN\n\nFinalize Aggregate  (cost=192382.43..192382.44 rows=1 width=8) (actual time=412.275..412.275 rows=1 loops=1)\n   ->  Gather  (cost=192382.21..192382.42 rows=2 width=8) (actual time=412.269..412.273 rows=3 loops=1)\n         Workers Planned: 2\n         Workers Launched: 2\n         ->  Partial Aggregate  (cost=191382.21..191382.22 rows=1 width=8) (actual time=408.734..408.734 rows=1 loops=3)\n               ->  Parallel Seq Scan on records  (cost=0.00..190577.33 rows=321955 width=0) (actual time=0.852..386.003 rows=257563 loops=3)\n                     Filter: ((NOT deleted) AND (parent_id = '/buckets/build-hub/collections/releases'::text) AND (collection_id = 'record'::text))\n                     Rows Removed by Filter: 1\n Planning time: 0.763 ms\n Execution time: 414.734 ms\nNote, if I create an index...:sql\ncreate index records_parent_id_collection_id_not_deleted_idx ON records (parent_id, collection_id) where not deleted;\n```\n```\n                                                                                               QUERY PLAN\n\nFinalize Aggregate  (cost=59101.87..59101.88 rows=1 width=8) (actual time=118.455..118.455 rows=1 loops=1)\n   ->  Gather  (cost=59101.66..59101.87 rows=2 width=8) (actual time=118.435..118.448 rows=3 loops=1)\n         Workers Planned: 2\n         Workers Launched: 2\n         ->  Partial Aggregate  (cost=58101.66..58101.67 rows=1 width=8) (actual time=114.181..114.181 rows=1 loops=3)\n               ->  Parallel Index Only Scan using records_parent_id_collection_id_not_deleted_idx on records  (cost=0.42..57296.77 rows=321955 width=0) (actual time=0.101..92.983 rows=257563 loops=3)\n                     Index Cond: ((parent_id = '/buckets/build-hub/collections/releases'::text) AND (collection_id = 'record'::text))\n                     Heap Fetches: 18777\n Planning time: 1.149 ms\n Execution time: 122.577 ms\n```\nSo it takes ~9 seconds. But if you break it up into a count and a plain select it could be 4.152 ms + 414.734 ms. And with the index, it would be 4.152 ms + 122.577 ms instead. \nBasically, what takes 9 seconds can take 0.5 seconds if we break it up. \n. Used best-explain-analyze.py to run the big fat query a bunch of times to see what the best possible time you can get. The result is:\nEXECUTION TIME\n    BEST    8543.617ms  <-- the important number\n    MEAN    8872.852ms\n    MEDIAN  8752.921ms\nPLANNING TIME\n    BEST    0.935ms\n    MEAN    1.148ms\n    MEDIAN  1.161ms\nMeaning, the best it can do (after 10 attempts) is 8543.617ms. \nFor the record, if I change it from LIMIT 10 to LIMIT 1000 the results are:\nEXECUTION TIME\n    BEST    8661.977ms  <-- the important number\n    MEAN    8952.208ms\n    MEDIAN  8906.576ms\nPLANNING TIME\n    BEST    0.933ms\n    MEAN    1.149ms\n    MEDIAN  1.019ms\nIn conclusion, doing LIMIT 10 or LIMIT 1000 doesn't make a big difference. \n. And in the same vein, if I run the simple select\nsql\nselect id, as_epoch(last_modified) AS last_modified, data\nfrom records\nWHERE parent_id = '/buckets/build-hub/collections/releases'\n  AND collection_id = 'record' and deleted=false\n  order by last_modified desc limit 10;\n100 times, I get:\nEXECUTION TIME\n    BEST    1.483ms  <-- the important number\n    MEAN    1.746ms\n    MEDIAN  1.728ms\nPLANNING TIME\n    BEST    0.824ms\n    MEAN    0.939ms\n    MEDIAN  0.903ms\nSo, instead of ~4ms the actual number is 1.483ms.. The scary thing about this is that during those 9 seconds, it's really CPU intensive and can cause other more pressing and complex queries to be blocked and build up. \nI have a question though: Why the SELECT DISTINCT id FROM collection_filtered part? \nAdding that to the simple select so it becomes:\nsql\nselect DISTINCT id, as_epoch(last_modified) AS last_modified, data\nfrom records\nWHERE parent_id = '/buckets/build-hub/collections/releases'\n  AND collection_id = 'record' and deleted=false\n  order by last_modified desc limit 10;\nThen you get:\nEXECUTION TIME\n    BEST    5803.857ms\n    MEAN    5955.790ms\n    MEDIAN  5901.252ms\nPLANNING TIME\n    BEST    1.004ms\n    MEAN    1.090ms\n    MEDIAN  1.070ms\nIt looks like this:\n```\n                                                                     QUERY PLAN\n\nLimit  (cost=1147472.86..1147472.96 rows=10 width=1008) (actual time=5590.636..5590.695 rows=10 loops=1)\n   ->  Unique  (cost=1147472.86..1155199.78 rows=772692 width=1008) (actual time=5590.635..5590.693 rows=10 loops=1)\n         ->  Sort  (cost=1147472.86..1149404.59 rows=772692 width=1008) (actual time=5590.634..5590.636 rows=10 loops=1)\n               Sort Key: (as_epoch(last_modified)) DESC, id COLLATE \"C\", data\n               Sort Method: external merge  Disk: 772928kB\n               ->  Seq Scan on records  (cost=0.00..390511.38 rows=772692 width=1008) (actual time=0.787..1698.278 rows=772688 loops=1)\n                     Filter: ((NOT deleted) AND (parent_id = '/buckets/build-hub/collections/releases'::text) AND (collection_id = 'record'::text))\n                     Rows Removed by Filter: 4\n Planning time: 1.102 ms\n Execution time: 5925.728 ms\n```\nIf there are multiple different IDs in that parent_id/collection_id the DISTINCT id won't filter out anything, because they're different. The only time the IDs might be repeated (and DISTINCT id does something) is if the parent_id or collection_id is different. Right?\nAfter all you can't ever have something like this:\nbuildhub=# select id, parent_id, collection_id from records where parent_id = '/buckets/build-hub/collections/releases' AND collection_id = 'record' and deleted=false order by last_modified desc limit 3;\n                 id                  |                parent_id                | collection_id\n-------------------------------------+-----------------------------------------+---------------\n firefox_beta_60-0b14rc2_win64_zh-tw | /buckets/build-hub/collections/releases | record\n firefox_beta_60-0b14rc2_win64_vi    | /buckets/build-hub/collections/releases | record\n firefox_beta_60-0b14rc2_win64_vi    | /buckets/build-hub/collections/releases | record\nTHIS IS IMPOSSIBLE. (because of the index \"records_pkey\" PRIMARY KEY, btree (id, parent_id, collection_id)). I faked the sample output.. Ah! I get it. If the parent_id is a wildcard expression you will a benefit from the DISTINCT id\nhttps://github.com/Kinto/kinto/blob/c0a08d66faf6154e637bc30e6f72b741ce7434f5/kinto/core/storage/postgresql/init.py#L625\nSo this is what I propose;\n1. Break up the counting from the select. I.e. do two conn.execute(count_query) and conn.execute(select_query).\n2. If the '*' in parent_id is true, use DISTINCT id in the plain select query. \nI'm still a bit confused about the DISTINCT at all. If you ask to get all records in parent_id=\"something*\" why should you only get the first one (sorted by last_modified desc)? . > I am skeptical that separating the COUNT into a separate query will be faster.\nThe select one doesn't scan the table at all. It just uses an index based on last_modified.\n\nBut please feel free to open a PR with some benchmark numbers!\n\nWill do! \ud83e\udd20. > I don't recall but I am pretty sure if you remove that DISTINCT and run the postgresql storage tests one test will fail and explain it.\nTried that. Running make tests didn't fail. \nI still thing it's a weird thing to use distinct at all. But I don't want to solve that as part of this issue. This issue can ignore that debate and walk around the \"problem\".. Mind you, Buildhub is being slowly replaced with Buildhub2 which doesn't use Kinto. It's a slowly dying project. \nOne thing I'm curious about is; are there other collections in the wild (I guess we are restricted to knowing about Mozilla projects) that have large number of records per collection? \n```bash\n\u25b6 cat ~/count.sql\nselect parent_id, collection_id, count(*) as count from records\ngroup by parent_id, collection_id\norder by count desc limit 20;\n\u25b6 psql buildhub < ~/count.sql\n                   parent_id                   | collection_id |  count\n-----------------------------------------------+---------------+---------\n /buckets/build-hub/collections/releases       | record        | 1037997\n                                               | bucket        |       2\n /buckets/2ca20155-dd42-fa2b-8e18-7102d2c3af79 | collection    |       1\n /buckets/build-hub                            | collection    |       1\n(4 rows)\n\u25b6 psql workon < ~/count.sql\n                            parent_id                            | collection_id | count\n-----------------------------------------------------------------+---------------+-------\n /buckets/22cf4aa5-9bf3-2539-da76-a7d382a7c354/collections/todos | record        |    58\n /buckets/396037c3-8d15-495d-2e0a-037068da6dfa/collections/todos | record        |    56\n /buckets/f6d78db1-bcd7-8518-2f94-01545e622769/collections/todos | record        |     8\n /buckets/4a96c0e8-bed0-5c26-dcad-3b0a7619a6a5/collections/todos | record        |     6\n                                                                 | bucket        |     5\n /buckets/f6d78db1-bcd7-8518-2f94-01545e622769                   | collection    |     1\n /buckets/396037c3-8d15-495d-2e0a-037068da6dfa                   | collection    |     1\n /buckets/ff27fd9d-5a5b-5d94-ef7c-c7e8103bb25c                   | collection    |     1\n /buckets/4a96c0e8-bed0-5c26-dcad-3b0a7619a6a5                   | collection    |     1\n /buckets/22cf4aa5-9bf3-2539-da76-a7d382a7c354                   | collection    |     1\n(10 rows)\n```\nIf Mozilla's Buildhub1 is a globally unique instance then your point @glasserc is extremely relevant. \nBy the way, would it be an idea to release a plugin called \"kinto-without-counts\" or something that basically overrides the SELECT queries as per my naive patches mentioned above? I don't think I would even personally care about using it for Buildhub, under the circumstances, even if it existed. . I think the gist of https://github.com/Kinto/kinto/issues/1624 isn't about doing two SELECT queries. It's about doing 1 SELECT * FROM ... when there's a GET request and 1 SELECT COUNT(*) FROM ... when there's a HEAD request. . For the record, when setting up pyup you have choices. If you split up your dependencies as requirements/default.txt and requirements/constraints.txt you can tell PyUp to only bother checking requirements/default.txt and (I've never done this but I assume it's possible) only security alerts on requirements/constraints.txt. Then you don't get flooded with pyup pull requests for \"trivial\" packages like requests, six or botocore. \nI failed to do this with Tecken so now I get PRs for all sorts of \"unimportant\" packages. . Still an open issue https://github.com/renovatebot/renovate/issues/2212. One immediate thought that springs to mind is that the query uses UNION ALL for two queries. (The ALL just helps to avoid duplicates across the queries). But the python code uses fetchone(). There's something illogical there. \"Give be A and B. Result is the first one.\". Sorry, the \"UNION ALL\" does the opposite. \n\"This PostgreSQL UNION ALL operator would return a category_id multiple times in your result set if the category_id appeared in both the products and categories table. The PostgreSQL UNION ALL operator does not remove duplicates. If you wish to remove duplicates, try using the PostgreSQL UNION operator.\"\n-- https://www.techonthenet.com/postgresql/union_all.php\n\"[UNION] eliminates duplicate rows from its result, in the same way as DISTINCT, unless UNION ALL is used.\"\n-- https://www.postgresql.org/docs/8.3/static/queries-union.html. Happened again in buildhub: https://gist.github.com/peterbe/fca3ab72f91869bd3f6218a69dec878b. More examples for those who can see this: https://sentry.prod.mozaws.net/operations/kinto-testpilot-prod/issues/3321530/. When you say \"I cannot reproduce\" did you mean you wrote a unit test (functional with real Postgres) or did you mean you tried via HTTP?\nI studied the SQL and tested it locally and it looks correct. If the record doesn't exist, it works. If the record existed but was deleted, it works (and makes it not deleted). If it already existed and wasn't delete it still works. \n\nnone of the 2 requests in the union returns a record\n\nHow could that happen?? The only time the first part of the UNION would return 0 records is if it already exists (by id, parent_id and collection_id) and the update did not do anything. If that is the case, the second part would find it and return at least 1 record. But that makes no sense. \nI'm starting to suspect that it lies somewhere else outside this SQL query. I don't actually know how transactions in kinto are done but one thing that makes me nervous is that the SQL query is a write operation (sometimes) but there's no commit on the transaction. . I've tried really hard to reproduce this and failing. \nI think the current solution isn't thread-safe but it's hard to prove because of the way transactions are done in kinto. It's not immediately clear where the commit happens after the kinto_client.create() record happens. \nThe SQL query can do three things:\n\nDo nothing, just return the row unchanged (inserted=FALSE)\nInsert the record (inserted=TRUE)\nUpdate the existing record and change deleted=TRUE (inserted=TRUE)\n\nIf the first thing happens, it will raise a UnicityError. (I guess that's to inform the client that you tried to create a record that already existed!)\nBut it's not clear where the COMMIT happens. I suspect what might happens is that record is changing during an insert. But it's not clear either. \nOne interesting thing to remember is that we've seen a lot of these errors in buildhub. In buildhub, we never delete things. I.e. we never set deleted=TRUE on any records. So what happens there is probably concurrent calls to kinto_client.create(same, arguments, in, concurrent, threads). But the strange thing is that if you try to call this SQL with the same it should raise an exception like:\nduplicate key value violates unique constraint \"idx_records_parent_id_collection_id_last_modified\"\nDETAIL:  Key (parent_id, collection_id, last_modified)=(/buckets/build-hub/collections/releases, record, 2018-04-16 09:39:00.004) already exists.\nIt concerns me what this can happen. Perhaps we can work together to audit how the transactions are committed. I really think there are better patterns to insert something . Some progress! \nI managed to demonstrate the problem that Erwin talks about in: https://stackoverflow.com/a/15950324/205832\nSee (but don't judge me how ugly code is): https://gist.github.com/peterbe/883da6f65e315383ca83b7ade5e94e42\nWhen you run that you get this:\n\u25b6 python dummy.py\n! 0\n! 1\ncommit 1\n1 page data = ('firefox_beta_58-0b15rc1_linux-i686_cs2', {}, 1523861592005, True)\ncommit 0\n0 page data = None\n...every time!\nWhat it simulates is two concurrent threads. If you merge their timelines you get this:\n1) (Thread 1) BEGIN\n2) (Thread 2) BEGIN\n3) (Thread 1) WITH create_record... \n4) (Thread 2) WITH create_record... \n5) (Thread 2) COMMIT\nBasically, if you extrapolate that to the Python/kinto layer I think this happens:\n```\nThread 1\nkinto_client.create('myid', 'mycollection', 'mybucket', '2018-04-16 06:53:12.004')\nThread 2\nkinto_client.create('myid', 'mycollection', 'mybucket', '2018-04-16 06:53:12.005')\n``\nThe combination (parent_id, collection_id, last_modified) is different in both calls so you don't get trapped by theidx_records_parent_id_collection_id_last_modified` uniqueness index on the inserts. \nPlease check if I've understood that right. If that's the case, the right way to write a unit test would be something like these pseudo kinto_client.create(...) above. . > I really think there are better patterns to insert something\nErwin suggested you use a loop instead. I don't really yet know what that means for us. \nEither way, we could perhaps instead reject on a Python level if inserted = result.fetchone() becomes None. If that happens, we know you called create() with the same ID (and parent_id and collection_id) but with different last_modified). It could push the problem onto the calling client. \nThe reason that's probably a good idea is that one of the clients did get an OK so it would not make sense to update the record for that other client. \nMeaning, if it's true that two concurrent clients attempt the same .create() (with possibly different JSON!) it would be weird to \"correct\" the second client's call. \n. The easy fix would be to pursue my unfinished PR and just deal with the fact that the inserted becomes None without any locks. \nThe upsert prototype tries to break up the task by attempting to do an update (e.g. undoing the logical delete) with an UPDATE (using row-level locking), then it tries to do an insert and watch out for IntegrityErrors. That makes sure we can control two concurrent attempts to call create() with the same parameters. \nLooking for thoughts and feedback on this. . @leplatrem I need your help to finish this PR. Lots of help :)\nI've only just started getting into kinto dev. Not sure where to add a test or even what should happen. In https://github.com/Kinto/kinto/issues/1525#issuecomment-381739832 I outlined a very rough way to trigger the insert is None case but I did it with pure psycopg2 and not in the context of kinto. Also, I suspect the unit test, to trigger the race condition, needs to use a threading which I don't know if/how we already do that. \nIn your hands for guidance. . (it's my intention to return to the checkboxes in the PR description once I get going). Before I dig deeper into this, I'm excited about this idea (of mine): https://github.com/Kinto/kinto/issues/1407#issuecomment-382489691\nBasically, instead of doing fancy upsert CTE functions, we probably ought to use proper row-level locking and rely on the primary key integrity checking. . > What's the status of this? \nMe, dragging my feet. \nThere are two possible solutions. My PR started down one possible path and that is to \"accept\" that the UNION sometimes yields nothing. E.g....\npython\nif inserted is None:\n    # Potential conflict trying to call create twice\n    # XXX needs the right/relevant error message\nThe other possibility is to rewrite the query entirely and use a ON UPDATE row lock. It that is the best way to do updates but if there are no tombstones or anything like that, the only way to protected against identical inserts is to use except IntegrityError and check if the primary key was raising a uniqueness error. E.g:\npython\ntry:\n    cur.execute(\"INSERT INTO records (...) VALUES (...)\", ...)\nexcept IntegrityError as exception:\n    if 'duplicate key value violates unique constraint \"records_pkey\"' in exception.args[0]:\n        # You tried to call kinto_client.create(...) twice with the same arguments! \n        # XXX needs the right/relevant error message\n   else:\n       raise\nOption 2 is more right and probably safer. Option 1 is probably easier to accomplish. I just got stuck knowing how to raise the appropriate error. . Did some benchmarking first. See https://gist.github.com/peterbe/c4b6bb31e2b957d85d14932f5200f08a. In https://github.com/Kinto/kinto/issues/1616#issuecomment-384956128 I discovered something. \nThis PR uses a DISTINCT if '*' in parent_id. That means it will return only 1 single ID + last_modified + data combo if they're all identical, but only differ in parent_id value. That's not what the original query (which this PR replaces) did. It returned duplicate rows. \nThat means this PR behaves different from master and the tests didn't catch it :(\n. To be clear; in my last commit, I removed the DISTINCT functionality when '*' in parent_id. It now behaves exactly like get_all in master and as a fun-fact, this changed was never caught in tests. . @glasserc When you talked about reentrence, does that refer to the network overhead of having to send the query twice to the Postgres server. Especially if it's latency is slightly scary. \nNote that the psycopg connection is kept open by the Python process. So the re-entrence doesn't have pay a \"connection fee\" more than once. \nOr, are you referring to it as a risk of getting wrong numbers between the two queries? I.e. \ntime 1. (thread 1) SELECT COUNT(*) FROM records WHERE x=y  (returns 100)\ntime 2. (thread 2) DELETE FROM records WHERE x=y and z=z   (deletes 1 row)\ntime 3. (thread 1) SELECT id, last_modified FROM records WHERE x=y (returns 99 rows)\nAlso, in terms of benchmarking performance, see https://gist.github.com/peterbe/c4b6bb31e2b957d85d14932f5200f08a#gistcomment-2571339\nThat's using requests.get on my local kinto on :8888 which talks to a database on localhost. It's under no other concurrent load. This benchmark is entirely synchronous. But still, it's showing (not proving) that the HTTP GET of records (with ?_limit=10) is 30 times faster now. . Perhaps I'm trying to prove something that isn't all that important or disputed, but I updated the HTTP GET benchmark by seeing how it behaves under concurrent load. \nhttps://gist.github.com/peterbe/c4b6bb31e2b957d85d14932f5200f08a#gistcomment-2572108\n. > Ethan has worked a lot on race conditions / TOCTOU stuff ;)\nAh! Yeah, it's a real concern. I stand by the fact that this is now going to get significantly an un-risk. What I mean by that is that since the select id, last_modified, data FROM records WHERE parent_id... collection_id=... ORDER BY last_modified DESC LIMIT 10 is a pure index-level read, it's always going to be fast. It doesn't even need to read the records table. \nIn https://gist.github.com/peterbe/c4b6bb31e2b957d85d14932f5200f08a I was able to show that I can finish the select in 1.59ms on a 183,244 records database. And what proves that it's an index-level read (apart from looking at the EXPLAIN ANALYZE) is that that number is 1.51ms for an even larger database. (Why it's not exactly the same I don't know). \nAnyway, there is a real way to prevent the len(SELECT) != COUNT across the two executions. You can use REPEATABLE READ\nSee https://gist.github.com/peterbe/546e782b5ae51afb22ab0eed9b3ddab1\nIt demonstrates the race-condition (comment out line 34-35) and a solution. \nI haven't attempted to use this set_session inside kinto at all. Nor have I run a benchmark to see how much it costs. . > add a test to this PR that captures the subtle bug\nCriss-cross github issue madness. https://github.com/Kinto/kinto/issues/1616#issuecomment-385069391\n\nThat's why I asked you to benchmark with and without that change.\n\nSo my change here comes at a danger in that you CAN end up with count != len(records) due to an unlucky edit whilst these two queries are sent. \nI think we have strong benchmarks showing that the SQL is \"better\" and I've done bencmarks using my local localhost:8888 kinto server. \nBut I haven't made any benchmarks with/without the technique discussed in https://gist.github.com/peterbe/546e782b5ae51afb22ab0eed9b3ddab1\nI can attempt that. . Now I understand your point @glasserc \nHere's one version using the OVER () technique:\nsql\nselect COUNT(*) OVER (), id, as_epoch(last_modified) AS last_modified,\nMD5(jsonb_pretty(data)) AS data\nfrom records\nWHERE parent_id = '/buckets/build-hub/collections/releases'\nAND collection_id = 'record'\nORDER BY last_modified DESC\nLIMIT 10;\nCompared to these two:\n```sql\nselect count(*)\nfrom records\nWHERE parent_id = '/buckets/build-hub/collections/releases'\nAND collection_id = 'record';\nselect id, as_epoch(last_modified) AS last_modified,\nMD5(jsonb_pretty(data)) AS data\nfrom records\nWHERE parent_id = '/buckets/build-hub/collections/releases'\nAND collection_id = 'record'\nORDER BY last_modified DESC\nLIMIT 10;\n```\nIf I break these up and run all three 10 times and record the best possible time with my 183,240 rows database:\n\n955.45ms\n99.19ms\n1.72ms\n\nDifference is that it's roughly 10x slower to do the COUNT(*) OVER (). /me stunned!\nWhen I attempt the same benchmark but on my larger database (775,557 rows) it blows up:\n\n5179.24ms\n758.27ms\n1.70ms\n\nTo sanity check I compared it with the original query (the one still in master) and output looks the same: https://gist.github.com/peterbe/21b3e12484cc4937ec002c76f277f2cd\nLastly, the COUNT(*) OVER () is really meant for doing partitioning. For example, a count of something by weekday for example. \nAlso, the biggest problem with the SELECT COUNT(*) OVER (), id, ... query is that it's using the same WHERE clause for the count as it does for the LIMIT 10 records retrieval. In particular, according to the unit tests if you filter by including tombstones, the number of records isn't expected to the best same as the \"total_count\". \nNext, anybody got a really good window function to do the same that I can use?. By the way, I tried to write a CTE query but after a lot of trial-and-error the only thing I could come up with was one just like the original and back to square one where it takes several seconds to execute it. :(. I took a copy of my database and deleted a bunch of random records. Now it only has 30,000 records. Half of them I changed the parent_id. Now it looks like this:\nbuildhub_small=# select parent_id, count(parent_id) from records group by parent_id;\n                parent_id                | count\n-----------------------------------------+-------\n /buckets/build-hub/collections/funny    | 14504\n /buckets/build-hub/collections/releases | 15555\nNow, let's compare\nsql\nWITH collection_filtered AS (\n    SELECT id, last_modified, data, deleted\n      FROM records\n     WHERE parent_id = '/buckets/build-hub/collections/funny'\n       AND collection_id = 'record'\n  ORDER BY last_modified DESC\n),\ntotal_filtered AS (\n    SELECT COUNT(*) AS count_total\n      FROM collection_filtered\n     WHERE NOT deleted\n)\n SELECT count_total,\n       a.id, as_epoch(a.last_modified) AS last_modified,\n       a.data\n  FROM collection_filtered as a,\n       total_filtered\n LIMIT 10;\nAgainst...\nsql\nselect count(*)\nfrom records\nWHERE parent_id = '/buckets/build-hub/collections/funny'\nAND collection_id = 'record';\nand\nsql\nselect id, as_epoch(last_modified) AS last_modified,\ndata\nfrom records\nWHERE parent_id = '/buckets/build-hub/collections/funny'\nAND collection_id = 'record'\nORDER BY last_modified DESC\nLIMIT 10;\nResults:\n\n138.09ms (the combined)\n6.84ms (the count)\n1.62ms (the select)\n\nSo combined is still much slower. 16x slower. \nI ran each query 100 times which makes the mean ~= median on the Execution time. . This time, I try with a parent_id that only matches 10 items:\nbuildhub_small=# select parent_id, count(parent_id) from records group by parent_id;\n                parent_id                 | count\n------------------------------------------+-------\n /buckets/build-hub/collections/10records |    10\n /buckets/build-hub/collections/1records  |     1\n /buckets/build-hub/collections/funny     | 14497\n /buckets/build-hub/collections/releases  | 15551\nSame three queries as above but instead of parent_id = '/buckets/build-hub/collections/funny' it's now parent_id = '/buckets/build-hub/collections/10records'\nResults:\n\n1.48ms\n0.15ms\n1.55ms\n\nSo in this case, the split up select & count is 10% slower. . All three EXPLAIN ANALYZE are as follows:\nThe order is:\n1. The COUNT query\n2. The SELECT query\n3. @glasserc's last suggest CTE query but with the parent_id that matches 10 records.\n```\n                                                                              QUERY PLAN\n\nAggregate  (cost=4.44..4.45 rows=1 width=8) (actual time=0.106..0.106 rows=1 loops=1)\n   ->  Index Only Scan using idx_records_parent_id_collection_id_last_modified on records  (cost=0.41..4.43 rows=1 width=0) (actual time=0.066..0.095 rows=10 loops=1)\n         Index Cond: ((parent_id = '/buckets/build-hub/collections/10records'::text) AND (collection_id = 'record'::text))\n         Heap Fetches: 10\n Planning time: 0.692 ms\n Execution time: 0.190 ms\n(6 rows)\n                                                                            QUERY PLAN\n\n\nLimit  (cost=8.69..8.70 rows=1 width=1064) (actual time=0.672..0.674 rows=10 loops=1)\n   ->  Sort  (cost=8.69..8.70 rows=1 width=1064) (actual time=0.672..0.672 rows=10 loops=1)\n         Sort Key: (as_epoch(last_modified)) DESC\n         Sort Method: quicksort  Memory: 41kB\n         ->  Index Scan using idx_records_parent_id_collection_id_last_modified on records  (cost=0.41..8.68 rows=1 width=1064) (actual time=0.596..0.618 rows=10 loops=1)\n               Index Cond: ((parent_id = '/buckets/build-hub/collections/10records'::text) AND (collection_id = 'record'::text))\n Planning time: 0.259 ms\n Execution time: 1.971 ms\n(8 rows)\n                                                                          QUERY PLAN\n\n\nLimit  (cost=8.47..8.77 rows=1 width=80) (actual time=0.064..0.086 rows=10 loops=1)\n   CTE collection_filtered\n     ->  Index Scan using idx_records_parent_id_collection_id_last_modified on records  (cost=0.41..8.43 rows=1 width=1065) (actual time=0.009..0.016 rows=10 loops=1)\n           Index Cond: ((parent_id = '/buckets/build-hub/collections/10records'::text) AND (collection_id = 'record'::text))\n   CTE total_filtered\n     ->  Aggregate  (cost=0.02..0.03 rows=1 width=8) (actual time=0.032..0.032 rows=1 loops=1)\n           ->  CTE Scan on collection_filtered  (cost=0.00..0.02 rows=1 width=0) (actual time=0.003..0.030 rows=10 loops=1)\n                 Filter: (NOT deleted)\n   ->  Nested Loop  (cost=0.00..0.30 rows=1 width=80) (actual time=0.064..0.084 rows=10 loops=1)\n         ->  CTE Scan on collection_filtered a  (cost=0.00..0.02 rows=1 width=72) (actual time=0.010..0.015 rows=10 loops=1)\n         ->  CTE Scan on total_filtered  (cost=0.00..0.02 rows=1 width=8) (actual time=0.003..0.003 rows=1 loops=10)\n Planning time: 0.168 ms\n Execution time: 0.142 ms\n(13 rows)\n```\nAll three use an index scan. . In Buildhub we have this thing were it uses kinto_http.Client().get_records() to get every single record from the Kinto database. It does it 10,000 records at a time. I put a time measure around that beast in Python:\npython\nimport time\nt0=time.time()\nnew_records_batches = [client.get_records(\n    _since=previous_run_etag,\n    pages=float('inf')\n)]\nt1=time.time()\nprint(\n    \"TOOK\",\n    t1 - t0,\n    \"seconds to paginate fetch\",\n    len(new_records_batches[0]),\n    \"(in {} batches of 10,000)\".format(int(len(new_records_batches[0]) / 10_000))\n)\nraise Exception\nThe output becomes:\nTOOK 1066.8049581050873 seconds to paginate fetch 785908 (in 78 batches of 10,000)\nThen I literally copied the __init__.py from this PR into my kinto inside my virtualenv and ran it again. This time the output is:\nTOOK 83.82302474975586 seconds to paginate fetch 785908 (in 78 batches of 10,000)\nTo sanity check, I watched my /usr/local/var/log/postgres.log where I have it log every single query.\nBefore\nAfter\nI also saved each massive list of dicts to disk to be able to compare them:\n```\n\n\n\nimport json\nold =json.load(open('new_records-old.json'))\nnew =json.load(open('new_records-new.json'))\nlen(old)\n785908\nlen(new)\n785908\n```\n\n\n\nHowever! They were not identical. If I parse them and analyzed them a bit more in detail. \nIf I convert each list to a dict by the 'id' I can see that there were 2 IDs in the one that the other didn't have and vice versa. \n```\n\n\n\nold_s - new_s\n{'devedition_aurora_58-0b6rc1_linux-x86_64_et', 'devedition_aurora_59-0b6_win64_bs'}\nold_d['devedition_aurora_58-0b6rc1_linux-x86_64_et']['last_modified']\n1524241288164\nold_d['devedition_aurora_59-0b6_win64_bs']['last_modified']\n1524240460834\nnew_s - old_s\n{'devedition_aurora_58-0b6rc1_linux-x86_64_as', 'devedition_aurora_59-0b6_win32_uk'}\nnew_d['devedition_aurora_58-0b6rc1_linux-x86_64_as']['last_modified']\n1524241288164\nnew_d['devedition_aurora_59-0b6_win32_uk']['last_modified']\n1524240460834\nSo the old (`master`) code fails to retrieve two IDs. And the new (my code) also fails to retrieve two IDs. All four records are in the database:\nbuildhub=# select id, as_epoch(last_modified), last_modified from records where id in ('devedition_aurora_58-0b6rc1_linux-x86_64_as', 'devedition_aurora_59-0b6_win32_uk', 'devedition_aurora_58-0b6rc1_linux-x86_64_et', 'devedition_aurora_59-0b6_win64_bs');\n                     id                      |   as_epoch    |       last_modified\n---------------------------------------------+---------------+----------------------------\n devedition_aurora_58-0b6rc1_linux-x86_64_as | 1524241288164 | 2018-04-20 16:21:28.163601\n devedition_aurora_58-0b6rc1_linux-x86_64_et | 1524241288164 | 2018-04-20 16:21:28.16417\n devedition_aurora_59-0b6_win32_uk           | 1524240460834 | 2018-04-20 16:07:40.833634\n devedition_aurora_59-0b6_win64_bs           | 1524240460834 | 2018-04-20 16:07:40.834225\n(4 rows)\n```\n\n\n\nI'm not even sure where to begin debugging this! Or if now's the time to debug it at all. One culprit might be the rounding error of rounding the last_modified up to the nearest second. Note that each two pairs of last_modified is different but their as_epoch is the same. :(\nEnd of the day, the new code works just as well as the old code but it's 13 times faster. . > for some requests, it's slower than what we have\nI don't think that's a fair evaluation. When there were only 10 records to be matched, the sum of the SELECT + COUNT query was 10% slower. Also, it was a difference between 1.48ms vs. 0.15ms+1.55ms. That might just be noise. There is admittedly a tiny overhead of having to send two distinct queries on the open connection. \nThe proposed solution works for tiny queries. Paying 1.7ms for a count and a set of records is cheap. And it scales rapidly when it goes way beyond 10 matching records. \nAlso, in terms of priorities I think we're missing a subtle point in that if a READ query takes 15 seconds (not unrealistic at all at the moment on databases like Buildhub) that means the Postgres server is potentially distracted and resource hogging for other queries (read or write) that needs to be dealt with. Perhaps that's why we saw, in New Relic, these monster times for queries that, on paper, should be fast. \nMy perspective on Kinto that of a single instance that I'm familiar with. That's why I'm hesitant to speak to the risk evaluation of this in totality. Hence be now slightly withdrawn involvement. \n. So can we close this now that https://github.com/Kinto/kinto/pull/1622 has landed? I think so. . Check this out. I messed with my buildhub_copy database and now I have two records that have identical ID, last_modified and data. The only difference is that they have different parent_id. This is normal.\n(Note: In this database every single row belongs to the same collection_id)\nFirst I run the original query from get_all:\n```sql\nWITH collection_filtered AS (\n    SELECT id, last_modified, data, deleted\n      FROM records\n     WHERE parent_id LIKE '/buckets/build-hub/collections/%'\n       AND collection_id = 'record'\n       AND NOT deleted\n),\ntotal_filtered AS (\n    SELECT COUNT(id) AS count_total\n      FROM collection_filtered\n     WHERE NOT deleted\n),\npaginated_records AS (\n    SELECT DISTINCT id\n      FROM collection_filtered\n)\n SELECT count_total,\n       a.id, as_epoch(a.last_modified) AS last_modified,\n       MD5(jsonb_pretty(a.data)) AS data\n  FROM paginated_records AS p JOIN collection_filtered AS a ON (a.id = p.id),\n       total_filtered\n  ORDER BY last_modified DESC\n LIMIT 10;\nand I get:\n count_total |                      id                      | last_modified |               data\n-------------+----------------------------------------------+---------------+----------------------------------\n      183241 | firefox_beta_58-0b15rc1_linux-i686_cs        | 1523875992587 | 3d29a75fcf0ed7dfff86d3db8f92fc69\n      183241 | firefox_beta_58-0b15rc1_linux-i686_cs2       | 1523861592005 | 3d29a75fcf0ed7dfff86d3db8f92fc69\n      183241 | firefox_beta_60-0b10rc1_win32-eme-free_en-za | 1523630817174 | 54efb0c5bcfae989a74c1a9fd68daeb3\n      183241 | firefox_beta_60-0b10rc1_win32-eme-free_en-gb | 1523630817158 | 1e7f84a3ae2c7b4f66e045d99473fff7\n      183241 | firefox_beta_60-0b10rc1_macosx_ur            | 1523630817149 | 3d29a75fcf0ed7dfff86d3db8f92fc69\n      183241 | firefox_beta_60-0b10rc1_macosx_ur            | 1523630817149 | 3d29a75fcf0ed7dfff86d3db8f92fc69\n      183241 | firefox_beta_60-0b10rc1_win32-eme-free_el    | 1523630817147 | d5681a5f6f040ff5c44910acb9812d41\n      183241 | firefox_beta_60-0b10rc1_macosx_uk            | 1523630817138 | ef2ab418fb87dc88fb49c38d2e289740\n      183241 | firefox_beta_60-0b10rc1_win32-eme-free_dsb   | 1523630817137 | 9d4c8cb0ba8d1d4e0328453fe9c5e4cc\n      183241 | firefox_beta_60-0b10rc1_macosx_tr            | 1523630817128 | 2098bd485166b7b5088a8d0fa71a75f9\n``\nNote the two *identical* rows with IDfirefox_beta_60-0b10rc1_macosx_ur`. Arguably useless and useful too as a JSON response. Who am I to judge. \nNext, change that SQL to NOT do a DISTINCT:\n```sql\n WITH collection_filtered AS (\n     SELECT id, last_modified, data, deleted\n       FROM records\n      WHERE parent_id LIKE '/buckets/build-hub/collections/%'\n        AND collection_id = 'record'\n        AND NOT deleted\n),\n total_filtered AS (\n     SELECT COUNT(id) AS count_total\n       FROM collection_filtered\n      WHERE NOT deleted\n ),\n paginated_records AS (\n     SELECT id\n       FROM collection_filtered\n)\n  SELECT count_total,\n        a.id, as_epoch(a.last_modified) AS last_modified,\n        MD5(jsonb_pretty(a.data)) AS data\n   FROM paginated_records AS p JOIN collection_filtered AS a ON (a.id = p.id),\n        total_filtered\n   ORDER BY last_modified DESC\n  LIMIT 10;\nNow you get this:\n count_total |                      id                      | last_modified |               data\n-------------+----------------------------------------------+---------------+----------------------------------\n      183241 | firefox_beta_58-0b15rc1_linux-i686_cs        | 1523875992587 | 3d29a75fcf0ed7dfff86d3db8f92fc69\n      183241 | firefox_beta_58-0b15rc1_linux-i686_cs2       | 1523861592005 | 3d29a75fcf0ed7dfff86d3db8f92fc69\n      183241 | firefox_beta_60-0b10rc1_win32-eme-free_en-za | 1523630817174 | 54efb0c5bcfae989a74c1a9fd68daeb3\n      183241 | firefox_beta_60-0b10rc1_win32-eme-free_en-gb | 1523630817158 | 1e7f84a3ae2c7b4f66e045d99473fff7\n      183241 | firefox_beta_60-0b10rc1_macosx_ur            | 1523630817149 | 3d29a75fcf0ed7dfff86d3db8f92fc69\n      183241 | firefox_beta_60-0b10rc1_macosx_ur            | 1523630817149 | 3d29a75fcf0ed7dfff86d3db8f92fc69\n      183241 | firefox_beta_60-0b10rc1_macosx_ur            | 1523630817149 | 3d29a75fcf0ed7dfff86d3db8f92fc69\n      183241 | firefox_beta_60-0b10rc1_macosx_ur            | 1523630817149 | 3d29a75fcf0ed7dfff86d3db8f92fc69\n      183241 | firefox_beta_60-0b10rc1_win32-eme-free_el    | 1523630817147 | d5681a5f6f040ff5c44910acb9812d41\n      183241 | firefox_beta_60-0b10rc1_macosx_uk            | 1523630817138 | ef2ab418fb87dc88fb49c38d2e289740\n``\nWhat the hell?! *4* records with IDfirefox_beta_60-0b10rc1_macosx_ur. I can see the benefit of theDISTINCT` for this particular query. \nCompare this with my prototype in https://github.com/Kinto/kinto/pull/1615\nIgnore the count_total thing and let's just look at the SELECT:\nsql\nselect id, as_epoch(last_modified) AS last_modified,\nMD5(jsonb_pretty(data)) AS data\nfrom records\nWHERE parent_id LIKE '/buckets/build-hub/collections/%'\nORDER BY last_modified DESC\nLIMIT 10;\nYOu get:\nid                      | last_modified |               data\n----------------------------------------------+---------------+----------------------------------\n firefox_beta_58-0b15rc1_linux-i686_cs        | 1523875992587 | 3d29a75fcf0ed7dfff86d3db8f92fc69\n firefox_beta_58-0b15rc1_linux-i686_cs2       | 1523861592005 | 3d29a75fcf0ed7dfff86d3db8f92fc69\n firefox_beta_60-0b10rc1_win32-eme-free_en-za | 1523630817174 | 54efb0c5bcfae989a74c1a9fd68daeb3\n firefox_beta_60-0b10rc1_win32-eme-free_en-gb | 1523630817158 | 1e7f84a3ae2c7b4f66e045d99473fff7\n firefox_beta_60-0b10rc1_macosx_ur            | 1523630817149 | 3d29a75fcf0ed7dfff86d3db8f92fc69\n firefox_beta_60-0b10rc1_macosx_ur            | 1523630817149 | 3d29a75fcf0ed7dfff86d3db8f92fc69\n firefox_beta_60-0b10rc1_win32-eme-free_el    | 1523630817147 | d5681a5f6f040ff5c44910acb9812d41\n firefox_beta_60-0b10rc1_macosx_uk            | 1523630817138 | ef2ab418fb87dc88fb49c38d2e289740\n firefox_beta_60-0b10rc1_win32-eme-free_dsb   | 1523630817137 | 9d4c8cb0ba8d1d4e0328453fe9c5e4cc\n firefox_beta_60-0b10rc1_macosx_tr            | 1523630817128 | 2098bd485166b7b5088a8d0fa71a75f9\nJust like the original query (the one currently in master, first in this comment). Two identical rows with ID firefox_beta_60-0b10rc1_macosx_ur. \nMeaning, even though the ID, last_modified and data are identical, you get repeated IDs with the code we have in master. At least you only get 2 identical rows and not 4. \nIf you really want to get distinct ID, last_modified, data combos you need to run this query:\nsql\nselect DISTINCT id, as_epoch(last_modified) AS last_modified,\nMD5(jsonb_pretty(data)) AS data\nfrom records\nWHERE parent_id LIKE '/buckets/build-hub/collections/%'\nORDER BY last_modified DESC\nLIMIT 10;\nThen you get:\nid                      | last_modified |               data\n----------------------------------------------+---------------+----------------------------------\n firefox_beta_58-0b15rc1_linux-i686_cs        | 1523875992587 | 3d29a75fcf0ed7dfff86d3db8f92fc69\n firefox_beta_58-0b15rc1_linux-i686_cs2       | 1523861592005 | 3d29a75fcf0ed7dfff86d3db8f92fc69\n firefox_beta_60-0b10rc1_win32-eme-free_en-za | 1523630817174 | 54efb0c5bcfae989a74c1a9fd68daeb3\n firefox_beta_60-0b10rc1_win32-eme-free_en-gb | 1523630817158 | 1e7f84a3ae2c7b4f66e045d99473fff7\n firefox_beta_60-0b10rc1_macosx_ur            | 1523630817149 | 3d29a75fcf0ed7dfff86d3db8f92fc69\n firefox_beta_60-0b10rc1_win32-eme-free_el    | 1523630817147 | d5681a5f6f040ff5c44910acb9812d41\n firefox_beta_60-0b10rc1_macosx_uk            | 1523630817138 | ef2ab418fb87dc88fb49c38d2e289740\n firefox_beta_60-0b10rc1_win32-eme-free_dsb   | 1523630817137 | 9d4c8cb0ba8d1d4e0328453fe9c5e4cc\n firefox_beta_60-0b10rc1_macosx_tr            | 1523630817128 | 2098bd485166b7b5088a8d0fa71a75f9\n firefox_beta_60-0b10rc1_win32-eme-free_de    | 1523630817126 | 98d706e1bd14644d0378259fc6714475\nAll truly distinct rows. . What's weird about this is that the count_total is likely to be off. At the very least; very confusing. \nIf you have a certain identical ID+last_modified+data combination all spread across 100 different parent_id. E.g. parent_id='/parent001', parent_id='/parent002', etc. \nAnd you do: SELECT COUNT(*) FROM records WHERE parent_id LIKE '/parent%' the answer will 100. But then when you do the actual records you'll get exactly 1 single row. But there are 100 rows in the database but you only return 1. It's a bit like doing a query like:\nget_all(first_name='peter', last_name='*', age=38, location='USA') and getting 1 row when clearly there are many different 38 year old Peters in the USA. \nIt smells like a weird result and I honestly don't get it. . Another (perhaps unimportant) reason why I'm pessimistic towards the use of DISTINCT is that it's really expensive. \nLook at these two queries:\n```\nexplain analyze\nselect id, as_epoch(last_modified) AS last_modified,\nMD5(jsonb_pretty(data)) AS data\nfrom records\nWHERE parent_id LIKE '/buckets/build-hub/collections/%'\nORDER BY last_modified DESC\nLIMIT 10;\nexplain analyze\nselect DISTINCT id, as_epoch(last_modified) AS last_modified,\nMD5(jsonb_pretty(data)) AS data\nfrom records\nWHERE parent_id LIKE '/buckets/build-hub/collections/%'\nORDER BY last_modified DESC\nLIMIT 10;\n```\nThe results:\n```\n                                                                            QUERY PLAN\n\nLimit  (cost=0.42..4.75 rows=10 width=87) (actual time=0.064..0.170 rows=10 loops=1)\n   ->  Index Scan Backward using idx_records_last_modified_epoch on records  (cost=0.42..79412.79 rows=183242 width=87) (actual time=0.064..0.168 rows=10 loops=1)\n         Filter: (parent_id ~~ '/buckets/build-hub/collections/%'::text)\n         Rows Removed by Filter: 1\n Planning time: 0.127 ms\n Execution time: 0.199 ms\n(6 rows)\n                                                         QUERY PLAN\n\n\nLimit  (cost=101126.69..101126.79 rows=10 width=87) (actual time=1833.516..1833.522 rows=10 loops=1)\n   ->  Unique  (cost=101126.69..102959.11 rows=183242 width=87) (actual time=1833.515..1833.521 rows=10 loops=1)\n         ->  Sort  (cost=101126.69..101584.80 rows=183242 width=87) (actual time=1833.515..1833.517 rows=11 loops=1)\n               Sort Key: (as_epoch(last_modified)) DESC, id COLLATE \"C\", (md5(jsonb_pretty(data)))\n               Sort Method: external merge  Disk: 18352kB\n               ->  Seq Scan on records  (cost=0.00..76337.24 rows=183242 width=87) (actual time=0.067..1699.084 rows=183241 loops=1)\n                     Filter: (parent_id ~~ '/buckets/build-hub/collections/%'::text)\n                     Rows Removed by Filter: 3\n Planning time: 0.091 ms\n Execution time: 1841.550 ms\n(10 rows)\n```\n1.8 seconds versus. 1.3 milliseconds. . Yikes! The above comment was on my little buildhub_copy database. This is what happens when I try it with my larger buildhub database:\n```\n                                                                             QUERY PLAN\n\nLimit  (cost=0.42..11.48 rows=10 width=84) (actual time=0.073..0.185 rows=10 loops=1)\n   ->  Index Scan Backward using idx_records_last_modified_epoch on records  (cost=0.42..854442.25 rows=772692 width=84) (actual time=0.073..0.183 rows=10 loops=1)\n         Filter: (parent_id ~~ '/buckets/build-hub/collections/%'::text)\n         Rows Removed by Filter: 2\n Planning time: 0.201 ms\n Execution time: 0.227 ms\n(6 rows)\n                                                          QUERY PLAN\n\n\nLimit  (cost=541965.59..541965.69 rows=10 width=84) (actual time=13976.616..13976.623 rows=10 loops=1)\n   ->  Unique  (cost=541965.59..549692.51 rows=772692 width=84) (actual time=13976.615..13976.620 rows=10 loops=1)\n         ->  Sort  (cost=541965.59..543897.32 rows=772692 width=84) (actual time=13976.614..13976.616 rows=10 loops=1)\n               Sort Key: (as_epoch(last_modified)) DESC, id COLLATE \"C\", (md5(jsonb_pretty(data)))\n               Sort Method: external merge  Disk: 75328kB\n               ->  Seq Scan on records  (cost=0.00..392443.11 rows=772692 width=84) (actual time=0.558..13193.046 rows=775553 loops=1)\n                     Filter: (parent_id ~~ '/buckets/build-hub/collections/%'::text)\n                     Rows Removed by Filter: 4\n Planning time: 0.117 ms\n Execution time: 14020.070 ms\n```\n14 seconds versus 0.2 milliseconds.. > Ok we need to fix that, thanks for investigating\n\"fixed\" :). This issue title is \"Do we need to support get_all with a wildcard parent_id?\" So I guess the answer to that is Yes. \nI uncovered that if you remove the DISTINCT from the get_all query, no tests broke and that was sad. \nSomething that's still a weird is that if you have two identical rows in records with only the parent_id being different, without the DISTINCT you'd get these duplicated. I.e. You'd see the same ID 4 times. With the DISTINCT you only see the ID 2 times. \nIf you want to I can attempt to add a test that simulates that. I.e. that you get records in a list that are indistinguishable. I.e. \n```\nself.storage.clear()\nnow = datetime.utcnow()\ndata = {'foo': 'bar'}\nself.storage.add(\n  collection_id='a', \n  parent_id='a1', \n  last_modified=now,\n  data=data,\n  id='myid'\n)\nself.storage.add(\n  collection_id='a', \n  parent_id='a2',  # Different\n  last_modified=now,\n  data=data,\n  id='myid'\n)\ntotal, records = self.storage.get_all(collection_id='a', parent_id='a*')\nassert total == 2\nassert len(records) == 2\nassert records[0] == records[1]\n``. @glasserc It sucked that removing theDISTINCT ` from the query didn't break any tests. And I agree that that indicates that we lack a test. \nIt's more pressing to me that, today, get_all will yield two identical records in the final JSON with no distinct difference. I.e. you do:\nnow = datetime.now()\nstore..create(id='peter', last_modified=now, collection_id='guys', data={}, parent_id='Bengtsson')\nstore..create(id='peter', last_modified=now, collection_id='guys', data={}, parent_id='Bennet')\nIf I then query for: get_all(parent_id='B*', collection_id='guys') I'm going to get:\njson\n[\n    {\"id\": \"peter\", \"last_modified\": \"2018-05-01T12:00:00\", \"data\": {}},\n    {\"id\": \"peter\", \"last_modified\": \"2018-05-01T12:00:00\", \"data\": {}},\n]\n(it's implicit that I don't need to know the returned records' collection_id because I just specified that in my get_all query)\nI think what I'm saying is that, let's think about that first and then we can either fix this or add a test case. . This is my attempt to file a followup to this comment where I found that selecting 10,000 records at a time from 709,000 records caused it to miss two records that had distinctly different ID and distinctly different last_modified, yet they got missed. . > I though we were precise at the milliseconds so as_epoch should be unique\nNo as_epoch rounds to what looks like the nearest second or something. \nFrom my database:\n```\nbuildhub=# select id, as_epoch(last_modified), last_modified from records where id in ('devedition_aurora_58-0b6rc1_linux-x86_64_as', 'devedition_aurora_59-0b6_win32_uk', 'devedition_aurora_58-0b6rc1_linux-x86_64_et', 'devedition_aurora_59-0b6_win64_bs');\n                     id                      |   as_epoch    |       last_modified\n---------------------------------------------+---------------+----------------------------\n devedition_aurora_58-0b6rc1_linux-x86_64_as | 1524241288164 | 2018-04-20 16:21:28.163601\n devedition_aurora_58-0b6rc1_linux-x86_64_et | 1524241288164 | 2018-04-20 16:21:28.16417\n devedition_aurora_59-0b6_win32_uk           | 1524240460834 | 2018-04-20 16:07:40.833634\n devedition_aurora_59-0b6_win64_bs           | 1524240460834 | 2018-04-20 16:07:40.834225\n(4 rows)\n. I'm not sure if it's worth it but we *could* skip the count part if the request is for the next page. E.g.\n$ curl localhost:8888/v1/collection/records\n< 200 OK\n< Total-Records: 1,234,567\n< Next-URL: http://localhost:8888/v1/paginate=somelonghashthing\n$ curl http://localhost:8888/v1/paginate=somelonghashthing\n< 200 OK\n< Total-Records: 1,234,567\n< Next-URL: http://localhost:8888/v1/paginate=anotherlonghash\n``\nIn this case, theTotal-Records` number could come from the cache rather than having to do another query again. \nGranted, I don't really know how the pagination works in Kinto but if the number really is only there for helping pagination then storing the first count in the cache would definitely make it possible to skip it for the next couple of pages. \nToo complicated or every-little-helps?\n. Another not-crazy idea is to keep a tally count of records per collection and parent. E.g.\n```python\nif not filters:\n    cur.execute(\"\"\"\n      select count from count_records where \n      collection_id=:collection_id and parent_id=:parent_id\"\"\", ...)\nelse:\n    # Crap! Have to count them manually.\n    cur.execute(\"\"\"\n      select count(*) from records where \n      collection_id=:collection_id and parent_id=:parent_id and\n      {filters}\n\"\"\", ...)\ncount, = cur.fetchone()  \nNow we have then count, now we just need to the the paginated records\ncur.execute(\"\"\"\n  select id, last_modified, data from records \n  WHERE collection_id=:collection_id and parent_id=:parent_id and {filters}\n\"\"\", ...)\nrecords = cur.fetchmany()\n```\nA trigger function would increment and decrement the count_records table. \nObvious caveat (apart from trigger functions being annoyingly subtle) is that if the particular kinto database isn't used ever without complex filters this is a wasted record keeping. . I extracted the query and compared. \nIn this database I have 183K records (almost) all in the same parent_id. \nBest execution times...\n\nThe query in master: 3477.01ms\nThis PR: 1313.54ms\nTwo separate queries (count and select): 118.88ms + 1.69ms\n\nWith filtering on &has_foo=true which returns 2 rows\n\nThe query in master: 160.06ms\nThis PR: 356.93ms\nTwo separate queries (count and select): 104.29ms + 322.52ms\n\nThis concludes what @glasserc been trying to explain to me; Sometimes the count is expensive when it has to be separate. Sometimes it's cheap when it can count the (few) returned records. \nThis is also an emphasis about your point above about trying to outsmart the query planner in Postgres. \nNot sure if this helps. Either way, we have choices of the best approach and they each depend and fit different environments/contexts. . \ud83c\udf89\ud83c\udf8a \\o/\nCan't wait to get this into the Kinto that buildhub is using. . > relying on Total-Records to do correct pagination is essentially always wrong\nYes! That!\nPagination is best done with a cursor-technique. Like, if there is a Next-URL header, keep going. Any client that tries to do...:\npython\nres = requests.get(url)\nall=[res.json()]\npages = int(res.headers['Total-Records'] / 10000) + 1\nfor p in range(pages):\n    res = requests.get(res.headers['next-url'])\n    all.extend(res.json())\n...is doomed to fail and burn. \nCategory 3 talks about \"could stick a constant value in there\" which I think is best avoided. I'd vote for something like:\npython\nif request.headers.get('prefer')=='include-total-records' or request.method == 'HEAD' or request.query.get('include')=='total-records':\n    response.set_header('Total-Records', self._count_records(collection_id, parent_id, filters))\nelse:\n    response.set_header('Total-Records-Excluded', \"See documentation if you want the 'Total-Records' header\")\n. Because I'm not sure where else to share this; here's a benchmark I did by manually breaking up the WITH collection_filtered AS (SELECT, COUNT) and two individual just SELECT COUNT(*) & SELECT id, data, ... LIMIT.\nhttps://docs.google.com/spreadsheets/d/1l7UgSJWxg_PRoCF1gIn8Y1gqODJxeT3YgDRmWaRpFdM/edit?usp=sharing\nWhat it shows is that for a collection with 10 records, it takes...\n\n1.46ms to do the combined COUNT + SELECT\n0.09ms to do just the SELECT\n0.12ms to do just the COUNT\n\nThat's approximately 10x difference. \nFor collections with 100 records, it's also about 10x difference. And for 1,000 records it's about 5x. \nWhen there was filtering, I edited 1 record per collection to have some JSON and then I used (data->'name' IS NOT NULL AND data->'name' = '\"peter\"') which means that each individual count would yield exactly 1 record. \nMore to come! In particular, this idea done properly in the kinto python code and just as a pure SQL exercise. . That spreadsheet \"proved\" that the individual SQL statements were a performance boost but I wanted to test this by running the whole thing end-to-end. That would give me a number of how long it takes to make, say, 100 GET requests via HTTP. \nUsing master:\n```\n\u25b6 python bench-queries.py 100 http://localhost:8888/v1/buckets/mybucket/collections/10/records http://localhost:8888/v1/buckets/mybucket/collections/100/records http://localhost:8888/v1/buckets/mybucket/collections/1000/records http://localhost:8888/v1/buckets/mybucket/collections/10000/records\n==================http://localhost:8888/v1/buckets/mybucket/collections/10/records==================\nSUM    1.7185s\n BEST   0.0126s\n WORST  0.0392s\n MEAN   0.0172s\n MEDIAN 0.0173s\n=================http://localhost:8888/v1/buckets/mybucket/collections/100/records==================\nSUM    1.9184s\n BEST   0.0151s\n WORST  0.0534s\n MEAN   0.0192s\n MEDIAN 0.0185s\n=================http://localhost:8888/v1/buckets/mybucket/collections/1000/records=================\nSUM    2.4350s\n BEST   0.0205s\n WORST  0.0322s\n MEAN   0.0244s\n MEDIAN 0.0242s\n================http://localhost:8888/v1/buckets/mybucket/collections/10000/records=================\nSUM    8.8490s\n BEST   0.0734s\n WORST  0.1346s\n MEAN   0.0885s\n MEDIAN 0.0817s\n```\nUsing my branch:\n```\n\u25b6 python bench-queries.py 100 http://localhost:8888/v1/buckets/mybucket/collections/10/records http://localhost:8888/v1/buckets/mybucket/collections/100/records http://localhost:8888/v1/buckets/mybucket/collections/1000/records http://localhost:8888/v1/buckets/mybucket/collections/10000/records\n==================http://localhost:8888/v1/buckets/mybucket/collections/10/records==================\nSUM    1.6176s\n BEST   0.0120s\n WORST  0.0482s\n MEAN   0.0162s\n MEDIAN 0.0159s\n=================http://localhost:8888/v1/buckets/mybucket/collections/100/records==================\nSUM    1.6034s\n BEST   0.0125s\n WORST  0.0210s\n MEAN   0.0160s\n MEDIAN 0.0160s\n=================http://localhost:8888/v1/buckets/mybucket/collections/1000/records=================\nSUM    2.3436s\n BEST   0.0177s\n WORST  0.0350s\n MEAN   0.0234s\n MEDIAN 0.0228s\n================http://localhost:8888/v1/buckets/mybucket/collections/10000/records=================\nSUM    8.7577s\n BEST   0.0706s\n WORST  0.1923s\n MEAN   0.0876s\n MEDIAN 0.0796s\n```\nFor each of the 4 different collections (named per their cardinality), the performance gain is 0.1 seconds. Not very impressive. But it's what we have to deal with. \nI think what's going on is that the more performant SQL query is just a tiny minority of all the other stuff such as the pyramind HTTP stuff, auth, and all these inserts for the timestamp. . I know I've said that we shouldn't worry about Buildhub's crazy 1M records per collection but at least this branch gives some hope.\ndev/KINTO/kinto  master \u2717\n\u25b6 time curl http://localhost:8888/v1/buckets/build-hub/collections/releases/records\\?_limit\\=1\n{\"data\":[{\"build\":{\"as\":\"z:/build/build/src/vs2017_15.8.4/VC/bin/Hostx64/x64/ml64.exe\",\"cc\":\"z:/build/build/src/clang/bin/clang-cl.exe -Xclang -std=gnu99 -fms-compatibility-version=19.15.26726\",\"id\":\"20181122182000\",\"cxx\":\"z:/build/build/src/clang/bin/clang-cl.exe -fms-compatibility-version=19.15.26726\",\"date\":\"2018-11-22T18:20:00Z\",\"host\":\"x86_64-pc-mingw32\",\"number\":1,\"target\":\"x86_64-pc-mingw32\"},\"source\":{\"tree\":\"releases/mozilla-beta\",\"product\":\"firefox\",\"revision\":\"4fcfd15911a112ef9444082b78bfcc41ec974216\",\"repository\":\"https://hg.mozilla.org/releases/mozilla-beta\"},\"target\":{\"os\":\"win\",\"locale\":\"zh-TW\",\"channel\":\"beta\",\"version\":\"64.0b12\",\"platform\":\"win64\"},\"download\":{\"url\":\"https://archive.mozilla.org/pub/firefox/releases/64.0b12/win64/zh-TW/Firefox Setup 64.0b12.exe\",\"date\":\"2018-11-23T06:11:35Z\",\"size\":44851760,\"mimetype\":\"application/msdos-windows\"},\"id\":\"firefox_beta_64-0b12_win64_zh-tw\",\"last_modified\":1543262158074}]}curl   0.01s user 0.02s system 0% cpu 33.094 total\nversus\n\u25b6 time curl http://localhost:8888/v1/buckets/build-hub/collections/releases/records\\?_limit\\=1\n{\"data\":[{\"build\":{\"as\":\"z:/build/build/src/vs2017_15.8.4/VC/bin/Hostx64/x64/ml64.exe\",\"cc\":\"z:/build/build/src/clang/bin/clang-cl.exe -Xclang -std=gnu99 -fms-compatibility-version=19.15.26726\",\"id\":\"20181122182000\",\"cxx\":\"z:/build/build/src/clang/bin/clang-cl.exe -fms-compatibility-version=19.15.26726\",\"date\":\"2018-11-22T18:20:00Z\",\"host\":\"x86_64-pc-mingw32\",\"number\":1,\"target\":\"x86_64-pc-mingw32\"},\"source\":{\"tree\":\"releases/mozilla-beta\",\"product\":\"firefox\",\"revision\":\"4fcfd15911a112ef9444082b78bfcc41ec974216\",\"repository\":\"https://hg.mozilla.org/releases/mozilla-beta\"},\"target\":{\"os\":\"win\",\"locale\":\"zh-TW\",\"channel\":\"beta\",\"version\":\"64.0b12\",\"platform\":\"win64\"},\"download\":{\"url\":\"https://archive.mozilla.org/pub/firefox/releases/64.0b12/win64/zh-TW/Firefox Setup 64.0b12.exe\",\"date\":\"2018-11-23T06:11:35Z\",\"size\":44851760,\"mimetype\":\"application/msdos-windows\"},\"id\":\"firefox_beta_64-0b12_win64_zh-tw\",\"last_modified\":1543262158074}]}curl   0.01s user 0.01s system 12% cpu 0.152 total\nSame output, obviously different headers, but it's 33 seconds vs. 0.152 seconds. . @Natim you're fast! \nAlso, does an Approval mean you're going to merge it? I have write permission to this repo by the way. . Calm down! :)\nI use Ubuntu 16.04 on my Digital Ocean servers and they only have 3.5 by default.. Ubuntu 16.04 still uses 3.5 and 16.04's end-of-life is April 2021. And as you said 3.5 is still supported until Sept 2019. \nBut it's already getting old. 3.7 is already a thing. Is f-strings the only benefit of dropping 3.5? I love f-strings and their clearly very performant but does that performance matters in the IO world of talking to a SQL database? Also, is it worth the pain of preventing some from upgrades just for f-strings? :)\nIf you drop support for 3.5, you can simply say to the people stuck in Ubuntu 16.04 etc. to just not upgrade any more. But what if there are security releases. Does Kinto promise any support at all? Are they documented?\nMozilla is Kinto's biggest consumer and Mozilla uses Docker almost everywhere for deployments so it's not at the mercy of slow-moving Linux distributions. \nBy the way, beyond f-strings, one place that needs a lot of attention when dropping 3.5 is the .travis.yml file.. I'm not a core contributor to Kinto but I would recommend with leaving this issue and filing a new one that lists the pros and cons. I can think of some to get started:\nPros\n- Only having to support 3.6 and 3.7 makes the surface area of debugging and support smaller for the core team. \n- f-strings are more performant than string.format.\n- Fewer Python environments in TravisCI means for faster feedback on CI from pull requests. \n- 3.6 and above preserve the insertion order in dicts. (But only 3.7 guarantees it)\nCons\n- Drops support for LTS Linux releases that are stuck on 3.5. E.g. Ubuntu 16.04.\n- Security releases become extremely hard to provide to people stuck on old pre-3.6-only platforms. \nWhat else? Are there any other backports required that we'd be able to drop in favor of built-ins?. I'm trying to figure out how to test this. Just trying to find my way around tox and venvs and stuff. Right now impatiently waiting for make tests to finish. . What's the procedure for merging etc.?. Not sure how to review this. I can't really look at the file. \nIs it documented that developers have to remember update this if they upgrade anything in package.json? Something similar to this?. This solved the problem I had. In my React app I keep an eye on the expires_at that gets set in localStorage. If my code deems the access token too old, it triggers the same code path as was used to redirect to the kinto authorize endpoint but with &prompt=none added. \nIf I try to go to http://localhost:8888/v1/openid/auth0/login?callback=http%3A%2F%2Flocalhost%3A3000%2F%23provider%3Dauth0%26tokens%3D&scope=openid%20email%20profile&prompt=none I get:\n< HTTP/1.1 307 Temporary Redirect\n< Location: https://peterbecom.auth0.com/authorize?client_id=R6R1t40cXQnuPQBdC8D83WOVyuUppZdw&response_type=code&scope=openid+email+profile&redirect_uri=http%3A%2F%2Flocalhost%3A8888%2Fv1%2Fopenid%2Fauth0%2Ftoken%3F&state=de6b3235872078a889f2c9134fe8c65c3167ee6819bf71289473570f8c927b74\nHowever, with the patch in this PR, that HTTP response becomes this instead:\n< HTTP/1.1 307 Temporary Redirect\n< Location: https://peterbecom.auth0.com/authorize?client_id=R6R1t40cXQnuPQBdC8D83WOVyuUppZdw&response_type=code&scope=openid+email+profile&redirect_uri=http%3A%2F%2Flocalhost%3A8888%2Fv1%2Fopenid%2Fauth0%2Ftoken%3F&state=de6b3235872078a889f2c9134fe8c65c3167ee6819bf71289473570f8c927b74&prompt=none\nThe only difference is the extra &prompt=none at the end of the URL. Auth0 needs that so that when my browser arrives there at https://peterbecom.auth0.com/authorize... it doesn't ever present a 200 OK. Instead the only thing that can and should happen is that it redirects back to http://localhost:8888/v1/openid/auth0/login with a code or with an error. . Note, I don't know where to add this to the documentation. Tips appreciated. . @leplatrem Hopefully all feedback addressed. . I restarted the PR build in Travis. It failed to connect to Github.com. I suggest we close this issue because switching to python-fastjsonschema is probably NOT the right package to use.\nTake a look at https://www.peterbe.com/plog/jsonschema-validate-10x-faster-in-python\nThe point of that blog post is that if you reuse an instance, with the same schema, for multiple validations you get a 10x speed boost with good old python-jsonschema and potentially even more so with python-fastjsonschema. \nBUT, if you look at the benchmark numbers and compare:\n```python\ndef f1(qs):\n    for build in qs:\n        validate(build.build, SCHEMA)\ndef f4(qs):\n    for build in qs:\n        fastjsonschema.validate(SCHEMA, build.build)\n``\nthis becomes a \"fair\" comparison where you *don't* reuse an instance. In this case the numbers point to thatpython-jsonschema` is faster:\n```\nFUNCTION: f1 Used 3 times\n    BEST   1247.9ms\n    MEDIAN 1309.0ms\n    MEAN   1330.0ms\n    STDEV  94.5ms\nFUNCTION: f4 Used 3 times\n    BEST   2032.3ms\n    MEDIAN 2033.4ms\n    MEAN   2143.9ms\n    STDEV  192.3ms\n```\nAlso, python-jsonschema looks like a very healthy project. It's mature. I base that one the fact that it been around since 2012. It's an active project with ~2,000 stars on GitHub. python-fastjsonschema on the other hand is very immature in comparison and has much fewer eyeballs on it. \n. Leave it to @leplatrem to decide. \nMore interestingly would be to file a new issue that measures how often the JSON Schema validation happens on a busy environment and if it'd be possible to use something like a module level cache of reusable instances. E.g something like this:\n```python\n_json_schema_validators = {}\ndef validate(record, schema):\n    # return validate(record, schema) # Old way\n    schema_hash = hash(schema)\n    if schema_hash not in _json_schema_validators:\n        _json_schema_validators[schema_hash] = create_json_validator(schema)\n    return _json_schema_validators[schema_hash].validate(record)\n``. In https://github.com/Kinto/kinto/pull/1941 I suggest it closes this issue even though the issue title doesn't really match the solution. . Django has a great \"solution\" to this, the perfectly named [django.exceptions.ImproperlyConfigured` exception](https://docs.djangoproject.com/en/2.1/ref/exceptions/#improperlyconfigured). \n. @glasserc I fixed the black problem. . Haven't dug in yet but the base.js you pointed to is inside a function called paginatedList and the doc string...\n* Fetch some pages from a paginated list, following the `next-page`\n   * header automatically until we have fetched the requested number\n   * of pages. Return a response with a `.next()` method that can be\n   * called to fetch more results.\nSo, if the idea is that you use...\njavascript \nfor (const page in client.paginatedList(args)) {\n  ...\n}\n...then we're fairly certain the total records is not needed or used. The pagination is done using Next-Page.\nPerhaps my brain is a bit end-of-day fried and there's a lot of mind-bending async in that code but it looks like the totalRecords isn't actually used. . > This PR badly needs a rebase\nDo you mean a squash? Isn't that done with the green button when it's fully approved? \nOr do you mean it needs the latest and greatest of master?\nIt's hard to remember what different projects have as best practices with active PRs and the landing protocol. . I can rebase this to get rid of unimportant small commits but keep stuff like the master merge and various others. But I don't think we're done yet :). @leplatrem It's a bit of a mess but check out the latest couple of commits related to documentation and whether it solves the figure out a way to nicely document that we Total-Records is now deprecated in favor of Total-Objects because of checkbox above. \nAlso, see the latest commit regarding how I broken up model.get_objects so we no longer need this count_only=boolean stuff. . > I let you rebase/squash/do whatever you want before pressing the merge button\nI don't think there are any commits that are worthy to have to be squashed. If I do try to selectively squash some of them, I will have to go through the same merge conflicts you went through, no? . What do you think? I'm confident this solution is faster but I'm not sure I can see the whole picture to judge if it's worth it. \nHere's how I benchmarked it\nI put in a print([data, schema]); raise Exception('break!') right befor the call to validate() and collected all the various data and the schema dicts that get used in the tests. Then I put this into a little test file which runs some a bunch of these calls a total of 10,000 times. There are only 4 unique schemas. Anyway, instead of taking 3.46 seconds it now does it in 0.18 seconds. So for this particular scenario of repeating the schema it's a 20x improvement. \nIn https://www.peterbe.com/plog/jsonschema-validate-10x-faster-in-python I discovered that if you make the instance and reuse it repeatedly it's a 10x improvement. In that benchmark/blog post the data blob was large and the caching of the schema was once. \nThe big question is, are the total number of distinct schemas, during the lifetime of a started Kinto server, so many that that _schema_cache module level global would build up too much memory.\n. > uwsgi will renew the worker automatically\nreally?! why would it do that? Is there like a timer that says how long the process can stay alive? Does it depend on the threading option?\nEither way, suppose you have 1,000 different schemas in a Kinto instance then you have 1,000 dicts and 1,000 dicts-as-strings. The Buildhub schema is 2,456 bytes as a string and 368 bytes as a dict and 1,056 as Validator instances. If there were 1,000 of these that are all different, it would mean 1,000 * 2,456 + 1,000 * 1,056 ~= 3.5MB in RAM. \nBasically, 1,000 different schemas cached would be 3.5MB per Python process/Gunicorn worker. That's extremely little memory for a production system running on state-of-the-art hardware. Also, 1,000 different schemas is probably an exaggeration. . @leplatrem \n\nand maybe a test?\n\nDo you have some suggestions as to how to do that?\nThere's no test_schema_validation.py or anything like that. The only tests that execute this code are tests/test_views_schema_*.py and they don't really care about implementation details within. . Changelog entry added. Mergy merge?. @leplatrem How did you make this change? Or rather, I suspect your version of hashin is old. \nI checked out master and ran this:\nbash\ncat ~/kinto/requirements.txt | xargs python hashin.py -r /tmp/reqs.txt\nIt produced this: https://gist.github.com/peterbe/c68d723ba7543b6ff5c51e9833994ff1\nNote that the package isn't called pyramid-tm but pyramid_tm and it seems an older version of hashin fails on that whereas the latest version corrects that. \nAnyway, instead of obsessing over how or when, I just went ahead and pushed a change too this PR. . Why are tox and wheel and setuptools in dev-requirements.txt? Is legacy or a good reason? . We can tidy up the mention of wheel, setuptools and tox later. wheel and setuptools are always installed, by default, in any new virtualenv. And tox is installed by Travis. \nOne thing I did on hashin was to mention these as \"dev\" requirements in setup.py. It's the minimal you need to bootstrap. \nThat means you can do:\nbash\ngit clone repourl\ncd repo\nmkvirtualenv --or-whatever-you-prefer\npip install -e \".[dev]\"\ntox\n. Let's zoom out a little... I jumped into this issue because, I guess, I'm interested in usage of hashin :)\nI think it's a mistake to use hashes. Yes, for projects like kinto-dist that tries to put together kinto, with some other specific stuff, in a very deterministic way. \nI think we should remove ALL requirements files and move all listings of dependencies in the setup.py. Then, things like pip install -e \".[dev]\" will work perfectly. It'll serve to do manual testing and for doing tox testing in CI. . So the requirements.txt is only used for CI?? \nArguably the name is misleading and it's a noisy pain. I much prefer the Python lists we currently have in setup.py. \nIf there are specific versions of stuff we need/want purely for unit and functional tests we should move that into setup.py and add another key/value to the extra_requires and use pip install -e \".[test]\" (or something) in tox/travis. . So then let's just close this issue. \nSuppose that we move the list of know-good-requirements-for-shipping-a-docker-image was a Python list inside the setup.py then Dependabot's automation wouldn't be able to help us test that Kinto builds with the latest versions of stuff. . The comment in migration_018_019.sql about why the use of a specific collation would be useful here. . Would be nice with a comment here that justifies this hack. . ditto. Why the os.path.abspath? os.path.dirname should always give a valid directory path. . nit: Ending a function without return None is the same as ending the function with a return None. . nit: If the metadata table already existed, it's not a guarantee that the column order is exactly 'name', 'value'. A safer INSERT statement would be:\nINSERT INTO metadata (name, value) VALUES ('permission_schema_version', '2');. I'm confused. Why isn't this COLLATE \"C\" too?. No need to (object) in any py 3 code. . Also, is MigratorMixin a better name to indicate to the code reader how you're supposed to use this?. This should probably be raise NotImplementedError('method not overwritten'). Weird that a privately named method is expected to be overridden. . not necessary. This looks dangerous. You create an instance of Migrator but mutate it within the tests. \nIt'd be much better to ...:\npython\n    def setUp(self):\n        self.migrator = Migrator()\n        ...\n. Why repr()? Won't it already be a perfectly fine string object?. Arguably, perhaps all logging you should be captured. E.g.\npython\n    @mock.patch('kinto.core.storage.postgresql.migrator.logger')\n    def setUp(self, mocked_logger):\n        self.migrator = Migrator()\n        self.mocked_logger = mocked_logger. This is now repeated in 3 of the 5 tests so it should probably be mocked in the setUp method. . What I mean is; If there's a strong reason for using os.path.abspath it should be a code comment that explains why. If there isn't a reason, it can be deleted and only use os.path.dirname(__file__).. Indent this whole block one to the right and avoid the second connection creation. . ditto about use of abspath. \ud83d\udc4d . Awesome!. I get it now. The access token is \"shipped\" from the kinto server to the kinto-admin SPA by putting the tokens, as JSON, in a hash on the URL. I totally didn't realize that before. \nHopefully the access_token is sufficiently shortlived since this might get stuck in log files. . OAuth or Auth0?. I checked my Nginx server and it doesn't write down anything in the log files after the # character. Because, I guess, the browser doesn't even bother sending that as part of the URL to server. Nothing to worry about then. . How would I get that record? Fetching it? E.g. SELECT data FROM records where id=:object_id AND parent_id=:parent_id AND collection_id=:collection_id ?. There might be some further work to do here. \nThis early exit allows us to being able to skip the COUNT query since the SELECT query yielded 0 results anyway. \nThe reason for why I didn't use the exact filter for the COUNT and the SELECT was because of this test:\nhttps://github.com/peterbe/kinto/blob/51c7bf9ec9eb1f89d7e7d3a015429f2bc525551d/kinto/core/storage/testing.py#L1217-L1218\n(there might be more like this!)\nIn that test it does a get_all(include_deleted=True, ...) and it expects the number of records to be different from the total count. \nIsn't that strange? If you include_deleted=True why should the total count be always filter out the deleted records??\nIf that test is wrong, I can rewrite the two queries so that the SELECT and COUNT uses the exact same WHERE clause. Then, if we do that we can do the COUNT first (slightly faster since it's just an integer) and if it's 0 we can skip the SELECT and just return an empty list. . @glasserc Is it worth taking the risk perhaps?\nIf the first thread (who manages to make the successful insert) does a delete right afterwards, they better do so quickly. Really quickly :)\nWhat I'm alluding to is that swallowing that risk and doing something like:\npython\nwas_there = self.get(collection_id, parent_id, object_id)\nraise UnicityErrror(was_there)\n...will be a pretty decent solution. \n. This is unrelated but it stood out so I fixed it. . TypeError: __init__() got an unexpected keyword argument 'validator'. prompt = colander.SchemaNode(colander.String(),\n                                 validator=colander.Regex(\"none\"),\n                                 missing=colander.drop)\nworked. Either way, I think that line never belonged there, right? It should be part of 12.0.0 and the line is there now. Resolved?. What do you want to do with that? Should there be a \"Count of collections\" section in some file, for example?. Fixed in the next push.. Did you fix this?. > In Python 3.6 dict keys are stable right?\nYes but not guaranteed. Unlike 3.7. . Why don't these two have hashes?. Lemme investigate if this is a bug in hashin.. Lemme investigate if this is a bug in hashin.. Is this just cleaning up whilst-you're-at-it?\nAlso, why is it not using core.storage.DEFAULT_DELETED_FIELD?. ",
    "elelay": "I've removed the custom id, to only use generated ids (I was getting errno=110 on occasions). Now I'm pretty sure I only get 201 or 500 responses.\n. I'll try Tomorrow. \n. No error with the PostgreSQL backend.\n. This may be too much mutex!\nI've switched to running from source:\n- default config, simply increased max_requests to 200\n- make serve\nWith master I get the exceptions listed in description but my program terminates.\nWith 759-fix-memory-mutual-exclusion I don't get the exceptions BUT my program doesn't terminate: cpu goes idle, but 3 out of 48 batch requests don't return. As soon as I interrupt kinto (Ctrl-C in its console) my program terminates (with socket errors from the returning requests).\nThere are no errors in the log file. Counting \"201\" lines, I get a total of 8438, while there are 8647 items to insert, so the program is stuck before it has inserted everything.\n. More data:\nI've lowered the number of tickets to 400 (2 batches of 200 tickets) and it's still gets stuck for one of them.\nI've got an hyperthreaded dual-core (appears as 4 cores in htop).\nOnce kinto is stuck and I interrupt my program, I can re-run it with more tickets and it all succeeds (as if the stuck kinto threads wouldn't get used anymore so wouldn't pose a problem on subsequent batch inserts).\n. I can send you my semi-private data and upload program, if you'd like to play with it on your side\n. #949 was the rational to change the default config (fails when no network).. Contrary to what I said in the description, it's visible in kinto/kinto-server:latest. I can't find where in the mocks is the non-unicode password stored.\nBecause this existing test  should fail.. Well, now tests do fail.... @glasserc, @Natim indeed, tests do use the memory backend, which doesn't touch the given record\nOn the contrary, the postgres backend sneakily uses ujson.dumps to pass the record as json string to PostgreSQL.\njson.dumps({'hello': 'hach\u00e9'.encode(encoding='utf-8')}) explodes, while ujson.dumps({'hello': 'hach\u00e9'.encode(encoding='utf-8')}) happily returns '{\"hello\":\"hach\\\\u00e9\"}'. \nFollowing the PUT to create account:\n - the password is hashed and put in the record as bytes\n - with memory backend, the record is stored as-is in memory  => we get bytes in authentication.py\n - with postgres backend, the record is converted to utf-8 JSON => we get str in authentication.py\nNow I think the right way to fix the issue is not in the authentication as I did, but storing the hashed password as string, explicitly calling decode on bcrypt's result, which is base64 anyway. This way, tests and production work.\n\nDo you concur? \n\nIs it ok if I force-push the new solution in this PR or do I open a new one?\n\n\nmaybe the memory backend should call record =  ujson.loads(ujson.dumps(record)) before storing for consistency with the postgres backend (yes it adds the conversion cost),\n\nas a side note, performance may be gained by setting ujson.ensure_ascii to false in postgres backend, if it's supported by psycopg2,\n. @glasserc \nIs there an option for ujson to let us not serialize bytes, but only the usual booleans, integers, floats, strings, lists, dicts, and None?\n\n\n\nNo, there isn't : str and bytes are handled the same way - lines 543,550.\nBut ujson will raise on non utf8 bytes, though, so it's safe-ish.\nTo my mind, what should be enforced is consistency between memory and postgresql storage, by calling record = ujson.loads(ujson.dumps(record)) before storing in the memory backed (in memory.Storage.create and memory.Storage.update.\nIt would have caught this issue and would also catch non-dict objects, etc.. Great, thanks!. @glasserc  good idea: the specification for records is then a dict that is JSON serializable according to the builtin json module. \nAnything that is accepted by json would be accepted by ujson. With the already excellent test coverage, the more lax behaviour of ujson would be hidden as a production optimisation.\nI'll try it out and let you know.. @leplatrem \n\nWe should probably confirm that with updated figures.\n\nI see an up to 5x speed improvement (decode 256 UTF8 strings) for ujson/json, with an average of 2x for encode and decode.\nFollowing table is the output of python tests/benchmark.py with Python 3.6.1. It lists calls/s (the more, the better).\n|                                                                               | ujson      | yajl       | simplejson | json       |\n|-------------------------------------------------------------------------------|------------|------------|------------|------------|\n| Array with 256 doubles                                                        |            |            |            |            |\n| encode                                                                        |   22485.14 |    8507.37 |    5752.49 |    6314.80 |\n| decode                                                                        |   35739.87 |   15104.25 |   14935.88 |   15758.40 |\n| Array with 256 UTF-8 strings                                                  |            |            |            |            |\n| encode                                                                        |    3941.41 |    3788.01 |    2562.49 |    2573.70 |\n| decode                                                                        |    2675.51 |     918.95 |     536.55 |     522.48 |\n| Array with 256 strings                                                        |            |            |            |            |\n| encode                                                                        |   51644.13 |   21904.67 |   23306.93 |   25884.61 |\n| decode                                                                        |   33265.51 |   25833.36 |   40359.65 |   29960.73 |\n| Medium complex object                                                         |            |            |            |            |\n| encode                                                                        |   15259.40 |    8426.39 |    5482.92 |    7910.24 |\n| decode                                                                        |   14702.96 |    8594.63 |    8479.10 |   10029.45 |\n| Array with 256 True values                                                    |            |            |            |            |\n| encode                                                                        |  159535.24 |  172716.43 |   78707.41 |   96372.96 |\n| decode                                                                        |  234235.84 |  109203.62 |  142965.52 |  168322.68 |\n| Array with 256 dict{string, int} pairs                                        |            |            |            |            |\n| encode                                                                        |   20273.73 |   15388.58 |    4463.77 |    9060.82 |\n| decode                                                                        |   17670.78 |   11974.63 |    9352.05 |   12167.52 |\n| Dict with 256 arrays with 256 dict{string, int} pairs                         |            |            |            |            |\n| encode                                                                        |      76.93 |      56.22 |      15.78 |      33.29 |\n| decode                                                                        |      44.10 |      34.39 |      27.66 |      33.44 |\n| Complex object                                                                |            |            |            |            |\n| encode                                                                        |     644.05 |            |     554.48 |     586.59 |\n| decode                                                                        |     591.66 |     307.53 |     226.03 |     219.96 |\n. > @glasserc  But what I'm most worried about is that we would serialize a bytestring that seems OK until by chance it contains some non-UTF-8 encoded text and then failing.\n+1 this is why I took the trouble to implement this PR.\nNow, choosing between ujson and json could maybe be implemented more elegantly. Is it possible to mock an attribute in any future instance of a class or sthing? Then we could switch the json attribute of StorageBase before tests and not have to explicitly configure it.. Meanwhile, I'm modifying ujson to add a 'reject_bytes' parameter.\nIf it's merged, it would allow us to always use ujson, with this parameter always True.. Thanks @glasserc. I think all nits are addressed.. yes!. UnicodeDecodeError would make sense, but it's OverflowError for any python to json error, actually. It seems rather specific to ujson. Do you want that in the tests?. ",
    "zeddmaxx": "@leplatrem I would like to work on this, could you please elaborate on what exactly needs to be done?\n. ",
    "mvalipour": "Sure, I'd love to.\nin regards to the name, surely we could detect the fact that the field following in_ is a string field and not an array, therefore interpret it differently? You are right, I was originally confused by array fields.\n. Once, we are all happy with the solution, I can go ahead and add documentation, etc.\n. @Natim I thought contains might be a confusing term. I'm happy to debate this, but maybe like_ or even search_ will speak better about what it does?\n. @Natim Am I right assuming this change is not classified as a change in HTTP API ?\n. I felt it's naive to have this regex listing exactly what is in Comparison enum.\nOnly downside is that it also includes eq_ as a prefix, which surely should be fine?\n. very cryptic to have the state of the world in a for loop for our unit tests. do you agree that it benefits us to have a nicely readable and solid list of records instead?\n. Yes, that's were I was stuck. There doesn't seem to be any unit-tests running in postgres mode. So is covering it in test_storage enough?\n. fair enough. done.\n. ",
    "anna-liao": "I would like to work on this for my outreachy contribution.  Can you assign to me?\n. Thanks!  I still need to look into how resources work in Kinto.  I understand what the output should be for a given input, but need to figure out which modifications to the code need to be made.  Primarily the advice I received from glasserc is to look through the docs for resource and also in kinto/views/foo.py... which, now that I'm looking it up, I don't see a foo.py, unless I read that too literally.  If you have any suggestions of where to look, that would be helpful.\n. @leplatrem Thanks for the info!  Understandably, this contribution will be too late for Outreachy, but I still want to work on it.  I'm going to look into fixing it and also writing a test for it.\n. Has this been fixed already?  I just checked and it is no longer throwing a \"400 Bad Request\" error.\nhttp PUT :8888/v1/buckets/bid/groups/atest --auth token:blah\nHTTP/1.1 201 Created\nAccess-Control-Expose-Headers: Retry-After, Content-Length, Alert, Backoff\nContent-Length: 156\nContent-Type: application/json; charset=UTF-8\nDate: Fri, 28 Oct 2016 21:34:13 GMT\nEtag: \"1477690453885\"\nLast-Modified: Fri, 28 Oct 2016 21:34:13 GMT\nServer: waitress\n{\n    \"data\": {\n        \"id\": \"atest\",\n        \"last_modified\": 1477690453885\n    },\n    \"permissions\": {\n        \"write\": [\n            \"basicauth:12e00e7821f216ae3dac21c3f996b2fd123ed72c6b8245cea6cd3e7c9dde7a7e\"\n        ]\n    }\n}\n. @Natim Is there an example of a similar test in the repo?  I have used unit tests, but not sure how the test structure works in this repo.\n. oh, nevermind, I see the tests now under kinto/tests so will take a look through that.\n. @leplatrem Thanks for the feedback.  I would still like to look into this.  Sorry for the delay.. thanks, appreciate the nice comment to clarify and really appreciate all of you for taking the time to work with newbies.  I feel like the structure of how this all works is probably quite standard, but new to me.  I would like to learn, and hopefully once I have spent some time with it, will be able to contribute more to this project.  I have extra time during the holidays, so going to spend some quality time looking into this.  Cheers!. ",
    "kulshekhar": "I've been exploring kinto and it looks very promising - except for the authentication story. I came across this issue, took a look at portier & kinto-portier and think that this looks like a great solution.\nI'd like to do what I can to help get this in. Since I'm not familiar with the codebase, if someone can tell me what needs to be done, I can give it a shot!. @leplatrem I'm new to kinto but if I had a little bit on how to start exploring & using the accounts API (just a paragraph or two), I could play with it and start documenting it.. Done. I set the permissions up from the admin UI while testing but seeing that this works for you, I probably did something incorrectly. I'll try this from scratch again right away.\nThanks!. Will do. @Natim This works as you described. The issue was that I had set permissions based on the auth token that appears at the top on the kinto-admin UI. Using the value obtained from /v1/ as you advised did the trick.\nThanks :smile: . While taking the screenshot, I realized that kinto-admin for this user was running against https://kinto.dev.mozaws.net/v1/ instead of http://localhost:8888/v1/. After fixing that, the tokens are indeed the same.\nSorry for the noise :disappointed: . > I don't think we should put the built-in account plugin too visible until it becomes enabled by default.\nIt was my understanding that by the time this branch is merged with master, this plugin would become the default and all related documentation needs to be updated to highlight this.\nIf this is not the case, it'd be helpful to have some pointers to which docs need to be updated.\nMy initial list consisted of the following:\n\ndocs/core/quickstart.rst\ndocs/concepts.rst\ndocs/faq.rst\ndocs/configuration/settings.rst\ndocs/tutorials/first-steps.rst\ndocs/api/1.x/authentication.rst\n. \n",
    "sahildua2305": "@almet Do you mean the link given in sidebar of http://kinto.readthedocs.io/en/latest/index.html? It works for me. Am I taking it wrong?\n. @Natim how do we plan to take input for the salt (or the pattern) from the user?\n. @leplatrem did you mean to include the options commented out in /config/kinto.ini to kinto.tpl?\n. Just checking in - @shreab373 are you still working on this? I'll be interested in working on this otherwise.. ",
    "juhieta": "After disabling the plugin everything (including DELETE) works normally again, so somehow the problem is related to the plugin.\n. Hi @leplatrem, thanks for looking at this! I'll gather the steps and also the permissions attached to the bucket, maybe that also has some effect.\n. Hi, and sorry about the delay, I'll re-test asap (should have a chance to look at this latest in two weeks). I had to disable the history plugin temporarily, but would be great to get it working.\n. ",
    "amalleIntesens": "Does some of my heroku logs correspond to kinto logs ? (and should also be in sentry)\nOr are they all heroku ? (for example the heroku[router] ones don't seams to comes from kinto (or does they?)) \n. ",
    "oronsan": "can I please work on this feature?\nI want to add a command to the cli first\nThank you\n. thanks, @leplatrem \nI appreciate that :)\nI saw that util.py file you mentioned, and wasn't sure if it fits there\n. I am done working on the feature, according to the guidelines.\nPlease review my work @leplatrem  \nthank you :)\n. is it possible that there's a problem with the build process with the docs job?\nI didn't do anything in particular to make to break, and it's not passing\nI noticed that other recent build jobs have this issue\nthank you\n. I did copy, but not exactly\nthe code there assumes the format is source_url;dest_url i.e:\n/buckets/sbid/collections/scid;/buckets/dbid/collections/dcid\nand my code only expects a single url.\nso I only took the relevant tests from there\ndo you think it's necessary to have source;dest format?\n. Well, I'm trying to figure out how the tests for the history plugin work.\nI'd love it if you have anything that can help me, even a more elaborate explanation \nabout the existing tests\nThank you!\n. done, please review\n. done, please review\n. Ok, I got it.\nFound a different solution with assertRaises()\nThank you for the tip :)\n. Ok, so I switched back to pytest.raises and got it working now :)\n. Is this the best way to call the history endpoint from inside the code?\nI am sure there is a more elegant way, using the request object or registry object,\nbut I couldn't find it\nplease suggest a better way to do that\nthank you :)\nOron\n. Thank you for the review @leplatrem \nI changed the files according to your requests\n. ",
    "VarnaSuresh": "Can I work on this?\n. @Natim I still have to make the changes right?\n. @Natim They are all there. Was just wondering because you said you had merged it by mistake.\n. @Natim The path looks correct to me. But it is causing an issue.\n. @Natim Can I just move the test to the tests/plugins folder where all the other plugin tests are are configure them in the second way?\n. ",
    "essymo": "Added some instruction on how to install postgresql 9.4+\n. ",
    "d1ndra": "@leplatrem I'd like to work on this. How should I go about it?\n. Should I just be changing the prefixes in initialization.py? Did that, but running make tests gave 3 errors all referring to the 3 (cache, storage, `permission).\n. @leplatrem Made requested changes.\n. ",
    "suraj1074": "@Natim So basically we need to make this change in the file https://github.com/Kinto/kinto/blob/master/kinto/plugins/default_bucket/init.py#L172\nsecret = settings['default_bucket_ID_salt'] \nif secret == None:\n    secret = settings['userid_hmac_secret']. ",
    "chinchaun": "Hello there i was looking at this issue and trying to fix it, i have a question related testing the changes,\nin the test files the logic is been mimic of the function default_bucket_id\n``` python\ndef test_default_bucket_exists_and_has_user_id(self):\n        bucket = self.app.get(self.bucket_url, headers=self.headers)\n        result = bucket.json\n        settings = self.app.app.registry.settings\n        hmac_secret = settings['userid_hmac_secret']\n        bucket_id = hmac_digest(hmac_secret, self.principal)[:32]\n    self.assertEqual(result['data']['id'], str(UUID(bucket_id)))\n    self.assertEqual(result['permissions']['write'], [self.principal])\n\n````\nbut the method is not been invoked, i don't have to much experience in python so i don't know how to invoke the method that is need to be tested of the new behaviour implementation or maybe i'm missing something.\nKind regards. ",
    "noisedispatch": "Hi @leplatrem, I would like to work on it but this is my first timer PR, do you think I'm qualified? Thanks a lot!. Hi @leplatrem ! Thanks for your approval and encouragement! A quick question, when I followed the tutorial to install kinto from source, I found an error here:\nnoisedispatch:~/workspace (master) $ make serve\n.venv/bin/kinto --ini config/kinto.ini init\nTraceback (most recent call last):\n  File \".venv/bin/kinto\", line 6, in <module>\n    from pkg_resources import load_entry_point\n  File \"/home/ubuntu/workspace/.venv/local/lib/python2.7/site-packages/pkg_resources/__init__.py\", line 3017, in <module>\n    @_call_aside\n  File \"/home/ubuntu/workspace/.venv/local/lib/python2.7/site-packages/pkg_resources/__init__.py\", line 3003, in _call_aside\nimport platform\n    f(*args, **kwargs)\n  File \"/home/ubuntu/workspace/.venv/local/lib/python2.7/site-packages/pkg_resources/__init__.py\", line 3030, in _initialize_master_working_set\n    working_set = WorkingSet._build_master()\n  File \"/home/ubuntu/workspace/.venv/local/lib/python2.7/site-packages/pkg_resources/__init__.py\", line 661, in _build_master\n    return cls._build_from_requirements(__requires__)\n  File \"/home/ubuntu/workspace/.venv/local/lib/python2.7/site-packages/pkg_resources/__init__.py\", line 674, in _build_from_requirements\n    dists = ws.resolve(reqs, Environment())\n  File \"/home/ubuntu/workspace/.venv/local/lib/python2.7/site-packages/pkg_resources/__init__.py\", line 853, in resolve\n    raise DistributionNotFound(req, requirers)\npkg_resources.DistributionNotFound: The 'transaction<2' distribution was not found and is required by kinto\nI checked the release note of transaction and make a change: https://github.com/noisedispatch/kinto/blob/master/setup.py#L29. After which I can run kinto locally.\n. ",
    "rmorris1218": "Happy to help with this. For clarity, would it be a setting to only send backoff header under heavy load if, say, random.random()*100 < backoff.percentage?. ",
    "jvce92": "Hi @leplatrem, is this issue still available? This is my first attempt on contributing to a project. Just to make sure I understand what needs to be done, in case backoff is not none in (https://github.com/Kinto/kinto/blob/cad62f33cd668857a53820b2818c22ddd8602ce8/kinto/core/initialization.py#L134-L135) a random number is generated and the backoff header is sent only if random() < backoff percentage, right?\nAlso, we'd need a new field on the configuration file (e.g. kinto.backoff_percentage), right? . Do you have any idea how this could be tested?. ",
    "jkieberk": "Hey @leplatrem, first time attempting to contribute to an open source project, so not sure how much  changing around the structure of a file is acceptable in this instance where I'm new to a project.\nWould you like to keep the general layout of the kinto.tpl file? For example, my plan was to go through the configuration file and copy the general structure of that to try and make the configuration layout consistent across files. \nWhat I'm hung up on is that I see someone has added a \"Production settings\" section to kinto.tpl (Line 85), that has the setting kinto.http_host which is also in the Scheme, Host, and Port section.\nIn situations like this, should I move the settings to their own sections (kinto.http_host and kinto.http_scheme for example) or keep them where they are?\nThanks!. Sounds good! :)\nOne more question, is there a style guide somewhere? Haven't been able to find one looking through the docs.. /config/init.py throws a KeyError: u'cache_prefix' even though cache_prefix (line 42) is commented out? \nI'm able to test with 0 errors with the original file.. ",
    "heron182": "Hey all!  That seems like a good first PR for me \ud83d\ude04 , is it still up for grabs ? . Guys please let me know if there\u00b4s any other changes needed and i\u00b4ll fix the unittest \ud83d\udc4d . Yo guys, please let me know if there\u00b4s any other changes needed.  I made the requested changes and added an example for endpoint disabling as for #1295 . No problem, thanks for all your input \ud83d\udc4d . Ah ok np, you mean just add the seetings like that?\n```\nkinto.eos\nkinto.eos_message\nkinto.eos_url\n``. Yep i think it\u00b4s a good idea . Hmm I\u00b4m not sure I understand it.\nThe documentation examples are incorrect ?\nIt should be something likekinto.record_record_article_delete_enabled = false ?(mind the two \"record\"). \nIf the examples on the documentation area not yet reflecting the new changes (#710) I think it\u00b4s ok if we just skip that part.. Yeah I\u00b4m waiting on @leplatrem response aboutkinto.collection_article_delete_enabled = false`  setting. If the documentation is not correct about those settings I think it\u00b4s ok to remove it from kinto.tpl, otherwise I can write a correct example, it\u00b4s just a i didn\u00b4t quite understand what\u00b4s incorrect.. ",
    "pocmo": "We have been using this in Fennec, so I guess this has worked before. We will need to ship an update that just selects attachment.original and therefore all fields. Or we deploy a fix to the kinto server soon. :)\n. ",
    "callahad": "Just for the sake of cross-referencing, it looks like work on this is happening in https://github.com/Kinto/kinto-portier/pull/1. ",
    "adngdb": "Support for Github authentication would be nice to have, especially if this makes it easier to install / use than using a home-made plugin like proposed on the tutorial. :). ",
    "VamsiSangam": "I am a noob. I made the necessary changes in my branch in my forked version (VamsiSangam:edits). So, do those commits automatically get included in this pull request to merge VamsiSangam:edits with Kinto:master?. Oh yes, they did. Yeah @leplatrem, it is awesome \ud83d\ude04 ! Sure, thank you! \ud83d\ude04 . ",
    "PeriGK": "Hi there,\nLooks like a simple change, the aforementioned IP is only located in a few places. Just checking though, do you mind if I just replace the IPs as is, or maybe \"centralise\" it a bit?\n\ngrep -rn \"0.0.0.0\" *\ndocs/troubleshooting.rst:134:port is already in use: ``listen tcp 0.0.0.0:5432: bind: address\ndocs/tutorials/authentication-github.rst:118:    serving on http://0.0.0.0:8888\nkinto/config/kinto.tpl:7:host = 0.0.0.0\nloadtests/server.ini:19:host = 0.0.0.0\ntests/test_configuration/test.ini:7:host = 0.0.0.0\n\nCheers,\nP.. Cool, I can have a look :). Hi @gabisurita ,\nI have updated the changelog as well.\nThanks,\nP.. ",
    "m-charlton": "I can do this. Looks like I've caused a problem on one of the tests for Py3.4 - investigating. I see the problem, I will submit the fix tomorrow.. mocks now inject modified paths to the calls to random used in the implementation files.\n. O.K - I can set multiple tests at my end or, come up with an alternative approach.. Sure, will do. Apologies fro breaking the build earlier on.. No worries, I'm free to do some more fixes so I can get to know the \ncode base better. Going to spend some time getting my test environment \nworking, had some gyp with getting a postgres server woking correctly. . ",
    "tusharmakkar08": "Is this issue fixed? . ",
    "delijati": "There are two ways of creating a valid json api with openapi (swagger) support:\n1.) swagger.yaml (use yaml, we need to read it) as master + some validation [1]\n2.) cornice + colander as master and create a swagger.yaml file [2]\nEvery way has its advantages and disadvantages.\n[1] https://github.com/pipermerriam/flex or https://github.com/striglia/pyramid_swagger\n[2] https://github.com/Cornices/cornice.ext.swagger. @gabisurita \n\n\nYes every request/ response against the spec. I looked bravado_core up, they seem also to \n     provide validation of requests and responses. (Sorry i assumed you have no validation at all)\n\n\ncornice.ext.swagger is the other way (generating swagger.yaml) from colander schema. That \n    makes only sense if you already use or have plans to use cornice. I'm also not sure if the \n    generated swagger.yaml is feasible for yours needs.\n\n\nFor the YAML part, swagger2.0 understands json, yaml:\n```python\nclass YamlRendererFactory(object):\n    def init(self, info):\n        pass\ndef __call__(self, value, system):\n    response = system['request'].response\n    response.headers['Content-Type'] = 'application/x-yaml; charset=UTF-8'\n    return yaml.dump(value).encode('utf-8')\n\ndef includeme(config):\n    config.add_renderer(\n        'yaml', 'pyramid_swagger.api.YamlRendererFactory'\n    )\n`. As you mentioned that kinto is already usingcornicei integratedcornice.ext.swagger(with a minor patch) and the resultingswagger.json`` looks promising.\nswagger_json.txt\n. @gabisurita I hacked a small plugin together, check it out if you like.\n```bash\n$ pip install git+https://github.com/delijati/kinto_swagger.git\n$ vim config/kinto.ini\nkinto.includes=kinto_swagger\n$ firefox http://0.0.0.0:8888/v1/swagger \n`. @gabisurita i tried it on themasterofkinto`` with only two plugins activated:\nbash\n$ git clone https://github.com/Kinto/kinto.git\n$ cd kinto\n$ virtualenv env\n$ env/bin/pip install -e .\n$ env/bin/pip install git+https://github.com/delijati/kinto_swagger.git\n$ kinto init\n$ kinto migrate\n$ vim config/kinto.ini\n...\nkinto.includes = kinto.plugins.default_bucket\n                         kinto_swagger\n...\n$ kinto start\n$ firefox http://0.0.0.0:8888/v1/swagger\nBtw. the error seams to be a older version of cornice_swagger. I also fixed the path to the swagger js files in kinto_swagger.. 1. How should responses be documented?\nI think currently cornice does not support that @leplatrem ? Maybe this can be added as docstrings and extracted from there?\n2. Patch requests should have a body, but that doesn't show on the documentation\nMaybe the body schema is not defined right see 3. \n3. How to document query strings?\nThat is a cornice feature and they are extracted. (cornice docs \"Schema validation\")\n```python\nclass Query(MappingSchema):\n    yeah = SchemaNode(String())\n    mau = SchemaNode(String())\nclass RequestSchema(MappingSchema):\n    body = Body(description=\"Defines a cornice body schema\")\n    querystring = Query()\n```\n4. Does it allows customizing the tags? I think putting all the operations under the tag buckets may be confusing, specially when using client generators.\nCurrently it only does tag_name = service.path.split(\"/\")[1] so sure this can be improved somehow.\n5. How to set up authentication?\nYou mean this? https://github.com/swagger-api/swagger-ui#header-parameters\n6. Finally it doesn't seems to generate valid swagger, but I understand it's just a sketch.\nNever checked that ;)\n. ",
    "windwww-zz": "I guess it is related to #1008 too.. I just down the version of pyramid with:\npip install \"pyramid==1.7.3\"\nit solved.. ",
    "vsokoltsov": "Could you please provide more information about that?. ",
    "sk0g": "I'd like to solve this issue, if I could. I checked the logs.py, and from what I saw, the access control failures aren't tested for right now. Am I off track already?. So you're finding the permission type in 50+, but at 53 it's testing whether the user is allowed to access/ change the file, or whether further testing has to be done (in case the permission is dynamic, and the permission will be checked while running.) Then some of the fail cases show up at 77, 85. \nIs there an actual permits method, or did you mean permission? \nWould a block of code saying if not allowed or not allowed_to_create, log something work there? Obviously, after determining the need to actually log something, we could again check to see which one to log, and then add on log statements in logs.py to facilitate logging.. ",
    "g-k": "It might be useful in dev.\nFor stage and prod, we usually have nginx log to a file:\n```\n    location /cspreport {\n        access_log /media/ephemeral0/nginx/logs/CSP.log CSP;\n        proxy_pass http://127.0.0.1/csp-proxy;\n    }\nlocation /csp-proxy {\n  access_log off;\n  return 204;\n  allow 127.0.0.1;\n  deny all;\n}\n\n```\nor nginx w/ openresty:\nlocation = /__cspreport__ {\n        access_log /media/ephemeral0/nginx/logs/CSP.log CSP;\n        lua_need_request_body on;\n        rewrite_by_lua 'ngx.exit(204)';\n    }. ",
    "Osmose": "Moved: https://github.com/Kinto/kinto-admin/issues/388. ",
    "ghost": "hi, i'm a newcomer, i wanted to take up this bug, could you guide me through it?. i'm getting this error while installing and  /tmp/pip-build-8aitcx1c/ujson/ doesn't exist. Go ahead :). ",
    "suryajoshi007": "Would love to work on this. Can i get started? . Ok will file it as soon as possible:)\nOn 10-Sep-2017 10:57 PM, \"R\u00e9my HUBSCHER\" notifications@github.com wrote:\n\nYes please go ahead, you don't need to ask. Take the issue and file a\npull-request.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/Kinto/kinto/issues/1107#issuecomment-328357991, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AXvFoS_9TRgchYZAQo7rtckJETRuLLUlks5shBwUgaJpZM4MKRu3\n.\n. \n",
    "palash25": "Hi there I would like to be assigned to this issue.. Is anyone working on this issue. I'd like to take it up. From what I understand the links to various communication channels need to be added in the SUPPORT.md file. Am I right? . @Natim please review. @Natim requested changes made. Please review.. ",
    "chartjes": "The one on staging is the one we're having problems with. No, it's https://kinto.stage.mozaws.net. > Fixes #1916\n\n@chartjes Is this the dependency error you had?\n\nNo, mine was that a module we no longer need to use couldn't be installed. But thanks for thinking of me ;)\n. ",
    "flukeout": "Yeah, that did it. Thanks!. First pass at a Thimble project using Kinto for storage, and works great!\nhttps://thimbleprojects.org/flukeout/250660/. ",
    "delebash": "Thanks for the quick response\nError is now \"Please authenticate yourself to use this endpoint.\"\n. That fixed it, thank you.. ",
    "mostlygeek": "~~Multiple commands is ok~~. A multiple personality container is OK. The recommended way to do this is with a run.sh. You could use balrog's run.sh as an example. \nYour ENTRYPOINT will be the run.sh. You don't need a CMD in your dockerfile. \nWhat's the rational behind doing migrate start ... with every command? Does that modify the schema of the underlying database? . Schema migration should be explicit, separated and not default. It is better to have migration and server startup as two discrete functions. Using migrate-and-start as a default is convenient during development but is too risky for production. \nFor ops, code deployments and schema changes are usually discrete steps. Deployment are either: \n\nUpdate the schema, old code continues working. Deploy new code.\nDeploy new code, continues working with old schema. Update the schema. \n\nWe should keep migration and server startup separated. . I suggest removing all stored procedures/triggers and do it all in app code. . > Should we try to log any information about the user who hit the error?\nWe can log the uid. The PII is auto-scrubbed for that key before it's sent downstream to other sources. . ",
    "cfguimaraes": "Hi, all.\nIs this the second view I do to this project, it's fantastic and I'm looking for this in a current project. In the next week I think that I have to decide which storage mechanism I need, Auth is a essential part of the app to permit users share their data with other (Kinto does it extremely well, congratulations), could some member give a report about status of this feature.\nIf there are no plans, can someone give a way to integrate Kinto with Auth0?\nThanks in advance.. Until my last post, I was reading on contributing and looking for implementations, couldn't find anyone.\nI'm planning to make a wrapper on auth0 SDK for pyramid, I will setup things to run Kinto locally to make tests and after that make a status report.. @leplatrem thank you for the mention, I will try this on Codenvy. Good news, working today in this feature I could connect with Auth0 OIDC Conformant JWT Token.\nHowever, the code looks for a Bearer+OIDC Authorization Header, I couldn't find a place where this Header is described, only Bearer token.\nThe code in the branch doesn't seem to work properly, I've needed to fork python-jose implementation of the at_hash issue of leplatrem, after that all works fine.\nI will clear the local code, and make new tests to ensure the python-jose code has a bug or not in the current version of Kinto.\nIn 4 hours I'll make a report.\n. I've cleaned local code, make a pull and update the code to reflect the locations for the plugin and all work fine, without the code on python-jose.\nSadly I don't have many use cases to test, but Authentication is working fine, with a valid acess_token and Forbidden with an invalid JWT.\nIf there is something you'll want I do, I will be happy to help @leplatrem.\n. I really think that a Bearer token as proposed is the best as default.\nIf one wants a different behavior that could configure that, I think that a tool has to be standard compatible, those that are exceptions have to write code for exception, IMO.. @Natim, I like standard things, don't you think that being standard this tool will help much more developers at all?\nIn OIDC Core, token response section says\n\nThe OAuth 2.0 token_type response parameter value MUST be Bearer, as specified in OAuth 2.0 Bearer Token Usage [RFC6750], unless another Token Type has been negotiated with the Client\n\nI think, having a non-standard Header like Bearer+OIDC will force 2 implementations, one for tools that accept content negotiation, and another for standard tools only. In the first case we will force developers to write and manage more code, to accept negotiation with Kinto endpoint, and to access other API's that are standard compatible only sending a Bearer jwt.\nI as a developer don't like how this sounds, if I need a non-standard solution just implementing an interface and settings in kinto.ini (configuration file) will make me much happier.. > I don't think so.\nCould you say more about how you see this?\nI still see 2 implementations, in this case, one for Bearer (standard), and another for any non-standard header (as any developer can extend kinto) like Bearer+OIDC as invented for @leplatrem in her code.\nI've made a login in an Auth0 OIDC compliant client, sending a compliant acess_token Authorization heared as a Bearer jwt I've been Unauthorized, so I've to send a Kinto compliant Bearer+OIDC token or change the code to expect a Bearer.\nI've made the first because I'm writing request in a REST plugin, but when I've made an app to make tests with Angular the tools I used sends standard Bearer token. I don't investigate how to extend the js lib I used to send a custom Header, but I really, don't wish to do that.\nAnd is this I'm saying, if we'll deliver a built-in plugin with Kinto, this SHOULD be OIDC standard compliant, this way we can bring a more convenient tool for developers.\nIf one needs a different solution than that, this already will have to write custom code, so is acceptable.\nWhat you think about this?. > Then maybe I am wrong. Can you show me how you use your plugin?\nOf course, I can demonstrate.\nRecently I cleaned local code that I changed for make tests.\nI've put all apps (kinto, ng) running.\nWhen I make a request with curl using an Authorization Bearer+OIDC as expected in the code, all works and I've been authenticated.\nIf I go to Angular app, authenticated to Auth0 (OIDC Conformant) and make a request using angular2-jwt, maintained by auth0, that put an Authorization Bearer token, the code is looking for another AuthMethod, I got a 401 and a header Www-Authenticate | bearer+oidc realm=\"Realm\"\nWhen I look for the www-authenticate definition I found in mozilla developers network \n\nThe HTTP WWW-Authenticate response header defines the authentication method that should be used to gain access to a resource.\n\nBecause this I'm saying, if we go with OIDC standard that says the Bearer is the default transporter (if I coud say) for  JWT acess_token we can benefit to be standard compatible and write less code, the same time, other developers will work smooth.\nHowever, if we choose another Authorization header that isn't a Bearer we'll deliver to third-party developers the responsibility to write code to manage custom authentication just for Kinto.\nAnd as I said previously if one needs another Auth mechanism that is not OAuth, this one already will have to write custom code, almost easy for Kinto, just implementing an Interface and some change in configuration, and another in Client (s) code, is perfectly presumable, don't you think?\nI don't have knowledge about Realm, but the definition I've found isn't the same I think I've understood of   @Natim written.\nI've understood that Bearer+OIDC (Authentication Mechanism) is just a Realm.\nIn my understanding, Bearer+OIDC will be another Authentication Mechanism, like Basic is, and Realm is apart of that.\n. Are keys [\"id_token\", \"acess_token\"] mandatory in JWT from an OIDC provider?\nI've created a non-interactive client on Auth0 dashboard, from the APIs gotten the JWT token using curl, however, I always got HTTP 401 Unauthorized from Kinto.\n{\n  \"iss\": \"https://tenant.auth0.com/\",\n  \"sub\": \"key@clients\",\n  \"aud\": \"https://tenant.auth0.com/api/v2/\",\n  \"iat\": 1516993206,\n  \"exp\": 1517079606,\n  \"azp\": \"gaJ9QUArBJTPpL76SYV8jDhqu9Cztq93\",\n  \"gty\": \"client-credentials\"\n}\nThe code above is the Payload extracted from JWT.io site. Accordingly to section 2 from Open ID Core the keys required are all right.. My bad, I'm testing all day with a non-interactive client from Auth0, the purpose of that is to grant authorization to scripts, in a server-server communication channel.\nTomorrow I will plug Auth0 lock (login) and update this topic with discovers, I'm really happy with how simples this code are at the same time how great are thanks to OIDC discovery.\nThanks to @leplatrem too for spend resources on this code.. Status update:\n1. First of all, I become testing this in an Ionic project, already configured with Auth0, but when trying to integrate with kinto.js I don't know why, but sadly doesn't work\n2. Download quick start from Auth0's GitHub samples, inspecting the code on this branch I've seen that this is relying on python-jose for authentication, specifically to decode the JWT, also, @leplatrem  fixed an issue and make a PR to address an error on at_hashclaim being required, but accordingly to OIDC that is not required at all\n3. I've forked the @leplatrem repo from python-jose and build the branch with her contributions to generate a wheel (whl) and installed it with pip3, however, I'm always getting an error from Authentication.py \nIncorrect claims, please check the audience and issuer: **at_hash claim missing from token**.\nI think that the local installation of python-jose (whl) is not being reflected on kinto source, can someone give me a help, I don't know what I have to do to make the decode function of python-jose work with enhanced code from @leplatrem in order to advance in these tests.\nThe good news is that after all, we already have a sample demonstrating how to integrate OIDC compliant like Auth0 to kinto.\n. I've logged the code and verified that the error at_hash claim missing from token is being raised from this function.\nI cloned (https://github.com/leplatrem/python-jose/tree/75-at_hash-optional)[leplatrem python-jose] implementation that is supposed to address the issue in order to test, but I don't know if the changes on code is being reflected on kinto source. ",
    "mariustresor1": "Thanks @glasserc \ud83d\udc4c. ",
    "TaoufikBouabid": "command line : docker restart [kinto-container]. ",
    "swapnilaga3": "hello gabisurita,\nmay i take this as my first issue to solve.. ",
    "S2606": "@leplatrem what content should we have in SUPPORT file?. ",
    "Grahack": "I don't understand what's going on here, but let's retry!!!\nI got an error: Cannot import name Utc which I see you mention.\n.venv/bin/kinto init --ini config/kinto.ini\nTraceback (most recent call last):\n  File \".venv/bin/kinto\", line 11, in <module>\n    load_entry_point('kinto', 'console_scripts', 'kinto')()\n  File \"/home/chri/prj/kinto/.venv/lib/python3.5/site-packages/pkg_resources/__init__.py\", line 560, in load_entry_point\n    return get_distribution(dist).load_entry_point(group, name)\n  File \"/home/chri/prj/kinto/.venv/lib/python3.5/site-packages/pkg_resources/__init__.py\", line 2648, in load_entry_point\n    return ep.load()\n  File \"/home/chri/prj/kinto/.venv/lib/python3.5/site-packages/pkg_resources/__init__.py\", line 2302, in load\n    return self.resolve()\n  File \"/home/chri/prj/kinto/.venv/lib/python3.5/site-packages/pkg_resources/__init__.py\", line 2308, in resolve\n    module = __import__(self.module_name, fromlist=['__name__'], level=0)\n  File \"/home/chri/prj/kinto/kinto/__init__.py\", line 4, in <module>\n    import kinto.core\n  File \"/home/chri/prj/kinto/kinto/core/__init__.py\", line 10, in <module>\n    from kinto.core import errors\n  File \"/home/chri/prj/kinto/kinto/core/errors.py\", line 1, in <module>\n    import colander\n  File \"/home/chri/prj/kinto/.venv/lib/python3.5/site-packages/colander/__init__.py\", line 22, in <module>\n    from . import iso8601\n  File \"/home/chri/prj/kinto/.venv/lib/python3.5/site-packages/colander/iso8601.py\", line 3, in <module>\n    from iso8601.iso8601 import (parse_date, ParseError, Utc, FixedOffset, UTC, ZERO, ISO8601_REGEX)\nImportError: cannot import name 'Utc'\nMakefile:74: recipe for target 'config/kinto.ini' failed\nmake: *** [config/kinto.ini] Error 1\n\n. About writing English, I'd recommend this book, which also improved my French writing!!!\nhttps://en.wikipedia.org/wiki/The_Elements_of_Style. ",
    "hiteshramani": "Hi,\nIs this issue resolved? If not I'd like to pick it up. Would like some more details on this.. ",
    "alexryabkov": "@leplatrem I've just tried to reproduce this using 7.3.1 - it doesn't crash :) Just FYI: I used Python 3.7.. @leplatrem Could you please mark it as closed? It's still open.... I suppose the issue was fixed by PR #1653, could you please close it?. @janani-sridhar @OhadArzouan Are you guys on this one? I can pick it up if needed.. @Natim @leplatrem guys, just to make sure I understand correctly: this issue is already covered by test test_permissions_are_deleted_when_collection_is_deleted, correct?. @leplatrem Thanks, will do my best )). @Natim @leplatrem Guys, please take a look at my PR when you have time. Please let me know if something is wrong, I'm a newbie))). Thank you guys for explanation, appreciate it!. Could somebody mark this issue as \"question\" please?. Sorry, I forgot to update my local fork... I will update CHANGELOG.rst once again.. @Natim @leplatrem Guys, I'm really sorry for such a big number of commits, I should be move attentive.... @glasserc @Natim @leplatrem Thank you, too!. @Natim I thought the creation is covered by setUp method:\npython\n    def setUp(self):\n        super().setUp()\n        bucket = {**MINIMALIST_BUCKET,\n                  'permissions': {'collection:create': ['system.Everyone'],\n                                  'read': ['system.Everyone']}}\n        self.app.put_json('/buckets/beers', bucket,\n                          headers=self.headers)\n        self.app.put_json(self.collection_url, MINIMALIST_COLLECTION,\n                          headers=self.headers)\n        resp = self.app.post_json(self.collection_url + '/records',\n                                  MINIMALIST_RECORD,\n                                  headers=self.headers)\n        self.previous_ts = resp.headers['ETag']\n        record_id = resp.json['data']['id']\n        self.record_url = self.collection_url + '/records/{}'.format(record_id)\n        self.app.delete(self.collection_url, headers=self.headers)\nDo I need to implement \"create/delete\" explicitly?. Sure, I will update PR later today. ",
    "mohit2872": "i would love to help. . ",
    "TDress": "I'm interested in giving this a try.  I haven't used Hawk but it would be a good learning experience.. just let me know if you'd rather someone else look into it \nhere is my understanding of the goal: \nHawk  on the client side (application server) will need to send the MAC with a nonce to the kinto backend, where we check that the nonce wasn't already used, and then we store it (nonce checking is required).\nThe user can opt-in to using Mohawk by setting new configuration options: one turns on Mohawk authorization, and the others specify credential values (client_id, secret_key, and algorithm). \nAm I off about anything?\n. #1453  This is NOT ready yet.  I wanted to show some code and get feedback.\nI'm using mohawk with nonce checking (the cache layer is used to check if a nonce has been seen).\nIn the settings config I added options for only a single client/secret pair, but I'm guessing we want to allow for an arbitrary number.\nResponse signing (back to the client) is not implemented yet. \nTests are currently only checking for valid configuration and a 401 auth failure.  I still need to write tests for HAWK auth actually working :-)\nHopefully this is enough to check if I am on the right path. . thanks for looking at it @Natim \nI will start making the changes in the next week or two.\n. Hey @Natim, please see new commit.  Some code to keep the discussion going, but it still needs work.  #1466 \nThe secret for HAWK auth is stored on the account record.\n\n. Thanks @leplatrem and @Natim  for the granular feedback on these PRs!  I'm enjoying the learning experience and would love to bring this all the way to fruition.  I'm going to get another PR ready with more progress.\nJust to be clear that the design is on the right track: we are essentially wrapping the account plugin with a new hawk auth policy.  Kinto uses account IDs as hawk client IDs and generates secrets stored on account records.  The secrets are exposed to the account user when doing a GET account (and when creating account).  @Natim seemed to have some ideas about how to \"rotate\" secrets.\n. Thanks for the blueprint-- looks good.  One question I have is about removing the current session (endpoint DELETE /accounts/(userid)/hawk-sessions/current).  Does the current session = most recently used?  If there are multiple sessions, and another user on the account uses a different session, then that DELETE call would remove the wrong one?  . Ok, ammended my commit with a new route to create a session, and a test for the token in the response header.   more commits to come. Worked my way through saving all creds on the account.  New dependency requests-hawk for doing the HKDF  work.. @Natim, sorry this is kind of a delayed follow-up question, but when you say\n\nthe current session means the one we are currently logged in with\n\nthis means that the DELETE session endpoints need to be hawk auth protected so that we can match the hawk creds to the correct session.  All new endpoints require hawk auth except for creating a new session, which will still require account basic auth.  \nDoes this sound correct?  In the blueprint the DELETE example doesn't have an 'authorization' request header for HAWK. Do you want me to add that to the blueprint?\nAnother thing.. We want to save hawk-sessions on account records so that we can make a DELETE call to the sessions endpoints and remove the session(s) tied to an account.  But when we authenticate using HAWK on different endpoints where we don't have the account userid (because the userid is not in the URI path), how would we find the session /credentials to use to authenticate the request?   E.g. if you called the 'hello world' endpoint with account basic auth it looks like this:\nhttp GET http://localhost:8888/v1/ --auth bob:azerty123\nIf we enable hawk auth and call this endpoint we can't lookup the hawk sessions by account because we are already using the authorization header for hawk (the basic auth creds for the account aren't going to be there).\nDo you think we should save the sessions as their own independent records and then also save session tokens on account records when we first create sessions?  That way we could lookup hawk creds fast with just a client id from the request, and we can remove hawk sessions from accounts by iterating over the sessions tokens that are saved on the account.\nNot sure what the best solution is.... Thanks @Natim for the clarification on how you think sessions and creds should be stored.  The only remaining issue I see is for removing all of the sessions that are tied to an account \nDELETE /accounts/(user_id)/hawk-sessions\nIf we have the account user id stored within the session record, then when it comes time to remove every session linked to an account, we will have to look at every session record to see if the account user id matches the account of the current request.  If there are N session records, we have to look at N records in every case.  Am I making sense?  The hawk client id is the key for the session record, so we can't look up all sessions linked to an account.  The performance will be weak if we have to scan all sessions.\n. Hey @Natim and @leplatrem ,\nThe commit I just added is a start for taking the approach of saving the creds to the session, like Natim suggested, and also saving client IDs on the account for fast lookup when it comes time to delete all sessions tied to an account (like I talked about in my previous comment).  Please let me know if I'm on the right track.\n. No problem  PR #1455. Hey @Natim ,\nSo you think we should use one secret to authenticate all users on a kinto instance? So userid will be used as client ID and the secret will be defined in settings.  Am I misunderstanding that? \nWhen you say we can \"rotate the secret as needed\", do we want users to just update the plaintext secret in the settings when they want to, or do we want to provide a way to generate a new secret and rotate it from the CLI?    \nthanks!  . Maybe it's not necessary, but I included those references because the user will need to implement the hawk client.. thanks for reading through my docs change!  Most of the change is outdated and I shouldn't have included it in the PR.  Since we are moving in the direction of basically using hawk auth as a wrapper around the account plugin, I will need to redo this.  Your comments are helpful in understanding what needs to be in the docs . Much better since the hawk implementation (library) might change in the future. good call!. I accidentally let this slip in from a previous commit.  I will get rid of it!. thanks for the tip!  Is this better style or is there another reason to avoid relative imports here?  . I must have had the idea that it was more modular, but looking at it again I think you are right-- it makes more sense as one method. ",
    "furquan1993": "I am new to python, and would like to get my hands dirty. This issue seems to be tagged easy-pick and i would like to contribute. Just guide me to the right direction, how to build the project and all and i will get started.. ",
    "mayurvadhavana": "Hi @leplatrem !\nAs per your suggestion, I would like to express my interest in this project. Could you please give some information regarding project details?\nThanks in advance.\n. Hi @leplatrem ,\nThanks for your message. \nI tried to understand this new scope. Goal here is to add other backend (redis,postgresql, memory) rather than default (storage backend).\n. Hello @leplatrem \nThanks. I will do that part. Which platform do you prefer for Kinto (Linux or Windows)?\n. Thanks for prompt reply. I will go for Linux than.. Hello, I am intermediate user of python, and would like to contribute myself on this project. Can I work on it? This is my first project. Thanks. ",
    "skepticleo": "Hey @leplatrem I would like to take this one, will send a pull request soon.. @leplatrem sorry, It's been a bit hectic for me lately. If anyone else is interested in taking this up, they should go ahead.. ",
    "aimanparvaiz": "@leplatrem should I give this a shot? I am done with https://github.com/Kinto/kinto/pull/1499 and can find some time to work on this.. https://github.com/Kinto/kinto/pull/1653. @leplatrem I have submitted PR, quick question though, some of these options (available in PR) are not valid in this case. So I have left them blank. Please let me know if I am missing something.\n  Add documentation.\n  Add tests. (done)\n  Add a changelog entry.\n  Add your name in the contributors file. (done)\n  If you changed the HTTP API, update the API_VERSION constant and add an API changelog entry in the docs\n  If you added a new configuration setting, update the kinto.tpl file with it.. @emamurho @leplatrem Hi guys, I am new here. Very interesting project I must say. I was going through this issue and had a question. Pardon my ignorance if this is a stupid question. I understand that we use Redis list in our worker code to listen for events but how do we allow only kinto/blocklists bucket to publish to that redis list on every create event. I followed the the tutorial to set up kinto-redis and created two buckets. On creating records under both the buckets, worker code picks up the event and fires the dummy code.\nAssumption is that we want to trigger lambda only when we create a resource in kinto/blocklists bucket. I would be grateful if you could point me to the right direction.\nThanks. @Natim Yeah I am aware of that but I feel using Redis might be more efficient.\n@leplatrem Indeed this can be a good little enhancement to implement and I can take a shot at that. Question though, would we want to hold off on this issue? If we plan to proceed with this issue first then can you please point me to the lambda details. I plan to pretty much use the worker code mentioned here: http://kinto.readthedocs.io/en/stable/tutorials/notifications-custom.html and add a call to lambda where the comments says \"simulate long task\". Please let me know if I am missing something.\nOne more thing, I did try and look in to where we can put some logic for filtering based on object_ids etc and with what ever little understanding I have of the code base (I am in no way an expert since I have been reading this codebase only for the past 2 days occasionally) I want to propose that we add it in the Listener class in kinto-redis under call https://github.com/Kinto/kinto-redis/blob/master/kinto_redis/listeners.py#L23\nI would be more than happy to learn a better way of doing this. Please let me know.\nThanks. You are right @leplatrem initialization.py kind of approach would be better. I am reading up on events in Pyramid and have some idea about how we can go about this. I agree, lets first do the design part. Please let me know how we proceed from this point.\nThanks. @leplatrem I suggest we should do something like this in the .ini file:\n```\nkinto.event_listeners = redis\nkinto.event_listeners.redis.use = kinto_redis.listeners\nkinto.event_listeners.redis.url = redis://localhost:6379/0\nkinto.event_listeners.redis.pool_size = 5\nkinto.event_listeners.redis.listname = eventqueue\nkinto.event_listeners.redis.actions = create\nkinto.event_listeners.redis.resources = record\nkinto.event_listeners.redis.resourceId = mybucket mycollection\n```\nthen we can define a class to be used in the event predicate like this in initialize.py and call add_subscriber_predicate:\n```\nclass EventResourceIdFilter:\n    def init(self, resourceIds, config):\n        self.resourceIds = resourceIds\ndef phash(self):\n    return 'for_resource_id = {}'.format(','.join(self.resourceIds))\n\ndef __call__(self, event):\n    for resourceId in self.resourceIds:\n        if resourceId not in event.payload.values():\n            return False\n    return True\n\n```\n```\nconfig.add_subscriber_predicate('for_resource_ids', EventResourceIdFilter)\nOptional filter by resource object id\nresource_id_setting = prefix + 'resourceId'\nresource_id_value = utils.read_env('{}.{}'.format(project_name, resource_id_setting), settings.get(resource_id_setting, ''))\nresource_id_names = aslist(resource_id_value)\noptions = dict(for_actions=actions, for_resources=resource_names, for_resource_ids=resource_id_names)\n```\nLet me know if I am missing something or if you would set this up differently.\nThanks. @leplatrem I feel that having the URI in the ini file can be an interesting option too for the genuine questions you have posted in your last comment. For example:\nwe can have the URI of the resource like this: \n```\nkinto.event_listeners.redis.actions = update\nkinto.event_listeners.redis.resources = record\nkinto.event_listeners.redis.resource_ids = /buckets/mybucket/collections/mycollection/records/7283568b-4afa-40c1-ab39-62bca69b4312 \n(Here we want to fire some code any time an update happens for that particular record.)\n```\nand we can check the resource id (bucket id, collection id, record id) or uri in the event payload in the new class I mentioned in my last comment and compare it with self.resource_ids and if there is a match we return True.\nFor Create event it gets a little tricky because my assumption is that we can have the use case where \n- We can run the remote code whenever a new resource is created(we don\u2019t know the name). \nSince we don\u2019t know the new resource name we can check just for the URI to the parent of the resource.\nFor example, I want to fire some code when ever I create a new record in bucket mybucket and collection mycollection. Here the ini file would have \nkinto.event_listeners.redis.resource_ids = /buckets/mybucket/collections/mycollection\ni.e in create case where we don\u2019t know the name of the to-be created resource we pass the URI of the parent in the logical hierarchy.\nP.S We can have a case for delete and update events too where we fire code when any resource gets updated or deleted (we dont know the name of the resource getting deleted or updated) but I am not sure if that is a requirement.\nI hope I was able to explain myself.\nThanks :). Sounds good! I will start working on this and keep you guys updated. Thanks. @leplatrem I have created this PR https://github.com/Kinto/kinto/pull/1499\nIt has nothing right now but this way we can track progress and bring to my notice if some implementation can be improved. . @leplatrem Before proceeding any further I wanted to share my understanding of the requirements and the logic of how I have implement this so far.\nThe idea is that the user is expected to pass the path of the resource for us to trigger the web hook. For example: updating(or deleting) a bucket, collection, record would boil down to the following in the config file respectively:\nkinto.event_listeners.redis.resource_ids = /buckets/mybucketname\nkinto.event_listeners.redis.resource_ids = /buckets/mybucketname/collections/mycollection\nkinto.event_listeners.redis.resource_ids = /buckets/mybucketname/collections/mycollection/records/dasdad-addsa-saddaad\nUser is expected to specify the name of the resource they want to update(or delete).\nIn case of Create event, user is expected to pass the path of the parent. For example \nCreating a record:\nkinto.event_listeners.redis.resource_ids  = /buckets/mybucketname/collections/mycollection\nCreating a collection:\nkinto.event_listeners.redis.resource_ids  = /buckets/mybucketname\nCreating a bucket:\nThis is a special case since bucket doesn\u2019t have a parent. In this case user can simply avoid adding kinto.event_listeners.redis.resource_ids line in the config and web hook would be triggered whenever a new bucket is created. I am happy to handle create bucket in a different manner if you have a suggestion.\nI am aware that several tests are failing for now and I would be working on fixing them(some of the tests might not be valid anymore but we will talk about them once we agree on what I have stated above). I wanted to update the PR so that you know how I am handling this. \nThanks. @leplatrem thanks for the advice, I will back up a bit and start writing more tests. I will also incorporate your comments on the PR in my future commits. One question though, I am not clear about how the settings should be written. I thought depending on what we are updating or creating we would pass that resource with full path(or the path of the parent in case of create) in the config file. For example, if I am updating a record then it would be\n kinto.event_listeners.redis.resource_ids = /buckets/mybucketname/collections/mycollection/records/dasdad-addsa-saddaad\n if I am updating a collection it would be \nkinto.event_listeners.redis.resource_ids = /buckets/mybucketname/collections/mycollection\nif its a bucket then \nkinto.event_listeners.redis.resource_ids = /buckets/mybucketname.\nI am unaware of a case where the config would look like this \nkinto.event_listeners.redis.resource_ids = /buckets/mybucketname\n                                           /buckets/mybucketname/collections/mycollection\n                                           /buckets/mybucketname/collections/mycollection/records/dasdad-addsa-saddaad\nNot sure what you meant in your last comment about how the settings should be written. \nPlease let me know if I am missing something.\nThanks\n. Hey @leplatrem \nI have updated the PR taking in to account various relevant points which you had brought up earlier. I wanted to run what I have done so far by you before I made any more progress. I have added a test for checking callback when resource id is not filtered, mocking out kinto.core.utils.parse_resource and kinto.core.utils.view_lookup functions since I understood this test is about whether call back function is being called or not and not about the functionality of the mocked functions. Please correct me if I am wrong here. If I get a green light on the test I will create similar tests for resource id - collection and tests around resource ids being filtered. For now I am not entertaining the special case of creating a bucket as you suggested in you previous comment.\nI have fixed a couple of breaking tests too which were breaking because I added a subscriber predicate in setup_listeners function in initialization.py and it was calling kinto.core.utils.parse_resource and kinto.core.utils.view_lookup functions. I have mocked out those functions. In general I have used mock.patch decorator please let me know if this is not the best way to go about it.\nAnother change is in the test test_malformed_url_raises_an_exception in /tests/core/test_utils.py because one of the URI pattern which was illegal before is now a legal case.\nI have incorporated all your comments from the PR except for one which I couldn\u2019t understand where you mentioned the following:\nyou can put those matchdict.get() and returned_resource_ids.get() above the if to ease reading\nI would be grateful if you could please throw more light on this and I will take care of this too.\nIf all of this is ok, I will continue working on fixing rest of the breaking tests and adding more tests where possible.\nThanks for your patience.. @leplatrem Sorry, I havent been able to work on this for some personal reasons. Give me a couple of days to catch up, I would like to continue working but I might need some help around writing tests. I will update you in a couple of days if thats ok with you. . Sure, I will take a shot at rebase over the weekend most probably.. @leplatrem Sorry for the late response. I rebased my work and the commit history is clean now. The tests are failing because of a system issue I guess\ncurl: (7) Failed to connect to s3.amazonaws.com port 443: Connection timed out\nUnable to download 3.5 archive. The archive may not exist. Please consider a different version.\nPlease let me know if I am missing something here. Thanks for your patience.. @leplatrem Sorry, wont be able to work on this in the near future, please feel free to take over or delegate this. Thanks for the opportunity.. @leplatrem The reason why I decided to mock these is, the test (test_callback_called_when_action_is_not_filtered)  was breaking when the newly added class (EventResourceIdFilter) to filter by resource by ID calls view_lookup in utils.py. It expects a upath_info to be passed in request (which can be easily added in test_listener.py) and a non blank uri. I thought that this test is meant to check if the callback is being called or not and not a test view_lookup function. I might be wrong here, as I can surmise from your comment. Please guide me how to handle this blank URI issue then, assuming that adding upath_info in the Request class in test_listener.py file is ok. Also, you made this comment for this test only or for other tests too in this file where I am mocking these 2 functions?\nThanks. This was helpful, thanks for pointing me in this direction.. My understanding is that we need to execute custom code for create, update, delete actions for a  given bucket. This logic is implemented in parse_resource by checking len(parts)==3 hence test input \"/fo/o\" is not a malformed URL anymore since it satisfies the len(parts) condition in parse_resource. \nLet me know if I am wrong in my understanding of the requirement for triggering custom code around a given bucket or there is a different way you want me to handle this.. I might have a bug here, let me take a deeper look.\n. ok, going out in the next commit. yes, fixed. yep, I am keeping the id_generator check but removing the check for blank resources. yes. quick question, in my understanding cache_backend cant really be none (it can be default, which would be memory) since we are asking for user input in a while loop in __main__.py. Please let me know if I am missing something here. \nThanks. ",
    "emamurho": "Hi Natim, \nI'm new to kinto project and require clarification on this issue.\nDo you mean to add some pip install command to dockerfile and update docker compose yml file? Are there any other relevant files work on?. Hi @leplatrem thanks for asking am still on it :) sorry @mayurvadhavana  :)\n. @Natim @leplatrem can i look into this?. @Natim I am wondering what will be in the whitelist. I think everything  in this map excluding the popped values in client.py. Is this the case?. reminds me of the hammer and the fly :)\nmore refactoring?  :). I made the changes accordingly. Is there something else i need to do?. Hi @Natim, \nCan I also look into this issue (1410) ?. ",
    "bqbn": "I did some more tests, and I suspect that \"create-user\" doesn't create the user at all. For example, I run,\n```\n$ sudo docker run --rm --net host \\\n    --env-file /etc/dockerflow/buildhub.txt \\\n    -v /etc/kinto.ini:/etc/kinto.ini \\\n    --log-driver=syslog hub.prod.mozaws.net/pipelines/buildhub:4.2.0 \\\nkinto create-user -u user1 -p password --ini /etc/kinto.ini\n/usr/local/lib/python3.5/site-packages/kinto/core/storage/postgresql/client.py:91: UserWarning: Reuse existing PostgreSQL connection. Parameters permission_* will be ignored.\n  warnings.warn(msg)\nINFO   Running kinto 7.4.1.\nCreating user 'user1'\n```\nAnd afterwards I ran curl -s -u user1:password https://buildhub.stage.mozaws.net/v1/, which doesn't return the user property.\n$ curl -s -u user1:password https://buildhub.stage.mozaws.net/v1/ | jq .\n{\n  \"http_api_version\": \"1.17\",\n  \"project_name\": \"kinto\",\n  \"project_version\": \"7.4.1\",\n  \"settings\": {\n    \"batch_max_requests\": 25,\n    \"readonly\": false\n  },\n  \"project_docs\": \"https://kinto.readthedocs.io/\",\n  \"url\": \"https://buildhub.stage.mozaws.net/v1/\",\n  \"capabilities\": {\n    \"elasticsearch\": {\n      \"description\": \"Index and search records using ElasticSearch.\",\n      \"version\": \"0.3.0\",\n      \"url\": \"https://github.com/Kinto/kinto-elasticsearch\"\n    },\n    \"accounts\": {\n      \"description\": \"Manage user accounts.\",\n      \"url\": \"https://kinto.readthedocs.io/en/latest/api/1.x/accounts.html\"\n    }\n  }\n}\nFurther more the user_principals table doesn't contain the user1 user either.\nbuildhub=> select * from user_principals where user_id like '%user1%';\n user_id | principal\n---------+-----------\n(0 rows). Sounds good.\nWhen this gets implemented, do we must put the user password in the env file?. ",
    "haroon-sheikh": "That makes sense @Natim. Will close the PR.. ",
    "sebasrp": "My mistake - I was looking at some examples and this was an oversight. Will\nsubmit a new PR today.\nOn Wed 4 Oct 2017 at 07:45, R\u00e9my HUBSCHER notifications@github.com wrote:\n\n@Natim commented on this pull request.\nIn SUPPORT.md\nhttps://github.com/Kinto/kinto/pull/1348#discussion_r142591527:\n\n@@ -0,0 +1,10 @@\n+# Support\n+If you're looking for support for Atom there are a lot of options, check out:\n\nWhy are we talking about Atom here?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/Kinto/kinto/pull/1348#pullrequestreview-66971930, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAUPJmjvVqemtDcLzvjoqk9hzIvsWEAhks5soymHgaJpZM4PsxjP\n.\n-- \n\n\nSebastian Rodriguez\n. ",
    "tiaod": "Version 7.5.1 works fine.\n\n. ",
    "pyup-bot": "Closing this in favor of #1392. Closing this in favor of #1395. Closing this in favor of #1434. Closing this in favor of #1447. Closing this in favor of #1480. Closing this in favor of #1514. Closing this in favor of #1539. Closing this in favor of #1540. Closing this in favor of #1541. Closing this in favor of #1553. Closing this in favor of #1880. Closing this in favor of #1881. Closing this in favor of #1978. ",
    "Stanley": "Sure, I'll do it :). Done. All tests are passing :) Anything else?. Done :). Thought about it too, but couldn't figure out how to implement cache that would expire after one request. Any ideas?. ",
    "AnthonyGaruccio": "Hi @Natim thanks for the welcome!  I can update the changelog, contributor file, and documentation tonight.. I don't believe so, otherwise\npython\nif random.random() > (backoff_percentage / 100.0)\nwould have raised a TypeError exception when the tests ran. ",
    "rfk": "\nWe could make this piece of code work with both Auth0 and Firefox Accounts \\o/\n\nFWIW I'm a strong \ud83d\udc4d  to this goal :-). Out of curiosity, is this approach based on some prior art, or your own scheme?  I'm not sure how well it will interact with refresh tokens, which would allow you to generate a fresh access_token that's not bound to the id_token.. > My understanding of OAuth was that sending the access_token should be enough\nThat's my understanding as well.  The id_token is a point-in-time confirmation that we successfully authenticated  a particular user, and the access_token is an ongoing grant of authorization to do a particular thing.  I don't know much about Auth0, but having to send both on every request doesn't mesh with my expectations of OIDC.. > Looking at the Auth0 documentation is seems that the only way to verify an access_token is to use the id_token\nCan you please drop a link to this for my reference?. ",
    "munderseth": "Hi @Natim,  \nTestspace focuses on capturing your test results in an organized fashion based on your source repo (for example).  Of course you can customize how your test results are organized.  One of the benefits for your contributors is they can find test failures faster versus a Travis Log(s). Testspace also monitor's the status of all your local branches, pull requests (including forks), etc, from a single dashboard. \nThis example is from our own development: https://s2.testspace.com/projects/142.  You might find some of the metrics pages interesting - https://s2.testspace.com/spaces/424/metrics?timespan=6m\nCoderalls is focused on your code coverage metrics. Now your repo has 100% code coverage, and your test execute fairly fast (~ 11 minutes).  So Testspace might not be that helpful based on how healthy your repo is. But I hope you will still give it a try.  \n\nMark\n\n. ",
    "mozillazg": "@leplatrem Sorry for late reply (I am currently on holiday). I may not have time to work on this.\n. OK. I'll change it to allow other fields.\nBTW, _before, last_modified, gt_last_modified and lt_last_modified have same issue\uff1a\n```\n$ http https://kinto.dev.mozaws.net/v1/buckets/default/collections/tasks/records?_before= --auth 'token:my-secret'\nHTTP/1.1 503 Service Unavailable\nAccess-Control-Expose-Headers: Backoff,Retry-After,Alert,Content-Length\nConnection: keep-alive\nContent-Length: 151\nContent-Type: application/json\nDate: Mon, 05 Feb 2018 15:12:32 GMT\nRetry-After: 3\nServer: nginx\nX-Content-Type-Options: nosniff\n{\n    \"code\": 503,\n    \"errno\": 201,\n    \"error\": \"Service Unavailable\",\n    \"message\": \"Service temporary unavailable due to overloading or maintenance, please retry later.\"\n}\n$ http https://kinto.dev.mozaws.net/v1/buckets/default/collections/tasks/records?_since= --auth 'token:my-secret'\nHTTP/1.1 503 Service Unavailable\nAccess-Control-Expose-Headers: Backoff,Retry-After,Alert,Content-Length\nConnection: keep-alive\nContent-Length: 151\nContent-Type: application/json\nDate: Mon, 05 Feb 2018 15:12:43 GMT\nRetry-After: 3\nServer: nginx\nX-Content-Type-Options: nosniff\n{\n    \"code\": 503,\n    \"errno\": 201,\n    \"error\": \"Service Unavailable\",\n    \"message\": \"Service temporary unavailable due to overloading or maintenance, please retry later.\"\n}\n$ http https://kinto.dev.mozaws.net/v1/buckets/default/collections/tasks/records?last_modified= --auth 'token:my-secret'\nHTTP/1.1 503 Service Unavailable\nAccess-Control-Expose-Headers: Backoff,Retry-After,Alert,Content-Length\nConnection: keep-alive\nContent-Length: 151\nContent-Type: application/json\nDate: Mon, 05 Feb 2018 15:13:21 GMT\nRetry-After: 3\nServer: nginx\nX-Content-Type-Options: nosniff\n{\n    \"code\": 503,\n    \"errno\": 201,\n    \"error\": \"Service Unavailable\",\n    \"message\": \"Service temporary unavailable due to overloading or maintenance, please retry later.\"\n}\n$ http https://kinto.dev.mozaws.net/v1/buckets/default/collections/tasks/records?gt_last_modified= --auth 'token:my-secret'\nHTTP/1.1 503 Service Unavailable\nAccess-Control-Expose-Headers: Backoff,Retry-After,Alert,Content-Length\nConnection: keep-alive\nContent-Length: 151\nContent-Type: application/json\nDate: Mon, 05 Feb 2018 15:13:39 GMT\nRetry-After: 3\nServer: nginx\nX-Content-Type-Options: nosniff\n{\n    \"code\": 503,\n    \"errno\": 201,\n    \"error\": \"Service Unavailable\",\n    \"message\": \"Service temporary unavailable due to overloading or maintenance, please retry later.\"\n}\n$ http https://kinto.dev.mozaws.net/v1/buckets/default/collections/tasks/records?lt_last_modified= --auth 'token:my-secret'\nHTTP/1.1 503 Service Unavailable\nAccess-Control-Expose-Headers: Backoff,Retry-After,Alert,Content-Length\nConnection: keep-alive\nContent-Length: 151\nContent-Type: application/json\nDate: Mon, 05 Feb 2018 15:13:53 GMT\nRetry-After: 3\nServer: nginx\nX-Content-Type-Options: nosniff\n{\n    \"code\": 503,\n    \"errno\": 201,\n    \"error\": \"Service Unavailable\",\n    \"message\": \"Service temporary unavailable due to overloading or maintenance, please retry later.\"\n}\n```. ",
    "SeriousFrest": "Sorry for my english. Could you help me to configure and run tests correctly. My system info:\nArch Linux\nPython 3.7.0\nGNU Make 4.2.1\nAfter all tutorials reading, I use in virtual environment(after make serve writing \"Serving on http://localhost.localdomain:8888\"):\n$ tox -- tests/test_views_schema_collection.py\nAnd I get large list of warnings and errors and don't find direction, which I have to go:\n```\nResults (3.51s):\n       6 passed\nERROR: InvocationError for command '/home/iurez/Projects/Python-projects/kinto/.tox/py37/bin/py.test --cov-report term-missing --cov-branch --cov-fail-under 100 --cov kinto tests/test_views_schema_collection.py' (exited with code 1)\nflake8 inst-nodeps: /home/iurez/Projects/Python-projects/kinto/.tox/dist/kinto-10.1.2.dev0.zip\nERROR: invocation failed (exit code 1), logfile: /home/iurez/Projects/Python-projects/kinto/.tox/flake8/log/flake8-6.log\nERROR: actionid: flake8\nmsg: installpkg\ncmdargs: '/home/iurez/Projects/Python-projects/kinto/.tox/flake8/bin/pip install --no-deps -U /home/iurez/Projects/Python-projects/kinto/.tox/dist/kinto-10.1.2.dev0.zip'\nProcessing ./.tox/dist/kinto-10.1.2.dev0.zip\n    Complete output from command python setup.py egg_info:\n    warning: no previously-included files found matching '*.nix'\n    warning: no previously-included files found matching 'appveyor.yml'\n    warning: no previously-included files found matching '.travis.yaml'\n    warning: no previously-included files found matching '.pre-commit-config.yaml'\nInstalled /tmp/easy_install-5dugmz6o/pytest-runner-4.2/.eggs/setuptools_scm-3.1.0-py3.7.egg\nzip_safe flag not set; analyzing archive contents...\nTraceback (most recent call last):\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/sandbox.py\", line 157, in save_modules\n    yield saved\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/sandbox.py\", line 198, in setup_context\n    yield\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/sandbox.py\", line 255, in run_setup\n    DirectorySandbox(setup_dir).run(runner)\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/sandbox.py\", line 285, in run\n    return func()\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/sandbox.py\", line 253, in runner\n    _execfile(setup_script, ns)\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/sandbox.py\", line 47, in _execfile\n    exec(code, globals, locals)\n  File \"/tmp/easy_install-5dugmz6o/pytest-runner-4.2/setup.py\", line 76, in <module>\n    'paste.app_factory': [\n  File \"/usr/lib64/python3.7/distutils/core.py\", line 148, in setup\n    dist.run_commands()\n  File \"/usr/lib64/python3.7/distutils/dist.py\", line 966, in run_commands\n    self.run_command(cmd)\n  File \"/usr/lib64/python3.7/distutils/dist.py\", line 985, in run_command\n    cmd_obj.run()\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/command/bdist_egg.py\", line 209, in run\n    os.path.join(archive_root, 'EGG-INFO'), self.zip_safe()\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/command/bdist_egg.py\", line 245, in zip_safe\n    return analyze_egg(self.bdist_dir, self.stubs)\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/command/bdist_egg.py\", line 355, in analyze_egg\n    safe = scan_module(egg_dir, base, name, stubs) and safe\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/command/bdist_egg.py\", line 392, in scan_module\n    code = marshal.load(f)\nValueError: bad marshal data (unknown type code)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/tmp/pip-req-build-5sv_1rb1/setup.py\", line 119, in <module>\n    entry_points=ENTRY_POINTS)\n  File \"/usr/lib64/python3.7/distutils/core.py\", line 108, in setup\n    _setup_distribution = dist = klass(attrs)\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/dist.py\", line 318, in __init__\n    self.fetch_build_eggs(attrs['setup_requires'])\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/dist.py\", line 375, in fetch_build_eggs\n    replace_conflicting=True,\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 851, in resolve\n    dist = best[req.key] = env.best_match(req, ws, installer)\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 1123, in best_match\n    return self.obtain(req, installer)\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 1135, in obtain\n    return installer(requirement)\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/dist.py\", line 443, in fetch_build_egg\n    return cmd.easy_install(req)\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/command/easy_install.py\", line 673, in easy_install\n    return self.install_item(spec, dist.location, tmpdir, deps)\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/command/easy_install.py\", line 699, in install_item\n    dists = self.install_eggs(spec, download, tmpdir)\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/command/easy_install.py\", line 880, in install_eggs\n    return self.build_and_install(setup_script, setup_base)\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/command/easy_install.py\", line 1119, in build_and_install\n    self.run_setup(setup_script, setup_base, args)\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/command/easy_install.py\", line 1105, in run_setup\n    run_setup(setup_script, args)\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/sandbox.py\", line 258, in run_setup\n    raise\n  File \"/usr/lib64/python3.7/contextlib.py\", line 130, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/sandbox.py\", line 198, in setup_context\n    yield\n  File \"/usr/lib64/python3.7/contextlib.py\", line 130, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/sandbox.py\", line 169, in save_modules\n    saved_exc.resume()\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/sandbox.py\", line 144, in resume\n    six.reraise(type, exc, self._tb)\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/six.py\", line 692, in reraise\n    raise value.with_traceback(tb)\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/sandbox.py\", line 157, in save_modules\n    yield saved\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/sandbox.py\", line 198, in setup_context\n    yield\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/sandbox.py\", line 255, in run_setup\n    DirectorySandbox(setup_dir).run(runner)\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/sandbox.py\", line 285, in run\n    return func()\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/sandbox.py\", line 253, in runner\n    _execfile(setup_script, ns)\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/sandbox.py\", line 47, in _execfile\n    exec(code, globals, locals)\n  File \"/tmp/easy_install-5dugmz6o/pytest-runner-4.2/setup.py\", line 76, in <module>\n    'paste.app_factory': [\n  File \"/usr/lib64/python3.7/distutils/core.py\", line 148, in setup\n    dist.run_commands()\n  File \"/usr/lib64/python3.7/distutils/dist.py\", line 966, in run_commands\n    self.run_command(cmd)\n  File \"/usr/lib64/python3.7/distutils/dist.py\", line 985, in run_command\n    cmd_obj.run()\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/command/bdist_egg.py\", line 209, in run\n    os.path.join(archive_root, 'EGG-INFO'), self.zip_safe()\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/command/bdist_egg.py\", line 245, in zip_safe\n    return analyze_egg(self.bdist_dir, self.stubs)\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/command/bdist_egg.py\", line 355, in analyze_egg\n    safe = scan_module(egg_dir, base, name, stubs) and safe\n  File \"/home/iurez/Projects/Python-projects/kinto/.tox/flake8/lib/python3.7/site-packages/setuptools/command/bdist_egg.py\", line 392, in scan_module\n    code = marshal.load(f)\nValueError: bad marshal data (unknown type code)\n\n----------------------------------------\n\nCommand \"python setup.py egg_info\" failed with error code 1 in /tmp/pip-req-build-5sv_1rb1/\nflake8 installed: appdirs==1.4.3,flake8==3.5.0,kinto==10.1.2.dev0,mccabe==0.6.1,packaging==18.0,pycodestyle==2.3.1,pyflakes==1.6.0,pyparsing==2.2.2,six==1.11.0\n_____________ summary ______________\nSKIPPED:  py35-raw: InterpreterNotFound: python3.5\nSKIPPED:  py35: InterpreterNotFound: python3.5\nSKIPPED:  py36: InterpreterNotFound: python3.6\nERROR:   py37: commands failed\nERROR:   flake8: InvocationError for command /home/iurez/Projects/Python-projects/kinto/.tox/flake8/bin/pip install --no-deps -U /home/iurez/Projects/Python-projects/kinto/.tox/dist/kinto-10.1.2.dev0.zip (see /home/iurez/Projects/Python-projects/kinto/.tox/flake8/log/flake8-6.log) (exited with code 1)\n``\nAlso, when I run make test, some of them crashes too with similar errors. I was watching through issues, but didn't find anything. What is wrong?. I have tried to delete all .pyc files and no changes. But on Xubuntu(from VirtualBox) this error doesn't exist. and if I run test withtox `, then I get IvocationError. But if I run pytest directly , then all's ok. i will goggle and I'll try solve that. ",
    "eugene-kulak": "@leplatrem I'm trying to reproduce this issue and it looks like the schema is incomplete (minVersion and maxVersion use $ref). I'm not an expert in jsonschema, so I might be wrong.. Thank you @leplatrem, I manage to reproduce the issue now.\nThis schema should be enough to reproduce:\n{\n  \"title\": \"Add-on\",\n  \"description\": \"Add-on\",\n  \"type\": \"object\",\n  \"additionalProperties\": False,\n  \"required\": [\n    \"guid\"\n  ],\n  \"properties\": {\n    \"guid\": {\n      \"type\": \"string\",\n      \"title\": \"Add-on id\",\n      \"description\": \"The add-on unique identifier or a regular expression.\",\n      \"minLength\": 1,\n      \"default\": \"\"\n    },\n    \"versionRange\": {\n      \"type\": \"array\",\n      \"title\": \"Versions\",\n      \"description\": \"The list of impacted versions.\",\n      \"items\": {\n        \"type\": \"object\",\n        \"title\": \"Version range\",\n        \"description\": \"Version range\",\n        \"additionalProperties\": False,\n        \"required\": [\n          \"minVersion\",\n          \"maxVersion\"\n        ],\n        \"properties\": {\n          \"minVersion\": {\n            \"type\": \"number\"\n          },\n          \"maxVersion\": {\n            \"type\": \"number\"\n          }\n        }\n      }\n    }\n  }\n}\nWith this record:\n{\n  \"guid\": \"TestGUID\",\n  \"versionRange\": [\n    {\n      \"minVersion\": 1\n    }\n  ]\n}\nThis issue related to error_handler, it doesn't expect array indexes as element names here\nhttps://github.com/Kinto/kinto/blob/c78817514ae0141424d34dfe1ec8fc1488036c8b/kinto/core/errors.py#L151\nIt seems quite easy to fix, but the question I have is more about the format of message we want to show.\nNow it will be something like this:\n\"0 in body: \\'maxVersion\\' is a required property\". @leplatrem done. ",
    "bhaveshpoddar94": "First Timer here. Could I take up this bug?. So only the users with multiauth policies assigned should be appended to openid_poilicies?\nfor example if multiauth.policies = google, then only google should be appended.\nI am sorry what do you mean by capability?. @leplatrem So from what I understand, if multiauth.policies = foo, m = re.match('multiauth\\.policy\\.foo\\.use', k). And if multiauth.policies = [foo, bar] then m will be generated for only foo and bar.. Got it. Thanks a lot @leplatrem. ",
    "SushantGahlot": "Hi, new here. Does this need to be resolved even now? The last comment was three months back. ",
    "stloma": "Hi there,\nReally enjoying this project so far!\nI haven't worked on a bigger project like this before, but would like to try and take care of this issue.\nMy first thought was adding a new {'/bucket':'write'} item to perms_by_object_uri if {'bucket_create_principals':'system.Everyone'}. However, I wonder whether that's a clean solution?\nThanks!. Thanks for the detailed response!\nIt looks like allowed_resources in the following snippet will always evaluate to false as from_settings is {'': 'bucket:create'}, so there will be no intersection.\nhttps://github.com/Kinto/kinto/blob/110ace2ea0688c3abfdec8e8f471a540a502fba1/kinto/views/permissions.py#L87\nSecondly, I'm getting a key error on bucket:create on this line:\nhttps://github.com/Kinto/kinto/blob/110ace2ea0688c3abfdec8e8f471a540a502fba1/kinto/views/permissions.py#L123\nI've been digging through the permissions a bit and don't see a bucket:create key in perms_descending_tree, which seems like it would fix the problem.\nIn any case, I'll keep going through this and hopefully I'm not too off base here :)\nThanks!\n. May I ask, what is the reason for seeing a \"create\" permission vs a \"bucket:create\" permission in the response from http://localhost:8888/v1/permissions? Since it is a top-level object, it needs an unbound permission?\nFor example, this is working:\n'bucket:create': {\n    '': ['bucket:create', 'create']\n}\nHowever, it responds with:\n{\n    \"uri\": \"/buckets\",\n    \"resource_name\": \"bucket\",\n    \"permissions\": [\n        \"bucket:create\",\n    ],\n}\nFinally, I'm assuming it is desired behavior that with only kinto.experimental_permissions_endpoint = true, that an authenticated user should see the create permissions on the /buckets uri?\nI'm asking because it's failing several tests in test_views_permissions.py so I just wanted to make sure before rewriting them and adding my own :). Awesome, thanks for the direction and the suggestion of a work-in-progress pull-request.\nMy thought on the response mirrors yours; I think it makes sense for a bucket:create perm and \"uri\": \"/buckets\" (partially because there's already a home view mapped to /).\nI'll make some finalizations and submit soon.. Do you have info on what type of request caused this?. Hey Natim, sure thing!\nSorry, I have a silly question, how do I push my changes here?\nI've made changes on my local branch and read that to push them to a pull request, I would do a commit --amend, force push them to my my branch, and they would automatically integrate into this pull request, but it looks like they're just showing as outdated here. What is the best method for this?. Ok great, thanks. I'm just not seeing the updated code here.\nIn any case, I was able to cleanup the code and a solution to the PERMISSIONS_INHERITANCE_TREE if you all think that it works.\nI also took out the view_lookup code, thanks a lot for the explanation on that leplatrem, it made a lot of sense.\nIf you all have any more suggestions, please let me know, otherwise I'll start the test cleanup.. Hmm, I'm seeing it there. I took out the bucket:create perm from '' here for instance:\nhttps://github.com/stloma/kinto/blob/fa9652583cff52233c022cb864f12ef3da8a4466/kinto/authorization.py#L27-L29. Will do, I'll just do a regular commit next time with the same message, thanks for the help :)\n. Yeah, that was awesome to see the code get whittled down to what we had left, felt so clean at the end.\nHaha, no patience needed, I enjoyed working on this!\nI'll push those final changes now, thanks for your guidance and code review!. Actually, hold off on this commit if you can :(\nI've been looking into displaying if the user has account:create permissions for the /permissions endpoint that you mentioned and think I found a bug.. Ok, fixed :)\nI thought with both the accounts plugin and kinto.bucket_create_principals = system.Everyone it was working, but there was an issue where account:create was applying to the /buckets uri. I fixed that and adding more testing so it wouldn't happen again.\nBy doing it this way, the /accounts uri and /accounts/{username} is now showing on the permissions endpoint without creating an additional issue and without going outside of the scope of fixing the original issue that this pull request references.\nIt should be good to go!. Hey leplatrem, sorry, sick of me yet? :)\nMy latest push is hitting a test failure that I didn't pick up on my local machine. Where we changed one of my tests to test by dictionary comparison:\nself.assertEqual(accounts, {\n    ...\n   'permissions': ['write', 'read'],\n  ...\n})\nIt is hitting a sort of race condition (if that's the correct term) since the value of the permissions key is a set, thus unordered, so sometimes I get 'permissions': ['write', 'read'], other times 'permissions': ['read','write']. These values are populated by:\nhttps://github.com/Kinto/kinto/blob/7ea5061c6dd3e8a452be0d901948ab55f14e18c3/kinto/views/permissions.py#L73\nSo all permissions displayed on the permissions endpoint, e.g., buckets, collections, etc, will come out in different orders.\nFor example:\n\"bucket_id\": \"mybucket\", \n            ....\n            \"permissions\": [\n                \"read\", \n                \"collection:create\", \n                \"group:create\", \n                \"write\", \n                \"read:attributes\"\n            ],\nvs.\n\"bucket_id\": \"mybucket\", \n            ....\n            \"permissions\": [\n                \"collection:create\", \n                \"read\", \n                \"read:attributes\",\n                \"group:create\", \n                \"write\"    \n            ],\nI don't know if this is an issue or not, or whether I can just go ahead and change my test so it deals with it, I just wanted to bring it to your attention before I moved forward.\nAlso, please correct me if there's a better way to handle these issues that are coming up, I'm not trying to be a bother :). Awesome, thanks for your help!. Natim might be able to give you more information, but I looked at it quickly to help get you started and it seems that it's caused by turning on the history plugin in config/kinto.ini. Hmm, when I'm just using the default_bucket and flush plugins, with a PostgreSQL backend, I get the proper 409 constraint violation on the second bucket. When I turn history plugin on I get a 503.. I'm sure leplatrem can weigh in on this better than I can, but my initial reason they don't have an id is that they're top-level items.\nFor the permissions endpoint, the ids get mapped from here:\nhttps://github.com/Kinto/kinto/blob/fd440e11473e1372014e1b95315b5031c36bb6e0/kinto/core/utils.py#L438\nSo the return for a uri ending with /v1/buckets/recipes/collections/steak would be {'bucket_id': 'recipes', 'id': 'steak'}.\nWhere the two new items that are returning on the permissions endpoint, /buckets and /accounts, would be a null value for both bucket_id and id.\nI suppose this is more of a technical reason why I didn't include them, but I don't see any reason for not including them, other than what we would name them while remaining consistent with the existing convention.\nbucket_id refers to the name of a bucket, whereas id refers to the name of the current resource. So for /accounts and /buckets, the only convention I can think of would be accounts and buckets for the bucket_id and id, which isn't exactly correct.\nBut just my initial thoughts, I look forward to others!. Local tests weren't running correctly I guess, I'll have to rethink this fix. The failing test might present a problem to my solution.. When I looked further into why I needed the begin method before the doom method in order to halt the request, it seems like begin was the one actually aborting the request; doom actually just saves a isDoomed boolean onto the request for checks later, but doesn't abort the transaction.\nSo, I added the abort method which does what I wanted.. I still need to cleanup the tests a bit and understanding the v0 endpoint. If there are any suggestions if that's the correct or incorrect way to do it, I would appreciate it!. Darn, sorry, I was trying to clean up some of my older branches and deleted this by mistake :(. Reopened from reflog, so it's the exact same changes that were already reviewed.. Thanks!\nWell, there were certainly a lot of dead ends! My eventual path started with the information from the reported issue that binary was somehow getting through. Tracing the request object from the entry point, I found that all requests come in with a binary request.body but, depending on Content-Type, either request.body or request.json_body is used:\nhttps://github.com/Cornices/cornice/blob/ded8422de830688ca5d2dd1656feddce331b4b20/cornice/validators/init.py#L52-L58\nSo my hypothesis was that the is_json regex was not matching, and body was simply getting assigned from the binary request.body. At that point I could reproduce the original error message with a request using Content-Type:text/plain.\nThen it was just a matter of seeing how other routes (e.g., /buckets) handled content-types other than application/json and reproduce that on /batch!\n. I think another reason .ini configurations are useful is for non-developers to configure the project. That is, rather than editing source code, an ini file is a bit more user friendly.. Yes view_lookup does return \"bucket\", {} without that code, the issue I'm seeing is that I need it to return '', {} for this:\nhttps://github.com/Kinto/kinto/blob/6d77dcb2b94f9198fa08db489776440f7df0c275/kinto/views/permissions.py#L123\nperms_descending_tree is populated with:\nhttps://github.com/Kinto/kinto/blob/6d77dcb2b94f9198fa08db489776440f7df0c275/kinto/authorization.py#L26\nSo I need '' for resource_name in the obtained = perms_descending_tree[resource_name][perm] code above.\nThat's what's causing some of the back and forth between assigning bucket and '' in some of my other changes.. Yes absolutely, thanks!. Thanks, this was my first time doing real testing, I'll clean up all of that.. This is due to getting a KeyError since the top level bucket doesn't have an id. Will do. From my comment on kinto/core/utils.py, I need '' to get the permissions in:\nhttps://github.com/Kinto/kinto/blob/6d77dcb2b94f9198fa08db489776440f7df0c275/kinto/views/permissions.py#L123\nThen I have to switch it back to bucket for the response payload the user sees. If I didn't make this change, the response would be:\n\"data\": [\n        {\n            \"permissions\": [\n                \"bucket:create\"\n            ],\n            \"resource_name\": \"\",\n            \"uri\": \"/buckets\"\n        }\n    ]\nRather than:\n\"data\": [\n        {\n            \"permissions\": [\n                \"bucket:create\"\n            ],\n            \"resource_name\": \"bucket\",\n            \"uri\": \"/buckets\"\n        }\n    ]\n. The issue I saw with that is the way you wrote it, perms_descending_tree['bucket'] = {'bucket:create': {'bucket': {'bucket:create'}}}, would overwrite the existing bucket permissions taken in from PERMISSIONS_INHERITANCE_TREE\nWe could do something like perms_descending_tree['bucket'][''] = {'bucket:create': {'': {'bucket:create'}}}, but then obtained = perms_descending_tree[resource_name][perm] would get messed up and we'd be back to another if statement.. No, you're right, I can do the following and remove the if statement:\nperms_descending_tree['bucket'].update({'bucket:create': {'bucket': {'bucket:create'}}}). Just let me know if that's acceptable and I'll start on the tests.. I found that the accounts plugin also populates from_settings with account:create, so I added a for loop that will allow for multiple settings.. I was following the naming convention for resource_name, i.e., bucket, collection, group, and record, so thought account would be appropriate for the uri /accounts.\nThanks for the rest of the input too, I'll incorporate them. I'll just wait for your thoughts on account vs accounts for resource_name and then send the changes.. Yes, the resp.status check is a good idea. I'm trying to figure out how that should look and there seems to have been some discussion in the past on how a response should respond when a sub-response breaks.\nIt seems from the following discussions that it should be assumed when a sub-response breaks with a 4XX, the entire batch should come back with a 4XX:\nhttps://github.com/Kinto/kinto/issues/1205\nhttps://github.com/Kinto/kinto/issues/624\nI guess I'm confused as the following test seems to contridact that:\nhttps://github.com/Kinto/kinto/blob/382adcdc2dccff7151798bc7d250769dc818d83e/tests/core/test_views_transaction.py#L59\nIf the former is true, I will need to check that the resp.status is 4XX (as this contraint violation is a 409) and 5XX, but not 401 as the test asserts 401s should not effect other responses being committed.\n. As far as the begin(), short answer is I used it because it didn't work without it :) As far as my understanding, I agree, it shouldn't be necessary to use it. abort() does work without a begin(), but I'll look into this and get an answer. . ",
    "ssWitcher": "Working on this. ",
    "sebastienbarbier": "More than likely from me \ud83d\udc4b, but could not reproduce.\nUsing kinto.js, I was deleting an array of records using collection().delete(). On a loop of 8 may be, only one crashed, returning 500. I'm now using deleteAny (thought that was a good idea even if not so sure right now \ud83e\udd14). Please let me know if you have questions or if I can help.. ",
    "vladikoff": "@leplatrem could you check if you are getting more of these? Softvision is telling us they are getting a lot of those and all their DELETE ops are failing. cc @Natim . @leplatrem I haven't seen a 404 but we are seeing both: \n2 delete operations - 2 200s:\n\nand then in another case: 2 delete operations - 1 200, 1 500:\n\n. ",
    "manishbit": "Hi , \nI am eager to contribute. But since this is my first time can you please brief e a little about the issue.. ",
    "atulpillai": "Hi Guys, new here. I was trying to reproduce the issue on my local but no luck:\nPlease check below, I might be missing something....\nkinto-wizard load -s http://localhost:8888/v1 -a admin:admin demo.yaml --force -b demo -c demo\n```\ndemo:\n  collections:\n     demo:\n        records:\n           abcd:\n              data:\n               last_modified: 123\n       efgh:\n          data:\n           last_modified: 123\n\n\n$ kinto-wizard load -s http://localhost:8888/v1 -a admin:admin demo.yaml --force -b demo -c demo\nBatch #0: PUT /buckets/demo - 200 \nBatch #1: PUT /buckets/demo/collections/demo - 200 \nBatch #2: PUT /buckets/demo/collections/demo/records/abcd - 201 \nBatch #3: PUT /buckets/demo/collections/demo/records/efgh - 201 \n```\n```\n$ http GET http://localhost:8888/v1/buckets/demo/collections/demo/records -a admin:admin\nHTTP/1.1 200 OK\nAccess-Control-Expose-Headers: Cache-Control, Total-Records, Retry-After, Backoff, Alert, ETag, Pragma, Next-Page, Expires, Content-Length, Last-Modified\nCache-Control: no-cache, no-store\nContent-Length: 78\nContent-Type: application/json\nDate: Thu, 19 Apr 2018 20:00:13 GMT\nEtag: \"1524167996115\"\nLast-Modified: Thu, 19 Apr 2018 19:59:56 GMT\nServer: waitress\nTotal-Records: 2\nX-Content-Type-Options: nosniff\n{\n    \"data\": [\n        {\n            \"id\": \"abcd\",\n            \"last_modified\": 123\n        },\n        {\n            \"id\": \"efgh\",\n            \"last_modified\": 123\n        }\n    ]\n}\n```\n. ",
    "ronhanson": "Hi @Natim - thanks for instant reply,\nWell, it is like if I would use sort of a queueing system. Someone will add a \"job\" to be consumed, and someone else would consume the job. \nBut if I do :\nSELECT id WHERE status=pending            # returns ID1\nUPDATE status=running WHERE id=ID1\n\nand that these calls are not atomic, 2 or more consumers might retrieve the ID1 and therefore duplicate the job and also override what the other just updated.\nI need atomic select and update, but not based on ID. This is not something that Restful APIs usually give the ability to do so.\nIn SQL, it would relate to a SELECT FOR UPDATE statement. In MongoDB it is a findAndModify statement.\nI guess with transaction we would be near from what I want, but I don't know if I can use the retrieved ID variable in a second update statement - not sure I am clear in that sentence.\nThanks for your answer.\n. Well, the system I build is a long running task running/queueing service, and it uses mongodb + a dummy naive custom built API to access it. Thus I am interested in Kinto as it has many more features. Using a push to redis and a BLPOP was something I was planning to dig into but you confirm me it would be a good solution. About the double PATCH request, I am a bit uncertain but it might also be really valid indeed. \n2 additionnal questions : \n\nHow hard is it to add a storage like MongoDB? I see that kinto-redis seems pretty much inactive and not much used at the moment.  \nHow hard would you think it would to add a custom rest API request like //findAndUpdate ? I guess it would need a storage class function more and some added http methods which makes it hard for one plugin.\n\nThanks again for ideas and great help.. ",
    "mattt416": "Can't comment on the code change itself, but tested this commit and found that it works perfectly for a use case I have. \ud83d\udc4d . Is it worth being explicit that contains_ and contains_any_ can both use comma-separated or JSON list?. ",
    "webwurst": "Thanks! The page works now, but I didn't a receive the invitation for that, have tried two times so far.. Sorry, my fault :) I had already registered some time ago, it seems. So all good now.. Ok, seems to be this one: https://github.com/Kinto/kinto-admin/issues/535. ",
    "janani-sridhar": "I'd like to work on this issue.. @OhadArzouan sorry for the lack of response. sorry I wasn't able to work on it.. ",
    "OhadArzouan": "Is this still relevant? @janani-sridhar are you on this? If not I'd like to take a look.. ",
    "fpiedrah": "Hi! Is this task still available? I would like to take it.\nShould I just add a new section in the troubleshooting.rst describing this issue? or is there any other suggestion on where to place this? . I'm not sure. should I try to replicate the issue and see if it is kinto the one where the error originates from?\nBecause if it's kinto-admin specific we could move this issue to the kinto-admin repo.. @itaisteinherz I like the change suggestions! Added them now to the PR. Thanks! . I've been taking a look at this error, I've installed psycopg2-binary==2.7.6.1 but did not solve the issue. The only thing that worked out was to get an older version of the library psycopg2==2.7.3.2 but I do not like the idea. Any other thoughts on how to solve this issue? . True! Had not thought about that. I'll change that and add a link to the Auth0 supported Identity providers.. That  like in param could be troublesome. Fixed it now to use operator instead! Thanks! . ",
    "DrFaustie": "Is this something we are still interested in doing?. My only concern is if some of the logic and references regarding the f strings is changed during this time, it might end up very unwieldy to merge. Or perhaps Github has ways to account for this problem?. What would be good practice here? Should I start a pull request immediately and work on that, or simply submit one when I've finished most of it?. If f-strings are the only benefit of dropping 3.5 then this wouldn't be a very pressing concern, as there is plenty of time before support needs to be dropped. That said, i believe there are some other issues open? I'm not too familiar though, so that's better for others to discuss.\nOn the other hand, it's not a bad idea to get the work done in preparation from when it is necessary to move on.. wouldn't something like raise VersionNotFound do the trick?. I'll do this in an hour or so, no worries!. Sorry, I've been busy.\nI made a pull request here: https://github.com/Kinto/kinto/pull/1860\nIf I messed up, feel free to take it. Travis CI seems to still be failing, I'm looking at it now. But can someone please advise me on how to update this pull request instead of spamming with more new ones?. Thank you. Can't believe I made that mistake! I'm still very new to pull requests so apologies for the mistakes :>. Regarding the changelog, should I just add the change 11.2.0 (unreleased)?. Thank you for holding my hand through this!. Misclicked, apologies. I thought it may be better to have a checklist of tasks on the top, since it was decided we could at least start work on this. If others think it's unnecessary we can of course close this.. That makes sense. I'll make a pull request once my initial tests pass.. There may be some issues still. My local builds still fail on lint and functional ENV's.\nhttps://i.imgur.com/6UrNgXI.png\nPerhaps it is correct for the functional build to fail as it runs on 3.5?\nThere are also some lines of code that I'm unsure of on how to convert to fstrings at the moment. I'll look into those over the next few days. Code review/advice is very much appreciated. It's my pleasure!\nAbout the TravisCI config, we should update the python version but also tell Travis that we expect 3.5 to fail, correct?. > \n\nThank you for this work. To be honest I didn't expect it to be so much of an improvement. \ud83d\udc4d \ud83c\udfb1\n\nYou and @leplatrem have been very kind to me and made my first experience with open source extremely welcoming. I'm very happy to have started here at Kinto \ud83d\ude00 . > \n\nLet's make a quick poll: https://twitter.com/Natim/status/1064904568272764931\n\nI think you may need to edit your link. Looks good!. Is there anything that still needs to be done from me? \ud83d\udc4d . Changelog is not properly dated on 12.0.0. Sorry, I seem to have created a new pull request instead of updating this one. I'm not entirely sure how to do that. But I've changed Kinto/kinto/tests/core/test_views_version.py:29 to match our new expected behavior.  https://github.com/Kinto/kinto/pull/1862\nAgain, sorry for the clutter. Is there a way to simply update this pull request? Cheers.. Thank you. Again, sorry for the clutter. I'll update the new pull request from now on. Perhaps raise FileNotFoundError(\"Version file missing from {}\".format(files.join(\",\"))) can be used here too?. We could do this, I think it should work\nsuggestion\n        #     def __repr__(self):\n        return f\"<{self.__class__.__name__} action={self.payload['action']} uri={self.payload['uri']}>\". ",
    "zeeshanabid94": "Thanks for that link. It looks like I could develop this as an external dependency. \nI will start planning and working on this in my past time, so the timeline is indefinite for this project. I will need help and suggestions about kinto and its workings. I will keep posting my questions here.\nAnything I should know before starting this project apart from contributing.md?\n. @Natim @leplatrem \nI have looked at kinto-redis and these are the ideas/Questions that I got from the code base of kinto and kinto-redis. Correct me if I am wrong:\n1- The base classes including storagebase, cachebase and permissionbase define behavior for the derived classes. Correct? They are there to make sure a standard API is exposed.\n2- Working with storage, I do not need to know how Cornice and Pyramid are working in getting the request and processing it. Correct? Although I am aware that in the future if I want to add a middleware to process a request, I will need to learn the docs of pyramid and cornice.\n3- The cache in kinto-redis seems to be using redis as a default. Can I make the cache for SQLite in memory and the storage on the physical drive? This would make retrieval fast but also provide a consistent storage for testing purposes as that would mitigate the need to reload test data into the storage.\nAgain, Thank you for your time. I love to code, and this is my first time trying open source.. Hi guys,\nI am working on this. I am making progress. I have understood testing it as well.\nI opened an issue with one of the test cases in kinto.core.storage.testing. Have a look and let me know if I am wrong or the issue is real.\nhttps://github.com/Kinto/kinto/issues/1711. @Natim @leplatrem \nHey guys. I pushed an initial version on my repo. It involves the basic methods to create, update, insert and delete records. I am working on the more complicated methods get_all, delete_all and others. I am making these methods pass the base tests first. Once they pass the base tests, I will write SQLite specific tests. Have a look, review the code, let me know your questions and validate if I am going on the right track. \nAlso, thank you for the patience, feels good to be contributing to an open source project.\nhttps://github.com/zeeshanabid94/kinto-sqlite/tree/initial-code. I haven't heard from you guys, but here is an update. So SQLite doesn't support json blobs. It has support for simple text blobs. Hence, I serialize and deserialize on writing and reading. But now in get all, I can not filter based on fields and sub fields of the data. Any workarounds or suggestions for this?. Nevermind. Closing the issue. I was looking at it the wrong way. Its not being added twice. The test is fine. There was a bug in my code. Thanks for the help! \ud83d\udc4d . ",
    "JEricaM": "Thank you so much for your answer :) . Thank you, I tried and the accounts endpoint works good!!\nI have only another little problem, when I run from the Heroku dyno the command  (I have kinto.ini out of the etc folder, so I don't have /etc/kinto.ini but only kinto.ini) \nkinto create-user --ini kinto.ini --username admin --password mypass \nI have this error:\nsqlalchemy.exc.ArgumentError: Could not parse rfc1738 URL from string \u2018\u2019\nThis is my full stacktrace https://pastebin.com/Ek6rDD45\nThank you in advance.\n. Thank you, I'll check asap!. Sorry for the late.\nI solved by creating the account through endpoint not with the kinto create-user command.\nSo you can close the issue.\nThank you again!\n. ",
    "Cnidarias": "Hey, if this is still open I would like to work on this - where would be the best place to put a test for this?. And to add to this, what would the expected result be? . Okay great!\nI will work on it shortly, the aim is to stay compatible with 3.5 for now right?. Sure,\nyes this is very possible. I know some larger projects basically have a type def file where they define such horrible types to shorten them.\nI will let black run over it and refactor some of the larger type annotations tonight when I get home from work, then we can see if the direction we are heading is any good or not. So I basically just added the stuff you linked -- not sure I did it correctly though especially regarding therapist/travis/tox\nBut it seems like its fine?\nStill need to add some documentation though.. Hey,\nyes the diff is quite massive. \nThis does beg another question, when looking at the diffs alot of changes are changing single quotes to double quotes\nBlack does provide the option to omit normalizing quotes. \nAfter testing it - the diff would still be massive. When omitting the quite normalization black still touches all but 24 files. \nI have also added some documentation now. \nI would prefer to rebase once we are happy with the documentation and everything else because there will always be merge conflicts as of now.\nEdit:\nWhen adding black to the dev-requirements.txt\nTravis will fail the py35 build as black requires python 3.6. Hey, \nsorry about not getting back to you on this earlier.\nWe should probably move therapist and black to its own requirements.txt file (maybe something like lint-requirements.txt) as, like I said travis will fail the py3.5 build because it cannot install black.\nI will adjust the documentation accordingly if that is okay.\nI will only be able to work at this later tonight though after work. Okay - so I went ahead and got rid of my changes because I did not feel like merging 40+ merge conflicts.\nThis commit now has everything we had earlier with the additional changes that we now have a lint-requirements.txt file as well as adapting the documentation.\nThe code has not yet been formatted with black so it will be easier for me to rebase it once we are ready to merge.. Alright - I ran black and merged the conflict. Yes, when testing against Postgre I get the original error that you posted in the issue. If I just use the BaseWebTest then I was unable to reproduce the error.. Don't you have to tell therapist to create the hook in your .git dir?. Yes I should have removed it in travis. . ",
    "adebisi-fa": "Woops! Kinto all the way.  It worked!\nThanks @Natim! So so much grateful!\nThanks, please.\n. Would be nice to have all acceptable issuer values for the common OpenID Connect Providers, at least, in the documentation.\nSpent a good part of today looking around for this value.  And the providers' documentations didn't help either.\nThanks, once again @Natim.\n[Apologies for posting after issue has been closed.]. I'll do that, asap.  Thanks!\nAs a side note, I noticed that the Yahoo OpenID Provider doesn't support the email scope, as such  I couldn't login into the kinto-admin with it. \nA careful examination also shows that specifying only openid is enough to get the email claim from a provided Yahoo JWT token. (This is unlike some providers, e.g. Google, that requires explicit email scope to get the email into their token).\nTo solve login into kinto-admin, can OpenID providers scopes for the kinto-admin plugin be configurable to allow provider specific scopes, instead of using the generic openid & email, for all enabled providers?\nThanks, please.\n[I added this here to keep all Yahoo OpenID issues in one place.]. ",
    "yatinmaan": "This issue seems to be fixed already (in 8172d312a421540d7d8278a80733cb8ebd97fd60).. ",
    "schobewankenobi": "Requesting another review @leplatrem , since Travis is finally building correctly.. Added the aslist, was not aware of that in Pyramid (haven't used Pyramid!).. ",
    "jeff-tista": "Added a line, let me know if that's satisfactory. Thanks!. Travis seems to be failing for an unrelated reason..hm.. Thanks for the opportunity!. ",
    "abk-code": "In order to fix this, do we need to install Py3.6? I don't see these warnings in \n.venv/lib/python3.5/site-packages/webob/acceptparse.py file. . Thanks, I will pick this one up. But may need some help.\nhttps://github.com/Pylons/pyramid/pull/3326 : That has similar \nissues for a different method. I wonder what is the recommended\nway. Also using iPython3 (or jupyter) is there a way to see this warning?\n(Basically trying to recreate, apply a fix and  unit test before I  implement\nthe code for Kinto) . I wonder if this is also related:\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1625599#c11. Ok, thanks. Where do I see the right method to use instead of this old method?\nSpecifically for 'best_match' . Thank you. How do I unit-test to make sure my changes are fine? . Can I work on this ?. PR here: https://github.com/Kinto/kinto/pull/1783 . Few questions: \n1. I see assertEquals being used in many other files. Is the goal here to remove all the usage\nor only in test_utils.py ? \n 2. I picked backend as postgresql and cache as memory while testing. Is that  right?\nThanks.. @leplatrem : How do I add reviewers here? I can't seem to assign the names.. Thanks much. I've made the modifications requested. Please review. . Test results are as below.\ntox -e flake8\nGLOB sdist-make: /home/abk/kinto/setup.py\nflake8 inst-nodeps: /home/abk/kinto/.tox/dist/kinto-10.1.2.dev0.zip\nflake8 installed: appdirs==1.4.3,bcrypt==3.1.4,certifi==2018.8.24,cffi==1.11.5,chardet==3.0.4,colander==1.5.1,colorama==0.3.9,cornice==3.4.0,cornice-swagger==0.7.0,dockerflow==2018.4.0,flake8==3.5.0,hupper==1.3,idna==2.7,iso8601==0.1.12,jsonpatch==1.23,jsonpointer==2.0,jsonschema==2.6.0,kinto==10.1.2.dev0,logging-color-formatter==1.0.2,mccabe==0.6.1,packaging==18.0,PasteDeploy==1.5.2,pkg-resources==0.0.0,plaster==1.0,plaster-pastedeploy==0.6,pycodestyle==2.3.1,pycparser==2.19,pyflakes==1.6.0,pyparsing==2.2.1,pyramid==1.9.2,pyramid-multiauth==0.9.0,pyramid-tm==2.2,python-dateutil==2.7.3,repoze.lru==0.7,requests==2.19.1,simplejson==3.16.0,six==1.11.0,transaction==2.2.1,translationstring==1.3,ujson==1.35,urllib3==1.23,venusian==1.1.0,waitress==1.1.0,WebOb==1.8.2,zope.deprecation==4.3.0,zope.interface==4.5.0\nflake8 runtests: PYTHONHASHSEED='563059735'\nflake8 runtests: commands[0] | flake8 kinto tests docs/conf.py\n______________________________________ summary ______________________________________\n  flake8: commands succeeded\n  congratulations :). Can someone please review? . ",
    "srivama": "Hey! Can I work on this issue? Also can you please elaborate on the issue? Thanks :)\n. ",
    "Pac23": "@Natim @leplatrem has this been done ? if not can i work on this ? . I will then @leplatrem asap. Can you provide a rundown of some sort. Any pointers that you might want to add? I did understand that I simply have to make the changes in the argparse section and add the command as an argument. . @leplatrem thank you for the info, expect a pr soon. . @leplatrem i have made a pr,i think i am on the right track as far as the parsing goes, not sure if registry.cache.flush() is the function to actually call. . sure will write a doc \nwhenever i build from source using make serve the cli does not work,adding a path in the os env too leads to a command not found error. Is there a way to fix this on debian based systems ? . > What do you mean the cli doesn't work? How do you run it?\n\n.venv/bin/kinto flush-cache --ini kinto.ini\n~/kinto/kinto$ .venv/bin/kinto flush-cache\n/home/rhubscher/kinto/kinto/kinto/core/initialization.py:555: UserWarning: HTTPS is not enabled\n  warnings.warn(\"HTTPS is not enabled\")\nINFO   Running kinto 12.0.0.dev0.\nINFO   Cache has been cleared.\n~/kinto/kinto$ .venv/bin/kinto start\n/home/rhubscher/kinto/kinto/kinto/core/initialization.py:555: UserWarning: HTTPS is not enabled\n  warnings.warn(\"HTTPS is not enabled\")\nRunning kinto 12.0.0.dev0. \nRunning kinto 12.0.0.dev0. \nStarting server in PID 3983.\nServing on http://localhost:8888\n\ndid the same did dont work on my debian machine,but the same worked on a fedora vm.I guess this is some env prob on my deb machine. . > The tests seems to be sufficiant, can I let you write a bit of doc about the new kinto command?\nDone added documentation. . > Thanks for the hard work!\n@leplatrem i would like to do more open issues/contributions. Is there anything that has not yet being picked up for someone. . @leplatrem that has been tested, works documentation is remaining. . i was thinking maybe if in the future someone needed to add another flush functionality,they could simply add a subparser underneath this. \nI will refactor this asap with just flush-cache . @Natim @leplatrem what cache clean function is being used exactly there are two flush funcs one in /core/cache/memory.py and the other one is memcached.py in the same directory,also i have noticed postgresql has its own flush function writtern.\ni am asking this because implementing/calling any of the three cache.flush(), leads to test failures in test_cache.py some help would be awesome. . will do :+1: \nalso what i dont get yet is how does this work without me referencing to an instance of the cache class,i can't simply call the cache class directly,imo this shouldn't work. \ni also asked This on reddit on /r/learnpython and others were confused as well. . yeah that's what i meant it wont work,what instance am i supposed to call here? for it to work \ni am kinda confused,help would be really appreciated.\nRn the solution i have worked out is to write a func in the scripts file that inherits from the cachebase and initiates the cache flush as per the specific backend. I am sure there is a shorter way to do the flush. . oh,this helps a lot thanks :smile: . will refactor asap . will do . yes . @leplatrem i implemented that and @Natim tested it as well,i don't see the code you are referencing in my fork. :thinking:   . Done, also fixed the collections subparser which was similar. Also, the formatting between the if statements was not as per the standard. Fixed that aswell. . @leplatrem Done, although can you elaborate as to why the usage:should was to be removed? I see that every other function description in the rst file has it. . Done.. No worries,. ",
    "faanq": "@leplatrem Please review. ",
    "anshvyas": "Hey, @leplatrem I am interested in taking up this issue. I am a newbie to open source contribution. . Hey @leplatrem ,\nOn it. . Hey @leplatrem,\nThe command $ py.test tests/test_views_schema_record.py runs successfully without any errors but the command $ make tests show certain failing test related to MemcachedCacheTest. How do I proceed with this?. Thanks, @glasserc.\nCan you explain to me how the schema_validation.py gets executed in the following line\nresp = self.app.put_json(\n            COLLECTION_URL, {\"data\": {\"schema\": newschema}}, headers=self.headers, status=400\n        )\n. Thanks @leplatrem That was helpful in understanding the flow.. ",
    "anselmos": "Hi @leplatrem, \nIt may be a way for /batch subrequests to reuse one instance for validation - but that would propably require some changes at Record process_record method or invoking it outside of Record and pre-fail before request reaches process_record method. WDYT ?. ",
    "peterr101": "I would like to take on this issue if it's still open?. Ok, so I am blocked on this issue for now or is there something else I should try in the meantime?. I updated the bravado_core to the most recent version that has the appropriate JSONSchema compatibility. The changelog and contributors list have also been updated; none of the other items on the checklist seem relevant? Is there anything else I may have missed before this commit can be merged?. Yes, sorry about that, it was duplicated by accident.. Hello, can I begin working on this issue? Is there anything else I should know before I begin?. is there a need to update the CHANGELOG here? It seems unnecessary since its just a minor fix of a depreciation warning?. Is there any need here to update the CHANGELOG? . Okay the changelog has been updated and the fix seems to pass all the tests.. For future knowledge how could I have known that this line would have been needed to be added as a dependency to this file as well? What steps could I have taken to figure this out on my own (new to open source and would like to learn more)?. I see - ok no worries!. ",
    "mmerickel": "try bumping pyramid-tm to 2.2.1 and see how things go. ",
    "benjamindhimes": "Is this issue still open?. ",
    "tedjacobs": "I am new to the pull request/contributing aspect of github. I'm at work but if I remember correctly I was searching for repos to contribute to and I didn't get to finish with yours just yet.. ",
    "itaisteinherz": "I'm closing this and opening another PR with just the added changes, since this PR got really crowded with commits for some reason.\nSee #1857.. @leplatrem Continuing the discussion from https://github.com/Kinto/kinto/pull/1855#issuecomment-434628803:\n\nI think the admin build should have a dedicated entry in the matrix instead.\n\nI'll add a dedicated entry to the matrix.\n\nIs that what you say that fails?\n\nNo, what I meant is that running (from the project root):\nbash\ncd kinto/plugins/admin/; npm run test\nfails.. @leplatrem I ended up using a simple bash check to build the plugin only on the main matrix entry (Python 3.7). This keeps the CI build as simple as possible and reduces unnecessary complications.\n47c6ef03317277aa1cf3f5fc9ab9625c281e012a. > @itaisteinherz why did you pick this option rather than adding something to the matrix?\nAs I wrote above:\n\nThis keeps the CI build as simple as possible and reduces unnecessary complications.\n\nFor every entry in the matrix, Travis has to start a container, install all of the necessary packages and frameworks on it, and finally start Kinto, and only then can it start the tests. Avoiding creating additional matrix entries makes the CI faster.. Why was this added? @Natim. suggestion\nas this will cause the incoherent userID behaviors.. suggestion\nThis was specifically noticed while using Auth0 and Google as multiauth policies.. suggestion\nOne simple solution is not to use Auth0 in conjunction with other auth policies.. suggestion\nThis is because Auth0 allows to fetch profile information from other providers,. suggestion\n- Add documentation on troubleshooting the Auth0 multiauth issue. (#1889). ",
    "bertjwregeer": "@Natim PEP0333 :-/. I'm working (slowly in my spare time) on WebOb 2.0 which should make it easier to catch the unicode decode errors by turning them into a webob specific exception that can easily be caught and dealt with.. ",
    "AnanthKumarVasamsetti": "Hi, can I take up this bug and work on. As I started my open source contribution this would be my first fix. ",
    "taus-semmle": "@Natim Awesome! I'm glad I could be of help.\n@glasserc Thank you for the kind words, but really I can't take credit for this -- it was all down to our automated analysis. Subtle bugs of this kind can be very difficult to catch \"by hand\".\n@leplatrem I'll add a change note. I also just realised that the def validate_from_bucket_schema_or_400 function has the same problem, so I'll add a fix for that. (I also notice that our analysis didn't catch that instance, so I'll be looking into extending it.)\nIncidentally, I notice that the tests are failing due to lack of coverage. I'm not terribly familiar with Travis CI, but I guess this means the function is never actually called in such a way that the default parameter is used? . I'm doing it now. Sorry for the delay!. :man_facepalming: Thanks for pointing this out! . ",
    "dependabot[bot]": "Dependabot tried to automerge this PR, but received the following error from GitHub:\nYou're not authorized to push to this branch. Visit https://help.github.com/articles/about-protected-branches/ for more information.\nAs a result, we've disabled automerging on this repo (you can re-enable it in your Dependabot settings).. Dependabot tried to automerge this PR, but received the following error from GitHub:\nYou're not authorized to push to this branch. Visit https://help.github.com/articles/about-protected-branches/ for more information.\nAs a result, we've disabled automerging on this repo (you can re-enable it in your Dependabot settings).. Dependabot tried to automerge this PR, but received the following error from GitHub:\nYou're not authorized to push to this branch. Visit https://help.github.com/articles/about-protected-branches/ for more information.\nAs a result, we've disabled automerging on this repo (you can re-enable it in your Dependabot settings).. Dependabot tried to automerge this PR, but received the following error from GitHub:\nYou're not authorized to push to this branch. Visit https://help.github.com/articles/about-protected-branches/ for more information.\nAs a result, we've disabled automerging on this repo (you can re-enable it in your Dependabot settings).. \ud83c\udf89 This is the 500th Dependabot pull request merged for Kinto! \ud83c\udf89\nCan we use this moment for a quick request of our own?\nWe're always trying to get more people using Dependabot. If you tweet about us or tell a friend then we'll be forever grateful.. Looks like this PR has been edited by someone other than Dependabot. That means Dependabot can't rebase it - sorry!\nIf you're happy for Dependabot to recreate it from scratch, overwriting any edits, you can request @dependabot recreate.. A newer version of jsonschema exists, but since this PR has been edited by someone other than Dependabot I haven't updated it. You'll get a PR for the updated version as normal once this PR is merged.. ",
    "MichaelKohler": "Thanks, we could recover the password.. ",
    "fbertsch": "@Natim done and done. ",
    "palutlaanirudh": "I would like to contribute to this issue. Can you guide me on how I may help?. "
}