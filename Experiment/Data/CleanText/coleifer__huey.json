{
    "coleifer": "Yeah, totally, just been too busy\nBut it's on my list\nOn Dec 30, 2011, at 2:29 AM, coderbuzz\nreply@reply.github.com\nwrote:\n\nCan you provide some doc / example to show how to use this library?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/coleifer/huey/issues/1\n. Started work on docs, http://charlesleifer.com/docs/huey/\n. I've added your change but left a note that django-admin works, too.  Thanks for suggesting this.\n\n31756ea83e5a010ea44d04f8d3abfe444406738b\n. Glad you like it :D\n. Cool idea -- will merge!\n. phew, thanks mane!\n. Thanks for catching this!  And bonus points for a testcase.\n. I cherrypicked a6629b6 but will leave th gitignore as this is something generally personal.  I have a global one that i use.\n. thanks for adding this.  travis-ci doesn't seem to come up on my browser...and their ssl cert is invalid?  who are these clowns!\n. the functions accept a time parameter so we can test them as well as ensure that multiple calls to the same function can receive the same time for \"now\".  just looking at the commit...what the difference, did you just rename a bunch of vars?\n. All tests pass for me locally so I'm not sure why you changed the testcase.\n. I would like to add this.  I can pretty easily add this for normal tasks, but it is harder to do for \"periodic\" tasks.\nFor normal tasks: on revocation, simply remove them from the queue\nFor periodic tasks: these are \"tracked\" in a registry that is populated on startup.  A separate thread runs every X seconds and sees if any of the given tasks need to run.  If so, they are enqueued.  All instances of a periodic task have the same task id.\nThere is currently no way to signal the registry that a task should be removed from the periodic execution group, but if there were it would essentially guarantee this periodic task did not run again until the consumer was restarted.  If we're just talking about not running a periodic command \"the next time\" its supposed to run, again there's not really a good way but we'd need a different solution than simply removing it from the registry.\nWe could use the datastore to track what commands are not to be run, and simply check the datastore before executing a command...that'd probably work fine, but is messier than simply removing something from the pending queue of items.\n. I've started work here: https://github.com/coleifer/huey/compare/feature;revoke-tasks\n. Making some good progress!\n:hamster:\n. Finished, added docs:\nhttp://huey.readthedocs.org/en/latest/getting-started.html#preventing-tasks-from-executing\nAlso see the API docs:\nhttp://huey.readthedocs.org/en/latest/api.html\n. http://huey.readthedocs.org/en/latest/getting-started.html#executing-tasks-in-the-future\nThis uses the .schedule() api.\nSo,\n``` python\nright now\nsend_mail('some.body@gmail.com')\nin 2 seconds\nsend_mail.schedule(args=('some.body@gmail.com',), delay=2)\n```\n. no worries, delay is a nice api\n. I would try:\nhttp://docs.python.org/3.1/library/functions.html#bytes\n``` python\ncommand_data = pickle.loads(bytes(data))\n```\n. Haha, thanks for the tip:\n7907e42a3e7eaa6014b07c0b515a19b72881e81e\nThis should resolve the issues w/pickle i hope :put_litter_in_its_place: \n. I think the issue is that you still need to specify which minute to run things at.  The crontab is covered by unit tests and i have not had issues with it myself.\nTry this and let me know:\n``` python\nevery other hour, on the hour\n@periodic_command(crontab(minute='0', hour='*/2')\ndef foo:\n    pass\n```\n. It uses UTC by default:\nhttp://huey.readthedocs.org/en/latest/api.html#module-huey.bin.config\nIf you want, set UTC = False in your config\n. From the author of python-daemon,\n\nA well-behaved Unix daemon process is tricky to get right\n\nFor code clarity, this is not provided as a part of 'huey'.  Adding this would require a dependency outside the standard lib, which I'm not really interested in adding.  If you want, though, you should be able to very easily use:\n- http://pypi.python.org/pypi/python-daemon/\nI run all my web apps and consumers using supervisord.\n. The time it takes you to type Res.get in the interpreter is sufficient for the results to be ready. When executed all at once there isn't enough time for the results to be available.\nTry a time.sleep in your script to see the effect..that's basically what blocking=true does... or read the docs or code to see more.\nAlso yes it returns before results are ready. That is kinda the idea.\n. I might be missing something, but can you not just do x.command.task_id ?\nAlso, I do not want to change the return value of .get() because a string uuid could be a valid response.\n. On the other hand, you can always run multiple instances of the consumer.\nIf you implement multiprocessing that'd be sweet.  There shouldn't be any gotchas.\n. @apendleton -- thank you very much for all the hard work you've put into this patch.  I agree, the Consumer is a bit of a mess.  I'd like to get it cleaned up one of these days.\nAs to your patch, unfortunately I don't think that this is going to be something I'll be merging in.  The scope of the changes is pretty large, even though I'm sure you've done everything that was possible to minimize them given the structure and design issues inherent in master.  I use huey myself for a number of things and it's served me well, but I know it needs improvement and I'm a bit concerned that merging these in may make further large changes difficult.\nI apologize for being so slow responding, I usually try to be a better maintainer.  Thanks for the work, there are some really neat ideas here.  For now I will pass on merging and look to a larger-scale refactor down the road.\n. I replied -- basically need more info!\nOn Mon, Feb 18, 2013 at 6:22 PM, jakubzitny notifications@github.comwrote:\n\nHi,\nI'd like to try huey out, but I'm stuck with the configuration issue.\nAccording to your tutorialhttp://huey.readthedocs.org/en/latest/getting-started.htmlI should start the consumer with the\nhuey_consumer.py main.Configuration command, but it returns Unable to\nimport \"main\". I know it's mentioned in common pitfallshttp://huey.readthedocs.org/en/latest/troubleshooting.html,\nbut it's not really helping me. Could you please help me to complete the\ntutorial? I'm quite new to python also.\nI have also written on SOhttp://stackoverflow.com/questions/14947671/where-is-the-huey-consumer-configuration\n.\nThanks.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/coleifer/huey/issues/19.\n. @n3storm -- are the files you are trying to import dynamically on your python path?  I think that may be the problem.\n\nHere's an example... install huey in a new virtualenv:\n``` sh\nvirtualenv htest\ncd htest && source bin/activate\npip install huey\n```\nThen put the config file in lib/python2.7/site-packages/example.py\nSwitch dirs back to the root of the virtualenv.  Observe it works fine:\n``` sh\n$ huey_consumer.py example.Configuration\n```\n. As I understand the problem is you do not want a task to be interrupted if the consumer is asked to shut down.\n. I definitely understand not wanting a task that is halfway complete to be 'lost' if the consumer is halted, at that point the options are to\n1. re-enqueue\n2. halt in a half-finished state (current behavior)\n3. block until complete\nI'm not very clear on how this patch changes the current behavior would you mind explaining your changes?\n. Thank you for the comments.  I think that right now I'm looking at doing some refactoring in the library so I will not merge these changes as they're a little unique to your use-case.  I appreciate the input!\n. Thank you, this should be covered by #19\n. It depends.  If you have the RAM to spare, you could just run 20 huey consumer processes, one for each application.\nDo these tasks operate on 20 different databases?  If so you're probably best off looking at running 20 consumers.\n. I don't think this will actually work because an in-memory database cannot be shared by two processes (your producer process(es) and the huey_consumer).\n. @boblefrag -- If you wanted to add configuration to accept a database file name that'd be all you needed to make it work.  Then the only requirement would be that the producers and consumers were either on the same physical machine or could access the db over a networked file system.\n. What about simply running multiple instances of the huey_consumer process with a single worker thread?\n. > You end up duplicating a bunch of infrastructure around scheduling.\nYes, this is true and would need to be addressed.\n\nIt greedily pulls things off of the shared Redis queue and pushes them into a local work queue within the consumer process.\n\nIt actually only pulls one extra task...so if you're single threaded and receive three tasks (A, B and C), the worker will start working on task A, task B will be sitting ready in an in-memory queue once the worker gets free and task C will stay in Redis until the worker picks up B.\n. I'll look into re-organizing the code, thanks for the ideas.\n. I've rewritten much of the consumer code -- things should hopefully be quite a bit simpler to work with now.\n. Master contains some changes to add multiprocessing and greenlet worker classes. Still working out the kinks, but that's the direction huey is headed.\n. Apologies for the confusion thanks for bringing this to my attention.\n. What version (or sha) of huey are you running at the moment?\n. I've updated the docs.  If you are running off the master branch, then these are correct: http://huey.readthedocs.org/en/latest/django.html#huey-settings\n. I agree -- it is probably better to make this configurable rather than based on what settings.DEBUG is.  Thanks for the PR, will merge.\n. I will try to review this later today - thanks for your work!\n. This is pretty neat, I really like the thought that went into this!  Great work.\nI think the only thing I would like to see is that the pubsub logic be integrated with the huey_consumer script.\nIf you want to add a BasePubSub, DummyPubSub and RedisPubSub implementation then we could treat it as another pluggable component in the architecture (although to date I don't know of anyone using anything but redis, so maybe that's silly).  Could add hooks in the consumer and, if a pubsub component is specified, send messages on it.  This would remove the need for a separate mgmt command and consumer, at the expense of a little more optional configuration checking.\nWhat do you think?\n. Yeah, started/completed/error/retrying sounds good.\nAs to task names...since the name of the class in the registry is serialized along with the task ID, it might be OK to just look at that.\nCheck out registry.task_to_string(type(task))\n. Looks like I forgot it, so I pushed a new version 0.4.1\n. @asmedrano -- I will not be able to re-review this until Monday.  Thanks for re-submitting!\n. I've made a few commits to add an event publishing system to huey.  It's similar to your implementation, but fits in a little more closely w/the existing patterns.  I need to add docs, but you can check the code in huey_consumer.py to see what is getting sent.\n. You need to install the python bindings to redis:\npip install redis\nSorry for the confusion.  Also, you will need the redis server running on your machine: http://redis.io\n. Believe me you are not the first person to be tripped up by this.  I tried to add a troubleshooting section to the docs, but clearly the error message is garbage and needs to indicate the actual problem.\nI will push a fix for this.\n. Hmm, that's odd.  What error do you get if you try to run from main import huey ?\n. Try:\nhuey = RedisHuey('testing', host='localhost', port=8778)\nOn Tue, Jun 11, 2013 at 11:37 AM, Sam Zaydel notifications@github.comwrote:\n\nThis seems to suggest that huey =\nRedisHuey('testing',{'host':'localhost','port':8778}) is my issue, but it\nseems perfectly correct.\n(tasks)bash-3.2$ python -c 'from main import huey'\nTraceback (most recent call last):\n  File \"\", line 1, in \n  File \"main.py\", line 1, in \n    from config import huey\n  File \"config.py\", line 3, in \n    huey = RedisHuey('testing',{'host':'localhost','port':8778})\nTypeError: init() takes at most 2 arguments (3 given)\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/coleifer/huey/issues/31#issuecomment-19273850\n.\n. Thanks for this!\n. The crontab has a resolution of 1 minute.\n. I do not plan on making <1 minute supported for the cron.\n\nIf you could tell me a little about what you're building I might be able to suggest some alternatives though.\n. Hmm...well, the scheduler runs every second so theoretically you could use the crontab to schedule your metrics-collecting tasks, but that seems really hacky.\n. What kind of monitoring system would that be? What kind of monitoring will the tasks be doing, and with what frequency?. Thanks for the explanation. The reason I asked is because I have a sense that a general tool like Huey may not be the best fit for what sounds like a very specific, latency-sensitive application.\nYou could very easily write a simple script that delegates the monitoring checks to a handful of worker threads/processes. Just have the main thread run an endless loop and on given intervals delegate work to your pool.\nDo you even need a task queue? I mean...if you're just running a single task over and over, why do you need a queue at all?. If its not latency-sensitive, and you don't really care when the data will be available then....what??. You want to spam the shit out of some ~1000K (1 million?) servers, you don't really care about latency, you don't really care if there's missing data... yeah, don't use huey. Please.. There are many existing linux utilities for this.\n. I believe it should be configured automatically if you are using redis.  The channel used will be the same as the queue name.\n. Good catch, thanks mane\n. The Django logging documentation doesn't give any hints (that I could see) for developers of third-party apps.  Do you have a suggestion for implementing this?\n. I believe this may be fixed by 5bc208d3 -- can you give it a try?\n. Thank you for this, I did not notice this bug.\n. My preference would be for you to maintain this as a 3rd party backend rather than adding it directly to huey.  I do not use mongo myself nor do I feel qualified to evaluate your design.  For this reason I'm not interested in taking on the maintenance of this backend should it be part of the huey repo.\n. Thank you, though!  I appreciate you sharing your code with me.\n. I have not experienced this issue myself, and I have several huey processes that have been running for months.  Can you give me the details on your task?\n. When you instantiate your Queue object just pass in the parameters you would pass to redis:\npython\nqueue = RedisQueue('my-app', host='1.2.3.4', password='secret')\nhuey = Huey(queue)\nOr if you're using the shortcut:\npython\nhuey = RedisHuey(host='1.2.3.4', password='secret')\n. Sorry, been on vacation the past week.\nDocs: \n- http://huey.readthedocs.org/en/latest/getting-started.html#getting-results-from-jobs\n- http://huey.readthedocs.org/en/latest/api.html#AsyncData\nPlease reopen if this does not answer your question.\n. You can construct an AsyncData object by hand. Or simply pass the task I'd to huey._get().\nFor granular info store task state in a table you manage.\n. I wonder if the problem is with the decorator...\n``` python\ndef close_db(fn):\n    \"\"\"Decorator to be used with tasks that may operate on the database.\"\"\"\n    def inner(*args, kwargs):\n        try:\n            return fn(*args, kwargs)\n        finally:\n            close_connection()\n    return inner\ndef db_task(*args, kwargs):\n    def decorator(fn):\n        return close_db(task(*args, kwargs)(fn))\n    return decorator\n```\nShould that instead be:\npython\ndef db_task(*args, **kwargs):\n    def decorator(fn):\n        return task(*args, **kwargs)(close_db(fn))\n    return decorator\n. Updated the decorator, I believe this should fix the issue.\n. A partially-finished task that is interrupted will not be resumed. A task that has not been started yet will be picked up and processed when the consumer is restarted, however.\n. Yes, you can specify a name. The default is queuecmd_<the func>, but you can give it a more helpful name.\n. > I just remembered the original question that led to this. Is there way to modify the task name when it gets ran? I'd like to add some meta data to the message the event emmiter produces.\nThat sounds like quite a hack!\n. I would recommend using a data-store for that, i.e., when the task starts, put a record in the db.\n. No, but that's not a bad idea.\n. You can try using a process manager like supervisor or upstart to run your huey consumer. This isn't exactly a bug with huey so I am closing.\n. Also, check out -n or --no-periodic -- you can use that to start a consumer without periodic tasks: http://huey.readthedocs.org/en/latest/consumer.html#options-for-the-consumer\n. @jbaiter -- this is awesome, thank you!  Do you mind if I pull it down and maybe make a few tweaks here and there?\n. I haven't forgotten about this, just so you know. Been very busy between work and writing a book, but I hope to look at this asap.\n. Cool, awesome work man, let's merge it and go from there.\n. Thank you for all the effort you put into this!\n. Yeah, I'm testing with py3k and, aside from that test, there seem to be a multitude of other failures and errors.\nEdit ok, most are related to metaclass issues.\n. Fixed.\n. Oh wow... did you do any profiling to see what was hurting the most with SQLite?\n. Very nice, look forward to it!\n. As cool as this is, I don't think I will be merging as I don't want to maintain a backend I don't think I'll use. Thank you very much for your work. Maybe I can add a contrib submodule to huey and that would be a good place for things like this?\n. It uses threads and not processes.\n. Yep, memory usage. I've got a open GH issue to support process-based workers, but currently huey relies on a lot of shared state so that may be a while off.\nNo built-in way to monitor workers at the moment. There is an event emitter you can configure to \"monitor\" events as they occur but it's fairly low-level.\n. http://huey.readthedocs.org/en/latest/consumer.html#consumer-event-emitter\n. Hmm... I'm not sure what could have happened. I tested the dbtask changes by hand locally.\n. Is there any way you can share with me the output logged when the consumer starts up?  It should log what commands it has found, e.g.:\npython\nMainThread 2014-03-07 09:07:12,922 huey.consumer INFO Setting signal handler\nMainThread 2014-03-07 09:07:12,922 huey.consumer INFO Huey consumer initialized with following commands\n+ try_thrice\n+ foo\n+ every_five_mins\n+ count_beans\nMainThread 2014-03-07 09:07:12,922 huey.consumer INFO 2 worker threads\n. You can add django settings to specify logging for the consumer. The following should log to standard out, which will get picked up by supervisor:\nHUEY = {\n    ... whatever your options are ...\n    'consumer_options': {\n        'loglevel': logging.DEBUG,  # add this.\n       ... other consumer options ...\n    }\n}\n. @tijs -- I believe I have fixed the issue. Is there any way you could try pulling master and letting me know if things work?\n. I don't believe I've changed the logging code in a while, so I'm not sure what may have happened.\n. Good deal ,thanks for working with me on this one. Yep I'll push a new release.\n. Pushed 0.4.2\n. Check out the django example code:\nhttps://github.com/coleifer/huey/tree/master/examples/django_ex\nIf you've already done this, can you share the relevant portion of your settings module?\nis djhuey in your installed apps?\n. Nice, looks clean. I'll check it out this weekend.  Thanks for all your help with this project!\n. Not at the moment, though it probably could have led to a bit cleaner sqlite implementation.\n. I think the thing I like best about huey is that it has no deps outside the standard library (except if you're using redis).  For that reason alone, I have avoided using peewee.\n. I'm not sure what could be causing that. Can you provide any more info?\n. Things that might be interesting:\n- Does it happen only on regular tasks, or periodic/cron tasks?\n- Does it happen only when running one particular task?\n- Does it happen at a specific time?\n- Does the task that is being executed run for a long time (more than a few minutes)?\n. > Any way to retry the task if it fails?\nYes, you can try @db_task(retries=3) for example.\nHas this still been an issue?\n. Sure!\n. Closing since no activity.\n. See the docs:\nhttp://huey.readthedocs.org/en/latest/getting-started.html#executing-tasks-in-the-future\nYou would write:\n``` python\n@huey.task()\ndef my_task():\n    print 'whatever'\nmy_task.schedule(delay=300)\n```\nIf you want to always delay execution for 300 seconds, then you could write a helper function:\npython\ndef my_task_delayed():\n    my_task.schedule(delay=300)\n. When instantiating a RedisHuey object, you can pass in arbitrary conn_kwargs which are passed back to the Redis connection instance. As you can see, the default db is 0 but you can specify a different one:\nhttp://redis-py.readthedocs.org/en/latest/#redis.Redis\npython\nhuey = RedisHuey('whatever', db=13)\n. Cool, good lookin out!\n. But...sqlite is part of the python standard library. Is this a real issue?\n. Interesting, I thought that sqlite was just a given (like the datetime module). OK that makes sense then!\n. When I wrote huey, which was some time ago, it was partly in response to what I perceived to be the extreme complexity of celery. Before 3.0, celery had lots of dependencies and required lots of configuration.\nHuey differs from celery in that:\n- Less dependencies\n- Less configuration\n- Threaded model as opposed to multi-process\n- Less features\nI designed huey for people who need a task queue for simple things like:\n- sending emails\n- generating thumbnails\n- making API calls\n- checking spam\nIf you have any of the following needs, then celery is probably a better choice for you:\n- CPU-bound tasks.\n- Distribute tasks to multiple processes, possibly on multiple hosts.\n- Dedicate particular workers to particular tasks.\n- Sophisticated workflows.\n- Auto-scaling and built-in rate-limiting.\n. For compatibility, maybe try to import close_old_connections and failing that, import close_connections as close_old_connections?\n. I've gone ahead and changed the code to: 4234d7f294d641d8faa597702ee6d766bcd4c1bb\n. gg\n. Wow that's a really strange one... Perhaps different versions of python / pickle between your client and server?\n. > so do you think it could be the contents of the data I'm passing into the task?\nYeah, I think that's it. Can you tell me anything about the data you're passing?\n. Try passing in the models primary key instead, and re-querying the model instance inside the task.\n. Can you include a test-case? I can't verify the unicode failure locally -- it seems to be working correctly for me.\n. I'd like to know a bit more what the nature of the error is. Apparently one of the parameters has a bool when huey expects both to be datetimes, which indicates something is wrong higher up the stack.\n. I can investigate, thanks for reporting.\n. I haven't seen this problem myself. Tasks get added to the schedule when they need to be executed in the future, and they are removed from the schedule when they are ready to run.\nHow are you calling your tasks? Can you provide any info about your tasks?\n. > When I run my test suite, when a test calls a huey task, it seems to kick off a new instance of huey.\nWhat do you mean a new instance of huey?\n\nIs it possible to either (1) force the test suite to use the existing huey process running under supervisortctl\n\nI'm not sure I understand -- how would huey know about an existing huey process?\n. > If I run ps -aux | grep huey before running my tests I have one entry for manage.py run_huey. After running my test suite once, there will be two. Each time I run the tests it increments so when I first discovered this error there were 7 run_huey processes.\nWhat test suite are you referring to? The huey tests?\n\nWhen huey tasks get called in my tests, instead of using the existing run_huey process, the tests will start a new one\n\nI'm not sure why this is happening, but there is no code in huey that will auto-start a run-huey.\n. Pushed 0.4.3!\n. That is definitely odd... Have you tried the example Django app that comes with the code link? I believe that should work correctly. I don't believe this is a bug in huey, but maybe a config issue?\n. Ahh, so you have the task ID and wish to cancel it some arbitrary time later?\n. If so, you can try:\npython\nfrom huey.api import QueueTask\nfake_task = QueueTask(your_task_id)\nhuey.revoke(fake_task)\n. Yeah, if you don't mind opening a PR I'd love to take a look at the implementation. Thanks for opening this issue!\n. Looking good - there are some travis-ci issues, but doesn't look too bad. I'll take a closer look in the next day or two.\n. I would suggest packaging this up as a separate package. Huey can use backends that exist as separate packages, and I honestly don't want the maintenance burden.\n. If you do release this as a separate package, please let me know and I will mention it in the documentation.\n. Yes, this needs to be fixed. I will look into it.\n. Fixed.\n. Thanks friend!\n. Not yet, but I'd definitely merge a rabbitmq backend implementation.\n. Closing this as this was mostly added in #82 \n. Not really, I'll try thinking about it some more...\n. I prefer the explicitness of setting the pythonpath and relying on that to work, rather than adding cwd to the path.\n. I believe this should fix part of the issue: eb5c096ad029fbb498ae11764211a8ac9a97dd12\n. I tested by running the consumer, killing Redis, then re-starting Redis. I was able to send and schedule tasks after the restart.\n. This should be fixed.\n. Oh no, is this with the very newest release, 0.4.4?\n. OK I believe i've fixed this. I'm going to blow away the current 0.4.4 and push a new release.\n. Just created 0.4.5 release and push to pypi. Thank you for the quick bug report, really appreciate it!\n. I tried it out locally with 1.8 and the fix I merged seems to have worked. Can you explain? Did you try it and it broke?\n. Alright, hopefully we're good to go. Pushed 0.4.6 with your suggested change.\n. And thanks again for your help with this!\n. Hmm, I'm not sure as I haven't run into this particular bug before. Technically huey isn't ever daemonized, it just runs in the foreground and supervisor keeps an eye on it. I checked on my server and when I restarted the PID changed and there was only ever 1 instance running.\n[program:blog_queue]\ndirectory=/whatever/path/\ncommand=/path/to/bin/huey_consumer.py blog.main.huey --logfile=/path/to/huey-blog.log -S 300\nuser=whoever\nautostart=true\nautorestart=true\nredirect_stderr=true\nstdout_logfile=/path/to/huey_supervisor.out.log\nstderr_logfile=/path/to/huey_supervisor.out.err\nenvironment=PYTHONPATH=\"/whatever:$PYTHONPATH\"\n. I'm not quite sure what to do here...I'm unable to replicate this bug locally. Closing for now.\n. Actually that may be the problem... Huey will keep running until the long-running task finishes.\n. OK, that's good to know about the tasks in your app. I'll audit the code and see if I can find any issues.\n. One thing, do you mind sharing the invocation you use to start huey consumer?\n. Thanks @miohtama -- I'm going to take a look and see what I can see. When you run huey using the following invocation directly from the shell what happens when you press Ctrl+C?\n``` console\n$ cd /srv/django/tatianastore\n$ /srv/django/tatianastore/manage_wrapper.sh run_huey --periodic\nWait til huey starts up, then press Ctrl+C.  What happens?\n```\n. Alright I was able to replicate this locally and the issue is the fact that you're using a bash script to run the consumer. When I used a bash script to invoke the consumer, the consumer would continue running indefinitely. When I replaced the bash script with a direct invocation of the consumer, it worked as expected.\nSo, here is how I would suggest changing your config -- I believe this will accomplish the same thing as your wrapper:\n[program:tatianastore_huey]\ncommand=/srv/django/tatianastore/bin/python /srv/django/tatianastore/manage.py run_huey --periodic\n. More info: http://supervisord.org/subprocess.html#pidproxy-program\n. The info in this comment is a bit outdated:  when huey consumer receives SIGTERM, it will not wait for any currently-executing tasks to finish.. With Huey, because of the GIL, only one thread will ever be running at a time. For CPUbound tasks this will be slower than a single thread. For IO bound tasks, huey will be faster.\n. Hi @antijedi / @deathowl -- I think I will pass on merging this. If you're interested in listening for events, check out the EventEmitter, which will emit enqueued, started, and finished events (as well as others).\n. > We were using huey and it was working well, but i had to change the database structure and adapt the task and now it takes hours to execute tasks that would take 30 secs if they would not be inside a task. \nI'm not sure I understand. So you were using huey in the past and it worked fine. You changed your database and now huey is taking hours, but if you run the code outside of huey it takes only 30 seconds?\n. That's incredibly bizarre. Perhaps the issue is with the use of db_periodic_task(). Does anything happen if you use periodic_task() instead?\n. I'm probably not going to at this time, thanks.\n. If you check out the tests, you can also see an example:\npython\npubsub = huey.events.listener()\nfor message in pubsub.listen():\n    handle_huey_event(message)\n. Interesting approach. I would prefer, though, to follow the \"retries_as_parameter\" approach and add an additional param to the @task decorator itself for including the instance, e.g.\npython\n@huey.task(include_task=True)\ndef my_task(foo, bar, task=None):\n    do_something_with_task_obj()\n. Looks great, just a couple minor things and I'll merge it up. Thanks for this.\n. You'll need to store a reference to the task's ID somewhere. When you schedule a Task, you'll get back an AsyncData object that can be used to retrieve the task's return value. This object also provides you the task object:\npython\ndata = some_task.schedule(args=('foo', 'bar'), delay=3600)\ntask = data.task\nTo revoke it:\npython\nhuey.revoke(task)\nThen rather than re-scheduling the task, just spin up a new task instance:\n``` python\nCreate a new task instance.\nnew_task = some_task.schedule(args=('foo', 'bar'), delay=3600)\n``\n. I believe @g-cassie is correct. I'm not sure the exact logging settings you need, but it should be easy since huey logs tohuey.consumer.\n. ThePeriodicTaskThread, which runs the cron-like tasks, is still running only once per minute though, so I don't think this has the effect you were going for.\n. This will force the periodic task thread to run once per second, so that tasks matchingsecond == 0` are sure to run. That is not a change I'm all that desirous of making.\nWhat if I add consumer options to allow you to configure the interval at which the periodic task thread runs, then you just write a custom validate function?\n. Haha nevermind, that option already exists (-P / --periodic-task-interval).\nOK, so I am going to pass on this one, but know that by changing the periodic task interval to 1 (from default of 60) and writing a custom validate function, you should be all set.\n. Probably an error in the organization of the code or how you're running it. Try the suggestions in http://huey.readthedocs.org/en/latest/troubleshooting.html\n. Maybe this can be parameterized, i.e. \npython\nqueue = RedisQueue(read_timeout=5) # default would be None, for no timeout\n. I think the real issue is the consumer crashing... can you provide any info about that?\n. To somewhat answer your question, there is an EventEmitter API which is poorly documented, but can be used to capture various events. You'll need to check the source code and tests for examples, unfortunately.\nI'm closing this for now, but please comment if you can provide info on the consumer crashes. That would be extremely helpful for me.\n. Alternatively I suppose Huey could use a lock of some sort. Has this come up in practice?\n. Yeah, I agree, the Lua idea is definitely the best option. Do you think you could put together a PR?\n. I think I will pass on this, but thank you. There are basic backend tests in huey.tests.backends.\n. Cool, is there any way you could modify this to use the Script API?\nhttps://github.com/andymccurdy/redis-py#lua-scripting\n. I imagine the script could be registered in the __init__() method on the RedisSchedule.\n. Thanks so much for making this happen!\n. Thanks!\n. Thanks!\n. > but if I define it as periodic task, after sometime all available workers will be working on this task.\nYou need to use some kind of locking. That, to me, seems like the correct approach.\n. I would definitely accept that PR.\n. Although I think the entry_points would be:\npython\nentry_points={\n    'console_scripts': ['huey_consumer = huey.bin.huey_consumer:main']\n}\n. fixed a typo in 2a160db. thanks for adding this.\n. See #33. Basically, I don't have plans to modify this.\n. Yeah, the way the periodic task runner works I'd be concerned that tasks that are supposed to run every minute would run 60x a minute.\n. It may be an easy fix, though...\n. @wldcordeiro -- if all of your tasks that run every minute also specify a second, you could simply set the --periodic-task-interval (or -P) to 1 when running the consumer.\nThis would ensure that the periodic task scheduler runs every second as opposed to the default of every 60 seconds. The hitch would be crontab tasks that execute at a particular minute. Because the periodic task scheduler will \"think\" the task is valid for 60 ticks during that given minute, it will be enqueued 60 times. Obviously not correct. The solution is to have all tasks that run on a particular minute also specify a particular second.\n. I think this can be closed.\n. Just to update as my comments are not quite correct anymore --\nYou can run tasks at intervals of 1 second. However, the crontab helper function that is typically used with the periodic_task decorator only supports a granularity of a minute, so you'll need to define your own validation function for sub-minute tasks.. Released 0.4.9\n. It probably depends on how soon after firing your task you are calling .get(). You probably need to call .get(blocking=True) if you want the call to block until there is a result value.\nhttp://huey.readthedocs.org/en/latest/api.html#AsyncData.get\n. Hmm, you could try the queue.flush() method.\n. And also you'll want to call schedule.flush().\n. That actually doesn't revoke tasks, it just removes everything that's currently in Redis. If you enqueue tasks subsequent to the FLUSH, they will get executed.. I think there's a race condition due to improperly implemented locking during the read.\n. The snippet the implementer of this backend references appears to do the right thing while reading, which is acquire a RESERVED lock. I think the author mistook the sqlite3 isolation_level parameter for meaning the same thing as explicitly executing BEGIN IMMEDIATE.\nI'll look into reworking the code.\n. I ended up killing off the SQLite backend in the 1.0.0 release of Huey, so this issue is no longer valid.\n. Huey emits events as it processes items (enqueued, scheduled, revoked, task started, task finished, task error, etc. These are poorly documented so perhaps that's a first step?\n. http://huey.readthedocs.org/en/latest/consumer.html#options-for-the-consumer\nSee -w, that is the number of worker threads.\n. For the moment, you can find them here: http://huey.readthedocs.org/en/0.4.9/\nI am doing some rewriting of the consuming APIs for the 1.0 release and so things are a bit in flux right now.\n. In master there are new methods:\n- http://huey.readthedocs.org/en/latest/api.html#Huey.pending\n- http://huey.readthedocs.org/en/latest/api.html#Huey.scheduled\n- http://huey.readthedocs.org/en/latest/api.html#Huey.all_results\n. Just use always_eager in your tests and you should be alright, right?\n. Thanks!!\n. Well, the monkey-patch needs to occur in the task instance loaded into RAM by your test. If you're running the consumer in a separate process, the patch needs to be applied there.\n. You know about always_eager, right? If not check the docs. I think that's\nwhat you are looking for.\nOn Jan 25, 2016 12:55 AM, \"Muromi Rikka\" notifications@github.com wrote:\n\nOK, finally found a way to test\nhuey_tasks.py\ndef _function():\n    import requests\n    print(requests.get('http://www.google.com'))\nfunction = huey.task()(_function)\nimport huey_tasks\n@patch('requests.get')\ndef call_patched(fake_get):\n    fake_get.return_value = '1'\n    huey_tasks._function()\nThen directly run test code without launching huey_consumer.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/coleifer/huey/issues/134#issuecomment-174419135.\n. Can you share how you're running huey (command, settings, options, etc)?\n. If you're running in debug mode, huey by default will assume you want to run tasks \"in-process\" for easier debugging. Since typically you are not using a separate queue process when developing.\n. Just update your huey settings dict to have always_eager=False.\n. Fixed, thank you!\n. Can you provide more information? How are you enqueueing your task? What parameters are you passing to the consumer?\n. So, behind the scenes, huey converts local timestamps into UTC. The utils.local_to_utc function does this:\n\npython\ndef local_to_utc(dt):\n    return datetime.datetime(*time.gmtime(time.mktime(dt.timetuple()))[:6])\nIt may not be correctly accounting for timezones, I'm not really sure as I'm not very familiar with Python's timezone implementation.\n. OK, so by default, Huey consumer treats date-times as UTC. When you call task.schedule() it will automatically convert the timestamp, which it assumes to be localtime, to UTC.\nSo if you're running your consumer with --utc=False, then when you call .schedule() you should pass in convert_utc=False:\npython\nmy_task.schedule(delay=10, convert_utc=False)\n. Yeah, peewee compares things to the current time (or current UTC time if the consumer is running without --localtime), and these do not have a timezone.\nWhere are your timestamps coming from? Is there a way you can convert them to naive before sending them to Peewee?\n. Released 1.1.1\n. Cool, looks good! Thank you.\n. I have no clue, but this sounds very much like a configuration issue as opposed to a bug in huey.\n. @Rand01ph, how many and what type of worker are you using with the consumer? Can you share any logs showing the issue, or steps to reproduce?. This would lead me to believe that redis isn't running on port 20000.\n. Huey supports a number of config options for running the consumer:\nhttp://huey.readthedocs.org/en/latest/consumer.html#options-for-the-consumer\nAnything else would be beyond the scope of running the consumer, and should be handled by the application. If you have some very specific use-case in mind I can try to respond more specifically.\n. +1 for not reinventing the wheel\n. > Additionally this makes it hard to unit test the task.\nSeparate your task logic from your task-decorated functions.\nI've merged a fix that will not close the db conn for always_eager=True. Thanks for the suggestion, I think it's spot-on. I am going to pass on merging the periodic special-casing, as I think it could be interpreted either way and it is easier to reason about without a special case.\n. Commit 653f0b1 adds a new method to the Huey object, Huey.result. You can now do something like:\n``` python\nfrom huey.consumer import EVENT_FINISHED\nfor event in huey.storage:\n    if event['status'] == EVENT_FINISHED:\n        result = huey.result(event['id'])\n        process_result(result)\n``\n. I should add that the data is deserialized by theresultmethod. Additionally, theresultmethod supports all the same arguments asAsyncData.get()` (so it can block, etc).\n. https://github.com/coleifer/huey/blob/master/CHANGELOG#L4-L15\n. Nice, thank you!\n. Uhhh... see if the process exists would be the obvious answer.\nYou could make a task that pings your dashboard but Linux can tell you that a lot more easily.\n. Hmm...peewee supports gevent, what about that? I'm not in love with the way the asyncio APIs require completely different syntax from the rest of Python and am not sure how to implement it in a compatible way. Any ideas?\n. @zbyte64 -- could you put together a bit of sample code I can look at? or maybe point me to prior art in something like celery project, etc?\n. You need to use datetime.datetime.utcnow() most likely. Will you please check and verify?\n. Did you try that, though? \n. How are you running the consumer, and how are you instantiating Huey object?\nOn Jun 7, 2016 8:41 PM, \"Chayim\" notifications@github.com wrote:\n\nI did.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/coleifer/huey/issues/152#issuecomment-224464161, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe/AAHUpqLST1Ami7ziF0Sq_s33T8unRLXJks5qJh3IgaJpZM4IwWgT\n.\n. Oh, and can you turn on logging and send me some of the logs demonstrating\nthe issue?\nOn Jun 7, 2016 8:42 PM, \"Charles Leifer\" coleifer@gmail.com wrote:\nHow are you running the consumer, and how are you instantiating Huey\nobject?\nOn Jun 7, 2016 8:41 PM, \"Chayim\" notifications@github.com wrote:\n\nI did.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/coleifer/huey/issues/152#issuecomment-224464161, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe/AAHUpqLST1Ami7ziF0Sq_s33T8unRLXJks5qJh3IgaJpZM4IwWgT\n.\n. Hey @chayim -- please take the extra moment or two to properly format your code samples. I've fixed the code in the issue report, you can see how I've done it by clicking the \"Edit\" icon.\n. No worries! Hmm... so I'm just wanting to make sure I understand exactly what you're seeing. Can you let me know if I've got it right?\n\n\nLet's say I have a periodic task, perform_checks that runs every 3 minutes. I've also got a plain old task, check_item that is enqueued by the perform_checks periodic task. The logic is:\n- every 3 minutes, perform_checks will run. When it runs, it schedules 3 instances of check_item() at the following times:\n  - now + 0 seconds\n  - now + 60 seconds\n  - now + 120 seconds\nYou're noticing that instead of the check_item sub-tasks running at the above intervals, they all execute immediately?\nIf that's the case, then I'm unfortunately not able to reproduce it locally. To test it, I went into the examples/simple dir in the huey source tree and added the following to tasks.py:\n``` python\nimport datetime\n@huey.periodic_task(crontab(minute='*/3'))\ndef perform_checks():\n    now = datetime.datetime.now()\n    for i in range(3):\n        eta = now + datetime.timedelta(seconds=(60 * i))\n        print 'scheduling check_item(%s)' % i\n        check_item.schedule(args=(now, '%s mins later' % i), eta=eta)\n    print 'done enqueueing tasks'\n@huey.task()\ndef check_item(caller_ts, msg):\n    print 'check item: %s, %s' % (caller_ts, msg)\n```\nI then fired up the consumer (./cons.sh) and watched the output, which appears correct. You'll notice that the periodic task (perform_checks) runs at 22:00. The first check_item call (now + 0 seconds) runs a few milliseconds later. Then, nothing happens unti 22:01, when the second check_item call (now + 60) runs. Ditto at 22:02. At 22:03 perform_check runs again and the pattern repeats.\n```\n[2016-06-07 22:00:38,727] INFO:huey.consumer.Worker:Worker-1:Executing queuecmd_perform_checks: queuecmd_perform_checks\nscheduling check_item(0)\nscheduling check_item(1)\nscheduling check_item(2)\ndone enqueueing tasks\n[2016-06-07 22:00:38,730] INFO:huey.consumer.Worker:Worker-1:Executing queuecmd_check_item: 0a860431-a844-434c-b103-71ce20f66d3a @2016-06-08 03:00:38\ncheck item: 2016-06-07 22:00:38.727863, 0 mins later\n...\n[2016-06-07 22:01:45,277] INFO:huey.consumer.Worker:Worker-1:Executing queuecmd_check_item: 4637e437-40c6-4c7c-84dc-464c3e7e6683 @2016-06-08 03:01:38\ncheck item: 2016-06-07 22:00:38.727863, 1 mins later\n...\n[2016-06-07 22:02:51,807] INFO:huey.consumer.Worker:Worker-2:Executing queuecmd_check_item: 6bbaefac-7c24-4b99-8b16-29bc22b35b28 @2016-06-08 03:02:38\ncheck item: 2016-06-07 22:00:38.727863, 2 mins later\n[2016-06-07 22:03:34,476] INFO:huey.consumer.Scheduler:Scheduler:Scheduling periodic task queuecmd_perform_checks: queuecmd_perform_checks.\n[2016-06-07 22:03:35,337] INFO:huey.consumer.Worker:Worker-2:Executing queuecmd_perform_checks: queuecmd_perform_checks\n```\nThe timestamp printed after \"check item: ...\" is just to show the value of \"now\" when the check_item task was initially scheduled. the timestamp in the log-message preceding it shows when it was executed.\n. For sure, I just wanted to eliminate the possibility the bug was in the consumer or the core APIs.\n. Oh, you know what... I wonder about something. When you say the management command is running the tasks immediately, do you mean that the management command process is executing the huey tasks synchronously? Or do you mean the mgmt cmd is sending the tasks to the queue consumer, and the queue consumer itself is running them immediately?\n. Do you have DEBUG=True in your Django settings module by chance?\n. I used the same approach for the django_ex example code and can verify that it, too, is working correctly. I think this should rule out the possibility of a bug?\n[2016-06-08 12:00:22,060] INFO:huey.consumer.Scheduler:Scheduler:Scheduling periodic task queuecmd_perform_checks: queuecmd_perform_checks.\n[2016-06-08 12:00:23,549] INFO:huey.consumer.Worker:Worker-1:Executing queuecmd_perform_checks: queuecmd_perform_checks\nscheduling check_item(0)\nscheduling check_item(1)\nscheduling check_item(2)\ndone enqueueing tasks\n[2016-06-08 12:00:23,556] INFO:huey.consumer.Worker:Worker-1:Executing queuecmd_check_item: 2e45573c-3121-4ec8-8bbe-45c1964b8a9c @2016-06-08 17:00:23\ncheck item: 2016-06-08 12:00:23.549548, 0 mins later\n[2016-06-08 12:00:23,558] INFO:huey.consumer.Worker:Worker-1:Adding queuecmd_check_item: 3dcc1705-e4f1-48b1-b532-20de6c59cdc4 @2016-06-08 17:01:23 to schedule\n[2016-06-08 12:00:23,560] INFO:huey.consumer.Worker:Worker-1:Adding queuecmd_check_item: df4e0fdc-30ee-481e-98c4-c7c896b2d11a @2016-06-08 17:02:23 to schedule\n[2016-06-08 12:01:27,118] INFO:huey.consumer.Scheduler:Scheduler:Scheduling queuecmd_check_item: 3dcc1705-e4f1-48b1-b532-20de6c59cdc4 @2016-06-08 17:01:23 for execution\n[2016-06-08 12:01:30,110] INFO:huey.consumer.Worker:Worker-1:Executing queuecmd_check_item: 3dcc1705-e4f1-48b1-b532-20de6c59cdc4 @2016-06-08 17:01:23\ncheck item: 2016-06-08 12:00:23.549548, 1 mins later\n[2016-06-08 12:02:27,170] INFO:huey.consumer.Scheduler:Scheduler:Scheduling queuecmd_check_item: df4e0fdc-30ee-481e-98c4-c7c896b2d11a @2016-06-08 17:02:23 for execution\n[2016-06-08 12:02:27,895] INFO:huey.consumer.Worker:Worker-1:Executing queuecmd_check_item: df4e0fdc-30ee-481e-98c4-c7c896b2d11a @2016-06-08 17:02:23\ncheck item: 2016-06-08 12:00:23.549548, 2 mins later\n. The timestamps are as follows:\n- 12:00:23 - run the periodic command\n- 12:00:23 - run the scheduled \"check items\" that was scheduled with an ETA of \"now\"\n- 12:01:30 - run the scheduled \"check items\" that was scheduled with an ETA of now + 1 second\n- 12:02:27 - run the now + 1 \"check items\"\n- 12:03:23 (not shown, but repeats the loop)....\n. Whats up?\n. Closing for now, please comment with any updates and I'll re-open.\n. Cool, thanks!\n. Link: http://huey.readthedocs.io/en/latest/api.html#Huey\nNo problem I've had a to-do item to rewrite and reorganize the Huey docs for some time. Thanks for updating and letting me know you found the fix.\n. While I appreciate the effort that went into this, I'm going to pass on merging. Huey already logs the list of registered commands, by the way. The code is in consumer.py:\nhttps://github.com/coleifer/huey/blob/3a13cdb37cd146112f196e0c9c9436bed3c437ec/huey/consumer.py#L422-L426\nThe output looks like:\n[2016-06-15 22:22:53,099] INFO:huey.consumer:MainThread:The following commands are available:\n+ try_thrice\n+ slow\n+ every_five_mins\n+ count_beans\n. It should be possible to attach a console log handler, so this is do-able.\n. from logging import StreamHandler\n. Thanks!\n. Wow, that's very interesting! I'll take a look at the patch very soon. Thanks!\n. Thank you, sorry for the delay.\n. Not asking you to make any changes here, but how would you test this?\n. Eek I am very sorry for the spam. I will fix the history hopefully it'll clear out the notices.\n. Looks all better now :)\n. Thank you and sorry for the delay, I was travelling the last week.\n. That's a pretty cool idea. By the way, I edited your comment to include code formatting. PLEASE format your code when you submit a ticket. It takes literally 5 seconds and communicates to the project maintainer that you actually care. When I see an issue without code formatting it sends a very bad message, in other words.\nOK, anyways,\nYes that's a cool idea. There are some potential pitfalls, though. Gevent relies on cooperative multi-tasking. If your misbehaving Python task is chugging along without yielding for I/O, then Gevent's event loop hsa no way of pre-empting the misbehaving task. So, for people using the gevent worker model, task timeouts will work but with a big freakin caveat.\nFor threaded tasks this should be straightforward.\nFor multi-process I imagine it should be as well, but I'm less familiar with the multiprocessing module so I'll need to read up on how this might be implemented.\nDo you have any suggestions on how it might work?\n. Thanks for the kind words about the project! No worries i just wanted to ask if that any thoughts about the implementation.\nI think it should be straightforward as a decorator that wraps your task functions (and hence is executed in the consumer).\n``` python\n@huey.task()\n@huey.timeout(600)\ndef my_task():\n    ...\n```\n. So, for threads, it is actually not at all straightforward. Python highly discourages you from killing a thread that's actively working from another thread. Gevent and multiprocessing should both be easy to implement timeouts on tasks, but with threading I don't see any viable options.\nGoing to close this for now, may revisit it in the future.\n. I'm not sure what might be going on.\nWhat version are you using? How are you instantiating your huey object? How are you instantiating the storage backend (if you are, if not don't worry about it)?\nAre you calling your tasks with a delay, or are these cron tasks that seem to be failing (if you can tell)? My guess is that you've got a busted task and the real errors are masked, but I'm not positive.\n. Man...I have no idea. What I can tell you, though, is that I don't believe there's a fundamental bug in the scheduler code...I have to assume something funky going on in your app.\nYou might try pulling down the huey repository and checking out the example app.\n. Also, if you haven't tried it already, you might just try specifying \"always_eager=True\" when instantiating your Huey instance. This will cause tasks to bypass the consumer/scheduler APIs and run in the calling thread.\n. You will get the task's ID via the TaskResultWrapper object returned by a task.\nTo update the status, I'd suggest having your task push updates to a shared resource, and have your dashboard or whatever poll for updates from the task.\nIt's a common pattern but one that depends entirely on your application.\n. A couple small little changes and then I'd be happy to merge this. It'd be a very nice feature to have, so thank you for taking the time to implement it and add tests. I appreciate it.\n. Once you feel all comments are addressed, please also rebase this into a single commit. Thanks!\n. Ahh, thanks for letting me know. I utterly despise Python 3!\nNice work on the patch, please feel free to let me know of any other ideas you have as I'd welcome more patches of that quality.\n. Oh, and btw, I finally settled on:\npython\nif sum(1 for p in (url, connection_pool, connection_params) if p) > 1:\nlol\n. 4306c3f6a89d4e98775ed56d308a176659789304\n. Thanks!\n. Testing locally, the consumer seemed to pop right back online after turning off Redis and turning it back on. This is using the \"simple\" example code, which is included in examples/simple, then running ./cons.sh:\n```\n[2016-07-12 22:14:08,153] DEBUG:huey.consumer.Worker:Worker-1:No messages, sleeping for: 0.305902286254\n[2016-07-12 22:14:08,460] DEBUG:huey.consumer.Worker:Worker-1:No messages, sleeping for: 0.351787629192\n[2016-07-12 22:14:08,460] DEBUG:huey.consumer.Worker:Worker-2:No messages, sleeping for: 0.351787629192\n[2016-07-12 22:14:08,812] DEBUG:huey.consumer.Worker:Worker-1:No messages, sleeping for: 0.404555773571\n[2016-07-12 22:14:08,813] DEBUG:huey.consumer.Worker:Worker-2:No messages, sleeping for: 0.404555773571\n[2016-07-12 22:14:09,218] DEBUG:huey.consumer.Worker:Worker-1:No messages, sleeping for: 0.465239139606\n[2016-07-12 22:14:09,218] DEBUG:huey.consumer.Worker:Worker-2:No messages, sleeping for: 0.465239139606\n[2016-07-12 22:14:09,684] DEBUG:huey.consumer.Worker:Worker-1:No messages, sleeping for: 0.535025010547\n[2016-07-12 22:14:09,684] DEBUG:huey.consumer.Worker:Worker-2:No messages, sleeping for: 0.535025010547\n[2016-07-12 22:14:10,220] DEBUG:huey.consumer.Worker:Worker-2:No messages, sleeping for: 0.615278762129\n[2016-07-12 22:14:10,220] DEBUG:huey.consumer.Worker:Worker-1:No messages, sleeping for: 0.615278762129\n[2016-07-12 22:14:10,837] DEBUG:huey.consumer.Worker:Worker-2:No messages, sleeping for: 0.707570576449\n[2016-07-12 22:14:10,837] DEBUG:huey.consumer.Worker:Worker-1:No messages, sleeping for: 0.707570576449\n[2016-07-12 22:14:11,551] ERROR:huey.consumer.Worker:Worker-1:Error reading from queue\nTraceback (most recent call last):\n  File \"/home/charles/pypath/huey/consumer.py\", line 94, in loop\n    task = self.huey.dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 225, in dequeue\n    message = self._dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 164, in inner\n    wrap_exception(exc_class)\n  File \"/home/charles/pypath/huey/utils.py\", line 18, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.name, exc))\nQueueReadException: ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n[2016-07-12 22:14:11,552] ERROR:huey.consumer.Worker:Worker-2:Error reading from queue\nTraceback (most recent call last):\n  File \"/home/charles/pypath/huey/consumer.py\", line 94, in loop\n    task = self.huey.dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 225, in dequeue\n    message = self._dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 164, in inner\n    wrap_exception(exc_class)\n  File \"/home/charles/pypath/huey/utils.py\", line 18, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.name, exc))\nQueueReadException: ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n[2016-07-12 22:14:11,552] DEBUG:huey.consumer.Worker:Worker-1:No messages, sleeping for: 0.813706162916\n[2016-07-12 22:14:11,552] DEBUG:huey.consumer.Worker:Worker-2:No messages, sleeping for: 0.813706162916\n[2016-07-12 22:14:12,372] ERROR:huey.consumer.Worker:Worker-2:Error reading from queue\nTraceback (most recent call last):\n  File \"/home/charles/pypath/huey/consumer.py\", line 94, in loop\n    task = self.huey.dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 225, in dequeue\n    message = self._dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 164, in inner\n    wrap_exception(exc_class)\n  File \"/home/charles/pypath/huey/utils.py\", line 18, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.name, exc))\nQueueReadException: ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n[2016-07-12 22:14:12,372] DEBUG:huey.consumer.Worker:Worker-2:No messages, sleeping for: 0.935762087354\n[2016-07-12 22:14:12,373] ERROR:huey.consumer.Worker:Worker-1:Error reading from queue\nTraceback (most recent call last):\n  File \"/home/charles/pypath/huey/consumer.py\", line 94, in loop\n    task = self.huey.dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 225, in dequeue\n    message = self._dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 164, in inner\n    wrap_exception(exc_class)\n  File \"/home/charles/pypath/huey/utils.py\", line 18, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.name, exc))\nQueueReadException: ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n[2016-07-12 22:14:12,373] DEBUG:huey.consumer.Worker:Worker-1:No messages, sleeping for: 0.935762087354\n[2016-07-12 22:14:13,314] ERROR:huey.consumer.Worker:Worker-2:Error reading from queue\nTraceback (most recent call last):\n  File \"/home/charles/pypath/huey/consumer.py\", line 94, in loop\n    task = self.huey.dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 225, in dequeue\n    message = self._dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 164, in inner\n    wrap_exception(exc_class)\n  File \"/home/charles/pypath/huey/utils.py\", line 18, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.name, exc))\nQueueReadException: ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n[2016-07-12 22:14:13,315] ERROR:huey.consumer.Worker:Worker-1:Error reading from queue\nTraceback (most recent call last):\n  File \"/home/charles/pypath/huey/consumer.py\", line 94, in loop\n    task = self.huey.dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 225, in dequeue\n    message = self._dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 164, in inner\n    wrap_exception(exc_class)\n  File \"/home/charles/pypath/huey/utils.py\", line 18, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.name, exc))\nQueueReadException: ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n[2016-07-12 22:14:13,315] DEBUG:huey.consumer.Worker:Worker-2:No messages, sleeping for: 1.07612640046\n[2016-07-12 22:14:13,315] DEBUG:huey.consumer.Worker:Worker-1:No messages, sleeping for: 1.07612640046\n[2016-07-12 22:14:14,396] ERROR:huey.consumer.Worker:Worker-1:Error reading from queue\nTraceback (most recent call last):\n  File \"/home/charles/pypath/huey/consumer.py\", line 94, in loop\n    task = self.huey.dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 225, in dequeue\n    message = self._dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 164, in inner\n    wrap_exception(exc_class)\n  File \"/home/charles/pypath/huey/utils.py\", line 18, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.name, exc))\nQueueReadException: ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n[2016-07-12 22:14:14,397] DEBUG:huey.consumer.Worker:Worker-1:No messages, sleeping for: 1.23754536053\n[2016-07-12 22:14:14,398] ERROR:huey.consumer.Worker:Worker-2:Error reading from queue\nTraceback (most recent call last):\n  File \"/home/charles/pypath/huey/consumer.py\", line 94, in loop\n    task = self.huey.dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 225, in dequeue\n    message = self._dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 164, in inner\n    wrap_exception(exc_class)\n  File \"/home/charles/pypath/huey/utils.py\", line 18, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.name, exc))\nQueueReadException: ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n[2016-07-12 22:14:14,398] DEBUG:huey.consumer.Worker:Worker-2:No messages, sleeping for: 1.23754536053\n[2016-07-12 22:14:15,640] ERROR:huey.consumer.Worker:Worker-1:Error reading from queue\nTraceback (most recent call last):\n  File \"/home/charles/pypath/huey/consumer.py\", line 94, in loop\n    task = self.huey.dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 225, in dequeue\n    message = self._dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 164, in inner\n    wrap_exception(exc_class)\n  File \"/home/charles/pypath/huey/utils.py\", line 18, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.name, exc))\nQueueReadException: ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n[2016-07-12 22:14:15,641] DEBUG:huey.consumer.Worker:Worker-1:No messages, sleeping for: 1.4231771646\n[2016-07-12 22:14:15,642] ERROR:huey.consumer.Worker:Worker-2:Error reading from queue\nTraceback (most recent call last):\n  File \"/home/charles/pypath/huey/consumer.py\", line 94, in loop\n    task = self.huey.dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 225, in dequeue\n    message = self._dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 164, in inner\n    wrap_exception(exc_class)\n  File \"/home/charles/pypath/huey/utils.py\", line 18, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.name, exc))\nQueueReadException: ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n[2016-07-12 22:14:15,642] DEBUG:huey.consumer.Worker:Worker-2:No messages, sleeping for: 1.4231771646\nException in thread Scheduler:\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/threading.py\", line 801, in bootstrap_inner\n    self.run()\n  File \"/usr/lib/python2.7/threading.py\", line 754, in run\n    self.__target(self.__args, *self.__kwargs)\n  File \"/home/charles/pypath/huey/consumer.py\", line 360, in _run\n    consumer_process.loop()\n  File \"/home/charles/pypath/huey/consumer.py\", line 227, in loop\n    for task in self.huey.read_schedule(now):\n  File \"/home/charles/pypath/huey/api.py\", line 323, in read_schedule\n    for m in self._read_schedule(ts)]\n  File \"/home/charles/pypath/huey/api.py\", line 164, in inner\n    wrap_exception(exc_class)\n  File \"/home/charles/pypath/huey/utils.py\", line 18, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.__name, exc))\nScheduleReadException: ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n[2016-07-12 22:14:17,067] ERROR:huey.consumer.Worker:Worker-1:Error reading from queue\nTraceback (most recent call last):\n  File \"/home/charles/pypath/huey/consumer.py\", line 94, in loop\n    task = self.huey.dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 225, in dequeue\n    message = self._dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 164, in inner\n    wrap_exception(exc_class)\n  File \"/home/charles/pypath/huey/utils.py\", line 18, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.name, exc))\nQueueReadException: ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n[2016-07-12 22:14:17,068] DEBUG:huey.consumer.Worker:Worker-1:No messages, sleeping for: 1.63665373929\n[2016-07-12 22:14:17,070] ERROR:huey.consumer.Worker:Worker-2:Error reading from queue\nTraceback (most recent call last):\n  File \"/home/charles/pypath/huey/consumer.py\", line 94, in loop\n    task = self.huey.dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 225, in dequeue\n    message = self._dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 164, in inner\n    wrap_exception(exc_class)\n  File \"/home/charles/pypath/huey/utils.py\", line 18, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.name, exc))\nQueueReadException: ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n[2016-07-12 22:14:17,070] DEBUG:huey.consumer.Worker:Worker-2:No messages, sleeping for: 1.63665373929\n[2016-07-12 22:14:18,709] ERROR:huey.consumer.Worker:Worker-1:Error reading from queue\nTraceback (most recent call last):\n  File \"/home/charles/pypath/huey/consumer.py\", line 94, in loop\n    task = self.huey.dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 225, in dequeue\n    message = self._dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 164, in inner\n    wrap_exception(exc_class)\n  File \"/home/charles/pypath/huey/utils.py\", line 18, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.name, exc))\nQueueReadException: ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n[2016-07-12 22:14:18,710] DEBUG:huey.consumer.Worker:Worker-1:No messages, sleeping for: 1.88215180019\n[2016-07-12 22:14:18,710] ERROR:huey.consumer.Worker:Worker-2:Error reading from queue\nTraceback (most recent call last):\n  File \"/home/charles/pypath/huey/consumer.py\", line 94, in loop\n    task = self.huey.dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 225, in dequeue\n    message = self._dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 164, in inner\n    wrap_exception(exc_class)\n  File \"/home/charles/pypath/huey/utils.py\", line 18, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.name, exc))\nQueueReadException: ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n[2016-07-12 22:14:18,711] DEBUG:huey.consumer.Worker:Worker-2:No messages, sleeping for: 1.88215180019\n[2016-07-12 22:14:20,596] ERROR:huey.consumer.Worker:Worker-1:Error reading from queue\nTraceback (most recent call last):\n  File \"/home/charles/pypath/huey/consumer.py\", line 94, in loop\n    task = self.huey.dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 225, in dequeue\n    message = self._dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 164, in inner\n    wrap_exception(exc_class)\n  File \"/home/charles/pypath/huey/utils.py\", line 18, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.name, exc))\nQueueReadException: ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n[2016-07-12 22:14:20,597] DEBUG:huey.consumer.Worker:Worker-1:No messages, sleeping for: 2.16447457022\n[2016-07-12 22:14:20,599] ERROR:huey.consumer.Worker:Worker-2:Error reading from queue\nTraceback (most recent call last):\n  File \"/home/charles/pypath/huey/consumer.py\", line 94, in loop\n    task = self.huey.dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 225, in dequeue\n    message = self._dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 164, in inner\n    wrap_exception(exc_class)\n  File \"/home/charles/pypath/huey/utils.py\", line 18, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.name, exc))\nQueueReadException: ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n[2016-07-12 22:14:20,599] DEBUG:huey.consumer.Worker:Worker-2:No messages, sleeping for: 2.16447457022\n[2016-07-12 22:14:22,765] ERROR:huey.consumer.Worker:Worker-1:Error reading from queue\nTraceback (most recent call last):\n  File \"/home/charles/pypath/huey/consumer.py\", line 94, in loop\n    task = self.huey.dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 225, in dequeue\n    message = self._dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 164, in inner\n    wrap_exception(exc_class)\n  File \"/home/charles/pypath/huey/utils.py\", line 18, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.name, exc))\nQueueReadException: ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n[2016-07-12 22:14:22,766] DEBUG:huey.consumer.Worker:Worker-1:No messages, sleeping for: 2.48914575575\n[2016-07-12 22:14:22,768] ERROR:huey.consumer.Worker:Worker-2:Error reading from queue\nTraceback (most recent call last):\n  File \"/home/charles/pypath/huey/consumer.py\", line 94, in loop\n    task = self.huey.dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 225, in dequeue\n    message = self._dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 164, in inner\n    wrap_exception(exc_class)\n  File \"/home/charles/pypath/huey/utils.py\", line 18, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.name, exc))\nQueueReadException: ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n[2016-07-12 22:14:22,768] DEBUG:huey.consumer.Worker:Worker-2:No messages, sleeping for: 2.48914575575\n[2016-07-12 22:14:25,258] ERROR:huey.consumer.Worker:Worker-1:Error reading from queue\nTraceback (most recent call last):\n  File \"/home/charles/pypath/huey/consumer.py\", line 94, in loop\n    task = self.huey.dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 225, in dequeue\n    message = self._dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 164, in inner\n    wrap_exception(exc_class)\n  File \"/home/charles/pypath/huey/utils.py\", line 18, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.name, exc))\nQueueReadException: ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n[2016-07-12 22:14:25,258] DEBUG:huey.consumer.Worker:Worker-1:No messages, sleeping for: 2.86251761911\n[2016-07-12 22:14:25,262] ERROR:huey.consumer.Worker:Worker-2:Error reading from queue\nTraceback (most recent call last):\n  File \"/home/charles/pypath/huey/consumer.py\", line 94, in loop\n    task = self.huey.dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 225, in dequeue\n    message = self._dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 164, in inner\n    wrap_exception(exc_class)\n  File \"/home/charles/pypath/huey/utils.py\", line 18, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.name, exc))\nQueueReadException: ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n[2016-07-12 22:14:25,262] DEBUG:huey.consumer.Worker:Worker-2:No messages, sleeping for: 2.86251761911\n[2016-07-12 22:14:28,122] ERROR:huey.consumer.Worker:Worker-1:Error reading from queue\nTraceback (most recent call last):\n  File \"/home/charles/pypath/huey/consumer.py\", line 94, in loop\n    task = self.huey.dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 225, in dequeue\n    message = self._dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 164, in inner\n    wrap_exception(exc_class)\n  File \"/home/charles/pypath/huey/utils.py\", line 18, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.name, exc))\nQueueReadException: ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n[2016-07-12 22:14:28,122] DEBUG:huey.consumer.Worker:Worker-1:No messages, sleeping for: 3.29189526198\n[2016-07-12 22:14:28,129] ERROR:huey.consumer.Worker:Worker-2:Error reading from queue\nTraceback (most recent call last):\n  File \"/home/charles/pypath/huey/consumer.py\", line 94, in loop\n    task = self.huey.dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 225, in dequeue\n    message = self._dequeue()\n  File \"/home/charles/pypath/huey/api.py\", line 164, in inner\n    wrap_exception(exc_class)\n  File \"/home/charles/pypath/huey/utils.py\", line 18, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.name, exc))\nQueueReadException: ConnectionError: Error 111 connecting to localhost:6379. Connection refused.\n[2016-07-12 22:14:28,129] DEBUG:huey.consumer.Worker:Worker-2:No messages, sleeping for: 3.29189526198\n[2016-07-12 22:14:31,419] DEBUG:huey.consumer.Worker:Worker-1:No messages, sleeping for: 3.78567955128\n[2016-07-12 22:14:31,424] DEBUG:huey.consumer.Worker:Worker-2:No messages, sleeping for: 3.78567955128\n[2016-07-12 22:14:35,208] DEBUG:huey.consumer.Worker:Worker-1:No messages, sleeping for: 4.35353148397\n[2016-07-12 22:14:35,213] DEBUG:huey.consumer.Worker:Worker-2:No messages, sleeping for: 4.35353148397\n^C[2016-07-12 22:14:36,928] INFO:huey.consumer:MainThread:Shutting down\n[2016-07-12 22:14:37,029] INFO:huey.consumer:MainThread:Consumer exiting.\n. The workers in this case are not blocking but polling, which may account for the difference?\n. Thanks for the input. This was an experiment I was trying out and I agree actually that it's got some issues (performance, clunky API, usefulness). I'm planning to scrap it in the next release :)\n. Feature removed and 1.2.0 release tagged and pushed to pypi. Thanks for getting me motivated to fix this one!\n. Are you running your Redis instance on a separate server from your consumer?\n.\n\"HEXISTS\" \"huey.results.mpfq\" \"r:b7e7473a-da89-4e31-af46-0e9ac8772c66\"\n```\nSo if you look at that key, you'll see it begins with \"r:\" -- this indicates that this is the key used to indicate that a task has been revoked. When you enqueue something and the consumer determines it is not scheduled for some time in the future, it will check to see if the user has \"revoked\" the task before actually executing it. Revoking a task is equivalent to saying \"if you see this task, don't run it as long as the revoke flag is in place\".\nSo that is why you see a HEXISTS before your task runs.\n. The storage of task results is now treated differently from revoking and scheduling as of the big changes in 1.1.0. Basically, you always have the option to schedule and revoke, as it's part of the core storage api as opposed to an individual component you need to install.\n. http://huey.readthedocs.io/en/latest/api.html#Huey.task\nSpecifically scroll down to the description of retries_as_argument\n. Out of curiosity, why would the worker get killed? I guess oom...and of course if the user kills it...hmm.  yeah, I agree, though that a new one needs to be created. Thank you for bringing this to my attention!\n. The loglevel is especially weird because of the way Django uses \"verbosity\" as a default argument/\n. But yes, this can definitely be improved.\n. I don't like to complain, but there is an unbelievable stench coming from Django's management command API, which is compounded by argparse and it's fappy as fuck and annoying as all hell refusal to let me just. remove. a. damn. option.\n. Sorry. I spent the last hour digging through the code of Django 1.8, 1.9 and argparse trying to figure out a way that doesn't completely suck to get rid of the \"--verbosity\"/\"-v\" option. Turns out it was a herculean task beyond my abilities. So I renamed the huey option.\n. Running the consumer with always_eager=True is definitely not a use-case I had ever considered. If you're running your periodic tasks in a consumer anyways, why not let the consumer run your regular tasks as well? I guess, to me, the whole point of always_eager was to allow for testing and development without the need for a separate consumer + message queue process + etc.\nI'm not sure how familiar you are with the consumer internals, but inside the consumer is a thread (or process or greenlet, depending on your chosen execution model) called the Scheduler that does two things:\n1. Every minute it checks to see if any periodic tasks should be run, and if so, enqueues them into the work queue.\n2. Continually checks its list of tasks that were scheduled to run in the future, and enqueues any tasks whose due-date is not longer in the future and is thus eligible for execution.\nThe key word in both cases is enqueues.\nWhen always_eager is True and a task is enqueued, instead of putting it on a queue, Huey executes the task right then and there and returns you whatever the task returned (skipping redis and the result store in the process).\nThis has an interesting consequence, which is that you cannot schedule tasks for future execution when always_eager=True. For instance, if always_eager is True, then the following code will run immediately as opposed to an hour in the future:\npython\nmy_task.schedule(args=('foo', 'bar'), delay=3600)\nIt runs immediately because always_eager is designed for testing and is synchronous. To make the delay work we'd need to be running the consumer or a the least a lightweight thread that acted like the a scheduler.\nI think there are two ways this could go:\n1. When always_eager is True, allow tasks to be scheduled in the future, and make it clear to the user that these future-scheduled always-eager tasks will not run unless the consumeris running. Additionally, re-use the error-handling code from the consumer's worker threads to make sure the scheduler doesn't blow up if it encounters a misbehaved periodic/scheduled task.\n2. Do not allow the consumer to be run if always_eager is true.\nI think the second choice is the correct one. It's the easiest to understand, and it will make it very obvious to anyone using Huey if they deploy an application but accidentally have always_eager turned on.\n. An exception is now raised if you attempt to run the consumer with always_eager=True.\n. Thanks for bringing this to my attention, I'll push a fix soon.\n. It looks like you're using version 1.1.2, have you tried upgrading to the latest version 1.2.0? I think there's a possibility this one's been fixed.\nAlso:\n- What does this task return?\n- Is this a regular task or a periodic task?\n. @rahul3103 -- :bell: can you please get back to me regarding the questions I've asked?\n. Can you try upgrading to 1.2.0 and letting me know if that fixes it? And is this a regular or periodic task?\n. Is the above traceback after upgrading?\n. Can you tell me what, if anything, is returned by this task function? i.e. does the task have a return statement anywhere? And what are you returning?\n. Are you sure that is the exact code?? I was able to reproduce the first error by returning the task itself from the task-decorated function.\nAnd how is it that you first submitted this issue where the problem was Python could not pickle a task instance. Then you posted that the problem was <function StrictRedis.<lambda> at 0x105b079d8>. Lastly the issue was Lock.\nThe only place threading.Lock is used is in a test of the consumer.\nI believe this has very much to do with problems in your code and that you are not being forthright about what code you are running.\nPlease update this ticket if you have a reproducible example, otherwise I'm considering this closed.\n. When you are using the RedisHuey object, the argument signature of the constructor looks like this:\npython\nclass RedisStorage(BaseStorage):\n    def __init__(self, name='huey', blocking=False, read_timeout=1,\n                 max_errors=1000, connection_pool=None, **connection_params):\nIf a connection pool is not specified, then the parameters in **connection_params** will be used to set up a new connection pool.\nSo you have two options. If you already have a Redis ConnectionPool that uses unix domain sockets, you can pass that to RedisHuey.\npython\nmy_pool = ConnectionPool(\n    connection_class=UnixDomainSocketConnection, \n    path='/tmp/my_redis.sock')\nhuey = RedisHuey(connection_pool=my_pool)\nAlternatively, you can pass in the parameters needed to create a new connection pool:\npython\nhuey = RedisHuey(\n    connection_class=UnixDomainSocketConnection, \n    path='/tmp/my_redis.sock')\n. Oh, I'm glad I spent all that time typing up an answer to your question.\n. Can you please tell me a bit more?\nDo you mean that when settings.DEBUG = True, and you call a task, it is not being run immediately?\nAre you attempting to run the consumer when DEBUG = True?\n. Sorry, I do not understand. Can you please tell me exactly what settings you're using, what you're running, and what you think is not doing the right thing?\nI can't tell from your reply whether the task is running in-process or being executed by the consumer.\n. Thanks for the info, that definitely clarifies the issue. I could have sworn this was documented but it was not, so I've created a new docs section. What it amounts to is that huey explicitly sets \"always_eager = True\" when DEBUG=True, because most dev/test environments do not want to run both Redis and a consumer process.\nDoes this clear things up?  http://huey.readthedocs.io/en/latest/django.html#debug-and-synchronous-execution\n. Huey.result method is covered by test-cases and works correctly in my opinion. You can fire up the simple example included in the huey repo and verify for yourself:\n``` ipython\nIn [1]: from main import *\nIn [2]: count_beans(100)\nOut[2]: \nIn [3]: r = _\nIn [4]: r.task.task_id\nOut[4]: 'd924b9cc-0033-4def-a051-3c4c54cb61d1'\nIn [5]: tid = r.task.task_id\nIn [6]: huey.result(tid)\nOut[6]: 'Counted 100 beans'\n```\nSo my guess is that the tasks you're attempting to work on are periodic tasks... If that's the case, then Huey will not store any return values for them.\nFor one, since periodic tasks are not invoked by the end-user, the task id should theoretically be unavailable. It's an implementation detail that, in fact, the task ID for periodic tasks is always the same...but from an API perspective, you shouldn't be able to access it.\nCan you clarify your use-case and what's going on in the code you pasted?\n. I'm not sure what you want to test. That the task is scheduled? The task logic itself?\n. Well, huey the library already tests that when you schedule a task it goes in the schedule, but of course it's good to have integration tests.\nI don't think you are talking about unit tests at all, though, rather integration tests since you seem to want to involve many components of the system including libraries.\nI'd suggest hitting up stackoverflow as I don't intend to give advice on these types of things on GitHub.\n. To clear everything, call huey.flush()\nTo revoke a task given only it's id, do something like this:\n``` python\nfrom huey import QueueTask\nhuey.revoke(QueueTask(task_id=mytaskid))\n```\nIf you  have the return value wrapper from calling the task, just use its revoke method.\nI may, for simple, add a revoke_by_id method to huey,...\n. At the moment, there's no real way to group a bunch of tasks and make sure they're all done... the best idea I have would be a meta-task:\n``` python\n@huey.task()\ndef metatask():\n    r1 = subtask1()\n    r2 = subtask2()\n    r3 = subtask3()\n    return (\n        r1.get(blocking=True),\n        r2.get(blocking=True),\n        r3.get(blocking=True),\n    )\n@huey.task()\ndef subtask1():\n    ...\n``\n. BTW I did add methods to revoke a task and restore a task using just an id:revoke_by_idandrestore_by_id.\n. In the task decorator, you'll want to set theretries_as_argument` to true.\nhttp://huey.readthedocs.io/en/latest/api.html#Huey.task\n. I'd try stackoverflow\n. Can you provide any additional information? Best would be a chunk of your huey log file showing the task being scheduled by the app, the call to revoke it, and the task being run in spite of this.\nHow much time is there between scheduling the task and actually sending it, typically?\nWhen you say that it doesn't work, what do you mean? Is there an error?\nAre you sure you're actually matching tasks based on their IDs and calling revoke?\nHelp me help you by including useful details.\n. Let me know if you want to pick this back up. Thanks for the response\n. Unused.\n. Periodic tasks do not support retries.\n. This appears to be happening with the example application that ships with Huey. The example is configured to run with a scheduler delay of 10 seconds. If you look here, you can see that the consumer is being run with -s 10:\nhttps://github.com/coleifer/huey/blob/master/examples/simple/cons.sh#L8\nThe default value is 1 second, so as long as you are not overriding this setting, tasks should always execute within 1 second of being scheduled so long as there is an available worker to take the task.\n. Another option is to run huey in \"blocking\" mode, which is kind of like long-polling if you're familiar with that from web development. If you're running huey in \"blocking\" mode, then you should see tasks executing without delay. To use blocking mode, add blocking=True when you declare your huey instance:\npython\nhuey = Huey(..., blocking=True, ...)\n. It's not \"cron.sh\", it's \"cons.sh\" ... anyways.\nHow are you instantiating huey, and what arguments are you passing the consumer on the command line? It looks to me as if you are using the same ones the example app uses.\n. That's a pretty interesting question, let me think about it!\n. Hmm, you know, I think the answer will be \"no\", simply because when you decorate a function with \"@huey.task\" the function calls are magically turned into queued function invocations. How would one differentiate intent when calling a function that is wrapped by both @task and @periodic_task?\nWhy not just do this:\n``` python\ndef my_function():\n    pass\n@huey.task()\ndef my_task():\n    return my_function()\n@huey.periodic_task(...)\ndef my_periodic_task():\n    my_function()\n``\n. Hmm...yeah, I would think that if you are absolutely 100% sure you're running the consumer in local-time mode, then it sounds like there's a bug.\n. The thing is, the logic is quite straightforward in the code... The Scheduler has aget_now()method which returnsdatetime.datetime.now()if the consumer was initialized withutc=False`. That datetime is passed around and used by the function that evaluates whether the periodic task should execute or not.\nCan you tell me how you're running the consumer? If you're using Django, what options are you passing in?\n. Are you comfortable adding some additional logging code to your copy of huey? If so, I'd love if you could add something to the consumer.py module in the consumer's __init__ method that printed the value of utc.\nSomething like:\n``` python\nclass Consumer(object):\n    def init(self, ...):\n        self._logger = ...\n        # then towards the end of the method:\n        self._logger.info('UTC is initialized to: %s', utc)\n```\nThen restart the consumer and share the logfiles with me. That'd be great!\n. I think that between 8e704b3 and 7d7566d this should be fixed.\n. Well, maybe not...Ugh.\n. :+1: . 1.3.0. Thanks to you and @Antwan86 for the fixes and for the excellent job reporting the issue.. Thanks!\n. I think that between 8e704b3563914ee59ca7ce2778c099ca5980991c and 7d7566d49a82ffaf6d039e5a484fc9cc374dbb94 this should be fixed. Could you pull down the latest code and verify that it's working for you? In my testing it seemed to be working.\n. meow! thanks\n. :cat: \n. What would this even look like, or how would this work?  The function is called (with no arguments) by the huey consumer at the appropriate interval, so no arguments are ever passed to it.\nAm I misunderstanding what you're asking?\n. There's no way to pass a parameter in to a cron-type function is what I was trying to say. Refactoring into two tasks is the correct way.\n. You can just call Huey.result(task_id).\nhttp://huey.readthedocs.io/en/latest/api.html#Huey.result. No problem at all, it's a new API and kind of buried amidst the other methods.. > I imagine that the task is still stored in redis although i removed the code and is restarting because it was interrupted before it finished. Still, i would like to flush it.\nThat is not how huey works. If the process running the queue consumer sees the task, then it will execute it (providing it has not been revoked). There's no way something could be persisted in redis that would somehow allow the task to mysteriously/randomly execute.\nRegarding the CPU usage - Python is effectively single-threaded, due to the global interpreter lock. It can peg a single CPU but unless you have multiple interpreter processes running you'll only ever be maxing out one core. If your server, too, is single-core, I suppose you could run into trouble but then the question would be why are you running a single-core server?\n\nHow do i stop it?\n\nKill the process? No idea. huey does not contain any logic to handle killing tasks.\n\nAt any rate, I do not believe this is a bug with Huey, and any questions about systems administration are so beyond the scope of this issue tracker that I won't venture any guesses.. Consumers will not greedily pull jobs from the queue, it should be safe to run multiple consumers though I haven't done this myself so am unaware of any potential edge cases. One thing to note is that you will want to ensure that only one consumer is running with the flag for periodic tasks, otherwise every consumer will enqueue a copy of the periodic task (periodic tasks being the crontab functionality).. I don't think you're following. If you're using huey's crontab functionality, then it's important to understand that each consumer you run will enqueue a ln instance of your crib task at the appropriate time. This is most likely not what you want: you'll only want one instance of the crib job to run as opposed to n (one for each consumer master process). To avoid the issue, just run all consumers but one with periodic tasks disabled.. Any consumer in the group will be able to run the periodic tasks. In this regard I believe huey is the same as celery. It's just a single consumer process that is in charge of enqueueing the periodic tasks, any consumer can execute them.. When you instantiate Huey object, specify \"blocking=True\" and you will get BRPOPs.\nhttp://huey.readthedocs.io/en/latest/api.html#Huey. You can specify a timeout, called read_timeout, which is 1 by default. This is to avoid the client getting stuck in a bad state which some users reported. You can bump that up to 300, 600, 86400 whatever.. It is the amount of time to wait for the BRPOP to return something. If it doesn't return something in X seconds, then it will fire off another BRPOP immediately.. That should be possible, but I'm not sure how easy it will be considering you're using Django... The huey integration for Django creates a single huey object per project, so I'm not sure how you'd divvy up the tasks. If you were using Flask, it'd be quite easy:\n```python\nhuey = Huey('my_app')\nhuey_long_tasks = Huey('my_app.long_tasks')\n@huey.task()\ndef short_task():\n    ...\n@huey_long_tasks.task()\ndef long_task():\n    ....\n```\nThen you could run two consumers, one pointing at each huey instance.\nFor Django, it's slightly more complicated because Huey only creates a single huey object.. I'm going to pass. This sounds like a problem that arose out of your architecture, patterns, etc, rather than something particular to Huey. Why not just use a config file and configure huey using values taken from that? It can be that simple!. The scheduler is needed if you specify a task to run at a later time.. You'll need to implement some kind of locking outside of Huey itself. It'd be very easy to do -- just create a new task decorator that wraps the huey.task method and have it perform the locking there.. Windows is supported provided redis and python both work on windows.. Huey actually has the ability to lock tasks, via lock_task():\nhttps://huey.readthedocs.io/en/latest/getting-started.html#locking-tasks\nhttps://huey.readthedocs.io/en/latest/api.html#Huey.lock_task. I have no idea why the worker processes are dying in your application, but I don't believe the problem is in Huey...perhaps you're running out of memory and the OS is killing the processes?  Does the issue happen when running with threads or greenlets?  Huey's unit tests should cover this behavior, and anecdotally I haven't experienced issues running multiprocess huey consumers on my own system.. This looked like it?\n``diff\ndiff --git a/huey/contrib/djhuey/management/commands/run_huey.py b/huey/contrib/djhuey/management/commands/run_huey.py\nindex 45b6fc3..f7018d6 100644\n--- a/huey/contrib/djhuey/management/commands/run_huey.py\n+++ b/huey/contrib/djhuey/management/commands/run_huey.py\n@@ -30,6 +30,8 @@ class CompatParser(object):\n         if 'type' in kwargs:\n             # Converttype=inttotype=\"int\"`, etc.\n             kwargs['type'] = kwargs['type'].name\n+        if kwargs.get('default') is not True:\n+            kwargs.pop('default', None)\n         self.command.option_list += (make_option(args, *kwargs),)\n@@ -65,6 +67,8 @@ class Command(BaseCommand):\n                     short = '-V'\n                 if 'type' in kwargs:\n                     kwargs['type'] = self._type_map[kwargs['type']]\n+                if kwargs.get('default') is not True:\n+                    kwargs.pop('default', None)\n                 parser.add_argument(full, short, **kwargs)\n def autodiscover_appconfigs(self):\n\n``. Pushed 1.2.3, sorry for the delay!. There are existing tools out there that can handle restarting a service. Loads of them probably.. Theoretically anything passed in on the command-line should override the settings insettings.HUEY`, which is why it is in the order you see.. Thanks!. Not at the moment, no. It's not really possible to interrupt a running thread, and since gevent is cooperatively-scheduled, we aren't able to interrupt that either. Technically one could use timer signals, but my sense is that would only work when the workers are independent processes. Since I am not aware of an approach that would work for all 3 worker classes, it's not implemented.. What do you mean \"always running\"? Why would you need huey to do this?. Ah, you want a periodic task. http://huey.readthedocs.io/en/latest/api.html#Huey.periodic_task\nYou'll of course need to ensure your Huey consumer starts up whenever your web application process starts. But periodic tasks run according to a cron-like schedule which you can specify, that should suffice I hope.. The most granular resolution supported currently by the crontab decorator is once/minute. You can write your own validation function to run more frequently.\nThe function accepts a datetime and returns True or False indicating whether the task should run.\nThis isn't how I'd go about it, but just to give you an idea:\ndef validate_30s(dt):\n    return dt.seconds % 30 == 0. The information presented here is outdated, the scheduler now runs once-per-minute.. IDK, Windows isn't supported with multi-process workers I guess?. Theoretically this would only be an issue if you were running huey in production on a windows server, right? My assumption is that, even if you develop on a Windows machine, you probably deploy your Python to linux most of the time. So using threads on Windows may be acceptable because it's a dev environment.. Literally nobody should be running Windows.. That's definitely odd, but I'm not sure what huey has to do with it.. I'll probably pass on this.. Unfortunately you cannot pass a connection object around like that. Many objects can be pickled (serialized and then deserialized into python objects later) but things with context-specific state like a db connection don't make sense for pickling. Instead, what you would probably do is pass in the database name and arguments required to create a connection, then in the huey task create a new connection using the parameters passed in.. You need to apply the monkey-patch before anything else, even import statements.\n```python\nrun_huey_greenlet.py\nfrom gevent import monkey\nmonkey.patch_all()\nfrom huey.contrib...\nfrom django.conf ...\nclass Command(...)\n    etc\n```\nCould you try that and follow-up with whether that helps?. ouch... man, Django sucks! Thanks for sharing what you found.. Added docs: http://huey.readthedocs.io/en/latest/contrib.html#using-gevent. There currently is not. I suppose I could add a SIGINT handler and wire that up to allow graceful shutdown, though.... Added support for graceful shutdown via SIGINT: 25bf307e46ec055699d653560bd15db7f9aae276\nDocs: 625cf1abd07d2cd2fb0e070bb06c1a2053cf19a7. From https://www.quora.com/What-is-the-difference-between-the-SIGINT-and-SIGTERM-signals-in-Linux\n\nSIGINT is the interrupt signal. The terminal sends it to the foreground process when the user presses ctrl-c. The default behavior is to terminate the process, but it can be caught or ignored. The intention is to provide a mechanism for an orderly, graceful shutdown.\nSIGTERM is the termination signal. The default behavior is to terminate the process, but it also can be caught or ignored. The intention is to kill the process, gracefully or not, but to first allow it a chance to cleanup.\n\nSo I believe the huey implementation has the correct semantics.. Thanks, fixed in master.. Thanks!. Let's do it!. Thanks. Nice.. 214f3e7d5e4c5302dc5f14c4b1df82e1b4796b03. I definitely set out to make it possible to use other backends. The Redis implementation is the default and works extremely well, of course, but there's also a SQLite implementation included in the source tree (undocumented at the moment, though):\nhttps://github.com/coleifer/huey/blob/master/huey/contrib/sqlitedb.py\nWas there a particular tool you were wanting to use instead of Redis?. closing. don't create frivolous issues in the future on my projects you clown.. Yes, when decorating a task you typically would write something like:\n```python\nhuey = RedisHuey(...)\n@huey.task()\ndef my_task(foo, bar):\n   return foo + bar\n```\nIt is possible, however, to have the huey consumer call your task function passing in the task as the first parameter:\npython\n@huey.task(include_task=True)\ndef my_task(foo, bar, task=None):\n    print task.task_id\n    return foo + bar. Brought this up to date, thanks for your patience! https://github.com/coleifer/huey/blob/master/CHANGELOG.md. Thank you!. You can use include_task=True when declaring your task, and it will be passed in using the task keyword argument.. Good question. So, huey tries to keep as little stuff in memory while working, so things like un-consumed tasks, or tasks sitting in the schedule until a future time, will be managed by the storage engine. It's possible, but unlikely, that huey could read from the schedule and be killed before it has time to enqueue the scheduled tasks...but that's quite unlikely since the interval between reading and enqueueing is very small.\nSo, long story short, huey will persist scheduled and enqueued tasks from execution to execution.. Unfortunately not. So I understand the issue correctly, what happens is:\n\nSchedule a task to run at 1:05\nShut down consumer at 1:03 -- task has not run yet.\nRestart consumer at 1:07 -- it runs the task from 1:05.\n\nAnd at step 3 you would prefer to discard the task from 1:05? Here's one idea:\nDeclare you task as include_task=True and try something like this:\npython\n@huey.task(include_task=True)\ndef my_task(task):\n    delay = task.execute_time - datetime.datetime.utcnow()\n    if delay.total_seconds() > 60:\n         # This task is being run more than 1 minute after it was scheduled.\n         return. What?. I'm still not clear what the issue is.. Yes, the SQLite storage backend has a dependency on peewee. You can read about the library here: http://docs.peewee-orm.com/en/latest/ -- I've updated the docs c593df5919400bcab6056b6b8230a3784ce5123f. Wow, this is quite clean. Thanks. I will review this as soon as I can with an eye towards getting it merged into master.. Yes! It does! I'm sorry I have been so flakey about going over this. Thanks for your patience.. Apologies for the slowness... Could you rebase into a single commit, remove all \"stylistic\" (i.e. newlines/whitespace) changes, and resolve conflicts? When that's done I'm happy to review.. Thanks @Sebubu - I'm sorry for letting this sit idle and accumulate conflicts. I'm happy to help with failing tests once you submit a clean/rebased patch.. Very cool, will give it a review so we can get this merged.. Looks good. A few small things here and there, but I can clean them up after merging. Thanks!. Clean-ups: cfdc87cc7f438dac7b6b68db9f34f9b83b31ff80. @MarcoGlauser / @Sebubu -- are you all running this in production with the new queue option? There have been a couple brain-dead bugs that I think would've cropped up if you all were using this:\n\n\n297\n\n\n300\n\n\nI don't want to revert this, but am concerned about the stability of the changes that were introduced...especially given the types of issues people are encountering.. I've decided to roll this patch back and have pushed a new release, 1.9.0.\nI apologize for the inconvenience this may cause you all, but I can't maintain a patch that has bugs like the two that were reported. If you want to re-submit a clean patch that addresses the reported issues and includes a more robust test-suite, I'll be happy to bring this functionality back.. Thanks!. If you're running multiple consumers, you can do a couple things.\n1) Since Huey relies on import-time side-effects to register tasks, ensure that the modules imported by the various consumer instances only contain the tasks you wish those consumers to run.\n2) Run all but one huey instance with -n or --no-periodic, which will prevent multiple instances of a periodic task getting spawned.. Although, perhaps it makes sense to attach a TaskRegistry to a particular huey instance? That's another possibility, but the above options should work in the meantime.. ee4cd0f6d9c4b153c512e8d28aa3c4fee5fe0ea6\nWith this patch, if you instantiate your  Huey object with global_registry=False, then I believe you'll see the behavior you're expecting -- tasks are registered to the Huey instance they were decorated with.. I'm sorry but this isn't the best place to ask this type of question. Try StackOverflow. The huey docs are pretty clear on how to set things up: http://huey.readthedocs.io/en/latest/imports.html\nAnd at the end of the day it's just Python and the way the import statement works.... You can call a task from inside another task brobeans.. I have avoided consideration of the backend going away...I'm not sure how best to handle that, and part of me feels that using something like supervisor would be the correct way to approach things. That said, Huey should probably be able to tolerate the backend going away for a short time without dying.... I believe this should actually address the issue: 0ae06cec00469d5bde2c4bbe8177adad8991112d\nEverywhere else in the consumer there appears to be sufficient exception handling code to keep things running if Redis went away for a moment.. Can you share the full traceback for those exceptions listed in 1?. Looking at the code in the worker, I would have thought that Huey would be sleeping if there were problems de-queueing tasks:\n```python\n    def loop(self, now=None):\n        exc_raised = True\n        try:\n            task = self.huey.dequeue()\n        except QueueReadException:\n            ...\n        except QueueException:\n            ...\n        else:\n            exc_raised = False\n    if task:\n        self.delay = self.default_delay\n        self.handle_task(task, now or self.get_utcnow())\n    elif exc_raised or not self.huey.blocking:  # NOTE THIS CONDITIONAL\n        self.sleep()\n\ndef sleep(self):\n    if self.delay > self.max_delay:\n        self.delay = self.max_delay\n\n    self._logger.debug('No messages, sleeping for: %s' % self.delay)\n    time.sleep(self.delay)\n    self.delay *= self.backoff\n\n```. I have no idea what \"django-celery-beat\" is, but I can tell you that Huey supports:\n\nRunning tasks asynchronously (duh)\nRunning tasks at a scheduled time (i.e., if a user signs up for an account, schedule an event to run in one week that sends them a welcome email).\nRunning tasks at regular intervals (like a crontab)\nPausing individual tasks (i.e., temporarily disable this cron job)\nCancelling scheduled tasks (i.e., this user deleted their account, cancel the welcome email event).\n\nIt's all in the docs.. That's not supported by Huey because there's no actual need for huey to support that. You can build that on top of Huey incredibly easily. For example, you could have a cron task that runs every minute and all it does is check your DB config to see what other tasks should run and then run them:\npython\n@huey.periodic_task(crontab(minute='*'))\ndef conditionally_run_other_tasks():\n    # query database and see if some tasks should be run.\n    # call the tasks in here and they will be enqueued and executed. Yes, crontab returns a function that, for a given datetime, returns whether or not it matches the pattern specified in the crontab.. Hey, yes, the information is misleading in #207 and is no longer correct. The fact is that the finest granularity you can achieve using periodic tasks is once per minute. The reason per-second isn't supported is because to do that we'd need to enforce that the scheduler runs once per second and I just don't think that's always realistic -- especially if your huey instance is talking to a Redis server across the internet or has a large number of tasks to read/write.. You can run the scheduler at once per second and, inside a periodic task, schedule tasks at sub-minute intervals, but that's more a hack than anything else.. > Have you worked out an efficient way for scheduling such tasks with a delay longer than 60s?\nWhat do you mean \"with a delay longer than 60s\"? This ticket is about running periodic tasks at intervals lower than 60seconds...it has nothing to do with \"delays\".. @tehfink -- you can specify an arbitrary delay -- any amount of time you like.. Periodic tasks take a callable as their first parameter. It accepts a\ndatetime and returns true or false if the task should run. The crontab\nfunction generates a callable but you can supply your own.\nOn Wed, Mar 21, 2018, 5:46 AM Ajurna notifications@github.com wrote:\n\n@tehfink https://github.com/tehfink unfortunately i don't have a\nconfig. after doing some testing i ran into lots of issues with by the\nsecond scheduling that ended up in abandoning this. as i said i rewrote the\npart that i wanted to update this often as a service.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/coleifer/huey/issues/237#issuecomment-374896837, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAHUpqWS5JIt_tN-GioCg5eBsPzr9xshks5tgi9pgaJpZM4Od8Gf\n.\n. Check out the docs on consumer shutdown: http://huey.readthedocs.io/en/latest/consumer.html#consumer-shutdown\n\nHuey supports graceful shutdown via SIGINT. If you want to stop the consumer but allow the workers to finish any tasks they are currently executing, use SIGINT.\nBy contrast, SIGTERM will stop the consumer and workers regardless of whether they are working on a task.. At present, you'll need to revoke the task and then run it again with the new execution time.\nI can see possibly adding a convenience method to the TaskResultWrapper, TaskResultWrapper.reschedule, but am not sure how feasible that would be without looking into the code some.. So if you schedule a task, you'll receive a TaskResultWrapper instance as the return value. The TaskResultWrapper will conveniently be holding a reference to the underlying Task object, which encapsulates the task id, task data (arguments for function call), etc. In this case, re-scheduling would be straightforward -- we'd revoke the task and construct a new one using the data we have at-hand.\nOn the other hand, if you all have is the original task's task_id it becomes more tricky. The task could either:\n\nBe sitting in the queue, having not yet been processed by a worker.\nBe sitting in the schedule waiting to be run.\nHave been run already.\n\nWe'd have to search the task queue and the schedule for the task so we could reconstruct the arguments the task was called with. That's not good... Not to mention the fact that doing so is fraught with race conditions.\nNeither would it work to extend the logic of the task revoking code. The way task revoking works is the task is completely left alone -- we just add a key elsewhere that contains the tasks' id and signifies that this particular task id was revoked. It's not until the worker reads the task that it checks to see whether the task has been revoked, and at that point it throws it out. So it'd be impossible to re-schedule a task to run sooner.\nLastly, what would be the proper thing to do if the task had already been run? i.e. you think you're rescheduling it, but for whatever reason your code has bugs or is unexpectedly slow, and the task finishes before you can reschedule it?\n\nI think that in light of these complications, the simplest/naive solution may be the best: revoke the original and spawn a new one via the TaskResultWrapper . Additionally require that the TaskResultWrapper was returned by the original task invocation (and thus has access to the task's data). No checks will be done to see if the original task was already executed.\nWDYT?. Yep, it's possible, the short version is:\n```python\n@huey.task()\ndef some_function(a, b):\n    pass\ntask_result_1 = some_function(3, b=4)\nprint task_result_1.task.data\n((3,), {'b': 4})\nprint task_result_1.task.execute_time is None\nTrue\ntask_result_2 = some_function.schedule(args=(1, 2), delay=3600)\nprint task_result_2.task.data\n((1, 2), {})\nprint task_result_2.task.execute_time\ndatetime.datetime(2017, 7, 31, 23, 46, 59, 460309)\n```. > Will I be able to get the args based on a task_id only?\nTheoretically yes. You can call the huey instance's pending() and scheduled() methods to get the lists of tasks that are waiting in the queue to be processed or sitting on the schedule waiting til their specified execution time (respectively). Those methods will return task objects and you should be able to access the data attribute to get the args/kwargs.. Like I said, though, there's a race condition such that the task could be executed while you're combing through the lists of pending and scheduled tasks...but sounds like in your case that may not come up in practice?. The timetuple() function returns the day of week such that Monday=0 and Sunday=6. We want to normalize this so that Monday is not 0, but 1.\nSo Python's timetuple() tells us:\n\n0 = Mon\n1 = Tues\n2 = Weds\n3 = Thurs\n4 = Fri\n5 = Sat\n6 = Sun\n\nHuey uses:\n\n0 = Sun\n1 = Mon\n2 = Tues\n3 = Weds\n4 = Thurs\n5 = Fri\n6 = Sat\n\nThe (w + 1) % 7 accomplishes the conversion from Python value to Huey value.\nIn terms of inputs, huey validates that the day-of-week is within the range of 0 - 6, so specifying 7 would cause a value error:\n```python\nIn [8]: crontab(day_of_week=7)\n\nValueError                                Traceback (most recent call last)\n in ()\n----> 1 crontab(day_of_week=7)\n/home/charles/code/huey/huey/api.pyc in crontab(month, day, day_of_week, hour, minute)\n    642                 piece = int(piece)\n    643                 if piece not in acceptable:\n--> 644                     raise ValueError('%d is not a valid input' % piece)\n    645                 settings.add(piece)\n    646 \nValueError: 7 is not a valid input\n``. I've updated the docs to clarify the valid inputs and their corresponding day.. Added. a1802fd91342975c788399f74a2792467a532043. Shoot mane this is not the right place for this type of question.. Yeah, Django is interpreting options with action=\"store_true\" or action=\"store_false\" as having a default value of the opposite, which is jacking things up.. I believe this is fixed. Testing locally it seemed to be doing the right thing.. Thanks!. I think I'll pass on these changes, but thank you for sharing the code and the ideas. Definitely some interesting stuff here.. I guess you're probably passing an un-pickle-able object to the task. See if you can pass something else, or implement the pickle protocol for the object.. It's something to do with the exception being raised.. I'm not sure why it's pickling a traceback? The traceback returned in the metadata is the result of callingtraceback.format_exc()` which returns a string.. Wow, I'm not sure what's going on. Exceptions seem to be generally pickle-able to me:\n```python\nIn [1]: import pickle\nIn [2]: try:\n   ...:     1 / 0\n   ...: except Exception as exc:\n   ...:     pass\n   ...: \nIn [3]: pickle.dumps(exc)\nOut[3]: \"cexceptions\\nZeroDivisionError\\np0\\n(S'integer division or modulo by zero'\\np1\\ntp2\\nRp3\\n.\"\n``. Given the trouble folks are having I'm going with @Antwan86's suggestion of just using the exception'srepr` instead.. Huey doesn't provide rate limiting, no, but there are plenty of third party libraries you could use in addition to Huey to achieve this. Or of course switch to celery.. Docstrings: https://github.com/coleifer/huey/commit/59ea58df2fa9f69d8132e4ad601267b0ed8c351f. > If I understand correctly, data can be huge, because it contains task arguments.\nDepends on what you're passing to your task. It will be whatever parameters you specify, along with a small amount of task metadata (task ID and such). Since task parameters must be pickled and are shuffled around the network/database, it's smart to keep them small. Of course huey doesn't prevent you from sending large pieces of data around, but it's better, if possible, to offload large chunks of data to dedicated storage and simply pass around references in your tasks. i.e., instead of passing a number of rows from a database, I'd pass a list of IDs or some other compact representation.. Periodic task ID is simply the task name.. See https://github.com/coleifer/huey/issues/255#issuecomment-334520003. > Though some dosctrings would really help.\nYou're absolutely right, it's not exactly clear what the APIs are intended to do and you have to know and understand Redis to get an idea of their expected behavior. I hope to fix this soon.. You can use the huey events stream (Redis only at the moment) to subscribe to events from the consumers. They publish all sorts of info. http://huey.readthedocs.io/en/latest/events.html. Docstrings: https://github.com/coleifer/huey/commit/59ea58df2fa9f69d8132e4ad601267b0ed8c351f. The tasks are being enqueued by the first consumer and executed by a worker in the second. This is by design. It allows you to run multiple consumers reading from a single queue if you so desire (and is a bit of a holdover from before huey consumer got multiprocessing support).\nLet's say you had 2 huey instances, instantiated with a unique name parameter and with global_registry=False (meaning a task decorated by one huey instance is not visible to the 2nd huey instance). If you started up two consumers, the two would not interact with each other because they are separate instances using separate queues.\nIn other words, the no-periodic option does not restrict which tasks a consumer will run. It only restricts whether or not that consumer process will run a scheduler which enqueues periodic tasks.. Updated the docs, the wording was indeed ambiguous. Thanks!. You'll need to implement that yourself or use an off-the-shelf library.. At the moment the consumer doesn't implement restart. Sorry, I think I misunderstood your question.. That's a gross hack to work around real memory leaks in your code.. Celery depends on a 3rd-party library to implement this (setproctitle). Because huey aims to not depend on outside libraries, I'm going to pass on this.. I don't believe there is a race condition in either. Redis is single-threaded and brpop and rpop are atomic operations. In SQLite, we request the task ID and then execute a DELETE using that specific ID and only return the task data if the task was, in fact, deleted (atomic operation).\nIn the second case, if a task is accepted by a worker, then the task will be executed. If the worker dies for some reason (killed, OOM, whatever) then the task is lost, correct.. No, because we have the check that res == 1 before returning the task data. Only one consumer thread/process will be able to delete the row, and only that thread that does the delete successfully will return the task data.. :+1: . That is correct, periodic tasks do not get unique identifiers and instead use the task name as the ID.. It's all to do with the task revocation logic. When you revoke a regular task, it puts a marker in the key/value data-storage indicating that the task with  is revoked along with some metadata about how long to revoke the task, etc. When revoking a periodic task, I wanted huey to revoke all instances of that task until such time as the task is restored or the revocation expires. So periodic tasks do not have a unique task ID.\nI think I'll modify the logic and extend it so that the following is possible:\n\nRevoke an instance of a task\nRevoke all instances of a task\n\nA follow-on effect of this will be to give periodic tasks their own ID. And also to support revoking all instances of a regular task as well. Best of both worlds.\nThank you for all your feedback, by the way. The project is improving quite a bit as a result.. 5f1318663722deca079a5ae5552679e81e4d8d09. I've considered that, and in fact, that is the API that the huey.contrib.minimal.MiniHuey uses. For the time being I'm going to pass on modifying Huey.task, though. There's just a little bit too much special logic in there to handle \"regular\" tasks (the schedule and inner_run methods, specifically).. I'm going to pass on this, as huey treats the data as an opaque sequence of bytes for the purposes of the storage engine.. It's treated that way because the storage engine is a storage engine -- it doesn't know about the data.. This would be a backwards-incompatible change as it alters the serialization format for existing users. For that reason alone I'm not very inclined to merge it.. It has the potential to cause problems when upgrading. Anything persistent in the queue would need to be consumed before upgrading. That's what I meant.. Fixed!. Right now there is not, but I don't see why we should implement a restart signal at the very least. SIGHUP for instance?. I'm suggesting using SIGHUP to trigger a restart. I'm not too sure how to restart processes with Python from within the process itself... is it sufficient to restart the workers or should the whole consumer process get restarted, for example? Would I use the os.exec family to start the new process?. Looks like I want https://docs.python.org/3/library/os.html#os.execl. Wanna try out 1ffb3ddbbc20e8716743011d2a4e02802f61f659 ?. I did not implement this on a worker-by-worker basis. It applies to the consumer as a whole.. If you're running the worker health checker, it should be possible to just kill the worker process using the standard SIGTERM and huey consumer will automatically restart a new worker to take it's place?. You can just subclass RedisHuey / RedisStorage and implement whatever you like.. It depends on what worker model you're using.\nWith greenlets you can wrap your task like so (docs):\npython\nwith gevent.Timeout(60):\n    this_better_take_less_than_60_seconds()\nWith threads and processes it may require a bit more effort. You should be able to use the signal module but I haven't tested this myself:\n```python\nfrom functools import wraps\nimport errno\nimport os\nimport signal\nclass TimeoutError(Exception):\n    pass\ndef timeout(seconds=10, error_message=os.strerror(errno.ETIME)):\n    def decorator(func):\n        def _handle_timeout(signum, frame):\n            raise TimeoutError(error_message)\n    def wrapper(*args, **kwargs):\n        signal.signal(signal.SIGALRM, _handle_timeout)\n        signal.alarm(seconds)\n        try:\n            result = func(*args, **kwargs)\n        finally:\n            signal.alarm(0)\n        return result\n\n    return wraps(func)(wrapper)\n\nreturn decorator\n\n``. I'd just subclassRedisHuey(or whatever) and add a newtimed_task()` helper that returns a wrapped task...something like that?\nSame goes for your other question. Just subclass and extend the task decorator.. Correct. Because the default behavior for Huey is not to enforce timeouts or have pre-/post-execution hooks.. No, I think that may be worth looking into. Let me take a look into the code :). What do you think about the API proposed by 0716408 ?. Huey has \"events\". The corresponding events in huey would probably be:\n\nEVENT_STARTED\nEVENT_FINISHED\nEVENT_RETRYING\n\nThey are emitted by the consumer, if you're curious about the code: https://github.com/coleifer/huey/blob/07d7940760067a149367b14df76e08608e0fabfc/huey/consumer.py#L153-L228. I believe that should work reliably so long as you're using the process worker model (as opposed to thread / greenlet).. If threads, I think it might be possible for one worker thread to clear the alarm that was set by a different worker, since the alarm is specific to the process rather than the thread (?). Yeah...let me look into it.. 51f951e4c942577489ee0b9f720860fe4c1dff53. Semantically I never felt it made sense to store periodic task results. If they're doing an important computation, theoretically that would involve manipulating a relational database/reporting/etc.\nIf you weren't careful it could also mean clogging up your result store with a ton of results -- i.e. a task that runs every minute and, purely by accident returns an integer, would store 1,440 results a day.. So to fetch the result of a task you would, theoretically, want to have the actual TaskResultWrapper instance handy -- since this provides APIs for querying the data-store for the task result. Alternatively knowing the task's ID would work (via a call to Huey.result()). In either of those cases, though, to get at the task result you would need information from the QueueTask instance.\nPeriodic tasks are enqueued by the consumer, so the application really has no knowledge of the task ID or way to get at the TaskResultWrapper instance (if one existed for the periodic task).\nSo to my thinking, it doesn't make sense to store the results since there's no real way to get at them from the application.\nIf you're dead set on storing the result you can always use the result-store APIs directly in your periodic tasks.. Huey consumer is configured at start-time, so you need to pass --no-periodic to the consumers you want to run w/o scheduler. Anything beyond that will involve doing some hacking around the internals.. You can subclass the Consumer class and override to your heart's content.. Check out b35818b5232924c1227c74c737430361ecc1ce59. Should be possible to accomplish whatever you need using something like:\n```python\nclass MyScheduler(Scheduler):\n    pass\nclass MyConsumer(Consumer):\n    def _create_scheduler(self):\n        return MyScheduler(...)\nclass MyRedisHuey(RedisHuey):\n    def create_consumer(self, config):\n        return MyConsumer(self, config)\n```. You'll want to use something to store a lock and check it in the task. Huey provides a general-purpose key/value interface that you can use, or you can use Redis, etc.\nSomething like this:\npython\n@huey.periodic_task(...)\ndef my_task():\n    if lock_is_set():\n        return\n    try:\n        set_lock()\n        ... do task ...\n    finally:\n        clear_lock()\nPerhaps I can abstract this into a context manager, but in the meantime you'll need to do it yourself.. See: 0b4ccf5288f062c060046467e8a64f154340cfc6\nAdded a new decorator / context manager you can use with/in your tasks.. What exception does it fail with? ImportError?. Is ModuleNotFoundError a subclass of ImportError? That's strange.... I think 4a5dda8 ought to fix things.. While the code here is quite clean, this is not really something I'm interested in maintaining (or having as part of the core consumer). There are, however, some new APIs (see Huey.create_consumer and the pre/post-execute hooks) that you could use to implement such a feature without needing to touch core code. I'd suggest that as the best path forward.. Hey @mindojo-victor -- I'm not too sure what could be causing that. The \"S\" indicates \"sleeping\", right? I agree that seems ridiculously high. You might try adding logging or running with cProfile to see what's going on. strace might help, too.. What parameters are you running the consumer with? What are you using as the storage backend? Are you using Redis? Polling?. > I am using my custom MongoDB backend, so I think profiling is the only option.\nMy strong sense is that this is where the problem lies. Can you share the code you're using?. Oof, that's a lot of code. I'd suggest just running the consumer using python -m cProfile -o results.out <run consumer> then use pstats module to inspect the results afterwards.. You end up figuring out what it was?. @mindojo-victor -- right on, thanks for the update!. I have no idea, but please let me know in the comments if you have a specific comment about huey.. I don't use sentry and cannot advise. I'd suggest stackoverflow (?).. Just do this:\n```python\ndef bi_export_payment():\n    ...\nif settings.ENV == settings.Environment.PRODUCTION:\n    bi_export_payment = huey.periodic_task(crontab(minute='0'))(bi_export_payment)\n```. I'm not familiar with celery, so I can't comment on other approaches.\nAs of af9ad0ab867e1458892c6869a021f081c99d39aa any kwargs passed to the task() decorator will get passed on to the task class. See 8a98bcad6d8c37e7da2898cce05a09c55e355ee2 for an example.\nDoes this address your use-case?. Oh good, any settings will apply to all instances of the given task, so I didn't know if you were trying to get per-instance priority or just on a per-task-class basis.. Right, in registry you can see how a task becomes serialized. It basically just dumps:\n\ntask id\ntask name\nexecution time (if relevant)\nnumber of retries\nretry delay\ntask data (i.e. arguments passed to task)\non complete (i.e. task to run next if set)\n\nThe task settings are not passed along, because they are tied to a task-class, as opposed to an instance (or invocation) of a task.. All the information I listed is on a per-task basis. Or, per-invocation, if you prefer. That all gets serialized to form the message that's stuck in the queue -- all the relevant task data and metadata, including how many retries are left, etc.. You'll probably want to pass retries_as_argument=True in your task declaration, so that the send_email() function will receive the current number of retries as a parameter. Alternatively you could specify include_task=True and then the whole task instance would be passed as an argument to send_email() which could the inspect task.retries.\nEx:\npython\n@app.task(retries=3, retry_delay=60*5, include_task=True)\ndef send_email(to, subj, body, task=None):\n    try:\n        _send_email(to, subj, body)\n    except Exception as exc:\n        if task.retries == 0:\n            notify_of_task_failure(task)\n        raise. Since there's already a mechanism for specifying the task name, I'm not inclined to change things up.\nYou could write another decorator:\npython\ndef my_task(*args, **kwargs):\n    def decorator(fn):\n        task_name = '.'.join((fn.__module__, fn.__name__))\n        return huey.task(name=task_name, *args, **kwargs)(fn)\n    return decorator\nRe: your last point, refactoring the task decorator, I think that has merit and will consider it for a future release.. I reconsidered and pushed the change: af9ad0ab867e1458892c6869a021f081c99d39aa\nI've also added the ability to pass arbitrary keyword args to the task() decorator method. Those kwargs are set as attributes on the QueueTask class.. I would:\n```python\ndef one_func():\n    pass\none_func_task = huey.task()(one_func)\none_func_cron = huey.periodic_task(crontab(...))(one_func)\n```. It's not very convenient? Well, write a helper function...it's just python.\n```python\ndef make_task_and_cron(cron_rules, fn):\n    task_fn = huey.task()(fn)\n    periodic_fn = huey.periodic_task(cron_rules)(fn)\n    return (task_fn, periodic_fn)\ndef one_func():\n    pass\none_func_task, one_func_cron = make_task_and_cron(crontab(...), one_func)\n```\nThink outside the box, I'm sure there are other ways.. The only reason it is the way I've written it, is to provide instances of the function that can be called normally and as a task (as well as a reference to the periodic task, for convenience).\nYou don't need that, though. You could:\n```python\ndef task(validate_fn=None, kwargs):\n    def decorator(fn):\n        task_fn = huey.task(kwargs)(fn)\n        if validate_fn is not None:\n            # Store a reference to the periodic task as an attribute on the\n            # decorated function. Alternatively you could remove the assignment\n            # and just call huey.periodic_task(validate_fn)(fn).\n            task_fn._periodic = huey.periodic_task(validate_fn)(fn)\n        return task_fn\n    return decorator\n@task(crontab(minute='*/10'))\ndef one_func():\n    pass\n```\nIt's just python.. Updated.. Correct!\nOn Dec 7, 2017 11:08 AM, \"Victor Varvaryuk\" notifications@github.com\nwrote:\n\nSorry for being dumb. I thought _periodic is an attribute used by Huey.\nNow I understand: we decorate the function twice, but do not wrap task\nwith periodic_task or viceversa. So if we call the function, the regular\ntask decorator is called. At the same time we register the function for\nperiodicity. I guess the assigning result of huey.periodic_task(validate_\nfn)(fn) to task_fn._periodic is not necessary, as the function is\nregistered in a periodic task registry?\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/coleifer/huey/issues/277#issuecomment-350032502, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAHUpjR8_mQIolKAE8ZDaKWeQyRYx-uZks5s-BupgaJpZM4Q5EdH\n.\n. This code doesn't make sense:\n\npython\nhuey.contrib.djhuey.periodic_task(crontab(minute='*/1'))(tasks.count_beans(20))\nYou're passing \"tasks.count_beans(20)\" as if it were a function, but that's actually a task invocation (and hence a task result wrapper). I think you meant:\npython\nhuey.contrib.djhuey.periodic_task(crontab(minute='*/1'))(tasks.count_beans). Ah, I guess count_beans is decorated already by the task() decorator?\nI can look into making this work, but the correct approach is this:\n```python\ndef count_beans(n):\n    print('Counted %s beans.' % n)\ncount_beans_task = huey.task()(count_beans)\ncount_beans_cron = huey.periodic_task(crontab(minute='/1'))(count_beans)\n```. What you would do for dynamic tasks is store the task metadata in some kind of persistent storage, and then create a \"master\" task that always runs and scans the dynamic task metadata, spawning tasks as necessary.. sigh*.... Can you be more clear what the issue is you're experiencing?. Well, the task lock should address them running at the same time, but if one is scheduled then you'll need to check the queue.\nTypically one would use a distributed lock or something to prevent this.. As far as logging goes, the Python logging framework is pretty good and I imagine you could write a filter for your purposes:\nhttps://docs.python.org/2/library/logging.html#filter-objects\nYou can retry a task silently by simply re-calling it from within the task (or calling it's .schedule() method).\nI don't see a need for another API.. > it is not a property of the function implementation, but how that function is registered into Huey\nI may be misunderstanding your comment, but I don't think this is correct.\nThe way huey works is the enqueue() method accepts a QueueTask instance. The QueueTask contains the name of the function to invoke (which was registered), the arguments passed to the function, along with the number of retries. The Huey.task() decorator function dynamically creates a QueueTask subclass which, when the function is called, is instantiated with the appropriate metadata and enqueued.\nAll that may be beside the point, though, when the main consideration is an API to invoke the retry logic without raising an unhandled exception (or being forced to re-schedule the task).\nI'll give it some more thought.. If you're running multiple processes, then yes, it's possible that the scheduler process could get killed if the OS ran out of memory. Unlikely, but not impossible. Huey does try to keep an eye on the workers, I suppose I could add logic to check the scheduler as well?. 00c33127c012854e601d8cd09e05c51235df02de. Can you share the traceback or anything to help me debug the issue? Where is the exception occurring?. Can you try: 06f4c6ede53fb7ab998e7b98a479502b441a3982 and let me know if that addresses the issue? I think it had to do with overriding the class name to be the dotted path (including the decorated function's module).. What's the traceback when running the most recent code?. Nevermind, I've written a test-case to replicate. I mistakenly thought I already had such a test but apparently not. Working up a fix now.. Dope, thanks!. Merged equivalent to the ones I liked. Thank you!. I just read the celery docs for group and chord...my own opinion is that it's hideously complicated and hard to understand (littered with .s(), .si(), pipes, etc). I recognize the engineering talent that's required to make a library like celery, but if I was reviewing code that looked like those examples I'd definitely take issue with it on account of it being almost unreadable.\nThat being said, I think there's probably an analogous pattern in threading for spawning a bunch of threads (which may put values in a queue), then waiting for all to join and doing something with the values put in the queue.\nTo implement that kind of thing with huey you'll want to do something like:\n```python\n@huey.task()\ndef fetch_from_api(resource):\n    return api.get(resource)\n@huey.task()\ndef initialize_data_from_api():\n    resources = ['foo', 'bar', 'baz', 'something']\n# Spawn 4 tasks.\ntasks = [fetch_from_api(resource) for resource in resources]\n\n# Block this task until the 4 fetch tasks have returned.\nresults = [task_result.get(blocking=True) for task_result in tasks]\n\n# Insert the resulting data into the db.\ninsert_into_db(results)\n\n```\nIn the above code you have a master task that spawns individual API-call tasks and then blocks until all tasks have been executed and returned, before inserting the resulting data into the db. Obviously for the above to work you'll need at least 2 workers, since the master task is going to block up a worker for the duration of the API calls.\nIs there any particular reason you're migrating away from celery?. Just added support for pipelining. No docs yet, but might interest you:\n312370f48f7f0e61a5e455cb41f135a4c37115f5. It's not the same as a chord, where you've got a group running in parallel and a callback when they're all done, but just FYI.. > As a general rule, I like to use as lightweight a library as possible for my needs and if possible one whose codebase I'm comfortable diving into\nSame here! Exactly the reason why I wrote huey (and peewee, vis-a-vis sqlalchemy).\nI'm looking into adding support for chord-like API, but don't want to commit to an implementation as I'm not sure how cleanly I can do it.. Right, sorry I mistyped my example -- I had meant to add blocking=True. Updated comment as well.. If the task fails, all bets are off. The task will return upon failure and the TaskResultWrapper will raise an error for the failed task.. Committed: d6a5f372715737cbfbed6ff71dc685107ade1e5e\nThe above commit adds a reset() method to TaskResultWrapper so that you can re-get() the value of a task that failed and was subsequently retried successfully.. Correct. When running in always_eager mode, then the return value is whatever is returned by the task itself. If you are executing a pipeline in always_eager mode, then the pipeline is executed and a list is returned with all the result values.\nI do understand your point, though, and I dislike that the return values are different. The TaskResultWrapper object exists to facilitate communication between the calling-code and an opaque \"result store\". The fact that always_eager=True should not really come into play.\nLet me see about unifying these interfaces.\nI am concerned, though, that this might break things for other people who are depending on the current behavior.. You know...I don't like to say this, but I think it's just going to have to remain as-is. There's too much going on to try and achieve a 100% faithful replication of the ordinary \"execute task via consumer\" logic, without some refactoring. Error handling, for one, is a bit tricky.\nI can suggest that if you need to unit-test some tasks, then test them as pure functions. Either by implementing a normal function and storing the task-decorated wrapper under a new name, or by using the decorated function's .call_local() helper.. Created #384. Zen of Python says there should be one and preferably only one way of doing this...so I'm inclined to think this may cause more confusion than how it was before.\nIf you want to be explicit about enqueueing tasks, you can:\npython\nhuey.enqueue(task_func.s(task, args, here))\nWhen I first wrote huey I made the decision to have task invocations happen in place of the function call (as opposed to how celery works, where you call a special method).. Yes, Huey supports gevent, threads or processes.. > This is particularly annoying as users have to flush the queue and recreate tasks again, sometimes for things planned months in advance.\nThis is my bad. I should've made it clear in the changelog. Apologies for the inconvenience.\nI've merged an equivalent patch, updated the changelog, and pushed a new release 1.6.1.. Seems like a bug, let me check it out.. So, here's the relevant code (api.py):\n```python\n    def execute(self, task):\n        if not isinstance(task, QueueTask):\n            raise TypeError('Unknown object: %s' % task)\n    try:\n        result = task.execute()\n    except Exception as exc:\n        if self.result_store:\n            metadata = self._get_task_metadata(task, True)\n            metadata['error'] = repr(exc)\n            metadata['traceback'] = traceback.format_exc()\n            self.put(task.task_id, Error(metadata))\n            if self.store_errors:\n                self.put_error(metadata)\n        raise\n\n```\nSo we're storing errors as results, but I think the fix would be to move the \"store_errors\" conditional up to the line reading \"if self.result_store\".. Proposed change:\n```diff\n--- a/huey/api.py\n+++ b/huey/api.py\n@@ -356,13 +356,12 @@ class Huey(object):\n         try:\n             result = task.execute()\n         except Exception as exc:\n-            if self.result_store:\n+            if self.result_store and self.store_errors:\n                 metadata = self._get_task_metadata(task, True)\n                 metadata['error'] = repr(exc)\n                 metadata['traceback'] = traceback.format_exc()\n                 self.put(task.task_id, Error(metadata))\n-                if self.store_errors:\n-                    self.put_error(metadata)\n+                self.put_error(metadata)\n             raise\n     if self.result_store and not isinstance(task, PeriodicQueueTask):\n\n```. Cool I'll push a new minor release.. 1.7.0 pushed to pypi.. This looks cool to me, I added a question.. I appreciate what you're going for, but I'm not interested in this additional state/complexity. Going to pass on merging.. What huey version are you running?. I have no idea...are you configuring logging elsewhere in your Django settings module?. Good deal, I was gonna say -- I set up a test env with Django 2.0 and it was working just fine. Cheers.. Right now Huey doesn't support priorities, but you can use multiple queues and run a consumer-per-queue to achieve a little bit more control over execution time.. So what you might do is:\n```python\ndef send_email(recipient, subj, message):\n    whatever()\n    send_the_email(...)\n@queue.task()\ndef send_email_task(args):\n    print('sending email from the regular queue')\n    send_email(args)\n@fast_queue.task()\ndef send_email_fast_task(args):\n    print('sending email from the fast queue')\n    send_email(args)\n```\nOr,\n```python\nsend_email_task = queue.task()(send_email)\nsend_email_fast_task = fast_queue.task()(send_email)\n```. The problem may be that you have a global registry. You may instead want to:\n```python\nqueue = RedisHuey(global_registry=False)\nfast_queue = RedisHuey(global_registry=False)\n```. Yep, will fix.. It says in the README that it works with 2.7 and 3.4+.. Should work with anything that runs python. > Making first argument optional and second argument required (for periodic_task) is very unusual and in fact force to always specify both positional arguments or call function with keyword parameter @huey.periodic_task(validate_datetime=crontab(minute='0', hour='3')) in our case.\nYes, this should have been caught when I was reviewing. Gross. Will push a fix. cc @Sebubu. I think this should address the issue: 8181e32d69afc4ece0cd39438b757503aa987744\nIt restores the original behavior and, to specify a different queue, requires that you use queue='some-queue'.. cc @MarcoGlauser. Hmm, I have no idea. Perhaps you can share your Huey configuration? Are any errors being logged? Using redis? You polling or using the blocking approach?. OK, yeah that makes sense. Do the workers continue logging \"Sleeping for X\"? Or at some point do the log messages cease?\nWhen you restart the huey consumer, does it run through any backlog of messages from when it was not responsive?\nPlease try and paint a picture here, as there's some issue in your deployment and I'd like to help you diagnose it.. Please comment with additional details and I will reopen the issue.. Glad you got it sorted out, thanks for the update.. It sounds like there's a bug in your periodic task... Huey does not automatically retry tasks that fail. If a task will be retried, you'll see log messages like this:\n[2018-03-12 10:08:36,851] INFO:huey.consumer.Worker:Worker-3:Executing tasks.queue_task_try_thrice: 13116962-dc4a-4dfa-87dd-3684ff31651a 3 retries\n[2018-03-12 10:08:36,854] DEBUG:huey.consumer.Worker:Worker-3:Task tasks.queue_task_try_thrice: 13116962-dc4a-4dfa-87dd-3684ff31651a 3 retries ran in 0.002s\n[2018-03-12 10:08:36,854] ERROR:huey.consumer.Worker:Worker-3:Unhandled exception in worker thread\n(traceback would appear here)\n[2018-03-12 10:08:36,855] INFO:huey.consumer.Worker:Worker-3:Re-enqueueing task 13116962-dc4a-4dfa-87dd-3684ff31651a, 2 tries left. @MarcoGlauser @Sebubu -- ... this is related to your patch so feel free to jump in.. Potentially fixed by: f85efe0a89270436211d71fca80d0a8c849b764b. Considering the types of issues relating to this patch, I've decided to roll it back and have pushed a new release, 1.9.0, that returns to the single huey instance behavior of 1.7 and previous.\nApologies -- I should have been more thorough when reviewing this patch. I should have insisted on better test coverage as well.. No worries, I should have insisted on better test coverage.\nYes, I definitely think it's a great feature, and would merge with a more thorough test-suite.. Can you give an example? I'm not understanding. Let's say you have the following periodic task:\npython\n@huey.periodic_task(crontab(minute='*'))  # Runs every minute\ndef every_minute():\n    time.sleep(61)\nThe above task will be enqueued to run every minute, but the task itself runs for 61 seconds. What will happen? Huey will enqueue the task every minute (and eventually the queue will become backed-up):\n\nt0: task enqueued, sleep for 61\nt60: task enqueued again\nt61: previous task finishes\nt120: task enqueued\nt122: previous task finishes\netc...\n\nSo, regardless of how long a periodic task runs for, it will still be enqueued on it's schedule. Depending on how many workers you have, this can be problematic for what I hope are obvious reasons.\nNote: if you want to restrict multiple instances of a task from running, check out the task locking docs. http://huey.readthedocs.io/en/latest/api.html#Huey.lock_task. > But sometimes the \u0441onverter works more than an hour, because of what the next start of the task is skipped.\nAre you sure that it is skipped? I mocked-up an example with 1 worker and a periodic task that runs every minute and sleeps for 90s. The task is enqueued every 60 seconds regardless of how long it takes to run:\n[2018-03-19 09:17:06,550] INFO:huey.consumer.Scheduler:Scheduler:Scheduling periodic task tasks.queue_task_every_90s: 0e24c28a-1f8c-41ee-8fc4-1eb8b07884df.\n[2018-03-19 09:17:06,553] INFO:huey.consumer.Worker:Worker-1:Executing tasks.queue_task_every_90s: 0e24c28a-1f8c-41ee-8fc4-1eb8b07884df\n[2018-03-19 09:18:06,606] INFO:huey.consumer.Scheduler:Scheduler:Scheduling periodic task tasks.queue_task_every_90s: e75040c9-af32-4cbe-914f-4f28ce4c6acb.\nslept 90\n[2018-03-19 09:18:36,641] INFO:huey.consumer.Worker:Worker-1:Executing tasks.queue_task_every_90s: e75040c9-af32-4cbe-914f-4f28ce4c6acb. > Further down in that page, this section references synchronous code\nIt refers to the fact that, when always_eager is set, the tasks are not run by the consumer at all but are called immediately and in the same thread as they were invoked originally. So, instead of the task being put on a queue, read by the consumer, and executed in the consumer's python interpreter -- they are run \"inline\".\n\nWhat's the correct configuration/usage for always_eager & Django?\n\nalways_eager is helpful for debugging because it means that, when developing your app, you don't need to run a separate queue and consumer. The tasks execute exactly as if they were normal Python functions.\nWhen developing (DEBUG=True) you should use always_eager.\nWhen in production (DEBUG=False) always_eager should also be False.. My guess is that you aren't monkey-patching? Do you have the following code as the first line of Python in the entrypoint to your applicatoin?\npython\nfrom gevent import monkey\nmonkey.patch_all(). It's also clearly described here: http://huey.readthedocs.io/en/latest/troubleshooting.html. If you're planning to use gevent/greenlet, be sure you understand what you're using.. Are you using gevent/greenlet workers?. As you probably know, gevent is single-threaded and any CPU- or disk-bound operations will block the main thread (including all greenlets). So if you have a task that blocks up the main thread it's possible that could be causing the drift.\nThe other possibility is just that huey, in an effort not to waste CPU, is sleeping a tad bit longer than it should and this accumulates over time. I can see about trying to fix if this is the case...as I'm starting to suspect now that I'm looking at the code.. I've pushed a commit that, in testing locally, seems to address the drift issue. It does this by keeping track of when the scheduler started and incrementing that timestamp by the scheduler loop interval. That incremented timestamp gives huey an absolute point-in-time instead of a relative point, allowing the sleep interval to be adjusted accurately each iteration. I also added a check to ensure that, if things get blocked up, that the scheduler runs no more than once per interval.. You can use the consumer event-stream to subscribe to events:\nhttp://huey.readthedocs.io/en/latest/events.html. I guess you won't be able to run multiprocess mode on windows. Try threads? Wontfix.. The interpreter will preempt threads, so even though you're effectively running single-threaded, they should switch every x instructions.. You should be fine to run multiple huey instances side-by-side. It strikes me as odd that you are running huey on Windows for your data-processing.. Huey does not support rate limiting. You'll want to look into a third-party library to handle that. Upon being rate-limited, you'd probably want to force a retry, so you could raise a RetryTask exception, which will re-enqueue for retry.\nThere are a lot of ways you could work around this inside the map_reduce master-task as well.. Check out 2509a0b -- it adds the \"-f\" option to the consumer, which will flush stale locks at startup. A caveat is that huey only knows about locks that are instantiated at module-load time, so huey will find stuff like this:\n```python\n@huey.task()\n@huey.lock_task('foo')\ndef foo():\n    pass\n@huey.periodic_task(...)\n@huey.lock_task('bar')\ndef bar():\n    pass\n```\nBut it would not see this, since it is not encountered (and therefore registered) until it is interpreted:\npython\n@huey.task()\ndef baz():\n    with huey.lock_task('baz-lock'):\n        pass. Please comment if you have trouble, I'll re-open if needed.. 0447c6046e7475ec31e9d0796ccc6c7f906bfaef. Closing in favor of #362. Events are enqueued by the application, typically, whereas events apply to operations performed by the consumer/workers. Anyways, you'd have to manage a bit of state to ensure you counted the queue length correctly.\nIf you want to measure the length a better way is to use the storage API's \"queue_size()\" method, e.g.\n```python\nhuey = RedisHuey(...)\nprint('queue size:', huey.storage.queue_size())\n``. While I understand the desire to track enqueued tasks, it's fundamentally a different type of operation from all the other events and that's why I'm opposed to adding it.. Rather than using a thread, you could subclassRedisStorage` and override the enqueue method to push an event. That might be easier implementation-wise.. This kind of question is more appropriate to stack overflow.. Why is this an issue?. I'm grateful for the issues you've raised as they've led to Huey becoming a better library for everyone.\nBy \"code quality\" you are referring to the fact that an internal consumer data-structure is list<(Worker, worker_t)> instead of list<worker_t>.\nI do not plan on changing this, as I think it's clean and symmetrical to keep the worker instance alongside the thread/process that's running it.. You're correct. It makes things like testing easier to have the worker class and the associated process in the same data-structure, because once you wrap the worker class in a greenlet/thread/process, there's no way to reference it after the fact. It's not being used outside of the tests, at present, though. Perhaps I can make some better comments.. I feel like if Huey is a well-designed library then it will be easy to extend. It's not an explicitly-stated project goal to make all the internals override-able. A good rule of thumb is that the 80% case should be easy and the 20% case should be possible.\n\nAre you still against allowing easily overriding internals?\n\nWhen did I say this? I think you might want to look at your attitude and see what's going on -- there's an entitled vibe coming across that you may not be aware of.\n\nFor example I have to monkey-patch to name tasks not as 'queue_task_%s' % (func.name)\n\nReally? I thought that the task() decorator's name parameter would allow you to accomplish this, e.g.:\npython\n@huey.task(name='foo.bar')\ndef foo_bar(a, b):\n    return a + b. Something to bear in mind is that many, many people use this library happily (myself included). The public APIs are all documented, as is the behavior of the consumer. The test suite covers the documented APIs as well as some of the trickier internal bits. These are, to me, indications that the project is healthy.\nI don't know the details of what you're trying to implement, but it sounds like you are making significant modifications to the library and are deep into the internal data-structures.\nHuey is a task-queue. It's not a task-queue framework. I hope you understand the difference.\nAs I said earlier, my goal is to make the 80% use-case easy and the 20% use-case possible. Having clean, orthogonal APIs throughout is a good way to ensure this is possible. But because you are having some very specific issue overriding some very specific internal behavior doesn't necessarily indicate there's a bug that needs to be fixed.\n\nI feel like I am fighting with you.\n\nYou're only going to wear yourself out if you feel that way.. The currently-supported approach for this is to use multiple Huey() instances for the distinct task groups.\nThe reason why \"groups\" wouldn't work has to do with the underlying storage system. A typical huey setup will have a single Huey instance, which is using a Redis server for storage. Tasks are added to a Redis LIST specific to the huey instance whenever they should be executed. The consumer, in turn, reads tasks from this Redis LIST and distributes them as workers become available. \"Groups\" won't work because you could find yourself in a scenario where a consumer receives a task on the queue, but the task is not in any groups it's configured with...so what does it do with the task? Re-enqueue it and hope that a different consumer picks it up eventually? It doesn't work.\nInstead, you should use 2 (or more) huey instances and configure them as you see fit. When running the consumers you can provision them with workers as appropriate.. Is there any change when you move \"from gevent import monkey; monkey.patch_all()\" to the very first line of your WSGI file?. So gevent monkeypatches the threading and thread-local object in the Python standard lib. It looks like Django does some checking to ensure that database connections are thread-safe and are not used outside the thread in which they were created. It looks like you'll need to tell Django to allow thread-sharing or in your mini-huey tasks be diligent about using a fresh connection for the scope of the task.\nThe BaseDatabaseWrapper has some allow_thread_sharing parameter it can receive, but I have no idea how one would pass that since I'm not sure how it's constructed. Doesn't seem to be documented or a public API?\nAnyways, good luck, hope that gets you moving in the right direction.\nIf you're using Django I feel bad for you son.... Thank you for reporting this to me. I'm looking into it.. 2c465dc117e84b9d1119f8b06a5488f68a793e7d. Under what circumstances is having this reference useful?. Right but why would you need to use the enqueue method directly?. Ohhh I forgot that pipelines used enqueue. No that makes sense! Thanks.. Out of curiosity, what happens to the KeyboardInterrupt handlers when a SIGINT handler is registered? Do they even fire anymore?. Reading the SO thread, it seems that the sigint handler is disabled if the consumer is run without job-control from the shell... under what circumstances would someone running huey encounter this? Or, in other words, it seems like the SIGINT weirdness is occurring outside of Python, from the shell...and Python's just following what the shell has told it to do?. Kool, looks good, thanks!. Lol...actually I hit merge and then figured with something as big as this I probably ought to do some thorough testing. So at the moment it is not in master.. Sorry, do you mind rebasing all this stuff into a single commit and creating a new pull-request? The reason I backed out the change is because there's a good deal of KeyboardInterrupt handling that is still present and presumably will no longer be needed...but I'm not sure how everything will interact with this signal handler in place.. No rush man, sorry for the snafu.. So I'm wondering what happens to the SIGINT handlers in the child/worker-processes in the event you're using the process worker model... Additionally, it would seem that all KeyboardInterrupt exceptions are no longer needed. It'd be extremely important to ensure that this new behavior is identical to the previous behavior across all worker types (greenlet, thread, process), and unfortunately the tests are not broad enough to give me confidence that there aren't regressions.. This looks good, thanks -- merged.. Looks like a problem with gevent... I'd suggest you open an issue there.. There was a patch that a user submitted a couple months ago that implemented multiple huey for Django, but it had some fundamental issues that showed up when merged so I rolled it back. Here it is for reference: https://github.com/coleifer/huey/pull/230\nI'm not planning to implement this any time soon myself, but if a high quality patch comes through I'd definitely consider trying it again.. Multiprocessing doesn't work on Windoze. #208. 4138d454cc6fd4d252c9350dbd88d74dd3c67dcb. You need to ensure all your task modules are imported before requesting the list of scheduled tasks.. The docs explain: http://huey.readthedocs.io/en/latest/imports.html. Not built-in, no. You can subscribe the consumer events channel, however, and listen to messages that way: http://huey.readthedocs.io/en/latest/events.html\nAlternatively, you can build progress reporting into your tasks themselves. You'll probably want some external storage layer to track this stuff, but that's typically the way you would implement it. You could also dig into the internals -- the APIs are all documented -- and possibly use some of the existing features in huey to add the reporting features you want.. That's a reasonable request, but at present this is not the way huey works.. Committed a change that should add this behavior. See 44a4445. Oh shoot, that's my bad. I can fix.. a8909f2b8f539582725d32479132d232421a5434. Thanks for the report, I appreciate your help as well.. Not that I'm aware of, though it should be possible to build one to your liking with the provided APIs and/or the consumer events.. SGTM, thanks.. This won't work the way you think it would. Even if it did, with every iteration of the \"spawn_processor_daily\" task (which seems to run 3 * 24, or 72 times in a day), you would be declaring 4 periodic tasks. So you'd end up creating 72 identical periodic tasks that run at 9, 72 that run at 8, 72 that run at 2:15, 72 that run at 12:30, every 24 hours. So after 24 hours of running, at 9:00AM you'd end up calling \"send_daily_reports()\" 72 times in rapid succession. After 48 hours of running, at 9:00AM you'd end up calling \"send_daily_reports()\" 144 times.\nThe consumer is responsible for discovering periodic tasks at run-time. Huey relies on import-time side-effects to discover tasks. This is documented and hopefully makes sense to you. It might be possible to dynamically add periodic tasks from within a periodic task, but I think your code is broken.. I hope this doesn't diminish your faith in huey's reliability lol. Theoretically, yes. The consumer process relies on import-time side effects but so long as you run your \"loading from config and declaring\" code as part of the consumer start-up you should be fine.. Was fixed in 4138d454cc6fd4d252c9350dbd88d74dd3c67dcb but I may need to issue a new release.. 1.10.1. This has been requested before and you can see the discussion here: #261 and to a lesser extent in #251.\nYou can send a SIGHUP signal to the process which will restart the consumer. As far as implementing an automatic restart after X tasks, that is not something I'm interested in adding at this time.\nYou can also refer to the internal Consumer method \"_handle_restart_signal()\" and subclass/extend the consumer to implement similar logic after X tasks are processed.. It appears that huey is running your task. Perhaps you have some problem in your task implementation. Try adding logging and seeing if you can debug the issue.\nFor what it's worth, your if statement with the \"if not ...exists\" will never be executed because \".exists\" is a method. It should be \"if not ...exists()\".. I've always just run a single redis instance and never had issues. No recommendations as far as I'm concerned.. You can use task locks for this: https://huey.readthedocs.io/en/latest/api.html#Huey.lock_task. Well, I'd suggest you keep the lock around the periodic task, and then once you've enqueued all the sub-tasks, just wait for them all to finish...kind of like calling .join() on a bunch of threads.. e.g.\n```python\n@db_periodic_task(crontab(minute='*/1'))\ndef fetchexchanger():\n    tasks = []\n    for pagenumber in range(1,7):\n        r = requests.get(\"https://www.feixiaohao.com/exchange/list_\"+str(pagenumber)+\".html\")\n        print(\"Current Page:\"+str(pagenumber))\n        soup = BeautifulSoup(r.content, 'html.parser')\n        lines = soup.find_all('tr')\n        for line in lines:\n            task.append(fetchexchangerworker(line))\n            counter = counter+1\n    # Wait for all tasks to finish.\n    for task in tasks:\n        task.get(blocking=True)\n\n@task()\ndef fetchexchangerworker(line):\n    #some other time-consuming task\n``. No idea. If you're using threads/green threads for your workers you should be able to simply monitor the consumer process, but if you're using process workers it'll be more complicated.. Certain objects cannot be pickled. It looks like you are passing a function object to your task as an argument? How are you calling the task?. The error store is not designed to be used for re-enqueueing tasks. If you want to retry tasks that have errors, specifyretries` in your task declaration.\nThere's an additional problem with including the task data in the error queue -- it can frequently result in problems pickling, which is why it's not True by default.\nYou can, if you want, subclass RedisHuey and override the signature of _get_task_metadata to always include the data for errors:\npython\nclass MyRedisHuey(RedisHuey):\n    def _get_task_metadata(self, task, error=False, include_data=False):\n        return super(MyRedisHuey, self)._get_task_metadata(task, error, include_data=error). See discussion on #340 for workaround. Closing.. I'm not reading the whole issue because the thing that jumped out at me is... if you've got DEBUG set to True in your settings file, why are you trying to run the huey consumer? There's no reason to do that!. Of course when you try to run the consumer it opens a connection to Redis to listen for incoming messages. When DEBUG=True (and thus huey is in \"always eager\" mode) there's no reason to run the consumer, though. Tasks are executed synchronously. Always-eager means the tasks are run just as if they were not decorated / normal functions.\nI have no idea what \"debug toolbar\" may or may not be doing...jacking with log handlers? Who knows?\nHuey works. I think you do not understand it, though. Closing as I do not believe this is an issue.. I don't think that huey is what you're looking for. Or, maybe it is, but it's designed to read from some persistent queue/message broker. The consumer coordinates the receipt of messages, running the worker processes, distributing tasks, etc. I don't know if huey works on windows in multi-processing mode, probably not.. Looks like possibly a circular import? Not sure. This is not a huey issue so I suggest trying stackoverflow.. This is basic Python function composition. This is not a huey problem and I suggest you take the question to stackoverflow.. If you have:\n```python\ndef something(s):\n    return s + 1\nsomething_task = huey.task()(something)\ncall something_task with an argument:\nsomething_task(3)  # equivalent to \"something(3)\" but called as a task\n``. I thought the issue was database corruption -- perhaps you could clarify what you mean by that? From reading the description its not quite clear what you mean by \"sharing\" data.. > each object'srecur()method performs a calculation and saves the results on the object via Django's standardsave()` method\nIt sounds like there's a bug in your implementation, but I'm at a loss how to debug it.\nIf you can make a minimal setup to reproduce the issue I could take a look at it, but my sense is that this is not a huey problem.. > But if I create the chromedriver inside some_long_calculation_task, the function executes normally.\nYes. Some objects cannot be pickled. Huey serializes the arguments it is called with using pickle and stores them in the queue. When a worker gets a message, it unpickles the arguments and calls the appropriate task function passing in the unpickled arguments.\nIt's a good practice to pass only basic values into your tasks as parameters. So creating the chromedriver in the task is the way to go.. You can't pickle a zmq context, simple as that.. This is expected, since you're using the task result-storage APIs for synchronization (rather than for what it's intended use-case is, namely: the storage of task results). You're depending on huey to store a result for task that does not return a result, so you can determine that the task is finished.\nBy default, Huey does not store None results in the result-store. This is to avoid needlessly clogging up the storage system with tasks that do not return a meaningful result.\nYou can explicitly store None results, by: huey = RedisHuey(..., store_none=True).\nDocumented here: https://huey.readthedocs.io/en/latest/api.html#Huey. It's complicated. And it may depend on the worker type you select.\nIf you are running the consumer with the \"process\" worker-type, you should be able to just kill the worker process. As long as you're running the worker health check, huey will determine that a worker has died and spawn a new process.\nIf you are using thread or greenlet/gevent, there is no such option. There is no \"clean\" API for killing a running thread in Python. With gevent it is only possible to kill a greenlet if it should yield at some point.\nOn the other hand -- you can design your tasks such that they check for some kind of a signal from another process -- and upon receiving such a signal, will terminate. But the consumer itself is not responsible for this. You can even use the huey result-store for communication.\nThis is a very vague question so it's hard to be more specific.. Why do your workers need to connect to a database?. > For example because they need some data from them :-)\nI don't want to be presumptuous, but I don't get the impression that you understand very well how huey works. The worker process is spawned by the main consumer process and is managed by the consumer. Workers are not stateful. They simply execute tasks.\nIf you need to connect to elasticsearch to push some data up to it, you would theoretically pass any connection information to the task.\nIf the task is generating a report and writing to the database, then inside your task function you would open a connection to the database and perform your writes, and close it afterwards.\nLike I said, I don't think you understand how huey works.. Thanks for clarifying!\nYou might also consider -- when you start the huey consumer, you pass it the path to the module containing the \"huey\" instance. As a result, huey relies on import-time side-effects to load and register your tasks. So anything that happens at import-time, such as setting up a global database connection or whatever, will occur in the consumer's main process.\nNow -- and this is especially true for multi-process worker -- when consumer process forks and spawns the workers, that global connection is \"copied\" into the child processes. The interaction of the child/parent processes using that connection could be a source of problems, so I think it'd be best to set up your \"global\"/process-specific connections at some time after the fork.\nYou could write a function like:\n```python\nThe first time this is called it will create a client and cache it as an attribute of\nthe \"get_elasticsearch_client\" function. Subsequent calls will simply return the\nattribute-cached client.\ndef get_elasticsearch_client():\n    if not hasattr(get_elasticsearch_client, '_client'):\n        get_elasticsearch_client._client = Elasticsearch([...])\n    return get_elasticsearch_client._client\n@huey.task()\ndef index_document(document):\n    client = get_elasticsearch_client()\n    client.index(...)\n```\nThis is oversimplified but I hope the pattern makes sense. Setting up a global connection during import-time is problematic because the worker processes aren't forked until afterwards. You can still have a global connection object, however -- you'll just want to ensure it isn't created until after.\nIt might make sense to add a signalling API that can call user-defined functions when the consumer is ready to start up (which if I understand, is exactly what you were asking for in the first place)?. I think this is a good idea -- I've got a first-cut at the implementation pushed: b05f70777bcede61385ee9bd50f728e0b809f7e7\n```python\ndb_conn = None\n@huey.on_startup()\ndef setup_db_conn():\n    global db_conn\n    db_conn = psycopg2.connect(database='my_db', ...)\n@huey.task()\ndef write_to_db(data):\n    cursor = db_conn.cursor()\n    # ...\n```. How would you pass information to it, given that it's called from within the consumer and not by the user?. Huey pickles the task arguments because it has to serialize them and send them to the workers. Some objects cannot be pickled -- the io.BufferedReader being one of them (for what I hope are obvious reasons).\nIn other words, you cannot pass a request to a huey worker, which this error message is telling you.. Made some additional tweaks, including removing the unnecessary sleep(). Not sure what that was doing in there.. I don't know what you mean by \"app\". It's a path to a Python module / class. So blog.main is a module and \"huey\" is an object in the blog/main.py file.. This is so irrelevant and off-topic. I'm going to pass on these changes, but thank you.. Not interested...auto-reloading tasks, particularly a consumer, seems misguided. Also it seems you're using this with Django. Typically when doing huey development with Django, huey is run in \"always_eager\" mode (due to settings.DEBUG being True) ... so your tasks autoreload when your django dev server restarts.\nPresumably you'll only be running an actual huey consumer when actually running your django app outside of debug mode, and in that case your django code won't be reloading anyways.. > Is there interest to integrate it directly into huey?\nNot right now, no.. Huey serializes task args/kwargs with pickle before serializing them and writing them to the queue. Similarly, return values are pickled and stored in the result-store, then unpickled when read. So the APIs you interact with deal with python objects, but the actual storage layer is dealing with plain old bytes. For a higher-level view/task reporting I'd anticipate you'd be interested in dealing with the unpickled Python results.\nYou can hook into huey in a number of ways...by decorating the task functions -- which will add whatever work you're doing (db connections, inserting rows into a db, whatever) to every task executed by the worker process. Keep in mind if you're writing to a db your worker processes will all need to manage their db connections / transactional state / etc.\nThere's also the event streaming API which can be used to monitor events from the consumer in real-time, but that's not what you're after I don't think.\nAny kind of advanced reporting or persistence beyond the normal logging done by the consumer, and the event streaming, is not something I want to add to huey.. In what version of Django was this added?. Nevermind, looks like previous commenter indicated 1.7. Thanks!. I have no idea what might be going on in your setup, in your functions, in \"capsys.disabled()\", etc, etc.\nCould you identify where exactly in huey the code seems to be hanging? Have you tried setting a breakpoint and stepping into the code? As-is this is completely useless information you have provided me.. > Running pytest on our project with a debugger is a somewhat finnicky\nprocess\nAnd you don't suspect that this might be the problem?\nThere's no use in speculating until you can point me to where in huey things are getting locked up. Set a breakpoint. Use pdb.set_trace() or something to step into the code. I'll gladly reopen if you can provide something concrete for me to go on.. I'm still not clear on how this is a Huey issue. Are you sure \"args\" is a single Event instance? Based on what you've given me, here is the simplest example I can think of showing that huey works correctly:\n```python\nfrom huey import RedisHuey\nhuey = RedisHuey(always_eager=True)\nclass Event(object):\n    def init(self, name):\n        self.name = name\n    def repr(self):\n        return '' % self.name\n    def getitem(self, item):\n        return self.dict.get(item)\n    get = getitem\n@huey.task()\ndef event_task(event):\n    print('task received', event.name)\n    return event.name\nevents = [Event(name='name-%s' % i) for i in range(10)]\nfor event in events:\n    event_task(event)\n```\nSeems to work fine -- prints 'task received name-#' 10x.. In your example, resolving the r object to get the result will raise the error:\npython\nr = failed()\nactual_result = r()  # Exception raised.\nThere appears to be an inconsistency in the result() API, however, which your example illustrates.\nI've pushed a fix in 2ac97394661b86edba450a1155859a1a642d6503. Couple thoughts...\nYou shouldn't assign .on_complete - that's why it's not documented, really. The docs show you how to create a pipeline -- the assumption is that if your task returns a value and you are using a pipeline, you want to carry the return value forwards -- (otherwise just call the tasks serially). Documentation for pipelines.\nIn your example, it may be returning None because the queue hasn't processed the second item yet, so be sure you call .get(blocking=True) when resolving the results of a pipeline, e.g.\n```python\n@huey.task()\ndef add2(x):\n    return x + 2\nt = add2.s(4).then(add2)  # No args, it will receive the return value.\nres1, res2 = huey.enqueue(t)\nprint(res1.get(blocking=True))  # 6 (2 + 4)\nprint(res2.get(blocking=True))  # 8 ( 2 + 6, previous return value)\n```\nIf your task does not return a value, then of course nothing is carried forward:\n```python\n@huey.task()\ndef dont_carry_results(msg):\n    print(msg)\nt = dont_carry_results('message1').then(dont_carry_results, 'message2')\nhuey.enqueue(t)\nConsume will print \"message1\", then \"message2\".\n```\nSo I believe I've shown how to use pipelines correctly with argument passing, answered the question about None in the results, and also shown how to construct pipelines that do not pass a return value.\nYou said you don't care about the return value of the first task, they just need to happen in order. You can write a third task that calls both functions in succession?\n```python\n@huey.task()\ndef process_new_signup(email):\n    actually_do_some_stuff(email)\n@huey.task()\ndef send_new_signup_email(email):\n    success = actually_send_an_email(email)\n    return success\n@huey.task()\ndef process_and_email_new_signup(email):\n    actually_do_some_stuff(email)\n    return actually_send_an_email(email)\n```\nSince the first function in the above example does not return a value, we can call it in a pipeline as well:\n```python\nt = process_new_signup.s(some_email).then(send_new_signup_email, some_email)\nprocess_result, email_result = huey.enqueue(t)\nIf you want to get the return value of the send_new_signup_email task, just:\nprint('email task result: ', email_result.get(blocking=True))\n```\nIf you did want to send the output of one function to another, then the following example shows how:\n```python\n@huey.task()\ndef generate_report()\n    report = actually_generate_the_report()\n    return report\n@huey.task()\ndef send_email(message):\n    success = actually_send_the_email(...)\n    return success\nt = generate_report.s().then(send_email)\nreport_result, email_result = huey.execute(t)\n```\nAlthough of course you could always just make a third task that calls both functions:\npython\n@huey.task()\ndef generate_report_and_send_email():\n    report = actually_generate_the_report()\n    success = actually_send_the_email(report)\n    return success. f7c5b1d72b13896bc8e660c6931743426496ecd5\nThanks for reporting, this is now fixed and I've added a regression test. Pushed a new release, 1.10.3.. I've merged a roughly equivalent patch. I also removed the debugging statement that logged the duration.. Personally, I'm not interested in abstracting out the serialization logic. Pickle works, and has been a good fit. Also, besides task serialization, the result-store APIs use pickle as well for storing arbitrary key/value data, such as task results or task error metadata.. Security concerns could easily be solved by putting a message digest or whatever around the serialized data, and verifying the digest from within huey. No need, in my opinion, to come up with other serialization schemes or abstractions. And if you're running your redis on the public internet, you probably got more problems than worrying about a malicious pickle getting thrown in your task queue.... Not sure. It may be because it's being run by a separate worker process, and supervisor doesn't see the output? Supervisor may be doing some buffering or something? I'm really not sure but if you run huey from the command-line the output is normal so I don't think this is a huey issue.. Its \".s\", not \".a\".. I don't know where you got \".a\" from, but docs are clear:\nhttps://huey.readthedocs.io/en/latest/getting-started.html#task-pipelines. What version of huey?. Not sure what might be the problem. This logic is tested:\nhttps://github.com/coleifer/huey/blob/master/huey/tests/test_consumer.py#L404-L417. You can try it out...modify the tasks.py in the \"simple\" example (included with the huey source):\npython\n@huey.task(include_task=True)\ndef print_task(task=None):\n    print('got task id=%s' % task.task_id)\nResults in:\n[2018-11-01 14:15:12,158] INFO:huey.consumer.Worker:Worker-4:Executing tasks.queue_task_print_task: 7b232b7d-d368-4e96-babb-e9bbe7dc8619\ngot task id=7b232b7d-d368-4e96-babb-e9bbe7dc8619\n[2018-11-01 14:15:12,158] INFO:huey.consumer.Worker:Worker-4:Executed tasks.queue_task_print_task: 7b232b7d-d368-4e96-babb-e9bbe7dc8619 in 0.000s. What do you mean \"free\"?. Released 1.10.4.. OK so if you're using the multiprocess worker/scheduler presumably you won't experience this issue since the worker/scheduler processes are stopped before the restart occurs. This would be a \"normal\" process exit, so their resources, such as open connections, would be closed. I mention this because I don't think the solution described in your PR would work for the multiprocess situation, as the linux implementation relies on enumerating /proc/self/fd/ from the main consumer process and all the open fds in the child processes (workers + scheduler) would need to be handled separately. It doesn't matter, though, because I am guessing that when the workers/scheduler procs terminate the OS handles the cleanup.\nSo we're just concerned with threads+greenlets, yeah?. Are you all not able to run huey with a true process manager? Something like systemd, supervisor, upstart? A tool like that would probably be the correct approach, versus closing fds en-masse?. Well, I think the answer is: don't use Python 2.7. I was reading up on fnctl and FD_CLOEXEC and ran across PEP 446, which:\n\nThis PEP proposes to make all file descriptors created by Python non-inheritable by default to reduce the risk of these issues.\n\nIt was accepted and is available from 3.4 onwards. I see from your logs that you're using 2.7, so that explains the issue.\nI verified that it behaves as advertised -- running a threaded consumer and restarting it multiple times did not lead to a growth in the number of connections as reported by Redis.\nTo all the people who thumbs-up'd the issue -- are you all running 2.7?. I think I'll mention this in the docs as a potential gotcha and close the issue.\nA couple thoughts:\n\nIf using the consumer with multiprocessing then you won't have issues, as the child processes exit and their resources are closed by the OS.\nIf you are using Python 3.4 or newer then you won't have issues because Python opens files and sets the FD_CLOEXEC flag. The OS will handle closing the file-descriptors when an exec occurs.\nIf you are using Python 2.7 + threads + a process manager of some kind then you won't have issues.\n\nIf you still want to implement some kind of cleanup routine, I'd suggest using fcntl.fcntl(fd, fcntl.FD_CLOEXEC) rather than os.close(fd). Letting the OS handle it seems like a much safer option.. Discussion and reasons for closing are in #374.. Replaced with similar patch.. Wow...that's a lot of worker connections to your Redis server. 100 greenlets * 6 consumers = 600 connections to Redis. Do you have a ton of purely IO-bound tasks (e.g. reading from a socket)? If not I'd suggest using threads for mixed workloads or processes for CPU workloads, and reducing the worker count to number of cores or so.\nThe Redis storage supports two modes of operation: blocking and polling. By default it will poll. Which means it uses exponential backoff up-to a timeout of say 10 seconds between polling. Each worker has its own connection to Redis and depending on which reads first (and in the event multiple requests come in, which one Redis processes first), that worker will dequeue the task.\nYou can try enabling blocking-mode, which uses a Redis blocking-right-pop. Just do huey = RedisHuey(...blocking=True).\nThere's no distribution algorithm. Tasks get added to a Redis list and workers attempt to pop items off that list. In polling-mode, they will try to pop and if nothing is returned, will wait before trying again. In blocking-mode they will do a blocking-right-pop, which decreases latency.. File I/O is not cooperative with gevent. And unless your db driver is pymysql or psycopg2 with a gevent wait callback, you're running those synchronously too.. You're missing a comma\npython\nmy_task.schedule(args=('string1',), delay=10). Not sure what the actual error is. The code being executed is relatively straightforward when you add something to the schedule:\npython\n    def add_to_schedule(self, data, ts):\n        self.conn.zadd(self.schedule_key, {data: self.convert_ts(ts)})\nPerhaps you have the wrong type of key (e.g. self.schedule_key is a list or a string instead of a sorted set)? Perhaps there's an issue connecting to the redis server?\nI'd suggest you use an interactive debugger and step-into the code to see where the failure is occurring.. Ahhh....yeah that's a big upgrade. Your application (which generates the tasks) and the consumer (which runs on the server executing the tasks) both need to be upgraded.. Ahh, thanks @vladlep -- I didn't realize I had not yet released the Redis-py 3.0 compatibility fixes.\nI've pushed a new release, 1.10.5, which specifies redis-py 3.0.0 as a dependency. This should resolve the issues.. Note: please format your code when posting an issue. You can learn how to do that here: https://guides.github.com/features/mastering-markdown/. The task has the execute time stored as a metadata attribute, that is visible in the task repr, which shows '@2018-12-11 19:03:19'.\nIs there a reason you are circumventing the usual APIs and manually instantiating the task instances? Huey does some normalization of the execute time when called via the decorators.\nSee the notes here: https://huey.readthedocs.io/en/latest/api.html#TaskWrapper.schedule\nI do not believe there is a problem, but perhaps a misunderstanding of how times are used in huey. The consumer runs in UTC time by default. A quick fix might be to simply run the consumer in localtime-mode (\"-o\"): https://huey.readthedocs.io/en/latest/consumer.html#options-for-the-consumer. I've just tested using the \"simple\" example found in the \"examples/simple\" folder in the source tree. Both the delay and the eta functions are working as expected.. \nIn the above example, I scheduled two commands to run after a delay of 5 seconds and 10 seconds, respectively. Both ran after (approximately) the appropriate duration from invocation.. Why not:\n```python\n@huey.task()\ndef my_task(foo):\n    print(foo)\nUse an absolute datetime\ndynamic_date = datetime.datetime.now() + datetime.timedelta(60)\nmy_task.schedule(args=('in a minute',), eta=dynamic_date)\nOr in seconds.\ndelay = 60\nmy_task.schedule.schedule(args=('in a minute',), delay=60)\n```. > First: How can i easier get all pending task IDs?\npython\npending_task_ids = [task.task_id for task in huey.pending()]\nRegarding EmptyData etc, huey doesn't store the results of tasks that return None. This is to prevent using up all your RAM storing tasks that have no return value.\nYou can always block until a task finishes by resolving the result:\n```python\ntask_result = call_task_function()\nblock until task is done.\nactual_result = task_result.get(blocking=True)\n```\nAlternatively you should use your primary storage, e.g. your database or the redis server, to store completion info from within the task.\npython\n@huey.task()\ndef my_task():\n    # do some stuff...\n    # ok, now the task is done.\n    save_some_state()\nYou can use the event stream to listen for task completions, but huey does not store \"completion\" info. Huey tasks. You can force huey to store \"None\", but be warned you can run out of ram if you aren't careful.. I would suggest that such an approach to testing is probably foolish, because you're essentially testing (at that point) that huey works as it should. Huey has its own unit tests and, provided you trust that it works, all you should need to do is use always_eager.. Why not just block when reading the result from the task itself?\n```python\ntask_result = call_task_function()\nBlock until task finishes.\ntask_result.get(blocking=True)\n``. If I were your employer I'd probably fire you for wasting so much time.. That's odd, I'm not sure. Can you print out for meregistry._registry.keys()?. The problem is that the identifier being used to identify the task is seemingly not found in the registry. The problem is most likely that when you're checkingpending()` you haven't imported all the task functions from your app. So the in-memory registry of tasks sees a task name but doesn't know what class / function it maps to.\nThe fix would be, wherever you're calling pending(), to ensure that all tasks have been imported by that point.. That doesn't make any sense to me, but ok.. Not me, but feel free to put it on github or whatever.. 7b4fc3eea819d5417f510b7ec2bf116b26fafbe9\nGreater refactoring does not seem sensible, given the inter-connected nature of executing tasks, re-enqueueing failed tasks, revoking, restoring, result-storage, etc. These mechanisms all rely on a persistent store located outside of huey, which provides a communication channel for the various moving parts. Until such time as these are all re-implemented to provide a synchronous, in-memory replica of the consumer logic, I think this is a suitable compromise.. Have you tried specifying a name for the task?\npython\none_func_task = huey.task()(one_func)\none_func_cron = huey.periodic_task(crontab(...), name='one_func_cron')(one_func). This is now fixed: 78856b07936efc80d56b1b1ac147f268de46d6ed\nAn error will now be raised if you attempt to register (or decorate) a task that conflicts with the name of a previously-registered task. So no more silent failures.\nA side-effect of how I implemented this is that the task serialization scheme has changed to accommodate the new naming scheme. So these changes should be considered backwards-incompatible in terms of the serialization format used.. What version of the Python Redis client library are you using?\nWhat error are you receiving?. You need redis-py >= 3.0, you have 2.10 installed.. I'm unclear what the issue is. If you send the same task (with the same task id), then it will use the same task id?\nPlease format your logs. The output is unreadable.\nIf you can provide more info I'll reopen.. Use triple-backticks or indentation to express code blocks. Single backticks are for inline code. The GitHub docs (see link below the comment text-box) are helpful: https://guides.github.com/features/mastering-markdown/\nWhen someone is too lazy to properly format their ticket/issue description, I am not very inclined to try to help.. I wonder if your code is somehow not threadsafe...I'd suggest looking in that direction.\nThis is a very unusual and difficult-to-understand use-case, with lots of weird parts (is dynamic import the issue? does it only happen with multiple queue managers? etc, etc). If you can create a very minimal test-case to replicate, I will be better able to help you.. What interval are you running the scheduler at?\nI've made the change, by the way.. That would imply that any scheduler_class and worker_class overrides would implement the exact same constructor. Just override the _create_worker and _create_scheduler methods.. I didn't think it was a good idea at first. After a day I thought it would probably be a fine addition: db68a555080270ff4195ccd861542e7a4164cc6e. > Do I understand correctly that ... you prefer to keep Huey non-extendable so it can serve mostly your purposes?\nIt was quite easy to extend Huey in exactly the way you wished. This just makes it even easier -- two attributes instead of two methods for the simple case.\nI do keep Huey extensible as much as I think is useful. I rely on people who use the library to help find the places where this becomes difficult. Look at the storage backend abstractions -- they are extremely amenable to extension or customization.. By default Huey will not store results for tasks that return None. This can be controlled by the store_none parameter (defaults to False). So if you wish to avoid storing results for a given task, you can simply return None (or omit a return) and by default nothing will be stored.. What I'm saying is that Huey already has the capability: just do not return anything and your task will not put anything in the result store.. You need to specify at what minute and hour it should run. The way you have it configured, it will run every minute of every hour every 5 days.. It's still the case that the return values of periodic tasks are not stored:\npython\n        if self.result_store and not isinstance(task, PeriodicQueueTask):\n            if result is not None or self.store_none:\n                self.put(task.task_id, result)\nThey do have their own unique ID, but they are not stored.. The reason for this is described in the commit I just pushed, 1c39de8\n\nThe result (return value) of a periodic task is not stored in the\nresult store. This is primarily due to the fact that there is not\nan obvious way one would read such results, since the invocation of\nthe periodic task happens inside the consumer scheduler. As such,\nthere is no task result handle which the user could use to read the\nresult. To store the results of periodic tasks, you will need to\nuse your own storage.\n\nYou can of course manually put results in the result store:\npython\n@huey.periodic_task(...)\ndef my_periodic_task():\n    # do some stuff\n    huey.put('my-periodic-task', some_result_obj). Releasing one now.. > I'm polling a remote API that emits events and I want to ingest them frequently\nFound the problem.. Yes and no. Yes in the sense that Huey is just Python and as such is very hackable.\nNo in the sense that the consumer only logs the task ID and the task name, typically, so getting extra metadata in your huey logs will take a bit more work.\nI'm going to assume that you're spawning these tasks from somewhere within the request/response cycle. Since you're using django to set a request ID already, and since huey's TaskResultWrapper exposes the task's ID, you could correlate the request ID with the task ID, e.g.\n```python\ndef some_view(request):\n    task_result = some_task()\n    logger.info('request %(request_id)s invoked task %(task_id)s', task_id=task_result.task.task_id)\n``. I'm not sure how the context you're talking about works. Huey supports 3 approaches to concurrency -- threads (default), processes or greenlets. How well it works may depend on which worker model you're using.. Huey provides anon_startup` hook that runs whenever a worker thread starts (typically this is just at the very start of the consumer running).\nDocs: https://huey.readthedocs.io/en/latest/api.html#Huey.on_startup. MySQL kills idle connections after a certain amount of time.\nI'd suggest consulting the Django docs for the solution, as Django is managing your database connections.. Huey is detecting the tasks. I have no idea why your other tasks are not being executed. If I ignore all the useless information, your issue boils down to: I have some tasks and they are registered by the consumer, but are not being run.\nHere are some steps you can follow to debug the issue. How are the \"alerts\" tasks called? Where are they called from? Are you sure they're being called? The consumer can be configured with quite verbose logging -- have you tried that? Have you inspected the Redis instance you're using to store the tasks in-flight? etc., etc.\nExecuting tasks is the fundamental behavior of Huey. It is tested. Etc.. result doesn't seem to be being used here.\n. Maybe the create_threads method in consumer should be refactored into separate methods for each thread, so you only need to override the part that creates the worker threads?\n. I thought you didn't want :memory:?\n. Multi-line string instead.\n. buffer is python 2, I believe.\n. Wait...is huey even py3k?\n. Ah yeah, looks like there's no select for update in sqlite.\n. What happens to your begin immediate; -- do you need to commit or anything?\n. This should be a non-blocking queue and just let Huey take care of the polling.\n. Does this connection ever get cleaned up?\n. I'm a little unsure if the \"event emitter\" makes sense for sqlite.\n. Oh, I just meant that I'm not sure the event emitter idea makes as much sense with Sqlite as the data transport.\n. Should this be re-entrant?\n. Why is this removed?\n. why is this removed?\n. Any reason this is called twice? Seems to be doing the same thing as the previous block.\n. Just some more notes... pep8 should be 79 chars long.\n. ditto here line length.\n. ditto here line length.\n. Why is it necessary to check the return value here of zremrangebyscore?\n. Cool, makes sense.\n. This should be retained for compatibility.\n. Why is this '-i' and not '-v'?\n. Is the redis_url mutually exclusive with other parameters here? What is the behavior if a user erroneously supplies arguments for both url and connection_pool?\n. Also, why is url not just a regular keyword argument?\nname='huey', blocking=False, read_timeout=1, max_errors=1000, connection_pool=None, url=None, **connection_params)?\n. > To fix this: Would you like a ValueError being raised if more than one of these parameters are specified at the same time? I'm happy to supplement this PR :)\nThat'd be awesome, do you mind? I can handle it as well ifyou prefer.\nMaking url a regular keyword argument also seems like a good idea to me.\n. Can you change this to:\npython\nif len(filter(None, (url, connection_pool, connection_params))) > 1:\n. Can you change the error message to:\n\nThe connection configuration is over-determined. Please specify only one of the the following: \"url\", \"connection_pool\", or \"connection_params\"\n. This can be an elif, right?\n. For future reference please note that peewee uses a 79 character line limit. I will go ahead and fix it once it's merged.\n. You're relying on the quirk that Python considers True to be 1 -- that is why this trick works. I think it is quite obscure, though...summing booleans.\n\nSince filter() isn't as nice because fucking stupid ass Python3, how about changing this to a list comprehension?\npython\nif len(item for item in (url, connection_pool, connection_params)) > 1:\nWould you consider changing that?\n. You can reduce these into a single test using itertools.combinations:\npython\nfor pair in itertools.combinations((url, connection_pool, host), 2):\n   self.assertRaises(ValueError, RedisStorage, ...)\nThat's not exactly what you need, but hopefully that makes sense?\n. len is semantically what you are interested in. The use of sum is predicated on the strange fact that Python treats True as 1.\n. I would've thought this (and the lines above it) would have been sufficient to clear out the defaults?. Probably ought to be checking sys.platform?. Makes sense, thanks!. Why close the connections here? The purpose of this decorator is to close the connections after executing the callback.. It seems like a code-smell to me, so let's remove it from the huey implementation. If you don't mind making that change, I'd be happy to merge...maybe you could, while you're at it, rebase into a single clean patch?\nAlso, what is the minimum Django version that supports this API?. I'm guessing this is a 3.x-only API? It's not documented in the 2.x documentation and so is probably a non-starter. It might be fine just to write a new signal handler for SIGINT instead of overloading the existing TERM handler to do both.. ",
    "coderbuzz": "Very impressive, thank you for providing this Charles\n. ",
    "jsullivanlive": "It's great to have an almost pure python option for distributed task queues, so thanks back at you!\n. ",
    "dmr": "The new test you wrote now passes on my computer. Do you know why the \"now\" has to be included?\n. I renamed the vars, yes. I'll undo it if you don't like it.\nI passed a time to the fist check and changed\nself.assertFalse(schedule.should_run(cmd1))\nto\nself.assertFalse(schedule.should_run(cmd1, now))\n. On my computer (OSX 10.7.5) and on Travis-CI they didn't pass.\nBut I agree, your version of the test should work fine.\n. Thank you, works like a charm!\nNext time I'll read more of your documentation before posting a feature request ^^\n. That's what I thought, too.\nBut if I do bytes(data,'utf8'), the result is something like\nb\"b'\\x80\\x03N.\"\nThe only way I remembered was eval. This is not something I suggest, I'm still looking for a good alternative.\nIs there a reason why you store the message using the \"message_template\" instead of just pickle?\ndef get_message_for_command(self, command):\n    return pickle.dumps((\n        command.task_id,\n        self.command_to_string(type(command)),\n        command.execute_time,\n        command.retries,\n        command.retry_delay,\n        command.get_data()\n    ))\ndef get_command_for_message(self, msg):\n    task_id, klass_str, ex_time, retries, delay, command_data = pickle.loads(msg)\n. It solves the issue, great!\n. Thanks :)\n. @JuriKern do you have plans to make this graceful, i.e.\ntry:\n    from django.db import close_old_connections\nexcept ImportError:\n    # Django < 1.8\n    from django.db import close_connection as close_old_connections\n. Thanks.\nThis probably solves #85\n. I'll post an update here once I can reproduce it but the huey worker is working really well sending thousands of mails and doing search index updates and other things every day and after many months it crashes once, so it's really not that big of a deal, huey is running really well, thanks for building it :)\nSo after this crash I'll add some more debugging info to hopefully catch the issue next time.\nThanks for the EventEmitter hint, I'll look into that.\n. Looks like travis is still failing, did it work 6 month ago @72squared ?\n. Ok, I'll look into the events next time, thank you :)\nI was just curious if anybody is listening here and maybe already did some of the work.\n. Python 2.6 can be dropped IMO\n. ",
    "rthill": "that's it, you saved my day :+1: \nand to run a task every day I'm using:\n@periodic_command(crontab(minute='0', hour='0', day='*/1')\ndef foo:\n    pass\nWhat is the base of the scheduling, the startup time of huey or the local time?\n. ",
    "szaydel": "I think I solved my problem, but I am not entirely sure why. When I add blocking=True to res.get(), i.e.: res.get(blocking=True), things work as expected. I do not however understand why this is. Is the function returning before results are actually ready, resulting in None instead of actual data?\n. @coleifer : Thanks, this makes perfect sense.\n. Actually, yes I don't know why I did not think to do it this way. I have not yet verified, but see no reason why this won't be suitable. Thanks.\n. Have it installed, and still had same issues. But, after you mentioned it, I realized that I never did install bindings in virtualenv. Will validate as soon as I have a moment. I suspect that is all there is to it. Lack of sleep could be main culprit. Thank you.\n. Yep, it was a bit of a trap. Just installed bindings, but same issue persists. Will do more troubleshooting, but may have to ask for more help! Thanks in advance!!!\n. This seems to suggest that huey = RedisHuey('testing',{'host':'localhost','port':8778}) is my issue, but it seems perfectly correct.\n(tasks)bash-3.2$ python -c 'from main import huey'\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"main.py\", line 1, in <module>\n    from config import huey\n  File \"config.py\", line 3, in <module>\n    huey = RedisHuey('testing',{'host':'localhost','port':8778})\nTypeError: __init__() takes at most 2 arguments (3 given)\n. I did that seconds before you posted this and in fact it is working correctly. So, it seems like the problem was passing in a dict instead of using kwargs.\n$ PYTHONPATH=.:$PYTHONPATH huey_consumer.py main.huey\nNo handlers could be found for logger \"huey.consumer\"\nThank you for helping me troubleshoot this!\n. Is it possible to do more frequently than 1min. with any of the currently available methods, or is the 60 second resolution highest possible at the moment? Thanks a lot @coleifer, appreciate a rapid response.\n. Thanks in advance. I am trying to figure out if it is appropriate to use Huey as a runner for arbitrary metric collection tasks. The tasks may all be very different in nature, but many may require sub-60sec. resolution. I am not yet sure what the best approach is. I really like Huey and thought it would be a good answer here. I am not sure if this gives you any more to go on, or if maybe I am still too nebulous. Thanks!\n. Hacky indeed. Thanks for the feedback.\n. ",
    "apendleton": "Okay, will try to do a first pass in the next few days.\n. So it turns out huey had a lot more inter-thread shared-memory state in it than I thought, which made this quite a bit more involved than expected it to be.  Still, I think I've got things to a working state now, after a fair bit of refactoring, and the tests pass, though there's some lingering hackery to make that happen.\nThe tests also needed a fair bit of tweaking -- they made lots of assumptions about the innards of the consumer that are no longer true, so a lot of that functionality moved into the consumer base class as formal API, which the tests now consume.\nI don't expect that this is in a mergeable state, just yet, but when you get a chance, let me know if the general approach is sane, and what else you'd want to see done.\n. No worries!  I agree that this is maybe not a good future direction... enough contortionism was necessary to maintain the current API that some really hacky stuff was necessary.  The fact that everything in multiprocessing-land ends up getting pickled before IPC and rebuilt on the other side is hugely complicating (storing retries on Command objects, for example, ends up not being practical because workers have their own unpickled copies of a given command, rather than sharing the same one).\nIf you're willing to make breaking changes, that opens up some possibilities for implementing some of this stuff much more cleanly, so if you do end up rewriting some stuff, I'd be excited to see where it goes, and possibly interested in contributing.\n. I think this would work, but wouldn't be optimal.  You end up duplicating a bunch of infrastructure around scheduling, retrying, etc., in each consumer process.  You also end having to do a bit more to get your process supervisor (e.g., supervisord) set up to watch a potentially-large number of separate consumers.  Finally, I don't think the consumer is really designed for this kind of setup, at least at present.  It greedily pulls things off of the shared Redis queue and pushes them into a local work queue within the consumer process, which, I suspect, would lead to suboptimal distribution of tasks amongst separate huey_consumer processes through which you could easily have one worker occupied with a task but hoarding other tasks in its internal work queue while other workers sat idle -- task distribution would be, at best, round-robin, rather than distributing tasks to the first available worker, as is the case with threads.  It may well be, though, that resolving these challenges is easier than writing an MP consumer... I'm not really sure.\n. > It actually only pulls one extra task\n\nAh, okay.  It looks like the code that shuffles jobs from the Redis queue to the internal one now acquires a lock before doing so, which I don't think it did the last time I poked around in the code.  Nevertheless, this probably isn't ideal.\n\nWhat's the rationale for the Python-side queue in the first place?  I could imagine a share-nothing architecture where the main Redis (or whatever) queue only dealt with immediately-executed tasks, and each worker thread/process pulled from that Redis queue directly, rather than having a dispatcher.  You could then have one thread/process that would deal with all the scheduling (I guess using a separate Redis queue), and push things onto the main work queue when it was time to execute them.  Seems like that would simplify things a great deal, and would make the thread/process distinction much less important.\n. ",
    "jakubzitny": "I've also replied on SO.\n. ",
    "n3storm": "Import method used at huey_consumer.py is not working properly.\nWhen moving huey_consumer.py to the same folder of other files: main.py ... import works right.\nIt doesn't look like there is an easy way for doing dinamically loading a module.\nI tried importlib and imp, without success. When main was importing then count_beans could not be imported.\nAre you sure huey_consumer.py is meant to be used at /usr/local/bin/huey_consumer.py?\nI am correcting myself at SO.\n. Sorry for the delay.\n@coleifer you are completely right. I think it should be pointed in the documentation. For testing purpose not everybody gets into creating virualenv's, though is a good practice, but new users (and new python developers) may be falling on this again.\n. ",
    "collinwat": "Yeah, I wasn't very clear on that point... sorry about that.\nThat's correct. I am trying to make sure that all my tasks are completed across any number of consumer restarts.\nAn optional approach is to put the work back on the queue with self.invoker.enqueue but I'm not sure if that makes sense in all cases.\nThanks for taking the time :)\n. This patch only addresses \"block until complete\". The following procedure will only occur if the config.THREAD_WORKER setting is False.\nInstead of completing work in a worker thread, the work is completed in the worker_pool thread. Since process_command acquires the pool and the worker releases it, we can safely acquire the pool in our shutdown process to ensure that the worker_pool thread has completed the work.\nHowever, this will only occur when config.THREADS > 1. Otherwise, _pool will not block since you can acquire more than once.\nSince this patch is specific and naive, I'm thinking that a new issue should be opened with the intention of synchronizing all worker threads on shutdown, using this issue as a starting point. I can also add a pull request for the example.\nHow does that sound?\n. Sounds good. Thanks for following up, much appreciated :)\n. ",
    "filipp": "Thanks for your comment. Yes, the 20 instances all use their own database, no data should be shared among them, only code. Preferably, the solution would scale up to hundreds of instances.\nMore and more this begins to smell like a bigger design issue with my app then anything else. I guess I have to think about it... :)\n. ",
    "boblefrag": "actualy you can share in-memory database between thread using check_same_thread=False but threads are not processes and your right in the fact it does not work with the implementation I have made.\nI definitly think sqlite3 can be a nice solution for huey as it can be a no-dependencies solution (for testing purpose or really small projects).\nI will be back with a better implementation as soon as possible.\n. ",
    "asmedrano": "HRM... Have the django settings names changed? The docs have 2 examples\nhttp://huey.readthedocs.org/en/latest/django.html#django\nand http://huey.readthedocs.org/en/latest/upgrading.html#simplified-django-settings\nIt looks like the first are for whats on github right now and later is for what you get from pypi. \n. Thanks!\n. Hi again, \nI'm still having some issues but I suspect its partially my understanding of what to expect.\nI have some tasks defined. These are long running processes that would take too long to complete in a HttpRequest. So I'd like to hand the task off to Huey. \nWhat ends up happening is that the response doesn't complete till after the task does its thing.\nDo I understand this correctly?\nWhat output should I expect in the console when the Django consumer receives a task?\n. So... I went down a rabbit hole and found some funkyness. This is by no means a fix but you may know whats going on. \nIn tasks.py \n```\nfrom time import sleep\nfrom huey.djhuey.management.commands.run_huey import HUEY # I did this instead of from huey.djhuey import task cause for some reason those calling those tasks never actually got to the consumer that was started with ./manage.py run_huey\n@HUEY.task()\ndef count_beans(number):\n    if number > 1000:\n        number = 1000\n    out = 0\n    for i in range(number):\n        sleep(0.20)\n        out = i\n    return 'Counted %s beans' % out\n```\nI modified the run_huey command.\n```\nimport imp\nimport sys\nfrom optparse import make_option\nfrom django.conf import settings\nfrom django.core.management.base import BaseCommand\nfrom django.utils.importlib import import_module\nfrom huey.bin.huey_consumer import Consumer\nfrom huey import Huey\nfrom huey.backends.redis_backend import RedisBlockingQueue\nfrom huey.backends.redis_backend import RedisDataStore\nimagine queue name still comes from settings.HUEY\nqueue = RedisBlockingQueue('unique name', host='localhost', port=6379)\nresult_store = RedisDataStore('results', host='localhost', port=6379)  \ninstantiated a Huey object here.\nHUEY = Huey(queue, result_store=result_store)\nclass Command(BaseCommand):\n    \"\"\"\n    Queue consumer.  Example usage::\nTo start the consumer (note you must export the settings module):\n\ndjango-admin.py run_huey\n\"\"\"\nhelp = \"Run the queue consumer\"\n\noption_list = ... # same stuff\n\ndef autodiscover(self):\n...\n\ndef handle(self, *args, **options):\n    #from huey.djhuey import HUEY # removed this\n    ...\n    consumer = Consumer(HUEY, **consumer_options) # passed the HUEY object we created here into the Consumer.\n    consumer.run()\n\n```\nAnd after all that nasty hackery, the consumer got tasks as expected.\nAm I nuts?\n. Ignore everything I've said, see pull request.\n. Yeah totally makes sense. I tried to separate all that stuff so I wouldn't taint the good code :D\nSo maybe we should stop calling it PubSub cause its really more like Pub. I'm with you on the hooks idea. Right now I am really only interested in when the task is \"Started\", \"Completed\", \"Error\", \"Retrying\". \nYou reckon those are adequate hooks to start with?\nAlso, what do you think about letting the tasks have names or labels or something?\n. Closing this cause I've submitted a different pull request.\n. Thanks. I've updated the pull request and what the Django settings end up looking like. BTW I'm mostly working on this to make it work for our use case so don't feel obligated to keep it. :D\n. This should probably just be Events (if that) not pub or sub ... \n. Awesome! Thanks for adding that!\n. Cool. I dont mean to keep raising \"issues\". Its just the only way to send questions.\nMaybe a mention of task name could be added to the docs?\n. I just remembered the original question that led to this. Is there way to modify the task name when it gets ran? I'd like to add some meta data to the message the event emmiter produces.\n. I agree. \nHere's my use case though:\nLets say I have Users and these users can queue up a task. \nA User defined task might look like this:\n@task(name='User Defined Task')\ndef some_fn(user, a, b):\n    task_user = user\n    return a + b\nHow would I can i give a User feedback (via the event emitter) about their own task? The emitter only returns status, id, etc... It would be nice to be able to pass some context to the emmiter no? Is that foolish?\n. Makes sense. I arrived at that conclusion about 2 mins ago :) I guess it\nhelps to think out loud. Thanks!\nOn Thu, Jan 30, 2014 at 10:48 AM, Charles Leifer\nnotifications@github.comwrote:\n\nI would recommend using a data-store for that, i.e., when the task starts,\nput a record in the db.\n\nReply to this email directly or view it on GitHubhttps://github.com/coleifer/huey/issues/47#issuecomment-33700133\n.\n\n\nAngel Medrano\nangelmedrano.com\n@asmedrano\n214-392-2597\n. Last question: Is there a way to access the task id from within the wrapped (@task) function\n. Cool! That would be awesome. I'm doing some silly workarounds to get that\nOn Thu, Jan 30, 2014 at 2:45 PM, Charles Leifer notifications@github.comwrote:\n\nNo, but that's not a bad idea.\n\nReply to this email directly or view it on GitHubhttps://github.com/coleifer/huey/issues/47#issuecomment-33725314\n.\n\n\nAngel Medrano\nangelmedrano.com\n@asmedrano\n214-392-2597\n. ",
    "swilcox": "No problem! Thanks for huey! Love it!\n. ",
    "vitormhenrique": "Hello, is this still the case?\nI'm building a monitoring system, where the background task would be collecting the data and would like to have a better control than 1 minute interval.. Hello @coleifer thanks for the response, I'm monitoring a bunch of data from several machines using a simple API, the goal is to build a real time application with all that data at the end. It takes around 2 seconds to query 1000K machines and populate a PostgreSQL database. I would like to be able to run it every 30 seconds. \nI saw that there was one pull request apparently with the feature?https://github.com/coleifer/huey/pull/100/commits/7f1d83a78a755b95d52e344a62874c1753e6831e\nAlso, is there a way for multiple threads consume the same queue? I'm not really sure if setting multiple threads in the consumer is enough for this to happen.. Hi @coleifer, no worries, \nThe monitoring it's not really \"latency-sensitive\" I want to have control of when the monitoring starts \"trying\" to get information, but I don't really care when the data will be available. So my idea was to have one scheduled task to to start other individual tasks to get the data.\nSomething like the this:\n\n@task()\ndef get_server_data(server):\n    do_semething_here\n\n@periodic_task(crontab(seconds ='*/30'))\ndef every_ thirty_ seconds():\n    for each server in server_list:\n        get_server_data(server)\n\nAnother thing is that this is just one part of the application, another part is that the django application will act like as rest api to another solution and will get a list of servers for example to turn off, them I'll put that list into a queue, where I can have better control if the task fail, etc...\nHopefully this explains a little bit better my intent.. what I meant is that I don't need the data \"asap\", and if it fails to get the data, that is ok.... @coleifer no, I don't want to spam any server, I'm sorry you got that impression.\nI'm building a monitoring system for miners. And I had the incorrect value of computers, it's 1k to 10k, not 1000k lol... Sorry...\nFor each miner I want to get the heath of the machine to build a dashboard, I \"care\" about the data, but I just don't need it to be \"right away\".\nFor each machine I query the temperature, fan speed, voltages etc... . ",
    "psyonara": "Cool, that's fair enough. :-)\n. Client and server are on the same machine, and use the same virtual env, so python version shouldn't be a problem.\nI noticed that this error happens only on some messages (specific ones, i.e. re-trying the same one would repeat the error), and not on others. In the stack trace it does bomb out where it tries to pickle the task's message, so do you think it could be the contents of the data I'm passing into the task?\n. The task is a function that takes a django model instance as a parameter. So it will have to do with the data of that instance, probably. Will have to make some time to investigate properly.\n. Man, that is genius. So simple... can't believe I didn't think of that.\nThank you so much, this will most certainly \"solve\" the problem.\n. I'm actually going to use your solution to #67 to solve this one as well. It's a much cleaner solution anyway, since transport between backends is even less that way.\nThanks again, it is much appreciated.\n. The Django settings file contains this:\npy\nfrom huey import RedisHuey\nHUEY = RedisHuey('blah')\nThen we run Huey with:\nsh\npython manage.py run_huey\nEverything else is set to defaults (e.g. Redis).\nAnd as stated before, this produces the errors on the \"older\" setup, but runs fine on the \"newer\" setup.\n. Never mind, it has been resolved. For some reason (which is beyond me), it had somehow cached the old settings. But a restart of everything solved that.\nSorry for the trouble!\n. I've done that myself. It was very easy to do, you just write a custom back-end.\nHowever, unfortunately I don't have the code anymore, since we switched our installation over to Redis.\nBut you should be able to easily write the code for it in a day or less.. You could copy the code from the sqlite back-end, and then change it to interface with MongoDB instead. I think I used pymongo, if I remember correctly. You'll have to map the individual commands to the equivalent ones in MongoDB.. ",
    "Edke": "Have 7 different running, trying to determine, which causing problems. Will add more info soon.\n. ",
    "alijnclarke": "That was almost embarrassingly easy, thanks!\n. ",
    "qgriffith": "I think I figured it out by doing\n``` python\nfrom huey.djhuey import HUEY\nHUEY._get(task_id)\n```\nThat seems to get me the information about a task by id\n. ",
    "eldamir": "Sorry for resurrecting this issue. I cannot find anything in the docs about this usecase. It seems that the API required me to keep a reference to the task and ask it for results until there is a result.\nI want my website to request an action. An id string is returned. The website can then request information about the action by providing the id.\nSo how do I get the ID of a task? And how do I get task results, when all I have is the ID?\nI suppose I can get the ID by\nres = count_beans(100)\nreturn res.task_id\nBut how do I get the task from the id?\n. ",
    "tijs": "@coleifer i started using the @db_task decorator from master for all tasks with DB connections after i was running into similar issues with idle postgres processes and although this seems to have fixed it i now get \"server closed the connection unexpectedly\" errors now and then for some of the tasks. I don't see any particular attribute of these tasks in common so i assume it is some sort of timing issue.. could it be the task is returning (and thus closing the connection) before the database connection has finished somehow?\n. awesome! i'll try that out let you know how it works out...\n. aha! makes sense, i guess i'm used to celery still. is there a benefit to using threads instead of processes? Memory use i would assume? Does seem a bit harder to monitor this way, does huey have a recommended method of monitoring the workers?\n. @coleifer ok great. thanks for the explanation! and yeah the event emitters would seem to do what i need if i ever find the time to hook those up to some logger thingy :smile: \n. @coleifer for now i've simply downgraded to the 0.4.1 release and do the close_connection() calls manually for each task. Not sure how i could track down the exact source of the issue in this case...\n. I log the ouput of huey to a log file but it's empty i'm afraid... i do not have the verbose option on i guess. This is my supervisor conf in case your wondering (maybe not :)\n```\n[program:huey]\ncommand = /home/myapp/venv/bin/python manage.py run_huey --no-periodic --workers 4\ndirectory = /home/myapp/app\nuser = deploy\nnumprocs=1\nautostart = true\nautorestart = true\nstdout_logfile = /var/log/supervisor/huey.log\nstderr_logfile = /var/log/supervisor/huey.err.log\nenvironment = DJANGO_SETTINGS_MODULE=\"myapp.settings.production\"\nstartsecs=10\n; Need to wait for currently executing tasks to finish at shutdown.\n; Increase this if you have very long running tasks.\nstopwaitsecs = 600                                                                                                                    \n```\n. ok thanks, i'll probably try the latest master in staging again next week. will keep you posted.\n. @coleifer ok sorry it took a while but there is indeed quite a difference between the tasks detected in 0.4.1 and master. This is my log in 0.4.1:\nMainThread 2014-03-08 13:27:23,446 huey.consumer INFO Setting signal handler\nMainThread 2014-03-08 13:27:23,446 huey.consumer INFO Huey consumer initialized with following commands\n+ drip_new_members\n+ create_initial_notifications\n+ send_feedback\n+ send_email_activation_token\n+ add_credit_after_signup\n+ send_password_reset_token\n+ create_and_send_invoice\n+ password_reset_sent\n+ send_invite_email_to_friend\n+ create_notification\nAnd this is the same app after upgrading to master and changing all task() decorators to db_task():\nMainThread 2014-03-13 14:24:09,096 huey.consumer INFO Setting signal handler\nMainThread 2014-03-13 14:24:09,096 huey.consumer INFO Huey consumer initialized with following commands\n+ inner\n. @coleifer yeah i can try that out now one sec.\np.s. i noticed the task logging is going to stderr instead of stdout? is that by design?\n. ok i just replaced my version with the latest from master and it seems to find the tasks now; the full list of tasks is logged and they run again (no queuecmd_inner not found in TaskRegistry error). Time for a 0.4.2 release? :)\n. if i get it again i'll try and collect some more data!\n. Does it happen only on regular tasks, or periodic/cron tasks?\nregular tasks only so far\nDoes it happen only when running one particular task?\nseems to affect one task more than others. this is one of the few that itself also starts a new task?\nDoes it happen at a specific time?\nnope\nDoes the task that is being executed run for a long time (more than a few minutes)?\nno, maybe 200-300ms.\n. The tasks it seems to happen to more than others:\n```\n@db_task()\ndef create_initial_notifications(recipient_id):\ntry:\n    recipient = User.objects.get(pk=recipient_id)\n    default_company = get_default_active_company(recipient)\n\n\n    ## create initial notifications for new user\n    create_notification('Maak je bedrijfsprofiel compleet', 'Complete your company profile',\n                              '[Met een compleet bedrijfsprofiel](%s) weet je zeker dat op de facturen die je '\n                              'verstuurd aan je klanten alle benodigde informatie staat.' %\n                              reverse(\"accounts_edit_company\", kwargs={'company_id': default_company.id }),\n                              '[Completing your company profile](%s) will make sure all the required info is on the '\n                              'invoices you send your clients.' % reverse(\"accounts_edit_company\",\n                                                                          kwargs={'company_id': default_company.id }),\n                                                                          recipient_id, True)\n\n    create_notification('Voeg een of meer klanten en projecten toe', 'Add one or more customers and projects',\n                              'In Gekko zijn alle facturen (en eventueel) kosten [gekoppeld aan een project](%s) '\n                              'zodat je makkelijke kan zien wat je omzet per project is.' %\n                              reverse(\"addressbook_display\"),\n                              'In Gekko invoices are always [for a specific project](%s). This way you can always '\n                              'track your revenue per project, and customer, later.' % reverse(\"addressbook_display\"),\n                              recipient_id, True)\n\n    create_notification('Verstuur je eerste factuur!', 'Send your first invoice!',\n                              'Tijd om [geld te gaan verdienen...](%s)' % reverse(\"invoices_add_invoice_step1\"),\n                              'Time to start [making come money...](%s)' % reverse(\"invoices_add_invoice_step1\"),\n                              recipient_id, True)\n\n\n    # and the notification explaining how things work\n    notification_help_en = '''[snipped for readability]'''\n\n    notification_help_nl = '''[snipped for readability]'''\n\n    create_notification('Berichten en de nirvana balk', 'Notifications and the nirvana bar',\n                              notification_help_nl, notification_help_en, recipient_id)\n\nexcept (User.DoesNotExist, DatabaseError) as e:\n    logger.error(e, exc_info=True)\n    return False\n\n```\nthe create_notification() calls are calls to another db_task()\n. thanks! using that for a few tasks now. need to read before i ask though. sorry.\ni have not seen this issue since i reported it here so i would consider it a moot point.\n. ",
    "MaximBoyarskiy": "I've got some simple solution - having single lock record in the DataStore and trying to change it by atomic operation. Thank you for your package!\n. ",
    "jbaiter": "Sure, go ahead! I fixed some of the things you commented on :-)\n. No worries, take your time :-)\n. Not very thoroughly, but most (~80%) of the time was spent on getting results from the datastore.\nMy guess is that SQLite flushes the data to disk after every write, globally locking the database during that time[1]. Combined with the fact that due to SqliteEventEmitterevery action incurs at least two distinct writes, the database will spend a lot of time in a locked state, during which nothing can be written to or read from it.\nI'm pretty certain that this can be optimized, but I was curious about LevelDB anyway and it was surprisingly easy to hack together the backend, so I didn't look further into it.\nFor low-volume scenarios SQLite should be fine, still.\n[1] http://www.sqlite.org/faq.html#q5\n. After some experimenting I managed to get the SQLite (disk) time down to 1150ms by using write-ahead logging, in-memory temporary tables/indices and handing over syncing responsibilities to the OS.\nI'll submit a pull request later tonight .)\n. If you think it provides a benefit, sure. I'm not so sure really, I wrote the backend because performance with the SQLite backend sucked horribly at the time. But with the performance tweaks you merged a few weeks ago, it's really \"good enough\" for a non-distributed use case IMO. I think keeping this closed PR and my branch around should be enough for users who feel like SQLite is too slow and Redis too fat of a dependency. :smile:\n. No problem at all, thanks for all the previous work, I've been looking for something like huey for a long time :-)\n. Yes. Huey does not care which framework you're running.\n. Whoops, you are right, seems I forgot to change that file after making the decision. Will be fixed!\n. According to #13 it should be, however the tests currently run into an infinite loop in consumer.ConsumerTestCase.test_message_processing on my machine (with Python 3.2).\n. Not deliberately, no. However, once the caller is done, it should be garbage collected, given that no references are kept for it.\n. Yup, that crossed my mind as well, but I wanted to keep it in tune with the base API and the other backends. Would \"SqliteEvents\" be better suited?\n. I'd say that's up to you, I'm not really using the functionality myself, I just implemented it for the sake of API completeness .)\n. ",
    "vindarel": "Hi ! I get this error after following the django tutorial. Looks like to me a small bit is missing about organizing the imports.\nThe doc gives a clear example with a config, a tasks.py and a main.py. However the Django doc doesn't say on how to organize the imports. \nI tried to put my decorated task into a new tasks.py and to import it into my models. I also feel I had to create a huey = RedisHuey(\"testing\") in my settings.py and import it at the same time as the task, into my models. I'm still getting the error.\nCan you give some tips ? Thanks !\n. I had not seen this example, but it's similar to the doc. I\u00a0can make it work in a new django project, but not in mine :(\nI have huey.contrib.djhuey in my settings.py:\n```\nDEBUG = False\nINSTALLED_APPS = (\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.sites',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n    'django_extensions',\n    'bootstrap3',\n    'bootstrap_admin',\n    'django.contrib.admin',\n    # Custom:\n    'mod_wsgi.server',\n    'huey.contrib.djhuey',\n'myapp',\n\n)\nHUEY = {\n    'name': DATABASES['default']['NAME'],  # Use db name for huey.\n    'result_store': True,  # Store return values of tasks.\n    'events': True,  # Consumer emits events allowing real-time monitoring.\n    'store_none': False,  # If a task returns None, do not save to results.\n    'always_eager': DEBUG,  # If DEBUG=True, run synchronously.\n    'store_errors': True,  # Store error info if task throws exception.\n    'blocking': False,  # Poll the queue rather than do blocking pop.\n    'connection': {\n        'host': 'localhost',\n        'port': 6379,\n        'db': 0,\n        'connection_pool': None,  # Definitely you should use pooling!\n        # ... tons of other options, see redis-py for details.\n    # huey-specific connection parameters.\n    'read_timeout': 5,  # If not polling (blocking pop), use timeout.\n    'max_errors': 1000,  # Only store the 1000 most recent errors.\n    # 'url': None,  # Allow Redis config via a DSN.\n},\n\n}\n```\nin tasks.py\n```\nfrom huey.contrib.djhuey import crontab, periodic_task, db_task\nfrom models import Inventory\n@db_task()\ndef longtask(pk):\n    print \"long task\"\n    import ipdb; ipdb.set_trace()\n```\nand in my api.py I just from tasks import longtask, but anyway with shell or run_server (I run run_huey first) it throws\nERROR [huey.consumer.Worker] Queue exception\nTraceback (most recent call last):\n  File \"/home/vince/.virtualenvs/abelujo/local/lib/python2.7/site-packages/huey/consumer.py\", line 94, in loop\n    task = self.huey.dequeue()\n  File \"/home/vince/.virtualenvs/abelujo/local/lib/python2.7/site-packages/huey/api.py\", line 225, in dequeue\n    return registry.get_task_for_message(message)\n  File \"/home/vince/.virtualenvs/abelujo/local/lib/python2.7/site-packages/huey/registry.py\", line 70, in get_task_for_message\n    klass = self.get_task_class(klass_str)\n  File \"/home/vince/.virtualenvs/abelujo/local/lib/python2.7/site-packages/huey/registry.py\", line 60, in get_task_class\n    raise QueueException('%s not found in TaskRegistry' % klass_str)\nQueueException: queuecmd_longtask not found in TaskRegistry\nI really think this is the same configuration and layout as the simple working project\u2026\nAny hints ? Thanks again.\n(I could point to my project if needed)\n. Found it. I'm so thankfull to a comment on another project: \n\nMust be named tasks.py and be in the top level of an INSTALLED_APPS directory\nfor Huey to find it.\n\nMine wasn't at the top level but alongside a models directory.\nWould you add a note about this in the doc ?\n. ",
    "AlJohri": "Would you be opposed to this if one were to submit a PR?\n. ",
    "72squared": "thanks, I figured it must be possible I just couldn't quite see how to do it in the docs.This should work!\n. Yeah sounds good to me.\n. The only way I can think of to solve it is to use a LUA script to read the values and then remove them if any are found and return them.\n. in the past I've used a lua script something like this to solve it:\n```\npop_lua = \"\"\"\nlocal res = redis.call('zrangebyscore', KEYS[1], '-inf', ARGV[1], 'LIMIT', 0, 1)\nfor i = 1, #res do\n    if redis.call('zrem', KEYS[1], res[i]) == 1 then\n        return res[i]\n    end\nend\n\"\"\"\ntask = self.conn.eval(pop_lua, 1, self.key, unix_ts)\n```\n. A lock won't work well if you have many consumer processes on different servers using the same redis queue. Besides I prefer non blocking solutions when possible. As for whether it has come up, I think this problem would be very hard to spot. \n. The nice thing about the Lua script idea is that it is only one network round trip and the operation is pretty much atomic. \n. Yeah, will do.\n. patch submitted! #107 \n. patch #107 was accepted. Issue resolved.\n. I made the suggested changes, squashing everything into one commit. Anything else?\n. +1\n. Actually, in my current design, no. I am running the consumer on the same server as redis. But I still feel it should be as efficient as possible. \n. Another easier way to improve efficiency is to look for ways to avoid making calls altogether. I sit and watch the redis monitor on a test setup and then queue a job and watch the consumer work. In my case, I have the result store disabled, but the consumer still does:\n\"HEXISTS\" \"huey.results.mpfq\" \"r:b7e7473a-da89-4e31-af46-0e9ac8772c66\"\nI don't know the code super well, but think this is because the TaskWrapper still is checking the result store even though it is disabled, here:\nhttps://github.com/coleifer/huey/blob/master/huey/api.py#L414-L428\nThoughts?\n. But if I don't have result_store enabled, there's no way for me to revoke it, right? So it's an unnecessary check.\n. that gives you the count of the elements it removed from the sorted set. If the count doesn't match up with the number you intended, that means it wasn't able to remove those elements from the sorted set and you don't want to return those elements from the list to be worked on. It will almost never happen since redis will be working inside that single thread to do that operation atomically but still it's not a bad practice to checksum it and it won't introduce any latency.\n. FYI, I've been using this patch on my dev server for the past week and everything is working flawlessly.\n. ",
    "miohtama": "Thanks a lot!\n. Thanks! I'll keep investigating why it doesn't restart properly. \nJust a question: What (should) happen if there is some periodical task running / hung and the process gets SIGTERM?\n. In my case, there should not be any long running tasks or those tasks should terminate eventually. However I have seen huey instances over few days old.\nI'll try to dump the huey state using Python 3 faulthandler ( https://docs.python.org/3/library/faulthandler.html )\n. Here is the exact supervisor config I am using (containing the invocation):\nhttps://github.com/miohtama/LibertyMusicStore/blob/master/conf/supervisor.conf\n. Ah, of course! I should have known this as I have run across the same issue couple of time during the years.\nThe rationale creating the (irritating) wrapper script is that venv module shipped with Python 3.4 on Ubuntu 12.04 is broken. It incorrectly fails to set PYTHONPATH and behaves differently than real virtualenv. Thus, one needs to run the script and source the environment. \nHowever the alternative solution is not to use python -m venv or supplied virtualenv, but simply install virtualenv from PyPi and override the system .deb installation.\n. Thanks for the help once again!\n. ",
    "humbled": "For the record, this is done via settings.py in huey as:\nHUEY = {\n    \"connection\": {\"db\": 2},\n    ...\n}\n. ",
    "GeyseR": "Hmm, in one of my production environments python build without sqlite3 support. \nSo this is real issue for me :)\n. ",
    "tangram": "Yeah, sorry, I may have caused this myself by diving into the api a bit. I _put() the bool there myself, so much for respecting the underscore. This probably doesn't warrant further investigation.\n. ",
    "n37r06u3": "Yes,  It was not huey system problem, \nI am running a redis publish task with huey periodic task,\nI think this made the redis memory overflow.\n. ",
    "g-cassie": "Sorry, as you can probably tell I have pretty loose understanding of devops. Please forgive my fairly loose usage of the terminology.\n\nWhat do you mean a new instance of huey?\n\nIf I run ps -aux | grep huey before running my tests I have one entry for manage.py run_huey.  After running my test suite once, there will be two. Each time I run the tests it increments so when I first discovered this error there were 7 run_huey processes.\n\nHow would huey know about an existing huey process?\n\nWhen my app server is running (either through gunicorn or local dev server), calls to huey tasks get handled by the run_huey process I have running on the server.  When huey tasks get called in my tests, instead of using the existing run_huey process, the tests will start a new one.  Presumably if the app server can use the existing run_huey process the tests could also?\n. Thanks for the response.  Having ruled out the testing issue based on your response I took a closer look at what was happening with my supervisor settings and realized that is where the problem is.  I have been starting huey using a script called huey_start. It turns out supervisor restart kills the huey_start process but not the corresponding run_huey.  Instead of the tests spawning the extra run_huey process, supervisorctl restart is failing to shutdown the old run_huey process.  \nThanks for the help - sorry I didn't see this sooner.  Obviously it's beyond the scope of this project but if you happen to know an easy way to fix the above it would be much appreciated.\n. I have huey working with Sentry.  You need to add some config to the LOGGING['loggers'] in settings.py\npython\nLOGGING['loggers']['huey.consumer'] = {\n  'handlers': ['sentry', 'console'],   # assuming you have a `sentry` handler defined in LOGGING['handlers']\n  'level': 'INFO'\n}\n. ",
    "zzzuzik": "Cheers!\n. @coleifer \nworks flawlessly! \nThanks a million for your quick feedback\n. Sorry, didn't get your second post... reading it now\nold post:\n\nIs possible to get the args of the revoked task to pass them into the new scheduled one?\n. That makes total sense. \n\nThe story behind it is that I schedule one task with different args with eta = now()+1 year to have a queue. Next, in a different task I go through that queue and see that I have resources to execute them. There is a lot of blows and whistles around that including priority, ownership, resources availability, etc. When I have a proper condition I want to execute the scheduled task (with unknown to me args).\nYou know, I plowed through the docs/github to find a way to get a revoked task args. Went through the HUEYand QueueTaskcode to find a method. Internally, I stored only taks_id of a scheduled task and next revoke it by id. \nWill I be able to get the args based on a task_id only?. yes, all of them are scheduled +1 year for eta. And, for sure, will be kicked off within a day or two.\nAs always, thank you for your quick help.\nSince my first question: #74 Huey is the most stable and enjoying part in our system.\n. ",
    "vgarvardt": "Finally, made PR. Closing this as we can move all discussions to #76 \n. any updates?\n. ",
    "mkoistinen": "It would be really wonderful if we could get this into a release.\n. ",
    "deathowl": "I might do the rabbitMQ part if i can find the time during the holiday. Look for incoming pull requests. :)\n. About schedule in a rabbit-y way:\nWe should declare multiple channels, exactly one for every TTL, and all of them would be routed to a queue after the TTL expires, so the consumers could just read from that queue, this way we would lose the ability to read from the queue for a given range, but timed delivery would be a solved problem. The tests would obviously break, because of the negative TTL\nThe not so rabbit-y way:\nwe could wrap the payload into an object, put the time next to it. Read the whole queue at every get, and return the elements, which didnt expire yet. The tests would pass of course, but:\nIt would be slow, if the queue is big. This is not the way rabbit works usually.\n. any ideas on that @coleifer ?\n. So i'll do as you prefer, expect changed patch soon.\n. An example:\n`author = 'deathowl'\nfrom time import sleep\nfrom jobqueue.config import simple_huey\n@simple_huey.task(include_task=True)\ndef simple_task(task=None, time=100000):\n    \"\"\"\n    :param msg: Message\n    \"\"\"\n    from utils.globals import app\n    with app.app_context():\n        for i in range(1, time):\n            simple_huey.emit_task(i, task)\n            sleep(1)\n    return \"done\"`\n. They are caught by huey and reported back via the redis pubsub if you use huey with redis.\n. A pluggable error handler would be handy also.\n. https://github.com/coleifer/huey/pull/141 This PR Solves this issue.\n. Hey @coleifer i know it's not nice to ask for releases, but could you release a new version to pip please?\n. Thank you for the quick merge.\n. i just followd the structure of your tests.\n. ",
    "KsaRedFx": "You should mention this in your docs then, that you need to set your pythonpath or else it will not work.\nCurrently it is extremely confusing for anyone wishing to use Huey. It simply appears to be broken. \n. ",
    "pizzapanther": "Yes looking at this further I think auto discovery is just broken for 1.7 and 1.8a.\n. Think your fix is going to still break stuff it needs:\nmodule_args = imp.find_module(module_name, app_path)\nimp.load_module('{}.{}'.format(config.name, module_name), *module_args)\nIf you just do module_name it conflicts with other imports\n. It probably has to do with relative imports, I'm using relative imports in my tasks.py and get ValueError: Attempted relative import in non-package with Huey 0.4.5.  If I change load_module to use the name '{}.{}'.format(config.name, module_name) it works.\n. Just tested, it works great.\nThanks for the great library.\n. ",
    "nmcode": "Understood, I'll try Huey. thanks.\n. ",
    "vladlep": "Yes.\n In the past the Django query - Subscription.objects.filter(cancelled=None) - was returning less elements and now it returns more but max 26. And if i call the same code from a simple django view (not a  huey task) it takes 30 millisecond (i wrote it wrong). \nI am trying different things and surprisingly i can not make it work. That is why i thought to ask, maybe i missed some constraints\n. Puff...I found the problem, it was on my side. The server was running out of memory at some point. For the test server i assigned fewer ram and it got consumed exactly when starting that task.\nUpgraded the server and now i see it runs much faster. \nThank you for your  patience,\nVlad\n. hi,\ni solved it. I was passing the invite object in this call and since it was saved just before the task I got that error. Now i passed the invite_id and then retrieved the object inside the tasks and all works fine. \nBest,\nVlad\n. Hi thanks for the ideas. I agree that it might not be a huey issue but i still have a feeling a huey config or something regarding heuy-redis is the key to fixing this.  We are running a  multiple core server.\nI do not know the exact implementation of huey but there is a persistence of task from my understanding, in case of whatever (server fails, power is down ...etc).\nI am looking at these links and trying to figure out:\nhttp://abhinavsingh.com/customizing-redis-pubsub-for-message-persistence-part-2/\nhttp://stackoverflow.com/questions/7149074/deleting-all-pending-tasks-in-celery-rabbitmq\nAnyways, I will find a solution in the end but was just trying my luck in case someone had a great idea. \nThanks,\nVlad. Hi,\nTo continue Tudor's work, i was looking in this issue and i can replicate it in a hello world project. It might be that there are some bugs with certain versions of the components or that I am missing something from the documentation, but it is a persisting issue.\nI installed the Redis server v=4.0.9 with sudo apt-get install redis-server\nOn my system i have Virtualenv 16.0.0, Python 2.7.15rc1 but on others we have python  2.7.14 or 2.7.9 and we still have the issue. In the requirement.txt you see the version of the python libs.\nI made a hello world project to test scheduled tasks with. To run it you can follow these commands: \ngit clone https://github.com/vladlep/test-django-huey.git\nvirtualenv venv\nsource venv/bin/activate\npip install -r test-django-huey/requirements.txt\npython test-django-huey/manage.py runserver &\npython test-django-huey/manage.py run_huey\nThen if I open in the browser the page: \nhttp://localhost:8000/huey/test/ \nI get the following error in the terminal:\n```\n(venv) vlad@vlad-laptop:~/work/temp$ python test-django-huey/manage.py run_huey\n[2018-12-19 14:03:34,750] INFO:huey.consumer:MainThread:Huey consumer started with 1 thread, PID 5581\n[2018-12-19 14:03:34,750] INFO:huey.consumer:MainThread:Scheduler runs every 1 second(s).\n[2018-12-19 14:03:34,750] INFO:huey.consumer:MainThread:Periodic tasks are enabled.\n[2018-12-19 14:03:34,750] INFO:huey.consumer:MainThread:UTC is enabled.\n[2018-12-19 14:03:34,750] INFO:huey.consumer:MainThread:The following commands are available:\n+ queue_task_hello_task\n[19/Dec/2018 14:03:43] \"GET /huey/test/ HTTP/1.1\" 200 12\n[2018-12-19 14:03:45,030] INFO:huey.consumer.Worker:Worker-1:Adding helloworld.tasks.queue_task_hello_task: 8caa75b1-da25-48eb-9c57-de6e57e74c5f @2018-12-19 14:04:43.933450 to schedule\n[2018-12-19 14:03:45,032] ERROR:huey.consumer.Worker:Worker-1:Error adding task to schedule: helloworld.tasks.queue_task_hello_task: 8caa75b1-da25-48eb-9c57-de6e57e74c5f @2018-12-19 14:04:43.933450\n```\nIn the  django view   you see how the task is called. If i would call it without scheduling like hello_task() it would work.\nAny idea what I could try? \nThanks,\nVlad. So I think i found it. If I change to redis==2.10.6 instead of redis==3.0.1 the scheduling seems to work. \nThey released their 3.x versions on Nov 15 and I presume they change some interface and now huey does not work with the new release.\nSo I would recommend to adapt  the documentation until huey is updated.\npip install redis  to pip install redis==2.10.6\nI will continue my testing to make sure other things are working now still. . Ahh great. Did not know that was already done. \nThanks! Vlad. ",
    "quamilek": "Huey use Redis PUB/SUB  http://redis.io/topics/pubsub feature to emit events.\n@mphuie this is example for consuming RedisEventEmitter\n```\nimport sys\nimport redis\nCONFIG = {\n    'host': 'localhost',\n    'port': 6379,\n    'db': 0,\n}\ndef main():\n    channel_name = sys.argv[1]\n    connection = redis.StrictRedis(**CONFIG)\n    pubsub = connection.pubsub()\n    pubsub.subscribe(channel_name)\nprint('Listening to {}'.format(channel_name))\n\nwhile True:\n    for item in pubsub.listen():\n        print(item['data'])\n\nif name == 'main':\n    main()\n```\nHow to run: \n$ python sub.py django_app_name\nOutput:\nListening to django_app_name\n1\nb'{\"error\": false, \"id\": \"41b7df79-7cc8-4599-b56c-2cc513ce2a8c\", \n\"retries\": 0, \"task\": \"queuecmd_my_task\", \n\"status\": \"started\", \"retry_delay\": 0, \"execute_time\": null}'\n. ",
    "laike9m": "Could you provide an example on how to use self aware task? I'm not sure what properties/information task object can offer. I would like to know how many times this task has been executed(retried), is this possible?\n. @deathowl Thank you. Can I get the information of how many times this task has been executed(retried) from task object?\n. @coleifer So what should I do? How do people usually test these code?\n. OK, finally found a way to test\n``` python\nhuey_tasks.py\ndef _function():\n    import requests\n    print(requests.get('http://www.google.com'))\nfunction = huey.task()(_function)\n```\n``` python\nimport huey_tasks\n@patch('requests.get')\ndef test_patched(fake_get):\n    fake_get.return_value = '1'\n    huey_tasks._function()\n```\nThen directly run test code without launching huey_consumer.\n. I know there's always_eager, but you can't test a function which is already decorated with @task and monkey patch it at the same time. The above solution is the only way I can think of. My question has nothing to do with whether huey runs with Redis or not.\n. ",
    "birdsarah": "Thanks!\n. ",
    "camilonova": "I'm not using Redis, seems it only needs some extra configuration at the logger, I'm right? @coleifer \n. Just for documenting how you should do:\nfrom huey.contrib.djhuey import HUEY\nHUEY.flush()\nThanks.. @martinmo please fix the conflicts to make easier merging it\n. @coleifer Please merge this one \ud83c\udf54 \n. #163 is what I was looking for. Thanks.\n. I just worked on a fix for this, please check #202 . @mskrzypek Please test the PR and let us know if it works for you too.. This issue can be closed now. @coleifer Could you please release a new version?. @coleifer \ud83c\udf7b  Thanks. @moises-silva Please fix broken tests.. @coleifer I can confirm the bug is real and it is fixed at the current master. Could you release a new version?. It has the fix for #190 and probably the fix for #187 as well.. @coleifer Can you please issue a release?. Thank you. @coleifer This is working fine on production, would you merge this and cut a release?. But the settings in settings.HUEY are overriden by the default command line options. This was the only way I could make it work.. @coleifer Any updates?. Pretty good. Thank you.. @Antwan86 Please fix conflicts.. Thank you. @Antwan86 thank you.. Looks awesome @Sebubu \ud83c\udf7a . @coleifer any ideas?. @coleifer Thank you. Thing is, we currently use Huey with Django, and when we have server errors with Django they are reported to Sentry. But when we have errors on Huey they don't.\nCelery have support with https://docs.sentry.io/clients/python/integrations/celery/\nMaybe it can be done using a decorator and I can work on that, but I'm not sure which way do you prefer.\nPlease let me know your thoughts.. @raphael-riel Amazing. Thanks a lot. It will catch you exceptions or just logging.error messages?. Cool. Thank you.. ",
    "robinhilliard": "Sorry it should all be 'second', a bit inconsistent with the plurals\n. Hi,\nYes I've been using this change successfully with --periodic-task-interval=1 and second=\"*/3\". The problem I referred to is that if someone sets periodic task interval to a value < 60 with the existing code, a task with minute=\"*\" will run more than once per minute, which is not the expected cron-like behaviour. I'd respectfully suggest that you need to either validate periodic-task-interval to be >= 60, or do something like this pull request to make sure tasks only run on the minute when the interval is < 60.\nJust to reiterate, people using the second argument would be responsible for explicitly setting the periodic-task-interval to a suitable lower value, I wouldn't suggest for a moment that you force a lower interval on users and even less that you set the default to 1 :-).\nCheers,\nRobin\n. ",
    "sheeshmohsin": "It works using --verbosity but i am not able to call the tasks function asynchronously in django. if i call the function it stucks at that and after completion it process further.\n. Fixed, changed setting always_eager from true to false\n. The same error happening, it seems fixed to me because i setted always_eager to true.\nThis is the error - http://ur1.ca/mwqkl\n. ",
    "oz123": "@coleifer thank your for the quick respond! I created the tiny PR. The test suite currently fails \non both master an my own branch, I hope it's not much of a problem ...\n. ",
    "wldcordeiro": "Is there a technical reason why not? Does the system fail with intervals less than a minute?\n. I'm interested in helping add the ability to use seconds, Celery is too heavyweight for my use case and I like your API. I noticed that obviously the crontab function would need changes, but if you could tell me which parts of the library are affected I'll take a look at making a PR\n. Also if that's the case I'd reopen this issue or #33 \n. ",
    "viperfx": "@wldcordeiro did you find a solution to your database based scheduling?. Yes, it supports crontab which is perfect for my use case. I see that you can specify the task at run time using the tasks file. But I am wondering its possible to periodically check a db for crontab values, and have the worker execute at those times. \nI think the answer is that - this is currently not supported?\nSo if I was to fork the project, what parts of the code would be the right places to look at for attempting a solution to this? . Ah,  I see! Okay. I will attempt this approach. Does huey have methods to check current time against crontab? I am currently storing crontab expressions in the db. If you could point to some useful functions/lines, that would be great.. I was just browsing the source code and it seems, the crontab method in api.py can validate against a datetime. I will start there.. I have two tasks\n@db_periodic_task(crontab(minute='*'))\ndef conditionally_run_other_tasks():\n@db_task()\ndef send_link(report_id):\nOne has no arguments, and the other has an integer as an argument. They should be pickle-able.. Just tried that change and it still behaves the same. The error occurs when I visit any page of the application. \nhere is the full stack trace \nTraceback (most recent call last):\n  File \"manage.py\", line 22, in <module>\n    execute_from_command_line(sys.argv)\n  File \"/Users/viperfx/.virtualenvs/scrumbot/lib/python2.7/site-packages/django/core/management/__init__.py\", line 363, in execute_from_command_line\n    utility.execute()\n  File \"/Users/viperfx/.virtualenvs/scrumbot/lib/python2.7/site-packages/django/core/management/__init__.py\", line 355, in execute\n    self.fetch_command(subcommand).run_from_argv(self.argv)\n  File \"/Users/viperfx/.virtualenvs/scrumbot/lib/python2.7/site-packages/django/core/management/base.py\", line 296, in run_from_argv\n    connections.close_all()\n  File \"/Users/viperfx/.virtualenvs/scrumbot/lib/python2.7/site-packages/django/db/utils.py\", line 234, in close_all\n    connection.close()\n  File \"/Users/viperfx/.virtualenvs/scrumbot/lib/python2.7/site-packages/django/db/backends/base/base.py\", line 283, in close\n    self.validate_thread_sharing()\n  File \"/Users/viperfx/.virtualenvs/scrumbot/lib/python2.7/site-packages/django/db/backends/base/base.py\", line 542, in validate_thread_sharing\n    % (self.alias, self._thread_ident, thread.get_ident())\ndjango.db.utils.DatabaseError: DatabaseWrapper objects created in a thread can only be used in that same thread. The object with alias 'default' was created in thread id 140736170554304 and this is thread id 4383314160.\nException KeyError: KeyError(4383314160,) in <module 'threading' from '/usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/threading.pyc'> ignored. I am launching many of the huey tasks from another background process. Not technically within request/response but the above suggestion would work.\nHowever, the reason I was hoping to find a way to wrap the task is because structlog allows binding context to the thread. Therefore, a task_id can be attached to all future logs that get run by huey.\nIf I am understanding correctly, the above suggestion would only work to log that one log line. Since the task is scheduled within another thread, the binding of the context would not work?\n. Okay, I am using threads for all my workers.\nStructlog allows me to bind a context onto the thread, that is used to call the huey task and carry out the rest of the work. \nI just need to do logger.new(request_id=<request_id>) somewhere early enough in the thread before huey does any work on the task. Here is a simple flask example - http://www.structlog.org/en/stable/examples.html#flask-example\nI am using the same technique in my Django middleware. Its early enough in the request, that until the request/response cycle ends, that request_id stays present in the thread.\n. The closest analogy to what I might need in practice is a custom task class in celery - http://docs.celeryproject.org/en/latest/userguide/tasks.html#instantiation\n. Hope my explanation made it clear what I'm trying to do @coleifer \nWaiting to hear back from you. ",
    "antoviaque": "@coleifer Thank you! : )\n. ",
    "anentropic": "does the build normally fail on everything but Python 2.7?   I don't really see how my change is causing that\n. any chance of a PyPI release with the fix in it?  1.2.0 is still broken if you try and pass --logfile under manage.py\n. ah never mind, I should just put logfile in the django settings rather than passing as command line arg\n. ",
    "perrylh": "Thank you ! It works now.\n. ",
    "vrakesh": "On further investigation , I found that this happens only when using sqlite backend. but redis backend does not create two instances (threads) of the same task. Which is ideal. But while using sqlite backend. Two workers grab the same task and run it.\n. @coleifer Thanks looking forward to the patch. All your projects are great :) Learning a lot from them. \n. ",
    "evaldobratti": "I don't know if the way you fixed works. With -v it throws error\noptparse.OptionConflictError: option -v/--verbose: conflicting option string(s): -v\nEven though that worked, the parameters goes nowher, because it keeps getting all data logging from consumer options, instead of overriding consumer options as others parameters.\n. -v is already defined by django itself and it throws errors when redefined :(\n. ",
    "cmanallen": "This:\nbash\npython /usr/local/lib/python2.7/site-packages/huey/bin/huey_consumer.py /src/nfc/tasks/__init__.huey --workers=2 -v -s 10 -k $WORKER_CLASS\nTo:\nbash\npython /usr/local/lib/python2.7/site-packages/huey/bin/huey_consumer.py nfc.tasks.huey --workers=2 -v -s 10 -k $WORKER_CLASS\n. @coleifer Version 1.1.2.  I'm not using storage (to my knowledge - I'm not doing anything explicit).\nHuey is instantiated like:\n``` python\nclass Scheduler(object):\n    _connection = None\ndef connection(self):\n    if self._connection is None:\n        app = application.app.app_context()\n        app.push()\n\n        self._connection = RedisHuey(\n            'scheduler', host=current_app.config.get('REDIS_HOST'),\n            port=current_app.config.get('REDIS_PORT'))\n\n        app.pop()\n    return self._connection\n\nhuey = Scheduler().connection()\n```\n\nSo basically my bac.tasks module looks like this.\n``` python\nfrom common.scheduler import huey\nfrom tasks.whatever import task\nif name == 'main':\n    task()\n```\nRunning the script causes the error in the OP.  But if I comment everything but the huey import out it still fails with the error.\nFull disclosure I'm running this script in an Ubuntu docker-machine (if it matters).\n. @coleifer Okay thanks for the always_eager.  I've been doing some debugging and I think the problem lies in how huey is being instantiated.  Once I figure out the error I'll let you know.\n. @coleifer Hah, found the error.  The redis host was being passed as None.  Manually specifying it to my redis hostname fixed the issue.\nKind of sucks that it fails so hard.  It may be worth raising an exception like ValueError: NoneType can not be redis hostname.\n. Okay I think I understand the issue.  There was an outbound HTTP request that was failing.\n. ",
    "dmcmulle": "Ah, I'm an idiot.  Thank you my friend!  All is well now :) \n. Always running as in, a task that checks if something needs to be done.  If it doesn't, it sleeps, then checks again.  The problem is, I run my apps on heroku and sometimes the servers randomly restart for maintenance etc, which would kill the thread spawned into Huey.\nI guess similar to the @reboot cron command. Hi @coleifer,\nI did take a look at the consumer shutdown, but this doesn't satisfy my needs as I am not in control of the servers and cannot issue a SIGINT.  I am using heroku, which from what I've seen seems to want you to design your applications to be somewhat 'crash resistant'.\nFurthermore, I'd like to post my solution to this problem using your library.  Just in case others need a solution to this problem.  I have tested this solution in production for 7 days now with no issues.\nPlease note I am using Django 1.11 and huey 1.2.3 and Python 3.6.1\n```\n@db_task(include_task=True)\ndef the_task_that_must_complete(task: QueueTask):\ndef ack(_job_uuid):\n    \"\"\"\n    Every 30 seconds, update the database entry.  If this thread dies, then the worker has died, and we need to re queue the job with the periodic 'heal' task\n    :param _job_uuid:\n    :return:\n    \"\"\"\n    ack_report = TheTaskThatMustBeCompleted.objects.get(uuid=_job_uuid)\n\n    # While the task that must be completed status is not 'done'\n    while ack_report.status != TheTaskThatMustBeCompleted._STATUS_DONE_:\n        # update it\n        # ack sent\n        try:\n            ack_report.updated_on = timezone.now()\n            ack_report.save()\n            time.sleep(30)\n            # Update the report with what's in the database\n            ack_report = TheTaskThatMustBeCompleted.objects.get(uuid=_job_uuid)\n        except:\n            print(\"Ack interrupted with error\")\n            break\n\n    print(\"%s ack done.\" % _job_uuid)\n\nack_thread = threading.Thread(target=ack, args=(task.task_id,)).start()\n\ntry:\n    # Do some long work that must be completed...\n    job.status = TheTaskThatMustBeCompleted._STATUS_DONE_\n    job.save()\nexcept:\n    print(\"The exception\")\n\n@db_periodic_task(crontab(minute=\"*/1\"))\ndef heal():\n    \"\"\"\n    Re queues jobs that failed\n    :return:\n    \"\"\"\n    print(\"Healing Queue...\")\nlist_of_jobs_that_probably_failed = TheTaskThatMustBeCompleted.objects.filter(\n    updated_on__lt=timezone.now()-timezone.timedelta(minutes=10)\n).exclude(\n    Q(status=TheTaskThatMustBeCompleted._STATUS_DONE_) | Q(status=TheTaskThatMustBeCompleted._STATUS_QUEUED_)\n)\n\nfor j in list_of_jobs_that_probably_failed:\n    # Re-schedule job\n    event = the_task_that_must_complete.schedule(delay=30)\n\n    # Point new UUID to task in DB\n    j.uuid = event.task.task_id\n    j.save()\n    print(\"Task %s was found to be broken, task attempted and sent back to queue\" % event.task.task_id)`\n\n```\nIf the 'ack' thread dies during execution, then we know that the job failed and needs to be re-queued via the 'heal'. . ",
    "JoseTomasTocino": "Is this documented anywhere? I've run into the same problem and was about to open an issue. Looks like the line that provokes this behavior is this one https://github.com/coleifer/huey/blob/master/huey/contrib/djhuey/init.py#L79\n. ",
    "ducky427": "Thanks a lot!\n. ",
    "mskrzypek": "I have django project, settings: USE_TZ=True, HUEY['consumer']['utc']=False\nI have model with datefield (value = 2016-02-24 19:23:42+01:00)\nLet's assume the datetime on the server is: 2016-02-24 19:08:42+01:00\nI want to schedule task on date from datefield: 2016-02-24 19:23:42+01:00\nSo let's try:\ndates = [\n    mymodel.datefield,\n    localtime(mymodel.datefield),\n    mymodel.datefield.replace(tzinfo=None),\n    mymodel.datefield.replace(tzinfo=utc)\n]\nfor date in dates:\n    mytask.schedule(args=(...), eta=date)\nResult is always like this:\n[2016-02-24 19:08:42,154] Executing queuecmd_mytask: 459[...]96b @2016-02-24 18:23:42\nSo the task executes immediatelly, because of one hour shift. How can I schedule task on 19:23 and not 18:23?\n. For all below python datetimes:\n2016-02-28 17:26:31+01:00\n2016-02-28 17:26:31+00:00\n2016-02-28 17:26:31\nlocal_to_utc function returns:\n2016-02-28 16:26:31\nShould this function convert localtime to utc, despite of \"utc=False\" setting?\n. Ok, I haven't noticed it in docs.\nWhen I set this parameter to False, I get this error:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/threading.py\", line 810, in __bootstrap_inner\n    self.run()\n  File \"/usr/lib/python2.7/threading.py\", line 763, in run\n    self.__target(_self.__args, *_self.__kwargs)\n  File \"/home/ms/.virtualenvs/vmf/local/lib/python2.7/site-packages/huey/consumer.py\", line 359, in _run\n    consumer_process.loop()\n  File \"/home/ms/.virtualenvs/vmf/local/lib/python2.7/site-packages/huey/consumer.py\", line 110, in loop\n    self.handle_task(task, now or self.get_now())\n  File \"/home/ms/.virtualenvs/vmf/local/lib/python2.7/site-packages/huey/consumer.py\", line 123, in handle_task\n    if not self.huey.ready_to_run(task, ts):\n  File \"/home/ms/.virtualenvs/vmf/local/lib/python2.7/site-packages/huey/api.py\", line 327, in ready_to_run\n    return cmd.execute_time is None or cmd.execute_time <= dt\nTypeError: can't compare offset-naive and offset-aware datetimes\n. Yes, I'm using Django.\n\n```\nsettings.py\nHUEY = {\n    'name': 'xxx',\n    'always_eager': False,\n    'consumer': {\n        'loglevel': logging.DEBUG,\n        'workers': 4,\n        'worker_type': 'thread',\n        'utc': False,\n    },\n}\n```\nConsumer runs without additional options:\n/www/.virtualenvs/xxx/bin/python manage.py run_huey\n. ```\nPython 2.7.6 (default, Jun 22 2015, 17:58:13) \n[GCC 4.8.2] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n(InteractiveConsole)\n\n\n\nimport datetime\ndatetime.datetime.utcnow()\ndatetime.datetime(2016, 10, 14, 13, 19, 16, 817603)\ndatetime.datetime.now()\ndatetime.datetime(2016, 10, 14, 15, 19, 21, 430033)\n```\n. Django==1.10.2\nhuey==1.2.1\n. Yes, sure.\n\n\n\n[2016-10-25 20:38:59,283] UTC is initialized to: True\n[2016-10-25 20:38:59,283] Huey consumer started with 1 thread, PID 16310\n[2016-10-25 20:38:59,284] Scheduler runs every 1 seconds.\n[2016-10-25 20:38:59,284] Periodic tasks are enabled.\n. Unfortunately, it has not been fixed yet.. ",
    "Rand01ph": "I also find this issue\uff0chow to resolve it \uff1f. @coleifer First time I use huey 1.2.2, which has a Django bug, so It run with only one thread. Today I find about 200 tasks unable to consume, then I find the issue and the Django bug, so I upgrade huey to 1.2.3 and run with 10 threads. After restart uWSGI and huey works, It's also have this issue. So i attempt comment the \"periodic_task\" and restart the Huey works, quickly all the tasks finished.\nI will analyse the program logs tomorrow, now I don't know how to reproduce. . Yes, If I send mail fail i will raise SendEmailError\n```python\n2017-12-22 11:32:17,199 INFO [8366:MainProcess] /opt/venvs/api/local/lib/python2.7/site-packages/huey/consumer.py consumer consumer.py process_task 170 Executing queuecmd_send_email: 3824d5ee-13b0-497e-bbbd-2c8ba2727e23 3 retries\n2017-12-22 11:32:17,207 INFO [8366:MainProcess] /opt/disk2/var/www/test/mail/tasks.py tasks tasks.py send_email 31 send_mail data is NoticeMail object\n2017-12-22 11:32:18,010 ERROR [8366:MainProcess] /opt/venvs/api/local/lib/python2.7/site-packages/huey/consumer.py consumer consumer.py process_task 208 Unhandled exception in worker thread\nTraceback (most recent call last):\n  File \"/opt/venvs/api/local/lib/python2.7/site-packages/huey/consumer.py\", line 177, in process_task\n    task_value = self.huey.execute(task)\n  File \"/opt/venvs/api/local/lib/python2.7/site-packages/huey/api.py\", line 367, in execute\n    result = task.execute()\n  File \"/opt/venvs/api/local/lib/python2.7/site-packages/huey/api.py\", line 768, in execute\n    return func(args, kwargs)\n  File \"/opt/venvs/api/local/lib/python2.7/site-packages/huey/contrib/djhuey/init.py\", line 93, in inner\n    return fn(*args, kwargs)\n  File \"/opt/disk2/var/www/test/mail/tasks.py\", line 153, in send_email\n    raise SendEmailError\nSendEmailError\n2017-12-22 11:32:18,012 INFO [8366:MainProcess] /opt/venvs/api/local/lib/python2.7/site-packages/huey/consumer.py consumer consumer.py requeue_task 234 Re-enqueueing task 3824d5ee-13b0-497e-bbbd-2c8ba2727e23, 2 tries left\n2017-12-22 11:32:18,013 ERROR [8366:MainProcess] /opt/venvs/api/local/lib/python2.7/site-packages/huey/consumer.py consumer consumer.py _run 466 Process Worker-2 died!\nTraceback (most recent call last):\n  File \"/opt/venvs/api/local/lib/python2.7/site-packages/huey/consumer.py\", line 462, in _run\n    process.loop()\n  File \"/opt/venvs/api/local/lib/python2.7/site-packages/huey/consumer.py\", line 129, in loop\n    self.handle_task(task, now or self.get_now())\n  File \"/opt/venvs/api/local/lib/python2.7/site-packages/huey/consumer.py\", line 145, in handle_task\n    self.process_task(task, ts)\n  File \"/opt/venvs/api/local/lib/python2.7/site-packages/huey/consumer.py\", line 228, in process_task\n    self.requeue_task(task, self.get_now())\n  File \"/opt/venvs/api/local/lib/python2.7/site-packages/huey/consumer.py\", line 240, in requeue_task\n    self.enqueue(task)\n  File \"/opt/venvs/api/local/lib/python2.7/site-packages/huey/consumer.py\", line 87, in enqueue\n    self.huey.enqueue(task)\n  File \"/opt/venvs/api/local/lib/python2.7/site-packages/huey/api.py\", line 318, in enqueue\n    self._enqueue(self.registry.get_message_for_task(task))\n  File \"/opt/venvs/api/local/lib/python2.7/site-packages/huey/registry.py\", line 61, in get_message_for_task\n    task.get_data(),\n  File \"/usr/lib/python2.7/pickle.py\", line 1377, in dumps\n    Pickler(file, protocol).dump(obj)\n  File \"/usr/lib/python2.7/pickle.py\", line 224, in dump\n    self.save(obj)\n  File \"/usr/lib/python2.7/pickle.py\", line 286, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python2.7/pickle.py\", line 562, in save_tuple\n    save(element)\n  File \"/usr/lib/python2.7/pickle.py\", line 286, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python2.7/pickle.py\", line 562, in save_tuple\n    save(element)\n  File \"/usr/lib/python2.7/pickle.py\", line 286, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python2.7/pickle.py\", line 649, in save_dict\n    self._batch_setitems(obj.iteritems())\n  File \"/usr/lib/python2.7/pickle.py\", line 663, in _batch_setitems\n    save(v)\n  File \"/usr/lib/python2.7/pickle.py\", line 331, in save\n    self.save_reduce(obj=obj, rv)\n  File \"/usr/lib/python2.7/pickle.py\", line 401, in save_reduce\n    save(args)\n  File \"/usr/lib/python2.7/pickle.py\", line 286, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python2.7/pickle.py\", line 562, in save_tuple\n    save(element)\n  File \"/usr/lib/python2.7/pickle.py\", line 286, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python2.7/pickle.py\", line 751, in save_global\n    (obj, module, name))\nPicklingError: Can't pickle : it's not found as mail.tasks.queuecmd_send_email\n2017-12-22 11:32:19,760 WARNING [8366:MainProcess] /opt/venvs/api/local/lib/python2.7/site-packages/huey/consumer.py consumer consumer.py check_worker_health 558 Worker 2 died, restarting.\n. @coleifer \nI use python2.7 and huey 1.5.6\nI find if I change huey api.py line 335python\n    def _get_task_metadata(self, task, error=False, include_data=False):\ntopython\n    def _get_task_metadata(self, task, error=False, include_data=True):\n```\nIt's work OK. Hi,I try this commit, but still have this ERROR.\nI think the problem is when a task whit includ_task raise a error, the function get_message_for_task will dumps a task.get_data(), the data have a class which python pickle can't dump it.. ",
    "hyperknot": "But none of those options can pass a parameter to the script. I need to\npass if the config is using development.ini or production.ini.\nAt the moment, I solved it using using environment variables.\nOn 23 March 2016 at 16:00, Charles Leifer notifications@github.com wrote:\n\nHuey supports a number of config options for running the consumer:\nhttp://huey.readthedocs.org/en/latest/consumer.html#options-for-the-consumer\nAnything else would be beyond the scope of running the consumer, and\nshould be handled by the application. If you have some very specific\nuse-case in mind I can try to respond more specifically.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/coleifer/huey/issues/145#issuecomment-200383202\n. \n",
    "iivvoo": "Actually I now realize that nested tasks isn't a problem (except in testing cases) since each task will run isolated with its own connection (at least that's my assumption)\nSo the only problem that remains is not closing the connection in test setups. Or more specifically in 'always_eager' situations.\nWould, in that case,\n```\nfrom huey.contrib.djhuey import HUEY\ndef close_db(fn):\n    \"\"\"Decorator to be used with tasks that may operate on the database.\"\"\"\n    @wraps(fn)\n    def inner(*args, kwargs):\n        try:\n            return fn(*args, kwargs)\n        finally:\n            if not HUEY.always_eager:\n                connection.close()\n    return inner\n```\nwork? It seems to work for me.\n. Lastly, periodic tasks are never eager, they're always fired through run_huey which means they should close the connection:\n```\ndef close_db(fn, iscron=False):\n    \"\"\"Decorator to be used with tasks that may operate on the database.\"\"\"\n    @wraps(fn)\n    def inner(*args, kwargs):\n        try:\n            return fn(*args, kwargs)\n        finally:\n            if not iscron and not HUEY.always_eager:\n                connection.close()\n    return inner\ndef db_task(*args, kwargs):\n    def decorator(fn):\n        return task(*args, kwargs)(close_db(fn))\n    return decorator\ndef db_periodic_task(*args, kwargs):\n    def decorator(fn):\n        return periodic_task(*args, kwargs)(close_db(fn, iscron=True))\n    return decorator\n```\n. ",
    "blakev": "Maybe something like this in RedisStorage\npython\n    def task_data(self, key, deserialize=None):\n        if self.has_data_for_key(key) and key is not None:\n            val = self.conn.hget(self.result_key, key)\n            if val:\n                if deserialize is None:\n                    deserialize = pickle.loads\n                return deserialize(val)\nThen, the event consumer loop would look something like this,\n``` python\nstorage = test_huey.get_storage()\nfor event in storage:\n    e_id = event.get('id')\n    e_result = storage.task_data(e_id)\nif e_result:\n    # ..do something\n\n```\n. I looked over your code, it's great!\nThanks!\n. ",
    "zbyte64": "Not really a fan of asyncio either but there may be times the task runner has to execute an asyncio function. The main crux of the problem is that you do not want to run the event loop inside the task loop itself but rather by task runner. \nYou don't have to require asyncio in order to support asyncio. You can detect if a task returns a coroutine and do special handling when that happens.\n. ",
    "chayim": "It equally occurs when specifying a delay, rather than an eta.  For fun - I have confirmed that (future - datetime.datetime.now()).seconds is working as it ought be, as I used for delay.\n. Unfortunately, that's not it.\nI've also gone down the path of:\nfrom django.utils import timezone\nnow = timezone.now()\nWhen looking at the time difference, it's definitely correct - in that the correct number of seconds come back from timedelta.\n. I did.\n. Sure.\nTo start, I'm running the consumer via django (manage.py run_huey) with the following settings:\nHUEY = { \n    'name': 'taggity',\n    'connection': {'host': 'localhost', 'port': 6379},\n    'consumer': {'workers': 20, 'worker_type': 'threads'},\n}\nAttached is the barebones django management command I crafted to pull this together, along with the associated tasks. The code has a bunch of prints in it, as it reflects my current broken(ish) hacking against it.\ntmp.zip\n. I should also mention - this is huey latest from pypi, django latest (1.9.7). Redis latest as well.\n. Apologies @coleifer - markdown fail on my part.  I appreciate your looking into this!\n. Your logic is correct, and reflects exactly how I was doing this in my non-django enabled project. I'm thinking that the issue is (in some way) django integration. When queueing the tasks via the management command - that task too runs immediately, rather than queuing/honouring the huey queues.\nI'm looking a bit further into that side now.\n. ",
    "canni": "NVMD, I missed the **storage_kwargs on base Huey class, but documenting that might be handy anyway.\n. ",
    "henriquechehad": "I needed a feature to list all registered tasks and implemented it in this PR, check if you need this feature.\n. @coleifer thanks, I was logging with Django logger, not used the --log-file option. I will use this option. \nIt would not be interesting to use to show in console?\n. Where is the console log handler implementation? I didn't located\n. I configured the logfile in django, but it didn't logged the registered tasks in logfile. What can it be?\nroot@cb891d57c8b5:~# cat /tmp/huey.log\n [2016-06-20 15:29:25,594] DEBUG:urllib3.util.retry:Scheduler:Converted retries value: False -> Retry(total=False, connect=None, read=None, redirect=0)\n [2016-06-20 15:29:25,595] INFO:urllib3.connectionpool:Scheduler:Starting new HTTP connection (1): elasticsearch\n [2016-06-20 15:29:25,601] DEBUG:urllib3.connectionpool:Scheduler HTTP/1.1\" 200 994\nDjango conf:\nHUEY = {\n     'name': 'NAME',\n     'connection': {'host': 'redis', 'port': 6379},\n     'consumer': {\n         'workers': 16, 'worker_type': 'worker',\n         'loglevel': 'DEBUG', 'logfile': '/tmp/huey.log',\n     },\n }\n. ",
    "adamchainz": "The link on the Github repo description also needs updating.\n. np\n. ",
    "toshka": "Please merge patch by @moises-silva \n. ",
    "moises-silva": "@coleifer I think the best is probably mock time.time() to test this function.\n. @coleifer Anything else needed to get this merged ?\n. @camilonova sorry, we've moved to using celery and I don't think I'll find the time to continue with this PR. I don't see how the changes would be related to the test failure from a quick glance. Closing the PR.. ",
    "hegga": "Sorry about the missing code formatting, collaboration through github is quite new to me.\nI'm afraid this feature would be a bit over my python level, but I'll try to look at the source code of \nhuey during the weekend to see if I can come up with some suggestions. Initially I were mostly wondering if this was something that you had thought of, or would like to add at all. \nBy the way, I really like the simplicity of huey, it's a great piece of software, thanks for making it open source. \n. Wow! I think that would be a very nice and clever way to implement this functionality. \n. ",
    "martinmo": "I have incorporated your suggestions and also added some tests. Unfortunately on Python 2.6 they currently fail because I am obviously using assertRaises() in an backwards incompatible way.\n. Fixed :+1:\n. @camilonova Done :+1:\n@coleifer Waiting for your feedback :shipit:\n. Thanks for the feedback! With one minor exception (see this comment), I have incorporated all suggested changes.\n. Done.\n. Cool. Thanks for merging! :tada:\n\nI'm not sure if the brackets are necessary\n\nThey are, you'll get a TypeError: object of type 'generator' has no len() on all Pythons.\n. I just realized that the reported behavior is very closely related to my other reported issue #164. Using the latest Huey installed from Git (i.e., including the fix for #164), everything now works as expected. Everything meaning: Django's run_huey command as well as the \"simple\" example. Thanks for your quick response!\n. > Is the redis_url mutually exclusive with other parameters here? What is the behavior if a user erroneously supplies arguments for both url and connection_pool?\nredis_url will take precedence even if a connection_pool or other connection_params have been specified. But such a conflict already existed with connection_pool and connection_params, where connection_pool wins if both are specified.\nTo fix this: Would you like a ValueError being raised if more than one of these parameters are specified at the same time? I'm happy to supplement this PR :)\n\nAlso, why is url not just a regular keyword argument?\n\nI just thought it was a good fit for connection_params.\n. No :( For compatibility with Python 3, filter() would need to be wrapped by list():\npython\nif len(list(filter(None, (url, connection_pool, connection_params)))) > 1:\nIMHO this is a readability \"downgrade\" in comparison to the original code. If len() is a must have for you I would suggest using len([x for x in (url, ...) if x]) > 1, which works on all Pythons >= 2.6.\n. Sure.\n. Yes.\n. ",
    "dmitryduev": "In my case, the system where I'm running huey operates without human supervision, and there's a 'supervisor' process that looks after the system that may kill a misbehaving (for whatever reason) process. So it's just an additional level of protection.\n. ",
    "rahul3103": "Yeah, I am on version 1.1.2. It adds articles to whoosh index.\n. Sorry, for the delay.\n. Its a regular continuous thing, whenever new article created its added to whoosh index.\n[2016-08-05 19:29:23,106] INFO:huey.consumer.Worker:Worker-1:Executing queuecmd_add_or_update_index: 57e74549-dece-4d1f-b0aa-a405722622b9\n1\n[2016-08-05 19:29:23,110] ERROR:huey.consumer.Worker:Worker-1:Unhandled exception in worker thread\nTraceback (most recent call last):\n  File \"/Users/rahul/.virtualenvs/search/lib/python3.5/site-packages/huey/consumer.py\", line 141, in process_task\n    self.huey.execute(task)\n  File \"/Users/rahul/.virtualenvs/search/lib/python3.5/site-packages/huey/api.py\", line 279, in execute\n    self._put_data(task.task_id, pickle.dumps(result))\n_pickle.PicklingError: Can't pickle <function StrictRedis.<lambda> at 0x105b079d8>: attribute lookup StrictRedis.<lambda> on redis.client failed\n. Yes its coming after upgrade to 1.2.0\n. This is the function\n@queue.task()\ndef add_article_to_index(_id=None):\n    '''Add a newly published article to index.'''\n    if not _id:\n        return False\n    article = get_article(_id)\n    if not article:\n        logger.error('Article ID: %s was not added to index.' % _id)\n        return False\n    writer = get_index_writer()\n    add_to_index(writer=writer, article=article, update=False)\n    writer.commit(merge=True)\n    return True\nError:\n[2016-08-06 00:42:07,114] ERROR:huey.consumer.Worker:Worker-1:Unhandled exception in worker thread\nTraceback (most recent call last):\n  File \"/Users/rahul/.virtualenvs/search/lib/python3.5/site-packages/huey/consumer.py\", line 141, in process_task\n    self.huey.execute(task)\n  File \"/Users/rahul/.virtualenvs/search/lib/python3.5/site-packages/huey/api.py\", line 279, in execute\n    self._put_data(task.task_id, pickle.dumps(result))\nTypeError: can't pickle _thread.lock objects\n. ",
    "mayli": "Ncc, saw the connection pool parameter.\n. ",
    "angvp": "Yes, when settings.DEBUG = True I call a task is being run immediately on the request .. and yes, the consumer is running with DEBUG = True\n. Hello @coleifer !\nLet me try to explain this better:\nI have a django project, I have an app, and I have several views there.\nI needed to run some tasks asynchronous while one of these views are being executed, so I choose to use huey, then I've created a task on tasks.py and called that task from one of my views. \nThat task runs in 30 seconds~, so I want to give a response to the view w/o being blocked by that task, huey does that fine but I found when I'm having in my settings the variable DEBUG in True (for dev purposes) and then I call the view, and the view call, the task is not being executed asynchronous, so I have to wait those 30~ seconds on the view. \nIt's clearer now or you need some code? to see it?\n. ",
    "ranihorev": "Fixed the problem - just ran 2 dockers separately - one for Gunicorn and one for Huey.\n. Hi,\nSorry but I gave up on doing that, so I can't send you the logs...\nThanks!\n. Hey,\nFollowing the questions above, is there an option to run multiple (2 in my case) consumers using Django.\nI have 2 types of tasks and I don't want them to affect each other. For example, one of the types could wait and block the consumer, and I want all other tasks from the same type to wait in line, but to keep running tasks from the second type.\nI hope it's possible using Huey.\nThanks!. Thanks for the quick reply. \nI guess I'll have to find a replacement (I love Huey!). \nI thought about django-rq. Do you have any recommendations? . The issue was I should have used datetime.datetime.utcnow()  :(\nClosing the issue. ",
    "felipe3dfx": "I want to set in cache the task_id, the tasks are schedule with a delay:\nupdate_task_id = update_delivery_minutes_change.schedule(\n    args=(instance.id,),\n    delay=(60 * 30)\n)\nso, i want get the uid from cache and know if the task was ended, if not, i revoke for create a new task\nbut the result always is None, in console i can see the task is queueing.\n. I use HUEY.scheduled() but when i tried revoke the task nothing happen on console,\nupdate_task_id = cache_location_tasks.get('update_task_id')\n    email_task_id = cache_location_tasks.get('email_task_id')\n    for event in HUEY.scheduled():\n        if event.task_id in [update_task_id, email_task_id]:\n            HUEY.revoke(event)\nis it the correct way to revoke a task?\n```\nIn [67]: HUEY.scheduled()\nOut[67]:\n[queuecmd_update_delivery_minutes_change: 89a77b56-9d19-4d2f-bb40-2b7e9788ae55 @2016-08-26 14:04:17,\n queuecmd_send_email: e6262126-cb03-418d-8d2b-885a24898548 @2016-08-26 14:04:17 3 retries,\n queuecmd_send_email: 7b83b099-a64c-42df-aaa2-336c1cd38395 @2016-08-26 14:04:26 3 retries,\n queuecmd_update_delivery_minutes_change: e6b33e23-92ba-4497-8991-514a243c559d @2016-08-26 14:04:26]\nIn [68]: for event in HUEY.scheduled(): print(HUEY.revoke(event))\nNone\nNone\nNone\nNone\n``\n. The revoke function works fine, but is confusing when is revoked a task its return is None\nThanks\n. i want test that the task is scheduled and schedule method return a task, with the task id i will save it in cache for ask it later for it and schedule it egain the task\n. the task has:@task(retries=3, retry_delay=(60*5), retries_as_argument=True)`\nWhen i try to create a functional test, it broken because the task raises exception for add a new retry, I need that the task run all retries and execute the code into the conditional.\nAny ideas?\n. The issue back using the following code:\nPython\nprocess_payment_success.schedule(\n    kwargs={\n        'payment_id': payment_id,\n        'retries': retries - 1,\n    },\n    delay=(60 * 10),\n    convert_utc=False,\n)\nredis-server 5.0.3\ndjango==2.1.5\nhuey==1.10.5\npython==3.6.7\nchannels_redis==2.3.3\ndjango-redis-cache==1.8.1\nAny ideas?. Error adding task to schedule: membership.tasks.queue_task_process_payment_success: e5a96f50-8e6f-41ef-bfb0-f25ebc99feaf @2019-01-31 14:57:37.034875\nacme==0.28.0\naioredis==1.2.0\nasgiref==2.3.2\nasn1crypto==0.24.0\nasync-timeout==3.0.1\nattrs==17.4.0\nautobahn==19.1.1\nAutomat==0.6.0\nbackcall==0.1.0\nbackports.tempfile==1.0\nbackports.weakref==1.0.post1\ncertbot==0.28.0\ncertifi==2018.1.18\nchannels==2.1.6\nchannels-redis==2.3.3\nchardet==3.0.4\nclick==6.7\ncolorama==0.3.7\ncommand-not-found==0.3\nConfigArgParse==0.11.0\nconfigobj==5.0.6\nconstantly==15.1.0\ncryptography==2.1.4\ndaphne==2.2.4\ndecorator==4.3.2\ndistro-info==0.18\ndj-inmemorystorage==1.4.1\nDjango==2.1.5\ndjango-admin-sortable==2.1.11\ndjango-appconf==1.0.2\ndjango-axes==4.5.4\ndjango-compressor==2.2\ndjango-debug-toolbar==1.11\ndjango-dynamic-fixture==2.0.0\ndjango-extensions==2.1.5\ndjango-ipware==2.1.0\ndjango-redis-cache==1.8.1\ndjango-test-plus==1.1.1\ndjango-widget-tweaks==1.4.3\nfail2ban==0.10.2\nfuture==0.15.2\ngunicorn==19.9.0\nh11==0.8.1\nhiredis==1.0.0\nhttplib2==0.9.2\nhttptools==0.0.11\nhuey==1.10.5\nhyperlink==17.3.1\nidna==2.6\nincremental==16.10.1\niotop==0.6\nipython==7.2.0\nipython-genutils==0.2.0\njedi==0.13.2\njosepy==1.1.0\nlanguage-selector==0.1\nlxml==4.3.0\nmock==2.0.0\nmsgpack==0.6.1\nndg-httpsclient==0.4.4\nnetifaces==0.10.4\nPAM==0.4.2\nparsedatetime==2.4\nparso==0.3.2\npbr==3.1.1\npexpect==4.6.0\npickleshare==0.7.5\nPillow==5.4.1\npiprot==0.9.10\nprompt-toolkit==2.0.7\npsycopg2-binary==2.7.7\nptyprocess==0.6.0\npyasn1==0.4.2\npyasn1-modules==0.2.1\nPygments==2.3.1\npygobject==3.26.1\nPyHamcrest==1.9.0\nPyICU==1.9.8\npyinotify==0.9.6\npyOpenSSL==17.5.0\nPyPDF2==1.26.0\npyRFC3339==1.0\npyserial==3.4\npython-apt==1.6.3\npython-debian==0.1.32\npython-magic==0.4.15\npytz==2018.9\nPyYAML==3.12\nraven==6.10.0\nrcssmin==1.0.6\nredis==2.10.6\nreportlab==3.5.13\nrequests==2.21.0\nrequests-futures==0.9.9\nrequests-toolbelt==0.8.0\nrequests-unixsocket==0.1.5\nrjsmin==1.0.12\nservice-identity==16.0.0\nsix==1.11.0\nsqlparse==0.2.4\nssh-import-id==5.7\nsystemd-python==234\ntblib==1.3.2\ntraitlets==4.3.2\nTwisted==18.9.0\ntxaio==18.8.1\nufw==0.35\nunattended-upgrades==0.1\nurllib3==1.22\nuvicorn==0.3.29\nuvloop==0.12.0\nwcwidth==0.1.7\nwebsockets==7.0\nz3c.rml==3.6.1\nzope.component==4.3.0\nzope.event==4.2.0\nzope.hookable==4.0.4\nzope.interface==4.6.0\nzope.schema==4.9.3\n. ",
    "kittles": "thanks. im queueing a bunch of tasks, then keeping track of their ids and listening to events to know when all have finished- is this the best way to handle this? figured id ask in case i missed something in the api and docs. \n```\npending_task_ids = []\nresults = []\nfor job in jobs:\n    result = run_task(job) # run_task is a huey task\n    pending_task_ids.append(result.task.task_id)\ntrack all tasks invoked, wait until they are all done\nfor event in huey.storage:\n# is there a good way to timeout of this loop if it goes on for too long?\n\n# handle finished events\nif event['status'] == EVENT_FINISHED:\n    # move the id to completed array\n    if event['id'] in pending_task_ids:\n        pending_task_ids.remove(event['id'])\n        results.append(huey.result(event['id']))\n    # check to see if all jobs are done\n    if len(pending_task_ids) == 0:\n        break\n\n```\n. ",
    "ivancarrancho": "@coleifer \nupdate that \nfrom huey.contrib.djhuey import HUEY\nHUEY.flush()\n. ",
    "amitt001": "I am not running huey with the example cron.sh script. I am using huey_consumer main.huey command.\n. Not passing any command and instantiating by this command- huey_consumer main.huey\n. ",
    "Gystark": "Thanks for the quick reply, the solution you have suggested should have come to my mind days ago.\n. ",
    "antwan": "The reason for this whole #202 #187 #190 etc is simple : The OptionParserHandler shouldn't be initialised with default values at all. When you run a consumer, it is instanciated with default options as per the ConsumerOption class settings. Having additional default options on top of it is redundant, and causes issues with DjHuey config being ignored.\nSee consumer_options.py files, all settings are defaulted twice, this definitely not good.. utc option has no effect because it's the default.\n@coleifer Can you please review #215 . @camilonova This implementation solves your problem but as @coleifer mentioned, it is now ignoring any command line arguments. The solution is to remove the default arguments completely (ie remove the line 33 here).\nIt would be better to have a proper options refactoring. See my comment.\n. It worked when patching the manage.py bootstrap script, as this is where the internal DB connection is made. Patching the actual command file doesn't work as it's too late.\n```\n!/usr/bin/env python\nimport os\nimport sys\nif 'run_huey' in sys.argv:\n    from gevent import monkey\n    monkey.patch_all()\nif name == \"main\":\n    os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"conf\")\n    from django.core.management import execute_from_command_line\n    execute_from_command_line(sys.argv)\n```\nI think it's worth mentioning that in the doc + troubleshooting, because :\n\nIt's not optional as stated, it's a mandatory thing to do.\nMost of the people use djhuey and there is no mention anywhere about how to do it properly using django.. Any comment @coleifer?. It's worth updating the docs and test config, (and discuss the drop of Django 1.7- here).. I have basically the same errors for all my failing tasks.\n\nEverytime it's trying to pickle the exception object and it crashes. I have to inspect the traceback of the traceback to find out what's the original error. It's very annoying.\nExample:\nTypeError: a class that defines __slots__ without defining __getstate__ cannot be pickled\n  File \"huey/consumer.py\", line 153, in process_task\n    self.huey.execute(task)\n  File \"huey/api.py\", line 277, in execute\n    self._put_error(pickle.dumps(metadata))\n  File \"python2.7/pickle.py\", line 1380, in dumps\n    Pickler(file, protocol).dump(obj)\n  File \"python2.7/pickle.py\", line 224, in dump\n    self.save(obj)\n  File \"python2.7/pickle.py\", line 286, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"python2.7/pickle.py\", line 655, in save_dict\n    self._batch_setitems(obj.iteritems())\n  File \"python2.7/pickle.py\", line 669, in _batch_setitems\n    save(v)\n  File \"python2.7/pickle.py\", line 331, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"python2.7/pickle.py\", line 425, in save_reduce\n    save(state)\n  File \"python2.7/pickle.py\", line 286, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"python2.7/pickle.py\", line 655, in save_dict\n    self._batch_setitems(obj.iteritems())\n  File \"python2.7/pickle.py\", line 669, in _batch_setitems\n    save(v)\n  File \"python2.7/pickle.py\", line 286, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"python2.7/pickle.py\", line 731, in save_inst\n    save(stuff)\n  File \"python2.7/pickle.py\", line 286, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"python2.7/pickle.py\", line 655, in save_dict\n    self._batch_setitems(obj.iteritems())\n  File \"python2.7/pickle.py\", line 669, in _batch_setitems\n    save(v)\n  File \"python2.7/pickle.py\", line 306, in save\n    rv = reduce(self.proto)\n  File \"python2.7/copy_reg.py\", line 77, in _reduce_ex\n    raise TypeError(\"a class that defines __slots__ without \"\nContext of the failure:\n\nSolution:\nSerialize the exception object before pickling.\nPlease reopen and fix the issue.. Exceptions can contain loads of misc data, for example HTTPError contains the request and response objects, both containing references to socket and miscellaneous objects.\nSo yes it's much better to serialize it beforehand.. Unless the defaults are true (this is why utc and no_periodic are not used).\nIt's not worth having the defaults set in the optparser in the first place at all, which is why I suggested to remove them.. ",
    "srj55": "This fix isn't working for me.  in my Django settings, the 'utc' option has no effect.  When I run 'run_huey', the only way to set utc is on the command line.   If I don't set it in the command line (--utc), then utc will always be False.. ",
    "smarnach": "@coleifer Thanks for issuing a new release so quickly!\n. ",
    "lockie": "This would be usable in scenario when you are processing large quantities of some items, which take long time. Then you can add two crontab jobs: one that processes only the latest few and called e.g. hourly, and one that tries to process all of them and called, say, weekly. The obvious method for this would be adding count parameter to the job function. Of course, you could refactor it to common function and call it from two distinct job functions, so the question is only matter of convenience.\n. ",
    "winkidney": "Sorry for my mistake, thanks a lot:). Great work!\nSince it is a breaking change, would you like to provide a method to keep compatible of the old version?\nBest Wishes. @Sebubu Sorry I missed it. It helps a lot : ). To resolve your problem, You should search google using  \"python package system\" or \"python absolute import\", etc. . ",
    "rstuart85": "Interesting. So if the volume of periodic tasks becomes too much then your only choice is to scale the consumer with the -w option. I'll keep that in mind.. I understand. My point is when you are relying on something like Kubernetes to do scaling rather than the -w option to a consumer, you are going to be limited on the bandwidth you can dedicate to periodic tasks because of the way they are implemented on the consumer side.\nIn contrast, Celery uses a special producer to put periodic tasks on the queue so they aren't tied to a specific consumer.. ",
    "tuukkamustonen": "\nI experimented locally with multiple consumers and it appears that one consumer gets scheduled all jobs. This appears to due to the backoff param and the jobs being short lived.\n\nI also ran similar experiment on top of the count_beans example in the docs (why beans?). I ran two consumer processes and when I started a batch of 100 jobs, one consumer ran them all while the other one sat idle. Then I added 100ms sleep inside count_beans(), and re-run 100 jobs. This time, roughly 50% were run by first worker and another 50% by second. There was no duplication of parameters (I ran for i in range(100): count_beans(i)).\nI would assume BRPOP that huey calls is safe for concurrent invocation (because Redis is single-threaded if not for anything else), but how about when there's a Redis cluster?\nI think huey polling Redis once per second (insteading of getting async ) may confuse the user. In the first test, without delay, I guess one worker just happened to hit Redis first and ran all the jobs quickly before the second one could poll anything. When I added some latency, both consumers found work.. Oh, right. So by default huey does RPOP. It executes that in interval defined by delay/backoff/max_delay.\nWhen you enable blocking=True, how long does huey worker keep the BRPOP open waiting for data? I see the default timeout is 1 (second), but is that timeout for reading the data when it becomes available? If it's timeout for wait time... will huey re-run brpop after timeout? I see nothing related to that in the logs.\n\nhuey polling Redis once per second\n\nLooks like this wasn't true either, I confused it with scheduler interval (1s by default). Scheduler runs future and periodic tasks and has no impact on running \"ad-hoc\" or instant tasks.\nStill about scalability: I'm no redis expert so by a quick glance it seems Redis \"simply\" shards data when run in a cluster. I see no reason why huey would not work also in such environment, though I assume you would need to run separate workers per cluster instance, to keep polling/waiting for data in every shard.. Yeah but what is that timeout exactly: If it is read timeout for receiving data when there is something to return, is there another timeout for defining how long huey waits for BRPOP to return something? And what happens after that timeout, a new BRPOP call?. Btw. I tested option (1) it so that in tasks.py:\nhuey = RedisHuey()\n\n@huey.task()\ndef foo():\n    ...\n\nIn main.py:\nfrom tasks import huey\n\ndef build_app(conf_dir):\n    # load configs and whatever\n\n    huey.__init__(...)\n\nIt seems to work but is ugly as... Peewee has Proxy, could I re-use it here?. Peewee's Proxy works just fine, but I'd like to suggest alternative API that supports calling class instances:\napp.py:\n```python\nfrom x import MessageClient\nfrom huey import RedisHuey\nfrom messenger import Messenger\ndef build_app(conf_dir):\nclient = MessageClient()\nmessenger = Messenger(client)\n\nhuey = RedisHuey()\nhuey.add_instance_task(messenger.send_message)  # register task handler into class instance\n\nreturn huey\n\n```\nmessenger.py:\n```python\nfrom huey import instance_task\nclass Messenger:\ndef __init__(self, client):\n    self.client = client\n\n@instance_task()  # would not register task, but wrap it either queueing to Redis or passthrough if always_eager is True\ndef send_message(self, message):  # self parameter would NOT be pickled/unpickled\n    self.client.send(...)\n\n```\nmain.py:\n```python\nfrom app import build_app\nif name == 'main':\n    huey = build_app('conf/')\n```\nRun huey_consumer main.huey as usual.\nThis way I wouldn't have to play with proxies or globals, I could use OO, IoC and different configurations in producer and consumer apps, and I wouldn't have to worry about import and init order.\nWhat do you think @coleifer ?. Sorry, I was busy in other experiments.\nYeah, it's about architecture. Rather than declaring stuff on module level, I tend to build applications in factories as suggested by Flask (http://flask.pocoo.org/docs/0.12/patterns/appfactories/) or DropWizard (http://www.dropwizard.io/1.0.5/docs/getting-started.html). I also like to inject dependencies when building the app and services, rather than accessing dependencies through globals/threadlocals (e.g. Flask's current_app.something) or by declaring instances at module level (or by not doing classes at all). This makes testing (mocking) so much easier and avoids a few problems with import order etc.\nIn my case, I would like to intialize huey the same way I initialize a Flask app (=app factory), so it could re-use the existing code.\nYeah, there are workarounds to bolt huey to such architecture. To load config:\n\n\nThe one I referred to earlier: using peewee's Proxy.\n\n\nWhat you suggested: just loading the config and instantiate huey within the same module:\n\n\nWhichever the approach, the problem is this:\nconfig.py:\n```python\nfrom huey import RedisHuey\nconfig = ...  # load config based on os.environ['CONFIG_PATH'] or something\nhuey = RedisHuey(config)\n```\napp.py:\n```python\ndef build_app():\n    ...\nclient = MessageClient(config['url'])\nnotifier = Notifier(client)\n\nfrom config import huey  # to initialize\nimport tasks  # to run the task decorators\n\n```\ntasks.py:\n```python\nfrom huey import huey\n@huey.task()\ndef send_msg(message):\n    ...  # the problem is here, how can I get hold of notifier that was built in build_app()?\n```\nWorkarounds to access notifier:\n\n\nAttach instances to huey instance (or it could be anything globally accessible), for example in app.py:\n```python\ndef build_app():\n    ...\nhuey.notifier = notifier\n\n```\ntasks.py:\npython\n@huey.task()\ndef send_msg(message):\n    huey.notifier.send(message)\n\n\nRe-construct dependencies within the function like:\npython\n@huey.task()\ndef send_msg(message):\n    ...  # load configs based on os.environ['CONFIG_PATH'] etc.\n    client = MessageClient(config['url'])\n    notifier = Notifier(client)\n    huey.notifier.send(message)\nNow this would be super clumsy.\n\n\nDon't use classes and just do functions... uh...\n\n\nSo... there are options, but it gets ugly. And testing gets difficult. Maybe I'm missing something here...\n\nIn any case, I tried decorating the instance method on the fly:\n```python\ndef build_app():\n    ...\nhuey = RedisHuey('messages')\nnotifier.send = huey.task()(notifier.send)\n\n...\n\n```\nIn service.py:\n```python\nclass Notifier:\n    def init(self, client):\n        self.client = client\ndef send(self, message):\n    self.client.send...\n\n```\nSo rather than decorating a function, I'm decorating an instance method here.\nThe problem with this is that huey saves attributes to the decorated function (https://github.com/coleifer/huey/blob/master/huey/api.py#L107-L108), and that's not allowed for instance method. So, I commented out those lines for a test, and it seems to work (it also avoids pickling self).\nSo... could we store the function attributes to Huey instance instead (a dict or like)? Would that change break/prevent something? It would open up this usage pattern (OO, app factories, IOC, whatever is the right term, I believe it's pretty common).\n(Finally, if user wants to pickle the whole class instance, which sounds risky performance & security wise, he can just decorate a method as usual so no change of behavior here:)\n```python\nclass Notifier:\n    ...\n@heuy.task()\ndef send(self, message):\n    ...\n\n```. Of course. For some reason I read \"no periodic\" as \"no scheduled\".... Alright, it's a good feature per se, but there's a workaround that I'm using at the moment (works on bash at least):\nhuey_consumer ... & echo $! > /var/run/huey.pid\n\nThat may not suit more complicated scenarios, but it works for my needs now.. Thanks, I don't know much about linux signals, but I've seen TERM and INT used in different ways. For example gunicorn uses TERM for graceful shutdown and INT for forceful shutdown. Recommendations seem to vary?\nI think OS (linux) first sends TERM signal, then waits X seconds, until it sends KILL, though I'm not sure about that.. Yeah, I read the same source. But I fear that's one just interpretation. Normally when you Ctrl-C something, it gets force killed. And on the other hand, even that source says that TERM may be gracefully handled.\nAnyway, I also ran the script given in https://askubuntu.com/a/819768 on my Ubuntu 12.04 LTS vm (I added catching of SIGINT and SIGQUIT signals to script). The result for shutdown -h now:\nrunning\nrunning\nrunning\nrunning\nrunning\nignoring signal 1  # this is HUP\nrunning\nrunning\nrunning\nrunning\ncaught SIGTERM                                                                                                                                                                                                                                              \n0.0000s after stop                                                                                                                                                                                                                                          \n0.1024s after stop                                                                                                                                                                                                                                          \n0.2026s after stop                                                                                                                                                                                                                                          \n0.3031s after stop                                                                                                                                                                                                                                          \n...<SNIP>...\n10.2122s after stop\n10.3134s after stop\n10.4138s after stop\n10.5141s after stop\n<log ends here so I guess it got SIGKILLed>\nThere was no SIGINT given. I think with current implementation (be it semantically correct or not), at shutdown huey will get force killed.. Yeah, so some simple retry loop (wait x, retry y times)?. Thanks, two observations:\n\nWhen Redis goes away (locally tested by just shutting down redis), the logs get flooded by:\n\n2017-07-07 12:04:01,751 - redis - DEBUG - Executed query (0 ms): BRPOP 'huey.redis.localhuey' 20\n2017-07-07 12:04:01,752 - redis - DEBUG - Executed query (0 ms): BRPOP 'huey.redis.localhuey' 20\n2017-07-07 12:04:01,753 - redis - DEBUG - Executed query (0 ms): BRPOP 'huey.redis.localhuey' 20\n...\nCould huey try reconnecting in a little bit of slower pace instead of as quick as possible? Maybe configurable option for delay between retry attempts?\n\nRetrying indeed works, after restoring redis, it's back to polling every second instead:\n\n2017-07-07 12:05:01,166 - redis - DEBUG - Executed query (0 ms): EVALSHA 'a08640cb6d2244b627dffdfd70c3f445d8c9cf2c' 1 'huey.schedule.localhuey' 1499407501.0\n2017-07-07 12:05:02,167 - redis - DEBUG - Executed query (0 ms): EVALSHA 'a08640cb6d2244b627dffdfd70c3f445d8c9cf2c' 1 'huey.schedule.localhuey' 1499407502.0\n2017-07-07 12:05:03,169 - redis - DEBUG - Executed query (0 ms): EVALSHA 'a08640cb6d2244b627dffdfd70c3f445d8c9cf2c' 1 'huey.schedule.localhuey' 1499407503.0\nHowever, the problem is that huey consumer may now eternally stay in a state where it cannot connect to cache. This means connectivity problems can go unnoticed, as the process is there, but it just never works. Would it be possible to specify max retry attempts?. Ok this seems to reproduce only when you run with blocking=True.\nStart:\n2017-07-07 14:36:47,309 - huey.consumer - INFO - Huey consumer started with 1 thread, PID 6718                                                                                                                                             \n2017-07-07 14:36:47,309 - huey.consumer - INFO - Scheduler runs every 1 seconds.                                                                                                                                                           \n2017-07-07 14:36:47,310 - huey.consumer - INFO - Periodic tasks are enabled.                                                                                                                                                               \n2017-07-07 14:36:47,310 - huey.consumer - INFO - UTC is enabled.                                                                                                                                                                           \n2017-07-07 14:36:47,310 - huey.consumer - INFO - The following commands are available:                                                                                                                                                     \n+ send_push_messages                                                                                                                                                                                                                       \n2017-07-07 14:36:47,311 - redis - DEBUG - Executed query (0 ms): EVALSHA '' 1 'huey.schedule.localhuey' 1499416607.0                                                                                                                       \n2017-07-07 14:36:47,311 - redis - DEBUG - Executed query (0 ms): SCRIPT LOAD \"local key = KEYS[1]\\nlocal unix_ts = ARGV[1]\\nlocal res = redis.call('zrangebyscore', key, '-inf', unix_ts)\\nif #res and redis.call('zremrangebyscore', key, '-inf', unix_ts) == #res then\\n    return res\\nend\"                                                                                                                                                                                        \n2017-07-07 14:36:47,311 - redis - DEBUG - Executed query (0 ms): EVALSHA 'a08640cb6d2244b627dffdfd70c3f445d8c9cf2c' 1 'huey.schedule.localhuey' 1499416607.0                                                                               \n2017-07-07 14:36:47,312 - redis - DEBUG - Executed query (1 ms): BRPOP 'huey.redis.localhuey' 20                                                                                                                                           \n2017-07-07 14:36:48,312 - redis - DEBUG - Executed query (0 ms): EVALSHA 'a08640cb6d2244b627dffdfd70c3f445d8c9cf2c' 1 'huey.schedule.localhuey' 1499416608.0                                                                               \n2017-07-07 14:36:49,317 - redis - DEBUG - Executed query (0 ms): EVALSHA 'a08640cb6d2244b627dffdfd70c3f445d8c9cf2c' 1 'huey.schedule.localhuey' 1499416609.0                                                                               \n2017-07-07 14:36:50,319 - redis - DEBUG - Executed query (0 ms): EVALSHA 'a08640cb6d2244b627dffdfd70c3f445d8c9cf2c' 1 'huey.schedule.localhuey' 1499416610.0                                                                               \n...\nShutdown Redis:\n2017-07-07 14:37:11,351 - redis - DEBUG - Executed query (0 ms): EVALSHA 'a08640cb6d2244b627dffdfd70c3f445d8c9cf2c' 1 'huey.schedule.localhuey' 1499416631.0\n2017-07-07 14:37:12,352 - redis - DEBUG - Executed query (0 ms): EVALSHA 'a08640cb6d2244b627dffdfd70c3f445d8c9cf2c' 1 'huey.schedule.localhuey' 1499416632.0\n2017-07-07 14:37:12,864 - redis - DEBUG - Executed query (0 ms): BRPOP 'huey.redis.localhuey' 20\n2017-07-07 14:37:12,866 - redis - DEBUG - Executed query (0 ms): BRPOP 'huey.redis.localhuey' 20\n2017-07-07 14:37:12,868 - redis - DEBUG - Executed query (0 ms): BRPOP 'huey.redis.localhuey' 20\n2017-07-07 14:37:12,869 - redis - DEBUG - Executed query (0 ms): BRPOP 'huey.redis.localhuey' 20\n...<BRPOP continues flooding>...\nA bit later (see timestamps):\n```\n2017-07-07 14:37:13,353 - redis - DEBUG - Executed query (0 ms): EVALSHA 'a08640cb6d2244b627dffdfd70c3f445d8c9cf2c' 1 'huey.schedule.localhuey' 1499416633.0\n2017-07-07 14:37:13,353 - redis - DEBUG - Executed query (0 ms): BRPOP 'huey.redis.localhuey' 20\n2017-07-07 14:37:13,354 - redis - DEBUG - Executed query (0 ms): BRPOP 'huey.redis.localhuey' 20\n2017-07-07 14:37:13,354 - redis - DEBUG - Executed query (0 ms): EVALSHA 'a08640cb6d2244b627dffdfd70c3f445d8c9cf2c' 1 'huey.schedule.localhuey' 1499416633.0\n2017-07-07 14:37:13,354 - huey.consumer.Scheduler - ERROR - Error reading from task schedule.\nTraceback (most recent call last):\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/redis/connection.py\", line 129, in _read_from_socket\n    raise socket.error(SERVER_CLOSED_CONNECTION_ERROR)\nOSError: Connection closed by server.\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/redis/client.py\", line 573, in execute_command\n    return self.parse_response(connection, command_name, **options)\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/redis/client.py\", line 585, in parse_response\n    response = connection.read_response()\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/redis/connection.py\", line 577, in read_response\n    response = self._parser.read_response()\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/redis/connection.py\", line 238, in read_response\n    response = self._buffer.readline()\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/redis/connection.py\", line 168, in readline\n    self._read_from_socket()\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/redis/connection.py\", line 143, in _read_from_socket\n    (e.args,))\nredis.exceptions.ConnectionError: Error while reading from socket: ('Connection closed by server.',)\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/redis/connection.py\", line 439, in connect\n    sock = self._connect()\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/redis/connection.py\", line 494, in _connect\n    raise err\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/redis/connection.py\", line 482, in _connect\n    sock.connect(socket_address)\nConnectionRefusedError: [Errno 111] Connection refused\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/huey/api.py\", line 171, in inner\n    return fn(args, kwargs)\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/huey/api.py\", line 216, in _read_schedule\n    return self.storage.read_schedule(ts)\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/huey/storage.py\", line 181, in read_schedule\n    tasks = self._pop(keys=[self.schedule_key], args=[unix_ts])\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/redis/client.py\", line 2694, in call\n    return client.evalsha(self.sha, len(keys), args)\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/redis/client.py\", line 1944, in evalsha\n    return self.execute_command('EVALSHA', sha, numkeys, keys_and_args)\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/redis/client.py\", line 578, in execute_command\n    connection.send_command(args)\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/pastry/extension/redis.py\", line 23, in send_command\n    super(XConnection, self).send_command(args)\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/redis/connection.py\", line 563, in send_command\n    self.send_packed_command(self.pack_command(args))\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/redis/connection.py\", line 538, in send_packed_command\n    self.connect()\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/redis/connection.py\", line 442, in connect\n    raise ConnectionError(self._error_message(e))\nredis.exceptions.ConnectionError: Error 111 connecting to 127.0.0.1:6379. Connection refused.\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/huey/consumer.py\", line 233, in loop\n    task_list = self.huey.read_schedule(now or self.get_utcnow())\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/huey/api.py\", line 333, in read_schedule\n    for m in self._read_schedule(ts)]\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/huey/api.py\", line 175, in inner\n    wrap_exception(exc_class)\n  File \"/home/musttu/Code/virtualenvs/cosmos/lib/python3.4/site-packages/huey/utils.py\", line 49, in wrap_exception\n    raise new_exc_class('%s: %s' % (exc_class.name, exc))\nhuey.exceptions.ScheduleReadException: ConnectionError: Error 111 connecting to 127.0.0.1:6379. Connection refused.\n2017-07-07 14:37:13,355 - redis - DEBUG - Executed query (0 ms): BRPOP 'huey.redis.localhuey' 20\n2017-07-07 14:37:13,363 - redis - DEBUG - Executed query (0 ms): BRPOP 'huey.redis.localhuey' 20\n2017-07-07 14:37:13,363 - redis - DEBUG - Executed query (0 ms): BRPOP 'huey.redis.localhuey' 20\n......\n```\nThis stacktrace is thrown every second.\nThen until I start Redis again:\n2017-07-07 14:37:16,363 - redis - DEBUG - Executed query (0 ms): BRPOP 'huey.redis.localhuey' 20\n2017-07-07 14:37:16,364 - redis - DEBUG - Executed query (0 ms): BRPOP 'huey.redis.localhuey' 20\n2017-07-07 14:37:16,364 - redis - DEBUG - Executed query (0 ms): BRPOP 'huey.redis.localhuey' 20\n2017-07-07 14:37:17,358 - redis - DEBUG - Executed query (0 ms): EVALSHA 'a08640cb6d2244b627dffdfd70c3f445d8c9cf2c' 1 'huey.schedule.localhuey' 1499416637.0\n2017-07-07 14:37:17,360 - redis - DEBUG - Executed query (0 ms): SCRIPT LOAD \"local key = KEYS[1]\\nlocal unix_ts = ARGV[1]\\nlocal res = redis.call('zrangebyscore', key, '-inf', unix_ts)\\nif #res and redis.call('zremrangebyscore', key, '-inf', unix_ts) == #res then\\n    return res\\nend\"\n2017-07-07 14:37:17,361 - redis - DEBUG - Executed query (0 ms): EVALSHA 'a08640cb6d2244b627dffdfd70c3f445d8c9cf2c' 1 'huey.schedule.localhuey' 1499416637.0\n2017-07-07 14:37:18,358 - redis - DEBUG - Executed query (0 ms): EVALSHA 'a08640cb6d2244b627dffdfd70c3f445d8c9cf2c' 1 'huey.schedule.localhuey' 1499416638.0\nAnd now it's back to polling once per second.. I am manually re-queueing the \"gracefully failed\" tasks with something like:\npython\n@huey.task()\ndef task_handler(...):\n    try:\n        ...\n    except RemoteServerUnavailable:\n        task.handler.schedule(...)\nIt's pretty straightforward and not bringing much boilerplate, plus manually re-queueing allows to multiply the delay with backoff factor and add some jitter (though these could be built-in huey features also).\nBut yeah, if I could just raise RetryException or similar, it would still be a bit less code to write / things to take care of.. ",
    "whoiswes": "FYI, in case anyone is googling this like I did, here's how I accomplished a decorator-based locking method in a somewhat generic way.  Has not been exhaustively tested, no warranty, not responsible for global thermonuclear war, etc.\nConstructive feedback welcome if anyone has a better way.\ndef lock(fn):\n    @functools.wraps(fn)\n    def inner(*args, **kwargs):\n        # Put KV object with key as wrapped func name + timestamp\n        lock = huey.storage.put_if_empty('{}-{}'.format(fn.__name__, datetime.datetime.utcnow().replace(second=0, microsecond=0).isoformat()), None)\n        if not lock:\n            return\n        return fn(*args, **kwargs)\n    return inner\nEDIT:  I should note that I use this with scheduled tasks, it probably won't work right for regular tasks without modification.. @coleifer - I was aware of the lock_task decorator, but that doesn't work with scheduled tasks when you have multiple instances of the consumer running, correct?\nI have a n+1 node application where each node is running a full app stack for redundancy/failover purposes (so, wsgi + huey processes).  Adding lock_task doesn't seem to prevent multiple scheduled task invocations, so if I have three nodes active, I get three scheduled task invocations.  I haven't exhaustively tested normal tasks as my use case is all about cron-style jobs.\nI might be missing something obvious, and apologize if I am, but in other, similar issues, you've stated to perform any task locking outside of huey, which is what I attempted to do above (and it seems to work, for my use case(s), at least).\n. ",
    "nikhil1910": "Thanks for the reply. As you stated my server was out of memory and hence the workers were killed by the OS. But also this issue happened when i was working with processes and not threads or greenlets. But huey is really and i hope you make it more better. And my problem is solved and hence i'm closing this issues.\nThank you very much!!!. ",
    "rahuldeve": "Ive run into the same issue on a windows machine. The_run() function inside the Consumer class is not pickle friendly. I tried changing the multiprocessing library to multiprocess hoping that dill would solve the issue but I just got another pickling error:\nTypeError: cannot serialize '_io.TextIOWrapper' object\nThis looks like a very low level issue so I think its safe to say that huey will not run on windows with multi-process workers. Yes but unfortunately my production server is windows based. For now I think I can create a separate set of \"async\" functions that calls the normal functions in a newly spawned process and tag those async functions as huey tasks. Anyways I think its best to mention about this issue in the docs somewhere.. ",
    "prokher": "Unfortunately there are multibillion industries where Windows is dominating (e.g. mechanical engineering), so the software developed needs to be cross-platform.. ",
    "ricosuave73": "Just a suggestion/FYI, there are more Python projects struggling with this problem. I read some projects just writing the issue off as 'not supported on Windows', because Windows doesn't have the fork() system call like Linux does. Instead it uses a spawn() call, which is not the same.\nBut I also saw a workaround/fix used in the chainer deep-learning framework that replaces pickle with dill, which does seems to work for them: https://github.com/chainer/chainerrl/issues/175\n. ",
    "mctinetti": "I will take your advice :+1: \nThank you for your quick answer!   . ",
    "achidlow": "Just got bitten by this. It'd be nice if the documentation mentioned this explicitly in the Django section. The examples all use 'greenlet' as the worker type, but no mention is made that run_huey requires patching to work. It's even more confusing that the failure is totally silent.\n(And thanks for the awesome project.). ",
    "JordanReiter": "I'm very sorry. I got inundated with work and haven't had any time for any spare time coding. I apologize for not responding. \nTo answer your question, I was hoping it might be possible to support AWS services (possibly SQS?). ",
    "StevenMedina": "Yes, please I am updating libraries and I do not know what changes there were from 1.3.1 to 1.4. ",
    "john-bonachon": "Great. Thanks for replying. Good idea. ",
    "hargup": "\nHere is the screenshot, cons.sh is highlighted in red. (Sorry, there were typos in the issue description, I have fixed it now.). ",
    "Sebubu": "@winkidney All the old configurations are still working with this pull request. It only adds a new way to use several huey instances. Thus it is not a breaking change.. This commit above fixes a bug in djhuey which always started the consumer with one thread.\nI really don't know why this bug fix lets one test fail. The changes have nothing to do with the main huey code.. I can make that. I'm currently busy in another project but I try to do that till the 24. february.\nMaybe I need your help briefly @coleifer in order to fix one test which didn't run the last time and I had no clue why.\n. > Although, perhaps it makes sense to attach a TaskRegistry to a particular huey instance? That's another possibility, but the above options should work in the meantime.\nI thought about something like that. The periodic task decorator is already integrated into the huey instance. Why not move the TaskRegistry to there?\nIm going to use the --no-periodic as a short term solution. I hope I will find time to move the TaskRegistry. Unfortunately, it looks like a bigger refactoring.. ",
    "Gasoid": "@Sebubu  Is it stable? We are looking forward this PR)). ",
    "ilyinon": "It looks amazing!  \n@coleifer Could you please answer,  are you planning to merge it into master?. ",
    "MarcoGlauser": "As @Sebubu is on holiday, I took over this PR.\n@coleifer I did a rebase patch and merged your master. \nBut the tests are failing and i cannot figure out why because the PR only changes files in djhuey. can you point me into the right direction?. after some more digging I found the culprit. The problem was that the django test runner also tried running all non django tests and failed. now that i configured the django runner only to discover djhuey test it works.. Rebased and removed duplicate closing of the old connections.\nThe API was introduced in django 1.6.. By the way thanks for creating and maintaining huey! We use it for a couple million events every day and it works like a charm!. sorry for the trouble you had with this patch. I didn't review it in detail, only fixed the merge conflicts. what are the next steps considering this issue? Do you still want to add it at a later time with better coverage? . In this case it would actually be easier to listen for an additional event and just calculate enqueud - started. Because i'm just forwarding the events and prometheus does all aggregation. with queue_size i'd have to add threading to poll it regularly. are you opposed to add an event on the producer side?. I subclassed RedisHuey and overrode the enqueue method there because i could use the emit_task method offered by the api. Thanks for your help!\nThe prometheus exporter can be found here if anyone is intersted. https://github.com/MarcoGlauser/huey-exporter. We just got this finished so there are probably some bugs flying around.. This is the same behaviour as django. Before every request old/broken connections get closed and after every request old/broken connections get closed.\nFrom https://github.com/django/django/blob/master/django/db/init.py\npython\nsignals.request_started.connect(close_old_connections)\nsignals.request_finished.connect(close_old_connections)\nI'm not 100% sure but my guess would be so that it closes broken/old connections from the pool before it starts processing a request.\nBut I can change it to only close old connections after the job.. ",
    "vaskokj": "I don't think its how I'm doing the import on my side but how huey specifically the huey_consumer.py is dealing with importing the information.\nhuey_test/hueytest\n    main.py\n    __init__.py\nhuey_test/hueytest/conf\n    test.py\n    __init__.py\nmain.py:\n```\nfrom hueytest.conf.test import testval\nif name = 'main':\n    print (testval)\n```\ntest.py:\ntestval = 234\nIn a command prompt relative to the huey_test folder...\n   C:\\Users\\Documents\\dev\\huey_test> python hueytest\\main.py \n   234\nHuey (huey_consumer.py) seems to want things in the same directory or relative to its own \"path\". For example the same pattern above does not work. \nhuey_test/hueytest\n    main.py\n    __init__.py\nhuey_test/hueytest/conf\n    config.py\n    __init__.py\nmain.py:\n```\nfrom hueytest.conf.config import huey\nif name == 'main':\n     print (huey)\n```\nconfig.py:\n```\nfrom huey import RedisHuey\nhuey = RedisHuey('simple.test')\n```\nIn a command prompt relative to the huey_test folder...(same as above)\n   C:\\Users\\Documents\\dev\\huey_test> python \"C:\\Program Files\\Anaconda3\\Scripts\\huey_consumer.py\" hueytest\\main.py \n\u001b[91mError importing hueytest\\main.huey\u001b[0m\nTraceback (most recent call last):\n  File \"C:\\Program Files\\Anaconda3\\Scripts\\huey_consumer.py\", line 51, in <module>\n    consumer_main()\n  File \"C:\\Program Files\\Anaconda3\\Scripts\\huey_consumer.py\", line 43, in consumer_main\n    huey_instance = load_huey(args[0])\n  File \"C:\\Program Files\\Anaconda3\\Scripts\\huey_consumer.py\", line 18, in load_huey\n    return load_class(path)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\huey\\utils.py\", line 44, in load_class\n    __import__(path)\nImportError: No module named 'hueytest\\\\main'\n. I apologize. I see what I did wrong. Nothing was wrong with my imports in the actual python code, but what was being sent to huey_consumer.py as the parameters. \nI had:\nC:\\Users<username>Documents\\dev\\huey_test> python \"C:\\Program Files\\Anaconda3\\Scripts\\huey_consumer.py\" **hueytest\\main.huey**\nI thought you were looking for an actual PATH to the object and not the object itself. So instead of hueytest\\main.huey I should have sent hueytest.main.huey as the parameters. \nThis is for anyone else that runs into the same problem.\n. Awesome! Thanks! Appreciate the information, changes and quick feedback!. ",
    "ajurna": "i was under the impression from #207 that i could just change the validator function and this would allow me to run a task at an arbitrary time in seconds.\nBut it appears the scheduler is designed to only run periodic tasks once a minute.\ni'm looking into this to see if it is a trivial fix to allow per second scheduling. created a PR #238 with the fix i applied. if you had any comments on why this would be bad please let me know.. after thinking about what you said and looking at issues with the scheduler locking up i came up with a better solution.\nif you need tasks at a sub minute interval make a governer task that queues up hte next minutes work.\nIt will not be 100% precise but it will allow you to approximate sub minute times. example below.\nThis works close to 15 seconds but it can be off by ~2 seconds either way.\n@periodic_task(crontab(minute='*'), name='monitor_huey')\ndef monitor_huey():\n    do_monitor_work.schedule(delay=15)\n    do_monitor_work.schedule(delay=30)\n    do_monitor_work.schedule(delay=45)\n    do_monitor_work.schedule(delay=60)\n\n. Nope. I ended up writing a separate service to handle that functionality. . @tehfink unfortunately i don't have a config. after doing some testing i ran into lots of issues with by the second scheduling that ended up in abandoning this. as i said i rewrote the part that i wanted to update this often as a service.. ",
    "tehfink": "@ajurna : Have you worked out an efficient way for scheduling such tasks with a delay longer than 60s?. @coleifer : ajurna's code suggestion uses various values for delay, e.g.:\n\ndo_monitor_work.schedule(delay=60). @coleifer: thanks for the reply. By asking about a \u2018delay\u2019 larger than 60s, I was referring to how to simulate dynamic periodic tasks (like in celery-beat), since it doesn\u2019t seem that Huey natively supports this?\n\n\n@ajurna: would you mind sharing your config, if possible?. @coleifer: thanks for the reply. Could you give examples of working code? Because I tried your suggestions here, but they resulted in errors\u2026. > one_func_cron = huey.periodic_task(crontab(...))(one_func)\nHave things changed much since you wrote this? With Django 2.0.2 and huey 1.9, I get this error:\n```python\n]: huey.contrib.djhuey.periodic_task(crontab(minute='*/1'))(tasks.count_beans(20))\n\nAttributeError                            Traceback (most recent call last)\n in ()\n----> 1 huey.contrib.djhuey.periodic_task(crontab(minute='*/1'))(tasks.count_beans(20))\n~/Documents/Code/\u2026-virtualenv/lib/python3.6/site-packages/huey/api.py in decorator(func)\n    150                 default_retry_delay=retry_delay,\n    151                 validate_datetime=method_validate,\n--> 152                 **task_settings)\n    153 \n    154         return decorator\n~/Documents/Code/\u2026-virtualenv/lib/python3.6/site-packages/huey/api.py in init(self, huey, func, retries, retry_delay, retries_as_argument, include_task, name, task_base, task_settings)\n    573             name,\n    574             include_task,\n--> 575             task_settings)\n    576         self.huey.registry.register(self.task_class)\n    577 \n~/Documents/Code/\u2026-virtualenv/lib/python3.6/site-packages/huey/api.py in create_task(task_class, func, retries_as_argument, task_name, include_task, **kwargs)\n    848 \n    849     if not task_name:\n--> 850         task_name = 'queue_task_%s' % (func.name)\n    851 \n    852     return type(task_name, (task_class,), attrs)\nAttributeError: 'TaskResultWrapper' object has no attribute 'name'\n. Thanks for the reply! Unfortunately, the same error still crops up:python\nhuey.contrib.djhuey.periodic_task(crontab(minute='*/1'))(tasks.count_beans)\n\nAttributeError                            Traceback (most recent call last)\n in ()\n----> 1 huey.contrib.djhuey.periodic_task(crontab(minute='*/1'))(tasks.count_beans)\n~/Documents/Code/\u2026virtualenv/lib/python3.6/site-packages/huey/api.py in decorator(func)\n    150                 default_retry_delay=retry_delay,\n    151                 validate_datetime=method_validate,\n--> 152                 **task_settings)\n    153 \n    154         return decorator\n~/Documents/Code/\u2026virtualenv/lib/python3.6/site-packages/huey/api.py in init(self, huey, func, retries, retry_delay, retries_as_argument, include_task, name, task_base, task_settings)\n    573             name,\n    574             include_task,\n--> 575             task_settings)\n    576         self.huey.registry.register(self.task_class)\n    577 \n~/Documents/Code/\u2026virtualenv/lib/python3.6/site-packages/huey/api.py in create_task(task_class, func, retries_as_argument, task_name, include_task, **kwargs)\n    848 \n    849     if not task_name:\n--> 850         task_name = 'queue_task_%s' % (func.name)\n    851 \n    852     return type(task_name, (task_class,), attrs)\nAttributeError: 'TaskWrapper' object has no attribute 'name'\n```. Thanks for the help. Still getting used to huey!\n\ncount_beans_cron = huey.periodic_task(crontab(minute='*/1'))(count_beans)\n\nI assume you meant: count_beans_cron = huey.contrib.djhuey.periodic_task(crontab(minute='*/1'))(count_beans) ?\nExcuting this:\n```python\nIn [9]: count_beans_cron = huey.contrib.djhuey.periodic_task(crontab(minute='*/1'))(count_beans)\nIn [10]: count_beans_cron\nOut[10]: \nIn [11]: count_beans_cron(10)\nOut[11]: \ngives this result in `python manage.py run_huey`:\nINFO:huey.consumer.Worker:Executing gather.tasks.queue_task_count_beans: c254743c-2ec9-4f5f-8826-6ec8b1aeadc2\n-- counted 10 beans -\n``\nI was hoping to see something like:INFO:huey.consumer.Scheduler:Scheduling periodic task\u2026`?. After going over the documentation again, I'm not sure if Huey will allow my intended-use. From here:\nhttp://huey.readthedocs.io/en/latest/imports.html\n\nBecause of the way this works, it is strongly recommended that all decorated functions be imported when the consumer starts up.\n\nI want to allow a user to dynamically create a periodic task via the admin: after clicking 'save' on a PeriodicTaskModel with cron_frequency of 60 seconds, is it possible/safe to create a new Huey task using arguments (e.g.: title, owner, cron_frequency, etc.)? And would it be better to trigger this using post_save or in the model's save()?. > dynamic task metadata, spawning tasks as necessary.\nBut would this work with periodic tasks? And what would be the benefit over creating a task after a model's save()?. Sorry if it's a stupid question, I guess I don't really understand from the documentation?. @coleifer  Trying to follow your code from above:\n\ndef count_beans(n):\nprint('Counted %s beans.' % n)\ncount_beans_task = huey.task()(count_beans)\n\nand assuming:\npython\nfrom huey.contrib.djhuey import HUEY as huey\nIs it correct?\nThen:\npython\nIn [5]: count_beans_task(5)\nOut[5]: <huey.api.TaskResultWrapper at 0x10d9c9ba8>\nResults in this error from python manage.py run_huey --huey-verbose:\npython\nERROR:huey.consumer.Worker:Queue exception\nTraceback (most recent call last):\n  File \"/Users/\u2026virtualenv/lib/python3.6/site-packages/huey/consumer.py\", line 113, in loop\n    task = self.huey.dequeue()\n  File \"/Users/\u2026virtualenv/lib/python3.6/site-packages/huey/api.py\", line 302, in dequeue\n    return self.registry.get_task_for_message(message)\n  File \"/Users/\u2026virtualenv/lib/python3.6/site-packages/huey/registry.py\", line 87, in get_task_for_message\n    klass = self.get_task_class(klass_str)\n  File \"/Users/\u2026virtualenv/lib/python3.6/site-packages/huey/registry.py\", line 73, in get_task_class\n    raise QueueException('%s not found in TaskRegistry' % klass_str)\nhuey.exceptions.QueueException: queue_task_count_beans not found in TaskRegistry. Thanks for the explanation! Very helpful. Thanks for your help. Sorry for the confusion; I'm not really sure what the correct term is for the incorrect data saved to the database. Perhaps \"scrambled\"?\nFor example:\n- the scheduler_minutely function iterates over a queryset of two active Django models\n- the call_recurring_obj function, decorated by @db_task, is called for each object\n- the run_huey --no-periodic --workers=5 process begins working on both\n- each object's recur() method performs a calculation and saves the results on the object via Django's standard save() method\nHowever, the results saved for object A are sometimes (clearly) from object B and vice versa, as well as unsaved object attributes (calculated as intermediary values and output to a log file). There's no issue with lost or corrupted saved data when the queryset contains only a single model.\nI've updated the settings.py above with database connection info.. ",
    "BennyAlex": "@coleifer \nBut sunday 0 is still a bit weird, maybe allow that 7 is sunday too?\nThen it would match pythons isoweekday (1=Mon, 7=Sun). ",
    "rajeshyogeshwar": "Wow, I did not know that. I should be looking at alternative solutions in that case. Thanks.. ",
    "nachtmaar": "May I ask you why you don't like the changes?\nDon't you like the hooks or the retry exception? \nI built some tooling around Huey, hence I needed the hooks. There is a tool to retry failed tasks. The failed tasks are stored by the hooks in a separate queue in addition to the already existing error queue (does not contain the actual task data.\nMoreover, I want to report failed task to a service which requires hooks too. Of course I can start and maintain my own fork, but incorporating the changes into the real Huey would be great.\n. ",
    "expresspotato": "I get this when an exception is raised... Which huey would handle this a bit more gracefully as the exceptions thrown could be out of my control without wrapping them in a try catch. \nTypeError: can't pickle traceback objects. So no original exception is thrown so not even sure why a traceback is being generated...\n[2017-12-13 22:00:08,816] INFO:huey.consumer.Worker:10104:Executing helium.tasks.tasks.send_communications_later: 1bb4891a-ab65-4826-9168-addc40716c2d\n[2017-12-13 22:00:08,823] ERROR:huey.consumer.Worker:10104:Unhandled exception in worker thread\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/site-packages/huey/consumer.py\", line 168, in process_task\n    task_value = self.huey.execute(task)\n  File \"/usr/lib/python2.7/site-packages/huey/api.py\", line 375, in execute\n    self._put_error(pickle.dumps(metadata))\n  File \"/usr/lib64/python2.7/pickle.py\", line 1374, in dumps\n    Pickler(file, protocol).dump(obj)\n  File \"/usr/lib64/python2.7/pickle.py\", line 224, in dump\n    self.save(obj)\n  File \"/usr/lib64/python2.7/pickle.py\", line 286, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python2.7/site-packages/dill/dill.py\", line 871, in save_module_dict\n    StockPickler.save_dict(pickler, obj)\n  File \"/usr/lib64/python2.7/pickle.py\", line 649, in save_dict\n    self._batch_setitems(obj.iteritems())\n  File \"/usr/lib64/python2.7/pickle.py\", line 663, in _batch_setitems\n    save(v)\n  File \"/usr/lib64/python2.7/pickle.py\", line 331, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"/usr/lib64/python2.7/pickle.py\", line 419, in save_reduce\n    save(state)\n  File \"/usr/lib64/python2.7/pickle.py\", line 286, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python2.7/site-packages/dill/dill.py\", line 871, in save_module_dict\n    StockPickler.save_dict(pickler, obj)\n  File \"/usr/lib64/python2.7/pickle.py\", line 649, in save_dict\n    self._batch_setitems(obj.iteritems())\n  File \"/usr/lib64/python2.7/pickle.py\", line 663, in _batch_setitems\n    save(v)\n  File \"/usr/lib64/python2.7/pickle.py\", line 331, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"/usr/lib64/python2.7/pickle.py\", line 419, in save_reduce\n    save(state)\n  File \"/usr/lib64/python2.7/pickle.py\", line 286, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python2.7/site-packages/dill/dill.py\", line 871, in save_module_dict\n    StockPickler.save_dict(pickler, obj)\n  File \"/usr/lib64/python2.7/pickle.py\", line 649, in save_dict\n    self._batch_setitems(obj.iteritems())\n  File \"/usr/lib64/python2.7/pickle.py\", line 663, in _batch_setitems\n    save(v)\n  File \"/usr/lib64/python2.7/pickle.py\", line 306, in save\n    rv = reduce(self.proto)\n  File \"/usr/lib64/python2.7/copy_reg.py\", line 70, in _reduce_ex\n    raise TypeError, \"can't pickle %s objects\" % base.__name__\nTypeError: can't pickle traceback objects. This is desired for us as well. A simple restart worker after serving X tasks. I agree for most use cases just fix the memory leak - in some regard though its a question of ease of use and increasing reliability for users / clients / investors. We make use of over 50 different libraries in our Django project and killing off workers does help us before the memory leaks (if there even are any are nipped in the bud before causing mayhem in production).\nSo gross hack in all honesty not really. You can work perfection until you're blue in the face or just add a few lines of code and keep everyone else happier. No one likes crashing code or unexpected backend results so the overhead to restart something every 16 32 64 runs is insignificant. . As this was really DB related just wanted to mention the following... We use the following decorator to close the connection after tasks are run. As our server will eventually close stale connections.\n```\ndef close_db_connection(ExceptionToCheck=Exception, raise_exception=False, notify=False):\n    \"\"\"Close the database connection when we're finished, django will have to get a new one...\"\"\"\n    def deco_wrap(f):\n        @wraps(f)\n        def f_wrap(*args, kwargs):\n            try:\n                return f(*args, kwargs)\n            except Exception as e:\n                raise e\n            finally:\n                from django.db import connection; \n                connection.close();\n    return f_wrap\nreturn deco_wrap\n\n```. ",
    "mindojo-victor": "ok, that sounds good. Do you have any readings, hints for me to do this correctly?. Thank you!. It's a pity there is not a single docstring in the code: https://github.com/coleifer/huey/blob/master/huey/storage.py. Great! Thank you. https://github.com/coleifer/huey/blob/15f0c755d3ab89b1d8910396b2e144ead8cdc78a/huey/contrib/sqlitedb.py#L80\npython\n    def unqueue(self, data):\n        return (self\n                .delete()\n                .where(Task.data == data)\n                .execute())\nIf I understand correctly, data can be huge, because it contains task arguments. But I have to index this field/column in order to make the query fast.\n. > This method is used to \"delete\" a task without executing it. It is not expected that this method will be used very often.\nOK. > It will be whatever parameters you specify, along with a small amount of task metadata (task ID and such).\nI could not find (periodic) task id in the data:\n```python\n\n\n\nimport base64\nbase64.b64decode('gAMoWBQAAABxdWV1ZWNtZF9jb3VudF9iZWFuc3EAaABOSwBLAE50cQEu')\nb'\\x80\\x03(X\\x14\\x00\\x00\\x00queuecmd_count_beansq\\x00h\\x00NK\\x00K\\x00Ntq\\x01.'\naa=base64.b64decode('gAMoWBQAAABxdWV1ZWNtZF9jb3VudF9iZWFuc3EAaABOSwBLAE50cQEu')\nimport pickle\npickle.loads(aa)\n('queuecmd_count_beans', 'queuecmd_count_beans', None, 0, 0, None)\n```\n\n\n\nIs this correct?. What if need to distinguish between different repetitions of the same task? Will assigning a unique id break anything?. Ok, I found a way to keep history of tasks. I'll create a back end for Mongo db. I will add is_deleted field and will work with it, instead of deleting the tasks from db. I'll also record the worker info in the task.\nThank you for an easy way to hook into this with storage subclassing! Though some dosctrings would really help.. If so, I think it's worth mentioning in the docs that this option is needed to prevent duplicate scheduling when there are several consumers in different processes -- each of them tries to schedule the periodic task in the specified times.. > In other words, the no-periodic option does not restrict which tasks a consumer will run.\nThat's my point and the issue. The docs should be changed, because right now they can be read wrongly:\n\nBy default, the consumer will execute periodic_task functions. To disable this, run the consumer with -n or --no-periodic.. What is the correct way to restart a consumer? Sending SIGHUP? Raising SystemExit?. @expresspotato You could count tasks in huey.consumer.Worker#process_task and raise SystemExit when you get a certain count of tasks.\n\nYou would have to override huey.consumer.Consumer#_create_worker.\nI would like this to be more elegantly, like declaring the worker/scheduler/consumer classes somewhere instead of imperatively overriding the whole method(s) risking to confuse the passed arguments (*args, **kwargs is not good). But.... Practicality beats purity. >  huey aims to not depend on outside libraries\nThis doesn't make sense.\nBut do as you wish.. def dequeue(self):\n        try:\n            task = (self\n                    .tasks()\n                    .order_by(Task.id)\n                    .limit(1)\n                    .get())\n        except Task.DoesNotExist:\n            return\n        res = self.delete().where(Task.id == task.id).execute()\n        if res == 1:\n            return task.data\nImagine that in almost the same moment 2 consumers get the last (and the same task) before the first consumer deletes it from db. This means that 2 consumers will run the same task twice.. Thanks for the explanation, you are correct.. If I need a scheduled task to have one, to be able to track it, will this break the huey's logic? I mean is it difficult to refactor? Or it's an architectural required decision?. Thank you! I found the code very well structured and easy to extend. Unlike Celery where are kombu, billiard, and other non-transparent stuff.\nMy ultimate goal is to be able to use Huey for reporting. Some of the report take time. Users need to see what's going on with their report, so I need to be able to show them what's the status of their tasks, when they were executed. And for devs we need to see on which host the tasks were executed, what's the average execution tasks to show ETA, etc.\nThis is my current implementation using mongoengine which I am planning to improve:\n```python\nclass MongoDbStorage(BaseStorage):\n    def init(self, name='huey', db_url='mongodb://127.0.0.1:27017/huey'):\n        super().init(name)\n    huey_db_alias = db_url\n    me.register_connection(huey_db_alias, host=db_url)\n\n    class HueyTask(me.Document):\n        \"\"\"A Huey task.\n        \"\"\"\n        queue = me.StringField(required=True)\n        data = me.BinaryField(required=True)\n        name = me.StringField()\n        args = me.DictField()\n        created_at = me.DateTimeField(default=lambda: datetime.datetime.utcnow())\n        user_id = me.ObjectIdField()\n        deleted_at = me.DateTimeField()\n\n        meta = {\n            'db_alias': huey_db_alias,\n            'collection': 'tasks',\n            'indexes': [\n                {'fields': ['queue']},\n                {'fields': ['name']},\n                {'fields': ['created_at']},\n                {'fields': ['deleted_at']},  # TODO: add TTL index for this field\n            ],\n        }\n\n    class Schedule(me.Document):\n        queue = me.StringField(required=True)\n        data = me.BinaryField(required=True)\n        timestamp = me.DateTimeField(required=True)\n\n        meta = {\n            'db_alias': huey_db_alias,\n            'collection': 'schedule',\n            'indexes': [\n                {'fields': ['queue']},\n                {'fields': ['timestamp']},\n            ],\n        }\n\n    class KeyValue(me.Document):\n        queue = me.StringField(required=True)\n        key = me.StringField(required=True)\n        value = me.BinaryField(required=True)\n\n        meta = {\n            'db_alias': huey_db_alias,\n            'collection': 'schedule',\n            'indexes': [\n                {'fields': ['queue', 'key'], 'unique': True},\n            ],\n        }\n\n    self.HueyTask = HueyTask\n    self.Schedule = Schedule\n    self.KeyValue = KeyValue\n\ndef tasks(self):\n    return self.HueyTask.objects(queue=self.name, deleted_at__exists=False)\n\ndef delete(self, **filters):\n    return self.HueyTask.objects(queue=self.name, **filters).update(\n        deleted_at=datetime.datetime.utcnow())\n\ndef enqueue(self, data):\n    self.HueyTask(queue=self.name, data=data).save()\n\ndef dequeue(self):\n    task = self.tasks().order_by('created_at').first()\n    if task is None:\n        return\n    res = self.delete(id=task.id)\n    if res == 1:  # if we were the first to delete the task, we take it\n        return task.data\n    # TODO: save started_at, host, pid\n\ndef unqueue(self, data):\n    return self.delete(data=data)\n\ndef queue_size(self):\n    return self.tasks().count()\n\ndef enqueued_items(self, limit=None):\n    tasks = self.tasks\n    if limit is not None:\n        tasks = tasks.limit(limit)\n    return list(tasks.scalar('data'))\n\ndef flush_queue(self):\n    self.delete()\n\ndef schedule(self, **filters):\n    return self.Schedule.objects(queue=self.name, **filters).order_by('timestamp')\n\ndef add_to_schedule(self, data, ts):\n    self.Schedule(data=data, timestamp=ts, queue=self.name).save()\n\ndef read_schedule(self, ts):\n    tasks = self.schedule(timestamp__lte=ts).only('id', 'data')\n    id_list, data = [], []\n    for schedule_id, task_data in tasks:\n        id_list.append(schedule_id)\n        data.append(task_data)\n    if id_list:\n        self.Schedule.objects(id__in=id_list).delete()\n    return data\n\ndef schedule_size(self):\n    return self.schedule().count()\n\ndef scheduled_items(self, limit=None):\n    return list(self.schedule.scalar('data'))\n\ndef flush_schedule(self):\n    return self.schedule().delete()\n\ndef kv(self, **filters):\n    return self.KeyValue.objects(queue=self.name, **filters)\n\ndef put_data(self, key, value):\n    self.KeyValue(queue=self.name, key=key, value=value).save()\n\ndef peek_data(self, key):\n    try:\n        return self.kv(key=key).only('value').get().value\n    except self.KeyValue.DoesNotExist:\n        return EmptyData\n\ndef pop_data(self, key):\n    try:\n        kv = self.kv(key=key).get()\n    except self.KeyValue.DoesNotExist:\n        return EmptyData\n    result = self.kv(key=key).delete()\n    return kv.value if result == 1 else EmptyData\n\ndef has_data_for_key(self, key):\n    return bool(self.kv(key=key).count())\n\ndef result_store_size(self):\n    return self.kv().count()\n\ndef flush_results(self):\n    return self.KeyValue.objects(queue=self.name).delete()\n\ndef put_error(self, metadata):\n    pass\n\ndef get_error(self, limit=None, offset=0):\n    pass\n\ndef flush_errors(self):\n    pass\n\ndef emit(self, message):\n    # from huey.consumer import EVENT_STARTED\n    log.info('`emit`: %s', message)\n\ndef __iter__(self):\n    return self\n\ndef next(self):\n    raise StopIteration\n__next__ = next\n\n``. I can moveBaseStorage`, if you are accepting PRs.. > The above methods are now added to decorated tasks (where formerly\nthey were only available on decorated periodic tasks).\nCan we then simplify the api, leaving only one decorator task, which when passed crontab argument behaves like a periodic task?. Oh, it's not a dictionary, it's a tuple.\npython\n('8b151c42-0eea-4eb4-b65d-f242732f2021', 'queuecmd_count_beans', None, 0, 0, None)\nhttps://github.com/coleifer/huey/blob/master/huey/registry.py#L48\nI think it would be nice to pass it as namedtuple then.. > huey treats the data as an opaque sequence of bytes\nWhat's the point of this?\n\nfor the purposes of the storage engine.\n\nI think you are coupling your code. The storage knows better how to store\nthe data.\n. You are limiting possibilities to extend the code. For what advantage\ninstead?\nOn Oct 6, 2017 6:17 PM, \"Charles Leifer\" notifications@github.com wrote:\n\nIt's treated that way because the storage engine is a storage engine -- it\ndoesn't know about the data.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/coleifer/huey/issues/258#issuecomment-334785156, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AQXVT8xedyjsR4JtdCX_l1wDeOjEk7z9ks5spkR2gaJpZM4PwNrj\n.\n. I am trying to extract from the data function arguments for my purposes.\nFor thus I'll to rely that you are pickling it from a certain format, this\nis coupling.\n\nOn Oct 6, 2017 6:19 PM, \"Victor Varvaryuk\" victor.varvaryuk@mindojo.com\nwrote:\n\nYou are limiting possibilities to extend the code. For what advantage\ninstead?\nOn Oct 6, 2017 6:17 PM, \"Charles Leifer\" notifications@github.com wrote:\n\nIt's treated that way because the storage engine is a storage engine --\nit doesn't know about the data.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/coleifer/huey/issues/258#issuecomment-334785156, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AQXVT8xedyjsR4JtdCX_l1wDeOjEk7z9ks5spkR2gaJpZM4PwNrj\n.\n\n\n. The only reason to theat the data as a byte sequence is unqueue method. But\nit should be changed anyway imo, passing it task id instead.\n\nOn Oct 6, 2017 6:21 PM, \"Victor Varvaryuk\" victor.varvaryuk@mindojo.com\nwrote:\n\nI am trying to extract from the data function arguments for my purposes.\nFor thus I'll to rely that you are pickling it from a certain format, this\nis coupling.\nOn Oct 6, 2017 6:19 PM, \"Victor Varvaryuk\" victor.varvaryuk@mindojo.com\nwrote:\n\nYou are limiting possibilities to extend the code. For what advantage\ninstead?\nOn Oct 6, 2017 6:17 PM, \"Charles Leifer\" notifications@github.com\nwrote:\n\nIt's treated that way because the storage engine is a storage engine --\nit doesn't know about the data.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/coleifer/huey/issues/258#issuecomment-334785156,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AQXVT8xedyjsR4JtdCX_l1wDeOjEk7z9ks5spkR2gaJpZM4PwNrj\n.\n\n\n. > But it should be changed anyway imo, passing it task id instead.\n\n\nactually this would not be needed, because tasi id can be taken from raw\ndata.\n. I partially agree. But at the same time:\n\nthe old way task_id, klass_str, execute_time, retries, delay, data = raw still works. I changed it for the sake of readability.. And you said the data is opaque for this very reason, that others would not deal with it directly?. I see, then I can change it back to task_id, klass_str, execute_time, retries, delay, data = raw and old serialized tasks would still work.. Thank you!\n\nOn Oct 8, 2017 19:16, \"Charles Leifer\" notifications@github.com wrote:\n\nFixed!\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/coleifer/huey/issues/260#issuecomment-335017494, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AQXVT_BRwX80hRdspfmgJKOeiDUmCob9ks5sqPVSgaJpZM4Pxnw7\n.\n. You mean why a signal? It's a common technique, afaik.\nhttp://docs.celeryproject.org/en/latest/userguide/workers.html#restarting-the-worker\n\nI could be wrong.\nOn Oct 8, 2017 19:17, \"Charles Leifer\" notifications@github.com wrote:\nRight now there is not, but I don't see why we should implement a restart\nsignal at the very least. SIGHUP for instance?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/coleifer/huey/issues/261#issuecomment-335017544, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AQXVTwK3nzDuL0lJ1Iur-jd8NblkuRRJks5sqPV9gaJpZM4Pxn4M\n.\n. If I understood correctly, if the master process receives SIGHUP, it restart itself with all the workers. If a worker receives SIGHUP, only it restarts. I am interested in the second case, because other workers could be ok.. > Wanna try out 1ffb3dd ?\nWill try this later. Thank you!. This should work. If health checker always running?. Looks like it is. This means that all I need is there in place already. I can count number of tasks and raise KeyboardInterrupt when I think the worker should restart. It will die and the consumer will raise another worker in its place?. Where is most appropriate place to apply this automatically to every task when it's executed?. And a more general question: how to get your code executed before/after any task?. That would mean changing the client code.. Is adding possibility to extend task behavior out of Huey's scope?. Looks good, @coleifer . Thank you! Do you plan to ever use signals? http://docs.celeryproject.org/en/latest/userguide/signals.html#task-prerun. Thank you, this works:\n```python\ndef _handle_timeout(signum, frame):\n    raise TimeoutError\n@huey.pre_execute()\ndef timeout_start(task):\nsignal.signal(signal.SIGALRM, _handle_timeout)\nsignal.alarm(10)\n\n@huey.post_execute()\ndef timeout_stop(task, value, exc):\n    signal.alarm(0)\n```. I am not using threads, they are difficult to cook.. Since periodic tasks have their own ids, does make sense to store their results too?\nhttps://github.com/coleifer/huey/blob/07164083f6357d63a2a192961b74c61b4fb74ebd/huey/api.py#L379. I think we should not limit what a periodical task does.\nA compromise would be to not store the result if it's None.\n. How about allowing to configure which scheduler class to use, like Celery does?\npython\n    def _create_scheduler(self):\n        return Scheduler(\n            huey=self.huey,\n            interval=self.scheduler_interval,\n            utc=self.utc,\n            periodic=self.periodic)\nWhy are you closing the issues so quickly?. If I understand correctly I will also need to write my own huey_consumer.py? \nMaybe add a configuration option to be able to specify consumer class which would default to huey.consumer.Consumer?\nAnd even then it's not nice to override the whole method:\npython\n    def _create_scheduler(self):\n        return Scheduler(\n            huey=self.huey,\n            interval=self.scheduler_interval,\n            utc=self.utc,\n            periodic=self.periodic)\nIt would be nice to be able to specify the scheduler class via a configuration option.. Thank you!\nOn Oct 17, 2017 10:19 PM, \"Charles Leifer\" notifications@github.com wrote:\n\nShould be possible to accomplish whatever you need using something like:\nclass MyScheduler(Scheduler):\n    pass\nclass MyConsumer(Consumer):\n    def _create_scheduler(self):\n        return MyScheduler(...)\nclass MyRedisHuey(RedisHuey):\n    def create_consumer(self, config):\n        return MyConsumer(self, config)\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/coleifer/huey/issues/265#issuecomment-337340665, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AQXVT0E9kmW_zVYyirLmIyacxaZDbwt8ks5stP2pgaJpZM4P7sBd\n.\n. Would you suggest me an entry point function to decorate with the profiler?. I am using my custom MongoDB backend, so I think profiling is the only option.. ```python\nimport datetime\nimport json\nimport logging\nimport pickle\nimport signal\nimport time\n\nimport huey.consumer\nfrom huey.constants import EmptyData\nfrom huey import crontab\nimport setproctitle\nimport mongoengine as me\nimport settings\nfrom brain import utils\nlog = logging.getLogger(name)\nclass MongoDbStorage(huey.storage.BaseStorage):\n    def init(self, name='huey', db_url='mongodb://127.0.0.1:27017/huey'):\n        super().init(name)\n    self.db_alias = db_url\n    me.register_connection(self.db_alias, host=db_url)\n\n    class HueyTask(me.Document):\n        \"\"\"A Huey task.\n        \"\"\"\n        id = me.StringField(primary_key=True, required=True)\n        queue = me.StringField(required=True)\n        data = me.BinaryField(required=True)\n        name = me.StringField()\n        args = me.DictField()\n        created_at = me.DateTimeField(default=lambda: datetime.datetime.utcnow())\n        user_id = me.ObjectIdField()\n        deleted_at = me.DateTimeField()\n        events = me.ListField(me.DictField())\n\n        meta = {\n            'db_alias': self.db_alias,\n            'collection': 'tasks',\n            'indexes': [\n                {'fields': ['queue']},\n                {'fields': ['name']},\n                {'fields': ['created_at']},\n                {'fields': ['deleted_at']},  # TODO: add TTL index for this field\n            ],\n        }\n\n    class Schedule(me.Document):\n        queue = me.StringField(required=True)\n        data = me.BinaryField(required=True)\n        timestamp = me.DateTimeField(required=True)\n\n        meta = {\n            'db_alias': self.db_alias,\n            'collection': 'schedule',\n            'indexes': [\n                {'fields': ['queue']},\n                {'fields': ['timestamp']},\n            ],\n        }\n\n    class KeyValue(me.Document):\n        queue = me.StringField(required=True)\n        key = me.StringField(required=True)\n        value = me.BinaryField(required=True)\n\n        meta = {\n            'db_alias': self.db_alias,\n            'collection': 'schedule',\n            'indexes': [\n                {'fields': ['queue', 'key'], 'unique': True},\n            ],\n        }\n\n    self.HueyTask = HueyTask\n    self.Schedule = Schedule\n    self.KeyValue = KeyValue\n\ndef tasks(self):\n    return self.HueyTask.objects(queue=self.name, deleted_at__exists=False)\n\ndef delete(self, **filters):\n    return self.HueyTask.objects(queue=self.name, **filters).update(\n        deleted_at=datetime.datetime.utcnow())\n\ndef enqueue(self, data):\n    _data = pickle.loads(data)\n    self.HueyTask(id=_data[0], queue=self.name, data=data).save()\n\ndef dequeue(self):\n    task = self.tasks().order_by('created_at').first()\n    if task is None:\n        return\n    res = self.delete(id=task.id)\n    if res == 1:  # if we were the first to delete the task, we take it\n        return task.data\n    # TODO: save started_at, host, pid\n\ndef unqueue(self, data):\n    return self.delete(data=data)\n\ndef queue_size(self):\n    return self.tasks().count()\n\ndef enqueued_items(self, limit=None):\n    tasks = self.tasks\n    if limit is not None:\n        tasks = tasks.limit(limit)\n    return list(tasks.scalar('data'))\n\ndef flush_queue(self):\n    self.delete()\n\ndef schedule(self, **filters):\n    return self.Schedule.objects(queue=self.name, **filters).order_by('timestamp')\n\ndef add_to_schedule(self, data, ts):\n    self.Schedule(data=data, timestamp=ts, queue=self.name).save()\n\ndef read_schedule(self, ts):\n    tasks = self.schedule(timestamp__lte=ts).only('id', 'data')\n    id_list, data = [], []\n    for schedule_id, task_data in tasks:\n        id_list.append(schedule_id)\n        data.append(task_data)\n    if id_list:\n        self.Schedule.objects(id__in=id_list).delete()\n    return data\n\ndef schedule_size(self):\n    return self.schedule().count()\n\ndef scheduled_items(self, limit=None):\n    return list(self.schedule.scalar('data'))\n\ndef flush_schedule(self):\n    return self.schedule().delete()\n\ndef kv(self, **filters):\n    return self.KeyValue.objects(queue=self.name, **filters)\n\ndef put_data(self, key, value):\n    self.KeyValue(queue=self.name, key=key, value=value).save()\n\ndef peek_data(self, key):\n    try:\n        return self.kv(key=key).only('value').get().value\n    except self.KeyValue.DoesNotExist:\n        return EmptyData\n\ndef pop_data(self, key):\n    try:\n        kv = self.kv(key=key).get()\n    except self.KeyValue.DoesNotExist:\n        return EmptyData\n    result = self.kv(key=key).delete()\n    return kv.value if result == 1 else EmptyData\n\ndef has_data_for_key(self, key):\n    return bool(self.kv(key=key).count())\n\ndef result_store_size(self):\n    return self.kv().count()\n\ndef flush_results(self):\n    return self.KeyValue.objects(queue=self.name).delete()\n\ndef put_error(self, metadata):\n    pass\n\ndef get_error(self, limit=None, offset=0):\n    pass\n\ndef flush_errors(self):\n    pass\n\ndef emit(self, message):\n    message = json.loads(message)\n    task_name = message.pop('task', None)\n    if task_name:\n        # remove redundant data\n        task_id = message.pop('id')\n        del message['task']\n        message = {key: value for key, value in message.items() if value is not None}\n        self.HueyTask._get_collection().update(\n            {'_id': task_id}, {'$push': {'events': message}})\n        # this causes an error (a bug in MongoEngine?)\n        # self.HueyTask.objects(id=task_id).update(set__events__push=message)\n\ndef __iter__(self):\n    return self\n\ndef next(self):\n    raise StopIteration\n__next__ = next\n\nclass Scheduler(huey.consumer.Scheduler):\n    \"\"\"Our scheduler that skips ticks if another scheduler is already running.\n    \"\"\"\n    max_interval = 10  # seconds\ndef __init__(self, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n    self.ts = None\n\n@utils.cached_property\ndef tick_coll(self):\n    conn = me.connection.get_connection(self.huey.storage.db_alias)\n    coll = conn.get_default_database()['tick']\n    # ensure the lock document exists\n    self.ts = self.get_server_time()\n    coll.find_one_and_update({'_id': 'lock'}, {'$setOnInsert': {'ts': self.ts}}, upsert=True)\n    setproctitle.setproctitle('Huey scheduler')\n    return coll\n\n@utils.cached_property\ndef admin_db_conn(self):\n    return me.connection.get_connection(self.huey.storage.db_alias)['admin']\n\ndef get_server_time(self):\n    host_info = self.admin_db_conn.command('hostInfo')\n    return host_info['system']['currentTime'].timestamp()\n\ndef loop(self, *args, **kwargs):\n    start = time.time()\n\n    ts = self.get_server_time()\n    result = self.tick_coll.update_one(\n        {'_id': 'lock',\n         '$or': [\n            # this process knows its timestamp which gives him priority\n            {'ts': self.ts},\n            # or if the last tick timestamp was long ago we must take the lead\n            {'ts': {'$lt': ts - self.max_interval}},\n        ]},\n         {'$set': {'ts': ts}},\n    )\n    if not result.modified_count:\n        self._logger.debug('Could not take the lead. Will wait, maybe the current lead dies.')\n        self.sleep_for_interval(start, self.max_interval)\n        return\n\n    self._logger.debug('Leading')\n    self.ts = ts\n\n    return super().loop(*args, **kwargs)\n\nclass Consumer(huey.consumer.Consumer):\n    def _create_scheduler(self):\n        return Scheduler(\n            huey=self.huey,\n            interval=self.scheduler_interval,\n            utc=self.utc,\n            periodic=self.periodic)\nclass MongoDbHuey(huey.api.Huey):\n    def get_storage(self, db_url):\n        return MongoDbStorage(name=self.name, db_url=db_url)\ndef create_consumer(self, **config):\n    config['worker_type'] = 'process'  # we support only this worker type\n    return Consumer(self, **config)\n\n-------------------------------------------------------------------------------------------------\nTIMEOUT = 3600  # TODO: move this to settings\nHUEY_DB_URL = utils.replace_db_name(settings.celery.broker_url, 'huey')\nhuey = MongoDbHuey('my_app', db_url=HUEY_DB_URL)\ndef _handle_timeout(signum, frame):\n    raise TimeoutError\n@huey.pre_execute()\ndef timeout_start(task):\n    signal.signal(signal.SIGALRM, _handle_timeout)\n    signal.alarm(TIMEOUT)\n@huey.post_execute()\ndef timeout_stop(task, value, exc):\n    signal.alarm(0)\n@huey.periodic_task(crontab(minute='*'))\ndef count_beans(num=100):\nprint('-- counted %s beans --' % num)\n...\n. Thank you for the comments!. No, will do this later.. Now you can see, why I was creating all those issues. I know you don't like my PR, but I hope it can be merged.python\n    def enqueue(self, data):\n        _data = pickle.loads(data)\n        self.HueyTask(id=_data[0], queue=self.name, data=data).save()\n```\nThis is tightly coupled to implementation details.. Looks like it's not the custom back end, but one of periodic tasks. This worked for me:\n```python\n    # huey.consumer.Consumer\n    def _create_process(self, process, name):\n        def _run():\n            import cProfile\n        pr = cProfile.Profile()\n        pr.enable()\n        try:\n            while not self.stop_flag.is_set():\n                process.loop()\n        except KeyboardInterrupt:\n            pass\n        except:\n            self._logger.exception('Process %s died!', name)\n        pr.disable()\n        pr.dump_stats(f'{name}.profile')\n    return self.environment.create_process(_run, name)\n\n``. Looks like it does. Thank you! Will test it later.. Yeah, the main use case is per-instance priority.. Unfortunatelytask_settingsis not stored anywhere in the db. At least I could not find it. The additional attributes are just made attributes ofhuey.api.QueueTaskbut they are not stored in the db. So if I add atimeoutattribute, orpriority` I cannot get this info in consumers.. so the only way to accomplish per task timeouts or priorities is to pass this metadata with the task data under some standard key? Then the consumer would introspect the data and do what it needs? Doesn't look nice mixing task metadata and data, but I'll go this way.. Thanks for the explanation.. Yes, I thought of this option, but it's not very convenient...\nOn Dec 7, 2017 16:57, \"Charles Leifer\" notifications@github.com wrote:\n\nClosed #277 https://github.com/coleifer/huey/issues/277.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/coleifer/huey/issues/277#event-1377059022, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AQXVT9x_-d2WEwnx6CQ2yt8RHchRtybPks5s9_zqgaJpZM4Q5EdH\n.\n. It's inconvenient from interface point of view. Having two functions doing the same, with different names, causes confusion.. Thank you for the response. Would you please comment on this line task_fn._periodic = huey.periodic_task(validate_fn)(fn) as I don't know Huey that well yet.. Sorry for being dumb. I thought _periodic is an attribute used by Huey.\n\nNow I understand: we decorate the function twice, but do not wrap task with periodic_task or viceversa. So if we call the function, the regular task decorator is called. At the same time we register the function for periodicity. I guess the assigning result of huey.periodic_task(validate_fn)(fn) to task_fn._periodic is not necessary, as the function is registered in a periodic task registry?. > I would:\n\n```python\ndef one_func():\n    pass\none_func_task = huey.task()(one_func)\none_func_cron = huey.periodic_task(crontab(...))(one_func)\n```\n\nIt's not working because of\nhttps://github.com/coleifer/huey/blob/533c681519f10b4e354e567b6d8790f07f8d8a4d/huey/registry.py#L26-L31\nThe call huey.periodic_task doesn't add the function to _periodic_tasks because it is already present in the registry as a task on demand.\n. Maybe he means he means that there is a task, which should not be scheduled/executed, if there is similar task already scheduled/running.\nI also had such a case, and I solved it finding the tasks in the queue by their names.. >  I suppose I could add logic to check the scheduler as well?\nYes, I think. Because scheduler is also an important part of the system.\nThank you!. @coleifer Is there an example how to set up a consumer per queue? Is it possible to send the same task to different queues? For example I have a task to send an email. In some cases I want the email to be sent ASAP via the \"fast\" queue, in other -- it can wait for its time in the regular queue.. I have created 2 queues:\n```python\nqueue = MongoDbHuey('huey', db_url=HUEY_DB_URL, always_eager=settings.huey.ALWAYS_EAGER,\n                    result_store=False, events=True, store_errors=False)\nfast_queue = MongoDbHuey('fast', db_url=HUEY_DB_URL, always_eager=settings.huey.ALWAYS_EAGER,\n                         result_store=False, events=True, store_errors=False)\nThen I start both consumers:bash\n huey_consumer.py ...huey.fast_queue\n huey_consumer.py ....huey.queue\n``\nOn both cases the same list of tasks is printed (The following commands are available:`).\nI am doing anything wrong?. global_registry=False shows empty list after The following commands are available:.\npython\n        msg = ['The following commands are available:']\n        for command in registry._registry:\n            msg.append('+ %s' % command.replace('queuecmd_', ''))\nLooks like the consumer reads the global registry.. I found worker used in tests. I just don't understand how it could be useful, because AFAIR it's in the consumer process. Maybe it makes sense in threading implementation, but in multiprocessing environment -- I don't see how.. You mean code quality?\nI was adding functionality needed for me (sending heart-beat messages for each worker) and was digging through the code. That part made no sense to me, making it more difficult to understand how it works.\nShouldn't I raise such issues?. That's ok. Just wanted to mention that keeping the worker instance in the consumer process doesn't make sense when using multi-processing, AFAIU, because you can do nothing with it, because the worker process has its own copy of the worker code.. > Huey becoming a better library\nAs a library it's not always user friendly.\nAre you still against allowing easily overriding internals?\nFor example I have to monkey-patch to name tasks not as 'queue_task_%s' % (func.__name__):\n```python\nMonkey-patch the function, because we require our own template for task names\ndef create_task(task_class, func, retries_as_argument=False, task_name=None,\n                include_task=False, _orig_create_task=huey.api.create_task, **kwargs):\ntask_name = task_name or f'{func.__module__}.{func.__name__}'\nreturn _orig_create_task(\n    task_class,\n    func,\n    retries_as_argument=retries_as_argument,\n    task_name=task_name,\n    include_task=include_task,\n    **kwargs\n)\n\nhuey.api.create_task = create_task\n```\nIt would be much nicer if create_task would be a method of TaskWrapper. And TaskWrapper to be used would be  a class attribute of huey.api.Huey:\n```python\nclass MyTaskWrapper(huey.api.TaskWrapper):\n    def create_task(...):\n          ...\nclass MyHuey(huey.api.Huey):\n    task_wrapper = MyTaskWrapper\n...\n\ndef task(self, retries=0, retry_delay=0, retries_as_argument=False,\n         include_task=False, name=None, **task_settings):\n    def decorator(func):\n        ...\n        return self.task_wrapper(...)\n    return decorator\n\n```\nI just don't understand why you don't want this approach. It doesn't make the code more complicated but gives more flexibility to others to override/extend the default behavior without monkey-patching and other ugly approaches.\nThe same approach can used to configure which Worker, Consumer, Scheduler classes to use.. I did override task decorator to set the name to what I want, but then it turned out I also have to override periodic_task -- and doing the same thing in two places is not fun. Both of the decorators are creating a TaskWrapper, so I thought it's a good place to put the common logic there. But I can't, as I explained above.. > When did I say this?\nI suggested the same thing here https://github.com/coleifer/huey/issues/265#issuecomment-337261204\nBut you suggested to use an uglier way. So I made the conclusion that you don't want to make it easier to override the internals.\n\nthere's an entitled vibe coming across that you may not be aware of.\n\nSorry, I am not a native English speaker, so I am not sure what this idiom means. But I think I understand what you mean.\nI feel like I am fighting with you. To me it looks like you oppose some of changes. I kind of understand why, but I don't think it's wise.\nThat's were my attitude comes from. \nSo I think I could address the same quote to you... :). > These are, to me, indications that the project is healthy.\nI think the project is healthy and the code is nice.\n\nAs I said earlier, my goal is to make the 80% use-case easy and the 20% use-case possible. Having clean, orthogonal APIs throughout is a good way to ensure this is possible. But because you are having some very specific issue overriding some very specific internal behavior doesn't necessarily indicate there's a bug that needs to be fixed.\n\nWell, I pose this issue not as a bug. Just as an issue. Changing two lines in consumer.py would make my life easier and would not make the original code more complicated.\nI can submit a PR, to take less of your time, but I am not sure you will accept it, because it looks to me you oppose the very idea.\n\nYou're only going to wear yourself out if you feel that way.\n\nWell, that's my job: to make my apps better so I have to fight over some architecture decisions sometimes. I try to not take it personally.\n. This should work. Thanks for an workaround!\nHowever, I think it's not uncommon for people to want the same task be called on demand and periodically. And using your solution is coupling to an implementation detail.\nI think if this is not supported, a user friendly approach would be to raise an exception or show a warning when a periodic task failed to be added to the list of periodic tasks, otherwise developers could find out that it doesn't work in production, like it was in my case.\nOr a better approach (IMO) would be to fix this side effect.\nOr provide a method to explicitly add/remove periodic tasks to/from TaskRegistry._periodic_tasks, because passing validate_datetime to huey.periodic_task essentially does the same, but with hidden and uncontrollable logic.. Thank you!. https://github.com/coleifer/huey/blob/fd90bdf85e0ee3fac83b16515b3cf267942f5a0b/huey/consumer.py#L356-L358. I have no idea. Using the default configuration.. Yes, the constructor would be the same. And in most of the cases the custom Worker or Scheduler classes would be subclasses of the the original classes, the constructor not touched at all, some other methods would be overridden.. Do I understand correctly that you don't welcome contributions (I haven't found any contribution guidelines) and you prefer to keep Huey non-extendable so it can serve mostly your purposes?\nIt would be nice to state this attitude in a CONTRIBUTING file, so that people would not waste their time.. Are you planning to make a release?. ",
    "cburza": "Celery is not installed as it is not required based on the configuration of Defender, thus we get the following exception.\nFile \"/Users/guest/venv/lib/python3.6/site-packages/defender/tasks.py\", line 6, in <module>\n    from celery import shared_task\nModuleNotFoundError: No module named 'celery'\nI had to override the management command and exclude the autodiscover method from the handle method to get past the exception.. ModuleNotFoundError is a subclass of ImportError. This is new as of Python 3.6.\nhttps://docs.python.org/3/library/exceptions.html#ModuleNotFoundError. Thank you, this fixes the issue.. ",
    "raphael-riel": "@camilonova Here's my Django's LOGGING setting to get Huey's ERRORs sent to Sentry.\npython\nLOGGING = {\n    'version': 1,\n    'disable_existing_loggers': False,\n    'handlers': {\n        'sentry': {\n            'level': 'ERROR',\n            'class': 'raven.contrib.django.raven_compat.handlers.SentryHandler',\n        },\n        'console': {\n            'class': 'logging.StreamHandler',\n        }\n    },\n    'loggers': {\n        'huey.consumer': {\n            'level': 'INFO',\n            'handlers': ['sentry', 'console'],\n            'propagate': False,\n        },\n        'raven': {\n            'level': 'DEBUG',\n            'handlers': ['console'],\n            'propagate': False,\n        },\n        'sentry.errors': {\n            'level': 'DEBUG',\n            'handlers': ['console'],\n            'propagate': False,\n        },\n        '': {\n            'handlers': ['console'],\n            'level': 'INFO',\n            'propagate': True,\n        },\n    },\n}. Huey is converting exceptions to logging.error and these are sent to Sentry as per the above configuration. \nThat's why Sentry wasn't catching exceptions in the first place; because Huey intercepts and convert ems in ERROR logs. All of this to avoid the exception to bubble up and cause a failure to the worker/consumer.. ",
    "meagerman": "The retry policy for a task is currently set when the task function is registered -- it is not a property of the function implementation, but how that function is registered into Huey. If the function itself starts making decisions about retries, then there would be two places that define retry policies, and these could conflict with each other. This could be mitigated by having the task passed to the function, which can be inspected for whether retries should be allowed or not.\nHowever, retrying explicitly also loses the information that the next run is actually a \"retry\" that can be kept and logged in Huey. Technically, the task is not being retried, but a new task is being scheduled. This means that the retry count is lost, and so finite retries could not be implemented properly within the function itself without receiving retry counts and other meta-data as arguments.\nThe solution I ended up implementing is the following:\n\nI raise a custom exception when I want to retry a task not due to an exception, say SilentError()\nI then add a log filter on huey.consumer.worker that filters out any log message related to SilentError exceptions, so they don't look like unhandled exceptions in the logs. \n\nIt's a fairly simple solution, but I would still argue that there is a missing need to be able to use Huey's retry system without having to raise an exception that will be logged as a critical problem. Perhaps as a task method like mytask.retry().\n. ",
    "distefam": "Thank you so much for the quick and detailed reply. I wanted to try it out before responding but haven't had a chance to yet. I'll be working on it today though and I'll also be sure to check out the new pipelining features.\nYou pretty much nailed my primary reason for wanting to move away from Celery. As you noted, the documentation and examples are frustratingly complex and in my opinion insufficient (just one example: chording, it took me far longer than necessary to realize, doesn't work with brokers other than Redis). As I've been using Celery I've accumulated a bunch of workarounds in my codebase and it's now peppered with comments like \"TODO: find an alternative to Celery\". Recently, I came across a bug and lost almost a day to debugging. This isn't the first time this has happened so I guess it was the final straw that led me to look into simpler alternatives.\nAs a general rule, I like to use as lightweight a library as possible for my needs and if possible one whose codebase I'm comfortable diving into. Celery just didn't fit this bill for me. I'm sure it's incredibly powerful but I just don't need that at this point\u2014I just want something that I can easily understand, works when I expect it to, and where I don't dread modifying parts of my codebase that touch it. . In your example above, you say in a comment to \"block until the four fetch tasks have returned\". It seems to me that an easy way to do that would be to modify the following line of your example to be:\npython\nresults = [task_result.get(blocking=True) for task_result in tasks]\nSince I intend to wait for all tasks to finish before returning results this seems like it would work. However, did you have something else in mind?. Great, thank you again. I'm going to close this issue then.. ",
    "slidenerd": "Apologies for the newbie question, If you say blocking=True what happens when one of the subtasks fails and there is no retry or worker shuts down and restarts due to some issue. ",
    "AzMoo": "\nI just read the celery docs for group and chord...my own opinion is that it's hideously complicated and hard to understand (littered with .s(), .si(), pipes, etc). I recognize the engineering talent that's required to make a library like celery, but if I was reviewing code that looked like those examples I'd definitely take issue with it on account of it being almost unreadable.\nThat being said, I think there's probably an analogous pattern in threading for spawning a bunch of threads (which may put values in a queue), then waiting for all to join and doing something with the values put in the queue.\nTo implement that kind of thing with huey you'll want to do something like:\n```python\n@huey.task()\ndef fetch_from_api(resource):\n    return api.get(resource)\n@huey.task()\ndef initialize_data_from_api():\n    resources = ['foo', 'bar', 'baz', 'something']\n# Spawn 4 tasks.\ntasks = [fetch_from_api(resource) for resource in resources]\n\n# Block this task until the 4 fetch tasks have returned.\nresults = [task_result.get(blocking=True) for task_result in tasks]\n\n# Insert the resulting data into the db.\ninsert_into_db(results)\n\n```\nIn the above code you have a master task that spawns individual API-call tasks and then blocks until all tasks have been executed and returned, before inserting the resulting data into the db. Obviously for the above to work you'll need at least 2 workers, since the master task is going to block up a worker for the duration of the API calls.\nIs there any particular reason you're migrating away from celery?\n\nHi, I'm sorry for dredging up such an old issue but it seemed the most appropriate spot to talk about the problem I'm having. \nI'm attempting to implement this pattern as you've described but I'm running into trouble when running in pytest with always_eager turned on. \nAs you're probably aware when a task is executed with always_eager enabled it executes immediately which is expected, but the issue is that it's returning the result of the task instead of a TaskResultWrapper instance. This means that I'm unable to call task_result.get(blocking=True) during unit and integration tests because the value in tasks is not a TaskResultWrapper instance and the call to .get fails.\nI can work around the problem by checking if always_eager is enabled and skipping the results line, but it seems odd to me that a task returns a different type depending on if always_eager is enabled. I think it would be beneficial to return a TaskResultWrapper instance with the result being immediately available to provide a consistent return type regardless of whether always_eager is enabled.. Would you be open to a pull request that does some refactoring if I could work it out? I share the concern about breaking code that depends on this behaviour, but I feel the inconsistency is egregious enough to warrant a breaking change in a major version.. ",
    "jedie": "@AzMoo I have a similar problem. But solved differently, without \"always_eager\" in tests.\nHere everything runs in Docker. If the tests run, redis and huey consumer are there and also run in containers.\nTherefore I did not use \"always_eager\" in tests, rather I let the task run correctly and wait until they are finished.\nHowever, \"wait for tasks\" is relatively complicated. But I now have a solution that works for me. You can read one of my odysseys here: #381 \nIf I have time and there is interest, I will publish the sourcecode.\nTest code with my AssertHueyTask looks like this:\n```\n    def test_wait_for_huey_task(self):\n        with AssertHueyTask(task_data=[(itegration_test_task, {\"test_wait_for_huey_task\": 1})], timeout=3):\n            itegration_test_task(message=\"test_wait_for_huey_task\", delay=0.1)\ndef test_no_task_called_ok(self):\n    with AssertHueyTask(task_data=[], timeout=0.5):\n        pass\n\ndef test_different_tasks(self):\n    task_data = (\n        (itegration_test_task, {\"test_different_tasks\": 2}),\n        (itegration_test_task_return, {\"foo\": 1, \"bar\": 1, None: 2}),\n    )\n\n    with AssertHueyTask(task_data=task_data, timeout=4):\n        itegration_test_task_return(return_value=\"bar\")\n        itegration_test_task(message=\"test_different_tasks\", delay=0.5)\n        itegration_test_task_return(return_value=\"foo\")\n        itegration_test_task_return(return_value=None)\n        itegration_test_task(message=\"test_different_tasks\", delay=0.5)\n        itegration_test_task_return(return_value=None)\n\ndef test_assert_not_called(self):\n    with self.assertRaises(HueyTaskNotScheduled) as error:\n        with AssertHueyTask(task_data=[(itegration_test_task, {})], timeout=0.5):\n            pass\n\n    error_message = str(error.exception)\n    self.assertEqual(\n        error_message, \"Error: Task missing: ['apps.huey_itegration.tasks.queue_task_itegration_test_task']\"\n    )\n\ndef test_wrong_complete_count1(self):\n    with self.assertRaises(HueyTaskCompleteCountError) as error:\n        with AssertHueyTask(task_data=[(itegration_test_task_return, {\"foobar\": 2})], timeout=1):\n            itegration_test_task_return(return_value=\"foobar\")\n\n    error_message = str(error.exception)\n    self.assertIn(\"Wrong task results\", error_message)\n    self.assertIn(\n        (\n            \"'apps.huey_itegration.tasks.queue_task_itegration_test_task_return':\"\n            \" Counter({'foobar': 1}) is not Counter({'foobar': 2})\"\n        ),\n        error_message,\n    )\n\n```\n. Oh: I also implement a context manager to use \"always eager\" in tests:\n```\nclass HueyAlwaysEager:\n    def enter(self):\n        HUEY.always_eager = True\n        return self\ndef __exit__(self, *exc):\n    HUEY.always_eager = False\n\n```\ne.g.:\n```\n    def test_decorator(self):\n        self.assertFalse(HUEY.always_eager)\n    with HueyAlwaysEager():\n        self.assertTrue(HUEY.always_eager)\n\n    self.assertFalse(HUEY.always_eager)\n\n``. @coleifer Great!. It seems that this is a stupid idea ;)\nAt least ifworker_type=\"process\"`\nAnd it seems that changes in tasks.py are not applied, after reload.. Ah! I didn't realize that the task is executed in \"always_eager\" mode and you don't need a separate consumer process. That's great.. Next question: How to store the return value of the task? Just accept only None and String? Or use repr() or pprint.pformat() or json or pickle ?\nIn celery is the \"result_serializer\" settings: http://docs.celeryproject.org/en/latest/userguide/configuration.html#result-serializer and used json as default and has built-in support for JSON, pickle, YAML and msgpack: http://docs.celeryproject.org/en/latest/userguide/calling.html#calling-serializers\nThis flexibility in celery is nice, but that's why it's so complex ;) That's why I think there should be no setting for it.\nThe target in the database is a text field. It would be good to have human readable entries in it.\nSo I would say spontaneously to json: But then you have the problem that json can't serialize everything. Pickle could, but it's not human readable.\nSo pprint.pformat() but that would be a little unusual, wouldn't it?\nSo: just allow a string. (and the task may serialized it, if needed?). OK, i start as separate project ;). Maybe set UNBUFFER environment variable, helps?. I better explain why I need all this: I want to write integration tests. I want to test the complete stack with redis server and without \"always_eager\" ;)\nSo, i need a solution to wait in tests for the completion of tasks. I'm trying to implement this as a context manager. It looks like this:\n```\nwith WaitUntilHueyTaskEnded(, timeout=2):\n    self.client.get(...)\nself.assert_task_are_done()\n```\nSo the real question is: How to wait for task completion??\nCurrently my idea:\n\ncollect all pending IDs only for <task_func>\nwait until all pending tasks are done by if result != EmptyData\n\nBut maybe everything is much easier to solve?\n\npending_task_ids = [task.task_id for task in huey.pending()]\n\nThat doesn't help my function get_pending_ids_by_func(task_func)\nI didn't want all pending tasks IDs: I only want the IDs for a given task func ;)\nThe return values are deleted when they are retrieved. How long are they stored if they are not retrieved? Forever?\n. This isn't about testing Huey himself. It's about testing the whole stack. That includes huey and redis as backend...\nIn my case it's a docker compose project and django, huey, redis (and more) services are in separate containers.... I now try store_none=True but this doesn't help here:\nI'd have expected that HUEY.get(key=task_id, peek=True) return EmptyData as long as the task is not finished. But it returns None as long as the task is running :(\nBut it's coded to deliver None back: huey.api.Huey.execute() looks like:\ndef execute(self, task):\n        ...\n        result = task.execute()\n        ...\n        if self.result_store and not isinstance(task, PeriodicQueueTask):\n            if result is not None or self.store_none:\n                self.put(task.task_id, result)\n        ...\n. Now i found a working setup:\n\nresult_store=True and store_none=True is needed\nreplace HUEY.get() with HUEY.storage.has_data_for_key(<task_id>)\n\nhas_data_for_key is only True if task has been finished.\n. > Why not just block when reading the result from the task itself?\nI can only do this, if i start the task directly in the test code... But e.g.: the test code used the django test client and the view calls the task... I can't easy make .get(blocking=True) isn't it?\nOkay: I can try to patch the code via unittest.mock... But this is everytime a little bit tricky.... I'm changing my approach and check: HUEY.all_results()\nall_results() returns a dict with the task id as keys. But I can't find a way to get the actual task class based on that task id.. > The fix would be, wherever you're calling pending(), to ensure that all tasks have been imported by that point.\nI'm sure the task is registered.\nAdding a time.sleep(0.1) in the task fixed that. So i think it's a timing problem.\n. Think it's a good idea to insert more examples in the docs, isn't it?. I made this in #362. ",
    "joealcorn": "Fair point, ideally (imo) the new way would be documented and the old deprecated. Instead I will just see if I can subclass SqliteHuey and add the enqueue method that way. ",
    "rfyiamcool": "so so. ",
    "amcclanaghan-kvh": "Looks right.  I'll apply this locally and let it run in dev for a bit.  Thanks for the quick response!. Passing for me and desired result achieved; huey.results.huey much less noisy.  Thanks again!. ",
    "sloweclair": "OS: Debian 9\nDjango: 2.0.1\nHuey: 1.7.0. Ahh that was the key,\nI setup the logging in the settings, so I added huey.consumer loggers and its working.\nThanks!. ",
    "yarwelp": "I mean in terms of operating systems. ",
    "umang0202": "Here's our configuration (from django's settings.py):\nHUEY = {\n    'name': database_name,  \n    'result_store': True, \n    'events': True,  \n    'store_none': False,\n    'always_eager': False, \n    'store_errors': True,\n    'blocking': False,\n    'backend_class': 'huey.RedisHuey',\n    'connection': {\n        'host': host_name,\n        'port': 6379,\n        'db': 3,\n        'connection_pool': None,\n        'read_timeout': 1,\n        'max_errors': 1000,\n        'url': None,\n    },\n    'consumer': {\n        'workers': 20,\n        'worker_type': 'thread',\n        'initial_delay': 0.1,\n        'backoff': 1.15,\n        'max_delay': 10.0,\n        'utc': True,\n        'scheduler_interval': 1,\n        'periodic': True,\n        'check_worker_health': True,\n        'health_check_interval': 1,\n    },\n}\nNo errors are being logged. Logs are full of \"Sleeping for 0.999596118927002\"s. Turns out our db connections were dying out. We caught the error and forced a \ndjango.db.connection.close()\nIt worked!. ",
    "isergey": "http://c1.backup4all.com/uploads/backup4all_en/media_items/task02.640.482.s.png\nFor example. Video converter run once at hour. It is mean than convereter must complete the work in less than an one hour. But sometimes the \u0441onverter works more than an hour, because of what the next start of the task is skipped. I want to start skepped task immediately after finish previouse overtime task.. @coleifer thank you very much for help! Everything works!. ",
    "Jafte": "\nAre you using gevent/greenlet workers?\n\nyes, my starting parammeters:\nhuey_consumer.py app.huey -l huey.log -q -k greenlet -w 100\nstarting time increase to 5-10 seconds by day. ",
    "diegocortassa": "I'll have a look at it, thanks for your help!. ",
    "ctsrc": "I was using threads first but because the task is long running and CPU heavy it blocks all other tasks from running until it has completed.\nWhile you don't want to fix this issue yourself would you accept pull requests if someone else were to fix it? Don't have time to do so myself atm but might in the future if I know that PR would be accepted.. This task takes several minutes to complete and only performs a very little amount of I/O and it does all the reading up front and all the writing at the end so once it's running it runs till completion which is why only multi-process parallelism will help me.. What would happen if I were to run multiple instances of huey_consumer side by side? Would that be safe and give me parallel execution, or could race-conditions occur such that multiple consumer instances start the same task, or would it just lead to straight up corruption right off the bat?. It turned out to be not quite like I said -- it does switch a little between tasks when threaded. Still it is CPU heavy and it ends up taking a lot of time. Even more so when I have multiple of that kind of task running of course and it's a shame to not be able to utilize the multiple CPU threads which could have reduced the time taken by a lot. The last question I asked still stands though wrt what would happen if I were to run multiple instances of huey_consumer side by side.. I am making this software for someone else. Personally I don\u2019t run Windows on any of my computers. The choice for the server that this will run on to be running Windows Server was not a choice of my own. They are using that server for other things already. If we were setting up a dedicated server I would have requested that it run Linux.\nPersonally I think Windows is a horrible experience in every way possible.\nAnyway I landed on Huey because it seemed nice to use and sufficiently documented. The other alternatives I looked at either stated that they didn\u2019t support Windows (for example Celery said this) or they seemed too convoluted or too lacking in documentation.\nSome parts of Huey were a bit difficult to understand and I struggled a bit with it but all over I am glad that Huey exists and that I chose to use it despite not being able to use the \u201cprocess\u201d option and despite some problems that I had that even though I eventually managed to get the SQLite mode running on the Windows 7 laptop I am developing on still prevents me from using SQLite as broker on the Windows Server. The issue in question has to do with pewee but I have not reported it because I am going to use Redis instead of SQLite as broker.\nGlad to hear that running multiple Huey instances side-by-side should be fine. Thank you.. ",
    "amcclanaghan": "Looks like a nice addition.  Will give this a go in dev.  Thanks!. ",
    "blablacio": "I'd say mostly aesthetic reasons. It's easier to just import it from djhuey along with decorators instead of importing HUEY and using HUEY.enqueue.. I'm using enqueue for pipelining like this:\nenqueue(\n    fetch.s(\n        link,\n        crawl=True\n    ).then(\n        parse_link,\n        link\n    )\n)\nAm I getting it wrong?. ",
    "logannc": "This also makes restarts graceful, by default.. They do not. KeyboardInterrupt is raised by https://github.com/python/cpython/blob/master/Modules/signalmodule.c#L194 .. Personally, I have a huey_consumer running as a service on ubuntu (which means systemd, now, IIRC).. Sure... gimme a minute.. KeyboardInterrupt is caught 6 times in this codebase, excluding tests.\n\napi.py#Ln222 reraises the exception, so it doesn't really matter.\nconsumer.py#Ln179 reraised the exception\nconsumer.py#Ln266 receives a KeyboardInterrupt which cancels the execution of a task in a worker. Without modifying our current approach, this cancellation would not occur and the process would only stop/restart when the main thread/greenlet resumed execution.\nconsumer.py#Ln591 ignores KeyboardInterrupts.\nconsumer.py#Ln651 treats a second SIGINT as a sign to ignore waiting on the remaining workers to join and just terminate early. This would be a change, but only if joining on the workers was an issue.\nconsumer.py#Ln668 the normal KeyboardInterrupt catch, which initiated a graceful stop. It would do nothing now, but wouldn't really change behaviour.\n\nNow that I think about it, really I was trying to solve two problems: 1) make sure a signal handler was assigned and 2) make restarts graceful.\nI can accomplish the first by just always setting the default python handler. We don't actually need to set our own, your code already works with the default one, we just need to fix the weird edge case when python doesn't set a handler.\nThe latter I can do by just making graceful stops the default, with SIGTERM the exception setting the stop to non-graceful.. Ah, it might be. I hadn't thought to check if the signal library differed in 2.x.. ",
    "gchadder3": "I just tried import gevent and it fails in a similar way, so I guess this is probably an installation problem with gevent on my machine.. I had some problems uninstalling and reinstalling gevent, but after resolving those, both gevent and huey import within both Spyder and the python interpreter.  However, for some reason, I still get:\nC:\\GitRepos\\OptimaRepos\\Nutrition\\nutrition\\hueytest>huey_consumer.py main.huey\nTraceback (most recent call last):\n  File \"C:\\Users\\gchad\\Anaconda2\\Scripts\\huey_consumer.py\", line 6, in <module>\n    from huey.consumer import Consumer\nImportError: No module named huey.consumer\nNot sure why things would import in Spyder and python, but fail from the script.. Okay, I was able to work around this by doing:\npython C:\\Users\\gchad\\Anaconda2\\Scripts\\huey_consumer.py main.huey\nI guess there must be some kind of path problem on my setup, so I need to actually use python to call the script rather than depending on my OS to properly execute it.\nSo now the tutorial example is up and running and works fine.\nHope this is helpful to someone.. ",
    "GrayCygnus": "@leench  thank you. You helped me figure out how to obtain the huey instance object, so I could then subscribe to the events channel (HUEY.storage.listener()) . ",
    "danielecook": "Awesome - thank you!. Ah - I thought this would also include task_value and exc for testing... (looks like you can easily pass task_value to the callback?) but I think I can work around it for now. I looked at the code a bit and there is a large block dedicated to catching exceptions so it might be cumbersome to add. Either way this is helpful - thanks.. Thank you very much! Very helpful! Congrats on the 600th commit!. ",
    "bobozar": "working all of a sudden!. ",
    "timkock": "@coleifer that was quick! thank you kindly. ",
    "ChefJ": "Well...Thanks for your comment..\nI forgot to paste that lock part . I do add lock to the the fetchexchanger(),but the fetchexchanger() would   done is work quickly due to all the fetchexchangerworker() are executed as task. If fetchexchanger() hits it's next period while the fetchexchangerworker() called by the former are not all ended, the task will accumulate,which would eat the resources up..\nGive a lock to fetchexchangerworker() do solve the problem , but that would be slow..... That's awesome !!!\nThanks a lot for giving me this fantastic solution!. Hey dude.\nusing this may can help you checking the task status.(and maybe you can re-enqueue the task when failed)\nhttps://huey.readthedocs.io/en/latest/events.html?highlight=huey.storage\nhowever, I failed to use this 'storage' thing....\nGood luck to you and I'll Really appreciate if you can share your progress.. ",
    "ovalseven8": "I was passing Django's Request object and a Form object to the task. Removed that, sounds like it does not work with those objects.\nIs that normal?. Thanks for your answer.\nWhile trying to debug this I just thought that it could have something to do with always_eager set to True/False. I mean, somehow it had an effect. Turns out, it also has something to do with the urlpatterns defined in urls.py.\nToday I did some further tests and now I can at least isolate the problem and it's indeed a problem caused entirely by django-debug-toolbar.\nSo, you're right with \"I think you do not understand it\". But, honestly, this behaviour is not that easy to understand. :smile: . @coleifer: Just in case you're interested: https://github.com/jazzband/django-debug-toolbar/issues/695#issuecomment-414113249. ",
    "huangxiaohen2738": "Maybe it's a trouble. Because,  the task has not arguments which was in the error queue.\nLoads the error info which in error queue, I get: \n{'retries': 0, 'task': 'queue_task_test', 'traceback': 'Traceback (most recent call last):\\n  File \"xxxx/api.py\", line 380, in execute\\n    result = task.execute()\\n  File \"/xxx/huey/api.py\", line 880, in execute\\n    return func(*args, **kwargs)\\n  File \"/xxxx/task.py\", line 78, in test\\n    raise\\nTypeError: exceptions must be old-style classes or derived from BaseException, not NoneType\\n', 'execute_time': None, 'error': \"TypeError('exceptions must be old-style classes or derived from BaseException, not NoneType',)\", 'retry_delay': 0, 'id': 'e2a41d7c-9896-49ee-9c7d-c70f8720bd69'}\nI want to run again,  but no arguments\nThe reason:\n  the function _get_task_metadata which in api.py,  the args include_data is still False.. ",
    "FelixSchwarz": "Thank you for quick answer. I'll check if I can make it work quickly - otherwise I'll look for other options :-). > I don't know if huey works on windows in multi-processing mode, probably not.\nJust so others might save some time if they research this: Huey Huey doesn't work on Windows (at least for worker processes) due to Windows limitations. Basically everything which is passed to the workers must be \"picklable\" and on Windows only static top-level functions can be pickled (source and source). Internally huey relies a lot on dynamically creating callables which are passed to workers.\nSo again a case where Windows is just too limited. I guess I forget too often how easy Unix/Linux is - until I have to build something which also works on Windows.... For example because they need some data from them :-) But the database was just one example.\nFor example a task may be to extract some text from a document and to store the text in an elasticsearch server - need elasticsearch hostname, index name etc.  Or the task should generate a report which takes up to a few hours or so (and the result is - stored in the database). \nAlso some (older) frameworks rely on global state which needs to be initialized. Basically this is about having control over workers.. > I don't want to be presumptuous, but I don't get the impression that you understand very well how huey works.\nThat is certainly possible :-) - though I implemented quite some tasks with celery which should be similar in nature.\n\nIf you need to connect to elasticsearch to push some data up to it, you would theoretically pass any connection information to the task.\nIf the task is generating a report and writing to the database, then inside your task function you would open a connection to the database and perform your writes, and close it afterwards.\n\nThat is certainly a way of approaching it but in my case I think it means a quite a bit of overhead (ElasticSearch is easy because it is just a simple HTTP request). My current use case is to push about 10-50k tasks during peak hours and in the past we achieved measurable gains (I'm adapting existing code which was used in different scenarios) by reusing DB connections (and similar resources).\nHowever based on your reply I'll just try to do everything per task and see how bad the performance hit actually is. If its too bad I'll check if I can either add some quirks to huey (as I did with a multiprocessing-based adaptation) or need to go to a different library.\nPS: Thank you again for your stellar support :-). Thank you - that looks very much like the API I had in mind, The only issue for me is now how to pass data to the .on_startup() function. Probably the huey instance could store that data but I think I have an idea at least for my immediate needs.. ",
    "Balykovsky": "@coleifer Thank you for response. i'll try to solve this problem and then post it here in comments.. ",
    "vrbrito": "\nOK, i start as separate project ;)\n\nAny updates on that? I would be interested in seeing what you've got.. ",
    "ttt733": "capsys.disabled() is just a pytest command that stops it from eating\nconsole logs and lets me show you the output I put towards the bottom of my\npost. (Seeing the same behavior with it removed.) There's not much in the\nway of setup code for our tests. Is there any particular part of the\nsetup/configs you're interested in? I'm not sure what additional info about\nthat I can provide - I'd probably need to get approval to post a more\nsignificant amount of the code involved, and I'm not sure it'll help. I\ncould probably get that on Monday for you, but as I said, the tests work\nwhen the function being tested is not decorated with huey.task(), so I'm\nthinking it has more to do with Huey or the way we're using it than the\nserver/test logic.\nRunning pytest on our project with a debugger is a somewhat finnicky\nprocess, but if you think that's an avenue I should pursue, I can put some\ntime in to getting that running on Monday and see where it's hanging.\n(Worst case, I think I could figure out where to hack some print statements\nin, or try writing a more minimal breaking case in a new project.) I just\nthought that, since it works without the scheduling layer (which, from my\nunderstanding, should be pretty thin with always_eager=True set) I should\ncheck and see if there was something obvious we weren't doing correctly\nwith it or if there might be another issue here.\nIf there are any watchers who happen to be looking and are successfully\nrunning tasks through pytest in a similar fashion (i.e. without pipelines,)\nusing the always_eager scheduler and Huey>=1.10.0, I'd appreciate seeing\nsome snippets of your implementation.\nOn Fri, Sep 7, 2018, 7:36 PM Charles Leifer notifications@github.com\nwrote:\n\nI have no idea what might be going on in your setup, in your functions, in\n\"capsys.disabled()\", etc, etc.\nCould you identify where exactly in huey the code seems to be hanging?\nHave you tried setting a breakpoint and stepping into the code? As-is this\nis completely useless information you have provided me.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/coleifer/huey/issues/363#issuecomment-419598991, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AGfzpnWqT_iKX7MEMTws94oyY0RXevcZks5uYxEIgaJpZM4WfePp\n.\n. >And you don't suspect that this might be the problem?\n\nNo; it's something I heard other devs complain about, but it's just a weird interaction between VScode and pytest. pdb works fine, though. Here's what I'm seeing (- still with the handle_event task from the original post, which takes an Event object as an argument.)\nWhen the always_eager flag is set to true, it goes through _execute_always_eager and goes to task.execute() as expected. However, once in the task.execute() method, I'm seeing something odd.\n```\n(Pdb) ll\n874         def execute(self):\n875             args, kwargs = self.data or ((), {})\n876             if retries_as_argument:\n877                 kwargs['retries'] = self.retries\n878             if include_task:\n879                 kwargs['task'] = self\n880  ->         return func(args, *kwargs)\n(Pdb) p func\n\n(Pdb) p args\n\nSo args gets set to just that Event object. Now, I found this on the Event object, which might have a lot to do with what happens next:\n    def getitem(self, item: str) -> Any:\n        return self.dict.get(item)\ndef get(self, key: str, default: Any = None) -> Any:\n    return self.__dict__.get(key, default)\n\n``\nNow, if I step one more time, rather than taking me to thehandle_eventfunction, it takes me to thegetitemfunction. (I'm assuming it does this in the course of trying to handle the*args` in execute.)\n```\n(Pdb) s\n--Call--\n\n.../metronome/event.py(161)getitem()\n-> def getitem(self, item: str) -> Any:\n(Pdb) p self\n\n(Pdb) p item\n0\n``\nAnd the infinite loop seems to come from the fact that, from there, it keeps callinggetitem` over and over again.\n\n```\n(Pdb) s\n\n.../metronome/event.py(162)getitem()\n-> return self.dict.get(item)\n(Pdb) s\n--Return--\n.../metronome/event.py(162)getitem()->None\n-> return self.dict.get(item)\n(Pdb) s\n--Call--\n.../metronome/event.py(161)getitem()\n-> def getitem(self, item: str) -> Any:\n(Pdb) ll\n161  ->     def getitem(self, item: str) -> Any:\n162             return self.dict.get(item)\n``\nTheitemargument increases every few steps. I'm not super familiar with Python internals, but I'm guessing that's part of how it's trying to interpret the Event object as a list of arguments when *args is used in execute. My best guess at a diagnosis is that it should be something likeargs=[self.data]` in the execute function when it's coming from _execute_always_eager, since the data isn't put through the processes it normally is when a task is enqueued. Could be off, though - hope that's concrete enough for you to take a look at.\n\n(Edit to add: I still have no idea how the single console interrupt letting things move forward plays into this. I thought that alone might be enough to go on, but having looked at the code as it runs, I'm just more confused about that than before. I'm chalking that up to some python internal thing as well for now.). Yeah, this is strange. I tried it with your minimal case in the same virutalenv, worked out to run through pytest and everything, and it works. Debugging got me this:\n(Pdb) ll\n874         def execute(self):\n875             args, kwargs = self.data or ((), {})\n876             if retries_as_argument:\n877                 kwargs['retries'] = self.retries\n878             if include_task:\n879                 kwargs['task'] = self\n880  ->         return func(*args, **kwargs)\n(Pdb) p self.data\n((<Event: name={'name': 'event1'}>,), {})\n(Pdb) p args\n(<Event: name={'name': 'event1'}>,)\nAs shown above, when I printed args on my project at the same point , I got this:\n(Pdb) p args\n<Event{'id': None, 'uuid': None, ...}>\nSo it's not as simple as I hoped. I'll do some more digging and see why it's going in as an Event rather than a tuple in my project.. Ugh, this can stay closed. Someone wrote a handle_event.schedule() call that I didn't know about into our code with args=(Event.create(**kwargs)) instead of args=(Event.create(**kwargs),), so python just ignored the parentheses and didn't put it in as a tuple. Sorry about the hassle.. ",
    "chrisk314": "Thanks for the quick reply and suggesting some different approaches. As I don't want a proliferation of specific task handling functions for every combination of functions that may need to be executed in sequence I have gone with using a pipeline and changing the first function to not return anything. This is working for my purposes. Thanks again.. ",
    "mojeto": "great, thank you . ",
    "rammie": "Would you be open to a PR that abstracted serialization across the board?\nAlso, one last ditch effort to convince you that it is worthwhile to support this at some point - https://www.benfrederickson.com/dont-pickle-your-data/. ",
    "MisLink": "@jedie Thanks! Setting environment variable PYTHONUNBUFFERED=1 let my program work fine. . ",
    "simplynail": "sorry @coleifer should have went to sleep, looks like it was the highest time... . ",
    "kultz": "Name: huey\nVersion: 1.10.1\nSummary: huey, a little task queue\nHome-page: http://github.com/coleifer/huey/\nAuthor: Charles Leifer\nAuthor-email: ****@gmail.com\nLicense: UNKNOWN\nLocation: /usr/local/lib/python2.7/dist-packages. Updating to 1.10.3 solved the issue.. ",
    "NMelis": "those that do not work. ",
    "alexandredufour": "@coleifer \nForgot to explicitly mention that we're using the thread consumers. But yes that's our concern. Multiprocess worker/scheduler is not an option for us as we are already struggling with memory usage.  Do you want me to edit the PR so it only affects consumer running on thread? I haven't tried with greenlets, so I'm not sure it's needed. . ",
    "laurrentt": "@coleifer (I work with @alexandredufour )\nFirst of all, thanks for answering so fast \ud83d\ude04. \nI'm not against using a process manager, however in my opinion that's not the correct approach. Here's a rundown of why I think it should be handled by Huey:\n- The SIGHUP signal is supported and documented by Huey, so I think that even when using thread it should not leak fds by default. \n- We found other projects using os.execl that relied on the proposed code change for cleaning up opened fds (1,2).\n- We run this in a docker container and it's recommended to run the main process as PID 1. The use of a process manager is not recommended. \nIn short, my recommendation would be to either implement the proposed changes or stop supporting SIGHUP restarts when using thread or gevent and documenting why and how to workaround the issue.. ",
    "lsetiawan": "@coleifer Thanks for the thorough answer. That is very helpful. I have lots of tasks that read and write files and perform database inserts so that seems like an IO-bound tasks rather than CPU since I am not performing any computations. I will try the blocking mode and see if anything changes. :+1: . Hmm... interesting. Good to know. Thanks for the info!. ",
    "valhallen13": "Hi again, \nalthough i forgot the comma when writing this issue, the comma does exist in my code, so that is not the issue.. Thanks for the help. \nI realized i should have also specified that while upgrading django I also upgraded huey from 0.4.8 to 1.10.4. Maybe in between these 2 version some things changed that are backwards incompatible?\nI am looking more into this and I noticed 2 extra things: \n1) if i do redis-cli monitor \n1544620470.141828 [0 127.0.0.1:46743] \"EVALSHA\" \"a08640cb6d2244b627dffdfd70c3f445d8c9cf2c\" \"1\" \"huey.schedule.gekkotasks\" \"1544616870.0\"\n1544620470.141878 [0 lua] \"zrangebyscore\" \"huey.schedule.gekkotasks\" \"-inf\" \"1544616870.0\"\n1544620470.430138 [0 127.0.0.1:51521] \"EVALSHA\" \"a08640cb6d2244b627dffdfd70c3f445d8c9cf2c\" \"1\" \"huey.schedule.gekkotasks\" \"1544616870.0\"\n1544620470.430185 [0 lua] \"zrangebyscore\" \"huey.schedule.gekkotasks\" \"-inf\" \"1544616870.0\"\n1544620470.949141 [0 127.0.0.1:51774] \"EVALSHA\" \"a08640cb6d2244b627dffdfd70c3f445d8c9cf2c\" \"1\" \"huey.schedule.gekkotasks\" \"1544616870.0\"\n1544620470.949207 [0 lua] \"zrangebyscore\" \"huey.schedule.gekkotasks\" \"-inf\" \"1544616870.0\"\n1544620471.141796 [0 127.0.0.1:46743] \"EVALSHA\" \"a08640cb6d2244b627dffdfd70c3f445d8c9cf2c\" \"1\" \"huey.schedule.gekkotasks\" \"1544616871.0\"\n1544620471.141845 [0 lua] \"zrangebyscore\" \"huey.schedule.gekkotasks\" \"-inf\" \"1544616871.0\"\n1544620471.429755 [0 127.0.0.1:51521] \"EVALSHA\" \"a08640cb6d2244b627dffdfd70c3f445d8c9cf2c\" \"1\" \"huey.schedule.gekkotasks\" \"1544616871.0\"\n1544620471.429816 [0 lua] \"zrangebyscore\" \"huey.schedule.gekkotasks\" \"-inf\" \"1544616871.0\"\n^C\nI don't see the huey.schedule.gekkotasks key exist, if i do keys * . \n2) I also noticed another error that probably is related. It happened when i did the upgrade  but i got it around 7000 times :\nScheduleReadException\nResponseError: Error running script (call to f_a08640cb6d2244b627dffdfd70c3f445d8c9cf2c): @user_script:3: WRONGTYPE Operation against a key holding the wrong kind of value\nhuey/api.py in read_schedule at line 510\n        ex_time = task.execute_time or datetime.datetime.fromtimestamp(0)\n        self._add_to_schedule(msg, ex_time)\n    def read_schedule(self, ts):\n        return [self.registry.get_task_for_message(m)\n                for m in self._read_schedule(ts)]\n    def read_periodic(self, ts):\n        periodic = self.registry.get_periodic_tasks()\n        return [task for task in periodic\n                if task.validate_datetime(ts)]\nIf you have any suggestions, it would be highly appreciated.\nThanks,\nTudor . ",
    "ErickGSJ": "@coleifer\nI just want to schedule tasks dynamically, using decorator couldn't do that, so i use enqueue func adding tasks to queue, it works. But if execute_time is configured, the task will never be scheduled.\nThanks in advance. ",
    "samsagaz": "Tested the 2nd choice and works!\n. ",
    "teodoricoramos": "Hi, sorry for not explaining clearly.\nIn my setup, there is a main task (called send_to_queue) that sort of acts like a queue manager.\nWhat its doing is executing the \"work\" tasks and sending them to the queue.\nAll the work tasks are placed in a directory and imported dynamically and executed dynamically also. \nThe sequence of executing the work tasks is dynamic (read from an excel config file).\nAn example of work flow is like this:\nwork_task_1 (repeat n times)\nwork_task_2 (repeat n times)\n...\nwork_task_n\nWhat was shown above was a single work flow that will be executed sequentially by the queue manager.\nThe queue manager can be invoked multiple times to execute different work flow at the same time.\nIn this case, there will be at least 3 queue manager running at the same time as separate tasks and each of this are executing their own work flow. For example,\nQueue Mngr Task 1 (Work Flow 1)\nwork_task_A (repeat 20 times)\nwork_task_B (repeat 30 times)\nQueue Mngr Task 2 (Work Flow 2)\nwork_task_B (repeat 10 times)\nwork_task_C (repeat 10 times)\nwork_task_A (repeat 5 times)\nIn the queue manager (send_to_queue) the line that executes a work task is like below:\nhandler = getattr(work_tasks_module, task_name)(args)\nThe problem that I encountered is that 2 different queue manager tasks executing the same work_task but different arguments can sometime get \"the same UUID\" causing one of the 2 to not be executed at all.\nFor an example, please see the below logs:\n[2019-02-02 12:13:19,239] INFO:huey.consumer.Worker:Worker-7:Executing test_modules.sample_group.test_save_results.queue_task_test_save_results: f1eb2270-12ab-44a8-9a28-47424e5855b5\n[2019-02-02 12:13:19,604] INFO:huey.consumer.Worker:Worker-5:Executing test_modules.sample_group.test_save_results.queue_task_test_save_results: f1eb2270-12ab-44a8-9a28-47424e5855b5\nIn this case, there are 2 queue managers. The first one executed the task test_save_results in worker 7.\nAnd the other queue manager executed also the task test_save_results in worker 5.\nThe problem is, they both get the same UUID:\n f1eb2270-12ab-44a8-9a28-47424e5855b5\nThis resulted in only one task executing. The other one did not since it was masked by the other one with the same UUID.\nI invoke my consumer like below:\nhuey_consumer lib.manager.huey -w 8\nAnd all the tasks uses the @huey.task() decorator.\nHope this explains the case clearly and I apologize for my bad phrasing as my English is not that good.\nPlease do tell me if you need more info.\nThank you for creating this library. It is very easy to use and very solid.. ",
    "thomassross": "What I'm suggesting is a way to disable result storage at call time, so you can have a task that can be called discarding the result and storing the result:\n```python\n@task\ndef my_task():\n    return True\n@task\ndef my_task_discard_result():\n    my_task.call_local()\ndef use_one():\n    # Queue my_task and print the result\n    res = my_task()\n    print(res(blocking=True))\ndef use_two():\n    # Queue my_task and ignore the result\n    # This does what I'm suggesting, but it's a bit convoluted\n    my_task_discard_results()\n# do some other stuff...\n\ndef use_three():\n    # My suggestion\n    my_task.call_no_result()\n# or maybe\nres = my_task()\nres.discard_result()\n\n# do some other stuff...\n\n```. ",
    "santiavenda2": "I thought about that but I chose this implementation because is more general and is able to manage other platforms that don't support SIGHUP signal.\nLet me know if you prefer to user sys.platform to check that and I will make the change. thank you :+1: . ",
    "rsalmaso": "autodiscover_modules is available from django 1.7 https://github.com/django/django/commit/6feb75129f42fdac751d0b79a2a005b4c0ad5c2d\nso I think it could be used directly.. "
}