{
    "vohof": ":+1: Thank you for creating this tool.\n. :+1: Thank you for creating this tool.\n. ",
    "robertcollier4": "Thanks, great software. Would also really like to be able to upload to folders! Currently when I do a command such as:\ndrive.exe upload --file testfile.txt --title redfolder\\testfile.txt\nit still uploads the file to the root directory but with a backslash in the filename. Would be nice to interpret a backslash or forwardslash as meaning to put it in the redfolder.\nWould also be nice to have the \"list\" command show which folder the file is in.\n. Thanks, great software. Would also really like to be able to upload to folders! Currently when I do a command such as:\ndrive.exe upload --file testfile.txt --title redfolder\\testfile.txt\nit still uploads the file to the root directory but with a backslash in the filename. Would be nice to interpret a backslash or forwardslash as meaning to put it in the redfolder.\nWould also be nice to have the \"list\" command show which folder the file is in.\n. ",
    "xiconet": "Could you please provide some details for the -q option? It's hard to deduce the correct syntax based only on the url you provide. Thanks in advance.\n. OK, I finally found how to make it work. Thanks for this nice tool.\n. Could you please provide some details for the -q option? It's hard to deduce the correct syntax based only on the url you provide. Thanks in advance.\n. OK, I finally found how to make it work. Thanks for this nice tool.\n. ",
    "treeder": "You can upload to a folder by specifying the parent id with -p in upload. \n. @BoiseComputer did you use the -p option to specify the folder?\n. I submitted a pull request for this already,  #26 \n. You can upload to a folder by specifying the parent id with -p in upload. \n. @BoiseComputer did you use the -p option to specify the folder?\n. I submitted a pull request for this already,  #26 \n. ",
    "BoiseComputer": "I see I can create a folder in the application, but, I cannot upload files to that folder. The upload command is limited to the root of the folder. Are we missing some command arguments to accomplish this?\n. I see I can create a folder in the application, but, I cannot upload files to that folder. The upload command is limited to the root of the folder. Are we missing some command arguments to accomplish this?\n. ",
    "prasmussen": "--parent / -p is used to specify the parent directory, examples has been added to the README.\n. Fixed in version 1.0.2 (4a3888aaf6)\n. I was able to reproduce the problem and I got the following error:\n```\npanic: invalid memory address or nil pointer dereference\nfatal error: panic during gc\n[signal 0xb code=0x1 addr=0x1 pc=0x8054162]\ngoroutine 1 [syscall]:\n[fp=0xf73238dc] syscall.Syscall()\n    /usr/local/go/src/pkg/syscall/asm_linux_386.s:14 +0x5\n```\nAfter recompiling the binary with go1.2 I have not been able to reproduce the problem. Can you see if the new binary works for you as well?\n- drive-linux-386 v1.0.2\n. Cool!\n. I don't mind at all, this is great.\n. The argument parser has been replaced in in gdrive 2 and -i is no longer required.\n. I don't think this is a reproduceable problem in newer versions of gdrive.\n. Im currently working on gdrive v2, which will support update.\n. gdrive 2 is now available.\n$ gdrive update 0B3X9GlR6EmbnNTk0SkV0bm5Hd0E gdrive-osx-x64\nUploading gdrive-osx-x64\nUpdated 0B3X9GlR6EmbnNTk0SkV0bm5Hd0E at 2.0 MB/s, total 8.3 MB\n$ gdrive revision list 0B3X9GlR6EmbnNTk0SkV0bm5Hd0E\nId                                                    Name             Size     Modified              KeepForever\n0B3X9GlR6EmbnOFlHSTZQNWJWMGN2ckZucC9VaEUwczV1cUNrPQ   gdrive-osx-x64   8.3 MB   2016-02-21 20:47:04   False\n0B3X9GlR6EmbndVEwMlZCUldGWUlPb2lTS25rOFo1L2t6c2ZVPQ   gdrive-osx-x64   8.3 MB   2016-02-21 21:12:09   False\n. Thanks @igloosPat :)\n. Basic progress bar is enabled by default for larger files in gdrive 2.\n. @szepeviktor: you might get better help setting up a go dev environment on stackoverflow.\n@kylecordes: relative imports seems to be discouraged in go.\n. @cagnulein: the pull request from @treeder is merged and is available in the 1.3.0 version\n. I'm not familiar with trickle but looking at the man page it says \u201ctrickle will not work with statically linked executables\u201d. That is probably why it does not work width gdrive as all go applications are statically linked.\n. gdrive 2 supports recursive download: gdrive download -r <id>\n. GDRIVE_CONFIG_DIR environment var is available in gdrive 2.\n. In 1.7.0 there is a new flag --include-docs that will include google docs in the listing and a --format flag to download a google doc in a specified format.\n. Recursive upload has been added in 1.4.0. It replaces the old behaviour which only took the first directory.\n. Was fixed some time ago.\n. In 1.7.0 there is a new flag --include-docs that will include google docs in the listing.\n. This has been fixed in gdrive 2.\n. Thanks!\n. Try gdrive 2 if this is still a problem.\n. You can use the --order flag with gdrive 2:\ngdrive list --order \"name asc\"\ngdrive list --order \"modifiedTime desc\"\n. Resumable uploads requires the size of the file up-front, thats why its not used when uploading via stdin, as I have no way of knowing the size.\nI see that pv takes the filesize in as an argument, that could be a solution for gdrive as well. What do you think?\n. Agreed\n. Oh, thats too bad.\nI haven't followed the code to see what happens to the Reader, so i don't really have any other ideas at the moment. Im guessing seeking is required when resuming an upload -- I'm not sure why you get a seek when doing a normal upload though.\nIf you get the wrapper to work and it seems reliable, I will accept the pull request and I could mark it as an experimental feature or something.\n. Sounds promising :)\n. ResumableMedia has been deprecated in google-api-go-client and the problem with long uploads failing with Media seems to be fixed according to my tests with gdrive 2.\nbash\n$ cat video.mp4 | pv -q -L 50k | gdrive upload - video.mp4\nUploading video.mp4\nUploaded 0B3X9GlR6EmbnSFRwSTNMZkY3Nzg at 51.2 KB/s, total 1.8 GB\npv -q -L 50k  21.88s user 18.02s system 0% cpu 10:00:43.71 total\n. Good catch @cnbeining.\nThe chunk size seems to be defined here: https://github.com/google/google-api-go-client/blob/master/googleapi/googleapi.go#L303\nI will experiment a bit the value to see if it helps the upload speed.\n. There is definitively an improvement.\nAt 2^19 bytes i don't see any great speed boost, but at 2^20 i more or less max my 50mbit connection.\nI think I will set 2^20 as the default and add a command line flag as @cnbeining suggested, to override the value if needed.\n. Version 1.6.0 has a default chunk size of 2^20 bytes (1MiB) and can be changed with the -C flag.\n. I've added the drive quota command in 1.8.0 which will print out free space, etc. I've also added a --bytes flag to info, list and quota to force size in bytes.\nI wont be implementing the min_free_space logic at this time, but it should be possible to write a wrapper script now that checks for free space before uploading.\n. gdrive 2 has the update command which will create a new revision of a single file. gdrive 2 also has some new sync commands that can be used to update multiple changed files. Readme contains an example.\n. gdrive 2 includes a couple of new sync commands that can be used to update changed files. The readme contains an example.\n. Thanks @hwiorn for doing the research :)\nI've just released gdrive 1.9 which uses os.Chdir, hopefully this will fix directory upload on windows. I don't have a windows machine to test it myself so feedback is appreciated.\n. Great, thanks.\n. gdrive 2 lets you specify multiple parents:\ngdrive upload --parent 0B3X9GlR6EmbnR1pNR1FsRGR2bWs --parent 0B3X9GlR6EmbndHlqbWVxSi16WVE foo.txt\n. The readme now contains some more information regarding this under installation instructions.\n. Have not been able to reproduce this. I would suggest trying gdrive 2 and see if you still experience the same problem.\n. Can you see if this situation has improved in gdrive 2? I have been able to do 10 hours+ uploads without a problem at least. \n. Thanks for doing the initial work on this, I know people have been asking for it. I will do some changes to the logic before releasing a new version.\n. I would suggest trying gdrive 2 and see if you still experience the same problem.\n. The --delete flag has been added to gdrive 2 which does this:\n$ gdrive upload --delete foo.txt\nUploading foo.txt\nUploaded 0B3X9GlR6EmbnU0ZRSmFnTE1BRjA at 6.0 B/s, total 10.0 B\nRemoved foo.txt\n. gdrive 2 should be easier to build. I've added compile instructions to the readme (it assumes you have GOPATH set though).\n. :)\n. gdrive 2 supports downloading directories using the --recursive flag.\n. In gdrive 2 the upload will timeout when no data has been transferred for a while, I think that should solve this problem.\n. Not sure why this should be avoided.\n. In gdrive 2 the chdir syscall is not used anymore and should have the same behaviour on both windows and unix.\n. gdrive 2 supports updating files: gdrive update 0B3X9GlR6EmbnNTk0SkV0bm5Hd0E gdrive-osx-x64.\n. In gdrive 2 gdrive share gives you more control on how the file is shared. upload --share still gives read access to anyone, but it is not discoverable by default anymore.\n. gdrive 2 supports downloading by query: gdrive download query --recursive \"name contains 'gdrive'\"\nNote that some files might be downloaded multiple times when using the recursive flag though. I.e. if you have a file named gdrive inside a gdrive folder \u2013 it will be downloaded as a single file and as a subfile of the folder. I might fix this in the future.\n. gdrive 2 has a basic progress indicator enabled by default for larger files.\n. gdrive -c foo list\nThis will look for a token.json inside the directory foo. If the directory does not exist, it will be created and prompt you for a new verification code.\n. If you are still having this issue you could try gdrive 2 which uses the new v3 of the drive api.\n. gdrive 2 will timeout when no data has been transferred for a while, I think this will solve the problem. The timeout is 2 minutes for now, but I might add a flag that can override the timeout if needed.\nThanks for helping out answering issues btw :)\n. Yes, gdrive should exit with exit code 1 and write an error message on stderr. The message at the moment is \"context canceled\", I will change this to something more suitable in the future.\n. In gdrive 2 gdrive info will show the path of the first parent.\nI've also added a --absolute flag to gdrive list which will show the full path in the listing.\n. In gdrive 2 you can use gdrive update to create a new revision of the file.\n. The current version does not have any verbose output. gdrive 2.0 will have a progress indicator, and will probably be ready later this month.\n. That depends on the processor type in your router. The arm or rpi build might work.\n. gdrive 2 is ready and has a basic progress indicator enabled by default for larger files.\n. I'm not sure if i understand the problem, but in gdrive 2 you can give either the access-token or refresh-token as arguments to gdrive. Note that the token will show up in e.g. ps and is not recommended to use on multiuser systems.\n. I'm currently working on gdrive 2.0 which uses golang.org/x/oauth2/oauth: https://github.com/prasmussen/gdrive/blob/2.0-wip/auth/oauth.go\n. gdrive 2 defaults to max 30 files which should solve this.\n. In gdrive 2 you can use gdrive update to create a new revision of the file.\n. In gdrive 2 you can use --name-width 0 to show the full name.\n. Hmm, this is probably because of the default query trashed = false and 'me' in owners.\nDoing --query \"\" should show you the shared files as well. I don't remember why I put 'me' in owners as a default query so I will probably remove it in the next version.\n. Did you use gdrive 1 on the same system without limitations? It might be related to the chunksize,  you could try experimenting with the --chunksize flag, the default in gdrive 1 was 4194304.\n. @przemika is right, you have to run a command that requires authenticaction to get the link.\nYou might have better luck compiling now, a change was done to the graph library 3 days ago regarding 32-bit support: soniakeys/graph@a9791afcc6492cb33c614dc71755bdbdd947add1\nJust make sure you get the latest version of the graph library.\n. You might have better luck compiling now, a change was done to the graph library 3 days ago regarding 32-bit support: soniakeys/graph@a9791af\nJust make sure you get the latest version of the graph library.\n. Excellent, thanks @soniakeys \n. When you give gdrive permission to access your drive it is allowed to access your drive by using an access/refresh token. The access/refresh token is obtained by exchanging the verification code you enter the first time, and the tokens are saved inside the ~/.gdrive directory. Anyone with access to the tokens will be able to access your drive.\nMore details can be found here: https://developers.google.com/identity/protocols/OAuth2InstalledApp\nIf you lose your tokens you can revoke the gdrive permission here to invalidate them: https://security.google.com/settings/security/permissions\n. I'm not sure if I have a fix, but can you provide the mime type from gdrive info <id> on one of the files that is browsable?\n. I will change the error message in the future, but it means that no data has been transferred for 2 minutes, so it gives up. This was added to gdrive2 to avoid uploads that hangs forever.\nAre you getting this error often? Do you have enough free space on drive?\n. I've increased the default timeout to 5 minutes in v2.1.0 and added a --timeout flag. If you still get the timeout error you can set the timeout to 0 to disable the timeout logic.\n. Yeah, the api changed, the title field is now called name. Overview can be found here: https://developers.google.com/drive/search-parameters\n. @ryanhle you need to provide a conflict resolution flag. You probably want to use --keep-local in your case, which will overwrite the file on drive.\n. @robertthiemann are you using sync upload or just upload -r? upload -r does not have any syncing features and will always create new files on drive.\n. Thanks, I wanted to use the new vendoring feature of 1.5+, but never got around to doing it.\n. I've tagged the latest commit as 2.1.0\n. Cool, great work :)\n. It's because of golang's very good cross compile support I'm able to create binaries for all those platforms. I'm using this bash script to compile to all platforms from my OSX machine.\n. gdrive is probably not in path.\nYou can set the path manually at the top of your crontab by copying the output of echo $PATH. Mine looks like this:\nbash\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nor you could use the full path to the gdrive binary in your script.\n. You can delete the .gdrive directory in your home directory to reset all state. The path to the config directory is also shown in the description for the --config flag if you write for example gdrive help list.\n. ${var/Pattern/Replacement} is a valid bash command as explained here.\nbash build-all.sh works fine for me with bash 4.3.30 on linux and 3.2.57 on OSX.\n. Thanks!\n. Thanks!\n. Thanks!\n. Thanks!\n. Sure, thanks.\n. Cool, thanks.. --parent / -p is used to specify the parent directory, examples has been added to the README.\n. Fixed in version 1.0.2 (4a3888aaf6)\n. I was able to reproduce the problem and I got the following error:\n```\npanic: invalid memory address or nil pointer dereference\nfatal error: panic during gc\n[signal 0xb code=0x1 addr=0x1 pc=0x8054162]\ngoroutine 1 [syscall]:\n[fp=0xf73238dc] syscall.Syscall()\n    /usr/local/go/src/pkg/syscall/asm_linux_386.s:14 +0x5\n```\nAfter recompiling the binary with go1.2 I have not been able to reproduce the problem. Can you see if the new binary works for you as well?\n- drive-linux-386 v1.0.2\n. Cool!\n. I don't mind at all, this is great.\n. The argument parser has been replaced in in gdrive 2 and -i is no longer required.\n. I don't think this is a reproduceable problem in newer versions of gdrive.\n. Im currently working on gdrive v2, which will support update.\n. gdrive 2 is now available.\n$ gdrive update 0B3X9GlR6EmbnNTk0SkV0bm5Hd0E gdrive-osx-x64\nUploading gdrive-osx-x64\nUpdated 0B3X9GlR6EmbnNTk0SkV0bm5Hd0E at 2.0 MB/s, total 8.3 MB\n$ gdrive revision list 0B3X9GlR6EmbnNTk0SkV0bm5Hd0E\nId                                                    Name             Size     Modified              KeepForever\n0B3X9GlR6EmbnOFlHSTZQNWJWMGN2ckZucC9VaEUwczV1cUNrPQ   gdrive-osx-x64   8.3 MB   2016-02-21 20:47:04   False\n0B3X9GlR6EmbndVEwMlZCUldGWUlPb2lTS25rOFo1L2t6c2ZVPQ   gdrive-osx-x64   8.3 MB   2016-02-21 21:12:09   False\n. Thanks @igloosPat :)\n. Basic progress bar is enabled by default for larger files in gdrive 2.\n. @szepeviktor: you might get better help setting up a go dev environment on stackoverflow.\n@kylecordes: relative imports seems to be discouraged in go.\n. @cagnulein: the pull request from @treeder is merged and is available in the 1.3.0 version\n. I'm not familiar with trickle but looking at the man page it says \u201ctrickle will not work with statically linked executables\u201d. That is probably why it does not work width gdrive as all go applications are statically linked.\n. gdrive 2 supports recursive download: gdrive download -r <id>\n. GDRIVE_CONFIG_DIR environment var is available in gdrive 2.\n. In 1.7.0 there is a new flag --include-docs that will include google docs in the listing and a --format flag to download a google doc in a specified format.\n. Recursive upload has been added in 1.4.0. It replaces the old behaviour which only took the first directory.\n. Was fixed some time ago.\n. In 1.7.0 there is a new flag --include-docs that will include google docs in the listing.\n. This has been fixed in gdrive 2.\n. Thanks!\n. Try gdrive 2 if this is still a problem.\n. You can use the --order flag with gdrive 2:\ngdrive list --order \"name asc\"\ngdrive list --order \"modifiedTime desc\"\n. Resumable uploads requires the size of the file up-front, thats why its not used when uploading via stdin, as I have no way of knowing the size.\nI see that pv takes the filesize in as an argument, that could be a solution for gdrive as well. What do you think?\n. Agreed\n. Oh, thats too bad.\nI haven't followed the code to see what happens to the Reader, so i don't really have any other ideas at the moment. Im guessing seeking is required when resuming an upload -- I'm not sure why you get a seek when doing a normal upload though.\nIf you get the wrapper to work and it seems reliable, I will accept the pull request and I could mark it as an experimental feature or something.\n. Sounds promising :)\n. ResumableMedia has been deprecated in google-api-go-client and the problem with long uploads failing with Media seems to be fixed according to my tests with gdrive 2.\nbash\n$ cat video.mp4 | pv -q -L 50k | gdrive upload - video.mp4\nUploading video.mp4\nUploaded 0B3X9GlR6EmbnSFRwSTNMZkY3Nzg at 51.2 KB/s, total 1.8 GB\npv -q -L 50k  21.88s user 18.02s system 0% cpu 10:00:43.71 total\n. Good catch @cnbeining.\nThe chunk size seems to be defined here: https://github.com/google/google-api-go-client/blob/master/googleapi/googleapi.go#L303\nI will experiment a bit the value to see if it helps the upload speed.\n. There is definitively an improvement.\nAt 2^19 bytes i don't see any great speed boost, but at 2^20 i more or less max my 50mbit connection.\nI think I will set 2^20 as the default and add a command line flag as @cnbeining suggested, to override the value if needed.\n. Version 1.6.0 has a default chunk size of 2^20 bytes (1MiB) and can be changed with the -C flag.\n. I've added the drive quota command in 1.8.0 which will print out free space, etc. I've also added a --bytes flag to info, list and quota to force size in bytes.\nI wont be implementing the min_free_space logic at this time, but it should be possible to write a wrapper script now that checks for free space before uploading.\n. gdrive 2 has the update command which will create a new revision of a single file. gdrive 2 also has some new sync commands that can be used to update multiple changed files. Readme contains an example.\n. gdrive 2 includes a couple of new sync commands that can be used to update changed files. The readme contains an example.\n. Thanks @hwiorn for doing the research :)\nI've just released gdrive 1.9 which uses os.Chdir, hopefully this will fix directory upload on windows. I don't have a windows machine to test it myself so feedback is appreciated.\n. Great, thanks.\n. gdrive 2 lets you specify multiple parents:\ngdrive upload --parent 0B3X9GlR6EmbnR1pNR1FsRGR2bWs --parent 0B3X9GlR6EmbndHlqbWVxSi16WVE foo.txt\n. The readme now contains some more information regarding this under installation instructions.\n. Have not been able to reproduce this. I would suggest trying gdrive 2 and see if you still experience the same problem.\n. Can you see if this situation has improved in gdrive 2? I have been able to do 10 hours+ uploads without a problem at least. \n. Thanks for doing the initial work on this, I know people have been asking for it. I will do some changes to the logic before releasing a new version.\n. I would suggest trying gdrive 2 and see if you still experience the same problem.\n. The --delete flag has been added to gdrive 2 which does this:\n$ gdrive upload --delete foo.txt\nUploading foo.txt\nUploaded 0B3X9GlR6EmbnU0ZRSmFnTE1BRjA at 6.0 B/s, total 10.0 B\nRemoved foo.txt\n. gdrive 2 should be easier to build. I've added compile instructions to the readme (it assumes you have GOPATH set though).\n. :)\n. gdrive 2 supports downloading directories using the --recursive flag.\n. In gdrive 2 the upload will timeout when no data has been transferred for a while, I think that should solve this problem.\n. Not sure why this should be avoided.\n. In gdrive 2 the chdir syscall is not used anymore and should have the same behaviour on both windows and unix.\n. gdrive 2 supports updating files: gdrive update 0B3X9GlR6EmbnNTk0SkV0bm5Hd0E gdrive-osx-x64.\n. In gdrive 2 gdrive share gives you more control on how the file is shared. upload --share still gives read access to anyone, but it is not discoverable by default anymore.\n. gdrive 2 supports downloading by query: gdrive download query --recursive \"name contains 'gdrive'\"\nNote that some files might be downloaded multiple times when using the recursive flag though. I.e. if you have a file named gdrive inside a gdrive folder \u2013 it will be downloaded as a single file and as a subfile of the folder. I might fix this in the future.\n. gdrive 2 has a basic progress indicator enabled by default for larger files.\n. gdrive -c foo list\nThis will look for a token.json inside the directory foo. If the directory does not exist, it will be created and prompt you for a new verification code.\n. If you are still having this issue you could try gdrive 2 which uses the new v3 of the drive api.\n. gdrive 2 will timeout when no data has been transferred for a while, I think this will solve the problem. The timeout is 2 minutes for now, but I might add a flag that can override the timeout if needed.\nThanks for helping out answering issues btw :)\n. Yes, gdrive should exit with exit code 1 and write an error message on stderr. The message at the moment is \"context canceled\", I will change this to something more suitable in the future.\n. In gdrive 2 gdrive info will show the path of the first parent.\nI've also added a --absolute flag to gdrive list which will show the full path in the listing.\n. In gdrive 2 you can use gdrive update to create a new revision of the file.\n. The current version does not have any verbose output. gdrive 2.0 will have a progress indicator, and will probably be ready later this month.\n. That depends on the processor type in your router. The arm or rpi build might work.\n. gdrive 2 is ready and has a basic progress indicator enabled by default for larger files.\n. I'm not sure if i understand the problem, but in gdrive 2 you can give either the access-token or refresh-token as arguments to gdrive. Note that the token will show up in e.g. ps and is not recommended to use on multiuser systems.\n. I'm currently working on gdrive 2.0 which uses golang.org/x/oauth2/oauth: https://github.com/prasmussen/gdrive/blob/2.0-wip/auth/oauth.go\n. gdrive 2 defaults to max 30 files which should solve this.\n. In gdrive 2 you can use gdrive update to create a new revision of the file.\n. In gdrive 2 you can use --name-width 0 to show the full name.\n. Hmm, this is probably because of the default query trashed = false and 'me' in owners.\nDoing --query \"\" should show you the shared files as well. I don't remember why I put 'me' in owners as a default query so I will probably remove it in the next version.\n. Did you use gdrive 1 on the same system without limitations? It might be related to the chunksize,  you could try experimenting with the --chunksize flag, the default in gdrive 1 was 4194304.\n. @przemika is right, you have to run a command that requires authenticaction to get the link.\nYou might have better luck compiling now, a change was done to the graph library 3 days ago regarding 32-bit support: soniakeys/graph@a9791afcc6492cb33c614dc71755bdbdd947add1\nJust make sure you get the latest version of the graph library.\n. You might have better luck compiling now, a change was done to the graph library 3 days ago regarding 32-bit support: soniakeys/graph@a9791af\nJust make sure you get the latest version of the graph library.\n. Excellent, thanks @soniakeys \n. When you give gdrive permission to access your drive it is allowed to access your drive by using an access/refresh token. The access/refresh token is obtained by exchanging the verification code you enter the first time, and the tokens are saved inside the ~/.gdrive directory. Anyone with access to the tokens will be able to access your drive.\nMore details can be found here: https://developers.google.com/identity/protocols/OAuth2InstalledApp\nIf you lose your tokens you can revoke the gdrive permission here to invalidate them: https://security.google.com/settings/security/permissions\n. I'm not sure if I have a fix, but can you provide the mime type from gdrive info <id> on one of the files that is browsable?\n. I will change the error message in the future, but it means that no data has been transferred for 2 minutes, so it gives up. This was added to gdrive2 to avoid uploads that hangs forever.\nAre you getting this error often? Do you have enough free space on drive?\n. I've increased the default timeout to 5 minutes in v2.1.0 and added a --timeout flag. If you still get the timeout error you can set the timeout to 0 to disable the timeout logic.\n. Yeah, the api changed, the title field is now called name. Overview can be found here: https://developers.google.com/drive/search-parameters\n. @ryanhle you need to provide a conflict resolution flag. You probably want to use --keep-local in your case, which will overwrite the file on drive.\n. @robertthiemann are you using sync upload or just upload -r? upload -r does not have any syncing features and will always create new files on drive.\n. Thanks, I wanted to use the new vendoring feature of 1.5+, but never got around to doing it.\n. I've tagged the latest commit as 2.1.0\n. Cool, great work :)\n. It's because of golang's very good cross compile support I'm able to create binaries for all those platforms. I'm using this bash script to compile to all platforms from my OSX machine.\n. gdrive is probably not in path.\nYou can set the path manually at the top of your crontab by copying the output of echo $PATH. Mine looks like this:\nbash\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nor you could use the full path to the gdrive binary in your script.\n. You can delete the .gdrive directory in your home directory to reset all state. The path to the config directory is also shown in the description for the --config flag if you write for example gdrive help list.\n. ${var/Pattern/Replacement} is a valid bash command as explained here.\nbash build-all.sh works fine for me with bash 4.3.30 on linux and 3.2.57 on OSX.\n. Thanks!\n. Thanks!\n. Thanks!\n. Thanks!\n. Sure, thanks.\n. Cool, thanks.. ",
    "marcinlawnik": "Disregard, noticed its a binary :/\n. Disregard, noticed its a binary :/\n. ",
    "viktorlindgren": "It works fine!\nOne problem though is that everything is pumped into memory. That is not good when uploading a large file(>1GB).\n. It works fine!\nOne problem though is that everything is pumped into memory. That is not good when uploading a large file(>1GB).\n. ",
    "crosbymichael": "I'm not having any trouble with file types.  7z and zip archives are correctly uploaded.\n. @prasmussen FYI, i hope you don't mind the PRs.  This is a really nice project and I plan on using it alot.\n. What breaks if you don't have a blank line? \n. I'm not having any trouble with file types.  7z and zip archives are correctly uploaded.\n. @prasmussen FYI, i hope you don't mind the PRs.  This is a really nice project and I plan on using it alot.\n. What breaks if you don't have a blank line? \n. ",
    "jakenjarvis": "I've found the cause. Was work with you to specify the mimetype.\nBatchfile\n\"C:\\gdrive\\drive-windows-386.exe\" upload --file \"C:\\test.apk\" --mimetype \"application/vnd.android.package-archive\"\nI'm glad when this automatically recognizes the mimetype...\nThanks.\n. I've found the cause. Was work with you to specify the mimetype.\nBatchfile\n\"C:\\gdrive\\drive-windows-386.exe\" upload --file \"C:\\test.apk\" --mimetype \"application/vnd.android.package-archive\"\nI'm glad when this automatically recognizes the mimetype...\nThanks.\n. ",
    "keramidasceid": "Nothing breaks. It is just an UX change. See the example.\n. Nothing breaks. It is just an UX change. See the example.\n. ",
    "HackedServer": "Resolved!\nGoogle's API page now says 1024GB supported, and upon testing with a 22GB file it indeed supports files larger than 10GB now!\n. Resolved!\nGoogle's API page now says 1024GB supported, and upon testing with a 22GB file it indeed supports files larger than 10GB now!\n. ",
    "ghost": "i cant see a way to do this on their API page\nClosest thing is:\nhttps://developers.google.com/drive/v2/reference/files/copy\nare they limiting doing this  i wonder ?? anyone now\n. Ah yes found it !! Thanks\n. hi prasmussen,\n+1 here. 145MB file.\n\nUploading /tmp/svn.7z\n512.0 B/145.0 MBFailed to upload file: context canceled`\n\ni rarely back up this file on google drive, last success was with version 1.9.0\n. yup, i cant confirm this.. Can I do it? Can you tell me how?. i cant see a way to do this on their API page\nClosest thing is:\nhttps://developers.google.com/drive/v2/reference/files/copy\nare they limiting doing this  i wonder ?? anyone now\n. Ah yes found it !! Thanks\n. hi prasmussen,\n+1 here. 145MB file.\n\nUploading /tmp/svn.7z\n512.0 B/145.0 MBFailed to upload file: context canceled`\n\ni rarely back up this file on google drive, last success was with version 1.9.0\n. yup, i cant confirm this.. Can I do it? Can you tell me how?. ",
    "m93a": "@gedw99 What? The link biophysics referenced is on their API page. What's the problem?\n. @gedw99 What? The link biophysics referenced is on their API page. What's the problem?\n. ",
    "ljoli": "Hi everybody ! !\nAccording to your discussion. \nWhat is the command line for update a file ?\nRegards\n. Hi everybody ! !\nAccording to your discussion. \nWhat is the command line for update a file ?\nRegards\n. ",
    "mingram8": "Did anybody figure this out?\n. Did anybody figure this out?\n. ",
    "a-legrand": "+1 !\n. +1 !\n. ",
    "idiomatic": "a series of increasingly longer uploads was tested through:\nbash\n$ dd if=noise.dat of=/tmp/noise-500.dat bs=1m count=500\n$ time gdrive upload --file /tmp/noise-500.dat\nand adjusting the \"500\" until it takes approximately 1 hour, at which point it consistently fails.\n. This issue is discussed at https://code.google.com/p/gdata-issues/issues/detail?id=5124.\n. Perhaps https://developers.google.com/drive/web/manage-uploads#resumable would be in order.  Alas, https://code.google.com/p/google-api-go-client/issues/detail?id=17\n. a series of increasingly longer uploads was tested through:\nbash\n$ dd if=noise.dat of=/tmp/noise-500.dat bs=1m count=500\n$ time gdrive upload --file /tmp/noise-500.dat\nand adjusting the \"500\" until it takes approximately 1 hour, at which point it consistently fails.\n. This issue is discussed at https://code.google.com/p/gdata-issues/issues/detail?id=5124.\n. Perhaps https://developers.google.com/drive/web/manage-uploads#resumable would be in order.  Alas, https://code.google.com/p/google-api-go-client/issues/detail?id=17\n. ",
    "JWJr": "NM: revisited the \"problem\", and figured out how to use the \"list\" and \"delete\" commands in sequence to remove files directly, without using the (un-automatable) trash. Thanks again for a great program!  -JW\n. NM: revisited the \"problem\", and figured out how to use the \"list\" and \"delete\" commands in sequence to remove files directly, without using the (un-automatable) trash. Thanks again for a great program!  -JW\n. ",
    "alfablac": "Noticed that. This programs have future. One of the best. The other one requires so many dependencies, which means it is restricted for user without root access.\nAnd a progress bar is very useful! Just to know where you are on time.\n. Noticed that. This programs have future. One of the best. The other one requires so many dependencies, which means it is restricted for user without root access.\nAnd a progress bar is very useful! Just to know where you are on time.\n. ",
    "limoragni": "+1 to the progress bar or some percentage indicating that things are getting uploaded! \n. +1 to the progress bar or some percentage indicating that things are getting uploaded! \n. ",
    "pimlottc": "Agree, getting some feedback when transferring a multi-gig file would be much appreciated.\n. Agree, getting some feedback when transferring a multi-gig file would be much appreciated.\n. ",
    "szepeviktor": "A step further\n```\nexport GOPATH=/root/gdrive\ngo get\ngo install: no install location for directory /root/gdrive outside GOPATH\n```\n. A step further\n```\nexport GOPATH=/root/gdrive\ngo get\ngo install: no install location for directory /root/gdrive outside GOPATH\n```\n. ",
    "kylecordes": "This project appears to have a strange dependency: looking for some of its own files (!) in a \"go get\" from github even when working directly in the project. This is an oddity the developer will hopefully clean up.\n. Ah, my Go knowledge had fallen behind, sorry for the noise!\n. This project appears to have a strange dependency: looking for some of its own files (!) in a \"go get\" from github even when working directly in the project. This is an oddity the developer will hopefully clean up.\n. Ah, my Go knowledge had fallen behind, sorry for the noise!\n. ",
    "cagnulein": "+1\n. I didn't notice that!\nThanks man!\n. Have you got a raspberry pi build of your version?\nCould you share it?\n. Thank you guys|\n. +1\n. I didn't notice that!\nThanks man!\n. Have you got a raspberry pi build of your version?\nCould you share it?\n. Thank you guys|\n. ",
    "willemw12": "There is the option to remove the file when downloading a file (drive download --pop ...).\nHowever, there is currently no option to trash files, with the same name and which are in the same folder, when uploading a file (drive upload --push ...).\n. Works now (at least with go 1.6). Close this issue?\n. Unfortunately not. See my comment on https://github.com/soniakeys/graph/issues/41.\n. Gdrive builds and runs fine now on \"linux_arm\".\n. There is the option to remove the file when downloading a file (drive download --pop ...).\nHowever, there is currently no option to trash files, with the same name and which are in the same folder, when uploading a file (drive upload --push ...).\n. Works now (at least with go 1.6). Close this issue?\n. Unfortunately not. See my comment on https://github.com/soniakeys/graph/issues/41.\n. Gdrive builds and runs fine now on \"linux_arm\".\n. ",
    "schans": "The overwrite option for downloads is part of my pull request for exporting google docs:\nhttps://github.com/prasmussen/gdrive/pull/61\n. The overwrite option for downloads is part of my pull request for exporting google docs:\nhttps://github.com/prasmussen/gdrive/pull/61\n. ",
    "stevenandres": "Is there any progress on having overwrite enabled during UPLOAD? This would be useful when using Google Drive for backups, to overwrite last week's backup instead of a never-ending amount of backups\n. Is there any progress on having overwrite enabled during UPLOAD? This would be useful when using Google Drive for backups, to overwrite last week's backup instead of a never-ending amount of backups\n. ",
    "Zitrax": "This would indeed be useful ( I am thinking of the overwrite on upload ).\n. This would indeed be useful ( I am thinking of the overwrite on upload ).\n. ",
    "hex": "Yes, we need overwrite please! \n. Using --chunksize 104857600 seems to help. Try that.\n. Yes, we need overwrite please! \n. Using --chunksize 104857600 seems to help. Try that.\n. ",
    "limkokhole": "You guy can try revision (old version will removed after 30 days), e.g.:\n```\n$ gdrive mkdir bk_bash_history #create a new directory\nDirectory XXX created\n$ gdrive upload /home/xiaobai/.bash_history -p XXX #upload the initial file to that directory id\nUploading /home/xiaobai/.bash_history\nUploaded YYY at 3.9 MB/s, total 9.5 MB\n$ gdrive update YYY /home/xiaobai/.bash_history #update revision by using file id\nUploading /home/xiaobai/.bash_history\nUpdated YYY at 3.2 MB/s, total 9.5 MB\n. You guy can try revision (old version will removed after 30 days), e.g.:\n$ gdrive mkdir bk_bash_history #create a new directory\nDirectory XXX created\n$ gdrive upload /home/xiaobai/.bash_history -p XXX #upload the initial file to that directory id\nUploading /home/xiaobai/.bash_history\nUploaded YYY at 3.9 MB/s, total 9.5 MB\n$ gdrive update YYY /home/xiaobai/.bash_history #update revision by using file id\nUploading /home/xiaobai/.bash_history\nUpdated YYY at 3.2 MB/s, total 9.5 MB\n```. ",
    "ahippo": "I currently know only the following way:\nbash\ndrive list --query \" '<folder_id>' in parents\"\n. I currently know only the following way:\nbash\ndrive list --query \" '<folder_id>' in parents\"\n. ",
    "lmmx": "drive download --id $fileid\nfor every id found by\ndrive list --query \" '<folder_id>' in parents\"\n. @monperrus The Google Docs .gdoc format is totally minimal, just containing the URL in plain text basically. \"Backing them up\" therefore doesn't really have much meaning.\nI've given up the thought of using gdrive for this (it's generally quite buggy), but you may be interested in backing up Docs as markdown - I currently do this just to work with Docs in drafting.\nSee this repo, a tool I've modified that converts Docs to markdown and HTML\n. Oh, neat! I always found the conversion butchers my document, whereas the markdown generation is nicely programmatic and you can work around formatting bugs, but great that it's an option now, nice work! :+1: \n. drive download --id $fileid\nfor every id found by\ndrive list --query \" '<folder_id>' in parents\"\n. @monperrus The Google Docs .gdoc format is totally minimal, just containing the URL in plain text basically. \"Backing them up\" therefore doesn't really have much meaning.\nI've given up the thought of using gdrive for this (it's generally quite buggy), but you may be interested in backing up Docs as markdown - I currently do this just to work with Docs in drafting.\nSee this repo, a tool I've modified that converts Docs to markdown and HTML\n. Oh, neat! I always found the conversion butchers my document, whereas the markdown generation is nicely programmatic and you can work around formatting bugs, but great that it's an option now, nice work! :+1: \n. ",
    "oroce": "Oh I needed the same thing, this is how I solved it:\ndrive-darwin-amd64 list -n --query \"'<folder_id>' in parents\" | awk '{print $1}' | xargs -I {} sh -c 'drive-darwin-amd64 download --id {}'\n. I'm not sure whether it's possible through the API, but you can check it yourself.\nI'm using a recursive bash script to download all the files. If you are interested i can share but im on mobile atm\n. @xrobin \nhere we go:\n```\n!/bin/bash\nIFS=$'\\n'\nfiles=()\nrecurse() {\n  id=$1\n  echo \"query '$id' in parents\"\n  files=$(drive-darwin-amd64 list -n -m 1000 --query \"'$id' in parents\")\n  for file in $files\n  do\n    # idnamesize\n    # splitting things\n    id=$(awk '{print $1}' <<<\u00a0$file | sed -e 's/ //g')\n    id=${id:0,1} #substring\nname=$(awk '{print $2}' <<<\u00a0$file)\nsize=$(awk '{print $3}' <<<\u00a0$file)\n\n# ops it's a directory\nif [ \"$size\" == \"0.0\" ];\nthen\n  echo \"recurse on $name\\n\"\n  recurse $id\n  continue\nfi\n\nfiles+=(\"$id;$name\")\n\ndone\n}\nrecurse ''\nprintf \"Found %s files\\n\" \"${#files[@]}\"\n```\nWhat it does, it runs through a folder and finds all the files and puts into files array as a semicolon separated value.\n. Oh I needed the same thing, this is how I solved it:\ndrive-darwin-amd64 list -n --query \"'<folder_id>' in parents\" | awk '{print $1}' | xargs -I {} sh -c 'drive-darwin-amd64 download --id {}'\n. I'm not sure whether it's possible through the API, but you can check it yourself.\nI'm using a recursive bash script to download all the files. If you are interested i can share but im on mobile atm\n. @xrobin \nhere we go:\n```\n!/bin/bash\nIFS=$'\\n'\nfiles=()\nrecurse() {\n  id=$1\n  echo \"query '$id' in parents\"\n  files=$(drive-darwin-amd64 list -n -m 1000 --query \"'$id' in parents\")\n  for file in $files\n  do\n    # idnamesize\n    # splitting things\n    id=$(awk '{print $1}' <<<\u00a0$file | sed -e 's/ //g')\n    id=${id:0,1} #substring\nname=$(awk '{print $2}' <<<\u00a0$file)\nsize=$(awk '{print $3}' <<<\u00a0$file)\n\n# ops it's a directory\nif [ \"$size\" == \"0.0\" ];\nthen\n  echo \"recurse on $name\\n\"\n  recurse $id\n  continue\nfi\n\nfiles+=(\"$id;$name\")\n\ndone\n}\nrecurse ''\nprintf \"Found %s files\\n\" \"${#files[@]}\"\n```\nWhat it does, it runs through a folder and finds all the files and puts into files array as a semicolon separated value.\n. ",
    "kaimast": "What about folder with subfolders? Why can't I just download the folder with all its content?\n. What about folder with subfolders? Why can't I just download the folder with all its content?\n. ",
    "rbeede": "I know the Google Drive UI lets you download a folder.   It is zipping the contents and any sub-folders and providing a single zip download.   I'm not sure if the API has a call for that or not.\n. What about the following property:\nhttps://developers.google.com/drive/v2/reference/files#resource\nfolderColorRgb - Folder color as an RGB hex string if the file is a folder. The list of supported colors is available in the folderColorPalette field of the About resource. If an unsupported color is specified, it will be changed to the closest color in the palette.\nAlso folders used to be called labels.   Not sure if that helps with the API.\n. I am seeing the same issue as well on my Windows 7 system.  Tried latest version.\ngdrive: 2.1.0\nGolang: go1.6\nOS/Arch: windows/amd64\n. I have seen performance improvement if I use:\n--chunksize 104857600\nSetting a 100MiB size when uploading a 10.7GB file seems to help.  I went from ~300KB/sec to ~1.5MB/sec.\n. I know the Google Drive UI lets you download a folder.   It is zipping the contents and any sub-folders and providing a single zip download.   I'm not sure if the API has a call for that or not.\n. What about the following property:\nhttps://developers.google.com/drive/v2/reference/files#resource\nfolderColorRgb - Folder color as an RGB hex string if the file is a folder. The list of supported colors is available in the folderColorPalette field of the About resource. If an unsupported color is specified, it will be changed to the closest color in the palette.\nAlso folders used to be called labels.   Not sure if that helps with the API.\n. I am seeing the same issue as well on my Windows 7 system.  Tried latest version.\ngdrive: 2.1.0\nGolang: go1.6\nOS/Arch: windows/amd64\n. I have seen performance improvement if I use:\n--chunksize 104857600\nSetting a 100MiB size when uploading a 10.7GB file seems to help.  I went from ~300KB/sec to ~1.5MB/sec.\n. ",
    "xezpeleta": "+1\n. +1\n. ",
    "xrobin": "@oroce it would be very useful if you could share the script. Detecting if a file is in fact a folder and needs recursion instead of download doesn't seem very trivial (0.0 B seems to be a hint but not fool-proof, one need to call drive info on the file and look for an Md5sum, missing on folders).\nUltimately one could think of a -r (--recursive) argument on download that would do it automatically.\n. However it looks like I can not just replace the import with golang.org/x/oauth2/oauth. Other things seems to have changed. Specifically there is no oauth2/oauth in golang.org/x/oauth2. And it is not possible to use oauth2 directly instead of oauth.\n. @oroce it would be very useful if you could share the script. Detecting if a file is in fact a folder and needs recursion instead of download doesn't seem very trivial (0.0 B seems to be a hint but not fool-proof, one need to call drive info on the file and look for an Md5sum, missing on folders).\nUltimately one could think of a -r (--recursive) argument on download that would do it automatically.\n. However it looks like I can not just replace the import with golang.org/x/oauth2/oauth. Other things seems to have changed. Specifically there is no oauth2/oauth in golang.org/x/oauth2. And it is not possible to use oauth2 directly instead of oauth.\n. ",
    "jkaberg": "Sorry, I'm ignorant and should be shot. Closing this..\nPS: For anyone comeing here, use the -p tag and the id of the folder you wish to upload to\n. Sorry, I'm ignorant and should be shot. Closing this..\nPS: For anyone comeing here, use the -p tag and the id of the folder you wish to upload to\n. ",
    "dtgriscom": "Well, that didn't take long for me to figure out. There's a --max argument to the list command that specifies the maximum number of results to return:\nmacbookpro:~ griscom$ gdrive list --max 1000 | wc\n     449    3363   47594\nIf you don't specify that argument, then there's a default value which seems to be 94.\n(My personal inclination is that the default should be either a) unlimited, or b) something round like 100 so it's easier to realize there's a limit. My $0.02...)\n. Well, that didn't take long for me to figure out. There's a --max argument to the list command that specifies the maximum number of results to return:\nmacbookpro:~ griscom$ gdrive list --max 1000 | wc\n     449    3363   47594\nIf you don't specify that argument, then there's a default value which seems to be 94.\n(My personal inclination is that the default should be either a) unlimited, or b) something round like 100 so it's easier to realize there's a limit. My $0.02...)\n. ",
    "MarkKropf": "Looks like there is already upstream support in the api library maintained by the same author as this cli. \nhttps://github.com/prasmussen/google-api-go-client/blob/master/drive/v2/drive-gen.go#L3193-3205\nShould just be adding the argument to the CLI in this repo.\n. Ok, looks like this functionality may be disabled now. I noticed that the gdrive web ui no longer allows this option to be set. The API still receives the call, but the test PDF I uploaded did not get ocr'd. \nIt appears the new mode they are pushing for is for folks to use the 'convert' option instead for anything needing ocr.\nIf anyone else has found that this feature is still active the api, let me know.\n. Looks like there is already upstream support in the api library maintained by the same author as this cli. \nhttps://github.com/prasmussen/google-api-go-client/blob/master/drive/v2/drive-gen.go#L3193-3205\nShould just be adding the argument to the CLI in this repo.\n. Ok, looks like this functionality may be disabled now. I noticed that the gdrive web ui no longer allows this option to be set. The API still receives the call, but the test PDF I uploaded did not get ocr'd. \nIt appears the new mode they are pushing for is for folks to use the 'convert' option instead for anything needing ocr.\nIf anyone else has found that this feature is still active the api, let me know.\n. ",
    "DrStuartMcIntyre": "I also had this, but the files would spontaneously appear after a while. May be an issue with GDrive itself? http://stackoverflow.com/questions/13010191/uploaded-file-sometimes-doesnt-appear-on-the-google-drive-web-page\n. I also had this, but the files would spontaneously appear after a while. May be an issue with GDrive itself? http://stackoverflow.com/questions/13010191/uploaded-file-sometimes-doesnt-appear-on-the-google-drive-web-page\n. ",
    "Drezzler": "I can confirm , this is an issue with google drive itself , not gdrive.\n. And me too , started happening only recently , I cant upload even small files , files like 10Kb images ...\nI hope i am not the only one experiencing it this weird ..\n. Have you tried using an absolute path to the folder ?\n. The error shows that gopath is not set , set it by using\nexport GOPATH=/path/to/gdrive/folder\nAnd then run the build command \n. Disclaimer : I am not really a pro at golang , but this is how i have been creating binary for gdrive (in case i need/want to make some changes ) , and ones created , i just copy them (binary) from one system to another , unless the binary is broken or something else is wrong and i cant figure it out .\nNote : This is on a centos installation , but i believe it should work on most linux systems with some changes\nA good part of this method has been taken from the original documentation ..\nOfficial page - https://github.com/prasmussen/gdrive\nStep 1 - Install the Go tools - http://golang.org/doc/install\nIf you are upgrading from an older version of Go you must first remove the existing version.\nLinux, Mac OS X, and FreeBSD tarballs\nDownload the archive and extract it into /usr/local, creating a Go tree in /usr/local/go. For example:\ntar -C /usr/local -xzf go$VERSION.$OS-$ARCH.tar.gz\nChoose the archive file appropriate for your installation. For instance, if you are installing Go version 1.2.1 for 64-bit x86 on Linux, the archive you want is called go1.2.1.linux-amd64.tar.gz.\n(Typically these commands must be run as root or through sudo.)\nAdd /usr/local/go/bin to the PATH environment variable. You can do this by adding this line (at the end of /etc/profile) to your /etc/profile (for a system-wide installation) or $HOME/.profile:\nexport PATH=$PATH:/usr/local/go/bin\nStep 2 - Install mercurial with the command - yum install mercurial\nStep 3 - If the src folder of drive (IE drive/src) does not contain your version of gdrive , get it their with the follow commands -\nSet the environment variables like so\n- 'export GOROOT= /usr/local/go'\n- 'export GOPATH=/path/to/gdrive/folder'\n'cd /PATH/TO/GDRIVE/DIRECTORY'\n'go get github.com/prasmussen/gdrive'\nStep 4 - Ones you have edited the gdrive (optional) and want to complie the program  ,\ngo to the gdrive directory and run 'go build drive.go'\nget the 'drive' binary generated and place it in '/usr/local/bin' , make the binary executable with 'chmod +x drive'\n. @prasmussen  Apparently , this issue got fixed in windows by this - https://github.com/prasmussen/gdrive/issues/56 and broke it for Unix.\n. I am using \"gdrive upload -f FILE/FOLDERLOCATION -p DRIVE-PARENT-FOLDER-ID\"\nOr you can check out \"-f\" option by running gdrive -h\n. @berna - Are you using golang v1.4.2 when compliling gdrive ?\nIt is the only version i have ever used to compile gdrive , and it has always worked (tried with v1.5.2 , but was getting errors).\n. This an old issue , but the solution is to use golang v1.4.2 , as the versions past that have a bug .\n. I am sorry , but i had not read your first post carefully . \nIndeed that reference to google api is broken .\nIs their any particular advantage of using go v1.5 instead of 1.4.2 for gdrive build ?\nMay be you can send a pull request to @prasmussen \n. You can set the option for using a specific config file which will contain account specific details .\n. I only started having problems since yesterday , even tried some other repos (https://github.com/odeke-em/drive) , but even that did not help .\nTested with latest version of gdrive (v1.9) and that seems to be little on the ok side since it supports setting upload chunk size , but its still too damn slow ...\nSometimes upload completes but gdrive just hangs up and waits for a long time before actually completing the job.\n@thebaddie - since when are you having this problem ?\n. So my speed is back to normal , infact better ... getting really really good speeds now \n. What version of gdrive are you using ?\nIf it is >1.6 , may be you can have a look at this https://github.com/prasmussen/gdrive/issues/49\n. What is your OS ?\nIt is probably a persmission issue , are you running the cron job and commad line , commands as the same user ?\n. You can give a config path i think , with --config option ?\n-c, --config       Set application path where config and token is stored. Defaults to ~/.gdrive\nHave you tried that ?\n. Google drive api has been unstable lately , i have been having problems with the api every few days , which gets resolved on its own.\nFirst few times when i had similar issues , i thought something was wrong at my end , but after going through the same cycle a number of time , i have realised that the problem is with the drive api and not gdrive.\n. Is there an error returned when timeout occurs ?\nI love the new options/features you have added to gdrive and it looks like compiling from source will be much more easier now .\nThank you so much for this awesome tool .\n. I dont think their is anything wrong with gdrive , its the drive api playing games with you ...\nMay be you can give https://github.com/odeke-em/drive a quick try to make sure its not just gdrive.\nI keep having issues with gdrive as well , and every single time it gets resolved on its own in a few hours. The issue also occurs with the repo i recommended you above.\n. I dont think so , you can give this a try - https://github.com/odeke-em/drive , it has more features compared to gdrive , but is relatively more complex in setting up and usage.\n. What problems are you facing ?\n. I dont think their is such an option built into gdrive.\n. If you have a lot of files or sync/uploads (to drive) going on , its best to use -m parameter to limit the number of results , as fetching a lot of results will probably get stuck due to google drives api timeout restrictions.\nexample gdrive list -m 10\n. You need to use Parent folders id and not its name when uploading/creating files/folders inside a folder .\ndrive folder -t test2 -p PARENT_FOLDER_ID_HERE\n. > Can you output the response of the upload api call, this should provide the id of the new file uploaded and allow the application to continuing uploading the next file?\nIs that happening for you ? \nWhen i upload any file i get a reponse , which contains the information about the uploaded file.\nHave you tried giving gdrive permission to your entire drive , instead of just the app folder ?\nMaybe @prasmussen can help \n. Have you tried using absolute path to the log file ? \n. Please check this https://github.com/prasmussen/gdrive/issues/96\n. 1. Currently you cannot rename a file but can update the file by using update command.\n2. To get accurate file info when user asks for filesize to be shown in bytes ,its just a guess though.\n3. @prasmussen  - can you please chime in ?\n. Gdrive will use the systems proxy settings , you cannot force Gdrive to use a proxy with the current version , besides using a proxy will be slow when uploading or downloading files.\n. Provide a new config location (see --config option) or delete gdrive config directory.\nFrom the documentation \n- -c, --config          Application path, default: /Users//.gdrive\n- --refresh-token    Oauth refresh token used to get access token (for advanced users)\n- --access-token      Oauth access token, only recommended for short-lived requests because of short lifetime (for advanced users)`\n. For the sake of completeness , i am adding this quote from SO\n\nThe problem was while getting access token. I was not providing correct scopes. When i changed the scope to\nhttps://spreadsheets.google.com/feeds \nhttps://docs.google.com/feeds https://www.googleapis.com/auth/drive.file\nit worked fine. Your only option is to split that file into multiple files , else everytime you try to upload the file , the upload process will timeout due to the server upload speed.. I dont think you can sync with multiple accounts simultaneously. But you can sync them in a sequence , using each account separately.. Gdrive does not currently support file/recursive upload in a way you are doing , but it can upload entire folder recursively or you can write code in golang or any other language to run sequential commands to upload each file individually after getting a list of files that you want to upload.\n. Unfortunately , their is no such built in option , but you can use python or bash to read one id per line from a text file and loop through them to download each file. \n\nHere is a sample code \n```\n!/bin/bash\nfilename='file.txt'\nfilelines=cat $filename\necho Start\nfor line in $filelines ; do\n    gdrive download $line\ndone\n```. Yes , just dont define a parent folder when uploading.. From the documentation \ngdrive upload --parent 0B3X9GlR6EmbnY1RLVTk5VUtOVkk gdrive-osx-x64\nWhere 0B3X9GlR6EmbnY1RLVTk5VUtOVkk is the id of folder you want to upload to and gdrive-osx-x64 is the file you want to upload. It is safe  , the only way your account could be compromised is if the server/computer Gdrive is running on is compromised.. I can confirm , this is an issue with google drive itself , not gdrive.\n. And me too , started happening only recently , I cant upload even small files , files like 10Kb images ...\nI hope i am not the only one experiencing it this weird ..\n. Have you tried using an absolute path to the folder ?\n. The error shows that gopath is not set , set it by using\nexport GOPATH=/path/to/gdrive/folder\nAnd then run the build command \n. Disclaimer : I am not really a pro at golang , but this is how i have been creating binary for gdrive (in case i need/want to make some changes ) , and ones created , i just copy them (binary) from one system to another , unless the binary is broken or something else is wrong and i cant figure it out .\nNote : This is on a centos installation , but i believe it should work on most linux systems with some changes\nA good part of this method has been taken from the original documentation ..\nOfficial page - https://github.com/prasmussen/gdrive\nStep 1 - Install the Go tools - http://golang.org/doc/install\nIf you are upgrading from an older version of Go you must first remove the existing version.\nLinux, Mac OS X, and FreeBSD tarballs\nDownload the archive and extract it into /usr/local, creating a Go tree in /usr/local/go. For example:\ntar -C /usr/local -xzf go$VERSION.$OS-$ARCH.tar.gz\nChoose the archive file appropriate for your installation. For instance, if you are installing Go version 1.2.1 for 64-bit x86 on Linux, the archive you want is called go1.2.1.linux-amd64.tar.gz.\n(Typically these commands must be run as root or through sudo.)\nAdd /usr/local/go/bin to the PATH environment variable. You can do this by adding this line (at the end of /etc/profile) to your /etc/profile (for a system-wide installation) or $HOME/.profile:\nexport PATH=$PATH:/usr/local/go/bin\nStep 2 - Install mercurial with the command - yum install mercurial\nStep 3 - If the src folder of drive (IE drive/src) does not contain your version of gdrive , get it their with the follow commands -\nSet the environment variables like so\n- 'export GOROOT= /usr/local/go'\n- 'export GOPATH=/path/to/gdrive/folder'\n'cd /PATH/TO/GDRIVE/DIRECTORY'\n'go get github.com/prasmussen/gdrive'\nStep 4 - Ones you have edited the gdrive (optional) and want to complie the program  ,\ngo to the gdrive directory and run 'go build drive.go'\nget the 'drive' binary generated and place it in '/usr/local/bin' , make the binary executable with 'chmod +x drive'\n. @prasmussen  Apparently , this issue got fixed in windows by this - https://github.com/prasmussen/gdrive/issues/56 and broke it for Unix.\n. I am using \"gdrive upload -f FILE/FOLDERLOCATION -p DRIVE-PARENT-FOLDER-ID\"\nOr you can check out \"-f\" option by running gdrive -h\n. @berna - Are you using golang v1.4.2 when compliling gdrive ?\nIt is the only version i have ever used to compile gdrive , and it has always worked (tried with v1.5.2 , but was getting errors).\n. This an old issue , but the solution is to use golang v1.4.2 , as the versions past that have a bug .\n. I am sorry , but i had not read your first post carefully . \nIndeed that reference to google api is broken .\nIs their any particular advantage of using go v1.5 instead of 1.4.2 for gdrive build ?\nMay be you can send a pull request to @prasmussen \n. You can set the option for using a specific config file which will contain account specific details .\n. I only started having problems since yesterday , even tried some other repos (https://github.com/odeke-em/drive) , but even that did not help .\nTested with latest version of gdrive (v1.9) and that seems to be little on the ok side since it supports setting upload chunk size , but its still too damn slow ...\nSometimes upload completes but gdrive just hangs up and waits for a long time before actually completing the job.\n@thebaddie - since when are you having this problem ?\n. So my speed is back to normal , infact better ... getting really really good speeds now \n. What version of gdrive are you using ?\nIf it is >1.6 , may be you can have a look at this https://github.com/prasmussen/gdrive/issues/49\n. What is your OS ?\nIt is probably a persmission issue , are you running the cron job and commad line , commands as the same user ?\n. You can give a config path i think , with --config option ?\n-c, --config       Set application path where config and token is stored. Defaults to ~/.gdrive\nHave you tried that ?\n. Google drive api has been unstable lately , i have been having problems with the api every few days , which gets resolved on its own.\nFirst few times when i had similar issues , i thought something was wrong at my end , but after going through the same cycle a number of time , i have realised that the problem is with the drive api and not gdrive.\n. Is there an error returned when timeout occurs ?\nI love the new options/features you have added to gdrive and it looks like compiling from source will be much more easier now .\nThank you so much for this awesome tool .\n. I dont think their is anything wrong with gdrive , its the drive api playing games with you ...\nMay be you can give https://github.com/odeke-em/drive a quick try to make sure its not just gdrive.\nI keep having issues with gdrive as well , and every single time it gets resolved on its own in a few hours. The issue also occurs with the repo i recommended you above.\n. I dont think so , you can give this a try - https://github.com/odeke-em/drive , it has more features compared to gdrive , but is relatively more complex in setting up and usage.\n. What problems are you facing ?\n. I dont think their is such an option built into gdrive.\n. If you have a lot of files or sync/uploads (to drive) going on , its best to use -m parameter to limit the number of results , as fetching a lot of results will probably get stuck due to google drives api timeout restrictions.\nexample gdrive list -m 10\n. You need to use Parent folders id and not its name when uploading/creating files/folders inside a folder .\ndrive folder -t test2 -p PARENT_FOLDER_ID_HERE\n. > Can you output the response of the upload api call, this should provide the id of the new file uploaded and allow the application to continuing uploading the next file?\nIs that happening for you ? \nWhen i upload any file i get a reponse , which contains the information about the uploaded file.\nHave you tried giving gdrive permission to your entire drive , instead of just the app folder ?\nMaybe @prasmussen can help \n. Have you tried using absolute path to the log file ? \n. Please check this https://github.com/prasmussen/gdrive/issues/96\n. 1. Currently you cannot rename a file but can update the file by using update command.\n2. To get accurate file info when user asks for filesize to be shown in bytes ,its just a guess though.\n3. @prasmussen  - can you please chime in ?\n. Gdrive will use the systems proxy settings , you cannot force Gdrive to use a proxy with the current version , besides using a proxy will be slow when uploading or downloading files.\n. Provide a new config location (see --config option) or delete gdrive config directory.\nFrom the documentation \n- -c, --config          Application path, default: /Users//.gdrive\n- --refresh-token    Oauth refresh token used to get access token (for advanced users)\n- --access-token      Oauth access token, only recommended for short-lived requests because of short lifetime (for advanced users)`\n. For the sake of completeness , i am adding this quote from SO\n\nThe problem was while getting access token. I was not providing correct scopes. When i changed the scope to\nhttps://spreadsheets.google.com/feeds \nhttps://docs.google.com/feeds https://www.googleapis.com/auth/drive.file\nit worked fine. Your only option is to split that file into multiple files , else everytime you try to upload the file , the upload process will timeout due to the server upload speed.. I dont think you can sync with multiple accounts simultaneously. But you can sync them in a sequence , using each account separately.. Gdrive does not currently support file/recursive upload in a way you are doing , but it can upload entire folder recursively or you can write code in golang or any other language to run sequential commands to upload each file individually after getting a list of files that you want to upload.\n. Unfortunately , their is no such built in option , but you can use python or bash to read one id per line from a text file and loop through them to download each file. \n\nHere is a sample code \n```\n!/bin/bash\nfilename='file.txt'\nfilelines=cat $filename\necho Start\nfor line in $filelines ; do\n    gdrive download $line\ndone\n```. Yes , just dont define a parent folder when uploading.. From the documentation \ngdrive upload --parent 0B3X9GlR6EmbnY1RLVTk5VUtOVkk gdrive-osx-x64\nWhere 0B3X9GlR6EmbnY1RLVTk5VUtOVkk is the id of folder you want to upload to and gdrive-osx-x64 is the file you want to upload. It is safe  , the only way your account could be compromised is if the server/computer Gdrive is running on is compromised.. ",
    "djm68": "This issue is preventing gdrive from being much more useful.  I can use gdrive to upload and text document, I can then download the same document.  However, if I open the uploaded document in google docs, it is converted to google doc format which is then no longer visible to gdrive.\n. This issue is preventing gdrive from being much more useful.  I can use gdrive to upload and text document, I can then download the same document.  However, if I open the uploaded document in google docs, it is converted to google doc format which is then no longer visible to gdrive.\n. ",
    "monperrus": "+1\nI'd like to use gdrive to backup my Google Documents. Is it possible?\n. @lmmx I've rolled my own Python script for backing up my Google Documents: https://github.com/monperrus/dl-gdocs\n. If you want to add a listing of Google Documents in gdrive, the request\nto be done is mimeType=application/vnd.google-apps.document (resp.\napplication/vnd.google-apps.spreadsheet and\napplication/vnd.google-apps.presentation).\n(note that mimeType contains google-apps.document does not answer\nanything.\n. +1\nI'd like to use gdrive to backup my Google Documents. Is it possible?\n. @lmmx I've rolled my own Python script for backing up my Google Documents: https://github.com/monperrus/dl-gdocs\n. If you want to add a listing of Google Documents in gdrive, the request\nto be done is mimeType=application/vnd.google-apps.document (resp.\napplication/vnd.google-apps.spreadsheet and\napplication/vnd.google-apps.presentation).\n(note that mimeType contains google-apps.document does not answer\nanything.\n. ",
    "quinncomendant": "gdrive list -q \"mimeType = 'application/vnd.google-apps.spreadsheet'\" returns only two items, out of about fifty spreadsheets I have in my account. gdrive list -q \"mimeType = 'application/vnd.google-apps.document'\" returns nothing, despite many documents existing. Any ideas why this query isn't able to retrieve the full list of documents?\nUpdate: attempting to download the spreadsheets found by the above query doesn't work either:\n```\n[q@haywire/0 ~] gdrive list -q \"mimeType = 'application/vnd.google-apps.spreadsheet'\"\nId                                             Title                      Size    Created             \n0Anonp6KHFhl8dEk4bktHTGtXd1lGaF9tZGs4OExSR2c   Working WM Budget w/ P&L   0.0 B   2010-06-15 19:53:13 \n0Anonp6KHFhl8dFQ5TVRYanFMeGx5Skc0bXMxY2VUR3c   WM Budget w/ P&L           0.0 B   2010-05-22 20:04:06   \n[q@haywire/0 ~] gdrive download -i 0Anonp6KHFhl8dEk4bktHTGtXd1lGaF9tZGs4OExSR2c\nAn error occurred: open Working WM Budget w/ P&L: no such file or directory\n[q@haywire/0 ~] gdrive download -i 0Anonp6KHFhl8dFQ5TVRYanFMeGx5Skc0bXMxY2VUR3c\nAn error occurred: open WM Budget w/ P&L: no such file or directory\n``\n. \ud83d\ude0d\n. Yes, that solved it! Thanks!\n.gdrive list -q \"mimeType = 'application/vnd.google-apps.spreadsheet'\"returns only two items, out of about fifty spreadsheets I have in my account.gdrive list -q \"mimeType = 'application/vnd.google-apps.document'\"` returns nothing, despite many documents existing. Any ideas why this query isn't able to retrieve the full list of documents?\nUpdate: attempting to download the spreadsheets found by the above query doesn't work either:\n```\n[q@haywire/0 ~] gdrive list -q \"mimeType = 'application/vnd.google-apps.spreadsheet'\"\nId                                             Title                      Size    Created             \n0Anonp6KHFhl8dEk4bktHTGtXd1lGaF9tZGs4OExSR2c   Working WM Budget w/ P&L   0.0 B   2010-06-15 19:53:13 \n0Anonp6KHFhl8dFQ5TVRYanFMeGx5Skc0bXMxY2VUR3c   WM Budget w/ P&L           0.0 B   2010-05-22 20:04:06   \n[q@haywire/0 ~] gdrive download -i 0Anonp6KHFhl8dEk4bktHTGtXd1lGaF9tZGs4OExSR2c\nAn error occurred: open Working WM Budget w/ P&L: no such file or directory\n[q@haywire/0 ~] gdrive download -i 0Anonp6KHFhl8dFQ5TVRYanFMeGx5Skc0bXMxY2VUR3c\nAn error occurred: open WM Budget w/ P&L: no such file or directory\n```\n. \ud83d\ude0d\n. Yes, that solved it! Thanks!\n. ",
    "tanc": "Agreed, this just burnt me. Took ages to figure out what was happening.\n. Great! Will try this out soon.\n. Agreed, this just burnt me. Took ages to figure out what was happening.\n. Great! Will try this out soon.\n. ",
    "vtraag": "Same for me here, took me a while to figure out. A recursive mode would be much appreciated.\n. Same for me here, took me a while to figure out. A recursive mode would be much appreciated.\n. ",
    "pgcd": "Brilliant!\n. Brilliant!\n. ",
    "batteryshark": "This is apparently a pretty common thing in a lot of gdrive programs. I wrote a python script as a workaround to pull all the file ids in a directory and pass that to this program; the issue appears to come from not fully polling all the pages of results when calling list()\n. This is apparently a pretty common thing in a lot of gdrive programs. I wrote a python script as a workaround to pull all the file ids in a directory and pass that to this program; the issue appears to come from not fully polling all the pages of results when calling list()\n. ",
    "s920361": "Sorry,I am too stubit.\nI forgot to use drive info -i \nNow ,my problem is I don't know how to delete an issue\n. Sorry,I am too stubit.\nI forgot to use drive info -i \nNow ,my problem is I don't know how to delete an issue\n. ",
    "rdeavila": ":+1: \n. You're calling the binary using the full path? I had this problem, because the cron PATH is different from the terminal PATH. Calling the executable using the full path (in my case /usr/local/bin/drive) solved the problem.\n. @jmrezayi2 I don't know if the question is for me, but... :smile: \nYes. I'm calling the drive executable with the full path (/usr/local/bin/drive -f some file). I don't know if /usr/local/bin is the right place to install it, but that's the place I'm using now.\nHere is the AskUbuntu answer that helped me find the problem with cron.\n. If you ping accounts.google.com, you can resolve the IP address?\n. I've seen this before on #55...\n. The Trace/breakpoint trap message is not generated by the go language? Does not seem to be an API error ...\n. Hi @amidia \nTry this: #55 \n. :+1: \n. You're calling the binary using the full path? I had this problem, because the cron PATH is different from the terminal PATH. Calling the executable using the full path (in my case /usr/local/bin/drive) solved the problem.\n. @jmrezayi2 I don't know if the question is for me, but... :smile: \nYes. I'm calling the drive executable with the full path (/usr/local/bin/drive -f some file). I don't know if /usr/local/bin is the right place to install it, but that's the place I'm using now.\nHere is the AskUbuntu answer that helped me find the problem with cron.\n. If you ping accounts.google.com, you can resolve the IP address?\n. I've seen this before on #55...\n. The Trace/breakpoint trap message is not generated by the go language? Does not seem to be an API error ...\n. Hi @amidia \nTry this: #55 \n. ",
    "bxshi": "I also have problem when uploading moderate large files (around 1GB), the error I get is \nAn error occurred uploading the document: Post https://www.googleapis.com/upload/drive/v2/files?alt=json&convert=false&uploadType=resumable&upload_id=AEnB2Urh1F-ybIYsMrE616kFv5rrmKEZLAN2NH2UI-f8FH7mOJRRYlSdit3xCYJrtZpaqPw7assXLSg96_GTLqN3aXXAzvKiYw: dial tcp 216.58.216.234:443: i/o timeout\nMy uploading speed is also 1MB/s.\n. I'm using internet2 which should be super fast...\nUnfortunately I do not know Go at all, so I have no idea about the cause of this problem...\n. I would appreciate if you can provide a new compiled version with a higher chunkSize by any chance.\n. I also have problem when uploading moderate large files (around 1GB), the error I get is \nAn error occurred uploading the document: Post https://www.googleapis.com/upload/drive/v2/files?alt=json&convert=false&uploadType=resumable&upload_id=AEnB2Urh1F-ybIYsMrE616kFv5rrmKEZLAN2NH2UI-f8FH7mOJRRYlSdit3xCYJrtZpaqPw7assXLSg96_GTLqN3aXXAzvKiYw: dial tcp 216.58.216.234:443: i/o timeout\nMy uploading speed is also 1MB/s.\n. I'm using internet2 which should be super fast...\nUnfortunately I do not know Go at all, so I have no idea about the cause of this problem...\n. I would appreciate if you can provide a new compiled version with a higher chunkSize by any chance.\n. ",
    "erpalma": "With bigger chunks of ver 1.6.1 the problem seems to be fixed\n. With bigger chunks of ver 1.6.1 the problem seems to be fixed\n. ",
    "alexjj": "On my FreeBSD machine I have no issue but on my Linux box I get this error when uploading a ~1GB file. I just installed the latest 64bit build.\n. I'm not the dev, nor have I contributed anything to this project...but Windows 2000! It made me chuckle. I was fond of Windows 2000 and remember using it for a long time myself. \nAlso, Microsoft stopped providing security patches for Win2k in 2010, so you're potentially at risk by running it, even in a VM.\n. @zedman2000 I can completely understand not wanting to buy a new version of Windows. I'd always encourage people to try Linux/BSD to replace their Windows usage because they are free and (in my experience) better at doing the job. If you're really limited on RAM/hard drive space you might want to consider not using virtual machines as these carry overhead. FreeBSD jails or Docker are good alternatives which offer isolation but minimise overhead. FreeBSD has the advantage that ZFS is baked in, so you've got your storage covered, but it's easy enough to install on Debian/Linux. \nThere's also the raspberry pi option! :neckbeard: \nA good community for virtualization is www.reddit.com/r/homelab\n. On my FreeBSD machine I have no issue but on my Linux box I get this error when uploading a ~1GB file. I just installed the latest 64bit build.\n. I'm not the dev, nor have I contributed anything to this project...but Windows 2000! It made me chuckle. I was fond of Windows 2000 and remember using it for a long time myself. \nAlso, Microsoft stopped providing security patches for Win2k in 2010, so you're potentially at risk by running it, even in a VM.\n. @zedman2000 I can completely understand not wanting to buy a new version of Windows. I'd always encourage people to try Linux/BSD to replace their Windows usage because they are free and (in my experience) better at doing the job. If you're really limited on RAM/hard drive space you might want to consider not using virtual machines as these carry overhead. FreeBSD jails or Docker are good alternatives which offer isolation but minimise overhead. FreeBSD has the advantage that ZFS is baked in, so you've got your storage covered, but it's easy enough to install on Debian/Linux. \nThere's also the raspberry pi option! :neckbeard: \nA good community for virtualization is www.reddit.com/r/homelab\n. ",
    "DarkLinkXXXX": "I am also having this issue. \n. I am also having this issue. \n. ",
    "johnr14": "For date sort : \n./gdrive list | sed \"1 d\" | sort -n -k 5,5\nFor name sort\n./gdrive list | sed \"1 d\" | sort -k 2,5\nFor size \nDoesn't work as mixed type of unit .. B, KB, MB...\n. For date sort : \n./gdrive list | sed \"1 d\" | sort -n -k 5,5\nFor name sort\n./gdrive list | sed \"1 d\" | sort -k 2,5\nFor size \nDoesn't work as mixed type of unit .. B, KB, MB...\n. ",
    "ppmathis": "I already expected that when I took a glance at the sourcecode, but I wasn't sure. I think it would be a great idea to do it similar like pv - if no size is specified, upload it non-resumable (and maybe print a warning/hint?), if a size got specified, use the resumable way of doing it.\n. I'll make a push request for that feature soon, stay tuned.\nEDIT: This might actually be a lot more difficult than I first thought. Your current implementation of UploadStdin takes a io.ReadCloser, but the ResumableMedia API requires the interface io.ReaderAt. I've tried changing it to input *os.File and it compiles atleast, but ofcourse the execution will not work properly:\nread /dev/stdin: illegal seek\nAs far as I can tell, your google-api-go-client repository does not do the actual fileuploads, it only passes those arguments to another library from Google, which indeed tries to seek. And pipes are non-seekable, so that call can only fail.\nOne possibility would be to wrap something around os.Stdin which just discards input when seeking forward and throws an error when trying to seek backwards, as that's ofcourse not possible. Sounds like a really ugly hack though, any other ideas?\n. Just a short ping @prasmussen, as I'm not sure if you'll get a notification about my EDIT or not. I'll possibly try later on to go that quick'n'dirty way - it would work for me but ofcourse isn't a proper solution.\n. Short update: I've successfully uploaded now multiple big files (several GB) during the last three days and some of them took over 10 hours. My wrapper class works fine - I just have to add some additional code so that mime type detection works, I've disabled that currently and always use \"application/octet-stream\". Otherwise than that, the solution works way better than I've expected - PR coming soon.\n. I already expected that when I took a glance at the sourcecode, but I wasn't sure. I think it would be a great idea to do it similar like pv - if no size is specified, upload it non-resumable (and maybe print a warning/hint?), if a size got specified, use the resumable way of doing it.\n. I'll make a push request for that feature soon, stay tuned.\nEDIT: This might actually be a lot more difficult than I first thought. Your current implementation of UploadStdin takes a io.ReadCloser, but the ResumableMedia API requires the interface io.ReaderAt. I've tried changing it to input *os.File and it compiles atleast, but ofcourse the execution will not work properly:\nread /dev/stdin: illegal seek\nAs far as I can tell, your google-api-go-client repository does not do the actual fileuploads, it only passes those arguments to another library from Google, which indeed tries to seek. And pipes are non-seekable, so that call can only fail.\nOne possibility would be to wrap something around os.Stdin which just discards input when seeking forward and throws an error when trying to seek backwards, as that's ofcourse not possible. Sounds like a really ugly hack though, any other ideas?\n. Just a short ping @prasmussen, as I'm not sure if you'll get a notification about my EDIT or not. I'll possibly try later on to go that quick'n'dirty way - it would work for me but ofcourse isn't a proper solution.\n. Short update: I've successfully uploaded now multiple big files (several GB) during the last three days and some of them took over 10 hours. My wrapper class works fine - I just have to add some additional code so that mime type detection works, I've disabled that currently and always use \"application/octet-stream\". Otherwise than that, the solution works way better than I've expected - PR coming soon.\n. ",
    "cnbeining": "Gotcha.\n\nTo make upload resumable, @prasmussen used \"resumable upload\" here, which is good.\nIn the SDK, it is required that the minimum chunk size is 256*1024 = 256K. \nIf the network is not stable, this is good; however, for most home users, especially for server users(whose peering is great and link is so stable that it has a SLA), 256K is too mild.\nI am trying to find the place where the chunk size is determined, but I do not know golang...\nIt would be better if this size is set larger(say, 5MiB), and adjustable with command line or config file.\nFYI.\n. I am so glad that I helped a little bit :smile: \nI suppose we can tolerate a chunk size as (Normal_Home_Bandwidth_Expected_Upload_Speed) * 5 sec. \nFor whose network is not stable(e.g., 3G signal in a fast moving car), it would not make their life more comfortable even reduce the chunk to minimum size; And for server hosted in datacenters, they can dump 20MiB of data every second to Google without any package lost...\n. Thank you very much!\nJust to let you know that the chunk size must be times of 256KiB.\n. FYI:\nFor lazy people:\nThrow this into your .bashrc:\nfunction gdupload() { \n  drive upload -C 52428800 -f $1\n}\nSave a tiny bit of work.\n. Gotcha.\n\nTo make upload resumable, @prasmussen used \"resumable upload\" here, which is good.\nIn the SDK, it is required that the minimum chunk size is 256*1024 = 256K. \nIf the network is not stable, this is good; however, for most home users, especially for server users(whose peering is great and link is so stable that it has a SLA), 256K is too mild.\nI am trying to find the place where the chunk size is determined, but I do not know golang...\nIt would be better if this size is set larger(say, 5MiB), and adjustable with command line or config file.\nFYI.\n. I am so glad that I helped a little bit :smile: \nI suppose we can tolerate a chunk size as (Normal_Home_Bandwidth_Expected_Upload_Speed) * 5 sec. \nFor whose network is not stable(e.g., 3G signal in a fast moving car), it would not make their life more comfortable even reduce the chunk to minimum size; And for server hosted in datacenters, they can dump 20MiB of data every second to Google without any package lost...\n. Thank you very much!\nJust to let you know that the chunk size must be times of 256KiB.\n. FYI:\nFor lazy people:\nThrow this into your .bashrc:\nfunction gdupload() { \n  drive upload -C 52428800 -f $1\n}\nSave a tiny bit of work.\n. ",
    "StefaanVanDooren": "I managed to (cross)compile a version, which seems to be identical to the rpi version using gvm on a development machine. \nenv GOOS=linux GOARCH=arm GOARM=5 go build drive.go\nI got the same core dump.\nenv GOOS=linux GOARCH=arm GOARM=6 CGO_ENABLED=0 go build drive.go\ngives me the runtime error....\nANy hints on how to debug this ?\nRunning the ARMv5 version on an ARMv7 nas (WD ex2) gives the following error :+1: \nunexpected fault address 0x298184\nfatal error: fault\n[signal 0xb code=0x2 addr=0x298184 pc=0x298184]\ngoroutine 1 [running, locked to thread]:\nruntime.gothrow(0x33ad48, 0x5)\n        /home/user/.gvm/gos/go1.4.2/src/runtime/panic.go:503 +0x84 fp=0x1065ded4 sp=0x1065dec8\nruntime.sigpanic()\n        /home/user/.gvm/gos/go1.4.2/src/runtime/sigpanic_unix.go:29 +0x2a4 fp=0x1065defc sp=0x1065ded4\nhash/crc32.init()\n        /home/user/.gvm/gos/go1.4.2/src/hash/crc32/crc32_generic.go:14 fp=0x1065df00 sp=0x1065df00\nnet/http.init()\n        /home/user/.gvm/gos/go1.4.2/src/net/http/transport.go:1275 +0x64 fp=0x1065df84 sp=0x1065df00\nnet/http.init()\n        /home/user/.gvm/gos/go1.4.2/src/net/http/transport.go:1275 +0x64 fp=0x1065e008 sp=0x1065df84\ngoroutine 2 [runnable]:\nruntime.forcegchelper()\n        /home/user/.gvm/gos/go1.4.2/src/runtime/proc.go:90\nruntime.goexit()\n        /home/user/.gvm/gos/go1.4.2/src/runtime/asm_arm.s:1322 +0x4\ngoroutine 3 [runnable]:\nruntime.bgsweep()\n        /home/user/.gvm/gos/go1.4.2/src/runtime/mgc0.go:82\nruntime.goexit()\n        /home/user/.gvm/gos/go1.4.2/src/runtime/asm_arm.s:1322 +0x4\ngoroutine 4 [runnable]:\nruntime.runfinq()\n        /home/user/.gvm/gos/go1.4.2/src/runtime/malloc.go:712\nruntime.goexit()\n        /home/user/.gvm/gos/go1.4.2/src/runtime/asm_arm.s:1322 +0x4\nthe ARMv7 version (or ARMv6 version) i compiled runs just fine on that one too.\neverything compiled using go1.4.2 with env \nGOARCH=\"arm\"\nGOBIN=\"\"\nGOCHAR=\"5\"\nGOEXE=\"\"\nGOHOSTARCH=\"amd64\"\nGOHOSTOS=\"linux\"\nGOOS=\"linux\"\nGOPATH=\"/home/user/.gvm/pkgsets/go1.4.2/global\"\nGORACE=\"\"\nGOROOT=\"/home/user/.gvm/gos/go1.4.2\"\nGOTOOLDIR=\"/home/user/.gvm/gos/go1.4.2/pkg/tool/linux_amd64\"\nCC=\"gcc\"\nGOGCCFLAGS=\"-fPIC -marm -fmessage-length=0\"\nCXX=\"g++\"\nCGO_ENABLED=\"0\"\n. I managed to (cross)compile a version, which seems to be identical to the rpi version using gvm on a development machine. \nenv GOOS=linux GOARCH=arm GOARM=5 go build drive.go\nI got the same core dump.\nenv GOOS=linux GOARCH=arm GOARM=6 CGO_ENABLED=0 go build drive.go\ngives me the runtime error....\nANy hints on how to debug this ?\nRunning the ARMv5 version on an ARMv7 nas (WD ex2) gives the following error :+1: \nunexpected fault address 0x298184\nfatal error: fault\n[signal 0xb code=0x2 addr=0x298184 pc=0x298184]\ngoroutine 1 [running, locked to thread]:\nruntime.gothrow(0x33ad48, 0x5)\n        /home/user/.gvm/gos/go1.4.2/src/runtime/panic.go:503 +0x84 fp=0x1065ded4 sp=0x1065dec8\nruntime.sigpanic()\n        /home/user/.gvm/gos/go1.4.2/src/runtime/sigpanic_unix.go:29 +0x2a4 fp=0x1065defc sp=0x1065ded4\nhash/crc32.init()\n        /home/user/.gvm/gos/go1.4.2/src/hash/crc32/crc32_generic.go:14 fp=0x1065df00 sp=0x1065df00\nnet/http.init()\n        /home/user/.gvm/gos/go1.4.2/src/net/http/transport.go:1275 +0x64 fp=0x1065df84 sp=0x1065df00\nnet/http.init()\n        /home/user/.gvm/gos/go1.4.2/src/net/http/transport.go:1275 +0x64 fp=0x1065e008 sp=0x1065df84\ngoroutine 2 [runnable]:\nruntime.forcegchelper()\n        /home/user/.gvm/gos/go1.4.2/src/runtime/proc.go:90\nruntime.goexit()\n        /home/user/.gvm/gos/go1.4.2/src/runtime/asm_arm.s:1322 +0x4\ngoroutine 3 [runnable]:\nruntime.bgsweep()\n        /home/user/.gvm/gos/go1.4.2/src/runtime/mgc0.go:82\nruntime.goexit()\n        /home/user/.gvm/gos/go1.4.2/src/runtime/asm_arm.s:1322 +0x4\ngoroutine 4 [runnable]:\nruntime.runfinq()\n        /home/user/.gvm/gos/go1.4.2/src/runtime/malloc.go:712\nruntime.goexit()\n        /home/user/.gvm/gos/go1.4.2/src/runtime/asm_arm.s:1322 +0x4\nthe ARMv7 version (or ARMv6 version) i compiled runs just fine on that one too.\neverything compiled using go1.4.2 with env \nGOARCH=\"arm\"\nGOBIN=\"\"\nGOCHAR=\"5\"\nGOEXE=\"\"\nGOHOSTARCH=\"amd64\"\nGOHOSTOS=\"linux\"\nGOOS=\"linux\"\nGOPATH=\"/home/user/.gvm/pkgsets/go1.4.2/global\"\nGORACE=\"\"\nGOROOT=\"/home/user/.gvm/gos/go1.4.2\"\nGOTOOLDIR=\"/home/user/.gvm/gos/go1.4.2/pkg/tool/linux_amd64\"\nCC=\"gcc\"\nGOGCCFLAGS=\"-fPIC -marm -fmessage-length=0\"\nCXX=\"g++\"\nCGO_ENABLED=\"0\"\n. ",
    "jeroenqui": "Did you manage to fix this eventually?\nI'm trying to get gdrive running on my QNAP NAS.\n. I have the same problem. Would be great if there was a flag to overwrite the file when a collision was detected\n. Did you manage to fix this eventually?\nI'm trying to get gdrive running on my QNAP NAS.\n. I have the same problem. Would be great if there was a flag to overwrite the file when a collision was detected\n. ",
    "tuxing": "Thanks @StefaanVanDooren for confirming that the compiled armv5 version was identical to rpi version.\nI was able to get the rpi version working on my qnap nas TS-412 with kirkwood armv5 processor.\nso for those with armv5 the rpi version will work just fine.\nthanks\ntuxing. Thanks @StefaanVanDooren for confirming that the compiled armv5 version was identical to rpi version.\nI was able to get the rpi version working on my qnap nas TS-412 with kirkwood armv5 processor.\nso for those with armv5 the rpi version will work just fine.\nthanks\ntuxing. ",
    "DerSeegler": "Would also love to have the feature that a file gets updated instead of created when there already is a file with the exact name. I'm using this tool to backup some data. Using Google Drives revision service would be amazing for this. Any chance this gets implemented?\n. Thank you so much for this. It works perfectly. Is there any way I can donate to you because I would really like to.\n. Would also love to have the feature that a file gets updated instead of created when there already is a file with the exact name. I'm using this tool to backup some data. Using Google Drives revision service would be amazing for this. Any chance this gets implemented?\n. Thank you so much for this. It works perfectly. Is there any way I can donate to you because I would really like to.\n. ",
    "berna1995": "Yeah, it would be amazing. \n. Yes, i would love gdrive to use Google Drive revision system for example.\n. @robertogomez Can you please upload a compiled version of that specific fork? Im not able to compile the source.\n. @Drezzler I tried the last version on Linux. Have you suceeded compiling with v.1.4.2?\n. @occho Thank you very much. I'll test later. :+1: \n. Yeah, it would be amazing. \n. Yes, i would love gdrive to use Google Drive revision system for example.\n. @robertogomez Can you please upload a compiled version of that specific fork? Im not able to compile the source.\n. @Drezzler I tried the last version on Linux. Have you suceeded compiling with v.1.4.2?\n. @occho Thank you very much. I'll test later. :+1: \n. ",
    "fnkr": "+1\n. +1\n. ",
    "alpi-ua": "I hope i will see this in gdrive.\n. I also need this if it real.\n. I hope i will see this in gdrive.\n. I also need this if it real.\n. ",
    "mceran": "Copying files. It would be great. \n. Copying files. It would be great. \n. ",
    "seadog007": "I think it is a useful function that can copy files from any file id. I think it is a useful function that can copy files from any file id. ",
    "ggoforth": "Any chance of this find it's way into a release?  . Any chance of this find it's way into a release?  . ",
    "tranvu711": "Please support in new release. \nThanks.. Please support in new release. \nThanks.. ",
    "markodudic": "I have same problem with crone. Do you find a solution?\n. I use full path as rdeavila suggest and it works for me.\n. I have same problem with crone. Do you find a solution?\n. I use full path as rdeavila suggest and it works for me.\n. ",
    "jmrezayi2": "Well I think I am.. I call the drive command in a shell script (called backp.sh). \nsummary of backup.sh:\n\nI use the following variable to get the absolute path and use absolute path everywhere:\nSCRIPTPATH=$(cd\" $( dirname \"$0\" )\" && pwd)\nthen I am using such line in it:\ndrive  -f $SCRIPTPATH/name.zip \n\nThen in my crontab I am using this line:\nsh /home/some path/backup.sh>>/home/some path/log.txt\nit does all the steps but fails to upload to google drive. I tried specifying the credentials by config (--config $SCRIPTPATH/) but it is not working. needless to say the  \"sh /home/some path/backup.sh>>/home/some path/log.txt\" runs perfectly from anywhere..\nDo you mean instead of typing drive -f somefile, I should call it with the full path?\nThanks\n. Still no luck...\nJust to be clear, I am using something like this in the shell script that is being called from crontab:\ndrive -f somefile.\nDo you think I need to use it with the full path to the bin of drive?\nThanks all!\n. can you clarify more please?\ndoes it mean instead of calling drive -f somefile, you used /usr/local/bin/drive -f some file?\nthanks\n. @rdeavila  Thank you! you saved the day! You had the solution from the beginning and I did not understand it.\nThanks!\n. Well I think I am.. I call the drive command in a shell script (called backp.sh). \nsummary of backup.sh:\n\nI use the following variable to get the absolute path and use absolute path everywhere:\nSCRIPTPATH=$(cd\" $( dirname \"$0\" )\" && pwd)\nthen I am using such line in it:\ndrive  -f $SCRIPTPATH/name.zip \n\nThen in my crontab I am using this line:\nsh /home/some path/backup.sh>>/home/some path/log.txt\nit does all the steps but fails to upload to google drive. I tried specifying the credentials by config (--config $SCRIPTPATH/) but it is not working. needless to say the  \"sh /home/some path/backup.sh>>/home/some path/log.txt\" runs perfectly from anywhere..\nDo you mean instead of typing drive -f somefile, I should call it with the full path?\nThanks\n. Still no luck...\nJust to be clear, I am using something like this in the shell script that is being called from crontab:\ndrive -f somefile.\nDo you think I need to use it with the full path to the bin of drive?\nThanks all!\n. can you clarify more please?\ndoes it mean instead of calling drive -f somefile, you used /usr/local/bin/drive -f some file?\nthanks\n. @rdeavila  Thank you! you saved the day! You had the solution from the beginning and I did not understand it.\nThanks!\n. ",
    "chuanzgh": "Maybe you can try importing your account profile at the start of your\nscript. depending on your shell, it's something like:\n. ~/.profile\nThis little line can solve the mystery sometimes.\nOn Apr 15, 2015 8:03 AM, \"jmrezayi2\" notifications@github.com wrote:\n\nWell I think I am.. I have the drive in a shell script (called backp.sh).\nsummary of backup.sh:\nI use the following variable to get the absolute path and use absolute\npath everywhere:\nSCRIPTPATH=$(cd\" $( dirname \"$0\" )\" && pwd)\nthen I am using such line in the shell:\ndrive --config $SCRIPTPATH/ -f $SCRIPTPATH/name.zip\nThen in my crontab I am using this line:\nsh /home/some path/backup.sh>>/home/some path/log.txt\nit does all the steps but fails to upload to google drive. I tried\nspecifying the credentials by config but it is not working. needless to say\nthe \"sh /home/some path/backup.sh>>/home/some path/log.txt\" runs perfectly\nfrom anywhere..\nDo you mean instead of typing drive -f somefile, I should call it with the\nfull path?\nThanks\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/prasmussen/gdrive/issues/55#issuecomment-93118860.\n. I would love to have the create/mod time preserved for files that I upload thru drive.google.com as well! ;) This should go to Google rather than here :laughing: \n. I don't see the purpose and benefits of intentionally limiting the speed for a particular platform? If you're using the vanilla version of the pi (i.e. you did not do any mods to the networking on the pi), it's more likely that you've hit some sort of hardware speed cap on the pi itself.. Because this is a CLI client?\n\"gdrive is a command line utility for interacting with Google Drive.\". Could you quantify \"very hard to download files shared on google drive via wget/curl\"?\n\nDo you mean, for example, this does not work?\nwget -O gdrive-linux-x64 https://docs.google.com/uc?id=0B3X9GlR6EmbnQ0FtZmJJUXEyRTA&export=download. Pretty sure gdrive can't help do what you wanted to do.. You are raising the issue to the wrong group.. Maybe you can try importing your account profile at the start of your\nscript. depending on your shell, it's something like:\n. ~/.profile\nThis little line can solve the mystery sometimes.\nOn Apr 15, 2015 8:03 AM, \"jmrezayi2\" notifications@github.com wrote:\n\nWell I think I am.. I have the drive in a shell script (called backp.sh).\nsummary of backup.sh:\nI use the following variable to get the absolute path and use absolute\npath everywhere:\nSCRIPTPATH=$(cd\" $( dirname \"$0\" )\" && pwd)\nthen I am using such line in the shell:\ndrive --config $SCRIPTPATH/ -f $SCRIPTPATH/name.zip\nThen in my crontab I am using this line:\nsh /home/some path/backup.sh>>/home/some path/log.txt\nit does all the steps but fails to upload to google drive. I tried\nspecifying the credentials by config but it is not working. needless to say\nthe \"sh /home/some path/backup.sh>>/home/some path/log.txt\" runs perfectly\nfrom anywhere..\nDo you mean instead of typing drive -f somefile, I should call it with the\nfull path?\nThanks\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/prasmussen/gdrive/issues/55#issuecomment-93118860.\n. I would love to have the create/mod time preserved for files that I upload thru drive.google.com as well! ;) This should go to Google rather than here :laughing: \n. I don't see the purpose and benefits of intentionally limiting the speed for a particular platform? If you're using the vanilla version of the pi (i.e. you did not do any mods to the networking on the pi), it's more likely that you've hit some sort of hardware speed cap on the pi itself.. Because this is a CLI client?\n\"gdrive is a command line utility for interacting with Google Drive.\". Could you quantify \"very hard to download files shared on google drive via wget/curl\"?\n\nDo you mean, for example, this does not work?\nwget -O gdrive-linux-x64 https://docs.google.com/uc?id=0B3X9GlR6EmbnQ0FtZmJJUXEyRTA&export=download. Pretty sure gdrive can't help do what you wanted to do.. You are raising the issue to the wrong group.. ",
    "aglim": "Same trouble: I'm trying to upload a folder using \n```\n\ndrive-windows-amd64.exe upload -f folder\n```\n\ncommand but all I get is:\n\nchdir [path]: not supported by windows\n\nIs this a limitation of Go's os lib?\n. Same trouble: I'm trying to upload a folder using \n```\n\ndrive-windows-amd64.exe upload -f folder\n```\n\ncommand but all I get is:\n\nchdir [path]: not supported by windows\n\nIs this a limitation of Go's os lib?\n. ",
    "SDCC-gholder": "I also get this issue on windows\nE:>C:\\VeeamToGoogleDrive\\drive-windows-amd64.exe -c C:\\VeeamToGoogleDrive.config upload -f \"Application Servers Backup Job\"\nchdir E:\\Application Servers Backup Job: not supported by windows\n. I also get this issue on windows\nE:>C:\\VeeamToGoogleDrive\\drive-windows-amd64.exe -c C:\\VeeamToGoogleDrive.config upload -f \"Application Servers Backup Job\"\nchdir E:\\Application Servers Backup Job: not supported by windows\n. ",
    "hwiorn": "I found Chdir() error problem which is not implemented in Windows. (https://golang.org/src/os/os_test.go#L835)\ngo\nfunc TestChdirAndGetwd(t *testing.T) {\n    // TODO(brainman): file.Chdir() is not implemented on windows.\n    if runtime.GOOS == \"windows\" {\n        return\n    }\ngdrive/cli/cli.go:250\ngo\n// Go into directory\nerr = input.Chdir() <-- \"chdir [path]: not supported by windows\" printed in windows.\nif err != nil {\n      return err\n}\n-> https://golang.org/src/os/file.go#L224\n--> https://golang.org/src/syscall/syscall_windows.go#L953\ngo\n   953  // TODO(brainman): fix all needed for os\n   954  func Fchdir(fd Handle) (err error)             { return EWINDOWS }\nI think gdrive need to be changed to os.Chdir(String) method below.\n-> https://golang.org/src/os/file.go#L214\n--> https://golang.org/src/syscall/syscall_windows.go#L369\n. I found Chdir() error problem which is not implemented in Windows. (https://golang.org/src/os/os_test.go#L835)\ngo\nfunc TestChdirAndGetwd(t *testing.T) {\n    // TODO(brainman): file.Chdir() is not implemented on windows.\n    if runtime.GOOS == \"windows\" {\n        return\n    }\ngdrive/cli/cli.go:250\ngo\n// Go into directory\nerr = input.Chdir() <-- \"chdir [path]: not supported by windows\" printed in windows.\nif err != nil {\n      return err\n}\n-> https://golang.org/src/os/file.go#L224\n--> https://golang.org/src/syscall/syscall_windows.go#L953\ngo\n   953  // TODO(brainman): fix all needed for os\n   954  func Fchdir(fd Handle) (err error)             { return EWINDOWS }\nI think gdrive need to be changed to os.Chdir(String) method below.\n-> https://golang.org/src/os/file.go#L214\n--> https://golang.org/src/syscall/syscall_windows.go#L369\n. ",
    "mago27": "@prasmussen, i tested drive-windows-x64.exe v1.9.0 and it works.\n. @prasmussen, i tested drive-windows-x64.exe v1.9.0 and it works.\n. ",
    "piermarcobarbe": "Hi,\nIf you want to use a different account you could just delete the \".gdrive\" folder in your home (~/.gdrive/).\nIf you want to manage more accounts at once, i do so, even if i think there are easier ways:\n1)Configure first account (Account X): ~/.gdrive is created \n2) rename .gdrive in .gdriveAccountX\n3)Configure second Account (Account Y): ~/.gdrive is created, now contains files about Account Y.\nNow, when you have to use account X rename .gdrive in .gdriveAccountY and .gdriveAccountX in .gdrive.\nWhen you want to use account Y rename .gdrive in .gdriveAccountX and .gdriveAccountY in .gdrive.\nIt's rude but it works.\n. Hi,\nIf you want to use a different account you could just delete the \".gdrive\" folder in your home (~/.gdrive/).\nIf you want to manage more accounts at once, i do so, even if i think there are easier ways:\n1)Configure first account (Account X): ~/.gdrive is created \n2) rename .gdrive in .gdriveAccountX\n3)Configure second Account (Account Y): ~/.gdrive is created, now contains files about Account Y.\nNow, when you have to use account X rename .gdrive in .gdriveAccountY and .gdriveAccountX in .gdrive.\nWhen you want to use account Y rename .gdrive in .gdriveAccountX and .gdriveAccountY in .gdrive.\nIt's rude but it works.\n. ",
    "HappyHub1": "Thanks for the reply. I actually figured out the -c argument a few days ago. \nIt is actually like this:  drive -c ./foobar upload --file file.mp4\nWhen ./foobar doesn't exist, it will ask for a token. I believe this should be clarified in the --help section.\n. Thanks for the reply. I actually figured out the -c argument a few days ago. \nIt is actually like this:  drive -c ./foobar upload --file file.mp4\nWhen ./foobar doesn't exist, it will ask for a token. I believe this should be clarified in the --help section.\n. ",
    "df1paw": "same for me :-(\n. same for me :-(\n. ",
    "goodpunk6": "Please reopen this issue. I am having the same problem.. I am having the same issue running on an ubuntu 16 lts. Please reopen this issue. I am having the same problem.. I am having the same issue running on an ubuntu 16 lts. ",
    "cburatto": "+1: uploaded a folder with several files and subfolders. Let it ran successfully for a while then stopped at \"An error occurred: googleapi: Error 401: Invalid Credentials, authError\". \nCould it be due to Oauth token expiration?\nhttps://developers.google.com/identity/protocols/OAuth2\n\nAccess tokens have limited lifetimes. If your application needs access to a Google API beyond the lifetime of a single access token, it can obtain a refresh token. A refresh token allows your application to obtain new access tokens.\n\nShould \"refresh token\" periodically when uploading folders?\nEnv: \n64 bits\nDistributor ID: Ubuntu\nDescription:    Ubuntu 14.04.2 LTS\nRelease:        14.04\nCodename:       trusty\n. +1: uploaded a folder with several files and subfolders. Let it ran successfully for a while then stopped at \"An error occurred: googleapi: Error 401: Invalid Credentials, authError\". \nCould it be due to Oauth token expiration?\nhttps://developers.google.com/identity/protocols/OAuth2\n\nAccess tokens have limited lifetimes. If your application needs access to a Google API beyond the lifetime of a single access token, it can obtain a refresh token. A refresh token allows your application to obtain new access tokens.\n\nShould \"refresh token\" periodically when uploading folders?\nEnv: \n64 bits\nDistributor ID: Ubuntu\nDescription:    Ubuntu 14.04.2 LTS\nRelease:        14.04\nCodename:       trusty\n. ",
    "helsont": "+1 Similar situation: was uploading a huge directory (overnight) and in the morning I saw that an error occurred: Error 401: Invalid Credentials, authError. \nSeems to be the expiration of the token.\n. +1 Similar situation: was uploading a huge directory (overnight) and in the morning I saw that an error occurred: Error 401: Invalid Credentials, authError. \nSeems to be the expiration of the token.\n. ",
    "abarrac1": "Has anyone found a way around this expiration?  I'm running into the same issue trying to upload a very large directory.\n. I was unaware there was an update!  I will check it out when I get a chance and report the results back.    \n. Installed gdrive 2 and am currently uploading a very large directory.  9+ TB  Speed is great at 7-9 MB/s.\nI initially tried the sync upload and it was bouncing back an error \"Failed to prepare local files: readdirent: remote I/O error\" on Cent (nfs mount to drive).  \nThe error I got for sync upload on the windows install was:\nFailed to prepare local files: GetFileAttributesEx Z:\\xxxxxxxxxxxxxxx\\xxxxxxxxxxxxxx\\xxxxxxxxxxxxxxxx\\xxxxxxxxxxxxx\\xxxxxxxxxxxx\\xxxxxxxxxxxxxxxxxxxxx\\xxxxxxxxxxxxxxxxxxxxx.PRV\\b50e39c2-b8f9-44a5-bb02-6391d58bc576+610ee9e9ee03d754fc88b590 48000.cfa: The system cannot find the path specified.\n. Has anyone found a way around this expiration?  I'm running into the same issue trying to upload a very large directory.\n. I was unaware there was an update!  I will check it out when I get a chance and report the results back.    \n. Installed gdrive 2 and am currently uploading a very large directory.  9+ TB  Speed is great at 7-9 MB/s.\nI initially tried the sync upload and it was bouncing back an error \"Failed to prepare local files: readdirent: remote I/O error\" on Cent (nfs mount to drive).  \nThe error I got for sync upload on the windows install was:\nFailed to prepare local files: GetFileAttributesEx Z:\\xxxxxxxxxxxxxxx\\xxxxxxxxxxxxxx\\xxxxxxxxxxxxxxxx\\xxxxxxxxxxxxx\\xxxxxxxxxxxx\\xxxxxxxxxxxxxxxxxxxxx\\xxxxxxxxxxxxxxxxxxxxx.PRV\\b50e39c2-b8f9-44a5-bb02-6391d58bc576+610ee9e9ee03d754fc88b590 48000.cfa: The system cannot find the path specified.\n. ",
    "satriyowibowo": "the binary for arm is not working\nplease fix it\n. the binary for arm is not working\nplease fix it\n. ",
    "mralexgray": "+1  this would eliminate a litany of nasty scripts (which I'd be happy to contribute, although they are not in GO), for monitoring/reacting to uploads.\n. BUMP!. +1  this would eliminate a litany of nasty scripts (which I'd be happy to contribute, although they are not in GO), for monitoring/reacting to uploads.\n. BUMP!. ",
    "fovea1959": "set http_proxy=http://myuproxyserver:8080/\nworks for me. (substitute the address and port of your proxy server in there)\n. set http_proxy=http://myuproxyserver:8080/\nworks for me. (substitute the address and port of your proxy server in there)\n. ",
    "susserj": "Hello favea1959. \nI tried your suggestion and set my Windows cmd environment parameter to our proxy server and  now  gdrive for Windows is now working for me. Perhaps this is an undocumented feature.\nThanks again.\n. Hello favea1959. \nI tried your suggestion and set my Windows cmd environment parameter to our proxy server and  now  gdrive for Windows is now working for me. Perhaps this is an undocumented feature.\nThanks again.\n. ",
    "ecostaalfaia": "Hi the directory download support doesn't work in this version.\n. Hi the directory download support doesn't work in this version.\n. ",
    "JoePython1": "Issue still occuring after setting GOPATH.\n$ export GOPATH=pwd\n$ echo $GOPATH\n/home/joev/Downloads/gdrive\n$ ls\nauth  build-all.sh  cli  config  drive.go  gdrive  LICENSE  README.md  upload.sh  util\n$ go build drive.go \ndrive.go:5:2: cannot find package \"github.com/prasmussen/gdrive/cli\" in any of:\n    /usr/lib/go/src/github.com/prasmussen/gdrive/cli (from $GOROOT)\n    /home/joev/Downloads/gdrive/src/github.com/prasmussen/gdrive/cli (from $GOPATH)\ndrive.go:6:2: cannot find package \"github.com/prasmussen/gdrive/gdrive\" in any of:\n    /usr/lib/go/src/github.com/prasmussen/gdrive/gdrive (from $GOROOT)\n    /home/joev/Downloads/gdrive/src/github.com/prasmussen/gdrive/gdrive (from $GOPATH)\ndrive.go:7:2: cannot find package \"github.com/prasmussen/gdrive/util\" in any of:\n    /usr/lib/go/src/github.com/prasmussen/gdrive/util (from $GOROOT)\n    /home/joev/Downloads/gdrive/src/github.com/prasmussen/gdrive/util (from $GOPATH)\ndrive.go:8:2: cannot find package \"github.com/prasmussen/google-api-go-client/googleapi\" in any of:\n    /usr/lib/go/src/github.com/prasmussen/google-api-go-client/googleapi (from $GOROOT)\n    /home/joev/Downloads/gdrive/src/github.com/prasmussen/google-api-go-client/googleapi (from $GOPATH)\ndrive.go:9:2: cannot find package \"github.com/voxelbrain/goptions\" in any of:\n    /usr/lib/go/src/github.com/voxelbrain/goptions (from $GOROOT)\n    /home/joev/Downloads/gdrive/src/github.com/voxelbrain/goptions (from $GOPATH)\n. Thank you\n. Issue still occuring after setting GOPATH.\n$ export GOPATH=pwd\n$ echo $GOPATH\n/home/joev/Downloads/gdrive\n$ ls\nauth  build-all.sh  cli  config  drive.go  gdrive  LICENSE  README.md  upload.sh  util\n$ go build drive.go \ndrive.go:5:2: cannot find package \"github.com/prasmussen/gdrive/cli\" in any of:\n    /usr/lib/go/src/github.com/prasmussen/gdrive/cli (from $GOROOT)\n    /home/joev/Downloads/gdrive/src/github.com/prasmussen/gdrive/cli (from $GOPATH)\ndrive.go:6:2: cannot find package \"github.com/prasmussen/gdrive/gdrive\" in any of:\n    /usr/lib/go/src/github.com/prasmussen/gdrive/gdrive (from $GOROOT)\n    /home/joev/Downloads/gdrive/src/github.com/prasmussen/gdrive/gdrive (from $GOPATH)\ndrive.go:7:2: cannot find package \"github.com/prasmussen/gdrive/util\" in any of:\n    /usr/lib/go/src/github.com/prasmussen/gdrive/util (from $GOROOT)\n    /home/joev/Downloads/gdrive/src/github.com/prasmussen/gdrive/util (from $GOPATH)\ndrive.go:8:2: cannot find package \"github.com/prasmussen/google-api-go-client/googleapi\" in any of:\n    /usr/lib/go/src/github.com/prasmussen/google-api-go-client/googleapi (from $GOROOT)\n    /home/joev/Downloads/gdrive/src/github.com/prasmussen/google-api-go-client/googleapi (from $GOPATH)\ndrive.go:9:2: cannot find package \"github.com/voxelbrain/goptions\" in any of:\n    /usr/lib/go/src/github.com/voxelbrain/goptions (from $GOROOT)\n    /home/joev/Downloads/gdrive/src/github.com/voxelbrain/goptions (from $GOPATH)\n. Thank you\n. ",
    "gknauf": "Update: I tried self to build a working binary and found that the golang toolchain (386 binary distro) already crashes exactly the same way; also tested now with a Pentium 3 with is even classified as i686 but the crash happens too ...; therefore I've created an issue for golang:\nhttps://github.com/golang/go/issues/11631\nFor now I found a workaround to create a true 32-bit Linux gdrive binary which works with my processors by using the gccgo compiler:\ngo build -compiler gccgo -gccgoflags '-static-libgo' drive.go\nalthough the resulting binary is really fat (>8MB), some brief testing shows all working so far; did list/upload/download/folder commands and all fine.\n. Got reply to the golang issue - quote:\n\"Go assumes SSE2 by default in our official binaries. Set GO386=387 when building from source, per instructions at http://golang.org/doc/install/source.\"\nI tried already to use this var when I compiled gdrive but that didnt work ...\nI followed the advice and did build the Go toolchain from source with GO386=387 and that works now fine: the toolchain itself runs on my 32-bit processors (without SSE2 support), and so does the gdrive binary compiled with:\ngo build -ldflags '-s' drive.go\nthe size of this binary is with 4.6M now also acceptable. If someone else  needs a gdrive binary for older processors without SSE2 support you can download it here:\ndrive-linux-386-387 v1.8.0\n. Update: I tried self to build a working binary and found that the golang toolchain (386 binary distro) already crashes exactly the same way; also tested now with a Pentium 3 with is even classified as i686 but the crash happens too ...; therefore I've created an issue for golang:\nhttps://github.com/golang/go/issues/11631\nFor now I found a workaround to create a true 32-bit Linux gdrive binary which works with my processors by using the gccgo compiler:\ngo build -compiler gccgo -gccgoflags '-static-libgo' drive.go\nalthough the resulting binary is really fat (>8MB), some brief testing shows all working so far; did list/upload/download/folder commands and all fine.\n. Got reply to the golang issue - quote:\n\"Go assumes SSE2 by default in our official binaries. Set GO386=387 when building from source, per instructions at http://golang.org/doc/install/source.\"\nI tried already to use this var when I compiled gdrive but that didnt work ...\nI followed the advice and did build the Go toolchain from source with GO386=387 and that works now fine: the toolchain itself runs on my 32-bit processors (without SSE2 support), and so does the gdrive binary compiled with:\ngo build -ldflags '-s' drive.go\nthe size of this binary is with 4.6M now also acceptable. If someone else  needs a gdrive binary for older processors without SSE2 support you can download it here:\ndrive-linux-386-387 v1.8.0\n. ",
    "SimonHova": "I am using gdrive on an old computer; could you please compile a more current binary for me?. I am using gdrive on an old computer; could you please compile a more current binary for me?. ",
    "tkgermany": "Same issue here.\nit opens more and more connections until the max open files limit is exceeded on linux and then quits, would like to see that fixed too\n. Hi Petter,\nI get this email currently every day... I have a 100gb-Drive and about 60gb left, so yes, enough space left to upload a 15gb file :)\nbtw. thanks for your great work...\nthomas\n\nReply sent via Mailstrom! http://mailstrom.co/\n\nI will change the error message in the future, but it means that no data has been transferred for 2 minutes, so it gives up. This was added to gdrive2 to avoid uploads that hangs forever.\nAre you getting this error often? Do you have enough free space on drive?\n\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub:\nhttps://github.com/prasmussen/gdrive/issues/127#issuecomment-205455617\n. timeout means for the whole transfer, from start to finish?\nAm 09.04.2016 10:05 nachm. schrieb \"Petter Rasmussen\" \nnotifications@github.com:\nI've increased the default timeout to 5 minutes in v2.1.0 and added a\n--timeout flag. If you still get the timeout error you can set the\ntimeout to 0 to disable the timeout logic.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/prasmussen/gdrive/issues/127#issuecomment-207845885\n. The timeout doesnt work...\nStarted the following at 16:00 today:\ngdrive2 upload --no-progress --timeout 1800 -r -p $ParentID $UploadFolder \nand it is still running don't doing anything.\nCurrently running the same without --no-progress to see its process/error, but seems to run fine.\n\nAny Idea?\nUpdate1:\nBy the way, found some hanging processes from the last few days too...\nseems any condition makes the gdrive2-process never to stop, even after 4-5days running\nUpdate2:\nOk, and after some tests some new input:\nRun with progress-Output:\ngdrive2 upload --timeout 1800 -r -p $ParentID $UploadFolder \nUploaded all Items, and showed this in shell.\nAlso showed the progress while uploading.\nAfter Uploading the last Item the Progress-Indicator gone away and after the last \"Uploading \"-Line theres just an empty line in the shell, but the process itself did not stop.\nCreating directory TEST_FULL_BACKUP_20160410_1516\nUploading /data/backups/TEST_FULL_BACKUP_20160410_1516/package-states-manual\nUploading /data/backups/TEST_FULL_BACKUP_20160410_1516/package-states-auto\nUploading /data/backups/TEST_FULL_BACKUP_20160410_1516/packages.list\nUploading /data/backups/TEST_FULL_BACKUP_20160410_1516/fullbackup.tar.gz\nHope that helps?\nUpdate3:\nThe last (and largest) file (fullbackup.tar.gz) is listed in the upload-list and seemed to be uploaded 100%, as the progress indicated before it faded away. But now i saw, it does not show up in drive...\nMaybe there is an issue with completing the fileupload in the end?\n. Same issue here.\nit opens more and more connections until the max open files limit is exceeded on linux and then quits, would like to see that fixed too\n. Hi Petter,\nI get this email currently every day... I have a 100gb-Drive and about 60gb left, so yes, enough space left to upload a 15gb file :)\nbtw. thanks for your great work...\nthomas\n\nReply sent via Mailstrom! http://mailstrom.co/\n\nI will change the error message in the future, but it means that no data has been transferred for 2 minutes, so it gives up. This was added to gdrive2 to avoid uploads that hangs forever.\nAre you getting this error often? Do you have enough free space on drive?\n\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub:\nhttps://github.com/prasmussen/gdrive/issues/127#issuecomment-205455617\n. timeout means for the whole transfer, from start to finish?\nAm 09.04.2016 10:05 nachm. schrieb \"Petter Rasmussen\" \nnotifications@github.com:\nI've increased the default timeout to 5 minutes in v2.1.0 and added a\n--timeout flag. If you still get the timeout error you can set the\ntimeout to 0 to disable the timeout logic.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/prasmussen/gdrive/issues/127#issuecomment-207845885\n. The timeout doesnt work...\nStarted the following at 16:00 today:\ngdrive2 upload --no-progress --timeout 1800 -r -p $ParentID $UploadFolder \nand it is still running don't doing anything.\nCurrently running the same without --no-progress to see its process/error, but seems to run fine.\n\nAny Idea?\nUpdate1:\nBy the way, found some hanging processes from the last few days too...\nseems any condition makes the gdrive2-process never to stop, even after 4-5days running\nUpdate2:\nOk, and after some tests some new input:\nRun with progress-Output:\ngdrive2 upload --timeout 1800 -r -p $ParentID $UploadFolder \nUploaded all Items, and showed this in shell.\nAlso showed the progress while uploading.\nAfter Uploading the last Item the Progress-Indicator gone away and after the last \"Uploading \"-Line theres just an empty line in the shell, but the process itself did not stop.\nCreating directory TEST_FULL_BACKUP_20160410_1516\nUploading /data/backups/TEST_FULL_BACKUP_20160410_1516/package-states-manual\nUploading /data/backups/TEST_FULL_BACKUP_20160410_1516/package-states-auto\nUploading /data/backups/TEST_FULL_BACKUP_20160410_1516/packages.list\nUploading /data/backups/TEST_FULL_BACKUP_20160410_1516/fullbackup.tar.gz\nHope that helps?\nUpdate3:\nThe last (and largest) file (fullbackup.tar.gz) is listed in the upload-list and seemed to be uploaded 100%, as the progress indicated before it faded away. But now i saw, it does not show up in drive...\nMaybe there is an issue with completing the fileupload in the end?\n. ",
    "priyankt68": "I am facing this issue as well. I have installed gdrive in several Rpis. It worked perfectly fine for the first one when I proceed ahead to authenticate for the second one, I face the above mentioned error.\n. Hi,\nYou can use -p/--parent to upload 13-02-2016.7z in the right directory. drive info will list id of Databases directory. Let's say it is 0B2ANP4rELNp7OGpUdWdRTUFLV3c . Knowing now the id of the parent directory(Databases in your case) , you can place 13-02-2016.7z correctly with the following command.\ndrive upload --file 13-02-2016.7z --parent 0B2ANP4rELNp7OGpUdWdRTUFLV3c\nGood luck!\n. I am facing this issue as well. I have installed gdrive in several Rpis. It worked perfectly fine for the first one when I proceed ahead to authenticate for the second one, I face the above mentioned error.\n. Hi,\nYou can use -p/--parent to upload 13-02-2016.7z in the right directory. drive info will list id of Databases directory. Let's say it is 0B2ANP4rELNp7OGpUdWdRTUFLV3c . Knowing now the id of the parent directory(Databases in your case) , you can place 13-02-2016.7z correctly with the following command.\ndrive upload --file 13-02-2016.7z --parent 0B2ANP4rELNp7OGpUdWdRTUFLV3c\nGood luck!\n. ",
    "ypchen": "Perhaps checking to see if ca-certificates.crt exists in /etc/ssl/certs helps.\n. @diman82 Is your ca-certificates.crt installed/located in /etc/ssl/certs? Perhaps the https handler looks for ca-certificates.crt only in this folder.\n. Perhaps checking to see if ca-certificates.crt exists in /etc/ssl/certs helps.\n. @diman82 Is your ca-certificates.crt installed/located in /etc/ssl/certs? Perhaps the https handler looks for ca-certificates.crt only in this folder.\n. ",
    "nlouahedj": "I am having the same issue, and /etc/ssl/certs/ca-certificates.crt is empty.. I am having the same issue, and /etc/ssl/certs/ca-certificates.crt is empty.. ",
    "caipivara": "It worked for me with gdrive upload -f folder/*\n. It worked for me with gdrive upload -f folder/*\n. ",
    "qzcw": "This would be a very important function. I'd like to backup multiple files automatically, i.e. mirror the local folder to Google Drive cloud.\n. This would be a very important function. I'd like to backup multiple files automatically, i.e. mirror the local folder to Google Drive cloud.\n. ",
    "robertogomez": "@tonyroza The behavior you're seeing is how Google Drive works. It doesn't uniquely identify files by name.\nUser @occho made a fork to add an update file feature, which is what I believe you and others have been looking for. I tested it briefly and it works, although I had to change some of the imports to build the binary correctly. Example:\ndrive.exe upload -u 0BytCbNhl3nyPelYtNGNzdlEtbkU -f time.txt\n. @tonyroza The behavior you're seeing is how Google Drive works. It doesn't uniquely identify files by name.\nUser @occho made a fork to add an update file feature, which is what I believe you and others have been looking for. I tested it briefly and it works, although I had to change some of the imports to build the binary correctly. Example:\ndrive.exe upload -u 0BytCbNhl3nyPelYtNGNzdlEtbkU -f time.txt\n. ",
    "occho": "@berna1995 Hi\nI uploaded executables I made with golang v1.4.2. https://drive.google.com/file/d/0B5wVSvViMOXmSGVmdFlUX0dtVm8/view?usp=sharing\nI will remove it at some later point.\n. @berna1995 Hi\nI uploaded executables I made with golang v1.4.2. https://drive.google.com/file/d/0B5wVSvViMOXmSGVmdFlUX0dtVm8/view?usp=sharing\nI will remove it at some later point.\n. ",
    "Arvur": "@occho Works like a charm for me! Thanks a lot! :+1:\n. @occho Works like a charm for me! Thanks a lot! :+1:\n. ",
    "zedman2000": "@alexjj I'd agree about the security, aside from the fact that it is not open to the world behind a 2 layer firewall.  If Google is compromised, access to my Google Drive is the least of my worries!  :-)\nBut honestly, with a site license for it - anything that I can do to use it (for Windows related things), I do.  Just makes interfacing to things a bit easier.  It is also a REALLY compact OS (compared to fully patched XP or beyond).  So, it makes running as a VM highly desirable.  I'd rather run NT, but nothing runs on it any longer!\nSince I did not get any information or posts or anything, I've since installed a VM of DSL.  It has a similar footprint to Win2k (256MB ram, <2GB hard drive).  It SEEMS that if I can get the Linux version of GDrive to stop crashing (I'm sure it is me - so I've not posted), this will work as a machine I can use to run automated backups.  Basically, I setup a SMB share of files I want copied - then I use that to distribute the appropriate files to the appropriate Google Drive for long term retention.  Seems to be working so far!\n. @alexjj thanks for the advice!  It is not a matter of BUYING or being limited, but why waste 16GB of ram on a machine that's sole purpose is to copy stuff to Google Drive?  As for buying, it was not that either, just a matter of resources.  If I could get away with it, I'd use DOS or if I had the time/patience I'd use SLACKWARE...they use next to NOTHING for resources!\nI use ESXi, so resource sharing is not really an issue.  I typically see DSL only using 29MB or ram, so ESXi will reclaim the rest of the 256MB for other machines to use.  I'm not worried!\nI already have a RPI. It controls the Zwave stuff in my house - which reports to a Win7 VM that runs my home automation (www.homeseer.com)! \nAnyway, thanks for the link, I'll check that out.\n. @alexjj I'd agree about the security, aside from the fact that it is not open to the world behind a 2 layer firewall.  If Google is compromised, access to my Google Drive is the least of my worries!  :-)\nBut honestly, with a site license for it - anything that I can do to use it (for Windows related things), I do.  Just makes interfacing to things a bit easier.  It is also a REALLY compact OS (compared to fully patched XP or beyond).  So, it makes running as a VM highly desirable.  I'd rather run NT, but nothing runs on it any longer!\nSince I did not get any information or posts or anything, I've since installed a VM of DSL.  It has a similar footprint to Win2k (256MB ram, <2GB hard drive).  It SEEMS that if I can get the Linux version of GDrive to stop crashing (I'm sure it is me - so I've not posted), this will work as a machine I can use to run automated backups.  Basically, I setup a SMB share of files I want copied - then I use that to distribute the appropriate files to the appropriate Google Drive for long term retention.  Seems to be working so far!\n. @alexjj thanks for the advice!  It is not a matter of BUYING or being limited, but why waste 16GB of ram on a machine that's sole purpose is to copy stuff to Google Drive?  As for buying, it was not that either, just a matter of resources.  If I could get away with it, I'd use DOS or if I had the time/patience I'd use SLACKWARE...they use next to NOTHING for resources!\nI use ESXi, so resource sharing is not really an issue.  I typically see DSL only using 29MB or ram, so ESXi will reclaim the rest of the 256MB for other machines to use.  I'm not worried!\nI already have a RPI. It controls the Zwave stuff in my house - which reports to a Win7 VM that runs my home automation (www.homeseer.com)! \nAnyway, thanks for the link, I'll check that out.\n. ",
    "1v": "Same.\nUbuntu 14.04.2 LTS\n. PING accounts.google.com (216.58.213.237) 56(84) bytes of data.\n64 bytes from ham04s01-in-f13.1e100.net (216.58.213.237): icmp_seq=1 ttl=52 time=21.3 ms\n. Same.\nUbuntu 14.04.2 LTS\n. PING accounts.google.com (216.58.213.237) 56(84) bytes of data.\n64 bytes from ham04s01-in-f13.1e100.net (216.58.213.237): icmp_seq=1 ttl=52 time=21.3 ms\n. ",
    "mikkeloscar": "Any chance you could point me to a discussion of this bug in 1.5? I can only find a somewhat related bug golang/go#11307 but it has been fixed and is only related to importing local internal packages, which does work in 1.5.\n. I don't know if there is any advantage, but since v1.5 is the current stable release of golang I think it makes sense to keep gdrive (or anything else) up to date.\nI don't know if my suggested solution is the right way to fix it, that's why I haven't made a PR.\n. I see the same issue:\n$ go get\npackage .\n    imports github.com/prasmussen/gdrive/cli\n    imports github.com/prasmussen/gdrive/gdrive\n    imports github.com/prasmussen/gdrive/auth\n    imports github.com/prasmussen/gdrive/util\n    imports github.com/prasmussen/google-api-go-client/drive/v2\n    imports github.com/prasmussen/google-api-go-client/googleapi\n    imports google.golang.org/api/googleapi/internal/uritemplates: use of internal package not allowed\n$ go version\ngo version go1.5.2 linux/amd64\n. @avinash- have you tried to change the line as described in my original post? That should still fix the problem.\n. @avinash- \nIt looks like you need to change this file: /home/ventanni/Avinash/gdrive/src/github.com/prasmussen/google-api-go-client/googleapi/googleapi.go assuming /home/ventanni/Avinash/gdrive is your $GOPATH.\nThis is the changes you need to make:\n``` diff\ndiff --git a/googleapi/googleapi.go b/googleapi/googleapi.go\nindex c4d0b93..58077a0 100644\n--- a/googleapi/googleapi.go\n+++ b/googleapi/googleapi.go\n@@ -23,8 +23,8 @@ import (\n    \"sync\"\n    \"time\"\n\n\"github.com/prasmussen/google-api-go-client/googleapi/internal/uritemplates\"\n    \"golang.org/x/net/context\"\n\"google.golang.org/api/googleapi/internal/uritemplates\"\n )\n\n// ContentTyper is an interface for Readers which know (or would like\n``\n. @avinash- the binary is right there. It's the one calleddrive. You can run it with./drive` or copy it like you suggest.\n. It was fixed here: prasmussen/google-api-go-client#1\n. Any chance you could point me to a discussion of this bug in 1.5? I can only find a somewhat related bug golang/go#11307 but it has been fixed and is only related to importing local internal packages, which does work in 1.5.\n. I don't know if there is any advantage, but since v1.5 is the current stable release of golang I think it makes sense to keep gdrive (or anything else) up to date.\nI don't know if my suggested solution is the right way to fix it, that's why I haven't made a PR.\n. I see the same issue:\n$ go get\npackage .\n    imports github.com/prasmussen/gdrive/cli\n    imports github.com/prasmussen/gdrive/gdrive\n    imports github.com/prasmussen/gdrive/auth\n    imports github.com/prasmussen/gdrive/util\n    imports github.com/prasmussen/google-api-go-client/drive/v2\n    imports github.com/prasmussen/google-api-go-client/googleapi\n    imports google.golang.org/api/googleapi/internal/uritemplates: use of internal package not allowed\n$ go version\ngo version go1.5.2 linux/amd64\n. @avinash- have you tried to change the line as described in my original post? That should still fix the problem.\n. @avinash- \nIt looks like you need to change this file: /home/ventanni/Avinash/gdrive/src/github.com/prasmussen/google-api-go-client/googleapi/googleapi.go assuming /home/ventanni/Avinash/gdrive is your $GOPATH.\nThis is the changes you need to make:\n``` diff\ndiff --git a/googleapi/googleapi.go b/googleapi/googleapi.go\nindex c4d0b93..58077a0 100644\n--- a/googleapi/googleapi.go\n+++ b/googleapi/googleapi.go\n@@ -23,8 +23,8 @@ import (\n    \"sync\"\n    \"time\"\n\n\"github.com/prasmussen/google-api-go-client/googleapi/internal/uritemplates\"\n    \"golang.org/x/net/context\"\n\"google.golang.org/api/googleapi/internal/uritemplates\"\n )\n\n// ContentTyper is an interface for Readers which know (or would like\n``\n. @avinash- the binary is right there. It's the one calleddrive. You can run it with./drive` or copy it like you suggest.\n. It was fixed here: prasmussen/google-api-go-client#1\n. ",
    "kevin-cantwell": "You might want to give 1.5.2 a test drive. It appears to not have this bug.\n. You might want to give 1.5.2 a test drive. It appears to not have this bug.\n. ",
    "ksimka": "Exactly the same issue with 1.5.2\n. Exactly the same issue with 1.5.2\n. ",
    "labkode": "@Drezzler  for me the big advantage of 1.5* is the vendor experiment support\n. @Drezzler  for me the big advantage of 1.5* is the vendor experiment support\n. ",
    "avinashtanniru": "Same issue with go version 1.5.3\npackage github.com/prasmussen/gdrive/cli\n    imports github.com/prasmussen/gdrive/gdrive\n    imports github.com/prasmussen/gdrive/auth\n    imports github.com/prasmussen/gdrive/util\n    imports github.com/prasmussen/google-api-go-client/drive/v2\n    imports github.com/prasmussen/google-api-go-client/googleapi\n    imports google.golang.org/api/googleapi/internal/uritemplates: use of internal package not allowed\n[ventanni@oc0283078624 gdrive]$ go version\ngo version go1.5.3 linux/amd64\n@mikkeloscar Can you help me in solving this.\n. @mikkeloscar I can't change the main file because I need write access. \nPlz guide me how to change in which file I need to change ?\nThanks for Replying @mikkeloscar :)\n[ventanni@oc0283078624 gdrive]$ go build drive.go \ndrive.go:5:2: cannot find package \"github.com/prasmussen/gdrive/cli\" in any of:\n    /usr/local/go/src/github.com/prasmussen/gdrive/cli (from $GOROOT)\n    /home/ventanni/Avinash/gdrive/src/github.com/prasmussen/gdrive/cli (from $GOPATH)\ndrive.go:6:2: cannot find package \"github.com/prasmussen/gdrive/gdrive\" in any of:\n    /usr/local/go/src/github.com/prasmussen/gdrive/gdrive (from $GOROOT)\n    /home/ventanni/Avinash/gdrive/src/github.com/prasmussen/gdrive/gdrive (from $GOPATH)\ndrive.go:7:2: cannot find package \"github.com/prasmussen/gdrive/util\" in any of:\n    /usr/local/go/src/github.com/prasmussen/gdrive/util (from $GOROOT)\n    /home/ventanni/Avinash/gdrive/src/github.com/prasmussen/gdrive/util (from $GOPATH)\ndrive.go:8:2: cannot find package \"github.com/prasmussen/google-api-go-client/googleapi\" in any of:\n    /usr/local/go/src/github.com/prasmussen/google-api-go-client/googleapi (from $GOROOT)\n    /home/ventanni/Avinash/gdrive/src/github.com/prasmussen/google-api-go-client/googleapi (from $GOPATH)\ndrive.go:9:2: cannot find package \"github.com/prasmussen/google-api-go-client/googleapi/internal/uritemplates\" in any of:\n    /usr/local/go/src/github.com/prasmussen/google-api-go-client/googleapi/internal/uritemplates (from $GOROOT)\n    /home/ventanni/Avinash/gdrive/src/github.com/prasmussen/google-api-go-client/googleapi/internal/uritemplates (from $GOPATH)\ndrive.go:10:2: cannot find package \"github.com/voxelbrain/goptions\" in any of:\n    /usr/local/go/src/github.com/voxelbrain/goptions (from $GOROOT)\n    /home/ventanni/Avinash/gdrive/src/github.com/voxelbrain/goptions (from $GOPATH)\n[ventanni@oc0283078624 gdrive]$ ld\nld: no input files\n[ventanni@oc0283078624 gdrive]$ ls\nauth  cli  config  drive.go  gdrive  LICENSE  README.md  _release  util\n[ventanni@oc0283078624 gdrive]$ go get github.com/prasmussen/gdrive\nwarning: code.google.com is shutting down; import path code.google.com/p/goauth2/oauth will stop working\npackage github.com/prasmussen/gdrive\n    imports github.com/prasmussen/gdrive/cli\n    imports github.com/prasmussen/gdrive/gdrive\n    imports github.com/prasmussen/gdrive/auth\n    imports github.com/prasmussen/gdrive/util\n    imports github.com/prasmussen/google-api-go-client/drive/v2\n    imports github.com/prasmussen/google-api-go-client/googleapi\n    imports google.golang.org/api/googleapi/internal/uritemplates: use of internal package not allowed\n. @mikkeloscar Thanks Yor are Super you made my day. :+1: \n[ventanni@oc0283078624 gdrive]$ go build drive.go \n[ventanni@oc0283078624 gdrive]$ drive list \nCommand not found. \nI think I need  to replace 'drive' binary generated and place it in '/usr/local/bin' , make the binary executable with 'chmod +x drive'\nI think they are in \"/home/ventanni/Avinash/gdrive/src\"\n. @mikkeloscar Help me in configuring Binaries \nWhere are the compiled binary located to place in \"/usr/local/bin\"\n[ventanni@oc0283078624 gdrive]$ ls\nauth  cli  config  drive  drive.go  gdrive  LICENSE  pkg  README.md  _release  src  util\n[ventanni@oc0283078624 gdrive]$ go build drive.go \n[ventanni@oc0283078624 gdrive]$ ls\nauth  cli  config  drive  drive.go  gdrive  LICENSE  pkg  README.md  _release  src  util\n[ventanni@oc0283078624 gdrive]$ drive list\nCommand not found. \n. @mikkeloscar Thanks Again it Worked \nHow han we reset API, I need to switch google drive account with new gmail ID ?\n[ventanni@oc0283078624 gdrive]$ drive list\ngoogleapi: Error 401: Invalid Credentials, authError\n. Same issue with go version 1.5.3\npackage github.com/prasmussen/gdrive/cli\n    imports github.com/prasmussen/gdrive/gdrive\n    imports github.com/prasmussen/gdrive/auth\n    imports github.com/prasmussen/gdrive/util\n    imports github.com/prasmussen/google-api-go-client/drive/v2\n    imports github.com/prasmussen/google-api-go-client/googleapi\n    imports google.golang.org/api/googleapi/internal/uritemplates: use of internal package not allowed\n[ventanni@oc0283078624 gdrive]$ go version\ngo version go1.5.3 linux/amd64\n@mikkeloscar Can you help me in solving this.\n. @mikkeloscar I can't change the main file because I need write access. \nPlz guide me how to change in which file I need to change ?\nThanks for Replying @mikkeloscar :)\n[ventanni@oc0283078624 gdrive]$ go build drive.go \ndrive.go:5:2: cannot find package \"github.com/prasmussen/gdrive/cli\" in any of:\n    /usr/local/go/src/github.com/prasmussen/gdrive/cli (from $GOROOT)\n    /home/ventanni/Avinash/gdrive/src/github.com/prasmussen/gdrive/cli (from $GOPATH)\ndrive.go:6:2: cannot find package \"github.com/prasmussen/gdrive/gdrive\" in any of:\n    /usr/local/go/src/github.com/prasmussen/gdrive/gdrive (from $GOROOT)\n    /home/ventanni/Avinash/gdrive/src/github.com/prasmussen/gdrive/gdrive (from $GOPATH)\ndrive.go:7:2: cannot find package \"github.com/prasmussen/gdrive/util\" in any of:\n    /usr/local/go/src/github.com/prasmussen/gdrive/util (from $GOROOT)\n    /home/ventanni/Avinash/gdrive/src/github.com/prasmussen/gdrive/util (from $GOPATH)\ndrive.go:8:2: cannot find package \"github.com/prasmussen/google-api-go-client/googleapi\" in any of:\n    /usr/local/go/src/github.com/prasmussen/google-api-go-client/googleapi (from $GOROOT)\n    /home/ventanni/Avinash/gdrive/src/github.com/prasmussen/google-api-go-client/googleapi (from $GOPATH)\ndrive.go:9:2: cannot find package \"github.com/prasmussen/google-api-go-client/googleapi/internal/uritemplates\" in any of:\n    /usr/local/go/src/github.com/prasmussen/google-api-go-client/googleapi/internal/uritemplates (from $GOROOT)\n    /home/ventanni/Avinash/gdrive/src/github.com/prasmussen/google-api-go-client/googleapi/internal/uritemplates (from $GOPATH)\ndrive.go:10:2: cannot find package \"github.com/voxelbrain/goptions\" in any of:\n    /usr/local/go/src/github.com/voxelbrain/goptions (from $GOROOT)\n    /home/ventanni/Avinash/gdrive/src/github.com/voxelbrain/goptions (from $GOPATH)\n[ventanni@oc0283078624 gdrive]$ ld\nld: no input files\n[ventanni@oc0283078624 gdrive]$ ls\nauth  cli  config  drive.go  gdrive  LICENSE  README.md  _release  util\n[ventanni@oc0283078624 gdrive]$ go get github.com/prasmussen/gdrive\nwarning: code.google.com is shutting down; import path code.google.com/p/goauth2/oauth will stop working\npackage github.com/prasmussen/gdrive\n    imports github.com/prasmussen/gdrive/cli\n    imports github.com/prasmussen/gdrive/gdrive\n    imports github.com/prasmussen/gdrive/auth\n    imports github.com/prasmussen/gdrive/util\n    imports github.com/prasmussen/google-api-go-client/drive/v2\n    imports github.com/prasmussen/google-api-go-client/googleapi\n    imports google.golang.org/api/googleapi/internal/uritemplates: use of internal package not allowed\n. @mikkeloscar Thanks Yor are Super you made my day. :+1: \n[ventanni@oc0283078624 gdrive]$ go build drive.go \n[ventanni@oc0283078624 gdrive]$ drive list \nCommand not found. \nI think I need  to replace 'drive' binary generated and place it in '/usr/local/bin' , make the binary executable with 'chmod +x drive'\nI think they are in \"/home/ventanni/Avinash/gdrive/src\"\n. @mikkeloscar Help me in configuring Binaries \nWhere are the compiled binary located to place in \"/usr/local/bin\"\n[ventanni@oc0283078624 gdrive]$ ls\nauth  cli  config  drive  drive.go  gdrive  LICENSE  pkg  README.md  _release  src  util\n[ventanni@oc0283078624 gdrive]$ go build drive.go \n[ventanni@oc0283078624 gdrive]$ ls\nauth  cli  config  drive  drive.go  gdrive  LICENSE  pkg  README.md  _release  src  util\n[ventanni@oc0283078624 gdrive]$ drive list\nCommand not found. \n. @mikkeloscar Thanks Again it Worked \nHow han we reset API, I need to switch google drive account with new gmail ID ?\n[ventanni@oc0283078624 gdrive]$ drive list\ngoogleapi: Error 401: Invalid Credentials, authError\n. ",
    "kmand": "I also would find this valuable!\n. Thanks, with an increased block size I can get the same upload speed as the browser gets.\n. I've gotten this too, is there a workaround?. I also would find this valuable!\n. Thanks, with an increased block size I can get the same upload speed as the browser gets.\n. I've gotten this too, is there a workaround?. ",
    "sloth77": "If you are in a position to build yourself, you can add a simple progress output yourself by chaining a googleapi.ProgressUpdater function of your own to the FilesInsertCall call chain.  Basically, I added a function:\n\nfunc progCb(current, total int64) {\n    fmt.Printf(\"Progress: %.2f%%, %d/%d bytes                     \\r\", \n               float64(current)/float64(total))*100.0,current,total)\n}\n\nto gdrive\\cli\\cli.go\nand then referenced it in the uploadFile call:\ninfo, err := d.Files.Insert(f).Convert(convert).\n                ResumableMedia(context.Background(), input, inputInfo.Size(), mimeType).\n                ProgressUpdater(progCb).Do()\nBy the way - I should add that whilst I'm a programmer, I know zilch about Go and this is a complete hack.  It worked for me, but if it deletes all your files, don't blame me :-)\n. Hi @combucha.  File is listed below.  Had to rename it to get past the filter.  \ncli.go.txt\nI also have a prebuilt Windows binary if you need....\nOne thing I found is that you need to use Go <=1.4.2 or you get compilation errors with the Google API stuff.  That might have been what you were hitting.  Also, note I only implemented the progress indicator for uploads as that was all I needed and the download API seems different.\n. Yeah, I didn't need download so I never bothered.  Also, its a different API, so the same ProgressUpdater hook wont work.  Probably one for the maintainer.....\n. Thanks Drezzler - good to know its not just me :-)\nI might try splitting up the files into smaller chunks and see if that helps.\n. If you are in a position to build yourself, you can add a simple progress output yourself by chaining a googleapi.ProgressUpdater function of your own to the FilesInsertCall call chain.  Basically, I added a function:\n\nfunc progCb(current, total int64) {\n    fmt.Printf(\"Progress: %.2f%%, %d/%d bytes                     \\r\", \n               float64(current)/float64(total))*100.0,current,total)\n}\n\nto gdrive\\cli\\cli.go\nand then referenced it in the uploadFile call:\ninfo, err := d.Files.Insert(f).Convert(convert).\n                ResumableMedia(context.Background(), input, inputInfo.Size(), mimeType).\n                ProgressUpdater(progCb).Do()\nBy the way - I should add that whilst I'm a programmer, I know zilch about Go and this is a complete hack.  It worked for me, but if it deletes all your files, don't blame me :-)\n. Hi @combucha.  File is listed below.  Had to rename it to get past the filter.  \ncli.go.txt\nI also have a prebuilt Windows binary if you need....\nOne thing I found is that you need to use Go <=1.4.2 or you get compilation errors with the Google API stuff.  That might have been what you were hitting.  Also, note I only implemented the progress indicator for uploads as that was all I needed and the download API seems different.\n. Yeah, I didn't need download so I never bothered.  Also, its a different API, so the same ProgressUpdater hook wont work.  Probably one for the maintainer.....\n. Thanks Drezzler - good to know its not just me :-)\nI might try splitting up the files into smaller chunks and see if that helps.\n. ",
    "user501254": "@prasmussen this would be great. Progress indicators for downloads and uploads are an absolute necessity when using the command in external scripts. The blinking cursor looks really poor. \n@sloth77, maybe you could generate a pull request to help.\n. @prasmussen this would be great. Progress indicators for downloads and uploads are an absolute necessity when using the command in external scripts. The blinking cursor looks really poor. \n@sloth77, maybe you could generate a pull request to help.\n. ",
    "combucha": "@sloth77 this can't work, code has syntax error: cli.go: unexpected ), expecting := or = or comma\nI fixed it, but my new build goes without visible progress info, just like old one...\nCould you paste your whole cli.go somewhere?\nMaybe it's my system fault, xp :\\\n. Thanks @sloth77 \nWorking :-) It worked before too, I was just impatient, on my console progress monitor appears 30 seconds after upload start and is refreshed the same period also.\nWhat about download part?\n. Quite interesting community here.\nEspecially gdrive author responses :)\nDunno why, but they are invisible.\n. Not in my case.\nI fixed capped speed by playing with system registry entries (TcpWindowSize and AFD buffers).\nSeems it's related with old systems only (xp and below),\nhttp://www.speedguide.net/forums/showthread.php?85875-TCP-IP-amp-AFD-Parameters\n. @sloth77 this can't work, code has syntax error: cli.go: unexpected ), expecting := or = or comma\nI fixed it, but my new build goes without visible progress info, just like old one...\nCould you paste your whole cli.go somewhere?\nMaybe it's my system fault, xp :\\\n. Thanks @sloth77 \nWorking :-) It worked before too, I was just impatient, on my console progress monitor appears 30 seconds after upload start and is refreshed the same period also.\nWhat about download part?\n. Quite interesting community here.\nEspecially gdrive author responses :)\nDunno why, but they are invisible.\n. Not in my case.\nI fixed capped speed by playing with system registry entries (TcpWindowSize and AFD buffers).\nSeems it's related with old systems only (xp and below),\nhttp://www.speedguide.net/forums/showthread.php?85875-TCP-IP-amp-AFD-Parameters\n. ",
    "alvarokid": "@sloth77 I've installed gdrive running \"cd && sudo install drive-linux* /usr/local/bin/drive\" from it's binnary and I couldn't find cli.go and the other files to include your function, where are they supposed to be?\n. @sloth77 I've installed gdrive running \"cd && sudo install drive-linux* /usr/local/bin/drive\" from it's binnary and I couldn't find cli.go and the other files to include your function, where are they supposed to be?\n. ",
    "Grauen": "progressbar for uploads would be a great benefit. I got to upload lots of files and it kinda feels wrong doing it without steady feedback :).\n. progressbar for uploads would be a great benefit. I got to upload lots of files and it kinda feels wrong doing it without steady feedback :).\n. ",
    "eddOrnelas": "How this can be done?\n. How this can be done?\n. ",
    "JuliArianes": "@prasmussen i have try gdrive -c foo list . then I tried command \"gdrive list\"  ==> the list is my old account ... how to change account???\n. @Drezzler How to switch different account?\n. i have same problem ... \n. @prasmussen please step by step. this https://github.com/prasmussen/gdrive/issues/84 not answerd\n. @prasmussen i have try gdrive -c foo list . then I tried command \"gdrive list\"  ==> the list is my old account ... how to change account???\n. @Drezzler How to switch different account?\n. i have same problem ... \n. @prasmussen please step by step. this https://github.com/prasmussen/gdrive/issues/84 not answerd\n. ",
    "thebaddie": "Same issue here\nUpload speed decreased from 25 MB/s to 20KB/s\n. Same issue here\nUpload speed decreased from 25 MB/s to 20KB/s\n. ",
    "iamxie": "Same issue +1\nUpload speed decreased from 20 MB/s to 1MB/s\n. Same issue +1\nUpload speed decreased from 20 MB/s to 1MB/s\n. ",
    "pozirk": "I'm using CentOS 6.7.\nI tried drive in command line under root with no problems.\nMy cron task looks like this:\n\n10 10 * * 1 root /home/backup.sh\n. Thank you for your help people!\nI have found the problem, but in my case it was a bit different.\nWhen I run drive myself, it creates token file in /root/.gdrive, but with cron task it creates file in /.gdrive.\nI just don't know, why it uses a different path.\n. I have tried to change config path to some other, and it was changed fine.\nBut when cron task runs drive it still uses config from /.gdrive.\nThis is not a big problem, just wonder why it is so.\n. I'm using CentOS 6.7.\nI tried drive in command line under root with no problems.\nMy cron task looks like this:\n10 10 * * 1 root /home/backup.sh\n. Thank you for your help people!\nI have found the problem, but in my case it was a bit different.\nWhen I run drive myself, it creates token file in /root/.gdrive, but with cron task it creates file in /.gdrive.\nI just don't know, why it uses a different path.\n. I have tried to change config path to some other, and it was changed fine.\nBut when cron task runs drive it still uses config from /.gdrive.\nThis is not a big problem, just wonder why it is so.\n. \n",
    "gneissone": "I experienced the same problem with a cron job, but setting the -c flag worked fine for me. Glad I found this discussion, it saved me a big headache.\n. I experienced the same problem with a cron job, but setting the -c flag worked fine for me. Glad I found this discussion, it saved me a big headache.\n. ",
    "piccinif": "What I have to set when I am accessing Google Drive behind a proxy server?\nHow to provide proxy infos (server, username, password) ?\nThanks a lot for your help.\nFrancesco\nOn Wed, Nov 25, 2015 at 1:15 PM, Drezzler notifications@github.com wrote:\n\nWhat problems are you facing ?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/prasmussen/gdrive/issues/95#issuecomment-159590904.\n. What I have to set when I am accessing Google Drive behind a proxy server?\n\nHow to provide proxy infos (server, username, password) ?\nThanks a lot for your help.\nFrancesco\nOn Wed, Nov 25, 2015 at 1:15 PM, Drezzler notifications@github.com wrote:\n\nWhat problems are you facing ?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/prasmussen/gdrive/issues/95#issuecomment-159590904.\n. \n",
    "blackmantram": "Is this planned for any future release? I'm also behind a proxy server in my company and I can't upload anything using gdrive. I'm using OSX El Capitan.\ngdrive sync upload apk xxxx_xxxxxxxxxxxxxxxxxxxxx\nStarting sync...\nFailed to find root dir: Get https://www.googleapis.com/drive/v3/files/xxxx_xxxxxxxxxxxxxxxxxxxxx?alt=json&fields=id%2Cname%2CmimeType%2CappProperties: Post https://accounts.google.com/o/oauth2/token: dial tcp 216.58.222.237:443: i/o timeout\nI tried to set proxy settings in System preferences > networ, export ALL_PROXY, HTTP_PROXY, HTTPS_PROXY and using the network setupo utility but neither of them worked.\n. Is this planned for any future release? I'm also behind a proxy server in my company and I can't upload anything using gdrive. I'm using OSX El Capitan.\ngdrive sync upload apk xxxx_xxxxxxxxxxxxxxxxxxxxx\nStarting sync...\nFailed to find root dir: Get https://www.googleapis.com/drive/v3/files/xxxx_xxxxxxxxxxxxxxxxxxxxx?alt=json&fields=id%2Cname%2CmimeType%2CappProperties: Post https://accounts.google.com/o/oauth2/token: dial tcp 216.58.222.237:443: i/o timeout\nI tried to set proxy settings in System preferences > networ, export ALL_PROXY, HTTP_PROXY, HTTPS_PROXY and using the network setupo utility but neither of them worked.\n. ",
    "ordimans": "You can use that on Terminal :\nhttp_proxy=http://proxy:3129 https_proxy=https://proxy:3129 gdrive about\nIt worked for me.\nBut on Windows i don't know..\n. You can use this with command line (IN OS X ) :\nhttp_proxy=http://proxy:3129 https_proxy=https://proxy:3129 gdrive about\n. Any idea ?. I change my command line with\ndrive --refresh-token AUTH_TOKEN \nIt seems to be OK, i will confirm in some days, if no problem encountered.. Work without problem since several month.\nIssues can be closed.\n. You can use that on Terminal :\nhttp_proxy=http://proxy:3129 https_proxy=https://proxy:3129 gdrive about\nIt worked for me.\nBut on Windows i don't know..\n. You can use this with command line (IN OS X ) :\nhttp_proxy=http://proxy:3129 https_proxy=https://proxy:3129 gdrive about\n. Any idea ?. I change my command line with\ndrive --refresh-token AUTH_TOKEN \nIt seems to be OK, i will confirm in some days, if no problem encountered.. Work without problem since several month.\nIssues can be closed.\n. ",
    "eduardo4jesus": "I am getting this error when doing:\ndrive pull -export pdf -no-prompt --fix-clashes\nBy the way, last time I tried to pull all my files, it said the clashes were fixed, but I would have to call it again. Is there a flag to automatically run it again in these case?\n. I am getting this error when doing:\ndrive pull -export pdf -no-prompt --fix-clashes\nBy the way, last time I tried to pull all my files, it said the clashes were fixed, but I would have to call it again. Is there a flag to automatically run it again in these case?\n. ",
    "jeprojects": "Using appfolder is a alias for the folder ID when working with the private app folder of your application within Google Drive.\nI tried also using the actual id and not an alias and still the same issue.\n\nE:\\gdrive>drive upload -p 1vTytrrj87u02xwomvWPFaKmcXXX -f test.db\nAn error occurred: googleapi: Error 403: Insufficient Permission, insufficientPermissions\nE:\\gdrive>drive list\nId                                              Title         Size     Created\n1_OFq0h3vZWXIi_BulqLdhkaN7NeJAUi-e19KoJ7PXXXX   test.db   4.3 KB   2016-02-05 23:10:25\n\nThe file gets uploaded, but you cant do an api call for info on the file, which I think this application is doing.\nCan you output the response of the upload api call, this should provide the id of the new file uploaded and allow the application to continuing uploading the next file?\n. No, it happens exactly like this:\n\nE:\\gdrive>drive upload -p 1vTytrrj87u02xwomvWPFaKmcXXX -f test.db\nAn error occurred: googleapi: Error 403: Insufficient Permission, insufficientPermissions\n\nWhen I try with permissions for the entire drive + appfolder, I get this error:\n\nAn error occurred: googleapi: Error 403: Method not supported for appdata contents, forbidden\n. Using appfolder is a alias for the folder ID when working with the private app folder of your application within Google Drive.\n\nI tried also using the actual id and not an alias and still the same issue.\n\nE:\\gdrive>drive upload -p 1vTytrrj87u02xwomvWPFaKmcXXX -f test.db\nAn error occurred: googleapi: Error 403: Insufficient Permission, insufficientPermissions\nE:\\gdrive>drive list\nId                                              Title         Size     Created\n1_OFq0h3vZWXIi_BulqLdhkaN7NeJAUi-e19KoJ7PXXXX   test.db   4.3 KB   2016-02-05 23:10:25\n\nThe file gets uploaded, but you cant do an api call for info on the file, which I think this application is doing.\nCan you output the response of the upload api call, this should provide the id of the new file uploaded and allow the application to continuing uploading the next file?\n. No, it happens exactly like this:\n\nE:\\gdrive>drive upload -p 1vTytrrj87u02xwomvWPFaKmcXXX -f test.db\nAn error occurred: googleapi: Error 403: Insufficient Permission, insufficientPermissions\n\nWhen I try with permissions for the entire drive + appfolder, I get this error:\n\nAn error occurred: googleapi: Error 403: Method not supported for appdata contents, forbidden\n. \n",
    "hillz1": "That's great, I'm looking forward to that. Can this be installed in openwrt ? I've only tried installing it in ubuntu 14.04 and I thought that it'd be good if it could also run on openwrt routers.\n. That's great, I'm looking forward to that. Can this be installed in openwrt ? I've only tried installing it in ubuntu 14.04 and I thought that it'd be good if it could also run on openwrt routers.\n. ",
    "disrupted": "\ngdrive 2.0 will have a progress indicator, and will probably be ready later this month.\n\n@prasmussen  great news, man! been waiting forever for this feature.\n. > gdrive 2.0 will have a progress indicator, and will probably be ready later this month.\n@prasmussen  great news, man! been waiting forever for this feature.\n. ",
    "7yl4r": "Progress bars are a great improvement, but a --verbose option could still be useful I think.\nI'm syncing a large folder (~350GB) right now though and it does seem to be hung at \"Collecting local and remote file information...\" \nupdate: started getting more feedback after ~30min. If someone is looking for how to reproduce this: \nFor me this error was caused by stopping the script (ctrl+c) twice in the middle of a large sync upload. I.e. start, wait for a few files to upload, stop, start, wait, stop, start. The third start is where I encountered this issue. Although I suspect it is a bit random doing this repeatedly might produce this error eventually.. duplicate of #132 . . Progress bars are a great improvement, but a --verbose option could still be useful I think.\nI'm syncing a large folder (~350GB) right now though and it does seem to be hung at \"Collecting local and remote file information...\" \nupdate: started getting more feedback after ~30min. If someone is looking for how to reproduce this: \nFor me this error was caused by stopping the script (ctrl+c) twice in the middle of a large sync upload. I.e. start, wait for a few files to upload, stop, start, wait, stop, start. The third start is where I encountered this issue. Although I suspect it is a bit random doing this repeatedly might produce this error eventually.. duplicate of #132 . . ",
    "assh0le1": "I understand that one can be used without --config, but sometimes I need to change accounts for the users and that's it then I run into this proble\nupd missclick\n. I understand that one can be used without --config, but sometimes I need to change accounts for the users and that's it then I run into this proble\nupd missclick\n. ",
    "amidia": "solved with /root/.gdrive thanks\nbut thereis another problem, my log does not work. i create time log before and after execute the command on the script by echoing time stamp to some file\nthis is my script\n=BOF=\nSTART=$(date +%s.%N)\nLOG=\"log/log.log\"\nVAR1= echo \"$(date +\"%Y-%m-%d:%H.%M.%S\") - Backup Start: $(basename $0)\" >> $LOG\nVAR2= /usr/sbin/drive --config /root/.gdrive/ upload --file /root/BU_HRMS_MODULES/$(date +\"%Y-%m-%d_\")*_modules.tar.gz -p 0B7vD11QYCxa7SlJSdjdFX3B1cWc\nVAR3= echo \"$(date +\"%Y-%m-%d:%H.%M.%S\") - Backup Finish: $(basename $0)\" >> $LOG \nVAR4= echo \"ExecTime: $(echo \"$(date +%s.%N) - $START\" | bc)secs\" >> $LOG\nVAR5= echo \"--------------------------------------------------------------------\" >> $LOG\n$($VAR1 && $VAR2 && $VAR3 && $VAR4 && $VAR5)\n=EOF=\nany suggestion?\n. solved with /root/.gdrive thanks\nbut thereis another problem, my log does not work. i create time log before and after execute the command on the script by echoing time stamp to some file\nthis is my script\n=BOF=\nSTART=$(date +%s.%N)\nLOG=\"log/log.log\"\nVAR1= echo \"$(date +\"%Y-%m-%d:%H.%M.%S\") - Backup Start: $(basename $0)\" >> $LOG\nVAR2= /usr/sbin/drive --config /root/.gdrive/ upload --file /root/BU_HRMS_MODULES/$(date +\"%Y-%m-%d_\")*_modules.tar.gz -p 0B7vD11QYCxa7SlJSdjdFX3B1cWc\nVAR3= echo \"$(date +\"%Y-%m-%d:%H.%M.%S\") - Backup Finish: $(basename $0)\" >> $LOG \nVAR4= echo \"ExecTime: $(echo \"$(date +%s.%N) - $START\" | bc)secs\" >> $LOG\nVAR5= echo \"--------------------------------------------------------------------\" >> $LOG\n$($VAR1 && $VAR2 && $VAR3 && $VAR4 && $VAR5)\n=EOF=\nany suggestion?\n. ",
    "carbm1": "I get the same results with gdrive 1.9.\nI have tried playing with the chunk size going all the way up to 16MB. It actually goes slower the more I mess with it.\nIt only happens on my Windows 7 (32 and 64) and Server 2008 R2.  It basically caps out at 600KB/s.  I have Windows 10 Pro and Server 2012 R2 boxes using the same binary (386 and 64) and the same config file and it uploads at 10MB/s.\n. It also works fine on Ubuntu.   I mounted an admin share and uploaded my file from the share at full 10MB/s speed.  So I know its not an i/o problem with the disk I'm trying to work from.\nIt has to be something to do with Windows 7 and 2008.  I tried with two different antivirus as well wondering if that might be the issue. Doesn't seem to matter.\n. I just installed an original Windows 7 Pro (no SP1) and I have the same results.  So it's not a Windows Update that broke this.\nWill attempt at another site later and see if its my network with Windows 7/2008 only. Ubuntu/2012 works fine on this network but I really want to provide as much feedback as possible.\n. Offsite Update: Can confirm that on a fresh install of Windows 7 Home Premium 64bit that the upload is still slow. I got around 400KB/s upload. Windows 10 Pro at same location upload is at 4.5MB/s.\nNot sure what the total upload bandwidth is but results speak for themselves.\n. Providing as much feedback as possible:\nA Windows 10 VM on a Windows 7 Host works fine as well.\n. As a continued follow up.\nWindows 8.1 Pro fresh install works fine as well.\nAnything else I can do to help narrow down the issue?\n. Went back through the old binaries to 1.6.0 and all of them do the same thing.\n. I get the same results with gdrive 1.9.\nI have tried playing with the chunk size going all the way up to 16MB. It actually goes slower the more I mess with it.\nIt only happens on my Windows 7 (32 and 64) and Server 2008 R2.  It basically caps out at 600KB/s.  I have Windows 10 Pro and Server 2012 R2 boxes using the same binary (386 and 64) and the same config file and it uploads at 10MB/s.\n. It also works fine on Ubuntu.   I mounted an admin share and uploaded my file from the share at full 10MB/s speed.  So I know its not an i/o problem with the disk I'm trying to work from.\nIt has to be something to do with Windows 7 and 2008.  I tried with two different antivirus as well wondering if that might be the issue. Doesn't seem to matter.\n. I just installed an original Windows 7 Pro (no SP1) and I have the same results.  So it's not a Windows Update that broke this.\nWill attempt at another site later and see if its my network with Windows 7/2008 only. Ubuntu/2012 works fine on this network but I really want to provide as much feedback as possible.\n. Offsite Update: Can confirm that on a fresh install of Windows 7 Home Premium 64bit that the upload is still slow. I got around 400KB/s upload. Windows 10 Pro at same location upload is at 4.5MB/s.\nNot sure what the total upload bandwidth is but results speak for themselves.\n. Providing as much feedback as possible:\nA Windows 10 VM on a Windows 7 Host works fine as well.\n. As a continued follow up.\nWindows 8.1 Pro fresh install works fine as well.\nAnything else I can do to help narrow down the issue?\n. Went back through the old binaries to 1.6.0 and all of them do the same thing.\n. ",
    "dingerkingh": "I have the same issue on server 2008 R2. Only mine was 300KB/sec tops. Setting the chunk size to --chunksize 104857600 made no improvement. \n. I have the same issue on server 2008 R2. Only mine was 300KB/sec tops. Setting the chunk size to --chunksize 104857600 made no improvement. \n. ",
    "mandrews": "+1 - also having this issue \n. +1 - also having this issue \n. ",
    "youngmip": "+1 \n. +1 \n. ",
    "ibetovski": "+1. Are there any actions takes on this issue? Besides this the gdrive CLI works great.. +1. Are there any actions takes on this issue? Besides this the gdrive CLI works great.. ",
    "wf9a5m75": "Please support this.\nI want to use like this : $ gdrive list <folderID>\n. I have known folder id. For automatic routine purpose (such as download files from specific folder, but I don't want to sync), known folder id is better solution.\n. Please support this.\nI want to use like this : $ gdrive list <folderID>\n. I have known folder id. For automatic routine purpose (such as download files from specific folder, but I don't want to sync), known folder id is better solution.\n. ",
    "kiemrong08": "Yes, it may be an awesome feature\n. Yes, it may be an awesome feature\n. ",
    "goyometeojorito": "you can list files from a folder with this:\n$gdrive list -q \"'<folderID>' in parents\"\n. you can list files from a folder with this:\n$gdrive list -q \"'<folderID>' in parents\"\n. ",
    "dimitri0us": "And how we will get the folder id without list? \n. And how we will get the folder id without list? \n. ",
    "bluemeda": "how to list root folder?\n. how to list root folder?\n. ",
    "JayBrown": "The official MIME list by Google seems to be this one: https://developers.google.com/drive/v3/web/integrate-open#open_and_convert_google_docs_in_your_app\nEDIT: I just saw that application/octet-stream isn't even listed in $ gdrive about import\nAny chance to add that? Google Drive does recognize setting this MIME type for an upload (see above), so that would be very useful.\n. So now I tried it manually in the browser, and that also results in MIME type application/octet-stream. I.e. the Google end of the equation is fine, and the problem is apparently with gdrive. Maybe gdrive defaults to text/plain when the user specifies the wrong MIME type, or none at all. (?)\n. Still not working in v2.1.0; closing for new issue.\n. Seems to be related: https://github.com/prasmussen/gdrive/issues/118\nTry uploading the csv manually in your browser & check the mime type. In my case, using a signature file, the mime type was correctly set to application/octet-stream, which means that gdrive seems to be the problem.\n. Only worked with go get github.com/prasmussen/gdrive\n. The official MIME list by Google seems to be this one: https://developers.google.com/drive/v3/web/integrate-open#open_and_convert_google_docs_in_your_app\nEDIT: I just saw that application/octet-stream isn't even listed in $ gdrive about import\nAny chance to add that? Google Drive does recognize setting this MIME type for an upload (see above), so that would be very useful.\n. So now I tried it manually in the browser, and that also results in MIME type application/octet-stream. I.e. the Google end of the equation is fine, and the problem is apparently with gdrive. Maybe gdrive defaults to text/plain when the user specifies the wrong MIME type, or none at all. (?)\n. Still not working in v2.1.0; closing for new issue.\n. Seems to be related: https://github.com/prasmussen/gdrive/issues/118\nTry uploading the csv manually in your browser & check the mime type. In my case, using a signature file, the mime type was correctly set to application/octet-stream, which means that gdrive seems to be the problem.\n. Only worked with go get github.com/prasmussen/gdrive\n. ",
    "app-git-hub": "So I installed golang and did go get github.com/prasmussen/gdrive\nBut I got this error\n```\nC:\\Users\\pc 4\\Desktop\\username\\bz>go get github.com/prasmussen/gdrive\ngithub.com/soniakeys/graph\nC:\\Projects\\Go\\src\\github.com\\soniakeys\\graph\\bits.go:71: constant 2858702130513\n53865 overflows big.Word\nC:\\Users\\pc 4\\Desktop\\username\\bz>\n```\nAnd no\n\ngdrive binary should now be available at $GOPATH/bin/gdrive\n\nCan anyone help?\nIs this because 32-bit computer?\n. @prasmussen \nThanks man, gdrive about solved the issue, I was confused because of the line The first time gdrive is launched, you will be prompted for a verification code in README.md\nI didn't need to compile or fetch changes from soniakeys - the binary worked just fine.\nI have proposed a small change in README, please take a look.\nThanks.\n. So I installed golang and did go get github.com/prasmussen/gdrive\nBut I got this error\n```\nC:\\Users\\pc 4\\Desktop\\username\\bz>go get github.com/prasmussen/gdrive\ngithub.com/soniakeys/graph\nC:\\Projects\\Go\\src\\github.com\\soniakeys\\graph\\bits.go:71: constant 2858702130513\n53865 overflows big.Word\nC:\\Users\\pc 4\\Desktop\\username\\bz>\n```\nAnd no\n\ngdrive binary should now be available at $GOPATH/bin/gdrive\n\nCan anyone help?\nIs this because 32-bit computer?\n. @prasmussen \nThanks man, gdrive about solved the issue, I was confused because of the line The first time gdrive is launched, you will be prompted for a verification code in README.md\nI didn't need to compile or fetch changes from soniakeys - the binary worked just fine.\nI have proposed a small change in README, please take a look.\nThanks.\n. ",
    "przemika": "if you are trying to run gdrive binary from github you have to run at first step gdrive about,\nthen you will see url auth.\n. if you are trying to run gdrive binary from github you have to run at first step gdrive about,\nthen you will see url auth.\n. ",
    "jbryanscott": "n.b. this is also problem with gdrive export ... but instead gdrive will fail after attempting to write the file to the erroneous path.\n$ gdrive export --force --mime \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\" 1ZdRRv<redacted>\nUnable to create new file 'test / file/ with / bad/name.docx': open test / file/ with / bad/name.docx: no such file or directory\n. n.b. this is also problem with gdrive export ... but instead gdrive will fail after attempting to write the file to the erroneous path.\n$ gdrive export --force --mime \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\" 1ZdRRv<redacted>\nUnable to create new file 'test / file/ with / bad/name.docx': open test / file/ with / bad/name.docx: no such file or directory\n. ",
    "liquid98": "this is the case with all the windows reserved characters: \n```\n< (less than)\n\n(greater than)\n: (colon)\n\" (double quote)\n/ (forward slash)\n\\ (backslash)\n| (vertical bar or pipe)\n? (question mark)\n* (asterisk)\n```\n. this is the case with all the windows reserved characters: \n\n```\n< (less than)\n\n(greater than)\n: (colon)\n\" (double quote)\n/ (forward slash)\n\\ (backslash)\n| (vertical bar or pipe)\n? (question mark)\n* (asterisk)\n```\n. \n",
    "khoazero123": "Just remove file \"token_v2.json\":\nrm /root/.gdrive/token_v2.json\nand gdrive list to switch different an account\n. Just remove file \"token_v2.json\":\nrm /root/.gdrive/token_v2.json\nand gdrive list to switch different an account\n. ",
    "andyferra": "+1\n. +1\n. ",
    "soniakeys": "The graph library is changed hopefully to support arm but I have no way to test it.  Confirmation that it works for arm would be much appreciated.\n. The graph library is changed hopefully to support arm but I have no way to test it.  Confirmation that it works for arm would be much appreciated.\n. ",
    "dgriffie": "Relevant code is in drive/share.go, need to set the TransferOwnership flag on the PermissionsCall for 'owner' to work. Was trying to do the same thing myself (transfer ownership recursively)\n\nfunc (self *Drive) Share(args ShareArgs) error {                                                                                                     \n    permission := &drive.Permission{                                                                                                                 \n        AllowFileDiscovery: args.Discoverable,                                                                                                       \n        Role:               args.Role,                                                                                                               \n        Type:               args.Type,                                                                                                               \n        EmailAddress:       args.Email,                                                                                                              \n    }\n\n    call := self.service.Permissions.Create(args.FileId, permission)                                                                                 \n    if permission.Role == \"owner\" {                                                                                                                  \n        call.TransferOwnership(true)                                                                                                                 \n    }                                                                                                                                                \n\n    _, err := call.Do()                                                                                                                              \n    if err != nil {                                                                                                                                  \n        return fmt.Errorf(\"Failed to share file: %s\", err)                                                                                           \n    }                                                                                                                                                \n\n    fmt.Fprintf(args.Out, \"Granted %s permission to %s\\n\", args.Role, args.Type)                                                                     \n    return nil                                                                                                                                       \n} \n\n. Relevant code is in drive/share.go, need to set the TransferOwnership flag on the PermissionsCall for 'owner' to work. Was trying to do the same thing myself (transfer ownership recursively)\n\nfunc (self *Drive) Share(args ShareArgs) error {                                                                                                     \n    permission := &drive.Permission{                                                                                                                 \n        AllowFileDiscovery: args.Discoverable,                                                                                                       \n        Role:               args.Role,                                                                                                               \n        Type:               args.Type,                                                                                                               \n        EmailAddress:       args.Email,                                                                                                              \n    }\n\n    call := self.service.Permissions.Create(args.FileId, permission)                                                                                 \n    if permission.Role == \"owner\" {                                                                                                                  \n        call.TransferOwnership(true)                                                                                                                 \n    }                                                                                                                                                \n\n    _, err := call.Do()                                                                                                                              \n    if err != nil {                                                                                                                                  \n        return fmt.Errorf(\"Failed to share file: %s\", err)                                                                                           \n    }                                                                                                                                                \n\n    fmt.Fprintf(args.Out, \"Granted %s permission to %s\\n\", args.Role, args.Type)                                                                     \n    return nil                                                                                                                                       \n} \n\n. ",
    "gangofnuns": "Sure Peter -- thanks for the note.\nThe mime type of an apk file (Android app) is:  application/vnd.android.package-archive\nWhen the sync is performed, it shows up as:  application/zip\n(which is technically correct since the file is an archive - but not what Android expects). \nWorkaround is to set the mime type explicitly, so not a huge issue.\nCheers -- \n. Sure Peter -- thanks for the note.\nThe mime type of an apk file (Android app) is:  application/vnd.android.package-archive\nWhen the sync is performed, it shows up as:  application/zip\n(which is technically correct since the file is an archive - but not what Android expects). \nWorkaround is to set the mime type explicitly, so not a huge issue.\nCheers -- \n. ",
    "bspatter": "Bump. Bump. ",
    "AlessandroChecco": "This would be extremely useful!. This would be extremely useful!. ",
    "MInner": "yes. yes. ",
    "femee24": "Hi thank you. I had tried to resolve it by comparing the scenario between my mac and my linux. if i upload  a file on my linux, the file would only be available on google docs but if i upload it using my mac i can open this file on google apps available.\nbut the options \"--mime\" doesn't work for spreadsheet it only forces the file to be its original mime\nanyway I made an alternatives to this issue. thank you so much \n. Hi thank you. I had tried to resolve it by comparing the scenario between my mac and my linux. if i upload  a file on my linux, the file would only be available on google docs but if i upload it using my mac i can open this file on google apps available.\nbut the options \"--mime\" doesn't work for spreadsheet it only forces the file to be its original mime\nanyway I made an alternatives to this issue. thank you so much \n. ",
    "robertthiemann": "Hi, i'm having almost the same issue. I synced a rather large folder with recursion and all went fine, but when i wanted to do another sync of the same folder i encountered name collisions. I checked the google drive and found there were files there with identical names but different file id. Could they have been synced twice?\n. Hi Petter,\nI'm using sync upload. Somehow during the first upload, two files with the same name but different id's got created on the google drive.\n. @prasmussen let me know if you need any logs of screenshots or something. I like this software a lot but at the moment i cant sync with it. Let me know if i can help fix this ok?\n. Hi, i'm having almost the same issue. I synced a rather large folder with recursion and all went fine, but when i wanted to do another sync of the same folder i encountered name collisions. I checked the google drive and found there were files there with identical names but different file id. Could they have been synced twice?\n. Hi Petter,\nI'm using sync upload. Somehow during the first upload, two files with the same name but different id's got created on the google drive.\n. @prasmussen let me know if you need any logs of screenshots or something. I like this software a lot but at the moment i cant sync with it. Let me know if i can help fix this ok?\n. ",
    "alonebfg": "I am having this issue\nCollecting local and remote file information...\nFound name collision between 0Bxjv_mh2V96OTm1wdl9EU1ZjckU and 0Bxjv_mh2V96OaGNoSDJTRGV4akU\nand here is command im using gdrive -c /home/alonebfg/.gdrive/ sync upload --keep-local --timeout 300 /home/alonebfg 0Bxjv_mh2V96OcG41TGRBaG5TRTg\nhere is file info \nlooking at the file info both file are in same location sam md5 and also tring to upload the same file.\n. I am having this issue\nCollecting local and remote file information...\nFound name collision between 0Bxjv_mh2V96OTm1wdl9EU1ZjckU and 0Bxjv_mh2V96OaGNoSDJTRGV4akU\nand here is command im using gdrive -c /home/alonebfg/.gdrive/ sync upload --keep-local --timeout 300 /home/alonebfg 0Bxjv_mh2V96OcG41TGRBaG5TRTg\nhere is file info \nlooking at the file info both file are in same location sam md5 and also tring to upload the same file.\n. ",
    "pdelteil": "Hello there,\nI'm having the same issue.  While doing 'sync upload' the process stops and then when retrying I receive the error: \nFound name collision between X and Y \nDoing 'gdrive info X' and 'gdrive info Y' the files have the same name, path and m5sum. \nUsing --keep-local does not make any difference. \nAny updates on this? \n. After a lot of issues with gdrive ended up using 'syncdocs'. It's slow but it's 100% accurate. \n. Hello there,\nI'm having the same issue.  While doing 'sync upload' the process stops and then when retrying I receive the error: \nFound name collision between X and Y \nDoing 'gdrive info X' and 'gdrive info Y' the files have the same name, path and m5sum. \nUsing --keep-local does not make any difference. \nAny updates on this? \n. After a lot of issues with gdrive ended up using 'syncdocs'. It's slow but it's 100% accurate. \n. ",
    "MDXDave": "Same issue here.\n. Moved to rclone. Same issue here.\n. Moved to rclone. ",
    "petercoxphoto": "Same issue here. Would love a resolution to this. --keep-local or --keep-remote doesn't help.\n/usr/local/bin/gdrive2 sync upload --keep-local dirname 0B4p_knkv9C1UWHZfYTYxV3h1TWc\nStarting sync...\nCollecting local and remote file information...\nFound name collision between 0B4p_knkv9C1UMXJsNzlDQ2swdXM and 0B4p_knkv9C1USzd4Y3N4bHkyUjQ\n. Same issue here. Would love a resolution to this. --keep-local or --keep-remote doesn't help.\n/usr/local/bin/gdrive2 sync upload --keep-local dirname 0B4p_knkv9C1UWHZfYTYxV3h1TWc\nStarting sync...\nCollecting local and remote file information...\nFound name collision between 0B4p_knkv9C1UMXJsNzlDQ2swdXM and 0B4p_knkv9C1USzd4Y3N4bHkyUjQ\n. ",
    "proligde": "Same here: providing --keep-local didn't help. I just did a sync upload that went on for some hours. Then the connection was interrupted. When I restarted (without changing any files on both local or online) the \"Collecting local and remote file information...\" process is interrupted after some seconds with \"Found name collision between x and y\" I'd really love to get that back to work: The directory is too big to sync it again all the time if something fails.\n. I've got some additional info that might(?) help debugging this issue. I've came across this problem several times now. The setup is quite basic:\n- initial sync upload to a fresh and empty target on google drive\n- The sync runs for quite some hours without problem\n- Then the sync suddenly hangs without any error message, without network traffic and without exiting. I cancelled the sync manually.\n- After trying to recover just by entering the same sync command again the last file (where it stopped) is on gdrive twice with the same name producing that name collission.\n- Deleting one of the files (you have to delete and remove it from trash as well) fixes the issue:\nHere is my shell output where it hung\n[0801/23191] Uploading Fotografie/2014/2014-06-07/IMG_0838.CR2 -> photo/Fotografie/2014/2014-06-07/IMG_0838.CR2\n[0802/23191] Uploading Fotografie/2014/2014-06-07/IMG_0839.CR2 -> photo/Fotografie/2014/2014-06-07/IMG_0839.CR2\n[0803/23191] Uploading Fotografie/2014/2014-06-07/IMG_0840.CR2 -> photo/Fotografie/2014/2014-06-07/IMG_0840.CR2\n[0804/23191] Uploading Fotografie/2014/2014-06-07/IMG_0841.CR2 -> photo/Fotografie/2014/2014-06-07/IMG_0841.CR2\n[0805/23191] Uploading Fotografie/2014/2014-06-07/IMG_0842.CR2 -> photo/Fotografie/2014/2014-06-07/IMG_0842.CR2\ntrying to recover shows:\nStarting sync...\nCollecting local and remote file information...\nFound name collision between 0B1JkX4q8SB67NG9odmtsMjdvdVE and 0B1JkX4q8SB67dHRFYWdxQjRYS0E\ncompletey deleting one of the two files (IMG_0842.CR2) fixes that:\n`Starting sync...\nCollecting local and remote file information...\nFound 39595 local files and 17209 remote files\n22386 remote files are missing\n[0001/22386] Uploading Fotografie/2014/2014-06-07/IMG_0843.CR2 -> photo/Fotografie/2014/2014-06-07/IMG_0843.CR2`\n[...]\n. @ALiangLiang the problem is that gdrive itself creates these two files having different IDs but the same name. If this bug gets fixed there wouldn't be a name collision/conflict in the first place. I'd try to fix it but I'm not into go (yet).\n. Same here: providing --keep-local didn't help. I just did a sync upload that went on for some hours. Then the connection was interrupted. When I restarted (without changing any files on both local or online) the \"Collecting local and remote file information...\" process is interrupted after some seconds with \"Found name collision between x and y\" I'd really love to get that back to work: The directory is too big to sync it again all the time if something fails.\n. I've got some additional info that might(?) help debugging this issue. I've came across this problem several times now. The setup is quite basic:\n- initial sync upload to a fresh and empty target on google drive\n- The sync runs for quite some hours without problem\n- Then the sync suddenly hangs without any error message, without network traffic and without exiting. I cancelled the sync manually.\n- After trying to recover just by entering the same sync command again the last file (where it stopped) is on gdrive twice with the same name producing that name collission.\n- Deleting one of the files (you have to delete and remove it from trash as well) fixes the issue:\nHere is my shell output where it hung\n[0801/23191] Uploading Fotografie/2014/2014-06-07/IMG_0838.CR2 -> photo/Fotografie/2014/2014-06-07/IMG_0838.CR2\n[0802/23191] Uploading Fotografie/2014/2014-06-07/IMG_0839.CR2 -> photo/Fotografie/2014/2014-06-07/IMG_0839.CR2\n[0803/23191] Uploading Fotografie/2014/2014-06-07/IMG_0840.CR2 -> photo/Fotografie/2014/2014-06-07/IMG_0840.CR2\n[0804/23191] Uploading Fotografie/2014/2014-06-07/IMG_0841.CR2 -> photo/Fotografie/2014/2014-06-07/IMG_0841.CR2\n[0805/23191] Uploading Fotografie/2014/2014-06-07/IMG_0842.CR2 -> photo/Fotografie/2014/2014-06-07/IMG_0842.CR2\ntrying to recover shows:\nStarting sync...\nCollecting local and remote file information...\nFound name collision between 0B1JkX4q8SB67NG9odmtsMjdvdVE and 0B1JkX4q8SB67dHRFYWdxQjRYS0E\ncompletey deleting one of the two files (IMG_0842.CR2) fixes that:\n`Starting sync...\nCollecting local and remote file information...\nFound 39595 local files and 17209 remote files\n22386 remote files are missing\n[0001/22386] Uploading Fotografie/2014/2014-06-07/IMG_0843.CR2 -> photo/Fotografie/2014/2014-06-07/IMG_0843.CR2`\n[...]\n. @ALiangLiang the problem is that gdrive itself creates these two files having different IDs but the same name. If this bug gets fixed there wouldn't be a name collision/conflict in the first place. I'd try to fix it but I'm not into go (yet).\n. ",
    "dflasse": "Any news on this? I'm in the same situation and I'm a bit worried there were no follow up in months\n. Any news on this? I'm in the same situation and I'm a bit worried there were no follow up in months\n. ",
    "mauricioss777": "Hi! I had the same issue... I tried to use --keep-remote and --keep-local but didn't work\n. Hi! I had the same issue... I tried to use --keep-remote and --keep-local but didn't work\n. ",
    "dd-han": "same problem\nit show Found name collision between 0B8n4VsDeE1egMks4aUlUdnpYUUU and 0B8n4VsDeE1ega2UycXZDTUhJaDQ\nthen I run gdrive info0B8n4VsDeE1egMks4aUlUdnpYUUU and gdrive info 0B8n4VsDeE1ega2UycXZDTUhJaDQ for getting information\nthat I found already two file with same file name.Then I delete (not move to trash can) one of them, It Works find\n. just write a script to fix that\n```\n!/bin/bash\nwhile [ true ]; do\n    status=gdrive sync upload /path/to/folder gdriveFolderID\n    if grep \"Found name collision between\" <<< $status; then\n        statusLine=grep \"Found name collision between\" <<< $status | sed \"s/.*Found name/Found name/g\"\n        echo \"found same file name!!\"\n        echo $statusLine\n        file=sed \"s/Found name collision between //g\" <<< $statusLine | sed \"s/\\ and\\ /,/g\"\n        file1=cut -d ',' -f 1 <<< $file\n        # file2=cut -d ',' -f 2 <<< $file\n    echo \"same file: $file\"\n    echo \"deleting file: $file1\"\n    gdrive delete $file1\nelse\n    echo \"not filename collision\"\n    echo \"message:\"\n    echo $status\n    break\nfi\nsleep 10\n\ndone\n```\nslow but works. @szunyi Yes, I can force the download after confirming the warning on the browser.\nBut here I can't.. same problem\nit show Found name collision between 0B8n4VsDeE1egMks4aUlUdnpYUUU and 0B8n4VsDeE1ega2UycXZDTUhJaDQ\nthen I run gdrive info0B8n4VsDeE1egMks4aUlUdnpYUUU and gdrive info 0B8n4VsDeE1ega2UycXZDTUhJaDQ for getting information\nthat I found already two file with same file name.Then I delete (not move to trash can) one of them, It Works find\n. just write a script to fix that\n```\n!/bin/bash\nwhile [ true ]; do\n    status=gdrive sync upload /path/to/folder gdriveFolderID\n    if grep \"Found name collision between\" <<< $status; then\n        statusLine=grep \"Found name collision between\" <<< $status | sed \"s/.*Found name/Found name/g\"\n        echo \"found same file name!!\"\n        echo $statusLine\n        file=sed \"s/Found name collision between //g\" <<< $statusLine | sed \"s/\\ and\\ /,/g\"\n        file1=cut -d ',' -f 1 <<< $file\n        # file2=cut -d ',' -f 2 <<< $file\n    echo \"same file: $file\"\n    echo \"deleting file: $file1\"\n    gdrive delete $file1\nelse\n    echo \"not filename collision\"\n    echo \"message:\"\n    echo $status\n    break\nfi\nsleep 10\n\ndone\n```\nslow but works. @szunyi Yes, I can force the download after confirming the warning on the browser.\nBut here I can't.. ",
    "ALiangLiang": "Same issue here. I suggest adding a new function to auto scan and delete another file. eg gdrive merge.\nOr make a argument called --ignore-conflict.\n. Same issue here. I suggest adding a new function to auto scan and delete another file. eg gdrive merge.\nOr make a argument called --ignore-conflict.\n. ",
    "pincushman": "@dd-han: Yes! This worked for me.. @dd-han: Yes! This worked for me.. ",
    "valkjsaaa": "This is a pretty serious problem. Can someone fix it?. I'm not familiar with Go but I suspect there's something wrong with the following line:\nhttps://github.com/prasmussen/gdrive/blob/master/drive/sync_upload.go#L271\nMaybe it needs to check whether the folder (in this case) is already exist before tries again?. This is a pretty serious problem. Can someone fix it?. I'm not familiar with Go but I suspect there's something wrong with the following line:\nhttps://github.com/prasmussen/gdrive/blob/master/drive/sync_upload.go#L271\nMaybe it needs to check whether the folder (in this case) is already exist before tries again?. ",
    "f00dl3": "I am having this same problem. I have an IP camera shell script that grabs images, uses imagemagick to make a 3 image to one snapshot, and does this every 1/2 second. I had a sync setup using gdrive with the --delete-extraneous option, which worked fine for 2 weeks then just completely stopped removing the remote files. Even though I have each file uniquely named with the format \"push_YYMMDDHHMM.mp4\" (see https://drive.google.com/open?id=0B6ScTEIoK3tPZTVpUnRlZ3dBZ28 ) -- gdrive is (1) failing to delete any files when the local files are deleted after the 3 AM job that merges them all into a single MP4 and removes the temp MP4s, and (2) fails to upload new files due to this name error.\n. I am having this same problem. I have an IP camera shell script that grabs images, uses imagemagick to make a 3 image to one snapshot, and does this every 1/2 second. I had a sync setup using gdrive with the --delete-extraneous option, which worked fine for 2 weeks then just completely stopped removing the remote files. Even though I have each file uniquely named with the format \"push_YYMMDDHHMM.mp4\" (see https://drive.google.com/open?id=0B6ScTEIoK3tPZTVpUnRlZ3dBZ28 ) -- gdrive is (1) failing to delete any files when the local files are deleted after the 3 AM job that merges them all into a single MP4 and removes the temp MP4s, and (2) fails to upload new files due to this name error.\n. ",
    "3noch": "Serious issue needs to be fixed.. Serious issue needs to be fixed.. ",
    "vmkalbskopf": "Yeah, this is a problem for me too.. Yeah, this is a problem for me too.. ",
    "nickolay": "Try: gdrive export --mime text/tab-separated-values fileID\nI got the MIME type from gdrive about export. Try: gdrive export --mime text/tab-separated-values fileID\nI got the MIME type from gdrive about export. ",
    "paulz": "We would like to be able to install gdrive on mac using Homebrew official formula.\nCurrently we have to use a workaround by doing:\nbrew tap paulz/gdrive\nbrew install --HEAD gdrive\nbecause old formula was not building correctly and was moved to https://github.com/Homebrew/homebrew-boneyard/blob/master/gdrive.rb\nNew formula could be written much simpler given dependencies:\nhttps://github.com/paulz/homebrew-gdrive/blob/master/gdrive.rb\n. Thank you, @prasmussen!\nWould you be able cut a new release of the Google Drive CLI Client? This will allow us to use release tag in Homebrew formula. And promoting formula to the main repo will allow anyone with Homebrew to use it. Here is the plan to restore Homebrew installation for GDrive:\nhttps://github.com/paulz/homebrew-gdrive#todo\n. Thank you! The Homebrew core team accepted our formula for gdrive:\nhttps://github.com/Homebrew/homebrew-core/pull/754\nNow anyone can install gdrive on Mac:\nbrew install gdrive\nI can offer to maintain and update the formula with your new releases:\nhttps://github.com/Homebrew/homebrew-core/blob/master/Formula/gdrive.rb\nThank you @prasmussen for the awesome gdrive utility!\n. With Homebrew it takes few seconds to install gdrive with one command:\nbrew install gdrive\nUser can even install it from sources and usual benefits of homebrew:\nInstallation is happening from trusted source and binary was built from the source!\n. We would like to be able to install gdrive on mac using Homebrew official formula.\nCurrently we have to use a workaround by doing:\nbrew tap paulz/gdrive\nbrew install --HEAD gdrive\nbecause old formula was not building correctly and was moved to https://github.com/Homebrew/homebrew-boneyard/blob/master/gdrive.rb\nNew formula could be written much simpler given dependencies:\nhttps://github.com/paulz/homebrew-gdrive/blob/master/gdrive.rb\n. Thank you, @prasmussen!\nWould you be able cut a new release of the Google Drive CLI Client? This will allow us to use release tag in Homebrew formula. And promoting formula to the main repo will allow anyone with Homebrew to use it. Here is the plan to restore Homebrew installation for GDrive:\nhttps://github.com/paulz/homebrew-gdrive#todo\n. Thank you! The Homebrew core team accepted our formula for gdrive:\nhttps://github.com/Homebrew/homebrew-core/pull/754\nNow anyone can install gdrive on Mac:\nbrew install gdrive\nI can offer to maintain and update the formula with your new releases:\nhttps://github.com/Homebrew/homebrew-core/blob/master/Formula/gdrive.rb\nThank you @prasmussen for the awesome gdrive utility!\n. With Homebrew it takes few seconds to install gdrive with one command:\nbrew install gdrive\nUser can even install it from sources and usual benefits of homebrew:\nInstallation is happening from trusted source and binary was built from the source!\n. ",
    "kylehase": "+1\nIt would be great to have configurable output for machine readability. \nFor example, when a directory is created now the output is something like\nDirectory 0B703RoN1U created\nWhich needs to be awk'd to get the ID.  Adding a -o=raw or -o=xml with default being human readable as it is now would be ideal.\n. +1\nIt would be great to have configurable output for machine readability. \nFor example, when a directory is created now the output is something like\nDirectory 0B703RoN1U created\nWhich needs to be awk'd to get the ID.  Adding a -o=raw or -o=xml with default being human readable as it is now would be ideal.\n. ",
    "adichiru": "+1\ngdrive version shows: gdrive: 2.0.1 however I was supposed to have downloaded the 2.1.0\n. +1\ngdrive version shows: gdrive: 2.0.1 however I was supposed to have downloaded the 2.1.0\n. ",
    "pellejacobs": "It seems like you can only sync download folders you created with this plugin, as they need to have the syncRoot appProperty: https://github.com/prasmussen/gdrive/blob/5b72ec986f53ac0316424de89bdbff4bfb8d61e3/drive/sync_download.go#L99\nNot sure why though. \ud83d\ude15 \n. It seems like you can only sync download folders you created with this plugin, as they need to have the syncRoot appProperty: https://github.com/prasmussen/gdrive/blob/5b72ec986f53ac0316424de89bdbff4bfb8d61e3/drive/sync_download.go#L99\nNot sure why though. \ud83d\ude15 \n. ",
    "Craeckie": "This works for me:\ngdrive list --no-header --query \" 'root' in parents\" | awk '{print $1}' | xargs -L 1 gdrive download -r. This works for me:\ngdrive list --no-header --query \" 'root' in parents\" | awk '{print $1}' | xargs -L 1 gdrive download -r. This works for me:\ngdrive list --no-header --query \" 'root' in parents\" | awk '{print $1}' | xargs -L 1 gdrive download -r. This works for me:\ngdrive list --no-header --query \" 'root' in parents\" | awk '{print $1}' | xargs -L 1 gdrive download -r. ",
    "mulera84": "Yes you can use this string:\ndrive list -m 1000 --absolute -q \"mimeType = 'application/vnd.google-apps.folder'  and trashed = false\"\nyou can delete -m 1000 if you have less than 30 directories and --absolute if you don't want the full path\n. Yes you can use this string:\ndrive list -m 1000 --absolute -q \"mimeType = 'application/vnd.google-apps.folder'  and trashed = false\"\nyou can delete -m 1000 if you have less than 30 directories and --absolute if you don't want the full path\n. ",
    "archeious": "drive list --query \" 'IdOfParent' in parents\" \nwill list the items in a folder.  How do you do get the ID of the parent ID (folder in question).  Why you use the list command.  If you caught on to the fact there is a bit of a catch 22 then worry no longer.  You can also use\ndrive list --query \" 'root' in parents\" \nto get a list of objects in the root folder\n. You need to get the ID of the folder this can be done with the list command.  If there are a lot of object you will need to use the query option to narrow it down.  If you want a list of objects in the root you can use 'root' as the ID e.g.,\n./gdrive list --query \" 'root' in parents\"\nor \n./gdrive list --query \" 'IdOfTheParentFolder' in parents\"\n. drive list --query \" 'IdOfParent' in parents\" \nwill list the items in a folder.  How do you do get the ID of the parent ID (folder in question).  Why you use the list command.  If you caught on to the fact there is a bit of a catch 22 then worry no longer.  You can also use\ndrive list --query \" 'root' in parents\" \nto get a list of objects in the root folder\n. You need to get the ID of the folder this can be done with the list command.  If there are a lot of object you will need to use the query option to narrow it down.  If you want a list of objects in the root you can use 'root' as the ID e.g.,\n./gdrive list --query \" 'root' in parents\"\nor \n./gdrive list --query \" 'IdOfTheParentFolder' in parents\"\n. ",
    "alanef": "``\ndrive: 2.1.0\nGolang: go1.6\nOS/Arch: `linux/amd64\n001:~$ gdrive sync download  ./mydir\nStarting sync...\nProvided id is not a sync root `directory\n```\nAny reasons?\n001:~$ gdrive sync list\nId   Name   Created\n001:~$\n. ``\ndrive: 2.1.0\nGolang: go1.6\nOS/Arch: `linux/amd64\n001:~$ gdrive sync download  ./mydir\nStarting sync...\nProvided id is not a sync root `directory\n```\nAny reasons?\n001:~$ gdrive sync list\nId   Name   Created\n001:~$\n. ",
    "kamihouse": "@alanef i have the same problem.\n. @mvasin, i have the same problem. Can you solve this problem?\n. @alanef i have the same problem.\n. @mvasin, i have the same problem. Can you solve this problem?\n. ",
    "Guilucand": "Try with gdrive-linux-rpi instead of gdrive-netbsd-386\n. With 'drive help' you can see a list of available commands, for example if you want to list all files uploaded to google drive you can do it with the command 'drive list'\n. Try with gdrive-linux-rpi instead of gdrive-netbsd-386\n. With 'drive help' you can see a list of available commands, for example if you want to list all files uploaded to google drive you can do it with the command 'drive list'\n. ",
    "mrcrocodile556": "Thank you so much! appreciate your help,\nAfter verifying, this is the output that is being displayed:\nUser: Junnhui96@hotmail.com, Junnhui96@hotmail.com\nUsed:\nFree: 16.1 GB\nTotal: 16.1 GB\nMax upload size: 5.2 TB\nAm i on the right track? However, i typed in the command \"drive\" and it still give me a error of:\n\"No valid arguments given, use 'gdrive help' to see available commands\"\nAny idea why?\ufeff\n. Thank you so much! appreciate your help,\nAfter verifying, this is the output that is being displayed:\nUser: Junnhui96@hotmail.com, Junnhui96@hotmail.com\nUsed:\nFree: 16.1 GB\nTotal: 16.1 GB\nMax upload size: 5.2 TB\nAm i on the right track? However, i typed in the command \"drive\" and it still give me a error of:\n\"No valid arguments given, use 'gdrive help' to see available commands\"\nAny idea why?\ufeff\n. ",
    "ChrisMann89": "Awesome. A quick response and one that worked first time.\nThe top of my script now reads as follows:\n#!/bin/sh\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nThank you.\n. Awesome. A quick response and one that worked first time.\nThe top of my script now reads as follows:\n#!/bin/sh\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nThank you.\n. ",
    "robjlg": "Hi\nyou could tray a command like this\ngdrive   list   --query     \"name contains 'drawing.dwg'\"    -m 0    --absolute     --name-width 0\n. Hi\nyou could tray a command like this\ngdrive   list   --query     \"name contains 'drawing.dwg'\"    -m 0    --absolute     --name-width 0\n. ",
    "anguianoa": "It looks like it is this line\ndrive/upload.go\n184 f, err := self.service.Files.Create(dstFile).Fields(\"id\", \"name\", \"size\", \"md5Checksum\", \"webContentLink\").Context(ctx).Media(reader, chunkSize).Do()\nSeem like it should have a Convert flag somewhere.  I was not able to trace the google api that it used to do in the api 2.0\n. Ok, looking further.  It looks like v3 is using the mime type to determine if it should convert.\nWhen i import my file it looks like it has the right mime type.  \nIt is still not converting to a spreadsheet.  It is still a doc.\nImported 1qKpH0y4NdNiFms9huEdeXurhOIHSDtSc7LuXQE3gvXU with mime type: 'application/vnd.google-apps.spreadsheet'\n. I'm beginning to think that this is a google api problem and looked at the code\nI tried the other call to upload\ngdrive upload  --mime \"text/tab-separated-values\" myfile.csv\nit uploaded with, but the file icon was a green box with an X in it.\nIt didn't convert it, but it did let me convert it after i opened it.  The importing command from above would make it to a google doc and it would not let me convert it on the google drive.\n. It looks like it is this line\ndrive/upload.go\n184 f, err := self.service.Files.Create(dstFile).Fields(\"id\", \"name\", \"size\", \"md5Checksum\", \"webContentLink\").Context(ctx).Media(reader, chunkSize).Do()\nSeem like it should have a Convert flag somewhere.  I was not able to trace the google api that it used to do in the api 2.0\n. Ok, looking further.  It looks like v3 is using the mime type to determine if it should convert.\nWhen i import my file it looks like it has the right mime type.  \nIt is still not converting to a spreadsheet.  It is still a doc.\nImported 1qKpH0y4NdNiFms9huEdeXurhOIHSDtSc7LuXQE3gvXU with mime type: 'application/vnd.google-apps.spreadsheet'\n. I'm beginning to think that this is a google api problem and looked at the code\nI tried the other call to upload\ngdrive upload  --mime \"text/tab-separated-values\" myfile.csv\nit uploaded with, but the file icon was a green box with an X in it.\nIt didn't convert it, but it did let me convert it after i opened it.  The importing command from above would make it to a google doc and it would not let me convert it on the google drive.\n. ",
    "PaulCapestany": "I'm having the same issue trying to upload .csv files.\n. Hey @prasmussen, just wanted to ping you directly about this conversion issue in case you might know of an obvious reason for why things are seemingly currently broken? \nIf not, I'd be happy to dive into the code to try to sort things out myself (and submit a pull request, if you're still cool with accepting those)\u2014just hadn't been annoyed by this issue enough to do so myself yet =P \nWould be great to hear from you either way!\np.s. thanks for having made such an awesome open source CLI gdrive tool \ud83d\udc4d \n. I've got a (somewhat lame + gross, but effective) hacky fix that's been working quite well with regard to importing docs (including csvs/tsvs) into gdrive-native formats with no muss and no fuss. \nIf it's the case that the owner of this repo is too busy with other things to bother with issues and/or PRs, feel free to @ mention me here if you'd be interested in the fix. If there's enough interest (and prasmussen remains MIA) I'd be happy to publicize my fork (don't wanna just do that and then seem like I'm competing with this original repo though\u2014if at all avoidable... \ud83d\ude2c) \n. p.s. @prasmussen my \"fix\" is really a regression (to an earlier version of the gDrive API)\u2014also, I'm not totally sure how to incorporate it into a PR for the current version of gDrive API... which is why I haven't officially opened a PR for this. Totally open to discussing it here though if you're up for it!\n. I'm having the same issue trying to upload .csv files.\n. Hey @prasmussen, just wanted to ping you directly about this conversion issue in case you might know of an obvious reason for why things are seemingly currently broken? \nIf not, I'd be happy to dive into the code to try to sort things out myself (and submit a pull request, if you're still cool with accepting those)\u2014just hadn't been annoyed by this issue enough to do so myself yet =P \nWould be great to hear from you either way!\np.s. thanks for having made such an awesome open source CLI gdrive tool \ud83d\udc4d \n. I've got a (somewhat lame + gross, but effective) hacky fix that's been working quite well with regard to importing docs (including csvs/tsvs) into gdrive-native formats with no muss and no fuss. \nIf it's the case that the owner of this repo is too busy with other things to bother with issues and/or PRs, feel free to @ mention me here if you'd be interested in the fix. If there's enough interest (and prasmussen remains MIA) I'd be happy to publicize my fork (don't wanna just do that and then seem like I'm competing with this original repo though\u2014if at all avoidable... \ud83d\ude2c) \n. p.s. @prasmussen my \"fix\" is really a regression (to an earlier version of the gDrive API)\u2014also, I'm not totally sure how to incorporate it into a PR for the current version of gDrive API... which is why I haven't officially opened a PR for this. Totally open to discussing it here though if you're up for it!\n. ",
    "ehno5": "same problem \ud83d\udc4e \n. same problem \ud83d\udc4e \n. ",
    "hemsh": "I am having same problem\n. I am having same problem\n. ",
    "yurtesen": "I am having the same issue. It says imported with mime type spreadsheet, but drive opens it in text editor.\n. I only needed to upload files and convert so I wrote a small program which does exactly that, it also can detect existing file with same name and overwrite it. It uses pydrive and very small (31 lines only!)\nOnly takes 2 arguments, parent directory ID value and file path. (you can get the ID value by entering to folder and copying from URL. It is usually some long text like 0B5XXXXY9KddXXXXXXXA2c3ZXXXX. Script was running for a month now daily and it did not ask for re-auth etc. So  -> Works For Me TM! <- You may need to update some paths and what not...\nSo I use it like:\nupload.py 0B5XXXXY9KddXXXXXXXA2c3ZXXXX /path/to/my/file\nI only tested it with .tsv files and it converts successfully to google sheets file so when I click on it, I get sheets...\n``` Python\n!/usr/bin/python\nimport sys\nimport base64\nfrom os import path\nfrom pydrive.auth import GoogleAuth\nfrom pydrive.drive import GoogleDrive\nfrom pydrive.settings import LoadSettingsFile\ngauth = GoogleAuth()\ngauth.settings = LoadSettingsFile(filename='/usr/local/scripts/gdrive/settings.yaml')\ngauth.CommandLineAuth()\ndrive = GoogleDrive(gauth)\nparentId = sys.argv[1]\nmyFilePath = sys.argv[2]\nmyFileName = path.basename(sys.argv[2])\nfile_list = drive.ListFile({'q': '\"'+parentId+'\" in parents and title=\"'+myFileName+'\" and trashed=false'}).GetList()\nIf file is found, update it, otherwise create new file\nif len(file_list) == 1:\n    myFile = file_list[0]\nelse:\n    myFile = drive.CreateFile({\"parents\": [{\"kind\": \"drive#fileLink\", \"id\": parentId}]})\nmyFile.SetContentFile(myFilePath)\nmyFile['title'] = myFileName\nmyFile.Upload({'convert': True})\n```\nsettings.yaml\n``` Python\nclient_config_backend: settings\nclient_config:\n  client_id: INSERT YOUR CLIENT_ID HERE\n  client_secret: INSERT YOUR SECRET HERE\n  auth_uri: https://accounts.google.com/o/oauth2/auth\n  token_uri: https://accounts.google.com/o/oauth2/token\n  redirect_uri: urn:ietf:wg:oauth:2.0:oob\n  revoke_uri:\nsave_credentials: True\nsave_credentials_backend: file\nsave_credentials_file: /usr/local/scripts/gdrive/credentials.json\nget_refresh_token: True\noauth_scope:\n  - https://www.googleapis.com/auth/drive.file\n```\n. @RNabel thanks for asking. I am surprised that you even found it here :) I don't mind at all. It probably would be worthwhile to convert setting file path to a variable in the script. This was a real quick hack so I didn't bother making it pretty.\nI would appreciate it if you could just add a line showing that it came from me :) Perhaps something like, if it is ok for you.\n# Evren Yurtesen - https://github.com/yurtesen/\n. I am having the same issue. It says imported with mime type spreadsheet, but drive opens it in text editor.\n. I only needed to upload files and convert so I wrote a small program which does exactly that, it also can detect existing file with same name and overwrite it. It uses pydrive and very small (31 lines only!)\nOnly takes 2 arguments, parent directory ID value and file path. (you can get the ID value by entering to folder and copying from URL. It is usually some long text like 0B5XXXXY9KddXXXXXXXA2c3ZXXXX. Script was running for a month now daily and it did not ask for re-auth etc. So  -> Works For Me TM! <- You may need to update some paths and what not...\nSo I use it like:\nupload.py 0B5XXXXY9KddXXXXXXXA2c3ZXXXX /path/to/my/file\nI only tested it with .tsv files and it converts successfully to google sheets file so when I click on it, I get sheets...\n``` Python\n!/usr/bin/python\nimport sys\nimport base64\nfrom os import path\nfrom pydrive.auth import GoogleAuth\nfrom pydrive.drive import GoogleDrive\nfrom pydrive.settings import LoadSettingsFile\ngauth = GoogleAuth()\ngauth.settings = LoadSettingsFile(filename='/usr/local/scripts/gdrive/settings.yaml')\ngauth.CommandLineAuth()\ndrive = GoogleDrive(gauth)\nparentId = sys.argv[1]\nmyFilePath = sys.argv[2]\nmyFileName = path.basename(sys.argv[2])\nfile_list = drive.ListFile({'q': '\"'+parentId+'\" in parents and title=\"'+myFileName+'\" and trashed=false'}).GetList()\nIf file is found, update it, otherwise create new file\nif len(file_list) == 1:\n    myFile = file_list[0]\nelse:\n    myFile = drive.CreateFile({\"parents\": [{\"kind\": \"drive#fileLink\", \"id\": parentId}]})\nmyFile.SetContentFile(myFilePath)\nmyFile['title'] = myFileName\nmyFile.Upload({'convert': True})\n```\nsettings.yaml\n``` Python\nclient_config_backend: settings\nclient_config:\n  client_id: INSERT YOUR CLIENT_ID HERE\n  client_secret: INSERT YOUR SECRET HERE\n  auth_uri: https://accounts.google.com/o/oauth2/auth\n  token_uri: https://accounts.google.com/o/oauth2/token\n  redirect_uri: urn:ietf:wg:oauth:2.0:oob\n  revoke_uri:\nsave_credentials: True\nsave_credentials_backend: file\nsave_credentials_file: /usr/local/scripts/gdrive/credentials.json\nget_refresh_token: True\noauth_scope:\n  - https://www.googleapis.com/auth/drive.file\n```\n. @RNabel thanks for asking. I am surprised that you even found it here :) I don't mind at all. It probably would be worthwhile to convert setting file path to a variable in the script. This was a real quick hack so I didn't bother making it pretty.\nI would appreciate it if you could just add a line showing that it came from me :) Perhaps something like, if it is ok for you.\n# Evren Yurtesen - https://github.com/yurtesen/\n. ",
    "Simonzhaohui": "I got same issue. Do you plan to fix that ?  @prasmussen \n. I got same issue. Do you plan to fix that ?  @prasmussen \n. ",
    "RNabel": "@yurtesen I am the maintainer of PyDrive - would you mind me adding this script to the examples published in the repository?\n. @yurtesen Just pushed your sample to PyDrive's dev branch, feel free to comment on the commit!\n(My apologies for discussing this in this thread)\n. +1, would love this ability.\nRe the API limit, the GDrive API is limited to 100 accesses per 100s - should be enough to speed up larger uploads.\n. You have to set the correct environment variable first, as is explained in the readme.\nAdd this to your .bashrc or run it in a shell for a one off authentication: \nexport GDRIVE_CONFIG_DIR=\"/path/to/file\"\n. @yurtesen I am the maintainer of PyDrive - would you mind me adding this script to the examples published in the repository?\n. @yurtesen Just pushed your sample to PyDrive's dev branch, feel free to comment on the commit!\n(My apologies for discussing this in this thread)\n. +1, would love this ability.\nRe the API limit, the GDrive API is limited to 100 accesses per 100s - should be enough to speed up larger uploads.\n. You have to set the correct environment variable first, as is explained in the readme.\nAdd this to your .bashrc or run it in a shell for a one off authentication: \nexport GDRIVE_CONFIG_DIR=\"/path/to/file\"\n. ",
    "anneschuth": "This seems to be an issue still. The response mentions the right MIME-type ('application/vnd.google-apps.spreadsheet') but the document isn't converted into a spreadsheet.. This seems to be an issue still. The response mentions the right MIME-type ('application/vnd.google-apps.spreadsheet') but the document isn't converted into a spreadsheet.. ",
    "tomofumi-nakano": "Someone, can you see my patch? 4540c5c\nThe patch solves this issue in my environment. \nI guess a lack option of ContentType might cause the issue.\nAll sample codes set mimeType in the page https://developers.google.com/drive/v3/web/integrate-open#open_and_convert_google_docs_in_your_app\n. @carrodher \nSorry, I forgot about a command option.\n--mime is required.\ni.e.\nbash\n./gdrive import --parent 0B_ulNgvK6XduaUcz3UaaeGRSdWc4 --mime text/csv /tmp/nami20170222.csv. @carrodher \nFinally I found the cause.\nThis program use local packages and use github.com/username/...\ni.e.\nhttps://github.com/prasmussen/gdrive/blob/master/handlers_drive.go#L14\n\"github.com/prasmussen/gdrive/drive\"\nIt mean this program imports and use the original repository (prasmussen's) code, even if we modify local code.\nThat is why.\nWe need change the import source package name if we use forked repositories.\nFor validation, I put the fix code at latest commit in my forked repository.\nPlease try again.. Someone, can you see my patch? 4540c5c\nThe patch solves this issue in my environment. \nI guess a lack option of ContentType might cause the issue.\nAll sample codes set mimeType in the page https://developers.google.com/drive/v3/web/integrate-open#open_and_convert_google_docs_in_your_app\n. @carrodher \nSorry, I forgot about a command option.\n--mime is required.\ni.e.\nbash\n./gdrive import --parent 0B_ulNgvK6XduaUcz3UaaeGRSdWc4 --mime text/csv /tmp/nami20170222.csv. @carrodher \nFinally I found the cause.\nThis program use local packages and use github.com/username/...\ni.e.\nhttps://github.com/prasmussen/gdrive/blob/master/handlers_drive.go#L14\n\"github.com/prasmussen/gdrive/drive\"\nIt mean this program imports and use the original repository (prasmussen's) code, even if we modify local code.\nThat is why.\nWe need change the import source package name if we use forked repositories.\nFor validation, I put the fix code at latest commit in my forked repository.\nPlease try again.. ",
    "carrodher": "Hi @tomofumi-nakano, I am trying your solution (PR #224), but it doesn't work for me, it is possible that I am doing something wrong. I want to upload a local .csv as a Google Sheet.\nMy steps are:\ngo get github.com/tomofumi-nakano/gdrive\ncd /go/bin/gdrive\n./gdrive import --parent 0B_ulNgvK6XduaUcz3UaaeGRSdWc4 /tmp/nami20170222.csv\nI hope the result is a Google Sheet like this:\n\nBut I obtain:\n\nAm I doing something wrong? Thanks!. Thanks for your answer @tomofumi-nakano, but I continue with the same issue using --mime text/csv option... . Hi @tomofumi-nakano, I am trying your solution (PR #224), but it doesn't work for me, it is possible that I am doing something wrong. I want to upload a local .csv as a Google Sheet.\nMy steps are:\ngo get github.com/tomofumi-nakano/gdrive\ncd /go/bin/gdrive\n./gdrive import --parent 0B_ulNgvK6XduaUcz3UaaeGRSdWc4 /tmp/nami20170222.csv\nI hope the result is a Google Sheet like this:\n\nBut I obtain:\n\nAm I doing something wrong? Thanks!. Thanks for your answer @tomofumi-nakano, but I continue with the same issue using --mime text/csv option... . ",
    "SapelliBR": "same issue... the file is imported like a doc.. same issue... the file is imported like a doc.. ",
    "svsundar": "Hi Tomofumi-nakano, carrodher,\nI have the same requirement and I need to copy the CSV to google drive as a google spreadsheet. \nI am following the same steps\ngo get github.com/tomofumi-nakano/gdrive\ncd /go/bin/gdrive\n./gdrive import --parent *driveID*** /tmp/test.csv\nI hope this will access your forked code branch and downloaded the code.\nand I am getting the below error,\nFailed to upload file: googleapi: Error 400: Bad Request, badRequest\nI thought it could be authentication and I tried grdive list and its working perfect. Upload is also working.\nAny idea? Could you please help? Thanks a bunch in advance.\nRegards\nVaiyravan. Hi Tomofumi-nakano, carrodher,\nI have the same requirement and I need to copy the CSV to google drive as a google spreadsheet. \nI am following the same steps\ngo get github.com/tomofumi-nakano/gdrive\ncd /go/bin/gdrive\n./gdrive import --parent *driveID*** /tmp/test.csv\nI hope this will access your forked code branch and downloaded the code.\nand I am getting the below error,\nFailed to upload file: googleapi: Error 400: Bad Request, badRequest\nI thought it could be authentication and I tried grdive list and its working perfect. Upload is also working.\nAny idea? Could you please help? Thanks a bunch in advance.\nRegards\nVaiyravan. ",
    "mikeyfev1": "OK, so issue #84 solved this for me.\nYou can save the OAuth access token for different accounts.  My default access token was already stored in the default location, so I logged out of Google.com, then I logged in with the new credentials.  Then I ran GDrive with the --config dir option, where dir was a new directory that I had created.  GDrive asked me for an access token as the first time, so I followed the instructions again.\nNow when I want to list my GDrive files, I use:\n>gdrive list\nand when I want to list my new user's files I use\n>gdrive -config NWP list\n. OK, so issue #84 solved this for me.\nYou can save the OAuth access token for different accounts.  My default access token was already stored in the default location, so I logged out of Google.com, then I logged in with the new credentials.  Then I ran GDrive with the --config dir option, where dir was a new directory that I had created.  GDrive asked me for an access token as the first time, so I followed the instructions again.\nNow when I want to list my GDrive files, I use:\n>gdrive list\nand when I want to list my new user's files I use\n>gdrive -config NWP list\n. ",
    "seikan": "You are missing CA certificates in your system. Install them using following command:\napt-get install ca-certificates\n. You are missing CA certificates in your system. Install them using following command:\napt-get install ca-certificates\n. ",
    "LeightonFromKratus": "Thank you, I am really struggling with this minimal install ;)\n. Thank you, I am really struggling with this minimal install ;)\n. ",
    "diman82": "I'm facing the same issue, and I have 'ca-certificates' installed.\nAny other ideas?\n. I'm facing the same issue, and I have 'ca-certificates' installed.\nAny other ideas?\n. ",
    "rsclmumbai": "Upload a file to my Google Drive via CLI, it works well but when doing it via crontab, I get this error:\nFailed getting oauth client: Failed to exchange auth code for token: oauth2: cannot fetch token: 400 Bad Request\nResponse: {\n  \"error\" : \"invalid_request\",\n  \"error_description\" : \"Missing required parameter: code\"\n}\nOS: CentOS release 6.8 (Final)\nAny ideas what could be wrong and how can it be fixed?\nThanks. Upload a file to my Google Drive via CLI, it works well but when doing it via crontab, I get this error:\nFailed getting oauth client: Failed to exchange auth code for token: oauth2: cannot fetch token: 400 Bad Request\nResponse: {\n  \"error\" : \"invalid_request\",\n  \"error_description\" : \"Missing required parameter: code\"\n}\nOS: CentOS release 6.8 (Final)\nAny ideas what could be wrong and how can it be fixed?\nThanks. ",
    "remush": "Hi all,\nI have finally gotten gdrive-linux-386 to work on my old microcore linux server, and got the following message when trying to enter the key\nEnter verification code: 4/wlxxxxxxxxxxxx removed for privacy xxxxxxxxxDg4\nFailed getting oauth client: Failed to exchange auth code for token: Post https://accounts.google.com/o/oauth2/token: x509: failed to load system roots and no roots provided\nA suggestion above says that I need to installer missing CA certificates in my system.\nBut my distro of linux does not support apt-get, and I could not find any mession of CA certificates in tinycore 3.8.4's repository's.\nCan anyone suggest how I would go about setting this up from scratch ?\n\nUPDATE\nI found a ca-certificates.tcz installer for my distro and have installed the latest one available.\nI've created a soft link to /etc/ssl/certs, mine was /usr/local/etc/ssl/certs\nI've run \"sudo gdrive about\"\nAnd I still get the following error\n`$ sudo gdrive about\nAuthentication needed\nGo to the following url in your browser:\nhttps://accounts.google.com/o/oauth2/auth?access_type=offline&client_id=367116221053-7n0vf5akeru7on6o2fjinrecpdoe99eg.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&state=state\nEnter verification code: 4/sAgXXXXXXXXXXXXXXXXXXXXXXXXXXXXdodw\nFailed getting oauth client: Failed to exchange auth code for token: Post https://accounts.google.com/o/oauth2/token: x509: failed to load system roots and no roots provided\n`\n. Hi all,\nI have finally gotten gdrive-linux-386 to work on my old microcore linux server, and got the following message when trying to enter the key\nEnter verification code: 4/wlxxxxxxxxxxxx removed for privacy xxxxxxxxxDg4\nFailed getting oauth client: Failed to exchange auth code for token: Post https://accounts.google.com/o/oauth2/token: x509: failed to load system roots and no roots provided\nA suggestion above says that I need to installer missing CA certificates in my system.\nBut my distro of linux does not support apt-get, and I could not find any mession of CA certificates in tinycore 3.8.4's repository's.\nCan anyone suggest how I would go about setting this up from scratch ?\n\nUPDATE\nI found a ca-certificates.tcz installer for my distro and have installed the latest one available.\nI've created a soft link to /etc/ssl/certs, mine was /usr/local/etc/ssl/certs\nI've run \"sudo gdrive about\"\nAnd I still get the following error\n`$ sudo gdrive about\nAuthentication needed\nGo to the following url in your browser:\nhttps://accounts.google.com/o/oauth2/auth?access_type=offline&client_id=367116221053-7n0vf5akeru7on6o2fjinrecpdoe99eg.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&state=state\nEnter verification code: 4/sAgXXXXXXXXXXXXXXXXXXXXXXXXXXXXdodw\nFailed getting oauth client: Failed to exchange auth code for token: Post https://accounts.google.com/o/oauth2/token: x509: failed to load system roots and no roots provided\n`\n. ",
    "44ankan": "Date and time of your computer is right ?\nIf that is wrong , it may fail.. Date and time of your computer is right ?\nIf that is wrong , it may fail.. ",
    "celicoo": "Same issue here. #84 isn't clear at all.\n. Where is the default config file?\n. Same issue here. #84 isn't clear at all.\n. Where is the default config file?\n. ",
    "sepn": "When I first ran the command it created a .gdrive directory in my home. I used gdrive -c ~/.gdrive2 about to go through the auth process for a second account.\nI can now use gdrive about to get information about the first (default) account and gdrive -c ~/.gdrive2 about to get information about the second account. \nHope this helps.\n. When I first ran the command it created a .gdrive directory in my home. I used gdrive -c ~/.gdrive2 about to go through the auth process for a second account.\nI can now use gdrive about to get information about the first (default) account and gdrive -c ~/.gdrive2 about to get information about the second account. \nHope this helps.\n. ",
    "anuraagdjain": "rm -rf ~/.gdrive/token_*.json removes your first account,  and then try to upload a file gdrive upload <filename> it will ask for verification code. I use this method to switch b/w accounts. \n. rm -rf ~/.gdrive/token_*.json removes your first account,  and then try to upload a file gdrive upload <filename> it will ask for verification code. I use this method to switch b/w accounts. \n. ",
    "alexanderkjeldaas": "I also need this.\n. I also need this.\n. ",
    "Synesso": "I see now this is a problem with the Debian default version of golang (apt-get golang) being too old - 1.2.1 vs 1.5\n. I see now this is a problem with the Debian default version of golang (apt-get golang) being too old - 1.2.1 vs 1.5\n. ",
    "DHOscar": "The same problem here. Also because of this error, a folder can not proper shared with other developers. As if I create a folder on drive synced, the other developer in my team can not use sync function to edit the folder anymore. \n. The same problem here. Also because of this error, a folder can not proper shared with other developers. As if I create a folder on drive synced, the other developer in my team can not use sync function to edit the folder anymore. \n. ",
    "4SiB": "+1, the same problem.\nSync upload should be continue what the GUI created. Re-index of data by gdrive should be normal.\n. +1, the same problem.\nSync upload should be continue what the GUI created. Re-index of data by gdrive should be normal.\n. ",
    "bramkuijper": "+1, the same problem. \nWhy does sync upload need an empty directory in the first place? No rationale given for this in the source. \n. +1, the same problem. \nWhy does sync upload need an empty directory in the first place? No rationale given for this in the source. \n. ",
    "daparker": "+1, the same problem.\nI uploaded many gigabytes of data into a folder on Google Drive and then wanted to sync new files after they were added to the local folder, but I got this error.\n. +1, the same problem.\nI uploaded many gigabytes of data into a folder on Google Drive and then wanted to sync new files after they were added to the local folder, but I got this error.\n. ",
    "transbetty": "I found a manual workaround, create the new directory via gdrive mkdir, then move/rename the directory to desired location and try the sync upload again. It worked it for me.\n. I found a manual workaround, create the new directory via gdrive mkdir, then move/rename the directory to desired location and try the sync upload again. It worked it for me.\n. ",
    "ThunderRoad75": "+1, the same problem.\nThis is just a major design failure, right?\nWhat's the point of syncing if you can only sync into an empty directoy [sic]?\n. Stupid as it is, @transbetty's workaround works.  Create an empty dummy directory, start syncing, then immediately move everything from the original directory into the dummy, and rename the dummy to the original.. +1, the same problem.\nThis is just a major design failure, right?\nWhat's the point of syncing if you can only sync into an empty directoy [sic]?\n. Stupid as it is, @transbetty's workaround works.  Create an empty dummy directory, start syncing, then immediately move everything from the original directory into the dummy, and rename the dummy to the original.. ",
    "qdacsvx": "It seems another script I was running in the background was responsible for waking the screen. If I run gdrive alone, there is no problem.\n. It seems another script I was running in the background was responsible for waking the screen. If I run gdrive alone, there is no problem.\n. ",
    "truongnmt": "How to get that fileId ? I ran gdrive sync list but I got blank list.\n. How to get that fileId ? I ran gdrive sync list but I got blank list.\n. ",
    "gabrielsors": "@prasmussen , Gdrive is great and makes life easier for many google drive users. Thank you!\n@petercoxphoto i have the same problem... \nI use gdrive on multiple servers to upload backups of various types. And since December / 2016 I got the message below:\nStarting sync...\nCollecting local and remote file information...\nCould not find parent of 0ByqE7lC_kho3SXFmTHF6TkxDajA (backup_31.sync.gz)\nThe strangest thing is that the files reported are files that have been uploaded for more than six months and since then are not accessed, below file info command:\n/root/gdrive info 0ByqE7lC_kho3SXFmTHF6TkxDajA\nId: 0ByqE7lC_kho3SXFmTHF6TkxDajA\nName: backup_31.sync.gz\nPath: backupdb/xxxxxxxx/2016/05/yyyy/backup_31.sync.gz\nMime: application/x-gzip\nSize: 1.5 MB\nCreated: 2016-05-31 04:20:43\nModified: 2016-05-31 04:20:43\nMd5sum: f48bd46c541f362598898586240c81ea\nShared: False\nParents: 0ByqE7lC_kho3a1RQaFFnZzNhYTA\nIn cases of file collision I am deleting the files with problem and I repeat the process of synchronization, but in this case I can not do because I do not have the original file that was sent.\nCurrently spool the process daily using sync upload only:\n/root/gdrive sync upload --no-progress --keep-local /home/backupdb/ 0ByqE7lC_kho3ZHVCb3hCMXNRQXM\nI use Sync to ensure that no backup is forgotten.\nLooking at the source code, I have an extensive list of files and I realized that the logic fetches the parent folder from the file, can not this loop be caused by this problem? Any memory limitation for example?\nThank you!\n. I have create a new Issue about this\n. @mattpr , interesting, but this difference isn't because id \"0BylfOx0NAyx4UHdJVFJLUi1ZLU0\" is a folder and \"0B1HLIFeM7hsRMzNiWG5fY3RETGc\" is a file?\n. @prasmussen , Gdrive is great and makes life easier for many google drive users. Thank you!\n@petercoxphoto i have the same problem... \nI use gdrive on multiple servers to upload backups of various types. And since December / 2016 I got the message below:\nStarting sync...\nCollecting local and remote file information...\nCould not find parent of 0ByqE7lC_kho3SXFmTHF6TkxDajA (backup_31.sync.gz)\nThe strangest thing is that the files reported are files that have been uploaded for more than six months and since then are not accessed, below file info command:\n/root/gdrive info 0ByqE7lC_kho3SXFmTHF6TkxDajA\nId: 0ByqE7lC_kho3SXFmTHF6TkxDajA\nName: backup_31.sync.gz\nPath: backupdb/xxxxxxxx/2016/05/yyyy/backup_31.sync.gz\nMime: application/x-gzip\nSize: 1.5 MB\nCreated: 2016-05-31 04:20:43\nModified: 2016-05-31 04:20:43\nMd5sum: f48bd46c541f362598898586240c81ea\nShared: False\nParents: 0ByqE7lC_kho3a1RQaFFnZzNhYTA\nIn cases of file collision I am deleting the files with problem and I repeat the process of synchronization, but in this case I can not do because I do not have the original file that was sent.\nCurrently spool the process daily using sync upload only:\n/root/gdrive sync upload --no-progress --keep-local /home/backupdb/ 0ByqE7lC_kho3ZHVCb3hCMXNRQXM\nI use Sync to ensure that no backup is forgotten.\nLooking at the source code, I have an extensive list of files and I realized that the logic fetches the parent folder from the file, can not this loop be caused by this problem? Any memory limitation for example?\nThank you!\n. I have create a new Issue about this\n. @mattpr , interesting, but this difference isn't because id \"0BylfOx0NAyx4UHdJVFJLUi1ZLU0\" is a folder and \"0B1HLIFeM7hsRMzNiWG5fY3RETGc\" is a file?\n. ",
    "Irishsmurf": "+1 to this.\nIt's pretty frustrating to be in the middle of a relatively large -r upload, when you get a API 500 error and there's no way to resume uploading without duplicating work already done.. +1 to this.\nIt's pretty frustrating to be in the middle of a relatively large -r upload, when you get a API 500 error and there's no way to resume uploading without duplicating work already done.. ",
    "kmshort": "ahhhhh...\n\"c:\\Program Files\\gdrive-windows-x64.exe\" upload -p 0BwdQegLY2V1UU0doUDV5OWIybWs -r \"F:\\test.\"\nfails\nas does\n\"c:\\Program Files\\gdrive-windows-x64.exe\" upload -p 0BwdQegLY2V1UU0doUDV5OWIybWs -r \"F:\\test\\\"\nbut\n\"c:\\Program Files\\gdrive-windows-x64.exe\" upload -p 0BwdQegLY2V1UU0doUDV5OWIybWs -r \"F:\\test\"\nworks.. and uploads the whole directory structure, and files as I'd wanted.\nSorry for the bother.\n. ahhhhh...\n\"c:\\Program Files\\gdrive-windows-x64.exe\" upload -p 0BwdQegLY2V1UU0doUDV5OWIybWs -r \"F:\\test.\"\nfails\nas does\n\"c:\\Program Files\\gdrive-windows-x64.exe\" upload -p 0BwdQegLY2V1UU0doUDV5OWIybWs -r \"F:\\test\\\"\nbut\n\"c:\\Program Files\\gdrive-windows-x64.exe\" upload -p 0BwdQegLY2V1UU0doUDV5OWIybWs -r \"F:\\test\"\nworks.. and uploads the whole directory structure, and files as I'd wanted.\nSorry for the bother.\n. ",
    "mvdbos": "Have you found a solution? I am dealing with the same issue.\n. Have you found a solution? I am dealing with the same issue.\n. ",
    "vandenoever": "gdrive cannot  load mime.types. This file is not always installed under /etc/apache2/mime.types or /etc/apache/mime.types or /etc/mime.types. If that file is not present, gdrive could use file -bi FILE.\nA --mime option would be a nice fallback.\n. gdrive cannot  load mime.types. This file is not always installed under /etc/apache2/mime.types or /etc/apache/mime.types or /etc/mime.types. If that file is not present, gdrive could use file -bi FILE.\nA --mime option would be a nice fallback.\n. ",
    "timwis": "I had the same 2 thoughts today, @bramp! It'd be pretty easy to construct the url (just put https://docs.google.com/document/d/ before the doc id), but the ability to import from stdin like upload supports would be great. I was thinking there may be a hacky way to do it using a named pipe, but gdrive can't seem to detect the mime type (let alone filename).\n. I had the same 2 thoughts today, @bramp! It'd be pretty easy to construct the url (just put https://docs.google.com/document/d/ before the doc id), but the ability to import from stdin like upload supports would be great. I was thinking there may be a hacky way to do it using a named pipe, but gdrive can't seem to detect the mime type (let alone filename).\n. ",
    "fab-io": "I was able to isolate the problem, that is in the Polipo proxy cache server that I am using to speedup packer development.\nDisabling the proxy only for the upload solved my problem, now the analysis is on the interaction between polipo and gdrive.\n. Hi, \nthere are already some error messages, for example if the service account file does not exists, I get this:\nfdifabio$ ./gdrive -c /tmp --service-account foo.json about\nFailed getting oauth client: Service account filename \"/tmp/foo.json\" not found\nand others should be handled by the GDrive API directly, for example in case of invalid key:\nfdifabio$ gdrive -c ~/tmp --service-account service_account.json about\nFailed to get about: Get https://www.googleapis.com/drive/v3/about?alt=json&fields=maxImportSizes%2CmaxUploadSize%2CstorageQuota%2Cuser: private key should be a PEM or plain PKSC1 or PKCS8; parse error: asn1: structure error: tags don't match (16 vs {class:0 tag:13 length:45 isCompound:true}) {optional:false explicit:false application:false defaultValue:<nil> tag:<nil> stringType:0 timeType:0 set:false omitEmpty:false} pkcs1PrivateKey @2\nCould you help me in reproducing you setup, so I can find what is missing?. The build you are using does not have this new feature, since it is only available compiling sources from the master branch.\nPlease ask to @prasmussen when he plan to do a new binary release.\n. I was able to isolate the problem, that is in the Polipo proxy cache server that I am using to speedup packer development.\nDisabling the proxy only for the upload solved my problem, now the analysis is on the interaction between polipo and gdrive.\n. Hi, \nthere are already some error messages, for example if the service account file does not exists, I get this:\nfdifabio$ ./gdrive -c /tmp --service-account foo.json about\nFailed getting oauth client: Service account filename \"/tmp/foo.json\" not found\nand others should be handled by the GDrive API directly, for example in case of invalid key:\nfdifabio$ gdrive -c ~/tmp --service-account service_account.json about\nFailed to get about: Get https://www.googleapis.com/drive/v3/about?alt=json&fields=maxImportSizes%2CmaxUploadSize%2CstorageQuota%2Cuser: private key should be a PEM or plain PKSC1 or PKCS8; parse error: asn1: structure error: tags don't match (16 vs {class:0 tag:13 length:45 isCompound:true}) {optional:false explicit:false application:false defaultValue:<nil> tag:<nil> stringType:0 timeType:0 set:false omitEmpty:false} pkcs1PrivateKey @2\nCould you help me in reproducing you setup, so I can find what is missing?. The build you are using does not have this new feature, since it is only available compiling sources from the master branch.\nPlease ask to @prasmussen when he plan to do a new binary release.\n. ",
    "saivert": "They just appear in multiple places. If you are talking about using multiple --parent when uploading using gdrive upload.\nOtherwise if you mean how they appear hierarchically when you have multiple sublevels, each object has one parent that might also have a parent. So it just traverses the parents.\nHope at least one of them answers your question.\n. You would have to do that in two steps currently.\ngdrive mkdir Backups\nThis will return the id of the Backups folder to you. Next:\ngdrive mkdir --parent <id of Backups folder> test\nRemember that Google Drive is an object store and shouldn't be treated as an ordinary filesystem. Every file/folder has a unique ID that does not change even if you rename objects.\n. They just appear in multiple places. If you are talking about using multiple --parent when uploading using gdrive upload.\nOtherwise if you mean how they appear hierarchically when you have multiple sublevels, each object has one parent that might also have a parent. So it just traverses the parents.\nHope at least one of them answers your question.\n. You would have to do that in two steps currently.\ngdrive mkdir Backups\nThis will return the id of the Backups folder to you. Next:\ngdrive mkdir --parent <id of Backups folder> test\nRemember that Google Drive is an object store and shouldn't be treated as an ordinary filesystem. Every file/folder has a unique ID that does not change even if you rename objects.\n. ",
    "AndrewMcSwain": "Same problem here. i can't download or sync anything. I can see the files so the token seems ok.\n. Same problem here. i can't download or sync anything. I can see the files so the token seems ok.\n. ",
    "hernad": "You shoud use directory id, not name. Follow this example:\ndocker@greenbox:~/test$ gdrive list | grep testx\n0BzpQKRsGgLdHTml3aDI2VkVsRGs   testx                        dir               2015-05-20 10:07:35\ndocker@greenbox:~/test$ gdrive download -r 0BzpQKRsGgLdHTml3aDI2VkVsRGs\nDownloading tunnel.txt -> testx/tunnel.txt\ndocker@greenbox:~/test$ ls testx\ntunnel.txt\n. You shoud use directory id, not name. Follow this example:\ndocker@greenbox:~/test$ gdrive list | grep testx\n0BzpQKRsGgLdHTml3aDI2VkVsRGs   testx                        dir               2015-05-20 10:07:35\ndocker@greenbox:~/test$ gdrive download -r 0BzpQKRsGgLdHTml3aDI2VkVsRGs\nDownloading tunnel.txt -> testx/tunnel.txt\ndocker@greenbox:~/test$ ls testx\ntunnel.txt\n. ",
    "thmxv": "I had the same issue. I worked around it by deleting the token file in the ~HOME\\AppData\\Roaming.gdrive directory before restarting the command.. I had the same issue. I worked around it by deleting the token file in the ~HOME\\AppData\\Roaming.gdrive directory before restarting the command.. ",
    "eadmaster": "I've just found with the command gdrive sync content FOLDER-ID that the issue was due to filename collisions between some files in the synced folder and the recycle bin.\nAfter the emptying the recycle bin the conflicts are gone and now the folder is syncable again!\n. I've just switched to rclone because of this.\nDefinitively more user friendly for interactive use.\n. I've just found with the command gdrive sync content FOLDER-ID that the issue was due to filename collisions between some files in the synced folder and the recycle bin.\nAfter the emptying the recycle bin the conflicts are gone and now the folder is syncable again!\n. I've just switched to rclone because of this.\nDefinitively more user friendly for interactive use.\n. ",
    "jblazquez": "@prasmussen is this change something that you'd like to have? I found I had a need for it when using gdrive for the first time.\n. @prasmussen is this change something that you'd like to have? I found I had a need for it when using gdrive for the first time.\n. ",
    "willemdh": "Thanks for your answer!\n. Thanks for your answer!\n. ",
    "varung": "Me too. How does one create a syncable directory?\n. Me too. How does one create a syncable directory?\n. ",
    "yixiaoyx": "It seems you will need to sync from local to drive first in order to make the drive directory syncable. And the drive directory needs to be empty before you sync upload.\n. It seems you will need to sync from local to drive first in order to make the drive directory syncable. And the drive directory needs to be empty before you sync upload.\n. ",
    "octodile": "First you need to make a directory for syn.For example ,run command  \"gdrive mkdir sync\" to make a folder named \"sync\" on your google drive.This command will return the id of the folder \"sync\". ....... First you need to make a directory for syn.For example ,run command  \"gdrive mkdir sync\" to make a folder named \"sync\" on your google drive.This command will return the id of the folder \"sync\". ....... ",
    "sjfloat": "I not sure what's being suggested here. Do I have download my entire drive before this tool starts working? I still get the same error.. My mistake. I thought this was a later version of \nhttps://github.com/odeke-em/drive\nwhich is the app I actually use.\nPlease disregard.. I not sure what's being suggested here. Do I have download my entire drive before this tool starts working? I still get the same error.. My mistake. I thought this was a later version of \nhttps://github.com/odeke-em/drive\nwhich is the app I actually use.\nPlease disregard.. ",
    "CompClash": "I made the folder sync with mkdir and then moved everything from my folder I wanted to sync into the new sync folder and then renamed it. So I would have the correct name and the folder would be made by the program... FAILED :(. Every time I upload a new file I have to go through the auth process. So annoying. It even says GDrive has authentication but when I type gdrive -c cloud upload path it ask me to authenticate AGAIN!. I found out that if I do everything from the startup directory, it works. I guess I have to be in the same directory the folder for the current gdrive I'm trying to use, so if I do gdrive -c cloud upload  while I'm in cd ~ it works but if I cd home/user/blaa/blaa and try to do it. It always asks for authentication. Is there any way I can change this, so I can use cd and still not have to authenticate?. Nevermind. I made the folder sync with mkdir and then moved everything from my folder I wanted to sync into the new sync folder and then renamed it. So I would have the correct name and the folder would be made by the program... FAILED :(. Every time I upload a new file I have to go through the auth process. So annoying. It even says GDrive has authentication but when I type gdrive -c cloud upload path it ask me to authenticate AGAIN!. I found out that if I do everything from the startup directory, it works. I guess I have to be in the same directory the folder for the current gdrive I'm trying to use, so if I do gdrive -c cloud upload  while I'm in cd ~ it works but if I cd home/user/blaa/blaa and try to do it. It always asks for authentication. Is there any way I can change this, so I can use cd and still not have to authenticate?. Nevermind. ",
    "jayypluss": "I've created a syncable directory (named it \"syncable\") then I tried gdrive sync upload but it didn't work.\n```\n\u2570\u2500$ gdrive sync list                                                  \nId                             Name       Created\n0Bz3LWCvhllF1aDEybkVWeWc   syncable   2017-06-19 22:06:39\n\u2570\u2500$ touch test.md; gdrive sync upload test.md 0Bz3LWCvhllF1aDEybkVWeWc\nStarting sync...\nCollecting local and remote file information...\nFound 0 local files and 0 remote files\nSync finished in 1.166304588s\n\u2570\u2500$ gdrive sync content 0Bz3LWCvhllF1aDEybkVWeWc\nId   Path   Type   Size   Modified\n```\n. I've created a syncable directory (named it \"syncable\") then I tried gdrive sync upload but it didn't work.\n```\n\u2570\u2500$ gdrive sync list                                                  \nId                             Name       Created\n0Bz3LWCvhllF1aDEybkVWeWc   syncable   2017-06-19 22:06:39\n\u2570\u2500$ touch test.md; gdrive sync upload test.md 0Bz3LWCvhllF1aDEybkVWeWc\nStarting sync...\nCollecting local and remote file information...\nFound 0 local files and 0 remote files\nSync finished in 1.166304588s\n\u2570\u2500$ gdrive sync content 0Bz3LWCvhllF1aDEybkVWeWc\nId   Path   Type   Size   Modified\n```\n. ",
    "annasdtc": "It happens to me too. The exact same. It only happens in my laptop, not my desktop, although both have Ubuntu 16.04. Have you found what the problem is?\n. It happens to me too. The exact same. It only happens in my laptop, not my desktop, although both have Ubuntu 16.04. Have you found what the problem is?\n. ",
    "murathai": "I also can't figure that out.... I also can't figure that out.... ",
    "ghfields": "I got a temporary workaround.\nzfs send -R pool/ROOT/ubuntu@1609201008 |parallel -u -P 3 --pipe --recend '' --block 1G  'gdrive-linux-x64 upload - ubuntu,1609201008-{#}.zfssplit'\nThis splits the stdin into 1GB chunks and passes it to up to 3 cocurrent gdrive instances.  It in my case, 39 uploads later, I have a successful upload.  It still would be nice if gdrive natively split the pipe.\nI also have to work on finding a way to 'cat' the split downloads directly into a pipe to be fed into \"zfs receive\".\n. I got a temporary workaround.\nzfs send -R pool/ROOT/ubuntu@1609201008 |parallel -u -P 3 --pipe --recend '' --block 1G  'gdrive-linux-x64 upload - ubuntu,1609201008-{#}.zfssplit'\nThis splits the stdin into 1GB chunks and passes it to up to 3 cocurrent gdrive instances.  It in my case, 39 uploads later, I have a successful upload.  It still would be nice if gdrive natively split the pipe.\nI also have to work on finding a way to 'cat' the split downloads directly into a pipe to be fed into \"zfs receive\".\n. ",
    "ksz16": "I have partial solution of this problem, but only for KeePass users. Instead of keeping refresh token in the user's home directory, you can put it to encrypted KeePass database.\nFirst of all open a *.json file and copy value of refresh token. In KeePass DB create new entry e.g. GDriveRefreshToken and put value of token into Password field. Now you can delete folder ~/.gdrive.\nI'm using this to autobackup my local KeePass database to Google Drive:\nIn KeePass create a trigger e.g. GDrive.\nEVENTS: \nsaved database file or closing database file (it depends on you)\nACTION: \nExecute command line / URL\nFile/URL: %comspec%\nArguments: /c gdrive --refresh-token {REF:P@I:} update  \nIf you want to use gdrive in CMD manually, you have to paste value of token (you can fast and simply copy it from KP DB) after \"gdrive --refresh-token \" every time \n(Gdrive syntax: gdrive [global] update [options]  )\nIt works only with KeePass, but token is safe and encrypted.. I have partial solution of this problem, but only for KeePass users. Instead of keeping refresh token in the user's home directory, you can put it to encrypted KeePass database.\nFirst of all open a *.json file and copy value of refresh token. In KeePass DB create new entry e.g. GDriveRefreshToken and put value of token into Password field. Now you can delete folder ~/.gdrive.\nI'm using this to autobackup my local KeePass database to Google Drive:\nIn KeePass create a trigger e.g. GDrive.\nEVENTS: \nsaved database file or closing database file (it depends on you)\nACTION: \nExecute command line / URL\nFile/URL: %comspec%\nArguments: /c gdrive --refresh-token {REF:P@I:} update  \nIf you want to use gdrive in CMD manually, you have to paste value of token (you can fast and simply copy it from KP DB) after \"gdrive --refresh-token \" every time \n(Gdrive syntax: gdrive [global] update [options]  )\nIt works only with KeePass, but token is safe and encrypted.. ",
    "beresnyak": "this is also mentioned here: #210 \non linux manually delete ~/.gdrive/.json \non Windows -- find the application configuration folder and do the same\n. this is also mentioned here: #210 \non linux manually delete ~/.gdrive/.json \non Windows -- find the application configuration folder and do the same\n. ",
    "lucascrezende": "@beresnyak Thank you for the reply. I tried to look it up but haven't found it.\n. @beresnyak Thank you for the reply. I tried to look it up but haven't found it.\n. ",
    "alecuba16": "Just for info, I was able to compile gdrive with the patched go 1.4.2 for mips32 but since the code is incompatible with GO 1.4.2 because this issues: \ngolang.org/x/net/context/ctxhttp\ngdrive-master\\src\\golang.org\\x\\net\\context\\ctxhttp\\ctxhttp_pre17.go:36: req.Cancel undefined (type *http.Request has no field or method Cancel)\n google.golang.org/api/googleapi\ngdrive-master\\src\\google.golang.org\\api\\googleapi\\googleapi.go:289: u.RawPath undefined (type *url.URL has no field or method RawPath)\n github.com/soniakeys/graph\ngdrive-master\\src\\github.com\\soniakeys\\graph\\bits.go:210: constant 285870213051353865 overflows big.Word\nThis is due go 1.4.2 lacks of features/patches/functions needed above, so I have been patching the go compiler for mips32 (1.4.2.) in order to support the new features of 1.5.x that gdrive needs  and I was able to compile it. I had to patch:\nGo-mips32 compiler src:\n-mime\\type.go : add extensions and methods that include it from 1.5.x\n-net\\net\\http\\request.go: add cancel method.\n-net\\net\\http\\transport.go: implement cancel method.\n-net\\net\\url\\url.go: add rawpath method and variables.\nGdrive dependency (soniakeys) :\n-Add mips32 build flags to bits32.go\nHere you have the latest binary (2016-11-26) file for mips32\n (MSB - mipsbe):\nhttps://mega.nz/#!w59x2BIR!-A0bSwkqW-KCN-yZxrSw9r_17uSXwTHL9Jz1xEydKU4\n(LSB- mipsle)\nhttps://mega.nz/#!Eh0EwYaZ!8-qQgtEW3kXPSEoRQHhG5mk3QZ0VECxGyjeLuenlzoc. Another update, if you compile the master branch of go compiler (they are working on 1.8 that will include mips32) you will be able to compile go for mips32 with the newest 1.8 api, only needs the soniakeys  mips/mips32 build flag :)\n. Just for info, I was able to compile gdrive with the patched go 1.4.2 for mips32 but since the code is incompatible with GO 1.4.2 because this issues: \ngolang.org/x/net/context/ctxhttp\ngdrive-master\\src\\golang.org\\x\\net\\context\\ctxhttp\\ctxhttp_pre17.go:36: req.Cancel undefined (type *http.Request has no field or method Cancel)\n google.golang.org/api/googleapi\ngdrive-master\\src\\google.golang.org\\api\\googleapi\\googleapi.go:289: u.RawPath undefined (type *url.URL has no field or method RawPath)\n github.com/soniakeys/graph\ngdrive-master\\src\\github.com\\soniakeys\\graph\\bits.go:210: constant 285870213051353865 overflows big.Word\nThis is due go 1.4.2 lacks of features/patches/functions needed above, so I have been patching the go compiler for mips32 (1.4.2.) in order to support the new features of 1.5.x that gdrive needs  and I was able to compile it. I had to patch:\nGo-mips32 compiler src:\n-mime\\type.go : add extensions and methods that include it from 1.5.x\n-net\\net\\http\\request.go: add cancel method.\n-net\\net\\http\\transport.go: implement cancel method.\n-net\\net\\url\\url.go: add rawpath method and variables.\nGdrive dependency (soniakeys) :\n-Add mips32 build flags to bits32.go\nHere you have the latest binary (2016-11-26) file for mips32\n (MSB - mipsbe):\nhttps://mega.nz/#!w59x2BIR!-A0bSwkqW-KCN-yZxrSw9r_17uSXwTHL9Jz1xEydKU4\n(LSB- mipsle)\nhttps://mega.nz/#!Eh0EwYaZ!8-qQgtEW3kXPSEoRQHhG5mk3QZ0VECxGyjeLuenlzoc. Another update, if you compile the master branch of go compiler (they are working on 1.8 that will include mips32) you will be able to compile go for mips32 with the newest 1.8 api, only needs the soniakeys  mips/mips32 build flag :)\n. ",
    "chentz78": "For those that want a workaround to this. On the Linux I'm using throttle and the stdin upload and it works like a charm.\nThrottle man : https://linux.die.net/man/1/throttle\nand the source : ftp://ftp.fi.freebsd.org/pub/FreeBSD/ports/distfiles/throttle-1.2.tar.gz\n. For those that want a workaround to this. On the Linux I'm using throttle and the stdin upload and it works like a charm.\nThrottle man : https://linux.die.net/man/1/throttle\nand the source : ftp://ftp.fi.freebsd.org/pub/FreeBSD/ports/distfiles/throttle-1.2.tar.gz\n. ",
    "Efreak": "This would be great. Unfortunately, @chentz78 suggestion doesn't work for me because I need to download stuff.... This would be great. Unfortunately, @chentz78 suggestion doesn't work for me because I need to download stuff.... ",
    "chester-man": "--delete-extraneous\ngdrive [global] sync upload [options]  \nglobal:\n  -c, --config          Application path, default: /Users//.gdrive\n  --refresh-token    Oauth refresh token used to get access token (for advanced users)\n  --access-token      Oauth access token, only recommended for short-lived requests because of short lifetime (for advanced users)\noptions:\n  --keep-remote             Keep remote file when a conflict is encountered\n  --keep-local              Keep local file when a conflict is encountered\n  --keep-largest            Keep largest file when a conflict is encountered\n  --delete-extraneous       Delete extraneous remote files\n  --dry-run                 Show what would have been transferred\n  --no-progress             Hide progress\n  --timeout        Set timeout in seconds, use 0 for no timeout. Timeout is reached when no data is transferred in set amount of seconds, default: 300\n  --chunksize    Set chunk size in bytes, default: 8388608\n. --delete-extraneous\ngdrive [global] sync upload [options]  \nglobal:\n  -c, --config          Application path, default: /Users//.gdrive\n  --refresh-token    Oauth refresh token used to get access token (for advanced users)\n  --access-token      Oauth access token, only recommended for short-lived requests because of short lifetime (for advanced users)\noptions:\n  --keep-remote             Keep remote file when a conflict is encountered\n  --keep-local              Keep local file when a conflict is encountered\n  --keep-largest            Keep largest file when a conflict is encountered\n  --delete-extraneous       Delete extraneous remote files\n  --dry-run                 Show what would have been transferred\n  --no-progress             Hide progress\n  --timeout        Set timeout in seconds, use 0 for no timeout. Timeout is reached when no data is transferred in set amount of seconds, default: 300\n  --chunksize    Set chunk size in bytes, default: 8388608\n. ",
    "4getit": "Well thank you!!\nI downloaded your commit sha and with some fiddling to get it compiled, it works perfectly. \n. Well thank you!!\nI downloaded your commit sha and with some fiddling to get it compiled, it works perfectly. \n. ",
    "bcearthen": "It would be great if this 'rename' function were included in a regular gdrive release.. It would be great if this 'rename' function were included in a regular gdrive release.. ",
    "technoicon": "Looks like you could do this with gdrive update?\nBut not sure how to structure the command?. Looks like you could do this with gdrive update?\nBut not sure how to structure the command?. ",
    "Xaekai": "why did you close this?. why did you close this?. ",
    "stilliard": "Hey @rakeshr , did you resolve this? Suddenly received this error this morning?. Ok weirdly found an extra closing } inside ~/.gdrive/token_v2.json. \nNot sure how this occurred but removing the extra symbol resolved the issue for me.. Hey @rakeshr , did you resolve this? Suddenly received this error this morning?. Ok weirdly found an extra closing } inside ~/.gdrive/token_v2.json. \nNot sure how this occurred but removing the extra symbol resolved the issue for me.. ",
    "jayeshanandani": "Can you please try again with latest version? It works for me.. Can you please try again with latest version? It works for me.. ",
    "asmith20002": "Hello,\nI'd also like this. It helps managing backup files.. @fab-io,\nI thought this was totally abandoned. Thanks for taking time. I appreciate it :)\nI use \"gdrive-linux-386\" version from the main page but I  don't think it's been released for it yet.. Service accounts are separate accounts. That's why you're seeing different content.\nYour fastest shortcut is to give permission to your Service accounts for those files/folders you have in mind.. The service account feature hasn't been released for the latest builds. You have to compile it yourself from the source or wait for @prasmussen to update the builds.\nMore info on issue #242 . Hello,\nI'd also like this. It helps managing backup files.. @fab-io,\nI thought this was totally abandoned. Thanks for taking time. I appreciate it :)\nI use \"gdrive-linux-386\" version from the main page but I  don't think it's been released for it yet.. Service accounts are separate accounts. That's why you're seeing different content.\nYour fastest shortcut is to give permission to your Service accounts for those files/folders you have in mind.. The service account feature hasn't been released for the latest builds. You have to compile it yourself from the source or wait for @prasmussen to update the builds.\nMore info on issue #242 . ",
    "michaelmcmillan": "Here's a script I threw together that uploads a file and deletes all files which are older than 100 days in a given directory. It assumes that you have the gdrive executable in the same directory as the script.\n````bash\n!/usr/bin/env bash\nset -e;\nif [  $# -le 2 ] \nthen \n    echo \"Usage: ./backup.sh [platform] [gdrive folder id] [file to backup]\";\n    exit 1;\nfi \nArguments\ndirectory=dirname \"$0\"\ngdrive=$directory/gdrive-$1\nbackup_directory_id=$2\nfile_to_backup=$3\nBacks up the current file\n$gdrive upload --parent $backup_directory_id $file_to_backup;\nhundred_days_ago=python -c 'from datetime import datetime as dt, timedelta as delta; print((dt.now() - delta(days=100)).strftime(\"%Y-%m-%d\"))';\nexpired_backups=$gdrive list -m 1000 --query \" ('$backup_directory_id' in parents) and trashed = false and modifiedTime < '$hundred_days_ago'\" --order \"modifiedTime asc\" --no-header | cut -d ' ' -f1;\nDeletes backups that are more than 100 days old.\nwhile read -r backup_id; do\n    echo Deleting $backup_id;\n    $gdrive delete $backup_id;\ndone <<< \"$expired_backups\"\n````\nExample usage:\n./backup.sh linux-x64 0BwFfewfewwf-ofewfwF2WHM example.db. Here's a script I threw together that uploads a file and deletes all files which are older than 100 days in a given directory. It assumes that you have the gdrive executable in the same directory as the script.\n````bash\n!/usr/bin/env bash\nset -e;\nif [  $# -le 2 ] \nthen \n    echo \"Usage: ./backup.sh [platform] [gdrive folder id] [file to backup]\";\n    exit 1;\nfi \nArguments\ndirectory=dirname \"$0\"\ngdrive=$directory/gdrive-$1\nbackup_directory_id=$2\nfile_to_backup=$3\nBacks up the current file\n$gdrive upload --parent $backup_directory_id $file_to_backup;\nhundred_days_ago=python -c 'from datetime import datetime as dt, timedelta as delta; print((dt.now() - delta(days=100)).strftime(\"%Y-%m-%d\"))';\nexpired_backups=$gdrive list -m 1000 --query \" ('$backup_directory_id' in parents) and trashed = false and modifiedTime < '$hundred_days_ago'\" --order \"modifiedTime asc\" --no-header | cut -d ' ' -f1;\nDeletes backups that are more than 100 days old.\nwhile read -r backup_id; do\n    echo Deleting $backup_id;\n    $gdrive delete $backup_id;\ndone <<< \"$expired_backups\"\n````\nExample usage:\n./backup.sh linux-x64 0BwFfewfewwf-ofewfwF2WHM example.db. ",
    "AngryNinja": "To see the files shared with you, you can use the following command...\ngdrive list --query \"sharedWithMe\"\nHope it helps. . To see the files shared with you, you can use the following command...\ngdrive list --query \"sharedWithMe\"\nHope it helps. . ",
    "szunyi": "you can download this file from browser?. you can download this file from browser?. ",
    "leonardoInf": "Same here this link is broken: https://docs.google.com/uc?id=0B3X9GlR6EmbnNFRSSW1GaFBSRk0&export=download. Same here this link is broken: https://docs.google.com/uc?id=0B3X9GlR6EmbnNFRSSW1GaFBSRk0&export=download. ",
    "byron27": "Still broken, along with the 32bit version.. Still broken, along with the 32bit version.. ",
    "tleskin": "@ordimans We're having the same issue and haven't gotten it to work yet either. . @ordimans We're having the same issue and haven't gotten it to work yet either. . ",
    "freddi301": "hi, nice feature but i cant make it work in any way, please write some error message like file not found or key not valid. Downloaded from https://github.com/prasmussen/gdrive/tree/2.1.0\n./gdrive-linux-x64 -c /tmp --service-account foo.json about\nNo valid arguments given, use 'gdrive help' to see available commands\n./gdrive-linux-x64 -c ~/tmp --service-account service_account.json about\nNo valid arguments given, use 'gdrive help' to see available commands. hi, nice feature but i cant make it work in any way, please write some error message like file not found or key not valid. Downloaded from https://github.com/prasmussen/gdrive/tree/2.1.0\n./gdrive-linux-x64 -c /tmp --service-account foo.json about\nNo valid arguments given, use 'gdrive help' to see available commands\n./gdrive-linux-x64 -c ~/tmp --service-account service_account.json about\nNo valid arguments given, use 'gdrive help' to see available commands. ",
    "mintsoft": "This absolutely just tripped me up too; @prasmussen do you have any plans when new builds (especially windows!) will be available?. This absolutely just tripped me up too; @prasmussen do you have any plans when new builds (especially windows!) will be available?. ",
    "hnykda": "Wow, this is confusing! It seems that raspberry pi build doesn't work with --service-account as well. Why there is no warning in README?! I spent an hour trying to make it work to find out it is not present in the binary...\n$ ./gdrive-linux-rpi -c /tmp --service-account \"creds.json\" about\nthrows:\nNo valid arguments given, use 'gdrive help' to see available commands\n. Wow, this is confusing! It seems that raspberry pi build doesn't work with --service-account as well. Why there is no warning in README?! I spent an hour trying to make it work to find out it is not present in the binary...\n$ ./gdrive-linux-rpi -c /tmp --service-account \"creds.json\" about\nthrows:\nNo valid arguments given, use 'gdrive help' to see available commands\n. ",
    "AronNovak": "Actually it's not that complex to compile the binary, I compiled one for Linux x64 (to be able to download it to an older distro, without recent Go)\ngdrive-linux-x64.zip\nOtherwise +1 for the new release, it would be needed.\n. Actually it's not that complex to compile the binary, I compiled one for Linux x64 (to be able to download it to an older distro, without recent Go)\ngdrive-linux-x64.zip\nOtherwise +1 for the new release, it would be needed.\n. ",
    "mattpr": "Another example of this issue...  \nThe issue seems to come from listing all the remote files and trying to find the first parent path for each.  https://github.com/prasmussen/gdrive/blob/master/drive/sync.go#L219\nThe file was already uploaded by gdrive in the past but it was moved into a different folder after the scripted gdrive upload.   \ngdrive info \"fileId\" does return result for the file in question as well as its parent.  It is just the sync code that is having trouble.\nOne thing I noticed... gdrive info returns a ViewUrl of form: https://drive.google.com/a/[ga-domain] for the file in question, however for the parent it returns a ViewUrl of form https://drive.google.com/drive/ (ie without the GoogleApps domain).  Not sure if it is relevant or just a difference between view urls for folders and files on google drive.\n```bash\nls -1 scanner_upload\nauslage\nother-documents\npaid-invoices\nunpaid-invoices\nls -1 scanner_upload/paid-invoices/\n2017-02-02 - Hotel Alte Post - Rechnung.pdf\n2017-02-18 - Bahn - Bahncard Losch.pdf\n2017-02-24 - BMW - R\u00fcckstand.pdf\ngdrive  --refresh-token \"[token]\" info \"0B1HLIFeM7hsRY05xMGdIR3cyNm8\"\nId: 0B1HLIFeM7hsRY05xMGdIR3cyNm8\nName: scanner_incoming\nPath: scanner_incoming\nMime: application/vnd.google-apps.folder\nCreated: 2017-02-20 18:47:14\nModified: 2017-03-01 09:45:18\nShared: True\nParents: 0AFHLIFeM7hsRUk9PVA\nViewUrl: https://drive.google.com/drive/folders/0B1HLIFeM7hsRY05xMGdIR3cyNm8\ngdrive --refresh-token \"[token]\" sync upload \"scanner_upload\" \"0B1HLIFeM7hsRY05xMGdIR3cyNm8\"\nStarting sync...\nCollecting local and remote file information...\nCould not find parent of 0B1HLIFeM7hsRMzNiWG5fY3RETGc (2017-02-24 - BMW - R\u00fcckstand.pdf)\ngdrive  --refresh-token \"[token]\" info \"0B1HLIFeM7hsRMzNiWG5fY3RETGc\"\nId: 0B1HLIFeM7hsRMzNiWG5fY3RETGc\nName: 2017-02-24 - BMW - R\u00fcckstand.pdf\nPath: Rechnungsverwaltung 2017/RG Eingang/02 Februar 2017/2017-02-24 - BMW - R\u00fcckstand.pdf\nMime: application/pdf\nSize: 865.1 KB\nCreated: 2017-03-01 09:11:23\nModified: 2017-03-01 09:11:23\nMd5sum: 6bdc2625b56958278692026623c0543f\nShared: True\nParents: 0BylfOx0NAyx4UHdJVFJLUi1ZLU0\nViewUrl: https://drive.google.com/a/[ga-domain]/file/d/0B1HLIFeM7hsRMzNiWG5fY3RETGc/view?usp=drivesdk\nDownloadUrl: https://drive.google.com/a/[ga-domain]/uc?id=0B1HLIFeM7hsRMzNiWG5fY3RETGc&export=download\ngdrive  --refresh-token \"[token]\" info \"0BylfOx0NAyx4UHdJVFJLUi1ZLU0\"\nId: 0BylfOx0NAyx4UHdJVFJLUi1ZLU0\nName: 02 Februar 2017\nPath: Rechnungsverwaltung 2017/RG Eingang/02 Februar 2017\nMime: application/vnd.google-apps.folder\nCreated: 2017-01-04 16:02:58\nModified: 2017-01-04 16:02:58\nShared: True\nParents: 0BylfOx0NAyx4b0xDSzhGSWlMdm8\nViewUrl: https://drive.google.com/drive/folders/0BylfOx0NAyx4UHdJVFJLUi1ZLU0\n```\n. @gabrielsors it could be.  I ran a couple more tests and that hypothesis seems to hold.  \nMy primary theory is that this relates to folder ownership and moving files into folders owned by other users.  \nGiven the number of open issues I may just have to dust off my go and figure out why the referenced bit of code doesn't find that object id when gdrive info does find it.  But this is a minor issue for me and so it might be a while before I get a chance.. Another example of this issue...  \nThe issue seems to come from listing all the remote files and trying to find the first parent path for each.  https://github.com/prasmussen/gdrive/blob/master/drive/sync.go#L219\nThe file was already uploaded by gdrive in the past but it was moved into a different folder after the scripted gdrive upload.   \ngdrive info \"fileId\" does return result for the file in question as well as its parent.  It is just the sync code that is having trouble.\nOne thing I noticed... gdrive info returns a ViewUrl of form: https://drive.google.com/a/[ga-domain] for the file in question, however for the parent it returns a ViewUrl of form https://drive.google.com/drive/ (ie without the GoogleApps domain).  Not sure if it is relevant or just a difference between view urls for folders and files on google drive.\n```bash\nls -1 scanner_upload\nauslage\nother-documents\npaid-invoices\nunpaid-invoices\nls -1 scanner_upload/paid-invoices/\n2017-02-02 - Hotel Alte Post - Rechnung.pdf\n2017-02-18 - Bahn - Bahncard Losch.pdf\n2017-02-24 - BMW - R\u00fcckstand.pdf\ngdrive  --refresh-token \"[token]\" info \"0B1HLIFeM7hsRY05xMGdIR3cyNm8\"\nId: 0B1HLIFeM7hsRY05xMGdIR3cyNm8\nName: scanner_incoming\nPath: scanner_incoming\nMime: application/vnd.google-apps.folder\nCreated: 2017-02-20 18:47:14\nModified: 2017-03-01 09:45:18\nShared: True\nParents: 0AFHLIFeM7hsRUk9PVA\nViewUrl: https://drive.google.com/drive/folders/0B1HLIFeM7hsRY05xMGdIR3cyNm8\ngdrive --refresh-token \"[token]\" sync upload \"scanner_upload\" \"0B1HLIFeM7hsRY05xMGdIR3cyNm8\"\nStarting sync...\nCollecting local and remote file information...\nCould not find parent of 0B1HLIFeM7hsRMzNiWG5fY3RETGc (2017-02-24 - BMW - R\u00fcckstand.pdf)\ngdrive  --refresh-token \"[token]\" info \"0B1HLIFeM7hsRMzNiWG5fY3RETGc\"\nId: 0B1HLIFeM7hsRMzNiWG5fY3RETGc\nName: 2017-02-24 - BMW - R\u00fcckstand.pdf\nPath: Rechnungsverwaltung 2017/RG Eingang/02 Februar 2017/2017-02-24 - BMW - R\u00fcckstand.pdf\nMime: application/pdf\nSize: 865.1 KB\nCreated: 2017-03-01 09:11:23\nModified: 2017-03-01 09:11:23\nMd5sum: 6bdc2625b56958278692026623c0543f\nShared: True\nParents: 0BylfOx0NAyx4UHdJVFJLUi1ZLU0\nViewUrl: https://drive.google.com/a/[ga-domain]/file/d/0B1HLIFeM7hsRMzNiWG5fY3RETGc/view?usp=drivesdk\nDownloadUrl: https://drive.google.com/a/[ga-domain]/uc?id=0B1HLIFeM7hsRMzNiWG5fY3RETGc&export=download\ngdrive  --refresh-token \"[token]\" info \"0BylfOx0NAyx4UHdJVFJLUi1ZLU0\"\nId: 0BylfOx0NAyx4UHdJVFJLUi1ZLU0\nName: 02 Februar 2017\nPath: Rechnungsverwaltung 2017/RG Eingang/02 Februar 2017\nMime: application/vnd.google-apps.folder\nCreated: 2017-01-04 16:02:58\nModified: 2017-01-04 16:02:58\nShared: True\nParents: 0BylfOx0NAyx4b0xDSzhGSWlMdm8\nViewUrl: https://drive.google.com/drive/folders/0BylfOx0NAyx4UHdJVFJLUi1ZLU0\n```\n. @gabrielsors it could be.  I ran a couple more tests and that hypothesis seems to hold.  \nMy primary theory is that this relates to folder ownership and moving files into folders owned by other users.  \nGiven the number of open issues I may just have to dust off my go and figure out why the referenced bit of code doesn't find that object id when gdrive info does find it.  But this is a minor issue for me and so it might be a while before I get a chance.. ",
    "NorbiPeti": "After figuring the code out I think the issue is that the moved folder still has the \"syncRootId\" property set to the sync directory, but since it was moved from there, gdrive cannot find the moved folder in the sync folder - while the query reports the moved folder as well.\ngdrive list --query \"appProperties has {key='syncRootId' and value='<sync root dir id>'}\" reports the moved folder and that query is used for getting the file list for the sync download as well. Since the moved folder's parent isn't in the sync directory, it's not picked up, therefore it can't find it.\n. @fabzo I'm getting  Is '', but should be non existant or empty (with an empty ID) for each of my files outside the synced folder it looks like while applying the fix. Other than that it seems to work in my case as well. Thanks for posting it. \ud83d\ude1b . After figuring the code out I think the issue is that the moved folder still has the \"syncRootId\" property set to the sync directory, but since it was moved from there, gdrive cannot find the moved folder in the sync folder - while the query reports the moved folder as well.\ngdrive list --query \"appProperties has {key='syncRootId' and value='<sync root dir id>'}\" reports the moved folder and that query is used for getting the file list for the sync download as well. Since the moved folder's parent isn't in the sync directory, it's not picked up, therefore it can't find it.\n. @fabzo I'm getting  Is '', but should be non existant or empty (with an empty ID) for each of my files outside the synced folder it looks like while applying the fix. Other than that it seems to work in my case as well. Thanks for posting it. \ud83d\ude1b . ",
    "j0e1in": "Any update on this? Does this mean we can't move synced files to another folder?. Any update on this? Does this mean we can't move synced files to another folder?. ",
    "carmenates09": "I have the same Issue, I need help.\n`user@server:~/backups$ /home/user/backups/src/gdrive-linux-x64 sync upload /tmp/backups/201706021656/ ...my_google_folder_id...\nStarting sync... \nCollecting local and remote file information... \nFile ...google_folder_id... does not have exacly one parent`\nThe error become when I delete a folders inside my folder (my-id) on google drive, but I need delete folders on google drive (remote) and the gdrive continue sync.\nJose Carlos Ramos Carmenates. I have the same Issue, I need help.\n`user@server:~/backups$ /home/user/backups/src/gdrive-linux-x64 sync upload /tmp/backups/201706021656/ ...my_google_folder_id...\nStarting sync... \nCollecting local and remote file information... \nFile ...google_folder_id... does not have exacly one parent`\nThe error become when I delete a folders inside my folder (my-id) on google drive, but I need delete folders on google drive (remote) and the gdrive continue sync.\nJose Carlos Ramos Carmenates. ",
    "fabzo": "I've run into a similar problem when manually creating a directory on google drive and moving an already synced folder into the newly created one.\nIt resulted in a hierarchy similar to this:\n- syncRoot\n- - folder1 [syncRootId: 'of syncRoot']\n- - - folder2 [syncRootId: 'missing']\n- - - - folder3 [syncRootId: 'of syncRoot']\nWhich lead gdrive to report that it could not find the parent of folder3, since it was not obtained using the query mentioned by @NorbiPeti .\nI created a little function that builds a list of all files in a given syncRoot and adds the syncRootId to all of them. Similarly it will set the syncRootId to \"\" on all other files that have it set but are not in the syncRoot.\nSee this branch comparison. I just hacked it together as a quick fix for myself. But maybe this could be helpful/interesting with a little bit of cleanup and testing.\nOr maybe there is another way for gdrive to keep track of the syncDir files/folders? I have not yet worked with the google drive API apart from this little hack. But it seems that the syncRootId is used for efficiency reasons and is not strictly required?\nThe problem mentioned by @carmenates09 seems to have another cause and is not related to the misplaced syncRootId. As far as I understand...\nUpdate: Well I would say further testing is indeed needed. As it seems that i missed something which resulted in some files no longer being in the sync root ;-). I've run into a similar problem when manually creating a directory on google drive and moving an already synced folder into the newly created one.\nIt resulted in a hierarchy similar to this:\n- syncRoot\n- - folder1 [syncRootId: 'of syncRoot']\n- - - folder2 [syncRootId: 'missing']\n- - - - folder3 [syncRootId: 'of syncRoot']\nWhich lead gdrive to report that it could not find the parent of folder3, since it was not obtained using the query mentioned by @NorbiPeti .\nI created a little function that builds a list of all files in a given syncRoot and adds the syncRootId to all of them. Similarly it will set the syncRootId to \"\" on all other files that have it set but are not in the syncRoot.\nSee this branch comparison. I just hacked it together as a quick fix for myself. But maybe this could be helpful/interesting with a little bit of cleanup and testing.\nOr maybe there is another way for gdrive to keep track of the syncDir files/folders? I have not yet worked with the google drive API apart from this little hack. But it seems that the syncRootId is used for efficiency reasons and is not strictly required?\nThe problem mentioned by @carmenates09 seems to have another cause and is not related to the misplaced syncRootId. As far as I understand...\nUpdate: Well I would say further testing is indeed needed. As it seems that i missed something which resulted in some files no longer being in the sync root ;-). ",
    "tinti": "Removing the file_cache.json file solved the problem for me.\nMaybe the cache handler is missing some points.. Removing the file_cache.json file solved the problem for me.\nMaybe the cache handler is missing some points.. ",
    "animesh": "Having the same issue, but while push-ing changes... . Having the same issue, but while push-ing changes... . ",
    "anpar": "Same for me, only while pulling.. Same for me, only while pulling.. ",
    "cfbao": "I'm having a similar problem, and I believe the reason is that gdrive doesn't check if a file is trashed. All files that are in this folder, even if they're already in trash, are downloaded.. I'm having a similar problem, and I believe the reason is that gdrive doesn't check if a file is trashed. All files that are in this folder, even if they're already in trash, are downloaded.. ",
    "zbycz": "Try gdrive --config . list\nSee readme:\n\nThis will create a token file inside the .gdrive folder in your home directory. Note that anyone with access to this file will also have access to your google drive. If you want to manage multiple drives you can use the global --config flag or set the environment variable GDRIVE_CONFIG_DIR. . Try gdrive --config . list\n\nSee readme:\n\nThis will create a token file inside the .gdrive folder in your home directory. Note that anyone with access to this file will also have access to your google drive. If you want to manage multiple drives you can use the global --config flag or set the environment variable GDRIVE_CONFIG_DIR. . \n",
    "mccbala": "True. I assumed it might've been done in consideration to the hardware\ncapabilities of Pi. All other downloads happen in full speed through wget &\ncurl.\nI'm running the latest Raspbian Jessie Lite on RPi2. Ethernet connection.\nIs there a way I can find out some debug info on this? A verbose mode or a\nlog file that I could post here?\nOn Jan 19, 2017 7:51 AM, \"chuanzgh\" notifications@github.com wrote:\n\nI don't see the purpose and benefits of intentionally limiting the speed\nfor a particular platform? If you're using the vanilla version of the pi\n(i.e. you did not do any mods to the networking on the pi), it's more\nlikely that you've hit some sort of hardware speed cap on the pi itself.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/prasmussen/gdrive/issues/250#issuecomment-273663623,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABXaukUpfoteqv3FOD_B9uCfb6ZACGx-ks5rTsiTgaJpZM4LnNj-\n.\n. True. I assumed it might've been done in consideration to the hardware\ncapabilities of Pi. All other downloads happen in full speed through wget &\ncurl.\n\nI'm running the latest Raspbian Jessie Lite on RPi2. Ethernet connection.\nIs there a way I can find out some debug info on this? A verbose mode or a\nlog file that I could post here?\nOn Jan 19, 2017 7:51 AM, \"chuanzgh\" notifications@github.com wrote:\n\nI don't see the purpose and benefits of intentionally limiting the speed\nfor a particular platform? If you're using the vanilla version of the pi\n(i.e. you did not do any mods to the networking on the pi), it's more\nlikely that you've hit some sort of hardware speed cap on the pi itself.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/prasmussen/gdrive/issues/250#issuecomment-273663623,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABXaukUpfoteqv3FOD_B9uCfb6ZACGx-ks5rTsiTgaJpZM4LnNj-\n.\n. \n",
    "earonesty": "One trick is to just:\nzip png_folder.zip .png\nand then upload the png_folder.zip   Google drive will stick all the images in a folder.. One trick is to just:\nzip png_folder.zip .png\nand then upload the png_folder.zip   Google drive will stick all the images in a folder.. ",
    "wiless": "@earonesty you mean Google drive will automatically unzip ??  . @earonesty you mean Google drive will automatically unzip ??  . ",
    "mark-burns": "I had a similar problem and finally got it to work. This may help others to make multiple calls sequentially. My script looks like this. I loop through the list of folders, escape spaces in folder names, create a command, and eval the command.\nfor f in /mnt/mydir/2011_*; do f1=$(echo $f | awk '{gsub(/ /,\"\\\\ \")}8'); mycmd=$(echo \"./gdrive upload -r -p 0B4Bt91bcVSCddFBZRUFxNEF5MGc $f1\"); eval \"$mycmd\"; done\n. I had a similar problem and finally got it to work. This may help others to make multiple calls sequentially. My script looks like this. I loop through the list of folders, escape spaces in folder names, create a command, and eval the command.\nfor f in /mnt/mydir/2011_*; do f1=$(echo $f | awk '{gsub(/ /,\"\\\\ \")}8'); mycmd=$(echo \"./gdrive upload -r -p 0B4Bt91bcVSCddFBZRUFxNEF5MGc $f1\"); eval \"$mycmd\"; done\n. ",
    "aryabhatt": "I am getting the same error.. +1 please add the feature. I am getting the same error.. +1 please add the feature. ",
    "EmmaSimon": "I was getting the same error, you can fix it with the patch from saaros's pull request until the devs accept it.. I was getting the same error, you can fix it with the patch from saaros's pull request until the devs accept it.. ",
    "demonguy": "I see. Thanks. And sorry for asking such noob question. I see. Thanks. And sorry for asking such noob question. ",
    "stevenjswanson": "+1  this would be very useful.. +1  this would be very useful.. ",
    "vitalidze": "+1 for this feature. +1 for this feature. ",
    "davidvered": "+1 for this too. +1 for this too. ",
    "bethsheets": "+1 would greatly appreciate this feature. +1 would greatly appreciate this feature. ",
    "aleb": "Duplicate of https://github.com/prasmussen/gdrive/pull/257. Duplicate of https://github.com/prasmussen/gdrive/pull/257. ",
    "gnumoksha": "Hi. You can try this:\nuntil gdrive sync upload test_dir 0B1cVgeaJyIeKMUI5NkpncHA3aGM; do sleep 10s; done\nIt's means: until gdrive sync upload test_dir 0B1cVgeaJyIeKMUI5NkpncHA3aGM command returns success, it will stand by for 10 seconds and will try again.\nI've tested this in bash 4.4.5 and zsh 5.3.. Hi. You can try this:\nuntil gdrive sync upload test_dir 0B1cVgeaJyIeKMUI5NkpncHA3aGM; do sleep 10s; done\nIt's means: until gdrive sync upload test_dir 0B1cVgeaJyIeKMUI5NkpncHA3aGM command returns success, it will stand by for 10 seconds and will try again.\nI've tested this in bash 4.4.5 and zsh 5.3.. ",
    "Zuescho": "Would you have an idear how i could do this on windows, i'm trying right now to get the Linux Subystem under Win10 to run gdrive but i'm making no real progress.. Okay, i managed to get it run \nuntil ./gdrive sync upload /mnt/e/TestDoUntil 0B4F7TsQGANMfN0tKcWtHZkR6ejA; do sleep 10s; done\nIt then stops at \nStarting sync...\nCollecting local and remote file information...\nFound 4 local files and 0 remote files\n4 remote files are missing\n[0001/0004] Uploading 1.jpg -> UntilTest/1.jpg\nI can upload and download files normaly which suprised me.\nUpdate:\nFor some reason i can not Upload from /mnt/e/TestDoUntil\nOkay this i have no idear at this point, i can Upload what i download and what i create in /mnt/c/gdrive but any files i add there i have no chance of uploading.. Progress, \nPost https://www.googleapis.com/upload/drive/v3/files?alt=json&fields=id%2Cname%2Csize%2Cmd5Checksum%2CwebContentLink&uploadType=multipart: EOF\nThis seems have to do with size, i can upload files that are for example 71.1 KB but if i try anthing to big it takes a really long time and then throws this error.\nInteresting enough on my Win10 Machine everything gets uploaded without problems.. Would you have an idear how i could do this on windows, i'm trying right now to get the Linux Subystem under Win10 to run gdrive but i'm making no real progress.. Okay, i managed to get it run \nuntil ./gdrive sync upload /mnt/e/TestDoUntil 0B4F7TsQGANMfN0tKcWtHZkR6ejA; do sleep 10s; done\nIt then stops at \nStarting sync...\nCollecting local and remote file information...\nFound 4 local files and 0 remote files\n4 remote files are missing\n[0001/0004] Uploading 1.jpg -> UntilTest/1.jpg\nI can upload and download files normaly which suprised me.\nUpdate:\nFor some reason i can not Upload from /mnt/e/TestDoUntil\nOkay this i have no idear at this point, i can Upload what i download and what i create in /mnt/c/gdrive but any files i add there i have no chance of uploading.. Progress, \nPost https://www.googleapis.com/upload/drive/v3/files?alt=json&fields=id%2Cname%2Csize%2Cmd5Checksum%2CwebContentLink&uploadType=multipart: EOF\nThis seems have to do with size, i can upload files that are for example 71.1 KB but if i try anthing to big it takes a really long time and then throws this error.\nInteresting enough on my Win10 Machine everything gets uploaded without problems.. ",
    "Stayingfalse": "To add a bit of context this is the very rudimentary output cron script I have at the moment that runs the sync then removes everything from the src dir but there is no real error handling or processing and I am fairly certain it would be much cleaner as part of gdrive.\ngdrive sync upload \\\n        --keep-local \\\n                /Media/nas/Videos/ \\\n                0ByFen5bqfRmUR1pfbDAzbE5xaFU \\\n        && rm -r /Media/nas/Videos/*. Just realised this is possible when uploading individual files but not with sync. Issue with uploading individual files is I need to retain file structure above the parent which i think would be difficult to automate,. To add a bit of context this is the very rudimentary output cron script I have at the moment that runs the sync then removes everything from the src dir but there is no real error handling or processing and I am fairly certain it would be much cleaner as part of gdrive.\ngdrive sync upload \\\n        --keep-local \\\n                /Media/nas/Videos/ \\\n                0ByFen5bqfRmUR1pfbDAzbE5xaFU \\\n        && rm -r /Media/nas/Videos/*. Just realised this is possible when uploading individual files but not with sync. Issue with uploading individual files is I need to retain file structure above the parent which i think would be difficult to automate,. ",
    "mikan01": "This works for me:\ngdrive sync upload --keep-remote /root/tmp/ 0B5vfyxn3rCe-ZU1ubmVaWU53S3M && \nrm -rf /root/tmp/*`. This works for me:\ngdrive sync upload --keep-remote /root/tmp/ 0B5vfyxn3rCe-ZU1ubmVaWU53S3M && \nrm -rf /root/tmp/*`. ",
    "andrewdbate": "@Selektion You said that it was a permission error in the referenced issue. Can you confirm that this is the case?. @Selektion You said that it was a permission error in the referenced issue. Can you confirm that this is the case?. ",
    "pro99128": "I have the same problem.\nThis is my bash script\n```\n!/usr/bin/env bash\n/usr/local/bin/gdrive -c ~/.gdrive list >  /var/www/myweb/list.txt\n```\nThis is my cron\n10 12 * * * root /var/www/myweb/list.sh\nWhen I executed the command directly, it worked but. But it didn't work using cron\nCan anybody help?. I have the same problem.\nThis is my bash script\n```\n!/usr/bin/env bash\n/usr/local/bin/gdrive -c ~/.gdrive list >  /var/www/myweb/list.txt\n```\nThis is my cron\n10 12 * * * root /var/www/myweb/list.sh\nWhen I executed the command directly, it worked but. But it didn't work using cron\nCan anybody help?. ",
    "oncul": "there is a solution on this issue #151 . there is a solution on this issue #151 . ",
    "mxdpeep": "Used: 97.4 GB\nFree: -97386482878.0 B\nTotal: \nMax upload size: 5.2 TB\n. Used: 97.4 GB\nFree: -97386482878.0 B\nTotal: \nMax upload size: 5.2 TB\n. ",
    "wfeiereisen": "I have also had this same problem. From the google documentation, they have apparently set a daily limit. If directly using their API, they have suggestions about how to fix it, but I do not know how to fix it through gdrive. Suggestions? My problem would be solved if there were a gdrive option to zip and then download. Feature request?. Yes, up to maybe 3000 small (400kb) files at a time. This is output from a Raspberry Pi camera that is watching a birds nest. Each file is pushed individually to Google Drive during the day. The mass download of each day's files happens through:\nsystem(\"/usr/local/bin/gdrive download query -f \\\"name contains '$query_name' and name contains 'jpg'\\\";\");\nI'd let Google zip them and send one file if I could, but I don't know how.. I have also had this same problem. From the google documentation, they have apparently set a daily limit. If directly using their API, they have suggestions about how to fix it, but I do not know how to fix it through gdrive. Suggestions? My problem would be solved if there were a gdrive option to zip and then download. Feature request?. Yes, up to maybe 3000 small (400kb) files at a time. This is output from a Raspberry Pi camera that is watching a birds nest. Each file is pushed individually to Google Drive during the day. The mass download of each day's files happens through:\nsystem(\"/usr/local/bin/gdrive download query -f \\\"name contains '$query_name' and name contains 'jpg'\\\";\");\nI'd let Google zip them and send one file if I could, but I don't know how.. ",
    "cnrting": "problem +1 when try to upload a directory containing a lot of files,500+ i suppose.. problem +1 when try to upload a directory containing a lot of files,500+ i suppose.. ",
    "jstray": "I eventually \"solved\" this by moving to rclone. Using the -v option to print additional debug reveals that rclone implements exponential backoff when it encounters rate limits, and this enables it to complete successfully.. I eventually \"solved\" this by moving to rclone. Using the -v option to print additional debug reveals that rclone implements exponential backoff when it encounters rate limits, and this enables it to complete successfully.. ",
    "martinbrook": "Affected here also with upload of hundreds of smallish 1-10MB files,. Looks like sync up/down has code to handle the rate limit.\nJust needs adding to non-sync up/download?\nhttps://github.com/prasmussen/gdrive/commit/bdd7877be9c503e7968c221f3396d239edb267d2. Affected here also with upload of hundreds of smallish 1-10MB files,. Looks like sync up/down has code to handle the rate limit.\nJust needs adding to non-sync up/download?\nhttps://github.com/prasmussen/gdrive/commit/bdd7877be9c503e7968c221f3396d239edb267d2. ",
    "k0d3r3d": "+1 uploading lots of files I got a ratelimit error , I am using powershell to trigger gdrive, so upon the error i told it to wait for a bit then retry the same file transfer, in my preliminary testing seems to work around the error. . Does anyone have the windows version compiled? \n. +1 uploading lots of files I got a ratelimit error , I am using powershell to trigger gdrive, so upon the error i told it to wait for a bit then retry the same file transfer, in my preliminary testing seems to work around the error. . Does anyone have the windows version compiled? \n. ",
    "bogdan-calapod": "+1 - Same problem here. +1 - Same problem here. ",
    "euklid": "Hi there, I only implemented a fix for the download and download query sub commands, see PR #309. \nI think you can use the same approach for the other sub commands.\nTBH, I'm only using this tool to download a large set of files from a public Google drive and thus I had not looked into the sync/upload and other features. Feel free to rip off my code to use it for fixes in the other parts that need exponential back off. See #132 \nI just opened a pull request because I encountered the same problem and thus I just learnt Go for this purpose ;) @EverMineServer If you only need to use the download or download query command, then you should be able to use the code in my branch, but no promises until it's actually merged. @jucor probably you can take a look at my PR #309 and try to apply the same changes for the upload. I'm not using this program any more (only needed it for exactly one occasion for downloading...) and currently don't have time to apply similar changes to the other parts of the program. At least the download did work for me then, when I was downloading over 2000 files.. @prasmussen please review, this seems to be a much sought after feature.... Hi there, I only implemented a fix for the download and download query sub commands, see PR #309. \nI think you can use the same approach for the other sub commands.\nTBH, I'm only using this tool to download a large set of files from a public Google drive and thus I had not looked into the sync/upload and other features. Feel free to rip off my code to use it for fixes in the other parts that need exponential back off. See #132 \nI just opened a pull request because I encountered the same problem and thus I just learnt Go for this purpose ;) @EverMineServer If you only need to use the download or download query command, then you should be able to use the code in my branch, but no promises until it's actually merged. @jucor probably you can take a look at my PR #309 and try to apply the same changes for the upload. I'm not using this program any more (only needed it for exactly one occasion for downloading...) and currently don't have time to apply similar changes to the other parts of the program. At least the download did work for me then, when I was downloading over 2000 files.. @prasmussen please review, this seems to be a much sought after feature.... ",
    "boomsbloom": "You have to delete the old token and then add a new one:\nhttps://github.com/prasmussen/gdrive/issues/158\nor adding multiple users is addressed here:\nhttps://github.com/prasmussen/gdrive/issues/156. You have to delete the old token and then add a new one:\nhttps://github.com/prasmussen/gdrive/issues/158\nor adding multiple users is addressed here:\nhttps://github.com/prasmussen/gdrive/issues/156. ",
    "mikecarr": "wrong application, sorry. wrong application, sorry. ",
    "kamikazechaser": "This is a much needed feature.. This is a much needed feature.. ",
    "sanm22": "Hi Team,\nI am also facing the same issue.\nWhen I try to use a Service Account, I get this message:\nNo valid arguments given, use 'gdrive help' to see available commands\nCommand:\n./gdrive --service-account \"gdriveReporting-b3a818de89ee.json\"  list\nI'm using the linus x64 build, v2.1.0.\nAny examples on how to use it?\nThanks.. Hi Team,\nI am also facing the same issue.\nWhen I try to use a Service Account, I get this message:\nNo valid arguments given, use 'gdrive help' to see available commands\nCommand:\n./gdrive --service-account \"gdriveReporting-b3a818de89ee.json\"  list\nI'm using the linus x64 build, v2.1.0.\nAny examples on how to use it?\nThanks.. ",
    "maxx1e": "Looks like, no, as it is still not working. Looks like, no, as it is still not working. ",
    "divamgupta": "Sometimes HTML is returned from google's server and that is downloaded. . Sometimes HTML is returned from google's server and that is downloaded. . ",
    "robertbarrett": "If you're getting plaintext HTML, it means you're not using the right URL. I see this commonly with sourceforge, if someone wgets the download page link, instead of the direct link.. If you're getting plaintext HTML, it means you're not using the right URL. I see this commonly with sourceforge, if someone wgets the download page link, instead of the direct link.. ",
    "zimbatm": "\nMake sure that the client follows HTTP redirects. For example with curl, add the -L option. wget follows redirects by default.\nMake sure to quote the URL in the shell, some shells treat & as the background operator which means part of the URL is missing.\n\nExample:\ncurl -fLo gdrive \"https://docs.google.com/uc?id=0B3X9GlR6EmbnQ0FtZmJJUXEyRTA&export=download\". 1. Make sure that the client follows HTTP redirects. For example with curl, add the -L option. wget follows redirects by default.\n2. Make sure to quote the URL in the shell, some shells treat & as the background operator which means part of the URL is missing.\nExample:\ncurl -fLo gdrive \"https://docs.google.com/uc?id=0B3X9GlR6EmbnQ0FtZmJJUXEyRTA&export=download\". ",
    "slhck": "Could this be added to the installation instructions?. Could this be added to the installation instructions?. ",
    "jucor": "You can find the id of the folder by searching for it with:\ngdrive list -q \"name contains 'seaweedFS'\"\nSyntax for possible queries:  https://developers.google.com/drive/v3/web/search-parameters.. I'm having the same problem, when \"gdrive upload --recursive\" a directory containing 2000 small files totally a measly 8 MB.. You can find the id of the folder by searching for it with:\ngdrive list -q \"name contains 'seaweedFS'\"\nSyntax for possible queries:  https://developers.google.com/drive/v3/web/search-parameters.. I'm having the same problem, when \"gdrive upload --recursive\" a directory containing 2000 small files totally a measly 8 MB.. ",
    "y3nd": "So how you did this ?. So how you did this ?. ",
    "subrahmanyamags": "did anyone do this yet?. below will allow you to reconfigure the user id.\ngdrive --config . list . did anyone do this yet?. below will allow you to reconfigure the user id.\ngdrive --config . list . ",
    "jedkirby": "I didn't find a proper solution to this issue but, I did implement exponential backoff, which, has fixed the issue, for now.\nI'm closing this ticket as it's no longer needed.. I didn't find a proper solution to this issue but, I did implement exponential backoff, which, has fixed the issue, for now.\nI'm closing this ticket as it's no longer needed.. ",
    "kanhaic": "This is something I would be very interested in. let me know if you have a repo setup we can collaborate.. This is something I would be very interested in. let me know if you have a repo setup we can collaborate.. ",
    "hernandanielg": "I only have this PR #304 . Hello @prasmussen can you please take a look at this? \nRegards.. I only have this PR #304 . Hello @prasmussen can you please take a look at this? \nRegards.. ",
    "shellac": "I think the command ought to be:\ngdrive import --mime 'text/csv' sample.csv # Edit - sorry, import not upload\nImported [ID] with mime type: 'application/vnd.google-apps.spreadsheet'\nHowever that isn't working for me - I get a text document. I wonder whether it ought to be using application/vnd.openxmlformats-officedocument.spreadsheetml.sheet, which has worked for me using the API directly.. For anyone else having issues with this here is (sort of) a work around.\n\nCreate an empty sheet.\nGet the ID of the sheet (e.g. list contents of drive, or look at url bar).\nUpdate the sheet with your CSV (gdrive update SHEET_ID my.csv).\n\nHowever it's far from perfect (I'm using a service account, for example).\nThis python code works, so I suspect gdrive is at fault:\nfrom oauth2client.service_account import ServiceAccountCredentials\nfrom googleapiclient.discovery import build\nfrom googleapiclient.http import MediaFileUpload\nimport httplib2\n\nscopes = ['https://www.googleapis.com/auth/drive']\n\ncredentials = ServiceAccountCredentials.from_json_keyfile_name(\n    'etc/credentials.json', scopes)\n\nhttp = httplib2.Http()\nhttp = credentials.authorize(http)\n\ndrive_service = build(\"drive\", \"v3\", http=http)\n\nfile_metadata = {\n  'name' : 'Test Sheet',\n  'mimeType' : 'application/vnd.google-apps.spreadsheet',\n  'parents' : []\n}\n\nmedia = MediaFileUpload('test.csv',\n                    mimetype='text/csv',\n                    resumable=True)\n\nfile = drive_service.files().create(body=file_metadata,\n                                media_body=media,\n                                fields='id').execute()\n\n. I think the command ought to be:\ngdrive import --mime 'text/csv' sample.csv # Edit - sorry, import not upload\nImported [ID] with mime type: 'application/vnd.google-apps.spreadsheet'\nHowever that isn't working for me - I get a text document. I wonder whether it ought to be using application/vnd.openxmlformats-officedocument.spreadsheetml.sheet, which has worked for me using the API directly.. For anyone else having issues with this here is (sort of) a work around.\n\nCreate an empty sheet.\nGet the ID of the sheet (e.g. list contents of drive, or look at url bar).\nUpdate the sheet with your CSV (gdrive update SHEET_ID my.csv).\n\nHowever it's far from perfect (I'm using a service account, for example).\nThis python code works, so I suspect gdrive is at fault:\nfrom oauth2client.service_account import ServiceAccountCredentials\nfrom googleapiclient.discovery import build\nfrom googleapiclient.http import MediaFileUpload\nimport httplib2\n\nscopes = ['https://www.googleapis.com/auth/drive']\n\ncredentials = ServiceAccountCredentials.from_json_keyfile_name(\n    'etc/credentials.json', scopes)\n\nhttp = httplib2.Http()\nhttp = credentials.authorize(http)\n\ndrive_service = build(\"drive\", \"v3\", http=http)\n\nfile_metadata = {\n  'name' : 'Test Sheet',\n  'mimeType' : 'application/vnd.google-apps.spreadsheet',\n  'parents' : []\n}\n\nmedia = MediaFileUpload('test.csv',\n                    mimetype='text/csv',\n                    resumable=True)\n\nfile = drive_service.files().create(body=file_metadata,\n                                media_body=media,\n                                fields='id').execute()\n\n. ",
    "demidovakatya": "Same problem here.. Same problem here.. ",
    "karunasaxena": "Thanks. It might be a good temporary solution if it works.\nFor time being, this methodology can be referred either by using gdrive or by using any other free extension say \"Sheetgo\". Sorry about that. Thanks. It might be a good temporary solution if it works.\nFor time being, this methodology can be referred either by using gdrive or by using any other free extension say \"Sheetgo\". Sorry about that. ",
    "patbiber": "You need to request for higher Limits on the Google API.\nOver the Google Drive API on the Google Cloud Platform.. You need to request for higher Limits on the Google API.\nOver the Google Drive API on the Google Cloud Platform.. ",
    "spierepf": "I think you might be using an old version of go. When I upgraded from 1.3 to 1.9 I stopped getting the math/bits error.. I think you might be using an old version of go. When I upgraded from 1.3 to 1.9 I stopped getting the math/bits error.. ",
    "h1rule": "Can you also do it for upload?. Can you also do it for upload?. ",
    "webdevr712": "not sure what the deal was here, but a work around i found, was strangely enough, was to use IE browser instead of chrome.  Crazy I know, but access token window/tab stays open.\n. not sure what the deal was here, but a work around i found, was strangely enough, was to use IE browser instead of chrome.  Crazy I know, but access token window/tab stays open.\n. ",
    "musimate": "The magic words are \"service accounts\". Learn something new every day. :) Closing this. . The magic words are \"service accounts\". Learn something new every day. :) Closing this. . ",
    "ewwink": "delete %appdata%\\.gdrive\\token_v2.json. delete %appdata%\\.gdrive\\token_v2.json. ",
    "SwistakPL": "Thx. Thx. ",
    "prbs57": "I ran into the exact same issue with Team Drive. Please help!. @pekatete, when I try to upload using that syntax:\ngdrive upload --parent 0B<> --name tmp.sh ./tmp.sh \nFailed to get file: googleapi: Error 404: File not found: 0B<>., notFound\ngdrive mkdir -p 0B<> tempo\nFailed to create directory: googleapi: Error 404: File not found: 0B<>., notFound\nAre you able to work with team drive? Did you have to do any special setup or config/variable?. @pekatete, I have been using gdrive with regular google drive directory without a problem. It's only when I try to use team-drive that I run into the errors above. \nDuring setup, we get to authenticate and 'allow' the app to access one's google drive. There doesn't seem to be any distinction between regular drive and team drive when at this step of authenticating. Wonder how it'll identify team drive. . I ran into the exact same issue with Team Drive. Please help!. @pekatete, when I try to upload using that syntax:\ngdrive upload --parent 0B<> --name tmp.sh ./tmp.sh \nFailed to get file: googleapi: Error 404: File not found: 0B<>., notFound\ngdrive mkdir -p 0B<> tempo\nFailed to create directory: googleapi: Error 404: File not found: 0B<>., notFound\nAre you able to work with team drive? Did you have to do any special setup or config/variable?. @pekatete, I have been using gdrive with regular google drive directory without a problem. It's only when I try to use team-drive that I run into the errors above. \nDuring setup, we get to authenticate and 'allow' the app to access one's google drive. There doesn't seem to be any distinction between regular drive and team drive when at this step of authenticating. Wonder how it'll identify team drive. . ",
    "pekatete": "Try\ngdrive upload --parent 0B_XXXXXXXXXXXXXXXXXXXX --name file ./file. You probably don't have permissions to write in the .gdrive directory (resides in your home directory on Linux) which is strange or you did not run the setup command before trying to upload (it sets up the .gdrive directory).\nDid you run the first command as described in the README on the home page? Check if you have a directory named .gdrive\nedit:\nNo have not used it with team drive, just personal google drive. Also about the File not found, can you try by providing the full path name (or simply the name of the file if you are invoking from the directory where the file resides)? e.g\ngdrive upload --parent 0B<> --name tmp.sh /home/mine/tmp.sh\nor\ngdrive upload --parent 0B<> --name tmp.sh tmp.sh\nDo you get the --parent value value via the ./gdrive list command just before invoking? . Try\ngdrive upload --parent 0B_XXXXXXXXXXXXXXXXXXXX --name file ./file. You probably don't have permissions to write in the .gdrive directory (resides in your home directory on Linux) which is strange or you did not run the setup command before trying to upload (it sets up the .gdrive directory).\nDid you run the first command as described in the README on the home page? Check if you have a directory named .gdrive\nedit:\nNo have not used it with team drive, just personal google drive. Also about the File not found, can you try by providing the full path name (or simply the name of the file if you are invoking from the directory where the file resides)? e.g\ngdrive upload --parent 0B<> --name tmp.sh /home/mine/tmp.sh\nor\ngdrive upload --parent 0B<> --name tmp.sh tmp.sh\nDo you get the --parent value value via the ./gdrive list command just before invoking? . ",
    "dzg": "OK, I see, you have to share list first to get the IDs.\nThanks. OK, I see, you have to share list first to get the IDs.\nThanks. ",
    "Binomi0": "On Linux, configuration files are created on/home/$user/.gdrive/..... Hi, if you mean to change google user to another one you can try this:\ncd /home/$user/.gdrive/ && rm *\nand then: ./gdrive about again and it will prompt you to insert the new code for the new account.\nHope it helps!. On Linux, configuration files are created on/home/$user/.gdrive/..... Hi, if you mean to change google user to another one you can try this:\ncd /home/$user/.gdrive/ && rm *\nand then: ./gdrive about again and it will prompt you to insert the new code for the new account.\nHope it helps!. ",
    "ScrimForever": "I used tcpdump -n dst host 172.217.30.10 and no have any dropped packet. Someone can help me ?\n. I used tcpdump -n dst host 172.217.30.10 and no have any dropped packet. Someone can help me ?\n. ",
    "Du-St": "@tleesentons Hi, you can list just files/folders using query condition mimeType = 'application/vnd.google-apps.folder' for folders and mimeType != 'application/vnd.google-apps.folder' for files (see docs for more https://developers.google.com/drive/v3/web/search-parameters).\nRecursion - I am afraid that is the nature of the GDrive to list all files and folders by default (owned by you or shared to you) and just filter what you need or not.. @lewisxy Hi, it is possible using additional --query option like this: -q \"'root' in parents and 'me' in owners. It returns only files/folders without parent folder and owned by you (which is quite important because of files/folders shared to you by your colleagues).. Hi,\nI have added the possibility to impersonate (connect as another user) when connecting using service account.\nThe key change is setting the Subject property of the jwt.Config type.. @tleesentons Hi, you can list just files/folders using query condition mimeType = 'application/vnd.google-apps.folder' for folders and mimeType != 'application/vnd.google-apps.folder' for files (see docs for more https://developers.google.com/drive/v3/web/search-parameters).\nRecursion - I am afraid that is the nature of the GDrive to list all files and folders by default (owned by you or shared to you) and just filter what you need or not.. @lewisxy Hi, it is possible using additional --query option like this: -q \"'root' in parents and 'me' in owners. It returns only files/folders without parent folder and owned by you (which is quite important because of files/folders shared to you by your colleagues).. Hi,\nI have added the possibility to impersonate (connect as another user) when connecting using service account.\nThe key change is setting the Subject property of the jwt.Config type.. ",
    "sb98052": "Submitting updated version.. Submitting updated version.. ",
    "chrift": "Sorry, I have realised my mistake.. Sorry, I have realised my mistake.. ",
    "johnhcc": "As a follow on, attempting to force the download with gdrive download -r -f <folderID> results in the file with trashed descendants being downloaded multiple times, each of which immediately overwriting the next.\nA temporary workaround seems to be to use the GUI to empty the trash before using gdrive download -r <folderID>.  Of course, oftentimes emptying the trash isn't desirable.. As a follow on, attempting to force the download with gdrive download -r -f <folderID> results in the file with trashed descendants being downloaded multiple times, each of which immediately overwriting the next.\nA temporary workaround seems to be to use the GUI to empty the trash before using gdrive download -r <folderID>.  Of course, oftentimes emptying the trash isn't desirable.. ",
    "garrytre": "garrytre, the OP again.\nIt seems I can update an existing file in google drive's 'root' directory, 'My Drive', but not in a subdir.\ngarry@pianoX16:~$ gdrive update 0B8XS-SUhC1o5dmg5TjNmTVhHTjQ   /media/seg/GRaSP/weather/WaterConnectProject/accumulator/ArcoonaBluffAccumulator\nUploading /media/seg/GRaSP/weather/WaterConnectProject/accumulator/ArcoonaBluffAccumulator\nUpdated 0B8XS-SUhC1o5dmg5TjNmTVhHTjQ at 2.9 KB/s, total 5.5 KB\ngarry@pianoX16:~$ gdrive update -p 0B8XS-SUhC1o5RGtrYW5Zb1VlVHc    0B8XS-SUhC1o5ZVB1MF9tVmh6NlU   /media/seg/GRaSP/weather/WaterConnectProject/accumulator/ArcoonaBluffAccumulator\nUploading /media/seg/GRaSP/weather/WaterConnectProject/accumulator/ArcoonaBluffAccumulator\nFailed to upload file: googleapi: Error 403: The parents field is not directly writable in update requests. Use the addParents and removeParents parameters instead., fieldNotWritable\nSo\nIs this my incompetence on display?\nIs this a bug to be fixed?\nIs it a limitation, can't be fixed? If so, is it possible that the doc page https://github.com/prasmussen/gdrive \"Update file, this creates a new revision of the file\" has \"only possible for root dir\" added?. garrytre, the OP again.\nIt seems I can update an existing file in google drive's 'root' directory, 'My Drive', but not in a subdir.\ngarry@pianoX16:~$ gdrive update 0B8XS-SUhC1o5dmg5TjNmTVhHTjQ   /media/seg/GRaSP/weather/WaterConnectProject/accumulator/ArcoonaBluffAccumulator\nUploading /media/seg/GRaSP/weather/WaterConnectProject/accumulator/ArcoonaBluffAccumulator\nUpdated 0B8XS-SUhC1o5dmg5TjNmTVhHTjQ at 2.9 KB/s, total 5.5 KB\ngarry@pianoX16:~$ gdrive update -p 0B8XS-SUhC1o5RGtrYW5Zb1VlVHc    0B8XS-SUhC1o5ZVB1MF9tVmh6NlU   /media/seg/GRaSP/weather/WaterConnectProject/accumulator/ArcoonaBluffAccumulator\nUploading /media/seg/GRaSP/weather/WaterConnectProject/accumulator/ArcoonaBluffAccumulator\nFailed to upload file: googleapi: Error 403: The parents field is not directly writable in update requests. Use the addParents and removeParents parameters instead., fieldNotWritable\nSo\nIs this my incompetence on display?\nIs this a bug to be fixed?\nIs it a limitation, can't be fixed? If so, is it possible that the doc page https://github.com/prasmussen/gdrive \"Update file, this creates a new revision of the file\" has \"only possible for root dir\" added?. ",
    "VirenMohindra": "If i wasn't clear enough, there should be a condition to check for unlimited storage devices and return something else instead of subtracting 0 from the total amount used.\nRefer to \nhttps://github.com/prasmussen/gdrive/blob/9e8d2cd027c72b2364026dc32cd4ca5494d922d9/drive/about.go#L25\nNot sure if the Gdrive API permits checking for these kinds of edge cases though.. Works perfectly with the gdrive --config . about command when used on a normal (not unlimited) account.\nUser: User_Name, xyz@gmail.com\nUsed: 2.5 GB\nFree: 15.8 GB\nTotal: 18.3 GB\nMax upload size: 5.2 TB. If i wasn't clear enough, there should be a condition to check for unlimited storage devices and return something else instead of subtracting 0 from the total amount used.\nRefer to \nhttps://github.com/prasmussen/gdrive/blob/9e8d2cd027c72b2364026dc32cd4ca5494d922d9/drive/about.go#L25\nNot sure if the Gdrive API permits checking for these kinds of edge cases though.. Works perfectly with the gdrive --config . about command when used on a normal (not unlimited) account.\nUser: User_Name, xyz@gmail.com\nUsed: 2.5 GB\nFree: 15.8 GB\nTotal: 18.3 GB\nMax upload size: 5.2 TB. ",
    "elliott-beach": "@dominion66 Could you just chmod 777 the token file to make it accessible to the root user? \n. I realized the problem is the root user expects the token file in a different directory.\nUse the flag --config /home/<you>/.gdrive and it should work.. @spierepf This should be possible by altering the permissions token you give to gdrive. If you gave an upload-only token, gdrive couldn't modify files in google drive. This would cause the CLI to fail with non-user-friendly errors when you attempted to do write operations, but it would work to prevent them from occurring.\nCode to be modified would be the part that brings up the authentication bag in google when the cli is installed - doesn't sound that difficult!. It looks like the Great Firewall https://www.quora.com/Can-I-use-Google-drive-in-China.\nThis doesn't look like an issue that a commit on gdrive would solve.. @postyr \nI don't think this is possible using gdrive. I'm in the process of forking this project at https://github.com/e-beach/gdrive, would you be interested if I implemented this feature as a flag?. @unim21 Could you do\nfor f in *files_I_want.csv; do gdrive upload --parent <folderId> $f; done\ngdrive apparently doesn't support uploading multiple files.. Does the bash for loop not work? That should allow uploading multiple files. Also, this project isn\u2019t maintained, so no fixes :P\nThere are also some other projects that do the same thing: I\u2019d research what rclone provides.. 1) That link is definitely not gdrive1.\n2) Your question does not describe what you want to do.\nWhat do you want to do?. That\u2019s going to be a bash question, not really a question about gdrive because your shell, not gdrive, is what does the wildcard expansion.. @notaduck My previous comment was probably not helpful because I misinterpreted your question, but I don't think it's possible to do what you're asking. It would also be convoluted to implement.\n. @dominion66 Could you just chmod 777 the token file to make it accessible to the root user? \n. I realized the problem is the root user expects the token file in a different directory.\nUse the flag --config /home/<you>/.gdrive and it should work.. @spierepf This should be possible by altering the permissions token you give to gdrive. If you gave an upload-only token, gdrive couldn't modify files in google drive. This would cause the CLI to fail with non-user-friendly errors when you attempted to do write operations, but it would work to prevent them from occurring.\nCode to be modified would be the part that brings up the authentication bag in google when the cli is installed - doesn't sound that difficult!. It looks like the Great Firewall https://www.quora.com/Can-I-use-Google-drive-in-China.\nThis doesn't look like an issue that a commit on gdrive would solve.. @postyr \nI don't think this is possible using gdrive. I'm in the process of forking this project at https://github.com/e-beach/gdrive, would you be interested if I implemented this feature as a flag?. @unim21 Could you do\nfor f in *files_I_want.csv; do gdrive upload --parent <folderId> $f; done\ngdrive apparently doesn't support uploading multiple files.. Does the bash for loop not work? That should allow uploading multiple files. Also, this project isn\u2019t maintained, so no fixes :P\nThere are also some other projects that do the same thing: I\u2019d research what rclone provides.. 1) That link is definitely not gdrive1.\n2) Your question does not describe what you want to do.\nWhat do you want to do?. That\u2019s going to be a bash question, not really a question about gdrive because your shell, not gdrive, is what does the wildcard expansion.. @notaduck My previous comment was probably not helpful because I misinterpreted your question, but I don't think it's possible to do what you're asking. It would also be convoluted to implement.\n. ",
    "dominion66": "Thanks, I gave it a try and got the same responses as before running from CRON.  Running the same command outside of CRON works fine.. That did the trick and works beautifully.  Thanks so Much!. Thanks, I gave it a try and got the same responses as before running from CRON.  Running the same command outside of CRON works fine.. That did the trick and works beautifully.  Thanks so Much!. ",
    "Vywh": "This doesn't make sense, I've used proxy server.\n262\n\nProgress,\nPost https://www.googleapis.com/upload/drive/v3/files?alt=json&fields=id%2Cname%2Csize%2Cmd5Checksum%2CwebContentLink&uploadType=multipart: EOF\nThis seems have to do with size, i can upload files that are for example 71.1 KB but if i try anthing to big it takes a really long time and then throws this error.\n\nOthers had also encountered this problem.. This doesn't make sense, I've used proxy server.\n262\n\nProgress,\nPost https://www.googleapis.com/upload/drive/v3/files?alt=json&fields=id%2Cname%2Csize%2Cmd5Checksum%2CwebContentLink&uploadType=multipart: EOF\nThis seems have to do with size, i can upload files that are for example 71.1 KB but if i try anthing to big it takes a really long time and then throws this error.\n\nOthers had also encountered this problem.. ",
    "trcyprkr": "So is there a fix possibly forthcoming to this issue?  Seems this should be a fundamental task.  Also, i want to cd into a particular director and 'list' files in that directory.  Cant seem to make it happen.. So is there a fix possibly forthcoming to this issue?  Seems this should be a fundamental task.  Also, i want to cd into a particular director and 'list' files in that directory.  Cant seem to make it happen.. ",
    "unim21": "The for loop does work for this particular scenario, however the other problem I am running into is the uploading of duplicate files.  \nFor instance, I need one file with a static name, e.g. \"staticFile.csv\", and it's backups for the last 7 days uploaded into a directory.  Since my script runs every 15 minutes, \"staticFile.csv\" and it's backups get duplicated on the upload.  I haven't found a way to tell gdrive to ignore duplicates, so for the time being I'm using another cmd-line app located here https://github.com/odeke-em/drive\nIt's a bit more difficult to setup and requires Go dependencies to be installed, but it's much more robust and offers a broader range of functionality.  Regardless, it took me forever to setup on Ubuntu 14.04 and actually get it working properly.  \nGdrive would be a much better alternative for the current project I am working on if there was a workaround for the issue with duplicate files getting uploaded into drive.\n. The for loop does work for this particular scenario, however the other problem I am running into is the uploading of duplicate files.  \nFor instance, I need one file with a static name, e.g. \"staticFile.csv\", and it's backups for the last 7 days uploaded into a directory.  Since my script runs every 15 minutes, \"staticFile.csv\" and it's backups get duplicated on the upload.  I haven't found a way to tell gdrive to ignore duplicates, so for the time being I'm using another cmd-line app located here https://github.com/odeke-em/drive\nIt's a bit more difficult to setup and requires Go dependencies to be installed, but it's much more robust and offers a broader range of functionality.  Regardless, it took me forever to setup on Ubuntu 14.04 and actually get it working properly.  \nGdrive would be a much better alternative for the current project I am working on if there was a workaround for the issue with duplicate files getting uploaded into drive.\n. ",
    "cryoguy": "get it working with gdrive2\n(defvar gdocs-folder-id \"0B************\"\n  \"location for storing org to gdocs exported files, use 'gdrive list  -t <foldername>' to find the id\")\n(defun gdoc-export-buffer ()\n  \"Export current buffer as google doc to folder identified by gdocs-folder-id\"\n  (interactive)\n  (shell-command\n   (format \"gdrive upload --mime text/plain --parent %s %s\"\n       gdocs-folder-id buffer-file-name))). get it working with gdrive2\n(defvar gdocs-folder-id \"0B************\"\n  \"location for storing org to gdocs exported files, use 'gdrive list  -t <foldername>' to find the id\")\n(defun gdoc-export-buffer ()\n  \"Export current buffer as google doc to folder identified by gdocs-folder-id\"\n  (interactive)\n  (shell-command\n   (format \"gdrive upload --mime text/plain --parent %s %s\"\n       gdocs-folder-id buffer-file-name))). ",
    "notaduck": "Fair enough, but still a big thank your time!\n. Fair enough, but still a big thank your time!\n. ",
    "crobertwatson": "Never mind. It was a path problem with the crontab. I added proper paths and got it working.. Never mind. It was a path problem with the crontab. I added proper paths and got it working.. "
}