{
    "rbpark": "Thanks for the patch. It's a good find and I'll merge it in.\nI'll be also adding a new 'null' check before that because it's just good style to handle null cases.\n. There's no patches. I can make those changes in my next checkin.\n. Set retries= and retry.backoff=\n. Set lockdown.create.projects=true in azkaban.properties. Then only those users who have a Role containing the permission CREATEPROJECTS can create projects.\n. Added. Post multipart must have a valid session id:\nsession.id=, ajax=upload,project=,file=\nResponse will be projectName and version #.\n. Thanks for submitting this readme fix.\n. Turns out the default was 3 days. Set it back to one.\n. Completely removed EhCache. Wrote my own.\n. Refactored the FlowRunner to be simpler and in distinct stages preventing the issue of queued jobs not being properly handled in a restart situation.\n. Sorry, looks like we didn't make that file public. Please try it out now.\nThanks,\n-Richard\nOn Wed, May 15, 2013 at 10:29 AM, puluanau notifications@github.com wrote:\n\nlooks like a standard 403 from S3 to me... Just an FYI, thanks for the\nwork on the new site, looks awesome.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/issues/14\n.\n. In the config file, you can specify the default timezone which is how PDT is displayed. Is there different functionality that you'd like?\n. Ok. That's a bug. We'll put that on my issues list.\n\nOn Tue, May 21, 2013 at 12:05 PM, dstreit notifications@github.com wrote:\n\nIn conf/azkaban.properties:\ndefault.timezone.id=America/Chicago\nIn the UI when I schedule a job the two time zone choices are PDT/UTC (it\nlooks like that's hardcoded in scheduleoptionspanel.vm). If I schedule the\njob to run at 2:00PM PDT it shows up in the schedule job list as set to run\nat 16:00:00. Obviously I need to only schedule jobs using UTC.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/issues/19#issuecomment-18231545\n.\n. Merging the patch. Please fix the noted pieces of code.\n. Thanks for fixing this.\n. There are several way to fix this. One is to add the hadoop-core jar to the\nazkaban classpath. You can also add the hadoop-core jar to the extlib dir\nin the viewer plugin directory and add the following line to the\nplugin.properties:\n\nviewer.external.classpaths=extlib/hadoop-core-1.0.4.jar\nOf course change the hadoop jar to the version you're using.\nOn Thu, Jul 18, 2013 at 11:25 AM, Patricio Echague <notifications@github.com\n\nwrote:\nRan into this exception when trying to set up the hdfs viewer.\nVersion: Azkaban 2.1 (web server, executor and plugin)\nException in thread \"main\" java.lang.NoClassDefFoundError:\norg/apache/hadoop/security/AccessControlException\nat java.lang.Class.getDeclaredConstructors0(Native Method)\nat java.lang.Class.privateGetDeclaredConstructors(Class.java:2389)\nat java.lang.Class.getConstructor0(Class.java:2699)\nat java.lang.Class.getConstructor(Class.java:1657)\nat\nazkaban.webapp.AzkabanWebServer.loadViewerPlugins(AzkabanWebServer.java:585)\nat azkaban.webapp.AzkabanWebServer.main(AzkabanWebServer.java:446)\nCaused by: java.lang.ClassNotFoundException:\norg.apache.hadoop.security.AccessControlException\nat java.net.URLClassLoader$1.run(URLClassLoader.java:202)\nat java.security.AccessController.doPrivileged(Native Method)\nat java.net.URLClassLoader.findClass(URLClassLoader.java:190)\nat java.lang.ClassLoader.loadClass(ClassLoader.java:306)\nat java.lang.ClassLoader.loadClass(ClassLoader.java:247)\n... 6 more\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/issues/25\n.\n. Not in 2.1. However the code in trunk has the ability to turn off ssh and\ngo in unsecure mode.\n\nOn Wed, Jul 24, 2013 at 10:05 PM, Xiaofei Wang notifications@github.comwrote:\n\nhow disable jetty ssh ?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/issues/26\n.\n. There seems to be a bug in the Web Server. Have you bounced the web server\nto see if it picks up the correct status?\n\nOn Mon, Jul 29, 2013 at 3:15 AM, polaris2013 notifications@github.comwrote:\n\nthe issue happened when executing the flow, as a result, runningFlows at\nwebserver side( see ExecutorManager ) never remove the execId for its\nstatus is always stuck in \"preparing\" , then logically it goes to\ncallExecutorServer rather than retrieve log from DB, however,\ncallExecutorServer throws \"flow not found\" exception because the flow has\nalready been removed from runningflow at server side after the execution\nhas finished successfully at executorServer,\nI don't know whether the above issue is a bug or a known issue, but it has\nconfused me for nearly a week, i don't think it's a deploy or install\nissuer, i feel maybe sth need to be changed,\nI really really need someone to help me solve this issue ASAP, contact me\nat whuims.yuanju.page@gmail.com or mobile +086- 13916450206\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/issues/28\n.\n. Whoops empty message.\nThe web server keeps a copy of the executing flow for display purpose and\nto try to catch failures from dead executor servers. However, we found on\nseveral (very rare) occasions, the updater thread may die.\n\nWe've done a lot of fixes in trunk that may have fixed it, but we'll be\nadding more monitoring soon.\nOn Tue, Jul 30, 2013 at 12:06 AM, Richard Park richard.b.park@gmail.comwrote:\n\nOn Mon, Jul 29, 2013 at 7:19 PM, polaris2013 notifications@github.comwrote:\n\nu're right , if i i restart the web server, the status changed to\nsucceed, is this because when restart, the flow is forced to finalize? the\nflow is not in runningflows, so can retrieve it from db. but i can not\nrestart for every task i submit, is there a way to solve this bug? and the\nfirebug keeps showing \"flow not found exception\" when web server frequently\najax fetch executable Logs .\n[image: 2013-07-30 10 12 23]https://f.cloud.github.com/assets/5111899/876181/ddff8728-f8bd-11e2-98c2-a4b267ad5dfd.png\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/issues/28#issuecomment-21765576\n.\n. That error is interestingly weird, since the NoSuchMethodError occurred\nwith java.util.List. The version of Java we use is 1.6.  As far as I know,\nthe api hasn't changed since 1.5 and should work with 1.7.\n\n\nDoes the Error give you a line number?\nOn Tue, Jul 30, 2013 at 1:56 AM, polaris2013 notifications@github.comwrote:\n\nattached is the debug info:\nExecutorManagerUpdaterThread java.lang.NoSuchMethodError :\nazkaban.executor.ExecutorManager.access$2(Lazkaban/executor/ExecutorManager;\nLjava/util/List;Ljava/util/List;Ljava/util/List)\n2013/7/30 jujumao whuims.yuanju.page@gmail.com\n\nhi, Richard\nvery appreciate for your insight in azkaban , I also notice a\nexception in a update thread, do u mean that thread died?\nWhy cause the exception? and most important how to solve it ?\n2013/7/30 rbpark notifications@github.com\n\nWhoops empty message.\nThe web server keeps a copy of the executing flow for display purpose\nand\nto try to catch failures from dead executor servers. However, we found\non\nseveral (very rare) occasions, the updater thread may die.\nWe've done a lot of fixes in trunk that may have fixed it, but we'll be\nadding more monitoring soon.\nOn Tue, Jul 30, 2013 at 12:06 AM, Richard Park \nrichard.b.park@gmail.comwrote:\n\nOn Mon, Jul 29, 2013 at 7:19 PM, polaris2013 \nnotifications@github.comwrote:\n\nu're right , if i i restart the web server, the status changed to\nsucceed, is this because when restart, the flow is forced to\nfinalize?\nthe\nflow is not in runningflows, so can retrieve it from db. but i can\nnot\nrestart for every task i submit, is there a way to solve this bug?\nand\nthe\nfirebug keeps showing \"flow not found exception\" when web server\nfrequently\najax fetch executable Logs .\n[image: 2013-07-30 10 12 23]<\n\n\nhttps://f.cloud.github.com/assets/5111899/876181/ddff8728-f8bd-11e2-98c2-a4b267ad5dfd.png>\n\n\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/azkaban/azkaban2/issues/28#issuecomment-21765576>\n.\n\n\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/azkaban/azkaban2/issues/28#issuecomment-21773282>\n.\n\n\nSincerely yours\nYuan JU\nMaster of Information Science,Wuhan Univ\nTel 86-13916450206\nEmail whuims.yuanju.page@gmail.com whuims.yuanju.page@gmail.com\n\n\nSincerely yours\nYuan JU\nMaster of Information Science,Wuhan Univ\nTel 86-13916450206\nEmail whuims.yuanju.page@gmail.com whuims.yuanju.page@gmail.com\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/issues/28#issuecomment-21777742\n.\n. What version of Java are you using?\n\nOn Tue, Jul 30, 2013 at 6:49 AM, polaris2013 notifications@github.comwrote:\n\ni think the line number is 610\nmore information are provided :\n2013/07/30 21:43:43.498 +0800 INFO [ExecutorManager] [Azkaban] printing\nexecutor Host:localhost executor Port: 12321\n2013/07/30 21:43:43.501 +0800 INFO [ExecutorManager] [Azkaban] jujumao\nexecuting Manager started\n*Exception in thread \"ExecutorManagerUpdaterThread\"\njava.lang.NoSuchMethodError:\nazkaban.executor.ExecutorManager.access$2(Lazkaban/executor/ExecutorManager;Ljava/util/List;Ljava/util/List;Ljava/util/List;)V\nat\nazkaban.executor.ExecutorManager$ExecutingManagerUpdaterThread.run(ExecutorManager.java:610)\n*\n2013/07/30 21:43:43.502 +0800 INFO [ExecutorManager] [Azkaban] Cleaning\nold\nlogs from execution_logs\n2013/07/30 21:43:43.516 +0800 INFO [JdbcSLALoader] [Azkaban] Loading all\nSLAs from db.\n2013/07/30 21:43:43.548 +0800 INFO [JdbcSLALoader] [Azkaban] Loading all\nSLAs from db.\n2013/7/30 rbpark notifications@github.com\n\nThat error is interestingly weird, since the NoSuchMethodError occurred\nwith java.util.List. The version of Java we use is 1.6. As far as I\nknow,\nthe api hasn't changed since 1.5 and should work with 1.7.\nDoes the Error give you a line number?\nOn Tue, Jul 30, 2013 at 1:56 AM, polaris2013 notifications@github.comwrote:\n\nattached is the debug info:\nExecutorManagerUpdaterThread java.lang.NoSuchMethodError :\n\nazkaban.executor.ExecutorManager.access$2(Lazkaban/executor/ExecutorManager;\n\nLjava/util/List;Ljava/util/List;Ljava/util/List)\n2013/7/30 jujumao whuims.yuanju.page@gmail.com\n\nhi, Richard\nvery appreciate for your insight in azkaban , I also notice a\nexception in a update thread, do u mean that thread died?\nWhy cause the exception? and most important how to solve it ?\n2013/7/30 rbpark notifications@github.com\n\nWhoops empty message.\nThe web server keeps a copy of the executing flow for display\npurpose\nand\nto try to catch failures from dead executor servers. However, we\nfound\non\nseveral (very rare) occasions, the updater thread may die.\nWe've done a lot of fixes in trunk that may have fixed it, but\nwe'll\nbe\nadding more monitoring soon.\nOn Tue, Jul 30, 2013 at 12:06 AM, Richard Park \nrichard.b.park@gmail.comwrote:\n\nOn Mon, Jul 29, 2013 at 7:19 PM, polaris2013 \nnotifications@github.comwrote:\n\nu're right , if i i restart the web server, the status changed\nto\nsucceed, is this because when restart, the flow is forced to\nfinalize?\nthe\nflow is not in runningflows, so can retrieve it from db. but i\ncan\nnot\nrestart for every task i submit, is there a way to solve this\nbug?\nand\nthe\nfirebug keeps showing \"flow not found exception\" when web server\nfrequently\najax fetch executable Logs .\n[image: 2013-07-30 10 12 23]<\n\n\n\n\n\nhttps://f.cloud.github.com/assets/5111899/876181/ddff8728-f8bd-11e2-98c2-a4b267ad5dfd.png>\n\n\n\n\n\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/azkaban/azkaban2/issues/28#issuecomment-21765576>\n.\n\n\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/azkaban/azkaban2/issues/28#issuecomment-21773282>\n.\n\n\nSincerely yours\nYuan JU\nMaster of Information Science,Wuhan Univ\nTel 86-13916450206\nEmail whuims.yuanju.page@gmail.com whuims.yuanju.page@gmail.com\n\n\nSincerely yours\nYuan JU\nMaster of Information Science,Wuhan Univ\nTel 86-13916450206\nEmail whuims.yuanju.page@gmail.com whuims.yuanju.page@gmail.com\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/azkaban/azkaban2/issues/28#issuecomment-21777742>\n.\n\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/azkaban/azkaban2/issues/28#issuecomment-21779992>\n.\n\n\nSincerely yours\nYuan JU\nMaster of Information Science,Wuhan Univ\nTel 86-13916450206\nEmail whuims.yuanju.page@gmail.com whuims.yuanju.page@gmail.com\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/issues/28#issuecomment-21791790\n.\n. Can you attach the job logs instead of the flow logs?\n\nOn Thu, Aug 1, 2013 at 4:49 PM, lance-apx notifications@github.com wrote:\n\nInstalled 2.1 release of web, executor and plugin-types.\nTried command.zip downloaded from github site.\nIt has three commands. The executor only ran the first two.\nThe job file has a typo for the last command entry:\ntype=command\ncommand=echo \"hello\"\ncommand.1=echo \"This is how one runs a command job\"\ncomnand.2=whoami\ncom-N-and rather than com-M-and\nThis is the log:\n01-08-2013 16:39:07 PDT command INFO - Running execid:1 flow:command\nproject:2 version:1\n01-08-2013 16:39:07 PDT command INFO - Update active reference\n01-08-2013 16:39:07 PDT command INFO - Updating initial flow directory.\n01-08-2013 16:39:07 PDT command INFO - Fetching job and shared properties.\n01-08-2013 16:39:07 PDT command INFO - Starting flows\n01-08-2013 16:39:07 PDT command INFO - Submitting job command to run.\n01-08-2013 16:39:07 PDT command INFO - Job Finished command with status\nSUCCEEDED\n01-08-2013 16:39:07 PDT command INFO - Job command had output props.\n01-08-2013 16:39:07 PDT command INFO - Finishing up flow. Awaiting\nTermination\n01-08-2013 16:39:07 PDT command INFO - Flow is set to SUCCEEDED\n01-08-2013 16:39:07 PDT command INFO - Setting end time for flow 1 to\n1375400347232\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/issues/30\n.\n. Have you tried changing the failure option?\n\nBy default the failure option is set to finish the current running job and\nfail immediately. If job4 failed before job3 could finish, than everything\nwould immediately be killed after that.\nHowever, you can set the failure option to finish all possible jobs...\nwhich will run your flow up until it cannot go any further.\nIf that doesn't work, than it is indeed a bug we'll need to fix.\nOn Tue, Sep 3, 2013 at 2:42 AM, wowgeeker notifications@github.com wrote:\n\nRecently I deployed an azkaban system, and it is really awesome. But a bug\nappeared yesterday nigtht. I have tested it on my local computer, and the\nbug is for sure there.\nI tested the bug with some python jobs, as shown in the image in the\nattachment, job2,job3,job5 were just some python code, with\ntime.sleep(seconds), and job4 was intended to fail because i raised an\nhard-coded exception in it.\nWhen the flow began, job2 and job4 would be executed very quickly and\nafter 5 seconds ,job3 would began. When it came to job5, it will be killed\nbecause the system assumed the job2 was failed.\nof course, we do not want it that way. job5 should be launched because its\nparents were all successfully executed.\n[image: bug]https://f.cloud.github.com/assets/2759358/1071717/255f2120-147d-11e3-83e4-90201ab0f961.png\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/issues/37\n.\n. We use smtp for emails. The package we use com.sun.mail.smtp.SMTPTransport.\n\nThe properties we set are:\nmail.smtp.host\nmail.user\nmain.password\nOne thing to note is that mail.protocal.auth is set to true by default. I\ndon't know why it is, but maybe that's what is preventing the sending of\nemails?\nOn Mon, Oct 7, 2013 at 8:17 PM, zuopujun notifications@github.com wrote:\n\ncom.sun.mail.smtp.SMTPSendFailedException: 530 5.7.0 Must issue a STARTTLS\ncommand first. dk3sm36522188pbc.32 - gsmtp\nat com.sun.mail.smtp.SMTPTransport.issueSendCommand(SMTPTransport.java:2114)\nat com.sun.mail.smtp.SMTPTransport.mailFrom(SMTPTransport.java:1618)\nat com.sun.mail.smtp.SMTPTransport.sendMessage(SMTPTransport.java:1119)\nat azkaban.utils.EmailMessage.sendEmail(EmailMessage.java:170)\nat azkaban.executor.ExecutorMailer.sendSuccessEmail(ExecutorMailer.java:167)\nat azkaban.executor.ExecutorManager.finalizeFlows(ExecutorManager.java:725)\nat azkaban.executor.ExecutorManager.access$1000(ExecutorManager.java:52)\nmy property followed:\nmail settings\nmail.sender=...\nmail server to send job success/failure notifications to\nmail.smtp.starttls.enable=true\nmail.host=smtp.gmail.com\nmail.user=...\nmail.password=...\nmail.port=587\njob.failure.email=...\njob.success.email=zuopujun@gmail.com\nDid I set the properties wrong, looking forward to the answer.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/issues/51\n.\n. Sorry for the late reply. So instead of create two flows, create one that has multiple start nodes and multiple end nodes?\n. I may be misunderstanding the problem. However, if you click on Enable (without going to the submenu), can you not enable just that one job?\n. Looks good.\n. Fixes issue #137. Making sure that they're linked together.\n. Thanks! Merging.\n. Looks good. Merging.\n. Fixed\n. Only fixes a part of it. Stops selecting, but will have to pass the drag to the main svg navigation function. Will have to revisit.\n. Okay, looks good. The discussion of tabs vs spaces won't be resolved here (I'm for tabs, btw).\n\nNext time, any such changes should be committed in a separate build to keep track of diffs.\n. The change is good. We'll need to consider whitespace consistency in web resources in the near future. I'll wait for more reviews.\n. Looks good. Merging.\n. Okay nice. Merging.\n. Looks good, but didn't try it out. Where else were we using the graph-sidebar list that we needed this separation?\n. Simple enough change. Merging.\n. Nice. Wasn't even aware Less did that. Although, I guess it wouldn't be very useful if it didn't. Merging.\n. Merging\n. Most of the changes seem white-space based. The other changes look solid. Any objections to me merging?\n. Okay, merging\n. Lots of whitespace changes. This has more changes than I would've expected for just including an ant target.\n. Merging this in. Mainly because I'll probably get fed up soon and move to gradle.\n. Made all suggested changes. Can someone else merge this?\n. I would prefer all Hadoop and Hive stuff to be removed from the public start script. Keep these things indoors.\n. Merging for now. But lets file an issue to fix this problem.\n. Looks good otherwise. Merging.\n. Looks good to me.\n. Merging.\n. Yes. This is not 2.5. So yeah, lets stamp it.\nOn Wed, Mar 19, 2014 at 2:46 PM, David Z. Chen notifications@github.comwrote:\n\nLGTM!\nShould we stamp 2.5 as final first before merging this and have this be\npart of 2.6?\n\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/pull/209#issuecomment-38111096\n.\n. I've merged azkaban master\n. We can either fix ant, or drop ant support.\n\nWe followed gradle conventions for this.\nOn Tue, Apr 1, 2014 at 4:31 PM, Anthony Hsu notifications@github.comwrote:\n\nIf you build using \"ant\", the azkaban jar that is created does not include\nthe .vm files in src/main/resources/..., causing Velocity to complain it\ncannot find the .vm files when you start the Azkaban web server.\n\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/issues/214\n.\n. You are correct. Okay, sounds good.\n\nOn Tue, Apr 1, 2014 at 4:40 PM, Anthony Hsu notifications@github.comwrote:\n\nI fixed the problem in this pull request: #215https://github.com/azkaban/azkaban2/pull/215\nUntil we completely remove the Ant build files (build.xml), we should make\nsure they work to make it easier for other people to get up and running\nwith Azkaban.\n\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/issues/214#issuecomment-39273841\n.\n. I think this is a gradle dependency issue. Let me have a look.\n. Fixed build scripts wanna have another look?\nThanks,\n-Richard\n. Sadly they only have a few of the standard messages:\n500 for exceptions, 404 for missing paths, and 200 for success.\n\nHowever, it's still 2 more status codes than what currently is done.\n. Going to add the header comments\n. Okay headers committed.\n. Also this was branched off of my restli branch. When that branch is merged, this won't look as massive of change.\n. Right, documentation would be good.\nThe race condition shouldn't exist, because the JobTypePluginSet is filled\nseparately and only the swapped is synchronized. If a call to build Jobtype\nis invoked while an update happens, the old plugin set is used until the\nswap occurs.\nOn Wed, Apr 23, 2014 at 9:25 AM, Anthony Hsu notifications@github.comwrote:\n\nIn order to reload the jobtypes, you have to execute a curl command from\nthe Azkaban machine because the executor server ports are not exposed\npublically, right? It would be good to document instructions on how to\nreload the jobtype plugins without restarted the exec server, perhaps in\nthe Azkaban documentation.\nAlso, are there possible race conditions when reloading the jobtypes while\njobs are being launched?\nOtherwise, change looks good to me.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/pull/222#issuecomment-41182577\n.\n. Is this all good?\n. Nitpick. Boolean.TRUE is equal to the keyword 'true'. Any reason why we\nwant to use the constant rather than the primaries type?\n\nOn Wednesday, April 23, 2014, David Z. Chen notifications@github.com\nwrote:\n\nLooks good!\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/pull/223#issuecomment-41238021\n.\n. Looks good. Checking in.\n. Last hour and last day are common variables people tend to use for processing previous set of completed data chunks.\nAlthough it seems use-case specific to define these variables, we see a lot of people making hacky work-arounds to this issue.\n\nDoes anyone have an alternative suggestion to get the behaviour that Russ wants?\n. That's fairly bulky though. This would have to be added to most plugin types then.\n. Why is it better there than in the same place that current start date is applied?\nAlso, there's a difference with applying to a flow and applying to a job. If a flow crosses an hour or day barrier, than you may have inconsistency in a flow execution.\nHaving these variables would be powerful as variable replacements. However, maybe we can do something about their verbosity. Wonder if we can get away with azkaban.flow.one.week.back.day-1 or something.\n. No, that's not what I'm saying.\nFirst of all, these are more likely to be used in variable replacement. If he wants to use pig, why make him modify the pig plugin code for something that is commonly used? And if it's a part of the ProcessJob, I don't know what benefit we get over having it as a flow property?\nLast hour, day and week is a common use case. I'd argue that last month is probably not, but it is consistent. I agree that adding all these variables is a bit messy though. That's why I'm asking for suggestions.\n. The one thing I was arguing against is the slippery slope method of\nthinking. Adding these variables are messy, sure, but doesn't lead to the\nconclusion that it opens doors to the inclusion of more messy variables.\nWhat do you think of $() as a resolving variable type?\nOn Saturday, April 26, 2014, David Z. Chen notifications@github.com wrote:\n\nI agree. Another good option would be to support arithmetic operators in\nthe job files, which might be a good idea to consider since we are planning\nto add a flow DSL anyway.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/pull/224#issuecomment-41478872\n.\n. I've added a patch for property expressions. Hopefully this covers your use case.\nAwaiting review and merge.\n. Sure. $( expression). Variable replacement works so $(${day} - 1). Or nest\nexpressions in expressions.\n\nOn Wednesday, April 30, 2014, Russell Jurney notifications@github.com\nwrote:\n\nAwesome! I will pull at test. Can you summarize how it works briefly?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/pull/224#issuecomment-41844570\n.\n. Nice clean-up job on the rest of the gradle script.\nOtherwise, looks good. I'm assuming dust is a bit more difficult?\n. Haha. Wanna contribute that dust plugin to open-source? I'm sure the LinkedIn's team would be interested.\n. I've added a few more changes to fix some tests.\n\nOn Tue, Apr 29, 2014 at 12:28 PM, David Z. Chen notifications@github.comwrote:\n\nI've opened #227 https://github.com/azkaban/azkaban2/issues/227 for\nadding documentation.\nOtherwise, this looks good to me.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/pull/226#issuecomment-41721100\n.\n. Use IOUtils instead\n. Call close on stream\n. Use utc\n. cache directory should in properties.\n. BufferInputStream on every file inputstream\n. Change behaviour. Probably should do something here.\n. The criteria for orphan is any process that has the following:\n-A parent id equal to 1\n-'azkaban', but not 'Azkaban' in the command.\n\nIs this implication not too generic? Why can't this clean-up happen in the Azkaban process itself?\n. Azkaban should know when a process should be dead. Why can't it also check if the process is truly dead, log the error, and then do a SIGKILL on it? At least we'll have an idea of why and when the process may be orphaning, instead of running a script manually and not figuring out what the issue may be.\n. However, my main concern is that the conditions to determine whether azkaban process is orphaned is too general and may kill valid processes. It also may be easy to miss changing this script to account for future azkaban release.\nAt the minimum, it should print out the various suspected child orphans, and kill at our discretion.\n. I'll add a comment. This test is for the case where Azkaban will auto kill your job at the first sign of failure. This is why 'kill' doesn't need to be invoked.\n. Yup. Missed it.\n. Eclipse is being stupid.\n. What's with the formatting on this page? Are tabs this bad in Github?\n. I left it in as a transition phase and changed the source paths within it.\nWe can do an all or nothing approach too, and remove all traces of ant and\nivy.\nOn Wed, Mar 19, 2014 at 1:10 PM, David Z. Chen notifications@github.comwrote:\n\nIn build.xml:\n\n@@ -21,9 +21,9 @@\n   \n\nShouldn't build.xml be removed?\n\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/pull/209/files#r10769013\n.\n. Okay, will consider removing it. Will need to fix travis.\n. Actually, may leave it out for this release due to the travis failures. It should go into a new subsequent release.\n. I used out before... and then changed it. Will remove this line.\n. Good catch. Changing it.\n. Just followed patterns from others. Just read that it's not so useful. Will remove.\n. Ok. Let me not do it for now :p\n. Good catch.\nThe actual logging should not exists. It was there for testing purposes, which is why I just duplicated the method invocation.\n. Good point.\n. Yeah, not exactly in the Restli documentation. But needed to force it into Azkaban somehow.\n. Will do.\n. yeah. I think the idea is that upload could take a while so I wanted to close ASAP, but it's not really that bad.\n. Removed\n. Will do\n. Yup. See it.\n. k\n. K, greping through code for if( and for( to replace them\n. done\n. done\n. done\n. done\n. \n",
    "anykao": "Thanks.\n. ",
    "azkaban": "Thanks for finding this bug. It's been fixed and checked in.\n. ",
    "aNeutrino": "Looks like the path has been changed to:\nhttps://s3.amazonaws.com/azkaban2/azkaban-plugins/2.1/azkaban-hdfs-viewer-2.1.tar.gz\n. ",
    "itismewxg": "wonder if azkaban can provide the amazon s3 viewer plugin?\n. ",
    "dstreit": "This might be a separate Issue, but one UI change I'd like to see is have the schedule dialog show times in UTC and the localtime zone specified in the config file instead of UTC and PDT. \n. In conf/azkaban.properties:\ndefault.timezone.id=America/Chicago\nIn the UI when I schedule a job the two time zone choices are PDT/UTC (it looks like that's hardcoded in scheduleoptionspanel.vm). If I schedule the job to run at 2:00PM PDT it shows up in the schedule job list as set to run at 16:00:00. Obviously I need to only schedule jobs using UTC. \nThe \"nice to have\" would be for PDT to be replaced with CDT when the default.timezone.id is changed. If I get a chance this week I'll look more into the code to see what that would take. \n. ",
    "cjyu": "it should be fixed in the next release now.\n. We have this in the log as well. It seems transient and doesn't impact operations.\n. for release 2.1 and 2.2, hadoop-core jar and hadoop conf should be on azkaban classpath for both web server and executor server, and hadoop native library should be specified in azkaban jvm args.\nthe start script in 2.2 has been improved to reflect this.\n. if you config in azkaban.properties the following:\njetty.use.ssl=false\nit should disable ssl for jetty server.\n. Let us know if this is still a problem. I don't think it applies to other users.\n. \"com-N-and\" bears no meaning to command job type. It is ignored in this case.\n. I don't think we allow rest api other than uploading zip file. We will discuss this to see if we should implement the feature.\n. we have people upload zip file up to 1GB and never had any issue.\ni guess it is something else that is causing the issue.\n. Is there a sure way to repeat this problem?\nOn the other hand, schedule manager is going away. So likely \"won't fix\" for this.\n. it is fixed in later branches already. so I am not taking in this again.\nthanks for the help.\n. added to release 2.2.\nthanks pingpingdong.\n. Thanks, submitteddenied.\n. The example works in release 2.1\nIt is broken in release 2.2.\nThe reason is some people had circular definitions that sent azkaban into a permanent loop.\nWe had to refactor how we resolve properties so that we don't get into that situation. That change broke this feature.\nThe other format change is merged in the code. Thanks for that.\n. If you do have the use case in the provided example, you can do this for migration:\n+# common.properties\n+database_host=db.example.com\n+# myjob.job\n+database=${database_host}\nand have the admin who sets this up make sure this is correct. the users should not care about this difference for their job package.\n. I have to revert the rdiscount thing as it broke the other pages. Such as this one:\nhttp://submitteddenied.github.io/azkaban2/documents/2.1/jobconf.html\n. Yes, our docs needs rework. \nThe hadoopJava job will construct an object, the class name of which is specified in your job file. You can take a look at the example package http://azkaban.github.io/azkaban2/documents/2.1/hadoopjavatype.html\nYour problem looks like with your hadoop installation. When you talk to hadoop, you need the conf files to know where the name node and job tracker are. If you don't give any, they pick up all the default settings. Those xml files are normally in $HADOOP_HOME/conf\nIf it runs against local, it is because either you don't have the conf on the classpath, or you have given the wrong conf.\nFor questions like this, you can use this google group https://groups.google.com/forum/?fromgroups#!forum/azkaban-dev\n. You can't disagree with facts.\n1) Azkaban doesn't do special things in builtin types.\nIf it is command type, it simply start another process with the command as is in the job log.\n2) Any program can talk to any hadoop cluster. It only knows the url and everything from hadoop conf. \nI don't know how exactly you set up Azkaban and hadoop, but I have the following guess:\ntype=command\ncommand=hadoop jar my.jar com.my.JobRunner com.my.Job --hdfs\n-- runs, but not against the cluster, just local\nIf that was your whole command, you are using a \"hadoop\" script to start the jvm. Check if that one is good, say If you had exported another hadoop script in your environment.\n. The way I read it, your program starts fine, it just didn't pick up the right hadoop conf.\nThe point is to find out where that conf comes from. It needs to be on the local jvm classpath for javaprocess and hadoopJava jobs.\nIn the case of commad type, you don't start a jvm by yourself, so it is that \"hadoop\" script doing it.\nOf course I am assuming you didn't put a blank hadoop conf in your fat jar, which may just override other confs.\n. you may still want to work with hadoopJava type.\ncommand type doesn't handle hadoop security for you.\n. can you describe what exactly the problem is?\nI am not sure if we still need to set that property to jvm.\n. looks good.\n. +1! Ship it!\n. We used the following script to clean the orphan processes.\necho \"Looking for orphan processes from azkaban\"\nps -ef | awk '{if ($3 == 1) {print $0}}' | grep -v Azkaban | grep azkaban\necho \"Killing orphan processes\"\nfor i in ps -ef | awk '{if ($3 == 1) {print $0}}' | grep -v Azkaban | grep azkaban | awk '{print $2}' ;\ndo\n    kill -9 $i\ndone\n. One suspicion why the orphan process appear is this:\nWhen we cancel a running job/flow, we do a cancel on it. We try soft kill first, if it didn't die, we do a hard kill.\nUsed to be, the soft kill (kill process_id) and hard kill (process.destroy()) both do SIGTERM.\nWe should do SIGKILL on a user program if it just refuse to die.\nThis patch is related to this problem\nhttps://github.com/azkaban/azkaban2/commit/7c081b5654474fcb3738ca6eac3b3971c2f0777f\n. lgtm\n. Please don't remove that method.\nIt will break all old job type plugins.\n. I don't know a way to do it.\n. Don't get me wrong.\nThere may be some cumbersome ways to do it.\nBut I don't know exactly how. And we shouldn't do it cumbersomely. We should just spin up authentication servers which can't be done in very near future.\n. Looks good to me. And thanks for the contribution.\n. @jimternet , you may have problem with hive installation.\nFirst of all, hive with derby doesn't work well here as derby requires a fixed working directory. So please make sure of that.\nThe hive type in azkaban-plugin should work both if you are using mysql or metastore server. How does your job know this info? You need to make the hive conf files (hive-site.xml) on the job classpath. You can check this from azkaban job log (the process command).\nIf all above are not the problem, please check if that table in question does indeed exist.\n. Looks good to me.\n. I don't think we really need all these variables injected into flow properties for all jobs.\nIt is possible this is done for some specific job type if anyone needs them.\n. One possibility is to have those values supplied from job type plugins,\nrather than from Azkaban core.\nOn Fri, Apr 25, 2014 at 9:39 PM, Richard B Park notifications@github.comwrote:\n\nLast hour and last day are common variables people tend to use for\nprocessing previous set of completed data chunks.\nAlthough it seems use-case specific to define these variables, we see a\nlot of people making hacky work-arounds to this issue.\nDoes anyone have an alternative suggestion to get the behaviour that Russ\nwants?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/pull/224#issuecomment-41459769\n.\n\n\n--Chenjie Yu\n. We could add them into ProcessJob which is the base of most other job types.\nOn Fri, Apr 25, 2014 at 9:46 PM, Richard B Park notifications@github.comwrote:\n\nThat's fairly bulky though. This would have to be added to most plugin\ntypes then.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/pull/224#issuecomment-41459903\n.\n\n\n--Chenjie Yu\n. I wanted to keep azkaban core simple and clean.\nWe are already supplying flow execution time in timestamp.\nWhat he wanted is a translation service to translate it to year/month/day\nnumbers, as well as their -1 numbers. Why would that be inconsistent across\njobs in the same flow?\nAnd shall we add BACK_TWO_WEEK series if anybody asks?\nOn Fri, Apr 25, 2014 at 10:06 PM, Richard B Park\nnotifications@github.comwrote:\n\nWhy is it better there than in the same place that current start date is\napplied?\nAlso, there's a difference with applying to a flow and applying to a job.\nIf a flow crosses an hour or day barrier, than you may have inconsistency\nin a flow execution.\nHaving these variables would be powerful as variable replacements.\nHowever, maybe we can do something about their verbosity. Wonder if we can\nget away with azkaban.flow.one.week.back.day-1 or something.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/pull/224#issuecomment-41460221\n.\n\n\n--Chenjie Yu\n. One can always compute their own numbers if it is a java or embedded pig\npython.\nSome people start the flows with a init job that spits out all these for\nthe rest of the jobs in the flow.\nBut convenience wise, It is valid use case for stuff like vanilla Pig,\nespecially if the values are just not for UDF on the remote side.\nMy thinking is this kind of info is more user specific and could\npotentially grow into more dimensions. It is better to shove into some\nplugins.\nOn Sat, Apr 26, 2014 at 5:58 AM, David Z. Chen notifications@github.comwrote:\n\nIf I understand this correctly, this patch is for adding properties that\nprovide current time minus 1 time unit of hour, day, month, etc. It is not\nvery clear to me why this needs to be build into Azkaban as opposed to the\nactual query engine. For example, Pig provides the SubtractDuration UDFhttps://pig.apache.org/docs/r0.11.1/func.html#subtract-duratiointhat seems to fulfill this purpose. Also, what about the case where someone\nwants to use -2 hours rather than -1 hour?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/pull/224#issuecomment-41468025\n.\n\n\n--Chenjie Yu\n. LGTM. merging.\n. For this test, I am not testing any specific method.\n. @davidzchen \nNot sure when this needs to be run. We never know how they became orphans. I suspect majority of it is because when we kill some hard-to-kill ones, we weren't doing SIGKILL, which was fixed some time ago. Plus, it was only discovered on the most busy clusters, not anywhere else. So I suppose this is just handy in case someone really do a cleanse when everything is turned off.\n@rbpark \nAs above explained, we don't know the problem too well. It only happened on our busiest clusters. We don't know if it will happen at all after we change hard kill to SIGKILL.\nSo ... may enough just put it there until we are sure this is not an issue any more.\n. Azkaban probably could do better. This script is not for that purpose though. It is to clean up all the orphan processes that accumulated over time, while Azkaban itself is not running.\n. ",
    "zbstof": "We still experience this on 3.20. Is this expected?. ",
    "patricioe": "thank you. will try that.\n. ",
    "swarooppatra": "Adding HADOOP_HOME environment variable also helps. So I have added a line to azkaban webserver start up script for HADOOP_HOME like below.\n...\ntmpdir=\nexport HADOOP_HOME=\n...\n...\n. ",
    "zuopujun": "just like firecodeman said, how to disable jetty ssh?\n. Just like you said, I think it is mail.protocal.auth set to true that\nprevent sending mails too, when I use Azkaban-0.1, and send mails by gmail,\nit has no problem like this,\nLater I found  mail.smtp.starttls.enable should be true when use ssl to\nsend mails by gmails. But in  azkaban.utils.EmailMessage.java code,I found\nout this property can't be set to true by properties file. Then I add one\nline code followed, it works.\n//code in azkaban.utils.EmailMessage.java\npublic void sendEmail() throws MessagingException {\ncheckSettings();\nProperties props = new Properties();\n// props.setProperty(\"mail.transport.protocol\", \"smtp\");\nprops.put(\"mail.\"+protocol+\".host\", mailHost);\nprops.put(\"mail.\"+protocol+\".auth\", \"true\");\nprops.put(\"mail.user\", _mailUser);\nprops.put(\"mail.password\", _mailPassword);\nprops.put(\"mail.\"+protocol+\".timeout\", _mailTimeout);\nprops.put(\"mail.\"+protocol+\".connectiontimeout\", _connectionTimeout);\n_props.put(\"mail.\"+protocol+\".starttls.enable\", \"true\");\n               // added\n                ....\n          }\n2013/10/9 rbpark notifications@github.com\n\nWe use smtp for emails. The package we use\ncom.sun.mail.smtp.SMTPTransport.\nThe properties we set are:\nmail.smtp.host\nmail.user\nmain.password\nOne thing to note is that mail.protocal.auth is set to true by default. I\ndon't know why it is, but maybe that's what is preventing the sending of\nemails?\nOn Mon, Oct 7, 2013 at 8:17 PM, zuopujun notifications@github.com\nwrote:\n\ncom.sun.mail.smtp.SMTPSendFailedException: 530 5.7.0 Must issue a\nSTARTTLS\ncommand first. dk3sm36522188pbc.32 - gsmtp\nat\ncom.sun.mail.smtp.SMTPTransport.issueSendCommand(SMTPTransport.java:2114)\nat com.sun.mail.smtp.SMTPTransport.mailFrom(SMTPTransport.java:1618)\nat com.sun.mail.smtp.SMTPTransport.sendMessage(SMTPTransport.java:1119)\nat azkaban.utils.EmailMessage.sendEmail(EmailMessage.java:170)\nat\nazkaban.executor.ExecutorMailer.sendSuccessEmail(ExecutorMailer.java:167)\nat\nazkaban.executor.ExecutorManager.finalizeFlows(ExecutorManager.java:725)\nat azkaban.executor.ExecutorManager.access$1000(ExecutorManager.java:52)\nmy property followed:\nmail settings\nmail.sender=...\nmail server to send job success/failure notifications to\nmail.smtp.starttls.enable=true\nmail.host=smtp.gmail.com\nmail.user=...\nmail.password=...\nmail.port=587\njob.failure.email=...\njob.success.email=zuopujun@gmail.com\nDid I set the properties wrong, looking forward to the answer.\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/azkaban/azkaban2/issues/51>\n.\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/issues/51#issuecomment-25939649\n.\n. \n",
    "RexGibson": "adding this key doesn't turn off ssl. Seems to have no effect for me. \n. was running 2.1. I pulled down and built 2.2 and deployed. That works fine. \n. you could create previous job that writes out to the default properties file. -- or you could have the sh script have a default in your bash script\nbash\nif [[ -z $1 ]]\nthen \ntoday=date +%Y-%m-%d\nelse\ntoday=$1\nfi\n. I wouldn't want it in that tab, personally. Certainly not as the default. I'd prefer a tab/section for failed jobs. I can see jobs that have failed nodes that is still running showing up as a different status.\n. Thank you so much for this post. I am thrilled to read it!!! Much work will contain state and local computation on the Azkaban server. I would suggest that a solution for moving that state is considered if you are going to distribute a flow across multiple executors.  Alternatively I would accept a simpler solution that allowed a flow to be pinned to a specific server and all work for that flow is located there. I would love it if you could have kinds of executor servers akin to jenkins slaves where you could pin work to a note that is optimized for the work needed in the flow. I think a holy grail would also have a plugin that could spin up an new executor and register it with the \"cluster\".\n. However I was under the impression that Azkaban wasn't going to have the manpower investment made by LinkedIn to solve the executor problem because they are going to Ooozie.  We are currently considering other Workflow managers because of this understanding that multiple executors would not be invested in.  I would love some sort of clarity as to if this project is being carried forward by LinkedIn in a committed way or if this has become a lower priority. \n. That doesn't have as much value to us as we are not using azkaban as a direct hadoop connector we are firing off fruit fly clusters in EMR via Azkaban. \n. ",
    "davidzchen": "Are you running 2.1 or a later version?\n. Thanks! I have merged the PR.\n. This should be possible to do now (http://azkaban.github.io/azkaban/docs/2.5/#api-execute-a-flow). Please reopen if you are still experiencing this problem.\n. Given how old this issue is, it is most likely an obsolete issue. Please open a new issue if you can reproduce.\n. SGTM. I have updated the issue title.\n. Thanks!\n. Good catch! I've added #!/bin/bash to the scripts that were missing it.\n. PR has been merged.\n. LGTM!\n@cjyu - do you have any comments on this change?\n. LGTM!\n. LGTM.\n. @maczpc I noticed that you referenced this issue from a PR in your fork. Do you think you can submit a PR to this repository if this issue is still reproducing?\n. That's a good idea. We should add a script to be run at build time to attach the current commit hash to a properties file before creating the packages for the Azkaban binaries.\n. Duplicate of #130, which has been fixed.\n. CANCELLED jobs in the Job List table also do not display a status.\n\n. Interestingly, this problem no longer reproduces after restarting the solo server. Closing for now and will reopen if the problem reproduces consistently in the future.\n. LGTM!\n. Change has been merged.\n. LGTM!\n. LGTM!\n. LGTM.\n. LGTM.\n. Looks good to me. \n@cjyu - can you take a look at this too?\n. I apologize in advance about the diff. It is a mess because I converted all the tabs to spaces in build.xml.\nI know this is not usual code review procedure, but if you want more details on the changes, follow the commits listed on this PR. The commit messages mean exactly what they say.\n. LGTM!\n. Agreed. At some point, we should also add a doc to the repo and/or documentation that specifies the coding conventions for the project.\n. LGTM!\n. Reopening because I missed two.\n. The only other place is the Pig Visualizer.\n. Root cause turns out to be a plugins build issue. Closing.\n. Nope. Go ahead!\n. Looks good. Thanks!\n. Looks good!\n. So this is used only by the job type plugins?\n. Looks good!\n. My editor now strips trailing whitespace automatically. That is the bulk of the whitespace changes. The other major whitespace change is unit build.xml. I made some changes with spaces and some with tabs and in the end, I just made it consistent with the root build.xml.\n. Thanks! About ~80% of the tests pass. One of the issues is that a number of the tests currently depend on a MySQL instance running on the current machine, and those tests need to be changed use an embedded H2 database instead. There are also some old tests that need to be cleaned up.\n. FYI, I have not added ant test to .travis.yml yet because some of the tests need to be cleaned up. Once we clean up the tests, we should add it to .travis.yml so that Travis can both build and run the tests.\n. Looks good!\n. Just wondering, is it possible to have the jobtype plugins add these to the classpath when they are loaded?\n. I was not suggesting we fix it here. I was just wondering because this is the one other part of Azkaban core that hard-codes knowledge of Hadoop, Hive, etc. \nOtherwise, this looks good.\n. Will update docs on Flow Summary, Job Summary, and Pig Visualizer in separate PR.\n. We will be putting up both updated build instructions and the latest 2.5 RC tarballs shortly.\n. Thanks! This looks good.\n. FYI, .travis.yml would need to be changed as well to tell Travis to build using Gradle rather than Ant.\n. LGTM!\nShould we stamp 2.5 as final first before merging this and have this be part of 2.6?\n. Btw, can you merge or rebase on master? I think there are currently merge conflicts.\n. Added Gradle wrapper based on these recommendations: http://www.gradle.org/docs/current/userguide/gradle_wrapper.html\n. Looks good to me.\n. Can you verify whether building with Gradle has this issue? We are planning to remove all Ant build files since we are switching to Gradle.\n. Also, it looks like the build failed on Travis. It looks like some of the Rest.li sources either weren't compiled correctly or some paths weren't set correctly: error: package azkaban.restli.user does not exist\n. LGTM! :+1: \n. Actually, I just thought of another question. How does Rest.li handle HTTP response packets? Does it know to properly set the HTTP status codes in the event of an error (i.e. 4xx, 5xx, etc.)? And how does it determine which HTTP status code to set? Is it based on which exception you throw in the server resource?\n. Looks good. I think this is ready for merge.\n. Is the name of your hive plugin directory \"hive\" or \"hive-0.8.0\"? The path to your Hive jobtype plugin directory should be plugins/jobtypes/hive where plugins is the plugins directory of your executor server if you are running in two-server mode or your solo server if you are not.\n. That looks correct. Did you restart Azkaban after copying the jobtype plugin?\n. We will be putting up the final 2.5 packages later today.\nCan you send me the executor logs or the logger output from the server start-up? It seems that the plugin might have failed to load.\n. Interesting. I do not see anything immediately suspicious in the logs, but I'll take another closer look.\nBy the way, the 2.5.0 packages are now up if you would like to give that a try. Have you been using 2.1 or were you building from source?\n. That line is coming from azkaban.jobtype.hiveutils.RealHiveQueryExecutor. Which version of Hive are you running?\n. @cjyu, can you take a look at this as well? It might have something to do with the new Hive jobtype we recently added.\n. There are a number of changes here that are from #217. I'll make another pass through after we merge @217.\n. Looks good to me.\n. Looks good!\n. Can you give some examples of specific use cases that this would be used for?\n. If I understand this correctly, this patch is for adding properties that provide current time minus 1 time unit of hour, day, month, etc. It is not very clear to me why this needs to be build into Azkaban as opposed to the actual query engine. For example, Pig provides the SubtractDuration UDF that seems to fulfill this purpose. Also, what about the case where someone wants to use -2 hours rather than -1 hour?\n. I agree. Another good option would be to support arithmetic operators in the job files, which might be a good idea to consider since we are planning to add a flow DSL anyway.\n. I think I would like to go ahead and work on adding a DSL. I think the DSL should be the way forward for adding features like these since the existing Properties-based syntax is in great need of replacement anyway.\n. We discussed this offline today. Since adding support for arithmetic expressions in the current syntax (such as @rbpark's example above) will be an easy change, we will go ahead add that feature.\nDue to the interest in a new DSL both in and outside of LinkedIn, we will implement the new DSL over a longer release cycle since we need to coordinate development with other LinkedIn teams.\n. Yes, the change is in master now.\n. Thanks!\nThe main problem with Dust is that, as far as I know, there is no Gradle plugin for linkedin-dustjs available out there so I went ahead and wrote one myself: https://github.com/davidzchen/gradle-dustjs-plugin\nI have tested it with my azkaban-plugins Gradle conversion and it works pretty well so far. The only thing left to do for the plugin is to publish the artifact to Maven.\n. Definitely! I will try to move it over to the LinkedIn GitHub organization so that it will be maintained in the same place as Dust itself.\n. I've opened #227 for adding documentation.\nOtherwise, this looks good to me.\n. Looks good!\n. Looks good to me!\n. @pranayhasan Yes, I am aware that this plugin exists, but IMO workflow code should not be implemented by the build system.. Looks good to me.\n. Looks good. Thanks!\n. Thanks for catching this! I have opened a PR that fixes this.\n. Fix has been merged.\n. For the sake of maintenance, I don't want the Jekyll theme for the documents site and the main Azkaban landing site to diverge from each other too much, which is why I want to keep separate layout templates for the two sites.\n. Updated with common footer.\n. Thanks for your contribution, Mark.\nOne of the key design decisions that we should stick to is good separation of the executor server and the web server. This way, we can allow other application front-ends to call the executor server.\nThis change would effectively create a dependency from the executor server to the web server because the executor server is now adding webserver links. I think a better approach would be to just add the necessary information needed to construct links for the webserver, which should be done by the application that consumes properties, such as execution ID, project name, flow ID, etc.\n. @wagnermarkd From what I understand, you are inserting the links in JobRunner, which is part of the executor server and not the web server. Since you are hard-coding the URLs in the JobRunner, you are adding implementation details of the web server to the executor server, thus creating that dependency.\n. We discussed this offline. Given the number of dependencies between the web server and executor server currently, let's merge this change and open an issue for changing the properties from being URLs to being the individual properties that will allow clients to reconstruct the URLs.\n. In that case, other than the formatting comments by @erwa, this looks good to me.\n. @cwsteinbach I do not see how this is unfair or practical. This would be effectively exposing the Azkaban as a service to third party clients. This is no different from the way sites like GitHub, Twitter, or even LinkedIn, expose an HTTP API to third-party clients, which ultimately consists of the client sending HTTP requests to an API endpoint that consists of a hostname, port, and URI with parameters.\nNow, I do agree that the proper way to do this is via a client library, which would abstract the logic for  constructing the URI (and sending the request). Because the client library is a future work item, I think we should go ahead and merge this patch and just make a note to clean up this dependency in the future.\n. Merged. Thanks for your contribution!\n. The Travis failure is strange. In any case, you will need to merge or rebase due to #250. Let's try again with a new revision.\n. Looks good to me.\n. Thanks! I have changed all the other instances to 1.6 as well. I am excited to have a consistent coding style as well.\n@hluu Do you have any comments on this before it can be merged?\n. Addressed all the code review comments.\n@hluu Can you take a look when you get a chance and let me know if you have any feedback before we merge this?\n. Thanks for reviewing!\nazkaban-migration contains the tool that @cjyu wrote for migrating the schedules from Azkaban 2.1 to the triggers in Azkaban 2.5.\n. I have alphabetized the dependencies. Any other feedback before I merge this?\n. Other than the above formatting changes, looks good.\n. Looks good to me.\n. Looks like we needed to push a commit to the gh-pages branch of the azkaban repo after the rename before the site is live again.\nThe documentation is back up now. I have also updated the references on the site to point to azkaban rather than azkaban2.\nThe docs are at http://azkaban.github.io/azkaban\nI will also contact GitHub to see if they can add a redirect from the old documentation site to the new one.\n. It looks like there is a bug in the Gradle Distribution plugin documentation where it states:\n\nrun...\"gradle distTar\" to create a GZip compressed TAR file\n\nThe root cause of this is that gradle distTar creates a non-GZipped TAR archive.\n. Looks good!\n. Thanks for you contribution!\n. Merged.\n. Rebased on master.\n. Looks good!\n. @hluu - Can you add some code comments to document the relationship between the Future and the Runnable and that they both refer to one specific FutureTask?\n. Thanks for adding the documentation, Hien.\nCan you rebase on master? It looks like there are some merge conflicts from the PRs we just merged.\n. Other than the trailing whitespace, looks good!\n. Looks good!\n. Other than the minor formatting changes, looks good.\n. Looks good!\n. +1 Looks good!\n. Merging. Thanks!\n. +1 Looks good.\n. I just have one minor comment above.\nGreat job on this! This will be really helpful. We really appreciate your help!\n. LGTM!\n. Thank you for your contribution!\n. Looks good! Thanks for getting this to work!\n. Is this fixed by the commits listed here?\n. Duplicate of #42\n. Usually, the way to remove a flow is to upload a new project zip that does not contain the flow. Is this sufficient for you?\n. Sorry for the lack of clarify regarding the roadmap. I am no longer working at LinkedIn and have been emeritus for the past year or so. It is great to see so much interest in Azkaban, and as a result, I would like to resume my efforts in helping maintain this project.\nI see that @hluu has written a proposal for improving scalability with multiple executors in #439 and there has been a few PRs merged to support multiple executors by @evlstyle and @logiclord in #477 and #478. Can we give an update on the status of the work on multiple executors?\nI will be going through the backlog of open issues and revisiting the roadmap in the project wiki.\n@d3vnate - I am interested in learning more your long list of wishlist items. Would it be possible for you to share a public doc listing your wishlist items?\n. @vikramkone - It's really exciting to hear that you are using Azkaban at Microsoft!\nThank you for your feature requests and suggestions. I definitely agree that these features are greatly needed and that the Azkaban documentation could use improvement.\nWe'll try to put together an updated roadmap in the next couple of weeks to plan the work for the upcoming releases.\np.s. I am a former Microsoft employee myself. :)\n. Is this issue fixed by the commits listed here?\n. Is this issue fixed by the commits listed here?\n. Tracking bug: #439\n. Tracking bug: #439\n. Thanks for catching this. Can you open a Pull Request for this fix?\n. Merged. Thanks for fixing this!\n. Can we merge this?\n. Is this issue fixed in the commit ccaca0b?\n. Is this issue fixed with PR #493?\n. I have enabled error-prone and it is already catching a good number of potential bugs, many of which are raised as compile-time errors:\n/Volumes/Ocean/Projects/azkaban/azkaban/azkaban-common/src/test/java/azkaban/metric/MetricManagerTest.java:79: warning: [WaitNotInLoop] Because of spurious wakeups, wait(long) must always be called in a loop\n        wait(2000);\n            ^\n    (see http://errorprone.info/bugpattern/WaitNotInLoop)\n/Volumes/Ocean/Projects/azkaban/azkaban/azkaban-common/src/test/java/azkaban/project/ProjectTest.java:31: error: [LongLiteralLowerCaseSuffix] Prefer 'L' to 'l' for the suffix to long literals\n    project.setCreateTimestamp(1l);\n                               ^\n    (see http://errorprone.info/bugpattern/LongLiteralLowerCaseSuffix)\n  Did you mean 'project.setCreateTimestamp(1L);'?\n/Volumes/Ocean/Projects/azkaban/azkaban/azkaban-common/src/test/java/azkaban/project/ProjectTest.java:32: error: [LongLiteralLowerCaseSuffix] Prefer 'L' to 'l' for the suffix to long literals\n    project.setLastModifiedTimestamp(2l);\n                                     ^\n    (see http://errorprone.info/bugpattern/LongLiteralLowerCaseSuffix)\n  Did you mean 'project.setLastModifiedTimestamp(2L);'?\n2 errors\n9 warnings\n:azkaban-common:compileTestJava FAILED\nand others as warnings:\n:azkaban-execserver:compileJava\n/Volumes/Ocean/Projects/azkaban/azkaban/azkaban-execserver/src/main/java/azkaban/execapp/FlowRunnerManager.java:356: warning: [SynchronizeOnNonFinalField] Synchronizing on non-final fields is not safe: if the field is ever updated, different threads may end up locking on different objects.\n        synchronized (executionDirDeletionSync) {\n                     ^\n    (see http://errorprone.info/bugpattern/SynchronizeOnNonFinalField)\n/Volumes/Ocean/Projects/azkaban/azkaban/azkaban-execserver/src/main/java/azkaban/execapp/FlowRunnerManager.java:554: warning: [SynchronizeOnNonFinalField] Synchronizing on non-final fields is not safe: if the field is ever updated, different threads may end up locking on different objects.\n    synchronized (installedProjects) {\n                 ^\n    (see http://errorprone.info/bugpattern/SynchronizeOnNonFinalField)\nWhat's awesome about error-prone is that it also links documentation about why these are potential bugs and suggested fixes.\nI will open a PR with the changes to build.gradle and all the compile errors fixed. Because that patch may be somewhat meaty, I will open a separate one for fixing the remaining warnings.\n. LGTM. Thanks for your contribution!\n. ```\n\u276f\u276f\u276f ag @Ignore\nazkaban-common/src/test/java/azkaban/database/AzkabanDatabaseSetupTest.java\n61:  @Ignore @Test\n86:  @Ignore @Test\nazkaban-common/src/test/java/azkaban/database/AzkabanDatabaseUpdaterTest.java\n37:  @Ignore @Test\nazkaban-common/src/test/java/azkaban/executor/ExecutableFlowTest.java\n61:  @Ignore @Test\n99:  @Ignore @Test\n117:  @Ignore @Test\n157:  @Ignore @Test\nazkaban-common/src/test/java/azkaban/executor/JdbcExecutorLoaderTest.java\n357:  @Ignore @Test\n382:  @Ignore @Test\n424:  @Ignore @Test\nazkaban-common/src/test/java/azkaban/jobExecutor/PythonJobTest.java\n86:  @Ignore(\"Test appears to hang.\")\nazkaban-common/src/test/java/azkaban/project/JdbcProjectLoaderTest.java\n422:  @Ignore @Test\n457:  @Ignore @Test\n495:  @Ignore @Test\nazkaban-common/src/test/java/azkaban/trigger/ConditionTest.java\n69:  @Ignore @Test\nazkaban-common/src/test/java/azkaban/trigger/ExecuteFlowActionTest.java\n33:  @Ignore @Test\nazkaban-common/src/test/java/azkaban/trigger/JdbcTriggerLoaderTest.java\n151:  @Ignore @Test\n173:  @Ignore @Test\n187:  @Ignore @Test\nazkaban-common/src/test/java/azkaban/trigger/TriggerTest.java\n55:  @Ignore @Test\nazkaban-common/src/test/java/azkaban/trigger/TriggerManagerTest.java\n50:  @Ignore @Test\nazkaban-common/src/test/java/azkaban/user/XmlUserManagerTest.java\n67:  @Ignore @Test\n82:  @Ignore @Test\nazkaban-common/src/test/java/azkaban/utils/DirectoryFlowLoaderTest.java\n32:  @Ignore @Test\n41:  @Ignore @Test\n50:  @Ignore @Test\nazkaban-common/src/test/java/azkaban/utils/EmailMessageTest.java\n49:  @Ignore\nazkaban-execserver/src/test/java/azkaban/execapp/event/LocalFlowWatcherTest.java\n77:  @Ignore @Test\n106:  @Ignore @Test\n135:  @Ignore @Test\nazkaban-execserver/src/test/java/azkaban/execapp/event/RemoteFlowWatcherTest.java\n78:  @Ignore @Test\n109:  @Ignore @Test\n138:  @Ignore @Test\nazkaban-execserver/src/test/java/azkaban/execapp/FlowRunnerPipelineTest.java\n119:  @Ignore @Test\n292:  @Ignore @Test\n485:  @Ignore @Test\nazkaban-execserver/src/test/java/azkaban/execapp/FlowRunnerPropertyResolutionTest.java\n117:  @Ignore @Test\nazkaban-execserver/src/test/java/azkaban/execapp/FlowRunnerTest.java\n89:  @Ignore @Test\n125:  @Ignore @Test\n171:  @Ignore @Test\n209:  @Ignore @Test\n259:  @Ignore @Test\n305:  @Ignore @Test\n363:  @Ignore @Test\nazkaban-execserver/src/test/java/azkaban/execapp/FlowRunnerTest2.java\n147:  @Ignore @Test\n309:  @Ignore @Test\n382:  @Ignore @Test\n430:  @Ignore @Test\n491:  @Ignore @Test\n568:  @Ignore @Test\n650:  @Ignore @Test\n713:  @Ignore @Test\n823:  @Ignore @Test\n887:  @Ignore @Test\n956:  @Ignore @Test\n1072:  @Ignore @Test\n1137:  @Ignore @Test\n1208:  @Ignore @Test\n1283:  @Ignore @Test\nazkaban-execserver/src/test/java/azkaban/execapp/JobRunnerTest.java\n77:  @Ignore @Test\n114:  @Ignore @Test\n219:  @Ignore @Test\n274:  @Ignore @Test\n``\n. I think I have figured out why this test is failing. Whencache.get()is called, thelastUpdateTimeof theElementis updated usingSystem.currentTimeMillis(). Because the test callscache.get()on several elements in immediate succession, it seems thatSystem.currentTimeMillis()` does not have high enough resolution to capture the difference in access times for each of these accesses on fast CPUs. As a result, the timestamps for each of these elements is identical, leading to the wrong element getting evicted:\n```\nazkaban.utils.cache.CacheTest > testLRU STANDARD_ERROR\n    insert (key1, val1)\n    insert (key2, val2)\n    insert (key3, val3)\n    insert (key4, val4)\n    getElement key2 1445507468551\n    getElement key3 1445507468551\n    getElement key4 1445507468551\n    getElement key1 1445507468551\n    insert expire (key5, val5)\n    getNextExpiryElement key1 1445507468551\n    getNextExpiryElement key2 1445507468551\n    getNextExpiryElement key3 1445507468551\n    getNextExpiryElement key4 1445507468551\n    ejectionCandidate key1 1445507468551\n    getElement key3 1445507468553\n    getElement key4 1445507468553\nazkaban.utils.cache.CacheTest > testLRU FAILED\n    java.lang.AssertionError: expected: but was:\n        at org.junit.Assert.fail(Assert.java:88)\n        at org.junit.Assert.failNotEquals(Assert.java:743)\n        at org.junit.Assert.assertEquals(Assert.java:118)\n        at org.junit.Assert.assertEquals(Assert.java:144)\n        at azkaban.utils.cache.CacheTest.testLRU(CacheTest.java:47)\n```\nPerhaps we can also look at whether we can use the Guava Cache implementation rather than maintaining our own: https://github.com/google/guava/wiki/CachesExplained\n. Opened #552 for switching to Guava's Cache implementation. Once that is done, this test can be removed.\n. Thanks!\nThose build names, such as animalDistTar, are used to create the archives for the test projects under azkaban-test. I have opened #513 to see if we clean some of this up.\n. FYI, this PR depends on #507, which updates the Gradle version to 2.7 in the Gradle Wrapper, since error-prone 2.0.5 requires the newer version of Gradle. \n. Rebased. Waiting for CI to succeed.\n. LGTM\n. LGTM\n. As discussed with @hluu offline, Azkaban 3 will no longer support Java 1.6.\n. Can you rebase against master instead? That way, you do not have all the old commits polluting your diff.\nIdeally, I think it would be better to squash all of the commits into one instead of keeping all the intermediate patches:\ngit rebase -i master\n. Hi John,\nI took a look at your fork and the revision history for this PR. It looks like your master branch diverged from the azkaban/azkaban master a while ago and the commits for this PR are interleaved with more recent commits from upstream.\nI actually tried cloning your fork of Azkaban, adding azkaban/azkaban as upstream, and doing git rebase -i upstream/master. Given the number of merge conflicts you would get compared to the size of your patch, I think it would be much simpler if you simply apply the net diff for this PR on top of a clean master branch that is identical to the upstream master.\nHere is how you can do this:\n1. In your repository, assuming you have azkaban/azkaban added as upstream, first sync your upstream:\ngit fetch upstream\n2. Create a new branch; let's call it clean-master:\ngit checkout -b clean-master\n3. Reset this branch to make it identical to upstream/master:\ngit reset --hard upstream/master\n4. Download the diff for this PR:\nwget https://github.com/azkaban/azkaban/pull/517.diff\n5. Apply the diff:\ngit apply 517.diff\n6. The diff for your PR has now been applied on top of the clean-master branch, which is identical to upstream/master, but is not committed. Because you added azkaban-execserver/src/main/resources/execute-as-user.c as a new file, you would need to git add it. Now, remove the diff file, add execute-as-user.c, and commit:\nrm 517.diff\n   git add azkaban-execserver/src/main/resources/execute-as-user.c\n   git commit -am \"<write your commit message here>\"\n7. Now, you can make your master branch identical to clean-master and then do a force-push to push your squashed patch to this Pull Request:\ngit checkout master\n   git reset --hard clean-master\n   git push origin master -f\nOnce you have done this:\n- This Pull Request will only contain one commit for your changes on top of master.\n- Your master branch will be identical to the upstream master with the addition of your patch.\nUntil this PR is merged, if there are new commits that go into master before your commit, I would recommend rebasing so that your patch will come after those new commits:\ngit fetch upstream\ngit rebase -i upstream/master\nAfter your patch is merged, sync your master branch with upstream using:\ngit fetch upstream\ngit merge upstream/master\nAfter your patch is merged, I would recommend doing development in feature branches in your fork and keeping your master branch identical to upstream/master at all times, and when new changes land in master, rebase your feature branch on top of master. To illustrate:\n```\ngit checkout -b new-feature\nDo some work.\nSome new commits land in master.\nFetch upstream and sync master with upstream:\ngit checkout master\ngit fetch upstream\ngit merge upstream/master\nRebase your feature branch on top of master:\ngit checkout new-feature\ngit rebase master\nIf there are any merge conflicts, resolve the merge conflicts and then run\ngit rebase --continue until the rebase is successful.\n```\nThis way, your master branch will always be identical to upstream, and your commits are always on top of master and not interleaved with older commits. It is good to rebase often, whenever new commits land in master. This will greatly reduce the number of painful merge conflicts and will allow you to work on more than one change by using different feature branches.\nThe only caveat is that if you want to push your feature branch to your remote branch (such as if you want to continue working on a different machine), you would need to do a force push after you do a rebase:\ngit push origin new-feature -f\nI think force-pushes for feature branches in this case are fine, but force pushes for master branches should be avoided whenever possible. :)\nAnyway, sorry for the hassle. I think we should try to rebase and squash commits before merging pull requests. This way, we would reduce the likelihood of particularly nasty merge conflicts, keep the revision history cleaner, and make it easier to track down why a certain line of code is changed. This is also closer to what Apache projects do.\nFeel free to email me if you run into any issues. I am usually online in the evenings as well.\n. Thanks for the clarification. I didn't notice that your diff-base was multipleexecutors_canary and not master. That makes more sense now why the recent changes in master were showing up in this diff. :)\nSounds good. Feel free to let me know if you need any help with the rebase.\n. Friendly ping.\n. @logiclord - Thanks! Actually, something like that is not a bad idea. I have removed the duplicated test files and added a utility class to azkaban-test (TestExecutions) with a method that other tests can use to get a File object for the directory of one of the flows in azkaban-test.\nThis way, we build a JAR from azkaban-test that contains this class and all the test files, and other tests can use the TestExecutions class, which will load the resource files in the azkaban-test jar using its own class loader.\nI have also moved all the test flows in azkaban-test into the correct resource directory so that they can be loaded from the jar, though this would mean that we would need to update the paths in the TestUtils class that you wrote.\n. IIRC the remaining blocker for 3.0 is finishing the testing and merging in the changes for multiple executors.\n@hluu - Is there an updated ETA on the 3.0 release?\n. @hluu - Is there an updated ETA for 3.0?\n. Thanks for your contribution! Can you fix the indentation in your patch? We use 2 spaces for indentation.\n. Ping.\n. Hi @vikramkone, it looks like the $() syntax is clashing with some post-processing that Azkaban is doing to the properties files. I'll take a look.\n. I don't think there is currently a way to do this but what are the main downsides of modeling this via dependencies compared to setting priorities?\n. AFAIU, we have some of the infrastructure for conditionals such as these in place through the Trigger Manager but they are not fully exposed.\n. From what I understand, currently, the only ways are via JOB_PROP_OUTPUT_FILE or having one job write to a file in a predetermined location and have the next job read from that file. I think there should be a more explicit mechanism to do this though, such as having explicit properties for specifying the inputs and outputs for a job.\n. For sharing data between commands within a job, how about writing to a temporary file and/or using a temporary directory using mktemp?\n. LGTM\n. Thank you for your contribution!\n. FYI see documentation about Guava's Cache implementation here: https://github.com/google/guava/wiki/CachesExplained\n. Ping.\n. Ping. Can somebody take a look at this?\n. Thanks for reviewing, @hluu!\nYes, Guava Cache is widely used here at Google as well as our open source projects, such as Bazel, our build system, which I also contribute to. :)\nAccording to @rbpark, Azkaban originally used ehcache. However, it turns out that ehcache would phone home to check for updates, which is a very unusual behavior for a library. As a result, ehcache was ditched for a custom Cache implementation.\nGuava actually provides a lot of very useful data structures. Unfortunately, not all of them are very well known in the open source world. :)\n. Feel free to send a PR. Thanks, @vikramkone!\n. That's strange. It doesn't seem to be anything related to your patch; the error seems to be caused by some connection failure when trying to fetch artifacts from Maven.\nI am rerunning the CI to see if it goes away.\n. LGTM\n. Thanks, @vikramkone! I only have two minor style comments. Other than that, can you squash your commits into a single commit using git rebase -i? Then, I'll go ahead and merge your patch to master.\n. Hi @vikramkone, I noticed that your pull request is based off of your master branch. As a result, I don't think you would be able to do a straightforward rebase this way. Generally, it is better to make changes for a bug on a feature branch and keep your master identical to the upstream master. This way, you would be able to work on more than one change simultaneously, and it would make it easier to manage merge conflicts. Plus, Git was designed with this model in mind.\nI have a write-up about how to move your changes to a feature branch and make your master branch in sync with the upstream master at: https://github.com/azkaban/azkaban/pull/517#issuecomment-146736037.\nFeel free to let me know if you have any questions.\n. Hi @sowe - what are the file names you are using for your job files?\n. @sowe Both jobs should be in the same zip file. Your zip file would contain the following files:\n- basic_1st_comand.job\n- basic_2nd_command.job\n. I have restarted the failed CI build.\n. Nitpick: break up line if it is over 100 characters.\n. Nitpick: break up line if it is over 100 characters.\n. Nitpick: add space after \"if.\"\n. When is this script run? Is it run manually by the user?\n. Usually, the Make target is an output file, such as object files, executables, or, in this case, CSS files, but you also have targets that are not generated files, such as all and clean. .PHONY is used to indicate which targets are not files that are built:\nhttp://www.gnu.org/software/make/manual/html_node/Phony-Targets.html\n. Actually, I don't think the author config is actually being used anymore. :)\n@rbpark - do you remember what the author config was used for originally?\nIf it isn't necessary, I'll remove it.\n. Declare var selectionPosition somewhere unless it is supposed to be global.\n. This is really neat!\n. Since flow.less ends up as part of azkaban.css, global styles such as those for html and body should go in base.less.\n. You probably don't need sidebar-offcanvas here anymore.\n. Nitpick: can you use the separate-with-dashes convention for new CSS styles? I try to keep things consistent with Bootstrap, which follows this convention.\n. Change space to &nbsp;\n. This is because we have accumulated a mix of tabs and spaces over time, and I didn't make any wholesale whitespace changes in this changeset. Let's do a wholesale cleanup as a separate change later.\n. Yes, let's go with tabs for everything. It actually makes a bit more sense for the web resources since a tab is fewer characters than 2+ spaces.\n. Let's discuss this later. Richard is also fine with tabs for Java and 2 spaces for all web resources (since Bootstrap and a lot of existing web codebases do that already).\n. It is used for escaping in LESS, otherwise, lessc will actually perform the calculation during compilation.\n. Yeah we want to make this pluggable and make sure that Azkaban stays clean of any dependency or knowledge of Hadoop. Will put more thought into this and make a change later.\n. If you want to fix it now, here is an else that Eclipse reformatted that we missed.\n. Shouldn't build.xml be removed?\n. I think it might be better to do an all or nothing approach. Having two sets of build scripts might be confusing and the build scripts might get out of sync if we add dependencies or move sources around.\n. IIRC file(new File()) might be redundant. I think it should be possible to just do file(buildDir + '/less') but I could be wrong.\nEdit: nvm, buildDir is a File, not a String.\n. Including mavenLocal might be useful when developing, such as if we are trying out jars that we compiled locally, though for committed code, all dependencies should be available in Maven Central, which is nicely enforced by Travis CI since the Travis build would fail if any dependencies are unmet. :)\n. Sounds good. I'll make those changes in a separate PR.\n. Might be a bit cleaner to store this.getContext().getRawRequestContext() in a local variable to avoid calling this chain of calls multiple times.\n. Might be more clear to name this in rather than buff since we have out.\n. Interesting API.\n. Why does logger.error use user.getUserId() while the exception message uses user(.toString())? Is the exception message eventually displayed to the user?\nNitpick: if these two messages can be the same, it might be better to create the string once and pass it to both. Same with the MalformedURLException and IOException catches below.\n. Is this already covered by the fileOutputStream.close() in the finally block?\n. Move brace to the end of the last line.\n. Indentation of this line seems to be off.\n. If this method loads job types, it might be better to rename it loadJobType.\n. Nitpick: Add space after the if.\n. Needs file comment.\n. Needs file comment.\n. Needs file comment.\n. Needs file comment.\n. Nitpick: extra space at beginning of params list.\n. The catch should be on the next line.\n. Same here.\n. I didn't know we had these. :)\n. Add file header.\n. Looks like there are strange characters here.\n. These URL patterns are specific to the web server.\n. Good catch. I have been able to compile Azkaban fine with Java 7, but I think we should make the actual switch to Java 7 in a separate patch after more testing. I will change this value to 1.6.\n. Nitpick: might be better to use constants for these.\n. I don't know if there is an automated way to do this but I can reorder them manually. Do we generally order dependencies by group ID or by artifact name?\n. Sounds good to me too!\n. Add braces around this.\n. Might be good to add some documentation on what this method is used for.\n. Add file license header.\n. Add file license header.\n. I would like to know this too. In theory it might \"work\" because all objects have a hashCode() method which is used by Map.get() but I would be surprised that this would not cause a compilation error since the submittedFlows map is keyed by Future and not a class that is in the Runnable hierarchy such as RunnableFuture.\n. Does this patch add trailing whitespace?\n. Is this column necessary since we can order by Execution ID? I think adding a new column for holding the loop counter may lead to confusion over what that column means.\n. It still seems unclear to me how this actually works. Is the Runnable that the ThreadPoolExecutor.beforeExecute method receives actually a RunnableFuture, which is why they are the same project? Or is the Future's hashCode overwritten so that it returns the hashCode of the Runnable?\n. I understand why the code compiles as I explained in my earlier comment that all Objects have a hashCode method, which HashMap uses. What is unclear to me is how the Runnable and the Future refer to the same object in this case.\n. Discussed offline. The object is actually a FutureTask, which implements both the Future and Runnable interfaces. The Future returned by submit() does in fact refer to the same FutureTask object as one of the Runnables in the list returned by getInProgressTasks\n. Went over this offline. After looking at the UI, this is actually pretty nice to have.\n. We should grep through the codebase for similar comments at some point. :)\n. Nitpick: I know the formatter tends to do this but I think it is better to have logger.error( on the previous line and the argument on the next.\n. Trailing whitespace.\n. Can we use StringUtils.join from Commons Lang or Joiner from Guava instead?\n. I see. I didn't see that comment. That's fine.\n. This <ul> nested inside of the <pre> does not quite look right. Should this be removed?\n. This is a pretty long function, and this if condition spans the entire method. It would be better to check the negation of this condition and return early:\njava\nif (!new File(\"/bin/bash\").exists() ||\n    !new File(\"/bin/cat\").exists() ||\n    !new File(\"/bin/grep\").exists() ||\n    !new File(\"/proc/meminfo\").exists()) {\n  return;\n}\n...\n. Nit: line length\n. Nit: add space between braces and the statement. Same elsewhere.\n. Why the <pre> tags?\n. I don't think that is necessary here because it is just a paragraph and not code. <pre> is used displaying code blocks within in your documentation: http://docs.oracle.com/javase/7/docs/technotes/tools/windows/javadoc.html\nAlso, AFAIU, using <pre> here will not render the Javadoc tags within this documentation, such as {@inheritdoc} because they are treated as code and will be displayed as such.\n. It seems that your diff base is old since this patch contains a number of changes from #508. Can you please rebase?\n. Unfortunately, there does not seem to be a standard way to have this kind of cross-subproject dependency for resources in Gradle. The resources for a test must also be under the same package directory in the resource source set as the test. For example, tests under test/azkaban/executor need their resources to be under resources/azkaban/executor. Do you know of a non-hackish way to use resource files from a separate subproject in Gradle?\nOtherwise, I think having a bit of duplication for test files should be fine, especially since these test files are relatively small.\n. Done.\n. Are we building this? I don't see any changes to build files.\nIf so, perhaps it shouldn't be in resources but rather in one of the standard directories according to Gradle's docs on building native binaries?\n. Nit: Let's keep the style consistent and follow the same indentation style used by the original source in hadoop-common\n. Nit: Add space between if and paren and add braces. Same elsewhere.\n. Globals should be only be constants. It's better to instantiate these here in main and pass them to any other functions such as change_user.\n. Add braces.\n. Add braces.\n. Given that this is built as part of Azkaban and given that Gradle supports building native code, I think building this C file should be handled by the build system and we would not need to document how to build this file separately.\n. Unfortunately, Travis only supports oraclejdk8 right now and has not added support for openjdk8 yet. Adding openjdk8 to this config results in an error saying that openjdk8 is not found.\n. I have added a TODO comment to add openjdk8 once it becomes available.\n. Understood. Since this is a fork of Hadoop's implementation and since LOGFILE and ERRORFILE are pointer types, that's fine.\nCan you change the indentation back to the same convention used by Hadoop?\n. Nit: Make indentation and brace style consistent.\n. Nit: Please fix indentation (note: Azkaban uses 2 spaces and not tabs).\n. Nit: indentation\n. Nit: this entire if block is indented an extra level.\n. Nit: Line length. Split up this string to keep it within 100 chars.\n. Nit: Since each of these lines are part of the method call on L486, indent each of these lines in by 4 spaces.\n. Is this being built with the build system? I don't see any build.gradle changes here.\n. How about web.site_root instead? That might be more descriptive.\n. ",
    "jurgenweber": "with this key, I still get: SSL_do_handshake() failed (SSL: error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol) while SSL handshaking to upstream (using nginx reverse proxy).\nHow do you turn it off? I just want an environment for testing without ssl...\n. ",
    "polaris2013": "u're right ,   if i i restart the web server, the status changed to succeed,  is this because  when restart, the flow is forced to finalize?    the flow is not in runningflows, so can retrieve it from db.  but i can not  restart for every task i submit,   is there a way to solve this bug?   and the firebug keeps showing \"flow not found exception\" when web server frequently ajax fetch executable Logs .\n\n. hi, Richard\nvery appreciate for your insight in azkaban ,  I also notice a exception\nin a update thread, do u mean that thread died?\nWhy cause the exception?  and most important how to solve it ?\n2013/7/30 rbpark notifications@github.com\n\nWhoops empty message.\nThe web server keeps a copy of the executing flow for display purpose and\nto try to catch failures from dead executor servers. However, we found on\nseveral (very rare) occasions, the updater thread may die.\nWe've done a lot of fixes in trunk that may have fixed it, but we'll be\nadding more monitoring soon.\nOn Tue, Jul 30, 2013 at 12:06 AM, Richard Park richard.b.park@gmail.comwrote:\n\nOn Mon, Jul 29, 2013 at 7:19 PM, polaris2013 notifications@github.comwrote:\n\nu're right , if i i restart the web server, the status changed to\nsucceed, is this because when restart, the flow is forced to finalize?\nthe\nflow is not in runningflows, so can retrieve it from db. but i can not\nrestart for every task i submit, is there a way to solve this bug? and\nthe\nfirebug keeps showing \"flow not found exception\" when web server\nfrequently\najax fetch executable Logs .\n[image: 2013-07-30 10 12 23]<\nhttps://f.cloud.github.com/assets/5111899/876181/ddff8728-f8bd-11e2-98c2-a4b267ad5dfd.png>\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/azkaban/azkaban2/issues/28#issuecomment-21765576>\n.\n\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/issues/28#issuecomment-21773282\n.\n\n\nSincerely yours\nYuan JU\nMaster of Information Science,Wuhan Univ\nTel 86-13916450206\nEmail whuims.yuanju.page@gmail.com whuims.yuanju.page@gmail.com\n. attached is the debug info:\n ExecutorManagerUpdaterThread  java.lang.NoSuchMethodError :\nazkaban.executor.ExecutorManager.access$2(Lazkaban/executor/ExecutorManager;\nLjava/util/List;Ljava/util/List;Ljava/util/List)\n2013/7/30 jujumao whuims.yuanju.page@gmail.com\n\nhi, Richard\nvery appreciate for your insight in azkaban ,  I also notice a\nexception in a update thread, do u mean that thread died?\nWhy cause the exception?  and most important how to solve it ?\n2013/7/30 rbpark notifications@github.com\n\nWhoops empty message.\nThe web server keeps a copy of the executing flow for display purpose and\nto try to catch failures from dead executor servers. However, we found on\nseveral (very rare) occasions, the updater thread may die.\nWe've done a lot of fixes in trunk that may have fixed it, but we'll be\nadding more monitoring soon.\nOn Tue, Jul 30, 2013 at 12:06 AM, Richard Park richard.b.park@gmail.comwrote:\n\nOn Mon, Jul 29, 2013 at 7:19 PM, polaris2013 notifications@github.comwrote:\n\nu're right , if i i restart the web server, the status changed to\nsucceed, is this because when restart, the flow is forced to finalize?\nthe\nflow is not in runningflows, so can retrieve it from db. but i can not\nrestart for every task i submit, is there a way to solve this bug? and\nthe\nfirebug keeps showing \"flow not found exception\" when web server\nfrequently\najax fetch executable Logs .\n[image: 2013-07-30 10 12 23]<\nhttps://f.cloud.github.com/assets/5111899/876181/ddff8728-f8bd-11e2-98c2-a4b267ad5dfd.png>\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/azkaban/azkaban2/issues/28#issuecomment-21765576>\n.\n\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/issues/28#issuecomment-21773282\n.\n\n\nSincerely yours\nYuan JU\nMaster of Information Science,Wuhan Univ\nTel 86-13916450206\nEmail whuims.yuanju.page@gmail.com whuims.yuanju.page@gmail.com\n\n\nSincerely yours\nYuan JU\nMaster of Information Science,Wuhan Univ\nTel 86-13916450206\nEmail whuims.yuanju.page@gmail.com whuims.yuanju.page@gmail.com\n. i think the line number is 610\nmore information are provided :\n2013/07/30 21:43:43.498 +0800 INFO [ExecutorManager] [Azkaban] printing\nexecutor Host:localhost    executor Port: 12321\n2013/07/30 21:43:43.501 +0800 INFO [ExecutorManager] [Azkaban] jujumao\nexecuting Manager started\nException in thread \"ExecutorManagerUpdaterThread\"\njava.lang.NoSuchMethodError:\nazkaban.executor.ExecutorManager.access$2(Lazkaban/executor/ExecutorManager;Ljava/util/List;Ljava/util/List;Ljava/util/List;)V\n    at\nazkaban.executor.ExecutorManager$ExecutingManagerUpdaterThread.run(ExecutorManager.java:610)\n\n2013/07/30 21:43:43.502 +0800 INFO [ExecutorManager] [Azkaban] Cleaning old\nlogs from execution_logs\n2013/07/30 21:43:43.516 +0800 INFO [JdbcSLALoader] [Azkaban] Loading all\nSLAs from db.\n2013/07/30 21:43:43.548 +0800 INFO [JdbcSLALoader] [Azkaban] Loading all\nSLAs from db.\n2013/7/30 rbpark notifications@github.com\n\nThat error is interestingly weird, since the NoSuchMethodError occurred\nwith java.util.List. The version of Java we use is 1.6. As far as I know,\nthe api hasn't changed since 1.5 and should work with 1.7.\nDoes the Error give you a line number?\nOn Tue, Jul 30, 2013 at 1:56 AM, polaris2013 notifications@github.comwrote:\n\nattached is the debug info:\nExecutorManagerUpdaterThread java.lang.NoSuchMethodError :\nazkaban.executor.ExecutorManager.access$2(Lazkaban/executor/ExecutorManager;\nLjava/util/List;Ljava/util/List;Ljava/util/List)\n2013/7/30 jujumao whuims.yuanju.page@gmail.com\n\nhi, Richard\nvery appreciate for your insight in azkaban , I also notice a\nexception in a update thread, do u mean that thread died?\nWhy cause the exception? and most important how to solve it ?\n2013/7/30 rbpark notifications@github.com\n\nWhoops empty message.\nThe web server keeps a copy of the executing flow for display purpose\nand\nto try to catch failures from dead executor servers. However, we\nfound\non\nseveral (very rare) occasions, the updater thread may die.\nWe've done a lot of fixes in trunk that may have fixed it, but we'll\nbe\nadding more monitoring soon.\nOn Tue, Jul 30, 2013 at 12:06 AM, Richard Park \nrichard.b.park@gmail.comwrote:\n\nOn Mon, Jul 29, 2013 at 7:19 PM, polaris2013 \nnotifications@github.comwrote:\n\nu're right , if i i restart the web server, the status changed to\nsucceed, is this because when restart, the flow is forced to\nfinalize?\nthe\nflow is not in runningflows, so can retrieve it from db. but i can\nnot\nrestart for every task i submit, is there a way to solve this bug?\nand\nthe\nfirebug keeps showing \"flow not found exception\" when web server\nfrequently\najax fetch executable Logs .\n[image: 2013-07-30 10 12 23]<\n\n\n\n\nhttps://f.cloud.github.com/assets/5111899/876181/ddff8728-f8bd-11e2-98c2-a4b267ad5dfd.png>\n\n\n\n\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/azkaban/azkaban2/issues/28#issuecomment-21765576>\n.\n\n\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/azkaban/azkaban2/issues/28#issuecomment-21773282>\n.\n\n\nSincerely yours\nYuan JU\nMaster of Information Science,Wuhan Univ\nTel 86-13916450206\nEmail whuims.yuanju.page@gmail.com whuims.yuanju.page@gmail.com\n\n\nSincerely yours\nYuan JU\nMaster of Information Science,Wuhan Univ\nTel 86-13916450206\nEmail whuims.yuanju.page@gmail.com whuims.yuanju.page@gmail.com\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/azkaban/azkaban2/issues/28#issuecomment-21777742>\n.\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/issues/28#issuecomment-21779992\n.\n\n\nSincerely yours\nYuan JU\nMaster of Information Science,Wuhan Univ\nTel 86-13916450206\nEmail whuims.yuanju.page@gmail.com whuims.yuanju.page@gmail.com\n. java -version\njava version \"1.6.0_27\"\nOpenJDK Runtime Environment (IcedTea6 1.12.5) (6b27-1.12.5-0ubuntu0.12.04.1)\nOpenJDK 64-Bit Server VM (build 20.0-b12, mixed mode)\n2013/7/31 rbpark notifications@github.com\n\nWhat version of Java are you using?\nOn Tue, Jul 30, 2013 at 6:49 AM, polaris2013 notifications@github.comwrote:\n\ni think the line number is 610\nmore information are provided :\n2013/07/30 21:43:43.498 +0800 INFO [ExecutorManager] [Azkaban] printing\nexecutor Host:localhost executor Port: 12321\n2013/07/30 21:43:43.501 +0800 INFO [ExecutorManager] [Azkaban] jujumao\nexecuting Manager started\n*Exception in thread \"ExecutorManagerUpdaterThread\"\njava.lang.NoSuchMethodError:\nazkaban.executor.ExecutorManager.access$2(Lazkaban/executor/ExecutorManager;Ljava/util/List;Ljava/util/List;Ljava/util/List;)V\nat\nazkaban.executor.ExecutorManager$ExecutingManagerUpdaterThread.run(ExecutorManager.java:610)\n*\n2013/07/30 21:43:43.502 +0800 INFO [ExecutorManager] [Azkaban] Cleaning\nold\nlogs from execution_logs\n2013/07/30 21:43:43.516 +0800 INFO [JdbcSLALoader] [Azkaban] Loading all\nSLAs from db.\n2013/07/30 21:43:43.548 +0800 INFO [JdbcSLALoader] [Azkaban] Loading all\nSLAs from db.\n2013/7/30 rbpark notifications@github.com\n\nThat error is interestingly weird, since the NoSuchMethodError\noccurred\nwith java.util.List. The version of Java we use is 1.6. As far as I\nknow,\nthe api hasn't changed since 1.5 and should work with 1.7.\nDoes the Error give you a line number?\nOn Tue, Jul 30, 2013 at 1:56 AM, polaris2013 notifications@github.comwrote:\n\nattached is the debug info:\nExecutorManagerUpdaterThread java.lang.NoSuchMethodError :\n\n\nazkaban.executor.ExecutorManager.access$2(Lazkaban/executor/ExecutorManager;\n\n\nLjava/util/List;Ljava/util/List;Ljava/util/List)\n2013/7/30 jujumao whuims.yuanju.page@gmail.com\n\nhi, Richard\nvery appreciate for your insight in azkaban , I also notice a\nexception in a update thread, do u mean that thread died?\nWhy cause the exception? and most important how to solve it ?\n2013/7/30 rbpark notifications@github.com\n\nWhoops empty message.\nThe web server keeps a copy of the executing flow for display\npurpose\nand\nto try to catch failures from dead executor servers. However, we\nfound\non\nseveral (very rare) occasions, the updater thread may die.\nWe've done a lot of fixes in trunk that may have fixed it, but\nwe'll\nbe\nadding more monitoring soon.\nOn Tue, Jul 30, 2013 at 12:06 AM, Richard Park \nrichard.b.park@gmail.comwrote:\n\nOn Mon, Jul 29, 2013 at 7:19 PM, polaris2013 \nnotifications@github.comwrote:\n\nu're right , if i i restart the web server, the status changed\nto\nsucceed, is this because when restart, the flow is forced to\nfinalize?\nthe\nflow is not in runningflows, so can retrieve it from db. but i\ncan\nnot\nrestart for every task i submit, is there a way to solve this\nbug?\nand\nthe\nfirebug keeps showing \"flow not found exception\" when web\nserver\nfrequently\najax fetch executable Logs .\n[image: 2013-07-30 10 12 23]<\n\n\n\n\n\n\nhttps://f.cloud.github.com/assets/5111899/876181/ddff8728-f8bd-11e2-98c2-a4b267ad5dfd.png>\n\n\n\n\n\n\n\u2014\nReply to this email directly or view it on GitHub<\n\n\nhttps://github.com/azkaban/azkaban2/issues/28#issuecomment-21765576>\n\n\n.\n\n\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/azkaban/azkaban2/issues/28#issuecomment-21773282>\n.\n\n\nSincerely yours\nYuan JU\nMaster of Information Science,Wuhan Univ\nTel 86-13916450206\nEmail whuims.yuanju.page@gmail.com whuims.yuanju.page@gmail.com\n\n\nSincerely yours\nYuan JU\nMaster of Information Science,Wuhan Univ\nTel 86-13916450206\nEmail whuims.yuanju.page@gmail.com whuims.yuanju.page@gmail.com\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/azkaban/azkaban2/issues/28#issuecomment-21777742>\n.\n\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/azkaban/azkaban2/issues/28#issuecomment-21779992>\n.\n\n\nSincerely yours\nYuan JU\nMaster of Information Science,Wuhan Univ\nTel 86-13916450206\nEmail whuims.yuanju.page@gmail.com whuims.yuanju.page@gmail.com\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/azkaban/azkaban2/issues/28#issuecomment-21791790>\n.\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/issues/28#issuecomment-21813543\n.\n\n\nSincerely yours\nYuan JU\nMaster of Information Science,Wuhan Univ\nTel 86-13916450206\nEmail whuims.yuanju.page@gmail.com whuims.yuanju.page@gmail.com\n. ",
    "felix021": "you can solve this problem by modifying src/java/azkaban/webapp/servlet/ProjectManagerServlet.java on line1252, change it to:\nif(contentType != null &&\n        (contentType.startsWith(\"application/zip\")\n         || contentType.startsWith(\"application/x-zip-compressed\")\n         || contentType.startsWith(\"application/octet-stream\")))\nand then recompile it.\nI didn't recompile all the files using ant, I just did:\n$ cd web-server/lib\n$ unzip azkaban-2.1.jar\n$ mv azkaban-2.1.jar azkaban-2.1_old.jar\n$ for i in *.jar; do export CLASSPATH=$CLASSPATH:$i; done\n$ cp /modified/ProjectManagerServlet.java azkaban/webapp/servlet/ProjectManagerServlet.java\n$ javac azkaban/webapp/servlet/ProjectManagerServlet.java\n$ zip -r azkaban2.1.jar azkaban  log4j.properties  META-INF\n$ chmod +x azkaban2.1.jar\nthen restat the web-server.\n. ",
    "kingdom0719": "I guess we should  take this mime type \"application/x-zip\" into consideration. When I  use the newest Firefox to upload my project,  \"File type application/x-zip unrecognized.\" forbid me to.\n. ",
    "bugbeta": "\u65b0\u7248\u672c 3.59 \u4ecd\u9047\u5230\u8fd9\u95ee\u9898\uff0c\u53ea\u80fd\u628a .zip \u6587\u4ef6\u7684\u540e\u7f00 .zip \u5220\u9664\uff0c\u53ef\u4ee5\u6b63\u5e38\u4e0a\u4f20\u3002\u4f46\u4e0a\u4f20\u4e86\u540e\u7eedjob\u8c03\u7528\u4e0d\u6210\u529f\u3002\u8fd8\u662f\u9700\u8981\u4f7f\u7528zip\u6587\u4ef6\u4e0a\u4f20\u3002\u9700\u6dfb\u52a0 application/x-compressed . File type application/x-compressed unrecognized.. ",
    "ghost": "This is the problem, a typo in sample command file.\ncomnand.2=whoami\ncom-N-and rather than com-M-and\nIs it possible to make the code reject 'comnand'?\n. Did you find a way work through this issue ? please advise \n. Hi Luu, here is the sample . If you see, INFO is the log level how the application logs the message, but Azkaban shows them as Error \n16-09-2015 21:06:56 EDT ProgramABCDE ERROR - 15/09/16 21:06:56 INFO mapreduce.Job:  map 13% reduce 0%\n16-09-2015 21:06:59 EDT ProgramABCDE ERROR - 15/09/16 21:06:59 INFO mapreduce.Job:  map 20% reduce 0%\n16-09-2015 21:07:02 EDT ProgramABCDE ERROR - 15/09/16 21:07:02 INFO mapreduce.Job:  map 26% reduce 0%\n16-09-2015 21:07:05 EDT ProgramABCDE ERROR - 15/09/16 21:07:05 INFO mapreduce.Job:  map 33% reduce 0%\n16-09-2015 21:07:08 EDT ProgramABCDE ERROR - 15/09/16 21:07:08 INFO mapreduce.Job:  map 40% reduce 0%\n16-09-2015 21:07:11 EDT ProgramABCDE ERROR - 15/09/16 21:07:11 INFO mapreduce.Job:  map 47% reduce 0%\n16-09-2015 21:07:14 EDT ProgramABCDE ERROR - 15/09/16 21:07:14 INFO mapreduce.Job:  map 53% reduce 0%\n16-09-2015 21:07:17 EDT ProgramABCDE ERROR - 15/09/16 21:07:17 INFO mapreduce.Job:  map 60% reduce 0%\n16-09-2015 21:07:20 EDT ProgramABCDE ERROR - 15/09/16 21:07:20 INFO mapreduce.Job:  map 66% reduce 0%\n16-09-2015 21:07:23 EDT ProgramABCDE ERROR - 15/09/16 21:07:23 INFO mapreduce.Job:  map 73% reduce 0%\n16-09-2015 21:07:26 EDT ProgramABCDE ERROR - 15/09/16 21:07:26 INFO mapreduce.Job:  map 79% reduce 0%\n. We are using Azakaban 2.5 ? Is there a way to fix this in 2.5 ?\nOn Friday, September 18, 2015, Hien Luu notifications@github.com wrote:\n\nBTW, what version of Azkaban are you using? This is was fixed in 2.6.x.\nCan you try the latest version?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/43#issuecomment-141571816.\n. \n",
    "helena": "+1, but at only 42.7MB\n. I ended up automating my solution using the Azkaban restful API (auth request then upload) which worked perfectly.\n1. I have the project's CI tasks building and rsyncing the fat jar to /hadoop/myproject\n2. CI then executes a script I wrote that handles the azkaban api calls and uploads my azkaban .job .zips\nNow developers need only add a new job, git push (after testing), go to the project in CI, click a button :)\n. I have to disagree with your assessment. As I said, when I run my fat jar in EMR it runs against the cluster: \nhadoop jar my.jar com.my.JobRunner com.my.Job --hdfs\nBut when it is run by Azkaban it does not.\nAs for hadoop/conf, I wrote code that reads in all the correct hadoop configuration and in my  code check that mapred.job.tracker is not local but the correct host:port - and it is. So the only place the issue seems to lie is with Azkaban - the only place it does not run the jobs against the cluster.\n. Understood but if you read above I say that I tried all the commands for java: command, javaprocess, java, hadoopJava...\n. Yes, that was the money, your suggestion about the hadoop script. When I hard coded it to the Haddop_HOME/bin/hadoop it finds what it needs\nMy fat jar is reading from HadoopHome/conf/{ the xml files it needs } quite specifically\nThanks for helping me :-)\n. Yeah I'd really like to but everything I've tried thus far for hadoopJava has not worked. My job api is in scala using Scalding, thus the WordCount.java job sample from azkaban plugin samples does not apply - I had to decompile it to see what you are doing. If you can help me I'd be happy to contribute a scala/scalding code sample to the Azkaban docs.\nI am not clear on the following aspects:\n1. This does not seem to be picked up, perhaps that is a local issue but do you have any insight?\nclasspath=/home/hadoop/myproj/, /home/hadoop/,/home/hadoop/lib/* // these all have * after but not being picked up here\n(doing both because neither works) \njobtype.classpath=literally the same as the above classpath settings\nmain.args=com.....MyJobWriteToCassandra --hdfs\njob.class=com.....JobRunner.class\njobtype.class=azkaban.jobtype.HadoopJavaJob\nobtain.binary.token=true\nMy JobRunner is:\nimport org.apache.hadoop.util.ToolRunner\nimport org.apache.hadoop.conf.Configuration\nimport com.twitter.scalding.Tool\nobject JobRunner {\n  def main(args: Array[String]): Unit =\n    ToolRunner.run(new Configuration, new Tool, args)\n}\nWhere the scalding Tool is simply:\nimport org.apache.hadoop\nimport cascading.tuple.Tuple\nimport collection.mutable.{ListBuffer, Buffer}\nimport scala.annotation.tailrec\nclass Tool extends hadoop.conf.Configured with hadoop.util.Tool { .. }\nRight now I get class not founds - the classpath is wrong, but I\"ve also been working out expected contructor issues\nThanks!\n. ",
    "gitfrederic": "I had this issue (with only 10MB) and saw the following in the Azkaban log file:\nCaused by: java.sql.SQLException: Packet for query is too large (10771610 > 1048576). You can change this value on the server by setting the max_allowed_packet' variable.\nLooking at MySQL, I get:\nmysql> show variables like 'max_allowed_packet';\nmax_allowed_packet: 1048576\nOne way to resolve (there are others), is:\nmysql> set global max_allowed_packet=16777216;\nNOTE: Set the maximum to the largest file size you'll likely have. \nThen restart the Azkaban web server.\n. ",
    "dwatzke": "When uploading a bigger project zip file, I got the mentioned chunking error & this exception popped up in the web server log:\njava.sql.SQLException: The size of BLOB/TEXT data inserted in one transaction is greater than 10% of redo log size. Increase the redo log size using innodb_log_file_size.\nSo naturally increasing innodb_log_file_size has helped. Here's an official howto : http://dev.mysql.com/doc/refman/5.5/en/innodb-data-log-reconfiguration.html\n. ",
    "HappyRay": "I think we do now. See http://azkaban.github.io/azkaban/docs/latest/#ajax-api\nPlease let us know if that's not what you are looking for.. @juhoautio \nThanks.\nThis seems to be a useful feature. \nHowever, I just started resuming the work on DAG engine rewrite. #1486\nI would prefer implementing additional features after we have a stronger foundation. \nIn the meantime, I would be interested in your design and experience using it. . Python job type is not documented http://azkaban.github.io/azkaban/docs/latest/#job-types.\nCan you command job type work for you?\nIf there is no sufficient reason to maintain these job types, it would be easier to maintain fewer job types. This is an example of maintenance cost. . We are removing these job types. #1431. Is it still an issue with the latest code? . #872 . The branch is out of date. Could someone bring it up to date?\nHow was it tested? Any way to test it using an automated test?\n. @sathish316 have you considered using mocking objects to verify at least that the mail class gets the correct configuration?\nWe don't use the non default port currently and we don't have resources to test every change manually. If you include some automated tests, you can be more confident that your feature won't break because of a later change. \n. What I am looking for is some kind of automated tests that will ensure that the default case and the new feature continues to work. . @jamiesjc if you refactor the email code, you may consider making the port configurable.. #873 . Search for \"HTTP Job Callback\" in the doc\nhttps://azkaban.github.io/azkaban/docs/latest/#common-configurations. Thanks. \nMerged since the API design issue/question is an existing one. \n. Isn't there an opportunity for clients to specify an inconsistent project name and project ID to this API? In this case, the cost of such mistake seems to only affect logging. Would it be better to ignore the project name parameter and get the name from the project object directly? . Sorry about the delay.\nThe property files have changed.\nIt's a fine idea to add the config to the solo-server conf/azkaban.properties as an example. \nAre you still interested in this PR?. Please re-open if you are interested in continuing this PR.. Yes, I have read your issue description. \nTo answer my own question earlier:\n\"INFO - !!!! WE ARE NOT SUPPORTING JOB CALLBACKS FOR STATUS: READY\"\nIt's because the node status changes back to the ready state after the event has fired and no callback should be issued for ready state. Am I right?\n. The CI build failure is a known issue. We are working on it. I restarted the build for you.\n. Please fix the build error first before merging. \n. This seems to be a worthy fix.\nHow difficult would it be to include automated tests with this change?. Yes, @kunkun-tang added some js unit tests and setup the test frameworks.. We don't have the manpower to verify all features before every release. The expectation going forward is to have automated test for each change.  Given the test infrastructure we have, I would expect some exceptions can be made. . An exception is the UI changes since we don't have the test infrastructure set up. But at least the javascript logic can and should have automated tests.. It's fair.\n@ameyamk could you help us improve the process and communication?. As explained, automated tests are required unless a strong argument can be made for an exception.. It's a fair point. I am willing to grandfather this old PR request.\nOpened an issue #1193 to track updating the dev guide.\nThe constraint is to find the resources to review and test this change. @ameyamk can help with resourcing. \nI currently don't have the bandwidth, unfortunately.\n\nsee\nhttps://github.com/azkaban/azkaban/blob/f8fe27bdfbbbc8f8c585aaa2426fcb3a926775d5/azkaban-web-server/src/web/js/azkaban/test/test.js#L41-L41\nfor example js tests.\nSee jsTest gradle task for how the tests are invoked.\nhttps://github.com/azkaban/azkaban/blob/c8d505f0d61ac518a5e9495cd2ce0341bcfdfb5d/azkaban-web-server/build.gradle#L108-L108\nYes, we still have a long way to go to build up our UI/JS tests. We would like to start now rather than later to require new code to have tests. \n. Added #1194\n. I expect the conflicts are mostly formatting changes. If you take yours and apply saveAction plugins on top, I hope it will work with minimal effort.\nPlease work with @ameyamk to make sure someone will be working with you first. I wouldn't want to disappoint you again :(\nSorry about the delay. I wish we had more resources to work with external contributors. We all get busy. Things fall through the cracks sometimes. . @juhoautio if you or @artem-garmash is still interested in finishing this PR,  I will try to find some time to review this change or convince someone to review this change. . @artem-garmash \nThanks! \nCould you also add more details in the change description? What @juhoautio explained above is useful.\nThis change makes sense to me.\nI will try to find someone to review this change.\n. FYI @jakhani has agreed to review this change.. Any reason why this one was not merged? @kunkun-tang . Thank @kunkun-tang \n. @chengren311 is this PR still useful after your change in #894?. Sorry @bmsq for not responding to your PR. We need to improve our turn around time. Given other priorities, reviewing PRs especially the ones we don't have an immediate need sometimes fall through the cracks. \n. Thanks. There is no need to rush unless you have an immediate need for it.\n. @bmsq are you still interested in working on this PR? Sorry about the delay.\nThis seems to be a useful feature although we don't have a need for it now. And testing this change may be tricky since we currently don't have automated UI testing. Can you think of any way to include some automated tests? . Could you add your recent changes to this pull request to facilitate a faster review?\n. Thanks for making the suggested changes!\nIt looks much better now. I like the comments you added.\nI have a pull request pending https://github.com/azkaban/azkaban/pull/659 which added some unit testing facilities that can be used to test UI elements. You may consider taking advantage of that if you would like to go extra miles in testing. \n. The test code looks more comprehensive and easier to understand now.  I like the comments you added to the tests. Thanks!\n. You may want to wait until I merge my pull request I mentioned earlier to take advantage of the UI test capabilities if you would like to give it a try. \n. My pull request was merged yesterday.\n. LGTM. Thanks! \nI have added only one small suggestion.\nCould you please debase and collapse the commits into one?\n. You can login using your github account to try the test again. I am not sure if you need to be a project admin to do that though. I restarted the test. \nDid you take a look at the failed test? Is it a flaky test?\n. @evlstyle \nI added another commit to fix the issues we discussed in person. \nThanks for your review!\nIf it looks ok to you, I will rebase and submit another pull request with the rebased change.\n. @wagnermarkd Thanks for the comment.\nI think the refresh button can still be useful when a user wants to refresh the log display e.g. when the job is still running, or when the download was disrupted somehow.\n. LGTM\n. @EdwardsBean \nWhat tests have you done?\nWhat happens if the table was created using the original default character set ( Is it Latin1?) and they run this code to read from that table?\nDo other tables suffer from the same issue? \nHow about project descriptions?\nCould you include unit tests? \n. @EdwardsBean are you referring to \nazkaban.project.JdbcProjectLoaderTest#testProjectRetrievalByFetchProjectByName ? It doesn't test non-ascII characters, does it?\nThe test is currently skipped for me because it requires a test DB to be setup. But the instruction is not clear how it should be set up. As the result, I don't think it runs on the CI system automatically.\n\nAccording to \nhttp://stackoverflow.com/questions/7048745/what-is-the-difference-between-utf-8-and-iso-8859-1\nOnly the ASCII characters are compatible between these two encodings. \nIf so, there can be problems reading tables created with latin1. \nA DB update may be needed.\n. Sorry about the long delay.\n@EdwardsBean  Are you still interested in working on this PR? \nIf you can merge in the latest code, I can consider merging it now that we have functional DB unit tests using in memory H2 DB.\n@kunkun-tang @li-afaris  what do you think?. Thanks @juhoautio for the pull request!\nI agree that this message is confusing. \nI assume you included the flow status so that users don't have to click the link to see if a flow has been killed or failed. \nThe code is duplicated in two places. What do you think of changing the azkaban.executor.mail.DefaultMailCreator#createErrorEmail method to always include the flow status so that this extra information is included in both cases and also in other code paths that would call into this method?  \nAnd remove the extra reasons from these two places. The last extra reason seems redundant. If a flow has failed or been killed, doesn't it imply it is no longer running?\n\nAlso could you make the change description a bit more descriptive like what you have in your comment? \n\nCould you include in your change description how you tested this change? Ideally a screenshot with the test result would be great. \n. Thanks for the suggestion.\nI am interested hearing more specific use cases. e.g. why is this feature useful for you. . @mukund-thakur \nThanks. It makes sense. \nMay I ask what your design is? We are thinking about implementing this feature in the future.. Thanks.. @mukund-thakur Your design should work. \nHowever we are thinking about scaling out the web server. One option we are considering is to leverage a distributed queue to distribute flows/jobs. This may affect the design of the executor pool and flow priority support.. @logiclord looks great to me. \nDo you mind responding to other reviewers' comments so that we can merge this change soon.\nSince the HadoopShell job type is similar to the Hadoop Java job type, what do you think about just referencing the Hadoop java job type documentation and only highlight the differences. This way the documentation is not duplicated and it makes future updates to the common portion easier. However there are benefits of reading one job types's configuration in one place.\nThanks!\n. Very nice description! Thanks for the screen shots and tests.\n. Looks good to me. \nThanks for creating a new pull request to keep the change history cleaner.\nDo you mind doing the same for the new changes?\nIt would be great if you can separate the logging change into a separate pull request since that seems to be an independent change. \n. @juhoautio Thanks for your contribution!\n. @juhoautio you are welcome. I should thank you for your contribution instead.\nI wish I had more time working with the community. I've been very busy at work lately. \n. Could you reference the commit that introduced the regression? \nWhen the setting is set, users with createproject permission can also create projects. You may want to reference the documentation about this setting in your change description.\nPlease include what tests you have done.\nThe code change LGTM.\n. LGTM. Could you squash the commits?\n. Thanks!\n. Sorry about the long delay. \nThis seems to be useful.\nThe new config keys need to be defined in azkaban.Constants now. And see my comments in #598\n@jamiesjc could you take a look when you get a chance?\n. Are these configs for mails specifically? \nI would imagine there are other use cases where the user facing AZ url generation are needed. \nIf so, can you name these parameters more generically?\nI can't think of good names myself e.g. azkaban.server.hostname.external?\n\nCould you help me understand the relationship between these parameters and jetty.hostname?\nWhat's your set up? How is jetty.hostname used in your setup?\n. Typo: parameters. Your proposal LGTM.\n\nDoes it make more sense to describe it in the opposite direction?\nlocalhost:8081 -> proxy -> myazkaban:443 -> enduser\n user -> ...\n\n\nmail hostname and port parametters, when this parametters set then these parametters are used to generate email links.\n\nMove it to the end of the description as an example of how this information may be used?. The .external doesn't seem right as a subcomponent.\nHow about\nazkaban.webserver.external_hostname\nazkaban.webserver.external_ssl_port\nazkaban.webserver.external_port\n?. Thanks!. Thanks for the PR and sorry about the long delay.\nMaintaining a copy of the SQL DDL statement is error prone. Since we only use mysql DB. We can't easily provide good test coverage for other DB backends. And the provided automated tests seem to require some additional set up in order to be effective. \nAnd the DB code has been refactored recently.\nWe can consider adding this support if the code is structured in such a way that maintaining it wouldn't be too hard. . @huangfushun \nThanks.\nAnother way is to try to use standard SQL features.\nDo you remember the causes for treating the new DB differently other than creating the DB source differently?. Thanks. If you can summarize these differences, it will help us move in that direction.. Thanks for updating the doc!\n. @suvodeep-pyne \nThanks for your help with the project!\nCould you create an issue and associate it with this pull request? This way if you create a new pull request, you can associate it with the same issue.\n@juhoautio do you see a problem with dropping Java 7 support? \n. @juhoautio Thanks for your comment.\n. @suvodeep-pyne I like your comments in your change.\n. LGTM. Let's give the community members a few more days to comment on dropping Java 7 support. I will remind myself to merge this change by next Wed. What do you think?\n@suvodeep-pyne Could you prepare a pull request to remove java 7 test in travis-ci?\n. @juhoautio Thanks for the review and suggestion.\n@suvodeep-pyne \nLet's create a new release tag as you suggested.\nCould you also start a discussion about dropping Java 7 support in the mailing list and reference the issue you created?\n. I used the squash option to merge this pull request as described at\nhttps://github.com/blog/2141-squash-your-commits\nIt seems to work well. I can still see the individual commits Suvodeep made and its associated comments.\nThe only issue I noticed was that in the conversation view, the link to the full diff is not working. But if I go to the file view, all the contexts are there. So this doesn't seem to be a big deal. This may not be an issue if I commented on the commit view instead of the file changed view.\n. @fsi206914 do you think you can fix this? This is a simple fix.\n. @fsi206914 could you resolve the conflicts?\nCould you add a link to the issue #693 in your change description? \n. @fsi206914 Did you run into this problem the last time you set up a new cluster?\n. Is this still needed?. The logic LGTM. Thanks\n. Could you make the commit description more descriptive and self contained if you intend to merge this one?\n. Relate to #693 \n. It would be nice to add automated tests. How hard would it be?\n. @kunkun-tang what's your plan for this PR?. LGTM\n. LGTM. Please resolve conflicts.\n@fsi206914 did you test this change?\n. I tested the feature without your change on Safari, Firefox and Chrome and they all worked. Does this fix only help in IE?\n. How do you plan to deal with the js being cached? \n@fsi206914 chose to add a date based version number to the js include statement in one of his changes to force js files to be refreshed. \nI am not too worried about this one though since using the older version seems fine for most users. \n. LGTM. Thanks for making the code better!\nWhat testings have you done?\nClarify in the description the benefits of this change i.e. no longer need to check in the js files?\n. Can you reference the same issue? \nAnd update the pull request description unless you plan to use another pull request for the final merge?\n. LGTM\nI can't merge because of the test failure though. \n. You will need to rebase anyway. That should trigger another build/test.\n. Could you add a comment in the source code explaining why these tests are skipped?\n. Could you add more details on the commit message?\ne.g.\nreference the issue number,\nexplain how to enable this feature\nadd the summary of this change.\nThe commit message is what people will see when they do git log.\n. Where did you \"explain how to enable this feature\"? \n. I took a closer look at the change. Now I understand the confusion now. I thought you planned to show the old UI by default. \n. Great. In the future, could you add information about what tests are included in the commit message too?\n. Nice change description!\n. Please resolve the conflict and feel free to merge.\nIn the future I would suggest keeping the unrelated changes separate e.g. the UI change seems to be independent from the syntax conversion.\n. Have you checked why the ci build failed?\n. Explain in your comments why you changed the exceptions?\n. You have conflicts. \n. Pls resolve the conflict and ensure the check passes. \n. \"the hadoop security code to managed\" do you mean \" to be managed?\"\n. I wonder if we should remove the old code in the plugin repo instead to avoid confusion. Let's discuss off line.\n. Consider opening an issue that describes your overall plan for the plugin repo and link to this commit?\n. Explain why you combined these two projects and why you left out the hadoopsecuritymanager project?\n. Thanks for taking on this long overdue tech debt clean up effort!\n. Other than the suggestions above,  LGTM.\n. How did you test this change? Could you add that information to the commit description?\n. Thanks @logiclord for answering questions.\nThis is an interesting use case. I haven't seen enough demand yet to make it a priority. The team is busy automating the build, deployment, making it easier to operate in a large environment, fixing bugs etc.\n. Please clarify what \"this\" means in your commit description.\n. LGTM\n. Could you please explain why automated test is not included? \n. LGTM. Thanks for the improvements!\nMaybe add to the description as to why no automated tests are included in this pull request?\n. I noticed that you made some other improvements as part of this pull request as well.\nIt would be great if you can mention these changes in the change description.\nMaybe consider mentioning that the proposal to retire java 7 support has been published in the associated issue for over a month now and we haven't received any objection. \nLGTM\n. LGTM\nIt appears that this project is not complete. The test resources may still be useful?\n. \"Enforce gradle to download nodejs every time, in order to resolve npm can not be found issue.\" Is this going to slow down the build process? Is there no other way? How did others solve the same problem?\n. @suvodeep-pyne could you take a look?\n. LGTM. Thanks for adding the first JS unit test. With your work, adding more JS unit tests will be easier.\nThanks @suvodeep-pyne for the through review.\n. LGTM. Thanks!\nOne copyright notice date is still 2014. But I can merge it as it is.\n. LGTM, please update the branch again. \n. What do you think about adding a link to the wiki page which has more details?\nWhat do you think of moving our docs to the wiki in the future which is easier to update?\n. Can the AZ code itself look for the log4j config in the config directory first?\n. Another advantage of having the code search for the conf dir first is that it will remove the duplicate logic for the three scripts.\n. Discussed with Kyle off line. It's tricky to add the conf directory to the search path before log4j is initialized.\nSo we will go with Kyle's original design.\nThanks\n. I believe we have to use the internal version of Kafka. Have you check with the Kafka team?\n. Seems to make sense to me.\nFor my education, could you give an example of how the build directory variable is set and how it may be different from \"build\"?\n. Thanks\n. Thanks @jwoschitz !. I have the same question. Why shouldn't we always execute as user? If so, should we remove all references to it? e.g. in the run method.\n. Thanks @evlstyle !\n. LGTM\n. @pranayhasan since the issue is closed, should this PR be closed too?. Thanks for reporting this. \nRemoved the binaries that have issues.\n. Did you restrict the proxy user list?\nFrom the doc http://azkaban.github.io/azkaban/docs/latest/\n\"If proxy users are turned on, proxy users allows the project workflows to run as those users. This is useful for locking down which headless accounts jobs can proxy to. They are removed by clicking on the 'Remove' button once added.\n\"\nDid you login as an admin?. Consider adding a unit test for validateQuartzStr ?\nWhat testing have you done?\n. Thanks for adding tests!\n. LGTM. Thanks for doing the research.\n. As discussed, pls create a ticket to track future enhancement including our discussion of the alternative approach of using an exception to return the errors. \n. LGTM\n. Would it be better to make \n\"azkaban.job.kafkalogging.brokerlist=localhost:9092\nazkaban.job.kafkalogging.topic=azkaban-web-server\"\nconfigurable by the Azkaban server administrators. \nUsers don't necessarily know or care about this details. And it would be more reliable to have a centralized place to control this information.\n. Without unit tests, how do you protect against regressions? . Could you update the change description to reflect your new changes?. @fsi206914 Is it time to remove the code for the old scheduler UI and the control switch/config?\n. You may want to reference the old pull request you abandoned. \n. Please consider cleaning up the commit messages before merging. \n. The concern is that some users may still rely on it. \nMaybe we can leave it there for now?\n. @fsi206914 you set up a new cluster not long ago. What do you think? Shall we update the scripts. It's been a long time since the DB schema update. Maybe we can optimize for the new installations now.\n. @fsi206914 Maybe we can update the script as part of setting up a new staging cluster?\n. Can we keep a copy of the sample configs somewhere so that people can use them as a reference?\n. What will be logged if the log4j.properties files are removed and there is no log4j configs provided via the command line? I thought these files provide default logging settings for the application.\n. Maybe we can keep the config in the solo server as an example and make solo server easier to setup? see #800 \n. @suvodeep-pyne I thought the default log4j config will be replaced by an external config if provided. What exceptions did you run into? \n. Could you make the description more descriptive? e.g. remove the need for a private function to make the code easier to read.\n. It seems that most of the logic in the two setup methods are the same. Duplicate the logic will work. However it may make maintenance later harder.\nI know this is legacy code. But as we touch them, I'd suggest we improve it whenever we can. Gradually the code base will become healthier one step at a time.\nIt's up to you. I made it a comment only not a required change. \n. @jamiesjc please update the documentation as needed to reflect the new default. \nWhen we release a new version, we need to highlight this change. A user who upgrades will need to know the new behavior and adjust their configs accordingly..\n. LGTM\n. Reminder, please use the github feature to clean up the commit message before you merge.\n. How did you test this change?\n. Thanks for cleaning up the code.\n. \"No additional functionality was added by existing pieces of code was used.\" Do you mean \" no other additional functionality was added? \"\n. LGTM.\nIn the future, the API change seems to be independent of the port change. I would suggest making the independent changes separate pull requests.\n. In \npublic void uploadProjectFile(Project project, int version, String filetype,\n      String filename, File localFile, String uploader)\n      throws ProjectManagerException {\n    logger.info(\"Uploading to \" + project.getName() + \" version:\" + version\n        + \" file:\" + filename);\n    Connection connection = getConnection();\ntry {\n  uploadProjectFile(connection, project, version, filetype, filename,\n      localFile, uploader);\n  connection.commit();\n  logger.info(\"Commiting upload \" + localFile.getName());\n} catch (SQLException e) {\n  logger.error(e);\n  throw new ProjectManagerException(\"Error getting DB connection.\", e);\n} finally {\n  DbUtils.closeQuietly(connection);\n}\nDoes it make sense to do\nconnection.rollback();\nin the catch block?\nSee \nhttp://stackoverflow.com/questions/15761791/transaction-rollback-on-sqlexception-using-new-try-with-resources-block\nThis may be important when we implement connection pooling.\n. Consider explaining how this change would solve the problem and how it handles error cases.\n. Do you plan to make the same change to our internal version of shutdown scripts too? Or do you plan to start using this version?\n. LGTM.\nI noticed that you reformatted the code in this change as well. It's good to clean up the code. However it makes it a bit harder to review and trace the change history later IMHO.\n. How did you test?\n. Could you add unit tests?. How did you test?. @jamiesjc could you review this change?. The file database.properties is referenced in  azkaban.database.AzkabanDatabaseSetup#findOutOfDateTable.\nAre you sure it is no longer needed? If no, shall the code the references it be updated too?. Consider mentioning logging the time it takes to clean up the log table in the change description?. These job types are not documented. I am curious if these job types over significant value over simply using the command job type.. These job types have been removed. #1431 . This seems to be a good change to make.\n@suvodeep-pyne  what do you think?. Thanks for your contribution!. Yes, this is a good idea.\n@kunkun-tang just added one. See #994 \nIt would be great if you can help.. Ping. Are you still interested?. Discussed the PR in person. The eval method will be called by the scheduling thread in a regular internal. That part hasn't changed.\nLGTM.\nThanks for adding unit tests and making the code easier to read and maintain!\n. @mariacioffi Thanks for this PR.\nFor reference, # syntax is documented at http://www.quartz-scheduler.org/api/2.2.1/org/quartz/CronExpression.html. Looks like it is already configurable. . Please reference the existing PR on which yours bases.\n. Please describe the PR in more details in your change description.. #395 . Thanks for your quick response.\nPlease update your branch.\nDid you run an end to end default port test?. I manually tested the default port in a test environment.. Thanks!. @mariacioffi \nThe change LGTM.\nCould you include a unit test now that we have enabled memory based H2 DB tests? \n. @kunkun-tang any reason this one was not merged?. @kunkun-tang can this PR be merged if it is updated?. I don't see the problem with the original code either. \nHow would the new code work when the oldProps is null? Wouldn't the sql update command fail?. LGTM. Thanks for documenting the gh-pages README too!. @suvodeep-pyne When a new flow is uploaded, I believe the current behavior is that everything will be reset. But the executed flow will use the updated version if the flow still exists.. Could you consider making the description more descriptive?\ne.g.\nPrevent a new inactive executor instance from deleting old project files.\nAnd then describe the details.\nAlso explain that this variable only indicate if the executor is active or not. The flow manager will still serve requests regardless. . I don't see an automated test included. Is it possible to do? . Are you referring to this project https://github.com/researchgate/azkaban-ldap-usermanager?\nIf so, could you file a bug against that project?\nThanks. Thanks for reporting and debugging this issue!. * Have you considered using a command \"cp -arl\" instead?\n Could you add automated tests?\n The logic for running a shell command can probably be factored out to its own reusable component.\n* Since we are not using soft link, I'd suggest we only add it when needed.. Could you add more details to the description explaining why the other executor may delete the project files being used by another process? . The design relies on external programs to call the new APIs to make sure only one executor instance on a given host is active. Only the active one will delete old project files. \nThe following is still possible:\nInstance A starts downloading a project.\nBefore A finishes, B is deployed and made active. B starts downloading the same project.\nBecause the download process will download the project to a temp location first and do a file move atomically, only one copy will be preserved.\nHow will this change work in that scenario?\nAm I right that depending on timing, A may hard link to the first copy or the second? No deletion should take place since this is a new project.  I think it will be fine. What do you think? \nCould you add this design consideration in the change description as well?\n. Does it make sense to add a test that test the deep link behavior? i.e. delete the source dir and test the link still works? . LGTM. Thanks. It's currently not supported.\nCould you explain your business case i.e. why this feature is useful for you? . @chengren311 do you think this error may be related to your recent changes?. If I understand your change correctly, you are adding stack trace to the log. Previously only the exception message is logged. Am I right? If so, could you clarify in your commit message?. Thanks. @kunkun-tang what's your plan for this PR?. I think this PR can be postponed for now. We can pick it up again in the future. How about labeling it and closing it for now?. @wyukawa sorry about the long delay.\nThis seems useful.\nAre you still interested in this PR?. @wyukawa \nIf you can update your PR, I will try to find someone to review this change.\nPlease follow the updated README to set up the coding style config.. Thanks. I've asked the team members for volunteers. It may take some time.... @wangqiaoshi sorry about the delay. I am not sure I follow.\nCould you explain what the problem was and how the fix solved the problem?. ping. I understand your use case. Nice presentation. Thanks for being a champion for the project!\nOne of the benefits of keeping the API surface area small is to make automated testing simpler. We would like to have automated tests to cover all APIs. \nI would prefer returning the schedule id in this API which is useful anyway regardless. Is it too much work on the client side or multiple call latency a big issue in your case?\nAny code refactoring/cleaning up contributions are always welcome. . I am glad we are on the same page. :)\nAny contribution to documentation will be appreciated. \nThe refactoring change you made makes sense to me too.\nCorrection:\nI checked the code and saw that scheduleId is returned by the ajaxScheduleCronFlow and ajaxScheduleFlow APIs. \ncc @kunkun-tang . @sunghyuk  Thanks.\nThese packages are designed for production use. I think it makes more sense for the configs to be managed separated, possibly in a separate Git repo. \nThe solo server is designed for non production use. @juhoautio is doing some work there to improve the experience. See #1423 . Hi, sorry for the delay.\nCould you provide more details in the repro steps in the change description and how you verified the fix worked?\nI am not sure I understand the problem and the fix. Could you elaborate in the change description?\nThe logging change looks good. \nPer google style, LOGGER should be named logger. \nPlease see the udpated readme for the contribution guide.\nCould you open a separate PR for the logging change? We can merge that one quickly.. @shelocks Ping. Are you still interested in this PR?. Looks like it overlaps with #873 . Could you give an example?\nCould you provide automated tests?. Please remember to update your change description before you merge. Please include a short description of your refactoring change.. @li-afaris It looks like h2 DB should support this insert syntax. See\nhttp://www.h2database.com/html/quickstart.html\nIt worked for me.\nWhat problem did you observe?. @li-afaris I found out what the problem was.\nH2/SQL requires the single quote. MySQL seems to also accept the double quote.\nThe following worked for me:\n\n-- Populate enum values into lookup table\n\nINSERT INTO execution_flows_status (name, status) VALUES\n  ('READY',10),\n  ('PREPARING',20),\n  ('RUNNING',30),\n  ('PAUSED',40),\n  ('SUCCEEDED',50),\n  ('KILLED',60),\n  ('FAILED',70),\n  ('FAILED_FINISHING',80),\n  ('SKIPPED',90),\n  ('DISABLED',100),\n  ('QUEUED',110),\n  ('FAILED_SUCCEEDED',120),\n  ('CANCELED',130);\n===\nAlso, does it make more sense to make the status column the primary key so that it is indexed? The intended use case is to join based on the status code, not name. Right?\n. LGTM. I would suggest a shorter overall wait time, though. Maybe reduce the wait time between retries? . LGTM. @chengren311 what's the advantage of using \"volatile\" which code did you refer to?. LGTM. Great. This feature will be useful.\nHow do you decide which project to delete? \nWhat does projects.retention.ms represent? What do you think of a max size of the cache config? \nPlease see the new config name naming convention at\nhttps://github.com/azkaban/azkaban/blob/master/azkaban-common/src/main/java/azkaban/constants/ServerProperties.java and other files in this directory.\n. I see. \nI misunderstood the issue. I thought you were referring to the unbounded growth of the project directory ( cache ) disk space on the executors.  By max size of the cache config I was referring to setting up a max limit on how much disk space the project cache can consume.\n===\nYou are referring to deleting project data in the DB. Right?\nUnlike logs, there is an expectation that the DB contains the source of truth for a project definition and unless the project owner deletes the project, that data should be kept. \nI have to check the code to verify when the modified_time is updated. The name suggests that it is updated whenever a new version of a project is uploaded. Is it safe to delete when such a project may still be actively used? \n. It's a known issue with the current design. We are working on a solution that will allow ivy coordinates of jars to be specified for a project instead of including them in the zip. \nThere is a configuration that controls how many old versions of projects to keep. How many versions of your old projects do you current keep?\nHow do you make sure that the deleted project is not going to be used? Are you just deleting the project files or deleting the entire project? . Are you referring to azkaban.project.ProjectManager#purgeProject?\nThis will only delete the older version of projects, right? \nWe only keep the active project files. All important project files should be in source control. \n. Could you add monitoring in a follow up change?\nPlease include in the change description how you manually tested the change. \nI understand automated testing in this code is difficult. Given the importance of this change, I am ok with checking it in now and get some benefit out of it faster. It would be great if you can add automated tests in the future. \nLGTM after you addressed the earlier comments.. Pls search for Execute-As-User in the main doc\nhttp://azkaban.github.io/azkaban/docs/latest/\n. Yes, we would like to scale out web servers too.\nWe are actively researching ways to do that. e.g. use a message queue such as Kafka to hold the runnable flow queue instead of keeping this state in the web server. \nIdeas are welcome. . I believe it already escapes some characters. Do you have a consistent way to reproduce this issue?. Could you describe how you test this change? I can't find existing unit tests for this class.. What's the rollback strategy if something goes wrong?. Are there places where later calls can use the previous DB call results in the context of the same user request? How does it affect consistency?\ne.g. one user request translates to  get all projects, doing something else, get one project.\n. If we refactor project class and separate out the mutable states from immutable states, can we cache project information? . Removing the project related cache is not enough to scale out web servers. e.g.\nazkaban.project.JdbcProjectLoader#createNewProject(java.sql.Connection, java.lang.String, java.lang.String, azkaban.user.User) there will be a race condition if two users try to create projects with the same name at the same time.\nCurrently the name column is not marked unique, it may work if we change it to unique and let one of the insert fail.. I don't see anywhere in the non test code that azkaban.project.Project#isActive is used.. Is the SLA feature what you are looking for? search for SLA in \nhttp://azkaban.github.io/azkaban/docs/latest/. Thanks!. Thanks! Much appreciated.. Thanks!\nBTW, we are planning to add these configurations in the flow config files so that they can be defined as part of the flow and checked into source control as the flow definition. . Could you describe how you plan to use this feature to support rolling upgrade?. LGTM. I hope you can move this logic to executor as discussed earlier.. Both will work. I have seen examples of both styles. \nI like adding separate .gitignore files to sub-directories better since it limits the scope and gives better and more explicit control.. The code suggests that the name represents flow name+job name. It's not a file name.\nSee \nazkaban.executor.JdbcExecutorLoader#fetchLogs\nazkaban.executor.JdbcExecutorLoader.FetchLogsHandler\n===\nDid you run into issues with this limitation?\nWhy not go for 512 since this is varchar?. @hanny24 ping, are you still interested in working on this?. Close due to inactivity.. LGTM.\nPlease include more details in the change description when you merge as discussed in person.. Here is my understanding of this fix:\nUse fixed versions of dependent js libraries.  \nIssue: \nWe used ^ to use compatible versions of the js libraries in our build process.  See https://docs.npmjs.com/misc/semver \"Caret Ranges ^1.2.3 ^0.2.5 ^0.0.4\" for details on what compatible version means. \nIn issue #975, the build pulled in moment-timezone 0.5.13 which changed a name of the js file which this project explicitly depends on.  \nBased on this experience, it seems safer to specify the fixed versions and upgrade explicitly.\nI think we should evaluate how we reference this library and add unit tests. . Thanks for fixing this and adding tests!. Also is there a way to fail the build if a file being copied doesn't exist?. Is there a gradle config that will fail the gradle build process when the file is copied? . Related to #933 . Looks like we are using a very old version of mysql jdbc driver ( 2013 version).\nsee https://dev.mysql.com/doc/relnotes/connector-j/5.1/en/news-5-1.html. LGTM. What do you think of creating an issue for this PR and describe what we intend to do? \nThis is a relatively big change. Having an issue to tie the PRs together may be useful. \nAnd it also helps us to communicate with the OSS community.. @suvodeep-pyne Yes, we should fix that dependency.\nI tested manually the basics in our test cluster.. Requested the version to be imported to our internal artifactory.. Thanks. Will merge after the package is imported into internal artifactory.. LGTM. \nBecause a large block of code is moved around, it is hard to review. It would be great if you can describe in the change description the general strategy you used in this change. . Thanks for the cleanup!. This is great. I like the new code much better. Thanks!. I am thinking of using assertj's floating point assertions. \nBut that is not the only problem. That part of the testing doesn't seem to be a high priority right now.  So I am delaying that part. . Is it better to make DatabaseTransOperatorImpl package private?. This is a strange test failure on Travis:\n\"azkaban.utils.OsMemoryUtilTest > canReadMemInfoFileIfExists FAILED\n    java.lang.AssertionError\n        at org.junit.Assert.fail(Assert.java:86)\n        at org.junit.Assert.assertTrue(Assert.java:41)\n        at org.junit.Assert.assertTrue(Assert.java:52)\n        at azkaban.utils.OsMemoryUtilTest.canReadMemInfoFileIfExists(OsMemoryUtilTest.java:20)\n258 tests completed, 1 failed, 21 skipped\n:azkaban-common:test FAILED\"\nThe same test worked fine on my Linux test machine.\nAnd Travis didn't catch the real test failure somehow previously. See my second change set.\n. solo server already has the file.. I don't see a clear difference in speed.\nI will close this PR now until I see a clear evidence that jcenter is better.\nsee #1161 for details.. @xkrogen The general expectation for new changes is to include automated tests. However I understand making the existing code easier to test is by itself a challenge. It may take more effort than the change itself. \nIf the change is urgent, I am ok with a two step process: test manually first to get the change in, add automated tests later.\nWe can discuss what makes this code hard to test and what strategy we can use to refactor it to make it testable. Can you think of ways to test a small portion of the code you will touch? \nPlease work with @suvodeep-pyne and @chengren311 who are working on executors. . Looks Gobblin project uses a modified google java style as well.  http://gobblin.readthedocs.io/en/latest/developer-guide/CodingStyle/\n. It would be great if you can add instruction on how to apply this style. \nThanks!. Thanks @suvodeep-pyne \nYes, I agree other users can search for this information. However if you would like your effect to have the maximum effect, it is better to make it as easy as possible for your users.\nAfter following your link, it is still not clear to me how to apply the styles. So I searched again and found this instruction\nhttps://www.jetbrains.com/help/idea/2017.1/configuring-code-style.html\nThis seems to be a more direct instruction from the vendor itself. \nAnd I have to turn off Linkedin CheckSytle in the other settings. It appears that the coding style setting doesn't replace the functionalities provided by checkstyle. e.g. According to https://google.github.io/styleguide/javaguide.html#s5.1-identifier-names \" Identifiers use only ASCII letters and digits, and, in a small number of cases noted below, underscores. Thus each valid identifier name is matched by the regular expression \\w+ .\"\nWhen I added a _ in front of a member variable for testing, the ide didn't give me a warning.\nDo you know if there is more that need to be done to enforce the coding styles?\nAlso, the https://www.jetbrains.com/help/idea/2017.1/configuring-code-style.html shows that intellij also supports\nhttp://editorconfig.org/\nThis seems attractive since it makes applying consistent styles across editors easier. \nHowever, it doesn't appear that the options are as extensive. \nIt's worth looking into though.\ncc @chengren311 \n. Following the intellij help page, I was able to import the xml file and copy it to the project. I haven't verified it is working though. . Yes, updating the README is better than putting this information in a PR. When I suggested adding instructions, I meant adding instructions in a place where you think will be best to serve the purpose. :). \"We have different job set running on different servers\" could you share more details on why you need to set it up this way? . \"if we need to run different job on different executor server\" Could you describe more details of your use case? Why is it a requirement?. @huangfushun \nThanks \nHave you considered using a shell job to launch these jobs remotely on a different host? \nCould you point me the specific doc for this feature in Oozie?\n. I see. Thanks.\nYou can already write jobs that communicate with a remote host.\n. Azkaban currently only supports one web server configuration.\nI am curious about your use case of using multiple web servers.. According to this article\nhttps://community.hortonworks.com/articles/56702/a-secure-hdfs-client-example.html\nyou shouldn't need to use doas since you are not impersonating. What did I miss?. What happens if you run the tests while making sure that system default Kerberos ticket cache is empty? \n. @suvodeep-pyne do you mean the code before this change worked at least for a while, while making sure that system default Kerberos ticket cache is empty?. According to this http://stackoverflow.com/questions/34616676/should-i-call-ugi-checktgtandreloginfromkeytab-before-every-action-on-hadoop, \n\"\nCan I rely on the various Hadoop clients they call checkTGTAndReloginFromKeytab whenever it's needed?\nYou can rely on this if your application's usage pattern is to call the Hadoop clients, which in turn utilize Hadoop's RPC framework. You cannot rely on this if your application's usage pattern only calls the Hadoop REST APIs.\n\"\nThe renewal should be taken care of for you. . This MR method doesn't use doas\norg.apache.hadoop.mapreduce.JobSubmissionFiles#getStagingDir\n/**\n   * Initializes the staging directory and returns the path. It also\n   * keeps track of all necessary ownership & permissions\n   * @param cluster\n   * @param conf\n   */\n  public static Path getStagingDir(Cluster cluster, Configuration conf) \n  throws IOException,InterruptedException {\n    Path stagingArea = cluster.getStagingAreaDir();\n    FileSystem fs = stagingArea.getFileSystem(conf);\n    String realUser;\n    String currentUser;\n    UserGroupInformation ugi = UserGroupInformation.getLoginUser();\n    realUser = ugi.getShortUserName();\n    currentUser = UserGroupInformation.getCurrentUser().getShortUserName();\n    if (fs.exists(stagingArea)) {\n      FileStatus fsStatus = fs.getFileStatus(stagingArea);. The existing AZ code you pointed it \"There is similar code pattern inside Azkaban itself: https://github.com/suvodeep-pyne/azkaban/blob/d854fb04b71cfea0bc68dc03086e7128f4b4e7b4/azkaban-hadoop-security-plugin/src/main/java/azkaban/security/HadoopSecurityManager_H_2_0.java#L219-L231\" seems to be the impersonation use case which requires doas. \nWhat you proposed may turn out to the right thing to do. There are still conflicting signals, however. I don't feel I understand the problem and usage pattern well enough yet. I am concerned about hidden problems if we don't completely understand the behavior. \nI haven't found any Hadoop documentation that says that doas is required for non-impersonation use case. \nI would expect a simpler pattern to work:  login from the keytab once when the service starts up and make hdfs calls as normal. \nCan you try the example in \nhttps://community.hortonworks.com/articles/56702/a-secure-hdfs-client-example.html\n?\n```\nConfiguration conf = new Configuration();\nconf.set(\"fs.defaultFS\", \"hdfs://one.hdp:8020\");\nconf.set(\"hadoop.security.authentication\", \"kerberos\");\nUserGroupInformation.setConfiguration(conf);\nUserGroupInformation.loginUserFromKeytab(\"hdfs-user@MYCORP.NET\", \n   \"/home/hdfs-user/hdfs-user.keytab\");\nFileSystem fs = FileSystem.get(conf);\nFileStatus[] fsStatus = fs.listStatus(new Path(\"/\"));\nfor(int i = 0; i < fsStatus.length; i++){\n  System.out.println(fsStatus[i].getPath().toString());\n}\n```\n. I tried a modified example referenced above\nsee \"Via Keytab\" section. Note that this example doesn't require passing in a JAAS config file. It's very similar to your implementation before this change.\nThe code worked without problem as I expected for two days. \nI am curious why changing to doas would affect the behavior in your test.\nTest code:\n```\npackage ray.hadooptest;\nimport java.io.IOException;\nimport java.time.Duration;\nimport java.time.LocalDateTime;\nimport java.time.format.DateTimeFormatter;\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.FileStatus;\nimport org.apache.hadoop.fs.FileSystem;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.security.UserGroupInformation;\npublic class SimpleHDFSClient {\n  public static void main(String[] args) throws IOException, InterruptedException {\n    SimpleHDFSClient client = new SimpleHDFSClient();\n    client.listRootFolder();\n  }\npublic void listRootFolder() throws IOException, InterruptedException {\n    Configuration conf = new Configuration();\nUserGroupInformation.setConfiguration(conf);\nUserGroupInformation.loginUserFromKeytab(\"...\", \"...\");\n\nFileSystem fs = FileSystem.get(conf);\nwhile (true) {\n  printCurrentTime();\n\n  FileStatus[] fsStatus = fs.listStatus(new Path(\"/\"));\n  for (int i = 0; i < fsStatus.length; i++) {\n    System.out.println(fsStatus[i].getPath().toString());\n  }\n  Thread.sleep(Duration.ofMinutes(30).toMillis());\n}\n\n}\nprivate void printCurrentTime() {\n    DateTimeFormatter dtf = DateTimeFormatter.ofPattern(\"yyyy/MM/dd HH:mm:ss\");\n    LocalDateTime now = LocalDateTime.now();\n    System.out.println(dtf.format(now)); //2016/11/16 12:08:43\n  }\n```. Discussed with @suvodeep-pyne off line.\nI am ok with merging this change for now to enable testing in test environment while investigating further why the earlier code didn't work.. \"Schedule 2 , 3 and 4 were not loaded due to lacking EndTimeChecker\" \nThis makes rolling back the change impossible without user impact. Can you think of ways to mitigate? e.g. allow these flows to run as if the end date is not specified at least until we feel confident enough about the change.. @chengren311 could you also take a look?. Thank you very much for trying this difficult task of fixing these tests!\nMy understanding of the goal of this change is that:\nMake FlowRunnerTest pass consistently so that we can re-enable it.\nThe intermediate job state change is not necessary but it has no user-visible impact. However, it makes FlowRunnerTest flaky.  Am I right?\nThis change is becoming bigger and more complex. It would be better if you can think of ways to make this change incrementally.\nIMHO, the current test running time is already longer than I would like. Let's try to keep the running time to the minimum. . This is great. Thanks!\n. I set a breakpoint in \n  @Provides\n  @Named(\"ExecServer\")\n  @Singleton\n  private Server createJettyServer(Props props) {\nAnd it wasn't hit when running the flow runner tests as I expected.\nCould you point me to the code path that has this dependency?. Could you make a separate pull request for the injected server dependency change so that we don't delay this pull request? The rest of the change LGTM.. \"Open questions maybe worth investigating:\nDoes the FlowRunner set status for jobs that entirely crashed (exception in job thread)?\n\"\nWhen the job process crashes, I assume the return code of the process will be non zero and the job will be marked failed.\nin azkaban.jobExecutor.utils.process.AzkabanProcess#run\n      int exitCode = -1;\n      try {\n        exitCode = process.waitFor();\n      } catch (InterruptedException e) {\n        logger.info(\"Process interrupted. Exit code is \" + exitCode, e);\n      }\nAm I right?\n\"\nIs it a problem that the flow is sometimes saved with some \"outdated\" job statuses?\"\nI have not able to understand the sequence this happens. The jobrunner thread seems to share the same node instance with FlowRunner.  azkaban.execapp.JobRunner#run appears to set the status on the node object directly.\nIf your theory is true, I would expect this to be a problem. I remember seeing incorrect job status. I am curious if what you found is the cause. Could you help me understand this problem?. I think you are right. If the current azkaban.execapp.JobRunner#run throws a runtime exception, the flowRunner won't notice. Filed an issue #1123. Thanks! \n===\nNow I understand what you mean by the node statuses are not synchronized.  Since the node status is not synchronized or marked volatile, changes made to them by the job runner thread is not guaranteed to be seen by the flow runner thread. What would cause the change to be seen eventually?  Shouldn't the node status field be marked volatile?\nAnd because this test wrote the job status known to the flowrunner thread back to the node and it exposed this issue?\nOr in the future shall we use one thread to handle a flow to avoid synchronization problems?. Thanks! LGTM.\nMaybe switch to [[]] too? \nsee http://robertmuth.blogspot.com/2012/08/better-bash-scripting-in-15-minutes.html\nFavor [[]] (double brackets) over [] \n @li-afaris  what do you think? \nalso http://tldp.org/LDP/abs/html/varsubn.html. I realize now that solo server has both exeserver and webserver in the same process. They need different Jetty server instances.\nIs there any immediate benefit of having Guice create Jetty server instances?\nI'd like @suvodeep-pyne to weight in. He is currently on vacation.\n. For tests that need an executorServer instance, I would expect them to use a mock.\nHaving the ability to mock the JettyServer can be useful when testing the executorServer methods itself. . Excellent. Thanks!\nLGTM. Could you update the branch or do you mind that I update the branch so that we can merge?\nIt appears that you shortened the various Jetty timeout values. It would be great if you can describe what you did to speed up the tests.. Thanks!. Does this pull request depend on #1116? Fix bug in MockExecutorLoader . I thought the status synchronization issue caused this test to be flaky. Am I wrong?. Do you think it will be better to do all the following in the future?\n1. fix the node status synchronization issue\n2. replace MockExecutorLoader with Mockito mock objects when possible. . If the node status field is marked volatile, will that fix the status synchronization issue? Can we then use the existing test without this change to verify the behavior? Since the node captured in the mockloader is the same instance, overwriting the node status should be fine then. Am I right?. I understand now why this PR doesn't depend on the status sync fix. It's because the incorrect status is written to a copy of the original node object. Right?. LGTM. I appreciate the comments you added to the code.\nHowever mixing the style changes with the real changes makes it harder to see the real changes. I'd suggest keeping code style changes separately. This is going to be less of an issue once we complete code reformatting of the entire code base. \nPer @jamiesjc's request, we delayed reformatting some directories. This is one of them. She has some pending changes she would like to go in first.\nDo you mind reverting the code style change and only keep the functional change if it is not too much trouble?\nSorry about the trouble. \nAlso since the original bug as described in \"The problem was this (revealed when running FlowRunnerTest that also uses this mock class): ... \" has been fixed, should this change description be modified?\n. Thanks!\nI mean the \"executor\" directory and the corresponding one in test.. LGTM. Thanks!\n@chengren311 any further comments?. I am not against the idea of having this state given that administrators may choose to allow a relatively long timeout for a job to be terminated gracefully. \nAs you suggested, we need to find a way to reliably terminate jobs and if we can't, notify the users. \nThe current ProcessJob based jobs should force kill the job process see\nazkaban.jobExecutor.ProcessJob#cancel\nDo your jobs overwrite this method?\nWe typically avoid restarting executors since this will affect existing running flows. We start a new executor each time and leave the older executors running. . FYI since you use pipeline option, here is a related issue we discovered recently while reading the code. #1125 \"The pipeline concurrent option is not reliable in the multiple executor mode\". I am interested in your thoughts on how to implement such a feature.\nI hope to have the ability to reload executor processes without disrupting the existing flows. . Turns out that the RemoteWatcher handles this case.. Thanks for the detailed write-up.\nI will have to think more about it.\nAt Linkedin, we currently only start a new executor process and let the existing flows finish before shutting down the old executor processes. We don't have any resumable job type currently. \nYes, it wold be nice to support resuming in a case of an H/W failure. However, h/w failure is rare so far. OOM in the executor process is also rare. I am interested in supporting a way to restart the executor process without affecting the running job processes. This will simplify our deployment process and gives us the flexibility to recover from a software bug in the executor more quickly. \nDo h/w failure and OOM happen often in your environment? Or is the ease of software update the main motivation for you?. @juhoautio sorry about the delay. \nI plan to refactor the core DAG processing code to make it easier to maintain e.g. easier to unit test and understand. I hope to find time to do so in the next month or so. \nThis will likely touch many classes. I hope the end result will be better code that is easier to add new features.\nIf you can wait until the big refactoring is done, it may make your job and merge easier. \nFor your use case:\n\nAzkaban version update requires a restart to apply changes (especially in a single executor or solo-azkaban setup)\nDo you run in a multiple executor mode? If so, you should be able to start a new executor process to replace the existing instance as an active executor. Let the existing one finish processing existing flows. It has worked for us. Would it work for you?. I tried to update your branch and finish the review before the large reformat change is merged so that you don't have to deal with merge conflicts.\n\nHowever, two tests failed. See the Travis log:\n\"azkaban.execapp.FlowRunnerTest > exec1FailedFinishRest FAILED\n    java.nio.channels.ClosedByInterruptException\n        at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)\n        at sun.nio.ch.FileChannelImpl.size(FileChannelImpl.java:314)\n        at org.apache.commons.io.FileUtils.doCopyFile(FileUtils.java:1142)\n        at org.apache.commons.io.FileUtils.doCopyDirectory(FileUtils.java:1428)\n        at org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1389)\n        at org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1261)\n        at org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1230)\n        at azkaban.execapp.FlowRunnerTest.prepareExecDir(FlowRunnerTest.java:365)\n        at azkaban.execapp.FlowRunnerTest.exec1FailedFinishRest(FlowRunnerTest.java:260)\nazkaban.execapp.FlowRunnerTest2 > testFailedFinishingFailure3 FAILED\n    java.lang.IllegalStateException: joba1 wasn't added in testJobs map\n        at azkaban.executor.InteractiveTestJob.getTestJob(InteractiveTestJob.java:48)\n        at azkaban.execapp.FlowRunnerTest2.testFailedFinishingFailure3(FlowRunnerTest2.java:520)\n74 tests completed, 2 failed, 22 skipped\n\". Could you carry over the details in the change description you had in #115? . in azkaban.execapp.FlowRunnerTest2#testNormalFailure2\nduplicate asserts:\n    // After it starts up, only joba should be running\n    assertStatus(\"joba\", Status.RUNNING);\n    assertStatus(\"joba\", Status.RUNNING);\n. We just applied code formatting changes. Sorry about the inconvenience.\nPlease see the readme for the updated instruction on how to auto-format code changes. \nYes, it will be good to resolve conflicts. . Thanks!\nThese tests will provide much-needed safeguards against regressions.. Oops, somehow Github didn't include the full change description and I didn't catch it when I merged it. At least we have the link back to this pull request. \nI will be more careful next time. . @juhoautio The travis build on the master failed with the following error:\nhttps://travis-ci.org/azkaban/azkaban/builds\nhttps://travis-ci.org/azkaban/azkaban/builds/239316403\nazkaban.execapp.FlowRunnerTest2 > testRetryOnFailure FAILED\njava.lang.AssertionError: Wrong status for [jobb:innerFlow] expected:<SKIPPED> but was:<DISABLED>\n\n    at org.junit.Assert.fail(Assert.java:88)\n\n    at org.junit.Assert.failNotEquals(Assert.java:834)\n\n    at org.junit.Assert.assertEquals(Assert.java:118)\n\n    at azkaban.execapp.FlowRunnerTestBase.assertStatus(FlowRunnerTestBase.java:137)\n\n    at azkaban.execapp.FlowRunnerTest2.testRetryOnFailure(FlowRunnerTest2.java:661)\n\nLooks like the test is still flaky. \nCould you take a look?\nIf necessary disable the flaky tests while investigating.. Thanks. I will if it blocks progress. . The same test failed again.\ntestRetryOnFailure\nhttps://travis-ci.org/azkaban/azkaban/builds/239344361?utm_source=email&utm_medium=notification\nI am going to ignore this test for now.\nOpened a ticket #1155\n. Pull request to ignore two tests #1156. Oh. I have other files under the temp/conf directory:\nan empty global.properties\nMy own azkaban-users.xml\nand \nazkaban.private.properties\nOptional Properties that are hidden to the executions\nexecutor.port=12321\nmysql.user=xxxx\nmysql.password=xxxx\nAnd my own copy of \nlog4j.properties. It may be possible. Would you like to give it a try?\nI typically run gradlew build manually to get new UI changes. You can also set up the IDE run config to run the build every time which will add overhead.. Your plan sounds good to me. \nThe plugin  https://github.com/houbie/lesscss-gradle-plugin#lesscdaemon-task README gives a warning and points to some alternatives. I hope it is fine to use. I am not too worried about it though. If it doesn't work, we can switch.  I wonder if one of the alternatives  https://github.com/bertramdev/less-asset-pipeline would work too. But I haven't read enough to know.. @jamiesjc could you share the tests you did? e.g. the SQL explain result?\nReminder: find ways to notify users that they need to update their DB to avoid surprises. e.g. highlight it in the release note.\ncc @ameyamk . I think what @suvodeep-pyne did in azkaban-db/src/main/sql/upgrade.3.20.0.to.3.22.0.sql \nhttps://github.com/HappyRay/azkaban/blob/b4c4051ce835742124c34312572c566e71d73862/azkaban-db/src/main/sql/upgrade.3.20.0.to.3.22.0.sql#L6-L6\nis good in that it makes it easier to apply the DB update and more explicit. He also added comments.\nConsider following his example?. Is this still needed?. @reallocf \nCould you replace \nreplaceAll(\"\\s+\", \"\"),\nwith a utility method that has a more meaningful name?\ncc @chengren311 \n. This may be useful for this purpose\nhttp://joel-costigliola.github.io/assertj/assertj-core-news.html#assertj-core-2.8.0-isEqualToNormalizingWhitespace\n. Yeah. Thanks!. @reallocf Nice change descriptions including the intermediate changes. Thanks for including the link to the plugin that we decide to use.. Thanks for the PR.\nPlease see my comments in the linked issue #319.\nDoes the command job type suffer from the same issue?. @sjakthol \nThanks! I didn't realize that exe-as-user is not supported for these job types. They are not maintained. \n. We are removing these job types. #1431 . LGTM. Instead of trying to merge, you may try submitting this change without formatting change and do the formatting change in a separate PR when you are ready.. @juhoautio could you review?. Thanks! @juhoautio . Would merge after #1146 due to dependencies.\n@juhoautio. @juhoautio please take another look.. I would prefer small incremental commits too. And I suggested to the team members to use issues to tie multiple commits/PRs together when needed. \nIt's less work to combine this commit with the previous one #1146 for example. \nTo make this model work well, however, we need to have quick turn arounds on code review, unit tests etc.. Good suggestions on other improvements. I agree. Would you like to make these changes? . There are many areas in this code base that can be improved. As long as we continue to improve, over time, I am optimistic that developers will become more productive working on this project. . There is still a weak warning about some duplicated code left in this class. Since a fix is more involved, I will defer that. . That will be great. Thanks. It's great to see tests catch this type of issues.\nThanks for this work!\nHow did you make the test pass before this bug is fixed?. Yes.. Oh, I forgot. \nNow that we discovered this bug. Can you think of ways to prevent a regression?\nI'd prefer a targeted test that test one behavior at a time. It's easier to figure out what's wrong when a test fails.\nIdeally we would like to have that test together with the fix.. Thanks @chengren311 . When I added a suppress warning annotation for a parameter, this plugin incorrectly removed it.. see https://github.com/azkaban/azkaban/pull/1147/commits/717445eaca91e4509aa27bdc745dc87a9aa31f39. Thanks for separating these commits.\nSince we do squash and merge only, all the commits will be merged into one commit.\nThey seem to be independent enough even though one builds on another. Do you mind breaking them up into separate pull requests? . Have you considered using assertj instead?\nhttp://randomthoughtsonjavaprogramming.blogspot.com/2017/03/assertj-vs-hamcrest.html\nIt seems to me that assertj is a better choice. I also got the same recommendation from a testing expert.\n. Hamcrest for this one is fine. \nI am reading more about assertj and will discuss with the team if we want to standardize on one assertion library for the new code.. @juhoautio . Thanks @juhoautio !\nGiven the relative priorities, I may not get to the further improvements you suggested soon.\nPlease keep the suggestions coming and feel free to submit PRs for them. . I realized that we have the option to merge multiple commits. So another option is to create one PR but multiple commits. Before merging, make sure to clean up the commit history, rebase if necessary and request explicitly to merge them all as separate commits. . Another failure when running locally.\nCreate temp dir\n2017/06/04 10:20:37.812 -0700 INFO [main] [JobTypeManager] Loading plugin default job types\n2017/06/04 10:20:39.871 -0700 INFO [main] [JmxJobMBeanManager] Initializing azkaban.execapp.jmx.JmxJobMBeanManager\n2017/06/04 10:20:39.906 -0700 INFO [main] [FlowRunnerTest2] Adding test1.properties\n2017/06/04 10:20:39.907 -0700 INFO [main] [FlowRunnerTest2] Adding test2.properties\n2017/06/04 10:20:41.706 -0700 INFO [Thread-1] [jobf] Running execid:101 flow:jobf project:1 version:-1\n2017/06/04 10:20:41.721 -0700 INFO [FlowRunner-exec-101] [jobf] Update active reference\n2017/06/04 10:20:41.722 -0700 INFO [FlowRunner-exec-101] [jobf] Updating initial flow directory.\n2017/06/04 10:20:41.722 -0700 INFO [FlowRunner-exec-101] [jobf] Fetching job and shared properties.\n2017/06/04 10:20:41.731 -0700 INFO [FlowRunner-exec-101] [jobf] Starting flows\n2017/06/04 10:20:41.790 -0700 INFO [FlowRunner-exec-101] [jobf] Running flow 'jobf'.\nExecutableFlow: jobf RUNNING\nExecutableNode: joba1 QUEUED\nExecutableFlow: jobb READY\nExecutableNode: jobb:innerFlow READY\nExecutableNode: jobb:innerJobB READY\nExecutableNode: jobb:innerJobA READY\nExecutableNode: jobb:innerJobC READY\nExecutableNode: joba READY\nExecutableFlow: jobd READY\nExecutableNode: jobd:innerJobA READY\nExecutableNode: jobd:innerFlow2 READY\nExecutableNode: jobc READY\nExecutableNode: jobf READY\nExecutableNode: jobe READY\nTeardown temp dir\n2017/06/04 10:20:42.212 -0700 INFO [FlowRunner-exec-101] [jobf] Configuring Azkaban metrics tracking for jobrunner object\n2017/06/04 10:20:42.216 -0700 INFO [FlowRunner-exec-101] [jobf] Submitting job 'joba1' to run.\njava.lang.AssertionError: Wrong status for [joba] \nExpected :RUNNING\nActual   :READY\n \nat org.junit.Assert.fail(Assert.java:88)\nat org.junit.Assert.failNotEquals(Assert.java:834)\nat org.junit.Assert.assertEquals(Assert.java:118)\nat azkaban.execapp.FlowRunnerTestBase.assertStatus(FlowRunnerTestBase.java:137)\nat azkaban.execapp.FlowRunnerTest2.testPauseFailFinishAll(FlowRunnerTest2.java:994)\nat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat java.lang.reflect.Method.invoke(Method.java:498)\nat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\nat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\nat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\nat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\nat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\nat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)\nat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)\nat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)\nat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)\nat org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\nat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\nat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\nat org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\nat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\nat org.junit.runners.ParentRunner.run(ParentRunner.java:363)\nat org.junit.runner.JUnitCore.run(JUnitCore.java:137)\nat com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)\nat com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:51)\nat com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)\nat com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)\n\n. Another random failure \nsee #1157 . Fixed by #1162 #1158 . This appears to be another random failure\nI am concerned that there may be more.\nazkaban.execapp.FlowRunnerTest2 > testCancel FAILED\n    java.lang.NullPointerException\n        at azkaban.executor.ExecutableFlowBase.isFlowFinished(ExecutableFlowBase.java:398)\n        at azkaban.execapp.FlowRunnerTestBase.lambda$assertThreadShutDown$0(FlowRunnerTestBase.java:32)\n        at azkaban.execapp.FlowRunnerTestBase$$Lambda$9/1157486615.apply(Unknown Source)\n        at azkaban.execapp.FlowRunnerTestBase.waitFlowRunner(FlowRunnerTestBase.java:42)\n        at azkaban.execapp.FlowRunnerTestBase.assertThreadShutDown(FlowRunnerTestBase.java:31)\n        at azkaban.execapp.FlowRunnerTest2.testCancel(FlowRunnerTest2.java:729)\n. Could you take a look at #1156 so that we can stabalize the master branch?. Thanks. While you are investigating, could you approve #1156 so that the master is stable?. I thought more about this change. \nI am not convinced that on balance this change is better. \nI understand that the caller of this method has to do less work. \nThe benefit, however, is that it is more explicit to the readers what the contract is. i.e. this string is a path to a file. \n. Thanks. I appreciate that you have an open mind. \nI hope my objection didn't cost you too much time. \n. #1155 . Could you share more details on the problem and how the fix works? . It seems to me that both the production code and tests are complex given all the trouble we have. Can you think of ways to simplfy? e.g. can we do without mutliple threads? I understand this may require a large refactoring... . Please see another new failure.\nThanks for the explanation.\nWhy is the new code thread safe?. I see. \nThe getStatus method is only thread-safe after the status field is made volatile. \nLGTM.\n. Travis Running time doesn't seem to decrease\nPull Request #1161 Switch from MavenCentral to JCenter maven repository\nCommit ccf74fd\n #1161: Switch from MavenCentral to JCenter maven repository\n Branch master\nRay Yang avatar Ray Yang authored and committed\n#1954 passed\nRan for 3 min 8 sec\n about a minute ago\nhttps://travis-ci.org/azkaban/azkaban/builds/239389571?utm_source=github_status&utm_medium=notification. Looks like the build time ranges from 2 min to over 5 mins. \nhttps://travis-ci.org/azkaban/azkaban/pull_requests. second try\nPR #1161\nSwitch from MavenCentral to JCenter maven repository\nRay Yang avatar Ray Yang\n #1954 passed\n ccf74fd\n 2 min 32 sec\n less than a minute ago\n. Third try\nSwitch from MavenCentral to JCenter maven repository\nRay Yang avatar Ray Yang\n #1954 passed\n ccf74fd\n 3 min 28 sec\n less than a minute ago\n. From my local mac:\nrun\nrm -rf $HOME/.gradle/caches/\n./gradlew clean build  -x test\nBUILD SUCCESSFUL\nwith mavenCentral:\nTotal time: 48.007 secs\nwith jcenter:\nTotal time: 59.693 secs\nI don't see a clear difference in speed. \nI will close this PR now until I see a clear evidence that jcenter is better.\n. I will need more time to read the test code to understand the behavior. \nGiven the test results you have, I merged it first so that I don't delay you further from going to sleep.\nThanks!. Thanks. Thanks for the detailed change description.\nCould you describe your test strategy as well?. Thanks. Please add a testing section to the change description when you merge.. #1167 LGTM.\n@chengren311 what do you think?. I changed the change description a bit when merging, please check.. Thanks @reallocf . Thanks.\nGiven other priorities, I am afraid it will take me a while to review this change. @chengren311 do you have the bandwidth to review?\ncc @ameyamk . Thanks @chengren311 . @juhoautio Have you deployed a version that includes this change? \n@chengren311 is not familiar with the tests that failed after this change was made.\nIf this is important to you, do you mind submitting a pull request since you may be more familiar with the tests and this change?\n. Do you use subflows extensively?. See the test failures in https://travis-ci.org/azkaban/azkaban/builds/240580566?utm_source=github_status&utm_medium=notification. Could you take a look at #990 too?. Original warning:\n\"Servlet.java:111: warning: [ReferenceEquality] Comparison using reference equality instead of value equality\n          begin == \"\" ? -1 : DateTimeFormat.forPattern(FILTER_BY_DATE_PATTERN)\n                ^\n    (see http://errorprone.info/bugpattern/ReferenceEquality)\n  Did you mean '\"\".equals(begin) ? -1 : \n\"\nCould you add this info to the description when you merge?\nThe suggested fix above seems to be more concise.\nAlso see\nhttps://stackoverflow.com/questions/7520432/what-is-the-difference-between-vs-equals-in-java\n. Great to see \"dead code\" gone.\nThanks!. @chengren311 . No, it is not.. Backfill support is something we are considering too. \nThe details need to be hashed out. But what you described at high level sounds good to me. \nWe would like to build future UIs purely based on APIs. So it will be good to design and implement the APIs first. . Rephrased.. This is just an example.. The build failed again.\nazkaban.execapp.FlowRunnerTest2 > testFailedFinishingFailure3 FAILED\n    java.lang.AssertionError: Wrong status for [jobb] expected: but was:\n        at org.junit.Assert.fail(Assert.java:88)\n        at org.junit.Assert.failNotEquals(Assert.java:834)\n        at org.junit.Assert.assertEquals(Assert.java:118)\n        at azkaban.execapp.FlowRunnerTestBase.assertStatus(FlowRunnerTestBase.java:117)\n        at azkaban.execapp.FlowRunnerTest2.testFailedFinishingFailure3(FlowRunnerTest2.java:520)\n:azkaban-solo-server:check\n:azkaban-solo-server:build\n:azkaban-common:check\n:azkaban-common:build\n74 tests completed, 1 failed, 22 skipped\n@juhoautio I think we should disable this test file until it is stable. What do you think?. Unfortunately, I tried and couldn't get the console output from Travis. The best I was able to do was to get the stack trace when a test failed. \nPlease contribute the knowledge if you find a way. . @juhoautio I found a way to log test console output\nsee https://gist.github.com/HappyRay/84119110f957dc114402178258723632. No. The output is too noisy. \nIt's a tool, however, to debug issues when needed. It can be enabled on a per pull request basis. \nIn any case, the test should be reliable and repeatable (locally or in travis ) by design. I would prefer simplifying the current DAG engining design and tests. . If this model works well and others agree this is a good idea, we can do the same to the other modules.. It seems that git is smart enough to preserve the change history after the directory is renamed.\ne.g.\nruyang-mn1:azkaban ruyang$ git log --follow test/src/test/java/azkaban/test/executions/TestExecutions.java\ncommit 0e797b686896404b4039a54220f4a08026d88333 (HEAD -> shorter-project-names, origin/shorter-project-names)\nAuthor: Ray Yang ruiguo@gmail.com\nDate:   Sun Jun 11 09:32:20 2017 -0700\nSimplify the azkaban-test subprojet name to test\n\nThe azkaban prefix is redundant and requires unnecessary\ntyping.\n\nKeep the azkaban prefix in the jar file name.\n\ncommit fc5d415635e2d10f972538c4c7d85b50db316cb0\nAuthor: Charlie Summers csummers@linkedin.com\nDate:   Thu Jun 1 11:52:46 2017 -0700\nreformat everything excluding files under development (#1137)\n\nreformat the entire codebase excluding files under development based on our coding style\nreorganize the order of import\nrearrange member methods\nalso leverage save action plugin to refactor code(https://github.com/dubreuia/intellij-plugin-save-actions):\nAdd final to local variable\nAdd final to field\nRemove explicit generic type for diamond\nQualify field access with this\nRemove unused suppress warning annotation\nRemove final from private method\nRemove unnecessary semicolon\nAdd missing @override annotations\n\ncommit 85934a4314bb4d44ae891baef72f6f7de9556dbe\nAuthor: David Z. Chen dzc@google.com\n:. The ones I have seen don't have the duplicated prefix including the examples given in the gradle documentation. . @jamiesjc?. Thanks!. Thanks. I will wait a bit until I hear back from the tools team on the potential impact for integration with internal toolings.. How can these dependencies be cached on your machine if they are not available in the repository?. Discussed off line, due to the risk of not having this fix, we agreed to check in this fix first. @suvodeep-pyne agreed to address the remaining review comments later. . The test took almost 9 seconds to run on my mac. This is slow. Any idea how to speed it up?. How did you test this feature work? . That test is good for catching regressions. But it doesn't test the new functionality is working, does it?. It doesn't look like we have complete automated tests that would verify that this feature will work once all tests pass. Can you improve? I understand that you may have to build necessary supporting testing infrastructure to do so. . Thanks for the update.\nIf you use IDE to check the line coverage, you can see which lines you added have no test coverage. \ne.g.\nIt seems that if we remove the check in the web server code all the tests will still pass. . Could you update the relevant documentation after this change is merged?. Could you update the change description?\n\"Upload button is disabled from the UI if 'lockdown.upload.projects' is set to true\nor if the user doesn't have the necessary permissions.\" doesn't seem to be right.. Thanks!. I updated the pull request description to match the commit message.. Yes, this change seems to be useful.\nSorry, the team are behind in reviewing PR requests.\n. Thanks @chengren311 for reviewing this change.\nThe new code looks cleaner and it is no longer ignored! Thanks @juhoautio !. Travis CI failure seems to be caused by flaky tests:\nI restarted the test.\n:azkaban-solo-server:test FAILED\nazkaban.execapp.event.JobCallbackRequestMakerTest > basicPostTest FAILED\n    org.junit.runners.model.TestTimedOutException: test timed out after 4000 milliseconds\n        at org.apache.log4j.spi.LoggingEvent.<init>(LoggingEvent.java:165)\n        at org.apache.log4j.Category.forcedLog(Category.java:391)\n        at org.apache.log4j.Category.warn(Category.java:1060)\n        at azkaban.execapp.event.JobCallbackRequestMaker.makeHttpRequest(JobCallbackRequestMaker.java:158)\n        at azkaban.execapp.event.JobCallbackRequestMakerTest.basicPostTest(JobCallbackRequestMakerTest.java:164)\nazkaban.execapp.event.JobCallbackRequestMakerTest > unResponsiveGetTest FAILED\n    org.junit.runners.model.TestTimedOutException: test timed out after 4000 milliseconds\n        at org.apache.http.client.methods.HttpGet.<init>(HttpGet.java:65)\n        at azkaban.execapp.event.JobCallbackUtil.parseJobCallbackProperties(JobCallbackUtil.java:170)\n        at azkaban.execapp.event.JobCallbackUtil.parseJobCallbackProperties(JobCallbackUtil.java:94)\n        at azkaban.execapp.event.JobCallbackRequestMakerTest.unResponsiveGetTest(JobCallbackRequestMakerTest.java:141)\n\n@juhoautio  this failure seems to be related to this change.\n```\nazkaban.execapp.FlowRunnerPipelineTest > testBasicPipelineLevel2Run FAILED\n    java.lang.AssertionError: Wrong status for [pipelineEmbeddedFlow3:innerJobB] expected: but was:\n        at org.junit.Assert.fail(Assert.java:88)\n        at org.junit.Assert.failNotEquals(Assert.java:834)\n        at org.junit.Assert.assertEquals(Assert.java:118)\n        at azkaban.execapp.FlowRunnerTestBase.assertStatus(FlowRunnerTestBase.java:131)\n        at azkaban.execapp.FlowRunnerPipelineTest.testBasicPipelineLevel2Run(FlowRunnerPipelineTest.java:315)\n```\n. I haven't had time to look into the test logic yet. I've asked other team members to help to review your PRs.. Thanks @juhoautio \nSorry. I should have included a link. Can you see this page? https://travis-ci.org/azkaban/azkaban/pull_requests if you do, you can search for this PR there.\n. I can't find the failed build anymore. I shouldn't have restarted it.. @juhoautio \n@inramana is busy. I am taking over. The change LGTM. Please resolve the conflict and I will merge it.. Yes, this change seems to be useful.\nSorry, the team are behind in reviewing PR requests.\n. It appears that the imports are not organized correctly. Did you follow the new contribution guide?. It's not clear to me why the test flow uses so many jobs. Would 2 or three be sufficient?. It would be great if you can fix the code duplication for prepareExecDir and createFlowRunner too. They can be in a separate PR though. Intellij should be able to warn and help with this refactoring. . Thanks!. It would be great if you can follow up with some additional improvements we discussed here.. @juhoautio Thanks for the pull requests! I haven't had time to review them in details yet. Based on your descriptions, I think they are good candidates to merge.\nAlso, thank you for making separate pull requests.\nI don't have the bandwidth to review at this time. And I am going on vacation soon. We are also dealing with multiple production issues before the upcoming holiday. I've asked @ameyamk for help with resourcing. . Am I right that \n1243\n1244\nneed to be merged first?. The code LGTM.. @juhoautio what do you think about deprecating the support for level 1 and 2 pipeline modes and replace them with another option: run the flow after the previous one finishes. The current level1 and 2 pipeline modes are rarely used inside Linkedin and are not well understood and tested. This will greatly simplify the code. \nIt will make the engine rewrite project simpler. . I have started the DAG engine rewrite project by writing a prototype first. You can track it at https://github.com/HappyRay/azkaban/tree/dag-engine-refactoring. Is it ok to merge this before #1243?. Could you resolve the conflict?. > I wouldn't remove that feature. \nI understand. Thanks.\nI plan to get some statistics on how this feature is used in Linkedin. And then decide if it is cost-effective to maintain this feature. . > The main reason for us is that we have some flows with a lot of jobs, and we don't want the next days run blocked entirely by the previous days flow if some jobs from that are running slow or are even stuck.\nMost of flows at Linkedin don't suffer from this problem. They can run concurrently. Is it difficult to modify your flows to allow them to run concurrently? . Is it a clean revert?\nIf so, please indicate so in the commit message.. This doesn't look like a typo. Could you improve the change description? . Could you reference the pull request that introduced this bug?. I am not aware of a reason that AZ would need to use TRACE method. It seems reasonable to have it disabled if so.\nWhat are your concerns with it enabled?. I am ok with delaying adding more complexity until there is evidence that it is a big problem. I haven't seen such evidence yet. If DB is down for an extended period of time, we have a bigger problem.. Nice. Thanks for making it a separate pull request.. Thanks for making this change!. Could you add to the description why this change is backward compatible? I assume it is because this value should never have been persisted?\nThe previous error was not detected by unit tests. \nTo prevent future regression, does it make sense to add a unit test to test writing all the possible job statuses into an in-memory h2 DB? \ne.g. when someone adds a new status with a value of 140 and somehow miss the comment, the test should fail. . According to this doc\nhttps://dev.mysql.com/doc/refman/5.7/en/integer-types.html\nThe tinyint is not a standard sql type. \nShall we move to a standard type such as smallint?. @jamiesjc It appears that the activeJobRunners list modification is synchronized with \n synchronized (this.mainSyncObj) {\nsee azkaban.execapp.FlowRunner#runFlow and \nazkaban.execapp.FlowRunner#kill()\n  public void kill() {\n    synchronized (this.mainSyncObj) {\n\"it could happen that the JobRunner hasn't been added to the activeJobRunners yet when it tries to kill. In that case, the job wouldn't be killed as well.\"\nUnless I miss something, it appears that the list won't be modified until the FlowRunner#kill returns.\n. @jamiesjc Good analysis. This seems to be a valid race condition.\nDo you mind filing an issue? Is the fix as simple as protecting this code with the same lock?. Thanks @jamiesjc !. In the pull request description, you still refer to \"Setting the sticky bit \". \nLGTM otherwise.. Reminder: please describe why it is hard to write an automated test for this change in your commit message. . @reallocf did you find out why the triggerManager.shutdown is not called in azkaban.execapp.FlowRunnerManager#shutdown?. Could you explain why you chose to change the default instead of changing the configuration for each installation?\nSee http://azkaban.github.io/azkaban/docs/latest/\nsession.time.to.live. Could you add more details to your change description? I am not sure I follow. . Also adding a default log4j config in the jar files is problematic since it may interfere with user's own log4j configuration. . @reallocf could you add the motivations for reverting this change in the change description? This way, @juhoautio or someone else can address the concerns and move forward later.. https://services.gradle.org/distributions/ seems to be accessible and ./gradlew works for me. \nCould you point to the documentation that suggests this alternative URL should be used?. No problem. Thanks for trying to fix an issue you observed. . Why is this API needed? It seems odd to have the API to change the submitter without changing the schedule. . Please explain in the commit message the motivation for this change.\nMy understanding is that this is to make the API behavior consistent with the existing UI.. Thanks\nCould you make it clear in the commit summary line that this change applies to the API?. Thanks @jamiesjc !. Thanks @jamiesjc !\nDid you also try delaying the kill command a little bit to see if the job process is killed?. I am not aware of many web applications that enforces this IP check. If anyone knows good examples, I am interested in reading more about it.. Is it worth adding the version information when this change was introduced? Otherwise LGTM. It can help users who are not using the latest version. \nWhat's the downside?. It's less of a concern for users who deploys new versions regularly.. Some projects publish versioned docs. Maybe something to consider in the future. \nJust a suggestion. \nWe can evaluate this enhancement later.. LGTM. \"The motivation is to make it easy to add more routes to the web server.\" Other than making this code cleaner, how does this change directly make it easier?. @kunkun-tang should an upgrade*.sql file be created for such a change?\nCan this PR move forward?. Thanks @kunkun-tang.\nCould you investigate why the duplication happens? Is it easy to fix?. Is it an indication that the primary key design is flawed?. Did you run saveAction or reformat? The line length exceeded 100.. The Jodatime has facilities to mock time to make unit testing easier.\nWe should move to the new Java8 Time in the new code.. Thanks for the detailed commit message!\nI think a summary line can describe more details. e.g.\nsecurity: jobs should not inherit the Azkaban service group permissions\n. Nice found. Thanks for fixing this!. Here is my understanding of the problem you described. Please correct me if I am wrong.\nUsers issue kill command for a flow.\nDue to race conditions, the job may finish successfully and registered event listeners are notified as such.\nFinally, the kill thread marks the job as killed as the final status.\n\nThread synchronization is tricky to get right. I am afraid I don't quite follow your diagnostics and how your fix will solve this problem. \n\nI am thinking of refactoring the DAG processing engine to reduce the complexity and reduce the need for thread synchronization.  e.g. if there is one thread that is responsible for the job/flow status transition, it would be easier to reason about.\nIn the killing scenario, a successful return of the kill command only means the server has received and queued up the kill command successfully. The final outcome may still be either a job is killed or a job finishes successfully. The user or a user program would still need to poll the status to find out the final status. And there should not be a state transition from running -> killed -> success/failure.  It should either be running -> killed or running -> success/failure. \ncc @jamiesjc who has worked in this area.  \n. How big a problem do you think this is causing? . > I suppose you describe the situation how it is without this fix. Yes, that's how I see it pretty much. Is this just you ensuring that you understand how it works, or do you mean to say that this wouldn't be a real problem?\nI described it as the desired state. \n\nThe lack of synchronization does seem to be a problem.\nCould you describe an example sequence to better help me understand the particular race condition? And how it will interact with the killing status change?\nAre you seeing this issue in your production environment now?. Yes, I have looked at your example commit. It's great to have a repeatable program to demonstrate the problem.  The current code's complexity doesn't make it easy for me to remember all the details in my head. I am not very familiar with your killing status change. It would take me some time to research the code to understand. \nIn the mean time, it will help me understand if you can describe the sequence of thread A does ... Thread B.... and here is the race condition. Here is the new sequence after the fix.\nHere is an example of how I describe race conditions. It's a style that I use.\nhttps://github.com/azkaban/azkaban/commit/79f1f9927c151e226e9db601eaffc161df05ea8a\n. Thanks @jamiesjc \nI can follow the race condition you described.\nHow would the change fix this race condition? I don't see what's preventing the jetty thread from setting the final status to killed. . I didn't realize that the whole logic in the kill azkaban.execapp.JobRunner#kill method is within this lock synchronized (this.syncObject) {\nYour fix makes sense to me now. \nThe code is still overly complex since the lock is all over the place. \nCould you try to summarize your technique in preventing the race condition between the kill thread and the jobrunner thread?\nMy understanding is that you would check killed status before setting the final job status and place that check and set logic inside the jobrunner syncObject lock?\nThanks for your contribution and patience!\n. @juhoautio I can review and merge it if you could you update the change description and update the branch.. Yes, the default merge option now is to rebase. \nCould you suggest the change description you would like to use?. javax.inject should be part of the JDK.. Have you done end to end tests?. Please add a test section to the change description.. > Updating error-prone version to the latest (tried 2.1.1 and 2.1.0) did not work out well and I had to switch back to 2.0.15 to get the build going.\nIt's not a blocker. But could you try to find a way to overcome this limitation?. Thanks for updating the PR. \nCould you resolve the conflicts?\n. Thanks!. Fixed by #1434 \nand documented in the coding convention. #1435 . Could you describe why this change is needed?. How did the issue manifest itself? What problems will users or operators observe?. I am not sure I follow. What's the sequence of the events?\nAnd before your change, how was the list cleaned up?. Thanks for adding additional context. . Is it a user visible feature/change? How does it work?. @chengren311 what's your plan for this change?. Could you include unit tests?. Looks like the test failure is due to a flaky test\nhttps://travis-ci.org/azkaban/azkaban/builds/265386286?utm_source=github_status&utm_medium=notification\nI restarted it.\n. Could you run saveAction and run CheckStyle on new files?. reference:\nhttps://stackoverflow.com/questions/5644011/multi-project-test-dependencies-with-gradle/21484721#21484721 This seems to be a better solution because it works better with intellij's dependency management system.  This is the approach I took in this change.\nThis is an alternative approach.\nhttps://softnoise.wordpress.com/2014/09/07/gradle-sub-project-test-dependencies-in-multi-project-builds/\n. Thanks for the PR!. LGTM overall.\nDo these two changes have to be in the same PR?. Yes, splitting them would be ideal.. Travis failed:\n\":azkaban-common:test FAILED\nNote: Some input files use unchecked or unsafe operations.\nNote: Recompile with -Xlint:unchecked for details.\nFAILURE: Build failed with an exception.\n* What went wrong:\nExecution failed for task ':azkaban-common:test'.\n\nProcess 'Gradle Test Executor 11' finished with non-zero exit value 137\n* Try:\nRun with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output.\nBUILD FAILED in 4m 59s\n61 actionable tasks: 49 executed, 4 from cache, 8 up-to-date\n\"\nI restarted the build. . > Even though this PR looks good, \n\nDo you mean \"big\"?\nPlease summarize what this change is about in the commit summary line when you merge.. The code looks fine to me.\nCould you describe the issue in the change description to make it easier for readers?\nCould you describe more details of the fix e.g. what's wrong with the existing code and how you fixed it? \nWhat's your test strategy? Can it be automated?. Thanks.\nAm I right that the old code's check if an action is specified is ineffective since the list object itself will never be null? The new code checks if the list is empty instead. It would be good to include this details in the commit message as well when you merge.. Not sure why Travis is not building this PR after > 40 minutes. \nClosing this PR and re-openinging it to trigger a build. . No luck. Enabled and disabled travis in the settings page. See if it helps.\nhttps://travis-ci.org/azkaban/azkaban/pull_requests\n. Test failed.\nSeems to be flaky test.\n:azkaban-solo-server:distTar\nazkaban.execapp.FlowRunnerTest2 > testPauseFail FAILED\n    java.io.FileNotFoundException: File does not exist: build/tmp/_AzkabanTestDir_1503338507574/_job.1.job3.log\n        at org.apache.commons.io.FileUtils.forceDelete(FileUtils.java:2275)\n        at org.apache.commons.io.FileUtils.cleanDirectory(FileUtils.java:1653)\n        at org.apache.commons.io.FileUtils.deleteDirectory(FileUtils.java:1535)\n        at azkaban.execapp.FlowRunnerTest2.tearDown(FlowRunnerTest2.java:138)\n75 tests completed, 1 failed, 22 skipped\n:azkaban-exec-server:test FAILED\n. This seems to be a legitimate warning. I wonder why I never saw this warning in my local build and why Travis build would pass. . Maybe this change introduced this check.\nhttps://github.com/google/error-prone/commit/70e0ad796a4bad56e065a1880dbf880932dfcda2\n. Yes, this is the same version as published in our internal artifactory.. It's supported. see\nhttps://github.com/azkaban/azkaban/wiki/New-Azkaban-Schedule-Introduction. @juhoautio any idea?. Master failed with\nthe following error too today\nhttps://travis-ci.org/azkaban/azkaban/builds/268499837?utm_source=email&utm_medium=notification\nazkaban.execapp.FlowRunnerTest2 > testCancelOnFailure FAILED\n    java.lang.AssertionError: Wrong status for [jobb:innerJobB] expected: but was:\n        at org.junit.Assert.fail(Assert.java:88)\n        at org.junit.Assert.failNotEquals(Assert.java:834)\n        at org.junit.Assert.assertEquals(Assert.java:118)\n        at azkaban.execapp.FlowRunnerTestBase.assertStatus(FlowRunnerTestBase.java:117)\n        at azkaban.execapp.FlowRunnerTest2.testCancelOnFailure(FlowRunnerTest2.java:576). Another failure today:\nazkaban.execapp.FlowRunnerTest2 > testRetryOnFailure FAILED\n    java.lang.AssertionError: Wrong status for [jobb:innerJobB] expected: but was:\n        at org.junit.Assert.fail(Assert.java:88)\n        at org.junit.Assert.failNotEquals(Assert.java:834)\n        at org.junit.Assert.assertEquals(Assert.java:118)\n        at azkaban.execapp.FlowRunnerTestBase.assertStatus(FlowRunnerTestBase.java:117)\n        at azkaban.execapp.FlowRunnerTest2.testRetryOnFailure(FlowRunnerTest2.java:647)\n75 tests completed, 2 failed, 22 skipped. Thanks @juhoautio \nDo you think we should ignore these tests for now until the problem is fixed?. @juhoautio you asked if there is a standard way to do poll and wait in tests. I found this today. https://michaeltamm.github.io/junit-toolbox/com/googlecode/junittoolbox/PollingWait.html Do you think this is going to be useful in AZ tests?. @juhoautio Yes, I found it hard to debug flaky tests that only fail on Travis too. Unfortunately, I have not found a good solution to see full test output in Travis. Let me try the --info flag to see if it will work.\nI understand and agree with your concerns. A flaky test is a big drain on productivity. I hope that the problem can be debugged in a PR or personal clone while the main line has the flaky tests ignored. \n  . I would like to refactor the code to make tests easier to write and maintain in the long term.. > so I think the best solution is to loop with a short sleep, making the \"polling assert\" useful.\nSounds reasonable to me.\nDo you mind giving it a try?\n. > and I guess new builds can be triggered simply by closing & reopening an existing PR(?).\nI think so. I remember I may have tried it. . Here is another library that may help with testing asynchronous systems\nhttps://github.com/awaitility/awaitility. @juhoautio Thanks for looking into these issues.\nWe haven't disabled these tests since I made some changes to the build and the tests have not failed since.\nYour suggestions all seem reasonable.\nNo, I haven't found a way to download the html based test report from Travis. . Done. Thanks. We haven't seen this permission issue.  #1292 and #1325 may be related. \ncc @reallocf . @prokod There are some DB schema changes. Please take a look at azkaban-db/src/main/sql/upgrade.3.20.0.to.3.22.0.sql for example. Also take a look at the changes made to the sql directory azkaban-db/src/main/sql. @reallocf should have fixed this. He can share more details.. @reallocf what's your proposed change?. Got it. Thanks. \nShall we hold off the current deployment and patch the release so that we don't break the users that rely on this feature? What do you recommend?. Do we have an integration test for this feature yet?. @suvodeep-pyne Thanks. \nI agree that these are drawbacks. On balance, I think consistency and the ability to take full advantage of IDE are worth the cost. . It appears so.\ne.g.\nazkaban.jobtype.JobTypeManagerTest > testBuildClass STANDARD_OUT\n    2017/08/26 18:18:35.135 +0000 INFO [JobTypeManager] Job type plugin directory set. Loading extra job types from /tmp/junit9116303074802479980/jobtypes_test\n    2017/08/26 18:18:35.156 +0000 INFO [JobTypeManager] Common plugin job props file /tmp/junit9116303074802479980/jobtypes_test/common.properties found. Attempt to load.\n    2017/08/26 18:18:35.156 +0000 INFO [JobTypeManager] Common plugin load props file /tmp/junit9116303074802479980/jobtypes_test/commonprivate.properties found. Attempt to load.\n    2017/08/26 18:18:35.158 +0000 INFO [JobTypeManager] Loading plugin anothertestjob\nsee \nhttps://travis-ci.org/azkaban/azkaban/builds/268728495?utm_source=github_status&utm_medium=notification. I will have this change checked in as soon as another repo maintainer approves this change. \nIn the mean time, you should be able to do the same in your PR.. @kunkun-tang Thanks for your review!. cc @jamiesjc \nThis seems to be a good enhancement. Are you interested in sending a PR?\nThanks for the report.. It would be great to include a unit test with the PR.\n@jamiesjc plans to refactor the email code. One of the goals is to make writing unit tests easier.. It's strange. \nkilling status is introduced in #1172 first included in 3.31 and later reverted in 3.32 #1300 \n. LGTM otherwise.. Thanks!. Thanks for asking.\nI've searched the oss and internal plugin repos.. They were used in the removed class \nsee #1424 . Thanks! @reallocf . @reallocf Good catch. Yes. This is another reason that we should consider combining these two repos to get better compile time error checking.. How is upgrade*.sql supposed to be used? \nWhen there is a DB schema change does the change need to go to two places?. I have searched internal user code and have not found references to these job types.. Thanks for the PR!. @juhoautio if you submit a PR for this issue, I will review it. Thanks. Thanks @juhoautio! \ud83d\ude04 . > I'm wondering what the convention of static methods are? Should they all be put into an util class?\nThe \"favor small classes \" convention applies too. \nThere are cases where it's better to keep static methods in the same class e.g. to implement a factory pattern. \nI would also like to keep the list of coding conventions as small as possible to help people remember. . > In this doc, do we need to state that Azkaban build doesn't allow warning. If we have to bring code with warning, we must suppress it.\nDo you mean errorprone warnings? @reallocf has made the change to enforce the no warning rule. So I don't think it is necessary to mention it here. \n. Thanks for making the suggested changes.. > Thanks to this, found out that wait/notify was missing for dispatching new executions\nFixed that, which helps the new test testNotFoundFlows finish in ~100ms instead of >2000ms\n\ud83d\udc4d . @jamiesjc for big changes that require multiple PRs, it may be useful to create an issue and reference the issue from all the PRs. This way all the PRs can be tied together.. Thanks!. Yes. Sounds good to me.. A unit test that runs close to 1s is too long. I would prefer making it faster first before enabling it.. Yes, if they can be fixed to run quickly and reliably.  Thanks.. It appears that there were 8 test executors' running. Maybe reducing the number may help.. @juhoautio I remember your company is still using the single executor mode. Am I right? If so, how will this change impact you? I don't expect the migration to be too difficult. I would like to give you a heads up so that you can be prepared. . @juhoautio Thanks for the feedback. . Yes, I updated the description.. How about dev mode and production mode?. The main doc has detailed documentation about how to set up the multiple executor mode. Let us know if you have trouble setting it up.. The build is just to make sure the c code can compile. It needs to be built on the target platform I think. See the main doc for details.. @juhoautio Thanks for the suggestion.\nWe are thinking about introducing a more general form: conditional flow in the future. When we do, this will likely be a special case and we may remove this config from the code. So I would hesitate to document it now. \n. We don't plan to fix the missing color. However, if you submit a PR, we will review it when someone has the bandwidth to do so.\nWhat do you mean by \"retries\"?\nMy current thinking is that standard retry will still be applied before the conditional flow logic is applied. . Since you have done the work, we can review 2.\nI wouldn't recommend doing others at this time. . You can reference another issue with #1448 syntax.\nIt would be great if you can summarize the issue here as well.. Thanks for the refactoring. Could you add a bit more details on what's changed? It seems that you removed some logic to do an incremental update? How is the behavior going to be different? Or what the new code is designed to do?. Is azkaban-db/src/main/sql/database.properties still needed after this change?. I saw that it is still used by azkaban.database.AzkabanDatabaseSetup\nWhat's your plan for the azkaban.database package?\nDo you plan to move it and consolidate with the .db package?. I suggested the az- prefix so that it is easier to separate the new modules from legacy modules and allow us to apply different policies to them such as code style enforcement policies.. Be careful with the Props class, it is used in the public interfaces. User code may depend on the class's package name.. Should the test code be moved too? e.g. azkaban.utils.JsonUtilsTest. Thanks for the work. The new code is more readable.\n. I modified your description from #1445 as the change description.. The verbosity seems to be comparable. Thanks to autocompletion, I don't have the type more.\nI personally find assertj version easier to understand. . Thanks for reporting this issue and the detailed repro steps!\nAre you interested in fixing this issue? Please see the updated dev guide for instructions.\nhttps://github.com/azkaban/azkaban/blob/master/CONTRIBUTING.md\n. Cool. Thanks.\nI would suggest a separate PR for unrelated changes. It will increase your chance of getting a quicker review among other benefits.. Thanks!. @kunkun-tang any reason this PR is not merged?. State machine diagram\n\n. related papers:\nhttps://blog.acolyer.org/2017/12/04/ffwd-delegation-is-much-faster-than-you-think/\nhttps://blog.acolyer.org/2015/06/05/scalability-but-at-what-cost/. Replaced by #1755 . Could you add more details to the change description? Duplication between the change description and the issue is ok IMHO. It makes it easier for readers.. Do they need to be Singleton?\nIs there a problem the way they are?\nSingleton should be a special case, not a norm. . Please describe in the change description more details why this config is needed? The relationship with the existing config and the plan for the existing config.. Please use the mailing list for general questions. See the readme and the dev guide. https://github.com/azkaban/azkaban/blob/master/CONTRIBUTING.md. Nice change description.\nHow come I forgot compileOnly.. @armisael Sorry that you run into these issues.\nYes, with this change, users need to provide their own Hadoop jars now. \nThe included startup script already adds Hadoop jars to the classpath when provided.\nhttps://github.com/HappyRay/azkaban/blob/10fc229f4982757a44ac4fc59f11100cd9971f82/azkaban-web-server/src/main/bash/azkaban-web-start.sh#L30\nCould you provide more details on the exceptions? e.g. call stack?\n. For simple PRs, a separate issue is not required. It's recommended to have an issue if a fix requires multiple PRs.. >   became no longer writable due to an upgraded execute-as-user executable that stopped user processes from having the azkaban group permission.\nA bit more detail will be useful. e.g. the file is written to by the job process. Since the file can only be written to .... It worked before because ..... > It is uncertain whether or not JOB_PROP_FILE is intended to be written to, but I believe it's a good idea to do allow it to be in order to prevent regressions.\nI am pretty confident based on the doc that this file is not supposed to be written to by the user job process. Given that all the files are currently readable by \"others\", I don't think we need to change the permission of this file. We can discuss in person.. LGTM. Please update a comment in the code too.. @juhoautio could you give examples of the convenient accessors you think will be useful? . I understand. I prefer having many focused smaller composable classes/interfaces.\nImplementing these convenient methods on top of a key value string map like interface would be simple.\nIf there is enough demand, we can create a shared common library if such a library doesn't already exist in the open source world. . If it is not documented, it is considered internal, probably to support the UI.\nI would suggest updating the name and callers. I suspect it is called by some js files. \nWe would like to improve our API in the near future. I hesitate to expand our public API set now. . I'd appreciate a PR. Thanks.. Thanks.. @armisael Thanks! . Please follow the setup guide to set up and activate executors.. Please include more details such as version number, repo steps.. Please clarify in the change description that this is only a problem if users don't supply their own Hadoop jars in the classpath.\nHow did you test?\nIs this code path covered in an automated test, unit test?. Thanks for linking the related changes.. Any reason this can't be unit tested?. In case you haven't considered this option, you could have reverted the default event listener implementation part only. This will unblock the release also but has the benefit of reducing the chance of a conflict when you introduce it again. \nIt's one reason I would encourage breaking up a large change into smaller ones.. Got it. Make sense. Thanks.. Please include more details. e.g. how did you invoke Gradle. Did you follow the readme? . How does do-echo-a.job reference echo.job?. The existing schema migration method appears to be broken already.\nI asked @kunkun-tang to come up with a new strategy.. This is the platform part of the earlier PR #1332 which was reverted. . Thanks for reporting this issue and its cause.\nI wonder if it is better not to finalize flows on the web server side. We haven't had time to clean up that part of the logic completely yet.. Could you give an example of how to reproduce the issue? . Got it. Thanks for reporting this issue.. Anyway to catch this error in a unit test?. Thanks @juhoautio \n@kunkun-tang did you find out why saveaction was not working for you?. Thanks @ismailsimsek . It appears that GitHub will offer the commit message sometimes as the final commit message instead of the pull request description. \nI should have copied the pull request description when I merge. . I haven't read this PR in detail. But the rule looks complicated. At least I still don't follow it after I read the explanation. \n@jamiesjc is working on a different YAML based representation of flows. Is that design subject to the same issue?\n@armisael how urgent is it for you to solve this issue? . @armisael \nAt LinkedIn, we use the following DSL to generate AZ flow files.\nhttps://github.com/linkedin/linkedin-gradle-plugin-for-apache-hadoop\nThe new YAML based flows assume code/config sharing will be handled by a higher level DSL. Will this approach work for you? \n. Yes, we are thinking of merging these two projects.\nI hope people will come up with different DSLs that would best suit their needs. Here is an example I know.\nhttps://github.com/aslotnick/azflow\nThe new YAML based representation hopefully would make creating such DSLs easier. @jamiesjc has submitted a few pull requests related to that feature. Please feel free to ask her if you have questions. \n. AZ is designed as a lightweight launcher. If you are running many resource-intensive jobs at the same time, is it possible to offload them to an external distributed processing system such as Hadoop/Yarn? e.g. run each job in YARN. . @Free0xFF Thanks for the contribution! \nCould you add a unit test?  . \"Since currently Emailer.java can only be tested via integration test, I didn't write unit test but verified by sending a email with the new method in local mode.\"\nNot having automated tests for new code is ok for a PR only if tests will be added shortly after.\nI would suggest refactoring email component. This piece can be improved anyway. @jamiesjc and I had discussions about it. She planned to do it but it hasn't become a priority.\nSince you modified the code, you are on the hook now. :). Other choices I found:\nJava mail testing:\nhttp://www.icegreen.com/greenmail/\nhttps://stackoverflow.com/questions/1033076/mail-server-for-javamail-testing\n. To make the unit tests effective, I think the mail module needs to be refactored. . Please include tests if they don't exist already. \nAlso please explain how you verified that this new code will scale with the number of the files per project, unlike the existing code. . Thanks for your interest and reaching out!\nYes, we still maintain the plugins repo. However, we plan to merge that repo with this one in the near future. For new job type plugins, I'd suggest contributing directly to the main repo. \n@jamiesjc plans to share more details on Flow 2.0 design soon.\nIn case you haven't, please take a look at the contribution guide at\nhttps://github.com/azkaban/azkaban/blob/master/CONTRIBUTING.md\n. @kunkun-tang Thanks for the review and helping us improve the quality of our changes which include change descriptions. . Thanks for this work!\nFor new code, I would suggest slf4j as documented in\nhttps://github.com/azkaban/azkaban/blob/master/CONTRIBUTING.md\n\nUse slf4j instead of log4j.\nUse the form:\nprivate static final Logger logger = LoggerFactory.getLogger($CLASS_NAME$.class);\n\nslf4j provides a more efficient API called  parameterized logging. \nTry to use that format.\nsee\nhttps://stackoverflow.com/questions/30975026/log4j-implicit-string-formatting\nI think we should update the guide to standardize on using parameterized logging. What do you think? \n. Thanks for the update.\nIt looks fine to me.\nIt would be great to convert to parameterized logging as mentioned earlier. But it can be done later. Since this is legacy code, it's up to you if you would like to make the improvement. . Please take a look at https://github.com/azkaban/azkaban/blob/master/CONTRIBUTING.md\n\nPlease don't report an issue as a way to ask a question. Use the Google group instead.\n\nYour question is better answered there.. BTW, do you use Azkaban at work? If so, do you mind sharing your company name?. @kunkun-tang any idea?. The message referenced above is standard gradle message. Are you sure it is gradle not our test that is the problem?. I thought all the DBs in these tests are created in memory independent of each other. Is it not the case?. How come travis never reported this issue to my knowledge?. @dave-r12 \nThanks!\n\nI wasn't able to find an easy way to run tests in specific order via gradle.\n\nYou shouldn't have to. And I would recommend against that as long-term fix to fix issues in the tests.\nIdeally, tests should be independent of each other. If your theory is confirmed, I suggest we find a way to break this dependency. \nSure, each test should do its best to release resources. In unit tests, however, wouldn't it be easier if tests are independent and the resources are automatically released when the tests end ( e.g. as the test class instance is garbage collected)? \n@kunkun-tang \nany comment?. @kunkun-tang in\npublic class JdbcTriggerImplTest {\npublic static AzkabanDataSource dataSource = new AzkabanConnectionPoolTest.EmbeddedH2BasicDataSource();\nWhy does the dataSource field need to be static?\nhttps://github.com/HappyRay/azkaban/blob/5ec24676202eba45355eb5e331c15556c8b5e274/azkaban-common/src/test/java/azkaban/trigger/JdbcTriggerImplTest.java#L46\n. Thanks for reporting this issue!\nSomeone will follow up. \nAre you interested in contributing a fix?. @ggalves \nThanks!\n@reallocf  you are secondary on call this week. Could you take a look?. May I ask what company you are working for?\nCould you include the version numbers? The latest version can change.. Thanks. What's the version that worked for you? Have you reviewed the change list between these two versions?\nAnd what's your company name? I am interested in who is actively using Azkaban to help us better serve the community.. Nice change description. I like it that you referenced the pr that introduced the bug.\nHow difficult would it be to have automated tests for this feature?. I am glad you found a simpler way.\nIn your earlier attempt:\n\n## Converted the executionOptions to JSON strings for clearer readability purpose.\n+      document.querySelectorAll('.executionOptions-json').forEach(\n+          function (element) {\n+            element.innerHTML = JSON.stringify(JSON.parse(element.innerText), null, 2);\n+          });\n+\n\nDid you intend to inject an object ( instead of a string ) into the template? What was the behavior?\nAnd you convert the html content to json using Javascript?\n. What's your use case?. Could you add to your PR description how you tested this change?\nOtherwise LGTM. Thanks!. Thanks for adding unit tests!\nLeft one comment. Otherwise LGTM.. Thanks for the update.\nCould you submit new commits with a description about each commit without rebasing? This will help reviewers see the changes better and allow the whole change history to be preserved. \nWe will rebase for you when the PR is merged. \nMake sure you keep the PR description updated. We will use that as the final commit message. . @mtrna sorry about the delay in getting back to you. I have been very busy with other tasks.\nYour change LGTM. I will try to merge it now.\nI am curious why you decided to close this PR. . Unfortunately, there is a merge conflict now.\n@mtrna are you interested in resolving the conflict? I will try to merge it as soon as you update this PR. . cc @ameyamk . @wyukawa \nThanks.\nSomeone will get back to you. \nPlease see my comments for the referenced PRs. e.g. unit tests.. @wyukawa sorry about the delay.\n@ameyamk I am too busy to keep up with PR reviews. If secondary oncalls can't handle the load too, could you assign someone? \nThanks. @wyukawa  and @kunkun-tang \nThanks. >  I believe it will execute the \"skipped\" flows due to our leveraging the Quartz scheduler.\nI don't believe this behavior depends on the new Quartz scheduler.. @mtrna Are you no longer interested in finishing this PR? Is there anything we can do to help?\ncc @ameyamk . Thanks for the PR and reporting the issue!\n\nIn practice the automatic evicting has caused more trouble than benefit in our case.\n\nI wanted to simplify the automatic evicting logic and also the load balancing logic for a long while now. However, we haven't prioritized that work.\nWhat if we remove the auto eviction logic entirely for now and re-think the strategy? I don't remember any incident that auto eviction helped in practice. \nWe haven't seen this particular problem so far. I guess it is because we run with many executor hosts, set the max concurrency to a low number. Thus each executor doesn't run too many executions concurrently.\nWhat's your setting? How often do you see this issue? \n. I can see why this is a problem for you now. \nI would view this new config as a temporary workaround. Are you ok with NOT documenting it as a public API ( config setting ) and reserve the right to deprecate it after we fix the underlying issues? \nSomeone from the team will review the details. We agreed internally to have secondary on-call to review new PRs. . @juhoautio I would agree with you that this piece of code has a lot of room for improvement. That's one of the reasons I would like to refactor/simplify it. \nI am interested in your improvement ideas.\nI would argue that it should be possible to improve this code so that users like you don't need to resort to configuration tweaks to make it work. . I have to refresh my memory about the logic here before I can be of more help with details. But yes, I would like to see your more detailed proposal which may include removing the auto eviction logic.\n@jamiesjc I remember you looked at this part of the code in depth in the past. Do you have any comment?. If you decide to remove the logic instead, how about creating a separate PR? How would that decision affect the other PR #1655 ?. Your approach seems reasonable to me. \nLonger term, I would like to rethink this part of the code. If possible, retire the entire logic.\nHave you considered switching to post only and remove the get support? . > My change here is backward compatible as long as executor is upgraded first. \nI am not sure this level of backward compatibility is required. We typically upgrade both web server and executors together. \n\nBut why not support all operations with post already now?\n\nCould you elaborate? I am not sure what your position is. . I like the detailed description.\nCould you remove the references to terminologies that are internal to Linkedin so that the content is more readable to people outside Linkedin? \nYour choice makes sense to me. \nAs discussed off-line, could you consider updating the DB schema to make the sorting order explicit and not relying on the default? I assume this will not trigger an index rebuilt since it will match the current default setting. Also do you plan to make a change to the H2 DB which you found has a different default? . Thanks @chengren311 for pointing out in his earlier comment that we do have\n\nFavor composition over inheritance.\n\nin https://github.com/azkaban/azkaban/blob/master/CONTRIBUTING.md\nThe earlier attempt of extending the ConcurrentHashMap class violates both conditions that are mentioned in the referenced article.\nhttp://thefinestartist.com/effective-java/16\n\nSafe way to use inheritance\nWhere the subclass and the superclass implementations are under the control of the same programmers\nWhen extending classes specifically designed and documented for extension\n\n. @chengren311 @juhoautio \nThanks\nHow can we catch this type of bugs earlier? . @juhoautio Mistake happens. No worry. We deploy a new release to test clusters first. In this case, I don't believe it had any production impact on our users. \nThanks for your quick response!\nThis issue surfaced a gap in our test coverage. I'd suggest we run some integration tests against each commit. Linkedin internal CI pipeline supports it. But being an OSS project, we haven't implemented something similar. \nWhy should single-executor mode be different in this regard? I would prefer to consolidate the code path, support only the multi-executor mode for example. It's something on my todo list for a while. \nI have to read the code and think more about your suggestions 1 and 2. . Thanks! @juhoautio . Let me ask the team to see who can take over the review.. @juhoautio Thanks for making this change.\nWe deployed the version 3.59 which contains this change. We started noticing following issues:\nSome flows are displayed as running while according to the DB, they have finished. This causes some subsequent flows to fail. It also causes users to get alerts which wouldn't stop. \nWe think that there are some problems in the code that manefest themselves more clearly with this change. It may be related to how we deploy changes at Linkedin. \nThe deployment to more clusters is currently blocked because of this issue.\nI know @jamiesjc and you are discussing how to fix forward. \nI wonder if you are ok with making a change to \na. rever back to the original behavior of finalizeFlows\nb. stop sending alert emails\nfor now to unblock our next release.\nYou can keep other changes in.\nThis will allow you and code reviewers more time to prepare a better fix. I wouldn't want such a change to be rushed.\nWe should continue to discuss how a longer term fix should look like. \nWhat do you think?\nRay\n. Thank you for your quick response and being cooperative! \nI will need to discuss with @chengren311 and @jamiesjc more on this. But my current understanding is as follows:\nAfter a deployment, we keep the old executor running until all running flows finish. The deployment script will sed the shutdown command to the old executor instance. see https://github.com/azkaban/azkaban/blob/7cd51237ad9e9f1994931cbe64f6dc1a640c0ece/azkaban-exec-server/src/main/java/azkaban/execapp/ExecutorServlet.java#L122\nWhen flows finish, the executor instance is shut down and the DB entry removed. However, the web server keeps checking the running flows' status by asking the now missing executor instances.\n@chengren311 @jamiesjc please correct me if I am wrong.\nDoes it make sense?\nI will take a look at your change. I just thought of another workaround. I will discuss with the team first and get back to you.\n. Thanks for this PR!\nWe should regularly review the test runtime. I remember both intellij and gradle have nice reports regarding test run times. . @juhoautio left comments.. @juhoautio Thanks. It seems that you changed the metrics related tests implementation to make it faster instead of ignoring it. Shouldn't the PR description be updated to reflect the new changes?\n@kunkun-tang could you also review since you are most familiar with this test?. @juhoautio Thanks.\n@kunkun-tang Ping. \nThe sooner we merge this PR, the sooner we can get the benefits.. @juhoautio, @kunkun-tang \nThanks!. Thanks for the cleanup effort!. Thanks @chengren311 for the review!\n@juhoautio I am sorry for the delay in reviewing your changes. I have been assigned some high priority work that I may not be available to do reviews for a while.. @juhoautio \nThanks for the refactoring!\nYes, multiple commits make it easier to review. \nI wonder if we should preserve these separate commits when we merge. . @chengren311 could you comment here with the sample program that demonstrates your alternative approach here? . @li-afaris \nThanks for the quick review!\nActually, I didn't add additional unit tests. I just modified the existing ones you added to make it work with the existing data structure. I did add more comments to the existing unit tests.\nAs a side note is there any way to run these tests automatically like the Java unit tests? I looked at the shunit project site and couldn't find a way. \nI'd suggest we move to Python as the scripts become more complex. Among other benefits, python has better unit test supports.. Thanks @chengren311 \nI chose the multiple files approach because:\na. It facilitates better code sharing. The same internal scripts can be shared.\nb. Users can customize the simpler wrapper script more easily e.g. set different JAVA options. \nc. the readability is just as good IMHO. Shawn:\nContinue the discussion In #1703:\n\nI'd suggest you start that discussion in the PR that introduced this change. The PR description explains the rationale for that change. Happy to discuss if it is not clear or if you have concerns about the design.\nIf you mean this PR #1669, I did read it. However I think I would probably just merge the two start scripts into one instead of keeping the current setup. In fact I think the start-exec.sh is redundant. User should just invoke the main script directly. If they want to redirect output to a file, they can easily wrap that with a one liner in upstart or systemd. As an OSS project, azkaban should let user choose what the launching behavior they want rather than choosing for them. In fact having all pieces in one file is generally what java based apps do when they provide launch scripts. For example: https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot-tools/spring-boot-loader-tools/src/main/resources/org/springframework/boot/loader/tools/launch.script\nWith that said I think this is out of the scope of this PR. I bring this up b/c otherwise the scripts can be simplified.\n\nUsers can still customize and use their own launch scripts today, can't they? \nHow would you solve the stated problem in this PR? \n. Related to #1669 . @jamiesjc Thanks for the review and helping to ensure a consistent coding standard!. see https://docs.npmjs.com/files/package-lock.json#description for why the file is checked in.. @li-afaris I remember you said you saw an issue with the scheduling page with your first attempt. I don't see a description of the problem here and its resolution here. Could you provide some details?. @reallocf Thanks for the review!. @chengren311 did we miss this file when we did mass formatting change in the past?. We don't use HiveServer2 yet. So we won't exercise this functionality regularly. \nDo you have ideas how to automate testing of this feature? . @aycaacar I just saw your earlier comment about unit testing. I am glad you already thought about this.\nThe challenge for us is that we don't have a test environment set up to test this feature. \nIt's a gap that we have to have test coverage for testing these scenarios. I am not aware of an existing test that you can use as a reference yet. It's something we should work on and I would appreciate any contribution there.. @aycaacar We will have an internal discussion about what accepting changes that we can't test ourselves first. We will get back to you. . @chengren311 and I discussed.\nI haven't had time to take a look at this PR in details. \nIMHO, the current email related classes have mixed concerns and I've suggested that we refactor them.  However, we haven't prioritized that work.\nIf this change moves us in that direction, I think we should evaluate and merge the change.\nI've asked @chengren311 to take a closer look and I will help if needed. \nThanks again @juhoautio \nAnd sorry about the wait to start reviewing this PR. . Hadoop core team members pointed out that PIg/HIve jobs can run multiple MR jobs and the AZ logs may contain multiple links. \ne.g.\na pig job\nJob DAG:\n25-03-2018 13:06:54 PDT pymk-profile-views INFO - job_1521836707298_331557  ->  job_1521836707298_334891,job_1521836707298_335536,\n25-03-2018 13:06:54 PDT pymk-profile-views INFO - job_1521836707298_334891  ->  job_1521836707298_335424,\n25-03-2018 13:06:54 PDT pymk-profile-views INFO - job_1521836707298_335424  ->  job_1521836707298_335536,\n25-03-2018 13:06:54 PDT pymk-profile-views INFO - job_1521836707298_335536  ->  job_1521836707298_337213,\n25-03-2018 13:06:54 PDT pymk-profile-views INFO - job_1521836707298_337213\nThe UI needs to take this into consideration.\n. Have you evaluated the option of just showing the additional job history server URLs after the existing log URLs as I suggested earlier offline?\nBy doing that the implementation is much simpler and we don't have to worry about the compatibility issues and its associated testing costs. \nI am not sure how much additional value users will perceive the buttons/dropdowns compared with the solution above. I don't expect them to look at the log URLs unless they are debugging an issue. In that situation, they would probably want to look at the complete logs for context anyway. At least they may not mind looking through the logs since they don't need to do it that often hopefully.\nAnd users are already familiar with where to look already. As an example, when you tested it with Subu the other day. He was looking at the log and saw the old link and missed the new button until I told him. \nHave you got some feedback from users which design works better for them?\nWhy is it considered an experimental feature? . Sounds good. Thanks. Looks like most of the logic don't have unit test coverage. We really should enable code coverage reports.. @chengren311 Thanks\n. @ameyamk  please prioritize this work.. @xunnanxu Thanks for your contribution.\nIf you haven't already, please familiarize yourself with the contribution guide. See the project readme.\nI will let secondary on-call or @li-afaris who is more familiar with the operation to review this change. . > Discussion: I generally doubt why we need to split the original single script to external/internal. \nI'd suggest you start that discussion in the PR that introduced this change. The PR description explains the rationale for that change. Happy to discuss if it is not clear or if you have concerns about the design. . I am glad you have read the contribution guide already. It's just a reminder since these are your first PRs to this project.. Continued part of the discussion in #1669.. I would prefer simplifying the dispatching logic. I haven't seen evidence that the current design ( before your change) provides meaningful benefits in practice.  . Does it work better than random assignments in practice?. Could you describe in more detail how the filter setup was broken for you?\nThere are configurations to control concurrency in executors. And recent changes made by @chengren311 will queue java jobs if memory is running low. Do you run java based jobs? Are these measures not enough for your use cases? Could you explain how the filters will work better for you?. No, random assignment is not implemented today. It's a thought experiment. And we could implement it.. > recent changes made by @chengren311 will queue java jobs if memory is running low.\n@chengren311 do you remember your PR link \n@xunnanxu I am not seeing some of the answers I am looking for. Maybe my questions are not clear enough. \nIf it is not clear to you yet, I am interested in retiring this entire feature and replace it with random assignment and leverage flow controls at the individual executor level. . @kunkun-tang:\nThanks\nDoes it make sense to break up the plugins into their own subprojects? This will improve build/test parallelism and modularity in general. \nWhy does this jar file need to be checked-in?\nA az-jobtype-plugin/lib/teradata-connector-1.4.2.jar (0)\n. I see.\nHow about we move only the essential job types for now? i.e. leave the TD one alone for now until we have a better handle of it. . @kunkun-tang your suggestion sounds good to me. Make sure you modify the deployment pipeline accordingly.. I agree.\nIt's on the todo list to give user jobs more control over logging.. Thanks.\nThis PR helps.\nWhat I proposed to the team was to find an alternative design so that AZ interfere with job code's logging as little as possible. i.e. normal logging for jobs should be the job designers' chose and responsibility. I believe this design is possible. Make sense?. Yes, it is one of the problems.\nAnother problem is that the logging infrastructure is inefficient and the logging user experience can be improved. Logs are stored in a MySQL DB which is not the best choice for storing logs IMHO.  \nI would like to redesign the entire log handling. The work is not prioritized yet. If you are interested. you are welcome to participate. \nI added some ideas in this new issue #1744 . What Travis test failures did you run into? We would like to know so that we can fix the flaky tests. . Thanks. I haven't seen this error before. And I looked at the log. It's not clear to me which class caused this error. . @xunnanxu Thanks for answering user questions.\n@trentgerman in case you are not aware yet\nin\nhttps://github.com/azkaban/azkaban/blob/master/README.md\nhttps://github.com/azkaban/azkaban/blob/master/CONTRIBUTING.md\n\nPlease don't report an issue as a way to ask a question. Use the Google group instead.\n. It's fair to open an issue that you find the documentation needs an improvement. PRs for docs are welcome.. The file names/paths look the same to me.\n\nWhat was the problem?. I haven't had time to look at this PR in details yet. \n@mtrna I appreciate your contribution to make our product better, based on your description!\nI am glad to see the community-driven reviews. \nThanks @juhoautio !.  At a glance, the change LGTM. I will need more time to review this since I don't remember the details of these tests now.\nI trust @juhoautio's judgment. If he is ok with it, chances are the change is fine. :) \nThis PR reminds me that I need to remember to check with company lawyers and open source team our policy of allowing committers from outside of Linkedin.\n@juhoautio do you think this change is going to fix the recent unit test in-stability reported by multiple users?\n@kunkun-tang since you are more familiar with this code. Could you review and merge if it looks fine to you? \n. Shouldn't the admins get an error when loading the xml file?. Failing fast seems reasonable to me.. > Do you also want to render users the full log config flexibility\nYes.  It's part of what I meant by \"Jobs can decide the format and content of the logs\"\n\nAZ may define a default log4j config, and jobs are able to override part of it.\n\nI think it makes more sense to make this part job type specific.  This is not so different from letting each process/application decide about their logging configs. In this context, each job process corresponds to a job type. This part needs to be designed.  This is related to the job type re-design we talked about.. +1 to @juhoautio's suggestion.\n. @juhoautio Thank you for your continued support.. @juhoautio Thanks\n@chengren311 \nDid you forget to configure save action to be applied automatically?\nCould you review?\n. @juhoautio Thanks for your review.. Forgot to create a branch first. Will create a new one.. Could you elaborate? \nI don't see the code adding the same node twice in this file. . @reallocf \nThanks for such a quick response!. Looks like a flaky test:\nazkaban.execapp.event.JobCallbackRequestMakerTest > simulateNotOKStatusCodeTest FAILED\n    org.junit.runners.model.TestTimedOutException: test timed out after 4000 milliseconds\nretesting.. Thanks. Mine does.. @li-afaris \nThe error out goes to a different log file. Is there any reason not to use the standard log4j config to capture such error logs?\nWhat are the benefits to log the same in both places?\n\nWhile not frequently used, our documentation does reference WEBSERVER_URL/executor?ajax=...\n\nWhat do you mean?\n. I see. No,  the error output won't be returned to clients. . I would suggest separate commits for independent changes.\ne.g.\n\nchange retention period of historic trigger execution rows to 30 days.\nis a functional/config change, not a refactoring.\n. Looks like this is a fix\n\nhttps://github.com/tbroyer/gradle-errorprone-plugin/issues/50\n. Thanks.\nThis is related to #1680. Thanks for the PR!\nI added the following to the description to help with navigation and alert the original author and reviewers.\n\nThe issue was introduced in #1680\n\nCould you or @senecaso-sf think of a unit test to test this condition? \n. Thanks.\nLGTM although I haven't verified the examples in the test. \n@jamiesjc could you do a more detailed review?. Thanks.\nPlease see the config key naming conventions at \nhttps://github.com/HappyRay/azkaban/blob/98497ede72ee47ddabaa2d57038171f6161e2040/az-core/src/main/java/azkaban/Constants.java#L34. I would download the raw travis log and look for test failures. \nHow to find test failure from the ci log\nDownload the raw log\nOpen in an editor such as intellij:\nUse the reg expression\nTest > \\w* FAILED\nE.g.\nFound \nazkaban.execapp.event.JobCallbackRequestMakerTest > simulateNotOKStatusCodeTest FAILED\n. I added the tip to https://github.com/azkaban/azkaban/wiki/Developer-Tools-and-Tips. @kunkun-tang has added additional support for our new documentation system. Going forward, we would expect changes to include documentation changes as needed in the same PR whenever possible. That work is still in progress.\nCould you work with him to see if it is doable now?\n@kunkun-tang \ncould you review this change?\n. Please work with @kunkun-tang . Where are the tests for this change?. How do you plan to monitor this feature?. Why is this change needed?\nConsider adding an example before and after log.. Who uses this method and for what purposes?. I don't think it is currently supported. What's your use case? . Is it safer to turn off this feature by default? Otherwise, users including us may get surprised with the current default behavior. . It's great to see the code coverage report.. Is there a test coverage badge that we can add to the project like the travis badge we have?. As an example, the current Java test code is in a separate directory. Similar patterns should help with python too.. If I comment out the code block that calls shutdownNow, the test fails with:\nWanted but not invoked:\nexecutorService.shutdownNow();\n-> at azkaban.utils.ExecutorServiceUtilsTest.force_shutdown_after_timeout(ExecutorServiceUtilsTest.java:60)\nHowever, there was exactly 1 interaction with this mock:\nexecutorService.shutdown();\n-> at azkaban.utils.ExecutorServiceUtils.gracefulShutdown(ExecutorServiceUtils.java:48)\n. How do you plan to generate the files for existing cache directories?. Remember to take into consideration how our OSS users will use the feature. . I saw \"Thread.sleep(1000);\" is still there. I don't see a response to my earlier comment regarding this. \nIs the sleep necessary? Unit tests should be as fast as possible.\nPlease ask another member for a review too. . Thanks for improving our documentation infrastructure! The demo doc looks good to me.\nAs discussed, consider having one shared python virtual environment i.e. requirements.txt at the root level? . Could you include screenshots of before and after the fix?. > As you can see, the fix sets a fixed height to the log textbox, and as the screenshot shows it gets cut off if the window size is not as high.\nI am not sure I follow.\nOtherwise LGTM. Thanks for the explanation.\nCan you think of a way to use the available space more efficiently? If this is a blocking issue, I am fine with checking in this change first.. @kunkun-tang do you know a better way?. I am not sure this is the best tradeoff. Ideally, we should not have to choose. We should try to find a better solution.\nI will defer to @kunkun-tang. \n. see https://github.com/direnv/direnv\nI can show you.. The test failure seems to be\n\"azkaban.execapp.FlowPreparerTest > testProjectCacheDirCleaner FAILED\n    java.io.IOException: java.lang.RuntimeException: java.nio.file.NoSuchFileException: projects/1.1/azkabanproject_dir_size_in_bytes_\n        at azkaban.execapp.FlowPreparer$ProjectCacheDirCleaner.deleteLeastRecentlyUsedProjects(FlowPreparer.java:268)\n        at azkaban.execapp.FlowPreparer$ProjectCacheDirCleaner.deleteProjectDirsIfNecessary(FlowPreparer.java:292)\n        at azkaban.execapp.FlowPreparer.setupProject(FlowPreparer.java:170)\n        at azkaban.execapp.FlowPreparerTest.testProjectCacheDirCleaner(FlowPreparerTest.java:176)\n    Caused by:\n    java.lang.RuntimeException: java.nio.file.NoSuchFileException: projects/1.1/___azkaban_project_dir_size_in_bytes___\n        at azkaban.execapp.FlowPreparer$ProjectCacheDirCleaner.lambda$deleteLeastRecentlyUsedProjects$0(FlowPreparer.java:264)\n        at java.util.TimSort.countRunAndMakeAscending(TimSort.java:355)\n        at java.util.TimSort.sort(TimSort.java:220)\n        at java.util.Arrays.sort(Arrays.java:1512)\n        at java.util.ArrayList.sort(ArrayList.java:1460)\n        at azkaban.execapp.FlowPreparer$ProjectCacheDirCleaner.deleteLeastRecentlyUsedProjects(FlowPreparer.java:258)\n        ... 3 more\n\n        Caused by:\n        java.nio.file.NoSuchFileException: projects/1.1/___azkaban_project_dir_size_in_bytes___\n            at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)\n            at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)\n            at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)\n            at sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)\n            at sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:144)\n            at sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99)\n            at java.nio.file.Files.readAttributes(Files.java:1737)\n            at java.nio.file.Files.getLastModifiedTime(Files.java:2266)\n            at azkaban.execapp.FlowPreparer$ProjectCacheDirCleaner.getLastReferenceTime(FlowPreparer.java:250)\n            at azkaban.execapp.FlowPreparer$ProjectCacheDirCleaner.lambda$deleteLeastRecentlyUsedProjects$0(FlowPreparer.java:260)\n            ... 8 more\n\n\"\nOpened an issue #1901. @bhatiakartik \nYour suggested pattern is possible.  We have discussed this subject within the team. This is a tradeoff between features vs cost ( complexity etc). One consideration is that currently, AZ doesn't prevent jobs from making assumptions that all jobs in the same flow run on the same host. Maintaining backward compatibility increases the cost of such implementation.\nHere is my current thinking:\nAzkaban is designed to be a scheduler/task launcher with DAG capabilities. It's not intended to be a replacement for scalable distributed execution systems( spark, Hadoop etc). It currently has decent integration with Hadoop ecosystems. I recommend launching from Azkaban resource intensive/parallelizable tasks in such execution systems. \nI think we should continue to enhance AZ to make it easier to launch tasks in external systems, minimize the resource consumption of the AZ jobs, improve the job resource consumption isolation/fairness, resilience in the face of demand exceeding available resources.\nCould you share more details about your use case? e.g. how many jobs does your flow contains? How many of them can run in parallel? What do they do? What resources do they require? . Thanks for the suggestion.\nI made the change.\nI hope it won't make the result too noisy.\nI also changed the permission to allow anyone to edit the wiki. Please let me know if it is not working. . Thanks for fixing this.\nCan you think of a reason why the project is not deleted?. Yes.. @jamiesjc I remember we had a discussion about this behavior before. This behavior causes some other issues too if I remember correctly.\nDo you remember the outcome of that discussion?. @jamiesjc Thanks.\nShall we try removing the inactive project logic then? This will simplify the code a bit.. We can still make this change for now.. Thanks for improving the tests!. I agree. \nI opened an internal issue to get it fixed. But it still hasn't been prioritized. :(\n. > Also, it would be nice to rename the test file/class to FlowRunnerYamlTest? To have the usual *Test suffix, right?\nMake sense to me. @jamiesjc is there any reason not to follow the standard test class naming convention?\nsee the discussion on https://github.com/azkaban/azkaban/issues/1902#issuecomment-412796786. Reducing test running time is also important.\nPlease research better alternatives. \n@chengren311 faced similar issues in the past. You may want to check with him. \n@juhoautio, any assistance/suggestion will be appreciated as always.. I agree sleep in tests should be avoided as much as we can. . @jamiesjc  Thanks. A test that is hard to understand is a sign that there is room for improvement. Maybe the test is done at a suboptimal level or the production code needs to be improved... A good test needs to be readable just like production code. \nI suggested to @jamiesjc to take a look at the unit tests I wrote for the new engine as a comparison. . Where is the documentation for this feature?. @jamiesjc \nWhat's the plan for this test next? Is there a ticket to track the remaining work?\nIf this test has no value, it should be removed.\nIf it is flaky because of test implementation, could you try fixing it? \nIf the test failure is signaling us that there is a bug in the production code, you know what to do :)\n. @jamiesjc \nThanks for the explanation. I saw your comment in the test now. It is great that you are documenting why a test is disabled.\nI saw that #1311 is still open. I don't remember the exact details now.  That references my previous fix #1310. Is that fix what you are referring to?\nI am too busy on other projects to continue the work on the new DAG engine. There is still a lot of work to do. With the added complexity of conditional workflow, the integration work will take even longer. \nIf you know a fix already for the existing code, I wouldn't wait for the DAG engine to replace this code.. \ud83d\udc4d Thanks. Consider using Duration? \nAnd in the configuration, I now think it is better to standardize on what @suvodeep-pyne suggested earlier in #955\n\"\nRegarding configuration parameters, Duration can be there as well. There are methods like java.time.Duration#parse which uses the ISO-8601 duration format PnDTnHnMn.nS. Example:\nSet max flow running time to 15 min\nazkaban.server.max.flow.running=PT15M\n\". @juhoautio Thanks.. @li-ygerchikov @kunkun-tang Thanks for looking into this.. @li-ygerchikov Thanks!\nCould you share how you fixed the cache for future reference?. Thank you for your contribution!. @juhoautio what do you think of the proposed conventions?. > For example, if I apply save actions with this configuration on ExecutorManager.java, there are many references to the logger in the inner classes that then become ExecutorManager.logger.\nI believe it won't happen with the proposed rule above:\nAdd class qualifier to static member access outside declaring class only\n. I see. Do these inner classes need to share the parent class's logger?. I need to review the code to remember what they do. A good thought. Care to refractor it?. Thanks. Thanks. This is a tricky area to get right. I wish I had time to finish the engine rewrite.\nLooking at the code, it is still not clear to me how this change makes a difference. \n@chengren311 since you worked on this code, could you take a look?. @chengren311 could you try to repo the test failure?. Thanks for the pull request! I want to simplify this logic for a long time now.. @jamiesjc since you are familiar with this part of the code, do you mind reviewing this change?. @chengren311 added support for this feature on top of the flow 2.0 design @jamiesjc did. @chengren311 can share more details.. > > Related issue is that az-web doesn't currently support catchup of scheduled executions if az-web itself has been down.\n\nRight, the scheduled executions will be missed during the downtime of az-web.\n\n\nI thought the scheduled executions were saved in DB and will resume after the web server is back.  We rely on this to not miss scheduled executions during deployment. Did I miss something?. Thanks. By running executions do you mean the executions that have started consuming the old version of the project? \nCould you make it more clear what the symptoms are in this PR description? I understand they are described in the referenced PR. IMHO, it is better to make it more explicit here as well.. The PR description is clear. Thanks.\nI remember the executor will hard link the project directory when it starts execution. I wonder how that design doesn't prevent the issue you observed. @burgerkingeater what do you think?. I see. I will need to read the code again to refresh my memory first.  It may take a while before I can get to it.\n@burgerkingeater could you also take a look?. We decided to try an alternative fix first #2007 \nThe deployment is taking place. So far so good. But it takes a while for the symptoms to show up. \nThis change will be our backup plan.\n. @chengren311 does the #2007 slow down the normal shutdown process too?. @juhoautio Thanks for sharing this information here.\n@jamiesjc shall we include this information in flow 2.0 documentation also if it is not there or obvious?. By DSL, I mean this project\nhttps://github.com/linkedin/linkedin-gradle-plugin-for-apache-hadoop\nThis is what most Linkedin engineers use to author their flows.. I can compile with the same JDK fine. \n. Thanks. I added your explanation to the merged commit message.. The executor was shut down gracefully and the entry removed. . How did you test this change?. > Yes, my point was that a better fix would be to make the updater check from DB does the executor exist any more if it can't be reached. And if the executor has been removed, just finalize the execution instead of trying to call executor to get the same information.\nI am not sure this solution will be subject to a race condition yet:\nthe web server checks a running flow status for an executor instance that is shutting down. It gets an error because the executor is shutting down. It checks the DB and sess that the instance is still there because the executor instance hasn't removed itself from the DB yet. According to the code below\nhttps://github.com/azkaban/azkaban/blob/c564f24837cf4ea1cf0c1d6469eef735ba81d5f0/azkaban-exec-server/src/main/java/azkaban/execapp/AzkabanExecutorServer.java#L185 \nThis race condition may not be possible. But we need to be sure. What do you think?\n@jamiesjc told me that you and she were discussing other alternative fixes. She mentioned the above too. Please continue to explore better alternatives including your suggestion above.\nI suggested this \"simpler\" approach for now to\na. unblock the release\nb. allow us to test if this issue indeed disappears because your earlier change makes the issue more apparent. \nI am still not sure if emailing users, in this case, is a better choice than notifying administrators though.\n@jamiesjc is writing a new design proposal that would hopefully simplify the dispatching logic. She will share it with you and others here to get feedback. \n. Where does this requirement come from i.e. why is it necessary?. Thanks for fixing this test failure.\nIs there a way to remove the hardcoded year assumption in this test?. Never mind.\nI thought you replaced 2018 with 2019 based on your description. . > Could it be a goal in Azkaban project to keep the tests quick & especially avoid Thread.sleep?\nYes. Thanks for the investigation. \n. @abti is the new manager. Please work with him directly. Thanks\n. Is this still being actively worked on?\nI haven't had a chance to look at the change in details yet. I am not sure I follow the PR description. I can use some help in understanding the goal of this change.. I took the liberty of updating the change description.. Thanks for reporting this issue. I agree 401 seems to be more appropriate.. Could you elaborate the benefit of doing so in the PR description?\nIt seems that the counter is backed by AtomicLong too.\nThanks.. Could you add more comment? e.g. how the %s works?\nComment out these configs. Users can uncomment and customize.\n. Define the string as a const?\n. Is the string URL encoded?\n. Consider adding some logging?\n. Will execution id do? Do you expect applications would need the full URL? \n. What do you think about separating this part into its own method and add a unit test for it?\n. Is the button going to show up to the right of the other execution related buttons? \n. Could you explain how the tabindex=-1 is intended to do? Is it to disable keyboard navigation? If so, why?\n. Are there existing classes that you can use? Do you have to create a new class?\n. Your suggested approach sounds good to me. \n. Could you help me understand why Dr. Elephant needs the full url instead of just the execution id? How difficult is it to add the capability? \nThe URL would look cleaner with just the execution id. \n. Got it. Could you add comments to the code to explain this?\n. Sorry, I am not sure I follow the \"the tab order is broken\" part. Could you elaborate a bit more?\nI thought the resume and pause buttons wouldn't be displayed at the same time. They are controlled by the logic in the js.\nIn any case, could you add comment in the code to explain? It may not be obvious to the readers of this code.\n. Let's discuss when we know the LOE from Dr. Elephant side.\n. I wondered why your button needs to be different enough from other buttons that you had to define your own style. The more styles, the more work it will require to maintain. If there is a good reason to be different, it is fine. Please consider adding comments to explain. \n. This will completely disable the ability to focus on the analyzer button, right? \nWould it be a better trade off to have the button show up next to the Stabs tab? This way the code reflects the same order as the order of the UI elements and tab order is more natural. \nGiven that I don't expect keyboard based navigation to be widely used, I am more concerned about the code readability.\n. Order it by alphabetical order?\n. Would it be easier to use Mockito to create mocks?\n. This doesn't seem to assert the result link is generated correctly.\nAnd the return value of the method seems to be only used for this testing purposes.\nSee my comment in the production code about a possible alternative.\n. Did you add extra white spaces?\n. What if you structure the code so that the method will return a URL string to be inserted into the page? Your test will be able to assert the string has the correct content. And your test will not have to deal with page object.\n. I was working on another unit test in this project and had to add this dependency as well. In my case, it appears to be testRuntime dependency. \n. I see.\nIn this case, let's not complicate this feature. \nSupport the complete URL only is fine with me. Could you add a comment explaining why the complete URL is used? I don't expect this feature to be widely used other than integration with Dr. Elephant in the near future. \nI agree %url seems to reflect better what's happening than %s.\n. That's what I am hoping for. See my todo comment above.\nEven if that is possible, we can't just turn it on without risk regression. It's better to do it separately IMHO.\n. What do you mean?\nThis file is used as a \"plain text\" to verify the test output. \n. No, it is not necessary for this change.\nHowever this is here to mimic the production code in anticipation of future tests of .vm files that need this object.\n. Yes.\nI explained this change in the change description. \"Also change Gradle wrapper to bring Gradle source to enable autocomplete.\n\"\n. Nice log.\nConsider making it logger.error?\n. Is it the convention to name the logger LOGGER?\n. Is there a method that will return the complete URL from the req object?\n. It's easier to read now. Thanks\n. Is it possible that ret is null here? What happens if it is null?\n. Would using a dispatch table be easier to read and maintain?\n. Should this error be printed to a log?\nThis exception shouldn't happen though. It should have been caught by the unit test you wrote. \n. Would it work using a table that maps strings to objects that implements an interface?\nIn any case, since this is the existing code you just moved around, your change looks fine to me.\n. It would be great if you do. Thanks!\n. This method is for unit testing only, right?\nHow about making it package private? This way the readers would know that this is not a public API outside this package and would reduce the search space. \n. Same comment as getBody method above.\n. This is only used for unit testing, right?\nHow about changing the name to something like setCurrentTimeMillisForTesting? \nOr alternatively add a comment. \nIdeally, I would prefer using a mocking framework to mock out the call to System.currentTimeMillis. However the change required would be much more significant. What you have done is an improvement. Having a test is much better than not having one!\n. How about a name like useSystemTime? Or add a comment explaining what this is for?\n. Thanks for adding unit tests!\n. Does it make sense to use a constant and add a comment to explain what it represents?\n. Why this change? We want to ignore the build directory but not the file build if any under the project root, right?\n. Nice change and comment.\n. Nit: could you keep the style consistent? I don't have a strong opinion either way.\n. Nice.\n. Do you mean the specified time zone at the end will be ignored unless it is UTC?\n. Maybe explain the reason for this check? This is there because of the assumptions the cleanOlderProjectVersion made, right?\n. This logic seems to be common in both cases. Right? If so, do it in a common place?\n. Does it return the time based on the browser's time zone which may be different from the server's time zone?\n. Consider making the switch to the new UI using a config value.\n. Add cron info?\n. Write to logs?\n. Thanks Gaurav. \nIf we control and modify all of the clients of this API, is it still a concern?\n. It may be useful for debugging purposes to save the original exception as an inner exception.\n. @logiclord Even though this is a public method, is it documented anywhere publicly that this is a public API that can be relied on outside of this project?\n. Sort import. You can use IDE's organize import feature.\n. There are too many parameters. Maybe using a builder would be useful. You can refactor it in a separate commit if you decide to do so.\n. Is the intention to have one constructor for the old period based schedule and a new one for the Cron based schedule?\nIs it possible to call the other constructor internally which has all the options?\n. When is the setter needed?\n. How often is this method called? Does the expression need to be parsed multiple times?\n. Could you add comment to explain the logic here? \nMy understanding is that you want to avoid returning a datetime that is in the past. Right? What does the scheduleTime represent? What if you pass the later of ( current time and scheduleTime ) to getNextValidTimeAfter? \nSince we don't support schedule a time after a future date, we can simplify it further by passing just the current time. Did I miss something?\n. These two methods seem to be identical except the names. Any idea why two methods are needed?\n. How about cronExpressionString?\n. How about cronExpression ?\n. Add a comment to explain that the the timezone types need to be converted? Thoughts on how to avoid this conversion in the future? What if we move to Java 8 only?\n. When will this happen? How would the service behave when this happens?\n. See my earlier comment. The logic here seems to be similar to the other method I commented earlier.  Thoughts on reducing the duplication? \n. I remember seeing a similar logic elsewhere....\n. Unit tests for these methods? How do you know they work and stay working?\n. Thanks for adding tests.\nCould you at least add tests for DST handling? This will serve as documentation as well.\n. Any idea what this migration is used for? Is it still useful?\n. Add a comment to explain what it does? It's not obvious to me.\n. \" everything in Azkaban functions is at the minute granularity\"\nHow about:\nThe scheduling thread currently checks  every minute. Thus the current implementation doesn't support sub-minute granularity in schedules.\n. What do you mean by adding 0?\n. Is it less likely to make config mistakes if we make the config a binary switch?\n. Isn't it better to keep the data immutable?\n. Either true or false : use old UI or new UI.\n. This method will no longer take into consideration of the current time. Is it right?\n. to \"API call\"\n. A more descriptive test name? It will make it easier to see which test fails\n. Add links to an article that describes how the transition works?\nDescribe how our system works?\n. Is this time 2020 Aug 3 2:30 UTC?\n. Why not just use time now since the delta between these two times should be very small. This will simplify the logic a bit.\n. Could you also add a comment to the old code? Explaining the difference between this new code and the old.\n. Add more details? The next execution time will become 3:30 PDT instead of 2:30 PST before.\n. Add another assert based on PDT? And maybe mention that there is no 2:30 PST on that day.\n. choose an expression to demonstrate that the missing time will be skipped?\n. Could you find out if this code can be retired? If so, open a ticket? \n. Rename to \"SchedulePanelPageName\" ?\nEven better, make it \"enableNewSchedulerUi\" and make it a boolean type?\n. Do you mean the API will ignore the second field effectively?\n. Add comment to explain what this style is for?\n. Add a comment as to why \"adding 0\" here?\n. Add a comment: this is to update the instruction panel based on which field is selected?\n. Clarify what \"Cron\" mean here?\n. Adding a unit test for this function?\n. It would be great if we don't need to include this file.\n. Open a ticket to update the moment.js so that we don't have to checkin this modified code?\n. Clarify that this test is designed to show that using UTC timezone will not skip a run but will shift execution time  based on the Pacific time when DST changes.\n. Remove this comment\n. Clarify that the schedule will still be executed once on that day.\n. Add a comment highlighting that the local time remains the same.\n. Defer supporting this parameter until later?\n. Use server time?\n. typo: browser\n. How about naming it \"serverTime\"? \n. Name it \" serverTimeInJsDateFormat\"?\n. Add comment why this number 6 is chosen?\n. In order to enable the gradual roll out, shouldn't the default be the old page?\n. What happens if this line is removed? Will this plugin use the same default config?\n. How did you determine that these dependencies are not needed?\n. Any suggestion on how to keep the dependencies' versions consistent across submodules?\n. Thanks for adding comments.\n. Nice. Thanks for doing this!\n. Can you think of ways to reduce the logic duplication?\n. Unit tests?\n. Is deleting the temp dir new logic?\n. Why catching this exception?\n. Consider making each error on its own line?\n. Does it need to be public method?\n. Consider asserting an exception is thrown directly?\nhttp://stackoverflow.com/questions/156503/how-do-you-assert-that-a-certain-exception-is-thrown-in-junit-4-tests\n. Nice comment.\n. Consider asserting that the exception contains the expected error msgs?\n. Consider adding a test for multiple errors?\n. The same comment is in the date.js already. What do you think about removing this to make the comment easier to maintain?\n. We have source control, do we still need the author name and date here?\n. Java doc?\n. Document what the path parameter should represent.\n. Nice. \n. Should it go to the log?\n. Nice. It would be even better to link to a ticket.\n. Add an example?\n. Is there a library method that can do the same?\n. Is it worth definging execute-as-user as a constant?\n. Nice use of the final in many places.\n. Nice defensive programming.\n. Technically the azkaban user has read access too. \nIf you would prefer avoiding duplicating comments, may be point to the comment of the other method?\n. Instead of partitioning the argument string, have you considered passing an array or something that is easier to parse? Python subprocess module uses that approach.\n. This assumes that the user running this process is \"azkaban\". It's probably a safe assumption. It would be better if this is documented somewhere. \nShould 'azkaban' be a constant?\n. I recognize that creating a ticket adds overhead. So use your judgement.\nThe benefit of creating a ticket is to remind / force us to follow through. \nIf the plan is to address the todo items shortly, a ticket would be required anyway.  If we don't intend to address them soon, I agree the overhead of a ticket may be relatively high. \n. I must have missed your comment that this is code copied from the existing code.\n. Is it needed for this pull request?\nIn the future, what do you think of keeping different changes in separate commits? \n. This change seems to be related to the unit test you added. Right? If the change is small, maybe mention it in the change description if you want to avoid the overhead of making another change?\n. Does the expression need to be URL encoded? Do you need to pass the additional parameter? \nsee\n\"To URL-encode the value of a form field you may use --data-urlencode.\"\nhttps://curl.haxx.se/docs/manpage.html\n. What's the motivation for having this static method and making the constructor private?\n. What's the purpose of the nestedId? Add a comment?\n. What's the use case for making this field mutable after the instance is created?\n. This will throw an exception if the condition is not met. How did you make sure that all the callers don't pass in null? \nIt's a risk that the exception may cause a thread to die. Before this change, such a bug may have been hidden but may not cause a production issue.\n. Why this change? The old code sets shouldUpdate to false. You removed it. Could you explain your design?\n. What do you mean?\n. Can this return value cause public static Event create(Object runner, Type type, EventData eventData) {\n-    return new Event(runner, type, null, true);        +    Preconditions.checkNotNull(eventData, \"EventData was null\"); to throw an exception potentially?\n. Same as above. How do you test this error condition?\n. The caller has the status value already, what's the advantage of returning the same value?\n. I see. You can keep the check. \nWhat do you think of adding a comment here to raise awareness that this may throw an exception? When people make changes in the future, this can help remind them not to pass Null into this method. Compiler won't be able to catch this error, can it?\n. I still don't see a value to create these static methods. This adds unnecessary complexity although not much. What do you think of just using plain constructors?\n. Got it.\n. Got it.\n. I see. \n. nestedid seems to be a human readable id for the node. Maybe add a comment that this value corresponds to the return value of azkaban.executor.ExecutableNode#getNestedId?\n. Nit: would making it a checked exception be too restrictive? I assume it doesn't for the existing callers since they have to catch exceptions already. It's a small concern though.\n. Agreed in this case.\nCould you make this last change?\n. Keep the Javadoc warning users about not passing null as the value of the EventData parameter. Remove the checked exception. Make sense?\n. My bad. What you have looks good.\nI have approved this change. I am not sure how the new code review approval works. Could you try merging yourself?\nIf it doesn't work, please let me know and I can merge it for you.\nThanks!\n. Could you think of a way to reduce the code logic duplication in this method and the other one?\n. What's \"fillFlowInfo\" for?\n. Consider breaking this logic out to its own method?\n. Why not just remove it?\nHaving commented out code is not a good practice in general.\n. What about passing the client IP ( the last hop remote address ) into a common method? One call will be a value from req.getRemoteAddr() and another will be from context.getRawRequestContext().getLocalAttr(\"REMOTE_ADDR\"); \n. Pls add copyright notice.\n. Is the comment valid? \n. Doesn't this code assume that the conf dir will be under the binary dir? The location can be overwritten by using the -conf parameter eg. -conf temp/conf \nWhat do you think about adding the conf directory to the search path? Or use PropertyConfigurator see http://stackoverflow.com/questions/7390521/change-location-of-log4j-properties  What's the implication for log4j2? \n. I share with @suvodeep-pyne's concern that this information doesn't seem to fit well in the logic definition of a project. \nCould you describe your new GenericValidator interface better? Maybe in the issue?\n. Could you add JavaDoc? \n. Consider making \"X-Forwarded-For\" a constant?\n. Make it 2016\n. Link to the Quartz doc?\n. Add a comment e.g. the optional year field is present?\n. Aren't the indexes fixed at 3 and 5?\n. Does users have control over the message? i.e. is it subject to XSS risk?\n. Instead of 1 and 2, consider making them constants. And document the return values in the method signature?\n. I don't see the code updated to take advantage of this fact yet. Did I miss it?\n. Consider const? https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/const\n. Is it necessarily a client error?\n. Consider making azkaban.job.kafkalogging.enabled a constant?\n. What's the impact to the future migration to log4j2?\n. Is it possible to catch more specific exceptions?\n. What will happen if kafaAppender is not null in this case? What's the effect of the removeAppender call later?\n. Add the constant to a file that lists the job level properties?\n. How would you envision using log4j2's ability to dynamically adjust logging here? What's the use case? \n. @logiclord Thanks for your comment. \nIMHO having option in general is typically a tradeoff between complexity and flexibility. I will comment on the conversation.\n. Is this method still necessary? The second param is no longer used.\n. Explain why this property is necessary?\n. Consider adding why in the comment. e.g.\nThe execute_as_user binary requires special permission. It's not convenient to set up in a unit test that is self contained.\n. Consider consolidating the common code in a common setup method in tests?\n. Why this change?\n. Is this class shared between the web server and executor?\n. Is it necessary to make the port file name configurable?\n. Our automation may rely on the port file being there. Should we allow the exception to be bubbled up?\n. What's the benefit of having jobExecutorTests as a member variable? \nWhat do you think about making the method static? Afterall, it is a stateless method.\n. Never mind. I saw you changed it already in a later commit.\n. Thanks for your attention to details.\n. Could you make a separate pull request later to fix the logging here and others in this file?\n. Have you considered raise the same exception here? \n. Do you mean \"incomplete project files?\"\n. Do you mean \" this is desirable to ensure that the next version number will be unique\"?\n. Not sure I follow the comment.\n. Nice improvement to the logging. Thanks.\n. Do you mean \" something goes wrong after this entry is inserted\"?\n. Explain why this update goes first before inserting the data chunks?\n. Explain the reason. \nHow about \" to reduce the transaction duration and conserve sql server resources\"?\n. Thanks for adding comments.\n. Make sense to me.\n. Who needs error checking? Just kidding :) Nice.\n. Is it still useful to keep the port file so that we can match the number in our logs?\nI don't have a strong opinion either way. If we find such a need later, we can easily remove this line.\n. Is this mechanism compatible with log4j2 and slf4j?\n. I was thinking how a component that uses slf4j would be affected. I guess this change doesn't affect the producer of logging messages. \nwrt log4j2, could you share more details how the migration plan would be? We may eventually move to log4j2.. How does this version work?. Thanks for refactoring this code. It's easier to read now.. Good defensive programming.. Since exec should never be null in production, consider changing it to an assert?. Do you mean  you don't want users to control this behavior?. Make the config name a constant and add it to a file that is easy for users to find.. Consider a more consistent naming convention for the config property names?\ne.g.\nazkaban.server.logging.enableKafka\nazkaban.job.logging.enableKafka. What happens if the kafka server config is not configured and user enables this feature at the job level? . If you are sure and expect this should not happen, may be change it to an assert?. Consider adding a unit test for this method?. Use constants for config names and follow a consistent naming convention as suggested above?. Nice usage of the class to make the code easier to read than using raw strings.. Is this step necessary? I thought it would only affect the reference in this method's scope. . Log the stack trace to logger?. How about \" log clean up time:\" ?. Log to the logger?. What do you think of a name like azkaban.server.logging.kafka.brokerList? This way the name signals that this is a server config.\n. What do you think about removing this config and just use presence of the brokerlist and topic config as an indication if admins would like to enable this feature?. Are these configs injected by the AZ itself ( vs. created by users )?. What do you think about creating separate constant classes? One for server config, one for flow config, one for job config? \nThis file seems to be define constants that are not user visible. . See my earlier comments about using other configs to determine if admin has enabled the kafka logging globally. Maybe log an info message if users enables this feature but admin disables it?. This has an added benefit of dealing with the situation when the admins forgot to config one of the two server configs more explicitly and make it easier to debug.. When will the props contain this key?. Is it simpler to rely on the active and deactivate API calls?. Nice.. Where is this method used?. Thanks for updating the date. The context key doesn't seem to be path related.\nWhat do you think about naming it something more generic like Server and put all server internal constants here?. Maybe info? This doesn't indicate an error in most cases, right?. So this method is not used yet. Right? Would it be better to include that change in the next pull request then so that they are together?. See #813 . I am not sure why the API requires both project name and project ID as inputs. Wouldn't it introduce more opportunities for clients to make mistakes? . The existing code has duplicate logic. The method mentioned has two overloaded versions which are almost identical.. Yes.\nI don't have a strong opinion either way. \nI wanted to minimize my changes. . The return value of true indicates that the init method is successful. Right?\nConsider adding javadocs for the new code.. Isn't the method used above in \"public Object eval() {\" ?. Am I right that this code will be called multiple times until the job or flow starts and  slaExpireTime can be determined? \nIf so, how often is it called?\nWhen is the trigger removed?. Add a test for default port? . Add a similar test for Emailer?. Please remove the author information in the code. It's already in Git.. Change to 2017. Clarify that this is for testing default port?. Consider making it a separate test? \nAnd reduce duplicate code?. Remove author name.. This test is almost identical to the AbstractMailer test. Can you think of a way to consolidate?\n. What's the advantage of loading the properties from the resource file instead of your previous approach?. Your previous approach seems to be easier to read. The tests for Emailer and AbstractEmailer are very similar except the class.  Why do you use different styles for them? It would be great if you can consolidate them. But I am fine with some code duplication if the tests are still easy to read.. Why is this test ignored? If this test is not complete, I'd suggest removing it.. I saw that this test is no longer ignored. How does it work? Where is the email actually delivered?\nI think it is a fine idea to create a test to make end to end testing email sending feature easier. In that case it should be clearly documented how that test should be customized to fit the test environment and run.\n. Looks like this test will throw an exception of socket time out error as I expected. But since the exception is caught and only logged, the test continue to succeed.\nSo even if the port number logic is long, this test will still pass. \nI am not sure the added test run time is worth the benefit. \nIt would be great if you can add instruction/comment for the test to allow it to actually send a real email and disable this test so that it will only run manually. \nIf not, I'd suggest removing it.. How about clarifying further that this test is an integration test?\n. Do you mean\nplease make sure these variable{host,mailPort,password,receiveAddr} are set to real values that would allow an email to be sent successfully?. I would prefer that the test to fail when these varaibles are not set or set incorrectly. But I am ok with the current implementation for now.\nMaybe also mention that this test will currently succeed because email sending errors are caught. To verify email functionality is working, users need to manually verify that a real email is sent and received?. Could you add a comment that with this change, the project directory can't be stored in a different partition from the partition that the executions directory is in?\nIt is probably better to add it to the change description as well. . Great. Thanks for adding this test.\n. Yes, I also think createDeepHardLink makes more sense.. Also we may use a VIP name of the host. Another reason to get the host name from one place. . Did you rename this file and class name? It would be best in the future to rename the file first in a separate commit to make the diff easier to track.. This logic is specific to a particular naming convention. \nWhat do you think about adding a config to the config file and allowing an external system to set the hostname? Fall back to local host name detection as you do now.. Would it be more direct to say that these metrics are common between the web servers and executors?. _metrics sounds more to me like a list of metrics. How about _registry? . It's called dropwizard metrics now. \nDo you mean it is thread safe?. Consider adding a comment to explain what this meter measures?. Add a javadoc?\n. Do you mean web server module?\nHow about just mention that they need some classes defined in common module's tests? This way the comment stays valid even if you add other dependencies.. Have you considered timers? http://metrics.dropwizard.io/3.1.0/getting-started/#timers. Make it a common utility helper method in tests?. Consider consolidating these two tests using parameterized tests?. Consider using a utility method to share the implementation of the addMeter method? Do we need to add additional methods for other metrics in the future? If so, the code duplication will increase. . This config is exposed to the users. Shouldn't it be in azkaban.constants.ServerProperties and follow the naming convention there?. Add a new line?. Why '_'? Is it consistent with the naming convention?. Could you document the reason for not using timers here in a reply?. The name atomicLong is very close to the type name. How about simply value? It's clear to what type this parameter has.. Consider adding a comment to the code where the enum is defined that this sql script needs to be updated when the enum is changed. And there is no automated test due to the low return on investment. . Consider adding a comment similar to the pull request description so that readers know what this table is for.. Is there a concern with moving charset to utf8? I remember a user asked for UTF8 support to store international characters ( maybe in project names?). . Is this change needed?. Could you add a comment here that this section of the constants are legacy configs?\nThe new configs should follow the naming convention of azkaban.server. for server configs.. Depending on the report interval, the timer may provide more accurate measurement. e.g. if there are many events happen in one minute and the reporting interval is 1 minute, only the last one is reported. \nhttp://metrics.dropwizard.io/3.1.0/apidocs/com/codahale/metrics/Timer.html\nWe can try this measure for now and re-evaluate later.. \"the web server\"?. Consider making this a separate re-factor pull request? If it is too much trouble since you've made the change, could you at least add it to the change description?. Is this change still necessary?. @shuzhang1989 thanks for reviewing the change! Do you mean removing this empty line?\nThe empty line helps to separate the heading of this section from the rest. . Consider \nazkaban.server.<rest of the name>\nto make it more explicit.\nAdd '.' to end a sentence. . I meant the grammar in the comment.. It's hard to get the grammar right. How about just \"count: $try\"?. Remove unused code?. Will it fail the deployment? . The logics for the web server and executor are the same. \nCan you think of a way to consolidate the code? . The issue is more general than what's described in the issue. All metrics in the common class will subject to this issue. . Update the date to 2017. This is not the number of threads. It is the queue size. The metric name doesn't look right. . Grammar: in the future.. Is this comment still valid?. Does this method need to be synchronized?. I wonder if centralizing all the registration of metrics is a good idea. This class now has dependencies on many other components which makes testing a bit harder.\nYour new appoach of registering jetty related metrics inside the Jetty related code seems to get around this issue. . \"That said\", do you mean \"With this support,\"?. Shall we fail faster? If the process won't shut down within 10 seconds, I would expect a problem.   Is it better to fail the operation and let operator take some manual action sooner? At this point, the service is probably unavailable already. It's better to react fast. . Yes, kill -9 would be an option. However, on balance I would rather warn the operator if the process can't be shut down and allow the operator to take manual actions. Otherwise, the failure will go unnoticed and it won't be much better than just do kill -9 always.  . Would it be simpler to detect low memory situation in azkaban.execapp.JobRunner#run and retry after sleeping for some time? . Please add a copyright notice.. Please add a copyright notice to all new files.\nIs there a tool to check and auto update copyright notices?\n. Could you add a new line?. I like this refactoring. . The getSlaOptionList throws a serveletException already. \nCould you explain why you would like to use a different error handling strategy?. Is 10 min too long? What do you think about 1 minute? Unless there are many jobs in this state, I don't expect the CPU overhead to be too high.. Why this change? . If the check is turned off, it seems reasonable to log that the memory is always granted without an exception.\nIn any case, I would suggest keeping non essential changes and refactoring changes separate.. Isn't this an anti-pattern described by https://github.com/google/guava/wiki/Why-we-deprecated-Throwables.propagate\nShall we move away from using a deprecated method in general?\n. Why is it a warn or info?. Should the exception be logged?. Does it need to be a member variable? It is currently only used in one method.. Nice. This class is too big.. Does it makes sense to  compute the installDir when the ProjectVersion is instantiated? This way we can have one constructor and make the installdDir final. . Add a trailing newline?. Nice. Thanks for adding tests!. In the production code, it appears that the project directory was not passed to the constructor. Shall the test match the usage in the production code?. Why log.warn not log.info?. Please add a javadoc.. Got it. That's fine. . Got it. Warning seems to me like a situation that may not be normal or dangerous.  In this case, this is routine and normal. I don't have a strong opinion either way. We can adjust after we gain more experience working with the logs. . I am interested in your thoughts on the future plan. We can discuss in person.. Multiple refactoring is fine too.\nThanks. . deleteDirectory seems to have side effects. Would making it static makes mocking it later more difficult?. This is a destructive operation, warn seems to make sense to me. . Agreed.. Sounds good.. Ok.. Both styles have issues. Server should return 4xx error in this case. It's something we should fix in the future. I am interested in your thoughts on how to fix it. . How about azkaban.server.flow.max.running.mins so that we can group flow related server configs together?. This is a more expensive operation. \nIs this information always needed when getProjects() is called?. Add the project id to the log?. If the project already exists, a DB exception will be thrown now. Right? How is that new exception handled differently from the existing one?. With this change, the script will fail if the pid is NULL, right? . Did you put the source inside a function to prevent accidental execution of the code from the external file?. Thanks for contributing the first bash tests!\nIt will be great if the tests can be run automatically like java tests. \nBut this is a big improvement already. . I don't have a strong opinion either way. Since the name and the comment clearly indicate the unit is in minutes, I think it is a fine choice.. Nice!. Another PR sounds good to me too.. Interesting story. Thanks!\nRegarding the suggestion to use Duration, yes, I agree Duration seems to be a better choice. I saw below in another comment that Cheng agrees too.\nMy comment was referring to \n\" // Max flow running time in mins, server will kill flows running longer than this setting.\n +  // if not set or <= 0, then there's no restriction on running time.\n +  public static final String AZKABAN_MAX_FLOW_RUNNING_MINS = \"azkaban.server.max.flow.running.mins\";\n\"\nThis is a admin facing config name. I think having the unit in the name in minutes makes sense. Usage of Duration doesn't seem to apply in this context. . Also use xxx.minutes instead of xxx.mins to make it more explicit? . This is a backward incompatible change since the property name is part of the contract.\nI understand the unit makes it less convenient to config this value. Is it a big problem for you?\nYou are welcome to improve the code by switching to use Duration class for the internal implementation. . Add space between if and (.\nYou may want to consider letting IDE format the modified methods. . Is this change still needed until we have a better fix in place? This will only help with the race condition between scheduled flow and non-scheduled flow executions. \nThe other change would fix the bigger vulnerability. . This will ignore this file in all sub-folders. . In the future, I'd suggest keeping unrelated changes in separate pull requests. It will make the review easier and more focused. More importantly, it will make it easier for readers to understand the change history.\nFor this change, please describe in your change description this change as well.. This metrics is only exposed in executors. Should it be defined in azkaban.execapp.ExecMetrics instead?. Is it better to track the current number of jobs blocked waiting for memory? This will also give us the information about how long the jobs wait. . Is this comment necessary? The name of the method seems to be explanatory. . Why this change?. Looks like this is an existing query. How was it used?\nIs there a need to return inactive project?. I think it is a good practice to always initialize local variables.. How was this method used?. Why does it need to be synchronized?. Is this helpful? http://junit.org/junit4/javadoc/4.12/org/junit/rules/TemporaryFolder.html. Is this log necessary? . Can this method be reused? \nazkaban.project.JdbcProjectLoaderTest#assertProjectMemberEquals. Also have you consider overwriting the equals method of the Project class?. see azkaban.project.Project#equals\nWhat's the source member used for? It doesn't seem to be used.\nazkaban.project.Project#source. It wasn't clear to me at first where the assertions are.\nConsider keeping the util function just as a helper to create projects but not do assertions.. Remove some code duplications?. Since the method is simple\n  public synchronized Project removeProject(Project project, User deleter)\n      throws ProjectManagerException {\n    projectLoader.removeProject(project, deleter.getUserId());\n    projectLoader.postEvent(project, EventType.DELETED, deleter.getUserId(),\n        null);\n    return project;\n  }\nWould using mockito to verify the internal calls be a better test? This will cover for example the user parameter is passed correctly.. Do you plan to update the unit tests for JdbcProjectLoader too? It's ok to do that in a separate pull request.\n. Doesn't this code depend on the working directory to be set in certain way?\nsee http://stackoverflow.com/questions/28673651/how-to-get-the-path-of-src-test-resources-directory-in-junit for an alternative. You can find existing tests that use this technique.. What do you think of separating independent tests into separate files? . I am surprised. Not sure. What happens if you remove it and build again?. Consider using Duration class instead?. This is a gauge not a meter. Will OOM-waiting-job-count be a better name?. Similarly, would it be better to rename it \" incrementOOMJobWaitCount\"?. ditto. Alternatively, you can consider this method:\nhttp://stackoverflow.com/questions/2593154/get-a-resource-using-getresource. Yes, maybe after next release so that we can isolate potential problems with updates.. Got it. Make sense. Thanks. Understood.. Good to know that compiler/IDE will take care of this. Thanks. Is it going to be used as a key in the server config file?. Comment on what the props will contain?. Nice usage of @link. Is it better to make DB the default so that OSS users don't have to migrate?. Is in(Scopes.SINGLETON) necessary here since the provider has the singleton annotation already.. What do you think of always asking the class name in the config? It will simplify this code. It's the method used by other projects such as Hive, hadoop. . Add a class doc?. It will cause logical errors. Please see the change description.. I like the idea. It makes sense. \nThanks. It's fine either way with me. \nFrom the Guice doc: \nhttps://github.com/google/guice/wiki/Scopes\n\"If there's conflicting scopes on a type and in a bind() statement, the bind() statement's scope will be used. \"\n\"The annotation is preferred because it allows the module to be reused in different types of applications. \". I think it will make debugging easier if we log consistently the project id in this class. Maybe create a helper log method?\ne.g. \nlog consistently with: project () in the log line.. Would it be better to use a strong type for the metadata parameter and do the validation at the object creation time?. Add the project id in the exception message to make debugging easier? . It's a bit surprising to me that validation would have this side effect. Can you think of a better strategy?. Should there be a finally block to delete the testFile? Or use https://docs.oracle.com/javase/tutorial/essential/exceptions/tryResourceClose.html. What do you think about moving the testing of writability to a utility class and test it separately. It can be reused in other places. And the name of the method can be used as a documentation. . Why is it necessary to store the props?. What do you think of centralizing all the server configs into one config object in the future? That may make it easier to support hot reload of configs.. The name storageManager seems a bit general. It doesn't manage the entire persistent layer.\nMaybe use a more specific name? As long as we have the option to change the name, we can retain the flexibility.\nConsider adding a class doc?\n. Could you check if we can use javadb instead which is part of the JDK?. In this case, how about we stick with H2 DB?. Typo in connectionPool.\nalso do you mean \"reset\"?. This works.\nIt would be even better if each test stays focused and test only one thing if possible so that it is easier to read and debug.. What does local file represent?. Log project name consistently for easier debugging?. Consider keeping each test focused on one thing.\n. Is there a test for this method?. Sounds good.. Consider setting this only in the tests that need it. . This check and set optimization is not safe. See the effective java book.\nPlease use Guice instead.. I am not too concerned as long as there is an upper bound on the threads from AZ hosts that will call this method.. Will putting this statement inside the catch (SQLException ex) { block have the same effect?. What's the benefit of having this wrapper?. Is this map serialized and saved to the  DB? Could you elaborate how the backward compatibility is handled here and in the change description? . Nice clean up.\nWould it be better to keep the clean up code in a separate pull request?. This is great. It was very difficult to debug without the trigger id. Thanks!. Is it simpler to name it FlowExecutionMonitor?. Why not keeping this variable private?. Good point. Will investigate.. Changed. Thanks.. What's the advantage?\nShall we throw an exception if the setting is null here? \nIf so, I would suggest doing it in another pull request to keep refactoring and functional change separate.. Yes. Intellij can automatically reformat code.\n@chengren311 Do you still plan to set up a code format standard? . Where does the warning come from?. Thanks. In the future, please add your name to the todo comment. See our todo code convention. . Why is catching throwable here better than catching just RuntimeException?. Thanks for the comment. It makes review much easier.. Even when an Error is thrown?\nsee https://www.cis.upenn.edu/~bcpierce/courses/629/jdkdocs/api/java.lang.Error.html\nAn Error is a subclass of Throwable that indicates serious problems that a reasonable application should not try to catch. Most such errors are abnormal conditions. The ThreadDeath error, though a \"normal\" condition, is also a subclass of Error because most applications should not try to catch it.. I found the suggested name harder to read.\nI am fine with the change if it is part of the naming convention. Could you point me to the naming convention doc that mandates this?. No. It is never designed to work on Mac. The check will be disabled when the file doesn't exist.. Will fix.. The IDE doesn't do it for me automatically. \nI didn't find the manual effort worth it.  I can change if you insist or suggest a way for tools to do it for me.. Yes, same here. I did some research on the same.\nTurns out that there is no platform independent way to do so.. Why global change if we can do it incrementally?. Will fix.. Found this http://stackoverflow.com/questions/16761227/how-to-make-intellij-idea-insert-a-new-line-at-every-end-of-file. Will add a comment.. Added.. Changed to an array.. The column editing mode works. Thanks!. We already have both in place. I think it will be good to require new code to use slf4j. What do you think?. Please mention this functional change in the description.. Are they no longer needed? \nThis change is not mentioned in the change description. This may make it harder to trace problems later. . FYI I remember Gauva has a convenient class to load resources. . Nice usage of assertions.. Is this necessary?. Why not use in memory h2 db for testing?. Why do you need to care about what the entry is in the props? The test is in full control of what's in the props. Right?. Is it necessary? I added it to the common module.. This looks familiar. \nDiscussed off line. It's fine to consolidate later. Maybe add a todo?. Consider using an in memory version. . Thanks. Isn't @AfterClass designed for that purpose?. Yes, we should invest in making that easier since we are likely going to write more unit tests against DB.. I can't find the todo tag. Could you point me to it?. May want to add a comment to explain this is safe.\ne.g.\nin org.apache.commons.dbcp2.BasicDataSource#createDataSource\n        // Return the pool if we have already created it\n        // This is double-checked locking. This is safe since dataSource is\n        // volatile and the code is targeted at Java 5 onwards.\n        if (dataSource != null) {\n            return dataSource;\n        }\nPlease see \"effective java\" book for details.. Please follow the todo naming convention.. Is it necessary? Maybe just pointing to the intellij help page?. See http://stackoverflow.com/questions/1371940/unit-testing-is-it-a-good-practice-to-have-assertions-in-setup-methods. Why does the thread need to sleep here? \nIt's important to keep a unit test run as fast as possible. in a few ms is the norm.. My understanding is that isTestSetup will return false in Travis effectively disabling this test. Am I right?\n. Have you considered setting up an in-memory DB state and just test the fetch method? \n@kunkun-tang has introduced some tests using in-memory DB.. Got it. I was confused by the diff display.. +1. We would like unit tests to run as fast as possible.\nIt seems that in this test you can control the flow end time. If you set an end time e.g. 20 minutes in the past, the test doesn't need to sleep, does it?\nAlso I don't see a positive test case, i.e. there is a flow that finishes within 10 minutes. . It's not obvious what the lifeTimeMs means. Add a javadoc?\nDoes the name like \"maxAge\" more closely reflect the intent?\nHow about using the Duration instead here and convert to long when needed? At this level of abstraction, users of this API shouldn't care how this value is represented in the DB.\n. This will call\nvoid error(Object message) {\nwhich will not log the exception details such as call stack.\nAlways use this method to log an exception. \nvoid error(Object message, Throwable t) {. Should the server return a server error (5xx) instead?. What do you think about limiting the returned result to the most recent N flows instead regardless of how long ago they finish?. Is this log statement right? I don't see metrics manager being instantiated here.. Does this statement need to be in the finally block? Can it be put in the catch block?. Is it better to re-throw the sql exception when it gives up?\nWhat's the effect of returning null?. Why 5?\nIs it better to retry for a long time? What's the downside?. Consider adding a comment explaining that autocommit will be reset for the next connection. And refer to the unit test for that behavior.. Do you mean \"when to commit\"?. This operation seems to contain only one update. Can it use the simpler update azkaban.db.DatabaseOperator#update method?. This test doesn't seem to verify that the change is actually committed which is a key part of this method.\nCan you improve it?. The loggedInUser is not volatile and the method is not synchronized, the check is not guaranteed to work.. Consider wrapping it in a setter method? Annotate the method with @visablefortesting and add a comment?. I wonder if with the recent introduction of Guice. There is a better way to construct different dependencies in tests so that we can avoid introducing this new test only constructor.\n@suvodeep-pyne . Log to a logger instead?. With this change, does the code in run method azkaban.execapp.JobRunner#run still apply?\nif (isKilled()) {\n  // even if it's killed, there is a chance that the job failed is marked as\n  // failure,\n  // So we set it to KILLED to make sure we know that we forced kill it\n  // rather than\n  // it being a legitimate failure.\n  finalStatus = changeStatus(Status.KILLED);\n}\n\n. Thanks for improving this slow test.\nAny suggestion on how to make the tests run faster so that we can run them on every commit?. Why does it need to use @Named? \nDoes plain bind work too?\nI'd prefer minimizing the usage of Guice's advanced features to reduce the learning curve needed and make the code easier to understand.. Just like how AzkabanExecutorServer is constructed, can't the Server instance be constructed in the same way without using a Guice provider? \nI'd prefer keeping the module file as simple as possible.. Why does the exeServer need direct access to root Context now?. Is a FakeApp class needed? Can test use a Mockito mock instance instead?. Can test use a Mockito mock instance instead?. How does FlowRunner depend on AzkabanExecutorServer? In the future, we should refactor FlowRunner so that lower layer components shouldn't depend on higher level components. . Yes. . Please clean up the imports. There are some unused imports.. The refactoring of ExecSever class is useful.\nIs it possible to use a mock class instead in these tests so that we can separate that refactoring change into a separate pull request and finish this one first?. Exec server and tests can use different Guice modules if needed.. You can use azkaban.webapp.AzkabanWebServer#AzkabanWebServer(org.mortbay.jetty.Server, azkaban.utils.Props) as an example.. No problem. I have to manually tell IDEA to organize the imports.. Thanks for the detailed description. However, I am still having trouble understanding this problem and fix. \nThe new instance of the exFlow is just a clone of the existing one, isn't it?. In this test, would a Mockto based Mock ExecutorLoader which does nothing work and with less complications?. Is this an indication of a real production bug? \n@chengren311 . \"the current flow status, which is not synchronized with the job runner threads\"\nWhy isn't it synchronized? . Why making a copy here is not obvious without reading this change history. Could you add a comment? . Why is this change necessary?. Could you add a comment that this check is for the unit test only?. Thank you for making them constant and moving them to the central location.. Which code path did you refer to?\nHow is it going to help readers understand why cloning here is needed? . I see.. It would be great if you can add comments in both places.\nMy understanding is that the class is simulating a DB layer which should be a copy of the original. Thus cloning is the right choice. Am I right?. LGTM after you add the comment. . Why is this index needed?. Returning a server error will help with the monitoring system for example.. I don't see the change yet. Did you submit it?. Is this comment still necessary? The code seems to be clear enough. . I would suggest adding a todo here to fix the error handling.. Another strategy to consider is to break up a larger pull request into multiple smaller ones.  Create an issue to tie them together and help explain the bigger picture of the changes. This can speed up the review process. In case there is a need to rollback, you have an option to roll back a portion of the changes.\ne.g. adding a new method like this can go in first independently. Since it is not used yet, it is safe.. Is it necessary to modify the current time? Isn't create a new time enough?\nWe should use the java8 java.time api instead of jodatime in the new code. \nhttps://stackoverflow.com/questions/29750221/is-joda-time-deprecated-with-java-8-date-and-time-api-java-time. Any idea why this is happening? Can you think of a better way? . It seems that this error happened consistently. It would be good to find out if this is an indication of a real issue. . As long as the tests are stable and you are working on improving it, I will be happy to accept this pull request after the conflicts are resolved.. Done. Thanks. The method name change is fine.\nWhat's the advantage for turning the eventCollector from a local variable into a member variable?\nThe existing style seems to be more explicit to me since I don't have to navigate to the base class to understand the logic and since this method is protected, I will need to pay attention to see if it is overwritten.. Thanks for catching this issue. \nI don't see the instruction for setting up copyright notice in the README. Did I miss it?\nI found this instruction\nhttps://www.jetbrains.com/help/idea/2017.1/generating-and-updating-copyright-notice.html\nAnd used it to update the copyright.\nHere is the profile I used:\nCopyright 2017 LinkedIn Corp.\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not\nuse this file except in compliance with the License. You may obtain a copy of\nthe License at\nhttp://www.apache.org/licenses/LICENSE-2.0\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\nWARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\nLicense for the specific language governing permissions and limitations under\nthe License.\nWould you like to update the instruction and even better do a batch update? I wonder if there is a way to auto update copyright notice when saving files.. \nNavigation is not a big issue although I would prefer minimizing the redirection when possible. e.g.   protected void assertEvents(final Type... types) {\n    eventCollector.assertEvents(types);\n  }\nis one of such redirection. Now I have to remember where the eventCollector member comes from and where it is modified. I am looking at the base class. But the member is modified in the subclasses.\nThe bigger issue is to reduce the mental overhead of figuring out the states.  I prefer limiting the scope of a variable as much as possible. e.g. What's the advantage for turning the eventCollector from a local variable into a member variable? as I asked earlier.\n I would prefer composition over inheritance. e.g. it looks like the FlowRunnerTestBase can be turned into a utility class with static methods and pass in the runner object when needed to the methods that need it. \nSee my pull request #1151 for an example. the new prepareProject method is relatively simple to understand in terms of what are the inputs and outputs. \nReference:\nhttps://stackoverflow.com/questions/11343840/favor-composition-over-inheritance\nAnd the \"Effective Java\" book item 14: favor-composition-over-inheritance\nIf you can break up this pull request into simpler multiple ones, we can merge the first commit while we discuss the rest. This is another advantage of smaller and independent pull requests i.e. we can treat different parts differently.. Why making it public?\nI wonder why this is static too.. Yes, I have the same question. If in doubt, I am in favor of failing early. At least we understand the behavior better.\nThat said, I would suggest that we make small incremental changes. e.g. fix this issue first and then do further improvements. . Maybe. But I would defer it to another PR. I would prefer small incremental improvements.. Agreed. Or even better to a logger.\nAgain, I would like to defer these changes.\nDoes the rest of the change look good to you?. Yes, we can agree to disagree. I am hoping to learn from this discussion and your perspective too. It doesn't mean that we have to agree on everything.\nWith the help of IDEs, I find it easier nowadays to optimize for reading than writing. \nThe code duplication you referenced is much less than before. Yes, I'd like to further simplify the code. \n\"this.flowMap = FlowRunnerTestUtil\n    .prepareProject(this.project, dir, this.logger, this.workingDir);\n\"\nAgain, I would prefer an incremental approach, especially when dealing with legacy code which I don't understand well enough.  I would welcome any suggestion on how to simplify this logic further. \nRegarding the overhead, I tried the approach myself see \n1147 with the help of intellij and your quick review, it didn't take much longer to make two PRs than one.\nI understand the overhead. Again I'd like to optimize for reading than writing. After all, we read the code more often than modifying it. \nThanks again for your help and understanding!. \n\"I guess my thinking there is that you already know for example that assertEvents will check against the \"current eventCollector\" or that assertStatus will check against the \"current flow\" withouth having to every time echo the reference to event collector or flow runner.\"\nI see.\nBut the contract wasn't clear to me when I read it and I think I will have the same reaction the next time I read this code.\nMy personal experience is that my mental overhead goes up when I see code that relies on inheritance typically. . np. I didn't catch this in earlier reviews.\nDo you mind improving it later? . Would synchronization be needed?\nNote that in the future we may want to run tests in parallel.. How did this change help?. So only one thread will call this method at any given time?\nCan it ever happen that one thread starts to remove testJobs while another assumes that testJobs are there?. Thanks. Do you mean the single executor mode will be broken after this change?. Have you considered adding the status here instead of having the caller passing in a value? \nI think it will be easier to read and less likely for callers to pass in the wrong value. There is no need for different callers to pass in a different value. Right?. Similar comment as the other SQL query above.. Similar comment as the other SQL query above.\n. When a flow .... in the queued state.. Is there a possibility to remove update time in a separate commit?. I have the same question.. But not all 13 apply to flow status. Right?\nNot listing them explicitly may expose us to problems when an incorrect status somehow shows up.\nHaving it listed here also serves as documentation. Maybe have a central place to return such subsets?. Thanks. This looks much better.\nIs http://joel-costigliola.github.io/assertj/core/api/org/assertj/core/api/AbstractCharSequenceAssert.html#isEqualToNormalizingWhitespace(java.lang.CharSequence) more appropriate?. Got it. It's unfortunate. Does it sound like a possible enhancement request for assertj?. According to the implementation:\nprivate boolean areEqualNormalizingWhitespace(CharSequence actual, CharSequence expected) {\n    if (actual == null) return expected == null;\n    checkCharSequenceIsNotNull(expected);\n    return normalizeWhitespace(actual).equals(normalizeWhitespace(expected));\n  }\nIt seems like this method should work. Have you tried it?. Thanks for reporting the documenting this issue. \nAny suggestion on how to fix it?\nI hope to use h2 DB more for unit testing.. And I am not sure why the status can't be just 1, 2, 3 etc. I tried it. Here is the difference.\n<h2 style=\"color:#FF0000\"> Execution '-1' of flow 'mail-creator-test' of project 'test-project' has encountered a failure on unit-tests</h2>This flow is set to complete all currently running jobs before stopping. <table> <tr> <td>Start Time</td> <td>2016/07/17 11:54:11 EEST</td> </tr> <tr> <td>End Time</td> <td>N/A</td> </tr> <tr> <td>Duration</td> <td>10 sec</td> </tr> <tr> <td>Status</td> <td>FAILED_FINISHING</td> </tr> </table><a href=\"http://localhost:8081/executor?execid=-1\">mail-creator-test Execution Link</a><h3> Reason</h3> <ul> <li><a href=\"http://localhost:8081/executor?execid=-1&job=test-job\">Failed job 'test-job' Link</a> </li> </ul>\n<h2 style=\"color:#FF0000\"> Execution '-1' of flow 'mail-creator-test' of project 'test-project' has encountered a failure on unit-tests</h2>This flow is set to complete all currently running jobs before stopping.<table><tr><td>Start Time</td><td>2016/07/17 11:54:11 EEST</td></tr><tr><td>End Time</td><td>N/A</td></tr><tr><td>Duration</td><td>10 sec</td></tr><tr><td>Status</td><td>FAILED_FINISHING</td></tr></table><a href=\"http://localhost:8081/executor?execid=-1\">mail-creator-test Execution Link</a><h3>Reason</h3><ul><li><a href=\"http://localhost:8081/executor?execid=-1&job=test-job\">Failed job 'test-job' Link</a></li></ul>\nThe actual output doesn't separate some elements with white spaces. It's not ideal and makes the test less strict.\nHowever, I am willing to defer an improvement for now given other priorities. \nThanks. Yes, that's what I thought too. I was hoping someone smarter than me can come up with a better solution. :). This class is indirectly created by Guice already. Right? \nAnd it doesn't require Guice's assistance to create an instance. So I think what you have is fine. . Consider saving this reference in the constructor? This class can be considered a dependency of this class. . Why not take MetricRegistry directly as a dependency and have Guice create it?. Declare MetricRegistry as a dependency and have Guice create it for you? . Did you apply saveaction?. Here is an alternative:\nCommonMetrics constructor takes an instance of MetricRegistry. In the production code, it is constructed using Guice.\nIn test code, simply new the instances you need without using Guice. . I see. Why do they need to be in BeforeClass?. Typically it is better to have tests to be independent of each other as possible i.e. create their own instances when needed.. What is this used for?. Not in this PR, but in the future, we should get datasource from Juice. \n@kunkun-tang . Shouldn't this use this.commonMetrics too?. +1. Why not depend on MetircsRegistry directly?. Will a mock work here? Same for other tests.. Why not just get the MetricsRegistry directly?. Have you tried binding MetricsRegistry class to a singleton in a GuiceModule?. I see. I would suggest listing all the direct dependencies directly to make the dependencies more explicit. . Why not \n    bind(MetricRegistry.class).in(Scopes.SINGLETON);\nit also seems to work.. Is this right? \nNot com.google.inject.Inject;?. Why is this change necessary?. Is this Todo necessary?. Shouldn't get it from Serivce_provider too?. Could you find out what the problem is and then remove this comment?. If this logic is need, please find a way to reduce the code duplication.\nsee azkaban.test.Utils#initServiceProvider. @kunkun-tang could you explain?. In general, try to make small incremental changes. When a change becomes bigger, it is more likely to miss issues. It takes longer to finish reviews too. And you risk having to deal with change conflicts more often.. Sounds good. Thanks for thinking about how to prevent regressions.\n. IMHO, I prefer annotating the class itself with singleton if the class is designed to be used as singleton everywhere. It's less code and the information is centralized. Otherwise, readers have to check the module files too to find this information.. Yes if it is not a lot of work.\nCan you reuse the code I referenced?  see azkaban.test.Utils#initServiceProvider\n  . I think this is a different change. I don't expect resolving conflict will be too hard.. Yes, I am in favor of phased approach.\nIn this case, I replaced your Guice initiailization code with \nimport static azkaban.test.Utils.initServiceProvider;\ninitServiceProvider();\nAnd the tests in this file passed. Since CommonMetrics is annotated as singleton already, I think you don't need this line here. same with MetricsManager. . Why not directly get the MetricsRegistry instance? . Why is this change necessary?. Same as the previous comment. . Yes,         hadoopAnnotations   : \"org.apache.hadoop:hadoop-annotations:${versions.hadoop}\",\nalso works.\nWhy do you think the $ version is better?\nThe + version requires less typing. And IMHO it is as readable. \nI don't have a strong opinion though. \nIf you feel strongly about it, how about you create a PR after this is merged? . This is an example of why Guice is helpful. Otherwise, we may have more similar code in the production code. . So far there is no need to create separate sql DDLs for h2 yet. \nI think it is simpler to change the schema for both DBs.. Why?. When would rollback not be desirable?. This is gradle. And gradle has its own syntax.. Good point. I missed it. Will do. . 1. gradle will reduce the number based on the max-worker config. On my mac, the actual number is 4.\n\nI suspect not all tests are run concurrently. Even they do, the overall time is dictated by the slowest test. Good question. I am not sure exactly though. The improvement is observable consistently though.\n\nDo you have any objection to this change?. It's autogenerated. And it documents when the file was generated.\nI don't think we should manually edit this file.. Ok, if you don't feel comfortable with this change. I will close it.\nThanks. Why is it necessary to exclude these modules?. Why is this change necessary?\nHave you considered adding a dependency to the testCompile config directly?. Nice. Thanks for remembering to add the notice. I configured Idea to add it automatically. Did you do the same?. The convention is to use \"logger\". \nLOG should be marked as violating the google style guide.. Did you set up the checkstyle check? We should standardize the setup.. Should log the stack too?. shouldn't it be , e to include the inner exception?. If the exception is caught here, why not catch the HiveException here?. Is this code new or is it moved from somewhere else?. Is this an independent code clean up change?. Shouldn't it come before hiveMetastore?. Why is this approach better? . Consider using assertJ. \nIt would be good that new code standardizes on assertJ.. I saw you had a cleanup call in the beginning of the test already. Is it the idea to be able to inspect the state after the test fails and still be able to run the next test run with a clean state?. I am not familiar with this hive code. Is there a common utility function or an overload that will do this?  It doesn't look like it is specific to our use case. . Why having three overloaded constructors when we only use one?. This is odd. Did you check with Hive team?. Consider adding a comment in the code if this change needs to stay.. Don't you have the same problem if someone adds to compile a dependency this test module needs?\nIMHO, it is better to stay with the default/convention to avoid surprises as much as possible.\nIf someone forgets to add a dependency, tests will fail. Right? Why isn't it good enough? . I'd suggest you keep them separate in the future. It makes review harder. If you want a quicker review, keep the change as small and focused as possible.. I saw the link to Gobblin. But I didn't click through.\n. It's not clear that Gobblin has to make these build changes. Should you have @erwa review this change?. Do you have a reference to this behavior ( a test program, article etc?)\nIf this is the issue, how does \"  throw new MetaException(\"Failed to get storage handler: \" + e);\" work then?. I don't follow why this code is needed and what it is doing. \nConsider adding comments.. How does the test verify the retry behavior?. Either log or logger sounds good to me. The main problem is that it should be lower case. You can read the Google style doc. \nNo, we haven't setup the proper style check instruction yet. Are you interested in helping?. How does Gobblin enforce code styles? . Is the question clear?. ?. Thanks for making the update. It will make the job of the reviewers easier if you leave a comment suggesting that the change is made. Otherwise, the reviewers may have a hard time remembering which ones have been addressed.. Please follow up. Simpler code is better code. \nAnd we need to understand what the code does.. I saw the change now. This is an example of why I found it hard to track which comment has been addressed. I wish Github has a feature like the Review Board has that can make it easier. Do you know such a feature in Github?. This looks like a formatting change.  Is it intentional? I though the earlier code was formatted properly by the save action.. This just indicates that this method will throw this checked exception. Will it work if we change it to throws HiveExecption? . @erwa could you comment?. \"This one, for example, has been lurking around for a long time and I haven't touched it because I wanted to make a refactor PR that never happened.\" How can I help so that you can make it happen more often in the future? :) Any suggestion?. I would take into consideration of the reviewers and more importantly the productivities of the future readers of this code and change history. . Modifying the sourceSets is not an issue and is expected. \nI thought extendsFrom would replace the existing superConfigs. After some experiments, I realized that it adds to the existing configs. \nThis change is fine. \nAlso since the build only packages the jar and not the run time dependencies, does it need to use compileOnly in the first place? What's your long term plan? . Is this addition necessary? If lockdown.upload.projects is set to true, what if we only allow admins to upload. Is the intention to limit the uploader's permission?\nHow do you plan to grant users this permission?. This logic is duplicated in multiple places. Can you think of ways to improve?. Is it worth logging this event?. Is there a test for this method?. We are standardizing on assertj. Can you give it a try?. Nice formatting. Did you use the saveaction plugins?. Sounds good.\nSorry, I meant configurations, not sourceSet.. Does it make sense that admins can't upload when lockdown.upload.projects is set to true? Why?\n\nHow are users granted UPLOADPROJECTS permissions?. This project follows a different style. Please take a look at the project readme.. The name seems to suggest that it will return a true or false as a check.\nCan you come up a better name? e.g. hideUplodButtonWhenNeeded?\nIt doesn't look like there is test that covers this method.. Is package private good enough?\nIDE should give you suggestions.\nOr do you intend to make it reusable in other packages as well? In that case, should it be moved to another package?. We have Guice support now. Consider using Guice to manage the dependency on userManager. \nIt's a more involved change. It's fine to do it in a separate pull request.. This comment is helpful. Thanks. Is this log statement correct? . Why isn't this variable prefixed with this.? \nIs it intentional to keep the file as close as the original in this step?\n. Do you plan to apply the saveaction plugin once you are done with the change?. When will the azkabanProjectLoader be non-null so that the delete will happen?. Is it better to control the temp dir explicitly in the test? . Could you add javadoc?. What's the purpose of this test? . It looks like when the existing lockdown.upload.projects config is set, no one can upload projects even for AZ admin. \nHowever lockdown.create.projects config behaves differently, it allows AZ admins or users with the create project permission to create projects.\nif (this.lockdownCreateProjects &&\n    !UserUtils.hasPermissionforAction(this.userManager, user, Type.CREATEPROJECTS)) {\n\nIt seems to me this model makes more sense. The uploadproject permission only applies when lockdown is set. \nIf you choose this model, it may help to add a comment to this permission to explain this relationship.\nThoughts?. See the earlier comment about the relationship between the lockdown config and the permissions.. Consider org.assertj.core.api.AbstractBooleanAssert#isFalse method?. Adding this permission makes sense only if we are willing to do the work to take advantage of the finer grained control. \nDo you plan to change dr elephant user from admin role to upload and create project roles? . It doesn't appear that this method has test coverage. \nI realize that there is not much REST API level automated tests currently. We will need to invest in this area.\nFor this change however, given the lack of test infrastructure, examples and potential regression risks, I will leave it to you to decide if you would like to add tests for it. \n. I see. It wasn't obvious to me. Consider adding a comment.. Is 403 response code more appropriate?\nhttps://stackoverflow.com/questions/3297048/403-forbidden-vs-401-unauthorized-http-responses\n. Nice message.. Should the thread be started after the gauges are registered?. Have you tested that this change works with embedded flows?. requireNonNull seems odd. Why not assert the instance is not null using junit assert or assertj?. I agree with @suvodeep-pyne.. Aren't these metrics web server only? If so, should they be in azkaban.webapp.WebMetrics?. I see. Thanks. +1.\nTo make it useful to test other Guice modules, consider taking an Injector as a parameter.\n. Change requireNonNull to another assertion?. Is http://joel-costigliola.github.io/assertj/core/api/org/assertj/core/api/AbstractAssert.html#isSameAs(java.lang.Object) better?. Why not assert that azkabanObj1 and azkabanObj2 is not null instead?. Shouldn't it be http://joel-costigliola.github.io/assertj/core/api/org/assertj/core/api/AbstractAssert.html#isSameAs(java.lang.Object) \nisSameAs?. I don't see this comment addressed in the latest code. . This is not sticky bit, is it? This is setgid. Right?\nsee\nhttps://docs.oracle.com/cd/E19683-01/806-4078/secfiles-69/index.html\n\"When setgid permission is applied to a directory, files that were created in this directory belong to the group to which the directory belongs, not the group to which the creating process belongs. Any user who has write and execute permissions in the directory can create a file there. However, the file belongs to the group that owns the directory, not to the user's group ownership.\n\"\n. According to this doc\nhttps://dev.mysql.com/doc/refman/5.7/en/integer-types.html\nhttps://stackoverflow.com/questions/12812362/mysql-tinyint-as-unsigned\nThe signed tynyint type has the same range. \nThis is confirmed by @jamiesjc's tests which use mysql.\n@juhoautio how did you reach the conclusion that mysql was different?. Is the catch necessary? What if we allow the exception to bubble up?. Got it. Thanks. The service account name may not be azkaban. Consider using a more generic term.. Linux?. Is there a way to centralize these metrics reporting? Inside sendEmail?. Add that this logic doesn't work on windows and it works on Linux and MacOS?. Why is it better?. Doesn't shutdownnow call shutdown which will call the delete function?. My mistake, I mis-interpreted the call to the shotdown method for the triggerManager as the call for the FlowRunnerManager.. Is the shutdown hook invoked in the orderly shutdown process? How did you test it?\nThe deletion could be made internal to the flowRunnerManager in the previous commits. Why does it need to be made public? . Please update the comment to match.. Where is it used?. It's good to remind ourselves possible improvements.\nI would suggest keeping the refactoring PR focused especially for code that doesn't have sufficient unit test coverage.. Why not use attemptNo instead of another call to getAttempt?\nEven better, consider using a private method to calculate this string. This logic is in two places. . It would be good in the future to get this object from Guice to make unit test easier.. Should this throw an exception instead? Won't the job fail later which may be harder to debug? . Wouldn't it be cleaner to create the directory with the proper permission in the first place? I understand you tried and had issues. It would be good to document what the issue is and fix it if possible. . If you plan to address it soon, documenting it here is easier. Otherwise, I will leave it to you. Just consider how others can find and use this information to make documenting it worthwhile.. When will the job status remain \"unfinished\" when it gets here? And if killed is true, who will update the final status?. I see. \nIf job.run throws an exception, the finalStatus variable will be set to Killed. So the !this.killed will not be evaluated.\nIf there is no exception when will the killed be true? And what's the expected state transition for this job?\n. If this line is hit\nhttps://github.com/HappyRay/azkaban/blob/0d59dd63f0d694ffd9ef16368fd3b2e9230946e8/azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java#L745\nThe finalStatus variable is set, so Status.isStatusFinished(finalStatus) will return true.\nYour change will only have an effect when this.job.run(); doesn't throw an exception. Right? \n\nif (!Status.isStatusFinished(finalStatus) && !this.killed) {\n\nWhat scenario is this modification designed to handle?. The rest of the code uses isKilled(). Any reason to use this.killed directly here?. I think I understand this logic now. \nThis code is to set the final status to success when there is no exception. It is possible that the kill thread is executed between this line and a successful return of the job.run() call. This check is to prevent the status to be set to success in this scenario. . Please make it more explicit that the service won't start. . Is 1 a better default? \n . What happens when the web server crashes after this step?. When we get this exception, how do we recover?. And how do we plan to detect this error?. Please use javax.inject package.. see #1333 . This method looks the same as https://github.com/HappyRay/azkaban/blob/96ad15a98af88adb1c17b7486802ed016bd109f1/azkaban-exec-server/src/test/java/azkaban/execapp/FlowRunnerTestBase.java#L120\nIt would be great to consolidate them. . According to the Google style guide, the name should be ExecutionFlowDbManager.\nsee\nhttps://google.github.io/styleguide/javaguide.html#s5.3-camel-case\nNote \"DB\" should be \"Db\"\n@azkaban/team-azkaban FYI. Yes, that will be great. . Could you use this method to replace the same logic in \nhttps://github.com/HappyRay/azkaban/blob/96ad15a98af88adb1c17b7486802ed016bd109f1/azkaban-exec-server/src/test/java/azkaban/execapp/FlowRunnerTestBase.java#L120\nIt can be done in a separate PR.. The original test has 2 seconds sleep. However one second delay in test is still not ideal. It would be great if you can think of ways to make it better.. Oh, I read it wrong. Sorry.. Yes, I recognize the improvement. Thanks.\nI don't know a \"standard\" way. \nThe polling method you suggested sounds reasonable if it can result in further reduction in test running time. . Shouldn't it be testCompile?. Shouldn't it be testCompile?\n. Would adding an Assert.fail(); statement at the end of the try block as the examples in \nhttp://errorprone.info/bugpattern/MissingFail work better?\njava\n public void expectedException_withFail() {\n    try {\n      dummyMethod();\n      Assert.fail();\n    } catch (Exception expected) {\n    }\n  }. Is it better to use junit's temp directory rule?\nhttps://garygregory.wordpress.com/2010/01/20/junit-tip-use-rules-to-manage-temporary-files-and-folders/. Please use azkaban.test.executions.ExecutionsTestUtil#getFlowDir instead\nSee an example at https://github.com/HappyRay/azkaban/blob/1cbe49cce50ffde71784e73c2f03097e83e86780/azkaban-common/src/test/java/azkaban/executor/JdbcExecutorLoaderTest.java#L973. Please use a wrapper method.\nSee an example \nhttps://github.com/HappyRay/azkaban/blob/1cbe49cce50ffde71784e73c2f03097e83e86780/azkaban-common/src/test/java/azkaban/executor/JdbcExecutorLoaderTest.java#L973. Is it better to modified it to\nconfigurations {\n    testOutput.extendsFrom (testCompile)\n}\nas the article suggested?. I think testJar task is still needed. \nThis change will give it more flexibility. . I am fine with keeping 0 as the default.. Will it cause inconsistency between DB and storage?. So there is no harm in leaving the older version entries in the DB even when older storage files are deleted, right?. Why this change? @chengren311 refactored this code earlier.. ditto. Please log the exception in the logger.. Does it mean that any version of error_prone_core newer than 2.0.15 will also work?. I specified the errorprone version recently too. Your way of specifying the dependency seems to be simpler.  How did you verify the specified version was used?. Does this change require any additional change to the IDE to support lombok?. I assume we need to use the Linkedin internal Kafka when used inside linkedin.\nHow would that work?. Please define all configuration parameters in the azkaban.Constants class. This makes it easier to identify all the configuration keys.. Why isn't it prefixed with event.reporting like other configs?. Why isn't it prefixed with event.reporting like other configs?. Is the instance designed to be a singleton? If so annotate with @Singleton?\nhttps://github.com/google/guice/wiki/Scopes. How about providing a default \"AzkabanKafkaAvroEventReporter\" here so that you don't have to have a special case?. This FlowRunner class is getting too big. It would be great to define this class in a separate file. It will make it easier to test this class too. . Consider getting the listener instance from Guice. It would be great to refactor FlowRunner to use Guice. For now getting the dependency from azkaban.ServiceProvider is fine.. Same for JobRunnerEventListener. Refactoring can be done in multiple PRs.. Use constant azkaban.Constants.ConfigurationKeys#AZKABAN_SERVER_HOST_NAME. Do you mean azakbanHost? \nI thought it is defined in the config. You should be able to access it anywhere via Guice. . The keys in the metaData become part of the contract. Shall they be defined in an interface?. Have you considered adding the reporter to the flowRunner instance here instead?\nAnd check if it is null. If it is, don't add it so that the report call won't be called and extra information won't be logged.. Should the content of metadata be defined? Or is it the intention that the metadata should be treated as a black box by the reporter?. Event class is an implementation detail and it includes methods you don't need for this interface. Consider defining an event interface for this purpose?\nWe have an spi ( service provider interface ) module. e.g. azkaban.spi.Storage\nShould this API go into that module? Clients can depend on this module to get the API definitions. . Move to azkaban.Constants. Similar for other config keys.. Also, we start to prefix the keys with Azkaban to make it clear that these keys are defined by Azkaban instead of defined by plugin code. . Is catching Exception enough? . Why are these additions necessary?. What happens if the reporter is Null here?. If you follow the developer setup instruction in the README, import the google style xml and use the latest Intellj, it appears that it will import individual classes. Could you give it a try?. I am not sure why the node status will be failed if it is being retried.\nazkaban.execapp.FlowRunner#retryJobIfPossible should have set the status to READY again. . Based on the example you gave in the issue #862, here is my interpretation of what may have happened, please correct me if I am wrong.\nJobB finished successfully first, it is added to the finishedNodes.  azkaban.execapp.FlowRunner#progressGraph adds JobC to the nodesToCheck list. azkaban.execapp.FlowRunner#runReadyJob calls azkaban.execapp.FlowRunner#getImpliedStatus, at this time, jobA fails it sets its status to failed in azkaban.execapp.JobRunner#runJob. But it has yet to have a chance to be added to the finishedNodes list so that retryJobIfPossible has not been called to reset the status. JobC is canceld because it sees that jobA has failed. . Not able to upgrade is still an issue.\nAccording to https://github.com/rzwitserloot/lombok/issues/1332 this issue is fixed. Could you give it a try?\nAlso after you merge in the latest change, please use one way to specify the error-prone version.. Could you double check with the Kafka and Gobblin team? The open source version may work. But I thought the internal version has to be used. It's good to be prepared even if we can use the open source version for now.. The convention is to prefix all azkaban config keys with azkaban.\nReporting can be interpreted as a noun too such as financial reporting, right?\nSomething like\nazkaban.event.reporting....?. This refactoring is tricky. May have to introduce additional classes to hold state and the stateless part of the class can be injected via Guice.. AzkabanExecutorServer.getApp() is deprecated. Don't use in the new code.\nTry azkaban.ServiceProvider instead for now to get this information.  e.g. define a singleton class to provide some configuration information if needed.. Please define how the metadata is supposed to be used. \nThe schema of the metadata is still part of the contract between the producer (azkaban) and the consumers of this information. Right? If so, where is this contract defined?. I meant \" not to add the flowListener if the event reporter is null\". Does it make sense?. What are the additional dependencies?. I see. See the earlier comment on not adding the reporter to the listener list if it is null.. It appears that this change brought in a large number of dependencies.\n./gradlew :azkaban-exec-server:dependencies\n+--- com.linkedin.gobblin:gobblin-kafka-08:0.11.0\n|    +--- com.linkedin.gobblin:gobblin-api:0.11.0\n|    |    +--- org.slf4j:jcl-over-slf4j:1.7.21\n|    |    |    \\--- org.slf4j:slf4j-api:1.7.21\n|    |    +--- commons-io:commons-io:2.5\n|    |    +--- io.reactivex.rxjava2:rxjava:2.1.0\n|    |    |    \\--- org.reactivestreams:reactive-streams:1.0.0\n|    |    +--- org.apache.hadoop:hadoop-common:2.3.0 -> 2.6.1 (*)\n|    |    +--- com.google.guava:guava:15.0 -> 23.0 (*)\n|    |    +--- com.google.code.gson:gson:2.6.2 -> 2.8.1\n|    |    +--- com.typesafe:config:1.2.1\n|    |    +--- org.jasypt:jasypt:1.9.2\n|    |    +--- org.slf4j:slf4j-api:1.7.21\n|    |    +--- org.projectlombok:lombok:1.16.8\n|    |    +--- org.reflections:reflections:0.9.10\n|    |    |    +--- com.google.guava:guava:18.0 -> 23.0 (*)\n|    |    |    +--- org.javassist:javassist:3.18.2-GA\n|    |    |    \\--- com.google.code.findbugs:annotations:2.0.1\n|    |    +--- commons-codec:commons-codec:1.10\n|    |    +--- org.apache.commons:commons-lang3:3.4\n|    |    +--- org.slf4j:slf4j-log4j12:1.7.21 (*)\n|    |    +--- joda-time:joda-time:2.9.3\n|    |    +--- org.apache.hadoop:hadoop-mapreduce-client-core:2.3.0\n|    |    |    +--- org.apache.hadoop:hadoop-yarn-common:2.3.0\n|    |    |    |    +--- org.apache.hadoop:hadoop-yarn-api:2.3.0\n|    |    |    |    |    +--- commons-lang:commons-lang:2.6\n|    |    |    |    |    +--- com.google.guava:guava:11.0.2 -> 23.0 (*)\n|    |    |\n...\nMany of the compile time dependencies are not esssential.\nThis is not ideal. It will increase the maintenance cost. \nIs there a better way? \nIssac from Gobblin team told me that there may be another library you can depend on. I've shared the PR link with him.\nFrom talking to him, I understand the Gobblin library makes it easier to produce a Kafka message that conforms to the Linkedin's requirements.. The format seems to be different from the google style. Did you import and activate the new style config? See the readme.. Sleep interrupted?. This doesn't seem to be ideal. Is there no better way?. Have you tried calling invalidateConnection and maybe clear the connection pool too when the connection is readonly to force DBCP to reconnect to the new host?\nhttps://commons.apache.org/proper/commons-dbcp/apidocs/src-html/org/apache/commons/dbcp2/BasicDataSource.html#line.1971\nhttp://commons.apache.org/proper/commons-pool/api-2.4.2/org/apache/commons/pool2/impl/GenericObjectPool.html#clear--\nhttps://commons.apache.org/proper/commons-dbcp/apidocs/org/apache/commons/dbcp2/BasicDataSource.html#getConnectionPool--\n. Another possibility is to wrap the datasource and proxy calls to it.\nhttps://stackoverflow.com/questions/5007371/refresh-datasource-using-springdbcp. When the connection can't be established during a failover for example, other threads who are trying to get a connection are likely run into the same issue.  I don't think the overhead of synchronizing this method call is too high.  It's safer to do so when in doubt.\n\ngiven createDataSource().getConnection() is already synchronized\n\nWhere is this documented?. Why?. Isn't the behavior different? Here we do want the sleep to be interruptable, right?. Good discussion.\nYes, some alerts would be useful.\n+ @li-afaris . Good point.. Discussed with @kunkun-tang offline. This change does introduce another network call to check if the DB is readonly each time a connection is requested. Having this method synchronized does have some performance implications. \norg.apache.commons.dbcp2.BasicDataSource's methods seem to handle synchronization already.. My question is why it need to be uninterruptable. . wait 15 seconds to match the code?. Could you convert it to tempDir junit rule too?. Is the TODO still valid?. Please use the wrapper method to get the file object.. This logic is duplicated in the same class. It would be great if they can be consolidated. It can be a separate PR though.. What's the difference between this test and the previous one testLevel1RemoteFlowWatcher? The only difference I can see is that the test flow file has two additional jobs. \nCould you add a comment to describe the purpose of this test or remove it if it is not necessary?. Please use Singleton annotation and remove this explicit binding.\nWe plan to remove existing such usage pattern.. Is there a way not to generate these files in the project root? Put them into local directory instead? \nThis is one of the reasons I put all my custom config files in the temp directory.. Put this logic in a separate method?. Users will still need to configure mysql DB. right?\nHave you considered using H2 instead?. \" file doesn't exist\"?. No problem.  Could you update your PR with the suggested change?. Why isn't package private enough?. Please define the new key names in the Constant class. This will make them easier to discover.. Could you describe when these settings should be used?. \"Parameters to generate links to Azkaban pages in emails?\"\n. It's covered in the referenced Google style guide.. 2017. Is there any reason not to give different names to these methods?. \ud83d\udc4d . \ud83d\udc4d . Yes. H2 can be configured to be persistent.\nAnd users can customize the config to use mysql.. Make sense. Thanks! Do you mind making this improvement in a later PR?\nIt would be helpful for reviewers if you can mention that this code is just an exact copy of the original. It's hard to compare when the code is moved to another file.. \"User facing web server configurations used to construct the user facing server URLs. They are useful when there is a reverse proxy between Azkaban web servers and users.\"?\ntypo: values\nI use https://www.grammarly.com/ and intellij to check my spelling.. Thanks for adding comments here as well. \nTo reduce duplication, maybe we should add a comment in the beginning of this file to refer to the Constant class for documentation?. I am still concerned about the large additional dependency this change brought in.\nWhat additional jars would this change bring in?\n. Use Javax. See the new coding convention. #1435 . Why is this test commented out?. Refer to the constant instead using javadoc syntax. https://stackoverflow.com/questions/17496038/javadoc-link-to-method-in-other-class ?. FYI I set up the copyright notice in intellij and it will auto update.\nI plan to share how I did it in a wiki when I find time to do so.. Why is it better than using EventType directly in this interface?. IMHO, having a local variable is fine. Having a local variable makes it easier to debug. At least that is my experience. . I prefer keeping the changes to the minimum when moving code. Make improvement in separate PRs. \nSometimes, it is hard to tell which logic is new which is just move though. . Maybe, there is currently no plan to do so.. Glad to know the library turns out to be useful. :). How do you plan to discover and update all the users of this interface?. Yes, I've read the Effective Java book and remember this recommendation. My understanding is that it is not a problem if the constants are part of the contract. Did I miss something? A counter example would be great. . Are you sure? I was able to use e.g. \n{@link azkaban.utils.AbstractMailer}. Could you add more detailed comments to this sections to explain how to use these configs? This can be a separate PR.. Nice usage of @Nullable.. The convention is to use  see the google style guide and use checkstyle to check. You can change it later.. Could you add a javadoc explaining what this class does? According to the style guide, every public interfaces need to have javadocs.. Please follow the coding style guide for how the summary line should look like. . Why is it better to proceed? Isn't it better to fail fast? This is used in tests.. +1. change to \"Creates\"\nHow about just \"Creates DB tables.\"?. FYI,  is not required if you don't care about having a separate paragraph in the rendered javadoc.. Why not implement a provider that returns an instance of AzkabanDataSource? . Never mind. I understand now. You would like to use Guice to construct the DataSource instances instead of using \"new\" in the provider.. Please add javadoc for public interfaces such as classes per the style guide.. Does assertj provide similar functionalities? We favor assertj over hamcrest.. https://blog.jayway.com/2014/04/23/java-8-and-assertj-support-in-awaitility-1-6-0/\nhttps://solidsoft.wordpress.com/2014/04/29/using-assertj-and-awaitility-together-thanks-to-java-8-and-lambdas/. Could you add a comment to explain why notifyAll is needed? It may not be obvious to readers.. Does it make sense to move these common test methods to the test module so that they can be used in all other modules more easily? e.g. the new az-core module can't depend on the common module. . Is it done so that mockito doesn't bring its own version of Hamcrest which causes conflict with the intellij's builtin version?. Found this https://solidsoft.wordpress.com/2012/09/11/beyond-the-mockito-refcard-part-3-mockito-core-vs-mockito-all-in-mavengradle-based-projects/\nCould you add a comment here so that people don't accidentally change back to -all?. Also https://github.com/mockito/mockito/issues/324\n\"mockito-all is deprecated and is no longer published starting with version 2.0.3-beta to not confuse users.\"\nLooks like we can update the mockito itself. The latest is\nhttps://mvnrepository.com/artifact/org.mockito/mockito-core/2.10.0\nIf you update the version, then no comment is necessary since the -all version is no longer published.. Below example works for me.\njava\n  @Test\n  public void test_wait() {\n    Awaitility.await().untilAsserted(() -> assertThat(1).isEqualTo(1));\n  }\nSee\nhttps://github.com/awaitility/awaitility/wiki/Usage#version-3x-and-above\n. That would be good.. It would be good to use assertJ here as well. It can be done in another PR.. Tracked in the issue #1471. In the future, per our convention, please use the format TODO userid :. ExecutionsTestUtil is specific for execution related tests. \nAny benefit in combining them?\nI prefer smaller classes.. I am not sure. I don't use Eclipse. \nIf we don't actively use it, how do we know it is working?\nIf there is a need for it, someone should send a PR.. Thanks. Could you update the change description to include more details such as what I described above? . Thanks for including the Javadoc.\nPlease see the style guide for how to write a summary line.\n. It's good to use strong types to represent values.. Is it better to stored typed value here too? \nIt's not clear what properties are allowed here.. Why did you choose the project package?. Why?\nWhy can't a flow specify a schedule only? This is the case today, which we need to support anyway.. Make it a method and remove this comment?. Make it a method and remove this comment?\n. This method is deprecated.\nSee\n\nNote for Java 7 and later: this method is now unnecessary and should be treated as\ndeprecated. Instead, use the {@code HashSet} constructor directly, taking advantage of the new\n\"diamond\" syntax.\n. It wasn't obvious to me until I checked the API doc for add that it will return false when it finds a duplicate element. \nCan you find a way to make it easier to understand? A bit more code is a fine tradeoff.\nOr add a comment?. Does it make more sense to have the builder class do the validation?. Consider adding a common utility method to check for duplicates in a list. \nI can't find a standard library to do so with a quick google search.\n\nHave you considered overriding the FlowTriggerDependency's equals method and hashCode method so that you may use a generic duplicate checking method?. prefix it with azkaban.\nMaybe\nazkaban.server.schedule.enable_quartz?. The current convention is to create one .sql file per table. \nAnd the database setup code relies on it.\nIs there any reason to break this convention?. Other tests are named with xxxTest.java.. If the sql statements are changed incorrectly and this file is not updated, the tests may pass.\nCan you think of ways to remove this duplication? \n. Yes.\nSince the constructor is private, the only place where an instance can be created is in the builder. It makes more logical sense to me to have the builder validates inputs. This way we can keep the value class itself simpler.. Let's discuss in person.. Make sense. I will update it. Thanks.\nIn either case, the job status should reflect what actually happened.. The sub-flows are handled at a higher level as demonstrated by the unit tests. \nAt the DAG engine level, it doesn't have the sub-flow concept. This is to separate the concerns so that each layer's code can be simplified. \nThe higher layer will make sure the sub-flow won't start until the parent flow tells it to start. This happens as the node representing the sub-flow is asked to run.. Oops. I can't rely on spell checking too much, can I?. I didn't even notice. https://www.grammarly.com/blog/canceled-vs-cancelled/. As mentioned earlier, at this layer, there is no concept of sub-flows.. Good suggestion. Thanks. e.g. if the caller makes a mistake, passing a prop without the name for example, the constructor will throw an exception.  If you define the method that explicitly requires the needed information, the compiler will do the checking for you and fail at the compile time.\nYou won't need the following validation code here.\nYou will need the validation code in the parsing logic. And even there, the compiler will remind that author what information is required.\njava\n   final String MISSING_REQUIRED_ERROR = \"missing required param: %s\";\n +\n +    final Set<String> requiredParam = ImmutableSet.of(Constants.TriggerProperties.SCHEDULE_TYPE,\n +        Constants.TriggerProperties.SCHEDULE_VALUE,\n +        Constants.TriggerProperties.SCHEDULE_MAX_WAIT_TIME);\n +\n +    for (final String param : requiredParam) {\n +      Preconditions.checkArgument(props.containsKey(param), String.format(MISSING_REQUIRED_ERROR,\n +          param));\n +    }. You don't seem to have tests for missing a required information from the props. \nCould you check your test coverage?. Yes, I was thinking about the same. Haven't decided which way is better.\nLet me try your suggestion.. Because camel case doesn't' work well with long names. Google style guide permits it.. Good point.. done.. done. Removed this method.. I like your suggestion. Changed.. done. done. done. I am less worried about the length. We can copy and paste easily.\nIMHO a more descriptive name is better. We would like to maintain a clear and consistent name hierarchy and namespace going forward.. I see. \nSo you are ok with breaking the database setup code then?\nCould you come up with a plan for how to evolve DB schemas?. I see. Then the name is fine. . When we update Quartz, the sql statements may change. Am I right?\n. See the dev guide for how to update the copyright automatically.. Please move the keys to the Constant class. See the dev guide.. Could you add unit tests? \nThe email component is not unit test friendly yet. We would like to refactor it.\nI think components of this change such as this method can be unit tested at least.. Is this part of the user-facing contract? Where is it used? . As you refactor, it would be good to add missing class docs.. New code should follow the dev guide as much as possible.. I am not sure I follow the comment. Let's chat off line.. Is this comment needed? Seems to duplicate the information conveyed by the method name below.. Is this comment needed? \n\nload external validators to do the validation.\n\nIt seems to be an implementation detail. Do readers need to know here?. log exceptions properly.. Is it ok to remove this method?. @jamiesjc plans to refactor the email component.\nI am suggesting that even before that takes place, new changes should have automated test coverage as much as possible.\nIt's on the todo list to get code coverage report integrated with the review process.. How about the mysql datasource?. Why this change?. See https://google.github.io/styleguide/javaguide.html#s7.2-summary-fragment\nI'd suggest reading the style guide.. It's better to describe the purpose of the class.. Add @throws?. Is a builder necessary? . Why isn't a simpler data structure such as map sufficient here?. daliviewdepenency doesn't belong to the OSS version.. Have you considered https://docs.oracle.com/javase/8/docs/api/java/time/Duration.html. Why not just cronExpression string? This is the only schedule we support today.. Does the max wait time belong to the Schedule class? It seems to be a dependency's property.. Got it. Thanks. Discussed offline. I understand it now.\nIn general, I think the Props are overused in the current code.. Can it be tested separately? It can be in a separate PR.. How about azkaban.job.hive.other_hcat_clusters?\nPlease move the existing config to this class too while you are refactoring.. remains the azkaban service account name?. Just say the call should not block?. Shutdown the DependencyCheck plugin?. plugin not instance? . Why isn't it an interface?. Why isn't it an interface?. Why isn't it an interface?. version_2? or version_2_0?. Can this logic be encapsulated in loader class?. Nice.. Use slf4j logger instead? See the dev guide and tips wiki.. yaml is an implementation detail. Does it have to be part of the name?\nproject_file_suffix and flow_file_suffix?\n. What is this method used for?. Have you considered using the composition instead of inheritance see the dev guide.. Thanks for the comment. . A new line is missing.\nDid you use the saveAction plugin?. Does it need to be a singleton?. Per our earlier discussion, do you plan to change it to \"dependedBy\" later?. Could you add a heading such as \"New line at the end of a file\"?. Is the link needed?\nIf need, I try to link to the intellij doc directly if possible. . See https://github.com/google/guice/wiki/Scopes\n\"Singletons are popular in Java applications but they don't provide much value, especially when dependency injection is involved. Although singletons save object creation (and later garbage collection), initialization of the singleton requires synchronization; getting a handle to the single initialized instance only requires reading a volatile. Singletons are most useful for:\nstateful objects, such as configuration or counters\nobjects that are expensive to construct or lookup\nobjects that tie up resources, such as a database connection pool.\". Since we may not have direct control over the plugin code, using an interface gives us more flexibility to evolve this type. . If there is validation error, is it safe to load and save the project?. Change to one @throws with longe description?. Is this assert necessary? . Thanks for adding a test.. What's the behavior when the key doesn't exist?. How is this id used?. Please include javadoc for public interfaces.. Is the type here necessary? Doesn't a .flow file always represent a flow type?. Please see the dev guide.. Intellij should be able to recognize the proper JavaDoc syntax for a new paragraph. see https://google.github.io/styleguide/javaguide.html#s7.1.2-javadoc-paragraphs\nDid you install the new updated style config?. Can the VelocityUtil be injected? . https://google.github.io/styleguide/javaguide.html#s5.2.3-method-names\nallows such usage:\n\u201cUnderscores may appear in JUnit test method names to separate logical components of the name, with each component written in lowerCamelCase. One typical pattern is _, for example pop_emptyStack. There is no One Correct Way to name test methods.\n\u201c             . Would the new Path, FIles API be easier to use than the old File API?. Thanks for improving the tests.\nI'd suggest a separate test for the special long argument case. This will keep the tests more focused and intention clearer.. I think it depends on the intention of this test.\nThe more likely culprit I think is the use of new Date() in \nhttps://github.com/HappyRay/azkaban/blob/b13ecc2854c0f28ba731fffb1586679329ed47ac/az-core/src/main/java/azkaban/utils/Utils.java#L617\ncronExecutionTime.getNextValidTimeAfter(new Date()) == null)\nThis call doesn't allow the time to be controlled in the tests.. How big is the overhead to do this check on every log?. Is it necessary to add the URL here? . Nice. Thanks for updating the comments.. Nice. Thanks.. This value is static per an AZ web server instance. Right?\nCould you describe your use case in more details? . I haven't seen such a scenario even though some of our zips are very big. \nIsn't the session extended when there is activity? \nDo you have reference to other popular web applications that do this?. For new logging code, I would suggest \n\"slf4j provides a more efficient API called parameterized logging.\nTry to use that format.\nsee\nhttps://stackoverflow.com/questions/30975026/log4j-implicit-string-formatting\n\"\nSee my comment in #1604 \n. I see your point.\nThe client has the following choices that I can think of:\na. always login first\nb. re-login if it gets an authentication error\nIs it not enough?\nPlenty of web applications use session tokens. I am curious how many of them use the patten you suggested.\n. > what would be the benefit of having sessions when clients would authenticate before every action?\nNot every action.\nA session allows multiple actions to be performed without authentication for each one. But not long enough to reduce security risk. \nDid I miss something?. Got it.\nActually, I like the changes you made except the line \"ret.put(\"session.ttl\", String.valueOf(cache.getEffectiveSessionTimeToLive()));\" I understand it may have some value for some clients. But I am not convinced that the benefit is worth the lifetime cost of maintaining this additional contract. \nIf you create a new PR with the line referenced above removed, I would be happy to review again and merge it. \nIt would be even better if you can move the key name session.time.to.live to the common class that defines configuration keys. We would like to gradually migrate the existing constants there as the related code is changed.  \nThanks. We also use the gson library. Is there any reason to use this json library over gson?. Could you elaborate more on how the unique count works?. Is this comment necessary? \n. Where is the code that parses the executionOptions-? . I suggest keeping the template code as simple as possible i.e. no function calls within ${}.\nHow about moving this logic into java code? . Why does this field need to be static?. Please use AssertJ for new unit tests.\nsee https://github.com/azkaban/azkaban/blob/master/CONTRIBUTING.md\n\nUse AssertJ as the assertion library in unit tests.\n. The import organization doesn't seem to be correct.\n\nDid you set up the style and SaveAction plugin as described in the contributor guide? \n. Thanks.\nDid the SaveAction plugin and style config work for you?. Please update the copyright year.\nI have my intellij setup so that it is done for me automatically. I will try to find time to document the tip.. It's ok to change code in the future. We do it all the time. \nThe question is how easy it is to change. \nIf it is an implementation detail, we can change them in the future relatively easily. In that case, I would prefer the simplest and most readable solution.. What's the significance of the number 0 and 3? Can it be made more readable? \n. Is it possible to gradually move away from joda time to java8's time apis?. Please move user-facing config keys to the Constant class.. Yes, switching to new classes will take some manual work. \n\nCan we have this change though\n\nWhat do you mean? Keeping joda time?. No worry. \nOur strategy is to gradually move the keys to the commonplace as we make changes. Do you mind moving the other keys in this class too? \nThanks. Oh, sorry, I didn't realize it was just a re-ordering. I thought you added new logic that uses joda-time. \nPlease keep this change.\nIt still happens that auto formatting doesn't cover some cases. It can be because someone didn't set up the save action plugin correctly or the tools we used somehow missed some places. . Please help to delete dead code!\nThanks!. Thanks!. Have you considered using an existing library https://commons.apache.org/proper/commons-collections/apidocs/org/apache/commons/collections4/map/CaseInsensitiveMap.html ?. As discussed offline, please check if external synchronization is already required.. Thanks for adding new test cases. Is it worth adding a new unit test to make sure that the cache stays consistent with the DB schemas?. Why are these comments removed? Where did they come from?. Please leave a comment that this is DB specific.. Thanks for the summary. As discussed offline, I think it's premature to optimize for performance here. I don't think the performance impact will be big enough to offset the benefits of more reliable/easier to reason about code. \nA separate PR is fine. \nCould you have it reviewed by other team members as well?. Thanks. Add a class doc?\ne.g.\nThe name doesn't say if the map key is case insensitive or the value will also be case insensitive.. Does H2 DB not use the DB schema definition files? . There seems to be a bug in the existing code. Your change and investigation uncovered it. Thanks!\ne.g. \nIf two threads create projects with the same name at about the same time, it seems that they may both succeed and create two entries in the DB. What's in the cache is not deterministic, the projectsById cache may point to one and the projectsByName cache may point to another.\nsee\nhttps://github.com/HappyRay/azkaban/blob/eb8450a55e03b7a5cbf3768373e5f091804ed880/azkaban-common/src/main/java/azkaban/project/ProjectManager.java#L270\nThe usage of synchronized keyword in this class is also inconsistent.\nGranted that it should be very rare that such a race can happen and one may even argue that the resulting data corruption is acceptable given that it can be traced and corrected manually,  with a restart of the web server. You probably remember how costly and painful it is to debug timing related subtle bugs. I would rather spend time writing code that I have higher confidence that it is correct than debugging race conditions even if it is rare. And like other race condition bugs, it is hard to convince myself that I have covered all cases if we allow operations from multiple threads to interleave. That's what I mean by \"easier to reason about\" code.  \nGiven our access pattern and the chance of this race condition, I don't think I have a sufficiently strong argument to block your change. However, I would encourage you to seek other people's opinion and make your own decision. \nIf you do decide to keep the current design, I'd suggest you add a comment to the code, alerting readers of this potential race condition and your reasoning for your design.\nAs discussed, it should be possible to run a micro benchmark to evaluate how much the synchronization will add to the user-visible latency. It may be a beneficial exercise for you. It will help you build a better sense of how to estimate performance impact. Seek help from performance team if needed. . Thanks. I am glad we are in agreement. . I see. Thanks for the explanation.\nThe concurrentHashMap is a complex class. I looked at the documentation. It doesn't seem to indicate that it is designed for inheritance. Are you sure it is safe to override these methods? Is it going to violate some invariance? \nIt's one of the reasons I feel more comfortable with an existing library which has been tried in production. \nIf you would like to keep this approach, I'd suggest you think about forwarding the calls to an internal private instance of the concurrentHashMap. This way you may have higher confidence that this code works by reducing the APIs your class exposes. \n. This is a clever change. \nI assume this is designed to address your goal\n\nWhen one user is removing the project while the other user is fetching the project, the correct project will be returned instead of null.. Consider adding unit tests for this class?. I don't think this constant should belong to this class.\n\nThis class is designed to be one place to capture user facing config keys, until we find a better way... \nThis constant can stay in the class that uses it. . Thanks for adding the comment.\nThis is good. \nWhat do you think of an alternative?\n\"Both projectsById and projectsByName cache need to be thread safe since they are accessed from multiple threads concurrently without external synchronization for performance.\" . This may be used for limiting the attachment size for reportal. Did you check the plugin repo?. Thanks for the explanation.\nIs it to be expected that sometimes sec will be 0?\nIf so, would it be better to add a comment to the code since it is not obvious? . @kunkun-tang can you think of a way to make this test run faster? . @chengren311 thanks for the review.\nIt's a tradeoff. Ideally, we should invest in some mechanisms to allow slower tests to run automatically to flag potential problem but without blocking commits. Linkedin internal testing infrastructure allows it. We should take advantage of it. e.g. have these tests run in our internal wrappers. I'd suggest that we research how other OSS projects handle this. @juhoautio I am interested in your suggestions. Before that, @juhoautio's suggestion makes sense to me. \nWe should have a JIRA to track the long-term improvement plan for how to handle slower tests and set standards.\n@ameyamk how do you propose we track the tasks? internal JIRA or Github JIRAs?\n. The sec seems to control how many seconds to wait before failing the job. Am I right? \nCould you point me to a test that sets the wait time to 0? I can search for it. But since you are more familiar with this code, it's easier for me to ask. \nIf 0 wait time is provided and to be expected, then a wait call doesn't make logical sense, even with wait(1). Yes, your suggested alternative looks better to me. \n\nI'd rather handle it with self-documenting code like this instead of explaining in a comment.\n\nIn general, yes I agree with you.. Thanks for the suggestion. This looks like something that can help. We will still need a way to automatically select the different category of tests to run. \nI will invite the team to participate in this discussion.. Ping.. @chengren311 do you have any objection if @juhoautio does what he suggested above?\n@oliverhu \nThanks for your comment. \nI suggest moving forward with this change with some minor modifications ( see this and other comments) and file issues to address the longer-term issues. An alternative is to wait until the improvements you suggested are implemented, which is currently unfunded. cc @ameyamk  IMHO, it is a better tradeoff to make this change as long as we don't delay the longer term investment for too long.\n. Thanks for checking!. The '.' in the key names are used to separate namespaces, NOT to separate words. \nHow about azkaban.external_resources.resource_manager? \n\nWhy is it better than using the full name in the variable name e.g. RESOURCE_MANAGER_LINK ?. Are you parsing the html content here? \nHow reliable is this method? What if newer versions change the content? . >  AZKABAN_SPARK_JOB_HISTORY_SERVER_JOB_LINK\nWhy is it necessary to have the Azkaban prefix? . Why not use a more realistic server address e.g. \nhttps://rm.example.com:8443/....\n. Are the rest of the URL patterns expected to be same? i.e. which part of the URL needs to be customizable?\nIs it sufficient to ask admins to only provide the hostname, protocol, and port only? \ne.g.\nhttps://rm.example.com:8443 only?. How do you plan to catch compatibility issues before users do when upgrading Hadoop or Spark? . Do you have references to docs that explains how the URL will look like in different configurations?. > We can create a ticket to keep Hadoop team in the loop and notice us if anything changes related to Hadoop/Spark logs.\nI don't think this is a realistic expectation. You can test by asking them.\n\nWorst case would be the \"Hadoop Job Log\" button doesn't show up or the link is invalid. This is not affecting core Azkaban functionality and users still have other ways to find the job logs. This is a nice-to-have feature and has low risk. So I would say we do our best to communicate with Hadoop team to keep us updated with new changes.\n\nUnderstood. I would agree not to make the investment to make the code robust and have good test coverage now if this is an experimental feature and we are just testing if users will find it useful and this is not the final state. Is this the case? \nOtherwise, it is a slippery slope IMHO. How would you feel about a product that most of the \"non-essential\" features are not reliable? What are the objective criteria for classifying the \"non-essential\" features anyway? Isn't the user experience with a product all inclusive? Why would iPhone designers care about some details such as packaging of the products then if they argue that the phone still works if the packaging sucks? \n\nLet me know if you have any better suggestions.\nHow difficult will it be to write an automated test to verify this dependency/assumption? Such a test only needs to run before any Hadoop/spark upgrade.. I see. The key name has the full name already. So I am not too worried about using the short name in the hostname. How often do you see the full names used in actual server names?\n\nI've seen more example urls using more realistic host names though.\nIt's a small detail. I will defer to your judgement.. Thanks.\nI don't see configurations that would affect how the rest of the URL would look like in https://spark.apache.org/docs/2.1.2/monitoring.html, do you? \n\nAt least some of the URL patterns are not the same as ours.\n\nCould you give an example?. @juhoautio I am happy to continue to review and accept this PR if you can respond to the comments. \n. Thanks @chengren311 \n@juhoautio do you mind making your suggested changes above?. Could you find out from the Spark team how they configured this different URL patterns and why?. I don't think testing this assumption would require testing UIs. The assumption here is not related to how the AZ button is presented, is it?\n\nAlso the test case is not easy if you want to catch all possible scenarios. \nWhat are the scenarios you have in mind? \n\nHappy to discuss in person.\n.  @aycaacar\nThanks\nWhat update do you suggest?\nCould you give examples of the issues you saw?\n. This part is getting long. Make it a method?. This is a key in the job config file, right?\nIf so, please move it to the Constant class. \nNew key names should follow the convention: use . to separate name spaces only. use _ to separate words in one namespace. See recently added new keys for examples. . Do you mean Java inspection options conflict with Save Action plugin options?\nWhere can I find these settings you referenced? . How about \nazkaban.obtain_hiveserver2_token?\n. Strange. I don't see the same screen.\nHere is what I have\n\nI checked. I have the latest version of the plugin 0.16. Got it. I haven't updated. Thanks for reporting the issue. I will discuss with the team and update the guide. . I like the way you break up long command lines into smaller more readable pieces.. As the scripts become more complex, I'd prefer Python-based implementation over Bash. \nIt's easier to read and test among other benefits.. I see your point.\nIsn't one of the benefits of using docker to control the dependencies/environment? If the product requires Python (2 or 3), isn't it easier to make sure the requirement is met with a container? . I see.. This is a server software, not a utility library or command line tool etc that are designed to run in as many different environments as possible. \nIMHO, it is a better tradeoff to use Python than Bash for developer productivity reasons than to optimize for the ease of deployment. I understand that developers who like Bash better than Python may disagree with the benefits. It's my personal opinion. \nBash has its place. My evaluation criteria are not the function of the code but the complexity of the code. \nThere are alternative ways to make the deployment easier. Docker is one of them. Larger companies like LInkedin have configuration management systems.\n. A new line is needed at the end.\nDid you follow the contributor guide and set up Save actions plugin? . Thanks for fixing typos. \nIn the future, I would suggest separate PRs for independent changes.. Add Javadocs? . How does this implementation compare to using Gauva Resources\nhttps://www.stubbornjava.com/posts/reading-file-resources-with-guava\nIs it necessary to have the parent parameter?\n. I see.\nI can see some advantage of organizing the resources based on the test class's package name. However, this strategy doesn't work if a resource is used by multiple test classes in different packages. Thus, I don't think this organization strategy can be applied consistently. IMHO, allowing the resources to be organized independently seems to offer better flexibility without sacrificing readability if named appropriately. \nThat said I acknowledge that this is a departure from some of the existing code. I will leave the decision to you as the author of this code. \n\nIf you choose the package name based organization, have you considered\npublic static URL getResource(Class<?> contextClass,\n                              String resourceName)\nGiven a resourceName that is relative to contextClass, returns a URL pointing to the named resource.\nhttps://google.github.io/guava/releases/21.0/api/docs/com/google/common/io/Resources.html#getResource-java.lang.Class-java.lang.String-\nThe parent parameter's type is weaker than I would like to see. The API above makes a different choice. I am interested in your opinion comparing these two different designs.\nUsing the Gauva APIs referenced above seems to simplify the implementation slightly IMHO.\n. I found this discussion useful.\n\n\n\"I just tend to think that on the test side avoiding additional verbosity is really nice\"\n\nI agree. I would create wrapper methods in tests for that purpose.\nIn this case, what do you think about having a private method  getTestString(\"firstErrorMessage.html\")? \nThe shared utility method can be more flexible. \nI would let you decide. . I think this is self-explanatory. The return value is not used. . The design is not my preferred choice based on what I know so far. But I am ok with it.. I plan to refactor this part later: separate construction of DAG from running a DAG.\nI am interested in what you think of the different API choices. We can chat more off line.\n. Good question.. Good question.\nI thought about it.\nThe main factor that made me decide to use the same enum is to make testing easier. The same type can be put in the StatusChangeRecorder. \nThat said, I can use string in the StatusChangeRecorder. Let's discuss more if it is worth refactoring. . Not yet. It's not implemented.. see the referenced prototype PR discussion:\njuhoautio on Sep 19, 2017  Collaborator\nWhy no camel case? :)\n@HappyRay\nHappyRay on Sep 19, 2017  Owner\nBecause camel case doesn't' work well with long names. Google style guide permits it.\n@HappyRay\nHappyRay on Dec 4, 2017  Owner\nhttps://google.github.io/styleguide/javaguide.html#s5.2.3-method-names\nallows such usage:\n\u201cUnderscores may appear in JUnit test method names to separate logical components of the name, with each component written in lowerCamelCase. One typical pattern is _, for example pop_emptyStack. There is no One Correct Way to name test methods.\n\u201c. Discussed offline, we agree it is ideal to make the DAG as immutable as possible. . I will try it. . Discussed offline, Cheng is fine with this style.. This is intentional. \nAny downside?. Discussed with Cheng offline. \nHe agreed that it is ok to use in test code.. This is how package private access level is specified.\nhttps://docs.oracle.com/javase/tutorial/java/javaOO/accesscontrol.html\nThe method is needed by other classes in the same package. \n. See the answer to the other one.. Thanks. Will fix. . Fixed in the next patch.. Because there may be others.. If true means \" if the check returns true\" \nI can make it a complete sentence if it is not clear enough.. No. This is for debugging purposes. It's not an error.. I see. I forgot to remove this comment. I moved it to the class javadoc above. Will delete.. Fixed.. Gradle writes such output to a log file instead of the console by default. I agree that writing large verbose debug outputs can make searching for failures in the log more difficult. However, most of the test failures can be reproduced locally and it is easy to see which tests fail from console or IDE. \nI left this log in the code to make it easier to see the exception message when running in an IDE.\nOn balance, I think it is OK to leave some reasonable amount of debugging information in the test output log after considering the tradeoffs.     . Done.. In this example, x and z in the parent dag would form a circle and this code will detect it.\na node can't be added to two different dags. see checkBuildersBelongToSameDag in NodeBuilder.. Subflow is a higher level concept and will be implemented at a higher layer. \nThe included unit tests can illustrate how this package should be used. see simple_sub_dag_success_case in DagServiceTest for example.. >  \"what if there's a circular dependency inside a sub-flow\"\nCould you give a specific example? . Thanks for the question. I would have to examine the existing code and think about how the integration will work to handle such cases.\nOne possibility is to treat a.job as a template and create a new instance of the job for the subflow x. Another option is to not allow this configuration i.e. two flows share the same node. I understand this may potentially break backward compatibility.  I don't think the new flow format will have this issue though. . Yes, it is a non-blocking call.. No. Unless the test machine is super busy. We can adjust the buffer if it happens.. It's tested indirectly by the tests.\nThe annotation is just for documentation.\nsee\n/\n * Annotates a program element that exists, or is more widely visible than otherwise necessary, only\n * for use in test code.\n \n * @author Johannes Henkel\n /\n@GwtCompatible\npublic @interface VisibleForTesting {\n}\n. Thanks.\nThe class is not used in production code yet. But you can see example usages in the unit tests.. Yes, that's milliseconds. \nI'd like to see how often this operation takes longer than 100ms. The worst I have seen so far took 11ms.. @juhoautio \nI thought more about your suggestion. I think you are right. I increased the threshold.\n@kunkun-tang \nThe time is how long it took to interrupt the thread that is sleeping. The 11ms was seen on travis. . I don't think the change would make any difference. If the shutdown method does nothing, the test will still run as quickly as the host allows. \nThanks for your comment, I realized that the test is not testing the right thing. Made a change. . It appears that the junit runner main method will call system.exist and force the process to terminate even when a non daemon thread is still running.\npublic static void main(String... args) {\n    Result result = new JUnitCore().runMain(new RealSystem(), args);\n    System.exit(result.wasSuccessful() ? 0 : 1);\n}\n\n. Good question.. Thanks for adding this test!. Consider explaining why this zip is insecure. . Please use the standard class doc format. . Nice. The intent is more clear than using a file in the previous version.. Consider https://docs.oracle.com/javase/tutorial/essential/exceptions/tryResourceClose.html. The file is not cleaned up after this test. Please fix.. Consider making the format change in a separate PR first.. I am glad you asked.\nHow would you test the code that uses this method if this method is made static? . I don't expect the users of this method to recover from this exception by dynamically changing the node name and re-use the existing builder. Thus, it doesn't make much difference.\nThat said, I agree it is better to do the check before modifying the builders. \nI will make a change. \nThanks. see #1808 . I haven't used these libs. Do you think using these mocking libraries is better? If so, why?. Thanks for adding tests!\nIs there a good reason to make this a setup method instead of a regular private method?. This assert seems to suggest that this test is designed to test loading of the project too. That logic should have been covered in a separate test, I assume.\nMaybe a regular assert is more appropriate? . Consider adding the unit in the key name? e.g.\ndir_max_size_in_mb?\nDo you foresee other keys in the project namespace? Project-dir can be interpreted as an individual project directory. \nWould it be better to name it \nazkaban.project_cache_max_size_in_mb? . What do you think about making this an integer?\ne.g.\n60 means 60%?. Why not make it \"\"azkaban.project.stop_cleanup_threshold\" without '+'? Isn't it more readable?. How about using the word high water mark and low water mark? These terminologies are used in other places already.. For our purpose, is this level of accuracy needed?. How long does it take to get this information? Is the time required proportional to the number of files in the directory?. How does the existing code handle synchronization?. Is this change necessary to be included in this change?\nThis is not related to the project cache directory. . \"projectDirMaxSizeInMb\" see coding standard naming.. Why is 2 TB a good default? I don't think most of the deployment will require such a big cache.. Is 10% buffer big enough when the default max size is smaller?. I would suggest a lower number so that each clean up can clean up at least 20% or more of the max to reduce the number of times the clean up needs to run and thus reducing the amortized cost of each clean up.. These are not arguments. It seems a bit odd. . Consider adding methods to get config values and add validation logic there.. Should this value be configurable?. Make this block a private method?. What happens if the runningFlows changes between this statement and the call to .values()?. Have you measured the performance of the current design?\nIn case performance is proven to be an issue, have you considered the following alternative design? \nDelete older versions of the project immediately. This will free up disk space more quickly.\nCreate a file in each project directory and write the size of the project to the file when the project is created. The project files are not supposed to change after creation. Touch this file each time the project is used. This way, we can have a more efficient LRU algorithm based on last access time, not creation time. \nMaintain the total size of the project cache in memory to avoid the overhead of re-calculating it. The size shouldn't change too often. This way we can afford to run the check more frequently.\n. The downside is unnecessary complexity. \nThe referenced article seems to refer to a sparse file. The project files are not sparse files, are they?. Was it subject to race conditions then? Could you describe the problem you tried to fix in more details?.     public static final String PROJECT_DIR_CLEANUP_START_THRESHOLD =\n        \"azkaban.project.start_cleanup_threshold\";\nseems to work for me.. Is it in MB? \nShould it be 128_000 then? . Is it better to use composition instead of inheritance here? Using inheritance for code reuse only is an anti-pattern IMHO. . Please define new config keys in the Constants class.. Make the key \"displayExecutionPageSize\" a constant? . Add new line.. It is not clear to me what these lines are for.\nCould you add some comments? e.g. reference online documentation?. Fixed. Thanks. The DAG component is designed with minimal assumptions including the validations done to its inputs prior to passing these inputs to the DAG engine.\nThis allows this component to be used in more scenarios. e.g. the test included in this PR doesn't have a need to convert the v2 flow into Flow object which is where the azkaban.project.DirectoryYamlFlowLoader#buildFlowEdges is called. \nIn the future, we can consider getting rid of one of the validations in the AZ loading scenario.  For the time being, the cost of double validation seems small. . I haven't looked at the DirectoryYamlFlowLoader code in detail.\nEventually, yes, we will need to handle running both v1 and v2 flows. Will look into reducing logic duplication then.. Make it \"___*\" three underscores to make it even less likely to have a collision?  I assume it will be hard to change the file name once this change is deployed.... Have you considered accepting a https://docs.oracle.com/javase/8/docs/api/java/nio/file/Path.html instead? You can benefit from stronger type checking.. Is this necessary?. Why not use Path as the argument to touchIfExists? File is a legacy class. Path is preferred now if I remember correctly.. https://gquintana.github.io/2017/09/02/Java-File-vs-Path.html. Is there a better way?. Since this constant is an implementation detail rather than a user-facing API, is it better to define it in a place where it is used? . Have you considered https://docs.oracle.com/javase/7/docs/api/java/nio/file/Files.html#readAllLines(java.nio.file.Path,%20java.nio.charset.Charset). It's generally a good practice to reduce the scope of a concept.  For example, if a constant is only used in a class, define it for that scope. The test classes can access it via FooClass.BAR if needed. \nWe don't have a good way to organize our user-facing key names etc yet, the current arrangement for this central class is a compromise until we find a better solution. \nMake sense?. Why does this change show up here? This seems to belong to another change.\n. What's this for?. Thanks for improving tests!\nPlease use assertj for new tests. See the contributor's guide.. A good unit test should finish within milliseconds. \n@jamiesjc\nThanks for paying attention to test running time.. \ud83d\udc4dalthough in this case, this call appears to be the only client that I saw. That said, the suggestion seems to be more robust against changes.\n@chengren311 do you know why this method has to be synchronized? \n. Specify the minimum version of the plugin that has these options?. I suggest keeping formatting changes a separate commit. . How does this change reduce the log output?. Is it because it no longer runs with the --info option?. Have you considered retiring this config? What are the downsides? . LGTM.\nCould you add a TODO to retire this required config?. \ud83d\udc4d . I am not sure I follow this comment. What API calls are you referring to?. I like the usage of Duration here. . Is it just a refactoring? \nNice.. I like shorter methods.. Make it a Todo and add more details? Copying the description from the PR is fine.\n. ",
    "wowgeeker": "it works. thanks, it's not a bug.\n\nHowever, you can set the failure option to finish all possible jobs...\nwhich will run your flow up until it cannot go any further.\n. \n",
    "TalAntR": "yes, it would be great to have such customization\n. ",
    "Ddper": "I also need such customization.\n. ",
    "alfredo-ramos": "+1\n. Would be better that azkaban could upload tar files, then permissions can be preserved.\n. ",
    "xunnanxu": "+1. @kunkun-tang it would be nice if:\n1. allow flow name to be changed via UI (not great for automation)\n2. or, allow user to specify flow metadata like\nflow-name: myFlow\nand use that as the flow name if this is specified in leaf node or throw an error if specified in the middle of a flow (or wait until there's conflict)\nhope that makes sense. > Users can still customize and use their own launch scripts today, can't they?\nThey can, but that means they would invoke internal/XXX which seems anti-pattern to me.\nI think it would have been a good idea to just run azkaban in foreground by default and offer only one script start-executor.sh. In that script we use exec such that java process will use the same pid.\nIn that case if user wants to run it in background and dump pid they can just do\n(./start-executor.sh &); echo $! > currentpid\nAnd if they want to redirect output they can do\n(./start-executor.sh > output 2>&1 &); echo $! > currentpid\nIn other words, azkaban scripts should not do too much IMHO. Users can always handle the output however they want but if azkaban launch scripts assume users want something, they can't reset the behavior if they don't like that.. > How would you solve the stated problem in this PR?\nErr what stated problem? If you mean what's mentioned in this PR then the answer above would be my solution.. @HappyRay @chengren311 Let me know if this makes sense. 1st PR. Not sure whom should be reviewing this or how it should be labeled.. @HappyRay thanks for reviewing. I think I've read the contribution guide but if I miss something please feel free to point out.. > I'd suggest you start that discussion in the PR that introduced this change. The PR description explains the rationale for that change. Happy to discuss if it is not clear or if you have concerns about the design.\nIf you mean this PR https://github.com/azkaban/azkaban/pull/1669, I did read it. However I think I would probably just merge the two start scripts into one instead of keeping the current setup. In fact I think the start-exec.sh is redundant. User should just invoke the main script directly. If they want to redirect output to a file, they can easily wrap that with a one liner in upstart or systemd. As an OSS project, azkaban should let user choose what the launching behavior they want rather than choosing for them. In fact having all pieces in one file is generally what java based apps do when they provide launch scripts. For example: https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot-tools/spring-boot-loader-tools/src/main/resources/org/springframework/boot/loader/tools/launch.script\nWith that said I think this is out of the scope of this PR. I bring this up b/c otherwise the scripts can be simplified.. @HappyRay do you guys normally label the PRs?. @ashahab I don't think there's a bullet proof way to detect that. On the other hand, user should know what they want. Containerization is just one of the techniques to get an isolated environment ready quickly. What if they just run it directly in a cloud instance using AMI for example?. @HappyRay could you elaborate on what you mean by \"meaningful benefits\"? This is useful to prevent instances from being overloaded IMHO and it's part of dispatching logic today.. @HappyRay I think these are 2 separate things. The executor selector will first use the filters to filter out unqualified nodes and then use the comparators to find the best one. First of all I don't think random assignment is supported ftm. Secondly then we would run the risk of overloading executors. Judging from the current default value it seems like you guys tend to run executors on machines with enormous amount of memory so that might not be a concern esp. if you use azkaban to just launch/track hadoop jobs but it is sensitive factor for cloud users. For example we run multiple executors on machines each having 4/8GB memory only.. In practice the current filter setup (before this change) has been broken for us and we have to build extra monitoring infrastructure to avoid overloading from happening. If node is overloaded, executor will stop responding but web node will assume it's still working just fine causing other issues like https://github.com/azkaban/azkaban/issues/1698. > Could you describe in more detail how the filter setup was broken for you?\nAs described in the issue, the hard-coded 6GB memory limit does not work if executor runs on an instance with 4/8GB only. Enabling such filter will either cause no jobs to be dispatched to the nodes or most of the memory resource is not utilized. 95% hard-coded CPU limit doesn't work for a similar reason. I have to not use the filters but implement other monitoring mechanisms to avoid nodes from being overloaded.\n\nrecent changes made by @chengren311 will queue java jobs if memory is running low.\n\nWhat changes are you specifically talking about?\n\nDo you run java based jobs?\n\nWe mainly run python jobs.\n\nCould you explain how the filters will work better for you?\n\nThe hard coded values should be replaced by configurable values and hence this PR.. > If it is not clear to you yet, I am interested in retiring this entire feature and replace it with random assignment and leverage flow controls at the individual executor level.\nI'm sry but I don't see the logical transition here. What's the answer you are expecting? What's the reason for \"retiring this entire feature\"? After all you have not yet proven to me that random assignment is better than current design after I typed this much. I guess I still don't understand why we keep talking about random assignment as that's more of an alternative to comparator in current design not filter.\nUsers should have the right to choose what they want. If you want to rip off all the code and replace it with something else that's ok but that should be on the 4.x road map.. I don't honestly care about what random assignment is. Maybe that's better. But my point is we should not be randomly taking features away in a public software project.. Hmm after checking that PR if I understand your proposal correctly, you want to let scheduler send jobs to executor regardless, and let executor determine when to actually execute it based on certain conditions.\nThis might be fine in certain scenarios but I don't think that is right in general. Think of a scenario where executors run long-running jobs. If new jobs get blindly dispatched to busy executors, they will be stuck there forever until other jobs finish, which might take hours even days. That will severely delay the new jobs, whereas in the current model, they will be queued on the web node side, and I can easily mitigate the congestion by adding more executor nodes.\nIf you want to let executor do the job, the only right way I can think of is changing the push model to pull model. That means jobs will only get picked up by an executor node if it is capable of handling it (or it thinks so), otherwise it will stay in a queue. However that's a fundamental change and I don't think it can handle more sophisticated scheduling logic.\nAgain, I think users should have the right to choose what they want. That is one of the fundamental principles of building any successful OSS projects.. @trentgerman I think it depends on how you configure your job. You might want to share your .job file. The context here is not enough.. Actually I think it has something to do with your command.\nI guess you just literally put command=cd whatever....\nTo understand why this fails, you need some background knowledge:\n1. Azkaban basically just uses java ProcessBuilder to invoke an external binary.\n2. The command must invoke an executable file. When you run echo, it actually invokes /bin/echo in a typical linux based system.\n3. cd is not an executable. It's a shell built-in command. There's no /bin/cd, which is why this fails.\n4. On the contrary, echo is a bit special as it has two versions in a general shell (e.g. bash) - a shell built-in command and a /bin/echo executable. When you invoke echo in bash, you actually run the built-in command (which echo) whereas the same command invokes /bin/echo when used in java. However, not all shells are guaranteed to have echo as a built-in command.\nIf you want this to work, you can use bash -c 'ur cmd' for the reason above.. I think you are generally right but I slightly disagree here b/c that would assume python is available. This is generally true if you run this in general full-fledged linux environment but if you run it inside docker then it's not always there (like popular bare bone alpine image). And it doesn't quite make sense to force people to install python just for this purpose. I even think we should support bourne shell only environment for that purpose to remove the requirement for bash.. However since bash is typically available in most environments and installing bash is easier than python (as you don't need to worry about 2/3), degenerate to sh is less of a concern here.. This is not just for readability but to make it clear that these are the 2 arguments passed to that function. These two are quoted later for that reason.. I think it would make sense if user jobs require python to be present. I don't think python should be required just for the purpose of launching the nodes.. @HappyRay I disagree. This is an OSS project, not dogfood any more. We should be thinking how users should use our software, not \"no you are using it wrong\" unless it's made by Apple.\nI think my concerns are:\n1. Switching to python introduces unnecessary dependency issues. Yes you can say \"why don't you set up your environment properly?\". But be aware it's tricky to have python 2 and 3 both in the system without help of other software like virtualenv or pex. What if the script assumes 3 while user scripts want 2, or the other way around? This requires either extra build system (which increases complexity in terms of your concern) or requires users to separate the environments for their scripts and azkaban's launch script properly. Both are suboptimal IMHO.\n2. It does not necessarily reduce complexity. Most of the complexity in this PR comes from the fact that the logic is unnecessarily split into 2 files (discussion in #1669), in which case to keep the pid both need to be executed with exec and vars need to be handled carefully. We would have similar issues if we just switch to python but keep the same design. Again I don't want to side track this PR as that's not our main concern.. > it is a better tradeoff to use Python than Bash for developer productivity reasons than to optimize for the ease of deployment\ndoes not seem like a good argument to me considering the fact that those scripts have only been touch so many times since the beginning of 3.x.. Hi @ashahab, hmm I'm not quite sure if you are proposing something new here or just repeating my suggestion in this PR. In fact I think \"no fork\" should have been the default option (see new discussion in  #1669). HOWEVER, the current default behavior is to run it in background. I don't want to change that because users might be relying on that behavior already so it's not something we should be changing in 3.x. This PR just gives other users (like me) an option to run stuff differently.. ",
    "kunkun-tang": "curious how this customization could contribute?. #683  fixed.\n. @HappyRay It makes full senses to me. I got confused when I was reading this part of code.. Since the author still keeps offline, can @juhoautio pull a new PR, resolve conflicts there and we can review forward? @HappyRay @ameyamk . Thanks. I will take a look.. Duplicated issues\n. 3.2 I believe now.\n. @bmsq May we know why removing transform assignment is able to fix this Auto Pan Zoon bug?\n. LGTM. Thanks @bmsq for the explanation.\n. This issue is already fixed in #1338 . Closing. I believe 3.0 azkaban-sql folder has all necessary tables now. Please check it out.\n. Hi @superwood , I can not understand what you mean by relaunched manully\n. #673 fixed. Thank you guys.\n. @vvii @juhoautio   Guys, is that correct that class SendEmailAction is never called?\n. #673 was merged. Closing this.\n. Hi @devangorder , we haven't tested the compatibility. Thanks for raising this point. Would you mind testing this if you have time? and pull request some documentation supplement?\n. Nice! Thanks @devangorder for your update.\n. I think the message is supposed to be _\n\nJob was killed while waiting on pipeline. Quiting\n\n_. ?\n. Important fix!! BTW, Is that right that class SendEmailAction never used? \n. Hi @Vimos , I still don't quite understand why we have to make it configurable. Any benefit?\n. Referring to #698. Closing this one.\n. Good catch!\nLSGM.\n. It works! We are not familiar with velocity. @arumugarani , May I know why recentlyFinished.isEmpty() doesn work? and what does !$null.isNull mean?\nThank you!\n. LSGM. Will merge your request soon.\n. Introduction: Our team deployed the latest azkaban web server last week. we met a serious issue: every user could not create a project. After investigation, this is caused by the logic we are modifying now. we are reverting the logic back before this pull request.\nIn the documentation, we already mentioned that when lockdown.create.project is true, only admins are able to create project. The latest commit ignored this, so we need to change this.\nExperiments are conducted in our test cluster. New code works very good.\n. Done. Just learned how to use rebase to Squash. :)\n. Looks like a gradle issue. Have you tried building in other machine?\n. Hi @rajivchodisetti , thanks for your interests. We're still doing tuning stuff to fix daylight saving change issue. Will update this thread!\n. Resolved by #728 \n. @rajivchodisetti yes. However, you have to specify \n\nazkaban.schedulePanelPageName=schedulepanel.vm\n\nin azkaban.properties file  to enable this feature.\nPlease read the commit messages in https://github.com/azkaban/azkaban/pull/728/commits carefully.\n. Also, you might want to read our wiki:\nhttps://github.com/azkaban/azkaban/wiki/New-Azkaban-Schedule-Introduction\n. #766 should fix this.\n. Created a new pull request to fix the comment issues refer #704 \n. #728 fixed this pull request.\n. Closing this as already fixed.\n. @binhnv Thanks for letting me know. you are correct. I believe you are setting up multi executor mode. We will look into how to adjust this.\n. @binhnv Please use the last two files () in azkaban-sql folder. https://github.com/azkaban/azkaban/blob/master/azkaban-sql/src/sql/update.execution_flows.3.0.sql\nCurrently we have to keep the original sql clauses to protect backward compatibility. some people might be using older version of azksban\n. A new pull request #824 was made to resolve this problem. Closing.. Hi @hitwangyu , thanks for reporting this bug!! You are correct. The azkaban server seems not updating new Trigger to DB immediately when the schedule changes. I'll look into this later.\n. Can be closed due to #708 \n. Closing this PR.\nI would guess #1346 made a change to the internal project file code. We would rebuild the API if we propose the purge active projects API.. Hi @JasonBian , could you please give us more details about this bug?\n. #728 fixed this pull request. closing\n. @binhnv Please use the last two files () in azkaban-sql folder. https://github.com/azkaban/azkaban/blob/master/azkaban-sql/src/sql/update.execution_flows.3.0.sql\nCurrently we have to keep the original sql clauses to protect backward compatibility. some people might be using older version of azksban\n. @binhnv I used once. Will update create-all script to handle the new change.\n. Let me investigate the automated test on Scheduling service.\n. This issue should be already fixed by #1328 . Closing now. . Closing this.\n. Hi @wanglifengwf , thanks for reporting this incident. LOW_MEM_THRESHOLD can not be configured currently. If you can contribute the this change and add some tests, that would be great. Thank you for looking into this!\n. @Codefor It actually need more for some certain jobs.\n. @bmsq \nThanks for reporting this bug. Do you know more context why event.wheelDelta does not work for IE? Is it due to our outdated jquery version?\n. @HappyRay I believe I already tested before. @bmsq , you might want to resolve the conflicts before merging.\nThanks.\n. Since this pull request is outdated, may we close this pull request?\n. Hi @adfel70 , thanks for letting use know this problem. could you please paste the full logs you faced ?\n. Found a glitch if bootstrap-datetimepicker.min.js is updated to new version. \npickDate and pickTime are retired in recent bootstrap-datetimepicker.js. So I made a replace to all affected variables in order to accord with current API.\nVerified  all datetimepicker locations in Repo. Should be good now. Also experimented in my local environment. Didn't find bugs.\n. Is working on the Final Test. Will modify description soon.\n. Opened #728 to merge this pull request\n. Hi @cilier , this is feature is going to release soon. Please wait for two seconds for the merge of #719 \n. @inoviavenkat Thanks a lot for your feature request. Below  are the answers to your questions.\n1). The blob is used by webserver only. Jobs in executor will only be triggered by webserver calling.\nNo other tables. \n2). 3). They are called in triggermanager class. There is a thread to check these conditions periodically. \nBTW, you might contribute to adding this feature after #719 is merged. Flexible Scheduling will be released soon.\n. Close this due to the new pull request #723 \n. Resolved the test failure problem in #724 . Will merge of #724 automatically make this pull request pass?\n. Merged.\n. Added a TODO comment.\n. @HappyRay Can we merge this pull request?\n. resolved by #728 \n. The API documentation will be at #709 . \n. @HappyRay updated.\n. @HappyRay Still confused what you mean by \"enable\"? It should be transparently there. Do you mean enable the legacy scheduling page?\n. @HappyRay Code and commit message are updated.\n. It looks like squash-merge in github works good. So we may have multiple commits in one pull request when updating code, right? Squash could help us rebase. \n. @suvodeep-pyne Thanks a lot your detailed explanation.\n. I tried \"update branch\" button in this page. Do I still need to rebase myself? Let me know if it is good to merge.\n. Oops. Looks like I have to rebase locally due to suvodeep's change.\n. Reopened this pull request in #738 \n. @HappyRay Could you please have a look at this?\n. #756 wrapped up this pull request. closing.\n. Have you checked your flow? Is there a recycled job dependency?\n. Are referring to http callback? Please checkout #442 \n. LGTM!\n. Maybe I'm wrong, but this configurations should be inside one job I believe.\n. @xFaris Have you tried putting these configurations to job files?\n. Closing this issue as @Codefor confirmed.\n. I even don't realize we have this folder! We should remove it. Should we also remove src files inside?\n. +1. Let's move these to build folder to keep web root folder clear.\n. @suvodeep-pyne I will fix this by checking in JsTest conponent.\n. @hreview Not sure how to do this work? we should move these files after :build, right? I noticed that :build and :distTar is two different tasks? Then how could we handle this?\n. #756 resolved this issue.\n. @suvodeep-pyne Tools guy taught me how to debug gradle in IDEA. The root cause of npm_install failling in IDEA is that $PATH is not right in IDEA. I enforce gradle always download the specific nodejs version, and resolved this issue.\n. @suvodeep-pyne Do you have any comment for this pull request? I noticed that our pull request sometimes failed for some reason. This change enforced downloading a specific node js version, might solve that issue.\n@HappyRay \n. @HappyRay I didn't observe slowness in my local laptop.\nAlso, it should be one-off process. Unless you do gradle clean, you don't need to download after the first build.\n. Thanks a lot for @suvodeep-pyne 's reviews. Learned a lot.\n. I met this issue when I run solo server in Idea IntelliJ. I resolved by discarding h2 conf and use real Mysql Instead.\n. Link was added. If we will make a big change in future, like AZ 4.0, we might seriously consider rewrite and organize docs in Wiki only.\n. Comments were fixed, and Merging.\n. Yes. LGTM. The original hardcode gradle statement makes our system choose a wrong folder to copy. This change works finally.\n. This is not possible in current AZ implementation.\n. @hugoboos I'm not aware of any LDAP change inside Azkaban since AZ 3.0.0. \n. Yes, I know.\nYou mean AZ 3.1.0 is compatible with this LDAP 2.0.13, but AZ 3.2.0 can not ?\n. @suvodeep-pyne I believe jobs should execute as user. If we make execute-as-user to false, most jobs also work. @georgezhlw should have more context about this.\n. You both have good question. Since that will be a separate security question, how about re-evaluating it after merging this.\n. There is also a common property file, why not put it there?\n. @suvodeep-pyne \nYes, I agree. I'd suggest putting this logic in cluster and see what happened. If it works very well, we may remove all cache logic, since Ray and I didn't figure why we needed a cache for fetching state. It looks redundant.\nYour thought is right. However, the period of time can not be predicted. Sometimes a couple of minutes; Sometimes, half an hour.\n. No need to re-upload all the projects.\nhttp://azkaban.github.io/azkaban/docs/latest/\nChange configurations, which is described Multiple Executor Mode section. Also, you need to change DB schema which is also in document.\nWhy not try deploy the latest code on you local machine. \n. Uni tests were added just now. Verified in my local environment, and That works well.\n. I think we can push this pull request. @HappyRay \n. Closing this, as refactored in  #828. @HappyRay I believe so. Will do a pull request next week.\n. Looks good. Please validate this change in our AZ test instance. \n. @HappyRay Yes, I totally agree with you. It's time to updae the sql scripts to be consistent with AZ 3.8\n. @HappyRay @jamiesjc  Program readability is also important to readers. I don't have preferences given this case.\n. Confused if this change is merged or not. @jamiesjc \n. LGTM. Merging.\n. I guess there was something wrong with you AZ config.. @hderms This issue is fixed by #827, and is under review now.. Is the bash folder newly created recently? Will the bash scripts directly go to the production cluster from now on? I believe azkaban4 also has some bash scripts, like shutdown? Should we remove them in future?\n. @tk0485 are you testing some jobs using your solo server? the default port should be 8081, right?\n. I already released the new sql changes to one of our new AZ DB. Will evaluate how it behave after AZ is set up there. @HappyRay . @suvodeep-pyne I believe these sql files were not read/used in the internal AZ code. I just copy tables one by one every time I set up an AZ db.. removed database.properties file.. @HappyRay I checked the logic. There is a boolean configuration database.check.version. If it is true, we will do the setup table automatically when web server start. I believe we should keep safe and get the file back to repo.. Evaluated in our another az cluster, and it is working well.. Maybe no. Just curious, why do you want to kill all running flows?. LGTM.. LGTM. Found an imperfection in code. The reporter plugin constructor should at least have a name field, in order to distinguish webserver or executor who launches the reporter thread.. Already evaluated in our staging server. Pushing.. @HappyRay All Comments fixed.. LGTM.. @juhoautio Thanks a lot for reporting this issue. Do you have any suggestion?. Please pull the latest code. This issue should be already resolved by #827.\nSee  #818. I see. You are running on standard mode with web server and executor installed separately, right?  Any thought?\n @jamiesjc. The easiest work around I can think of is to set execute.as.user to false in your common property file under plugin/jobtype.\nhttps://github.com/jamiesjc/azkaban/blob/a3390cd154c26e9ef6734eb06b66ea72126b3eeb/azkaban-solo-server/build.gradle#L26. Just create plugin/jobtype folder and put it inside executor folder.. @cquptEthan Thanks for point out. I'm confused that how do you define \"out going messages\" ?. Went through all listed threads. Learned new things!\nI checked quite a few throwable occurrences and found many wrong usages. . Thanks! Sounds good to me.  @HappyRay , any thought?. we use later.js to parse cron expression in UI, but use Quartz-Cron to trigger schedules in our back-end service. The UI might have some bugs, but it will execute as you like if it is following the correct Quartz-Cron grammar.. Closing as this is a bug for later.js. Found an issue to block this PR to merge. Since we don't know the port in advance, this API might be difficult to use.. Your idea sounds tons make sense to me! Will work on this when having bandwidth.. I renamed the API and added isAlive parameter to here.. LGTM.. @jh3155 @NaanProphet Still confused. Could you have a concrete example show what bug it is ?. @mariacioffi I couldn't see any correlation with #845. I'm able to see what happened on #845, but confused on this issue. If you are able to fix the bug #845 , feel free to open a pull request. I will review.. Closing this PR, and  creating #904 . May we have some general context why this upgrade is necessary in this pull request?. @suvodeep-pyne I thought this upgrade is related to having a safe server shutdown function.. @scofier I encountered this bug before. The workaround I did was killing the job process directly inside your executor.\n. Our team actually haven't met this issue till now. This error is thrown to indicate that the application\u2019s stack was exhausted, due to deep recursion in most cases. Anybody in this thread has more investigation and fixed?. Thanks @hikoz . @juhoautio Thanks for fixing bugs! We also encountered sometimes jobs get left in running / queued state even after the execution has been killed. It should be some bugs in the backend service, since I noticed that DB's state still kept running.. @hkiran This change looks makes sense to me. You stated that \n\nThis issue does not happen every time/run.\n\nDo you know why it is happening randomly?. LGTM. @suvodeep-pyne might want to see if it has conflicts against new Jerry Server.. @adfel70 Have you tried this feature in AZ ? https://github.com/azkaban/azkaban/issues/442 . What is the advantage of using it for unit test?. Just curious, may you access az web resources by redirecting in other app's configuration ? . Have you figured out why SLA expired ?. Thanks. I see. @suvodeep-pyne . @YuanGunGun It is defined here\nWe welcome and appreciate you having a pull request to make it configurable.. LGTM. . The change looks good to me. @mariacioffi FYI: We just moved the code to azkaban/executor/ExecutionFlowDao.java:270 . Welcome to contributing construct the zip file containing all create sql clauses.. How would you launch the solo server process, through Intellij/Eclipse? \nYou would better run \nligradle installDist\nunder azkaban-solo-server folder.\nThen run it from azkaban-solo-server/build/install/azkaban-solo-server. I was revisiting this PR, but can not figure out how NullPointerException is brought by the exiting code. @wangqiaoshi Could you please give us a concrete example about this bug?. Have you evaluated this change in staging cluster?. #892 re submitted this pull request.. this PR was evaluated in local laptop, and worked.. Closing this PR, as new one is created in #913. Referencing #854.\nEvaluated in Staging server, and it worked.. Waiting for merging #908 , where VIP name is implemented to fetch. Then I could leverage.. I would think we can close it now. @HappyRay @ameyamk Let me know if this PR still has value.. Closing now. This PR will act as a reference if we want to design new log4j pattern in future.. This change makes sense to me. Users need to set SLA options during scheduling.  Have you evaluated these changes @wyukawa ?\n. Not very sure if web server and executor could use the same H2 DB file. do you know? @wyukawa . @wyukawa I usually create a separate folder to put my conf files(mysql information), and specify the folder path as argument when web server process starts. In this case, this change should not help much. I don't know how many people could get benefit by your idea.. Don't understand Why the header being too large blocks you? You should be able to filter, right?. Is the issue still a block? @bleachzk . The PR let us have custom host name given one executor. I'm wondering how could we get port . @chengren311 ELK logs need to differentiate executors by executor_id or port. Besides, I'm seeing that getHost is not a static member. How could other modules know existing host name, like ELK? #906 would like to leverage getHost method here.. I see. Thanks, @chengren311 . One final thing confused me is how to use. All executors share the same configuration, right? how could AZKABAN_SERVER_HOST_NAME apply for an specific executor?. I don't understand what el stand for. what is its full name? @wangqiaoshi. That must be a quite interesting feature if we could have it implemented. Your idea is to let users define custom EL functions, right?. @suvodeep-pyne Could our new DSL parser have similar trait?. @HappyRay All comments were fixed. You might want to take a look again.. Local Evaluation passed.. I checked the recent dbcp common library 2.1.1 They already implemented a default getParentLogger method inside BasicDataSource, so that we don't need to take care of it ourselves. We probably need to upgrade jdbc libraries at some point in future. . @chengren311 Added \"The\" in the following two comments.. Have you checked logs? Is there any interesting observation? @iCoolchar \n@jamiesjc any inputs?. Is this exception seen in all job types, including shell, javaProcess, hadoopJava?. @jamiesjc Thanks, I see. I'm still wondering how shell/command jobs know ${azkaban.job.id}. Is this stored in environment variable?. @duanyixuan I don't understand your question. You want executions every hour even though one execution lasts more than 1 hours?. LGTM.. @lhcg Have you resolved this issue yet? You must define some properties inside plugin/.. Just double check Is this a complete RB to remove project info out of cache? I thought we probably need to modify class project as well. I guess this issue could be closed, as PR was merged.. #955 . I understand this interface is just an LDAP authentication client. You can not add LDAP user through Azkaban.. @dmeijboom You are likely right. I just rebuild the code, found that moment-timezone-with-data-2012-2022.js is fetched, rather than 2010-2020. I will do a PR to fix this problem. For now, please use @ameyamk 's suggestion to send schedules. Thanks.. #979 fixed.. Fixing #975 . How could you make a schedule as 00:00:00? Azkaban can only do 00:00. Second granularity is not supported for now.. @HappyRay Unfortunately this way can not guarantee a file being always copied. I made a quick research. It looks like running nodejs and browser is quite different. In order to detect if we have an exact js file, I guess we probably need to set up browser integration test.. #1021 reimplements this feature.. The change proposal looks much sense to me. I often thought we should have this feature.. @jirislav Thanks a lot for contributing. Merging.. Have you tried enforcing H2 never locking a file and see what happened?\nhttp://stackoverflow.com/a/39075506. Working on Failover evaluation on localhost and staging server Tests.\nAll tests passed.. @suvodeep-pyne We seldom use getDbType method. What's the advantage of using enum instead? Yes! Actually I had a PR to do the merge of azkaban-sql and azkaban-db in #1041 .. I finally removed SQL copy thing in gradle, but directly use sql files path in test code. @suvodeep-pyne . This PR is similar to #1040, which also tries leveraging newly constructed azkaban-db module.. rebased the latest code from master, and re-evaluated. Ready for review.. Hi @prokod @huangfushun , do you use only one executor instance in your AZ cluster setup? In  more general use cases, we have quite a few executors. When we spin up new executors (e.g., deployment), we don't activate them right away when launching executor process. We wrote a script to deactivate old executor and activate new executor at the same time. In that way, we can safely retire old executor and switch on to new executor. Does this make sense to you guys?. We don't update prior to web-server start.\nLet me introduce how we do a regular Executor deployment. Both old webserver and old executor(3.a) are up initially, and old executor is running jobs (we can not interrupt it). Executor Deployment starts:\n\ninstall new Executor (3.b) on our box without activating.\nRun job tests, which targets 3.b and make sure 3.b is working.\nActivate 3.b, and deactivate 3.a. Even though 3.a is deactivated, jobs still keep runnig there.\nDeployment completes.\n\nWe would better run tests against new executor before activating it. Is it a bit clear now?. Closing this due to roll back issue. Reopen this PR at #1110 . @juhoautio You can specify an executor a port by the blow configuration:\nexecutor.port=12321\nMy Mysql always has only one active executor:\nid | host | port | active\n-----| --- |------- | -------------\n1 | localhost | 12321 | 1\n(select * from executors). Will have a TODO comment (using standard SQL statements.) right there to remind us in future.. Any good example how other open source project name modules? I would say I'm already familiar with current namings. . Are you trying to sync code in your own azkaban fork? Please do it there. Thanks.. What's your file size? @chenruiSundun @jessica0530 ?. Thanks for reviewing. Merging.. @suvodeep-pyne ExecutorManager code needs to do a save-action refactor before changing guice. Others in azkaban-common module were all added. Web and Exec Guice refactor will be in a separate PR.. I just realized Jamie should be working on ExecutorManager code, so I'm just adding the annotation on top of this class, but would not refactor.. @suvodeep-pyne @HappyRay updated the PR again. Any more comments?. This is a good proposal. We can't think of the reason why can't we do this.. What's the objective for using tomcat?. @chengren311 It would be rational to check in this code to another branch, rather than master.. PR was updated. @HappyRay @reallocf . Thanks for your review. updated the description. @HappyRay . Just a bit worried if this could be a serious security hole. As long as this session ID is leaked, anyone can use it to do many things.. @iberezovskiy Have you already replicated successfully after this change? Have you run into any issues?. @HappyRay @iberezovskiy Our DBA checked our existing tables. There's a blocker to add the primary key to project_events.\nThe exception thrown:\n\nmysql> alter table project_events add PRIMARY KEY(project_id, event_type, event_time);\nERROR 1062 (23000): Duplicate entry '305-7-1463079491784' for key 'PRIMARY'\n\nLooks like there exists duplicate rows with the primary key combination.. I'm seeing all duplicates happening on EventType.Schedule.\n\n2017/08/18 01:12:19.622 +0000 INFO [ScheduleServlet] [Azkaban] User ..... has scheduled ...\n2017/08/18 01:12:19.622 +0000 INFO [ScheduleServlet] [Azkaban] User ..... has scheduled ...\n\nIs it possible that the user calling schedule api twice at the same time causing this.. I suppose users should be aware of that and don't need it after 30 seconds. Actually, even though it disappears even now, it will show up when the user navigates to another tab page, like history, proejcts. That said, as long as users click something, the message will show up.. LGTM.. Yes, my bad. Besides warnings, some issues like duplicate codes will be eventually fixed in the near future PR.. We can discuss together with @HappyRay . This test is quite flaky, and my mac never complains.. https://github.com/azkaban/azkaban/blob/53f09bb5fab6dd239c7e879f12f081c6c6c95927/azkaban-common/src/main/java/azkaban/jobExecutor/ProcessJob.java#L224-L229\n@lhcg Please check the above code.  The two names, including root and azkaban are blacklisted. You should give another name a try.. @HappyRay PR updated.. The Azkaban email use HTML template, which must not support Chinese Character for now.. @zxhfounder Is this your local setup or production server? What fix I did was trunk execution_flow of execution_jobs table completly so nokilling existing in DB.. I will replace all com.google.Inject.Inject by com.javax.Inject in the next PR.. I haven't. Will update the main doc when having a chance. Does Github provide some TODO list feature?. @HappyRay The new code is designed for unit Testing use only for now. I haven't tested using new code  to create tables when launching actual AZ. I'm planning to extend it if we rely on this in future.. I was considering consolidating the two packages, but am worried about if external users rely on azkaban.database.AzkabanDatabaseSetup. It is quite useful for launching soloserver in an empty Mysql DB today. We may support it in zkaban.db.DatabaseSetup future, then we should be able to retire it completely.. The original database.AzkabanDatabaseSetup should still rely on database.properties. We can remove it after retiring database package completely.. Let me create one issue. The original motivation is that azkaban-db needs to do monitoring, and can not call azkaban-common today. But there are more motivations beyond that. . #1462 \n. @HappyRay That's a very important reminder! What if they still rely on azkaban-common jar? In that way, people will not be able to get the Props. So, should we incorporate az-core classes into azkaban-common jar as a workaround for now?. #1461 . Merging. @HappyRay . @chengren311  Could you please review the sla related change? You should know more than me.. @chengren311 As an example how to new/use a quartz job, you might want to take a look at corresponding tests in this PR. Let me know if you have any questions.. @HappyRay I don't think we necessarily create multiple data source instances. One datasource should be able to manage all connections. Actually, I just realized we only initialize MySQLDataSource once in our code, since DatabaseOperator is set to singleton, and it is the only place to call AzkabanDataSource.\nhttps://github.com/azkaban/azkaban/blob/b4d893fd7fd02fe50c090a1de55e6baf26ee5108/azkaban-db/src/main/java/azkaban/db/DatabaseOperator.java#L37-L38. Updated description.. Does compileOnly introduce required dependency for compileTest?. Hi @armisael Does you team run Hadoop jobs on Azkaban?\nWe recently removed Hadoop from Runtime dependency. azkaban-web-server and azkaban-exec-server should explicitly specify the hadoop class path when they are launched.\nI would believe Guice should provide Dynamic Injection. Let me explore any alternatives.. @armisael I proposed a fix in #1516 . Thanks @reallocf ! JOB_OUTPUT_PROP_FILE and JOB_PROP_FILE usage are very important to my Security work as well. Will probably ask you in future. :). @juhoautio This is a good question. Any insights? @chengren311 . Understand more now, but still don't get the difference between DependencyInstanceConfig and DependencyPluginConfig. Can they be consolidated by one Map?. Sounds good! How about fetchAllSchedules ? . @juhoautio Sounds good. Filter can be an option.. Before merging, want to double check. I tried a search, but it looks like front-end code never calls this ajax method? @juhoautio . Description Updated. Unit Test should not cover HDFS coverage, and I evaluated the generated jar in staging cluster, and it works. @HappyRay . Yes, it should be unit testable. Added another method by providing Hdfs related props to test Hadoop Injections. @HappyRay . #1523 will fix this problem. Thanks.. Thanks for your find and fix. Let me take a look!. My local mac doesn't run into this issue on intellij. I flipped the enable.quartz twice, either true or false, don't run into guice problem. @juhoautio What's your setup?\n==============================================\nGot your thoughts. I should hide quartz during Guice initialization probably. Let me think about this.. You are right. @juhoautio . I will fix the test. Merging now to unblock users.. This PR is just an example how credential provider works. Proposing #1552, which should be merged.. Description Updated. Thanks. @jamiesjc . No that familiar with azkaban-web-start.sh, but have you defined where the web resource is before you start the web server?\nYou need to define the web resource location by\nweb.resource.dir=azkaban-web-server/build/install/azkaban-web-server/web\nin azkaban.properties. Thanks for the finding and fix. I am just about to address this issue. Taking a look. >  our scheduled flows are failing since id key for executor is updated.\nDo your scheduled flows specify a specific executor id? and why?\n@monanik39 . The failure could be many causes. Do you use execute.as.user feature?\nHave you tried running Kerberos manually on your host?\n. Hi @dave-r12 @rschmidtz , we tried but can not reproduce this issue in our laptops. Would you mind run the below command to try a single test?\n./gradlew :azkaban-common:test --tests azkaban.executor.ExecutorDaoTest . The possible cause is the test h2 database was not completely shut down and new jdbc test still can find the tables, for some reason. To unblock your usage, you may run the below command to skip test.\n./gradlew clean build installDist -x test. Thanks @rschmidtz .\nAs gradle output mentioned, \n\nParallel execution with configuration on demand is an incubating feature.\n\nIf all azkaban JDBC tests are running simultaneously, we should run into this issue, reported by the users. The possible fix might be to ignore existing tables in  azkaban.db.DatabaseSetup. @HappyRay I didn't say it is a gradle problem. What I suspected is that tests running simultaneously could cause this issue. Every individual test run looks fine. So I would suggest ignoring table creation if table exists.. @HappyRay we probably do not need a static dependency for DataSource. Today, we create a data source in @BeforeClass method, and it has to be a static variable in my understanding. We might need to change DB test architecture. However, JDBCImplTest dependes on a different H2 database from XXDaoTest uses. We should change it.. I think this is caused by the lately PR: \nhttps://github.com/azkaban/azkaban/pull/1590/files\nYou can set azkaban.max.concurrent.runs.oneflow to allow more concurrent runs. We also would like to understand your use case that why your flow needs to have more than 30 concurrent runs?. yes. May we know why do you need to change it?. Unfortunately still under development.. Hi @vblvbl @ismailsimsek , quartz feature is under development. Are you looking for something new? Why do you want to enable quartz?. The AZ quartz module is still being developed. The UI you see is using a separate Scheduler module, which doesn't use core Quartz scheduler. We haven't figured out the solution to migrate the today's flow schedules to quartz. @ismailsimsek \nYou might just want to keep enabl_quartz disabled. . We can only have DB case sensitive or case insensitive, so we don't have an ideal solution for everyone. No matter which solution we accept, one portion of users are affected. Is it possible that we add a method isDBCaseInsensitive in DataSource interface, so that it enforces a check if DB is case in-sensitive when webserver or executor starts. AZ could display a strking warning in the log if DB is identified to be case sensitive. \nRegarding Synchronization issue in this PR, I don't have strong opinions on the choices. That would be great that we label/comment places where the race condition could happen. It will be greatly beneficial to the future development.. I know that we don't have javascript integration test. How could we make sure the upgraded js binaries working with the latest AZ?. What commit message should this be if we merge it? Could you please elaborate the description a bit? @mtrna . Merged. Thanks for contribution!. Hi @juhoautio , one of the major bottlenecks should be name in table execution_logs, which is the combination and flow name and job name. I believe we should want to maximize name firstly.\nFurthermore, the reason we don't change flow_id is AZ webserver being able to identity too-long-flow name when user uploads the project. Too-long flow_id exception is thrown immediately after we upload the project. I experimented embedded flow case, and same there. However, too long 'job_id' cannot be identified at the beginning. it is only thrown when job starts to run. Therefore, I believe we should pay more attention to en-long job_id firstly, to guarantee uploaded flows running smoothly. \nI understand you use case that you are trying to maximize the embeded_flow length. Unless we enforce AZ users modify mysql server defaults and increase the innodb prefix length, Could you think of more possible solution? @juhoautio \n. This change has been in production for a while. We should merge this change.. @chengren311 We already simplified the flow-id composition format in flow 2.0 Project. The length of new flow-id has been optimized, if users use flow 2.0.. 1). This is a teradata jar, and I cannot find it in central maven.\n2). That sounds a good direction to follow-up. Today we don't have HadoopPig.jar or gobblin.jar. Instead, we only have one jobtype.jar to represent all these plugins. We may consider break up all these code to submodule in future refactors.\n@HappyRay . It might work, but the gradual migration solution should be taken care of carefully. If we move part of code to here, we may rename this package to az-hadoop-jobtype-plugin, and we should immediately remove the migrated code in azkaban-plugins repo, in order to avoid two jars having duplicate classes issue. How does it sound?. I removed teradata related code, including cypto plugin. @HappyRay . That's a good suggestion. Just created an Epic to track. @reallocf Sorry about the late replies. Yes, it would be great that we can have unit tests for servlet methods. Probably, we should set up Servlet testing infrastructure to evaluate all rest endpoitns.. I was trying to rename the whole package from az-jobtype-plugin to az-hadoop-jobtype-plugin.\nI used Intellij's rename-refactor function. For some reason, it didn't work very well.. Are you launching the web server from IDE? Looks like your IDE runtime environment miss google guava jars.. Agree! label this issue to project. please type host localhost, and let me know what it returns.. There must be something wrong with the database connection.  Are you able to see any errors from Mysql Server logs?. How about stop users login and throw the error that notRealRole doesn't exist.. The idea sounds good. Do you also want to render users the full log config flexibility? Some log4j configs example is \n enable log level specified by the user;\n determine which class need to be logged, and which class doesn't\nI think we should provide these support as well. AZ may define a default log4j config, and jobs are able to override part of it.. Why does it need to clean up data triggers short, like every 10 mins? Any specific reasons? Is the database operation expensive?. +1 on what @jh3155 mentioned.\nTable schedule keeps empty. Table Triggers includes all schedule info. @fwantastic Please rebase from the latest upstream master. Will start reviewing it from there. Thanks!. Thanks for the contribution!. Hey @fwantastic , have you tested this feature before?. Yes. It turned out the page still missed execution entires when it is being initialized. I'm able to reproduce the issue in my local solo server.\nPer my understandg , Before {size} is fully loaded, the javascript started to call it. @fwantastic . And Javascript cannot find the value.\nLooks like my fix #1797 doesn't work during the initialization phase as well.. Looks like flowpage.vm already exists the change you mentioned.\nI think I found the issue. We need to add \"page\" parameter in \npage.add(\"size\", getDisplayExecutionPageSize());\nin AbstractAzkabanServlet class. @fwantastic . That is for History Page. Looks like flow page also needs. @fwantastic . Good ask. @jamiesjc \nCreated a task to track. https://github.com/azkaban/azkaban/issues/1843\nIn fact, I'm about to discard the currrent documentation page and propose the new ones alternative. Will do it there.. What is its original intention that running flow needs to fetch the executor info when finalized?. Would you mind pasting some figure example show what's the change like?. Don't fully understand\n\nSeparate test code and production code into separate directories.\n\nWhat's that for?. What's the problems of gradle?. Since trigger service is only applicable to web server, so non-solo server configs should be the same as solo server. @inramana . We had similar issues when the warning banner is pulled down. Thanks for the fix. It looks good to me. This feature could be usefull for a portion of users, but we need to evaluate how many use cases really fall into this category. People today mainly use Azkaban as an interface to run jobs on Hadoop. Except your jobs are highly resource bounded(IO, CPU or Memory), the value of this feature cannot be maximized compare to other more important feature to be designed.. Not really, but we need to invest time to build a new one.. Please remember to remove code from azkaban-plugins accordingly.. Do you mean the original design choice why projects are not deleted. Actually, I cannot think of valid points for that. Projects should be entirely deleted IMO. @HappyRay . Great thanks for your review. @juhoautio . can not see the error screenshot.. That error is commonly seen if the job fails. You should focus on the exception message above.. At linkedin, we use Hadoop DSL to contruct workflows.\nhttps://github.com/linkedin/linkedin-gradle-plugin-for-apache-hadoop/wiki/Hadoop-DSL-Language-Reference. @Lqlsoftware I agree that there's large room to be improved in terms of ad-hoc project modification.. Could you please dive into the details? I'm also curious to learn the which side generates the restriction, Mysql/h2 or java Character settings. @AriesMg . Many thanks for the screenshot and the tentative explanation! It is helpful.  @AriesMg . No failure is identified in my local build.\n```\nlatang at latang-mn2.linkedin.biz in ~/LNKDRepos/azkaban/az-core on git:master \u25cf\n\u2192 ../gradlew clean compileJava\nParallel execution with configuration on demand is an incubating feature.\n\nTask :az-core:compileJava\nNote: Some input files use unchecked or unsafe operations.\nNote: Recompile with -Xlint:unchecked for details.\n``. what advantages could maven provide?. @vladislav-sidorovich Tody AZ exists quite many flaky tests, and coverage is up and down occasionally. When we review PR, we mainly consider the commit's coverage.. That would be great if we could rely on this opportunity to construct the new Executor Manager and new Unite Test solution to make our lives easy.. @jamiesjc's understanding is correct. . Ah, Got you now. That makes sense to me. Let me update the RB. @xkrogen . This jobtype needs to launch gobblin worker during job running phase, and that requiresjobtype.classpath`, that is a necessary setting for Gobblin. @HappyRay . Try change your mysql charater encoding settings.\n\nOn Tue, Feb 19, 2019 at 4:50 PM shengjianjia notifications@github.com\nwrote:\n\n\u5982\u9898\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/2127, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ACwwCkBUIfYPl5Wpqi9PT7JPbSliWcSXks5vPJvsgaJpZM4bELA3\n.\n. Have you checked the execution_logs table setting specifically? In our environment, table encoding could be different from each other.. @HappyRay \nYes. The code logic here might be not correct. \n. @HappyRay Did you indicate that I should state that cleanOlderProjectVersion will remove all version older than a specific version number.\n. fixed.\n. fixed.\n. fixed.\n. fixed\n. Thanks @logiclord ,\n\nDo you have any recommendation to add a variable to Schedule class?\n. Hi @HappyRay , thanks for your suggestion. It's still not clear to me how to implement your thoughts.\n. I believe these code was outdated, and replaced by new commit. Please checkout the new commit change.\nGood point in Explaining minute granularity!\n. What do you mean by binary switch?\n. Good point! Will add comment.\n. As discussed before, azkaban actually retired schedule tables now. We must migrate schedule to trigger when a schedule is created.\n. Thanks for reminder! I just realized BasicTimeChecker class have the same logic for parsing cron Expression. I might use this util function to replace it.\n. Learned new thing!\n. Often saw builder in other open sourced code. What is it specially focused on? Will dig into how it helps.\n. In my memory, never used. Should we discard the setter method?\n. Will investigate how to reduce code redundancy.\n. I believe this method will be called once when a schedule is created. It is intended to have the first Execution time, nextExecTime in code. There exists come potential optimizations in these code. Will have deep look.\n. One is for Trigger Condition, and the other is for Expire Condition. They did look the same.\n. Why cronExpression can not work?\n. Actually, this should not happen. As I already check the legality of cron Expression in Schedule Servlet. \n. fixed.\n. Added two DST handling tests.\n. Added TODO comment in utils's parseCronExpression method.\n. Added. Removed redundant logic, and will look clear now.\n. removed setter method.\n. removed one useless constructor method.\n. Yes. The previous log in current implementation is meaningless, since the current time in this method will be always after the time in Schedule Servelet. We don't need to compare them at all.\n. just found out that I just created last week.\n. fixed.\n. fixed.\n. fixed.\n. fixed.\n. fixed.\n. fixed.\n. fixed.\n. Made a comment here to introduce our plan.\n. @suvodeep-pyne Thanks for your review! I believe we might have this to keep readability. \n. Learned new thing! Let me follow your suggestion.\n. Thanks for review. I agree! Ray has the same concern for this. I will find a change to refactor the code in future.\n. Thanks for point this out. fixed.\n. Per Ray's suggestion, we should be able to switch the old and new schedule page by \"clicking a button\". This file is just a copy of old schedule-panel.js. \n. This file is just a copy of old schedulepanel.vm\n. Thanks for your comments! Yes, I agree that the file is a bit too big. We might refactor it in future.\n. Good Suggestion! It will increase readability.\n. Let me consolidate some logic here. Thanks! \n. Fixed.\n. How can you guarantee that bowerInstall is finished before copying?\n. Fixed by introducing a shared function.\n. Will add unit test after importing mocha + chai.\n. I intended to place it here, in order to let readers know why we need this transition. What do you think?\n. yes. should be removed.\n. Good to learn.\n. Okay!\n. Good to learn!\n. The json is used for downloading mocha and chai whole libraries, which includes complete mocha component, which bowerInstall seems not having.\n. This is good improvement!\n. Good Question! Just googled what is URL encoding. We did have a couple of special characters allowed by Quartz. Let me have a try.\n. @HappyRay , I tested some cron expressions, like 0 23/30 5,7-10 ? * 6#3 . All work.\n. Fixed by replacing by --data-urlencode mode\n. I often see nestedId from fetchExecutions API response. \n\"nodes\" : [ {\n    \"nestedId\" : \"_\",\n    \"in\" : [ \"__a\" ],\n    \"startTime\" : 1474698890218,\n    \"updateTime\" : 1474698890246,\n    \"id\" : \"__b\",\n    \"endTime\" : 1474698890242,\n    \"type\" : \"command\",\n    \"attempt\" : 0,\n    \"status\" : \"SUCCEEDED\"\n  }, {\n    \"nestedId\" : \"___a\",\n    \"startTime\" : 1474698890151,\n    \"updateTime\" : 1474698890219,\n    \"id\" : \"__a\",\n    \"endTime\" : 1474698890188,\n    \"type\" : \"command\",\n    \"attempt\" : 0,\n    \"status\" : \"SUCCEEDED\"\n}]\n. fixed.\n. This json is called by npm_install. Will add a comment inside the json.\n. Fixed. I noticed $buidDir is only recognized by double quote. Single quote can not identify $buildDir, do you know why?\n. Added.\n. Yes. I considered moving copyJS to Distribution Task. I was worried that would make Distribution Task looks Ugly.\n. Just removed.\n. linked\n. Yea, you are right.\n. Commented.\n. Learned new thing!\nActually I believe not. All callers of *messageDialogView are from AZ Internal Frontend code.\n. Googled, and didn't find any benefits for defining variables as const in this case. const was brought by recent ECMAScript. Might not be accepted in all browsers.\n. Good suggestion. Incorporated.\n. I just followed the regularities in this file.\n. This comment needs to be removed or changed.\n. Consider adding an comment to specify what is nativeLibFolder for.\n. When Intellij runs, will this file be enabled? Have you evaluated about this?\n. @suvodeep-pyne Never mind. I thought some azkaban-user.xml file inside repo might be loaded when Intellij runs the main method of az-solo-server. I guessed not now.\n. Static Methods might be more appropriate here.\n. Fixed.\n. Fixed.\n. Fixed.\n. Fixed.\n. One silly question: Why do we need to remove them? Does rpm uninstall being able to remove them?\n. I've no much idea how to modify this version. Just give it a recent number.. Great!\nWill move them to there.. Since the plugin uses slf4j library, we need to have sl4j-log4j library to let slf4j work.. I double checked the code hale metrics library. They didn't implement Functional interface, so we can not use lambda.. Very good suggestion! followed.. I didn't find many common code in startMetrics. Then I just rename them to startWebMetrics and startExecMetrics.. This reporter will be used by test, should not be used in production.. Checked the logic. since METRICS_ENABLE already passed in this function, we should use Error. changed.. Delete it pls.. put it to the right location.. Pls follow intellij's suggestion.. Confused what does the TODO message mean?. we can also directly return new Props ?. Added.. What's the advantage of this change? I can't find many usages of \".jor\".. As long as we documented this parameter, it should be fine I believe.. This is a cool API! just replaced.. Does this thread hung when we do shutdown?. Changed. Thanks @jamiesjc for reminding me adding an extreme test case.. I read the code again, and found that if result == false, the logic stays in while loop. Is that what we want?\n. interested to learn why we need to shutdown, then shutdownnow (sounds redundant). Should we write some messages inside the log?. I'm new to ExecutorService, but the logic in my mind should be like:\nif(executorService.awaitTermination(1, TimeUnit.MINUTES)) \n   print \"shut down completes\"\nelse\n   shutdownnow();\n. May we have some messages inside the error log?. What if DB is dead, are we able to shutdown executor as usual?. I still have a concern here. we have some jobs running over 10 days and never ends. can we shutdown it by calling this function?. I see. Thanks.. Then I'm confused in what cases would we'd better use rest call to shut down an executor?. Thanks for deleting this file. Good to me.. I guess this plugin was proposed by Evan before, and we may retire these code in future, right?. I don't understand why this statement should be removed.. The best practice for me should be written using if else structure.\nIf (props == null) {\n// For default job type, like javaprocess, noop, python.\n} else {\n// For custom plugin type, like hadoop, hive\n}. Another thing is that custom jobtype will still read jobprops defined in azkaban-plugin, right? You might want to emphasize it here in comments. It will resolve people's curiosity why we don't load commonPluginJobProps for custom jobProps.\n. I don't quite understand this statement. Now that node is SUCCEEDED, why we have to disable it?. Why this CANCELLED clause could be removed ? will it be replaced by node.missing?. Thanks a lot for education. Actually I thought cancelled is equal to FAILED_FINISHING.. The cancelled nodes will be still enabled after this unsuccessful execution. It makes sense to me that we should keep the peach color when preparing a new execution.. Does node.missing refer to some  job being left in running or queued state incorrectly? Could you please add some comment in this else block?. Thanks. node.noInitialStatus looks good to me.. not sure whether the change is appropriate. A util class should be more suitable to be put.. @wangqiaoshi if else logic looks redundant. Is it possible that we just move projectLoader.uploadProjectProperty(project, prop) outside of if else logics ?. That information is currently not in a static field, right? I've no idea how could we have it.. I was thinking this class could be supplemented with other custom patterns, and then could be used inside azkaban-server.log as well.. I didn't touch the original file. This file is newly created. using this new class needs conf change as well.. Yea. This change is also a part of refactor. I can't remove the original class directly as Production configurations still need it. Will remove duplicates afterward in a separate commit.. Could you please share more details how ?. I intended to create the switch structure to help more options being added easily in future. Will might have AZ version, AZ port attached to every log message.. I probably need to explain more in the comment here. CommonMetrics will be accessed by both web server and executor. However, webMetrics class can be only seen in web server. That said, web server specific metrics will not show in Executors (I haven't added executor metrics yet). get api stuff should not be shown in executor metrics.. I agree. Will explain details in comments.. don't have good insights about how long will mark take, and might need deep investigation.  we not only wait for markDBConnection, but also wait for dummyReport to collect the changes occurred in codehale metrics. I let DummyReporter collect metrics every 2 milliseconds. it threw the exception if I don't let it sleep.\nWill add more comments.\n. Thanks for finding.. Curious, what does getCanonicalHostName return in this case? VIP name?. Should we check the obtained URL a valid/legal VIP somewhere?  It might be helpful if perl gives a wrong vip name.. @suvodeep-pyne  Should we use eclipse-styles.xml to replace the default linkedin style in Intellij? After installation, it still delivers some warning.. Added.. Leveraged lambda and made this happen.. Done.. Changed.. Done.. I forgot timers! Experimenting.. changed the name to atomicLong. Enum is a common practice to construct singleton. Enum can not be inherited, which is one of  the most important advantages.. Modified.. Added.. Yes. Comments modified.. That was a typo. Changed.. Added. Changed.\n. We should be able to.. what do you mean by \"profile the time\" ?. Is canceled considered failed?. When it is changed to failed, will it cause the failure to be double counted?. There will be a collision when the web server and executor run on the same host.. Does it make sense to report the meter using a longer window than 1 minute given that the rate of flow finishing is low?. Please keep experimental code in your own branch. . Please add an example usage as a comment?\nClarify the usage of this parameter, please. e.g. allow methods that return different types to be used generically?. took?. Increasing the sleep interval is not a good solution. Could you find a better way?. Consider setThreadPool as a name? We don't care the kind of thread pool it uses internally, do we?. This is called after the reporter is started. This can cause NPE.. Comment on thread safety?. Seems that Canceled is an intermediate status between Running and Killed, after launching killing command.. Only consider Failed now.. Changed it to 15minuteRate.. For simplicity, I removed this method, as Idle and Total could represent this method.. Changed.. Moved startReporting after this.. Changed.. Removed.. Added. Created #931 to follow up.. Will improve Testing Strategy in another PR in future.. Updated.. updated.. Yes. I intended to say here that this function, getRunningFlows, should be modified or refactored, in order to get really running flows. Comments revisioned.. Good catch.. The advantage of this strategy is to put all related metrics code in one place, which is convenient for code readers. Also, developers would be able to easily extend metrics component. As we discussed last week, the Mockito Testing will be able to evaluate if any function is called. What if we just test if metrics registration is called.. Good question. I guess we should make something synchronized, in case List or List changes. Yet it can not solve this problem if we mark this supplier function to synchronized, right? That should not help, because RunningFLow or QueuedFlows may vary when we call this supplier function.. Why do you not like the article here? I believe it is necessary.. you missed a </pre>. I'm wondering if this method could be leveraged/called when some severe problem occurs in the executor.. I mean, the executor could kill itself.. Looks like this method is not used any longer? Who will call it ?Should we just remove it? Besides, the method name sounds a bit confused here. We should detect exist here, rather than active, right?. +1. Should be safe to combine.. This name should be specific for OOM, right?. Do we have a way to ignore all DS_Store filed in children folders? I guess this file might exist there.. One thing still confusing me is that There looks duplicate checking logics in Line90 and line 84.\nattempt <= ServerInternals.MEMORY_CHECK_RETRY_LIMIT\nAre they really necessary?. Should we also have a logger.error message here besides an Exception.. This method could be implemented inside azkabanDataSource, rather than implementing twice here.. I found that I also have this folder inside AZ folder. Do you know which azkaban module generate this folder?. Yes. We should do it when we have large extensively tests. For now, we may keep them together.. This is a very good question! We indeed have this risk if we keep the today's MysqlDataSource class structure. Let me investigate some simple fix if possible to resolve this issue. . Good catch.. Will considering how to add test after the code is reviewed to be valid and efficient.. I didn't know that. They are good example of good practice!. I thought dbcp2 might depend on a specific mysql driver. I tried commenting\n// compile('mysql:mysql-connector-java:5.1.28')\nLooks like grade doesn't fetch a MySQL driver automatically. Also Checked dbcp's maven specification, dbcp2 doesn't bring a specified mysql driver. Therefore, this should be a safe change.\nShould we also upgrade mysql driver and common-dbutils in later PR?. @HappyRay I'm only able to find 10.12.1.1 in our internal artifactory. Should we downgrade the version?. Quick question. Don't understand why this class is called AZCommonModule, but all code is storage related?. @HappyRay Checked online resources in google. Even though JDK comes with this jar, Java does not rely on it when being launched. So I come up this work around. What do you think?. Yes. Modified.. Tests are separated.. Should we use another class name? This name causes confusions. License missing.. As part of refactor, should we consider using builder pattern for Trigger Construction?. Why not use for(Map slaOption : flowObj.getList(SLAOPTIONS_PARAM)). Why this variable is called slaOptionObject? is it not a list?. Why do we need this? I believe we have some other logger info messages during inserting.. I would prefer DATASTORAGE over DATABASE regarding naming.. Understand that we need to do version initialization in a separate metho, but can't see the benefits why we need a separate method to have the two steps below. May we also consider using java 8 type annotations, like @NonNull  ?. Don't understand. paranetClassLoader sounds indicating some class in upper level, not this clas?\n. Looks like this class should not be called outside the its current package. Should we consider remove public?. I'm seeing that ExecutorServlet calls this method. Should we inject executorLoader there in near future?. DatabaseOperator sounds good to me. changing.. Thanks for suggestions.. We don't support other databases for now.. Yes.. Multiple statements are supported by DatabaseTranOperator.. This is a very good question. As we are able to control retry logics. we might have different retry strategies during implementation. Today, we enforce using DBUtils to do queries. We might consider unlock the restriction to allow alternative JDBC libraries.. It could be useful when we print out a datasource's name.. This style was recommended by intellij for some reason. Just googled. every line of comment should start by *.\nModified.. How it transform to one line? No idea about this.. :). good catch!. If something wrong happens, I will return -1 rather than throws an exception. The advantage is the caller doesn't need to deal with exception inside code.. Yes, we could have multiple DatabaseOperator Implementations.. Changed.. One issue is that we don't have db, table name things inside this method. In the upper level, caller will do logger.error again, which is able to log what goes wrong.. Good catch! Added todo tags. We could inject props to MySQLDataSource class. However, props is in azkaban-common now, could not be fetched inside azkaban-db.. Can' we put this method to config as well?. Will we also use hive/Dali ?. How metastore help us?. I believe, in this case, you should explicitly call DBUtils.close(connection) here. Otherwise, you could call createQueryRunner(), then you don't need to worry about conn.commit, and conn.close. In future, we will use DatabaseOperator to replace.. Why last method has multiple line method signature, but this one does not.. I think DBUtils.close should be called here as well.. Should addProjectVersion eventually be placed inside storage.put, right?. Good catch! fixed.. Good catch. fixed.. updated. updated. updated.. modified.. At the newly added test, I use in-memory db constructing AZ db tables, in order to fix out-dated tests. Those scripts have to be available in the module azkaban-common, so I made a copy.. You're right! Fixing.. fixed.. Yes. I clarified this in the comment.. DatabaseTransOperator is designed as an supplement of {@link DatabaseOperator}, which do commit at the end of every query. Given this interface, users/callers (implementation code) should decide where to {@link Connection#commit()}based on their requirements.\n\nThe diff between DatabaseTransOperator and DatabaseOperator:\n\n\nAuto commit and Auto close connection are enforced in DatabaseOperator, but not enabled in DatabaseTransOperator.\n\n\n\n\nWe usually group a couple of sql operations which need the same connection into DatabaseTransOperator.. curious do we have an API to fetch an inactive flow?. Consider adding a comment to explain what does \"active\" mean?. Does this comment mean some inactive executor with running flows?. Consider refactor this method name to getRunnableFlows to reduce confusion?. Consider refactoring this name to getAllRunnableFlows?. Looks like fetchNumExecutableFlows never bean used. Shall we remove it?. Just curious: do you know which server updates table active_executing_flows, web server or exeuctor, or both?. Good Catch. Removing.. Um.. My intellij doesn't allow me to point to the caller.. The test looks great.. My intellij reports another method fetchJobInfoAttempts, which also looks like never used.. This looks a bit strange. Haven't seen anywhere calling azkaban.use.multiple.executors?. Just would like double check this library is in our artifactory, right?. Is going to be a future convention for juice usage in Azkaban? Every class calls AzkabanCommonModuleConfig ?. We don't need to bind .class when we move this out?. Yes, this is new code.. I tried Inject this constructor, but didn't work. I believe Executor Manager still can not be imported by guice now. @suvodeep-pyne . loggedInUser here is azkaban, or specific user?. Looks like this guys is null initially, and then have a concrete value later?. if authrorize failed, it will continue running?. where is this file sample_flow_01.zip? Is it stored inside Az project code?. I just realized this is a runtime Exception.. Oops. Actually I'm refactoring this class. Eventually I will use another class (JdbcProjectImpl) to replace this class. Of course, you can still use this. But I would probably change AzkabanCommonModule to allow JdbcProjectImpl to be the only one implmentation of Projectloader.. Why can't we do setSubmitUser also?. Is it a good practice to have some requreNonNull check here to guarantee building process doesn't miss some important parameters? . should be 2017.. never used.. License missing..  Would FetchRecentlyFinishedFlowsHandler be a better name? though I know the handler classes in this file don't have this convention. What do you think?. Good test strategy!. Is Java smart enough to know the generic type here? Never knew this.. A bit confused what this comment want to tell readers? Should it be \"Execution_flows table should index end_time\". Thanks for your review. Do you have any good idea what name could be better here? @chengren311 . This comment was intended for previous commit. I would remove out of here. . I would believe 01/01/2050 could be regarded as never-expire schedule.. I know this is hacky. This hack is intended for distinguishing existing schedules (created before the release of this PR). In other words, I don't need this hack if AZ doesn't have any schedule today.\nBecuase existing triggers have the triggerCondition same as expireCondition, we need to tell the difference by this thack.. There exists pros and cons regarding this change.. Added. removed.. Why do we need to break here? The logics here is confusing, and I added a todo comment to clarify.. consolidated.. * I don't see UI change in this PR. WIll there be a separate one? \n\n\nI am confused why id could be checked here? Since Line 207 also check id,. new end line. Should flowRunnerManager be initialized in the body of constructor?. Looks like this method is never used. thoughts?. looks like never used.\n. Don't understand why the current AZ misses this remove, and still works.. You check two statuses here. One is Killed, the other is isKilledBySLA. Which one does it usually go firstly? What if we miss one round of progressGraph. What will happen?. Have you considered adding a * in front of every entry, Since this is a list.. @chengren311 I got your point, but I can't see too much difference on this change. Since this code is already in production, I would like not to change this number. . Great Explanation!. Not sure if this is a good practice. If me, I would have a CommonMetrics's instance in the Constructor of ProcessJob. Basically, I don't know the performance/efficiency of using SERVICE_PROVIDER.getInstance. Sort of believe We should put MetricManager in constructor parameter given this case.. Sort of believe We should have MetricManager in parameter given this case.\n. Yeah, probably.. +1.. We probably need to move this statement (metrics = SERV...) into separate tests, since we are testing itself specifically.. I just replaced this line by this.registry = SERVICE_PROVIDER.getInstance(MetricRegistry.class); and didn't observe any issues. What did you see if you use Serivce_provider ?. I was trying to google the difference between using @provide and to bind, but failed. Some online resources say that there'w no difference between the two approaches. I believe @suvodeep-pyne has better understanding on this case.. Is there some way that we could consolidate the code that set up an Executor Manager, but that could be a follow-up pull request.. Could these dependencies be declared in a json file?. In my standard practice experience, dependencies are usually put in json file, like azkaban-web-server/package.json  If everybody is OK, I'm good with this.. Do you mean not enabling rollback by default? @HappyRay . Does this number matter much? I remember the exception message like can not connect... How long does AZ find a SMTP connection if SMTP server is not reached? 30s * 3, 90s?. Good Catch! Changing.. I searched and recalled that this method has to be used in my test. So I didn't remove it.. Are we migrating to slf4j recently? I'm not aware of that.. +1 on moving static method to here. We could modify the comment following the actual method below getFifteenMinuteRate. Console Reporter was intended to help debug metric related code, even though we haven't tried it yet.. I was also thinking if metrics test could use it, but so far looks like it is not valued. . I'm wondering why we use a nested config here.  Why not just put command: at the same level of type: ?. Do we store yml file to database? as part of zip package?\n\nIn other words, when AZ loads the yml file, where will it be stored?. Have you considered the updating properties cases? People update properties in AZ web UI, and its yml file should be updated as well?. I remember @chengren311 was proposing some condition flow check. Is it easy for him to extend on this yml file?. The reason is that props is a local variable, and can only be seen in AbstractAzkabanServlet.. Thanks for find. Changing.. Sounds a not bad idea, but it is difficult to do at today's codebase, since Executor still exists in common module.. That's a good suggestion. I am constructing a static assert singleton method in common Test module, such that everybody could call this.. May I know what is another assertion specifically? @HappyRay . @HappyRay Just updated the code by using AssertJ.. I just remember what I wanted to ask. What if the node killed, but have not been initilized killedBySLA true. Could this happen?. needs a new line. updated.. This code is outdated in commt1.. I'm revisiting this design. I was thinking if we should have requireNonNull to wrap commonMetrics. However, if we do that way, other program (external MP) can not use Emailer easily. I'm thinking if we could let contructor doesn't include the commonMetrics? Does it make sense?. Why not use Guice?. Should we iniatialize guice @before any test, so that we can use Guice to get ExecutorManager?. I just realized I directly use the class EmailMessage, rather than Emailer. It is safe to have Metrics in the constructor.. Should CommonMetrics be placed as a private member as it doesn't change? Just a minor comment. Either way works.. In future refactor, I think we can have a setup method to have all properties. When some @Test doesn't need, we can do props.delete().. Good catch! Fixing.. 1). If me, I would not clean up this method, though Intellij can not identify its caller.\n2). There are quite a few methods below like getMailHost, which are also never called up. I would clean them together in future.. You are right!. typo: session.. Good catch! already removed.. not necessary. Either method looks working.. You are probably right. will evaluate if we should do exception. Sounds a better idea. Documented at #1337  to track.. I was still actively testing this feature. Should be a very big number when eventually enabling this feature.. documented at #1337 to track.. Looks like this pid is for Web server? Is that necessary to monitor? I believe executors' pid even deserves being monitored.. I don't see where df is used?. This issue is documented at #1337 to track.. This issue is documented at #1337 to track.. Synced up offline. When SQL exception occurs, the SQLexception will print the compelte sql query to track.. Synced up offline. When SQL exception occurs, the SQLexception will print the compelte sql query to track.. Synced up offline. When SQL exception occurs, the SQLexception will print the compelte sql query to track.\n. Just some random number should be fine.. Comments were added in #1040 . Thanks.. Right. I already made it as single line.. Rigjt. I removed useless comments out of Impl class.. Yes, you are right. The essential part of the transaction is to use a single connection to do multiple things at one time. For instance, if we use transaction to insert1, update2, delete3. When exception occurs to delete3, we should verify insert1 didn't evenly happen since rollback works at the connection level. Documented at #1337 to track.. I already rewrote this introductory comments in #1040 .. Good catch! I will use the existing method.. Actually, it should be never used. Removing this exception.. Since this class extends java.io.Serializable, it is recommended to explicitly declare serialVersionUID values, since the default serialVersionUID computation is highly sensitive to class details that may vary depending on compiler implementations, and can thus result in unexpected InvalidClassExceptions during deserialization.\nFrom: link. Yes! You are right! modifying.. Good suggestion. Adding.. Looks like cleanOlderProjectVersion implementation reset project_versions to 0 regarding satisfied rows. However, I don't understand why the previous authors do t his. I agree on your solution. Why not just change cleanOlderProjectVersion implementation?. Just thought of a concern. When upload fails due to Mysql error or HDFS problem, should we clean up the latest failed zip?. we remove old ones but keep latest ones, right?. Due to some legacy reasons, the current project_version table might be messy. It does not correspond what you observe in project_files table. For instance, project az_test might only have one entry in project_files, but it has too many entries in project_versions. Have you considered that? Not very sure about that because we changed schema by bringing resouce_id, but we need to be careful about this.. Good suggestion! Adding.. I added a TODO comment to fix this.. That's a good suggestion. I was considering using this name, but I didn't adopt it as I thought we don't have explicit Executor class, which sounded necessary for a DAO pattern to me. Now that there's no objection, I can rename it to DAO. Likely we could add and use Executor Class in future refactor.. Modifying.. Good finding! I also noticed just now and am modifying.. Yes. I agree! I planned to do the refactor.. Yes, you are right!. Yes, you are right!. No, I was actually testing only one class, but need two class dependencies in test.. This class JdbcExecutorLoaderTest is going to be deprecated. . I didn't know we should also use logger for test, Any benefits? @suvodeep-pyne . Merging this now. If necessary, I can do a separate PR to fix this.. Great Catch! fixed and added a comment.. Great Catch! fixed and added a comment.. Based on this article, testJar can wrap the test.outputs to a jar format, then hide details.. Resolved the comments by adding suggested thing.. Good suggestion!. I should be using Google Style. I just checked the details of the style. It should align multiline of parameters when method declaration parameter is too long. We may check together to make sure google style is working.. retry attempt starts from 0. Isn't correct?. This is a very good concern. I haven't thought about this much. The simple and straightforward solution to report retry Attempt count. If this number is too high, we should get alerted. . Based on the current design, we will never run out of retries due to retry maximum limit is extremely high. We can start from this, and think about what we can do if retry number reaches a threshold. . Good catch.. * Did you mean createDataSource() is synchronized as well? The benefit of this design can be easily observed in the failover test. When multiple threads are trying to getConnection during DB failover, only one thread keep retrying. It made log very clear. \n\nYou are likely right. Let me remove the throw Exception signature.. The parent class method signature has SQLException. Then we should keep it. I guess createDataSource().getConnection() might throw Exception.. After thinking, we can remove synchronized and give a try to guarantee normal cases performance.. Thanks. Let me fix this.. @juhoautio You might want to refer to #1428 .. Do we have name conventions?. Thanks for finding! I can not see much difference since we will never reach MAX_DB_RETRY_COUNT. IMO, it should not be a big deal. +1 on h2. I would believe h2 is more suitable in this case.. Now that we don't specify and use mail configs in solo server, should we just remove the 4 lines of email parameters.. Today executor will generate a random port, right? How this line can help?. why not just return it directly?. Will we check in additional code in this gradle sub project?. Should this constant name as AZKABAN_FLOW_VERSION rather than AZKABAN_FLOW_VERSION_2_0?. I guess this might be necessary for migration purpose.. Yes, I'm using save plugin.. Good find. I was adopting Intellij's suggestion from previous code, and not carefully checking that.. Thanks. Just added.. Yes, you should be right if we use this class for table create automation in production. This class is used for unit test only for now. We need to fix some reliability issues if we rely on this class to create tables when launching AZ in future. Updated java doc.. Modified.. Sounds a fair suggestion. Changing.. Should be right.. Yes, I know that, but I would think we should a separate line for this.. Modified as suggested. @HappyRay . Good find!. Yes. Thanks to Guice, we don't need to actually new a class. How powerful Guice is!. Can Eclipse support Azkaban code afterward? Some folks might work with Eclipse.. Should ExecutionsTestUtil and TestUtils have methods similar? should they be merged in some way?. Good Catch! Looks like this has been failing for a long time.. Is the message too long to be displayed ?. I didn't check out the screenshot. Looks good. +1 on the long message for detailed explanation. Otherwise, users should not understand what does FAILED_SUCCEEDED mean. I often got confused, too.. +1 on Unit Test! You might need to create a test file under az-core module, as we don't have one.. why do we need a long name? I like azkaban.enable_quartz.. these tables originally reside in one file together. I would believe we should not manage/modify these sql statements after those tables are built, as we should not change quartz code, right? In this way, why not just have a big file, which just serves as a reference to users.. This is a not test, right? Is SampleQuartzJob a good name?. I can not think of situations where we will change quartz SQL statements. Do I miss something?. Based on what I understand, your fix in flow-execute-dialog.js seems to fix the flow parameter display issue in #1481. I'm wondering what this change is for. Does Job property Editing have similar issue?. Hi @armisael , I'm not very familiar with jQuery usage here. What's the difference between evt.target and evt.currentTarget ? \nAnd this looks like not a bug, as the previous authors designed this behavior to clear out text when the user clicks the \"INPUT\".. Thanks! Please fill in some description in the description panel, which will serve as the commit message.. Um, I tried but failed to reproduce the job editing bug. What scenario will generate this issue?. be able to reproduce! Thanks for repairing! Could you please fill in some description for this PR? Then we are good to merge.. Got it. Thanks for fixing.. Mysql dataSource cannot be verified here, since Guice only have h2 Props, which has conflicts against Mysql Props.. This should be a typo. Adding back.. I found that CastException seems more appropriate. Updated. Wrote some java doc on top of it.. Updated.. What do you mean by breaking database setup code? I believe new DatabaseSetup should be able to deal with both the two cases: 1. Sql folders; 2. one Sql file.. Upgrade Quartz? Yes, that's quite possible.. Should this property be put under JobProperties class. Also, you might want to use azkaban.job.other_hcat_clusters. What if the string has some format error? What will happen? Like \nthrift:hcat1:port;thrift:hcat2:port. Is there any assertFalse cases?. Or, is other_hcat_clusters an existing configuration now?. Have you considered using Guice Proveder to create FlowLoader at AzkabanCommonModule? What're pros/cons?. Can we use protected modifier?. Why it is named by testLoadYamlFileFromDirectory ? Does it mean it will include all .flow files in the directory?. Good suggestion. Adding. What's the benefits over that approach?. Adding public modifier here. I will add a shut down hook with web server stop.. added.. explained in a comment.. Seems that shutdown doesn't need to getScheduler. For now, this method is never called by anyone.. Moving to prepareAndStartServer(). I'm seeing the method getWorkingDirectory requires a public modifier, but protected should be good enough.. I see!. +1 on this.. I was considering this question where we should put installModule, but can not find a good approach. First off, install module cannot be put under AzkabanServer class when injector is initialized, because Guice.createInjector can not optionally install a module. The second alternative location is inside configure method in AzkabanCommonModule. It will incur duplicate code to resolve storage type, which is same logic inside the method resolveStorageClassType. The final alternative is just here. Only when we provide HDFSStorage class, we install this module. I have some idea how to refactor HDFSStorage bindings, but it will result in a big code change, and we can do it in future.. Why these java doc lines are short compared to other interfaces.. Can we use azkaban/utils/Props.java#size Rather than toProperties?. Seems node.getEndTime() is not a necessary test, because we verify the endtime must be larger than start time.. Curious what does 9_000L mean? it doesn't look like a number.. Great Testing!. The ideal test should test out if runtime needs to resolve hadoop jars, but it cannot be straightforwardly tested. One reason is that Hadoop dependency is imported in CompileTest. However, this test can guarantee that Hadoop module is not installed, so I think it has values.. Nice.. In our Contribution guide, developers are recommended to use assertJ. \nhttps://github.com/azkaban/azkaban/blob/master/CONTRIBUTING.md. When parsing yaml runs into any issue, it looks like nodes are identified anyhow. What's the intention behind this behavior?. If I were to write this test, I would write a common assert method to consolidate all similar check statements.. Question: I'm seeing there exist a few common variables in class DirectoryYamlFlowLoader and class DirectoryFlowLoader, why not make FlowLoader an Abstract class rather than Interface?. My previous suggestion was to consolidate these duplicate code since you always need to test loader.getFlowMap().size() in every @test method. Also, flow.getNodes().size(), flow.getErrors().size().  So, why not consolidate them into one method with a number of arguments.. Those are format changes automatically forced by Intellij save-action plugin. CredentialProvider sounds better. Thanks.. I was considering to have Credentials (e.g. hadoop.Crednetials) as an explicit parameter. I think we might provide more APIs rather than register here later on. We could write the API to get token/credentials from this interface. In that case, may we consider add the object when we do constructor?. Will projectVersion always change when we upload a new zip?. If the project has two ymls. If one yml changes, will only one flowVersion change?. Can we have the same argument order as getUploadedFlowFile?. What will happen when a user submits a right size zip after a too big zip failure? Will flowVersion increase one? Have you considered moving the logic at the beginning of uploading yml logic, like before launching database operations?. why we don't throw exception here?. We should double check on this.. I remember we have a method with the same name in test module. May we change the method name there, like createTestExecutableFlow?\n\nazkaban.utils.TestUtils#createExecutableFlow. Discussed offline. We can remain it to be 128 as same as flow_id in other tables.. Good. Didn't see the throw key word.. nit: This can be made short by project.getFlows().forEach(). No, this will be configured under jobtype/commonprivate.properties.. corrected!. The key name and ServletUtil class name doesn't match perfectly. I would believe VmUtils class name would be appropriate in this case, since this helper class is not used in a Servlet.. Nit: In fact, if we use build pattern, we don't need to explicitly call this method with \"set{blabla}\", because almost every method other than build should be called set.. Good consolidation. You are right! Modifying.. Why not use AtomicInteger?. In my view, synchronized (this) should be too aggressive, because it locks out the whole object? . Do you mean there still exist possibilities that writing log to db would fail due to race condition?. Makes sense. Thanks for your contribution!. Is this job Prop? Can we detail the name as jobProp?. Why necessary to new here? . Is this overrideProp still for Job? Can we override Flow Properties in the long run?. What cause you to change the method name? To me, loadPropsFromYaml sounds good enough.. 1). Don't understand why we need to create a temp folder to do these things. \n2). Can we find a way to merge the two try-catch to reduce redundant code?. Just another way to handle: checkArgument(flow != null && flowFile.exists());. I studied this class TypeMapWrapper, and it is used for metadata wrapping. Java Generics is not necessary, as AZ always initialize a  instance. We may refactor it in future.. Made it configurable. 30 might hight, but we may set a high number initially, and decrease it gradually, in case break something.. Done.. We have to fix it again at the same time next year. Should we use a high number replacement? like \"0 0 3 ? * * 2022\".. Added a static variable to place the default number.\nChecking number validity. we may bring up a util function to cover all similar cases. Should refactor in future.. Fixed it!. 2018 has taken effect.. This just reminds me that did we consider publishing Trigger events to Azkaban Project Events page?. Might not follow your intention in this test case. What do you want to verify here?. The two lines can be merged into one.. mark this to public,. make it to public please.. don't understand this part. Please add a readme as an instruction for the implementation development.. I would believe az web server modules needs this test dependency if you write its implementations in the test.. What's the diff between Check1 and Check2? Should we use a more concrete name?. * I don't think we need a jar here. You might want to investigate an approach to not check in jar this way.. It should be 2018, right?. I'm seeing this variable List<TriggerInstance> runningTriggers exist in this class. In the long run, AZ web server will be stateless, so state should be removed eventually. For now, It might be ok to stay with this approach. Please come up with the solution to address it. . Is it possible to check if the scheduler is running or not here in the constructor.. We should not need to start or shutdown here.\nAfter sync-up, I still believe we should keep the original Quartz Scheduler a separate module. You don't need to handle start or shutdown API, which should be handled by AZ webserver, rather than plugin. Besides, this class might call APIs like Pause or checkExists, which should be QuartzScheduler's responsibility. This class should just call its API. It will be hard to evolve or enhance QuartzScheduler if we go this direction.. That's good Todo list!. Why don't we throw exception here. she ?. stateless means more than one AZ webservers will serve web requests, and each server should not contain states internally. Could you think of any solution?. Why does this class need to be Serializable?. I should have remembered. Does this QuartzJob run gobally only once or every flow trigger (called by user zip) will execute once?. new line needed.. should this move to the removeProject try catch block?\nAnother question. Do we remove normal schedule today when removing a project?. why this method is called scheduleAll ?. Don't understand what does this part of code do?. Wondering if it is possible to add a parameter in this API, because jobname is also necessary to locate a quartz Job. Would suggest we should do the change ASAP before flow trigger is in production. . This should not be called Flow Trigger. FlowTrigger should has its own flowTrigger job name, for instance, \"flowtrigger\". Shouldn't the error message be Error while looking for flow Trigger?. Is it possible that it is normal that this flow doesn't have flow trigger? Would it be an error given this case? Don't understand what the error message mean here?. Good Test strategy!. Is there a button for click to jump to the page?. 2018. Never used?. 2018. This tag looks being used by many other pages, like flowpage, jobdetailpage. Have you checked that everywhere is fine?. Good catch! I removed the for loop and only look for the constructor accepting three parameters.. Yes, it is feasible. See my second commit.. Synced up offline. I agree. We may convert quartz properties in Guice Module code.\nAdding a todo here for reminder.. So both mysql and h2 are verified that this query can work?. Is flowname also in-sensive today in mysql database?. This place doesn't need a parenthesis. . What could be the full value like given this key. Any examples? @jamiesjc \nIs this a resource manager link or a job log link?\nWhy not call it YARN at least? It should be more straightforward. In my understanding, it should be a Yarn Job Link.. Can this method move to a util place, and this API can be used by other features in future? . Hi @sthbig , I believe we have this check when job starts to run. What's the advantage having this check here?. The velocity embedding would be the only advantage of velocity that I could think of . Interested to learn why does ScheduledFlowTrigger object need project name? If not, you don't need to inject project object, I believe.. Great Test strategy to fix long wait.. Looks like we can use the same strategy to fix the Thread.sleep issue in \nhttps://github.com/azkaban/azkaban/blob/d0d63361ca9def7190823a754b28b7dc5d9a980c/azkaban-web-server/src/test/java/azkaban/scheduler/QuartzSchedulerTest.java#L133\n. I'd like the solution in \nhttps://github.com/mariacioffi/azkaban/blob/97a601ef2e3ac818bfcadd91159a1ae0b1122acc/azkaban-common/src/main/java/azkaban/executor/JdbcExecutorLoader.java#L1393\nWe should have ef followed by execution_flows immediately.. We are following the new standard that job properties should be placed here:\nhttps://github.com/azkaban/azkaban/blob/bb24a72373567e2d42a02879f9636efd2b886503/az-core/src/main/java/azkaban/Constants.java#L237-L240. year. Do you want to have an ascending or descending sort by time, based on the value of sortOnStartTimeDesc? Could you come up a better name?. or execution id?. I removed it.. Yes!. Added.. Good catch! removed the duplicate.. In the class DefaultMailCreatorTest,\nhttps://github.com/azkaban/azkaban/blob/c75ea9beaea61ef3d92a2948b0d16834e078fb1f/azkaban-common/src/test/java/azkaban/executor/mail/DefaultMailCreatorTest.java#L53\nShould we also change DataTimeUtils back when that test finishes?. Thanks for checking!. Do you have any sort of integration test suite? How would it affect the evaluation time length after this change?. Based on https://stackoverflow.com/a/18398829, we should name groupName as \"flowTrigger\", and jobName to be \"project_name+flow_name\".. Synced offline. We should also have a \"pause\" button inside Project Flow page.. Please also check if \"flowID\" is valid or not.. format issue. \"else\" should be placed in the line above. May we detail the logger message a lit  like\n\nerror in registering flow trigger  in Quartz,. As we decided to let groupname denote project.flow inside a Quartz Schedule. May we document the standard somewhere inside the Quartz Class?\n\n. The exception also needs to be modified a bit.. The exception also needs to be modified a bit.. Is the comment not finished?. Is sampleCircularNodes referring to circular results given a DAG? Why is it called sample ?. should we use System.err ?. What I want to point out is \n\nThe algorithm is described in\n\nThe \"where\" is not defined.. When service submits the sleep job, it will continue running the rest of the code?. Will there be any random errors if we write this way. What my understanding is that some methods to be validated in the unit test needs this annotation. However, getExecutorService itself should not need a test. Am I wrong?. Just one more question. Where will you call the method? I don't see any callers.. 11ms in your local machine or Travis? Any idea what could make the difference?. 30_000 sounds too long here. What if the shutdown method fail? Will it take 30 seconds to fail this particular test? I'd like this combination: Thread.sleep(5000) and islessThan(1000).\nIf JVM can not interrupt the sleep thread within 1s, there must be something seriously wrong.\n. This is old code. Let's change the copyright when we do refactors or format changes to these legacy codes.. Is two for-loop a duplicate? if me, I would use one for loop to walk through all the potential files.. Where do you check duplicate project file?. The comment should on the top of real configuration.. May we add a comment here to explain what cases should go into the else block?. How is the thread-safe guaranteed compared to HashSet?. I'd like to learn which part of code need the thread-safe data structure, activeExecutors? Would you mind point it out?. The corresponding plugin doc is referenced.. Do we only have Prop_In and Prop_Out files given a job? Is jobName_Props_tmp is the naming template we currently follow. why is called \"_tmp\"? Is it possible that we can change its naming template?. Should we include a successful-run test?. don't quite understand this comment. Do you want to say \"Some Cron Expressions possibly do not have follow-up occurrences\"?. Why the name followed up with _tmp?. I see. Thanks for the explanation.. Yes, please @fwantastic . After that, will ship it.. Please add a TODO: Today solo mode doesn't call setExecutorActive. We need to fix it.. Maybe add a comment to show what pattern should be correct, and what are wrong.. What if the condition is null? Should we handle the edge case?. Assume every node have a parent flow? What does the code do here?. Today LRU cache cannot work immediately on delete, because there's always a hardlink from execution to project directory.\nPlease add a todo comment to describe the current the situation. . Have we considerred using localStorage? What's disadvantages of it over sessionStorage?. Should we use \"false\" rather than null, for better expression?. I see clearnning is enforced when button is submitted or clearred. So what's disadvantages of persisting the data across all tabs?. I removed those highlights with intention, because I found it is not necessary. What do you think?. Good catch! WIll fix\n. Figure is just added.. change all the rubric to appropriate headling format.. When do you plan to release conditional workflow docs?. the naming should be called like projVersion, not version. A quick question. will this method be used by Spark job? If not, we may not use public for that? Also, that would be great if we can have some basic tests for this method.. Should we use UTF-8 instead of default character setting?. Good found! Let me fix it.. updated!\n. Isn't it too large for default solo server?. This should be removed, right?. We may don't need to introduce public here? package-access is good enough?. Why it introduces an extra blank line?. Just a quick typo fix: parentheses need a space ahead.. We may want to highlight with a comment. Because users easily write semi-colon and make mistakes, so we ignore any semi-colons?. Looks like we don't need to bind this class to an object in a guice module?. Is there a reason why we wipe out private declaration?. Do you want to review this again? @xkrogen . Have limited knowledge of chai testing. Looks like this script can only test against HTTP status code? what does version change mean here? Is it able to catch any js or css library break?. I'm trying to understand why the exception should be caught in this block. Any particular reason?. Just a Question. Did we consider moving this synchronized block to the downstream functions calls, like finalizeFlow? What's the reason to keep the synchronized call here?. Suprised to see finalizeFlow doesn't have concurrency protection originally. Is it necessary to add it?. ",
    "dwhu": "+1. ",
    "adfel70": "+1. Yes, that definitely helps. Thanks :). ",
    "khellan": "zip files don't keep permissions so Azkaban can't fix this.\n. I second the tar request. That being said, it's not more difficult than explicitly executing your script with bash so this is just a convenience request anyway.\n. ",
    "climberbrad": "I ran into this problem AND this post and solved it by adding this to my .job file:\ntype=command\ncommand=chmod 777 my_script.sh\ncommand.1=./my_script.sh\n. ",
    "radimk": "The workaround with chmod is not really a solution: it doesn't work if you use \"user.to.proxy\" and the script is just a link to a real place where it exists.\n. Also khellan's comment about zip not keeping permissions is not correct. It works properly on any recent Linux distribution so the problem in on Azkaban side.\n. I'd really like to see permission support for Zip files. Would it be acceptable to submit a patch adding dependency on http://commons.apache.org/proper/commons-compress/ where this is solved? Or should we create a PR re-implementing their solution?\n. Same here: using Azkaban 3.0.0 with plugin I see this exception caused by missing property value for key hadoop-inject.azkaban.link.execution.url. It seems there is some missing configuration step that break these plugins (hadoopJava, hive). It helped when I added to $AZKABAN_EXEC_SERVER_HOME/conf/azkaban.properties azkaban.webserver.url=https\\://azkaban.domain.name.com\\:8443\n. ",
    "hluu": "Can you attach some sample log statements?\n. BTW, what version of Azkaban are you using? This is was fixed in 2.6.x.  Can you try the latest version?\n. The fix has been merged\n. The fix has been merged\n. Like the notes that you captured at the provided URL.\n. Can we close this issue yet?\n. Looks good David.\nThanks for doing this.\n. Just curious, what is in azkaban-migration?\n. Other than the two questions I have, everything looks good.\nThanks for doing this.\n. Thanks for doing this.\nLet's get them in and then we will enable the remaining tests.\nLGTM\n. Please merge this pull request, or should I do it?\n. executor.flow.threads=500 - are you planning to support that many concurrent flows in one Azkaban instance? It seems very high.\n. This is more of a convenience than anything else.  If we ever send a curl request to the exec server  to retrieve JMX bean attributes, then the attributes will be displayed in alphabetical order.\n. Is everyone OK with me merging this pull request?\n. LGTM\n. LGTM and thanks for doing this.\n. LGTM\n. Added the check for the sum of all the sizes of all attachments.\n. LGTM\n. LGTM\n. Thanks for fixing this.\n. LGTM.  Do we need any more tests to verify the enhancement?\n. LGTM.  Tested\n. Let's try to get this merge by today so I can build for magic maintenance tomorrow.\n. LGTM\n. LGTM\n. I believe this issue is fixed with this pull request - https://github.com/azkaban/azkaban/pull/332\n. Hi Haidar,\nAzkaban has a job type called \"command\", which allows you to run arbitrary command.\nSee here for more info - http://azkaban.github.io/azkaban/docs/2.5/#command-type\n. LGTM.  Can you add some documentation (somewhere) on how to enable/disable the metrics?\n. LGTM\n. LGTM\n. Thanks for adding this Anthony.\n. Thanks for fixing the typo.\n. LGTM\n. LGTM\n. Are you waiting for any particular features?\n. We are in the middle of the integration testing of the multi-executor\nenhancement.\nWe've been making enhancements to 2.6 and will release 2.7 shortly (next\nweek)\nNate, can you share your wish list?\nOn Fri, Sep 18, 2015 at 3:12 PM, David Z. Chen notifications@github.com\nwrote:\n\nSorry for the lack of clarify regarding the roadmap. I am no longer\nworking at LinkedIn and have been emeritus for the past year or so. It is\ngreat to see so much interest in Azkaban, and as a result, I would like to\nresume my efforts in helping maintain this project.\nI see that @hluu https://github.com/hluu has written a proposal for\nimproving scalability with multiple executors in #439\nhttps://github.com/azkaban/azkaban/issues/439 and there has been a few\nPRs merged to support multiple executors by @evlstyle\nhttps://github.com/evlstyle and @logiclord\nhttps://github.com/logiclord in #477\nhttps://github.com/azkaban/azkaban/pull/477 and #478\nhttps://github.com/azkaban/azkaban/pull/478. Can we give an update on\nthe status of the work on multiple executors?\nI will be going through the backlog of open issues and revisiting the\nroadmap in the project wiki.\n@d3vnate https://github.com/d3vnate - I am interested in learning more\nyour long list of wishlist items. Would it be possible for you to share a\npublic doc listing your wishlist items?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/438#issuecomment-141581507.\n. We are planning to release 2.7 by next week.\n\nOn Sat, Sep 19, 2015 at 6:12 AM, Changjian Gao notifications@github.com\nwrote:\n\n@hluu https://github.com/hluu Could you please let me know when 2.7\nreleased?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/438#issuecomment-141666557.\n. We just released 2.7.  I am planning to upload the new jar file version\nonto Maven repository shortly.\n\nHien\nOn Mon, Sep 21, 2015 at 2:37 PM, Hien Luu hluu@linkedin.com wrote:\n\nWe are planning to release 2.7 by next week.\nOn Sat, Sep 19, 2015 at 6:12 AM, Changjian Gao notifications@github.com\nwrote:\n\n@hluu https://github.com/hluu Could you please let me know when 2.7\nreleased?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/438#issuecomment-141666557.\n. The multiple executor enhancement will be in 3.0 release.\nOn Sep 26, 2015 4:37 PM, \"Vikram Kone\" notifications@github.com wrote:\n\n@hluu https://github.com/hluu looks like 2.7 release is up on github.\nAwesome..! Does this support multiple executors now? I dont see any updates\nto the documentation referencing how to setup multiple exec servers.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/438#issuecomment-143505364.\n. Another interesting thought would be to spin up a Yarn application to manage the life cycle of a flow, which involves executing all the jobs in that flow.\n\nThe downside of this approach is the coupling of Azkaban to Hadoop cluster.\n. LGTM\n. The implementation is done, just need to update the documentation\n. Documentation has been udpated\n. LGTM.  Thanks for making this fix.\n. LGTM\n. LGTM\n. Thanks for making this fix.\n. LGTM\n. This is done.\n. Any information on testing Felix?\n. LGTM\n. LGTM\n. Good to go.\n. LGTM\n. LGTM\n. LGTM\n. LGTM\n. Thanks for the patch.\n. LGTM\n. LGTM\n. LGTM\n. For some reason the CI failed weird error.\n. LGTM\n. LGTM\n. Let me get back to you shortly about the Azkaban 3.0 release.\nOn Thu, Oct 29, 2015 at 7:38 AM, devangorder notifications@github.com\nwrote:\n\nMy team is also very interested in the Azkaban 3.0 release with support\nfor multiple executors. Am I correct in that I should wait for it to come\nout, rather than downloading and building one of the branches available\ncurrently? I'm a little confused which is the one to go off of currently,\nbetween master, multipleexecutors, multipleexecutory_canary, release 3.0...\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/544#issuecomment-152200218.\n. The merging of the multi-executor branch to main trunk has started and I\nthink in a week or two, we should have Azkaban 3.0.\n\nThanks for your interest in Azkaban 3.0.\nHien\nOn Sat, Nov 14, 2015 at 8:49 PM, Vikram Kone notifications@github.com\nwrote:\n\nping?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/544#issuecomment-156780004.\n. When starting up Azkaban server, you can add -Dlog4j.log.dir= to\ntell log4j where to place the log file.\n\nOn Tue, Oct 27, 2015 at 2:42 AM, Codefor notifications@github.com wrote:\n\nHi,there!\nin the first line of this file:\nhttps://github.com/azkaban/azkaban/blob/master/azkaban-webserver/src/main/resources/log4j.properties\nlog_dir=${log4j.log.dir}\nHow does the log4j.log.dir work?When I start the azkaban-webserver,I find\nit creates logs under / instead of the current working directory.\nI tig the file log4j.properties and find that:\n2015-09-01 13:34 Hien Luu           o Rotate web and exec server log and remove unnecessary log statements #475\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/556.\n. LGTM.  \n\nIs Google actively use Guava Cache implemetation?\nWe should of use Gauva's Cache from day one.\n. Looks like this is a bug.  Can you please file an issue?\n. Can you add some tests?\n. LGTM\n. LGTM.\nThanks for submitting this patch.\n. Good idea.  Will do\n. See the stats under azkaban.jmx.JmxJettyServer section of the JMX page.  Some examples are \nConnectionsOpenMax,  ConnectionsDurationTotal, Connections\n. Is there an easy way to organize the dependency list in alphabetical order?\n. Add casting Future<?> to make it more clear.\n. The complete signature of Map.get() is  Map.get(Object o).  I will add the casting to make it more clear.\n. If we do that then submittedFlows will not have flows that are in the queue, which will cause method getQueuedFlowIds() to return empty list.\n. done\n. done\n. My Eclipse is using the Hadoop formatting rules.  Not sure why it did that.\n. The reason for this column is to find out how many items are in the table.  I think the purpose of this column is pretty obvious.\n. Done.\n. Done.\n. We could, but I am following the comment in the join method, which is to avoid including Apache commons for plugins.\nSince this is a very light weight method, it didn't bother to exploring the option of including the entire Apache commons or Guava.\n. ./plugins/jobtype/src/azkaban/jobtype/HadoopPigJob.java:    return StringUtils.join((Collection) list, \" \");\n./plugins/jobtype/src/azkaban/jobtype/AzkabanPigListener.java:          + StringUtils.join(aliases, \",\") + \", name: \" + node.getName()\n./plugins/jobtype/src/azkaban/jobtype/AzkabanPigListener.java:          + \", features: \" + StringUtils.join(features, \",\"));\n./plugins/jobtype/src/azkaban/jobtype/HadoopHiveJob.java:    return StringUtils.join((Collection) list, \" \");\n./plugins/jobtype/src/azkaban/jobtype/PigProcessJob.java:    return StringUtils.join((Collection) list, \" \");\n/azkaban-webserver/src/main/java/azkaban/webapp/AzkabanWebServer.java:    String jarResourcePath = StringUtils.join(jarPaths, \", \");\n./azkaban-webserver/src/main/java/azkaban/webapp/AzkabanWebServer.java:    String jarResourcePath = StringUtils.join(jarPaths, \", \");\n./azkaban-common/src/main/java/azkaban/executor/ExecutorManager.java:        String ids = StringUtils.join(jobIds, ',');\n./azkaban-common/src/main/java/azkaban/executor/ExecutorManager.java:                  + StringUtils.join(running, \",\")\n./azkaban-common/src/main/java/azkaban/utils/PropsUtils.java:            StringUtils.join(visitedVariables, \"->\"), subVariable));\n./azkaban-common/src/main/java/azkaban/utils/PropsUtils.java:              StringUtils.join(visitedVariables, \"->\")));\nI think it is best to leave it alone.\n. Since Email extends AbstractMailer.  Is there a need for retrieving \"mail.useAuth\" property again?  Can Emailer class just call a method from AbstractMailer to find out whether authentication is on or not?\n. That would be great.  There is no need to duplicate the logic of getting a value for \"mail.useAuth\" property.\n. Since the parent class AbstractMailer already has an instance variable usesAuth, I don't think there is a need to redefine it here.\n. call super.hasMailAuth()\n. call super.hasMailAuth()\n. Notice \"mail.max.attachment.size.mb\" is in MB unit.  1GB ~= 1000 MB.\n. Good catch.  Missing an extra 0 :)\n. Done.\n. Reduce message length to fit on one line.\n. Totally agree\n. done\n. I wanted the default size to be large because currently there is no default, which means the default size can be anything.\nThe default value is meant to work for most email systems and can be changed through configuration.  We don't want the emails to stop working for other folks when they upgrade their Azkaban.\n. Good suggestion.\n. 100 it is.\n. Since status is an enum this line can be simplified to if (report.getValue().getStatus() != Status.PASS)\n. Please add javadoc\n. Please add javadoc\n. Please add javadoc\n. Please add javadoc\n. Do we need to check fi.exists()?\n. no need to call getName()\n. It would be good to also log out archive.getName()\n. Please add logging to make it easier to debug when XML_FILE_PARAM key doesn't exist.\n. Is XML_FILE_PARAM required?  \nIt would be good to add logging to help with debugging.\n. Add javadoc regarding ProjectValidator and how this is configured in the XML file.\n. Didn't see any tests for this class.   Please add some tests.\n. change to property\n. add a property to test\n. Thanks for spotting this.  Done\n. This may introduce NPE if a resource is not in the resourceTimestamps\n. Would make sense to add try/catch here to we don't miss anything in the future?\n. done\n. done\n. good suggestion. done\n. remove the need to set content length and the testing ran fine\n. Nope, it keeps only 3 versions :)\n. yes, the editor did it.\n. It only makes sense to explicitly catch each exception if the exception handling logic is different.  In this case it is not.\nI added a log statement.\n. Good catch. Done\n. Good idea. Done\n. does it make sense to be consistent in the naming? metricHistory -> getMetricHistory\n. It seems like we are introducing a new naming convention for member variables that starts with underscore.  To be consistent of existing code base's naming conventions, would you mind removing the leading underscore.\n. What's the rationale for catching NPE? Does it make sense to catch Throwable?\n. Does it make sense to introduce MetricException?  When a method throws Exception, it doesn't tell the caller much about the type of exception it can throw.\n. Seems like this needs to be volatile for visibility purpose.  Different threads can call disableManager() and  isAvailable() methods\n. It is better not to call toString() method.  Let logger.error prints out the entire stack trace.\n. same thing here\n. Does it make sense to separate this out into two cases?\n1) Argument metric is null -> throw IllegalArgumentException\n2) getMetricFromName(metric.getName()) == null\n. This seems a bit strange.\n. We will get more useful info. by\n_logger.error(\"Failed to purge data\",  ex);\n. So a TimerTask instance is created every time this method is called? Is that the intent?\n. Not quite sure about the \"Draw\" part of method \"getDrawMetric\".  Can it just be getMetrics()?\n. Is it absolutely critical to get the latest list of metrics for give metricName?  If not, then the synchronized block is a bit overkill.\n. Please add some javadoc\n. Please add some javadoc\n. Please add some javadoc\n. Can you elaborate on the reasoning? or add a few lines of javadoc about the intent.\n. Oops, I guess I missed it.\n. Sorry, should have commented on this sooner.  Can we use constants for \"executor.metric.interval.default\" and \"executor.metric.interval\"?\n. What is the unit for this prop.? Is it in seconds?  Can we add the unit to the prop. name somehow?\n. Can we create a constant for \"executor.metric.milisecinterval.\" and \"executor.metric.milisecinterval.default\"?  Let's follow the DRY principle.\n. It seems a bit weird for AbstractMailer class to depend on one of its subclasses (Emailer).  How about defining the constant DEFAULT_SMTP_PORT inside AbstractMailer class?\n. I wonder if there is already existing code for parsing xms and xms settings?\n. This may break existing code because a change in the constructor signature.  Can we overload the constructor?  Whether we use the props, needs to guard against props being null.\n. Please document the behavior and use conventional method name when a method return a boolean\n. can we make 30 seconds configurable?  the default can be 30 seconds.\n. It would be good to add a catch all clause and log out the exception to make it easier to debug.\n. What is the significance of 2KB at the end of the method name?\n. Should catch Throwable to catch unexpected exception so it doesn't bring down the web server\n. Are there tests for this method?\n. Ah, got it.\n. We can make it configurable with a default value.  That will give us an opportunity to adjust if needed.\n. Any comments on John's suggestion?\n. Add else condition for non-Linux system and print out the memory reader will not enabled\n. Any reason why we need to use the complete package name here?\n. Did you get a chance to take a look at JobCallbackValidatorTest.java?\n. Not sure what you mean by better by providing a function.\n. Good idea.  Done\n. Unfortunately it is not possible because each LoggingResonseHandler instance takes in a different job logger instance.\n. That is a good observation.  Yes, the HTTP calls are invoked sequentially, however they will be cancelled if response doesn't come back in a few seconds.  The other thing is we need to log out the callback request and response information using the job logger, which is valid until that job is finalized.\n. Good point.\n. The steps are similar, but not exactly the same.\n. Agree.\n. This class is meant to be singleton.  The initialization requires properties.\n. True.  However synchronization is already done in method handleJobFinishedByType.\n. True. However synchronization is already done in method handleJobFinishedByType.\n. Agree.  Will add an additional validation.\n. Good catch.\n. Good catch.\n. The challenge here is to submit a HTTP request, get a response and log out the response and make sure to cancel the HTTP request if it takes more a certain amount of time.  Plus, this needs to happen before the job logger will finalized.\n. Good catch.  Thx.\n. True.  AtomicInteger has an easy way to increment a value.  Just a tiny overhead.\n. I am surprised there isn't a method that does this already.\n. Should we check for null project and deleter parameters?\n. Great to see tests\n. seems like the method can be more clear in terms of what it is testing.\n. Retrival?  Do you mean Retrieval?\n. Maybe make this message more clear i.e \"Expecting exception, but didn't get one\"\n. extra semicolon\n. So the return object can have \"success\" as key and valid value as false.  Is that OK?\n. Does this go through Azkaban log file or go to job log?\n. Should we mentioned that the properties are sorted?\n. Is it necessary to check?\n. Should we do basic validations on these constructor parameters?\nport can't < 0\nhost can't be null\nid can't < 0\n. why default for active to true?\n. Does it make sense to make this class immutable?\n. Under what conditions this exception is thrown?  More doc. please\n. Does this method return null if it can't find one that matches the given host and port?\n. Does this method return null if it can't find one that matches the given executorId?\n. Does it make sense to combine these two methods into updateExecutor(Executor executor) method?\n. Should this throw an exception instead so caller can get more info. on the nature of the failure?  boolean is not very expressive.\n. I am a bit confused about what this method does based on its name.  More doc. please\n. exact match? or greater than or less then?  more doc. please.\n. just curious, why 128 for error?\n. Not sure about default to ERROR.  Makes more sense to thrown an IllegalArgumentException.\n. Should we do any kind of validations?\n. Does this method return null or empty list when there are not matches?  Please add documentation about this behavior.\n. Does this method return null or empty list when there are not matches?  Please add documentation about this behavior.\n. I wonder under what circumstance that update method returns 0 rows?\n. better to throw an exception\n. Looks like this exception is not being thrown up.  Silent killer :)\n. better to throw an exception, otherwise this test will silently pass every time the setup step is not properly done.\nsame comment for the tests below.\n. What about performing clearDB() in a general test cleanup method so each test doesn't have to remember to do this?\n. Since the constructor doesn't do much, another way to initialize an instance of this class w/o doing any synchronization is:\nprivate static ExecutorApiClient instance = new ExecutorApiClient();\n. It would be good to describe the behavior where this method can return either null or empty map.  Would it be simpler to always return empty map?  Should the caller behavior differently based on nulll or empty map?\n. Seems like this method is getting a map of executor stats.  Should we name it that way?  getExecutorStats(...)\n. Should we do any validation on method argument?\n. I feel a bit uneasy about the Object part of the Map.  How does the client deal with Object?  Should there be a base class to restrict what can be as the value so caller can have deal it value in a generic fashion w/o the need for casting.\n. It is not clear to me why return true when object2 is null.\n. Does it make more sense to throw an Exception rather than silently accept the given comparator when it is null or invalid weight?\n. Better to use factorName.length() == 0.  String comparison in Java is usually done using String.equals(String str) method to compare string content, otherwise == operator will compare object instance references.\n. should we throw an exception?\n. should we throw an exception?\n. Just a thought, does it make sense to cache the totalWeight?  I guess we will not have that many FactorComparators, so maybe it is ok to compute the total weight each time this method is called.\n. Method is name is too generic and doesn't explain what this method does.  Better name please.\n. This is comparing object instance references, is this the intention?\n. Using for loop is more clean and don't have to worry about advancing the iterator.\nfor (FactorComparator comparator : comparatorList) {\n   ....\n}\n. I think it is better to throw exception\n. check what?  please come up with a better name?\nReturning true means what? false means what?  Please add documentation to explain the behavior\n. It seems like this interface doesn't do any dispatching, is that true?\n. Should we add some validations  here?\n. Factor is a fairly generic name, can we have something more descriptive?\n. Can weight be negative?\n. Let's throw an exception\n. Please use factorName.equals(\"\")\n. throw exception\n. factorName.equals(\"\")\n. check -> shouldFilter?\n. method name should start with lower case letter\n. completeRequest -> addHeaders?\n. same comment as above\n. It will be easier to understand and maintain if these tests are broken into self-contained separate test methods.\n. I wonder if it makes sense to include these comments in the test because if they change tomorrow, then they are out of dated.\n. Good point.\n. Do we have any negative test cases? what about when there is only 1 executor?\n. When I see the name Dispatcher, I was expecting it to do some kind of dispatching.  This class is more about candidate selection.\n. OK\n. if it can't be negative, then should there be some sort of validation?\n. OK.  However the name \"completeRequest\" doesn't tell the reader much.  Since it is a private method, then it doesn't matter too much.\n. thank you.\n. That was my point, then it is reasonable to declare a method which will be called by junit to call after each test method is invoked.  This provides an opportunity to perform any kind of clean up between each test.\n. I believe that is case only when multiple JVMs are sending logs to same file.  In our case, it should be OK.\n. maybe just need better naming to distinguish this member variable and the one above it.\n. please add a comment about the duration so readers wouldn't have to do the math :)\n. If we switched from running local executor to multiple executors, would this also load the local executor?\n. Would be good to log out whether web server is running in local executor or multiple executors modes, if it is the later, also print out list of servers (host/port/status)\n. There is no need to update activeExecutors after fetching from DB?  How come?\n. What does it mean primary server?\n. Are we saying activeExecutors can contain duplicate server hosts and that is why ports is of type HashSet?\n. This method is returning a list of execution ids, but method name is \"getRunningFlows\".  I am a bit confused.\n. seems like this method always return false.\n. Looks like formatting is off\n. what if queuedFlowMap doesn't contain an entry with execId, will there be NPE?\n. Is sorting necessary? if so, why?\n. fetchExecutorByExecutionId?\n. do we have index on join column(s)\n. This line is removed.  Not needed\n. Good idea and thanks for the link.  Done.\n. I wonder if it makes more sense to call this class ExecutorInfo.\n. What kind of statistics does this class contain?  Maybe add that to the class name.\n. Should this have a different name than PRIORITY_COMPARATOR_NAME?\n. I think you can move the message into the IllegalArgumentException exception.  The log statement is optional.\n. same comment as previous one regarding exception message\n. Should these strings be constants at class member level?\n. boolean makes more sense.\nMethod name doesn't quite match what it does.\n. is the casting necessary?\n. this can just be int to avoid auto-boxing.\n. same here\n. Javadoc please\n. small thing - filterList.isEmpty() is shorter\n. is this necessary?\n. Looks like the junit Expected exception is useful here - http://www.mkyong.com/unittest/junit-4-tutorial-2-expected-exception-test/\n. lastFlowSubmittedDate?\n. Can we use System.currentTimeMillis() to achieve the same goal but w/o creating new object?\n. Please also log out the ex\n. System.currentTimeMillis()?\n. It seems like this is more complicated than it needs to be.  How long does each one of these methods take to complete?\n. log out exception please\n. +1\n. Is this third submit necessary?\n. what is a non-dispatched flow?\n. Is undispatched same as queued?\ngetQueuedFlows?\n. Please add javadoc for the comparison logic - descending order by priority,  ascending order by update time and ascending order by execution id\n. Add javadoc, that this will be used in the priority queue\n. should add add ex to the log.error()?\n. Should we check for null because we will reference it later - executor.getHost(), executor.getPort()?\n. small comment - is AZKABAN prefix necessary?\n. cool\n. runningFlowIds?\n. This message seems weird - successfully in catch clause?  how come?\n. Anything special that should be called out to give readers a sense of the responsibility of this class?\n. How come not logger.error()?\n. I believe this needs to be volatile, because it will be updated and read by different threads.\n. I believe this needs to be volatile, because it will be updated and read by different threads.\n. Would it be helpful for debugging purpose to log out a statement when this method is called.  This way, we can easily tell from the log.\n. It would be more clear to refactor this piece of logic into a method and name a method clearly to represent the logic\n. Seems expensive to create an instance of HashSet in a loop.  Who is responsible for updating activeExecutors?  Can we swap the list when the list is updated?\n. why synchronized on exflow?  multiple threads are manipulating a specific instance of exflow?\nA comment here would be helpful.\n. I wonder if this should be logger.warn() instead of logger.debug(), which we will not see in normal running mode.\n. Good to see helper method so the logic flow doesn't get cluttered.\n. Should we add logging to indicate this condition?\n. Should we add logging to indicate this condition?\n. Should we add logging to indicate successful dispatch for flow to specific executor?\n. Would be good to understand what the blocking queue and concurrent hashmap are used for and why they are needed.\n. Are there any tests based on execution ids?\n. Any reasons why we are removing these files?\n. What if obj is null?\n. If there are no selector comparator prefixes then everything else still works?\n. should we have MS in the key name as well so it is consistent with AZKABAN_ACTIVE_EXECUTOR_REFRESHINTERVAL_IN_MS?\n. Thread pool is a bit expensive, is it possible to reuse the taskExecutors thread pool?  any reason why you don't want to reuse?\nThis method can just submit refresh tasks.\n. What are the impacts when tasks don't come back in 5 seconds?  stale statistics?\nIt would be nice to have visibility into this refresh tasks  - i.e last refresh timestamp in the JMX page.\n. What are the scenarios where an exception can happen?  Does it make sense to bubble up the exception rather than logging it?\n. Do we have a jmx bean to indicate the status of the queue processor?\n. Would be good to mention that this code is borrowed from Hadoop\n. Not exactly sure how we would go about doing unit testing on this feature, but something to think about.\n. reformat this line\n. shorten the error msg\n. Add a test \n- Remove SUBMIT_USER and add USER_TO_PROXY\n- Make sure job run successfully\nAdd a test w/o both submit_user and user_to_proxy\n. replace space with underscore for project name, flow name, job name. etc.\n. why named alters?  how about this.alerts = alerts?\n. I think the INTERVAL part is causing the confusion.\nHow about AZKABAN_ACTIVE_EXECUTOR_REFRESH_BY_NUM_FLOW?\n. How big is the jsonString?  Do we really need to see the jsonString? or may be log out jsonString in a separate statement with debug level.\n. should we update the time after successfully calling executor?\n. can this be negative? under what scenario that it can be negative?\n. do we want to wrap this in an if statement?\nif (logger.isDebugLevel()) {\n}\n. do we want to wrap this in an if statement?\nif (logger.isDebugLevel()) {\n}\n. do we want to wrap this in an if statement?\nif (logger.isDebugLevel()) {\n}\n. Does this check need to happy every time this method is called?  Can you do this check once in the constructor?\n. ",
    "sillycow886": "@vgomprakash you should in AzkabanProcess.java at 74 line add this code:\n        ProcessBuilder builder = new ProcessBuilder(cmd);\n        builder.directory(new File(workingDir));\n        builder.environment().putAll(env);\n        //add this code the log show info replace error\n        builder.redirectErrorStream(true);\n        this.process = builder.start();\n        this.processId = processId(process);\n. you should run update.execution_flows.3.0.sql  @mycFelix \n. ",
    "lewchuk-inkling": "+1 to this request.\n. +1\n. I've seen the same result as you (flows being stuck in Preparing), however my errors are encountered quite infrequently and my logs look different:\n2014/07/17 09:00:25.165 +0000 ERROR [TriggerManager] [Azkaban] Failed to do action Execute flow Data_Pipeline from project Master_DataPipeline\njava.lang.RuntimeException: azkaban.executor.ExecutorManagerException: java.net.SocketException: Too many open files\n        at azkaban.trigger.builtin.ExecuteFlowAction.doAction(ExecuteFlowAction.java:241)\n        at azkaban.trigger.TriggerManager$TriggerScannerThread.onTriggerTrigger(TriggerManager.java:295)\n        at azkaban.trigger.TriggerManager$TriggerScannerThread.checkAllTriggers(TriggerManager.java:277)\n        at azkaban.trigger.TriggerManager$TriggerScannerThread.run(TriggerManager.java:225)\nCaused by: azkaban.executor.ExecutorManagerException: java.net.SocketException: Too many open files\n        at azkaban.executor.ExecutorManager.callExecutorServer(ExecutorManager.java:562)\n        at azkaban.executor.ExecutorManager.submitExecutableFlow(ExecutorManager.java:533)\n        at azkaban.trigger.builtin.ExecuteFlowAction.doAction(ExecuteFlowAction.java:235)\n        ... 3 more\nCaused by: java.net.SocketException: Too many open files\n        at java.net.Socket.createImpl(Socket.java:414)\n        at java.net.Socket.getImpl(Socket.java:477)\n        at java.net.Socket.setSoTimeout(Socket.java:1047)\n        at org.apache.http.conn.scheme.PlainSocketFactory.connectSocket(PlainSocketFactory.java:126)\n        at org.apache.http.impl.conn.DefaultClientConnectionOperator.openConnection(DefaultClientConnectionOperator.java:180)\n        at org.apache.http.impl.conn.ManagedClientConnectionImpl.open(ManagedClientConnectionImpl.java:294)\n        at org.apache.http.impl.client.DefaultRequestDirector.tryConnect(DefaultRequestDirector.java:640)\n        at org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:479)\n        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:906)\n        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:1066)\n        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:1044)\n        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:1035)\n        at azkaban.executor.ExecutorManager.callExecutorServer(ExecutorManager.java:626)\n        at azkaban.executor.ExecutorManager.callExecutorServer(ExecutorManager.java:560)\n        ... 5 more\nIt looks like there might be a few issues, the underlying errors in TriggerManager and the consequence of flows hanging in the Preparing state.  It looks like an error within TriggerManager will cause this hanging behavior. The errors are clearly being caught and logged, it would be really good to propagate that out of TriggerManager and mark the flows as failed, and if possible trigger notifications.\nI am running currently 2.5.\n. ",
    "Dima1224": "+1 for me as well. \nHas anybody found a good way of working around this? My use case is the same as @wacosta-harman.\n. @lynnfi no, I haven't found a good workaround. We were forced to fork and implement the functionality ourselves.. Hi @juhoautio, unfortunately I can't since this was done for a company I don't work for any longer. Are you planning on merging your implementation into Azkaban?. ",
    "lynnfi": "+1 for my project.\nHave you found a good way of working around this? @Dima1224 . @Dima1224 Thanks\uff0cI write a python_spider script to help me do this.And I have noticed many people recommend \u201cairflow\u201d,or you may try it~. ",
    "juhoautio": "@Dima1224 any chance to share your fork code? This feature is going to implementation on our side as well, already next week (we also use a private fork).. We have now implemented this feature on our private fork.\nUI was also modified to highlight such jobs:\n\nFor example here we have set:\n- Something bad in sub-flow-start.job to make it fail\n- cleanup=true in parallel3.job and example-flow.job\nYou can see how other jobs were cancelled after the flow failed, but the \"cleanup\" jobs were still run:\n. Maybe we could prepare a pull request, if repo owners are interested in having this feature.\n@ameyamk @HappyRay @chengren311 \u2013 what do you say?. Thanks @reallocf.\nHehe, the \u26a0\ufe0f symbol was put there mostly to warn users that that they probably don't want to disable the cleanup jobs when preparing an execution and manually disabling some jobs.\nIf the flow is killed, cleanup jobs are still run. We added a new \"Force kill\" button that can be used to stop even kill cleanup jobs if needed.\nFor sub-flows this is natural: if a sub-flow has not started at all, cleanup jobs inside that sub-flow are not executed. If a (sub-)flow has started, then any cleanup jobs inside that flow are always run. Cleanup property can also be inherited from parent etc. As you can imagine this is quite powerful in possibilities that it offers.\n\nI'd also be interested in the design\n\nI wonder what you mean by that?. @HappyRay:\n\nHowever, I just started resuming the work on DAG engine rewrite\n\nThat's great news!\nIndeed our implementation of cleanup jobs touches the flow execution logic, which makes your concern valid. It will be much easier to reason about the changes required for the cleanup implementation after that.\n\nIn the meantime, I would be interested in your design and experience using it.\n\nNot sure what I could say about the design..\nI could mention for example that when a project is uploaded, additional boolean field cleanup is set on the nodes based on the properties (which are all read when storing a project). This is mostly just an optimization to allow efficiently resolving if nodes are cleanup or not (without having to read the properties from file afterwards).\nOn usage experience I have to say that I think there could be some room for improvement on the UI side. These we haven't done, but would be useful additions:\n- If clicking \"Prepare execution\" for a previously failed execution, enable all cleanup jobs in the UI automatically, even those that were run successfully on the previous execution.\n   - This we will quite surely implement at least\n   - This is because cleanup jobs may typically have \"green/success\" status even if the execution as a whole has been killed or failed, but they may have to be run again.\n   - At least re-enable all cleanups that are after any jobs that are auto-enabled for preparing.\n- If a user tries to launch a flow with any cleanup jobs disabled, ask for an additional confirmation\n   - Something like this: \"Some cleanup jobs have been disabled \u2013 are you sure you don't want to enable them?\"\n  - This check can be limited to those cleanup jobs where the immediate \"owner flow\" is not entirely disabled \n- If a user clicks the new \"Force kill\" button, show a similar prompt\n   - \"Are you sure you want to kill any currently running & pending cleanup jobs?\"\nOur use case is mostly this:\n1. launch an aws emr cluster\n1. run some jobs against that cluster\n1. cleanup: terminate the emr cluster\nAs you can see, we don't typically want to accidentally run such flows with cleanup jobs disabled :) I suppose it's still good to allow disabling them because in some cases it may be needed.. Killed & Failed are both notified according to the failure callback.\nYou can include the actual status in callback params, for example:\njob.notification.failure.1.body=[?{status}] ?{project}: ?{flow}\n\nWould be formatted to either:\n[killed] myproject: myflow\n\nor:\n[failed] myproject: myflow\n\n\nI think it would be nice to support separate callback conf for killed status though. Eg.:\n\njob.notification.killed for KILLED only\njob.notification.failed for FAILED only\njob.notification.unsuccessful for any finished status != SUCCESS\njob.notification.failure deprecated, but supported for backward compatibility (for KILLED or FAILED)\n\n@HappyRay what do you think?. If you don't need 3GB free memory for some simple shell commands, you can also disable the memory check by setting memCheck.enabled=false in plugins/jobtypes/commonprivate.properties.\n. We have implemented this to manage parallel workload against a database. I'm thinking making a PR, but it doesn't seem like new features are getting into master easily, so I wonder if it would be worth the effort.\nIn azkaban.properties we define the groups.\n``` properties\nindividual priority groups\nprioritygroup.groups.test_group_analytics.maxParallelExecutions=2\nprioritygroup.groups.test_group_etl.maxParallelExecutions=4\n```\nSo this defines two global priority groups: test_group_analytics and test_group_etl.\nIt would be better to have these configured from the UI and stored in the database instead of props, but this was the easiest way to get it done as we rarely need to add new groups. Obviously azkaban executor node needs to be restarted to apply changes in group config.\nThen in .job files we set\nproperties\ntype=what_ever_job_type\nprioritygroup.name=test_group_analytics\nprioritygroup.priority=5\nNow if we have for example 3 jobs using test_group_analytics with priorities 1, 5, 10 that all start at the same time, jobs with 1 & 5 will be started and 10 will wait for a free slot. Also if a job with higher priority (let's say 2) is launched while 1 & 5 are running, it will take the first free slot and the job with priority 10 will wait further.\nJobs are blocked in a similar fashion as with concurrentOption=pipeline, showed as QUEUED in the UI.\nThe way we did this acts globally, so it doesn't matter if the jobs are from different flows, executions, or even projects. If you would need to have it on flow level only, then a straight-forward extension would be to allow creating ad hoc priority groups in the .job file of the flow (similar conf as now in azkaban.properties) that would only live during the flow execution.\n. > what are the main downsides of modeling this via dependencies compared to setting priorities?\nTLDR; With dependencies the child jobs are not run if any parent fails. Also there's more waiting and idle time when jobs can't be parallelized.\n\nScenarios to consider\nConsider a flow with some parallel jobs like this:\nA1 -> B1\nA2 -> B2\nA3 -> B3\nLet's say\n- We want to run all A jobs in parallel\n- We want a limited number of B jobs to run at the same time\n- We want to run each An -> Bn even if some other n chain fails\n- We want to B jobs in priority order if there's a need to decide which one to run\n- We don't want the resource for B jobs to be idle if there's any finished A job\nYou suggested something like this I suppose:\nA1 -> B1 -> A2 -> B2 -> A3 -> B3\nProblems with this:\n- A jobs not run in parallel \u2013 takes more time to finish\n- Can't have max 2 B jobs running in parallel, just one\n- 2 & 3 not run if 1 fails etc.\n- Lot of idle time for the B job resource\nAnother approach would be to have it like this\n(A1, A2, A3) -> B1 -> B2 ->B3\nThis has same problems as the previous graph, except that A jobs can be run in paralle, but then again none of the B jobs can start before all A jobs have completed.\n. @logiclord made #447 Enhance flow runner to prioritize ready jobs using some property (the commit: https://github.com/logiclord/azkaban/commit/52afa732741d404074fb5b960e58ba08cd3117e8).\nI don't quite get what it's supposed to do. Just ordering the jobs before submission doesn't seem too useful to me, because they will still all start executing immediately.\n. @logiclord thanks for comment, what did you mean by helping me?\nWhat benefit do you get from controlling the execution order, when it's actually just the start order, if the jobs are parallel in the flow graph? Obviously if the flow is sequential then the ordering doesn't matter any way.\n. 5/5, would use :+1: \n. Hey that's really useful \ud83d\udc4d\n. I encountered the same problem.\nThanks @todd-fritz: setting pluginLoadProps to a non-null value helps.\nIf you look at JobTypeManager you'll find out that pluginJobProps isn't even used after that line any more, so that piece of code is redundant.\n\nP.S. I couldn't get these log messages to be shown anywhere..? I was able to verify with System.err.println that this additional code is executed, though.\nThere's just logs/azkaban-execserver.log that is being populated with some logs, but only this line from the JobTypeManager:\n2015/12/07 13:05:36.138 +0200 INFO [JobTypeManager] [Azkaban] Loading plugin default job types.\nMaybe the logging system somehow gets misconfigured after that line is printed?\n. I could do a PR like that to at least fix job running, but I wonder if a proper fix would require something more? I mean why does it get set to null in the first place \u2013 maybe that's wrong and should be looked at. I wouldn't know \u2013 just getting started with Azkaban.\n. @jeroenvlek true, that makes sense. Please submit the fix by all means!\n. #591 has the required sql scripts.\n. :+1: \n. Fixed by https://github.com/azkaban/azkaban/pull/606. @logiclord @johnyu0520 @evlstyle \u2013 sorry to spam, but is there anything preventing to merge this? It's clearly a bug that's making the notification mechanism quite unstable.\n. @HappyRay, wondering if you would have time to check this? We've been running in production with this change for half a year without problems.\n. @HappyRay Could you check this? I just rebased & resolved conflicts that had appeared in the meanwhile.\n. > We haven't seen this problem from our internal users.\n\nI am not familiar with this part of the code yet. Could you elaborate why you got the error you described when the status is different from the value at the time of event firing?\n\nThanks for jumping in! The error is explained in detail in the issue,  https://github.com/azkaban/azkaban/issues/605.\nTrying to explain in brief why we got the error:\n- We have configured job.notification.success and job.notification.failure in our common properties, so these are pretty much enabled for all of our jobs\n- Whenever a job ends, Azkaban fires an event (Type.JOB_FINISHED) about the state change\n- Azkaban handles the notification callbacks asynchronously. The event contains a node with mutable state field, which is sometimes modified by other threads before the notification is handled.\n. > It's because the node status changes back to the ready state after the event has fired and no callback should be issued for ready state.\nYes, it's a concurrency issue. I would approach it from a bit different angle though, because callbacks themselves are not at fault here. No event should be fired with Type.JOB_FINISHED that has a \"not done\" status attached to it. Callback handling code doesn't expect to see for example that \"a job finished with status READY\".\n. I tried to fix all the issues you pointed out + synced with master. Good to go?\n. > Please fix the build error first before merging.\nSorry.\nBuild fixed.\nI removed that @NotNull annotation because I would've had to add another library dependency to keep it.\n. I would try merging myself, but the approval had expired because I modified the PR after that. Now I clicked \"Update branch\", which added merge commit from master (is that ok?). Please merge this if you still accept :) Thanks for your time and insight on this.\n. @logiclord there's a description & screenshot ^\n. @logiclord, @HappyRay, .. Are you ready to merge this if conflicts are resolved?. @chengren311 thanks for stepping in. I can explain why this is needed.\nYou can access job logs for current and failed attempts in the Job List tab of an execution.\n\nIf some job failed and has retries, it goes into QUEUED state while sleeping before the next attempt.\n\nIf you want to see why any of the previous attempts failed, you can right-click the gray attempt bar\nTo see how long it's going to sleep, you can check the job log\n\nWithout this fix you can't do either of those if the job is sleeping, because it's hidden if the state is QUEUED\nAlso if you have a job that hasn't yet started to run but is in QUEUED state (ie. blocked by pipeline), if you want to know why it's queued, you should check the job log. If you can't access the job log via Job List tab, this is not easily accomplished.. > How difficult would it be to include automated tests with this change?\nHuh, are there tests for the UI / javascript code?. We'll see what @artem-garmash thinks.. But would it be enough to resolve the conflicts (and verify manually that it still works) to get this in?. Here some general thoughts on the PR review process. Sorry I don't know what would be a better place to post this.\nIt would be good to know from the beginning what's required so that one can estimate a bit how much effort it will take to get a fix in. For example if reviewer asks for better description or resolving conflicts, it would be good to know also if for example additional tests are required.\nNow it seems a bit unfair that conflicting changes have been merged into master before this one, although Artem provided a description and screenshot as requested. I've also \"suffered\" from this myself a bit :) I guess the main problem is that PR submitter could spend time on resolving conflicts and then later on have to resolve more of them, even though nothing was pending on the PR itself.\nDon't take this in the wrong way.. I totally get it that you need to somehow verify the quality to be able to merge. But as I said, it would be good to know how much effort is needed, as early as possible, and have some kind of trust that someone is there to merge it after the required changes/additions have been made.\nWhen I get a comment or two on a PR I kind of expect that there isn't anything else wrong with it, and it would be merged once I've resolved the issues that were raised in the first place. To avoid confusion you could for example add a note if needed, that those are just some initial comments and you haven't yet gone through the thing as a whole just yet. Of course sometimes you just can't spot everything on the first time and then it's understandable that outstanding issues can be raised after the initial issues were fixed.. @HappyRay, sorry but what was the conclusion on this? Would it be possible to get this in if conflicts are resolved, without adding anything more yet (like UI or javascript tests)?. First of all, this fix has been working well for us without issues in production for a long time.\nWe don't have experience of developing the UI side tests, and learning about those doesn't seem too useful for us at this point. Actually I couldn't find documentation about how those are even run (or are they part of the gradlew build?).\nI was hoping that you could have this improvement in the repo mostly because when we first submitted this, there didn't seem to be such requirement on adding javascript tests (I wonder if that requirement indeed was introduced later).\nWe've spent some effort on this with expectation that it won't require more than fixing possible issues and explaining things if anything is unclear.\nIt will be better for you to have this fix than not. So I'm asking you to make an exception this time with this old PR, so that resolving conflicts would be enough. After all, not all of the existing javascript code is covered by tests either. For any future pull requests we will know that tests are required, so that we won't spend time on preparing a PR without knowing what it takes to get it merged.\nSorry for a long message.. Nice, thank you. We'll get those conflicts resolved next week.. Heh, ok, no worries. We'll wait and see what @ameyamk thinks.. @jakhani?. @HappyRay any update on this?. @ameyamk please help? Haven't heard anything from @jakhani after @HappyRay mentioned.. Thanks for stepping in @kunkun-tang. Hmm but that's not true (being offline). @artem-garmash resolved conflicts and updated PR description as requested, but then once again nothing heard from expected reviewer and new conflicts have appeared after that. I'm interested in this being reviewed and merged because I'd like to keep the diff as small as possible between our fork and the public repo. But I don't see why there would need to be a new PR.. If you could log your HTTP request, it might be easier to point out what goes wrong.\nYou could try this on command line and compare it to your code, it works for me:\ncurl -v -k -i -H \"Content-Type: multipart/mixed\" -X POST --form 'session.id='$sessionId --form 'ajax=upload' --form 'file=@'$fileName';type=application/zip' --form 'project='$projectName $AZKABAN_URL/manager. @georgezhlw, I added another commit:\n1. Add flow status to list of reasons in flow failure alert message\n   - Usually the status is FAILED or KILLED\n2. A bit of better message about executor really not running the flow anymore\n. @logiclord @georgezhlw how about pulling this in?\n. Added commit here as well, but rather have a squashed single commit -> new PR: https://github.com/azkaban/azkaban/pull/680\n. Candidate fix: https://github.com/azkaban/azkaban/pull/673\n. Fix was merged, this issue could be closed/resolved.\n. I believe this can be closed, as https://github.com/azkaban/azkaban/pull/673 was merged, fixing the same problem.\n. Tested. SLA e-mail alerts are going through with this fix.\n. @HappyRay any feedback? This is quite important as SLA e-mails don't work at all in the current version.\n. @fsi206914, \"fixing also SendEmailAction\" is mostly hypothetical.\nThis PR is primarily to fix the SLA e-mails, but so that any other usages of AbstractMailer benefit as well.\n. @HappyRay \n. @HappyRay: added 3 commits according to your comments. Good to go?\n. Here, in single commit: https://github.com/azkaban/azkaban/pull/687\nI'll create a PR about ExecutorManager error logging after that's been merged, because it may conflict.\n. Thanks @HappyRay for merging some PRs by me.\n. Looks like this PR https://github.com/azkaban/azkaban/pull/1172 (currently not merged yet) fixes the missing logs problem as a \"side-effect\".. Let's keeping this open though: I'm pretty sure that in case of an interrupted execution (azkaban-executor stopped in the middle of an execution), logs are still being overwritten with an empty value.. This one is fixed, created another one for the executor restart scenario: https://github.com/azkaban/azkaban/issues/1527. @HappyRay we use Java 8. Can't comment on behalf of other users, but personally I think it's ok to require Java 8 from now on.\n. > Let's give the community members a few more days to comment on dropping Java 7 support\nHow about mentioning that plan on the mailing list?\n. > The semver plugin requires Java 8 and therefore Java 7 builds are failing.\nThat was discussed in https://github.com/cinnober/semver-git/issues/1 and suggested:\n\nPlease use the version 2.2.1 released in April 13, which was actually rebuilt with Java 7.\n\n@suvodeep-pyne did you try that? Although it would be nice to drop Java 7 just to simplify the build infra and get Java 8 syntax goodies :)\n. Fixed by https://github.com/azkaban/azkaban/pull/1245. I don't think I have any good suggestions, but what I can see at least:\n\n\nRemove execution loggers manually from the log4j's internal Hashtable \n\nHashtable ht in org.apache.log4j.Hierarchy seems to have default/package visibility. So if we could create our own class in org.apache.log4j package and then somehow get a hold of the configured Hierarchy instance, we could remove execution loggers from the Hashtable after execution has ended (there won't be no more logging to that logger name).\n\n\n\nHave a pool of logger names\n\nWe could maintain a pool of execution logger names and assign from there to each thread. This pool would basically be as big as the max number of concurrent job executions that there has ever existed during the application runtime, but not (much) more.It seems like such a complicated feature just to avoid a simple Hashtable leak.. But this is at least a way that's independent from log4j internals.\n\n\n\nCall Hierarchy.clear()?\n\nThis may not work at all, but: Call org.apache.log4j.Hierarchy#clear every time after obtaining a new logger. Javadoc says: \"This call will clear all logger definitions from the internal hashtable. Invoking this method will irrevocably mess up the logger hierarchy. You should really know what you are doing before invoking this method.\" \u2013\u00a0Well, I don't know what kind of side effects this may have. Maybe this stops the loggers from working entirely, but it could also be that this doesn't have any unwanted side-effects in our case..\n\n\n\nMaybe there is some good way to fix this :). I replaced all catches Throwable ->Exception and been running jobs fine so far. Also deployed some new job type plugins and did the reload. I could make a pull request for this?. I learned a bit more about the OOM issue. Exiting the thread that sees OOM is not enough to take down the java process, because typically there are still other (non-daemon) threads running, that keep the JVM up.\nWhat I most likely need is the JVM option -XX:+ExitOnOutOfMemoryError (and a new enough JVM: http://www.oracle.com/technetwork/java/javase/8u92-relnotes-2949471.html).\nIt may be that Throwable-catching in Azkaban code doesn't cause any real problems.. I rather take back this suggestion, because it seems that catching Throwables could make things worse. Maybe sometimes a non-fatal throwable is thrown, and if it isn't caught, things like finishing a flow could be missed.. Review changes:\n\nRenamed variable missing -> noInitialStatus\nAdded comment \"job wasn't present in this flow during the original execution\". I don't know about that. You could look at the code to see if it's hard-coded or configurable.. I can't speak for the repo owners, but usually they have welcomed pull requests to add generally useful features (this seems like one).\n\nHowever I would recommend you to do what we do and keep your schedules in version control outside of Azkaban and deploy them from there via Azkaban's HTTP-based API. That way you can easily create a script to delete schedules & add them back.. 1. Can we change the default to -1 so that this feature is disabled unless the property is set?\n1. Shouldn't this feature be documented?\n1. In which file is this supposed to be set?\nBy the way seems that the property constant class has been moved to:\nhttps://github.com/azkaban/azkaban/blob/master/azkaban-common/src/main/java/azkaban/Constants.java#L89-L91. > The reason we have default value as 10 days is we do want to kill flows running over long being unnoticed.\nIsn't it a bit aggressive to have that as a default? Consider a user who has had a flow running happily for a couple of days and expects it to keep running.. Then it comes as a surprise that azkaban actually kills your flow after 10 days.\nIt's not only that it gives up tracking the execution, it even calls cancel() (which is kind of the right thing to do if Azkaban is going to stop tracking the execution, but..), which will definitely interrupt the running jobs in that execution.\nSorry, I couldn't find the sources for http://azkaban.github.io/azkaban/docs/latest/ in github. I wonder where it is..\n\nit's set in executor's property file\n\nBut the property is not present in the default executor props file. Having it there might help users because one usually reads through the props to see what they wanna customize when setting up Azkaban installation. I guess it should also be in the default props for solo Azkaban.. > Why would 10 days seem too short to you?\nIt's not as much about a specific limit. I think the execution time should be unlimited by default. That's the most natural behaviour. The problem is more like, 10 days is too much :) Because it can be easily missed, if you're testing that some job runs fine, maybe deploy/restart it once per week while still developing it.. then you consider that it's working fine, and leave it running there. But then it can come as a total surprise that the job gets suddenly auto-killed in the middle of the weekend and you get unexpected downtime.\nFor example we have a custom Azkaban job type that launches Apache Flink streaming jobs externally on AWS EMR. These streams are supposed to be going on forever unless touched. The job type also implements cancel(), which terminates the external EMR cluster. If the 10 day limit would be hit, the streaming job would be terminated, and we don't want that.\nFor people upgrading Azkaban from older version it can be easy to miss that they should add the new property to keep the existing behaviour. I think the optimal way to go about this would be to:\n- Default to -1 in Java code (if not defined)\n- Add to default props files, also set to -1 there as a \"default\"\nAt LinkedIn you could define the 10 day limit in props.\nThis is also related to \"Launching and monitoring long-living jobs (i.e. Samza, Storm, etc)\" mentioned on Azkaban 4.x Roadmap \u2013 for that use case it just doesn't make sense to stop after 10 days. By the way if you have some concepting document about this roadmap item, it would be good to mention azkaban.server.flow.max.running.minutes in there because it probably needs to be considered regardless of what the default is.. Ok, I'll create a PR to change the default. That means that the current comment on AZKABAN_MAX_FLOW_RUNNING_MINS can be left unchanged (ping @chengren311).\nThen the gh-pages branch needs an update as well \u2013 I will make a PR for that, too.. @justin-yan any chance you could share your code as a pull request so that others could fetch & use it?. Added commit:\nUse logger instead of printStackTrace()\n- Using the server logger instead of job log, because if JobRunner.doRun() throws an exception, it might be that the field JobRunner.logger is null.. Added commit:\nUse Guice to create AzkabanExecutorServer for testing:\n- Single constructor\n- Inject jetty Server instance from module. > My understanding of the goal of this change is that:\n\nMake FlowRunnerTest pass consistently so that we can re-enable it.\n\nI guess not a must if it can't be made run quickly enough, but I'm pretty sure we'll get there. But it will be useful to have it working even if only executed manually.\n\nThe intermediate job state change is not necessary but it has no user-visible impact. However, it makes FlowRunnerTest flaky. Am I right?\n\nYeah, that's my understanding. The change was needed to make the test work consistently. I guess the test could be stabilized with some synchronization instead of this change, but still it seems better to not have this back-and-forth setting of job status. There could be some place in the non-test code, too, where the job status is checked, and if it's temporarily FAILED instead of KILLED, something could go wrong.\n\nIt would be better if you can think of ways to make this change incrementally.\n\nI'll split this once ready otherwise.\n\nLet's try to keep the running time to the minimum.\n\nNaturally.. At the moment the test runs in ~5 seconds \u2013 and it's consistently passing. That's mostly because the kill/cancel test cases still use a sleep of 1 seconds. Should get rid of those and then we can remove @Ignore.. Now the test is quite fast: 0.557s on my laptop when run as part of the gradle build.. The injected Server dependency comes into play when you launch the server for realz. FlowRunnerTest passes new FakeServer() instead.. Split this into smaller chunks.. > AzkabanProcess..\nBut isn't that just in the scope of those job types? My question was about when JobRunner fails.. >> Is it a problem that the flow is sometimes saved with some \"outdated\" job statuses?\n\nI have not able to understand the sequence this happens.\n\nIn short, I guess this shouldn't really be any problem.\nJobRunner thread updates job statuses to ExecutableNode. The \"problem\" is, that the FlowRunner thread occasionally saves flow state into the DB, and that chunk of data also includes the job statuses. Because ExecutableNode.status is not synchronized (or volatile), it can happen that JobRunner has already set the status to something new, but FlowRunner writes to DB with an older job status after that.\nBut AFAIK this is still eventually consistent, because FlowRunner can't finalize the flow before it has seen that all job statuses are finished. Once it sees them, it writes the flow state once more and this time with the final statuses for all jobs.\nAlso AFAIK the flow state is a separate snapshot that includes also the job statuses. Apart from that I guess jobs are also saved to DB separately, and there the job status is never lagging.\n\nI remember seeing incorrect job status\n\nI can think of a case where executor node is terminated and on restart flow is just marked FAILED. In that case it may be that jobs are not cleaned up in the same way, and they can be for example left in RUNNING state forever. But this is not about synchronization of ExecutableNode.status.. I guess this can be closed in favour of https://github.com/azkaban/azkaban/pull/1113. Reopen if needed :). No hurry with this one from me. But I think this is definitely a nice improvement. Allows passing mocks to the constructor in a unit test etc.. Yes. Exactly.. Rebased & conflicts resolved.. How about this?. I wonder if @suvodeep-pyne is available to see this yet?. @suvodeep-pyne do you think this would be the way to go? I could resolve conflicts then... @suvodeep-pyne what do you say? I was originally asked to create this PR by some of the repo owners, and personally I would like to finish the job, because otherwise I would've done all of this in vain.. Yeah, Save Actions plugin is modifying some of the javadocs in AzkabanExecutorServer. I reverted those changes manually for now, but that class should be processed eventually.. I moved the constants as you requested, although I wouldn't endorse that kind of structure if it was up to me.\n\nAs long as it is a static variable, I don't think it should create a circular dependency since you don't need to instantiate the class to load a static constant.\n\nOk, I didn't mean a circular dependency in guice terms. I meant simply on Java code level. Not sure if there is a circle currently, but at least it becomes a good probability to happen when we start importing binding names from modules into concrete classes.\nMaybe a bigger argument for having the constants separataly is backed by DI itself. I mean, if we think about dependency injection with Guice more like as a principle, the idea is that dependencies can be provided from the outside. Now, when the AzkabanExecutorServer itself depends on a particular provider module (JettyServerModule), then it's not any more as much loose coupling, because you couldn't just remove JettyServerModule and make some other class provide the required injectables for AzkabanExecutorServer: because you also have to change the imports for the constants in AzkabanExecutorServer if JettyServerModule is deleted.. > How many Guice constants do we have in the immediate roadmap?\n\nHow many use cases of external injection, etc do we see in the near future?\nDo you plan to feed in your own Server and Context objects?\n\nI suppose none of these reasons apply currently :) I just like to avoid such dependencies in general. It might also help if these classes were subject to some refactoring in the future.\nSeems like this PR would be ready to merge?. @HappyRay, could you check this please?. Updated branch.\nHow this was speeded up: This test was being run using the default timeout values. In the test the normal request time is so short that we can set lower timeouts in test props and still test the timeout scenarios reliably.. No, this PR alone works fine.. Yes. But I haven't been able to make this fail now after I switched to using Mockito instead of the mock class that tangled with the job statuses. It requires extreme conditions to have this test fail because of the sync issue alone. To sum it up, this test is working fine even with that sync issue still lurking in the background.. Added the comment, @HappyRay.. Replaced by https://github.com/azkaban/azkaban/pull/1129. Yes, definitely.. IMHO it's not good that this test would modify the ExecutableNodes any way. The point is to just monitor the calls, similar to Mockito. So it's good to remove this problematic behavior in any case. Yes, volatile modifier should stabilize it, too, but I would see that as a separate issue.. Correct.. @HappyRay good to go?. @HappyRay: rebased & conflicts resolved.. > Do you mind reverting the code style change and only keep the functional change\nCan do, no problem.\n\nwe delayed reformatting some directories. This is one of them\n\nI believe you mean ExecutorManagerTest.java.. > Also since the original bug as described in \"The problem was this (revealed when running FlowRunnerTest that also uses this mock class): ... \" has been fixed, should this change description be modified?\nI think the current info should be kept, I will just add that since then FlowRunnerTest has been changed to use Mockito instead of MockExecutorLoader.. @HappyRay now without formatting changes.. @HappyRay & co., any chance to get some early feedback based on https://github.com/juhoautio/azkaban/pull/2? This is basically a working implementation, but it depends on some other PRs that I'd like to get in first. Then I will make a cleaned up & rebased PR based on https://github.com/juhoautio/azkaban/pull/2.. Yes, we override cancel(). We don't also want to restart when it causes interrupting some \"locally running jobs\". But it may be sometimes the only option to clean things up if a thread is stuck (in a custom job type). Related to restarting, we're planning support for resuming flows and jobs automatically if executor node crashes.. Thanks for the info. Currently we run a single web node + a single executor node (per environment). But going to explore \"rolling deployements\" with multi executor setup. We don't really need multiple nodes to scale the jobs themselves because we execute heavy stuff on external systems (launched & tracked by azkaban).. We had a discussion about the resuming feature in gittter.im, azkaban/Lobby. Wanna join the chat?. I took the notes from gitter discussion and cleaned them up into this new issue: https://github.com/azkaban/azkaban/issues/1127. Resolved by https://github.com/azkaban/azkaban/pull/1509. Yay \\o/. Hopefully soon, but as you can see this post is only 4 days old. First we would need review of this plan by repo owners and an \"ok\" before we can start implementing it in practice. I would say it will still take weeks before this could be seen as a working feature in the master branch.. The main motivation is being able to ensure that important scheduled flows are completed even if the executor crashes in the middle of an execution. A part of ensuring that is the ability to continue externally running jobs in a clean way after any kind of restart.\n- It would be a real problem if we couldn't continue polling externally launched jobs after a restart and launch a new overlapping job instead. Currently we have a custom way to synchronize the external jobs via a DB, but this still means that when we resume polling the job gets a new execution id and the previous execution has been marked as FAILED.\nMain OOM scenarios are:\n\nMetaspace (Java 8) runs out after reloading custom job types multiple times\nBecause each reload creates new classloaders that aren't always entirely cleaned up, most often because of some background threads left running and preventing classes to be garbage collected from the old classloaders\n\n\nOS level \"OOM\" that makes OS sacrifice java process and kills it\nThis can happen if additional processes created by command jobs consume too much memory (as a special case when a process creates sub-processes). That's partially caused because we have disabled available memory check before running command jobs, because of reasons.\n\n\nToo many / heavy flows running at the same time, basic OOM\nI can't be sure, but I think this is because azkaban-executor creates instances of ExcutableNode/ExecutableFlow for each node in the graph.\nExample of heavy graph: you have chained, say, some big flow, into a bigger flow that runs the same big sub-flow in a of sequence 30 times. \n\n\nRunning out of heap size because of running enough ~memory-hungry jobs that run within the executor JVM\nHasn't really happened to us, but I can imagine it rather easily\n\n\n\nOf course if we hit any of these issues we try to fix the cause of the problem. But you can't always predict problems so Azkaban should be able to recover from crashes automatically.\n\nI am interested in supporting a way to restart the executor process without affecting the running job processes.\n\nSounds nice \ud83d\udc4d We don't usually run any child process jobs, but I can see that being a really nice additional feature, that can help uninterrupted execution as long as the executor instance remains the same and hasn't been restarted on OS level.. > I'm curious about how you would plan to implement setState and getState\nFirst of all note that Job#setState(JobState) and JobState#setState(Props) are entirely different methods. Actually should rename the latter to JobState#setProps(Props). But I'll stick with the original method name for now..\nThen to some kind of impl. plan.\nLook at JobTypeManager#buildJobExecutor. When building the executor:\n1. Check if the job is resumable (how exactly, depends on what kind of Job API is chosen for resumable job types)\n1. Instantiate the job type as usual (call constructor with reflection)\n1. Call Job#setState on the created instance\n1. Continue as normal, eventually Job#run is called\nCreating the JobState:\n1. This would probably happen elsewhere and get passed as an argument to JobTypeManager#buildJobExecutor\n1. Load the state Props from DB by <execution id + attempt number> (if exists).\n1. If state is found for this execution/attempt, then it's a resume case and JobState is created with those Props and isResume=true. Otherwise it's created with empty Props and isResume=false.\n1. Set the state on the job by calling Job#setState\nAlso JobState needs to have a way to persist the Props into DB when the Job calls JobState #setState. So some kind of DB gateway instance must be passed to JobState constructor.\n\nand how do we define a state exactly?\n\nI'm not sure what this question means?. Thanks @priyanshjain28. We didn't consider \"replay\" mode for schedules, but that's a good addition, definitely. I think it could be handled separately, though. We haven't written any code for this yet. I was aiming at getting a common agreement on the specification with the repo owners before starting to implement anything. The goal being, getting code review to catch problems, and having this feature merged into the public repo to avoid diff with our own fork. We could have time to implement this, but I'm not sure how quickly we will be able to have a spec greenlighted by @HappyRay and @chengren311.. I'm going to start working on this. As there hasn't been a chance to prepare & agree on the spec with repo owners, I believe it won't be easy to get it merged in.. But even if so, please give any last feedback you might have. I think I'm going to drop a PR just for reference once this feature is ready.. I expect resuming functionality to have no impact on the DAG execution part of the application. Or it should be small at least.\nWe don't run multi-executor yet, but hoping to switch to that at some point. Making that switch requires some additional tooling and conf changes.\nYes, using multi-executor mode would help us with a deployment a bit and that alone is a reason enough to take it into use. But it won't help us with:\n- executor crash scenarios (because azkaban doesn't start the interrupted flows again)\n- long-running \"streaming jobs\" (can be running for days) that are running on an external cluster, that we'd rather not interrupt, but just continue tracking them. @swamisun yes, we have this implemented according to our needs and it's been in production use for a while. For us it was enough for now to implement the bullet points that you can find in the issue description in the beginning of the Design section (the ones before New Job API etc.)\nIn our case resumable jobs are typically such that are actually tracking some external task. The external task ids we store into a database in our custom job types so that they can fetch them from there when a job is resumed. It would be nicer if azkaban itself would support JobState as described above.\nAny way, if this (what we have) suits your needs, I guess I could prepare a pull request to share the code. But currently it seems to me like it won't get to be included in the main Azkaban repository at least any time soon.. Removed the duplicate assert.. Oops, new merge conflicts.. Is it now a good time to resolve them, so that this could be merged before new conflicts arrive? :). So do you actually require Intellij Save Actions Plugin to be applied on the code before submitting pull requests? Or is this formatting I have here fine as long as merge conflicts have been resolved?. I took the save actions plugin into use, so the diff grew a bit. I like how it improves the code structure, though.. > Could you carry over the details in the change description you had in #115?\nAdded (actually #1115).. Looks like running the FlowRunner in its own thread in FlowRunnerTest was indeed enough to get rid of ClosedByInterruptException in FileUtils.copyDirectory.. Ok done with the cleanup.. One more commit:\nMockExecutorLoader to use thread safe maps\n- This should be the proper fix to concurrency issue in updateExecutableNode().\n..but let's see how Travis likes it.\n\nedit: seems fine. Also we got one more successful test run for extra confidence now that I pushed one more commit below:. Sorry, I didn't see that happen. If you like, could add @Ignore asap. I can take a look later.. @HappyRay shared this with me, but it wasn't yet enough for me to run the solo-server successfully:\n\nI can start solo server in Intellij.\n\n\n\nHere is my property file\nazkaban/temp/conf/azkaban.properties:\n\n```sh\nAzkaban Personalization Settings\nazkaban.name=Local\nazkaban.label=My Local Azkaban\nazkaban.color=#FF3601\nthis assumes that this file is under a //conf directory\nweb.resource.dir=../azkaban-web-server/build/install/azkaban-web-server/web\ndefault.timezone.id=America/Los_Angeles\nAzkaban UserManager class\nuser.manager.class=azkaban.user.XmlUserManager\nuser.manager.xml.file=conf/azkaban-users.xml\nLoader for projects\nexecutor.global.properties=conf/global.properties\nazkaban.project.dir=projects\nazkaban.execution.dir=executions\nDB\ndatabase.sql.scripts.dir=../azkaban-db/src/main/sql\ndatabase.check.version=true\ndatabase.auto.update.tables=true\nmysql\ndatabase.type=mysql\nmysql.port=3306\nmysql.host=localhost\nmysql.database=azkaban\nmysql.numconnections=100\nh2 db\ndatabase.type=h2\nh2.path=data/azkaban\nh2.create.tables=true\nazkaban.jobtype.plugin.dir=plugins/jobtypes\nVelocity dev mode\nvelocity.dev.mode=false\nvelocity.dev.mode=true\nAzkaban Jetty server properties. Ignored in tomcat\njetty.use.ssl=false\njetty.ssl.port=8043\njetty.maxThreads=25\njetty.port=8081\nAzkaban Executor settings\nexecutor.maxThreads=50\nexecutor.flow.threads=30\nmail settings\nmail.sender=\nmail.host=\njob.failure.email=\njob.success.email=\nlockdown.create.projects=false\nJMX stats\njetty.connector.stats=true\nexecutor.connector.stats=true\nuncomment to enable inmemory stats for azkaban\nexecutor.metric.reports=true\nexecutor.metric.milisecinterval.default=60000\n```. So far I had to at least add these to get rid of some errors:\nsh\nmysql.user=\nmysql.password=\nAnd change these paths:\nsh\nuser.manager.xml.file=../azkaban-solo-server/src/main/resources/conf/azkaban-users.xml\nexecutor.global.properties=../azkaban-solo-server/src/main/resources/conf/global.properties\nI'm getting this error in the console:\n```\n2017/05/29 16:04:43.453 +0300 INFO [AzkabanExecutorServer] [Azkaban] No value for property: jmx.attribute.processor.class was found\n2017/05/29 16:04:43.453 +0300 INFO [log] [Azkaban] jetty-6.1.26\n2017/05/29 16:04:43.474 +0300 INFO [log] [Azkaban] Started SocketConnector@0.0.0.0:58691\nException in thread \"main\" 2017/05/29 16:04:43.508 +0300 INFO [AzkabanExecutorServer] [Azkaban] Started Executor Server on 192.168.184.228:58691\ncom.google.inject.ProvisionException: Unable to provision, see the following errors:\n1) Error injecting constructor, azkaban.executor.ExecutorManagerException: No active executor found\n  at azkaban.executor.ExecutorManager.(ExecutorManager.java:128)\n  at azkaban.AzkabanCommonModule.configure(AzkabanCommonModule.java:83)\n  while locating azkaban.executor.ExecutorManager\n  at azkaban.webapp.AzkabanWebServer.(AzkabanWebServer.java:186)\n  at azkaban.webapp.AzkabanWebServerModule.configure(AzkabanWebServerModule.java:33)\n  while locating azkaban.webapp.AzkabanWebServer\n    for the 1st parameter of azkaban.soloserver.AzkabanSingleServer.(AzkabanSingleServer.java:44)\n  while locating azkaban.soloserver.AzkabanSingleServer\n1 error\n    at com.google.inject.internal.InjectorImpl$2.get(InjectorImpl.java:1028)\n    at com.google.inject.internal.InjectorImpl.getInstance(InjectorImpl.java:1054)\n    at azkaban.soloserver.AzkabanSingleServer.main(AzkabanSingleServer.java:82)\nCaused by: azkaban.executor.ExecutorManagerException: No active executor found\n    at azkaban.executor.ExecutorManager.setupExecutors(ExecutorManager.java:221)\n    at azkaban.executor.ExecutorManager.(ExecutorManager.java:132)\n    at azkaban.executor.ExecutorManager$$FastClassByGuice$$e1c1dfed.newInstance()\n    at com.google.inject.internal.DefaultConstructionProxyFactory$FastClassProxy.newInstance(DefaultConstructionProxyFactory.java:89)\n    at com.google.inject.internal.ConstructorInjector.provision(ConstructorInjector.java:111)\n    at com.google.inject.internal.ConstructorInjector.construct(ConstructorInjector.java:90)\n    at com.google.inject.internal.ConstructorBindingImpl$Factory.get(ConstructorBindingImpl.java:268)\n    at com.google.inject.internal.ProviderToInternalFactoryAdapter$1.call(ProviderToInternalFactoryAdapter.java:46)\n    at com.google.inject.internal.InjectorImpl.callInContext(InjectorImpl.java:1092)\n    at com.google.inject.internal.ProviderToInternalFactoryAdapter.get(ProviderToInternalFactoryAdapter.java:40)\n    at com.google.inject.internal.SingletonScope$1.get(SingletonScope.java:194)\n    at com.google.inject.internal.InternalFactoryToProviderAdapter.get(InternalFactoryToProviderAdapter.java:41)\n    at com.google.inject.internal.InjectorImpl$2$1.call(InjectorImpl.java:1019)\n    at com.google.inject.internal.InjectorImpl.callInContext(InjectorImpl.java:1092)\n    at com.google.inject.internal.InjectorImpl$2.get(InjectorImpl.java:1015)\n    at com.google.inject.internal.InjectorImpl.getInstance(InjectorImpl.java:1054)\n    at azkaban.ServiceProvider.getInstance(ServiceProvider.java:52)\n    at azkaban.webapp.AzkabanWebServer.(AzkabanWebServer.java:195)\n    at azkaban.webapp.AzkabanWebServer$$FastClassByGuice$$81e0dd4a.newInstance()\n    at com.google.inject.internal.DefaultConstructionProxyFactory$FastClassProxy.newInstance(DefaultConstructionProxyFactory.java:89)\n    at com.google.inject.internal.ConstructorInjector.provision(ConstructorInjector.java:111)\n    at com.google.inject.internal.ConstructorInjector.construct(ConstructorInjector.java:90)\n    at com.google.inject.internal.ConstructorBindingImpl$Factory.get(ConstructorBindingImpl.java:268)\n    at com.google.inject.internal.ProviderToInternalFactoryAdapter$1.call(ProviderToInternalFactoryAdapter.java:46)\n    at com.google.inject.internal.InjectorImpl.callInContext(InjectorImpl.java:1092)\n    at com.google.inject.internal.ProviderToInternalFactoryAdapter.get(ProviderToInternalFactoryAdapter.java:40)\n    at com.google.inject.internal.SingletonScope$1.get(SingletonScope.java:194)\n    at com.google.inject.internal.InternalFactoryToProviderAdapter.get(InternalFactoryToProviderAdapter.java:41)\n    at com.google.inject.internal.SingleParameterInjector.inject(SingleParameterInjector.java:38)\n    at com.google.inject.internal.SingleParameterInjector.getAll(SingleParameterInjector.java:62)\n    at com.google.inject.internal.ConstructorInjector.provision(ConstructorInjector.java:110)\n    at com.google.inject.internal.ConstructorInjector.construct(ConstructorInjector.java:90)\n    at com.google.inject.internal.ConstructorBindingImpl$Factory.get(ConstructorBindingImpl.java:268)\n    at com.google.inject.internal.InjectorImpl$2$1.call(InjectorImpl.java:1019)\n    at com.google.inject.internal.InjectorImpl.callInContext(InjectorImpl.java:1085)\n    at com.google.inject.internal.InjectorImpl$2.get(InjectorImpl.java:1015)\n    ... 2 more\n``. Wow, thanks @kunkun-tang, that did the trick. Indeed that's also present inazkaban-solo-server/src/main/resources/conf/azkaban.properties`.\nI wonder how the conf that @HappyRay uses works then.. @HappyRay: could you copy here your complete set of VM Options? It gets cut off in the screenshot.. Clear then.\nDo you see a way how this could be supported \"out of the box\", just by running the AzkabanSingleServer without having to set up additional conf?\nAnd what about .less compilation in development mode?. Yes, I can try. I'm just wondering which way to go.. Maybe something like this:\n- When AzkabanSingleServer is executed without any args..\n  - If running for the first time, copy some required conf files to local/ (a new folder not managed by git)\n  - This way user is able to make changes like DB conf without having dirty files on git staging area\n  - So local/ is added to .gitignore, by the way which already has this:\n    # temp directory is ignored so that it can be used to store temporary files such as local testing configurations.\n    temp/\n\n- But I would prefer `local/` over `temp/` for the conf, because maybe it's not really that temporary if you have set your db credentials there etc.. do you mind what the folder is called?\n\n\nThen if local/azkaban.properties exists, run as if executed with -conf local\nMaybe this to auto-detect .less changes: https://github.com/houbie/lesscss-gradle-plugin#lesscdaemon-task\nwhat do you think? It would need to be started manually, but could be setup so that you only need to run one command to start it.\nI wonder if there's something similar to copy any of the static web files, so that you could edit them in the git-managed location but see changes instantly on the web pages.. Roger that. I didn't really check that less plugin at all yet, so I didn't notice that it's discouraged. Going to try the suggested alternatives instead.. Implemented in https://github.com/azkaban/azkaban/pull/1423. Oh perfect, of course it works. I didn't remember <pre> and only tried with <code>, which didn't help!. \ud83d\udc4d/+1/LGTM. \ud83d\udc4d . Good stuff \ud83d\udc4d Indeed I wanted to avoid making too many changes in the original PR that was to make these tests pass, although I could see a lot that could've been cleaned up. No more IDE warnings then?. For example look at these lines:\nhttps://github.com/azkaban/azkaban/blob/c55e88237ebc252eaedca6e2ea32e38cf853fca2/azkaban-exec-server/src/test/java/azkaban/execapp/FlowRunnerTest.java#L166-L173\n\u2013\u00a0shouldn't need to do anything else but call eventCollector.checkEventExists, and that in turn should be simplified to user Assert.* methods instead of custom conditions + throws: https://github.com/azkaban/azkaban/blob/c55e88237ebc252eaedca6e2ea32e38cf853fca2/azkaban-exec-server/src/test/java/azkaban/execapp/EventCollectorListener.java#L83-L91. Yeah I can handle that Exception -> Assert change, that I mention in https://github.com/azkaban/azkaban/pull/1147#issuecomment-306003984.. > How did you make the test pass before this bug is fixed?\n\nYeah, the test still passed, it just printed this error in the console and I happened to notice it.\nThis test only checks that a status change event to JOB_FINISHED was fired. It doesn't check the \"saved\" ExecutableNode status in MockExecutorLoader, so the test passed regardless of this error. And one part is of course that the error is being ignored in JobRunner instead of stopping there, which we discussed above.. Did I understand correctly that you like to have this change as it is? And make those further improvements separately.. But let me know if you're still expecting something from me here.. Added commit, assert that caught the error before fix in JobRunner. Next: resolving conflicts.. @HappyRay, plz check again.. > Have you considered using assertj instead?\nassertj is better in general, but in this case I'd like to stick with hamcrest, because:\n- No need to add assertj as a gradle dependency (hamcrest is already there)\n- In this particular case assertj API doesn't make it much simpler compared to using hamcrest API (and after all this is already written now \u2013 maybe the main benefit of assertj is that it's easy to write assertions with IDE)\n- I don't know what kind of output assertj would give in the error case, but I know for sure that hamcrest now gives exactly what's the right thing to print. So created https://github.com/azkaban/azkaban/pull/1152 and https://github.com/azkaban/azkaban/pull/1153 to follow.. \ud83d\udc4d (sorry forgot to say ok! my comments were just extra suggestions). Thanks for gathering the logs & stack traces. I ran FlowRunnerTest2 100 times in a row locally and got 1 failure, so should be possible to catch at least something.. @HappyRay, this issue can be closed.. Thanks. https://github.com/azkaban/azkaban/pull/1159 was also needed to fix.. Valid concern. I'll try to replicate the random failures by running the test multiple times in a row.. Looks like that error came from a synchronization issue, the way how ExecutableFlowBase#isFlowFinished works. I'm going to fix this by not calling that method but checking the flow finishing in another way.. Fix for that test failure is here: https://github.com/azkaban/azkaban/pull/1158. Yeah, I was thinking the same thing. Closing.. Regardless of the build failure, this change is for the better, because it narrows down the ways of checking statuses concurrently.. > Could you share more details on the problem and how the fix works?\nAdded to PR description.. > Can you think of ways to simplfy? e.g. can we do without mutliple threads?\nSure there are different ways to simplify and make this more robust. Maybe the simplest way would be to keep the threads as they are but use some concurrent utilities to make things easier to manage.. > Why is the new code thread safe?\nBecause it just checks the flow status, not statuses of every job in the flow. And this is enough to check if the flow has finished.. Added commit: \"Make ExecutableNode.status volatile\". Also added to PR description. After that change I just ran FlowRunnerTest2 1000 times in a row locally and didn't get a single test failure. Note that I didn't have anything @Ignored in the test.. Same thing with FlowRunnerTest\u00a0\u2013 ran 1000 times locally without failures (after making ExecutableNode.status volatile).. Now that I merged from master there are some of those @Ignores added. Once this has been merged I can create a new PR to remove the @Ignores.. Made a separate PR for that volatile status field: https://github.com/azkaban/azkaban/pull/1159. Only one test seems to fail randomly now:\n```\nazkaban.execapp.FlowRunnerTest2 > testRetryOnFailure[1] FAILED\n    java.lang.AssertionError: Wrong status for [jobb:innerFlow] expected: but was:\n        at org.junit.Assert.fail(Assert.java:88)\n        at org.junit.Assert.failNotEquals(Assert.java:834)\n        at org.junit.Assert.assertEquals(Assert.java:118)\n        at azkaban.execapp.FlowRunnerTestBase.assertStatus(FlowRunnerTestBase.java:139)\n        at azkaban.execapp.FlowRunnerTest2.testRetryOnFailure(FlowRunnerTest2.java:670)\nazkaban.execapp.FlowRunnerTest2 > testRetryOnFailure[20] FAILED\n    java.lang.AssertionError: Wrong status for [jobb:innerFlow] expected: but was:\n        at org.junit.Assert.fail(Assert.java:88)\n        at org.junit.Assert.failNotEquals(Assert.java:834)\n        at org.junit.Assert.assertEquals(Assert.java:118)\n        at azkaban.execapp.FlowRunnerTestBase.assertStatus(FlowRunnerTestBase.java:139)\n        at azkaban.execapp.FlowRunnerTest2.testRetryOnFailure(FlowRunnerTest2.java:670)\nazkaban.execapp.FlowRunnerTest2 > testRetryOnFailure[26] FAILED\n    java.lang.AssertionError: Wrong status for [jobb:innerFlow] expected: but was:\n        at org.junit.Assert.fail(Assert.java:88)\n        at org.junit.Assert.failNotEquals(Assert.java:834)\n        at org.junit.Assert.assertEquals(Assert.java:118)\n        at azkaban.execapp.FlowRunnerTestBase.assertStatus(FlowRunnerTestBase.java:139)\n        at azkaban.execapp.FlowRunnerTest2.testRetryOnFailure(FlowRunnerTest2.java:670)\nazkaban.execapp.FlowRunnerTest2 > testRetryOnFailure[33] FAILED\n    java.lang.AssertionError: Wrong status for [jobb:innerFlow] expected: but was:\n        at org.junit.Assert.fail(Assert.java:88)\n        at org.junit.Assert.failNotEquals(Assert.java:834)\n        at org.junit.Assert.assertEquals(Assert.java:118)\n        at azkaban.execapp.FlowRunnerTestBase.assertStatus(FlowRunnerTestBase.java:139)\n        at azkaban.execapp.FlowRunnerTest2.testRetryOnFailure(FlowRunnerTest2.java:670)\nazkaban.execapp.FlowRunnerTest2 > testRetryOnFailure[41] FAILED\n    java.lang.AssertionError: Wrong status for [jobb:innerFlow] expected: but was:\n        at org.junit.Assert.fail(Assert.java:88)\n        at org.junit.Assert.failNotEquals(Assert.java:834)\n        at org.junit.Assert.assertEquals(Assert.java:118)\n        at azkaban.execapp.FlowRunnerTestBase.assertStatus(FlowRunnerTestBase.java:139)\n        at azkaban.execapp.FlowRunnerTest2.testRetryOnFailure(FlowRunnerTest2.java:670)\n1457 tests completed, 5 failed, 22 skipped\n:azkaban-exec-server:test FAILED\n. lol:\nExecution failed for task ':azkaban-exec-server:test'.\n\nProcess 'Gradle Test Executor 4' finished with non-zero exit value 137\n```\nSo I guess it ran out of system resources this time.. It's too bad that Travis started failing on system resources now.. I guess it's too intensive to run 100x. Now trying 50x instead... Well, there we have it: successful build with 50x flow runner tests:\nhttps://travis-ci.org/azkaban/azkaban/builds/239387042\n\nNow I'll try once more that 100x.. Now already 2 builds with 50x succeeded and no test failures seen. I'm pretty confident that it's all good now.. The fix as its own PR: https://github.com/azkaban/azkaban/pull/1162. Resolved conflicts.. Good catch \ud83d\udc4c. Thank you @chengren311! Fixed the bad formatting. Waiting for your thoughts on that ImmutableMap.. @chengren311, could I have your verdict on https://github.com/azkaban/azkaban/pull/1172#discussion_r120729789 ?. Changed to ImmutableMap.. @chengren311: I've resolved all comments so far.. @chengren311: now fixed per comments, rebased & resolved conflicts.. @chengren311 anything else?. Hm.. bump? :). @chengren311 (same story as for the stuck pipeline fix..) I'd like to have this in use ASAP. What do you think, will you be able to review and get this merged on this side soon? I'd rather do it that way but can of course apply on our fork if not possible to prioritize here.. Added commit:\n```\nFix KILLED vs. FAILED status propagation\nBring back original assertions in FlowRunnerTest2.\n```\nAs you can see, FlowRunnerTest2 remains unchanged now when all commits are combined.. > where do we set job status from killing to killed\nThis is handled by existing code in JobRunner#doRun.\nIt's basically like this:\njava\n    runJob();\n    if (isKilled()) {\n      finalStatus = changeStatus(Status.KILLED);\n    }. > also how would killing status work with concurrent execution options?\nKILLING blocks in a pipeline the same way that RUNNING does. This may actually make the pipelining more robust in some situations. I think that before introducing KILLING status, RemoteFlowWatcher may have seen KILLED and deemed it as finished, allowing a pipelined job to be unblocked, even if the blocking job run had not completely ended yet.. Tests revealed a race condition that can make the flow not terminate. \nI need to figure it out before this is ready for production.\nI managed to reproduce the failure once locally, and for that test run I found this in the logs:\nINFO [JobRunner-job6-1] [derived-member-data-2] Job job6 finished with status KILLING in 0 seconds\nThat should not happen, as this is logged in a branch of FlowRunner.JobRunnerEventListener.handleEvent that handles event.getType() == Type.JOB_FINISHED. When handleEvent is called, the status should already be KILLED?. Ha, found & fixed. Added commit: Fix a race condition that prevents setting KILLING->KILLED (by making JobRunner.killed volatile).\nThis makes me wonder about JobRunner's other field: private BlockingStatus currentBlockStatus, which is accessed from another thread when JobRunner.kill() is called. I suppose that field should also be volatile.. Not related to this PR but just happened to notice.. Great catch.\nAdded commit:\n```\nBetter thread safety in FlowRunner\nMake the boolean flags volatile, because these are accessed from different threads.\n```. @jamiesjc definitely! Also it's been working without any problems on our deployments after those fixes that were made soon after introducing it.. @jamiesjc is there some way to proceed right now?. Yes. I guess I'll just revert the previous revert commit and resolve possible conflicts.. Here: https://github.com/azkaban/azkaban/pull/1509. I don't get it. How i this any different?. Ok, this changes it so that job is run even if upload fails. If that's normal, then shouldn't be logging an error about it. Better avoid upload when not needed, or even better: do it in a way that only inserts if it doesn't already exist?. Isn't project id the same if two subflows (in a flow) contain the same job? So should use full nested id or something?. But if this is currently affecting all such cases, isn't this a serious problem to have in master even for the time before a proper fix? Or are you doing that really soon now?. Ok. For us that's not even a rare case. Would it be possible to reopen this fix & merge to master for the time being?. Yeah subflows are also used. We're running a fork where #1167 has been reverted, so I haven't ever seen that problem in effect myself.. > @chengren311 is not familiar with the tests that failed after this change was made.\n@HappyRay, could you clarify what tests you mean? Also what is \"this change\" in your comment?\nMy understanding is that this isn't about any tests failing \u2013 at least not unit tests in this repo. The commit https://github.com/azkaban/azkaban/commit/ffd9ebd4910cd9e8ac46494c90c14f4d8a2cd7a2 was only done to \"fail faster\" (see the commit message there). I would still like to revert that commit until the job node key in DB is made unique also across sibling sub-flows. So I don't see a need to create a new pull request, because this (#1179), could be reopened for that purpose.. I have no idea about those failures :O The only simple explanation I can think of is that Travis was running really slow, so that the maximum waiting time limits are not enough.. I applied this \"revert\" locally on current master and ran those two failed tests 1000 times in a row \u2013 no failures (FlowRunnerTest2 > testFailedFinishingFailure3 & FlowRunnerTest > execAndCancel).. To continue on that, we can of course make the waiting timeouts longer to add stability in case of unexpected test runner slowness. On the other hand I feel that the current extra 1-2 seconds of waiting is quite much already, when you're actively developing something, so that the tests are failing because your changes are not good yet.. I tested what kinda message it prints in case of a failure, this:\norg.junit.ComparisonFailure: \nExpected :[FLOW_STARTED]\nActual   :[FLOW_STARTED, FLOW_FINISHED]\nIt's cool.. So, how about this? Quite clear that the occasional test failures were not caused by this change.. @HappyRay indeed it didn't fail even once. We will see another try after updating with current master... On this second run note that no tests failed. Travis ran out of resources running this intensive repeated test run:\n```\n* What went wrong:\nExecution failed for task ':azkaban-exec-server:test'.\n\nProcess 'Gradle Test Executor 4' finished with non-zero exit value 137\n```. Testing done, closing this.. Thanks for the comment.\nBackfill support is something we are considering too.\n\nCan you see it on some position of your 4.x roadmap? ping @ameyamk. Can you get the console output for the failed test on that Travis build somehow? Otherwise it's much harder to fix, when this can't be reproduced locally.. For example I ran both FlowRunner tests 2 x 50 times on Travis and there were no failures (see https://github.com/azkaban/azkaban/pull/1186). I also ran them 1000 x locally, no failures..\nLast time that there was a Travis failure, the failed tests were:\nazkaban.execapp.FlowRunnerTest > execAndCancel \nazkaban.execapp.FlowRunnerTest2 > testFailedFinishingFailure3 (this is the same that you reported as failed now again)\nI would add @Ignore only on those two test methods, not on entire files.\nStill, it would be really good if all of these tests could be kept running & stable, of course.. Should we give it a try and increase the minimum timeouts? Or maybe I can try to find the culprit locally by decreasing different timeouts temporarily... Here, maybe one last try before ignores :}\nhttps://github.com/azkaban/azkaban/pull/1207. Are you going to enable it for Travis builds? Otherwise it can be hard to catch problems if they occur rarely.. But I guess there haven't been more random failures after the latest stability fixes?. I'll try to figure out why this could happen.. Oh quite clear, that FlowRunnerTestBase.waitFlowRunner where it failed still only had 100 x 10ms max wait. Changing it to 1000 x 10 ms.. Fix: https://github.com/azkaban/azkaban/pull/1220. Would you like to have these tests? Looks like there's a new conflict to resolve.. Rebased with conflicts resolved.. Good stuff @HappyRay \ud83d\udc4d \nI have resolved the review comments so far. Anything else?. @HappyRay I went looking for the failed build because your message didn't reveal what the wrong status was :) Hmm but I didn't find it. Could you edit your message wrapping the stracktrace into a codeblock?\nI'll try to see if I can figure out what could cause it. It's a pity if we can't get the full output of this run from Travis.. No worries as I guess there wasn't more to obtain after all. That expected:<RUNNING> but was:<QUEUED> was what I was looking for.. This should be ok as well.\nI checked what tests failed in that build c74fad3. They are not related to FlowRunnerPipelineTest. \n```\nazkaban.execapp.FlowRunnerTest2 > testPauseFailFinishAll FAILED\n    java.lang.IllegalStateException: joba wasn't added in testJobs map\n        at azkaban.executor.InteractiveTestJob.getTestJob(InteractiveTestJob.java:55)\n        at azkaban.execapp.FlowRunnerTest2.testPauseFailFinishAll(FlowRunnerTest2.java:996)\nazkaban.execapp.JobRunnerTest > testDelayedExecutionCancelledJob FAILED\n    java.lang.AssertionError\n        at org.junit.Assert.fail(Assert.java:86)\n        at org.junit.Assert.assertTrue(Assert.java:41)\n        at org.junit.Assert.assertTrue(Assert.java:52)\n        at azkaban.execapp.JobRunnerTest.testDelayedExecutionCancelledJob(JobRunnerTest.java:303)\n:azkaban-web-server:test FAILED\nazkaban.execapp.FlowRunnerTest2 > testPause FAILED\n    java.lang.AssertionError: Wrong status for [joba] expected: but was:\n        at org.junit.Assert.fail(Assert.java:88)\n        at org.junit.Assert.failNotEquals(Assert.java:834)\n        at org.junit.Assert.assertEquals(Assert.java:118)\n        at azkaban.execapp.FlowRunnerTestBase.assertStatus(FlowRunnerTestBase.java:131)\n        at azkaban.execapp.FlowRunnerTestBase.assertStatus(FlowRunnerTestBase.java:136)\n        at azkaban.execapp.FlowRunnerTest2.testPause(FlowRunnerTest2.java:804)\n``. @inramana, just pinging in case this got buried under other things.. Would be nice to get this in so that we can proceed with the actual bug fix: https://github.com/azkaban/azkaban/pull/1245.. Conflicts resolved.. So.. would you like to have these tests? Looks like there's a new conflict to resolve.. Rebased & fixed.. Good that you mentioned the TemporaryFolder rule in https://github.com/azkaban/azkaban/pull/1243 \u2013 also used here now. Before this change the test was contaminatingtest/execution-test-data/exectest1/` with some temporary files :). I checked what tests failed in that build 88fb0ad. They are not related to RemoteFlowWatcherTest. \n```\nazkaban.execapp.event.JobCallbackRequestMakerTest > basicPostTest FAILED\n    org.junit.runners.model.TestTimedOutException: test timed out after 4000 milliseconds\n        at sun.misc.Unsafe.park(Native Method)\n        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)\n        at java.util.concurrent.FutureTask.awaitDone(FutureTask.java:426)\n        at java.util.concurrent.FutureTask.get(FutureTask.java:204)\n        at azkaban.execapp.event.JobCallbackRequestMaker.makeHttpRequest(JobCallbackRequestMaker.java:153)\n        at azkaban.execapp.event.JobCallbackRequestMakerTest.basicPostTest(JobCallbackRequestMakerTest.java:164)\nazkaban.execapp.event.JobCallbackRequestMakerTest > unResponsiveGetTest FAILED\n    org.junit.runners.model.TestTimedOutException: test timed out after 4000 milliseconds\n        at sun.misc.Unsafe.park(Native Method)\n        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)\n        at java.util.concurrent.FutureTask.awaitDone(FutureTask.java:426)\n        at java.util.concurrent.FutureTask.get(FutureTask.java:204)\n        at azkaban.execapp.event.JobCallbackRequestMaker.makeHttpRequest(JobCallbackRequestMaker.java:153)\n        at azkaban.execapp.event.JobCallbackRequestMakerTest.unResponsiveGetTest(JobCallbackRequestMakerTest.java:144)\n```. So this should be ok.. Applied save actions. As far as I can see, @HappyRay's open comments are about refactoring that should be done separately. Ready to merge?. @HappyRay & co., I'd like to have this fix in use ASAP. What do you think, will you be able to review and get this merged on this side soon? I'd rather do it that way but can of course apply on our fork if not possible to prioritize here.. Yeah, I got this proven with a unit test that disables a sub-flow. That's shared at #1248.. > Is it ok to merge this before #1243?\nRather not, because #1243 provides the basis for having the unit test.. Also testBasicPipelineLevel1RunDisabledJobs remains to be brought into this from https://github.com/azkaban/azkaban/pull/1248. I can do that once https://github.com/azkaban/azkaban/pull/1243 has been merged.. > what do you think about deprecating the support for level 1 and 2 pipeline modes and replace them with another option: run the flow after the previous one finishes.\nI wouldn't remove that feature. It has been actually the default mode that we use. I would expect this to be generally useful, as long as users are aware of it.\nThe main reason for us is that we have some flows with a lot of jobs, and we don't want the next days run blocked entirely by the previous days flow if some jobs from that are running slow or are even stuck.\nAnother case where the job level pipelining is really useful is backfilling. A simple example is that there's a combination of a hive job and an SQL job that both take 1 hour to run and handle a single day. Consider also that there can only be one of each job running at the same time, so it's not possible to run the flow in parallel. Now, if you want to run this flow to backfill some 4 days, it can finish in 5 hours. If it would need to wait on flow level it would take 8 hours. The speed boost is of course bigger if there are more long-running sub-sequent jobs in the flow.\n\nThe current level1 and 2 pipeline modes are rarely used inside Linkedin and are not well understood and tested.\n\nIt's true that it's a bit hard to understand. Maybe the terminology (level 1 / 2) could be deprecated, but keep the feature and give it more descriptive names. Like: pipeline: flow level and pipeline: job level?\n\nThis will greatly simplify the code. It will make the engine rewrite project simpler.\n\nI would tend to think that it should be possible to manage pipelining semi-individually \u2013 it shouldn't make the DAG processing code that much more complicated?. > Could you resolve the conflict?\nYes, now that #1243 is in.. Ready to roll again.. Yes, it can be quite a lot of work.. Updated branch. As expected, before fixes adding the test in 75ef7ad gave this Travis failure:\nazkaban.execapp.FlowRunnerPipelineTest > testBasicPipelineLevel1RunDisabledJobs FAILED\n    java.lang.AssertionError: Wrong status for [jobb:innerJobA] expected:<RUNNING> but was:<QUEUED>\n        at org.junit.Assert.fail(Assert.java:88)\n        at org.junit.Assert.failNotEquals(Assert.java:834)\n        at org.junit.Assert.assertEquals(Assert.java:118)\n        at azkaban.execapp.FlowRunnerTestBase.assertStatus(FlowRunnerTestBase.java:130)\n        at azkaban.execapp.FlowRunnerPipelineTest.testBasicPipelineLevel1RunDisabledJobs(FlowRunnerPipelineTest.java:167)\n\u2013\u00a0and after fix commits it's a success. Time to close this, test added in the fix PR: https://github.com/azkaban/azkaban/pull/1245/commits/a78877178406d4a1ab1ce44c2572011baad04190. Is the problem in ProcessJob only? If yes, sounds like it needs suitable synchronization between ProcessJob#run and ProcessJob#cancel, so that ProcessJob.this.process is not even created if the job has been cancelled. Basically make it an atomic operation to set ProcessJob.this.process and start it. I'm not so familiar with this, but could be enough to synchronize only the process start vs. ProcessJob.this.killed.. What was it, maybe flow stuck in killing status? Did you get a thread dump on the executor node to see if some of the threads on that execution were still running? If you have a bug causing hung threads, at least you can restart the executor node to clean the flow status to FAILED. Of course if my change is a at fault, I'm sorry for that, and willing to fix the problem.. I can fix it \u2013 maybe next week. Please share how to reproduce.. After looking at the open fix candidates, it seems to me that showing the status as KILLING was at least better than showing KILLED. I mean, if the jobs were actually running in the background. As Job#cancel is apparently missed in the problematic scenario, as you wrote \"it actually never gets killed\" \u2013 but I would assume that when the job eventually finishes or fails, the status will be moved from KILLING to some \"finished\" status. Am I right?. Thanks for confirming.\nDepending on the job type, killing could fail for various reasons any way. So I would say that killing is done on best effort basis. The underlying jobs might still manage to run completely even though they started around the same time when kill was triggered.\nBecause of this I would personally find it useful being able to click kill button again while the flow is killing, to try triggering Job#cancel again, in case there was a random error preventing the job to be cancelled.\nMaybe a better idea is that Azkaban could automatically keep trying to call Job#cancel until it succeeds.. @HappyRay, could you or someone have a look at this?\n\nIf you agree, I will make another PR with the fix alone.. > How big a problem do you think this is causing?\n\nI think currently the worst result is that you get a job callback that says SUCCEEDED (also could be FAILED, I suppose), although if you go and look at the execution, eventually it may be marked as KILLED instead.\nWith the additional KILLING status patch applied it's much worse: hitting this bug causes the flow to be stuck because a job is left stuck in KILLING status.. > I am afraid I don't quite follow your diagnostics and how your fix will solve this problem.\nThe core source of problem here is using the field Job.killed to decide how to set job status, but not synchronizing these operations. The code branch in Job#kill was already synchronized (it reads status, possibly writes killed flag and job status). However, Job#runJob was setting job status without synchronization (depending on the killed flag), so a race condition was possible.. > e.g. if there is one thread that is responsible for the job/flow status transition, it would be easier to reason about.\nDefinitely. May be a lot of work though, so I would appreciate having this bug fix ASAP.\n\nIn the killing scenario, a successful return of the kill command only means the server has received and queued up the kill command successfully. The final outcome may still be either a job is killed or a job finishes successfully. The user or a user program would still need to poll the status to find out the final status. And there should not be a state transition from running -> killed -> success/failure. It should either be running -> killed or running -> success/failure.\n\n~~I suppose you describe the situation how it is without this fix. Yes, that's how I see it pretty much.~~ Is this just you ensuring that you understand how it works, or do you mean to say that this wouldn't be a real problem?. > Could you describe an example sequence to better help me understand the particular race condition?\nActually I tried to show that in the 2 scenarios (buggy vs. synchronized) of my PR description. It might help reading it to know that Job job1 finished with status.. is the line that tells what status was fired as a JOB_FINISHED event.\nPlease let me know if you were looking for some other form of expressing it.\n\nAnd how it will interact with the killing status change?\n\nWhen the KILLING status change is applied, this line will set status to KILLING instead of KILLED:\nhttps://github.com/juhoautio/azkaban/blob/723a46ec93d6e52f178e5d2ab445d630099d0ad6/azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java#L833\nThen it would be possible that Job.run returns initially as SUCCEEDED, while Job.kill is being executed, but then Job.kill proceeds, setting status to KILLING. If the job runner thread proceeds only at this point, this branch is skipped:\nhttps://github.com/juhoautio/azkaban/blob/723a46ec93d6e52f178e5d2ab445d630099d0ad6/azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java#L597-L604\nAs a result the job exits with status KILLING and flow won't be able to terminate.\n\nAre you seeing this issue in your production environment now?\n\nIt was seen, but it's been patched in our fork (as in the second commit of this PR).. > I described it as the desired state.\nOh, now your description is clear to me (how could I think about it that much wrong..). Indeed that's what my fix here ensures.. > I don't see what's preventing the jetty thread from setting the final status to killed.\njetty thread returns if status is a finished status. On the other hand if jetty thread gets to setting the status, then jobRunner thread won't set it any more, because it also checks if the status is finished (or if the job is killed), before changing the status.. > Could you try to summarize your technique in preventing the race condition between the kill thread and the jobrunner thread?\nMy understanding is that you would check killed status before setting the final job status and place that check and set logic inside the jobrunner syncObject lock?\nReplace \"check killed status\" with \"check killed flag\" and we're there.\nTo sum it up in other words, I fix the problem by synchronizing in run & kill methods so that the combination of these operations are wrapped into \"a single atomic operation\":\n- checking the status and/or killed flag\n- based on the previous check result(s), setting the status and/or killed flag. Would you squash the commits when merging? I guess I don't need to create a new PR in that case :). > Could you suggest the change description you would like to use?\nOk, let's see what you think about this (I edited the PR description):\nhttps://github.com/azkaban/azkaban/pull/1330#issue-249587802\nFeel free to edit it if there's anything.. Hm, looks like master branch build is failing.. It looks like there was also a random failure with FlowRunnerTest > exec1Failed.\nThis new PR aims to stabilize it: https://github.com/azkaban/azkaban/pull/1364. It should work if the test fix is merged first separately. I didn't realize that at first. I can split this.. Replaced by https://github.com/azkaban/azkaban/pull/1373 and https://github.com/azkaban/azkaban/pull/1374.. > Currently there's no unit case covering FlowRunner#run\nHuh? What about\nhttps://github.com/azkaban/azkaban/blob/master/azkaban-exec-server/src/test/java/azkaban/execapp/FlowRunnerTest.java\nhttps://github.com/azkaban/azkaban/blob/master/azkaban-exec-server/src/test/java/azkaban/execapp/FlowRunnerTest2.java. 1. JobRunnerTest#testDelayedExecutionCancelledJob\n   - It might help to make the sleep longer before that assertion, for example 1 s -> 2 s. Any way I'm not sure if this will help.. What I know though is that it constantly fails with a similar-looking same error if the sleep is removed altogether.\n   - Better yet, that assertion could be changed to a \"polling assert\" with a, say, 10 s timeout.\n2. FlowRunnerTest2#testCancelOnFailure, that seems really strange to me.. I can't really imagine how that could happen. Makes me wonder, could it even be a real bug, not just a flaky test... If possible at all, could you try to explore if it would be possible to keep the full test output in case of a failed test on Travis? That would make it so much easier to debug why a test failed. When running these locally I never get failures even if I run the tests 1000 times :)\nIgnoring \"for now\" would probably mean that there's no way to find the fix any way, so it would be the same as ignoring permanently.\nAnd it's really sad if the tests have to be ignored for good, because who's going to remember to temporarily remove the @Ignore annotation when making changes to related classes... @HappyRay wrote:\n\nhttps://michaeltamm.github.io/junit-toolbox/com/googlecode/junittoolbox/PollingWait.html\n\nMaybe I'm missing the point, but the usage pattern that I was looking for would be simple as:\njava\nassertThat(timeout(10L, TimeUnit.SECONDS), node.getStatus(), is(Status.SUCCESS));\nI've seen this kinda thing somewhere, maybe Hamcrest..\nThis kind of pattern is most likely implemented as a loop that has a simple 10ms sleep or such, which is not 100% optimal. Instead I've used wait+notify pattern in some tests (in Azkaban) to let them run as quickly as possible. For the case at hand there's no way to wait for actual condition without modifying the non-test code, so I think the best solution is to loop with a short sleep, making the \"polling assert\" useful.. > I hope that the problem can be debugged in a PR\nYeah that makes sense to me as well. As long as the failure is not too rare :). Bottom line, I really like the idea of ignoring the tests in master and then actively trying to debug what's actually happening on Travis. Capturing the output would be really good, and I guess new builds can be triggered simply by closing & reopening an existing PR(?).. I can see from history that you haven't ignored any test cases yet:\n- https://github.com/azkaban/azkaban/commits/master/azkaban-exec-server/src/test/java/azkaban/execapp/JobRunnerTest.java\n- https://github.com/azkaban/azkaban/commits/master/azkaban-exec-server/src/test/java/azkaban/execapp/FlowRunnerTest2.java\nI was looking at a recently failed master build and found these:\nFlowRunnerTest > exec1Normal FAILED\n\nFailed to copy full contents from '../test/execution-test-data/exectest1/job2.job' to 'build/tmp/_AzkabanTestDir_1504050231923/job2.job'\n\nHuh? How about changing FlowRunnerTest to use the temporary test dir rule etc.?\nazkaban.execapp.FlowRunnerTest > exec1Normal FAILED\n    java.io.IOException: Failed to copy full contents from '../test/execution-test-data/exectest1/job2.job' to 'build/tmp/_AzkabanTestDir_1504050231923/job2.job'\n        at org.apache.commons.io.FileUtils.doCopyFile(FileUtils.java:1157)\n        at org.apache.commons.io.FileUtils.doCopyDirectory(FileUtils.java:1428)\n        at org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1389)\n        at org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1261)\n        at org.apache.commons.io.FileUtils.copyDirectory(FileUtils.java:1230)\n        at azkaban.execapp.FlowRunnerTest.prepareExecDir(FlowRunnerTest.java:320)\n        at azkaban.execapp.FlowRunnerTest.createFlowRunner(FlowRunnerTest.java:393)\n        at azkaban.execapp.FlowRunnerTest.createFlowRunner(FlowRunnerTest.java:387)\n        at azkaban.execapp.FlowRunnerTest.exec1Normal(FlowRunnerTest.java:102)\nFlowRunnerTest2 > testPauseFailKill: NPE in Arrays.sort\nThe test itself didn't fail, though. Never seen this before, but seems like this should be easy to fix.\nazkaban.execapp.FlowRunnerTest2 > testPauseFailKill STANDARD_OUT\n    Create temp dir\n    2017/08/29 23:43:51.235 +0000 ERROR [JobRunner-innerJobC-107] [JobRunner] Unexpected exception\n    java.lang.NullPointerException\n        at java.util.Arrays.sort(Arrays.java:1438)\n        at azkaban.execapp.JobRunner.finalizeLogFile(JobRunner.java:516)\n        at azkaban.execapp.JobRunner.doRun(JobRunner.java:614)\n        at azkaban.execapp.JobRunner.run(JobRunner.java:552)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:748)\n    2017/08/29 23:43:51.235 +0000 INFO [Test worker] [JobTypeManager] Loading plugin default job types\n    2017/08/29 23:43:51.239 +0000 INFO [JobRunner-jobc-107] [MockExecutorLoader] Uploaded log for [jobc]:[107]:\n    29-08-2017 23:43:51 UTC jobc INFO - Starting job jobc at 1504050231175\n    29-08-2017 23:43:51 UTC jobc INFO - azkaban.webserver.url property was not set\n    29-08-2017 23:43:51 UTC jobc INFO - job JVM args: -Dazkaban.flowid=jobf -Dazkaban.execid=107 -Dazkaban.jobid=jobc\n    29-08-2017 23:43:51 UTC jobc INFO - Building test job executor. \n    29-08-2017 23:43:51 UTC jobc ERROR - Kill has been called.\n    29-08-2017 23:43:51 UTC jobc INFO - Killing job\n    29-08-2017 23:43:51 UTC jobc ERROR - Job run killed!\n    java.lang.RuntimeException: Forced failure of jobc\n        at azkaban.executor.InteractiveTestJob.run(InteractiveTestJob.java:113)\n        at azkaban.execapp.JobRunner.runJob(JobRunner.java:748)\n        at azkaban.execapp.JobRunner.doRun(JobRunner.java:591)\n        at azkaban.execapp.JobRunner.run(JobRunner.java:552)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:748)\n    29-08-2017 23:43:51 UTC jobc ERROR - Forced failure of jobc cause: null\n    29-08-2017 23:43:51 UTC jobc INFO - Finishing job jobc at 1504050231223 with status KILLED\n    2017/08/29 23:43:51.241 +0000 INFO [JobRunner-jobc-107] [jobf] No attachment file for job jobc written.\n    2017/08/29 23:43:51.244 +0000 INFO [Test worker] [JmxJobMBeanManager] Initializing azkaban.execapp.jmx.JmxJobMBeanManager\n    2017/08/29 23:43:51.245 +0000 INFO [Test worker] [FlowRunnerTest2] Adding test1.properties\n    2017/08/29 23:43:51.245 +0000 INFO [Test worker] [FlowRunnerTest2] Adding test2.properties\n    2017/08/29 23:43:51.242 +0000 ERROR [JobRunner-innerJobB-107] [JobRunner] Unexpected exception\n    java.lang.NullPointerException\n        at java.util.Arrays.sort(Arrays.java:1438)\n        at azkaban.execapp.JobRunner.finalizeLogFile(JobRunner.java:516)\n        at azkaban.execapp.JobRunner.doRun(JobRunner.java:614)\n        at azkaban.execapp.JobRunner.run(JobRunner.java:552)\nFinding the FAILED tests\nI wonder if there's an easier way to get a list of failed tests from Travis. Any idea? Like getting an HTML test report or something? The best I could think of is this:\n1.  Download raw log from Travis\n1. Search with regex > [a-zA-Z0-9]* FAILED\n:D. Here's for that FlowRunnerTest > exec1Normal bug: https://github.com/azkaban/azkaban/pull/1417. Could someone edit the issue description to include this:\n\nDownload raw log from Travis\nSearch with regex > [a-zA-Z0-9]* FAILED. Some fix PRs submitted as seen above ^\n\nThese two I haven't analyzed yet, but the problems in them could be something quite similar to https://github.com/azkaban/azkaban/pull/1439:\nazkaban.execapp.FlowRunnerTest2 > testCancelOnFailure FAILED\njava.lang.AssertionError: Wrong status for [jobb:innerJobB] expected: but was:\nat org.junit.Assert.fail(Assert.java:88)\nat org.junit.Assert.failNotEquals(Assert.java:834)\nat org.junit.Assert.assertEquals(Assert.java:118)\nat azkaban.execapp.FlowRunnerTestBase.assertStatus(FlowRunnerTestBase.java:117)\nat azkaban.execapp.FlowRunnerTest2.testCancelOnFailure(FlowRunnerTest2.java:576)\nazkaban.execapp.FlowRunnerTest2 > testRetryOnFailure FAILED\njava.lang.AssertionError: Wrong status for [jobb:innerJobB] expected: but was:\nat org.junit.Assert.fail(Assert.java:88)\nat org.junit.Assert.failNotEquals(Assert.java:834)\nat org.junit.Assert.assertEquals(Assert.java:118)\nat azkaban.execapp.FlowRunnerTestBase.assertStatus(FlowRunnerTestBase.java:117)\nat azkaban.execapp.FlowRunnerTest2.testRetryOnFailure(FlowRunnerTest2.java:647)\n75 tests completed, 2 failed, 22 skipped\n. Maybe pointless to investigate those 2 without test logs.\nI suggest closing this issue and creating new tickets for any further test failures when they occur. When creating an issue, save the full \"raw log\" from the failed Travis build as a public github gist and add link to that in the issue description.. So, does that mean that all of the test output (stdout, stderr, logger logs) are shown?. Awesome.. This is the file tree it now creates when run:\n\n. Ready from my perspective. What do you say?. Now using the @Singleton annotation.. Replaced by https://github.com/azkaban/azkaban/pull/1438. What about taking this a step further and creating individual methods for different actions? For example instead of taking ConnectorParams.UPDATE_ACTION as an argument there would be a specific method ExecutorApiGateway#update?. It doesn't work so well when building on commits that are then squashed.. Creating a new PR.. Also the FlowRunnerPipelineTest has some createFlowRunner methods, so let's also have this first: https://github.com/azkaban/azkaban/pull/1243.. @ameyamk please let me know if there's review resources available for this change. Otherwise we could close the issue.. Resolved @HappyRay's comments.. @kunkun-tang: resolved your comment. That test failure is unrelated to these changes, and it will be fixed by this other PR: https://github.com/azkaban/azkaban/pull/1440. Could someone review this, please?. Hit this kind of hamcrest dependency conflict, so fixed it by switching to mockito-core: https://stackoverflow.com/questions/7869711/getting-nosuchmethoderror-org-hamcrest-matcher-describemismatch-when-running. Now using Awaitility. In case of failure it prints message like:\n  expected a finished status but was <READY> within 10 seconds.\n\n. Ok, comments resolved? Reverted adding LambdaMatcher.java and using Awaitility.await().untilAsserted instead \\o/. This was just for reference. Same fixes as separate PRs:\nhttps://github.com/azkaban/azkaban/pull/1440\nhttps://github.com/azkaban/azkaban/pull/1441. > However, it doesn't always happen because we only wait for joba1 status to become FAILED and do not wait for the JOB_FINISHED event.\nYes, the problem was that the test didn't wait for the JOB_FINISHED event to have been handled for the failed job before allowing those two other jobs to succeed. These test jobs are just waiting in RUNNING state before InteractiveTestJob#succeedJob or InteractiveTestJob#failJob is called.\nJust wanted to clarify that because in your description you didn't say anything about those InteractiveTestJob#succeedJob calls. But yes, I'm sure you understood the issue here.. Resolved conflicts.. Could someone look at this PR, please? Really small change :). Aha, this is just the normal case. It's worth having this test. Do you agree on changing this to use the InteractiveTestJob so that it can run as quick as possible?. Replaced with https://github.com/azkaban/azkaban/pull/1469. Now that I stopped to look, also all of these tests seem to be worth enabling. Do you agree on changing all of them to use the InteractiveTestJob so that it can run as quick as possible?. I will revisit this once https://github.com/azkaban/azkaban/pull/1469 has been dealt with.. Replaced by https://github.com/azkaban/azkaban/pull/1479. Well, as long as it works, it's not a problem :) And we're going towards starting to use multi-executor mode any way. Thanks for the heads up.. Ok. Can we add the missing color though? What about allowing retries before proceeding?\nFor the upcoming conditional execution feature, would it be possible to consider optional retries?. > What do you mean by \"retries\"?\nThe usual retry mechanism. If I set for example retries=3 in the job props. Currently the retries are not applied if job.succeed.on.failure=true. I would like to change this, or at least allow by configuration to use all the retries before giving up and marking the job as FAILED_SUCCEEDED.\n\nMy current thinking is that standard retry will still be applied before the conditional flow logic is applied.\n\nYeah, that sounds good to me!. I added this \"List of issues\" in the description:\n\nDocument job.succeed.on.failure\nAdd UI colors for FAILED_SUCCEEDED: Pull Request https://github.com/azkaban/azkaban/pull/1483\nWhen a flow finishes, set flow status to FAILED_SUCCEEDED instead of SUCCEEDED if any jobs finished with FAILED_SUCCEEDED status\nApply failure HTTP Job Callback also in case of FAILED_SUCCEEDED\nSend failure.emails also if flow finishes as FAILED_SUCCEEDED\nApply all possible retries attempts before ending the job as FAILED_SUCCEEDED\n\nWhich of these would you accept if pull requests are made?. On that latest commit Quick JobRunnerTest with thread waiting\n\u2013 After all I realized that there's a way to avoid 2s sleep in testDelayedExecutionCancelledJob (test that was already enabled before).. Anyone to review this? ( before hitting any merge conflicts X) ). @HappyRay, ping..?. Noo.. conflicts :D. @ameyamk, could someone review this? I have made the test run fast as requested.. Thanks for review so far.. Resolved comments, plz check the latest commit.. I'm not so sure about the color though. Would you agree on orange/yellow? To me that would be more like \"WARN log level\" ie. something between ok & failed. Using the light red (as in cancelled) is not as good now that I think of it.. @chengren311: updated. Thanks for the review @chengren311 and thanks for accepting this change \ud83d\ude47 . Thank you for this!!. I know DependencyInstanceConfig is an interface on purpose, but is there anything special compared to job Props? Could it be a more general interface (AzkabanProps?) that would have all the nice public methods that the Props class currently provides?. My question was more like: could you make an interface that has the convenient accessors that Props currently provides and use that interface here. Eventually there could be a new Job API that also uses it instead of the concrete Props class.. These are really basic & generally useful:\njava\nString getString(final String key, final String defaultValue)\nboolean getBoolean(final String key, final boolean defaultValue)\nboolean getBoolean(final String key)\nlong getLong(final String name, final long defaultValue)\nlong getLong(final String name)\nint getInt(final String name, final int defaultValue)\nint getInt(final String name)\ndouble getDouble(final String name, final double defaultValue)\ndouble getDouble(final String name)\nWe have also used this a lot but I think it would be more convenient for this to return some kind of \"sub-config\" object instead:\njava\nMap<String, String> getMapByPrefix(final String prefix)\nThen there are methods like these that can be useful sometimes but I'm not sure if they deserve to be there or not:\njava\npublic int size()\nList<String> getStringList(final String key)\nList<String> getStringList(final String key, String separator... > How about fetchAllSchedules ?\nI thought that fetchSchedules would be nicer because you can assume that without any additional params it returns everything. And then there's room for expansion: it would be easy to add support for some filter parameters like project id, and the name fetchSchedules would still work well.. > I would suggest updating the name and callers\nI'd like that. Want me to make a PR?. It's been renamed to fetchSchedules but loadFlow is still kept as an alias for compatibility.. Huh, another random test failure after this was merged:\nazkaban.execapp.FlowRunnerTest > exec1FailedKillAll FAILED\n    java.lang.AssertionError: Flow didn't reach expected status\n        at org.junit.Assert.fail(Assert.java:88)\n        at azkaban.execapp.FlowRunnerTestBase.waitFlowRunner(FlowRunnerTestBase.java:79)\n        at azkaban.execapp.FlowRunnerTestBase.waitFlowRunner(FlowRunnerTestBase.java:63)\n        at azkaban.execapp.FlowRunnerTestBase.assertThreadShutDown(FlowRunnerTestBase.java:45)\n        at azkaban.execapp.FlowRunnerTest.exec1FailedKillAll(FlowRunnerTest.java:186)\nhttps://travis-ci.org/azkaban/azkaban/builds/281370396\nTest output for debugging the failure:\nazkaban.execapp.FlowRunnerTest > exec1FailedKillAll STANDARD_OUT\n    2017/09/29 16:40:19.238 +0000 INFO [Test worker] [JobTypeManager] Loading plugin default job types\n    2017/09/29 16:40:19.241 +0000 INFO [Test worker] [JmxJobMBeanManager] Initializing azkaban.execapp.jmx.JmxJobMBeanManager\n    2017/09/29 16:40:19.258 +0000 INFO [Thread-19] [derived-member-data-2] Running execid:1 flow:derived-member-data-2 project:1 version:-1\n    2017/09/29 16:40:19.261 +0000 INFO [FlowRunner-exec-1] [derived-member-data-2] Updating initial flow directory.\n    2017/09/29 16:40:19.262 +0000 INFO [FlowRunner-exec-1] [derived-member-data-2] Fetching job and shared properties.\n    2017/09/29 16:40:19.262 +0000 INFO [FlowRunner-exec-1] [derived-member-data-2] Starting flows\n    2017/09/29 16:40:19.264 +0000 INFO [FlowRunner-exec-1] [derived-member-data-2] Running flow 'derived-member-data-2'.\n    2017/09/29 16:40:19.264 +0000 INFO [FlowRunner-exec-1] [derived-member-data-2] Configuring Azkaban metrics tracking for jobrunner object\n    2017/09/29 16:40:19.264 +0000 INFO [FlowRunner-exec-1] [derived-member-data-2] Submitting job 'job1' to run.\n    2017/09/29 16:40:19.303 +0000 INFO [JobRunner-job1-1] [derived-member-data-2] Created file appender for job job1\n    2017/09/29 16:40:19.304 +0000 INFO [JobRunner-job1-1] [derived-member-data-2] Attached file appender for job job1\n    2017/09/29 16:40:19.307 +0000 WARN [JobRunner-job1-1] [PropsUtils] Null value in props for key 'azkaban.flow.projectlastchangedby'. Replacing with empty string.\n    2017/09/29 16:40:19.307 +0000 WARN [JobRunner-job1-1] [PropsUtils] Null value in props for key 'azkaban.flow.submituser'. Replacing with empty string.\n    2017/09/29 16:40:19.308 +0000 INFO [JobRunner-job1-1] [derived-member-data-2] Job job1 finished with status SUCCEEDED in 0 seconds\n    2017/09/29 16:40:19.309 +0000 INFO [FlowRunner-exec-1] [derived-member-data-2] Configuring Azkaban metrics tracking for jobrunner object\n    2017/09/29 16:40:19.309 +0000 INFO [FlowRunner-exec-1] [derived-member-data-2] Submitting job 'job2d' to run.\n    2017/09/29 16:40:19.311 +0000 INFO [FlowRunner-exec-1] [derived-member-data-2] Configuring Azkaban metrics tracking for jobrunner object\n    2017/09/29 16:40:19.311 +0000 INFO [FlowRunner-exec-1] [derived-member-data-2] Submitting job 'job6' to run.\n    2017/09/29 16:40:19.313 +0000 INFO [JobRunner-job1-1] [derived-member-data-2] No attachment file for job job1 written.\n    2017/09/29 16:40:19.318 +0000 INFO [JobRunner-job2d-1] [derived-member-data-2] Created file appender for job job2d\n    2017/09/29 16:40:19.318 +0000 INFO [JobRunner-job2d-1] [derived-member-data-2] Attached file appender for job job2d\n    2017/09/29 16:40:19.319 +0000 WARN [JobRunner-job2d-1] [PropsUtils] Null value in props for key 'azkaban.flow.projectlastchangedby'. Replacing with empty string.\n    2017/09/29 16:40:19.319 +0000 WARN [JobRunner-job2d-1] [PropsUtils] Null value in props for key 'azkaban.flow.submituser'. Replacing with empty string.\n    2017/09/29 16:40:19.323 +0000 INFO [JobRunner-job2d-1] [derived-member-data-2] Job job2d finished with status FAILED in 0 seconds\n    2017/09/29 16:40:19.324 +0000 INFO [FlowRunner-exec-1] [derived-member-data-2] Setting derived-member-data-2 to FAILED_FINISHING\n    2017/09/29 16:40:19.324 +0000 INFO [FlowRunner-exec-1] [derived-member-data-2] Kill has been called on flow 1\n    2017/09/29 16:40:19.324 +0000 INFO [FlowRunner-exec-1] [derived-member-data-2] Killing 1 jobs.\n    2017/09/29 16:40:19.324 +0000 INFO [FlowRunner-exec-1] [derived-member-data-2] Cancelling 'job4' due to prior errors.\n    2017/09/29 16:40:19.324 +0000 INFO [FlowRunner-exec-1] [derived-member-data-2] Cancelling 'job3' due to prior errors.\n    2017/09/29 16:40:19.324 +0000 INFO [FlowRunner-exec-1] [derived-member-data-2] Cancelling 'job5' due to prior errors.\n    2017/09/29 16:40:19.325 +0000 INFO [JobRunner-job2d-1] [derived-member-data-2] No attachment file for job job2d written.\n    2017/09/29 16:40:19.330 +0000 INFO [JobRunner-job6-1] [derived-member-data-2] Job job6 finished with status KILLING in 0 seconds. Pretty clear that this is what went wrong:\n\nJob job6 finished with status KILLING in 0 seconds\n\nSo the job finished event was sent with status KILLING instead of KILLED.. The test failure seems to be coming from master:\nazkaban.execapp.FlowRunnerTest > exec1FailedKillAll FAILED\n    java.lang.AssertionError: Flow didn't reach expected status\n        at org.junit.Assert.fail(Assert.java:88)\n        at azkaban.execapp.FlowRunnerTestBase.waitFlowRunner(FlowRunnerTestBase.java:79)\n        at azkaban.execapp.FlowRunnerTestBase.waitFlowRunner(FlowRunnerTestBase.java:63)\n        at azkaban.execapp.FlowRunnerTestBase.assertThreadShutDown(FlowRunnerTestBase.java:45)\n        at azkaban.execapp.FlowRunnerTest.exec1FailedKillAll(FlowRunnerTest.java:186)\nThis PR will fix it: https://github.com/azkaban/azkaban/pull/1518. @chengren311 @kunkun-tang the build is passing, as expected... Front-end doesn't call it.\nI'm not planning to add documentation at this point, becaue @HappyRay commented in the issue:\n\nWe would like to improve our API in the near future. I hesitate to expand our public API set now.. Really sorry for introducing this bug in the first place. I should've checked this more carefully.. I guess it was so rare that it was never revealed by the tests before, but I'm glad it was caught this time!. @chengren311 & @kunkun-tang: shouldn't this have been done as a \"schema migration\" instead? Something like this: \nhttps://github.com/azkaban/azkaban/blob/master/azkaban-common/src/test/resources/sql/update.execution_jobs.2.1.sql\n\nedit: this works for me:\nsql\nALTER TABLE execution_jobs\n  DROP PRIMARY KEY, ADD PRIMARY KEY (exec_id, job_id, flow_id, attempt);\nDROP INDEX exec_job ON execution_jobs;\nDROP INDEX exec_id ON execution_jobs;\nHow are users expected to make any required DB changes when upgrading to a newer version?. \ud83d\udc4d  for this first of all.\nI'm mostly curious about how this will be reflected in the UI and what it will look like in job configuration. Would you have any examples to share about those?\nAfter all, from my perspective it maybe seems like this interface may not be as useful as it can be limiting when compared to custom polling scripts.. With an explicit job to poll for data it is quite clearly visible from the Job List where the flow is going, how long it has been \"blocked by a data dependency\", and why (you can log details in the job log of the data polling job). Personally I would really hope to have a similar level of visibility in the UI for the dependency checks.. @chengren311 this seems to be in progress - nothing done for UI side yet? What happens to a pending data dependency trigger if azkaban is restarted while it's waiting for data?. @kunkun-tang looking at the diff it seems that you don't have Save Actions plugin enabled.. Maybe you have those org.quartz.* properties defined in some non-version-controlled local conf?. Added commits:\n- Avoid NPE for quartzScheduler in shutdown (added a null check)\n- Ignore flaky slow unit test (causing random test failures on Travis) \u2013 Thread.sleep should not be used in unit tests. @kunkun-tang, maybe you will stabilize it and then remove the @Ignore?.  Added commit: \"Fix javadoc tags\" - the closing <ul> tag was wrong. And it seems that a closing tag is not used for <li> in javadocs.. @reallocf please consider this: it's common that users want to set environment-specific configurations in their own projects (zips) \u2013 so being able to set environment variables like env.LOCATION doesn't help there. How would you give an env-specific arg to your test.py? I don't see a way. The global config can't be changed by the users, and it's painful to add new properties in there.\n\nWe have implemented support for different environments in our custom job types.\nIt works like this.\nEnvironment is set globally on the azkaban installation;\nazkaban-exec-server/\n   plugins/\n      jobtypes/\n         commonprivate.properties\n         common.properties:\n            environment=dev\nWhen using our custom job types, the zip can be for example:\n```properties\nmyFlow/\n  myFlow.properties\n  foo.job\nmyFlow.properties\ndatabase=localhost:2181\ndev.database=dev-db:2181\nstage.database=some-host:2181\nprod.database=another-host:2181\nfoo.job\ntype=custom_type\nsome_arg=test value\nprod.some_arg=real value\ncommand=some_command --db ${database} \"${some_arg}\"\n```\nAfter resolving by env prefixes the result becomes =>\nproperties\ncommand=some_command --db dev-db:2181 \"test value\"\nWhen our custom job types resolve props, they look for ${environment}.* ie. dev.* in this case, and insert its value as the flat property, in this case dev.database -> database. This overrides a possibly existing non-prefixed value.\n\nI'd be really interested to hear if anyone has better ideas.\nI wonder if it would make sense for azkaban itself to support this pattern. But I also feel that it's a bit \"magical\" and maybe not so beautiful in that sense, but it seems to work well for us.\nI know that in many cases the environment specific configurations have been chosen to live in separate files. But it's always a bore having to edit 3 different files when you want to tweak some special property.\nTo me \"our way\" seems more like \"package by feature\" (which is good) while having env-specific files reminds me of \"package by layer\" (a mess).\nIMHO, having separate files like myFlow-dev.properties, myFlow-stage.properties, myFlow-prod.properties is not so natural many times, especially when you just have a simple job that needs some value to be different in each env. See that prod.some_arg \"override\" in foo.job \u2013 if the property is specific to this job (and you have many such jobs that all need different values per environment), how would you accomplish that? You could maybe put the job file into a separate sub-folder and create something like foo/foo-prod.properties just to set that value.. It doesn't seem too appealing to me.\n\nIf we would be using the \"out-of-the-box\" solution ${${environment}.database} it would more or less mean that we would need to prefix every property name with ${environment}.. Too much hassle. And if you want to set a property that is implemented by a job type directly, for example Azkaban's own java job types' classpath, you have to always go via a reference. You can't just do dev.classpath=something but have to define separately dev.classpath=something + classpath=${${environment}.classpath} \u2013 so much more verbose and hard to follow.\n\nBy the way, one thing that can't be done in any way at the moment is setting env-specific number of retries= for a job. Or dependencies=.. @HappyRay @chengren311 anyone to review?. Or maybe @kunkun-tang, @jamiesjc ?. @kunkun-tang, I've added two commits.. It seems like maybe you have the job property classpath defined with an empty value? If yes, delete that property, and Azkaban shouldn't be trying to add -cp without following args any more.\nAny way this seems like a bug to me; Azkaban should check mroe carefully if the list for -cp  is empty and not add it in that case.. Hmm and did you include some.jar (that contains the class AzkabanExample) in the same folder as your .job file is in the zip?. Maybe some of these new test cases in JavaProcessJobTest.java match with yours.. Repo owners, could you consider this, please:\nhttps://github.com/azkaban/azkaban/pull/1567. Could someone have a look? This is old but still valid. It would be nice if this improvement would be taken in, so that the effort wouldn't have been in vain.. @burgerkingeater how about this one? The more tests the merrier... @burgerkingeater bump. @kunkun-tang could you review? I can see that you added the problematic file: https://github.com/azkaban/azkaban/blob/master/azkaban-db/src/main/sql/create.quartz-tables-all.sql\nOf course it would be best to fix this properly, but a quick fix like this would be useful in the meanwhile.. @kunkun-tang, I added the @Deprecated tag.. Yes, it only replaces the first occurrence, as you can see in the code here:\nhttps://github.com/azkaban/azkaban/blob/master/azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackUtil.java#L274-L300\nI don't see why it should be like that. Hence, our internal Azkaban fork uses replaceAll instead of replaceFirst.. > What's your setting? How often do you see this issue?\n300 concurrent flow executions per executor currently. But would like to bump that up to 1000 at least.\nThis is not usually a problem for us either. But when we want to submit many executions (typically pipeline level 2) with different date params to backfill a year of data or more, this becomes a problem. We use a single executor and the executions themselves are usually light on the azkaban-executor, the heavy work is done by some external system, so it doesn't seem too sensible having to bump up number of azkaban executors just to have room for more executions.. > I would view this new config as a temporary workaround. Are you ok with NOT documenting it as a public API ( config setting ) and reserve the right to deprecate it after we fix the underlying issues?\nI don't view it as a temporary work-around though. Why should azkaban-web mark executions as failed any way just because it can't reach the executor to get the updates? As long as an executor is active, I would rather see the connectivity problem being highlighted in some other way so that it can be fixed, instead of marking executions as failed. For example e-mail alerts should work.\nIf it's not already the case, it should be checked if the executor has been removed from active executors or not. If it's been removed, then it's fine to evict executions bound to it. But this shouldn't be confused with problems in calling active executors.. > I wanted to simplify the automatic evicting logic and also the load balancing logic for a long while now. However, we haven't prioritized that work.\nWhat if we remove the auto eviction logic entirely for now and re-think the strategy? I don't remember any incident that auto eviction helped in practice.\nSorry, I missed this comment before. Sure, I agree 100%. Shall I modify this PR to get rid of eviction-related code?. > If you decide to remove the logic instead, how about creating a separate PR\nSure.\n\nHow would that decision affect the other PR #1655 ?\n\nDoesn't affect it. The 413 problem (when calling executor with many execution ids) should be fixed any way. Whichever route the eviction handling takes, #1655 is a mandatory pre-requisite.. Closing, new take on this at https://github.com/azkaban/azkaban/pull/1661. @HappyRay what do you mean by \"executors are actually up\"? I think this happens also if an executor can't respond for any reason. This could be for example because the executor java process is down or because there's some network issue between web & executor. Right? Or if the executor node is too busy somehow so that it can't respond to the call by web node at all or in time.\nIf executor is running, this could happen due to some bug that causes executor to response with a non-ok response. But it shouldn't happen in any normal situation if the executor is running and web has network connectivity to it.. @ameyamk question to you ^ (sorry pinged the wrong person at first). @ameyamk Yes, it should be rare. And it hasn't happened to us since fixing https://github.com/azkaban/azkaban/issues/1653.\nBut it can have nasty effects* if Azkaban ever goes into \"eviction mode\" for any reason, because then the concurrency limits aren't respected any more.\nNow my comments on the options (I was waiting for your clarification first, thanks for that).\n\n\nRemove/ Evict execution, email owner of the failure - treat this is any other failure scenario and restart the flow execution\n\n\nNo automatic eviction, please. Moreover, if changing the current behaviour to additionally start another execution automatically, it would only make it worse. Because in this situation web node just doesn't have the information whether an unreachable executor is still running the original execution.\n\n\nRemove/ Evict execution, email owner of the failure - treat this as special failure case - and do nothing.\n\n\nSame, no automatic eviction. Adding an alert email would be a big plus though, compared to the current behaviour of silently evicting executions.\n\n\nOnly email owner of this special case situation\n\n\nYes, this is the best I can think of. Owners should handle the situation by doing either of these:\n- Fix connectivity to the executor node so that web can successfully get updates again\n- If the executor is not supposed to exist any more, remove the executor from active executors list in DB (I'm not sure if this is the current behaviour, but should be like this: web node should eventually evict executions that are assigned to removed executors. This is fine because a human operator has ensured that the removed executor is not running anything - or running at all - before removing the executor from the DB. The alert email could explain the situation and give instructions for fixing).\nOf course this relies on alert emails to be enabled & working.\n\"Option 4.\": It would be better to have the problem of \"not able to get updates from executor\" visible in the UI as well, but seems like an overkill for such a rare issue.\n\n*) Examples of caused issues:\n- Breaking job results: multiple instances of a job are running in parallel (if that's normally prevented by the chosen Azkaban concurrent option)\n- Causing additional costs: launching multiple instances of some external jobs that for example provision a big cluster or run an expensive query. Ping @ameyamk my answer above.. ^\nThis PR is closed though. I had created a new one: https://github.com/azkaban/azkaban/pull/1661. > We may need to have super admin switch to evict executions\nWhen would that be needed? Is there really a situation where you would not rather do either of these:\n- Fix connectivity to the executor node so that web can successfully get updates again\n- Remove the executor from active executors (if it's not supposed to be enabled any more)\n?\nOnce the connectivity is re-established, executions get marked as failed if they're not running on the executor any more (executor answers that \"I don't know this execution\"). So there's no need to evict anything manually.. @ameyamk ping ^. @ameyamk, please?. @HappyRay or someone, even though WIP, could you check if this is a valid strategy in your opinion? Too bad the code was structured so that quite big changes were needed in the infrastructure to support POST in addition to GET.. > Have you considered switching to post only and remove the get support?\nI have indeed. My change here is backward compatible as long as executor is upgraded first. But why not support all operations with post already now?. >> But why not support all operations with post already now?\n\nCould you elaborate? I am not sure what your position is.\n\nI just meant that in the ExecutorServlet it would be easy to have the same exact request handling regardless of the HTTP method, be it GET or POST. This would make the code change minimal on executor side, but on the other hand offer a seamless upgrade route if you upgrade the executor servers first. We could leave it like this, wouldn't do much harm.\nAnd if I can switch everything from GET to POST that should simplify the changes on the client side (azkaban-web) quite a lot.\nI can make another PR from these ideas.. Closing in favour of https://github.com/azkaban/azkaban/pull/1659. @HappyRay, could you \"continue\" review on this, please?. Anyone got time to review?. Please?. @ameyamk, would it be possible to get someone to review this & other PRs that I've made to fix #1653? This is a rather nasty bug and I'd like to have the fix ASAP but wanted to try to get it in through the public repo without having to apply it in private fork first.. Thanks for looking into this.\n\nDo we know what will be the limit for POST?\n\nAzkabanWebServer sets this for jetty:\njava\nprivate static final int MAX_FORM_CONTENT_SIZE = 10 * 1024 * 1024;\n...\nroot.setMaxFormContentSize(MAX_FORM_CONTENT_SIZE);\n..so 10MB, right?\nIt's a pretty big chunk already. Ideally this would be a configurable property of azkaban?\n\nThe HTTP specification doesn't impose a specific size limit for posts. They will usually be limited by either the web server or the programming technology used to process the form submission.\n\nfrom: https://serverfault.com/questions/151090/is-there-a-maximum-size-for-content-of-an-http-post\nSo code-wise it's a very scalable solution.. > would you mind adding how you verified it\nI guess I had only verified it \"in theory\". Now I have added a test (which is manually run, though) that validates this. See https://github.com/azkaban/azkaban/pull/1707 for the test that reproduces the problem. And then the 3rd commit in this PR, which shows that even a really high number of executions can be sent in the form.\nTo find the new limit I also tried this:\nupdateExecutions(1_000_000);\n\nazkaban.executor.ExecutorManagerException: java.io.IOException: Form too large 13,100,061 > 10,485,760\n\nSo with the current form body size limit there can be almost 1M running executions to update. That's much better than ~200.. Thank you @chengren311!. @chengren311 yes, sorry. Fix PR coming up.. Fix PR here:\nhttps://github.com/azkaban/azkaban/pull/1711. @HappyRay  It was of course first of all my mistake because I didn't check carefully all usages of ExecutorApiGateway when changing the behaviour. Sorry for that.\nOtherwise these would've helped:\n1. Not allowing the servlet path to be passed as an argument to ExecutorApiGateway \u2013 implement specific methods for /serverStatistics, /jmx & /stats & /executor in ExecutorApiGateway so that the scope can be understood better without having to look at usages outside the class itself.\n1. Unit tests that verify calls of ExecutorApiGateway against a running executor side servlet (ideally using mocked http transport for speed, similar to jersey test-framework https://jersey.github.io/documentation/latest/test-framework.html \u2013 typically the servlets would be refactored to separate the HTTP interfaces and actual request handling, so that the handling can be mocked in unit tests)\n1. Using multi-executor mode on AzkabanSingleServer (drawback is that single-executor mode wouldn't be covered) \u2013 although I believe it's up to the user to manually run it and notice errors in logs (there are usually also harmless errors in the logs when running locally, so real errors could still be missed rather easily)\nI'd be happy to implement 1. if you agree.. > Why should single-executor mode be different in this regard? I would prefer to consolidate the code path\nTotally agree. Having two different code paths has caused a lot of confusion for me as well. Test coverage is worse for the multi-exec mode because the default seems to be single-exec.\n\nsupport only the multi-executor mode for example\n\nYes, naturally (what else would work any way?).. @HappyRay @chengren311 I've rebased & updated this.. Would you be able to spend a couple minutes on evaluating what you think about this concept of eviction? As I've written in the pr descr. I think it's a problematic behaviour... Rebased & resolved conflicts.\nI'm hoping to get @ameyamk to accept this change on the conceptual level.. @HappyRay I heard from Ameya that he moved away from Azkaban team. Can I get you or someone else to discuss this proposal?. @jamiesjc thanks for stepping in.\nConcurrent option is one issue that I'm trying to fix. Another one is just the reliability of scheduling, ie. not skipping scheduled executions just because executors are unreachable for any reason so that new executions can't be dispatched.\n\nHowever, if the executions remain in running status, should azkaban admins finalize the flows manually in the DB?\n\nNot in any normal situation.\n(I'm copying some text from https://github.com/azkaban/azkaban/pull/1654)\nIs there really a situation where you would not rather do either of these:\n\nFix connectivity to the executor node so that web can successfully get updates again\nRemove the executor from active executors (if it's not supposed to be enabled any more)\n\n?\nOnce the connectivity is re-established, executions get marked as failed (ie. \"evicted\") if they're not running on the executor any more (executor answers that \"I don't know this execution\"). So there's no need to evict anything manually.\nIf an executor is removed from the DB entirely, also then azkaban-web should evict all running executions that are assigned to the non-existing executor.\n\nAlso when users try to fetch the flow/job log, it will call the executor to fetch it instead of fetching it from DB since the flow status is still running. But there is no response from the executor, so the log would always show empty.\n\nDid you know that the flow & execution logs are also written out as blank if azkaban-web evicts the execution? This is because the logs are only finalized into the DB once the execution ends. Until that point azkaban-executor keeps them on local disk. My suggestion doesn't really change this behaviour, except for that user may get some kind of error message in the UI if trying access logs when the corresponding executor is unresponsive. In my opinion that's not a bad thing, because this can be one more way for users to become aware of an on-going executor problem.\n\nEven if we send emails to users, they still have no clue whether their job is actually still running or already failed.\n\nSure, but I'm not suggesting to leave the situation like that. Azkaban is not healthy on system level if it can't connect to some of the active executors, and admins should fix such problem asap.. @jamiesjc yes. Sorry for the confusing \"should\". More corrrectly:\n\nAlready with the current code, if an executor is removed from the DB entirely, azkaban-web evicts all running executions that are assigned to the non-existing executor.. @jamiesjc: so, would you agree to move forward with this change?. @jamiesjc thank you for comments! I made that javadoc update. Anything else?\n\nNote that it's a separate commit, so if merging this it's best to use the squash-merge.. @HappyRay sure, it should be possible to start finalizing again with a rather minimal change.\nWould you have more information on the stalled executions? I\u2019m suspecting that executor instances have been stopped but they haven\u2019t been removed from the db (executors table), or then azkaban-web hasn\u2019t been restarted after that.\nIn case of this kind of platform error, would it make sense to send alert email to some global admin email instead of the owners lf the flows?\nSorry for the trouble and thanks for being open to this change as a longer term goal.. Yes, if az-web is not restarted after an executor has been stopped, az-web would keep trying to get updates and fail to remove those executions from the running list.\nThe plan is to improve this by making azkaban-web check from the db if the executor has been removed when an update call fails. Additionally it can check the flow\u2019s status from the db to find out if it has finished without having to reach the executor.\nHowever, if the executor shutdown is not graceful and the entry is left in the db, admin would still need to somehow make sure that it is removed, if any executions on that executor had been left in some unfinished status.\nI think that this is the only way to reliably prevent violation of execution concurrency options. On the other hand this could of course be an overkill. It is after all quite rare that az-web evicts some executions that are actually running, which can only happen if it can\u2019t reach an executor that\u2019s still running. Of course even that shouldn\u2019t really happen, especially considering that there have always been some retries before eviction.\nAny way, in our case it was rather easy to add an external checker (actually run on azkaban itself) that compares executors in the db with running instances, and removes any missing executors from the db (+restarts az-web to reload).\nBut now that I think of it, I\u2019m starting to realize that maybe this model doesn\u2019t suit other users too well and automatic eviction should probably remain, at least as the default strategy if not disabled by setting a property.. Can I do something more to get this merged? It would be really nice to be able to run all tests quickly without some personal test run setup.. @HappyRay thanks.. I have resolved all slow tests properly, 3 commits added ^. Updated PR title, original description works.. @HappyRay, please?. The deletions are verified by the fact that I removed code that wasn\u2019t referenced anywhere - and it still compiles. I\u2019m also adding some unit tests (see another PR) but wanted to do this as an initial cleanup to build on.. Looks like ReportalMailCreator.java of azkaban-plugins is at least using some attachment-related features of the EmailMessage class though. For example message.enableAttachementEmbedment(false)\nAha, and EmailMessage.setTotalAttachmentMaxSize(getAttachmentMaxSize()) is then meaningful etc.\nI should check again in sync with azkaban-plugins if any of the removals in this PR can be done.. I have trouble testing azkaban-plugins against changes made in this repo. Please help first of all with building the plugins project:\nhttps://github.com/azkaban/azkaban-plugins/issues/285. Replaced by this: https://github.com/azkaban/azkaban/pull/1690. I think it\u2019s much easier to grasp if #1663 is dealt with first, separately. Usually at least @HappyRay has preferred splitting changes to individual pull requests to make it easier to follow.. Replaced by https://github.com/azkaban/azkaban/pull/1691. @chengren311 thanks for merging https://github.com/azkaban/azkaban/pull/1691 \u2013 now I was able to do this refactoring as unit tests exist to verify the change.\nI split these changes into separate commits so that it's hopefully easier to follow.. @HappyRay could you have a look, please?. @HappyRay, anyone?. Resolved conflicts.. @ameyamk, could someone review this, please? Bumping up the test coverage!. @chengren311 thanks! I can see that the diff is a bit messy.. Unfortunately had to move some code around to allow mocking.. Aren't these tests needed any way? They're mostly verifying the message formatting that needs to produce the same results regardless of what library is being used. If one were to change the library, isn't it even more important to have good test coverage before the change to support that?\nMy reason for making this PR is that I would like to add a method in the e-mailer to alert about connectivity error from web node to executor node(s).. @chengren311 sorry for missing the guidelines again. Could you have another look, please?. ping @chengren311. Thank you @chengren311 !. A bit less than year ago we bumped execution_jobs.flow_id up to VARCHAR(767) (just used the max size possible) for similar reason in our Azkaban DBs. It was indeed the flow_id column, so different than this PR. The problem occurred for us when there were many embedded sub-flows, as the flow_id was composed from all ancestor flow names.\nI wonder, has the DB structure been changed since then, or why is it that this PR is not changing execution_jobs.flow_id but execution_jobs.job_id? Or is it maybe some other kind of case, not one with multiple nested flows with rather long names?. Yes, @chengren311 the error does not occur when the flow is uploaded. It's because for embedded flows the concatenated id (parent:flows:embedded_flow:job_id) is only used as a key to store jobs logs. That doesn't happen on project upload. This model is quite limiting though. The index key prefix length limit of 767 is easily too low when you have any deeper nesting of embedded flows.. @chengren311 it's not the limit of varchar type itself, it's because that column is used as an index key. The term is \"index key prefix\" and innodb (MySQL) has a default limit of 767 for that.\nI found this though:\n\nThe index key prefix length limit is 767 bytes if you use the version of MySQL either 5.5 or 5.6. Or you use 5.7 the default is 3076 bytes.\n\n^ https://blog.codingecho.com/2017/08/09/index-key-prefix-length-limitation-on-innodb/\nWe're using AWS RDS as our MySQL DB. Looks like 5.7 is available so we might consider upgrading. Not a perfect fix, but at least it would offer 4x longer values than currently.. What about https://github.com/azkaban/azkaban/issues/1809, did it occur in your end in a flow that uses the traditional flow format? Would using flow 2.0 somehow prevent that from happening?. Rewind my comment a bit, we recently got an error in writing to execution_logs, but that's no surprise as we still had name        VARCHAR(128) there. We had only bumped up execution_jobs.flow_id to VARCHAR(767).. Another PR that included this was already merged -> closing. Seems to be my fault, caused by https://github.com/azkaban/azkaban/pull/1662. I must've missed synchronizing something. I doubt that there would've been any 10s pause in the test execution to cause this.\nI found a build on Travis that also failed because of this:\nhttps://travis-ci.org/azkaban/azkaban/builds/364040213\nazkaban.metric.MetricManagerTest\n  FAILURE (4 tests, 3 passed, 1 failed, 0 skipped)\nFound stdout for the failed test there:\n```\nazkaban.metric.MetricManagerTest > managerEmitterHandlingTest STANDARD_OUT\n    2018/04/09 09:59:13.405 +0000 INFO [MetricReportManager] Instantiating MetricReportManager\n    6715 [Test worker] INFO azkaban.metric.MetricReportManager  - Instantiating MetricReportManager\n    2018/04/09 09:59:13.409 +0000 INFO [MetricReportManager] Enabling Metric Manager\n    6719 [Test worker] INFO azkaban.metric.MetricReportManager  - Enabling Metric Manager\nSuccessfully started process 'Gradle Test Executor 8'\nPicked up _JAVA_OPTIONS: -Xmx2048m -Xms512m\n    2018/04/09 09:59:13.517 +0000 INFO [InMemoryMetricEmitter] First time capturing metric: FakeMetric\n    6827 [pool-1-thread-1] INFO azkaban.metric.inmemoryemitter.InMemoryMetricEmitter  - First time capturing metric: FakeMetric\nazkaban.metric.MetricManagerTest > managerEmitterHandlingTest FAILED\n    java.lang.AssertionError: Failed to report metric expected:<1> but was:<0>\n        at org.junit.Assert.fail(Assert.java:88)\n        at org.junit.Assert.failNotEquals(Assert.java:834)\n        at org.junit.Assert.assertEquals(Assert.java:645)\n        at azkaban.metric.MetricManagerTest.managerEmitterHandlingTest(MetricManagerTest.java:92)\n```\n. It seems that the actual issue was leaking DateTimeUtils tweaks from other tests, see fix PR at https://github.com/azkaban/azkaban/pull/1735. See also https://github.com/azkaban/azkaban/issues/1725. Great find @mtrna !. Btw, how did you find this? Were you able to somehow run the test locally so that it failed consistently (so that you could debug what the actual timestamps are)?. How about my suggestion on fixing this also in BasicTimeCheckerTest?. Left 2 more comments, otherwise \ud83d\udc4d from my perspective.. > @juhoautio do you think this change is going to fix the recent unit test in-stability reported by multiple users?\nYes.\n\nI trust @juhoautio's judgment. If he is ok with it, chances are the change is fine. :)\n\n\ud83d\udc4d from me for this PR in its current state.. How about doing refactoring separately first:\nhttps://github.com/azkaban/azkaban/pull/1665. > @juhoautio rebased\nThanks for letting my PR be merged first.. Aha, one refactoring idea after this one's been merged: change all MailCreator.java interface methods to pass a ready-baked String azkabanUrl instead of all three: String scheme, String clientHostname, String clientPortNumber. The MailCreator implementations always just build the URL from them any way.. This gets quite close to the \"cleanup job\" feature: https://github.com/azkaban/azkaban/issues/44. With that you could \"guarantee\" that the \"hook\" is run in any case.\nThere's one major difference: cleanup jobs don't know what the final status of the flow is going to be. Not sure if that's crucial in your scenario?. Renamed TestUtils#read to readResource. It's not necessarily only for regular files, so I didn't add \"file\" to the method name.. @chengren311 anything else?. Thank you @chengren311 & @HappyRay!. Have you tried setting mail.tls=true in Azkaban properties? AFAIK the javax mail library always uses protocol \"smtp\" but it can be encrypted (see also: https://stackoverflow.com/a/18333887/1068385).. @kunkun-tang thanks! Anything else required for this to be merged?. I don't understand this Travis build failure.\n```\nFAILURE: Build failed with an exception.\n\nWhat went wrong:\nExecution failed for task ':azkaban-common:compileTestJava'.\njava.lang.reflect.InvocationTargetException\n```\n\n\n\nThe build failed after 2 min 46 sec (while normally full azkaban build runs over 4 min on Travis).\nLocally the build works. Am I missing the actual reason?\n\nI have now rebased & force-pushed to trigger a new build -> it passed.. @kunkun-tang Executor info is not needed at the moment of finalizing a flow. But the initial loading also loads running executions that are periodically checked by calling the assigned executors. If an executor answers that such execution is not running any more, then the execution is finalized. This change also immediately finalizes executions whose assigned executor doesn\u2019t exist.. @chengren311 For all users It's mostly about special cases like these:\n- a flow is stuck and doesn't respond to killing (for example because of a bug in a job type plugin)\n- executor process has crashed / executor instance has went defunct so that it has to be replaced entirely\nSo it's about cleaning up after any corner cases where executor has been shutdown more or less forcibly. Not saying that this would be too common for most users.\n\nI had entirely missed the shutdown API. Using that would probably help avoid these cases most of the time.\nHowever waiting for shutdown doesn't really work for us because we have some long-running stream jobs that we don't want to kill (because it would kill the external job), and we rather prefer resuming polling for the external jobs after executor restart.\n\nThe recommended way is to call shutdown api of the executor then it will go into the shutting down mode\n\nThat would be nice but we have some long-running flows that we can't wait to end. We shut down the old executor without killing these executions, then they can be marked as failed, and we resume the same external job automatically once new executions are launched on the new executor. The corner-case here is that the old executions are never finalized as FAILED even though they are not shown in running executions (and are not running on an executor either).\n\nall running flows will be killed in 10 days\n\nWe have disabled automatic killing entirely (in azkaban conf), because of the long-running flows that we have. Also, when replacing an executor instance I would typically want to get rid of the old instance rather quickly. That could be done by manually killing any executions that are still running on the executor that is shutting down (but once again we don't want to kill them). But even for flows that are normally short-lived, if a job doesn't respect killing for some reason, then I would have to shut down executor forcibly any way.. @chengren311 I've made those changes to use warn level.. @chengren311 Ok, I didn't have such data in the DB and didn't expect it either. It's probably some old left-over data (not possible to be inserted with current code). This is the sequence that's setting the null value in the returned map:\njava\n        final byte[] data = rs.getBytes(3);\njava\n        if (data == null) {\n          execFlows.put(id, null);\n        } else {\nSo it seems like you have an unfinished execution row in your DB that has a null value for the data field, but its executor id is not found in the executors table any more.\nI will fix that NPE.\nYou would get the same NPE also without my changes, if you would \"add back\" the executor id of that execution into the executors table. . @chengren311 would you be able to get some additional details? For example, the results of running the sql FetchActiveExecutableFlows.FETCH_ACTIVE_EXECUTABLE_FLOW against that DB.. Thanks @chengren311, unfortunately it doesn't really help. The flow_data is in bytes, so I would need it in a different format to be able to parse it into an ExecutableFlow object.\nBut let's debug this way instead: could you merge or apply this patch https://github.com/azkaban/azkaban/pull/1867, test again, and report the stacktrace, please?. @chengren311 great, fix candidate here: #1868.\nCould you test again with both that and #1867, please?. @jamiesjc yes \u2013 currently it's so that azkaban-web should be restarted after removing an executor.\nHowever I'd like to make web server update active executors from the DB periodically so that restart wouldn't be needed.. @jamiesjc would you have more details on that timing issue? I thought that azkaban-web wouldn't keep asking for updates from executor as long as executor finalizes the status for all its executions before shutting down. If this is not the case, azkaban-web should be changed to act like that.. @jamiesjc I would've expected that error being logged even before my changes if an executor shuts down without finalizing all of its executions. No? Previously azkaban-web would eventually finalize the flow because it can't connect to the executor. But that's specifically what must be avoided, because if azkaban-web finalizes executions blindly without knowing the actual status of an execution it could for example violate the concurrency rules of a schedule.\nYour case is properly cleaned up, given that\n- stopped executor has been removed from the DB\n- azkaban-web is restarted\nUntil that, azkaban-web keeps notifying about the error. This is how it was intended. Admins should not leave ghost executors in the executors table and they should restart azkaban-web after making changes in the executors table (for example stopping an executor causes that, or then manual changes).\n\nHowever I'd like to make azkaban-web update active executors from the DB periodically so that restart wouldn't be needed.\n\n^ So, how about doing this?. > Yes, the error log is irrelevant to your change. The concern is about the timing issue between shut down api action and finalizing flow status from web server. I would prefer fixing this issue since this is the root cause.\nTo clarify, is the problem just that an error is logged? You wouldn't want any error logged on azkaban-web's side when executor is shut down gracefully? Indeed that can be avoided, but note that error should be logged if the executor is still found in the DB but is not responding.\n\nOne possible solution I can think of is to shut down the executor when there is no flow in the recently finished flow cache. All the finished flows will be moved from running flows cache to recently finished flow cache on executor and the recently finished flow cache will be cleaned up after 1~2 min. The web server should still have sufficient time to get flow status update from executor before the executor is shut down. Could this prevent the timing issue mentioned above?\n\nIn my opinion that's not so nice way to handle it. Because it adds extra delay in executor shutdown and depends on timing to match on executor & web.\nI think a better option would be to always reload executors from the DB before the update loop. Also, if an executor still cannot be reached, check the list of executors immediately again. If the executor was removed, finalize the execution as usual. If the executor has not been removed, then it's worth an error to be logged etc.\n\n@juhoautio For your proposed solution, does it mean the running flows cache on web server will be updated periodically as well?\n\nNot needed. The current way should work.\nYou can check ExecutorManager#finalizeFlows \u2013 it takes care of removing executions from ExecutorManager.runningFlows. Especially if a flow is finalized in a situation where the flow's locally cached status is RUNNING, finalizeFlows loads the actual flow status from the DB to check the actual status, and only marks it as FAILED if !isFinished(dsFlow) (where dsFlow is the up-to-date execution info from the DB).. > No, the main problem is that the flow status is inconsistent now. They are showing up on running flows page but are actually finished already.\nActually finished in what sense? Do you mean that they have some finished status in the DB, but azkaban-web still thinks they're running? If so, that's a corner case that is more about dispatching than about getting updates, and should be handled separately. I mean, when checking for the concurrent option, the status of any blocking executions should be checked from the DB, unless that's already the case.\n\nIn this case, the executor is not found in the DB because they are shut down by the shutdown api call and we are still seeing the error before we restart the web server.\n\nOk, this won't be an issue after the fix I proposed (refresh active executors from the DB before treating as an error).\n\nBy reloading, you mean reloading all the executors, not just the active executors, right?\n\nYes.\n\nWhy is it necessary to always reload executors? It seems you only need to fetch the executor info from DB when the executor cannot be reached?\n\nIt's not a must, but:\n\nThis way new executors are automatically taken into use without having to restart azkaban-web\nBut is it possible that people would not want this to happen in some cases? If so, it would be better to change executors so that they don't automatically activate themselves, because there could be other reasons to restart azkaban-web while not being aware that there are new executors in the DB that shouldn't be taken into use yet.\nI thought it would be better to avoid making a failed / timed out call on a removed executor.\nThis is a small optimization, but basically redundant (as you pointed out) \u2013 the code has to handle the failure case any way.\n\nThe executors table is about as small as the number of executor nodes though, so it shouldn't be a problem to read it often.\n\nHow about I make a PR with this plan:\n\nRefresh executors from the DB before each update round\nIf calling an executor fails (that is, no JSON can be received at all, not even JSON with the \"error\" field in it):\nRefresh executors from the DB\nIf the executor had been removed, finalize the execution\nIf the executor is still in the DB, do as before ie. increment failed update count & eventually notify about it with alerter according to the alerting threshold. @jamiesjc thanks for your reply.\n\n\nYes, they have finished status in DB but on the \"Currently Running\" executing flows page, they show up as Running status. And when you click the execution, it shows as finished status. The root cause of this inconsistency is the getting updates. Even if users do not submit the flows again, the inconsistency issue itself still exists, visible from the UI page.\n\nIt's natural though, that sometimes an execution finishes just after you clicked it, even if it was actually running. But if there's too much delay currently (by the updater thread) maybe the page should be optimized to get the running executions directly from the DB somehow. Still, I see this as a separate issue.\n\nwhen we do deployment, we have the last step to reload executors from DB (update activeExecutors cache), but only after the deployment is successful and integration tests run successfully. I think refreshing executors should not happen automatically.\n\nOk but wouldn't it be safer then that executors wouldn't automatically add themselves to the DB? Or they could add but as inactive only. Otherwise it could happen that azkaban-web is restarted before a new executor has been validated and it gets added to active executors for dispatching. Obviously if you control azkaban-web it most likely won't be restarted during executor deployment :) Any way I think it would be a cleaner concept to require enabling executors explicitly if you want to do some checks first.\nIn your case, instead of restarting azkaban-web your last step would be to activate the new executor. There's an API for that already, to do it in a clean way.\nThe executor startup behavior should be configurable so that azkaban would also allow adding executors just by creating them without having to restart azkaban-web or call the activate API, if simple is what the user wants.\nOne thing in favor of live reloading executors is that azkaban-web doesn't support HA. This change would remove azkaban-web downtime during executor deployments.. > This is not just a matter of delay, the inconsistency of flow status remains all the time until the web server is restarted\nOk, I thought you were talking about the normal situation, but you actually meant the situation where  an executor has been removed but azkaban-web doesn't yet know it. That will be fixed by the live-updating of executors by azkaban-web.\n\nActually when a new executor is deployed, we do the validation first and then set the executor to active\n\nWow, we had missed this change:\nhttps://github.com/azkaban/azkaban/commit/309a53e87eb5536531b5bce0b08a49c70fc9c5d9#diff-6bba907bedf62d34e7421866572b7f4d\nThus, in our DB the default is still active=TRUE, and thus any new executor automatically sets itself as active. We must change our internal deployment model to be similar to yours, ie.\n- change the default of executors.active to FASLE\n- validate the executor first\n- set executor as active\n- bonus: don't restart azkaban-web, call reloadExecutors instead (there seems to be an action reloadExecutors on azkaban-web's ExecutorServlet. I haven't tried it yet) \u2013 also this won't be needed at all once the automatic updating has been added.\nSo that part indeed doesn't need any changes in Azkaban.\nWill proceed with the plan outlined on the bottom of: https://github.com/azkaban/azkaban/pull/1833#issuecomment-427935427.. @chengren311 could you review, please?. No, it's not supported. Job-level execution is entirely managed by a single executor instance.\nAs a work-around you could split your jobs into multiple flows (grouped by executor id to use) and use the rather new conditional triggering feature to start each flow when its flow dependencies have finished.. @chengren311 to me it would seem sensible to merge this in. What do you say?. @HappyRay I included a screenshot after fix. Would you be able to check what the Flow Log currently looks like at your end using the current master, and maybe add a screenshot?\nI don't know how to build the less to css so that I could see the UI changes when running AzkabanSingleServer from IDEA.. Actually I suspect that this may have been caused by some merge conflict in our fork, and is not an issue with the public master(?). I'll have to check more closely.. @HappyRay I figured out the cause: for example a long value for Submit User causes this. Updated PR description accordingly.. I checked build failure on Travis, the failed test is:\n```\nazkaban.execapp.FlowPreparerTest > testProjectCacheDirCleaner FAILED\n    java.io.IOException: java.lang.RuntimeException: java.nio.file.NoSuchFileException: projects/1.1/azkabanproject_dir_size_in_bytes_\n        at azkaban.execapp.FlowPreparer$ProjectCacheDirCleaner.deleteLeastRecentlyUsedProjects(FlowPreparer.java:268)\n        at azkaban.execapp.FlowPreparer$ProjectCacheDirCleaner.deleteProjectDirsIfNecessary(FlowPreparer.java:292)\n        at azkaban.execapp.FlowPreparer.setupProject(FlowPreparer.java:170)\n        at azkaban.execapp.FlowPreparerTest.testProjectCacheDirCleaner(FlowPreparerTest.java:176)\n    Caused by:\n    java.lang.RuntimeException: java.nio.file.NoSuchFileException: projects/1.1/___azkaban_project_dir_size_in_bytes___\n        at azkaban.execapp.FlowPreparer$ProjectCacheDirCleaner.lambda$deleteLeastRecentlyUsedProjects$0(FlowPreparer.java:264)\n        at java.util.TimSort.countRunAndMakeAscending(TimSort.java:355)\n        at java.util.TimSort.sort(TimSort.java:220)\n        at java.util.Arrays.sort(Arrays.java:1512)\n        at java.util.ArrayList.sort(ArrayList.java:1460)\n        at azkaban.execapp.FlowPreparer$ProjectCacheDirCleaner.deleteLeastRecentlyUsedProjects(FlowPreparer.java:258)\n        ... 3 more\n\n        Caused by:\n        java.nio.file.NoSuchFileException: projects/1.1/___azkaban_project_dir_size_in_bytes___\n            at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)\n            at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)\n            at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)\n            at sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)\n            at sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:144)\n            at sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99)\n            at java.nio.file.Files.readAttributes(Files.java:1737)\n            at java.nio.file.Files.getLastModifiedTime(Files.java:2266)\n            at azkaban.execapp.FlowPreparer$ProjectCacheDirCleaner.getLastReferenceTime(FlowPreparer.java:250)\n            at azkaban.execapp.FlowPreparer$ProjectCacheDirCleaner.lambda$deleteLeastRecentlyUsedProjects$0(FlowPreparer.java:260)\n            ... 8 more\n\n```\nSo it's the same as the one reported at https://github.com/azkaban/azkaban/issues/1901. I mean that the existing CSS rule makes the flow log box grow according to the window size. My change makes it fixed height. So if screen is small, it gets cut and you need to scroll the screen to see the rest of the box. Then the box itself also has its own scrollbar :) And if you have a big screen then you would have some empty space below the flow log text box.. Personally I'm not an expert in CSS, but it seemed like it might require rather extensive refactoring to allow dynamically sizing the flow log textbox.\nI understood that the existing rule with position: absolute would be the way to go, but the structure of divs would need to be changed to make the tab bar be the \"parent\" of the textbox.\nIt would be better to get someone that's proficient with CSS to look at this. The bug itself is easy to reproduce as I showed with the screenshot.. @HappyRay ping. @HappyRay It'd be good to change the regex in https://github.com/azkaban/azkaban/wiki/Developer-Tools-and-Tips#how-to-find-test-failure-from-the-ci-log to > \\w* FAILED. This pattern is able to also catch strangely named tests like FlowRunnerTestYaml (see https://github.com/azkaban/azkaban/issues/1921). Looks like wiki pages can be only edited by repo owners and there's no PR-like process.. @HappyRay thanks.\n\nI hope it won't make the result too noisy.\n\nNot at all, it only had that one hit when the build failed due to FlowRunnerTestYaml.\n\nI also changed the permission to allow anyone to edit the wiki\n\nNice, it works. I just edited the wiki page to add a single space before '>' in the regex. Not a must, but makes it even more deterministic.. @HappyRay @chengren311 please have a look, I just noticed that @chengren311 was possibly working on that flaky test... I also saw this in the logs after upgrading to latest version.\nTo me it seems like this ERROR is always printed if you open a page that includes showing flow triggers BUT you haven't configured quartz scheduler:\nhttps://github.com/azkaban/azkaban/blob/master/azkaban-web-server/src/main/java/azkaban/flowtrigger/quartz/FlowTriggerScheduler.java#L132\nThat property is azkaban.server.schedule.enable_quartz\nhttps://github.com/azkaban/azkaban/blob/master/az-core/src/main/java/azkaban/Constants.java#L206\n..which defaults to false:\nhttps://github.com/azkaban/azkaban/search?q=ENABLE_QUARTZ&unscoped_q=ENABLE_QUARTZ\nIn my opinion it's wrong to fail loading exceptionally like that. As long as it's possible to not have quartz enabled, that should be properly checked & handled.. The Travis failure is not related to my changes as far as I can see. I created an issue about it: https://github.com/azkaban/azkaban/issues/1921. @jamiesjc I have a fix proposal for that test.\nThe test file is:\ntest/execution-test-data/basicflowwithoutendnode/basic_flow.flow\nContent:\n```\n\nconfig:\n  flow-level-parameter: value\nnodes:\n  - name: jobA\n    type: test\n    config:\n      seconds: 0\n      fail: false\n\n\nname: jobB\n    type: test\n    config:\n      seconds: 0\n      fail: false\n\n\nname: jobC\n    type: test\n    config:\n      seconds: 2\n      fail: false\n```\n\n\nSo jobC sleeps only 2 seconds.\nI was able to make the test fail constantly locally by adding a line of sleep before kill, like this:\njava\n  @Test\n  public void testKillBasicFlowWithoutEndNode() throws Exception {\n    setUp(BASIC_FLOW_YAML_DIR, BASIC_FLOW_YAML_FILE);\n    final HashMap<String, String> flowProps = new HashMap<>();\n    this.runner = this.testUtil.createFromFlowMap(BASIC_FLOW_NAME, flowProps);\n    final ExecutableFlow flow = this.runner.getExecutableFlow();\n    FlowRunnerTestUtil.startThread(this.runner);\n    assertFlowStatus(flow, Status.RUNNING);\n    assertStatus(\"jobA\", Status.SUCCEEDED);\n    assertStatus(\"jobB\", Status.SUCCEEDED);\n    Thread.sleep(5000L);\n    this.runner.kill();\n    assertStatus(\"jobC\", Status.KILLED);\n    assertFlowStatus(flow, Status.KILLED);\n  }\nHowever, if I increase the sleep time of jobC (in the YAML file) like this:\n...\n  - name: jobC\n    type: test\n    config:\n      seconds: 20\n      fail: false\nThen the test doesn't fail any more.\nSo, it seems that sometimes the test runner on Travis is running so slowly, that the 2 sec sleep time of jobC is over before the runner.kill() call is propagated / reaches that job, and the job & flow are marked as SUCCEEDED.\nTo stabilize this test it should be safe to set the seconds of jobC to anything greater than 10 seconds. It could just as well be infinite, doesn't matter.\nShould be obvious, but don't add Thread.sleep to the test method itself. It was there just to demonstrate what the race condition can be like.. Actually, my proposed fix makes another test FlowRunnerTestYaml#testBasicFlowWithoutEndNode fail. But that test has a problem of its own. It currently always takes > 2s because jobC sleeps the full 2 seconds.\nTest shouldn't contain any fixed sleeps. A case like testBasicFlowWithoutEndNode should be handled like this:\n- let the job start but make it go into Object.wait until notified\n- assert that job status is running\n- notify the job allowing it to return\n- assert that job status is succeeded\nThis is exactly how InteractiveTestJob is used in other tests. Especially InteractiveTestJob#succeedJob. You can find many usages in other tests.\nedit: but is it really required for the test to assert that RUNNING status? it would be simple to have 0s sleep and just assert that the job succeeded.. @jamiesjc Was this supposed to have been fixed? Issue is still open?\nMy other PR failed with this error again, but I realized that maybe it's because I haven't rebased that code for a long time.. Aha, it still happens after rebasing:\nhttps://travis-ci.org/azkaban/azkaban/builds/425279202?utm_source=github_status&utm_medium=notification\n```\nazkaban.execapp.FlowRunnerYamlTest > testKillBasicFlowWithoutEndNode STANDARD_ERROR\n    testJob: jobB SUCCEEDED\n    testJob: jobA SUCCEEDED\n    testJob: jobC RUNNING\n    ExecutableFlow: basic_flow KILLING\n    ExecutableNode: jobB SUCCEEDED\n    ExecutableNode: jobA SUCCEEDED\n    ExecutableNode: jobC RUNNING\nazkaban.execapp.FlowRunnerYamlTest > testKillBasicFlowWithoutEndNode FAILED\n    java.lang.AssertionError: Wrong status for [jobC] expected: but was:\n        at org.junit.Assert.fail(Assert.java:88)\n        at org.junit.Assert.failNotEquals(Assert.java:834)\n        at org.junit.Assert.assertEquals(Assert.java:118)\n        at azkaban.execapp.FlowRunnerTestBase.assertStatus(FlowRunnerTestBase.java:133)\n        at azkaban.execapp.FlowRunnerTestBase.assertStatus(FlowRunnerTestBase.java:138)\n        at azkaban.execapp.FlowRunnerYamlTest.testKillBasicFlowWithoutEndNode(FlowRunnerYamlTest.java:69)\n```\nWhen I run this test locally it succeeds.. Oh, do you mean that there is this kind of bug in the runtime code (not a testing problem then)? Disabling the test sounds like a solution \ud83d\udc4d. @chengren311 thanks for checking in the unit tests. How about this one now?. @chengren311 @kunkun-tang @HappyRay could you consider this, please?. Or @jamiesjc ?. Thank you!!. > If we set the sleep to 0, it means no wait and the job could finish early even before calling failJob() or succeedJob()\nNot true if fail property is not set at all. Note that there's a while loop in InteractiveTestJob, that keeps looping unless the fail property exists. If sleep=0, then wait() is not called at all, just because wait(0) would wait forever. The InteractiveTestJob class is a bit messy and this particular behaviour is a bit unintuitive.\nMy understanding is that it works like this:\n- fail=true -> fail immediately\n- fail=false -> sleep (if seconds > 0), then succeed (no further looping). Additionally the sleep can be interrupted from outside, for example if the flow is killed.\n- fail missing -> wait until succeedJob() or failJob() is explicitly called (note that killing ie. InteractiveTestJob.cancel() calls failJob())\nFinally, setting sleep=0 when fail is missing makes the while loop \"busy\". I think such scenario should be handled separately in InteractiveTestJob. Simple way to handle that would be:\nif (!this.jobProps.containsKey(\"fail\") && waitMillis <= 0) {\n    waitMillis = 10_000L;\n}\nBut that makes the code more and more messy. I'm sure there's a cleaner way to incorporate this behaviour..\nI could make another PR to make this improvement + code structure cleanup for InteractiveTestJob.\nTo comment your actual change, the last commit you made is a good one, because it avoids the busy while loop. The test would've been stable also without that change though.. \ud83d\udc4d by me for the whole changeset. @jamiesjc this was also related to timing problems that you faced when writing some tests. How about having this \"fix\"?. @happyapple668 See this: https://github.com/azkaban/azkaban/pull/1694#issuecomment-398513531\nDifferent MySQL versions have different defaults. Simple way to increase the index key prefix length is to upgrade to MySQL 5.7, if possible. It may be possible to also change the limit by configuration without changing MySQL version.. @kunkun-tang thanks. I'm resolving the conflicts... ok done. @chengren311 because you reviewed https://github.com/azkaban/azkaban/pull/1922 you're quite familiar with this part of the code. Would you have time to have a look?. Bump. If you have time, please review... @chengren311 you\u2019re absolutely right.\nThe history is that prior to making this PR I didn\u2019t realize that there should be a distinction between retriable @ non-retriable. But then I did, and wrote about those concerns in the PR description.\nI would still like to have this available as an experimental/use-at-your-own-risk feature before adding checks to detect retriable cases. After all, non-retriable dispatch errors seem very rare.\nFinally, I think the bug with \u201dalready running\u201d is severe enough to be worth a fix asap: if executor responds with that message, stop trying to dispatch that execution again.. Quick question on the matter of experimental feature: what do you mean it can\u2019t be turned off? There\u2019s no change in behaviour at all compared to previous version unless user specifically sets a high max retry in configuration.. @chengren311 here goes,\n\nWhat do you think of the complexity of implementing distinction between retriable & non-retriable errors?\n\nIt shouldn't be too complicated I think. I would do it so that clearly non-retriable errors are detected based on what the executor response says. I would add a new field in the response specifically to communicate this. Any other error would be assumed to be retriable.\n\nSince we are actually considering a new dispatching paradigm -\n\nThat sounds like a major effort. I feel like there are more important improvements to be done first. Allowing more dispatch errors (infinite in practice) would work for me.\n\n\nweb server pushes flow to dispatch to standalone dispatching queue(e.g mysql db as queue)\nexecutor pulls the flow from the queue when its resource is available.\n\nThe advantages would be \n1.dispatching logic is much simpler, eg. web server doesn't need to retry on failure.\n\nNot sure if it's actually going to be much simpler though? Somehow an executor would need to make in initial reservation to an execution in the queue, then only if it actually manages to start it, remove it from the queue. But you would need to achieve this kind of transactionality in a multi-node setup. The point is to avoid a case where an execution is removed from queue but executor doesn't even start running it because of an error.\nCurrent model makes an initial executor assignment and removes it if dispatching fails. It has some weakness in dispatching currently, but it could be rather easily be fixed to guarantee exactly once dispatching, thanks to azkaban-web's ability to synchronize on itself, being a single node. I'm sure same things can be done well enough with a queue-based solution, but I wouldn't expect it to be simpler to implement \u2013 rather more complex.\n\n\npaves way for decoupling web server and executor\n\n\nThe cleanup of executions left behind is also still needed. It can be done obviously, but just saying.\nWhat actual problem does the \"decoupling\" solve?\nCould you check also my previous comment, please?. @chengren311, this PR only allows configuring more dispatch attempts than number of active executors, which is the upper cap currently. Default value remains the same as before: the number of executors.\nFrom the PR description:\n\nThis change allows configuring a limit that is in practice high enough to keep retrying forever, until at least one responsive executor\n\nBy this I don't mean an actual infinite loop. I just mean that if you configure a really high value for max attempts, in practice it's basically the same as retrying forever.. The existing unit test testDispatchFailed verifies the behavior of giving up dispatching when max attempt is reached.. @chengren311 did my answers make sense? If yes, I can resolve the conflicts.. @chengren311 I've rebased + resolved conflicts. To make the test quick, I used a package-visible setter setSleepAfterDispatchFailureMillis(0L) instead of introducing a new property name. I hope you like that better :). @HappyRay ok I changed to use Duration. Code complexity grew slightly, but at least the arg name is shorter now.. \ud83d\udc4d for this change.\nI don't believe this change has anything to do with the decreased coverage. It's probably just that the tests have some randomness factor in what code gets executed, and as a result coverage can fluctuate between different test runs.. \ud83d\udc4d This looks really good.\nAny plans to apply these rules on all classes in the repo?\nFor example, if I apply save actions with this configuration on ExecutorManager.java, there are many references to the logger in the inner classes that then become ExecutorManager.logger.. @chengren311 @HappyRay see my other pr, I already started doing that.. Is this a duplicate issue #835: \"Memory leak of execution specific loggers in org.apache.log4j.Hierarchy\"?. @jamiesjc this is some groundwork for https://github.com/azkaban/azkaban/pull/1833#issuecomment-428481883.\nAnd especially as you wrote in https://github.com/azkaban/azkaban/pull/1833#issuecomment-428276401:\n\nIt would be great if you could figure out a proper way to test the changes as well.. @jamiesjc javadocs added. @jamiesjc I removed that TODO comment about refreshing executors. Would this PR be acceptable now?. @jamiesjc could you review maybe?\n\nI rebased & resolved conflicts. Possibly still getting unrelated test failures.. Would be good to merge at least this fix: https://github.com/azkaban/azkaban/pull/1985.. Travis failure:\n\nThe job exceeded the maximum log length, and has been terminated.\n\nXD. @jamiesjc I added a commit. @jamiesjc now the build has passed, thanks to https://github.com/azkaban/azkaban/pull/1983.. Bump this, anyone?. @chengren311 I've updated this ^. @chengren311 good to go now?. I would categorize this as a \"known issue\" though. I could at least create a github issue about this.. Do you have any insight into why it is like this? Should this be fixed?. Anyone to comment on this, please?. @chengren311 @jamiesjc could this be merged, please? Almost all PR merge builds are failing and it makes it quite slow to check if a PR is legit.. When making PRs it's a bit counterproductive that the \"codecov/project\" check is almost always failed. Do you think it could be disabled, or then set some higher threshold for that check? For example a limit of 0.5% would allow this PRs check to pass.. Was the behaviour different before, or is this just a general remark?\nIf you're observing a change, did you update Azkaban version recently, and what are the Azkaban versions involved?. @chengren311 @HappyRay I didn't investigate more what this is about exactly.\nApparently there's some condition that depends on whether the flow was killed by sla or if it was a basic kill.\nYou can see in the first commit how the test fails / flow gets stuck if there's some delay between the kill call & setting of killed by sla flag.. @chengren311 ?. @HappyRay @chengren311 bump?. Can I help with this, what do you want to know?. @HappyRay @jamiesjc I have now added a thorough explanation of the bug & fix into the PR description.\nI checked out the individual commits again locally & this time collected the output. I have edited the PR description to include them. Please have a look, this should show clearly enough what kind of bug there is & how the fix helps.. @HappyRay @jamiesjc please?. @jamiesjc added commit ^. No. In my company we have a custom file format for defining schedules, so that both job files & schedules can be stored in git and deployed to Azkaban automatically.\nI don't remember how scheduling is handled at LinkedIn? Do users just add schedules manually via the UI, does everybody have their own scripts..? I couldn't find anything about scheduling from https://github.com/linkedin/linkedin-gradle-plugin-for-apache-hadoop/wiki/Hadoop-DSL-Language-Reference either.. Sorry, I somehow understood your question originally as a question like \"is this supported?\". But looks like it's a feature suggestion. Would be a great addition, I couldn't agree more.\nI can't see why schedules couldn't be part of job files themselves. Maybe the scheduling-related properties should be prefixed with schedule. for clarity though.. Anyone? Tiny one line change... Please?. @chengren311 maybe? :). @HappyRay @jamiesjc ?. Hi, any chance to merge this one-liner in to avoid the flooded logs?. @HappyRay @jamiesjc how about? I wonder, aren't your logs also full of this warning... @jamiesjc in practice this has been only spamming a lot with .jor. I would keep the log line though, so that it can be enabled in logger conf for debugging if needed in some case.\nBy the way, I now tried to analyze a bit how the method is used otherwise. It doesn't seem like all corner cases are handled perfectly. For example, if ProjectManagerServlet#handleJobPage is called and job is concurrently deleted between the calls of projectManager.getProject and projectManager.getProperties, handleJobPage can fail with an NPE. Doesn't seem like a major issue to me but.. For example in this case there's no real need to have the warn about missing properties though, it's not really needed to find out what went wrong.. @jamiesjc could you comment, please?. > What's the ultimate goal of detecting non-retriable errors?\n\nTo not accidentally dispatch the same execution multiple times in parallel (on different executors)\nFor the dispatching queue to not get stuck too long in trying to dispatch one problematic execution.\nThis only really matters if azkaban.maxDispatchingErrors is set to some high value (to prevent giving up dispatching too quickly in case of transient errors)\nTo not give up dispatching an execution just because the executor that was tried is shutting down. >> To not accidentally dispatch the same execution multiple times in parallel (on different executors)\n\n\nCan you give an example of how this scenario could happen?\n\nYes, I admit that it's about a rare corner case.\n\naz-web sends dispatch request to executor 1\nexecutor 1 starts running the execution and returns OK \ndue to some transient network error az-web can't read the HTTP response\nthe basic case would be a socket read timeout\naz-web tries to dispatch the execution again\nconsidering that there are more than 1 active executors, az-web tries to dispatch to another executor, let's call it executor 2\nexecutor 2 accepts the execution\nresult: the same execution is now running on two different executors: 1 & 2\n\nNow, to fix this properly, az-web should actually check the DB after a failed request (this is only needed if it managed to connect & send the request, but failed to read response). The other executor wouldn't know to return ALREADY_RUNNING any way, so having ALREADY_RUNNING doesn't help against protecting dispatching the same execution on multiple executors.\nALREADY_RUNNING response makes it easy to reliably dispatch an execution exactly once when using a single active executor, but it is kind of redundant if DB has to be checked any way after a failed request.\n\n\nFor the dispatching queue to not get stuck too long in trying to dispatch one problematic execution.\nBy default, azkaban.maxDispatchingErrors is set to the number of active executors, which is not a big number.\n\nI don't see a problem here at least for our system. Is it currently a concern for you guys?\n\nCorrect. For us the ideal setup is to allow a low number of \"best-effort\" max dispatch attempts & a really high max attempts for \"always retriable\" executions. Why is this ideal? Because this way dispatching of scheduled executions won't be skipped if we have executor downtime that isn't resolved before a few hours. If we hit such downtime and devops fixes the broken executor, it will be quire hard for devops to manually trigger all the scheduled executions that were missed during the executor downtime. Related issue is that az-web doesn't currently support catchup of scheduled executions if az-web itself has been down. That should be fixed as well to guarantee that no scheduled executions are ever missed.\n\nIf an executor is shut down, then the web server could not get any update from it and would switch to another executor and dispatch. Isn't that the current behavior?\n\nOk, it seems likely to me that az-web never tries to dispatch to an executor that is shutting down. But it can't be ruled out. What I know for sure is that executor does reject a dispatch call if it's shutting down at the time. For completeness az-web should recognize that error type as \"forever retriable\" ie. keep trying to dispatch for next executor until it finds one that isn't shutting down :) Sorry, I didn't bother to investigate deeply if it's ever possible for az-web to try to dispatch on a executor that's shutting down. Given the asynchronous nature of updating executor stats etc., I would tend to think that this can happen.. @jamiesjc @HappyRay thanks for taking the time to look into this.\n\nDo you mean checking the flow status in the DB? It might still be in PREPARING status at the time when the check happens if there is any delay in starting the flow on the executor.\n\n@jamiesjc yes, but I was assuming:\n1. Delay in updating the status to RUNNING won't be too long if executor has accepted the execution\n1. After a failed request az-web will have a short but long enough grace period before checking the DB\n\nIf one executor is down, there are still other available executors ready for dispatching.\n\n@jamiesjc if any executor is unreachable, it's quite likely that all of them get hit by the same problem \u2013 for example a network outage or congested DB. Do you know more about handleNoExecutorSelectedCase? To me it has always seemed like that isn't ever reached unless there are 0 active executors to begin with. But in that case az-web would actually refuse to start? My understanding is that as long as there's at least 1 active executor, if azkaban.maxDispatchingErrors is reached az-web gives up dispatching \u2013 it doesn't re-queue the execution. handleNoExecutorSelectedCase might be dead code.\nAs such re-queueing in case of too many dispatch errors sounds good, because it would ensure that nothing gets discarded. But it will mess up the order of executions. That might be a problem (but I'm not sure what would happen to pipelined executions if the executions are submitted in an unexpected order?). Unless we can deduce that submission order doesn't matter, I would rather avoid shuffling.\n\nI thought the scheduled executions were saved in DB and will resume after the web server is back\n\n@HappyRay that would be perfect actually. Does that feature really exist (or does it work :)), because I have some recent experience where schedules were missed because az-web was down and I couldn't find the expected executions, not even in any abnormal state like PREPARING or FAILED. Of course I can rather easily test it \u2013 will do.\n\nEven if the error type is not specified, az-web will still try to dispatch for next executor until it finds the available one. If in the extreme case where all the executors are down and az-web still tries to dispatch to them, then the flow will be finalized in the end. I'm not sure if that's the scenario you are concerned about.\n\n@jamiesjc, again, I don't regard \"all executors down\" that much more extreme than \"one executor down\". Btw our current setup is 1 web + 1 active executor + 0-N inactive executors. We could have more active executors for additional availability, but that alone wouldn't guarantee much. Multiple executors can offer better availability (no downtime), but reliable exactly-once scheduling & dispatching must be handled by az-web (no missed executions).\n\nIf there are so many corner cases we need to consider and patch fixes on top, it might indicate that the original design itself needs to be changed towards some other direction.\n\nTrue that. But also the reality is that it seems like fixing smaller bugs and corner cases one at a time is an easy way to contribute and improve Azkaban's reliability. And maybe there aren't that many corner cases. The fixes that I've proposed in this discussion would already seem like a big plus from my perspective.. @jamiesjc what do you think? I know you commented about complexity, but to me this doesn't seem too complex. There aren't so many corner cases.\nI think I managed to craft a bit nicer plan for how to implement this.\nExecutor side:\n- If executor is shutting down, return 503 Service Unavailable HTTP status code instead of 200 OK with \"error\" in the response payload\n- If execution is already running, return 200 OK \u2013 dispatcher gets the confirmation that execution has been dispatched (I think it's actually a bug that this situation leads into an error currently)\nDispatcher side:\n- Don't give up dispatching if response is service unavailable or if connection times out\n- Give up dispatching immediately if executor returns 200 OK with \"error\" in the response payload.\n  - Optionally a couple of retries could be given even in this case, because maybe there's a small chance that it's not a bad request per se. Any way the cases where it makes sense to not give up as quickly are the ones where 200 OK can't be received in the first place.\nI think these rules should nicely cover all cases. There's no need to add a new enum ResponseErrorType that I have proposed in this PR. It's replaced by leveraging 503 Service Unavailable 503 & by changing \"already running\" case to return 200 OK with \"ok\" payload.. One chunk at a time seems like a good approach. First stab at it: https://github.com/azkaban/azkaban/pull/2023.. Obsolete now. Closing.. Could someone review, please? Created 11 days ago.. @HappyRay I wrote a brand new PR description. Is that clear enough?. @HappyRay, in case you missed this ^. Please, could someone review? Would be nice to have this fix.. @chengren311 thanks for merging https://github.com/azkaban/azkaban/pull/1993. I have now rebased this one to have a single commit.. @HappyRay, if you have time, could you revisit your comment https://github.com/azkaban/azkaban/pull/1994#issuecomment-431398770 and see if I've addressed your concern?. Please, anyone?. > I remember the executor will hard link the project directory when it starts execution. I wonder how that design doesn't prevent the issue you observed.\n@HappyRay that doesn't play a part in this. This is about a timing issue where the project version has been cleaned up from the DB before an executor has handled the dispatch request.. @burgerkingeater did you see this? ^. @HappyRay @burgerkingeater @jamiesjc what's up? Could you say something at least?. > does the timing issue happens when azkaban.project.ProjectLoader#fetchProjectMetaData is called to fetch the project version but that specific version has already been deleted due to new project uploads?\nI'm not entirely sure what you mean by that, but in practice I've hit this in JdbcProjectImpl#getUploadedFile. For reference, maybe check this earlier PR: https://github.com/azkaban/azkaban/pull/1993/files\n\nWe haven't seen this kind of issue before, but would like to know how often this would happen.\n\nYes, that's not surprising because in normal operation this would be rare to happen.\nIt only happens if there's a significant delay in dispatching (and on the other hand many project uploads in the meanwhile).\nWhat makes the issue more prominent in our setup is that we have implemented moving existing executions from an inactive executor to an active executor. For any long running executions (that are moved) it can happen much more easily that there have been enough uploads for the project to clean up the version that a running execution needs.. > What would cause the significant delay?\nIf there is no executor available for dispatching executions, but web server is available so that new versions of projects can be uploaded in the meanwhile before executor issue is fixed and dispatching continues.\n\nIs it possible to solve the delay problem itself instead of fixing it in deleting project versions?\n\nI can't think of another way that would be as reliable as what I've implemented in this PR. This works regardless of dispatch timing.\n\nBy inactive executor, do you mean the executor is still running but the active flag is set to false in DB?\n\nWe have custom code in our fork to support resuming. Main reason for implementing resuming is that if executor process crashes for any reason, interrupted executions are resumed automatically. This is crucial for us to make sure that flows don't stop running if executor process has been down for any reason.\n\nWhy do you need to move executions from inactive executor to an active executor?\n\nAs a bonus of resume support we're also able to shut down inactive executors without interrupting long running jobs that are \"external by nature\" (azkaban job is polling status of an externally running job). Running azkaban execution is automatically \"moved\" to an active executor when its original executor is found to have been removed. The error about cleaned up project versions obviously happens more easily when a long-running older execution is being dispatched (again).. @jamiesjc thanks. I pushed a new commit.. Great reviewing once again. Sorry for being sloppy with the naming so that you had to point those out.. @jamiesjc are you keeping this open until the next release or something, or just missed merging?. @HappyRay here it is. @HappyRay is this still urgent?. @HappyRay ref https://github.com/azkaban/azkaban/pull/1661#issuecomment-431197754, I thought you were in a need of this change. Did you find a way to live with the current code maybe?. @HappyRay this should provide an even better alternative: https://github.com/azkaban/azkaban/pull/2016. I wouldn't want to see additional delay in executor shutdown. Indeed https://github.com/azkaban/azkaban/pull/2016 makes it totally redundant.. Maybe this isn't needed since https://github.com/azkaban/azkaban/pull/2016 was merged.. I have asked the same question on the azkaban-dev mailing list and the answer was no.\nhttps://groups.google.com/d/msg/azkaban-dev/5mIEp-TaC9M/1WJ5FeyqCQAJ\nI'm copying @HappyRay's answer also here:\n\nThe philosophy of the new flow format is to keep it simple and rely on authoring tools like the DSL for more advanced use cases such as code sharing. \nI would like to see different authoring tools such as python based (airflow like) ones, Java based ones, web based ones to be developed. . Sorry for missing to add that property. Here's another related improvement: https://github.com/azkaban/azkaban/pull/2002. @jamiesjc here's a full fix: https://github.com/azkaban/azkaban/pull/2003 \u2013 maybe have just that instead of your PR?. > Is it worth explaining why it is harder to debug without this PR?\n\nDo you mean PR description or some comment in the code?\nAny way, without this change the ERROR from web startup is buried in an earlier phase of the logs. The JVM keeps running despite an exception thrown by web start call, because executor server's thread remains alive. As the executor server has already successfully started, it will keep logging some periodical stuff into the log file, making it harder to find out what was the last thing that happened on the web server's side.. What about refreshing executors automatically on az-web if the executor can't be reached? If the executor was shut down gracefully, it should have removed itself from the DB any way.. >> What about refreshing executors automatically on az-web if the executor can't be reached? If the executor was shut down gracefully, it should have removed itself from the DB any way.\n\nThe executor was shut down gracefully and the entry removed.\n\nYes, my point was that a better fix would be to make the updater check from DB does the executor exist any more if it can't be reached. And if the executor has been removed, just finalize the execution instead of trying to call executor to get the same information.\nWhy would this be better?\n- executor can shut down as soon as it has finished its work\n- updater can't miss the update depending on if the grace period was long enough. @chengren311 no, if a flow's executor has been removed from the DB, the execution gets finalized (and no trying to call executor for updates any more). If updater would also update executor list on the fly, the result would be that it would finalize any executions left behind by removed executors.. In the updater a couple of failed attempts are tolerated before taking action. I think checking executor's existence from the DB should work fine.\nTrue that it would be better to notify admins if an executor is deemed unresponsive. While there's an on-going issue like that, users should only be notified with SLA alerts if anything. However, after admins have resolved the issue (typically remove executor from DB), then the executions would be finalized as failed and users would get the alerts about it if configured.. This is most likely because of some recent changes. Sorry for the inconvenience.\nBefore anything else, have you tried restarting azkaban-web already? That would refresh the executor list from the DB.\n\nCheck your executors table in the DB.\nMost likely you'll find multiple entries, out of which you should be able to see which executor(s) are real and which ones don't exist any more.\nDelete the invalid executor entries from the table & restart azkaban-web.\nThe old execution should be automatically marked as FAILED.\n\nPlease confirm if this worked for you.\nCurrently this can happen if an executor crashes or is in any way not shut down gracefully, so that the executor doesn't get to remove itself from the executors table. The fix is to either start the executor again or remove the stale entry manually from the DB.. @jacksonKhUA if you're running a version that old, then what I wrote above doesn't even apply yet, sorry.\nYes, https://github.com/azkaban/azkaban/commit/e85075cd1ac90d27aba6737c89cbf41e096fb6b4 should take care of marking executions like that as FAILED. If I understood your situation correctly, it's more like a cosmetic issue, because the old execution with RUNNING status is not shown in the running executions list and it doesn't prevent or block new concurrent executions.. @trentgerman as a user of Azkaban my experience is that it's basically safe to make an UPDATE query directly on the DB to change the status when you know that the orphaned execution is not really running anywhere any more.\nYour screenshot seems like it's from the job history page \u2013 is that correct?\nWhat if you navigate to the execution page (of 6191), is the flow level status also still RUNNING?\nFrom Status.java you can find the mappings of status codes. Especially, FAILED = 70, RUNNING = 30.\nBefore update you can check:\nsql\nSELECT * FROM execution_flows WHERE exec_id = 6191;\nIf you want to change the flow level execution status, do this:\nsql\nUPDATE TABLE execution_flows SET status = 70 WHERE exec_id = 6191;\nIf the execution was still shown in running executions, restart azkaban-web at this point to refresh from the DB. \nIf you want to change the job level status in job history, do this (this specifically only changes that status for jobs that were left in RUNNING status):\nsql\nUPDATE execution_jobs SET status = 70 WHERE exec_id = 6191 AND status = 30;\nOf course you could check first what there is:\nsql\nSELECT * FROM execution_jobs WHERE exec_id = 6191;\nWhat these commands don't update is the graph object of the execution, so if you go to the execution page and view the graph or job list tab, jobs that were interrupted are still shown as running there. But the DB updates I have shown here let you at least get rid of the Running status in executions & job history pages.\nI haven't tried deleting any rows manually from execution_flows or execution_jobs, but I believe it shouldn't cause any problems either. If that's what you want instead, DELETE FROM x WHERE exec_id = y \u2013 but at your own risk :). Did you update both tables or only execution_flows?\n\nYour screenshot seems like it's from the job history page \u2013 is that correct?\n\nSame question also for this second screenshot. Flow executions is another view, which I'd expect to show the Failed status if you updated execution_flows.. @jamiesjc, as discussed.. @jamiesjc, updated ^. > a race condition scenarios could happen when multiple azkaban executor process are running\nOh, I didn't notice that before. And I was wondering, how could different executors on different machines interfere with each others' file systems :) Now it makes more sense :) Are you going to drop this change after all and stop running multiple executor processes on the same instance? Related: https://github.com/azkaban/azkaban/issues/2020. This can't mean stopping to support multiple executors per se.. Do you run multiple executor processes on the same instance during deployment or what is this about? Even if so, isn't that just deployment specifics that azkaban itself doesn't need to know about?. Ok, so we're in sync. We haven't tried running multiple executor processes on the same instance. I think the reasons are quite obvious. We create a new executor instance to deploy code changes, and keep the old executor running in inactive state until executions on it have finished.\nI don't see the need to add complexity to Azkaban as a product to prevent users from running multiple executor processes on the same instance. To me it seems quite obvious that successfully running multiple executor processes (with different ports I suppose) on the same instance is not easy to pull off without unwanted side effects and rather should not be attempted at all. But maybe it could be documented if it's not obvious.\nJust my two cents. Maybe I'm missing something.. > the case where an execution has been submitted successfully and is indeed running, but web server thinks it fails to dispatch due to some network error. In this case, I doubt it really makes any difference whether it throws an exception or just return OK because anyway web server cannot receive the response because of the network issue.\nNetwork error could happen randomly. In that case the first submit attempt would fail to read the response but already second time would succeed. I'm just trying to handle this corner case a bit better. (Although in reality I think it's very rare to end up in this state.) The current logic is flawed: dispatcher would finalize the newly submitted execution (mark flow status = FAILED) while executor is still running it.\n\nthe case where an execution is added to running flows cache but failed\nto be submitted to executorService. It doesn't make much difference to me that whether it throws an exception with..\n\nAs long as it's an \"error\", dispatcher shall treat it the same way, ie. basically give up & finalize. But maybe it can give a wrong idea if the message is just \"Execution is already running\". That sounds like nothing's wrong actually, even though there's this unexpected state (execution is in runningFlows but not in submittedFlows).\nThanks for sharing info on plans to switch to a pull model (push vs. pull, right?).. @jamiesjc I'd like to highlight this:\n\nThe current logic is flawed: dispatcher would finalize the newly submitted execution (mark flow status = FAILED) while executor is still running it.\n\nThis PR just fixes that, so I don't see why this wouldn't be an improvement worth doing?. I have asked the same question on the azkaban-dev mailing list and the answer was no.\nhttps://groups.google.com/d/msg/azkaban-dev/5mIEp-TaC9M/1WJ5FeyqCQAJ\nI'm copying @HappyRay's answer also here:\n\nThe philosophy of the new flow format is to keep it simple and rely on authoring tools like the DSL for more advanced use cases such as code sharing. \nI would like to see different authoring tools such as python based (airflow like) ones, Java based ones, web based ones to be developed.\n\nSee also: https://github.com/azkaban/azkaban/issues/1998. Backfill support might be enough for most use cases though. See also https://github.com/azkaban/azkaban/issues/1192.\nDo you often set flow overrides (execution scope) or why are the original params needed? . Sure, it still sounds like a backfill problem to me. It's just a more granular period (hour) than the most common backfill period (day).\nIn some scenario user might actually want to change some job properties (to fix some problem) and then run hourly backfill for a date/time range. Especially in such case one wouldn't want to use original properties. Backfill feature would only override the base timestamp for each execution that it submits.. > I think this feature should be a quick solution before the whole backfill coming out.\nIf using a snapshot of older properties is not generally needed, I would rather see new development focus on a more widely missed feature like backfill support.\nEspecially it seems that from the original executions's properties you're interested in using the flow.start.timestamp. However, to use it reliably for your use case, also its meaning should be changed. Currently flow.start.timestamp is set when the execution is started. For example, if the execution was scheduled at 00:00 but start of execution got delayed for any reason, the flow.start.timestamp could be set to something like 01:30. To me it would seem sensible to keep the current meaning, ie. it matches with the execution start time that you can also see in the Azkaban UI.\nOne independent part that's required for the backfill support would be adding a new provided property which could be called flow.base.timestamp. That can be overridden by user if so desired. In scheduled execution this would be the exact time of the schedule rule that triggered it.. @jamiesjc is this test going to become obsolete after the \"AZNewDispatchingLogic\"? If yes, I would disable or delete this test to stabilize the travis builds.. Problem solved more or less! Not sure if it will be significant enough to optimize between fetching flow data or not. Although on java side there could be some impact from parsing the zip data into ExecutableFlow, probably negligible any way.. We discussed this issue in https://github.com/azkaban/azkaban/pull/1991#issuecomment-431448447 but it hasn't been resolved. I'm not sure to what extent the new poll model will be protected against concurrency issues.\nThis improvement was recently done to the old dispatching logic: https://github.com/azkaban/azkaban/pull/2023. This should prevent double executions as long as you only have at most one active executor.. @burgerkingeater are you able to review this, too?. If there's an empty value like \"job.max.Xmx=\" in some properties, upload fails with this error:\n\nInstallation Failed.\nFor input string: \"\"\n\nSo it doesn't help much because it doesn't even tell the name of the problematic property.\nThis PR improves it by returning a better error message ie. one that includes the property name.\nCurrently user would need to grab the stack trace, get azkaban source code, and find the line, to know which property caused the upload failure.. @burgerkingeater ..good to merge?. @HappyRay ping. The quickest build in master build history's first page is 4 min 45 sec.\nThis PR built on Travis 4 min 57 sec.\nOn the other hand azkaban builds on Tarvis may some times take even 7 minutes.\nNeed more data to say anything sure about does this have an impact on build times on Travis on not.\nIf it's at least not making things worse, I'd like to have this change to optimize builds on my personal machine \u2013 which hopefully helps others too.. @HappyRay @jamiesjc anyone to test on your machine if you can see similar speed-up with this change?. @burgerkingeater yeah that's the theory, but the reality in practice seems different.\nThese are just guesses of course:\n\nMaybe the tests interfere with each other.. Maybe the additional forking is just expensive because every test needs to load some heavy classes / static members again..\n\nBut:\n\nWhatever the reason is, there's no point in having parallelism on if makes the total build time longer.\n\nIf I entirely remove maxParallelForks the execution time (51s .. 1m 4s as I tried two times) is on the same level as with maxParallelForks = 1.\nCould you also test it on your machine locally?. @burgerkingeater bump ^. @burgerkingeater have you been able to check what your local build time is and does this setting affect it?. @burgerkingeater tests shouldn't fail because of the maxParallelForks setting, at least when the value is 1. So maybe it was just some random error. Did you try only once? Maybe test once more with different settings?\nIf the conclusion is that at least maxParallelForks isn't making tests faster on any setup, would you be open to setting it to 1 in the repo?. @burgerkingeater are we able to conclude that this change can only make test run faster? In some environments it doesn\u2019t, but it also doesn\u2019t slow it down. Right? Please, this would be helpful for me at least, probably also for at least some other developers also. Now about a month old pr, so would be nice to reach a conclusion.. @burgerkingeater I've updated the PR description, is it what you were looking for?. @HappyRay could I get someone to review this, please?. @abti hi, could I get someone to review this one, please?\nSame question also for:\nhttps://github.com/azkaban/azkaban/pull/2111\n~~https://github.com/azkaban/azkaban/pull/2112~~\nhttps://github.com/azkaban/azkaban/pull/2113\nAll are quite small.. @burgerkingeater assert doesn't optimize the test, but:\n\nIt's actually best to leave the new assertion on CountdownLatch in place even though the problem was fixed. Because it will make the test fail instead of just being slow & succeeding, if the bug with skipping CountdownLatch is ever introduced again.. @burgerkingeater anything else?. @burgerkingeater usually it saves 9-10 seconds. Without this fix the test was always blocking the full 10 seconds on the countdown latch. Now it's only blocking until the latch triggers, which usually takes less than a second.. Could you update the comment to say that even on tomcat the jetty.* properties are used to generate links for email notifications?\n. Could you update the comment to say that even on tomcat the jetty.* properties are used to generate links for email notifications?\n. Could make that configurable globally:\n\njava\nresolvedProps.getString(\"time.replacement.default.format\", \"yyyy-MM-dd'T'HH:mm:ss.SSSXXX\")\nSo that I could for example set time.replacement.default.format=yyyyMMdd on the highest level and then just use ${time:-1day} in some jobs to yield 20160203 etc.\n. Sorry, but I didn't mean the PR title. I mean the comments in the azkaban.properties files. For example \"# Azkaban Jetty server properties. Ignored in tomcat\" above ^\n. The original PR title was fine I would say, LOL :)\n. I would say this is not the best fix because it still leaves other places like SendEmailAction broken.\nSee this alternative fix for the same issue: https://github.com/azkaban/azkaban/pull/673/files\n. implemenation -> implementation\n. implemenation -> implementation\n. The difference between common & commonprivate (in jobtype directory) is still a bit unclear to me.\nCorrect me if I'm wrong, but I've understood that in practice common.properties is only exposed when running an actual job. commonprivate.properties is also loaded when registering the jobtype class initially.\nOne specific case was that to allow Azkaban initialize the command job type with less available memory, we had to set memCheck.enabled=false in commonprivate.properties. Setting it in common.properties didn't help, because job type manager doesn't load it at the crucial phase. This feels pretty much like trial and error to me, but maybe there is some logical explanation to this :)\n. I think this fix should be good enough \u2013 keep it simple. Let's see if repo owners have any comments.\n. Could change that to logger.error(e); if you say so.\n. > This method is for unit testing only, right?\nYes. But no harm done if someone calls them in actual application code.\n\nHow about making it package private? This way the readers would know that this is not a public API outside this package and would reduce the search space.\n\nCan't use empty/default package because different packages:\nazkaban.utils.EmailMessage\nazkaban.executor.mail.DefaultMailCreator\nIn this case, I hope it's acceptable to add these getters.\n. I realized that joda-time is being used in the project already so switched to use DateTimeUtils and got rid of the getters/setters.\n. @suvodeep-pyne When I Open... the azkaban folder in IntelliJ IDEA, IDEA imports it automatically from the gradle build files. IDEA sets source & test folders and imports dependencies.\nIs there some benefit from letting gradle generate the project files instead? I don't mind having the idea plugin here, but I hope it isn't run by default when building distTar.\n. Sorry, should remove this. Added comment before the fix.\nedit: removed that comment\n. I mimicked the style of existing code like Event.create. As far as I'm concerned, it could be a public constructor, too.\n. No use case other than making it easy to see that \"it's the nestedId that is being set here\". I can change to have another create method and make both fields final.\nedit: did that (see diff again)\n. I don't really know, does it require a comment? Previously Node.getNestedId() was used in some event handlers, so I'm carrying it here, as the Node is replaced with EventData in Event.\n. I just modified this method signature. Code wouldn't compile if I hand't modified all its callers. So I did, and made sure that it isn't called with null. If someone adds a new call to Event.create, they can test that it works?\nI can remove the null-check here if you want, but it will be then much harder to debug where the null came from if NPE happens later in an asynchronous callback. At that point there won't be a useful stacktrace to point who created the event with a null value. What do you prefer?\n. I removed boolean shouldUpdate from Event.java because it wasn't used anywhere anymore.\nIt seems to be a historical leftover, for example see this file from 2013 where it was originally used:\nhttps://github.com/azkaban/azkaban/blob/0fe79f570a0bb789cbe33c20d464f3816e1b55d6/src/java/azkaban/execapp/FlowRunner.java#L522 :)\n. No. First of all, the null check is for EventData, not for Status.\nMore importantly, prepareJob() is a private method and this is the only occasion where it's used:\njava\n      Status prepareStatus = prepareJob();\n      if (prepareStatus != null) {\n        // Writes status to the db\n        writeStatus();\n        fireEvent(Event.create(this, Type.JOB_STATUS_CHANGED, EventData.create(prepareStatus)));\n        finalStatus = runJob();\n      } else {\n        finalStatus = changeStatus(Status.FAILED);\n        logError(\"Job run failed preparing the job.\");\n      }\nAs you can see, if prepareStatus is null, it isn't even passed to EventData.\n. Same private method (prepareJob()). No need for specific testing in my opinion.\n. It's used like this:\njava\n    if (Status.isStatusFinished(nodeStatus)) {\n      quickFinish = true;\n    } else if (nodeStatus == Status.DISABLED) {\n      nodeStatus = changeStatus(Status.SKIPPED, time);\n      quickFinish = true;\n    } else if (this.isKilled()) {\n      nodeStatus = changeStatus(Status.KILLED, time);\n      quickFinish = true;\n    }\nSo it's just to do with less lines inside the if-else blocks. Alternative would look like:\njava\n    if (Status.isStatusFinished(nodeStatus)) {\n      quickFinish = true;\n    } else if (nodeStatus == Status.DISABLED) {\n      nodeStatus = Status.SKIPPED;\n      changeStatus(nodeStatus, time);\n      quickFinish = true;\n    } else if (this.isKilled()) {\n      nodeStatus = Status.KILLED;\n      changeStatus(nodeStatus, time);\n      quickFinish = true;\n    }\nI find the first one easier to read.\n. Added javadocs with comment about nestedId.\n. Added javadocs & stuff to Event.create. I don't see how compiler could enforce it, but I put there @NotNull annotation, which might help some tools / IDEs detect possible violations of that constraint.\n. Yeah, indeed I only did that because Event uses that pattern. I now modified EventData to have just public constructors.\n. I feel that a checked exception would be an overkill. User should check the javadoc and not pass a null value.\n. Umm, what change would you like here?\n. Oh, but there is no checked exception. NullPointerException is a RuntimeException so doesn't require a catch block. I declared it with throws for clarity. Am I missing something?\n. Because if a job succeeded, we don't want to run that job again when preparing a new execution. Note that this function is only for the use case when you prepare a new execution based on a previous execution. Typically that only makes sense when some of the jobs were failed/cancelled/killed. If you prepare an execution based on a succeeded execution, then all jobs are initially disabled by this code.. Not by node.missing. It's handled by the else branch below. If status is anything else than disabled, skipped or succeeded, the node is enabled (those two first status aren't shown in this diff because there was no change, but you can see them if you look a the whole file).\nI'm removing node.status=\"READY\" which would change the color of cancelled jobs from peach to normal grey. I think it's better that all job states (and thus colors) are kept from the original execution when preparing a new one. The original status/color is also kept for green and blue jobs (although succeeded jobs are disabled so their color is light green, not normal green).. This function (assignInitialStatus) traverses the jobs in the flow and looks up the same job in original flow to assign an initial status. If that lookup fails, it means that a new job has been added to the flow since the original execution. In that case there is no initial status to copy from the original execution, so we set node.missing=true to mark that.\nI don't know if adding a comment in the code is the best way to improve. How about I rename this flag? For example, node.noInitialStatus or node.notPresentInOriginalExecution. What would you prefer?. The comment says \"if not set or <= 0, then there's no restriction on running time\", but when I check the condition in FlowRunnerManager, the code is this:\njava\nflowMaxRunningTimeInMins = azkabanProps.getInt(ServerProperties.AZKABAN_MAX_FLOW_RUNNING_MINS, 60 * 24 * 10);\nThis means that if the property is not set, the timeout actually defaults to 10 days?!. Can do, but let's first explore that Guice option you mentioned below.. Ok I hope so. The reason for the pattern I've chosen is because of trying to avoid merge conflicts, if these changes would only be done in private fork. I'm all in for doing it properly now that it's going towards the public repo.. Yes, sorry... I'll give it a try. First of this test should use some custom job type for tests, instead of type=java jobs that have a lot of overhead in launching.. The method checks the given list of job names on the runner to see if their status is something that means that they have been at least started, if not even finished.\nDo you mean that javadoc should be added?\nPersonally I feel that this method name should be clear enough, and having a glance at the code is probably better than my sorry attempt to explain it above :). So @chengren311, what does it mean that \"if not set .. there's no restriction on running time\"? Isn't that comment wrong then?. I think it's the best bet to keep it.\nI'm only improving the \"exit status of runJob() method\", but it's also possible that the job is killed before runJob() is called at all. And I don't think status setting is synchronized well enough at the moment, I believe if the timing of kill() overlaps with runJob() in a certain way, it could still cause the flapping of KILLED->FAILED->KILLED.\nThose possible mis-sync issues are really rare corner cases though. My change here was enough to keep the test passing without random failures. If someone wants to take it further, that could be done in another PR.. For that I added this commit:\nConvert FlowRunnerTest to use custom job type instead of java process\n- Using InteractiveTestJob instead of azkaban.executor.SleepJavaJob.\n- This makes the test run a bit faster already.\nThen I tried to continue from there, and got the test to run quite quickly by removing all the extra waiting time. But the test now reveals some rare race condition that I wasn't able to hunt down yet. The flow runner is getting stuck occasionally.. Because there's another Server (unnamed) created by the AzkabanWebServerModule.. I'm getting close to finding where the problem lies, but couldn't figure it out yet.. You mean creating a \"provider class\" instead? See how it's done in AzkabanWebServerModule.java:\nhttps://github.com/azkaban/azkaban/blob/master/azkaban-web-server/src/main/java/azkaban/webapp/AzkabanWebServerModule.java#L32. To call this on startup, and to avoid circular dependency:\njava\n    root.setAttribute(Constants.AZKABAN_SERVLET_CONTEXT_KEY, this);\nI think the proper way to refactor this would be to not make AzkabanExecutorServer depend on Server either, but I'm not sure if that can be easily done.. I prefer Mockito, but it wasn't in the dependencies yet when I started working on this :) I'll make the switch.. Huh, I finally found the reason to those random test failures and was able to fix it. The bug was in test code. Added a commit: \"Fix concurrency bug in MockExecutorLoader\".. Sorry, I need to find better IDEA settings to catch these.. +1. Yep, this is not a problem in test scope but actual running of azkaban solo server.. > Why isn't it synchronized?\nI guess it just doesn't matter too much. Job status is only changed by the designated JobRunner thread (at least in the cases that FlowRunnerTest covers). The FlowRunner thread keeps running until it sees that all jobs have reached a finished status before it ends the flow (and it will eventually see the changes in job statuses even though ExecutableNode.status is not synchronized).\nOpen questions maybe worth investigating:\n- Does the FlowRunner set status for jobs that entirely crashed (exception in job thread)?\n- Is it a problem that the flow is sometimes saved with some \"outdated\" job statuses?. > Is this an indication of a real production bug?\nNo! In production code nothing tangles with the job statuses. It's all done in a designated thread  per job.. > would a Mockto based Mock ExecutorLoader which does nothing work and with less complications?\nIt would be much better. I'll try to switch to that... > I am still having trouble understanding this problem and fix.\nI guess you checked the commit message?\nTo add a bit of background to that, this test uses MockExecutorLoader instead of JDBCExecutorLoader. The uploadExecutableFlow() method saves current flow state into DB (I'm not 100% sure if there's any another reason, but at least via the DB it becomes accessible to the Azkaban web server). The mock version doesn't use a DB but local maps to keep the flows and jobs. I guess this is so that you could verify in the test \"what would it save in DB\".\nNow on to the problem posed by this. The MockExecutorLoader created clones of the jobs, so (non-synchronized) job state updates didn't mess with the job nodes. But it didn't clone the flow object. And the original flow object has references to the original job nodes, too! When uploadExecutableFlow() was called, it also updated the job statuses on the original ExecutableNodes based on the status values know to the FlowRunner thread at that time (see the stack trace in fix commit message to see why this causes job statuses being set). It's quite clear that to \"mock the DB\" this test shouldn't modify the original flows/ExecutableNodes.. > How does FlowRunner depend on AzkabanExecutorServer?\nMaybe the only need to have AzkabanExecutorServer initialized comes from this line in FlowRunner:\nlogger.info(\"Assigned executor : \" + AzkabanExecutorServer.getApp().getExecutorHostPort());\n\nI guess this could be avoided quite easily at least.. This is enough to make the test work \u2013 otherwise there's no need to have that initialized instance of AzkabanExecutorServer available via the static getter.. I'd like to avoid that bigger change. For this I can easily see that I'm not breaking anything.. Nice one \ud83d\udc4d Actually I tried to revert this change and run some tests but couldn't get them fail any more (I didn't add volatile yet). It would take a bit of more effort to figure out if there's a real need for any of this, but making it volatile any way sounds good to me.. I can, but the same thing (cloning) is already done for job nodes, though... Because after cloning Object.equals() can't be used.. This: https://github.com/juhoautio/azkaban/blob/8272797bf60cf4009e20300e490e7838573a457c/azkaban-common/src/test/java/azkaban/executor/MockExecutorLoader.java#L129\nMaybe there could be a class level comment instead telling what the point of this class is (ie. capture status updates so that they can be checked in unit tests).\nShould I also add comments in these places where cloning is done why it's needed?. Sure.. Yes, on point.. After updating latest changes from master, the test was failing here because the node wasn't found in the map. That could be just concurrency issue, because here nodes is just a regular HashMap without thread safety.. Or then there's an actual change in behaviour that makes an update before initial upload. I wonder if that would be a problem when running against the actual DB layer... Yes, but I hope that wouldn't block getting these tests into master. This only started happening after some recent changes merged into master.. Actually good question and I think that's because some tests still run runner.run() in the main unit test thread. Part of FlowRunner design is calling interrupt() on the FlowRunner thread to wake it up for work. Should be possible to get rid of this error by always running the FlowRunner in its own thread. I'll try switching to that and then can remove all these hacks from the test (including call to Thread.interrupted();).. Hmm do I have a different line length limit?. I'll try loading intellij-java-google-style.xml again, looks like it was changed, too.. No change, this is still how the javadoc lines are being wrapped. Leaving like this then.. Auto-format doesn't treat this javadoc too well.. I fixed it manually for now ^. As FileUtils is already used on the previous \"line\", this could be replaced by a one-liner: FileUtils.forceMkdir(this.workingDir);. Ha! I remember thinking that now I can finally remove this method, but forgot about it.. Yes indeed. Will do. And also pass the exception to the logger for a stack trace.. Although it makes me wonder does it make sense to continue at all if this fails? Maybe throw an exception instead?. I think it makes the test cases easier to read. Same pattern is already used for assertStatus. I don't see it as a problem that you need to navigate to the superclass if you want to see how it's implemented. That isn't much different than navigating to the method if it was at the bottom of the concrete test class - at least if using an IDE, like one usually does.. I didn't check every usage, but can sourceDir be just a String, and wrap it with new File() here?. That could rather go to System.err.. Ok, disclaimer first of all: I totally respect the principles that you have. I think it's easier for both of us that I just make the changes that you want, even if my own preferences would be different. Below I'll also answer your questions, because maybe I can learn something here.\n\nWhat's the advantage for turning the eventCollector from a local variable into a member variable?\n\nThat you don't need that extra arg on every single line that needs to assert events.\n\nprefer composition over inheritance\n\nI recognize the problems with inheritance in general, but sometimes it's just the simplest way to go. In this case I personally don't see that it's causing any real confusion. In case of unit tests I feel more like working on a standalone script than part of bigger application architecture, and there I feel it's better to establish a kind of DSL that makes it easy to create and understand different test cases: easily seeing the essential parts of what's being tested. So I try to remove as much noise as possible.\nI checked https://github.com/azkaban/azkaban/pull/1151 and it's fine, but even there every test class has this \"much\" duplicate code:\njava\nthis.flowMap = FlowRunnerTestUtil\n    .prepareProject(this.project, dir, this.logger, this.workingDir);\nIf you want to add an optional argument or something like that, you need to update every class that calls this method. With inheritance you can just add a new field to the base class and deal with it without having to update the subclasses if they're not interested in that \"new feature\".\nWith inheritance all the other args could be protected fields in the base class, and maybe in setUp there would be:\njava\nsuper.prepareProject(dir);\n\navoid redirection\n\nI'm pretty sure eventCollector could be created in FlowRunnerTestBase#setUp and FlowRunnerTest#setUp would call super.setUp(). Maybe it could even be private then. But maybe that doesn't really improve the structure from your perspective.\n\nIf you can break up this pull request into simpler multiple ones, we can merge the first commit while we discuss the rest. This is another advantage of smaller and independent pull requests i.e. we can treat different parts differently.\n\nThat is very true, but will add quite much overhead (on my part) when the changes build upon each other. Any way I will try my best to separate different things into separate PRs.. > optimize for reading than writing\nMaybe I wasn't clear enough, but I didn't really mean that \"easy writing\" would mean \"less writing\". I was only aiming for maximal clarity.\nI actually feel that my way here was about optimizing for reading: that you don't have a lot of noise in the code, just the essential information in the context.\nFor this kind of unit test where we test multiple different scenarios and workflows on the same class, I think that less noise is more important than avoiding redirection or inheritance.\nI guess my thinking there is that you already know for example that assertEvents will check against the \"current eventCollector\" or that assertStatus will check against the \"current flow\" withouth having to every time echo the reference to event collector or flow runner.. Sorry for that. It was made public so that elsewhere one can do synchronized (testJobs) and testJobs.wait() to be notified immediately of an update. Of course better would be to have that method in InteractiveTestJob itself, so that testJobs could still be private.\n~~Static: I guess that's just been the easy way for someone to implement this, but it definitely wouldn't have to be so.~~. Sure, it's on me to do this properly.. No need to sync, it's ensured by other constrains before this is ever called. And the map itself is a ConcurrentHashMap.\nRunning in parallel in the same JVM? Then the static fields should be converted into instance fields, but otherwise should be fine.. When a job run is started, the created job type instance gets added into InteractiveTestJob's map. If a job is retried, another instance is created, but for InteractiveTestJob the key=jobname is the same.\nMy commit message says:\n\nClear previous test jobs so that .succeedJob() is called on the retried job instance.\n\nSo occasionally it happened that InteractiveTestJob.getTestJob(\"jobb:innerJobB\").succeedJob was targeted at the original failed instance. After that the retry attempt instance was added into InteractiveTestJob's map, but succeedJob was never called on it, so it was left in RUNNING state.. Correct (really well expressed question by the way \ud83d\udc4d).\n\nJobRunner threads only put to testJobs without checking it.\nTest main thread is the only thread to call getTestJob or clearTestJobs.. Now I realized why it is static: because this way we can affect \"job type\" behaviour in the tests. Basically to tell it to succeed or fail, when it's waiting for that kind of instruction (there are some test cases that wouldn't be possible otherwise). Other option would be to somehow expose the private field Job job in JobRunner, so that the test could get it, cast to InteractiveTestJob and call succeedJob or failJob. I'm not going to make any change to that.. Here's the PR for reverting public to private: https://github.com/azkaban/azkaban/pull/1163. Maybe, but I was following the pattern used in this class. Let's have it like this and refactor all those flags to volatile in a later commit?. Actually the difference with the other flags is that when they're toggled there's also this.notify(); so it's handy to cover both with the sync block... Want me to change ignoreCancel to volatile? Somehow I would be inclined to prefer the sync block because that way it can be maybe easier to understand this class as a whole? When you don't need to pay special attention to that special volatile field and how it differs from those other flags.. Well, that refactoring to change all of them is still possible. Then it would be just the waits and the notifys that need to be inside a sync block.. Nope, I didn't have it activated. I'm a bit afraid to activate save plugin because not all code is yet formatted (or is it now?), and if a previously unformatted class gets auto-formatted when I have also some manual changes in that file, I'm in trouble :) Usually I take care of formatting any way, this is plain mistake, sorry... I pushed separately here so that you can take a look:\ntruly immutable: https://github.com/juhoautio/azkaban/commit/23c9cdd43e6f74ecefcd3e246dad148633261abe\na bit of cheating but eventually immutable: https://github.com/juhoautio/azkaban/commit/bf0a7ee646270b67d0ba361bfec08dd54b41aa8d\n\nDo you think it's worth adding this much extra code to make it immutable?\nIt's pretty much closed down like it is any way... There must be some way to also do this with lesser code, using streams/collector.. Should I try that? Readability may be not so good on that?. Here's the way using streams \u2013 just 2 lines: https://github.com/juhoautio/azkaban/commit/b90c4969dacfae394604ce8e6384a9fb39cfa537\nPlease let me know which way you prefer, maybe even some 4th way? :). I just tried and at least ExecutorManager.java (changed in this commit) would be totally destroyed by Save Action Plugin :D So it must be that not all files in master have been reformatted just yet.. > Any suggestion on how to fix it?\nI don't know, that might not be so trivial..\n\nwhy the status can't be just 1, 2, 3 etc\n\nYeah :D. How about altering the column type from TINYINT to INT? That's the simplest fix I can think of.. Would it be possible to not touch AzkabanExecutorServer yet? This earlier PR has conflicting changes: https://github.com/azkaban/azkaban/pull/1113. Or, if you're going even further with injection on this class, maybe you want to check out that PR so that you don't have to figure out the same things again.. True.. If that change is done only for h2, that should be fine? How do the h2 tables get created?\nI can see in some props h2.create.table=true, but this property doesn't seem to be used anywhere.. IMHO this was a bit better:\n\"org.apache.hadoop:hadoop-annotations:$hadoopVersion\".\nIs anything similar possible with the new structure? I don't know about gradle, but maybe it supports something like this:\n\"org.apache.hadoop:hadoop-annotations:${versions.hadoop}\"\n?. Never mind, no strong opinion by me and can't really argue why I would prefer the $ way. I guess I just personally find it more readable when you can more easily see where a string starts and where it ends. Maybe someone even shared that view, because it was done with $ originally :). Yeah we can simply use Map#getOrDefault because ImmutableMap doesn't even allow null values.\n\nMap#getOrDefault:\njava\n  @Override\n  public final V getOrDefault(@Nullable Object key, @Nullable V defaultValue) {\n    V result = get(key);\n    return (result != null) ? result : defaultValue;\n  }. I was thinking \"additional\" DDL only. So the column would be altered for h2 when it's initialized for the first time. I would avoid any migrations required on existing installations on MySQL databases as long as possible.. Sorry, that was a mistake. There's something more that's needed because of KILLING status, but this is not the correct way. As you can see some assertions had been also changed in the FlowRunnerTest2, but I hadn't really thought about those. I should have been more careful.. I'll fix the comment.\nI set it to 30 s because if the flow is KILLING we can expect that it will finish ~soon. So have a shorter status polling interval.. I think it's worth preserving the information that this limitation comes from H2. Otherwise one could check MySQL and be confused as it allows larger values.. Oh, sorry. Probably I got confused with the max value on unsigned vs. signed tinyint.. > And if killed is true, who will update the final status?\nHere (KILLED is a \"final status\", it doesn't have to be set again after this):\nhttps://github.com/juhoautio/azkaban/blob/723a46ec93d6e52f178e5d2ab445d630099d0ad6/azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java#L833\nAlthough now that you mention it, I'm not sure what would happen if this row is hit:\nhttps://github.com/juhoautio/azkaban/blob/723a46ec93d6e52f178e5d2ab445d630099d0ad6/azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java#L822 \u2013 seems a bit weird, I think we should add this.changeStatus(Status.KILLED) before exiting with this special return.. > When will the job status remain \"unfinished\" when it gets here?\nIn the normal, successful case. As you can see, here the status is RUNNING:\nhttps://github.com/juhoautio/azkaban/blob/723a46ec93d6e52f178e5d2ab445d630099d0ad6/azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java#L740-L742 \u2013 the value of finalStatus is only changed before row 768 in case of an exception.. > If there is no exception when will the killed be true? And what's the expected state transition for this job?\nSorry but I'm not sure what you mean?. Yeah this should also use isKilled(), definitely.. This could also be the previous 2 seconds and offer maybe better stability, but on the other hand it will make the test run take longer than before, because below we need to add a new 1 s sleep.. Do you have a suggestion what to do? Create a new test helper class maybe?. Actually original had 2s + 0,5s. My version has 1s + 1s.\nThis sleep could be replaced with a \"poll (with a timeout) until assert succeeds\". Do you know of some standard way with junit or assertj?. Huh? That's what I did, see above :). So package name execapp is not enough? I can rename it of course if you say so.. The reason is that otherwise one might easily create a circular dependency between a module class and the classes to instantiate (that use @Named in constructor args). Do you want me to move these any way?. I really don't see why. After all, compareStates only checked for the \"expected states\" only. Maybe there was a bit more control on something like \"checking again that statuses haven't changed on execution 1 although expected them to change on execution 2\". But when I was converting these to single line asserts, I didn't encounter any case where it would've seemed important to \"check again that statuses haven't changed\". So I think it was originally just done in an over-complicated way \"by accident\" :). @HappyRay has been wanting to get rid of inheriting FlowRunnerTestBase and having some static utility methods instead.. I suspect Save Actions plugin but can't reproduce. So I will revert it.. I think this is already fixed in the pre-requisite PR that enables the RemoteFlowWatcherTest. Once that is merged I will update this PR.. I think this is already fixed in the pre-requisite PR that enables the RemoteFlowWatcherTest. Once that is merged I will update this PR.. I haven't analyzed it to see what the impact is, but there's a difference between using one of:\n- exec1-mod.flow\n- exec1.flow\nHere's the diff:\ndiff test/execution-test-data/exectest1/exec1-mod.flow test/execution-test-data/exectest1/exec1.flow\n33,35d32\n<   },{\n<     \"source\" : \"job7\",\n<     \"target\" : \"job9\"\n40,43d36\n<   },\n<   {\n<     \"source\" : \"job9\",\n<     \"target\" : \"job10\"\n129,138d121\n<     \"id\" : \"job9\",\n<     \"jobType\" : \"java\",\n<     \"layout\" : {\n<       \"level\" : 0\n<     },\n<     \"jobSource\" : \"job9.job\",\n<     \"expectedRuntime\" : 1\n<   },\n<   {\n<     \"propSource\" : \"prop2.properties\",\nI would assume it has some purpose.. I don't see why it should be removed without knowing if it really is redundant. But to me that's outside the scope of this PR. I'm just making the existing tests run.. Yes, it's too low level. Here, improvement to be done first: https://github.com/azkaban/azkaban/pull/1430.. Indeed it would be much nicer if instead of this we'd just have something like:\njava\n.when(this.apiGateway).update(any(), any(), any());. Because RemoteFlowWatcherTest is in azkaban.execapp.event. I tried, it can't see this class if it's package visible.. That would be much better. The only problem is that user will have to set the working directory to temp/ before running the server :( But hey, maybe there's a way to somehow prefix all file paths instead of writing to the root of the current working dir. I'll explore that possibility.. Sure. I think both should be supported so that it's easy to switch. What's important for me is that I can restart the server without clearing the database, but I guess that's possible with h2 as well.. Having a fixed port makes it easier to create for example scripts that are executed against the \"AJAX API\" of a locally running Azkaban?. What does it mean that \"we don't specify and use mail configs in solo server\"? I would find it handy to be able to have the mail settings for testing as well... > Is there any reason not to give different names to these methods?\nNo, that would be really handy actually. I tried to keep the diff minimal for now though.. > why not just return it directly?\nYeah, this was just moved from the existing code. But I'll change it.. Change at your own risk, but on Travis it's a whole different world. There are unexpected delays and in many places 1 second sleep hasn't been enough. Not saying this particular line would be as sensitive to random delays, but just trying to play it safe.. Kudos to @HappyRay for the suggestion.. Honestly I haven't given it any deeper thought. I'm merely changing it back to how it used to be. Now that we have the Awaitility in place, we got rid of ~1s, so having 2s instead of 1s here is affordable.. Oh sorry, I can see I made a mistake there. Changing back to 1000.. Actually now that this doesn't use any notify mechanism, can be replaced with the use of Awaitility. So blocked by https://github.com/azkaban/azkaban/pull/1442 to add Awaitility dependency.. I don't understand how to make that work. This doesn't compile:\njava\n    Awaitility.await().until(() ->\n        org.assertj.core.api.Assertions.assertThat(getFlowStatus(flow))\n            .matches(Status::isStatusFinished)\n    );\nAlso tried to take the example from the second link but it doesn't compile either:\njava\n    Awaitility.await().until( () -> org.assertj.core.api.Assertions.assertThat(1).isEqualTo(1) );\nUnless you know how to use this, I propose we go with the \"standard\" awaitility+hamcrest combo.. Yes, why not.. Maybe there could be a separate pull request after this to move TestUtils ~~and the new LambdaMatcher~~ into test/?. Added that comment but it starts on the next line so this comment remains to be shown.. Hmm, I just came across this, let me try it:\nhttps://github.com/awaitility/awaitility/wiki/Usage#version-3x-and-above-1. Yeah, this works:\njava\n    TestUtils.await().untilAsserted(() -> assertThat(getFlowStatus(flow))\n        .matches(Status::isStatusFinished, \"isStatusFinished\"));\nIn case of failure it prints:\njava\norg.awaitility.core.ConditionTimeoutException: Assertion condition defined as a \nazkaban.executor.ExecutorManagerTest \nExpecting:\n  <RUNNING>\nto match 'isStatusFinished' predicate within 10 seconds.. Do you know out of your head how that would be done? If not never mind I could look it up.. Thanks for the great review once again \ud83d\udc4d . This change is in already enabled test testDisabledRun: no reason to have sleep seconds=1 as the job is disabled and skipped immediately.. This change is in already enabled test testDisabledRun: relying on time constrains as short as 10 ms is too error prone. I think this test can serve its purpose by asserting the status (SKIPPED) without enforcing this kind of temporal check too tightly.. This change in already enabled test testPreKilledRun: no reason to have sleep seconds=1 as the job is already marked as killed and skipped immediately.. This change is in already enabled test testPreKilledRun: relying on time constrains as short as 10 ms is too error prone. I think this test can serve its purpose by asserting the status (KILLED) without enforcing this kind of temporal check too tightly.. I added screenshots in the description, please check it out. I don't think it's too bad. I think this label makes it clear to the users. Can you think of something else that would be as clear as this, without being clumsy? It's a special case after all, won't be too common to appear in practice.. Why so? I would tend to think that it's more important to know if a flow was killed ie. some human decided it should be stopped. If I would see an alert and see that the flow was killed, I would know that I don't need to check personally why the flow failed. If this is changed, then also the switch clause above should be adjusted.. azkaban.executor.Status has CANCELLED with 2 L's. Just saying... Applies :). Could these methods be simplified to be on the enum instances themselves? For example this line would become:\njava\nthis.status.isTerminal();\nMaybe that would even mean that there's no need for this method (Node#isInTerminalState).\nThis has always bothered me with the static methods of azkaban.executor.Status: isStatusRunning and isStatusFinished... This terminology can be confusing because if this is a sub-flow, parent should be the enclosing flow. So this field could be renamed to \"dependencies\", and below \"children\" -> \"dependents\"?. Just checking, I notice you have at least some unit test for sub-flows too, but I wonder if this works correctly? The thing is, you can't start a sub-flow \"alone\" even if it doesn't have any direct dependencies. It should be started once it's enclosing parent flow has been allowed to start. Maybe you are going to simplify this so that the parent flow node is added as a dependency to the starting nodes of a sub-flow?. Could be called runIfAllowed.. Maybe add to the end of that sentence: \"..for the nodes that depend on this node\". Without that it seems a bit confusing, I guess because of the word \"dependency\".. starting. Why no camel case? :). Wouldn't a default Mockito mock do exactly the same?. Not possible because there's a class called StringUtils in the same package (azkaban.utils) as Emailer.. Why would we want to include a \"job name\" that is whitespace only? I don't think that should be even possible.. Will do. I had thought that it would be either-or, but apparently flow name is available in SLA info also for job level SLAs.. Umm.. do you mean that you will refactor it to be unit test friendly (before writing a test)?. Yes. I suggested making it backward compatible but understood from @HappyRay's comment that he'd prefer a \"blunt rename\" :) ..it would be as simple as this:\njava\n// alias loadFlow is preserved for backward compatibility\n} else if (ajaxName.equals(\"fetchSchedules\") || ajaxName.equals(\"loadFlow\")) {\nShould I change to this?. Oh, this comment is \"on the wrong side\" so it won't go away :) But i have updated it, see the diff, please.. Heh, this is because I first had 10_000L, where the separation is good for readability. With 9000L it's not necessary. It's a perfectly valid syntax since Java 7, though.. This one also resolved.. Looks like this got messed up by Save Actions. Maybe @HappyRay can remember how to prevent this from happening.. This was the only change I was planning to make :). Yeah, why not use this method instead of checking with containsKey?. Paragraphs, as in <p>? There is no <p> here. I believe my style config is up-to-date.. But could you try this on your IDEA?. Yeah I don't mind, both work.. Do you? :). Ok, I can change it.. I'm not aware of any specific case at the moment, but it's really important to guarantee that JOB_FINISHED event is fired. Otherwise the flow execution remains stuck in RUNNING state without ever finishing. For example, if writing the logs fails because of any random reason (for example DB connectivity) it's not as severe as having the flow get stuck.. I was basically aiming at a less intrusive change. You'll see soon how much more complex the change becomes with AtomicInteger.. Actually this was automatic reorganization by the save actions plugin, I didn't import new classes. Can we have this change though, so that next committer doesn't have to worry about these imports flying around?. Ok, will do, sorry.. Sure I can move them as well. Ah sorry, I mean can we keep this reordering of imports (that was done automatically)? I don't intend to change the classes being imported.. This method isn't used for anything though. Should it be deleted, or keep for \"completeness\"?. In real usage UrlEncodedFormEntity provides the \"Content-Length\" header. Request becomes invalid if a duplicate header is also added manually. The unit test overrides sendAndReturn() so the \"Content-Length\" header is not seen in the unit test any more.. I created a separate PR for this https://github.com/azkaban/azkaban/pull/1660 (with the exception of not adding a new property for eviction). Can't find references to this property anywhere in the repo either. Seems like it's been undocumented (kinda expected).. wait(1ms) when sec=0. wait(0ms) waits forever so that's why this is better.. There's a 2000ms sleep in this method... Do you think that there's a substantial risk that the code would be changed to something else to cause regression?\nAny way, I suggest:\n- have this test @Ignore'd\n- add a good comment in the actual code why it's done like it is now (maybe point out that there's an ignored unit test available)\nThis way it shouldn't be possible that anyone changes the hard linking code to something else, causing regression. But it allows unit tests serve their purpose of being quick to run while making any changes.. In the plugin repo there's ReportalMailCreator.java but it implements the MailCreator interface directly.\nIt has its own MAX_ATTACHMENT_SIZE constant, it doesn't refer to the code I'm deleting on this side.. > Is it to be expected that sometimes sec will be 0?\nYes\n\nIf so, would it be better to add a comment to the code since it is not obvious?\n\nIn that case, what would you think about this instead:\njava\nif (sec > 0) {\n   this.wait(sec * 1000);\n}\n?\nI wanted to avoid such verbosity, but if the +1 way is not clear enough, then I'd rather handle it with self-documenting code like this instead of explaining in a comment.. > @juhoautio I am interested in your suggestions\nhttps://github.com/junit-team/junit4/wiki/categories. Do you know somehow that this was the culprit? Even 1 minute is a lot, so I would expect the bug to lie somewhere else.. Oh, so this test leaks DateTimeUtils offset? It would be safer to place the reset in an @After method to not cause side effects even if the test case fails.. It should be ok to use the \"simple\" DateTime.now() as long DateTimeUtils is not in some bad state?. Should be in a separate commit, maybe even PR of its own. If this change even matters... I tried this \u2013 this makes the test fail consistently:\n```java\n  @Test\n  public void managerEmitterHandlingTest() throws Exception {\n    // ADDING THESE TWO LINES:\n    final Duration FLOW_FINISHED_TIME = Duration.ofMinutes(2);\n    DateTimeUtils.setCurrentMillisOffset(-FLOW_FINISHED_TIME.toMillis());\nthis.emitter.purgeAllData();\nfinal Date from = DateTime.now().minusMinutes(1).toDate();\nthis.metric.notifyManager();\n\nthis.emitterWrapper.countDownLatch.await(10L, TimeUnit.SECONDS);\nassertEquals(0, this.emitterWrapper.countDownLatch.getCount());\n\nfinal Date to = DateTime.now().plusMinutes(1).toDate();\nfinal List<InMemoryHistoryNode> nodes = this.emitter.getMetrics(\"FakeMetric\", from, to, false);\n\nassertEquals(\"Failed to report metric\", 1, nodes.size());\nassertEquals(\"Failed to report metric\", nodes.get(0).getValue(), 4);\n\n}\n```\nIf I add this after the two added lines it works again:\njava\n    DateTimeUtils.setCurrentMillisSystem();\nMy suggestion for the eventual fix would be to only modify ExecutionFlowDaoTest.java by adding this into its existing @After method:\njava\n    DateTimeUtils.setCurrentMillisSystem();\nI found one more leaking test which is BasicTimeCheckerTest \u2013 it should also reset DateTimeUtils in an @After method.. It should be ok to use joda, because the joda millis provided shouldn't be in an inconsistent state. It could be even handy in some other test case that metrics manager itself would also use joda so that the provided system time can be controlled.\nThe main reason why I'd like to use joda in this particular test is that you can directly do .minusMinutes etc. on it and it's less verbose.. Whoa, ok! Another good finding. Then, may I suggest syntactic sugar with auto-closable:\njava\ntry (FileOutputStream os = new FileOutputStream(outputFile)) {\n    IOUtils.copy(tais, os);\n}\nThis is also safer because file gets closed even if the copy fails.. Yeah it just adds one line of code more. To me there\u2019s no difference if using joda time directly because underneath it should also be calling System#currentTimeMillis. Also it\u2019s safer to get the current time again after the emitter has been called. This shouldn\u2019t really happen, but if the metric call would take more that one minute this could fail because the to date is not after that.. I checked DateTimeUtils#setCurrentMillisSystem \u2013 calling setCurrentMillisOffset(0) is effectively the same. So why not use the simpler method that doesn't require an arg?. Should get the current time again here instead of using aboutNow from before the notifyManager() call.. Added copyright. A new sender needs to be created every time a message is created (in EmailMessage.java):\njava\n    final JavaxMailSender sender = this.creator.createSender(props);\n    final Message message = sender.createMessage();\nIf you compare this code with the previous implementation, you can see why we need to wrap the code that touches the final / static classes of javax.mail, if we want to replace them with mocks in unit tests:\njava\nfinal Session session = Session.getInstance(props, null);\nfinal Message message = new MimeMessage(session);\nThe JavaxMailSender just wraps the operations that would use javax.mail.Session.\nAs the class level javadoc on JavaxMailSender says:\n\nWraps javax.mail features, mostly because Session is a final class and can't be mocked. No need to change it, it's already done properly:\nhttps://github.com/azkaban/azkaban/blob/c75ea9beaea61ef3d92a2948b0d16834e078fb1f/azkaban-common/src/test/java/azkaban/executor/mail/DefaultMailCreatorTest.java#L84. Why?. Would it be better to refactor this to this.emailer.getAzkabanUrl() + \"/executor?triggerinstanceid=\"? getAzkabanUrl() could then be used also in Emailer itself, and wouldn't need to expose all those fields.. I mean why removing the newline at the end of the file? Github even adds a warning about it.. Missing space between getAzkabanURL() and +. How could that be? Save Actions plugin not in use?. Isn't operation = \"email message \" + message.getBody() a bit too much to be included in info-level logging (see Emailer.java)? I'd suggest for example \"flow trigger failure email\" instead (result => logger.info(\"Sent \" + \"flow trigger failure email\")). Any way if you're including the entire email body content on purpose, fine by me... How about using this strategy to check the output:\nhttps://github.com/azkaban/azkaban/blob/master/azkaban-common/src/test/java/azkaban/utils/EmailerTest.java#L97-L98\n?\n\nWhen you have the expected output saved as a .html file, you can easily render it in browser to check that it looks as expected, like this one:\nhttps://github.com/azkaban/azkaban/blob/master/azkaban-common/src/test/resources/azkaban/executor/mail/errorEmail2.html. Rename to createFailureEmailMessage? To me it was confusing to find out that this method is actually calling generateFailureEmailSubject, so it's not just a \"generic notification message\" but specifically about a failure case.. Extra line if you mind... There'a already this in DefaultMailCreatorTest:\njava\n  public static String read(final String file) throws Exception {\n    final InputStream is = DefaultMailCreatorTest.class.getResourceAsStream(file);\n    return IOUtils.toString(is, Charsets.UTF_8).trim();\n  }\nHmm, IOUtils.toString doesn't close the stream? Then it should be changed to use try-with-resources to take care of closing the InputStream:\njava\n  public static String read(final String file) throws Exception {\n    try (final InputStream is = TriggerInstanceProcessorTest.class.getResourceAsStream(file)) {\n      return IOUtils.toString(is, Charsets.UTF_8).trim();\n    }\n  }\nWhy not add a similar method in TriggerInstanceProcessorTest? Or better yet, combine them into some generic utility method that takes the parent class as an argument? (edit: did that here https://github.com/azkaban/azkaban/pull/1752)\nAny way, then the 10 lines of assertion code here would reduce to 2:\njava\n    assertThat(TriggerInstanceProcessorTest.read(\"emailTemplate/flowtriggerfailureemail.html\"))\n        .isEqualToIgnoringWhitespace(this.message.getBody());. Not in the scope of this PR, but sleep should be replaced with some dynamic wait to make unit tests run fast.\nedit: addressed here https://github.com/azkaban/azkaban/pull/1753. Could use Arrays.asList(varargs) instead of new + add? Just slightly cleaner... It would be more descriptive.. But, I wanted to keep this short to not bloat too much the test code that use this.\nIMHO \"read\" is clear enough when you look at the tests that are calling this. I'd tend to think that a more descriptive name would be worth the added verbosity if this would be more like a public interface (where you for example let your IDE's auto-complete show what methods there are to pick on this class).\nBut it's your call, obviously. Do you want it renamed?. Using the parent arg is there so that you don't need to prefix the resource name with the test class' package name. In my opinion it would be a bit messy to offer the same with Guava utils.\nIf there's a case where the resource path doesn't begin with the test class' package name, then I would directly use Guava. Personally I kinda like matching the package structure in resource paths though, so if it's up to me that wouldn't be too common... Will do if this approach is otherwise ok'd?. Ok, I have been personally a bit disappointed with the Guava Resources utils, because they pretty much always have failed to give me a one-liner solution. If the solution requires calling multiple Guava methods, I rather pick calling the same amount of JDK's own methods.\nThe reason for choosing Object arg over Class<?> was to have less verbosity in the test cases. This is also about personal taste: I like to keep unit tests readable in a way that you can easily see what the different test cases are about, not how different things about the test are implemented in practical detail. You can always look it up by jumping into methods, but I think it's valuable to have the test cases structured so that the code reveals at a glance what each test method is essentially about. This way there's no need to add comments/javadocs (that are prone to get outdated) to explain what each test is trying to check.\n\nThe parent parameter's type is weaker than I would like to see. The API above makes a different choice.\n\nYes. On general level you're absolutely right and I'm hesitating on this one a bit. I just tend to think that on the test side avoiding additional verbosity is really nice, and that it's enough if the code seems unambiguous when looking at it on the test case. It doesn't need to be that strongly typed or even easily understandable as a general-purpose API (although that's of course always a plus).\nIn this case I think there is no problem in understanding what for example this does: \njava\nTestUtils.readResource(\"firstErrorMessage.html\", this)\nSo, to have ~stronger type, it could be:\njava\nTestUtils.readResource(\"firstErrorMessage.html\", DefaultMailCreatorTest.class)\nThis is more verbose, and requires one more context-switch for the reader to check if DefaultMailCreatorTest is indeed this or some other class.\nBecause of that I would rather do this:\njava\nTestUtils.readResource(\"firstErrorMessage.html\", this.getClass())\n..but that also adds complexity by one more method call.\nWhen you just see this you pretty much automatically ignore it and move on, making it faster to read the code.\nI of course realize that my proposed utility method won't work if multiple tests are using the same input files. But why would they? If tests are pure unit tests this should be at least rare. Any way if that ever happens, adding another utility method for that purpose would be ok.\nBottom line, I haven't formed any strong opinion on this, so if you do, just let me know and I'll make those edits. I feel kinda bad for writing such a long post about such a marginal issue.. After all, I would go with my original choice. I wanted to avoid having to copy-paste + edit additional private methods like getTestString in each test class that needs to read resources like this.. Added this javadoc ^\nIs it ok?. IMHO there's no use leaving test debug output like this in place. If one needs similar thing at some point it's easy to add temporarily. Getting rid of extra output keeps the test logs cleaner. Just something for you to consider... Maybe add, to help reader:\n// circular dependency like this: nb1 <- nb2 <- nb3 <- nb1. Is this only the direct dependencies? What about sub-flows, if one creates for example:\nx.job:\ntype=flow\nflow.name=z\nz.job:\ntype=flow\nflow.name=x\nAlso, what if there's a circular dependency inside a sub-flow like a -> s, where s is a sub-flow that has a inside? + any cases with similar thing but behind some deeper nesting of sub-flows.. I couldn't tell.. Maybe because I'm not familiar enough with how the DAG is exploded. But maybe it wouldn't hurt to have explicit unit tests for sub-flows, like the two that I mentioned in my comment?. > Subflow is a higher level concept and will be implemented at a higher layer.\nOk, but will there be another checker for cyclic deps then (not enough)? Or extend this part of the code (that should work I think)? Considering the case \"what if there's a circular dependency inside a sub-flow\", I think that would require checking for acyclic dependencies on both layers together.. One full example would be:\na.job:\nproperties\ntype=noop\ns.job:\nproperties\ntype=flow\nflow.name=x\ndependencies=a\nx.job:\nproperties\ntype=noop\ndependencies=a\nTo me it seems like checking all possible cases (ie. traversing the sub-flows as well) is simpler than trying to think what are all the different types of cases where circular dependencies could be found because of sub-flows.. That's milliseconds? 100 would've still been way too low as sleep time to stabilize some flaky unit tests before as Travis builds seem to suffer from random slowdowns. Even 1 second wasn't enough sometimes. If it was up to me, I'd remove this assertion if it can't be set to something that's guaranteed to be high enough, like 10 seconds.. Maybe this operation is then more immune to random slowdowns.. I wonder if Travis can randomly have some longer GC pauses or such that cause unexpected extra delay between operations. But this is just speculation, I didn't ever measure the times on Travis and see how much they vary.. ^ moved by Save Actions plugin. Looks like not all classes have been re-formatted yet.. Yeah, why not. Added commit.. This is about cleaning up after finding executions in more or less unexpected state. I think warn would be ideal, what do you think? Any way I just used the same level that was already used for finalizing executions that are not found on their executor any more. If one is changed, I'd change both.. INNER JOIN only includes rows where the join condition executor id is found in both tables. LEFT JOIN also includes executions whose executor id is not found in executor table (any more).. Do you have some grounds for using @VisibleForTesting? Is it for example checked automatically in the build that it's respected ie. not accessed by other than test code?\nOtherwise it seems like redundant documentation that could easily get outdated and thus isn't too useful. If the wider visibility of the method is later desired also for some usage in non-test code, one might easily miss removing the @VisibleForTesting annotation and just use the method.\nIt's easy enough to find references if you want to check where the method is actually used. And if the annotation can't be trusted to be up-to-date, you'd need to check the actual refs any way.\nAs long as there isn't static code analysis that makes the build fail if @VisibleForTesting is not respected, I wouldn't use the annotation at all.\nJust my thoughts. If you want that annotation added to get this merged, I'd be happy to do it. Please let me know.. Ok, I will add @VisibleForTesting.\n\nthere's no other simpler alternative than it to let other developers know why we made such decision\n\nYou can search for actual current references and deduce that the wider visibility is for tests (if it's still the case). Additionally, git history can be used to find out the exact (original) intention. These \"built-in\" ways are not as fast as reading an annotation, but they can be trusted because they never get outdated like a manually maintained explicit annotation might do. Which one is simpler, that's a matter of taste I guess :). @kunkun-tang this seems like an accident. Yes, it would send the emails ~every 1 minute.\n// When we have an http error, for that flow, we'll check every 10 secs, 6\n// times (1 mins) before we send an email about unresponsive executor.\n// private final int numErrorsBeforeUnresponsiveEmail = 6;\nThe idea is to send e-mail again if the problem remains, but this is clearly too often.\nHow about sending these emails once per hour, ie. change to numErrorsBeforeUnresponsiveEmail = 360?\nedit: I made this change, see separate commit.. I'd rather not change this. I believe prefixing with test doesn't add value. I've seen for example @HappyRay also omit such prefix in some new tests he's created.. No. As you can see it's never null. Otherwise the existing code would've indeed failed on the next row.. This is needed to be able to send a single e-mail for any executions that have the same mail creator & recipients. Flows that have different mail creators can not be combined into a single message.\nOther option would be to send separate e-mail for every execution, but I think it's definitely nicer to group them.. Ok, this part is complex enough that I haven't tried to figure out if the null check is actually needed or not.\nHowever the existing placement of the null check didn't matter, because in case of pair=null an NPE would be thrown already before the check, so I removed it. My change doesn't change existing behaviour, it only simplifies code.\nBtw this happens inside a while loop that is protected by try-catch, so if NPE is thrown, it shouldn't happen on the next loop cycle.\nThat code could be analyzed & improved, but it's not in the scope of this PR. If NPE is ever thrown here, that would be a bug clearly, but fixing it properly might not be as simple as adding a null check. I don't feel comfortable to blindly introduce a new null check at this point, because I'm not sure if that would change the behaviour in some wrong way, but on the other hand it would hide the actual bug so that it can't be noticed as easily as it would when the NPE gets logged as an error.\n\nedit: I added a TODO comment instead. I added this TODO comment. I think it's better to point out the possibility of a bug intentionally like this instead of having unintentional code with a meaningless null check.. Could include a comment, something like this:\nThere seems to be an actual race condition bug in the runtime code. See: issue #1921: Flaky test FlowRunnerTestYaml & issue #1311: Potential race condition between flowRunner thread and jetty killing thread. True that. I thought this comment kind of covers both.. but not as clearly as it could. I'd like to change the comment to: \"GIVE UP DISPATCHING - exit\". Ok?. \"Executors\" is correct currently, because each available executor is only tried once at most \u2013 if all have been tried, give up. Also, this loop is about dispatching a single execution.. @chengren311 comment better now?. @chengren311 I changed while loop to for.. Minor thing but maybe it'd be clearer to use a different name for the different matchers here, and thus allowing both variables to be final.. For quicker unit tests. Users shouldn\u2019t have any reason to customize it AFAIK. But it\u2019s not totally absurd to think that in some setups it could even be useful to be able to change this.. Sorry, what so you mean?. This matches the existing behaviour. It's just a global counter of total dispatch failures seen. It covers both non-retriable & retriable failures.\nEventually it could be split to different counters, maybe:\n- markDispatchAttemptFail (any failed dispatch attempt)\n- markDispatchRetriableFail (all attempts used)\n- markDispatchNonRetriableFail (stopped dispatching because got a non-retriable error response)\nBut is anyone even looking at the \"common metrics\"? I know we don't.. The thing is I'm not so sure what would be the best way, but I'll think about it. The main point for having this TODO here is to remind that checking for active executors only is not enough.\nWhat I'm trying to say there is that one option would be call getFlowToExecutorMap() if executor can't be reached. Because the result of that can be used to check if the executor doesn't exist any more.\nOn the other hand reloading active executors won't be enough for this check, because active executors don't include inactive executors. This class needs to know if the executor has been removed entirely.\nOutside of this class there's a need for updating active executors: for the dispatching side to take new executors into use without manually asking to refresh via API or restarting azkaban-web.\nI'm wondering what would be the cleanest way to achieve both things. The ways mentioned above are nice in a way that they're pretty much additive in nature. Other approaches might involve more refactoring, but result in a cleaner outcome. For example, maybe it would make sense to load both inactive and active executors at the same time, and then filter them to only use the active ones in dispatching side.. > Is it necessary to wrap runningExecutions inside a new class?\nNot really, but this makes injection clearer. I could bind an instance of ConcurrentHashMap as a named singleton, but that would require using the @Named annotation also in the classes that require it in their @Inject constructor. So I would prefer having a dedicated class. Please let me know.. Yes. But as I said, this matches the existing behaviour, I'm not changing it. For example my proposal of splitting to different counters could be done later if desired.. I guess there are two branches:\n\nDelay minimization\nThis is the one that makes more sense probably\nUser is scheduling a lot of executions all the time and wants to minimize the dispatching delay due to any temporary dispatch failures (caused by executor replacement, for example).\nFor this to be used effectively in executor replacement, assuming that azkaban-web has been modified to automatically refresh executors without having to restart it (discussion is going on about that with @jamiesjc).\nCall throttling\nUser wants to use a longer sleep to avoid a high call rate on executors if dispatching keeps failing.\nThis seems more artificial because the dispatch call alone won't probably be too expensive \u2013 it would make more sense to increase the max number of dispatch attempts than to increase the sleep time between attempts.\n\nBut as I wrote it\u2019s not totally absurd, I mean that most likely users won't ever need to touch these. But I would like to have them as properties like this so that they can be customized for unit tests. Other option would be to add setters with package visibility, but that's not as clean IMHO.. > Currently, getFlowToExecutorMap() will only check the runningExecutions cache to get the result.\nI'm sorry, I somehow confused it with ExecutorManager#loadRunningExecutions(), which is only called when the ExecutorManager is created.\n\nHow about checking the executor info from DB directly if that executor cannot be reached? Then you wouldn't need to reload active executors.\n\nYeah, why not. I was just thinking of some way to possibly combine shared needs. At least I would implement that check so that I would call the existing executorLoader.fetchActiveExecutors() and check if the result includes the executor or not, instead of adding new DB-level code to check for the existence of a specific executor id.\n\nThen you wouldn't need to reload active executors.\nThis would be an improvement but not necessarily the fix for the current issue.\n\nYes, exactly. I also came to the conclusion that these are separate things, and it may not even make sense to combine them.\n\nAlso in our case, updating new executors is only required after new executor deployment, so I don't see much efficiency in updating frequently in the updater thread.\n\nThat is true, but then it would require user to call the refresh executors API, which complicates the operating side. My point was that listing executors periodically is not expensive at all because it's such a small table, and doing that often enough would make adding and removing executors more convenient. It doesn't have to be done by the executions updater thread, but IMHO it doesn't seem like a bad place for it either.. Nope, it makes the tests slower if there's some sleeping involved. Tests should never sleep.. This is to eventually (also) test the improvement where executor is checked again from the DB & it's not found any more. But this test should be also kept for the case where executor exists in the DB but is still not responding.. > why do we need test parallel scenario?\nSorry, not needed. The possibility of a concurrency issue was just an idea as I was trying to find out why we have some hash differences.. Moved this away from the constructor to fix AzkabanSingleServer (azkaban-solo). Because in AzkabanSingleServer Guice provisioning first creates instances of ExecutorManager etc., then starts the executor servlet, and finally web servlet. Executors can't be loaded (in ExecutorManager of azkaban-web) before the executor servlet has been started.. This field is read in the unit test to know how many times to run in order to simulate a failure email. Other option would be to hardcode 6 in the test, but I prefer this.. Yes, somehow didn't occur to me.. Not sure what you mean? The line below verifies that the mocked apiGateway's updateExecutions method was called with the expected args. There's no reason to assert that a mock has returned what it was mocked to return.. > Do we need to add (\"error\", \"Flow does not exist\") in the executionMap first before mocking the update response for this scenario?\nNo, the order doesn't matter because it's the same map instance. I mean, the mock won't be called before the entry has been added to the map.\n\nAlso, better to use ConnectorParams.RESPONSE_ERROR instead of error.\n\nThat's true.. Executor port is still needed on the executor side. It happens to be the same property name, unfortunately.. I wanted to make sure that users don't accidentally start azkaban with a new version thinking that their configured executor.host would be used. This will make it clear for the users that local mode won't work any more and they have to update their conf to start using the only supported mode (where the executor hostnames are automatically resolved on executor side & read from the db table on azkaban-web).\nEventually this code can be removed once confident enough that all active users have already updated to some version new enough to have this change, so that they must've acknowledgingly switched to multi-executor mode.. Yeah, Guice creates the instance if an instance is required for injection. It will only create one, because this class is annotated with @Singleton.. Yes it is. @jamiesjc thanks for noticing. I've added a commit to clean up all usages of executor port related properties and constants.. > Could you add a TODO to retire this required config?\n@HappyRay, done.. BAD_REQUEST is actually a more demanding instruction than \"should stop dispatching\". In this case client \"must stop dispatching\". This is used to prevent dispatching the same execution on multiple executors.\nNow that I think of it, maybe there should be a dedicated category for that case, though. For example: ResponseErrorType.ALREADY_RUNNING. That way the client could handle it gracefully: for example if it previously tried to dispatch but got a network timeout, then it could deem it as a successful dispatch if executor says that the execution had been dispatched on the previous attempt.. Done (added commit). > The logging message here is not accurate, please update it to reflect \"executor is removed\".\nI changed that as requested.\nAlthough I don't see how the message Executor id of this execution doesn't exist is not accurate. To me it seems to say the same thing + a bit more context. To be specific, this part of code doesn't necessarily know that executor has been removed. All it knows is that the executor id that the execution is assigned to doesn't exist. From this code's point of view it could also be that such executor id never existed :) Although with current Azkaban code that shouldn't ever happen of course \u2013 it's not possible that an execution is assigned an executor id that never existed.. Oh, sorry, I already forgot that there are two similar cases. I think they are about the same thing, could you check please? I believe the warn message could be unified for these. Should I extract a method? What would you want the message to be?. > For better debugging purpose, I would suggest keeping two different logging messages.\nGreat thinking \ud83d\udc4d I'll just flip them around then to match with your original request. Sorry for my mistake with the wrong line. I would still say that \"doesn't exist\" is more exact than \"is removed\" (which could be a stretch) but both work for me.. (also the fault was mine when creating executorRemoved / isExecutorRemoved which could also be renamed)\n\nThe previous one checks whether the executor is null in the running executions cache\n\nThat can only happen immediately after startup btw, because running executions are not updated from the DB afterwards.. Correct. @jamiesjc It's clearly a bug then. Sorry for that.\nTo summarize this, currently loadRunningExecutions uses this query:\nhttps://github.com/azkaban/azkaban/blob/a1b097857b17449d7b0070f0bcff2fc49ee53e68/azkaban-common/src/main/java/azkaban/executor/FetchActiveFlowDao.java#L61-L71\nAnd loadQueuedFlows:\nhttps://github.com/azkaban/azkaban/blob/a1b097857b17449d7b0070f0bcff2fc49ee53e68/azkaban-common/src/main/java/azkaban/executor/ExecutionFlowDao.java#L340-L344\nSo, the fix would be to modify FETCH_ACTIVE_EXECUTABLE_FLOW to exclude the executions that match the FETCH_QUEUED_EXECUTABLE_FLOW query. In practice, adding this condition:\nsql\n-- exclude queued flows that haven't been assigned yet\nAND NOT (ex.executor_id IS NULL AND ex.status = Status.PREPARING.getNumVal()). @jamiesjc were you expecting me to make a PR for this? If yes, let me know and I'll do it.. This assert reproduces the bug. It fails if run without the fix in FetchActiveFlowDao.. Will do. I suppose that even though fetchActiveFlows visits the DB, calling it on every project upload is not too much. I would optimize it to only fetch the execution ids though. Loading the DAG data is quite heavy.. > What about \"submit_user\"?\nSure, added it for completeness. @jamiesjc, do you have some practical experience on the performance impact on azkaban-web after switching to get unfinished executions from DB instead of caching? I mean situation when there are at least some, say 100 concurrent executions and those are for considerable big flows (with many nodes & properties) so that the flow data is big. We haven't tried running azkaban yet with your general cache->DB change.\nI have a vague memory that it can take long to load even a couple of flows, when the data is included.. I think I saw that in azkaban-web startup when it's initializing the cache of unfinished flows from DB, it could be something like 10 seconds. For example, if the flow updater thread is now fetching the list in a loop and it takes that long, it may become unmanageable with any higher number of parallel executions. Just suspicions so far, I hope you have some knowledge based on manual testing?\nNot sure how big difference it makes to exclude the flow data like here, but maybe this should be used as much as possible and only fetch the full flow data when it's required?. Actually it seems like there will be problems if executions table contains many rows. I tested by running some queries manually against the real DB, which you can see in this ticket that I created: https://github.com/azkaban/azkaban/issues/2091 Maybe we can continue discussion there.. How? I guess these are the only properties that azkaban parses expecting this pattern.. ",
    "reallocf": "This looks very cool - I like the caution symbol as a UI element (I'm not sure if caution correlates well to cleanup, but it certainly looks cool! \ud83d\ude04).\nAnother question on top of Ray's, how does this handle all the various states an Azkaban flow can be in? For example, if a kill is called on the flow, does it still execute the clean-up steps?\nAlso, if a flow fails before a subflow is started, do the clean-up steps in the subflow still get executed?\nI'd also be interested in the design. Good work @juhoautio!. @devangorder are you still seeing this issue?\nWe're only observing it when passing login credentials through the URI like this:\ncurl -X POST http://localhost:8081/?action=login&username=azkaban&password=azkaban\nWhich leads to this line being logged:\n2017/06/12 14:39:34.747 -0700 INFO [LoginAbstractAzkabanServlet] [Azkaban] 0  -  \"POST / action=login&username=azkaban&password=azkaban HTTP/1.1\" not-browser\nIt's common to log all information in the URI in this fashion. We expect users will pass sensitive information in the request body instead of in the URI like this:\ncurl -X POST -d \"action=login&username=azkaban&password=azkaban\" http://localhost:8081\nWhich leads to this line being logged:\n2017/06/12 14:41:38.628 -0700 INFO [LoginAbstractAzkabanServlet] [Azkaban] 0  -  \"POST / - HTTP/1.1\" not-browser\nAre we missing something? If so, could you provide the steps for reproducing the logging of the request body?\nAlso, do you think it would be valuable for us to explicitly tell users to pass sensitive information in the request body instead of in the URI in our documentation?\nThank you again for bringing this to our attention!. #1504 is the fix for this. It's in master and 3.36.0 but this release isn't stable so we'll be making a 3.36.1 soon. In a few weeks we should know for sure whether or not 3.36.1 is stable (i.e. has been in production here at LinkedIn for some time) and then I'd recommend upgrading to it :+1: thank you!. This is really cool :+1: . @suvodeep-pyne have any ideas on how to do this? I'm worried about adding complexity by having to pass around whether or not logs were uploaded successfully - particularly for nested flows.\n@HappyRay what do you think? When we talked offline it seemed like this risk was worth it given how rarely database uploads fail, do you still think that's true?. After speaking offline with @suvodeep-pyne, we agreed it'd be better to set a configurable TTL for these files instead of deleting them. While we don't use these files often in our debugging (unless the problem is with uploading logs files to the DB) our users might use the /execution/ directory to do their own testing then view the files via the HDFS viewer. While I don't think we have numbers regarding how often this is done, I can imagine users doing this.\nI'll start working on the configurable TTL today, likely using the cleaner thread. @chengren311 I might bug you about how the thread works as I look more into it :smile:. @HappyRay how does that sound to you?. No longer going about this problem this way, so I'm closing this PR and opening another one with changes discussed offline.. Had offline conversation with @HappyRay about this. I will be moving the change into an outside function and adding additional comments. I'll also be putting a little more thought into how to test this - possibly via the integration testing suite.. @HappyRay it turns out the shutdownInternal method in AzkabanExecutorServer which invokes the orderly shutdown process for FlowRunnerManager ends with System.exit(0) which calls the shutdown hook - so the orderly process calls the disorderly process. So the deletion will happen under all shutdown conditions.. @HappyRay yes! I'll add some more details. I'm currently working with @jamiesjc and @chengren311 to determine if we actually need to revert this or not.\n@juhoautio we think your change might have revealed an already existing bug. We're hoping to cut a new release (3.32.0) and are hoping to do so from master. If we were to revert your change, it would only be temporary to fix the related Azkaban bug before merging #1172 back in.\nWill give more details shortly!. What's the benefit of having the message disappear after 30 seconds? Wouldn't it be better to keep it live until an admin takes it down?. Is there any way we can pass this warning in an expected way so we don't have to suppress it? I feel like we should only suppress warnings that we really have to suppress.\nLink to related errorprone bug pattern: http://errorprone.info/bugpattern/MissingFail\nLook at the \"To reduce false positives\" section in the link above and they detail some ways to get around this test in a safe way without suppression.\nDoes that make sense?. :pray:. Hey @prokod!\nA couple thoughts. First, if you're coming from 3.0.0, I'd suggest upgrading to 3.30.1 which is our most recent stable release. 3.32.2 should also be good - we've been running it here in production for almost a month now and it will likely be marked as a stable build soon. We're only now releasing 3.34.0 so there might be additional bugs other than the one that might be here.\nNow for your problems with execute-as-user, could you please share an example of a flow that is failing with your setup? Between 3.32.2 and 3.34.0 we updated the execute-as-user.c file and it's possible that something regressed.\nThanks and sorry for the delay! :smiley:. @prokod that's interesting. I'm not seeing the same behavior when I try to run your job on our testing cluster here.\nHow is your execute-as-user executable permissioned?. Yes, that's the proper permissioning. Hmm, I'm not totally sure what's happening in your environment @prokod. I'm not familiar with the nuances of CentOS 6 - we're running our production instances on Redhat and I'm not sure if there's any substantive differences that could be the culprit there.\nI'm working now on a fix on top of 3.34.0 that should make execute-as-user work as expected going forward. For now, I'd suggest running with execute.as.user=false unless you can figure out a workaround in your particular environment. My fix should be out in 3.35.0 or 3.36.0, so sometime later this month. Hopefully you can fully upgrade and turn execute-as-user on then.\nSorry that it's not working as expected for you out of the box!. The fix I'm working on has to do with changing the permissions of the JOB_OUTPUT_PROP_FILE and JOB_PROP_FILE so they can be written to via the new execute-as-user executable. Because these files have been generated by the Azkaban process, they need to be updated to allow read/write access for the user.\nLuckily, I can leverage some of the code I wrote for updating the permissions of the /executions/ directory so it shouldn't be too much new work. Expect a PR in the next few days (as long as oncall doesn't take too much time).. We do not need to hold off on current deployment - because we haven't upgraded the execute-as-user executable on any cluster except Yugioh, there won't be a problem.. I'm also working on an integration test to ensure we don't regress in the ability to properly access this file in the future.\nQuestion: @HappyRay do you know of any ways to unit test things like this? I haven't been able to think of any great way to test thing like this that are so reliant on the filesystem.. Do we know for certain that this class isn't consumed by any plugin?. I'd rather the standard be that we fix warnings instead of suppressing them :wink:\nWe can mention it if we want to. But it should definitely say that any suppressed warnings must be justified somewhere - in the commit message at a minimum and ideally in a comment within the actual code.. In the documentation we say there's:\n1. Solo server mode\n2. Two server mode\n3. Multiple executor mode\nIs your suggestion that we get rid of Two server mode?. Awesome! I always thought it was a strange distinction.\nMaybe we should rename the modes? Have one be \"solo server\" and the other be \"remote executor(s)\" or something of that nature?. @HappyRay yes, that would be a good distinction.\n@wyukawa so your setup involves a single machine that is running two separate processes (one for web server, one for exec server) so that it's not just a solo-server, is that right?. You should be able to run a single machine with separate webserver/executor processes. You could also have multiple executors in a single machine I expect (have multiple exec server processes that are active on a single host).\nI know we run a couple of installations that are on a single host (with separate webserver/executor processes) so I don't think that will be deprecated. I believe your current setup will remain viable.. Looks interesting! Is this something that would be useful for us to run locally too?. Is there an issue or a project or something here on Github that illustrates the long term motivation for this change? What's the purpose of az-core compared to azkaban-common?. Cool - thank you!. @prokod we're actively working on data availability triggering and it's scheduled to be released Q4! :smiley:. UI design is still being figured out as far as I know, but we're trying to keep it minimal for now.\nThe feature will launch with HadoopDSL integration :+1:. @HappyRay updated my comment to provide a bit more information and to say that I'll be continuing to explore these features.. Looks like I need another ship it @HappyRay. Is that due to the new review requirement?\nThanks!. Hey @prokod, that does make sense but I'm surprised that you have to do it..\nThe \"azkaban\" user should still have read/write access on the current working directory because it should still be owned by the \"azkaban\" group. Are you not seeing that? How is the \"azkaban\" process permissioning the exec directories/files inside of them?. Yes, I do see a difference.\nIn our executions directory, the generated files are created with the following permissions:\n-rw-rw-r--. 4 user azkaban 5.0K Oct 5 16:28 FILE-NAME_props_2186224269708212984_tmp\nSo the azkaban group also has write permissions. This is important both for writing the log files and also for cleanup afterwards.\nI'm not exactly sure how that's configured because I don't think we do anything special with the Azkaban process to do that.. I imagine it's a system setting. Maybe @li-afaris can speak to it?. Thanks for raising the issue @Ralnoc! I believe this is something we intend to do in the future as we get closer to HA, but that isn't on our roadmap for this quarter. @ameyamk might be able to speak to it more.\nThat being said, if you wanted to contribute you should feel welcome to and we'd be happy to help you out!. Hey @liweigong - I'd suggest jumping up to 3.32.1 which is our latest pre-release (will soon be upgraded to a proper release). 3.34.1 is what we're using in production here at LinkedIn, though we're rolling out 3.36.0 and it's looking like it's free of bugs.\nBecause 3.12.0 was released in December 2016, I don't know if anybody is knowledgable about the bugs in that particular version. Upgrading should fix the problem (we're not seeing it in production here) and, if not, the current team will be better equipped to help troubleshoot.\nThanks!. @kunkun-tang any ideas? Maybe this is something particular to 3.30.1? I'm not sure how this script is tested.\n@dortegau if you want to try a newer build,3.34.1 or 3.36.0 are both viable.. Great @dortegau! Let me know if you need any more help :+1:. LGTM except for the thing @kunkun-tang pointed out. Once that's fixed I'll give a ship it :+1:.. Hey @vladislav-sidorovich,\nLooking at your stackoverflow example, I'm not sure how well the nested ${${}} will be handled. Could you set the db configuration in the system.properties file itself?\nFor example:\n```\nsystem.properties\nmyFlow/\n   foo.job\nsystem.properties in dev environment\ndb=localhost:2181\nsystem.properties in prod environment\ndb=aws:port\nfoo.job\nsome command --db ${db}\n```\nThat's how we handle stuff here - alternating the configs themselves for the dev/staging/prod environments so individual flow/job doesn't have to worry about it.\nDoes that make sense?\nThanks!\nCharlie\n. Well if your solution is working for you then feel free to go with that!\nAnother option would be to label each environment in a common.properties file in the plugins/jobtypes/ directory in your executor or solo-server. Properties defined there will be picked up by all jobtypes on that Azkaban instance (like global variables affecting the scope of every job) and you could differ the label for each environment.\nAfter doing that you could define in code using a hadoopJava job or something else that executes arbitrary code.\nSmall example:\n```\nIn built instance\nazkaban-exec-server/ (or azkaban-solo-server)\n   bin/\n   conf/\n   lib/\n   executions/\n   plugins/\n      jobtypes/\n         commonprivate.properties\n         common.properties:\n            env.LOCATION=prod\nIn your zip file\nsystem.properties\nmyFlow/\n   flow.job:\n      type=command (hadoopJava jobtype is preferable, but command works for a small demo)\n      command=python test.py\n   test.py:\n      from os import environ\n      if environ[\"LOCATION\"] == prod:\n         print(\"This is prod!\")\n```\nIn this way, users only have to think about defining things in code which may or may not be easier depending on the complexity of your files and who will end up using your Azkaban installation.\nThere are probably another 4 or 5 ways to get your desired outcome. I'd use whatever works best for you and your team :smile:. Can we create a test that tries to link a file with an impossibly long name? The ARG_MAX on the systems is 2621440 - if we generate a string with a name longer than that it can help handle regressions.. or maybe there's better for our integration testing suite?. After talking with @HappyRay offline, I'm going about this in a different way. Instead of making sure that StdOutErrRedirect can detect and handle these kinds of loops (which adds both an expensive system call in getStackTrace and complexity in logging overall) I'm cleaning up everything that writes to stdout/stderr and removing the StdOutErrRedirect overall.\nFirst (this PR) I'll fix all stdout/stderr messages so they write to a logger. Because this is already the best practice on the team there were only a few number that slipped through a few years ago.\nSecond (next PR) I'll work on how to make sure that error messages are sent to the logger. Once this is done, everything that I've seen being redirected through StdOutErrRedirect will be proceeding to the logger on its own.\nFinally (third PR) I'll remove StdOutErrRedirect because it will no longer be needed.\nThis should be a simpler design and should avoid this bug.. Other than that it looks good! Check out comments then I'll give ship-it.. Hey @wyukawa,\nThis PR looks good to me - if you could provide a unit test as Ray suggested then I'd be happy to give a ship-it and merge it.\nThanks!!. Hey @monanik39 - the scheduler logic exists within the web server, so if the web server is down then scheduled flows will no longer execute. However, if the web server is down for a few minutes for maintenance then I believe it will execute the \"skipped\" flows due to our leveraging the Quartz scheduler. @kunkun-tang is that feature rolled out yet or is it still in development?. This is something we've played with internally - we hacked together a bunch of our open source components into a single k8s cluster. You can check it out here: https://github.com/jfim/data-platform-demo\nBut yes, I think this would be awesome to prioritize (@ameyamk \ud83d\ude42) and I think is something we want to do in the medium-long term.. Hey @aycaacar can you explain a little more about this change? What's the purpose? How have you tested it?. For the hiveserver2 stuff, I asked @beeramsunitha to take a look because she knows Hive much better than me.. Other than that make sure to check out our contribution guide: https://github.com/azkaban/azkaban/blob/master/CONTRIBUTING.md\nI see some minor formatting issues but configuring your IDE to the specifications above should help clean it up. Let me know if anything in the guide is unclear - your feedback would be helpful. Thanks!. @beeramsunitha do you have the throughput to review this? Thanks!. @HappyRay no, I've just been instructing @aycaacar in how to set up their code styling. I think they have it right now :+1:. @HappyRay have any other thoughts on this PR? If not, I think we can merge.. Hey @sonncui sorry for the documentation mismatch! The execute-as-user.c file has been moved here: ./az-exec-util/src/main/c/execute-as-user.c\nI'll leave this issue open as a note that we need to update the documentation. Thanks for bringing this to our attention!. Hey @jatinderjawanda - are you using the DSL? https://github.com/linkedin/linkedin-gradle-plugin-for-apache-hadoop/\nIf not, you can create the following .job files to get this functionality:\nFOO.job\nYour-Content-Here\nBAR1.job\ndependencies=FOO\nYour-Content-Here\nBAR2.job\ndependencies=FOO\nYour-Content-Here\nEND.job\ndependencies=BAR1,BAR2\ntype=noop\nThe final END.job is required because Azkaban expects all jobs to converge to a single end point. This job is generated automatically if you use the DSL, which is the recommended way to create Azkaban flows.\nDoes that answer your question?. Change looks pretty good to me. Is there any way to write unit tests for these kinds of things?. Hey @ggalves I've tested your changes locally. Could you possibly split this into two PRs? The Download permission fix seems really important and I've tested it locally and it looks good, so we'd like to merge that.\nThe second fix involving the NullPointerException I think requires more thought. I opened a new issue to track: #1740 . Once we have resolution on how to handle these improperly defined users, maybe you can submit a second PR?\nThanks!. I like both of those ideas. @HappyRay would the error when loading the xml file result in a failed web server startup? I think that's reasonable given there's some erroring state present.. Hey @hszhsz - we already have pagination + search (well, an \"Advanced Filter\" that can be used as a search) in the History page. Do you think that's sufficient? Are you picturing it also being on the Executing/Scheduling pages?. Yes, this is an issue. What I tend to do when this happens is run ps aux | grep azkaban to find the running server, then kill manually. Does this not work for you?. Sounds like something worth fixing to me as long as it doesn't introduce a ton of new complexity. Thanks for bringing it up!. Hey @wu8685,\nCan you explain this a little bit more? What's the difference between providing hooks and simply adding a command job at the end of the flow to execute the command?. Hey @gao634209276 - isn't this the designed behavior of the more command?\nFrom the more man page:\nMore is a filter for paging through text one screenful at a time.\nWhen Azkaban simply launches a subshell that executes whatever commands are specified. I imagine it's being blocked because there's no user to actually page through my_file.\nCan't you accomplish a similar objective with cat instead?\ncount1=$(cat my_file | wc -l)\nBecause cat doesn't require user input (which subshells launched by Azkaban aren't able to receive) it prints everything to the screen immediately (or in this case, to the pipe which then counts all the lines).\nDoes that address your question?. @gao634209276 sorry for the late response. The difference between crontab and azkaban is that azkaban is a higher level application that is designed for integrating easily with Hadoop environments. It also offers a web ui and more advanced features than cron. But, if you're just running simple jobs on a schedule, cron might be sufficient.\nHmm, if you're killing a blocked Azkaban shell job and it's still running the remaining commands that sounds like a bug to me. Can you give more details?\n@vasuonweb if you're creating a .job file like above, you should include test.sh at the root of your zip. On the azkaban executor, it hardlinks the unzipped files into an execution directory and then sets the current working directory to the execution directory, so have test.sh present at the root of the zip should allow it to be picked up during your execution.. Hey @whyuds - two thoughts:\n1. Only users with ADMIN permission can specify useExecutor, so make sure that you have this permission set for yourself when testing. You can remove this restriction if you want ALL users to have this power, but this of course makes it more difficult for you as a system admin to ensure proper resource utilization.\n2. We normally set useExecutor at the flow level - so via that API or via the Flow UI Flow Parameters page. I'm not sure if it will work at the job level - if you have admin permissions and it's still failing then setting it at the flow level is the right way to go.\n@jamiesjc - how does this relate to Flow 2.0? Have we tested setting this at the Yaml flow level?. @whyuds what's your use case? The Azkaban executors aren't designed to run distributed jobs directly - each job/workflow is supposed to be launched within a single executor and stay there. But we heavily use it to launch Hadoop jobs and have a lot of plugins to make it easy for users to launch map-reduce, pig, hive, spark, etc. jobs which of course are distributed.\nSo, effectively, Azkaban is used to launch distributed jobs, but isn't designed to have jobs that span multiple executors itself.. You're right - it shouldn't be two lines. I had added a change here and then removed it, but forgot to remove the newline. Thanks!. I just followed the best practices I already saw in the file. Do you think it would be better to refactor the template using constant variables / string.format? What's the best practice now?. createFirstErrorMessage and createErrorEmail are (from what I can tell) two distinct things. I've never actually seen the first one (createFirstErrorMessage) so for all I know that copy is never seen by users. But we can definitely change it to one/the other and then template it if you think that'd be a good idea!. I did - metrics is static now because JUnit requires setUp to be static in order for it to be annotated @ BeforeClass which causes metrics and testUtil to be static. So \"this.\" is no longer recommended by intelliJ. Does that make sense?. This is being refactored to rely on MetricsManager dependency which is handled in constructor. The MetricsManager class is used explicitly on line 736 to take advantage of the startReporting method. Do you think it'd be better to depend on both MetricsManager and MetricsRegistry?\nAlso, MetricsRegistry is binded to a singleton locally, I'm resolving some consequences of that switch then I'll push a new version - thanks for the feedback! :+1:. That's a good point. I'll have it directly depend on both MetricsManager and MetricsRegistry then. Thanks again!. This was a recommendation @kunkun-tang made because he said the usage was similar to QueryRunner. Nice catch! Thank you!. Definitely, I appreciate the feedback. This one kind of got away from me as I was dealing with unraveling the dependencies. I also didn't understand Guice very well going into it, so it was a lot of learning on the fly \ud83d\ude05 . This is a consequence of the change that @kunkun-tang suggested in AzkabanCommonModule.. Yes, the problem has already been fixed. I just included this because there was no unit test confirming that WebMetrics is a singleton, which allowed me to build and run and then find the bug while using my local version. Adding bind(WebMetrics.class).in(Scopes.SINGLETON); to AzkabanWebServerModule fixed the problem, but it would probably be good to have a unit test in case anybody removes it for whatever reason. I didn't think it'd be wise to include it in this (already very large) PR, so I added the comment. What do you think?. This was included in order to handle the partial guicing of the ProcessJob class where I leverage the SERVICE_PROVIDER instead of injecting it the right way.\nThe problem with doing it the right was is then I have to refactor every class that extends the ProcessJob and then refactor every test for the classes that extend the ProcessJob and then suddenly I'm refactoring another 10+ files. I'd rather break this up into separate PR's which is why I'm leveraging this bandaid for now. Do you think it'd be better to implement Guice throughout this dependency chain now?. I can do that. Do you think it's a good idea to build that infrastructure when this code will (hopefully) be retired quickly?. Should we just use to bind then in order to standardize on that?. Awesome, thank you for doing that! I'll make the update \ud83d\udc4d . Will do!. :+1:. Would it be a good idea to standardize on the @Singleton annotation? Not in this PR, but in the future.. Looks like it isn't anymore! It was necessary when things were not guiced the right way, but it seems to be working now without the change. Thanks!!. I didn't know there was a difference \ud83d\ude04 haha. I'll switch it to boolean because that looks like it'll do the job. Thanks!. A && !(A && B && C)\n--> A && (!A || !B || !C) de Morgan's law\n--> (A && !A) || (A && !B) || (A && !C) distributive law\n--> (A && !B) || (A && !C) because (A && !A) can never happen\n--> A && (!B || !C) distributive law in reverse\nAnd A && (!B || !C) != !(A && B && C) because 1, 0, 0 leads to the first being true and the second being false.\nSo we should need both. Does that make sense? (Also, yay boolean algebra! :smile:). :+1: . How does Guice know to inject ScheduleManager here if it isn't a parameter of TriggerBasedScheduleLoader?. Will we want to inject AzkabanWebServer in the future? Do you expect any complications when if we do so?. Some commenting here and for the function below would be useful - especially because most of us aren't guice wizards \u26a1\ufe0f. Should we check requireNonNull for all injected classes when we guice? Is this best practice for dependency injection?. That makes sense - do you think we should make that the standard for when we inject moving forward?. Creating a public static final String DEFAULT_BLACK_LISTED_USERS = \"root,azkaban\" up top might make it easier to read what's going on here at a quick glance and make adding to the default list a bit simpler.. Not needed :smile: . \ud83d\udc46 good idea with the Set. Is there any value in setting the process to null like this?. :point_up_2: . Breaking this into two helper methods (one for connecting to SMTP server and one for sending the message) might make this a bit more readable.. IntHander or IntHandler?. Would it be better to import org.slf4j.Logger as well?. Yes! This still works with embedded flows :+1:. I think you're correct - thank you for the correction!. It will also work on MacOS. It will definitely not work on Windows.. Good idea :+1:. @chengren311 so you're saying I should call this in the AzkabanExecutorServer's shutdownInternal/shutdownNow methods instead of in the FlowRunnerManager?\nI figure it's better to do it here because the sequencing (all running jobs end, then delete execution directory) is more clear. What do you think?. I don't see the shutdownNow method calling the shutdown method anywhere. But maybe it'd be better if we didn't delete the execution directory on shutdownNow because logs that were only partially created would be lost. What do you think?. Can you just say:\nString concurrentOption = getParam(req, \"concurrentOption\", \"skip\");\nOr something like that so we don't need the if statement at all?. Good thinking. Do you think it's worth creating a NATIVE_LIB_FOLDER string in Constants then? Or should we just keep the strings that are local to ProcessJob and HadoopSecurityManager_H_2_0?. With this change, the default has changed. Before, users could always write to their directory. Now - due to the change to execute-as-user.c - they won't be able to until we allow them to.\nThe clean up change is a different problem that should be taken care of in 3.32.1 because of #1292 :+1:. This does use ExecuteAsUser - is there a way you think I can use it better? :smile:\nAnd yes! I moved it to azkaban-common. Glad to know that was the correct approach - thanks!. This actually is supposed to be a char being passed. The initgroups() function below takes in a char and a gid_t where the char is the username of the user. When \"uid\" is passed from the main function, it actually is a char - it's kind of hard to tell in github.. http://man7.org/linux/man-pages/man3/initgroups.3.html - takes in a char so %s should work I think. uid is declared/initialized as a char right above here on line 97 :+1:. Oh! You're right, this should be fprintf(LOGFILE, \"Error setting supplementary groups for user %s: %s\\n\", username, strerror(errno)); instead of user. Nice catch!. Agreed - this confuses me to. Will do.. It would be good to document this - do you think it'd be best to do so here? Or in a comment?. Yes I agree, this should throw an error - I'll make another PR on Monday doing so.. Can we have a value like None or False to imply all artifacts are stored?\nSetting \"azkaban.storage.artifact.max.retention=0\" makes me think no artifacts are being retained.\nOr maybe introduce a boolean true/false config corresponding to whether or not any artifacts are cleaned?. getWorkingDirectory is legacy code (last updated in 2012) and I'm concerned there might be plugins or something that use it. So I'd rather not update it in this PR. Does that make sense?. \ud83d\udc46 . If you use props.getString on line 347 then I don't think you need this if statement because if Constants.ConfigurationKeys.CUSTOM_CREDENTIAL_NAME isn't defined then an UndefinedPropertyException would be thrown.. Relatively large: https://stackoverflow.com/questions/2347828/how-expensive-is-thread-getstacktrace\nI can't really think of a better way to go about this though. Do you have any ideas? I mean, we could run this check randomly with like a 5% chance. But that seems like it's starting to get ridiculous.\nHonestly I don't know if there's a good way to recover from these sort of events short of restarting Azkaban. My dream would be able to hard fail Azkaban safely but it holds too much state in memory for that to be an option.\nWhat do you think? Do you have any other ideas?. Do you think we should change them for all of the loggers in this PR? Do you know of any risks involved with changes like this?. ^ cool - will fix :+1:. It looks like this is multiple tests wrapped inside a single test method, is that right? If so, it'll be easier to parallelize if broken out into multiple smaller tests. That would also make it easier for us to identify quickly what is broken and why if a test fails.. Same as last comment.. I don't understand, why are we creating a temp dir then deleting it?. Should this comment still be here?. This comment too. I think all other azkaban package names start with azkaban.. Should we change it for this package? Is there an easy way to make this also azkaban.flowtrigger without losing the benefits of this PR? It would also make it easier for a trigger dependency developer to identify through which imports they depend on azkaban.. What's the difference between the checks? Why would I use 2 instead of 1? Maybe a name can be made from that?. Should this default to false?\nSo something like:\nif (props.getBoolean(OBTAIN_HIVESERVER2_TOKEN, false)) {\n    ...\n}. I don't think this line is necessary for modern drivers. See documentation here: https://docs.oracle.com/javase/6/docs/api/java/sql/DriverManager.html\n@kunkun-tang what do you think?. Maybe I lead you down the wrong path, did you follow the guide to set up your local editor?\nGenerally we keep the final for all variables where it can be applied, as well as the this. prefaces.\nWe also tend not to preface the logger statements/other static variables with the class name, so the logger.info statements need not be updated nor should the ucl usage.. How will this method handle cases like:\nlib/gobblin-*\n?. Is there a reason we're using Object here instead of a closer shared parent class? Does DependencyCheck fail to work now? I might not understand.\nAlso, even if we're using Object we can probably still use the same more descriptive name of dependencyCheck for the variable.. Do you think this should be pulled out into its own file? I'm not sure - what's your intuition?. Can you leave a comment mentioning this? I could see somebody (either a dev or a user) getting confused in the future because there's certain expectations around the usage of * characters.. What are the consequences of this? Are users then able to access the resource or do they not have permission to access any resources?. Should we throw a 403 Forbidden error instead?\nHmm.. I'm wondering if there's any way to bubble up this error sooner. Like, when the user tries to login, it fails because of an improper role. I'd like to see this fail more quickly instead of when a user tries to access a resource. Maybe we can make a similar request at login time to confirm user role and, if it fails, stop login and throw an error?\nHave any thoughts along those lines? What do you think @HappyRay @kunkun-tang ?. Makes sense to me! Can you call it this.globalProperties though so it's in line with our style guide? After that I will ship it + merge \ud83d\udc4d \nThanks for the contribution!. Actually, one last thing. Can you have this comment say Using only globals props. instead of Using empty props.?\nThat will make this logger message line up with the new logic. Thanks! :). Do we need to introduce the new Resources dependency? Can we accomplish the same thing with the the Java File library?. Objects.nonNull isn't a typical way that we check if a variable is null.\nMaybe we can just use globalPropsPath != null?. Can we include braces here?\nSo something like:\nif (alertUser) {\n    sendAlertNotification(flow);\n}. Can you either resolve this warning or leave a comment with why it deserves to be suppressed? (I believe this is still the best practice, right?). Sounds good to me!. What's the consequence of this node having default scope instead of it being specified as private? Is it used elsewhere in the package? Is that intended? Because you mention it NOT being public it might be useful to have a comment saying why it IS default scope.. small typo - I think name is supposed to be dag, right?. Same question regarding the consequences of this scoping.. Sounds good to me \ud83d\udc4d thanks for clarifying. Sounds good!. Does this resource need to be included in this PR as well?. Having a comment describing what you mean by Invalid would be useful here. Because Invalid makes me think it includes an improper Azkaban flow.\nMaybe Insecure is a better word? I'm not sure... How thorough is the normalize() method?\nLooking at the documentation, it looks like it handles . and .., but does it handle ~? How does it handle symlinks? (i.e. what if there's a symlink in the zip file that points to root, then the file leverages that symlink?). ",
    "firemonk9": "Any update on when this issue will be merged into main branch ?. Any update as when this feature will be merger to main branch ?. ",
    "confessin": "Hello, I am getting same error, Do we have any way to fix this apart from changing the code?\n. +1, Its kind of frustrating, trying to find binaries for Azkaban 3.\nAll my efforts for snooping have failed for azkaban 3 solo server. \n. ",
    "logiclord": "@confessin No even in latest version of Azkaban you will automatically set \"mail.\" + protocol + \".auth\" to be true (https://github.com/azkaban/azkaban/blob/master/azkaban-common/src/main/java/azkaban/utils/EmailMessage.java#L190)\n. I looked deeper in this issue. Issue with job within embedded flows is that ExecutorServlet in azkaban-webserver expect nested path for job names. for example:-\nFollowing will not work\nhttps://localhost:8081/executor?project=test-command&execid=76459&job=test&attempt=0\nFollowing will work fine\nhttps://localhost:8081/executor?project=test-command&execid=76459&job= embeddedFlow: test&attempt=0\nThis nested path is required due to 2 reasons:-\n- We store job name as nested path in database\n- We need to reach to job node (at https://github.com/azkaban/azkaban/blob/master/azkaban-common/src/main/java/azkaban/executor/ExecutableFlowBase.java#L134) which require us to know the subflow path in which a job exists.\nI will submit a pull request for the fix\n. Updated the review\n. changelist updated\n. LGTM\n. Supported curl requests:-\n/stats?action=changeMetricInterval&metricName=NUmRunningJobMetric&interval=60000\n/stats?action=changeCleaningInterval&interval=604800000\n/stats?action=changeEmitterPoints&numInstances=50\n/stats?action=enableMetrics\n/stats?action=disableMetrics\n. These changes are live on experimental 's' cluster\n. Thanks Anthony. I have incorporated feedback comments. I will update Azkaban documentation once we merge this change.\n. Thanks for feedback, Anthony. I have updated the pull request and replied to comments.\n. Thanks @hluu. I have updated pull request by incorporating feedback comments.\n. Just added the must have params to enable Azkaban metrics in sample azkaban.properties.\n. incorporated feedback comments\n. Incorporated feedback comments.\n. Hi Anthony,\nI have added one more minor change. Can you please review that as well ?\nThanks,\nGaurav\n. minor indentation.. LGTM\n. Cool plugin :+1:\nLGTM.\n. LGTM\n. LGTM @hluu  any comments ?\n. @HappyRay Can you please have a look ? changes looks good to me.\n. LGTM\n. Can you please fix the Travis build ?\n. Looks Good. Suggesting some minor changes.\n. LGTM\n. LGTM\n. One suggestion. It will be good to test on a cluster, interface changes might break some dependency of azkaban-plugins on azkaban.\n. LGTM\n. multi-executors changes are part of mutlipleexecutors_canary branch :\nhttps://github.com/azkaban/azkaban/tree/multipleexecutors_canary. We will\nmerge it to master once we have are done with testing and documentation.\nOn Sat, Sep 26, 2015 at 6:16 PM, Hien Luu notifications@github.com wrote:\n\nThe multiple executor enhancement will be in 3.0 release.\nOn Sep 26, 2015 4:37 PM, \"Vikram Kone\" notifications@github.com wrote:\n\n@hluu https://github.com/hluu looks like 2.7 release is up on github.\nAwesome..! Does this support multiple executors now? I dont see any\nupdates\nto the documentation referencing how to setup multiple exec servers.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/438#issuecomment-143505364.\n\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/438#issuecomment-143511102.\n\n\nThanks,\nGaurav\n. yes\n. LGTM\n. This is a big change. We should add this in http://azkaban.github.io/azkaban/docs/\n. Minor comment. Otherwise LGTM\n. Issue #446\n. Thanks John. I have added the comment.\n. Incorporated feedback comments and updated the review.\n. incorporated feedback\n. LGTM\n. LGTM\n. Updated exception messages\n. Incorporated feedback.\n. LTGM\n. LGTM\n. LGTM\n. LGTM\n. Incorporated feedback and added queue processing as decided in design discussion today. Also, added guard statements to be backward compatible.\n. Incorporated feedback comments.\n. Incorporated new feedback comments\n. LGTM\n. Incorporated feedback\n. LGTM\n. LGTM\n. Fixed in #496\n. LGTM\n. Incorporated feedback. Please have a re-look.\n. Seems like a transient issue, It should pass as It seems to work on my box. I have re-triggered the build.\n. Please check out test failures in travis build\nazkaban.execapp.StatisticsServletTest > testFillMemory FAILED\n    java.lang.AssertionError at StatisticsServletTest.java:39\nazkaban.execapp.StatisticsServletTest > testPopulateStatistics FAILED\n    java.lang.AssertionError at StatisticsServletTest.java:54\n. LGTM\n. LGTM\n. LGTM\n. LGTM\n. LGTM\n. @juhoautio My change was also on the similar lines but it catered to control execution order of jobs. You approach is much more general.\n@HappyRay @georgezhlw @evlstyle can you please help @juhoautio ?\n. @juhoautio actually there is a limit to number of jobs that can run in parallel (https://github.com/azkaban/azkaban/blob/master/azkaban-execserver/src/main/java/azkaban/execapp/FlowRunnerManager.java#L105). This change was made due to an internal feature request where users want to control order or execution to reduce flow run time. \n. LGTM\n. LGTM\n. Incorporated feedback.\n. Hi vikramkone, can you please confirm your version of azkaban-plugins ?\n. Apologies for delayed response.  \nThis is a know issue we encountered while releasing Azkaban 3.0. Somehow it's fix fell through the cracks. We observe this issue  if we have no Azkaban plugins and hence common.properties from plugin directory is NULL.\nThanks @jeroenvlek  for the fix. \n. 5 sec seems like a really short interval. Can you please increase to say 2 mins ?\n. LGTM\n. can you please run tests in debug mode and share stacktrace ?\n. Please update db schema as per http://azkaban.github.io/azkaban/docs/latest/#upgrade-27\n. Good catch. Can you please file another bug for documentation update ?\n. LGTM\n. Can you please provide a small summary about your change ? some screenshots will be great.\n. Thanks \n. Thanks LGTM\n. LGTM\n. @kddeisz You are right. alert.type is part of flow properties section, which can only be specified overriide properties interface. We do have a backlog item to specify flow properties as part of zip project like .job properties file. Feel free to contribute on this\n. I tried searching older ticket but couldn't find it. Feel free to propose something for this and refer this issue.\n. Discarded\n. LGTM\n. Have you tried user.to.proxy ?\n. LGTM\n. yes, https://github.com/azkaban/azkaban-plugins/pull/201 takes care of this \n. LGTM\n. LGTM\n. @HappyRay can you please take a look ?\n. @JayMiao \n@devangorder  you are right setting it within UI or setting it using http request are the only two ways. Only job properties can be set in job files and 'useExecutor' is a flow property.\n. curl 'https://localhost:8443/executor?projectId=1&project=acceptance-test&ajax=executeFlow&flow=all-acceptance-tests&disabled=%5B%5D&failureEmailsOverride=false&successEmailsOverride=false&failureAction=finishCurrent&failureEmails=azktest%40linkedin.com&successEmails=azktest%40linkedin.com&notifyFailureFirst=false&notifyFailureLast=false&flowOverride%5BuseExecutor%5D=1&concurrentOption=skip' -H 'Cookie: bcookie=\"v=blah-blah-blah-blah-blah-blah-blah\"\n. from executors table in mysql/h2\n. You are not passing useExecutor correctly. It should be passed as flow params like:-\ncurl 'https://localhost:8443/executor?projectId=1&project=acceptance-test&ajax=executeFlow&flow=all-acceptance-tests&disabled=%5B%5D&failureEmailsOverride=false&successEmailsOverride=false&failureAction=finishCurrent&failureEmails=azktest%40linkedin.com&successEmails=azktest%40linkedin.com&notifyFailureFirst=false&notifyFailureLast=false&flowOverride%5BuseExecutor%5D=1&concurrentOption=skip' -H 'Cookie: bcookie=\"v=blah-blah-blah-blah-blah-blah-blah\"\n. LGTM\n. Hi folks.\nThanks for the feedback. I have incorporated all the feedbacks. I have kept a separate reading section of hadoopShell for easy understanding. Otherwise, it will be hard for many users to understand that HadoopShell is a wrapper on top of HadoopJava.\nCan you please have a look ?\n. LGTM\n. +1\nIt will be helpful in tracking bits version in production. This will be a good change to have. \n. No, at present you cannot have one flow depend on any other flow. \nThe closes thing supported for this is to make multiple executions of a flow wait e.g. We have E1 already running for a Flow F1 in project P then another execution say E2 can be made to until E1 finishes. \nOn a side note, it is very straight forward to add a feature and make any execution depend on any other execution by generalizing (asking user/config for some execution dependency information) and making changes at https://github.com/azkaban/azkaban/blob/master/azkaban-common/src/main/java/azkaban/executor/ExecutorManager.java#L999 @HappyRay thoughts ?\n. LGTM\n. May be on a tangential line but can we give user an option to switch zip file version for a project ? may be something like undo ?\n. We can remove elements in  generalSelectMetricHistory, because generalSelectMetricHistory has a duplicated data. I have shortlisted data using time frame https://github.com/azkaban/azkaban/pull/376/files#diff-4c45b04406f9bb2e09d70380bff7f401R121\n. Actually we have only one point of entry for storing data i.e. using reportMetric. So lists can never grow to large size as we are cleaning up after every addition ?\n. Yes, this we have removed this emitter due to some issue with the way gmetric display graphs. I have kept it if we ever decide to move to ganglia.\n. Good catch. Its a copy paste error.\n. Good catch. Synchronized metric while building command\n. I was using it before but forgot to clean up later. Thanks for pointing out.\n. Changed\n. Changed\n. Fixed\n. Fixed\n. Good suggestion. I have made changes to use this convention\n. Fixed\n. Added new message.\n. Added comment.\n. Fixed\n. Fixed.\n. Added comments\n. Added comments describing the relationships\n. Fixed\n. Fixed\n. Fixed. I have synchronized only when we take snapshot as we don't need to synchronize after cloning the object.\n. Fixed\n. My bad I intended to take from before notification. I have moved from declaration before notifying manager. \nBut yes, I also observed that we are not sure to complete the call in 2000 milliseconds. Actually, We need to use something like ConcJUnit, in order to completely solve race condition. But I found that we are using wait statements in all other tests so using a separate library for only one case would be an overkill ?\n. NumRunningFlowMetric already have java doc\n. java doc added\n. java doc added\n. I used synchronized to avoid simultaneous read and write on metric history for a particular metric.  getDrawMetric is called from a an executor service so it should not be blocking other azkaban functions ?\n. Name changed\n. Yes\n. fixed\n. modified as per other comment for line 155 \n. modified\n. fixed\n. fixed\n. Thanks for pointing out. Fixed.\n. Added MetricException\n. Thanks for pointing out. I used NPE to consider cases where metricManager is not specified. Throwable is a better fit here as it will isolate Azkaban main thread from failures in metrics code.\nI have made the changes.\n. @erwa  suggested and It seemed a better convention so I used it. I have again changed back.\n. changed\n. Expanded in java doc. Basically a Timertask cannot be modified to change event window, so we need a new Timer in order to support http request to change reporting window.\n. Modified the property name\n. added a constraint at timer level\n. Can you keep please indent < li > tag ? \n. Why not have mailPort as int since your are already parsing while calling t.connect ?\n. there is a getInteger method, if you have int mailPoint\n. Will be good to specify that PORT is exec server port not browser used port ?\n. It's not necessary that we will have an alphabet in the end for xmx. Things like -Xmx83886080 is also valid in bytes, which will make your code return 0 KB size.\n. Do we have properties resolved at this point ? Someone may have a \nXMS={FROM_FLOW} which will not be a valid value, if unresolved ?\n. It will be a good I idea to have a config to enable disable this feature from azkaban.properties or even curl requests\n. It will be a good idea to abstract SystemMemoryInfo implementation from the caller. Just wondering.. should we make it an interface SystemMemoryInterface and have SystemMemoryInfo implement it so later on we can change implementation without affecting client code or even use reflection to instantiate class reading conf ? \n. Actually these sort of changes used to break reportal deployment, which involved replacing jars e.g. replacing azkaban-common jar but now azkaban-executor jar. But now things should be fixed as we have gradle build process for reportal clusters.\n. How about using project Id ?\nProject names can be re-assigned if original owner deletes existing project with a given name and another user create another project with same name, which will give special privileges to new project. \n. replaceFirst ?\n. Will be good to have some examples ?\n. Should we have an upper limit on body size ? \n. logger.debug ?\n. Just had a look tests seems to be good examples,\n. SUFFIX ?\n. Actually we don't need this method. It serves same function as props.getMapByPrefix(\"\") i.e. prefix with empty string.\n. Should we make it generic to accept props as argument so we can leverage in case we want to extend to say sysProps ?\n. Yes, I named it InActive as there was already a method getProject to fetch active projects from Cache and to minimize code refractoring.\nI have merged two methods and added another method to test if a project is Active.\n. I expect to throw exception in that scenario. For purge API, I have handled that case while invoking this method.\n. fixed\n. fixed\n. changed\n. removed\n. yes\n. makes sense. incorporated the feedback\n. updated\n. updated\n. we want this class to be in singleton. ?\n. internal cache ?\n. nit: A bit verbose, commenting.. just mentioning a singleton class should be fine ?\n. I thought API class will not have functionality specific method as we discussed. I think we should have this in executor manager only and executor manage should use rest API exposed from this class ?\n. May be I am missing something, but should ExecutableFlow be available to comparator (ranker) ?\nThis will enable us to have more signals to chose an Executor A over Executor B in context of Executable flow C ? \nJust to make it more extensible and avoiding interfaces changes later on.\n. use apache java formatting template to auto-format all files.\n. makes sense, I can't remember why I though there will be a use case to have just id and not host:port.\n. good catch. forgot to clean.\n. Yes, I am looking for \"for this specific Flow tell me whether executor A or executor B suits better ?\" part. I think it makes sense to add this in interface (even if we are not use it), to give flexibility to extend and use other features derived out of ExecutableFlow and Executor combination. \nFor your other concern about end user manipulating properties to prefer some executor. If user is able to directly manipulate then there is a flaw in new admin level implementation which derived new features, on the other hand some properties will obviously lead to prefer some executors and that can be desirable in certain situation e.g. we may prefer to run spark jobs on current high memory instance but will also work with other instance due to other issues like memory, In an multi-cluster executors we may allow users to show affinity to certain cluster and help them avoid distcp, etc These types of cases cannot be accommodated by filters and need to have ExecutableFlow or a derived feature vector.\nYes, template solves that thing in this scenario.\n. good idea. Added validation\n. we are mostly dealing with active executor and any object created will be for an active executor. But I think we can remove the default value to give more flexibility.\n. No, we need to change active status of the Executor. We will need to keep inactive executor for some time when an admin will mark an executor invalid but we will need to maintain status of the flows previously scheduled on inactivated executor.\n. added\n. yes\n. yes\n. Good idea. Feedback incorporated.\n. updated. I wanted to avoid failures due to insertion in executor audit table.\n. This method is to fetch events recorded in executor audit table, inserted by postExecutorEvents;\n. this method is not part of review, it already exist \n. These statuses are inserted in database, so we want to easily identify a status while debugging some issues . Error is assign a higher code to anticipate any new status which may come in between the missing range.\n. updated\n. I think we can keep things light and skip the validation here.\n. updated\n. it returns empty list, added in doc\n. updated\n. changed.\n. These tests are sort of integration tests and not turned on by default as their need db.\n. We are doing clearDB() after all the test but we want each test to clean up all the insertions it make so there is no dependencies between the tests which can give incorrect test results.\n. yes, added a note in doc\n. Its better to use browser engine instead of browser name https://developer.mozilla.org/en-US/docs/Browser_detection_using_the_user_agent \nGecko   Gecko/xyz\nWebKit  AppleWebKit/xyz\netc\n. We want to avoid interface changes in ExecutorManager, due to which we need to keep this class.\n. good idea. name changed to queuedFlowList\n. simplified use case to assume that we will not have local as well as multi-executor simultaneously. Though we need to make a db entry due to the way we are now defining a flow running i.e. it has an assigned executor. So in local mode, we need to have an executor to assign to. This db requirement is for the use case where we use the ability to bounce webserver without affecting running flows.\n. added duration. Legacy code :(\n. @hluu \nas discussed offline, now no local and multiexecutor mode is mutually exclusive. Switching between from local<->multiexecutor needs a change in flag in azkaban.properties hence we need to bounce webserver for that. \n@evlstyle \nYup that is why this method is public. I plan to have a curl request for the time being. In case of multi executor mode we will be able to refresh executors without restarting.\n. Added log statement for the mode. Executor lists is available in /jmx page. I have changed behaviour of /jmx page from showing only executors which are running a flow to all active executors (executorManager is managing). \n. Legacy code. I have made all executors as primary for the time being.\n. Again legacy code. Can't change as it will change existing interface for executor manager.\n. Yup I was talking about this method when I mentioned about confusing methods. This is an existing public method which now returns ids of running as well as non-dispatched flows.\n. executor fetched may not be an active executor. In order to update an admin should use a curl request (to be exposed)\n. nope it will returns true when isFlowRunningHelper returns true i.e. when project-flow ids are present in either queuedFlowMap or runningFlows.\n. fixed\n. no that that condition is guarded with queuedFlowMap.containsKey(execId)\n. To be backward compatible. Older interface returns a sorted version.\n. changed\n. legacy code. Changed to executors.\n. on all except execution_flows(executor_id). Added for executor_id\n. updated\n. Again legacy code :(. Fixed\n. I like this idea. Updated unless someone has some concerns.\n. Even I though of this and created these methods. It will be part of next iteration of code change.\n. Very good point. Fixed to return a readonly version.\n. Even I want a separate class, Ideally I will prefer to recycle executionReference but We need to be backward compatible and Pair is used through out ExecutorManager. So we cannot make this change without an interface change.\n. As discussed offline, queue is now a BoundedQueue so we remove from queue using take() method each time we process a flow.\n. good idea. added\n. Using BoundedQueue has obviated this change.\n. I think will be better named as lastStatsUpdatedTime ?\n. is it /tmp disk space ?\n. I thought we removed priority as per yesterday's conversation ? \n. percentage of flow capacity used for comparator as per yesterdays conversation ?\n. Try Jackson ObjectMapper/ObjectWriter based utils from https://github.com/azkaban/azkaban/blob/master/azkaban-common/src/main/java/azkaban/utils/JSONUtils.java#L49 ?\n. Should weights be double ?\n. /DispatcherStatistics ? /statistics is a bit confusing with /stats\n. we may need to upgrade junit version, I tried it some time back but there were some issues\n. List = ArrayList ?\n. Should we move code which really determine  totalMemory and FreeMemory as it can be used in other places ? In this method we can can that new util method and populate memory executor stats.\n.  new Date().getTime() =>  System.currentTimeMillis() ?\n. We should guard this populateStatistics method to make sure that we don't make 2 attempts in parallel e.g. suppose we receive an http request to fetch statistics and that created 5 threads and wait for 5 sec. Within that 5 sec we receive another http call (very likely as from webserver side we have a refresh interval of 1 sec), for this second call we don't want to create 5 new threads to fetch stats ?\n. changed\n. From user's perspective it will be covered in documentation and from code perspective examples and details are defined in ExecutableFlowPriorityComparator and ExecutableFlowPriorityComparatorTest\n. Nice suggestion. Refactored to defined a separate data structure class and corresponding tests.\n. nope.\n.  non-dispatched  = Webserver queued flow. Initially i was planning to use non-dispatched nomenclature. \n. yes. Changed\n. Changed in some tests. Its not recommended to be used when multiple lines can through same expected exception but we want to validate exception from a specific line of code.\n. ExecutorManager manager has no visibility into the permission level for the submit user. So we need to fix up set/unset properties in ExecutorServlet. Moreover we don't want all admin submitted flow to have high priority\n. same reply as above.\n. same reply as above.\n. changed\n. We are synchronizing on exflow so if a flow is taken out then cancel flow call will be blocked until we finish processing the flow.\n. incorporated\n. moved embedded comments to java doc\n. added\n. added\n. just out of convention since AZKABAN_QUEUEPROCESSING_ENABLED =\n    \"azkaban.queueprocessing.enabled\" property is exposed via azkaban.properties.\n. Legacy code. This is a public method, changing this method will change interface of ExecutorManager.\n. it is outside the catch but inside the synchronized block. Catch completes at line 941\n. updated\n. Great catch\n. fixed\n. I was planning to have it logged in servlet which will take care of curl request to enable/disable it. changed to log in this method.\n. to synchronize for other existing operations like cancel.\n. Changed. Actually flow has not failed at this point so I didn't intend to log this step under normal running mode to avoid over logging. \n. added log to track stage transition for a flow to handleNoExecutorSelectedCase and handleDispatchExceptionCase.\n. added log to track stage transition for a flow to handleNoExecutorSelectedCase and handleDispatchExceptionCase.\n. added\n. as commented BlockingQueue is the actual queue for undispatched flows and map to easily access queued flows (to support existing operations)\n. These changes are already part of existing create* scripts\n. added a ExecutorManagerException for invalid arguments.\n. expanded documentation\n. As discussed offline,  I have added comment for this if statement. All the variables in this if statements are loop variables and it will be better to have it here instead of having a method with 4 arguments.\n. As discussed offline, we are going ahead with cloning activeExecutor set as we will have just one copy of executors at a time.\n. added\n. This is to keep things clean for multiple calls\n. This in line with your request to instantiate selector every time with choose an executor, probably to avoid synchronization issues with changing weights. For the time being, No we can have a class level instance.\n. Good catch, I think this change got dropped as it was conflicting for #478. Modified toString method.\n. We should never have a activeExecutors.size() =  0 as we fail AzkabanWebServer, if there is no activeExecutors and we do not update activeExecutors if new executor set is empty.\n. added\n. ExecutorManager will pass null comparatorMap to ExecutorSelector which is handled by selector.\n. @johnyu0520  maximum number of flows that can execute before we will have to refresh executorInfo\n@hluu Do mean add in_ms in azkaban.activeexecutor.refresh.milisecinterval ?\n. We can have executorManagerException and SQLException.\n. yes\n. updated\n. We return null as we want to default to normal behaviour of asking selector to pick an executor. Though I have added more log to identify different exception scenarios.\n. updated\n. updated\n. changed to _IN_NUM_FLOW\n. As discussed, moved executor service as member of executor manager and used futures to handle different scenarios\n. Exposed last successful refresh time in jmx and used futures to handle different scenarios\n. indenting is off for c file\n. cmd can be NULL if system failed to allocate memory\n. writing space will write int \"32\" in each byte for the memory allocated to char pointer. You can use cmd memset(cmd, '\\0', total_len+2) or memset(cmd, 0, total_len+2)\n. license ?\n. We already have a standard format to specify azkaban version i.e. digit.digit.digit. Moreover, we will control future versions which automatically takes care of padding.\n. camel case ?\n. I have already covered this fix using dispatch method in https://github.com/azkaban/azkaban/pull/500/files\n. already covered in #500 \n. You have a test failure because of this\n. changed\n. changed\n. As discussed, it will have about 4 lines with 25-30 chars each. We will retaining it as info for the time being .\n. Fixed as discussed.\n. no we may fail to call executor and our priority queue logic depends on update time. Moreover, executor server will update updatetime once it is successfully dispatched.\n. it can't be negative.\n. changed\n. makes sense. Though unassign will be a no-op but It will be cleaner. Updated the change.\n. nit: \nI think it will be better to have strict grep to avoid unintentional string match as currently Cached will also get you SwapCached. We can use start of line and \":\" to strict\ne.g. grep -E \\\"^MemTotal:|^MemFree:|^Buffers:|^Cached:|^SwapCached:\\\n. formatting is off\n. formatting\n. Let's add a TODO so we remember to create a utils method and remove redundancy later on. This method method perform almost same thing and in similar manner as https://github.com/azkaban/azkaban/blob/master/azkaban-common/src/main/java/azkaban/utils/SystemMemoryInfo.java#L105\n. nit: formatting\n. i think you missed this ?\n. removed pre. It's a good learning, we have been using pre for a while.\n. why don't we reuse flows from https://github.com/azkaban/azkaban/tree/master/azkaban-test/src/test/resources/executions ?\n. should we throw specific exceptions ?\n. setExecuteAsUserBinaryPath ?\n. We should also document building and setup for this c file\n. I am not sure if you will consider it as hack. Can you have a look at https://github.com/azkaban/azkaban/blob/multipleexecutors_canary/azkaban-common/src/test/java/azkaban/utils/TestUtils.java approach ?\n. If a flow wakes up from sleep then it is still in queue and we will not increment the count.\n. why not open openjdk8 ?\n. nit indentation\n. nit indentation. I think you can reformat this file.\n. This will fail command job if we do not have plugins directory. We should check whether pluginLoadProps = Null after this else and set pluginLoadProps = new Props(); in that scenario.\n. shall we make \"kill\" a constant like KILL_COMMAND\n. Should we append stdout as well ? \nWhile fixing Java 1.8 test cases, I observed that some failures where logged in stdout and not stderr. \n. 1 You don't need default value of \"false\" as you have already verified that EXECUTE_AS_USER_OVERRIDE is present in jobProps. Actually you can do away with if statement and have\nisExecuteAsUser = jobProps.getBoolean(EXECUTE_AS_USER_OVERRIDE, isExecuteAsUser);\n2 nit parenthesis ?\n. If nativeLibFolder don't exist, should we validate and throw an informed error ?\n. what if root is really a user in azkaban-users.xml and hence a valid azkaban user as well as unix user, who wants to execute a job ?\n. may be rename to enableExecuteAsUser\n. Good catch. Yes, that's a typo.\nFixed.\n. Multiple will have separate property. As discussed offline,  I have added an example and made specification more clearer by specifying that it is an integer weight and what can be the value for Memory {ComparatorName}. Thanks.\n. As discussed offline, we are keeping all 3 modes for the time being as some user might want to use 2 server mode. keeping for now.\n. Good catch. Added statements to specify both the points.\nThanks.\n. You need to merge update sql script as well. https://github.com/azkaban/azkaban/tree/master/azkaban-sql/src/sql/update* ?\n. Good catch. Fixed as discussed offline.\n. I meant it will be great to add executor_id column in DDL itself. We can create a single create file which will directly setup Azkaban 3.0 compatible DB.\n. I don't think that there is any default param for this. It is not a required param.\n. I have removed it for the time being to avoid confusion. I kept it as it should be similar to command and I not have access to AWS storage link. Thanks.\n. Fixed. Thanks.\n. Fixed. Thanks.\n. Fixed. Thanks.\n. Hi @juhoautio,\nYes, it is some what confusing and depends on implementation. common.properties consist of properties visible to user job (from environment variable and many other ways) while commonprivate.properties are only visible to jobtype class. For example:- HadoopPig for pig jobtype, HadoopJava for java jobtype, etc. \nTo answer your other question, where to set a property is actually an implementation specific question that can only be answered by looking at code. A simple rule of thumb is to categorize props as jobProps and sysProps. For example: memcheck.enable=true required setting sysProps https://github.com/azkaban/azkaban/blob/master/azkaban-common/src/main/java/azkaban/jobExecutor/ProcessJob.java#L76\n-Gaurav\n. Suggestion: it may not be a good idea to change interface for a public method. See if we can remain backward compatible ?\n. In ideal case no. But it will be pretty easy to miss some APIs (especially plugins in other repo). Moreover, people outside LinkedIn might have taken some dependency on previous version.\n. I think it is always good to have an option. I believe it will be good to keep the config and just change the default to \"true\" so you can remove default value from all .properties file. \n. ",
    "bgdnlp": "I don't know if mine is the same issue, but I'll fill in the details here.\nI have localhost set as mail server. It doesn't use authentication, so mail.user and mail.password are not set. Local MTA is sendmail. When Azkaban is trying to send an email, /var/log/maillog has this message:\nlocalhost [127.0.0.1] did not issue MAIL/EXPN/VRFY/ETRN during connection to MTA\nI ran a tcpdump, Azkaban connects, issues EHLO, gets a response, then just closes the connection with no further communication.\n. Heh. I made my own, was searching for the same thing, found this issue. Put mine in a gist: https://gist.github.com/bgdnlp/5a81ee71ff11c1ede26e\nI figure it should go under bin/ ?\n. +1 for this issue and the associated pull. Quick enough change, but would be nice to have it in main repo. Can confirm working.\n. ",
    "YOOC94": "Azkaban How to output error log instead of wrong link in mail. ",
    "FelixGV": "If your fat jar contains no conf or it contains a conf that is\nsomehow improperly packaged and can't be accessed from the java code, then\nhadoop defaults to running on the local filesystem instead of HDFS.\nIn the case of the command type job which calls the hadoop script, you can\npass an extra parameter to force it to load extra stuff on its classpath\n(off the top of my head, I think the param is --classpath, but you can\ndouble check that with hadoop --help).\nAdd the path to your conf in there and see what happens.\nOn Sunday, October 13, 2013, Chenjie Yu wrote:\n\nThe way I read it, your program starts fine, it just didn't pick up the\nright hadoop conf.\nThe point is to find out where that conf comes from. It needs to be on the\nlocal jvm classpath for javaprocess and hadoopJava jobs.\nIn the case of commad type, you don't start a jvm by yourself, so it is\nthat \"hadoop\" script doing it.\nOf course I am assuming you didn't put a blank hadoop conf in your fat\njar, which may just override other confs.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/issues/54#issuecomment-26222795\n.\n\n\n\nF\u00e9lix\n. I have not had time to test, unfortunately... Was pulled in too many meetings last Friday ):\n. Good to know I'm not the only one twitching at that @onurkaraman ;) ...\n@hluu, this is does not seem like a high risk change, does it? Do you think we could merge it in?\n-F\n. ",
    "FYJen": "Hi Helena\nThe reason why you got class not found was because you defined your job.class incorrectly in your .job file.\nYou don't need .class extension, simply com.my.JobRunner will do. \nI am also trying to setup Scalding with Azkaban but with no luck. By looking your wrapper, I think the next error would be \"java.lang.NoSuchMethodException\" because by default azkaban.jobtype.HadoopJavaJobRunnerMain will call run method which is not defined in your JobRunner nor the override attribute defined in your .job. \nHave you successfully configured Scalding with Azkaban ?\nThanks,\nAJ\n. ",
    "elad": "I agree with @helena here, coming across the same problem, regardless of whether Hadoop is on EMR or not. Out of the box, Azkaban only works in local Hadoop mode... :/\n. ",
    "hahnjiang": "I set \"default.timezone.id=Asia/Shanghai\" in azkaban.properties. When I schedule job with CST timezone, the scheduled flows show wrong time. I found this setting in properties doesn't work. I read code and know DateTimeZone.setDefault doesn't work. So I fix it.\n. ",
    "kaneda": ":+1: \n. @erwa any plan to implement this? This is an important feature to my organization.\n. @erwa I just commented on that PR, I agree with your concern about total size and would prefer that this limit the message to the lines leading up to and including the error. In fact, just knowing what job failed would be enough for my purposes.\n. @erwa I updated that PR https://github.com/azkaban/azkaban/pull/416 can you take a look please? I don't know how to test my change at the moment.\n. @MTGAnt I had an open PR that fixed up the previous one. I didn't have a chance to test it, and we're currently re-evaluating the use of Azkaban. Try https://github.com/azkaban/azkaban/pull/416 and let me know if it works for you.\n. @kingster wouldn't just the log lines leading up to and include the failure be what you're looking for? @erwa \n. Nvm, I forgot to tag the jobs in that directory with .job, closing as invalid\n. :+1: I'd like this to be a multi CRON like statement, so that I can schedule a flow using CRON-like syntax in multiple ways.\n. Jobs are scoped to a flow and ordered by naming; there is no reason to think that a job in two flows is the same job.\n. @erwa This should be a lot safer in all cases. The features default to off and there's a default max amount of errors to give in the inline message.\nI also took the liberty of reformatting this to style best practices and removed the import .* (I personally don't like this at all, not for efficiency but for readability reasons)\n. @erwa could take a look at this when you get a sec?\n. @erwa any chance you could take a peak at this when you get a moment?\n. @davidzchen could you take a peak when you get a sec?\n. @davidzchen / @erwa any chance you could look at this?\n. Given https://github.com/azkaban/azkaban/issues/439 I'm not clear if Azkaban will continue support going forward. Can someone from the project comment on the future of Azkaban?\n. @hluu As per the first comment in this thread: Specifically \"Improve scalability with multiple executors\"\n. @davidzchen great to hear that. I'm interested in both new features (as the title suggests, allowing for multiple executors that are orchestrated through some sort of redundant master node) as well as improved documentation. A good example for the documentation would be how to override variables/macros and set default values in the event they're empty/null.\n. @hluu I've been tracking the progress of this on the PR, is this going to include associated documentation and examples?\n. @suvodeep-pyne it's not unattended, I asked for review of this a dozen times under the associated issue.. @ameyamk I can certainly write some. Relative links for a web page make me cringe.\n. ",
    "erwa": "Can you try out this pull request and see if it satisfies your need?\n. LGTM.\n. Thanks for fixing this.  It was affecting me, too.\n. LGTM!\n. LGTM.\n. LGTM.\n. Nice text drawing of the flow.  LGTM!\n. LGTM.\n. LGTM.\n. I really like the idea of using Ivy to pull in dependencies rather than checking in external .jars into our repo.  No more having to manually download the mysql-connector jar (since we can't check it in to our repo due to licensing issues).\nYour changes look fine to me, though I'm not all that familiar with ant or ivy, so you probably want some one else to also sign off on this commit.\n. Looks good to me.\n. Nice! I'm all for more viewing space.\n. Ship it!\n. Looks fine to me.\n. LGTM\n. Nice.  The job summary code always did seem a bit out-of-place, with its Pig/Hive/Hadoop specific parsing.\n. Looks good.\n. Nice!  Much more readable than hardcoding color codes.\n. Nice!\n. Looks good.\n. Ok, I've undone by StringUtils changes.  Now this pull request only includes an update to .classpath to look for libs in build/ivy/lib instead of lib\n. Looks good.  Do all the tests pass?\n. Looks good.\n. According to http://stackoverflow.com/questions/15007794/modify-the-classpath-dynamically, you can use URLClassLoader to modify the classpath and then use\nThread.currentThread().setContextClassLoader(urlClassLoader);\nto update the classpath.\n. Looks good to me.\n. I asked a teammate, and he suggested you use the addConnectionProperty method of BasicDataSource: http://commons.apache.org/proper/commons-dbcp/apidocs/org/apache/commons/dbcp/BasicDataSource.html#addConnectionProperty%28java.lang.String,%20java.lang.String%29\nSince MySQLBasicDataSource inherits from BasicDataSource, you can access the method directly using \"this.addConnectionProperty(...)\".  Please use this instead, as it's a bit cleaner.\n. Looks good, apart from some indentation weirdness (flowexecutionpanel.vm L64-72, flow-execute-dialog.js L142 and 146)\n. LGTM\n. Looks good!\n. Didn't look too closely at the Gradle wrapper, but if this works, I'm cool with it.\n. I fixed the problem in this pull request: https://github.com/azkaban/azkaban2/pull/215\nUntil we completely remove the Ant build files (build.xml), we should make sure they work to make it easier for other people to get up and running with Azkaban.\n. Building with Gradle does not have this issue.  The azkaban jar created by the Gradle build process includes all the *.vm files.\n. LGTM\n. In order to reload the jobtypes, you have to execute a curl command from the Azkaban machine because the executor server ports are not exposed publically, right?  It would be good to document instructions on how to reload the jobtype plugins without restarted the exec server, perhaps in the Azkaban documentation.\nAlso, are there possible race conditions when reloading the jobtypes while jobs are being launched?\nOtherwise, change looks good to me.\n. LGTM\n. Your list of property resolution order would be an extremely useful addition to the Azkaban documentation.\n. LGTM!\n. Copying some documentation notes from an email from @rbpark:\nUpdating JobType plugins in real-time\nYou may periodically want to add, remove or modify jobtype plugins on the ExecutorServer. If a change is made to the jobtype plugin set, then the changes may not be properly reflected in the ExecutorServer until the server is restarted. However, there is now a simpler way of updating the ExecutorServer's jobtypes without a restart.\nOn a machine that has access to the ExecutorServer, all you need to do is invoke (i.e. through curl) to the following url command: http://:/executor?action=reloadJobTypePlugins\nThat's it. If a {\"status\":\"success\"} message is returned, that means the job type plugins have been installed successfully. Errors will cause an error {\"error\":\"\"} response, and will not update the jobtypes.\nThe updated jobtype list will be immediately respected. However, some care must be taken in removing jobtypes only when they are no longer being used. Once updated, there's no way to revert your changes.\n. LGTM\n. Do we need both a footer-home.html and a footer-documents.html?  It seems that they are the same except the Downloads link for the latter is prefixed with \"{{ site.home }}/\".  Can't we just add this prefix to footer.html and use footer.html for both the home and documentation pages?\n. Ship it!  Merging...\n. LGTM!  It's nice that adding the links didn't require too many code changes.  Also, thanks for cleaning up a lot of formatting issues.\n. Hey @wagnermarkd,\nCan you rebase against azkaban:master and update your pull request?  Right now, I can't merge.\n. You only added the http/https config in the createErrorEmail code path.  Can you add it to the createFirstErrorMessage and createSuccessEmail code paths, too?\n. Looks pretty good. One last thing -- since you're changing the MailCreator interface API, can you also update ReportalMailCreator (https://github.com/azkaban/azkaban-plugins/blob/master/plugins/reportal/src/azkaban/viewer/reportal/ReportalMailCreator.java) to conform to the new interface API?\n. LGTM!\n. Otherwise, looks good! I am a huge fan of having the unit tests run automatically at build.\n. LGTM\n. Something probably broke in the recent renaming of this repository from azkaban2 to azkaban.  Until we fix it, you can see the documentation at https://github.com/azkaban/azkaban/tree/gh-pages/_includes/docs/2.5\n. Looks good!\n. LGTM!\n. Tracked by internal JIRA HADOOP-6918.\n. Ship it!\n. LGTM\n. Looks good! It's amazing how easy jQuery's tablesorter makes it to sort tables!\n. LGTM\n. LGTM.\n. It's best to say \"internal JIRA HADOOP-6388,\" to avoid confusion with the Apache HADOOP-6388: https://issues.apache.org/jira/browse/HADOOP-6388\n. Is this endpoint sufficient?: https://github.com/azkaban/azkaban/blob/master/azkaban-webserver/src/main/java/azkaban/webapp/servlet/ProjectServlet.java#L89-92\n. Look in AzkabanWebServer to see what route ProjectServlet is mapped to.\nhttps://github.com/azkaban/azkaban/blob/master/azkaban-webserver/src/main/java/azkaban/webapp/AzkabanWebServer.java#L760-761\nIn this case, it's /index.\nThen look at the ProjectServlet code I linked to before and fill in any request parameters the code is looking for.  In this case, it's just looking for an \"all\" parameter.\nSo you could do something like this:\n```\nlogin\ncurl -k https://: -d \"username=&password=&action=login\"\n{\n  \"status\" : \"success\",\n  \"session.id\" : \"\"\n}\nget all projects\ncurl -k https://:/index?all -b azkaban.browser.session.id=\n```\n. Seems like there is currently no JSON endpoint for fetching all projects.  Can you parse the HTML or query the DB directly instead?\n. @timyitong, you should fork the azkaban project and make you changes in your fork, and then open a pull request to merge your changes.\n. I have some example curl requests to hit the Azkaban web server here: https://github.com/erwa/notes/blob/master/azkabanAndReportal\nThere are a lot more endpoints and the best way to figure them out is to look at the source code.\n. LGTM\n. I do not think the Travis CI build failure is related to my changes.  The test that failed -\n```\nazkaban.execapp.event.BlockingStatusTest > testMultipleWatchers FAILED\njava.lang.AssertionError at BlockingStatusTest.java:128\n```\nwas not one of the files I changed.  Seems like this is just a flaky test.  The Assertion that failed was:\nAssert.assertTrue(thread2.getDiff() >= 2000 && thread2.getDiff() < 2100);\nThis assertion could fail if thread2 were delayed for some reason (perhaps the JVM was doing some GC or the OS was doing some context switching).\n. Fixed #301 \n. Tracked by internal JIRA HADOOP-6675\n. Hi JM,\nAny reason you want to merge these changes into the release-2.5 branch instead of just using one of our newer releases?: https://github.com/azkaban/azkaban/tags\n. Actually, after I deleted the .gradle directory in the root directory and tried again, the less and dust output did get copied.\n. Please see https://github.com/azkaban/azkaban-plugins/issues/128\nThere is a pending pull request to fix the issue -- it's basically a one-line change -- just remove the line in HadoopSecureHiveWrapper that is causing the issue.\n@hluu, can you please approve and merge by pull requests?\n. I think this may be a bug.  I have this issue, too.  However, you can just go to the History tab to see all the past executions (up to 3 months in the past, I think).\n. Can you also fix the broken link in README.md?  Change \"Azkaban2\" to Azkaban\" and \"azkaban2\" to \"azkaban\".\n. This is SO AWESOME. This is a tremendous help and will be incredibly helpful for myself and for users. Thanks for writing this documentation.\n. fetchExecJobStats returns null for me, too.  Seems like this endpoint tries to fetch job attachments -- I'm not sure what that is.\nI think fetchexecflowupdate is more useful.\n```\ncurl -k https://:/executor -d \"ajax=fetchexecflowupdate&execid=&lastUpdateTime=-1&project=&flow=&session.id=\"\n{\n  \"id\" : \"test\",\n  \"startTime\" : 1408152686395,\n  \"attempt\" : 0,\n  \"status\" : \"RUNNING\",\n  \"updateTime\" : 1408152686423,\n  \"nodes\" : [ {\n    \"attempt\" : 0,\n    \"startTime\" : 1408152686412,\n    \"id\" : \"test\",\n    \"updateTime\" : 1408152686420,\n    \"status\" : \"RUNNING\",\n    \"endTime\" : -1\n  } ],\n  \"flow\" : \"test\",\n  \"endTime\" : -1\n}\n```\nCould you add documentation for this endpoint instead?\n. LGTM! @hluu and @davidzchen, do you guys have any other comments before we merge this?\n. I'll ask @hluu and @davidzchen in person tomorrow if they're okay with the merge.  If so, we'll merge it.\n. Hi Tanvi,\nWhy do you want to attach log files to the emails?  The logs are already viewable in the Azkaban web UI.  There are also AJAX APIs you can use to fetch job logs: http://azkaban.github.io/azkaban/docs/2.5/#api-fetch-execution-job-logs\n. Hi Kinshuk,\nI have concerns about this change.  Log files can be very big and trying to attach them may cause the email to exceed the max email size, causing the email send to fail.  Thus, I do not think we should merge this change.\n. This change is fine with me.  Just some formatting nitpicks.\n. LGTM.  I didn't see this until now because GitHub does not send me a notification for new commits.  In the future, please post a comment saying you have posted a new commit to get my attention :-).\n@hluu, any comments before merging?\n. Please feel free to submit a pull request to fix this issue.\n. Another good check to add is to make sure the sum of the sizes of ALL attachments is less than the maximum attachment size.  You might have one hundred 9 MB attachments, and we should check that the total size of all attachments combined is less than the maximum attachment size before attempting to send an email.\n. LGTM\n. LGTM.  Please remove the trailing whitespace on line 63 of Emailer.java and then go ahead and merge this PR.\n. Could you please add a test for XmlValidatorManager?  The test could load a test XML validators file and then call XmlValidatorManager.getValidatorsInfo() to verify the validators were loaded.\nIt would also be helpful if you added a comment before XmlValidatorManager.loadValidators() giving an example of what the contents of an XML validators file might look like.\n. General logic looks good.  Just some minor comments.  Also, tests should be added.\n. Other than a few more minor comments, looks good.\n. LGTM.  BTW, GitHub does not send notifications when you push a new commit.  It's best to add a comment to the pull request to notify reviewers that you have made new changes.\n. LGTM. @hluu, do you have any other comments before merging?\n. @hluu, any final comments?  If not, I'm planning to merge this after lunch today.\n. An issue came up on the Azkaban Google Group: https://groups.google.com/forum/#!topic/azkaban-dev/FmqiKMMwwzM\nWe need to update the Azkaban jars in azkaban-plugins because the return type of ProjectManager.uploadProject() changed from void to Map, and Reportal calls this method and needs to be recompiled against the new method signature: https://github.com/azkaban/azkaban-plugins/issues/151\nThis would also be a good opportunity to Gradle-ize the azkaban-plugins build.\n. Tracked by internal JIRA DSP-4716\n. The problem still happens for jobs in embedded flows.  For example, if the contents of the zip uploaded to Azkaban are:\n- embeddedFlow.job\ntype=flow\nflow.name=test\n- test.job\ntype=command\ncommand=asdf\nretries=3\nwhen you run embeddedFlow, and then try to view the logs for the failed test job, you get a blank page.\n. LGTM\n. Is there an internal JIRA ticket tracking this issue?\n. Found it - internal JIRA DSP-4716\n. LGTM\n. Ship it!\n. LGTM!\n. LGTM\n. Otherwise, looks good.\n. Nice!  LGTM\n. Thanks for fixing this, @hy2014.  This was an issue for me on OS X (not an issue on RHEL), and I originally worked around it by running\nexport JAVA_TOOL_OPTIONS=-Dfile.encoding=UTF-8\nfirst before running gradle test.  Your fix is a much better solution.\n. I verified on my MacBook Pro that your pull request fixes the problem.\n. BTW, the foreign characters are Korean characters, not Japanese characters.\n. LGTM.  Looks like you also need to fix a test case: https://travis-ci.org/azkaban/azkaban/builds/40150807\nazkaban.project.validator.XmlValidatorManagerTest > testNoValidatorsDir FAILED\n    java.lang.AssertionError\n. LGTM. Some minor comments.\n. Ship It!  Merging...\n. This change has been merge: https://github.com/azkaban/azkaban/commit/891bada672d6da9d3272e15add535af1e3a81481\n. LGTM\n. We should wait to merge the actual code change before merging this documentation update.\n. LGTM\n. LGTM. One minor comment.\n. LGTM. Merging\n. LinkedIn has an LDAP plugin, but currently it's internal only.\n. Hi SatyaHarish,\nThanks for reporting this issue.  Can you please make the buffer sizes configurable (let them be set by properties in the azkaban.properties file) instead of hardcoding them in AzkabanExecutorServer?\n. Ship It!\n. Looks good, apart from some minor comments.\n. Apart from minor comments, LGTM!\n. LGTM!\n. If you look at the change, it seems to be calling a REST API: https://github.com/hluu/azkaban2/commit/a9d832e50068b15da3176dec891ada72119c07a4#diff-b646b1e6590b8b22e25a009cbf141e51R140\nYou should be able to use this programmatically. It just hasn't been added to the Azkaban documentation, yet.\n. We would also be very happy to accept a pull request to update the documentation :-). See the \"Documentation\" section on this page for instructions on updating it.\n. Please upload a picture of what the new project page looks like or send me privately a link to your local Azkaban instance with this new button.\n. Overall, looks good. Just some minor comments and questions. I would also like to see a screenshot of where this new \"Download\" link shows up on the page and how it looks.\n. Looks better. Some more comments. Hopefully one more round and this will be good to go :smile:\n. Feel free to go ahead and merge this change once you address my comments.\n. Tracked by internal JIRA DSP-4029.\n. Seems like this is already supported. See https://github.com/azkaban/azkaban/blob/master/azkaban-webserver/src/main/java/azkaban/webapp/servlet/ExecutorServlet.java#L801\nIf you are able to use this, it would be great if you could update the documentation: https://github.com/azkaban/azkaban/tree/gh-pages\n. Need more time to review this, will continue later today, after sleeping.\n. Please upload a screenshot of what the new /stats page looks like. Or privately send me a link to your local Azkaban instance with this new page.\n. Documentation about how the /stats endpoint works and its APIs definitely needs to be added to the Azkaban documentation.\n. This is a very big change. We should add some unit tests for this new StatsServlet.\n. Thanks for updating your code, Gaurav. It looks better. Just a few more concurrency issues.\n. Looks good. Feel free to merge after addressing my comments. \n. Ship It!\n. Looks good! Merging...\n. Thanks for reporting this, @tmwilder. I fixed the link :-).\n. LGTM.  Please wait for the Travis CI build to complete successfully before merging.\n. Looks good. Merging.\n. Fixed the indentation in sidebar.html. If you want to confirm I only added the api-schedule-a-flow link, I suggest installing the Chrome Octosplit plugin (https://chrome.google.com/webstore/detail/octosplit/mnkacicafjlllhcedhhphhpapmdgjfbb) and selecting \"No whitespace\". It's a really handy plugin for viewing diffs, especially when there are lots of whitespace changes.\n. A user was confused about how to find the projectId, so I clarified the documentation a bit in https://github.com/azkaban/azkaban/pull/392\n. LGTM. BTW, did you figure out why Azkaban doesn't show any error message at all (instead of truncating them) when there are too many error messages/too many flows?\n. Good idea. Renamed PORT to EXEC_SERVER_PORT.\n. Looks good to me.  Thanks for updating the documentation!\n. I agree with your assessment. I could not find any tests either.\n. LGTM. Merging.\n. I think it should be \"Succeeded\", to match \"Failed\" and \"Killed\".\n. Yeah, I think \"Succeeded\" makes more grammatical sense.\n. Does gradle test in the root of the project work? I also think tests are automatically run when you do a gradle distZip. If you want to skip tests, you can do gradle distZip -x test.\n. I followed the guide here: https://help.github.com/articles/using-jekyll-with-pages/\nSomething like:\ngem install bundler\nCreate a Gemfile\nsource 'https://rubygems.org'\ngem 'github-pages'\nRun:\nbundle install\nbundle exec jekyll serve\nThen view the page at http://localhost:4000.\n. Thanks, Antall! Merging.\n. Thanks, Antall! I appreciate your help updating our documentation.\n. What is the internal JIRA for this feature?\n. Hey Todd,\nThe job type needs to handle the Kerberos stuff. Take a look at HadoopJavaJob.java as an example. Under the hood, HadoopSecurityManager_H_2_0.java takes care of most of the Hadoop token stuff.\n. I think you might need { } around your variable. Something like\nmy.job\ncommand=echo ${foo}\n. Hi Vikram,\nI think you can use the Azkaban AJAX URL to fetch a big log. Something like https://<host>:<port>/executor?execid=<execid>&jobId=<jobid>&ajax=fetchExecJobLogs&offset=0&length=2147483647&attempt=0\nAlso I believe if the log is too big (I think the limit is configurable), the log starts rolling and the beginning of the log will be overwritten.\n. I think Azkaban only retains a fixed amount of logs. See https://github.com/azkaban/azkaban/blob/master/azkaban-execserver/src/main/java/azkaban/execapp/FlowRunnerManager.java#L186\n. Removed some unused and unneeded parameters in revision 2.\n. Per discussion in #1816, the root issue is that the user overrode azkaban.flow.execid, which he shouldn't have. Azkaban should probably not allow users to override azkaban.flow.execid (#1818). The clean workaround if a user wants to use a unique identifier in other properties is to do the following:\nid=${azkaban.flow.execid}\noutput_location=/tmp/${id}\nThen, a user can override id when needed without changing the value of azkaban.flow.execid.. Hey Oliver,\nThe use case for overriding the execution id was as follows:\n\nA flow writes data to HDFS at a location configured via a parameter output_location=/tmp/${azkaban.flow.execid}.\nIn one run (execution id 123), the flow fails on job 3.\nIn the next run (execution id 124), instead of re-running all the jobs, the user just wants to run job 3 and read the data already generated, but it is located at /tmp/123 rather than /tmp/124. So he overrides ${azkaban.flow.execid} and sets it to 123.\n\nA simple workaround that does not require overriding Azkaban runtime properties is to define another property:\nid=${azkaban.flow.execid}\noutput_location=/tmp/${guid}\nThen the user can just override id and leave azkaban.flow.execid untouched.\nI've also filed #1818 for discussing whether Azkaban should allow Azkaban-injected runtime properties to be overwritten or not.. Thanks for the discussion, @chengren311. Upon further reflection, I think using the workaround is a cleaner solution. Will discard this pull request.\nI think Azkaban should enforce that runtime properties cannot be overridden. This can be taken up in #1818.. Do we want to try and follow the JUnit naming convention of naming test methods \"testXXX\"?  (Reference: http://sqa.fyicenter.com/FAQ/JUnit/What_Are_JUnit_3_8_Naming_Conventions_.html)\n. What does .PHONY mean?\n. Is it possible to have multiple authors :-D?\n. This test is called testPauseFailKill.  Do you need a runner.kill(\"me\") statement somewhere in the test?\n. Oh, cool, did not know there was a convention.  I will start using separate-with-dashes for my class and id names in the future.\n. Nitpick: Indentation is off.\n. Indentation looks a bit weird here.  Let's stick to tabs for now?\n. I think we should stick to tabs for now for consistency, and if we want to convert to spaces in the future, we should do that separately in a indentation-change changeset.\n. What does the tilde (~) here do?  I'm aware that the tilde is the general sibling selector (http://css-tricks.com/child-and-sibling-selectors/), but does it have any effect here?\n. dustjs is pretty cool.\n. A lot of the stats analyzed in this file, like mappers, reducers, and various counters, are very Hadoop-specific and should probably be moved into a plugin (like the job-summary plugin) in the future.\n. Indentation of this function varies pretty wildly :-).\n. You can remove this comment now that you've done it.\n. We shouldn't check in commented out code.  Same on line 67.\n. Just curious, was it you or Eclipse that added the space after the opening parenthesis?  I've always NOT used a space.\n. Please add a space before and after the +, to be consistent with the rest of the file.\n. You can move this import down to before line 8 (import org.junit.Test;).\n. I added velocity-tools for convenience, as it is used by Reportal.  However, Azkaban itself doesn't actually use it.  Do you think we should remove this?\n. Looks like this local variable \"out\" is never used.  Did you mean to \"return out\"?\n. Azkaban SQL Package\n. Do we want to include mavenLocal() in the list of repositories?  Shouldn't all our jars be in mavenCentral() already?\n. Indentation\n. Remove commented out code.\n. It would be a good idea to add \"executor.connector.stats\" to the template azkaban.properties files in src/package/{solo,web,exec}server/conf/azkaban.properties so that users know this is configurable.\n. What are some examples of stats that these connector stats include?\n. I think we should just remove this /* package */ comment.\n. A documentation comment explaining what this method does and why would be helpful.\n. Let's always use { } for code blocks.\n. { }s would be very helpful here.  Also, indentation looks a bit off.\n. Add braces.\n. Instead of hardcoding \"http\" or \"https\", can we set this based on whether the property \"jetty.use.ssl\" is true or not?\n. Does this mean Azkaban compiles fine using Java 7?  And going forward, are we going to use Java 7 to build Azkaban (and its plugins)?\n. You probably want to change this 1.7 to 1.6 as well, along with the occurrence on line 251.\nOther than this, this change looks good.  I am thrilled that all the tabs are being replaced by spaces.\n. Ordering by group ID (which I assume is the first part (e.g.: org.apache.commons)) seems like the better approach (visually, it's much easier to parse).\n. Add @Override.  Same with afterExecute.\n. Can we rename this to DEFAULT_FLOW_NUM_JOB_THREADS?\n. What is the point of this finally block?  It does not do anything.  I think you can replace the entire try-finally with just executingListener.beforeExecute(r);\n. Same here\n. I'm also wondering how this works -- how are you able to look up a value in a Map, Integer> by passing a Runnable key, when Runnable and Future are not in the same hierarchy?\n. Should you move this to the beforeExecute() method on line 807?\n. This is old code that should be removed. The Key in submittedFlows is no longer an Integer but a Future<?>.\n. \"An improved version of java.lang.Process.\"\n. If the client does not include the projectUser param, will the client be able to write to anybody's project?  Also, the client is able to spoof any user by just setting projectUser to any user, right?\n. Add a leading space to align indentation with previous line.\n. same here\n. same\n. Gotcha.  Looks good to me then.\n. The reason the code compiled before is because the Map interface get() and remove() methods both take an Object key, not a K key.  Thus, you can pass the get() and remove() methods any object.\n. Could you please add a comment explaining that runningFlows contains all PREPARING plus all RUNNING flows, and that submittedFlows contains only PREPARING flows?\n. Just grep'd the codebase. This was the only occurrence of the 's' word.\n. I think it would be easier to read if you just combined all this into\njobJVMArgs += (previousJVMArgs == null) ? \"\" : \" \" + previousJVMArgs\nand then used jobJVMArgs below instead of previousJVMArgs. I think it'll also think the \"ps -ef\" output will be easier to read if you put the -Dazkaban... JVM params first, before the previousJVMArgs.\n. Who is using the current join() method above?  Why would someone want the list of Strings returned with a trailing delimiter? Can we just change the behavior of the existing join() method and use that instead?\n. authentiate -> authenticate\nprovide -> provides\n. authentification -> authentication\n. It would be better to provide an example that returns something other than null.\n. Indentation here is off.\n. The default should probably be 10 (10 MB), not one thousand.\n. This does not look like 1 GB to me.  Looks more like 128 MB.\n. sizeInByte --> sizeInBytes\n. Is the line break between \"logger\" and \".info\" necessary?\n. logger.error\n. Should we logger.error(ste) here as well?\n. The max attachment size should be 10 MB, though, not 1 GB.  Outlook seems to reject emails larger than ~10 MB.  I still think this should be 10.\n. Add 's' to end of _attachmentMaxSizeInByte --> _attachmentMaxSizeInBytes\nI think we should use\n1024 * 1024 * 1024; // 1 GB\nas this is the more typical accepted value of 1 GB in bytes.\n. I think most mail systems will fail for anything larger than about 50 MB.  See http://www.outlook-apps.com/maximum-email-size/ for some typical max attachment size limits.\nI think a value of 50 or 100 would be more reasonable.\n. Can we please keep these alphabetized?\n. direcotry -> directory\n. You could just use\nPASS,\nWARN,\nERROR;\nand then you can remove the constructor, _status, and the toString methods.\n. Can we also rename this enum to ValidationStatus to avoid confusion with azkaban.executor.Status?\n. I think PROJECT_ARCHIVE_FILE_PATH = project.archive.file.path is a more accurate name.\n. It would be good to note in a Javadoc that this class stores the Status with the highest severity (ERROR > WARN > PASS).\n. This will throw a NPE if msgs is null.  You probably want to add a null check.  Same thing for the other methods.\n. validaotors -> validators\n. Why does this interface method include a Logger argument?  I feel this is not necessary.\n. Let's keep these alphabetized.\n. Remove the \".toString()\" part\n. Do you think it's too much overhead to load validators every time a project is uploaded?  On the plus side, this should allow us to update the validators without needing to restart the web server, right?\n. attempNo -> attemptNo\n. attempNo -> attemptNo\nYou can also move this line above line 459 and then use attemptNo in the logInfo() call instead of node.getAttempt()\n. Please add a comment why you need to create a new instance of Props here.\n. Can you add a comment explaining why you're adding this property, which is not used by the XmlValidatorManager itself?\n. commandt --> command\n. command.1 --> command\ncommand.2 --> command.1\n. I would just say something like \"The Pig installation directory. Can be used to override the default set by Azkaban.\"\n. I think it would be good to also include \"Failed to close the validator classloader.\" in the logged error message.\n. Oh, in that case, I don't think we should throw a ValidatorManagerException. We don't want Azkaban to crash if for some reason, .close() fails.\n. Should we throw an exception here and on lines 94 and 261?\n. According to http://grepcode.com/file/repo1.maven.org/maven2/org.mortbay.jetty/jetty/6.1.26/org/mortbay/jetty/AbstractBuffers.java#AbstractBuffers, the default buffer sizes are\nprivate int _headerBufferSize=4*1024;\n    private int _requestBufferSize=8*1024;\n    private int _responseBufferSize=24*1024;\nIt seems a bit extreme to increase the buffer sizes so drastically.  Can you please leave these as the default values and then in your own configuration, you can set it to whatever you like.\n. Same here, please keep these set to the default values (4 kb, 8 kb, 24 kb).\n. Please set the default RESPONSE_BUFFER_SIZE_KB and REQUEST_BUFFER_SIZE_KB values to 24 KB and 8 KB, respectively, which is what the default values in http://grepcode.com/file_/repo1.maven.org/maven2/org.mortbay.jetty/jetty/6.1.26/org/mortbay/jetty/AbstractBuffers.java/?v=source are. You can change the values in your own configuration files.\n. Please remove _KB from all the field names.  These values are in bytes, not kilobytes.\n. These property names should not have a .kb suffix. These values are in bytes, not kilobytes.\n. additionalProp --> additionalProps\n. Please add a private constructor to prevent instantiation of this class:\nprivate ValidatorConfigs() { } // Prevents instantiation\nReference: http://stackoverflow.com/a/66307/1128392\n. I suggest replacing lines 1427-1431 with:\nif (autoFix.equals(\"on\")) {\n  prop.put(ValidatorConfigs.CUSTOM_AUTO_FIX_FLAG_PARAM, \"true\");\n} else {\n  prop.put(ValidatorConfigs.CUSTOM_AUTO_FIX_FLAG_PARAM, \"false\");\n}\n. I know the variable name prop is used elsewhere in Azkaban, but props makes more sense to me, since the object can hold multiple properties.\n. Can you use the jQuery ui-icon-help or ui-icon-info icon instead of an ordinary question mark?\nSee http://api.jqueryui.com/theming/icons/\nAzkaban already includes a bunch of UI icons in https://github.com/azkaban/azkaban/tree/master/azkaban-webserver/src/web/css/images\n. This checkbox shows up gigantic in my browser:\n\nCan we make it more ordinary-sized?\n. prop --> props\n. What about:\nif (autoFix && autoFix.equals(\"on\") {\n  props.put(ValidatorConfigs.CUSTOM_AUTO_FIX_FLAG_PARAM, \"true\");\n} else {\n  props.put(ValidatorConfigs.CUSTOM_AUTO_FIX_FLAG_PARAM, \"false\");\n}\n. Please combine lines 80 and 81 into one.\n. How convenient that ProjectLoader already has a getUploadedFile method :-)!\n. The line lengths of lines 401-407 are quite variable. Can you justify them a bit?\n. If inStream.close() throws an IOException, the outStream may not get closed. You might consider using Apache Commons IO's IOUtils.closeQuietly\n. It's probably better to move the IOUtils.closeQuietly() to the finally block, and add\nFileInputStream inStream = null;\nOutputStream outStream = null;\nbefore the try block.\n. Can you ensure this cast from a long to an int is safe? Do we put a limit on the size of the Azkaban zip that can be uploaded?\n. If so, please add a comment explaining why this cast is safe.\n. The reformatting (I'm guessing your editor did this automatically) made this paragraph less readable.\n. Does this mean Azkaban keeps around every version of a project that's ever been uploaded? If I upload a 100 MB zip 100 times, does that mean Azkaban will store 100 copies of my zip in the DB?\n. Can you also fix the formatting here?\n. @hluu, do you know what the answer to the above question is?\n\nDoes this mean Azkaban keeps around every version of a project that's ever been uploaded? If I upload a 100 MB zip 100 times, does that mean Azkaban will store 100 copies of my zip in the DB?\n. What unit is this in? Bytes? Megabytes?\n. Why are you catching a Throwable here?  I think it's better to explicitly catch each exception that can be thrown.\n\nI think you should have separate catch blocks for ProjectManagerException and IOException. It might be good to log a message, too, if there is some useful information you could provide.\n. I still think it's better to list the exceptions explicitly because by using a superclass, you might accidentally catch some exceptions you didn't mean to (someone might add code to this method in the future that throws a new exception).\nIn Java 7, you can catch multiple exceptions very concisely using |:\ncatch (IOException|ProjectManagerException e) {\n  ...\n}\nSource: http://docs.oracle.com/javase/7/docs/technotes/guides/language/catch-multiple.html\n. You have an extra f here (bufffer --> buffer).\n. IN_BYTE --> IN_BYTES\n. lasy -> last\n. For consistency, please change ON to DATE, since the String contains \"date\".\n. Please document in a Javadoc comment the allowed actions.\n. I would make this constructor protected because you cannot directly instantiate abstract classes. See the answers to http://stackoverflow.com/questions/260666/can-an-abstract-class-have-a-constructor for a discussion.\n. DISBLE -> DISABLE\n. RETRIVAL -> RETRIEVAL\n. Please document what enabling useStats does. I cannot tell by looking at the UI.\n. else put an error message saying invalid action?\n. Indentation is a bit funky in lines 97 to 113.\n. Please prefix class and instance variables with underscores (_).\n. Please explain what this statisticalDeviationFactor is used for.\n. DEVIAION -> DEVIATION\n. Consider using the Apache Commons Math library rather than writing your own Statistics library. For example, http://commons.apache.org/proper/commons-math/javadocs/api-3.2/org/apache/commons/math3/stat/descriptive/DescriptiveStatistics.html will calculate mean, standard deviation, and variance for you.\n. Also, did you mean standardDeviationFactor?\n. standardDeviationFactor?\n. I think _timeWindow is a better name. I got very confused by the name interval, because to me, \"interval\" signals to me something repeating over and over, whereas \"window\" tells me there's a fixed length of time I'm interested in.\n. Do you really want to remove InMemoryHistoryNodes from the underlying LinkedList? This might change the results if I then choose statBasedSelectMetricHistory. I believe both of these filters should not modify the underlying data but should merely return a filtered view (you could copy elements of interest into a new list, say).\n. Seems like this cleaning of expired metrics should be done in its own background thread. It should not only be done when reportMetric and getDrawMetric are called. If no one calls those methods for a long time (e.g.: no one uses the /stats endpoint for a long time), then the historyListMapping could grow humongous and cause Azkaban to run out of memory. I think it's better to do the cleaning in a background thread that does cleaning periodically.\n. I did not find any code that uses this class. Is this class necessary?\n. Why do you have synchronized on an empty method?\n. Why are you synchronizing on metric here when the String gangliaCommand has already been constructed and you are not accessing metric's state at all?\n. You initialize server here but then you never use it.\n. It's a little confusing understanding how the MetricReportManager relates to the IMetricEmitters and the IMetrics. Can you please expand the Javadoc to explain the relation of all these parts?\n. What is this hidden input element for? Is the checkbox element not sufficient?\n. Oh, thanks for pointing that out.\n. Ah, I see.\n. If there's nothing to initialize, just omit the entire method and rely on the default implementation in the GenericServlet superclass (StatsServlet -> HttpServlet -> GenericServlet).\n(Also, if you did want to override the default implementation, it's good practice to annotate the method with @Override.)\n. According to Item 9 of Effective Java (2nd Edition) by Joshua Bloch, you should always override hashCode when you override equals.\n. It seems like you only need synchronized while calling this.clone(). I don't think this entire method needs to be synchronized. Once you've cloned this, I think you can call .reportMetric() without holding on to a synchronization lock.\n. You synchronized (metric) above, but you are using metric inside a new thread here, so the synchronization lock does not apply to this thread. See http://stackoverflow.com/questions/15926400/execution-of-new-thread-inside-a-synchronized-block for details.\n. Actually, I would recommend just doing the synchronized cloning inside MetricReportalManager.reportMetric() and get rid of synchronization for this method.\n. There's a race condition in this test. The metric is not guaranteed to be emitted in the interval [from,to]. You call metric.notifyManager() before you declare from, so the metric might be emitted before the starting time. (In theory, since the metric emission happens in a separate thread, it might even get emitted after the end time to.) I would move the Date from = new Date(); line before the metric.notifyManager(); line.\n. Could you please add a ## comment above this line explaining this? Apart from this, this change looks fine to me.\n. I was mainly just concerned about the from declaration. I think using wait is fine for our case.\n. Why do we need to create an XmlValidatorManager here even though we don't store it in any variable? It would be good to add a comment explaining this.\n. Indentation\n. Even though there's an error, the status is still \"success\"?\n. Ah, that's unfortunate. I've opened https://github.com/azkaban/azkaban/issues/407 for this issue.\n. ret won't be null because it is initialized to an empty HashMap on line 220. The null check was unnecessary.\n. Java doesn't make using dispatch tables easy because functions are not first-class objects. I could use reflection, but I think that actually makes the code harder to read and maintain.\n. User does not control the cancel() method that kills the job. The cancel() method should be able to find the log file that Azkaban created -- the log file is then searched for YARN application that need to be killed.. ",
    "MTGAnt": "This would be a nice feature to have. Makes it so much easier for us to know exactly what failed from the get go. How can I implement this on my solo 2.5 server instance?\n. ",
    "ismailsimsek": "+1. first i tried to solve this by restarting azkaban and that didnt worked.\nnext day i restart azkaban with mysql  and now it seem it fixed. \n. +1\n. +1. +1\n. currently having same issue  +1\n. similar to pull request #598. but with current jetty parameters i cant remap the port number when there is  nginx port redirection in between.\n. must be ok now.\nfollowing two files are removed which were conflicting, right ? \n azkaban-soloserver/src/package/conf/azkaban.properties\n azkaban-webserver/src/package/conf/azkaban.properties. Hi \ni needed it just for email messages, because url in the email and the url of the azkaban in-front of the reverseproxy were different that was causing broken urls in the email, in my case reverseproxy was changing url and port-number. dont know where else it can be used. agree that's better and more generic naming, i will change names to\njetty.hostname.external\njetty.ssl.port.external\njetty.port.external\nhttps://en.wikipedia.org/wiki/Reverse_proxy#/media/File:Reverse_proxy_h2g2bob.svg\n```\nmail hostname and port parametters, when this parametters set then these parametters are used to generate email links.\nif these parametters are not set then jetty.hostname, and jetty.port(jetty.ssl.port if ssl configured) are used.\nits used when there is reverse proxy between azkaban server and user, this parametters set to the values that enduser sees\nlocalhost:8081 -> proxy -> myazkaban:443 -> enduser\n. ok it should be up to date now. duplicate of #689. closing.\n. Hi \nis it possible to download existing flow as 'Flow 2.0' YAML file? \nOr is there any easy way to convert existing flows and jobs to 'Flow 2.0'. \nwe have multiple flows with a lot of jobs and complex dependencies, i was looking into easy way to do migrate existing flow to 'Flow 2.0'.\nthank you for the great work by the way. thank you @jamiesjc for the link will check the plugin. we are constructing it manually.\ni wrote following code to test the conversion. with this it is getting pretty close but still few changes needs to be made manually.\ntail -n +1 .job > combined.flow\nsed -i'' -e 's/==> /  - name: /g' combined.flow\nsed -i'' -e 's/type=/    type: /g' combined.flow\nsed -i'' -e 's/command=/    config: \\'$'\\n      command: /g' combined.flow\nsed -i'' -e 's/command.1=/    config: \\'$'\\n      command.1: /g' combined.flow\nsed -i'' -e 's/command.2=/    config: \\'$'\\n      command.2: /g' combined.flow\nsed -i'' -e 's/command.3=/    config: \\'$'\\n      command.3: /g' combined.flow\nsed -i'' -e 's/command.4=/    config: \\'$'\\n      command.4: /g' combined.flow\nsed -i'' -e 's/dependencies=/      dependsOn: \\'$'\\n        - /g' combined.flow\nsed -i'' -e 's/flow.name=.//g' combined.flow\nsed -i'' -e 's/retry.backoff=10000//g' combined.flow\nsed -i'' -e 's/.job <==//g' combined.flow\nsed -i'' -e '1s/^/nodes: \\'$'\\n/' combined.flow\nsed -i'' -e '1s/^/config: \\'$'\\n/' combined.flow\n```. Hi \ni believe you need another job which ties them together, try to a dd anew job like below.\n```\nJob_NameofMyflow.job\ntype=command\ncommand=echo 'end'\ndependencies=JobB,JobC\n```. shutdown  exception \n2018/02/14 18:30:42.727 +0100 ERROR [AzkabanWebServer] [Azkaban] Exception while shutting down quartz scheduler.\njava.lang.NullPointerException\n    at azkaban.scheduler.QuartzScheduler.shutdown(QuartzScheduler.java:105)\n    at azkaban.webapp.AzkabanWebServer$1.run(AzkabanWebServer.java:239)\n2018/02/14 18:30:42.729 +0100 INFO [AzkabanWebServer] [Azkaban] logging top memory consumer. Hi @kunkun-tang  i did azkaban migration from 3.0 and i was testing new features locally, i thought it might be useful to post the exception message. we are not using this feature at the moment,  i believe this can be closed if its being addressed with new development. . im seing following UI . is it default scheduler UI now? \n\nwhere i was expecting old scheduler UI\n\n. first image showing current behavior. with first one when going back one page JS popup is gone and you need to tiger scheduling action from beginning. but scheduling options are still saved somehow.\nsecond one is new behavior which is opening link in new tab.  \n\nNew \n\n. Thank you all for the new features and improvements . agree its duplicated and maybe too much comment, i can remove last lines, regarding location it makes sense keeping comment or some part of it in properties file, then its will be readable after build, to the user that seting up the configuration?. ",
    "jiminoc": "+1\n. ",
    "maczpc": "my pleasure\uff01\n. ",
    "cwsteinbach": "Would it be possible to include the commit hash as well, or something similar to what Hadoop displays when you run the 'version' command:\nHadoop 1.2.1\nSubversion https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152\nCompiled by mattf on Mon Jul 22 15:23:09 PDT 2013\nFrom source with checksum 6923c86528809c4e7e6f493b6b413a9a\n. @davidzchen \n\nThis change would effectively create a dependency from the executor server to the web server because the executor server is now adding webserver links.\n\nSo the plan is to avoid this by shifting the Az webserver dependency to third party consumers of this information? That doesn't seem very fair, or practical.\n. LGTM!\n. Seems like 'getValidatorName()' would be more appropriate. Also, is this expected to be the name of the Validator class, qualified name of the validator class, or a user friendly name?\n. Missing @Override annotations?. ",
    "vikramkone": "Hi David,\nHow do I enable Flow stats for command job types? I get \"not stats\" when I got to the tab\n. +1 I'm also seeing the same issue. I want to define some system level static variables in the global.properties file, which I can then reference in the .job file. Looks like this doesn't work?\nOnly variables defined in the *.properties files that are part of the zip package are working correctly.\n. +1 .. Does Azkaban support long running jobs like spark streaming jobs etc? If we use the command job type and kick off a spark submit command that starts a never ending spark streaming job..does azkaban kill it or let it be?\n. +1, We at microsoft are currently using Azkaban to schedule our spark jobs using command type and would really appreciate the continued support of Azkaban by the community and maintainers.\nHere are our lost of requests for enhancement that feel are necessary for azkaban.\n1. Provide high availability for Azkaban WebServer, SQL DB using  Zookeeper\n2. Improve documentation about the following areas\n   - How to schedule jobs to run in the past for back filling purposes\n   - How to pass the date of execution of the flow to the underlying job during back filling\n   - How to pass output of command to command.1 and output of command1 to command2 etc\n3. How to configure notification email settings for postfix\n4. LDAP integration for authentication\nThere will be more requests as we onboard more people to this\n. @david .. It's great to hear that our requests are being considered for future improvements. Glad to know that you are ex-microsoftie ;)\n. @hluu looks like 2.7 release is up on github. Awesome..! Does this support multiple executors now? I dont see any updates to the documentation referencing how to setup multiple exec servers.\n. @hluu and @logiclord great to hear that multi exec support is coming soon. Is there a tentative time line of when 3.0 is going to be release? I'm asking coz , wanted to know if we should hold off on upgrading from 2.6 to 2.7, so that we can go directly to 3.0 if it's sooner than a month.\n. When is 4.0 releasing and are there any docs on what the new features are?\nOn Apr 28, 2017 5:57 PM, \"Ameya\" notifications@github.com wrote:\n\nClosed #461 https://github.com/azkaban/azkaban/issues/461.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/461#event-1062868312, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ABX13XYc6Rt8-Ybb7OOxJ6MHk6WPM_xDks5r0mCsgaJpZM4Ftyu-\n.\n. I was able to figure this out by wading through internet pages and reading the source code on github.\nA better documentation is a must for this feature.\n\nHere is what I did to make it work.\n1. Configure postfix to server as a hotmail/outlook smtp relay.\n   This is what I added to my /etc/postfix/main.cf file to use outlook.com as relay\nSASL parameters\nsmtp_use_tls=yes\nsmtp_sasl_auth_enable = yes\nsmtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd\nsmtp_tls_CAfile = /etc/ssl/certs/ca-certificates.crt\nsmtp_sasl_security_options =\n1. The /etc/postfix/sasl_passwd file contains user name and password like this\n   [smtp.live.com]:587  username@outlook.com:Password\n2. Next run postmap and re-start posffix\n   postmap /etc/postfix/sasl_passwd\nservice postfix restart\n3. These are the changes I made to conf/azkanban.properties to make it work\n   mail.sender=username@outlook.com\nmail.user=username@outlook.com\nmail.password=Password\nmail.host=smtp.live.com\nmail.tls=true\njob.failure.email=email@domain.com\njob.success.email=email@domain.com\njetty.hostname=dnsname.cloudapp.net\n. ping?\n. ping?\n. Thanks David. Basically, I want to know how to pass output of a command to another command.\nI know that we can pass outputs between jobs by writing to JOB_PROP_OUTPUT_FILE.\nBut, is it possible to pass data between commands?\nex:\nmyjob.job\ncommand=export foo=bar\ncommand1.=echo $foo\nAlso, it would be great if I can do something like\ncommand=bash script1.sh\ncommand1=bash script2.sh ${command1.stdout}\nHope it makes sense\n. We can share data between jobs easily by writing to the JOB_PROP_OUTPUT_FILE. But there is no easy way to share data between commands within a job\n. @hluu @davidzchen  can you let me know which class I need to make changes to add the ability to azkaban to be able to schedule jobs in the past? I looked at the source code and it's not obvious which class(es) needs to be updated to support this. I would like to add this feature to azkaban asap\n. I have a fix locally..I'll send a pull request?\n. Sent.. Can you check my comments on PR#562?\n. It seems that there is ajax aoi call to remove schedule. Also if you create a new schedule for a flow which already has a schedule then it gets overwritten\n. Hi @davidzchen @hluu ..this is my first time contributiing back to azkaban. Can you let me know why the travis build is failing for oracle jdk and jdk8 but passing for jdk 7? What do I need to change to make the build work across all JDK versions? My changes don't seem to be spacific to any JDK version, so curious as to why it fails with errors related to dependencies not found.\n. Added unit test and fixed indentation\n. Thanks for the review. Do I need to do anything else from my side, to merge the request into the master?\n. @davidzchen  Made the changes as mentioned in your other thread...help review and merge\n. @sowe Your dependencies should match the name of the job file. So Job1.job dependeds on Job2.job then dependencies=job2\n. Weird..seems like If I do \"gradlew compileJava\" from cmdline and then do make project is intelij, it works. ! so looks like the cmdline build pulls the required dependencies correctly but not intellij auto import option\n. I figured this out. Turns our that when I use \"dse spark-submit...\" as the command to be executed then there is a child process that gets spawned by dse. When I press kill in the azkaban portal only the parent process is killed and not the child process and hence I see it still running in spark ui.\nSolution was to wrap the command in a shell script and use a trap function that kills the child process upon receiving SIGINT/SIGTERM\n. Gaurav\u00a0I'm not using any plugins. Only the default command job type\nv\nOn Thu, Dec 3, 2015 at 3:21 PM -0800, \"Todd Fritz\" notifications@github.com wrote:\nI was able to work around the problem by adding defensive code (after reviewing the git history of changes).  Try after adding this code to JobTypeManager after line 364, immediately before the job is populated.\nif (pluginLoadProps == null) {\n    logger.info(\"...pluginLoadProps was null, assigning new empty Props().\");\n    pluginLoadProps = new Props();\n  }\n  if (pluginJobProps == null) {\n    logger.info(\"...pluginJobProps was null, assigning new empty Props().\");\n    pluginJobProps = new Props();\n  }\n\u2014\nReply to this email directly or view it on GitHub.\n. Is someone going to do a pull request to fix the issue ? Seems like a DOA\nbug for 3.0 solo server\nOn Dec 7, 2015 4:44 PM, \"Juho Autio\" notifications@github.com wrote:\n\nI encountered the same problem.\nThanks @todd-fritz https://github.com/todd-fritz: setting pluginJobProps\nto a non-null value helps.\nIf you look at JobTypeManager you'll find out that pluginJobProps isn't\neven used after that line any more, so that piece of code is redundant.\nP.S. I couldn't get these log messages to be shown anywhere..? I was able\nto verify with System.err.println that this additional code is executed,\nthough.\nThere's just logs/azkaban-execserver.log that is being populated with\nsome logs, but only this line from the JobTypeManager:\n2015/12/07 13:05:36.138 +0200 INFO [JobTypeManager] [Azkaban] Loading plugin default job types.\nMaybe the logging system somehow gets misconfigured after that line is\nprinted?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/575#issuecomment-162487882.\n. There is no inbuilt HA mode for Azkaban web and executor server processes. You need to use either Zookeeper or Consul for supporting HA mode. I have used consul succesfully with azkaban to provide HA mode using distributed locking to ensure single instance of Azkabn Web Server is always up\n. @erwa Nope, that didn't work. Same error\n\n11-12-2015 14:39:56 PST Ping INFO - Starting job Ping at 1449873596083\n11-12-2015 14:39:56 PST Ping INFO - azkaban.webserver.url property was not set\n11-12-2015 14:39:56 PST Ping INFO - job JVM args: -Dazkaban.flowid=Ping -Dazkaban.execid=33 -Dazkaban.jobid=Ping\n11-12-2015 14:39:56 PST Ping INFO - Building command job executor. \n11-12-2015 14:39:56 PST Ping ERROR - Failed to build job executor for job PingCould not find variable substitution for variable(s) [command.1->foo]\n11-12-2015 14:39:56 PST Ping ERROR - Failed to build job type\n. ping?\n. @erwa \nAnthony, do you have any clue about this?\n. I tried this..but it doesn't work when the log file is rotated when it gets\ntoo big. Even when offset is 0 it doesn't get the beginning of the log as\nexpected.\nIs it possible to get this from MySQL dB?\nOn Feb 18, 2016 11:39 AM, \"Anthony Hsu\" notifications@github.com wrote:\n\nHi Vikram,\nI think you can use the Azkaban AJAX URL to fetch a big log. Something\nlike https://\n:/executor?execid=&jobId=&ajax=fetchExecJobLogs&offset=0&length=\n2147483647&attempt=0\nAlso I believe if the log is too big (I think the limit is configurable),\nthe log starts rolling and the beginning of the log will be overwritten.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/599#issuecomment-185884868.\n. Yes it does. There is a spark job type plugin that you can use to submit spark jobs internally via spark-submit command.\nAlternatively you can also use the command job type and call spark-submit command in your job config\n. Figured this out by looking at the code..need to do this\n\ncurl -k https://HOST:PORT/schedule -d \"ajax=setSla&scheduleId=2&slaEmails=foo@bar.com&settings[0]=,06:00,SUCCESS,true,true\" -b azkaban.browser.session.id=SESSION_ID\n. This feature is already available as SLA that you can set for your flows and jobs. You can check the docs. ",
    "rgabo": "True for all launch scripts, closing this PR and creating a real one...\n. ",
    "jackiesteed": "command=/data/udcanalyze/udc/b2c/b2c.sh date +%Y-%m-%d\nthis one also not working, while `date is the first parameter I got in the script\n. ",
    "airhorns": "I ran into this as well. Thanks for the fix!\n. ",
    "sorenmacbeth": "I figured out how to do this using bash -c like so\ntoday=bash -c 'date +%Y-%m-%d'\n. ",
    "hreview": "You will need to copy the hive plugin into plugins/jobtypes.\nOn Apr 20, 2014, at 8:25 AM, \"jimternet\" notifications@github.com<mailto:notifications@github.com> wrote:\nI've tried putting the hive plugin in the plugins folder and the lib folder. What am I doing wrong? When we alias hive, is that at the OS level (seems to be the case)\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/issues/219.\n. Ship It! Merging.\n. No I am not :-) - i am this guy - https://www.linkedin.com/in/ameyakanitkar/\nOn Fri, Apr 21, 2017 at 5:13 AM, Venkatesh Changegowda \nnotifications@github.com wrote:\n\n@ameyamk https://github.com/ameyamk\nAre you Ameya K Shetty, who studied at NIE, Mysore? I just ask out of\ncuriosity since it is a rare Indian name and I had a classmate long back\nwith this name and he was a good programmer. Just wondering about the\nprobablity of you being him..!\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/721#issuecomment-296174683,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AGN0AWxy0Ofi8LnDawBRIqvukGXDkZU7ks5ryJ1pgaJpZM4J3G-H\n.\n. Hey Liang\n\nSorry about that. I had to push because my change was huge.\nHowever, I don't think that you'll face any issues with it since they were\njust file renames.\nRegards\nSuvodeep\nOn Thu, Sep 15, 2016 at 4:54 PM, Liang Tang notifications@github.com\nwrote:\n\nOops. Looks like I have to rebase locally due to suvodeep's change.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/azkaban/azkaban/pull/732#issuecomment-247486453, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AGN0AWUE0yYtqFMxPr6mxc10eBByKJHJks5qqdqsgaJpZM4J9IEk\n.\n. You don't seem to have your password set. Could you please try with a\npassword and let us know ?\n\nOn Tue, Sep 27, 2016 at 2:29 AM, zhangnew notifications@github.com wrote:\n\nwhen I set :\ndatabase.type=mysql\nmysql.port=3306\nmysql.host=localhost\nmysql.database=azkaban\nmysql.user=azkaban\nmysql.password=\nmysql.numconnections=100\nI got this:\norg.apache.commons.dbcp.SQLNestedException: Cannot create PoolableConnectionFactory (Access denied for user ''@'localhost' to database 'azkaban')\n    at org.apache.commons.dbcp.BasicDataSource.createPoolableConnectionFactory(BasicDataSource.java:1549)\n    at org.apache.commons.dbcp.BasicDataSource.createDataSource(BasicDataSource.java:1388)\n    at org.apache.commons.dbcp.BasicDataSource.getConnection(BasicDataSource.java:1044)\n    at azkaban.database.DataSourceUtils$MySQLBasicDataSource$MonitorThread.pingDB(DataSourceUtils.java:195)\n    at azkaban.database.DataSourceUtils$MySQLBasicDataSource$MonitorThread.run(DataSourceUtils.java:183)\nCaused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Access denied for user ''@'localhost' to database 'azkaban'\n    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n    at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n    at com.mysql.jdbc.Util.handleNewInstance(Util.java:411)\n    at com.mysql.jdbc.Util.getInstance(Util.java:386)\n    at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1054)\n    at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:4237)\n    at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:4169)\n    at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:928)\n    at com.mysql.jdbc.MysqlIO.secureAuth411(MysqlIO.java:4736)\n    at com.mysql.jdbc.MysqlIO.doHandshake(MysqlIO.java:1342)\n    at com.mysql.jdbc.ConnectionImpl.coreConnect(ConnectionImpl.java:2493)\n    at com.mysql.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:2526)\n    at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2311)\n    at com.mysql.jdbc.ConnectionImpl.(ConnectionImpl.java:834)\n    at com.mysql.jdbc.JDBC4Connection.(JDBC4Connection.java:47)\n    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n    at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n    at com.mysql.jdbc.Util.handleNewInstance(Util.java:411)\n    at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:416)\n    at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:347)\n    at org.apache.commons.dbcp.DriverConnectionFactory.createConnection(DriverConnectionFactory.java:38)\n    at org.apache.commons.dbcp.PoolableConnectionFactory.makeObject(PoolableConnectionFactory.java:582)\n    at org.apache.commons.dbcp.BasicDataSource.validateConnectionFactory(BasicDataSource.java:1556)\n    at org.apache.commons.dbcp.BasicDataSource.createPoolableConnectionFactory(BasicDataSource.java:1545)\n    ... 4 more\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/753, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AGN0ATi6U6eV_wE4CLVBIGgGpKFDizz_ks5quOHlgaJpZM4KHccx\n.\n. awesome. let me know if you need any help with gradle.\n\nOn Tue, Sep 27, 2016 at 3:26 PM, Liang Tang notifications@github.com\nwrote:\n\n@suvodeep-pyne https://github.com/suvodeep-pyne I will fix this by\nchecking in JsTest conponent.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/754#issuecomment-250017587,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AGN0AXxN3fIQ4RbUKPkZ6Gn0V-2xyfaPks5quZgrgaJpZM4KH_MV\n.\n. Unfortunately this is not available you can only query for a particular\nproject and a flow:\n\nlike:\nGET /schedule?ajax=fetchSchedule&projectId=19&flowId=1\nYou can contribute proposed enhancement. This is where the code is:\nhttps://github.com/azkaban/azkaban/blob/master/azkaban-web-server/src/main/java/azkaban/webapp/servlet/ScheduleServlet.java\nAmeya\nOn Mon, Mar 20, 2017 at 1:00 AM, Ivan notifications@github.com wrote:\n\nIn azkaban document, I noticed that the only way to get schedule id is to\nfind in the Azkaban UI on the /schedule page.\nIf it is possible to retrieve the scheduler id by api based on params\n'flow' or 'project' or other params provided ?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/945, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AGN0AXuaomeSUdM1iHScn5L2YDJrXK0Uks5rnjIogaJpZM4MiHTa\n.\n. make sure your concurrent run option is turned off:\nhttp://azkaban.github.io/azkaban/docs/latest/\n and search for \"Concurrent Options\"\n\nOn Mon, Mar 20, 2017 at 1:52 AM, duanyixuan notifications@github.com\nwrote:\n\nhi,azkaban group:\nrecently,i discover some problems about azkaban crontab. for example,\nsometimes,some job flow execution over one hour in some time, but that is\ncrontabed every hour. As a result, it can`t be executed next hour. it can\nbe normaly executed thrid hour.\nin old version, there is no problem about this.\nfinally, the suggestion is that azkaban start and shutdown scripts add the\nfollowing code.\nbin=cd $(dirname $0);pwd\nazkaban_dir=$bin/..\ncd ${azkaban_dir}\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/946, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AGN0Aap5kaZK-l2_wwuLIRBaVVp-cW3mks5rnj5hgaJpZM4MiJnl\n.\n. Idea 2 is what we are implementing - with data store continues to be MySQL\nDB. We can replace this with something else - if it proves to be a\nperformance bottleneck.\n\nThis should be ready and in open source by mid July.\nDoes that sound good?\nOn Tue, Mar 28, 2017 at 7:01 AM, mukund-thakur notifications@github.com\nwrote:\n\nI have two ideas to solve this.\nIDEA 1\nWe put all the in memory state of azkaban web server info( like\nrunnableFlows etc ) in some data store(DS) , when active goes down send an\nevent so that passive one gets everything in memory from DS. We can use the\nleader election algorithm provided by zookeeper recipes for sending the\nevent to the passive node.\nIDEA 2\nWe put all the in memory state of azkaban web server info( like\nrunnableFlows etc ) in some data store(DS) ,there will be multiple web\nservers which will directly read/write from this DS rather than in memory.\nClients will connect to a load balancer which will be on top of all web\nservers.\nChoice of Data Store(DS)\nWe can evaluate between mysql, couchbase, kafka (as suggested by @HappyRay\nhttps://github.com/HappyRay ) and decide which one to use.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/952#issuecomment-289779324,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AGN0ASRq1Hmvrn6I4rfloIWx9VvfHmOQks5rqRK2gaJpZM4MmqdT\n.\n. If load is not too high \u2013 you can have all 3 on the same box \u2013 i.e. DB + web server + executor server.\nIf load is higher you can move them to separate boxes.\nThere can be more than 1 executor. So - you can setup several of them depending on your scaling requirements.\n\nTypical large installation includes DB on separate box, web server on another box and several executor machines.\nThere are installations with as many as 15 executor servers for the same Azkaban cluster.\nFrom: HTeam hteam@linkedin.com on behalf of yy1 notifications@github.com\nReply-To: azkaban/azkaban reply@reply.github.com\nDate: Friday, May 12, 2017 at 2:40 AM\nTo: azkaban/azkaban azkaban@noreply.github.com\nCc: Subscribed subscribed@noreply.github.com\nSubject: [azkaban/azkaban] azkaban job running on all the servers separately\uff1f (#1084)\nWe are trying to switch to azkaban for managing our jobs, but facing issue in understanding how to use azkaban for the distributed server environment. We have different job set running on different servers and we like to have a common managing point for all of them, as per my knowledge, we execute both web and execution servers on a single server.\nPlease help me understand if its possible or we need to have azkaban running on all the servers separately.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHubhttps://github.com/azkaban/azkaban/issues/1084, or mute the threadhttps://github.com/notifications/unsubscribe-auth/AGN0AdWvlqbZr4tPVnOuq5RghZTc-TNFks5r5CjzgaJpZM4NZEAY.\n. This is solved via Suvodeep\u2019s\n/status API\nFrom: HTeam hteam@linkedin.com on behalf of Adam Faris notifications@github.com\nReply-To: azkaban/azkaban reply@reply.github.com\nDate: Thursday, August 31, 2017 at 1:33 PM\nTo: azkaban/azkaban azkaban@noreply.github.com\nCc: Subscribed subscribed@noreply.github.com\nSubject: [azkaban/azkaban] please expose the Executor_ID in /jmx (#1416)\nWhen forcing a job flow on a particular executor, instead of running a SQL to get the executor id, it would be nice to expose the Executor ID somewhere in the GUI. The /jmx servlet inside the web server seems like it's a good location to display this info.\nThanks\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHubhttps://github.com/azkaban/azkaban/issues/1416, or mute the threadhttps://github.com/notifications/unsubscribe-auth/AGN0ASWWOdCgLAcOBh7qzh8dh8-SaXcqks5sdxiKgaJpZM4PJXu6.\n. ",
    "jimternet": "no dice. same error message. \n. And the contents of /plugins/jobtypes/hive.. should that just be the jar? \n. here's what I have \n.../azkaban-solo-server-2.5.0/plugins/jobtypes/hive\njimternets-MacBook-Pro:hive jimternet$ ls -l\ntotal 288\n-rwxr-xr-x  1 jimternet  staff   24067 Apr 19 23:27 azkaban-hadoopsecuritymanager-2.5.0-rc3.jar\n-rwxr-xr-x  1 jimternet  staff  113745 Apr 19 23:27 azkaban-jobtype-2.5.0-rc3.jar\n-rwxr-xr-x@ 1 jimternet  staff     211 Apr 19 23:27 plugin.properties\n-rwxr-xr-x@ 1 jimternet  staff     453 Apr 19 23:27 private.properties\n. Multiple times.\n. Is there a place to download the 2.5 plugins? \n. David, \nreally? Maybe I should/could try with those and see if it works.\n. Last login: Mon Apr 21 14:28:39 on ttys005\njimternets-MacBook-Pro:bin jimternet$ sh \nazkaban-access.log        azkaban-solo-start.sh     data/                     projects/\nazkaban-solo-shutdown.sh  azkaban-webserver.log     executions/               temp/\njimternets-MacBook-Pro:bin jimternet$ sh \nazkaban-access.log        azkaban-solo-start.sh     data/                     projects/\nazkaban-solo-shutdown.sh  azkaban-webserver.log     executions/               temp/\njimternets-MacBook-Pro:bin jimternet$ sh azkaban-solo-start.sh \nUsing Hadoop from /usr/share/dse-4.0.1/resources/hadoop\nUsing Hive from /usr/share/dse-4.0.1/resources/hive\n./..\n:./../lib/azkaban-2.5.0.jar:./../lib/commons-collections-3.2.1.jar:./../lib/commons-configuration-1.8.jar:./../lib/commons-dbcp-1.4.jar:./../lib/commons-dbutils-1.5.jar:./../lib/commons-email-1.2.jar:./../lib/commons-fileupload-1.2.1.jar:./../lib/commons-io-2.4.jar:./../lib/commons-jexl-2.1.1.jar:./../lib/commons-lang-2.6.jar:./../lib/commons-logging-1.1.1.jar:./../lib/commons-pool-1.6.jar:./../lib/guava-13.0.1.jar:./../lib/h2-1.3.170.jar:./../lib/httpclient-4.2.1.jar:./../lib/httpcore-4.2.1.jar:./../lib/jackson-core-asl-1.9.5.jar:./../lib/jackson-mapper-asl-1.9.5.jar:./../lib/jetty-6.1.26.jar:./../lib/jetty-util-6.1.26.jar:./../lib/joda-time-2.0.jar:./../lib/jopt-simple-4.3.jar:./../lib/log4j-1.2.16.jar:./../lib/mail-1.4.5.jar:./../lib/mysql-connector-java-5.1.28.jar:./../lib/servlet-api-2.5.jar:./../lib/slf4j-api-1.6.1.jar:./../lib/velocity-1.7.jar:./../extlib/.jar:./../plugins//.jar:/usr/share/dse-4.0.1/resources/hadoop/conf:/usr/share/dse-4.0.1/resources/hadoop/:/usr/share/dse-4.0.1/resources/hive/conf:/usr/share/dse-4.0.1/resources/hive/lib/*\njimternets-MacBook-Pro:bin jimternet$ 2014/04/21 20:39:46.247 -0500 INFO [AzkabanWebServer] [Azkaban] Starting Azkaban Server\n2014/04/21 20:39:46.268 -0500 INFO [AzkabanServer] [Azkaban] Loading azkaban settings file from ./../conf\n2014/04/21 20:39:46.268 -0500 INFO [AzkabanServer] [Azkaban] Loading azkaban private properties file\n2014/04/21 20:39:46.272 -0500 INFO [AzkabanServer] [Azkaban] Loading azkaban properties file\n2014/04/21 20:39:46.272 -0500 INFO [AzkabanWebServer] [Azkaban] updateDB :true\n2014/04/21 20:39:46.272 -0500 INFO [AzkabanWebServer] [Azkaban] scriptDir :/Users/jimternet/azkaban-solo-server-2.5.0/sql\n2014/04/21 20:39:46.273 -0500 INFO [AzkabanDatabaseUpdater] [Azkaban] Use scripting directory /Users/jimternet/azkaban-solo-server-2.5.0/sql\n2014/04/21 20:39:46.273 -0500 INFO [AzkabanDatabaseUpdater] [Azkaban] Will auto update any changes.\n2014/04/21 20:39:46.299 -0500 INFO [AzkabanDatabaseSetup] [Azkaban] Searching for installed tables\n2014/04/21 20:39:46.631 -0500 INFO [AzkabanDatabaseSetup] [Azkaban] Searching for table versions in the properties table\n2014/04/21 20:39:46.642 -0500 INFO [AzkabanDatabaseUpdater] [Azkaban] Everything looks up to date.\n2014/04/21 20:39:46.653 -0500 ERROR [AzkabanWebServer] [Azkaban] Starting Jetty Azkaban Executor...\n2014/04/21 20:39:46.654 -0500 INFO [AzkabanServer] [Azkaban] Loading azkaban settings file from ./../conf\n2014/04/21 20:39:46.654 -0500 INFO [AzkabanServer] [Azkaban] Loading azkaban private properties file\n2014/04/21 20:39:46.654 -0500 INFO [AzkabanServer] [Azkaban] Loading azkaban properties file\nSLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\nSLF4J: Defaulting to no-operation (NOP) logger implementation\nSLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n2014/04/21 20:39:46.711 -0500 INFO [AzkabanWebServer] [Azkaban] Loading user manager class azkaban.user.XmlUserManager\n2014/04/21 20:39:46.773 -0500 INFO [XmlUserManager] [Azkaban] Loading user azkaban\n2014/04/21 20:39:46.777 -0500 INFO [XmlUserManager] [Azkaban] Loading user metrics\n2014/04/21 20:39:46.809 -0500 INFO [ExecutorManager] [Azkaban] Cleaning old logs from execution_logs\n2014/04/21 20:39:46.809 -0500 INFO [AzkabanWebServer] [Azkaban] Loading JDBC for project management\n2014/04/21 20:39:46.814 -0500 INFO [ProjectManager] [Azkaban] Project version retention is set to 3\n2014/04/21 20:39:46.885 -0500 INFO [ExecutorManager] [Azkaban] Cleaning old log files before 2014-01-27T19:39:46.821-06:00\n2014/04/21 20:39:46.887 -0500 INFO [ExecutorManager] [Azkaban] Cleaned up 0 log entries.\n2014/04/21 20:39:47.087 -0500 INFO [TriggerManager] [Azkaban] TriggerManager loaded.\n2014/04/21 20:39:47.087 -0500 INFO [AzkabanWebServer] [Azkaban] Loading built-in checker and action types\n2014/04/21 20:39:47.092 -0500 INFO [CheckerTypeLoader] [Azkaban] Registering checker BasicTimeChecker\n2014/04/21 20:39:47.093 -0500 INFO [CheckerTypeLoader] [Azkaban] Registering checker SlaChecker\n2014/04/21 20:39:47.093 -0500 INFO [CheckerTypeLoader] [Azkaban] Registering checker ExecutionChecker\n2014/04/21 20:39:47.093 -0500 INFO [ActionTypeLoader] [Azkaban] Registering action ExecuteFlowAction\n2014/04/21 20:39:47.093 -0500 INFO [ActionTypeLoader] [Azkaban] Registering action KillExecutionAction\n2014/04/21 20:39:47.093 -0500 INFO [ActionTypeLoader] [Azkaban] Registering action AlertAction\n2014/04/21 20:39:47.093 -0500 INFO [ActionTypeLoader] [Azkaban] Registering action CreateTriggerAction\n2014/04/21 20:39:47.093 -0500 INFO [AzkabanWebServer] [Azkaban] Loading trigger based scheduler\n2014/04/21 20:39:47.097 -0500 INFO [AzkabanWebServer] [Azkaban] Loading plug-in checker and action types\n2014/04/21 20:39:47.097 -0500 ERROR [AzkabanWebServer] [Azkaban] plugin path plugins/triggers doesn't exist!\n2014/04/21 20:39:47.099 -0500 INFO [AzkabanWebServer] [Azkaban] Setting timezone to America/Los_Angeles\n2014/04/21 20:39:47.100 -0500 INFO [AzkabanWebServer] [Azkaban] Registering MBeans...\n2014/04/21 20:39:47.112 -0500 INFO [AzkabanWebServer] [Azkaban] Bean azkaban.jmx.JmxJettyServer registered.\n2014/04/21 20:39:47.114 -0500 INFO [AzkabanWebServer] [Azkaban] Bean azkaban.jmx.JmxTriggerManager registered.\n2014/04/21 20:39:47.116 -0500 INFO [AzkabanWebServer] [Azkaban] Bean azkaban.jmx.JmxExecutorManager registered.\n2014/04/21 20:39:47.116 -0500 INFO [AzkabanDatabaseSetup] [Azkaban] Searching for installed tables\n2014/04/21 20:39:47.120 -0500 INFO [AzkabanDatabaseSetup] [Azkaban] Searching for table versions in the properties table\n2014/04/21 20:39:47.126 -0500 INFO [AzkabanWebServer] [Azkaban] Setting up web resource dir /Users/jimternet/azkaban-solo-server-2.5.0/web\n2014/04/21 20:39:47.189 -0500 INFO [JdbcTriggerLoader] [Azkaban] Loading all triggers from db.\n2014/04/21 20:39:47.190 -0500 INFO [JdbcTriggerLoader] [Azkaban] Loaded 0 triggers.\n2014/04/21 20:39:47.232 -0500 INFO [AzkabanWebServer] [Azkaban] Server running on  port 8081.\n2014/04/21 20:39:47.232 -0500 INFO [AzkabanWebServer] [Azkaban] Azkaban Web Server started...\n2014/04/21 20:39:47.233 -0500 ERROR [AzkabanExecutorServer] [Azkaban] Starting Jetty Azkaban Executor...\n2014/04/21 20:39:47.233 -0500 INFO [AzkabanServer] [Azkaban] Loading azkaban settings file from ./../conf\n2014/04/21 20:39:47.233 -0500 INFO [AzkabanServer] [Azkaban] Loading azkaban private properties file\n2014/04/21 20:39:47.233 -0500 INFO [AzkabanServer] [Azkaban] Loading azkaban properties file\n2014/04/21 20:39:47.233 -0500 INFO [AzkabanExecutorServer] [Azkaban] Setting timezone to America/Los_Angeles\n2014/04/21 20:39:47.238 -0500 INFO [FlowRunnerManager] [Azkaban] Execution dir retention set to 86400000 ms\n2014/04/21 20:39:47.243 -0500 INFO [FlowRunnerManager] [Azkaban] Cleaning recently finished\n2014/04/21 20:39:47.243 -0500 INFO [FlowRunnerManager] [Azkaban] Cleaning old projects\n2014/04/21 20:39:47.243 -0500 INFO [FlowRunnerManager] [Azkaban] Cleaning old execution dirs\n2014/04/21 20:39:47.248 -0500 INFO [AzkabanExecutorServer] [Azkaban] Registering MBeans...\n2014/04/21 20:39:47.249 -0500 INFO [AzkabanExecutorServer] [Azkaban] Bean azkaban.jmx.JmxJettyServer registered.\n2014/04/21 20:39:47.251 -0500 INFO [AzkabanExecutorServer] [Azkaban] Bean azkaban.jmx.JmxFlowRunnerManager registered.\n2014/04/21 20:39:47.251 -0500 INFO [AzkabanExecutorServer] [Azkaban] Azkaban Executor Server started on port 12321\n2014/04/21 20:39:47.252 -0500 INFO [AzkabanWebServer] [Azkaban] Azkaban Exec Server started...\n. 21-04-2014 19:16:18 PDT hive-dse-demo ERROR - Failed to build job executor for job hive-dse-demoJob type 'hive' is unrecognized. Could not construct job[{azkaban.job.attachment.file: /Users/jimternet/azkaban-solo-server-2.5.0/bin/executions/35/_job.35.hive-dse-demo.attach, hive.query: drop table words;, dependencies: hivealias, working.dir: /Users/jimternet/azkaban-solo-server-2.5.0/bin/executions/35, azkaban.job.metadata.file: _job.35.hive-dse-demo.meta, azk.hive.action: execute.query, azkaban.job.attempt: 0, type: hive, user.to.proxy: jimternet,  parent = { parent = {azkaban.flow.flowid: hive-dse-demo, azkaban.flow.execid: 35, azkaban.flow.start.timezone: America/Los_Angeles, azkaban.flow.start.hour: 19, azkaban.flow.start.second: 18, azkaban.flow.start.year: 2014, azkaban.flow.start.milliseconds: 078, azkaban.flow.start.minute: 16, azkaban.flow.start.timestamp: 2014-04-21T19:16:18.078-07:00, azkaban.flow.start.month: 04, azkaban.flow.projectversion: 1, azkaban.flow.projectid: 3, azkaban.flow.uuid: 34ba0bea-5639-410a-a482-8cbae07f08a9, azkaban.flow.start.day: 21,  parent = {}}}}] of type[hive].\n. I just updated. still no dice :(\n21-04-2014 22:03:26 PDT hive-demo ERROR - Failed to build job executor for job hive-demoJob type 'hive' is unrecognized. Could not construct job[{hive.query.01: drop table words;, hive.query.03: describe words;, hive.query.02: create table words (freq int, word string) row format delimited fields terminated by '   ' stored as textfile;, azkaban.job.attachment.file: /Users/jimternet/azkaban-solo-2.5.0/bin/executions/1/job.1.hive-demo.attach, working.dir: /Users/jimternet/azkaban-solo-2.5.0/bin/executions/1, azkaban.job.metadata.file: _job.1.hive-demo.meta, azk.hive.action: execute.query, azkaban.job.attempt: 0, type: hive, hive.query.05: select * from words limit 10;, hive.query.04: load data local inpath \"res/input\" into table words;, user.to.proxy: azkaban, hive.query.06: select freq, count(1) as f2 from words group by freq sort by f2 desc limit 10;,  parent = {azkaban.flow.flowid: hive-demo, azkaban.flow.execid: 1, azkaban.flow.start.timezone: America/Los_Angeles, azkaban.flow.start.hour: 22, azkaban.flow.start.second: 26, azkaban.flow.start.year: 2014, azkaban.flow.start.milliseconds: 738, azkaban.flow.start.minute: 03, azkaban.flow.start.timestamp: 2014-04-21T22:03:26.738-07:00, azkaban.flow.start.month: 04, azkaban.flow.projectversion: 1, azkaban.flow.projectid: 1, azkaban.flow.uuid: 5e55a384-ac6e-4032-aa8c-fd0c0f286d80, azkaban.flow.start.day: 21,  parent = {}}}] of type[hive].\n. I think I left out something important. I'm trying to use Datastax Hadoop.\n. I got the plugin to try to start.. but now it's getting stuck on something else.\n. 22-04-2014 00:36:08 PDT hive-demo INFO - Starting job hive-demo at 1398152168373\n22-04-2014 00:36:08 PDT hive-demo INFO - Building hive job executor. \n22-04-2014 00:36:08 PDT hive-demo INFO - Not setting up secure proxy info for child process\n22-04-2014 00:36:08 PDT hive-demo INFO - No classpath specified. Trying to load classes from /Users/jimternet/azkaban-solo-2.5.0/bin/executions/51\n22-04-2014 00:36:08 PDT hive-demo INFO - 1 commands to execute.\n22-04-2014 00:36:08 PDT hive-demo INFO - Command: java  -Dhive.querylog.location=. -Dhive.exec.scratchdir=/tmp/hive-jimternet -Xms64M -Xmx256M -cp /Users/jimternet/azkaban-solo-2.5.0/lib/azkaban-2.5.0.jar:/Users/jimternet/azkaban-solo-2.5.0/bin/../plugins/jobtypes/hive/azkaban-jobtype-2.5.0.jar:/Users/jimternet/azkaban-solo-2.5.0/bin/../plugins/jobtypes/hive/azkaban-hadoopsecuritymanager-2.5.0.jar:/usr/share/dse-4.0.1/resources/hadoop/conf:/usr/share/dse-4.0.1/resources/hadoop/lib/:/usr/share/dse-4.0.1/resources/hive/lib/_:/usr/share/dse-4.0.1/resources/hive/conf:/usr/share/dse-4.0.1/resources/hadoop/hadoop-core-1.0.4.9.jar:/usr/share/dse-4.0.1/resources/hive/conf/:/usr/share/dse-4.0.1/resources/hadoop/*:/usr/share/dse-4.0.1/resources/hadoop/conf/:/usr/share/dse-4.0.1/bin/dse-4.0.1.jar azkaban.jobtype.HadoopSecureHiveWrapper -f select * from esv.retailproduct; \n22-04-2014 00:36:08 PDT hive-demo INFO - Environment variables: {JOB_NAME=hive-demo, JOB_PROP_FILE=/Users/jimternet/azkaban-solo-2.5.0/bin/executions/51/hive-demo_props_1477616953959423368_tmp, JOB_OUTPUT_PROP_FILE=/Users/jimternet/azkaban-solo-2.5.0/bin/executions/51/hive-demo_output_2945140915311815610_tmp}\n22-04-2014 00:36:08 PDT hive-demo INFO - Working directory: /Users/jimternet/azkaban-solo-2.5.0/bin/executions/51\n22-04-2014 00:36:08 PDT hive-demo ERROR - 2014-04-22 02:36:08.684 java[2312:1903] Unable to load realm info from SCDynamicStore\n22-04-2014 00:36:08 PDT hive-demo INFO - 2014/04/22 02:36:08.776 -0500 INFO [root] [Azkaban] Not proxying. \n22-04-2014 00:36:08 PDT hive-demo INFO - 2014/04/22 02:36:08.963 -0500 INFO [root] [Azkaban] HiveConf = Configuration: core-default.xml, dse-core-default.xml, dse-core.xml, core-site.xml, mapred-default.xml, dse-mapred-default.xml, mapred-site.xml, org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@56d0c5bb, file:/usr/share/dse-4.0.1/resources/hive/conf/hive-site.xml\n22-04-2014 00:36:08 PDT hive-demo INFO - 2014/04/22 02:36:08.963 -0500 INFO [root] [Azkaban] According to the conf, we're talking to the Hive hosted at: jdbc:derby:;databaseName=metastore_db;create=true\n22-04-2014 00:36:08 PDT hive-demo INFO - 2014/04/22 02:36:08.963 -0500 INFO [root] [Azkaban] No files in to expand in aux jar path. Returning original parameter\n22-04-2014 00:36:08 PDT hive-demo INFO - 2014/04/22 02:36:08.963 -0500 INFO [root] [Azkaban] Hive aux jars variable not expanded\n22-04-2014 00:36:08 PDT hive-demo INFO - 2014/04/22 02:36:08.987 -0500 INFO [root] [Azkaban] Got auxJars = \n22-04-2014 00:36:09 PDT hive-demo INFO - 2014/04/22 02:36:09.030 -0500 WARN [NativeCodeLoader] [Azkaban] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n22-04-2014 00:36:09 PDT hive-demo INFO - 2014/04/22 02:36:09.098 -0500 INFO [root] [Azkaban] SessionState = org.apache.hadoop.hive.cli.CliSessionState@49b69954\n22-04-2014 00:36:09 PDT hive-demo INFO - 2014/04/22 02:36:09.099 -0500 INFO [root] [Azkaban] Executing query: select * from esv.retailproduct;\n22-04-2014 00:36:09 PDT hive-demo ERROR - Exception in thread \"main\" java.io.FileNotFoundException: select * from esv.retailproduct; (No such file or directory)\n22-04-2014 00:36:09 PDT hive-demo ERROR -   at java.io.FileInputStream.open(Native Method)\n22-04-2014 00:36:09 PDT hive-demo ERROR -   at java.io.FileInputStream.(FileInputStream.java:146)\n22-04-2014 00:36:09 PDT hive-demo ERROR -   at java.io.FileInputStream.(FileInputStream.java:101)\n22-04-2014 00:36:09 PDT hive-demo ERROR -   at java.io.FileReader.(FileReader.java:58)\n22-04-2014 00:36:09 PDT hive-demo ERROR -   at org.apache.hadoop.hive.cli.CliDriver.processFile(CliDriver.java:454)\n22-04-2014 00:36:09 PDT hive-demo ERROR -   at azkaban.jobtype.HadoopSecureHiveWrapper.runHive(HadoopSecureHiveWrapper.java:190)\n22-04-2014 00:36:09 PDT hive-demo ERROR -   at azkaban.jobtype.HadoopSecureHiveWrapper.main(HadoopSecureHiveWrapper.java:115)\n22-04-2014 00:36:09 PDT hive-demo INFO - Process completed unsuccessfully in 0 seconds.\n22-04-2014 00:36:09 PDT hive-demo ERROR - caught exception running the job\n22-04-2014 00:36:09 PDT hive-demo ERROR - Job run failed!\n22-04-2014 00:36:09 PDT hive-demo ERROR - java.lang.RuntimeException: azkaban.jobExecutor.utils.process.ProcessFailureExceptionjava.lang.RuntimeException: azkaban.jobExecutor.utils.process.ProcessFailureException\n22-04-2014 00:36:09 PDT hive-demo INFO - Finishing job hive-demo at 1398152169127 with status FAILED\n. Where is this line coming from ?\n22-04-2014 01:19:01 PDT hive-demo INFO - 2014/04/22 03:19:01.798 -0500 INFO [root] [Azkaban] According to the conf, we're talking to the Hive hosted at: jdbc:derby:;databaseName=metastore_db;create=true\n. ",
    "rjurney": "This is a very common practice, for all job types. The last hour's data has finished arriving, and now you want to process it. Same for day, week, etc. I think it merits inclusion.\nThe common way to achieve this is to run a script as a \"command\" type that calculates the time period as an environment variable. The problem is that these environment variables don't persist between actual Java/Pig jobs, so you have to have many such scripts. This makes it difficult to persist the time in a way that it remains constant throughout the steps of a flow when the time period changes while the script is running (as in one hour to the next).\nI've spoken with several Azkaban users, and they all have this problem.\n. I think I already have. Any time you want to process data that finished arriving at the start of this (time period), you need a (last blank) datetime parameter. For example: \"every hour, run a script that operates on data from the previous hour\" is the most common Azkaban use case there is.  As I said, I think most Azkaban users have this use case, based on talking to several and my experience at LinkedIn. I've talked to LinkedIn users of Azkaban that have this problem. Do you not personally see it?\n. I think definitely having addition/subtraction, etc. is the right way to go. However, I am not up for implementing that. I don't know how, and I need one hour/day back. So this seems the best solution I can deliver, for a very common use case. Does anyone have a proposed way to implement simple expressions?\nAdmittedly, last year is not going to be used much, I just put it there for consistency. Can see it being used for annual reports.\nOne can compute one's own numbers, but one sacrifices restarting flows, and every other node in a flow has to be a command that re-generates the timestamps. This makes Azkaban pretty terrible to use. And many (if not most) people have to use it this way.\n. Can you add this as the first feature of the DSL and get it out quickly, or are we looking at a major release cycle?\n. Awesome, thanks!\n. Awesome! I will pull at test. Can you summarize how it works briefly?\n. Is this in master? Where can I get the patch and test it out?\nOn Wed, Apr 30, 2014 at 1:17 PM, Richard B Park notifications@github.comwrote:\n\nSure. $( expression). Variable replacement works so $(${day} - 1). Or nest\nexpressions in expressions.\nOn Wednesday, April 30, 2014, Russell Jurney notifications@github.com\nwrote:\n\nAwesome! I will pull at test. Can you summarize how it works briefly?\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/azkaban/azkaban2/pull/224#issuecomment-41844570>\n.\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/pull/224#issuecomment-41844943\n.\n\n\nRussell Jurney twitter.com/rjurney russell.jurney@gmail.com datasyndrome.com\n. Crap, one thing... does the arithmetic know about dates? For instance, for\nthe data 2014-04-30... +1 is 5-1? Or 31? Ugh, don't think this is simple.\nOn Wed, Apr 30, 2014 at 1:49 PM, David Z. Chen notifications@github.comwrote:\n\nYes, the change is in master now.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban2/pull/224#issuecomment-41848448\n.\n\n\nRussell Jurney twitter.com/rjurney russell.jurney@gmail.com datasyndrome.com\n. Upon further reflection, it seems that if this patch doesn't know about datetimes, it won't satisfy the requirements. Thoughts?\n. Since datetime math isn't included in the planned Azkaban DSL, can we please merge this commit? The majority of Azkaban users will use this feature.\n. ",
    "pranayhasan": "https://github.com/linkedin/linkedin-gradle-plugin-for-apache-hadoop. @suvodeep-pyne azkaban-solo-server has a transitive dependency on azkaban-common sub-project as can be seen in azkaban-solo-server/build.gradle.\n. @HappyRay This was done as a part of blocking zip uploads by maintaining a whitelist of users and projects where some custom validation was required. If we are NOT looking to add any validation in Azkaban, we are good to close this. . @suvodeep-pyne I wonder if we can refactor an interface, as it breaks all implementations of ProjectValidator interface, if there are any outside Linkedin. It is considered a good practice to extend interfaces in general or else create a new interface altogether.\nIn my view, the MetadataValidator defined above is generic enough to do any validation at a project level. The zip uploaded is at a project level, so the validation can only be done at a project level in Azkaban. We have to add a class Metadata and add generic types to it to be passed as a parameter to validateProject() method.\n@HappyRay What do you think?\n. You can declare job dependencies only inside a workflow in Azakaban. Currently, Azkaban doesn't support dependencies across projects or workflows.\n. It is the latest version in artifactory\n. Done\n. Yes, it is the ID of the latest uploader who tried uploading to azkaban be it successful/not. It is transient as there is no DB update. There exists a field lastModifiedUser which gets persisted after the upload succeeds and is fetched from the DB.\nWhat do you mean by all code paths? Why do you think it is optional?\n. Basically we want to have a list of projects and users who are allowed to upload to a cluster. Seems that your concern is that this authorization is cluster specific and not project specific. And so why do we want to include the uploader information in Project? Yes, you are right. \nFor this we need a Cluster Admin who can have a whitelist/blacklist of projects and users who are allowed to upload. Azkaban has users with Admin access and no cluster Admin, so how do we do it?\nProject Validation:\nWe already have a ProjectValidator interface which makes azkaban-plugins to implement project specific validation. So, we can use it to whitelist projects. No changes need in Azkaban for doing this.\nUser Validation:\nWe can have a new GenericValidator interface, which takes some specific metadata and validates on it. We pass the current user uploading zip to this and validate it. Also, if we want to validate on specific use-case in the future, if would be easy to add to this metadata.\nDoes this sound good?\n. @HappyRay Created an issue to discuss GenericValidator\n. Currently, the open-source Hadoop Plugin which has an azkaban client is performing b. re-login if it gets an authentication error in most of the Gradle tasks it supports. \n@mtrna As we've discussed in https://github.com/linkedin/linkedin-gradle-plugin-for-apache-hadoop/pull/199 the Hadoop Plugin checks if authentication is valid by making an API call to createProject and then to upload. \nRef: https://github.com/linkedin/linkedin-gradle-plugin-for-apache-hadoop/blob/master/hadoop-plugin/src/main/groovy/com/linkedin/gradle/azkaban/AzkabanUploadTask.groovy#L66\nLet us know if you have a different use-case which shall help clients with information about TTL.. ",
    "convexquad": "LinkedIn JIRA issue HADOOP-5301\n. Since there are some problems with this Pull Request, we made the decision not to include this with the main Azkaban code. Closing this Pull Request.\n. No, there is an existing check to see if the user from session can write to the project. In this case (at LinkedIn), it means that the CRT user must be logged in successfully to write to a project. Nobody can easily spoof logging in as the CRT user.\nHowever, if the deployment configured is mixed up and Joe requests a deployment, the CRT user might overwrite Bob's project with Joe's zip file. This patch adds a secondary check to verify that both CRT and Joe can write to Bob's projects (but Joe can't write to Bob's project, so it correctly fails).\n. I think the best long-term design would be a separate Permissions Rest.li resource.\nIn this resource, it checks if the logged in user (CRT) can read the project. Then it checks if the specified user (Joe) has some permissions property (write) on the project. We could make a call to this endpoint in my deployment script.\nIt might take a while to properly design such a service, so perhaps in the interest of finishing the CRT deployments, we could consider this Pull Request a stopgap.\n. ",
    "ft20082": "i resolve the problem.. ",
    "wagnermarkd": "Yup. Didn't get linked to the PR. Apologies.\n. This actually preserves that separation. The goal of including the URLs is not to answer \"Who submitted this execution?\" and thereby restrict the possible frontends, but rather \"Where can I find information about this job/flow/execution?\". This is exactly the role of the webserver so that seems to be the appropriate place to reference.\n. I've opened a new PR #259 for this.\n. There's a refresh button on the log page, which is what the message is referring to. Without this timeout, that button is unnecessary. Please remove it.\n. ",
    "wyukawa": "Thank you for merging!\n. I think that it is right to use \"jetty.use.ssl\" in order to avoid hardcording, too.\n. The Travis CI build failed, but succeed in my local envirionment.\nSorry, I don't understand why...\n. rebase done\n. OK, I added.\n. I update ReportalMailCreator.\nhttps://github.com/azkaban/azkaban-plugins/pull/100\n. Rebase for master changes.\n@fsi206914 @suvodeep-pyne ping. Thank you for merging.\nMy opinion is as follows.\nHmm, in my current usage, I use /manager API with project name, as result I get project ID.\nhttps://github.com/wyukawa/eboshi/blob/master/eboshi/project.py\nAnd then I use /schedule API with project name and project ID.\nhttps://github.com/wyukawa/eboshi/blob/master/eboshi/add_schedule.py\nAlthough current API desigin requires more cost because project ID is necessary, I don't think about introducing more opportunities for clients to make mistakes.\nAnd compatibility is important.\nThanks. +1. This change makes sense to me.\nUsers can see job status more clearly when job failed.\nCurrently, queued jobs were not shown when job failed.\nSo, sometimes, I confused.. Any progress?. I confirmed that this problem was resolved in azkaban-solo-server-3.15.0-1-g77411d7.. If you access http://localhost:8081/stats, you can confirm.\n/stats endpoint is the following.\nhttps://github.com/azkaban/azkaban/blob/master/azkaban-web-server/src/main/java/azkaban/webapp/AzkabanWebServer.java#L810. No, I confirm at azkaban-web and azkaban-executor mode.. If I check log after adding https://github.com/azkaban/azkaban/pull/890, there is the following stacktrace.\njava.io.IOException: MetricReportManager is not available\n    at azkaban.executor.ExecutorManager.callExecutorForJsonObject(ExecutorManager.java:1144)\n    at azkaban.executor.ExecutorManager.callExecutorStats(ExecutorManager.java:1193)\n    at azkaban.webapp.servlet.StatsServlet.handleStatePageLoad(StatsServlet.java:195)\n    at azkaban.webapp.servlet.StatsServlet.handleGet(StatsServlet.java:70)\n    at azkaban.webapp.servlet.LoginAbstractAzkabanServlet.doGet(LoginAbstractAzkabanServlet.java:122)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:668)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:770)\n    at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)\n    at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:401)\n    at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\n    at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n    at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n    at org.mortbay.jetty.Server.handle(Server.java:326)\n    at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\n    at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)\n    at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)\n    at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n    at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n    at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)\n    at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\nfail to access to executor /stats\n$ curl http://localhost:12321/stats?action=getAllMetricNames\n{\n  \"error\" : \"MetricReportManager is not available\"\n}. ah, I see. Thanks!. Thanks!. Ah, It seems good.\nI agree with you.\nBy the way, FailureAction is also same situation. I want to set FINISH_ALL_POSSIBLE.\nAnyway, thanks!. You are right. I changed the commit message.\nOnly exception message is not enought to debug.\nStacktrace is also important to debug.\nBy the way,when I encountered the following error, I did't understand the cause well.\nThis is the reason why I sent this pull request.\n2017-02-09 16:08:38 INFO  ExecutorServlet:120 - User  has called action log on 3285\n2017-02-09 16:08:38 ERROR ExecutorServlet:191 - azkaban.executor.ExecutorManagerException: Running flow 3285 not found.\n2017-02-09 16:08:38 INFO  ExecutorServlet:120 - User  has called action log on 3285\n2017-02-09 16:08:38 ERROR ExecutorServlet:191 - azkaban.executor.ExecutorManagerException: Running flow 3285 not found.\nAt this time, azkaban job was successful, it was not problem.\nI guess this error is the concurrency problem related to ConcurrentHashMap(runningFlows).\n. Thanks!. @HappyRay Could you check this pull request?. rebase done. >Are you still interested in this PR?\nYes. @HappyRay, the PR is up-to-date now.. Thanks!. @HappyRay Could you check this pull request?. Yes.\nIn my use case, I add a schedule through api.\nIn addition, I want to set SLA.. rebase done. ping?. Thank you for comment!\nFirst of all, let me explain my use case.\nIn my use case, I set schedule date through API, not using web browser because I want to maintein schedule informaion in GitHub.\nOur Azkaban job management is the following\nhttps://www.slideshare.net/wyukawa/azkabanen/17\nAnd I set Failure Options when I set schdule data.\nAlthough Azkaban default setting of Failure Options is \"Finish Current Running\", I want to set \"Finish All Possible\".\nAs a result, I use schedule API and then set schedule information and Failure Options at the same time.\nI created Azkaban API Client \"eboshi\" (https://github.com/wyukawa/eboshi) and use the following way.\neboshi addCronSchedule --url http://localhost:8081 --username azkaban --password azkaban --project azkaban_project --flow azkaban_flow --cron '0 10 * * *' --option '{\"failureAction\":\"finishPossible\"}'\nIn addition to this, I want to set SLA option.\nIn other words, I want to set schedule information(for example, '0 10 *  ') and Failure Options and SLA option at the same time.\nThis is the reason why I send this pull request.\nOf course, I understand what you said.\nBut If we can set SLA Option during scheduling, it would be useful.. Thank you for comment.\nYour thought is the following.\nCurrent schedule APIs(ajaxScheduleFlow and ajaxScheduleCronFlow method) return the schedule Id.\nSo user can use SLA API(ajaxSetSla method ) by using this schedule Id.\nAlthough user need to call two APIs, APIs are simple and easy to test.\nAnd SLA should be set after a schedule is set.\nIs that right?\nIf I understand correctly, you are right and I accept this pull request doesn't be merged.\n\nIs it too much work on the client side or multiple call latency a big issue in your case?\n\nMaybe No\nIf I have a time, I will try to create SLA API document.\nThanks. Thank you for your clarification. Sorry, I'm not sure.\nIf I understand correctly,  web server and executor use the same MySQL DB.\nIs that right?\nI don't talk about azkaban solo mode, H2DB.\nMy request is to simplify to deploy azkaban(two server mode).\nThanks.. Now, I do the following steps to deploy Azkaban after I build source codes and setup mysql.\nmkdir azkaban-web-server-${version}/conf\nvim azkaban-web-server-${version}/conf/azkaban.properties\nvim azkaban-web-server-${version}/conf/azkaban-users.xml\nvim azkaban-web-server-${version}/conf/log4j.properties\nazkaban-web-server-${version}/bin/azkaban-web-start.sh\nmkdir azkaban-exec-server-${version}/conf\nvim azkaban-web-server-${version}/conf/azkaban.properties\nvim azkaban-web-server-${version}/conf/log4j.properties\nmkdir azkaban-exec-server-${version}/plugins/jobtypes/\nvim azkaban-exec-server-${version}/plugins/jobtypes/commonprivate.properties\nazkaban-exec-server-${version}/bin/azkaban-executor-start.sh\nIf this steps are simplified, it would be nice.. Thanks!. I see.\nI fixed in https://github.com/azkaban/azkaban/pull/962/commits/4dd668fe00a3d6e03ca4dd72ed493f2e80698d68. Thanks!. Thanks!. Thanks!\n\nwe are planning to add these configurations in the flow config files\n\nSounds good!\n. ping. Thanks!. @jamiesjc \nOh, I use loadFlow API because I want to get all schedule data.\nhttps://github.com/wyukawa/eboshi/blob/master/eboshi/schedule.py#L18\nIs there alternative API?. send pull request https://github.com/azkaban/azkaban/pull/1219. @HappyRay Could you please take a look at this pull request when you get a chance?. Thanks!. I'm using the single executor mode.\nIn my environment, azkaban web server and executor and batch program are on the same machine.\nbatch program must be executed on the specified machine.\nfor example, hive job must be executed in the machine where hive client is installed.\nIf there is no support for the two server mode, migration guide will be helpful.\nThanks. @reallocf That's right. for example, is it possible to setup multiple executor mode in single machine?\nor do I need to setup in two machines(but acctually, one executor is not used) and use \"useExecutor\" = EXECUTOR_ID?. I have thought about job.succeed.on.failure=true in some case.\nfor example, although job A doesn't depend on job B, I want to execute A after B to avoid high load average.\nIn this case, this setting is useful.\nbut, if job A fails, the eventual flow status become to be SUCCEEDED.\nIn my opinion the eventual flow status should not be marked to be SUCCEEDED.\nAnyway, job.succeed.on.failure option should be documented.\nThanks. Thanks!. I use loadFlow API to get all schedules, but actually I think that the name is misleading.... Thanks!. @jamiesjc \nNo concern.\nThank you for fixing my bug.. Looks like it overlaps with #873 #915. @kunkun-tang @HappyRay Can you take a look at this pull request when you get a chance?\nI guess this is a simple issue.. @HappyRay @reallocf Thank you for comments!\nI add unit test.\nplease check.. @HappyRay @reallocf Could you please check?. @kunkun-tang hmm, test passes in my local environment.\nWhat can I do?. hmm, CI doesn't work well.... I don't know why CI failed...\nazkaban.metric.MetricManagerTest > managerEmitterHandlingTest FAILED\n    java.lang.AssertionError: Failed to report metric expected:<1> but was:<0>\n        at org.junit.Assert.fail(Assert.java:88)\n        at org.junit.Assert.failNotEquals(Assert.java:834)\n        at org.junit.Assert.assertEquals(Assert.java:645)\n        at azkaban.metric.MetricManagerTest.managerEmitterHandlingTest(MetricManagerTest.java:92)\nMy forked repository pass tests.\nhttps://travis-ci.org/wyukawa/azkaban/builds/364027602\nAny ideas?\n. Is https://github.com/azkaban/azkaban/issues/1725 related?. @kunkun-tang https://github.com/azkaban/azkaban/pull/1735 resolved the CI issue. please check.. Thanks!. It seems to be related to https://github.com/azkaban/azkaban/pull/1650. maybe fixed in https://github.com/azkaban/azkaban/pull/1685. I adapt the following coding style in ScheduleServlet\nExecutionOptions flowOptions = null;\n    try {\n      flowOptions = HttpRequestUtils.parseFlowOptions(req);\n      HttpRequestUtils.filterAdminOnlyFlowParams(userManager, flowOptions, user);\n    } catch (Exception e) {\n      ret.put(\"error\", e.getMessage());\n    }\nOf course, it's possible to catch ServletException, instead of Exception. Thanks!. Hmm, generally speaking, if user requests wrongly, server should return 4xx(for example, 400 Bad Request).\nIf there are some bugs, server should return 5xx.\nBut before you fix it in that way, I prefer to add stacktrace(for example, https://github.com/azkaban/azkaban/pull/890, https://github.com/azkaban/azkaban/pull/905)\nRegarding stacktrace, I will to send pull request later.. Regarding stacktrace, I sent pull request.\nhttps://github.com/azkaban/azkaban/pull/962. if colspan=\"11\" and there is no schedule, screenshot is as follows because 1 column(Execution Options) is added. Thanks!\n. hmm, it seems to be difficult because this is the servlet and we need to delete project.... @kunkun-tang Thank you for comment!\nI fixed in https://github.com/azkaban/azkaban/pull/1638/commits/e300bc90f67ff1f4247f154b5006905e51fcdfe1. ",
    "rohitsm": "This report is rather old and this bug has since been since fixed (checked with version 3.68).\nThe description limit is now capped at 2048 which is the maximum length of the the description column in the projects table as shown below:\nOriginal DDL script: https://github.com/azkaban/azkaban/blob/master/azkaban-db/src/main/sql/create.projects.sql\nsql\nmysql> describe projects;\n+------------------+---------------+------+-----+---------+----------------+\n| Field            | Type          | Null | Key | Default | Extra          |\n+------------------+---------------+------+-----+---------+----------------+\n| id               | int(11)       | NO   | PRI | NULL    | auto_increment |\n| name             | varchar(64)   | NO   | MUL | NULL    |                |\n| active           | tinyint(1)    | YES  |     | NULL    |                |\n| modified_time    | bigint(20)    | NO   |     | NULL    |                |\n| create_time      | bigint(20)    | NO   |     | NULL    |                |\n| version          | int(11)       | YES  |     | NULL    |                |\n| last_modified_by | varchar(64)   | NO   |     | NULL    |                |\n| description      | varchar(2048) | YES  |     | NULL    |                |\n| enc_type         | tinyint(4)    | YES  |     | NULL    |                |\n| settings_blob    | longblob      | YES  |     | NULL    |                |\n+------------------+---------------+------+-----+---------+----------------+\n10 rows in set (0.00 sec)\nExceeding 2048 characters, the process fails with the following errors, which is far more descriptive than what the OP originally specified above. \n\n\nProject creation: Insert <NAME OF PROJECT> for existing project failed\n E.g.: Insert temp2 for existing project failed\n\n\nUpdate Description of existing project: Error update Description, project <NAME OF PROJECT>\n  E.g.: Error update Description, project Temp\n\n\nThis bug could be closed. cc: @HappyRay and @kunkun-tang \n. @xufeng2013 - I came across your post here while facing the same issue. Even though this post is old, i'll add an answer here in case it helps someone else.\nWhen an exec server is rebooted (especially when it is gracefully shutdown), the active status of the executor changes in the DB (executors table), you'll need to reload the executors for the web server to update its cached list of active executors. \nHere's how you do this. You question is related to this: https://github.com/azkaban/azkaban/issues/2077#issuecomment-464973015. If it helps, here is a two line script that I ended up using that first gets the session ID and then use that in the subsequent cURL request. \nbash\nsid=$(curl -k -X POST --data \"action=login&username=USERNAME&password=PASSWORD\" http://localhost:8081  | python -c \"import json,sys;print json.load(sys.stdin)['session.id']\")\ncurl -k --data \"session.id=${sid}\" http://localhost:8080/executor?ajax=reloadExecutors. ",
    "sathish316": "Closing this issue. Found  a better way to output params using getJobGeneratedProperties() method from azkaban logs\n. There is a Pull request open for this - https://github.com/azkaban/azkaban/pull/395\n. Makes sense. I've changed mailPort data type to int.\n. This was done with the assumption that Emailer is for SMTP and there could be other emailers in the future (for example, using Mutt) where DEFAULT_SMTP_PORT in AbstractMailer will not make sense. Anyway, i've moved constant to AbstractMailer to avoid depending on subclass.\n. Is there any update on merging this fix to master?\n. This branch is synced with master.\nThere was no automation test. It was tested by deploying a patched version of Azkaban using gmail smtp config in azkaban.properties with mail.port=587.\nPlease suggest if there is any way to write an automated test for this.\n. ",
    "suvodeep-pyne": "Cleaning up unattended / old PRs. Cleaning up unattended / old PRs. Cleaning up unattended / old PRs. Cleaning up unattended / old PRs. Cleaning up unattended / old PRs. Cleaning up unattended / old PRs. Cleaning up unattended / old PRs. This has already been added.. Cleaning up unattended / old PRs. Cleaning up unattended / old PRs. Cleaning up unattended / old PRs. Cleaning up unattended / old PRs. Cleaning up unattended / old PRs. Cleaning up unattended / old PRs. Closed as out of date. Please reopen if you think that this PR is still relevant.\n. The semver plugin requires Java 8 and therefore Java 7 builds are failing.\n. closes #695 \nI like your nick :P @HappyRay \nAnd you are most welcome. I created issue #695 and linked it.\n. Thanks @juhoautio for pointing that out! 2.2.1 works like a charm. I have updated the pull request with the changes.\n@HappyRay I think we can pull this change without moving to Java 8. Although, I think that would be a good move. \nPlease note that it would be good to create a new release tag (example 3.1.0) with this commit.\nThe version plugin is showing 2.7.0 as the base version which is incorrect since we have already released 3.0.0. This may be a bug which is happening due to the complex git history that azkaban has.\n. @HappyRay \nI created issue #696 for discussing dropping Java 7 support. Let's discuss this issue there.\n. @logiclord : Thanks Gaurav! This has been merged already into master.\nClosing this issue.\n. This has already been fixed.\n. Hi @fsi206914 \nI think the incorrect versioning was happening since the 3.1.0 tag wasn't an annotated tag. I fixed that. It should build with the correct version now.\nPlease let me know if that is not the case.\nRegards\nSuvodeep\n. Hey Liang\nThere are different concepts here.\nSquashing is basically merging commits together. See\nhttp://gitready.com/advanced/2009/02/10/squashing-commits-with-rebase.html\nRebasing and Merging are different concepts. Although you can use the\nrebase feature in git to squash commits. See\nhttps://www.atlassian.com/git/tutorials/merging-vs-rebasing/the-golden-rule-of-rebasing\nRegards\nSuvodeep\nOn Tue, Sep 13, 2016 at 1:55 PM, Liang Tang notifications@github.com\nwrote:\n\nIt looks like squash-merge in github works good. So we may have multiple\ncommits in one pull request when updating code, right? Squash could help us\nrebase.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/azkaban/azkaban/pull/731#issuecomment-246820915, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ACdVMgVlctssEWd0LUKzSvN4zfOzo3aLks5qpw2lgaJpZM4J7KvZ\n.\n. @fsi206914 you are most welcome!\n. closes #730 \n. @HappyRay \nI created #736 to capture the entire effort. I also updated the PR description. I haven't pulled Hadoop 1 code from the repo. Do you think discarding the 3 projects makes sense?\n\nI just wanted to point out there are no tests for this code. It has been copied as is. It builds correctly and generates the necessary artifacts. We will need to add tests as we work on this.\n. closes #696 \n. @fsi206914 Hey Liang, travis build fails a bunch of times for node js. Is this a known issue?\nOn restart, it works fine.\n. The test resources are being used. It's just the distribution tasks which\nare not. Also, if you notice the distribution job configuration in the\ngradle script, the file locations in the script are incorrect. That's the\nreason it doesn't generate those artifacts. And following that our internal\nsystems complain about missing artifacts.\nThat's why I want to delete them.\nOn Mon, Sep 26, 2016 at 9:59 AM, HappyRay notifications@github.com wrote:\n\nLGTM\nIt appears that this project is not complete. The test resources may still\nbe useful?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/azkaban/azkaban/pull/750#issuecomment-249630293, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ACdVMgnlkhbhaYvfLzKfjJkrOJfeLqhRks5qt_npgaJpZM4KFYGk\n.\n. @fsi206914 I think you are more familiar with these components. Let me know your thoughts.\n. I see. Let's talk about it tomorrow. btw @hreview is me in the above comment.\n. @fsi206914 Thanks for sharing that. \n. yes. You can execute tests with ./gradew test. ./gradlew build will run tests anyway and build the entire project.\n\nUnit tests are good as long as they capture your changes. We expect the tests to implicitly document the expectation from your change. Of course additional context helps people understand the code / logic better.\n. Where do we use this ? It would be great if you can add something in the description detailing the issue / motivation for the PR.\nAzkaban builds successfully without any problems today. Are you sure this is a compile time dependency? \n. @pranayhasan \nAnother question is that you mentioned the solo-server is failing. However, you made changes to azkaban-common?\n. @pranayhasan \nThanks for helping us with this. runtime dependency looks good. I am aware of the transitive dependency.\nI have 1 question though: whether this should be a runtime dependency of azkaban-common or azkaban-solo-server ? Because, I am not sure whether azkaban-common always uses h2 DB. However, this seems more reasonable when a user wants to churn up a solo instance of Azkaban.\n. Fixed in #814 \n. don't print the id as well. remember ? HIVE_DELEGATION_TOKEN dumps sensitive info in the identifier.\nAlso check if we are printing this elsewhere in the class ?\n. @KyleFung Can you update the PR title and description with a little more detail. Then the title can be a little more concise.\n. do we need to do the same for exec server ?\n. Just recording what was discussed offline.\nThis code introduces compile time dependencies on Kafka. I'm just wondering whether that's the best way to go.\n. @fsi206914 please take a look when you get a chance\n. @HappyRay : you can take a look at this : http://stackoverflow.com/questions/23340946/gradle-global-build-directory\n. @fsi206914 quick question: shouldn't we always execute as user ?\n. Where are these caches being used? If these caches aren't being maintained correctly then shouldn't we remove all logic that depends on them?\nI think the preparing step is showing for a reasonable amount of time which means that the caches aren't being updated for long periods of time. Is this the case ?\n. @HappyRay Does it make sense to rename our original ProjectValidator to simply Validator ? I think the only plugin using this interface is the byte-ray plugin. It might be good to make that a generic class rather than have individual validator interfaces of different kinds.\nWhat other kinds of validators can we think of ?\n. Are you using the azkaban coding style? There seems to be some differences . @HappyRay I think the solo server config has been left intact for the exact same reason\n. @HappyRay , the default log4j configuration was leading to exceptions while running tests. The problem is that the default configuration will also conflict with external configuration which is difficult to debug because the log4j.properties gets shipped inside the jar.\nThe solo server ships with a default log4j config\n. @KyleFung\nI think you are accidentally including your older PR# in your new PR. Example 805. This might confuse people. You should be able to edit / remove older PR numbers from your requests.\n. Unless we have custom stuff to do in our internal scripts, we can directly use these.\n. nope. it's exists. git will show if files are created / modified.\nThese scripts won't be in effect immediately since we replace those bash scripts from the ones in our config repo. However, I would like to get rid of all bash scripts in config repo but before that I would like to clean up the existing scripts.. It gets difficult to read nested logic if the code is not indented properly.\n. Hey @fsi206914, How are the sql files being used / read in the code ?. from offline chat: This is a cherrypicked commit from master to hotfix branch.. Actually the pull request is for the Jetty upgrade. not the other way around.\nJust for context, Jetty 6 was released in 2009, 2010 ish timeframe. We should always work with or try to work with the latest libraries. Or may be I didn't understand your question ?. @kunkun-tang that's my guess, Although upgrading is probably always a good idea. I will go back to fixing the shutdown once this fix is in.. @kunkun-tang But yes, the shutdown is a separate problem and not to be related to this change. This change is so that we stop using obsolete libraries.. @kunkun-tang \nI haven't been able to reproduce the exact bug since it happened once every 2 months. The trigger management seems to be working for normal cases.\nThe logic is that whenever SLA expires, Azkaban should launch the corresponding trigger action. There can be 2 places where SLA expire logic can fail. \n- Trigger Scheduling logic: The trigger was never launched\n- The Sla Check logic didn't expire correctly\nThis change is to ensure that the SLA check performs as expected. Should we see this problem again, my strong suspect would be the trigger management code itself.. Thanks @HappyRay ! :). Thanks @li-afaris ! pr updated.. > The current behavior is that the initial state will be the state when the flow is uploaded. \nI think that's a good behavior. If you upload a new zip, you can pretty much change the entire flow and all its jobs. I am not entirely sure how will you preserve state if the jobs don't exist in the new flow ?. Hey @wyukawa ! Thanks for reporting.\nWhat are the steps to reproduce this?. I assume this is when you bring up the solo-server. correct?. Hey @wyukawa ! I understand your usecase. However, can you make the default configurable? Then we can keep the behavior as is.  While you can set your custom default.\nLet me know what you think.. @HappyRay \ncan you please let me know if this looks good. I added as much detail as I know about the issues caused by sync. Please feel free to do the same. I just want this problem to be recorded well enough because it was not that intuitive / obvious to me.. Thanks @HappyRay :). Thanks @chengren311 !. @chengren311 updated.. holding this off for now.. Offline discussion:\nOther synchronization options which can be looked at later if this runs into issues:\n - Convert the QueuedExecutions to a Queue instead of a PriorityQueue. Perform a peek instead of dequeuing it right away. This doesn't work in a PriorityQueue since the head can change\n - Manage locking in QueuedExecutions itself.\n. @kunkun-tang \nI don't suppose so because these classes were created relatively recently (Nov 2016).. @HappyRay \n\nWhat do you think of creating an issue for this PR and describe what we intend to do?\nThis is a relatively big change. Having an issue to tie the PRs together may be useful.\n\nI think it is a good idea to tie these PRs together. FYI #995 \n\nWhat's in sample_flow_01.zip?\n\nIt is a test zip file which contains some sample flows which I created for testing. Simulates a real use case of Azkaban.. pausing this for now.. @chengren311 updated PR with your comments.. @HappyRay \nMost of these are IntelliJ refactors and extract methods. I'll update the description.. Thanks @HappyRay . @kunkun-tang \nI wasn't aware that this change was checked in. There are some issues that need to be addressed. Let's chat offline.. Do you think getDbType should return enum ?. Should we merge azkaban-sql into azkaban-db?. splitting to smaller PRs. moving to #1069. Thanks @chengren311 . updated PR description.. Azkaban computes a md5 hash of each project zip file and stores it in the db for validation. This is just a refactor to expose the API in a way that is easy for the new StorageManager to consume it.. Don't know whether this is the best place for this conversation but should publish to jcenter aka bintray.com as well?. Thanks a lot for fixing this!. I added a link to the instructions. However, I think this is something very easily Google-able.. I think it makes sense to add a developer section to our readme regarding our recommended setup with the code style, etc. This would probably be more accessible than a PR.\nI have seen the jetbrains link that you posted. Even though it has a ton of information about codestyles, I didn't find the piece of information that we needed for setting up a code style file. While the link I posted just mentions that piece.\nI don't know about disabling LinkedIn checkstyle. I didn't have any such issues. I just switched my style file and it worked.\nThanks for sharing editorconfig. I wasn't aware about this. However, if you say that this isn't extensive enough, then I would stick with supporting IntelliJ as our preferred dev env.. Looks great! Thanks!. Looks good. minor comments.. Had an initial look at it. Seems good. Have some comments.\n\nCreate a new KillExecutionAction using flowrunnermanager instead of executormanager to kill flow. Still keep the old one in common module for being compatible with existing SLA trigger in the database. Will remove the old one when all existing triggers expire.\n\nPlease mark the older classes @deprecated in that case. It will be good to add these comments in those classes to in javadoc, etc.\nSome questions on testing:\n - What is your testing strategy for this change?\n - Can there be some automated tests added to help ensuring the reliability of the changes?\n. @HappyRay It works? or probably I didn't understand your question.. > @suvodeep-pyne do you mean the code before this change worked at least for a while, while making sure that system default Kerberos ticket cache is empty?\nBy 'while' I think you are talking about till Kerberos ticket expires? No I haven't but I think we can rely on standard Hadoop APIs. There is similar code pattern inside Azkaban itself: https://github.com/suvodeep-pyne/azkaban/blob/d854fb04b71cfea0bc68dc03086e7128f4b4e7b4/azkaban-hadoop-security-plugin/src/main/java/azkaban/security/HadoopSecurityManager_H_2_0.java#L219-L231\n. > According to this http://stackoverflow.com/questions/34616676/should-i-call-ugi-checktgtandreloginfromkeytab-before-every-action-on-hadoop,\nWhat are we trying to optimize here? The relogin code is a no op as is mentioned on the same page unless there is an actual login.\nFrom the same link:\n\nIt's fine to call UserGroupInformation#checkTGTAndReloginFromKeytab right before every action that needs to be authenticated. If the ticket is not close to expiration, then the method will be a no-op. If you're suspicious that your Kerberos infrastructure is sluggish, and you don't want client operations to pay the latency cost of re-login, then that would be a reason to do it in a separate background thread. Just be sure to stay a little bit ahead of the ticket's actual expiration time. You might borrow the logic inside UserGroupInformation for determining if a ticket is \"close\" to expiration. In practice, I've never personally seen the latency of re-login be problematic.\n\nPersonally, I think it is better that we manage the login and use Hadoop only for HDFS APIs. I think this coding pattern to authorize first and then perform action is pretty standard. I don't want to assume that for RPC calls, it works and when we plan to use REST we start having auth problems again.\n. @HappyRay updated PR.. > Can you try the example in\nhttps://community.hortonworks.com/articles/56702/a-secure-hdfs-client-example.html\n?\nI think we have a very similar if not identical implementation which doesn't work today. You can probably check the existing code? The difference that I see is the initial launch args where they are introducing JVM level JAAS config. Example:\njava -Djava.security.auth.login.config=/home/hdfs-user/jaas.conf \\\n-Djava.security.krb5.conf=/etc/krb5.conf \\\n-Djavax.security.auth.useSubjectCredsOnly=false \\\n-cp \"./hdfs-sample-1.0-SNAPSHOT.jar:/usr/hdp/current/hadoop-client/lib/*:/usr/hdp/current/hadoop-hdfs-client/*:/usr/hdp/current/hadoop-client/*\"  \\\nLet me explain why I think this is not the best design. This sets global kerberos credentials which is not required since the Hadoop access is required by a very specific part of the app. If and when we make HDFS storage a plugin, it would require system properties to be set by the parent app on launch which I think is inconvenient.\nThe doAs implementation contains the credential use in a way which is convenient. And as @Victsm (Min) pointed out, even yarn uses a similar pattern even though they only have the 'yarn' user and there don't have an impersonating use case.\n\nWhat you proposed may turn out to the right thing to do. There are still conflicting signals, however. I don't feel I understand the problem and usage pattern well enough yet. I am concerned about hidden problems if we don't completely understand the behavior.\n\nI think we already have a working + tested solution. These are precisely the concerns I raised when we were choosing Hadoop. There are some subtleties when using secure HDFS. And this has clearly introduced development + testing + setup delays. Can we leverage the Hadoop team to get a closure on this?. @HappyRay \nYou were correct. There is a much simpler alternate solution. Found a bug in the existing code. Please check #1222 for the new simpler fix.. @juhoautio, somehow I missed this totally. Let me take a look.. I see. . TL;DR How many Guice constants do you think the Azkaban Executor needs? If it is a lot, let's have a class. Else, let's hold off until that time.\n\nMaybe a bigger argument for having the constants separataly is backed by DI itself. I mean, if we think about dependency injection with Guice more like as a principle, the idea is that dependencies can be provided from the outside.\n\nI see your point now.\nMy take: I wasn't that keen on creating another constants class. We had 5 of them. People didn't know about it and we had (and still have) constants all over the place. I consolidated them together and we now have single Constants class. But having a giant Constants class isn't great. What's great is that now, everybody uses that single class.\nComing back to the point, I agree with your design and I think that should be the long term state when we have more named injections, etc. What I'm concerned about is a one off 2 member constants class. Some questions are:\n - How many Guice constants do we have in the immediate roadmap?\n - How many use cases of external injection, etc do we see in the near future?\nI don't see too many coming and that is what motivates my current suggestion. I am all in to refactor this at any time when there is a need to do so. Do you plan to feed in your own Server and Context objects? I'm curious.\nRegarding the circular dependency thing: I think having the constants in either the class (to be instantiated) or the module is not a good design. But I'm fine with either to start with. Let me also add that the Guice usage in Azkaban currently, is in a nascent stage. It is not set up in a manner to be flexible with external modules. For example, a lot of the main services are annotated with @Singleton in the class as opposed to the module. We may need to refactor that at some point and that's totally fine too!\nThat being said, I appreciate you being upfront with me on this.. > It might also help if these classes were subject to some refactoring in the future. \nAbsolutely. We are in a major rewrite phase at the moment. However, we are doing it in an incremental/iterative fashion.. @HappyRay \n\nWhen did you test this behavior? I saw that the directory name is test in the artifactory and the artifact name is azkaban-test. And the .ivy file seems to be correct.\nWhat problem did you observe?\n\nI don't see a direct issue since the artifact got published successfully. It is rather the structure of the publish which I think is not conventional. Let me explain.\nI need to fetch the artifact using the coordinates:\nruntime 'com.linkedin.azkaban:test:3.29.0'\nand the artifact downloaded is com/linkedin/azkaban/test/3.29.0/azkaban-test-3.29.0.jar\nNormally, the name of the artifact and the jar exactly match. Here, that is no longer the case and thus might be confusing. So you are fetching the test jar but it's named as azkaban-test.\nThis also violates the convention of all the other code modules since all modules are named as azkaban-* except this one which now also publishes a jar with a different custom output path.\nRegards\n. @HappyRay should we merge this now? . It seems 4.0.2 is the most stable in the 4.0.x pipeline\nhttps://docs.gradle.org/4.0.2/release-notes.html\nNo known issues. List of Releases: https://services.gradle.org/distributions/. This is a smart catch by Travis. Apparently this dependency comes transitively and is not present in maven central. This was cached on my machine but it fails on github.. @HappyRay \n\nHow can these dependencies be cached on your machine if they are not available in the repository?\n\nI remember making some extra effort in fetching dependencies from elsewhere. This was when I was working on the Hive codebase.\n. > The test took almost 9 seconds to run on my mac. This is slow. Any idea how to speed it up?\nIt is taking some seconds to run since it sets up a DB and brings up the Hive Metastore. One way of speeding it up would be to remove the cleanup before running the test. This would benefit second runs in which the HMS start up wouldn't have to create the local files every time.. > How did you test this feature work?\nI didn't test whether RetryingHiveMetaStoreClient works or not. This is a Hive class. I just tested whether existing Hive jobs are running fine. This would ensure that they are fetching the delegation tokens correctly.. @HappyRay \nrelated stacktrace\n* Exception is:\njava.lang.NullPointerException\n        at org.gradle.api.reporting.GenerateBuildDashboard.getInputReports(GenerateBuildDashboard.java:69)\n        at org.gradle.api.reporting.GenerateBuildDashboard_Decorated.getInputReports(Unknown Source)\n        at org.gradle.internal.reflect.JavaMethod.invoke(JavaMethod.java:73)\n        at org.gradle.api.internal.project.taskfactory.TaskPropertyInfo$4.create(TaskPropertyInfo.java:99)\n        at org.gradle.util.SingleMessageLogger.whileDisabled(SingleMessageLogger.java:217)\n        at org.gradle.api.internal.project.taskfactory.TaskPropertyInfo.getValue(TaskPropertyInfo.java:97)\n        at org.gradle.api.internal.project.taskfactory.TaskClassValidator.validate(TaskClassValidator.java:75)\n        at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:41)\n        at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:88)\n        at org.gradle.api.internal.tasks.execution.ResolveTaskArtifactStateTaskExecuter.execute(ResolveTaskArtifactStateTaskExecuter.java:46)\n        at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:51)\n        at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:54)\n        at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43)\n        at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:34)\n        at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:236)\n        at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker$1.execute(DefaultTaskGraphExecuter.java:228)\n        at org.gradle.internal.Transformers$4.transform(Transformers.java:169)\n        at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:106)\n        at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:61)\n        at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:228)\n        at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:215)\n        at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:77)\n        at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:58)\n        at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:63)\n        at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:46). scraping fix. DO NOT MERGE.. @HappyRay added.. @kunkun-tang This code is a POC code. Expect this to go through a lot of change. And as I mentioned earlier, this code will not be executed by Azkaban currently.. @kunkun-tang \nWhy do you think this should be in a new module? This is very closely tied to the project code.. @reallocf \n\nThe only downside is we won't be able to get user's flow logs if they do not get uploaded to the database due to some error, \n\nIs there a way to ensure that the delete only happens if we have a successful database copy?\n. Pausing this for now.. @es1220 \nI think they have different behaviors for different purposes. The solo server is intended to be a testbed for new users to play around with Azkaban. Thus it packages configuration along with it. And we don't recommend using it for production.\nWhile the web and exec server packages are intended for a distributed production setup. Here, the expectation is that the binaries and configuration are to be kept separate. The default configuration on the web server does not help since the user will have to modify/replace the config every time on deployment.\nLet me know what you think.. @HappyRay The answer is now, the code is no longer static. Thus, if I want to add a Status Servlet for example and depend on a Guice injected service, I can do so. In a static context, I would have to access it in a round about way.. +1. I think that is already in the description. It's a status API. It also\nincludes an example output. What are you looking for?\nOn Wed, Aug 9, 2017 at 5:55 PM Cheng Ren notifications@github.com wrote:\n\ncould you help me understand better on use case of the api? or explain it\nin the change description. Thanks!\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/azkaban/azkaban/pull/1320#issuecomment-321420749, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ACdVMoUpS2m_1zFwZurfF_cSSuJKaT0Lks5sWlUagaJpZM4Oypbl\n.\n. Both for ad hoc and systematically retrieving health data for the web\nserver. We already have a similar API for the executor.\n\nOn Wed, Aug 9, 2017 at 6:40 PM Cheng Ren notifications@github.com wrote:\n\ni'm curious about when it will be used.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/azkaban/azkaban/pull/1320#issuecomment-321426580, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ACdVMmY-_QwL6rQtbj1mobHE-E7r6pBXks5sWl99gaJpZM4Oypbl\n.\n. Oh I see. Makes sense.\n\nOn Wed, Aug 16, 2017 at 5:05 PM jamiesjc notifications@github.com wrote:\n\nMerged #1351 https://github.com/azkaban/azkaban/pull/1351.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/azkaban/azkaban/pull/1351#event-1209275620, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ACdVMrNJR4SGQpzOv6x9gTSUSXnFifHNks5sY4PNgaJpZM4O5i3l\n.\n. Another thing is to have tests for all the DAO methods. This can be a future thing but it's important since this is the class doing the actual DB work / has the core business logic.. > If possible at all, could you try to explore if it would be possible to\nkeep the full test output in case of a failed test on Travis?\n\nTry rerunning the build link I shared a few times. I don't think Travis\nsaves the build logs. However, it seems pretty frequent and should be easy\nto capture.\n\nIgnoring \"for now\" would probably mean that there's no way to find the\nfix anyway, so it would be the same as ignoring permanently.\nI agree. But we need to solve the problem of build failing intermittently.\nIt is pretty annoying.\nSo either we find a quick fix, or we need to disable it. That's the reason\nI filed an issue so that this doesn't get lost.\n\nRegards\nSuvodeep\nOn Sat, Aug 26, 2017 at 6:51 AM, Juho Autio notifications@github.com\nwrote:\n\nIf possible at all, could you try to explore if it would be possible to\nkeep the full test output in case of a failed test on Travis? That would\nmake it so much easier to debug why a test failed. When running these\nlocally I never get failures even if I run the tests 1000 times :)\nIgnoring \"for now\" would probably mean that there's no way to find the fix\nany way, so it would be the same as ignoring permanently.\nAnd it's really sad if the tests have to be ignored for good, because\nwho's going to remember to temporarily remove the @Ignore annotation when\nmaking changes to related classes..\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/1389#issuecomment-325129513,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ACdVMiLlfYxwP9LG-3PZzLgDDaQtJqEyks5scCLngaJpZM4PCFIO\n.\n. Yes. This will ignore all files / directories / sub directories named \"build\" as opposed to just directories / sub directories named \"build\". Personally I haven't seen code / files added with the name \"build\". They are mostly auto-generated by build tools. If you recommend reverting this, i'll do it.\n. @juhoautio yes. IntelliJ can understand gradle projects but the support is not that great. Gradle idea plugin is much more robust in building an intelliJ project. Also, you can configure version control, etc so it becomes very easy for a new contributor to download, run \"gradle idea\", launch the project and start working.\n\nLike the eclipse plugin, idea task is run only when invoked. distTar doesn't have any reason to declare idea as a dependent task. In gradle, the list of tasks to be run is constructed using a dependency task graph. Running distTar will invoke build since, distTar dependsOn build and build dependsOn compilaJava and so on and so forth. Unless a task A is dependent on task B in the task graph, B will not be invoked.\n. Do you think we should refactor the constructor? I think there are far too many arguments.\nUsually classes with so many members are built using a builder pattern or they are automatically injected using some DI framework like Guice.\n. can simply to return period != null || cronExpression != null;\nIf you use IntelliJ, it automatically suggests these refactors.\n. nit: too many constructor args. (similar to Schedule)\n. Nice test cases.\nI see some code duplication here though. Do you think we can extract some of the duplicate pieces out and simplify the test logic?\n. This is a reasonably large piece in itself. Do you think this should be in a separate class of its own ?\n. That will be great! Let's add a TODO note in the code in that case.\n. Well. Code maintainability is equally important. By the looks of the code, all 4 - 5 methods do share very similar logic which is duplicated across the tests. (Correct me if I am wrong here) Future changes in code logic would have to result in changes in all the tests individually which is not convenient.\nAs regards to readability, I think a smaller class with smaller methods would help in favor of large test methods which are replicated across the entire class. This will get worse as we add more tests.\n. nit: The general convention is to have test methods named as testName() or nameTest(). The same convention is followed for class names as well. We can stick to either one.\n. Do we need to update the copyright message?\n. What is the difference between schedule-panel and schedule-panelDeprecated?\n. newline missing?\n. Thanks for moving this out!\n. sounds good.\n. I commented out all the dependencies and enabled them 1 by 1. removed the rest which didn't cause compilation errors.\n. They need not be right? If 2 submodules are independent of each, there may not be relation between the version numbers that each of them use. And also we can upgrade each individually for that matter.\nIf however, the submodules are dependent, then the dependent submodule will automatically import the dependencies of the parent submodule since I turned transitive dependencies on. It was disabled previously. In such a case if there is a version conflict between 2 libraries, they will be resolved automatically by gradle to the latest version. Of course this behavior is customizable using Gradle's resolution strategy feature.\nThe third way of doing this is to extract the version as an ext variable and store it in gradle.properties file. This however, in my opinion makes version management more delocalized and may be harder to maintain.\n. Actually, this is no longer required. removing it.\nSince the errorprone plugin is applied to all subprojects, we do not need any custom configurations for plugin integration. This was required for previous versions of the plugin / gradle.\n. see line 141. from (bowerInstall) {\ncreates an implicit dependence on bowerInstall from the distribution tasks.\n. nit: checkReports seems more apt. You are taking a collection as an argument as opposed to a single Report object\n. nit: newline missing\n. Nice job with the tests!\nWhile this works. Consider having a simple method for created the kind of mock objects that you need for all your testing.\nAll your tests require creating ValidationReport objects with warn / error messages so why not create a simple method that gives you that with ease. \nExample: \nValidationReport validationWarn(String msg) {\n  // return new created ValidationReport object with the msg. \n}\n  ValidationReport validationError(String msg);\nThis results in lesser code duplication plus makes it more maintainable in case you need to add some other field later on.\nMake your tests as simple / small as possible and extract such constructs out so that adding new cases is a very minimal effort.\n. unused variable ?\n. working Directory is probably the current directory by default.\n. nit: use logger instead of println\n. nit: You can use jsTest instead of 'jsTest'\nThe quotes make it a string which results in late evaluation. This is useful when referring to external tasks / other cases where late resolution is required. The first preference however is generally to resolve it in configuration phase.\n. Curious. What is this json used for ?\n. removed it. I have it set up in my IDE and it adds by default. will fix that.\n. I actually updated the API itself.\n. yes. thanks for catching that. fixed it.\n. Do you think creating a ticket for every TODO is a good idea? I am thinking it to be an overhead as opposed to creating simple TODOs.\nIt is a plus since, it's a quick recommendation to anybody who is modifying the code as opposed to creating a separate ticket for modifying the code.\n. Updated it. I didn't modify any piece of that code. Hence I didn't bother to add tests. Moreover, I think this piece of code should be handled by a library as opposed to doing this by hand. I don't find it to be maintainable.\n. exactly my point. I think library utilities should exist to do the job. That's why I added a todo to fix that. The same logic is used in 2 places.\n. Actually I updated the API to have this logic inside it. My plan is to have ExecuteAsUser as the default way of leveraging the execute-as-user binary.\n. Thanks for pointing it out. updated it.\n. I actually like this idea. This simplifies things a lot. I'll implement this and update the pr.\n. Actually the user is not assumed, it is derived. However, the group name is assumed. \"azkaban\" is the assumed group name. \nI introduced constants for the purpose but I think this should a configurable parameter.\n. Hey @fsi206914 \nCould you please add some comments about the role of this plugin and how's it being used.\n. use $buildDir instead of hardcoding build.\nYou can either use buildDir + '/foo' or \"$buildDir/foo\"\nSame for the ones below.\n. You don't need to delete hidden directories like .gradle. They are used by gradle to manage different gradle versions and dependencies.\n. Is this supposed to be shipped in the tar ball. Then this should be part of the distribution configuration. You may not need a 2 step copy\n. What is this json used for ?\n. yes. you are correct. That's the reason I pointed it out.\nSymbols inside double quoted strings are resolved by gradle while single quoted string is not. This comes from Groovy and you can read more about it: http://groovy-lang.org/syntax.html#_double_quoted_string\n. I understand but it totally makes sense to me since the distribution task is the one place holder to gather all that is required in the package. This would avoid having copy tasks in different places.\nThis may increase the size of the distribution config but that's ok :)\n. I am afraid you won't be able to create comments inside json files. However, I just wanted to ask if this needs to be in the root directory of the subproject? \nI mean, we generally keep json / resource files in resources etc, but this seems to be a package configuration. I am not that aware about nodejs so I'll let you decide whether this needs to reside in the root level of the project. What are the best practices for this ?\n. nice comments ! really helps ! \ud83d\udc4d \n. By current, do you mean the latest uploader of the project ?\nHow is this information being persisted? Or is this a transient field?\nAlso I am not sure whether this data is set on all code paths. Since, every project will be uploaded by some user, this should not be an optional data.\n. So, the field is uploaded irrespective of the upload succeeds or fails ? How does this help? This means that it is probably not a project property but merely information about the current user trying to perform an action. Also, if it is transient, let's mention and document all this information on the member.\nIf it has to reside in the project, then I said this field should not be an optional piece of data. The way this field is being populated, there seems to be ways in which  currentUploaderID can be null. Let's ensure that this always stays populated. That's what I meant by covering all code paths.\n. so we are trying to avoid scheduling flows in the past. right ? Can you please add a small note.\nnit: else statement is not required.\n. nit: \nyou can static import Assert.* which would lead to lesser boiler plate code.\nAlso, I would break code the test cases to testValidExpressions and testInvalidExpressions\n. Let's use Optional here since this is a configurable parameter which may or may not be present.\n. @fsi206914 \nI didn't quite understand your question. Can you please clarify your concern? \n. I wanted to log the url in case of DB connection failures. \nApparently there is no easy API to access the url from that class.\n. yes. everything in azkaban-common is.\n. No. In fact I don't see any advantage in doing it.\nI just did it since I didn't see any disadvantage either. It allows people to put whatever name they like.\nThis can be changed to a constant.\n. yes. I updated the code\n. spoke to @HappyRay offline. removed config variable.\nThe argument is to not add configurations which would unnecessarily create complications. This could make it difficult for automation code to figure out the port.\n. jobAppender doesn't seem to be an optional parameter. Users would always want to view their logs in the UI\n. There is a props already in the JobRunner. Any reason why we didn't use that ?\n. I would prefer something like schema to be a resource file since managing this giant string in java will be a pain. What do you think ?\n. @fsi206914 \nThis commit actually has nothing to do with rpm build. It is just that I thought no pid file would make more sense than empty file.\nCurrently, when server runs, the pid file is populated. When it's shut down, the pid file is either empty or not present. Instead of that, the state is being simplified to not be present on shutdown.\n. I was noticing instances where shutdown wasn't shutting down the process in solo server.\n. The port number will be in the logs. \nDo you want to have an easy access to the last port number? Just want to understand the use case. My motivation is to clean up the temp files on shutdown.\n. I don't think this file is used anywhere. I'm ok with deleting this file.. There is already a azkaban.server.Constants class which you can use.. Is this a mandatory configuration ? Then we should report errors. Else, we can skip it or log the values of each anyway.\nThe point is we can straight away log the values of the config parameters instead of saying \"either A or B was not found\".. Does this report to console or logger? Probably it is a good idea not to output to console.. Duplicate logic between AzkabanExecutorServer and AzkabanWebServer. Should we use AzkabanServer to share the common code ?. nit: Can this be shortened into lamba expressions ?. I think we can get rid of 'azkaban-common' and the build should still work fine since it's transitively included.\nI'm curious how slf4j is being used ?. nice !. Quick question: What is the differences between server props and azkaban props? I see different usages from the code. Does it make sense to combine the two ?. Curious: Will this work if I print an integer ?\nBest practices: if you are overriding/implementing a function, use annotations to indicate them. Like in this case using @Override.. In the solo server case, there will be 2 PrintStream objects created. What do you think about maintaining a single instance of each in the class itself?\nDo you see any advantages of creating a fresh stream every time a redirect is called ?. Thanks for tidying this up. newline missing. preferably final ?. nit: Let's keep variables final whenever they can be. Can we have a separate differently named private method which does this, similar to the OutputStream in java. That makes the code much more readable than calling an already heavily overloaded and overridden method.. nit: formatting: single line gap between methods. nit: call it getId ? you are calling on the executor itself ?. There is a requireNonNull API in java Objects class itself that you can directly use.. Also this code is now common for uses, in the Executor server class and in this class, set active method. Should we refactor that into a single method to fetch current executor object ?. nit: grammar. \"The current executor cannot be null\". nit: same comment again. Why not GET_STATUS and getStatus ? The API is being called on the executor itself. Personally, I prefer succinct names which not include redundant information.. Don't think so. Note that this change will not fix the shutdown hang problem.\nHowever, the monitor thread isn't something that we need to hold up the executor for. That's the reason I marked it as a daemon thread.. QQ: Not sure what this does. Could you please add a comment.. The escaped pattern layout would capture exception messages correctly. right ?. Thanks for refactoring this ! . Oh! nice!. refactor to utilize getURLForTopic. refactor to utilize getURLForTopic. better to have unit tests for these small util methods. Let's add a test for Dr Elephant . Nice !. Yes. The logic is to wait for the flows to terminate. Timeout is a minute. You can see the awaitTermination documentation.. well. shutdown refers to a safe shutdown, while shutdownNow refers to an immediate (may be unsafe) shutdown. This is a default convention for lot of libraries. You can see java.util.concurrent.ExecutorService#shutdownNow for example.. The logging happens before this call. The main API call logs the shutdown call before calling the internal APIs. Nope. Why would you want to kill flows ? That would be a problem for running flows. The idea of shutdown is to wait for executions to complete before shutdown.\nSo shutdown \u2260 kill. shutdownNow is similar to kill. All these events are logged if you go down the trace. The db component logs the db change events.. No. The shutdown would fail. It will be unsafe to shutdown the executor while it might still receive active traffic. right ? The goal is to set the executor to inactive first before attempting shutdown.\nIf you want to shutdown now, you can just use the shutdown bash script or kill the process.. Not through this API. This API can be enhanced in the future to have a timeout functionality.\nKilling executors still needs to be done from the shell using the bash script. Currently this is intended for deployment use - when we update executors, we shutdown the older ones. This is intended to be the base commit. There are other issues which needs to be fixed and I will send out patches for those once this goes in.. agreed.. I don't think this class is used anywhere. Have you seen any usages of this class ?\nThat's why I removed it. Also, the class works on internal APIs of Jetty which are no longer supported or has been changed. I chose to get rid of dead code.. I see. Yes, I was unable to find any usages of these configurations in any of our clusters. I can delete them as part of a separate change.. This is some weird legacy code which is called via JEXL. It's cryptic and will break if I make any function signature changes.\nI think we might need to rewrite the Trigger Manager. This is kind of a spot fix.. Please see my comment above.\nThe APIs are kind of weird. there is a passed as well as failed API and they vary slightly. It is a quite confusing.. Added. . init() is called on every API call. However, once inited, these code blocks ar not executed. The trigger part is a different code, this class is just to check the condition. I suspect the code which calls these APIs also controls whether to stop the trigger.. yes. there are multiple code paths and am not sure of all of them. The reason I haven't changed the public APIs is because of JEXL. If / when I touch the trigger management code itself, I can refactor the logic and clean up a lot of the complexities. For now, I'm leaving them as is.. If that's the case, then they should be moved to a util class. Utils in general is a tricky thing in terms of coding practices. http://stackoverflow.com/questions/3340032/utility-classes-are-evil. How does this help ?. I'm kinda confused here. \nAre we creating-a-deep-hardlink or creating-a-hard-deeplink? :|. Could you please add some comments here on what's happening.. Do you think the JDBC Loader is playing too many roles here?\nWhat are your thoughts on this? https://en.wikipedia.org/wiki/Composition_over_inheritance\n. Does getDBConnection always create connections? If yes, should we rename the method to something like createDBConnnection ?. Some comments on each kind of event would help. \ncosmetic: AZ_DOWNLOAD_FILE and USER_DOWNLOAD_FILE seemed a bit confusing? What files? Are we talking about project zips?. code duplication.\nreuse previous constructor rather than implementing the same logic again?. Both the constructor and the static create method are very similar. What's the advantage of having a private constructor here?. The common convention is to have Interface I = new Implementation(); so probably Set<EventListener> instead of HashSet ?. We are synchronizing on a large code block here. \nWill we face any performance issues?\n. I suppose these methods are being accessed in a multi threaded scenario. In that case we need some protection if we are modifying listeners.\nShould we consider alternative like concurrent lists as opposed to managing this ourselves? \nhttp://stackoverflow.com/questions/6916385/is-there-a-concurrent-list-in-javas-jdk\n. I see. Let's revert this change as and when possible.\nNot urgent by any means.. The Azkaban Server object has methods for obtaining the port information. However, we need to check if accessing that class directly is the best option.. This may be duplicate code. The server has this information.. Is this specifically for the Kafka Appender. Then we should name it in that context.. I have to say. I really like the testing strategy. This is awesome!. I am a bit concerned about the coding style here.\nAzkaban uses a different coding style than LinkedIn. If we are moving to LinkedIn standard, let's change the entire codebase and move to it. Else let's stick to Azkaban's default. Having both styles in the same codebase may not be the best idea. newline missing. Quick Questions: \n1. Why do we need a Common Metrics and a Web Metrics, etc.?\n2. Does it make sense to have a single Metrics singleton class as opposed to multiple singletons?. cosmetic:\nWhat do you think about renaming this to COMMON_METRICS or probably METRICS (if we have a single class) instead of INSTANCE. Then you could static import the instance and have the code as\nMETRICS.markDBConnection();. Q: Is this an async call? Why do we need the wait?\nA comment here would be useful.\nAlso, what are the chances of the async call (if present) not finishing in the time limit? Will the build fail on slower machines?. typo in azkaban-web-server. same Question: Why is sleep required in the tests ?. Couple of Questions:\n1. Should we let the server run if the obtained hostAlias is null or should we crash the server (since metrics and everything will break)?\n2. Can hostAlias change during execution? Else should it be a final variable?. Questions:\n - What are the advantages of using perl to do this vs directly doing this in Java?\n - probably should be abstracted in a separate method / class since there's a lot going on to determine the vip?\nSome comments on what's going on here might help.. There should be a gradle plugin to do this. I have my IDE set up now.. @chengren311 \nThanks for the review. Both work. \nMy thought process of having an exception is to force the user (of this interface) to check for the key upfront before using it. A return value can be easily ignored and the user won't notice that a storage request failed. This may create problems in our case where user is unware that an artifact upload failed. By having a RuntimeException this is bubbled and the user is forced to handle this.\nThis is different from a Java Map API where it is Ok to just replace the value and return the current one.\nRegarding get and delete, I updated the API to throw exceptions as to keep it consistent.\n. This is kind of a debate and I don't have a strong opinion on this.\nIMO Checked exceptions add more overhead in the source code than handle the actual problem. Normally people just bubble it up by wrapping it into a RuntimeException. I wanted to keep it simple. Also, this allows to not handle the exception if they are not capable of handling it.. good catch! I'm actually gonna refactor all these try blocks. Handling this in each individual method doesn't make sense.. This is gonna be the more common case. I don't want to pollute the logs for this.. I agree wildcarding is not good. But it is not always bad.\nIn this case, this is kinda done intelligently by IntelliJ. If you see these classes, they are designed for static import. Example: Preconditions, Objects, Assert (in Junit).\nIt is a standard practice to wildcard import classes of these kind so that you can use the utilities easily and not have to write MyAwesomeLibraryClassName.myUtilMethod() every time. This in turn avoids multiple static import statements which kinda pollute your import paths.\n. May be its safer to assert that it exists before and then assert that is doesn't after delete.. nit:\nI prefer using mockito rather than using a complete mocked class. You can spy on methods and validate calls etc. But this is up to you.. Can we escalate this to warn. It is a major event.. Why is the shutdownNow call being skipped here?\nHow is the web server being killed ?. It currently doesn't require any public access since it is used just by the executor to prepare a working directory.. ProjectVersion is currently some data and some utils around projects. I am cleaning it up to be just a data class. I plan to rename it to ProjectInfo later.\nDeletion and management of data is already done in FlowRunnerManager. Also, if you notice, the deleteDirectory method in turn calls a utility method. I agree it can be static. Will change that.. yes. it is simply a convenience method. Changed the code a bit.\nBasically, I didn't want to handle IOException in a catch/finally block. Just made a method to make it look a little cleaner.. fixed.. Aah I see. Thanks for helping me understand this.. Interesting read. I kinda agree with the argument. Will refrain from using this. Updated PR.. It doesn't. I'm thinking of this class as a service. This gets instantiated with parameters that don't need to change per project. So FlowRunnerManager should depend on components like FlowPreparer and FlowExecutor. And they should work with some sort of ExecutorConfig. That's my thought process.. Oh I haven't touched this part yet. I'm attacking this class in parts.\nLet me fix this anyway. . warn is a stronger event that info. Deleting a project directory is an important event. Hence the categorization.. Thank you! Not only that. \nI thought of bringing the code for preparing flows at one place. So that I can update this easily.. I have thought about this. But I want to push this for later. This class is heavily used and I didn't want to alter the flow in the first change.. It is just a plain vanilla set method. I don't think this would change the behavior.\nThe main goal of the test is to test whether flow and project directories are setting up as expected.. same reasoning.\nwarn is a stronger event that info. Project preparation happens once for every version for every executor. Just wanted to capture that with a higher log priority.. I'm not sure what to add in the javadoc specifically.\nIf I add FlowPreparer prepares the flow or something: this is a perhaps redundant. I tried to name the methods and classes to be as self explanatory as possible so that documentation required is minimal. Also, I assume that these pieces of code will go through a lot of churn till they are stable. Documentation might be an overhead to maintain whilst this change. Should we add this later if at all? I don't see this to be an external facing API anyway.. I see what you mean. The problem is that the order is info, warn error! So, I really didn't have much of a choice :) . But I also wanted to highlight that project preparation complete was an important event.. @HappyRay \nyes. didn't think about this. I have it static for now as per @chengren311 's suggestion. But we can always revert it back if the need arises.. Any Collection class has toString() built in to do that. . @shuzhang1989 How do you suggest doing that?. setStatus just sets the status right? Should we set it once all the process has been killed? This seems to be more wishful where we assume that we will kill the flow in the upcoming steps.. mainSyncObj is not even a final member here. So, locking on it seems unsafe and not a best practice.\n. Also, I would ideally wrap the entire thing in a try catch block and log stuff when we are unable to kill jobs.\nThings to think about:\nYou have 10 jobs running. killing the 4th one failed or threw an exception. What do we do? \n - What's the status of the flow after that?\n - How do we handle failures?. Why some time values in mins and other in ms? Can we make this consistent. Also, I would encourage looking at Java's Duration class.. nit: You can shorten this with new Hashet<>(Arrays.asList(...)). Again, I would encourage using a class like Duration and objects for handling this rather than using primitives.. This is smart but hacky! I would probably prefer an alternate solution that would be more obvious to read/understand.. What does load all project flows do? Are there cases where I need the project and not load the flows?\nIf they need to always be done together. they should be encapsulated in a method probably in ProjectLoader if appropriate.. This may not be required since you either populate the project or you throw a runtime exception.. TL DR; There are some advantages to using classes like Duration as opposed to using primitives like int and long \n@chengren311 @HappyRay \nI totally understand the point you are trying to make but let me share a story. :)\nThis was narrated to me by Prof. Stroustrup himself. It's about a NASA probe which suffered a horrible crash probably more than a decade ago and costed more than $100 M. The controller code was written in C++. On investigation they found out that there were 2 components reading the same double constant which had a major role to play in the crash. I don't exactly remember the details but one of them was developed by the Americans and the other by some European country. The crash happened because the retro rockets which were supposed to stabilize and slowly land the probe stopped firing when the probe was 100 ft in the air. It was not a happy landing. On digging through the logs they found out the problem. As it turns out the Americans are fond of the pound system and the Europeans prefer the metric system. There was this evil double value which missed all conversions; slipped through the compiler and through code reviews and was passed as is to another component which expected a double but in different units. Rest is history :)\nHere we have Azkaban! which is open source :D However, I would still prefer using a dedicated data structure for measuring time like Duration as opposed to using long or int. While this convention has been there for decades in C and other languages, it hasn't always yielded the best results.\nRegarding intuition, Duration.ofMinutes(5) is more intuitive to me than a 5*60*1000 long with a comment. It is also very safe since the numbers are abstracted away in the API itself. The joda-time library has been extremely popular in the Java community and it was officially incorporated into Java 8 itself because of its simplicity and utility. Now, since we have Java 8 already, we can directly benefit from it instead of having variable names determine the units.\n. alright. That works too.. @chengren311 \nYou pretty much summarized my concerns in your above comment. I am good with the intern() approach as a hack for something better later on rather than use something that's breakable/buggy. One suggestion is to add your explanation comment in the synchronization logic code. I was thinking of the HashMap lock management approach but I agree it has a significant implementation overhead.\n. @chengren311 \nquick question: How does this fix the problem?. Agreed.\nMy comment was more directed against using primitives instead of dedicated classes for temporal variables in our internal code.\nRegarding configuration parameters, Duration can be there as well. There are methods like java.time.Duration#parse which uses the  ISO-8601 duration format PnDTnHnMn.nS. Example:\n```\nSet max flow running time to 15 min\nazkaban.server.max.flow.running=PT15M\n```\n(edited)\nThat being said, I totally agree with you in retaining existing configuration as is. However, for new configuration parameters like the one we are adding, should we use these libraries is the question.. I went with that approach initially. I agree that would simplify the code and can get rid of the enum, etc. The downside is that a hardcoded class reference is difficult to refactor. \nTomorrow if we decide to rename or move the class all configs need to change. This might be important today since the codebase is going through a lot of churns.\nSecondly, the name mapping kind of draws a strict line between what is supported out of the box versus what is supported externally.\nWhat do you think ?\n. Actually, both safeguards are helpful in a way. This line ensures that Guice creates only one Storage while the provider ensures that we have only one LocalStorage. In a fictitious case where someone decides to instantiate LocalStorage directly, it wouldn't create a second storage. \nBut, I think we can get rid of the provider @singleton annotation since it is not consistent with others, like DatabaseStorage, etc.. updated PR.. Oh! I already removed the @singleton in the provider yesterday since it was inconsistent.. We already have Props for that and it is not easy to manage. I personally prefer modular configs since they are much smaller and easier to deal with and also address a specific context. However, this class is expected to go through some churn. . It is designed to manage storage. It is a work in progress.\nI envision this to be the single point of contact for all Azkaban APIs to interact with Storage.. It is difficult to introduce Guice into an already established project since the programming model is very different in both cases. The current approach is to create a single fat module AzkabanCommonModule and add all bindings in it and expose this through a ServiceProvider API. Thus, this class is intended to be a container for all bindings.\nIt contains storage bindings for now as a start and both as an example on how to use Guice and benefit from it.. As we refactor more and more code into this pattern, we can think about breaking up the module into smaller ones. But now, feel free to put everything (in azkaban-common) in this module.. Currently the web server caches a local copy of the uploaded file before pushing to db. This is used to performing validations and computing hash etc.. The problem is name can have collisions. id is unique. And we can fix this later.. This tests the entire flow. I do a put and then a get. . No. How do you suggest we unit test this?. spoke offline. This can be unit tested by creating a dir and altering permissions using OS calls and verifying that we get the required results.. @shuzhang1989  This class seems to have a hierarchy. I think it would be good to refactor this separately.. Since it is just a map the code seems to load only when it is present. line 283. @HappyRay @chengren311 \nShould we choose to use a serialization library we should also think about schema migration. However, as @HappyRay pointed out, it is much better to use a standard library to do this instead of doing it manually.\nAlthough, it probably should be a separate change.. @chengren311 FYI. IntelliJ should automatically suggest these refactors. It might be good to take a look at those suggestions first and update the PR. It kinda mitigates obvious issues.. +1 Thanks for adding this!. yes. The builder pattern would be good here.. @chengren311 \nQuick question: What was the existing logic? and where is it moving to?. +1. The better convention is to implement a Runnable.\nhttp://stackoverflow.com/questions/541487/implements-runnable-vs-extends-thread. You can directly use Long.compare here.. Should we make this configurable? You can simplify it to Duration.ofSeconds(15) as the default value\n. nit:\nYou are using TriggerComparator just once probably. Once you simplify the function the code can be replaced by a simple lambda.. just use addAll ? \nAgain, I think IntelliJ offers these as suggestions.. So you dequeue all elements and then add them back after you exhaust the entire loop?\nLet's consider a scenario\n - Trigger A(time: 15)\n - Trigger B(time: 50)\nAfter processing A, the trigger time is set to lets say A(time: 30)\nBut your code will fire B first and then look for A. right? That means the trigger for A is missed. Correct me if I'm wrong here.. Also, use composition instead of inheritance. I don't see why we should inherit a Java thread and all its internals for a class which has a much more specific use case.. nit:\nI have read this logic earlier in the code. It still goes right over my head. Some doc here briefly describing what it does would be helpful. Else breaking it down into smaller functions would make it easy to read.. @HappyRay \nI am thinking more on the lines of the name TriggerManager. This class is running through the triggers and firing them. It is not 'technically' monitoring a flow.. nit:\nThis class can be Guice injected. I leave it to you if you wanna do this as part of this change. This is exactly what I would refer to as a class 'dependency'. +1. These classes seem to have similar data. We can use one to wrap the other. Or have a single Trigger class and have 'controller' kind of classes to work with these objects. thoughts?. nit: Use StringBuilder all the way?. I think a style checker would help here but the max length of a line is 120 characters.. @chengren311 : where does this logic move to?. Good point. Will add it. I am not too worried since the chunking logic, etc will go away when we move to the new storage.. Thanks. fixed it.. The constructor is used externally. It is complicated and that's why I didn't refactor this part as part of this change.. It is a hack to get DatabaseStorage to work without too much trouble. It may not be required later on. However, adding more metadata / context should hurt the code.. sounds good. btw. you have all sorts of helper methods - ofDays, ofHours, ofMinutes, etc.. ??\njava interface methods are public by default.. added final to the remaining ones. Although this is not a change about refactoring AzkabanWebServer. Thus, am not keen on making too many changes there.. because the pull request is on put :)\nadded UnsupportedOperationException. Just wanted to add that the refactor in the JdbcProjectLoader code simply splits the upload method into multiple smaller methods... This line changes the default storage implementation type from LOCAL file system storage to DATABASE which is the MySQL storage used today.\nDATASTORAGE is generic and doesn't convey anything about the implementation detail.. I don' think we do apart from that the outer api does connection handling, etc making the inner function simpler.. Oh, btw. This was an existing method wich I didn't remove. There are other refactors in my mind but I'll probably do that in stages.. protected static seems a bit confusing.\nhttp://stackoverflow.com/questions/24289070/why-we-should-not-use-protected-static-in-java\nShould we just make it package private or public (if it is accessed externally)?\nThere are other similar changes in this PR.\n. I think that's a good idea. btw can you point me to the annotation that you are referring to? I'm unable to find the annotation in our current classpath.. This is a functional change in itself - perhaps the only one in the PR. But this is required for the refactor.\nThe existing code modifies the config while setting up the server. This creates a spaghetti flow and I had to disentangle this to make that flow somewhat linear. The null check is required else some test fails. I don't want to focus on that now. The current direction is to make the initialization simple so that I can introduce Guice at the root level. This would simplify refactoring drastically since a lot of the entanglement is due to static referencing of data/ members of one class from another. This will be evident in subsequent PRs. I think we need that. I didn't autoformat the entire file though - because we don't have a standard style yet. Once we establish that, then we can have a single format change and update everything. Also we can add style check validations to make our life simpler.. I agree it is. I'll fix it. We need to change the entire args processing code anyway. The current code flow is very unclean and needs to be restructured. I'll add validations when I implement the new classes. Treat this as a stop gap change.. This code is not new. It is cut paste from AzkabanWebServer. Unchecked cast\nreturn (Class<? extends Storage>) Class.forName(storageImplementation);. This is being called by the solo server main. The solo server used the call the main methods for both web and exec servers.. Throwable is the mother class of all catchable classes in java. Exception is a subclass of Throwable. The idea is to catch all errors at this point since we are trying to shutdown the server.. Yes. This made sense when it was inside the web server code. updated it.. I wasn't aware of it. Let's discuss offline.. Just wanted to ensure that rest of the cleanup is executed no matter what.. I see. Thanks ! \nI'll fix it in my next PR.. There is no problem as such. It is just that I would prefer storage key to get a single parameter, URI in this case.\nFor example in LOCAL or HDFS storage, I would get the artifact based on path.. I don't think we have a naming convention yet, but this is probably difficult to guess or search even in IntelliJ. You can simply call it AzkabanDatabaseOperator. Or since we are already inside the Azkaban package, may be just DatabaseOperator. \nHaving consecutive capitals make sense of abbreviations like URI or something. . suggestion: remove static and make this a provider like the method just above this createLocalStorage The idea is to initialize only the minimal set of classes like config classes etc and leave the rest to Guice.. If you foresee this method to grow, then make it a provider class. example: ServerProvider. Do we need to specify hard coded settings for h2 and mysql? Are other database types not supported ?. single line ?. Again, I think it would be better to use Azkaban instead of short names. AZ or Az, etc . The consistency helps.. SQL statements ? Can one provide multiple statements? If so, how?. Just curious: What other kind of implementations do you foresee ?. I really like the javadoc but it is Ok to leave out the stuff that is already documented in the interface. . single line ?. Same comment as above. +1 for comment.. I don't completely understand how this works. Let's discuss offline.. call it Constants? I specifically avoid creating Util classes which become a static dumpground for people to dump random unrelated methods into.\nI think we are redoing some of the infrastructure in this module. How about @HappyRay 's idea of pulling out a core package and depending on that?. Why do we need this ? And why String ?. comment is aligned incorrectly I think ?. This should be Guice injected. nit: can be shortened to a single line. . ??. nice ! \ud83d\udc4d . I like the table name :). by parent the code was referring to AzkabanExecServer class. There was no code initializing FlowRunnerManager with a different classloader. It was a simple new call. This means that that classloader for AzkabanExecServer and FlowRunnerManager will always be the same. Therefore sending it via argument seems redundant. This is also true further down the flow but I didn't want to refactor too much in this change since the PR is for a different purpose.. I agree but by that logic, we may have to change the visibility of a lot of classes. I left it defaulted to public for now since that is the usual convention for classes.. Yes. we should. There are a lot of classes initialized in AzkabanExecServer and other top level services just to pass arguments around. These wirings can simply be removed by using Guice.. @HappyRay \nThe method call itself throws Exception so we cannot just catch RuntimeException. I have already made the suggested changes and pushed it #1019 . It's not. I'm just pulling the hadoop and hive versions out to gradle.properties.. I was thinking of it initially. But I also don't want too much business logic inside a config class. I'm leaving class loader specific code inside the module because that's what a module should do.. We do! as part of plugins! For now, this change is just pulling out these versions to an external file so that we can easily change these and also maintain a consistent version across all modules.. @kunkun-tang \nI think close() will be automatically called on connection since it is being called in a try-with-resources mechanism. Let me know if you still think it's a problem. I guess this was due to IntelliJ doing its thing based on code style. Fixed it.. same argument as above.. No. The way I am approaching this design is that the storage shouldn't be bothered about putting metadata into Azkaban DB. It should simply take care of storing the file and returning a valid uri to reference it. Currently the metadata management is being done inside the DatabaseStorage. That's the reason for the hack.. should we also get rid of @SuppressWarningshere ?. Coding style: Generally enum instances are coded as constants => all CAPS\nhttp://stackoverflow.com/questions/3069743/coding-conventions-naming-enums. nit: OSMemoryUtil ?. nit: generally the '* ' are continued in javadoc. I'm surprised there are no standard utilities for this? As in getting the memory  details directly instead of mining them.. Does this work on Mac?. I think slf4j is good. But should we do it as part of a global change?. so this is how it's ignored. Thanks \ud83d\udc4d . nit: missing newline. I think we can depend on other projects directly. What is the advantage of this copy?. Please use \"$buildDir\". The code already has examples for this. Hardcoding the build directory sometimes creates weird problems. For example, the last time when the web server had certain code failing because some moment.js was hardcoded to copy to 'build' directory?. \ud83d\udc4d . You mean azkaban-db package?. nite: single line. yes. That needs to be refactored.. Curious: What is the difference between DatabaseOperator and DatabaseTransOperator?. That's cool. There is no mandate as such. \nThere are examples like sun.security.x509.IPAddressName but there are counter examples like com.sun.jmx.snmp.SnmpIpAddress in Java itself.. I see. So this is kind of Linux only. We can probably call that out then.. yes. That's a pain. There is a quick way to do this though. Let's chat offline.. Having this change incrementally can create confusion. I am not sure whether this helps us migrate from one to another. Rather it may lead to a codebase with both loggers in use.. yes. That we can enforce. . updated to resourceId. Yeah. these are all the hacks to just instantiate the web server. :|. Yes. I am using the same h2 version as used elsewhere in the project. Haven't done any consolidation.. There were no changes to dependencies. These lines were just moved from below to top. I don't think this code should at all exist. The DB module should find its own scripts. This is a hack and I don't want to make this a standard way of running SQL scripts all over the place.. The DB is hardly used here. It's just there to make ensure that we can instantiate the object.. Yes. I missed this. will add it.. These are derived and duplicate dependencies. Removed it. updated description. tests can start from a clean state despite running into errors in previous execution. Honestly, I don't have much experience with h2. But I am not particularly concerned about performance in test code in a case where we don't have any SQL testing.\nIf we can make a default azkaban mode to pick up an in memory DB if not configured, that would be great.. copy paste error. fixed it.. That's a valid argument. The reason I left it there is because during debugging or fixing code you may leave the state inconsistent. For example, if you stopped while running a test, you would still have files and directories present which will not be cleaned on the next run unless we explicitly clean it.. Well, this is less bad than what it was. Let me explain.\nPreviously, solo server would call main methods of web and exec servers. I refactored that to call launch and created room for different injectors for solo, web and exec servers.\nThis goes one step ahead; such that we inject the Web server instance instead of properties. This is more Guicy. Since we are creating the service directly from Guice and sending it. Notice that we don't have to use the SERVICE_PROVIDER singleton. The lesser the calls to this, the better.\nFuture: As we integrate with Guice and refactor more code, we can get rid of the SERVICE_PROVIDER interface totally.. @kunkun-tang That's what I said earlier. I don't think we need this copy. Why can't we access these files directly ?. Is this new code ?. We are accepting triggerLoader as a parameter and then ignoring it. This seems a little tricky? \nAlso, all the dependencies in this class are Guice injectable now. I think we can just create TriggerManager directly? Then we can get rid of SERVICE_PROVIDER since TriggerManager should be Guice injectable directly.. Oh. I see. So DatabaseOperator is a single query runner. DatabaseTransOperator is a multi query runner? \nnit: The name confused me a bit. Technically both are doing transactions. I'll let you decide on this but I think SingleQueryRunner and MultiQueryRunner would be more self explanatory - since we are already using the QueryRunner library. \nAnd I also like the comments that you added. It helps!. I think classes operating on a config is a standard convention. Just that our module is too big - as in common has too much stuff in it. But for the time being I think, it is easier to work with a common config container since it also contains props as well.\nSo my suggestion is to use this model if it applies - for example if you need a bunch of props values and need to extract information from them.. No. Because I already have an @inject annotation in the class. Guice gets confused if there are no annotations and it has multiple constructors like we saw the other day.\nBindings are mandatory for interfaces where Guice doesn't know what implementation to use.. yes. it is inside test/resources. For our purposes yes. This is intended to be the user managing the azkaban app.\nBut we don't control what user and what keytab, therefore keeping it generic.. yes. you are right. once we have a loggedInUser we just renew the ticket.. I think migrating to a different logger in an incremental way is difficult. More so because people just copy the logger line from a different class. This needs to be done either all at once or one module at a time. and that dependency needs to be removed to make log4j compilation to fail.. I think we can use the same below constructor at all places. The usages of this are in test code. We should either mock it or just fill it with empty props to get it to work.. final ?. Let's remove alerters from web server as well.. my bad. will fix this.. The idea is to authorize every request. How do you ensure this otherwise?\nAlso, performance wise this isn't that bad. The ticket reissue occurs only when it is required - once in 8 hours or something, depending on the validity of the TGT.. I suppose not. Else there is no need for authorization.\nauthorize() throws an exception in case of an error. In that case the rest of the code path is not executed.. fixed.. agreed. fixed.. not at all. It's just convenient. I couldn't find a single liner page detailing just this part.. That's cool. I don't intend to merge this PR. I just wanted to have this patch available in case it becomes useful later on.. I agree. But this code involves some hacks with the JDBC interfaces which I don't intend to push to master. That's the reason why I published this as my fork.. would be good to turn these into constants.. Now that we are initializing everything in one shot, should we also make all trigger fields final?. nit: this is more like an fyi.\nFor some reason, this class has a private constructor which throws an exception! We can probably get rid of that since we already have another constructor. Also, one of the other ways of taking accepting parameters is to use a builder as a parameter itself and initialize all fields from it.. nit: probably good to do validations here. like requireNonNull checks, etc. Thanks @chengren311 ! \n@jamiesjc please take a look at the Duration class for storing time constants.. nit:\nWill the test take 5s to finish? Will it be possible to reduce the time? \nWe can mock this out if required.. I think we should probably delete this class :@. +1. probably this import is not used. You can install the new style and run it on your changed files only. It may fix some of these cosmetic issues.. This entire construct should probably be refactored as well. There are standard libraries like gson and jackson to do json serde. This is simply reinventing the wheel. \nIf we do that then the toObject and fillExecutableFromMapObject methods interfaces can be removed and along with it, all the constants etc can be cleaned up as well.. Do these fields change? Else just make everyone final. Makes things simpler.. same comment as above. use final if you can.. I suppose this is a logic change? What does this do?. you can probably reformat this.. This is counterintuitive. Why do we need to reassign isExpired? Can expireCondition.isMet() become false after returning true?. can we log this if we see any funny strings? \nIt is probably cleaner to have enums here.. Thanks for pointing this out. Let me fix it.. At some point, we would like to get rid of these custom injections as well. Looks Ok for now.. I am a bit skeptical about this. We have a lot of distribution code where we package stuff from a ton of locations. Will it be a good idea to stop exercising this code totally? I am wondering whether we could potentially run into surprises while publishing.\nIMO, I would sleep better if I know that all targets build and are working fine. I can sacrifice a minute of build time for that. Let me know your thoughts.. I would prefer the cleanup to not take place if something goes wrong. That is the reason I didn't put it a finally block. Else, I would have simply used @AfterTest to ensure that the cleanup always takes place.. @HappyRay yes. That was my motivation.. Main cause: They are not present in maven central or jcenter.\nWhy we don't care? These modules are not required to compile the code or run the test cases.. I don't want to duplicate each dependency. IMO, this is better than maintaining 2 duplicate dependency lists. That exposes us to cases like what if somebody adds it to one and not the other for example.. yes :) . It adds the copyright notice whenever I create a new class.. Where is the convention mentioned? I use log. I find log to be shorter and yet equally expressive as logger but that's just my opinion. In that case the style guide should fail the build.\n\nDid you set up the checkstyle check?\n\nYes. I followed the development instructions around a week back. Did things change again? . This class was picked up from the Gobblin code base. Let me refactor the code a bit.. yes.. Will take a look and update the PR.. I am not sure about this. This was the suggestion from our internal teams to use this implementation. For now, we can go ahead with this and we can refactor if we find something that is easier.. borrowed this code from Gobblin. Thought it may be useful since we have the same use case. but I agree this is more confusion than help. I'll get rid of them. The HiveException is inside a Lambda. I don't think you can propagate that directly. Correct me if I'm wrong here.. See the description. The code has been copied from Gobblin.. Regarding the log convention, I would just suggest using simply log\nThis is how lombok does it. link: https://projectlombok.org/features/log\n. No, I don't think so. testCompile extends compile by default. But it doesn't seem to pull in from compileOnly which is why I added this line.\n\nIMHO, it is better to stay with the default/convention to avoid surprises as much as possible.\n\nI find it intuitive to have the compileOnly classes available in my test classpath so that I can test my code! In fact, it is counter intuitive to me if my jar gets built successfully yet my tests don't compile.\nGradle configurations are built from file collections so that they can be extended, filtered and manipulated. So I don't think this should come as a surprise to a Gradle user. In fact, I think it might help to take a look at the task and configuration graph.\nlink: https://docs.gradle.org/3.3/userguide/java_plugin.html\n\nIf someone forgets to add a dependency, tests will fail. Right? Why isn't it good enough?\n\nThis is good. But why do have to add it in 2 places is the question. . The MetaException is part of the interface which the Lambda accepts. Pasting the interface below. \n```\n/\n * HiveMetaHookLoader is responsible for loading a {@link HiveMetaHook}\n * for a given table.\n */\npublic interface HiveMetaHookLoader {\n  /\n   * Loads a hook for the specified table.\n   \n   * @param tbl table of interest\n   \n   * @return hook, or null if none registered\n   */\n  public HiveMetaHook getHook(Table tbl) throws MetaException;\n}\n```. I am not too concerned about this since it is simply instantiating a HMS client. But I'm totally open to getting some feedback on how we can do this better.. I agree this is off context. I tried the other way and I see myself making less changes overall and it's counter productive for me. So, I would rather choose to make the code better and wait a little longer for the review. I tend to switch to other things and often forget / feel lazy to create a refactor patch before/after my code changes. \nI don't want to make a whole bunch of changes as well but definitely the ones that come to my eye. This one, for example, has been lurking around for a long time and I haven't touched it because I wanted to make a refactor PR that never happened.. > Modifying the sourceSets is not an issue and is expected.\nAFAIK, I didn't modify any source set. I don't understand the context here.\n\nI thought extendsFrom would replace the existing superConfigs. After some experiments, I realized that it adds to the existing configs.\n\nYes. It simply extends the configuration/collection with another.\n\nAlso since the build only packages the jar and not the run time dependencies, does it need to use compileOnly in the first place? What's your long term plan?\n\nCorrection: build packages the jar WITH the runtime dependencies. compileOnly means that this collection is only used for compiling the artifact and they are not added to runtime. It does not need to be compileOnly since HDFS storage introduced Hadoop as a compile level dependency at this time. But prior to that, Hadoop and Hive dependencies were not shipped with Azkaban.\nThe long term plan IMO should be to get rid of Hadoop, Hive etc dependencies from core Azkaban. HDFS Storage and Hadoop Security Manager code should run in a plugin module like environment.\n. @HappyRay \nLet me know if we should do probably a 30-min or 1-hour discussion on Gradle some time since a GitHub PR doesn't seem to be well suited for explaining Gradle intricacies.. It doesn't. Actually triggerSource is a static variable. Let me fix this.. Ha Ha. Actually, this is just code moved from the AzkabanWebServer class to here. These methods are used by Guice to create these objects. Ref: https://github.com/google/guice/wiki/ProvidesMethods\nSee AzkabanCommonModule code for similar examples.. I don't suspect that the class will be injected here. This should be a fetch since Guice maintains only a single instance of the web server class. Although, this may fail spectacularly if the injection happens while constructing the web server itself in which case this should throw up some sort of a circular dependency error. None of that seems to be happening though. Else the build will fail because of injection tests in AzkabanWebServerTest\n. Nope. This isn't about Guice. It's just defensive programming. \nIt is good to check arguments to make sure that you have lesser surprises.. @reallocf \nshort answer: yes.\nlong answer: This is not just about injection. If you are exposing public APIs or arguments, it is always better to state your requirements up front. This makes it fail fast and helps us figure out the problems earlier.. If this is a new configuration key, then you can add it to Constants.ConfigurationKeys instead. \nWe don't yet have a good standard for placing defaults. Some are listed as DEFAULTS_* in Constants class likeDEFAULT_SSL_PORT_NUMBER.. Just makeuserBlackListaSethere and do acontains()check. That has a couple of advantages.Setensures unique items and contains is an O(1) check.\nnit: probablyblackListedUsersinstead ofuserBlackList?. I know. I did that initially. Then I just decided to stick to the standard factory pattern and have a parameterlesscreate` method. . Valid point. We currently don't have a mapping from token to a conf or a client. Thus, I think the cancellation of \"other\" delegation tokens should be broken. I created #1261 for this. . nit: As @HappyRay suggested, can you try using assertj?. nit: Will this run for the entire 5 sec? I was wondering what happens if we cut the sleep times by a factor of 5. like 200ms and 1000ms. . TL;DR This is beyond the scope of the PR. Mostly my thoughts regarding this class.\nI think we need a better way of managing the status of a process here. Currently what we have is a boolean called killed but effectively what we need is some level of granularity and a way to express it - similar to status.\nThere are certain benefits of maintaining a proper status for a process like NOT_STARTED, STARTED, COMPLETE or KILLED or FAILED. The last 3 being terminal nodes; think of this like a state machine. Having a simple mapping between the job status to the process status may make things much easier. Isn't it? Because a job will fail if a process fails, etc.\nUsing the process as null or not null as signals may not be the most intuitive way of doing it. I think this class is more like a ProcessLifeCycleManager which creates, runs and manages the lifecycle of the process. Currently, it subclasses from Job which is weird. Maybe the Job should have ProcessLifeCycleManager in it since every job runs in its own process. We should probably think of how we can restructure this code to make it simpler and more flexible.. Please note: This logic is cut/paste from the ProjectManager class. Ideally never. This is just for safety. Just trying to keep the functions idempotent.\n. point taken. updated the code.. yup. my bad. fixed.. Yes. That's what @HappyRay is pushing for as well. And I think it has some advantages since we already have it in our dependency.. In such cases, probably we should expose a config parameter that can enable it. Since we are not using it I am thinking of removing it. let me know if you want to restore it. \nWe can also probably add that as a reporting feature separately.. I think we should have a better way of organizing metrics. Keeping all metrics together in one class seems like putting apples and oranges in one basket. Also, such organization of metrics hints that metrics events can be declared from anywhere else in the code. However, dispatch fail / success should only be controlled by the ExecutorManager. Thoughts?. Oh cool. @jamiesjc, In that case, should we just retain these Meters in ExecutorManager then instead? The existing metrics can be refactored separately in a different PR.. Code duplication? Can we create a utility like \nassertSingletons(TriggerManager.class, Triggerloader.class, ...);. Yes. You can refer the design doc.. This is explained in the doc as well.\nThis allows us to categorize any job specific configuration inside a config section as opposed to the top level which is read by the Azkaban Framework.. YML files are intended to be stored in a zip. They define a flow similar to a job file today which defines a job.. Those will come later. I don't foresee that to be an issue. The current change is just to be able to read YML flows.. This should probably be inserted at the top if at all? Do we have to include copyright notices for build scripts?. No content changed here. . This method is no longer static. It moved below because of the save actions plugin. no change in logic. just parameter names were updated.. It is currently being accessed in other classes and probably downstream plugins like TriggerPlugin for example. It may break something.. in the web server code. The loadTriggerPlugins method was extracted into a separate class. This requires further refactoring but phasing it for now.. The port is updated with the sslPortNumber in that case. See line 57. Actually, on second thoughts, I think the log statement in the if block is not required since we are already logging it at the end of the method.. Agreed. The problem is that this method ideally needs 2 outputs: a Connector and a port. I'm keeping this as is for now. I didn't want to create a Method object or maintain a port member to do this.. Agreed.. This method is not used and has been removed. The code below is copy paste from above except that the static modifier has been removed and references have been updated accordingly.. The reason I kept it Status is because the code is already in the web server module in the azkaban.webapp package. And this class is intended to provide the status of both the web and executor. Future changes will pull in the executor status into the web server.\nSo, it is kinda aimed at being the status of the entire system.. There is a configuration key with this name already. Let's have this in Constants.ConfigurationKeys. Removing this parameter may break downstream plugins. I suggest we avoid this refactor. Just mark this deprecated for now.. Removing this parameter may break downstream plugins. I suggest we avoid this refactor. Just mark this deprecated for now.. This needs to be a configuration parameter defaulted to azkaban. This seems tricky. If the effective user is able to write to the directory, then we don't set up permissions? I think we do run into cases today where the effective user is able to write but we are unable to clean up. no?. Let's use the  ExecuteAsUser class for this. If it is sitting in a different package, let's pull it to azkaban-common since this is precisely what the wrapper class was created for.. I would like to have all config keys in one place. But, I think refactoring any public static variable in these classes is a risk. Whether you want to keep things this way or refactor it and call deprecated is up to you. I'm fine with either.. Oh. Yes. Else it would create a cyclical build dependency! :). Possible direction: \nHave an OS Helper/Util class which leverages ExecuteAsUser class to execute OS level functions since we do plenty of that in Azkaban. We have an OsMemoryUtil for example.\n```\n// So OsHelper becomes our central place for doing these kinda stuff.\nnew OsHelper().chown(getWorkingDirectory(), user, group);\nHowever, I don't think this needs to be done now.. I think `uid_t` is a typedef of an `unsigned int`. `char*` might be incorrect. This should be evident if you do a `*username` somewhere - might result in garbage or seg fault. Correct me if am wrong.. Following up from the previous comment: I'm not sure how or whether this works.\nprintf(\"%s\", user); // user is of type uid_t\n``. And I would call iteffective_useror something since that's we are comparing against ingeteuid()`. \nCan we double check?\nfor initgroups() I saw the signature. But get*uid() returns uids which are probably not char*. Did we test this?\nhttps://docs.oracle.com/cd/E36784_01/html/E36872/geteuid-2.html\nThe getpwnam() function for example translates uid to username\nhttp://man7.org/linux/man-pages/man3/getpwnam.3.html. I didn't quite get that. Let's chat tomorrow. This looks a bit weird.. Can we rename the local variable uid to username since it is not the uid.  Even the code\nfprintf(ERRORFILE, \"Requires at least 3 variables: ./execute-as-user uid command [args]\");\nis confusing since it mixes up uid, which is actually an uint vs username which is a string.. same comment here as below. Let's call it username instead of uid.. Let's add a small comment on what needs to be used instead.. Let's add a comment on what needs to be used instead.. nit: Can mention the full reference:\nazkaban.Constants.ConfigurationKeys.AZKABAN_SERVER_NATIVE_LIB_FOLDER\nThis helps IntelliJ track renames inside comments. @kunkun-tang \nYes. This is the pid for the web server. It is not about 'monitoring' the pid. This API is about reporting the current status of the application and pid is an important piece of information here. I agree the executor piece is more important and we do have plans to add that as well.. Question: Generally, this is set to a random number instead of 1L. Does that matter?. The deletion process in project_version marks the project as inactive instead of deleting it. That's why project versions has a whole bunch of records but other tables do not.. As per @HappyRay suggestion, please use javax.inject package. check #1333. This pattern is pretty much a DAO pattern. Should we rename it to ExecutorDao then?\nhttps://stackoverflow.com/questions/19154202/data-access-object-dao-in-java\nhttps://en.wikipedia.org/wiki/Data_access_object. Is this dead code? Was it being used earlier?. Oh. got it. this refactor already went it. . Well, there is azkaban.executor.Executor. However, this is just a nitpick. I leave this to you.\nThis change looks good to go. I like the idea of moving the core data access layer to azkaban-db.. why not import javax.inject.Singleton instead of using the entire path?. I suppose this method has been moved? This code can be simplified a bit; may be in a later change.. Although, the comment seems a bit weird. :|. This is great! I really like the simplification of dependencies. Also +1 for removing the extends as well.. Awesome work adding tests! \ud83d\udc4d \ud83d\udc4d . nit: Can probably add a line in between methods.. Is this class testing 2 classes here? If yes, then it might be cleaner to split this into separate test classes. If this db setup code is common for too many classes, then we need to think of a way to consolidate them.. So the tests run only when the db exists? Else everything passes?. Let's use a logger here.. This is more like ExecJettyServerModule I presume?. Can probably move the constants inside the module itself.. Was this change intentional? Else can probably revert this. As long as it is a static variable, I don't think it should create a circular dependency since you don't need to instantiate the class to load a static constant. Could you give it a try and let me know. One of the injection tests should blow up in that case.. The class is abstract by design. The idea is that a DAG Node can be either a Job or an embedded Flow or may be something else. Here job and flow are concrete classes but a node technically doesn't mean anything. Hence it is an abstract class.\nWhy is it not an interface?\nIt could be! Just that I think there might be some common code between a Job and a Flow which we can house here.. I changed the code a bit here. The current code will simply catch the exception, log it and continue.. yes. Else, it would be a big problem!. Oh! now I get it. What I mean by the comment is that the latest ones are removed from the delete list. The remaining items in the list get removed.. I think if upload fails, then it probably will raise an exception and the delete code will not execute.. The database cleanup is tricky. There are several tables which are used to show data to the UI. This may be a bigger item but we need to improve the cleanup strategy there as well. Currently, this deals with just the storage cleanup.. done.. @HappyRay \nI would prefer to stick to all (0) as the default for now since it is in line with the current implementation. Therefore any new build doesn't suddenly change the behavior of the app. It's only when you turn on this knob, you see a behavior change.\n@reallocf \nI like the idea! It is much more explicit. However, I'm a bit reluctant to introduce that complexity in an almost non-user facing, and probably seldom used config variable. This keeps it very crisp. Less validation. Less code.\nThe same goes for introducing another boolean config variable. Thoughts?. Even if we face this error, this shouldn't affect the execution of Azkaban. In the next upload, the clean up will be attempted again. The recovery piece was missing and has been added.. updated.. typo in 'class'. Let's also mark it @deprecated then.. @kunkun-tang \nCan you test what @HappyRay suggested. In that case, we may not even have to add a testJar task.. The storage cleanup needs to be done before the DB cleanup. The reason is that the reference to the files in the storage is maintained by a key which is present in the db in the project_verions table.\nSo every time we try to cleanup, we find out all the versions of a project and remove the entries that we need to retain. The rest of the items are deleted one by one using the delete API call.\nSo as long as those entries are in the DB, they will eventually be cleaned up. However, vice versa is not true. If the database entry doesn't exist, then Azkaban has no idea what items exist in the storage and cannot clean them up. This ensures a conservative cleanup and mandates that the storage is cleaned up before the metadata in the DB is removed.\nSo, to answer your question, there is no harm in leaving the older versions entries in the DB. If the files aren't present in the DB it will simply log it and continue.. We have just 1 constant that we are using from hive_metastoreConstants right? Should we just import that?. ",
    "danybenjamin": "I am seeing a similar issue. \nAzkaban will not let me submit more than 10 jobs. However, it is not doing anything with the jobs in \"Preparing\" state. It did kill one job eventually - saying it was unresponsive and evicted it. \nIs there a way to kill these executions while in \"Preparing\" stage? Even if it's manually from the DB. \n\n. ",
    "xingfei": "I've got the same problem as you. Azkaban supports jexl expressions, you can get yesterday date using jexl.\nSample code is:\nday=$(new(\"org.joda.time.DateTime\").minusDays(1).toString(\"yyyy-MM-dd\"))\n. ",
    "taobaoguest": "@hluu but if i set executor.flow.threads to a small number,all job's status were set prepared and can not run,why?and now,the thread number like this:\n\"FlowRunner-exec-XXXX\" prio=10 tid=0x00007f4da5ff1000 nid=0x1fea waiting on condition [0x00000000438d8000]\njava.lang.Thread.State: WAITING (parking)\nat sun.misc.Unsafe.park(Native Method)\n- parking to wait for (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\nhave increased to 200.\n. ",
    "thejasr9": "How do I convert this in a CURL request? \n. But this returns the html source of the page. It doesn't return JSON. Am I missing something?\n. ",
    "timyitong": "Anyone currently is working on this issue? I also met with a situation that in need of this API with JSON response. \n. The current API doc is limited. I just added some basics in a branch, still working to gain push access so that I can send out a pull request.\n\nOn Aug 14, 2014, at 7:14 PM, alexBJW notifications@github.com wrote:\nWhere can I find theWeb-Service API documents? Thanks.\n\u2014\nReply to this email directly or view it on GitHub.\n. Thanks, Anthony!\n\nOn Aug 15, 2014, at 8:42 AM, Anthony Hsu notifications@github.com<mailto:notifications@github.com> wrote:\n@timyitonghttps://github.com/timyitong, you should fork the azkaban project and make you changes in your fork, and then open a pull request to merge your changes.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban/issues/298#issuecomment-52320718.\n. Hey, Anthony I just sent a pull request here towards gh-pages branch:\nhttps://github.com/azkaban/azkaban/pull/307\nOn Aug 15, 2014, at 10:20 AM, Yitong Zhou yizhou@linkedin.com<mailto:yizhou@linkedin.com> wrote:\nThanks, Anthony!\nOn Aug 15, 2014, at 8:42 AM, Anthony Hsu notifications@github.com<mailto:notifications@github.com> wrote:\n@timyitonghttps://github.com/timyitong, you should fork the azkaban project and make you changes in your fork, and then open a pull request to merge your changes.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/azkaban/azkaban/issues/298#issuecomment-52320718.\n. @erwa : Thanks lot! Great feedback! I'll make the modifications accordingly.\nOne more thing: I can only get \"null\" status for the fetch job status API, whether the job is running or has already finished. I am probably missing a parameter or misunderstand about what jobStats mean. Could you also try and see if that's the case?\n. @erwa : Hi Anthony, thanks for the confirmation! I've removed the jobStats API and added fetchExecutionFlowUpdate.\n. Thanks, David! The ul tag must be a leftover after copying and pasting. Got it removed.\n. ",
    "alexBJW": "Where can I find theWeb-Service  API documents? Thanks.\n. So,when can I see the Web-Service API documents?  I just know little about the APIs,which are shown in the examples.\n. I find it. Just right click on the button,and there is a 'enable'.\n. ",
    "mkanchwala": "Any updates on the same? I am also facing the same issue, Please help!\nI am using Azkaban 3.0\n. Any updates on the same?\n. ",
    "xibeilijp": "Hi,everyone.\nI want to ask a question.\nwhen I use hive-1.2.1 and zeppelin-0.5.6,I got an error like blow:\nnosuchmethor: org.apache.hadoop.hive.shims.HadoopShims.isSecurityEnabled()Z()\nIs this a hive bug?\nThk\n. when I see blow the information.It is dead code.\nhttps://issues.apache.org/jira/browse/HIVE-5786\n. ",
    "jsharley": "True, I do use the history tab in its stead.  I find the recently finished useful though -- especially for long running jobs that can disappear off the radar unless I resort the history tab to be based on End Time vs Start Time.\n. Are there plans to add this functionality to the AJAX API?\n. ",
    "kingster": "Hi Anthony,\nWe use azkaban as our monitoring and alerting system. In this scenario, log files as attachments, increases our response time to any issues, since the error files are readily available, specially on mobile devices ( though the same can be accessed via web UI as you mentioned but logging in and seeing the response becomes tedious time when there are multiple alerts, and action is to be taken based on the cause which threw the alert ) , and assessing the  severity of the issue straight away  and appropriate action if any taken immediately. \n. Hi Anthony\nThanks for pointing out this case. This skipped my mind, since for most of our use cases the log files are normally small. This change set doesn't by default start by attaching files. This has to be specifically enabled via the config.\nWe can have another config, which says the max size of the attachment, and if that is crossed, it would skip it from attaching to the email.  How do you think about it?\n. ",
    "hugoboos": "Yes, also having this issue. Same here: https://github.com/azkaban/azkaban/issues/588\n. I thought the same. Here it is also not working.\nLooking the source I found this: https://github.com/azkaban/azkaban/blob/71b5dd9a83935c2f253b0d944e47909b918b06bc/azkaban-common/src/main/java/azkaban/jobtype/JobTypeManager.java#L128\nLooks like the global.properties is only used when there is a plugins/jobtypes/common.properties file. But after creating that one, it still won't work.\n. Problem also described here: https://github.com/azkaban/azkaban/issues/310\n. I did some more testing with other versions. Version 3.1.0 works, 3.2.0 does not.\nTo be clear. The LDAP functionality is not part of Azkaban, but added via a plugin.\n. Yes that is correct. From 3.2.0 it does not work anymore. And i'm getting those errors.\n. ",
    "dhulse": "I am new to Azkaban (I started using it last week) and I have run into this same issue. I played around with some changes and I finally got the parameters in my Flows to use global.properties. In order for Azkaban to use my global.properties I had to do the following:\n1) I had to create the file plugins/jobtypes/common.properties (for reasons mentioned by @deepbluesnow )\n2) I had to make the following code change to public Job buildJobExecutor(String jobId, Props jobProps, Logger logger)in the JobTypeManager class. It appears that pluginSet.getCommonPluginJobProps() was not being called in buildJobExecutor, that is why the global properties were not being loaded into each job in a Flow.\nBefore\njava\nProps pluginJobProps = pluginSet.getPluginJobProps(jobType);\nif (pluginJobProps != null) {\n  for (String k : pluginJobProps.getKeySet()) {\n    if (!jobProps.containsKey(k)) {\n      jobProps.put(k, pluginJobProps.get(k));\n    }\n  }\n}\njobProps = PropsUtils.resolveProps(jobProps);\nAfter\n``` java\nProps pluginJobProps = pluginSet.getPluginJobProps(jobType);\nif (pluginJobProps != null) {\n  for (String k : pluginJobProps.getKeySet()) {\n    if (!jobProps.containsKey(k)) {\n      jobProps.put(k, pluginJobProps.get(k));\n    }\n  }\n}\n// added code\nProps commonJobProps = pluginSet.getCommonPluginJobProps();\nif (commonJobProps != null) {\n  for (String k : commonJobProps.getKeySet()) {\n    if (!jobProps.containsKey(k)) {\n      jobProps.put(k, commonJobProps.get(k));\n    }\n  }\n}\njobProps = PropsUtils.resolveProps(jobProps);\n```\n. ",
    "deepbluesnow": "Will do, sorry about that =)\n. Made the changes as requested, Emailer now calls AbstractMailer for useAuth property.\n. Removed usesAuth variable from emailer, it now simply calls the AbstractMailer method to get the useAuth property\n. Yes, there shouldn't be a need to. I was kinda puzzled as well as to why Emailer attributes didn't make use of the public methods in the AbstractMailer... didn't put too much thought into it and just followed the existing code to make it consistent. \nIf you'd like I could modify Emailer to have it grab the useAuth property from AbstractMailer instead.\n. ",
    "joeharris76": "Bump. Just lost an hour to this yesterday. :-/\n. The login lasts 24 hours as long as you're on the same connection. I'd suggest that you use a tool like LastPass to make user/pass entry quicker.\n. AFAICT the concept in Azkaban is that any given job should stand alone. E.g. it either succeeds and it's children can run or it fails and notifies the operator. There is no concept of branching logic or job skipping.\nIf you have logic that requires walking back from failure I'd suggest that you could encapsulate it inside a single job. Alternatively, on occasion I've created flows that ignore failures and just rerun on a schedule, e.g., no notifications on failures and disallow concurrent runs. \n. ",
    "vbauer": "I have the same problem with solo instance.. ",
    "prateekpatel": "Seems like you are trying to run azkaban-solo-start.sh run from /bin directory.\nTry to execute bin/azkaban-solo-start.sh bin from your root directory.. ",
    "sjakthol": "I don't remember if there was any particular reason to use python jobs instead of command jobs. Most likely the functionality of python (and any of the other extra job types) can be implemented as pure command jobs.\nMore generally, we would be happy to get rid of these extra job types as they are always executed as the user running the azkaban executor which gives users pretty much the rights to do anything they want. At least the command type jobs can be limited a bit with the execute-as-user functionality offered there.. This looks good and would definitely be useful for us (and I would guess to other users of Azkaban too). Would it be possible to get this moving forward now that it has waited for a bit over year to get attention?.  Any chance to move this forward? Ping @kunkun-tang. I rebased the changes on top of the latest master and tests seem to be passing. Consider this my monthly ping for this pull request :). Switched from [ to [[ in both places.. Rebased the changes.. As commented on the issue #319, we would be able to live without these job types.\nAs far as I can remember, the command job does not suffer from this issue.. Fix here: https://github.com/azkaban/azkaban/pull/1794. I created a new test case to ensure this feature works as intended in the future.\n@HappyRay, would any further test cases be required?. No particular reason. I just copied the boilerplate over from FlowUtilsTest.java and that happened to use this kind of approach.\nI have now changed this to be a private method instead.. Good comment. I changed this to a regular assert.. ",
    "aslotnick": "I'm running into a similar issue in version 3.1.0.  This functionality was working on 2.5.0 but I can't get it to work with the later version. \nI have defined a property in the file \"azkaban-exec-server-3.1.0/conf/global.properties\".  And I have set \"executor.global.properties=conf/global.properties\" in the file \"azkaban-exec-server-3.1.0/conf/global.properties\".  \nHowever, command jobs are not picking up the property from this file.\nAny idea what I might be doing wrong? Or, should this feature be removed from the 3.x documentation?\nThank you.\n. ",
    "gladmon": "I was able to get this to work, but only by looking through source and how the properties are loaded. You need to do the following from the azkaban-exec-server-3.8.0/ folder (thats the version we are using):\n\nmkdir -p plugins/jobtypes/command\n   touch plugins/jobtypes/common.properties\n   touch plugins/jobtypes/command/plugin.properties\n   echo 'jobtype.class=azkaban.jobExecutor.ProcessJob' > plugins/jobtypes/command/private.properties`. I just came across this too with 3.8. Seems that the update.execution_flows.3.0.sql file is when that column was added, but the sql file to create the table, create.execution_flows.sql, was never updated. Same for create.active_executing_flows.sql.\n\nWork around, run the update scripts. Docs could be updated to say to run the update scripts, but I think the intention was to have a single sql file to run to set up the DB.\n. ",
    "trentgerman": "@gladmon does this solution only work for jobs of type command? Or will it work for all job types? . @xunnanxu thank you! That was a clear, concise answer. Now I understand the error azkaban was showing. Is there any documentation on ProcessBuilder? \n. @juhoautio I'm on azkaban 3.39.0-12-gb44c688 . I've tried your solution and I still have a rogue flow that is running forever. \nThere is only 1 executor in the table now. Is there another way to fix this issue, other than updating the version of azkaban? I'm hesitant to start updating tables in the mysql database without guidance. I would hate to leave azkaban in a worse state than it already is!\nThat being said, I'm wondering if the easiest fix is to find each table with exec_id as a column and just delete the rows containing this exec id. How does that sound? \nHere is the rogue job: \n\n-Trent. @juhoautio This worked! (mostly). The flow still shows up as running when I query the history for that flows name -\n\nBut I don't see it when I query the history for running flows. This is good enough for me. \nThanks again! \nregards,\n-Trent . Oh! The error just happened again, starting with execution 7102. I see this in the logs -\n330 2019-02-12 20:15:39 INFO  ExecutionFlowDao:72 - Flow given product_dataset_int given id 7102\n331 2019-02-12 20:15:39 INFO  ExecuteFlowAction:230 - Invoked flow sqlserver.product_dataset_int\n332 2019-02-12 20:15:39 INFO  Condition:122 - Done resetting checkers. The next check time will be 2019-02-13T14:15:00.000-06:00\n333 2019-02-12 20:15:39 INFO  JdbcTriggerImpl:138 - Updating trigger 47 into db.\n334 2019-02-12 20:15:39 INFO  ExecutorManager:256 - Successfully refreshed executor: ip-10-99-47-200:12321 (id: 65) with executor info : ExecutorInfo{remainingMemoryPercent=75.98592472703717, remainingMemoryInMB=6066, remainingFlowCapacity=28, numberOfAss    ignedFlows=2, lastDispatchedTime=1550001639500, cpuUsage=0.0}\n335 2019-02-12 20:15:39 INFO  ExecutorManager:1799 - Using dispatcher for execution id :7102\n336 2019-02-12 20:15:39 INFO  ExecutorManager:1831 - Reached handleNoExecutorSelectedCase stage for exec 7102 with error count 0\n337 2019-02-12 20:15:39 INFO  ExecutorManager:1799 - Using dispatcher for execution id :7102\n338 2019-02-12 20:15:39 INFO  ExecutorManager:1831 - Reached handleNoExecutorSelectedCase stage for exec 7102 with error count 0\nSame error. Any ideas? . Yes! They are here -> \n$ find . -wholename '*conf/azkaban.properties' -exec grep -EHn \"azkaban\\.executorselector\\.filters|azkaban\\.executorselector\\.comparator\" {} \\;\n./azkaban-exec-server/build/install/azkaban-exec-server/conf/azkaban.properties:59:azkaban.executorselector.filters=StaticRemainingFlowSize,MinimumFreeMemory,CpuStatus\n./azkaban-exec-server/build/install/azkaban-exec-server/conf/azkaban.properties:60:azkaban.executorselector.comparator.NumberOfAssignedFlowComparator=1\n./azkaban-exec-server/build/install/azkaban-exec-server/conf/azkaban.properties:61:azkaban.executorselector.comparator.Memory=1\n./azkaban-exec-server/build/install/azkaban-exec-server/conf/azkaban.properties:62:azkaban.executorselector.comparator.LastDispatched=1\n./azkaban-exec-server/build/install/azkaban-exec-server/conf/azkaban.properties:63:azkaban.executorselector.comparator.CpuUsage=1\n./azkaban-web-server/build/install/azkaban-web-server/conf/azkaban.properties:59:azkaban.executorselector.filters=StaticRemainingFlowSize,MinimumFreeMemory,CpuStatus\n./azkaban-web-server/build/install/azkaban-web-server/conf/azkaban.properties:60:azkaban.executorselector.comparator.NumberOfAssignedFlowComparator=1\n./azkaban-web-server/build/install/azkaban-web-server/conf/azkaban.properties:61:azkaban.executorselector.comparator.Memory=1\n./azkaban-web-server/build/install/azkaban-web-server/conf/azkaban.properties:62:azkaban.executorselector.comparator.LastDispatched=1\n./azkaban-web-server/build/install/azkaban-web-server/conf/azkaban.properties:63:azkaban.executorselector.comparator.CpuUsage=1. excellent! I will try that. \nAny idea why the webserver will dispatch the flow after a bounce? . ",
    "togoon": "I also encountered the same problem,  Who can to solve this question?\n. I have the same question\n. @davidzchen   @rbpark  @cjyu   @hluu  @logiclord \n. +1, i'm also very looking forward to this function. @davidzchen  @rbpark @cjyu   @hluu . ",
    "wndhydrnt": "The gradle DSL reference provides information on this.\n. ",
    "Victsm": "Just pushed the changes related to removing the unnecessary SuppressWarnings annotations.\n. Pushed another commit that changes the name of the method getValidatorInfo() as suggested.\n. Just pushed the commit containing updates related to the property tag in the validator xml configuration file.\n. The ValidatorClassLoader class is basically taken from hadoop-common used in the separate job ClassLoader.\n. Just updated the pull request fixing the potential NPE problem.\n. Just commit the change to update the test case.\n. I have already tested this patch in single server mode to verify that when multiple uploads happening at the same time, the project archive file path passed to the validator plugin is the right one. \n. The previous fix depends on Java 7 to close the URLClassLoader. Since our Azkaban runs on top of Java 6, we do not have access to the close method and we need something else that fixes this problem.\n. Commit more code to this pull request.\n. Commit code that catches the exceptions and logs them.\n. Updated the pull request addressing these comments. \n. Updated the pull request.\n. Updated the pull request with the comment.\n. The problem is related to the size of the message that can fit in the Cookie. Azkaban puts these error/warning messages inside a Cookie and when the length of the message goes over 4000, the entire message gets discarded from the cookie. I added code to truncate the message at the length of 4000 to avoid missing messages again in the future.\n. Updated the pull request.\n. canRead() already checks for the existence of the directory.\n. This for loop checks for the highest level of status from all the ValidationReport. We still need to use compareTo() to see whether WARN or ERROR has been generated.\n. I was following the way that DirectoryFlowLoader uses ProjectManager's logger instead of its own to log messages.\n. That's my intention to make sure the validators can be changed without bouncing Azkaban server. Previously, the default validator, DirectoryFlowLoader, is also created each time a project is uploaded.\n. Do you think that throwing the ValidatorManagerException here is safe? It is a RuntimeException.\n. If the user uncheck the checkbox, then the field \"fix\" will not be sent to the server. This is the same if we just turn off this part of the UI entirely. Thus, there is no way to distinguish whether the user unchecked the checkbox or we simply do not turn on this UI. Adding this hidden input, when the user uncheck the checkbox, the field \"fix\" will have the value set in this hidden element. This will enable us to distinguish the 2 scenarios.\n. ",
    "zuzeep": "in version 3.50, if path azkaban-webserver/plugins/triggers is empty, it will the same exception. . ",
    "zhpngpeng": "hellow ,i got some problems when i set the deployment of project local and  i hope i could  get some help from you ...qq;1697516768 email:1697516768@qq.com please . hellow  , i am building the project azkaban and i am trouble with this \n\ni thought there maybe someone could help me with this .... hey , i'm a student . i try to build this project local and i hope i could get some help here .. . qq:1697516768 \nemail :1697516768@qq.com\nI leave my contact information here .. ",
    "hy2014": "thanks for your correct.\n. ",
    "letusfly85": "can someone create LDAP plugin for azkaban?\nor\nIs there any possibility LinkedIn open the plugin source?\n. I found that system requirement is at least 3GB memory for azkaban.\nAfter I changed an instance type on AWS from t2.medium to r3.large, it solved...\nSorry :sweat_drops: \nThank you.\n. ",
    "appanasatya": "BufferSize was added as static final in AzkabanWebServer previously. So, I went ahead and added it as static final for AzkabanExecutorServer. Let me make it configurable for both of these classes by dragging them to config(azkaban.properties).\n. Just made the changes for configurability and Pull request was updated.\n. Corrected kb related spellchecks and made few corrections..\n. ",
    "johnyu0520": "Hey Satya Harish,\nThe change looks good, except for a minor name change.\nThere's a recent merge request for setHeaderBufferSize for exec server.  Expect some minor merge conflicts.  However, since your change is more comprehensive, I think we should use the code you have in place.\nThanks!\nJohn\n. LGTM\n. added additional logging\n. LGTM\none minor suggestion is in the catch block, we should put either logs or comments to the effect of \"skipping this trigger, moving on to the next one\" (in addition to the logging the error, as you have already done)\n. Looks good, and we can observe the feedback from user on this timing changing\n. LGTM\n. LGTM\n. LGTM\n. lgtm\n. looks good\n. Looks good\n. LGTM\n. LGTM\n. LGTM\n. LGTM\n. closing the pull request for now as more modification is in progress\n. LGTM\n. +1 for changing second example to hdfs://\notherwise LGTM\n. LGTM\n. LGTM\n. LGTM\n. LGTM\nthough as a side note, I don't know if we can do something better for the build names (animalDistTar?)\n. LGTM\n. LGTM\n. LGTM\n. LGTM\n. LGTM\n. Hey David,\nDo you mean to merge the code from master branch?  Or do you mean for me to squash my commits so the log looks more clean?\nThanks!\nJohn\n. Hey David,\nThanks for your such detailed instructions!  I've copied them down somewhere, as it will come in handy when merging into master :)\nI'll do the squash, and that should reduce a lot of cluttering on the logs.\nHowever, for the branch, I've purposely worked off multiexecutor-canary.  That is the version currently deployed in Linkedin, and if I want to push my change, I'll need to build on top of multiexecutor-canary so that I can push my changes into Linkedin production.  \nWe plan to merge multiexecutor-canary into master after my execute-as-user feature request.  That will be another whole big operation, and we can watch out to use rebase at that time.\nThanks!\nJohn\n. also see https://github.com/azkaban/azkaban/pull/517 for previous comments and feedbacks\n. LGTM\n. LGTM\n. LGTM\n. LGTM\n. Verified with Gaurav that changing from Map to Map should not have downstream impact.  The reasoning is because the ultimate return format from the API is json, and also serializing the ExecutionOptions object is not an issue for the ObjectMapper\nLGTM\n. LGTM\n. LGTM\n. LGTM\n. isMemoryAvailable (or something similar) might be a better variable name for the boolean, because we are not actually asking for memory like how malloc is doing it.\nOtherwise, at least name it in the boolean variable name convention, e.g. isMemGranted\n. Maybe add quick a comment on what this method is doing and how is it computing the ProcMemory?   It doesn't seem like a trivial method.\n. +1\nyou might need to do\nloadAllProperties();\nprepareAllJobProps(flow, this);\nto have the variables resolved?\n. Given this is a static method, users/developers may not realize that an init needs to be called first.\nIn this case do you want to help the users/developers out by doing init for them, print a warning, or something of that sort?\n. this part need to handle \"strMemSize.endsWith(\"k\")\" as well.\n. jobProps.getBoolean(AZKABAN_MEMORY_CHECK, false)\nshould this be defaulted to true? so that we will by default check for memory?\n. do we want to name the function a bit better so that we know what exactly is being \"customized\"?\nmaybe insertMemoryCheckToJobProperties (or something)\notherwies commenting the method would also help\n. Could we make this name to be \n\"jetty.connector.*\"\nThis way it is more clear the setting is regarding jetty.connectors,\nand also fits with the \"jetty.connector.stats\" specification above\n. Could we make this name to be \n\"jetty.connector.*\"\nThis way it is more clear the setting is regarding jetty.connectors,\nand also fits with the \"jetty.connector.stats\" specification above\n. I was just thinking if there's a way to implement this feature (and sort it) without touching the Props.\nI think it can be done with:\nTreeSet keySet = jobProps.getKeySet();\nfor( String key : keySet ){\n// do the magic\n}\nA bit less code and a bit less code change?\n. nit picking, retrieval is mis-spelt :)\n. just curious, if the test is not setup, should we setting up the test, or should we be returning success with the test?\n. Just thinking, should the variable \"valid\" be renamed to something better?\nDoes it stand for \"shouldPurge\", or does it stand for \"purgeOperationSuccessful\"?\n. Looks like this if statement contains 2 possible scenarios.  One is project already deleted.  The other is user does not have admin permission.  Should they be sending out different error messages?\n. I think there's merits going both ways, so providing a flatten method is probably also fine\nif we are going the treeset route then yes, we'll still need to new a TreeSet...\n. I think \"skip\" means \"offset\"?\n. I think host and port should also be final? Given that they are all driven from the DB and should not be modified\n. When this fails, does this return null or does this throw an exception?\n. I don't know if tie-break (or something similar) is more intuitive?\n. I know the variable naming is meant to be generic, but in our case, how does ExecutableFlow and Executor map to \"item\" and \"object\"? which one maps to which? is it possible to make the naming a bit more specific?\n. should this method be called getMax, getBest, getTop, or something like that?\ngetNext gives me the impression of an iterator, so I would expect two calls to getNext() return 2 different values.\n. +1\nalso makes the test a bit hard to read\n. Just thinking\nDo we always need that much (12) executors to unit test our dispatching features?\nWondering if it's possible to prove certain aspects of our dispatch with less executors\n. Just wondering, are we going to try match these patterns case specific, or non case specific?\n. consolidate this browser pattern with the StringUtils.BROWSER_PATTERN?\n. I don't have a very strong preference between using Date or long (millis since epoch) to represent time\nHowever, if we are using Date before java 8, I think it's better to use JodaTime.  I think it is a lot more intuitive than the java built in Date functionality.\n. nit, typo on line 73\n. wondering what does this mean:\n\"default comparator from Collections class\"\n. using   in java doc can help with preserving formatting\n. I think the comment is not up to date?\nalso given that the return type is boolean, I am assuming the method name would something like isXXX, or hasYYY\nOr, is it possible to make the return type Integer, and use null as some kind of signal\n. maybe queuedFlowMap and queuedFlowList, to show that they are closely related? (just an idea)\n. is variable name \"ports\" a misnomer? As we seem to be putting server:port pair into the HashSet\n. maybe change the wording to \"running flows and non-dispatched flows\"\nI misread the comment to (running && non-dispatched)\nOr, we can define these terms somewhere (maybe top of file)\n. List = new ArrayList\n. I was thinking that it might be better for readability if we do\n1. this method returns List\n2. the calling method calls  executionIds.addAll(retval)\nOtherwise I had to infer that the executionIds List is actually modified on entering the method\nWondering if people have thoughts/preferences to this\n. want to create a queue and dequeue method for accessing the Map and the List? this way we can make sure people will not forget to do one or the other operation\n. +1 on Evan's logic.  Might be more straightforward to reason\n. Do we want to document somewhere saying whether bigger number is higher/lower priority?\n. might want to include id and isActive? (should be helpful for debugging)\n. I am actually thinking since these code are mostly newly added, is this actually a good time to create a separate class and put them outside of this already big ExecutorManager?\n. @logiclord  I think you accidentally hard coded the return value?\n. just thinking, do you think we should check in the queuedFlowMap first, then check in the runningFlows?\nOtherwise there is the very very very slim chance of when the check is being performed on RunningFlows, it was being taken out of the queue, and when we check the queue, it is already in the RunningFlows\n. should lastProcessingTime something like [last|previous]Executor[Refresh|Update]Time? \n. A method that can be put in a TestUtils class and reused?\n. expecting an exception?\nhttp://stackoverflow.com/questions/156503/how-do-you-assert-that-a-certain-exception-is-thrown-in-junit-4-tests\n. change to test for exception\n. change to test for exception\n. just wondering, is it better if we default to DEFAULT_FLOW_PRIORITY and only bump it up to ADMIN_PRIORITY if the submitter is an admin?\nThough logically it will behave the same\n. I was actually thinking of having the Statistics class below named ExecutorInfo or ExecutorStats..\n. what does this AZKABAN_ACTIVE_EXECUTOR_REFRESHINTERVAL_IN_FLOW control?\n. an aesthetic choice:  Do you think we should just pass in the ExecutionOptions object and executionId (for logging)? This method doesn't seem to require other things in the exflow.\n. update the javadoc to be more understandable?\nAlso my understanding on the logic is that if anything happens, it will return a null.\nIs it possible that you want to return with different types of exceptions (or different exception messages) so that we know what went wrong in this method? (db connection error vs not being able to find specified user specified executor)\n. +1 on reusing.\nI was also thinking whether a threadpool's necessary, or just an arraylist would do?  Because you are not using the threadpool to limit parallel execution or anything?\n. do we want to print a message that is more user/oncall actionable? (or say accordingly that this is just FYI and no action required)\n. nit: formatting is off, and second \"is\" should be \"if\"?\n. should status be renamed to enableQueue or queueEnabled?\n. I guess my question is, \nmight the caller function/code want to know which exception scenario it ran into?\nIf you have it in logs humans will understand why but it would be manual intervention\n. I've confirmed the flag to work, which will enable the worst case scenario of rolling back.\nHowever, how to warn users beforehand and the impact analysis will be something harder to do\n. done\n. done\n. sorry, what should this be changed to?\n. fixed both malloc and memset\n. done\n. done\n. I am just wondering: what happens if this sql command does not complete and throws an exception?\nThe system will be in an inconsistent state of having submitted the flow, but not having it registered in the DB (and not be in the RunningFlows map, etc).  Should we handle this scenario?\n. nit-picking on names again :)\nCan we name it something along the lines of SelectAndDispatchFlow? and also spell it out in the javadoc for it?\n\"process\" can potentially mean lots of different things even within the ExecutorManager.java context\n. Is it possible to re-write this code snippet into a function as it is used multiple times\n. do we want an else statement for this if?\njust in case we have a programmer error?\n. might help to print which actual values you got? (i.e. which of the 3 you got, for instance)\n. I believe  will help to preserve the format once it goes into HTML\n. I see.  That's a good point\n. per explained in offline discussion, setuid() and setgid() only affects the process in which it is invoked\n. done\n. done\n. done with paren and braces.\nFor my usage of LOGFILE and ERRORFILE, this is per coding convention of original Hadoop-Common code:  https://github.com/apache/hadoop-common/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/native/container-executor/impl/container-executor.c\n. I am curious, shouldn't \n\"currentContinuousFlowProcessed++;\"\nbe added right after line 1873?\notherwise we will count 1 extra when a exflow wakes up from the sleep section,.even though it hasn't been assigned\n. ok I guess the logic will perform correctly.  \nJust curious why not put the currentContinuousFlowProcessed++;\ncommand inside the else statement?\n. after sync up with Gaurav, looks good\n. format nit: maybe a space behind the comma?\notherwise LGTM\n. looks like it disappeared by accident.  Added back in\n. done\n. (won't fix for now)\n. If the concern is to make sure that the specified file exists, I have verified during testing that it will throw a FileNotFoundException further down the line, which is the expected behavior\n. Agreed we are sacrificing this option.\nHowever, since execute-as-user can pose as root and potentially take over the Azkaban box, I would rather be safe than sorry, and make this trade off \n. Good point.\nI did this because the 2 lines for EXECUTE_AS_USER_OVERRIDE (there are actually 2 different parameters in this method) is meant to be a short term loophole.  I would imaging those 2 lines be removed when the time comes to close this loophole.\n. done\n. done\n. done\n. done\n. do we still want to mention the 2 server mode?\n. Do we want to mention\n1. it's possible to choose multiple\n2. what is the delimiter if want to choose multiple\n. Do we want to mention\n1. it's possible to choose multiple\n2. what is the delimiter if want to choose multiple\n3. Does ordering of the comparator matter? (I remember we are suppose to change the weighting somewhere?)\n. exeu: typo? (or maybe it renders ok)\n. ",
    "wgzhao": "I have got the same error\n23-12-2014 03:05:41 CST 001_schedule ERROR - Error writing out logs for job mysql_dependent:sp_rpt_rcp:rcp_grpmobile_summary\nazkaban.executor.ExecutorManagerException: Error writing log part.\n    at azkaban.executor.JdbcExecutorLoader.uploadLogFile(JdbcExecutorLoader.java:706)\n    at azkaban.executor.JdbcExecutorLoader.uploadLogFile(JdbcExecutorLoader.java:650)\n    at azkaban.execapp.JobRunner.finalizeLogFile(JobRunner.java:378)\n    at azkaban.execapp.JobRunner.run(JobRunner.java:463)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n    at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:166)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:724)\nCaused by: java.sql.SQLException: Duplicate entry '1554-mysql_dependent:sp_rpt_rcp:rcp_grpmobile_summary-1-0' for key 'PRIMARY' Query: INSERT INTO execution_logs[xxxxxxx]\n    at org.apache.commons.dbutils.AbstractQueryRunner.rethrow(AbstractQueryRunner.java:363)\n    at org.apache.commons.dbutils.QueryRunner.update(QueryRunner.java:490)\n    at org.apache.commons.dbutils.QueryRunner.update(QueryRunner.java:403)\n    at azkaban.executor.JdbcExecutorLoader.uploadLogPart(JdbcExecutorLoader.java:728)\n    at azkaban.executor.JdbcExecutorLoader.uploadLogFile(JdbcExecutorLoader.java:702)\n    ... 9 more\n. ",
    "zpappa": "+1 I don't see this answered anywhere and have the same question.. ",
    "karanluthra": "I faced the same error message when uploading a project zip to a project (both via the WebUI and the AJAX API) and I found that starting the server like\n./bin/azkaban-solo-start.sh\ninstead of\nsh bin/azkaban-solo-start.sh\nhelps solve my case. Haven't thought yet why this happens though.\n. ",
    "PaniniGelato": "got the same error while uploading..\nthe comment of @karanluthra saved my life\ni am using azkaban v3.0. memCheck.enabled=false\nazkaban.memory.check=false\ntry add these config to skip memCheck @wanglifengwf . ",
    "badbye": "Still no document about it?. Thanks for your reply. At least I know how to change it if I really want to replace all of them.. ",
    "josiah14": "^ @erwa The line of code you provided does not make it obvious that flow parameters are supported per the definition here:  http://azkaban.github.io/azkaban/docs/latest/#executing-flows (go down to Flow Parameters).  I just see there that the request options are being parsed and that it's obvious that the e-mail options are utilized.\nThis line of code looks more relevant.  Is this, indeed, the purpose of the 'flowOverride' option?\nhttps://github.com/azkaban/azkaban/blob/master/azkaban-common/src/main/java/azkaban/server/HttpRequestUtils.java#L100\n. Google Groups has figured this out, it just needs to be added to the docs.\nhttps://groups.google.com/forum/#!topic/azkaban-dev/pUYYpsmNsbk\n. ",
    "vickyi": "the doc is: \nhttps://azkaban.readthedocs.io/en/latest/ajaxApi.html#request-parameters-8\nExample Values : flowOverride[failure.email]=test@gmail.com. +1, we need this function too!!. @archongum my flow config like this:\nconfig:\n  failure.emails: myemailname@xxxx.net\n  failure.action: FINISH_ALL_POSSIBLE. ",
    "Vimos": "Same problem here, due to different config of executor server, jobs need to run on a specific server. And these jobs may still in the same flow. \n. I suggest add executor group, and assign jobs to specific group, then the problem can be solved.\nExecutorFilter may also be an option.\n. Up vote for the idea, I am thinking that jobs of the same flow should be able to be assigned to different executor groups.\nGrouping becomes job properties, and executor servers are of different group, so ExecutorFilter can find the right group for each job of the flow.\n. Oh, in my situation, the actual visiting ip is changing due to a intermediate service EFE, so if checking ip, it just clear the session.\n. ",
    "tmwilder": "I'm able to reproduce this for all time ranges I try to filter on for Azkaban solo 2.5.0.\nFailing url:\nhttp://my_host:8101/history?advfilter=true&projcontain=&flowcontain=&u_contain=&status=70&begin=01/12/2015%208:13%20AM&end=01/13/2015%201:00%20PM 500 (Invalid format: \"01/12/2015 8:13 AM\" is malformed at \" 8:13 AM\")\nChrome gets the debug stack trace:\nHTTP ERROR 500\nProblem accessing /history. Reason:\nInvalid format: \"01/12/2015 8:13 AM\" is malformed at \" 8:13 AM\"\nCaused by:\njava.lang.IllegalArgumentException: Invalid format: \"01/12/2015 8:13 AM\" is malformed at \" 8:13 AM\"\n    at org.joda.time.format.DateTimeFormatter.parseDateTime(DateTimeFormatter.java:866)\n    at azkaban.webapp.servlet.HistoryServlet.handleHistoryPage(HistoryServlet.java:127)\n    at azkaban.webapp.servlet.HistoryServlet.handleGet(HistoryServlet.java:71)\n    at azkaban.webapp.servlet.LoginAbstractAzkabanServlet.doGet(LoginAbstractAzkabanServlet.java:106)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\n    at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)\n    at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:401)\n    at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\n    at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n    at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n    at org.mortbay.jetty.Server.handle(Server.java:326)\n    at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\n    at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)\n    at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)\n    at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n    at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n    at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)\n    at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\n. No problem. Respectable turnaround : ).\n. Worked around this locally - to fix on master, or for others looking to get started, the following will fix the latest (stable? - unclear from docs what sources one should get, and tip build failed) release (3.20.0):\n\nAdd conf, extlib, plugin empty directories to azkaban-web-server / azkaban-exec-server to install targets before packaging.\nAdd log4j.properties to do console logging to conf for both, the out of the box setup dies from stock 3.20.0 build.\nMake sure you have templating mechanism in deployment path to set properties files, since both exec and web server die without providing defaults if a number of different vals are missing.\n\nWe also wanted to run under init system, so modified the startup scripts to not background.  . ",
    "hyurtseven81": "+1\n. ",
    "jfgreen": "I just ran into this issue myself and was about to open my own PR, but then I saw this. Anything stopping a merge? I am happy to contribute if there are any issues that need resolving.\n. ",
    "kddeisz": "Bumping this because I just ran into this as well. We just locked down our network ACLs and it'd be great if this could go through 587.\n. @logiclord Any chance this could get merged?\n. @HappyRay Since it's been updated - any way this could be merged? Short of implementing something with docker compose I'm not sure how you would test this with automated tests.\n. @logiclord Tagging you because it seems like you're the only one contributing to this anymore.\nIs the above thing an issue or am I doing something wrong? Happy to work on it if it's an issue.\n. Thanks @logiclord, is there already an existing issue? Otherwise I'll just reference this one in the future\n. ",
    "wangqiaoshi": "@HappyRay @kddeisz , i  also need mailPort too. because of automatic  test for PR and get stuck. so i want to do a automatic test .\n@HappyRay  do you mean add a mock object of mailServer?. @superwood ,i think @superwood will expect executions saved startTime.\neg,\nThe execution failed at 2:00,the execution relaunched at 5:00 will auto set start-time=2:00 but 5:00. +1,we need this function too!. can We configure a parameter in azkaban.properties file?\neg\nexecute.as.user.bySystem=true\nif true,we can not set property \"user.to.proxy\".. 1.add EmailerTest  and AbstractMailerTest for test smtp.port \n2. remove the author information in the code of AbstractMailerTest.java\nbase on PR #395. Thanks for your quick response and help. @HappyRay \n1.AbstractMailer  add getMailPort function\n2.modify  2014  to 2017 in AbstractMailerTest\n3.change EmailerTest(Emailer load Props from config file). add send email  manually in MailerTest\nmove load properties for resource file in MailerTest\n. perfect annotation for testSendEmail function of Emailer.. i have a idea. when we add job on line,insert project_properties table.\nwhen modify or add flow, Operate project_flows table.\n\n\n. @HappyRay what do you think?. ok\nwe allow all data analyst, modeler,development engineer from different team can operator in azkaban.them can add,modify,delete and schedule flow.so that  we will be difficult to control the job who execute.\nso we expect azkaban can control job who run,but user control in job properties.\n. Is it necessary to add azkaban-env.sh file for this?\nWe can config HADOOP_HOME SPARK_HOME variables, etc in azkaban-env.sh file. express language. @kunkun-tang . yes, i think it will be useful to timing job. @kunkun-tang . Its implementation is also based on jexl. @kunkun-tang . The reason of loading the properties from the resource I modify is for  making  difference AbstractMailer  between Emailer.\nSorry,I do not understand what do you mean to consolidate the EmailTest code.. Because sender and failAddr now is not real.if real,will remove @Ignore\n. I very much agree with your point of  adding comment for sending email test and  I will add comment for it.. yes,it is.. Well, those are needed. and i add annotation for variable{host,mailPort,password,receiveAddr} .. ok.. i agree with you point,now we don't need this logic,but later?. yes,this code is redundant.the oldProps can not be null.\ni remove it. ",
    "inramana": "Looks like this has been submitted as part of #872 . Following up from @HappyRay's comment- @EdwardsBean do you still want to merge this? Please rebase on latest code. . Following up on Ray's comment- @hkiran . Close once #1638 is merged. . @wangqiaoshi reminder to follow up on @kunkun-tang query. . @wangqiaoshi follow up on @HappyRay query. . Close once #1638 is merged. . @juhoautio I was having a look at this over the past week but I am away from now until sep 11. Can this wait or should someone else have a look?. @HappyRay @kunkun-tang updated review posted.\n@kunkun-tang - yes compileOnly forces to add the dependencies back as compileTest- Gradle does not have a more elegant solution than that. \nHere are other people complaining about the same thing.. Remove references to your user name. . Link to schedules and API. . Link to general trigger documentation if available. . ",
    "Codefor": "I expect it work using system sendmail.\n. seems not\n. Thx.\nI've contributed a patch ,setting default log_dir to $AZKABAN_DIR/logs\nhttps://github.com/azkaban/azkaban/pull/557\n. CI ran failed because of maven:\nExecution failed for task ':azkaban-common:compileJava'.\n\nCould not resolve all dependencies for configuration ':azkaban-common:errorprone'.\nCould not resolve com.google.errorprone:error_prone_core:2.0.5.\n     Required by:\n         com.linkedin:azkaban-common:3.0.0\n      > Could not resolve com.google.errorprone:error_prone_core:2.0.5.\n         > Could not get resource 'https://repo1.maven.org/maven2/com/google/errorprone/error_prone_core/2.0.5/error_prone_core-2.0.5.pom'.\n            > Could not GET 'https://repo1.maven.org/maven2/com/google/errorprone/error_prone_core/2.0.5/error_prone_core-2.0.5.pom'.\n               > Connection to https://repo1.maven.org refused\n. But my question is why azkaban executor require 3G RAM? It actually doesn't need that more\n. putting these configurations to job files works!\n. same to me.\n\nI want Azkaban alert when a job takes too long to finish, but it don't work.. Why does the DefaultHeader add host azkabanHostName?\nFor a HTTP request's headers,the Host's value should be the remote server's host rather than the caller\n. Why use replaceFirst rather than replaceAll?\nDocuments do not mention it at all. \n. ",
    "liuqact": "in FetchExecutableFlows.FETCH_BASE_EXECUTABLE_FLOW_QUERY;\n\"SELECT exec_id, enc_type, flow_data FROM execution_flows\"\nwhen using advanced history seach, this SQL will throw out SQLException due to ambiguous column \"enc_type\". it would be better if changing the position for adding alias of table \"execution_flows\" and figure out the table alias in SELECT section.\n. ",
    "ahoefer": ":+1:\n. ",
    "mvignesh1990": "I have made a change in the source for the same. It is available through the REST api currently. The scheduling is done based on a CRON expression sent as part of the scheduleFlow call. Can you please suggest if I can check-in the same and which branch the check-in will be into?\n. ",
    "FrommyMind": "@mvignesh1990  does this available for 3.46+ Version?. +1,we need this function too!. I met the same problem, and cannot find more log about this error.. @hikoz  we have created conf dir  with azkaban.properties file in it . @hikoz  yes, when I and this file, the java.lang.StackOverflowError exception dispeared. Thanks. expected too. @monanik39 \n Also recreated executors are inactive by default(active =0 in database). is there any property which will set active executor flag to 1 once it is recreated? Cause as per my understanding new entry will be created only if server is up so active flag can be 1 by default?\nHave you solved this question?. @kunkun-tang\nhere is the result \n[root@dnode02 ~]# host localhost\nlocalhost has address 127.0.0.1\nHost localhost not found: 2(SERVFAIL)\nHost localhost not found: 2(SERVFAIL)\n@RoryLiuwenxuan \nMy DB is MariaDB \nServer version: 5.5.56-MariaDB MariaDB Server\n. @RoryLiuwenxuan \n[root@dnode02 ~]# mysql -h10.1.49.100 -uazkaban -pazkaban\nWelcome to the MariaDB monitor.  Commands end with ; or \\g.\nYour MariaDB connection id is 323\nServer version: 5.5.52-MariaDB MariaDB Server\nCopyright (c) 2000, 2017, Oracle, MariaDB Corporation Ab and others.\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\nMariaDB [(none)]>\nI mean it just try to connect local db not the one I configured in azkaban.properties. ",
    "Antall": "Looks like we should be returning from the catch block from here https://github.com/azkaban/azkaban/blob/master/azkaban-webserver/src/main/java/azkaban/webapp/servlet/ScheduleServlet.java#L647-L654\nSimilar to the code above. This may be another block of code worth changing too https://github.com/azkaban/azkaban/blob/master/azkaban-webserver/src/main/java/azkaban/webapp/servlet/ScheduleServlet.java#L656-L661\nAre there any tests for this? I could not find any. \n. A flow that has completed successfully shows the status of 'Success' in the table, I thought the filter should represent what the table displays. Are you suggesting that the table should also show \"Succeeded\" in the status column?\n. How do I run tests across the entire project?\n. Validated and it works. Thanks for the help.\n. That is true.\nvagrant@vagrant-ubuntu-trusty-64:/vagrant/squiddly$ curl -k http://localhost:8081/schedule -d \"ajax=scheduleFlow&is_recurring=on&period=15A&projectName=Guzzlr&flow=8_nine_east_wine_emporium&projectId=5&scheduleTime=12,00,am,UCT&scheduleDate=01/01/2015\" -b azkaban.browser.session.id=3825dc5e-c82e-4eef-be50-1365097d637c\n{\n  \"message\" : \"Guzzlr.8_nine_east_wine_emporium scheduled.\",\n  \"error\" : \"Invalid schedule period unit 'A\",\n  \"status\" : \"success\"\n}\nvagrant@vagrant-ubuntu-trusty-64:/vagrant/squiddly$\n. That change is in keeping with the other links defined. That said I'll make the necessary change. \n. ",
    "tonylee0329": "can we set upstream throught different flows?\n. ",
    "weikang2002": "made some code changes based on comments. Pls take a look at the newest code again.\n. I put in the newest code, please take a look. As discussed, \"memCheck.enabled\", \"memCheck.freeMemDecrAmt\" properties will be at the jobType plugins level. Because of this, javaprocess won't be covered by these new properties. However, javaprocess is rarely used anyway.\n. Another revisioin: make free-mem-check-thread interval configurable. Added some unit test for pasring mem string.\n. Test is done. These multiple commits will resolve #418 \n. Looks good.\n. LGTM\n. Fixed to take care of the bytes situation.\n. Fixed to resolve the properties.\n. Mem check logic can be disabled by putting \"executor.memCheck.enabled=false\" in azkaban.properties.\n. All existing code are taken care of by adding additional param.\n. Fixed by changing method name.\n. I am afraid this feature introduced too many configurable properties. Let's settle with 30 seconds for now. We can see if we have this needs or not later\n. Catch Throwable for the entire thread logic.\n. Removed 2KB\n. We are already in the shutting down process, so no need for that.\n. Change the method, varable name.\n. Good catch. Fixed.\n. test cases added\n. comments added for this func\n. Fixed by importing package.\n. Project id is just hard to read.\n. This is to be consistent with ExecutionOptions.memoryCheck, whose default value is false. But according to the logic, AZKABAN_MEMORY_CHECK should always be in job properties.\n. I will add some comments.\n. OK, change both places to use 'true' as default value.\n. I think it is better to provide a function here so that STATUS_TOKEN and SEQUENCE_TOKEN can be replaced in one call.\n. return right away if initialized already?\n. I can imagine some user starts the sequence from 0. Maybe some error checking for it?\n. Better use ConcurrentHashmap\n. Better use ConcurrentHashmap\n. You can just call initialize() directly from constructor.\n. Some comments?\n. This set of code is the duplicate of the code above? Maybe they can be combined?\n. return right away if initialized already?\n. Here, the code is doing all the http call sequentially: one task, wait for the task to complete, then next http call. It is not quite efficient. Maybe should submit all requests to future service, then check the status of all the future tasks?\n. Can just use one instance of LoggingResonseHandler?\n. OK, I see.\n. just noticed the typo. Response, not Resonse\n. Just feel it is inefficient to do sequentially since you are already using Future service. Otherwise, you can simply use a simple httpclient.\n. If you are sync on that level, i guess you don't need AtomicInteger.\n. ",
    "shahneil88": "Can we set the session timeout manually? I do not want it to logout every 24 hours\n. I found a variable called SESSION_TIME_TO_LIVE and it is declared as final in\nazkaban-common/src/main/java/azkaban/server/session/SessionCache.java\n. ",
    "darrenfu": "Looks like it resolved my same issue when set SESSION_TIME_TO_LIVE to a longer time (2 days).\n. ",
    "duke2012": "meet same problem when deploy with docker.. We met same problem, it is really an important feature. Any updates on this? Or is it on the road map releases?. ",
    "li-afaris": "Hi @duke2012, this is a very old issue to be updating.  Something to remember is the session ids are stored in memory on the webserver.  If you restart the docker container or the webserver process on a physical machine, the session ids will get lost.   \nSecondly, if you search session.time.to.live on the documentation site, you'll find the timeout is controlled with a configuration setting.  The default should be 24 hours.  \nIf this information doesn't resolve your question, please open a new issue that describes your environment and what the problem is.   Thanks. . I know this is a late update, but perhaps it will help someone else in the future.  I ran into the JAR path must start with jar: message while deploying the Azkaban webserver (version 3.50) into a new environment.  \nAfter looking at the Apache velocity developer guide, I realized jar.resource.loader.path had an issue and found both the AzkabanWebServer & TriggerPluginLoad classes dynamically build the jar.resource.load.path.  If there's an empty directory under 'plugins', it will trigger the Jar path must start with jar: exception.\nIf one is wondering what to put into the plugins dir, take a look at azkaban-solo-server/build/install/azkaban-solo-server/plugins/ for ideas.  . @HappyRay requested I split this PR into multiple commits as several changes are included with this PR.  Will close this PR and submit new ones containing single changes.. I'm going to close this PR without merging with the upstream azkaban project.  After submitting this PR, I discovered the embedded H2 database has a different grammar then mysql for inserting values into a table, and this change will break azkaban in solo-mode.  \nMy suggestion for a future PR to use directories to isolate the schema files for each supported database type,  (currently this is how it's done with the Apache Hive project).  Lookup tables should be added after the isolation occurs. . Nice find, I didn't think about attempting to replace the double quote with a single.  And yes I should use the status column as the primary key.  I'll make time to reopen this & update later today. Thanks. Hi and thank you for the feedback.  Could you provide more information about your proposal? Is this to replace the backend relation database with a key-value store (zookeeper), or to use zookeeper as a distributed lock?  If possible, please provide examples of where and how this has been implemented. Thanks.. Looks good and thank you for the patch.   Once the 'update branch' step is completed I'll merge the change.. PR for cleaning up most of the @Override warnings: https://github.com/azkaban/azkaban/pull/1026/commits. old issue that should have been closed after the review & merge. Looks good.  thanks for the patch @sjakthol.  . s/manpower/resources/ please :). Closing as this has been reviewed and merged a long time ago.. Thanks for pointing out this feature with documentation.   LGTM.. I have a TODO in my personal notes to expose this value in a .properties file.  Will try to get to it this week.  Thanks for the reminder. . Actually comparing production logs against my azkaban-solo logs, I don't think the new logging message is in the proper location.  \nAzkaban logs from production server:\n...\n2017/08/10 03:04:12.083 +0000 INFO [ExecutorManager] [Azkaban] Cleaning old logs from execution_logs\n2017/08/10 03:04:12.157 +0000 INFO [ExecutorManager] [Azkaban] Cleaning old log files before 2017-05-18T03:04:12.110Z\n2017/08/10 03:04:19.154 +0000 INFO [ExecutorManager] [Azkaban] Cleaned up ##### log entries.\n2017/08/10 03:04:19.155 +0000 INFO [ExecutorManager] [Azkaban] log clean up time: 6 seconds.\n2017/08/10 03:09:39.025 +0000 INFO [TriggerManager] [Azkaban] TriggerManager loaded.\n2017/08/10 03:09:39.036 +0000 INFO [AzkabanWebServer] [Azkaban] Loading built-in checker and action types\n...\nLocal Azkaban-solo logs:\n...\n2017/08/10 19:38:42.002 -0700 INFO [ExecutorManager] [Azkaban] Cleaning old log files before 2017-05-18T19:38:41.887-07:00\n2017/08/10 19:38:42.007 -0700 INFO [JdbcExecutorLoader] [Azkaban] Purging execution logs older then: Thu May 18 19:38:42 PDT 2017 from database\n2017/08/10 19:38:42.009 -0700 INFO [ExecutorManager] [Azkaban] Cleaned up 0 log entries.\n2017/08/10 19:38:42.009 -0700 INFO [ExecutorManager] [Azkaban] log clean up time: 0 seconds.\n2017/08/10 19:38:42.223 -0700 INFO [TriggerManager] [Azkaban] TriggerManager loaded.\n2017/08/10 19:38:42.226 -0700 INFO [AzkabanWebServerModule] [Azkaban] Loading user manager class azkaban.user.XmlUserManager\n2017/08/10 19:38:42.439 -0700 INFO [XmlUserManager] [Azkaban] Loading user azkaban\n2017/08/10 19:38:42.440 -0700 INFO [XmlUserManager] [Azkaban] Loading user metrics\n2017/08/10 19:38:42.482 -0700 INFO [AzkabanWebServer] [Azkaban] Loading built-in checker and action types\n...\nThis PR needs to be reworked  as I need to add a log statement into the time gap between the ExecutionManager deleting logs and the call to the TriggerManager.. I'm going to close this PR as I haven't added logging to the correct location.  Will submit a new PR when I get around to it. . Oh right, yes it is.  Thanks for the reminder.. Hi @RoryLiuwenxuan,\nQuick question, did you remember to run flush privileges after adding the azkaban user to mariadb?  It's usually required when updating grant statements to flush the internal caches.  More info can be found here: https://mariadb.com/kb/en/library/flush/\nThanks. It looks like the intent to move the stack trace from the HTTP reply into the host logs?  Why not have the stack trace in both places?  While not frequently used, our documentation does reference WEBSERVER_URL/executor?ajax=.... > What are the benefits to log the same in both places?\nMy understanding is that e.printStackTrace would be printed to STDOUT. This could be a bad premise on my part, but if the stack trace is printed to STDOUT the stack trace should be displayed to the client or browser accessing the API.  \n\nWhat do you mean?\n\nI mentioned the documentation because people occasionally have the need to access the API through a web browser.   As a web browser can be another api client, printing a stack trace to the client could be useful. \nIf I'm wrong about e.printStackTrace output going to the client accessing the API, then your change is good. . This got duplicated by creating a PR in issue #2026. \"ifconfig\" is being replaced by the \"ip\" command in linux distributions.  This will not work on newer debian or redhat/centos 7 distros. \nAlso instead of using backticks, you want to use the system function for executing external commands, (\"perldoc -f system\"). System this will perform a fork and wait for the child in the background.  Additionally you can right shift $? by 8 to get the exit code of the command called by system. \nAnother ifconfig (or ip) command replacement suggestion would be to read /proc/net/tcp for IPv4 and convert the hex strings to IPs and /proc/net/if_inet6 for IPv6 addresses. IPv4 regex matching should bound the octets its only possible for 1-3 digits per octet.  For example: '\\d{1,3}.\\d{1,3}.\\d{1,3}.d{1,3}'  You can can condense this idea further but loose readability when having fun with regular expressions: \"m!((\\d{1,3}.){3})(\\d+)!\" \nMy other question, is  what happens if you get a ipv6 address? It's a possibility these days. > What do you think about adding a config to the config file and allow an external system to set the hostname? Fall back to local host name detection as you we now.\nThis would be a good feature to have and avoids having to scrape & detect ipv4 vs ipv6 addresses.\n. > Should we let the server run if the obtained hostAlias is null or should we crash the server (since metrics and everything will break)?\nI think logging an exception and crashing the server is the way to go. . Could you add 'set -o nounset' guard against referencing undefined variables?  You will also want to add 'set -o errexit' to force an exit if any shell-outs  return a non-zero exit.  For example, if the cat command fails to find the currentpid file, the script will continue running and $pid is unset which is referenced on line 9.  By using both 'set -o' options, we can guard against this ocuring by forcing an early failure.. Would it be possible to refactor these script to use functions? It will allow for code consolidation and easier readability.  Additionally one could start writing unit tests using BATs (or other test framework).. Yes that's correct.  My thinking was the calling script would first call is_process_running before calling kill_process_with_retry, but failed to update azkaban-solo-shutdown.sh to demonstrate this behavior.   Now I'm questioning if that's appropriate behavior.\nI'll update this PR by placing a guard inside the kill_process_with_retry function to prevent killing non-existent pids.  . oneTimeSetup() is a shunit2 feature that is intended to prepare a environment for testing.  If temp directories are needed for testing, oneTimeSetup is when  they get created.   It seemed an appropriate place for sourcing the utils.sh file.  \nFWIW: there's also oneTimeTeardown() useful for cleanup after tests are completed.  More info can be found here: https://github.com/kward/shunit2. Intellij added this for me, and I didn't validate if it was needed. I went ahead and removed this import. Thanks for pointing this out.  . Thanks for the information about Constants.ConfigurationKeys.  I added the new key as suggested.. I changed this to a Set as suggested.  Thanks. Both the text and url are showing when viewed as markdown.  I think the new line on line #43 is causing an issue with converting the text to a hyperlink.  Otherwise it looks fine, remove the newline and merge the change.. I agree that for startup scripts, bash is sufficient. There was either a thread on the Apache Yetus mailing list or Jira that had a nice discussion of the pro's & cons of replacing bash with python. (Sorry I can't find it tonight.)\nEssentially we can get 'good enough' testing by writing functions & using something like shunit2 or bats for testing. The other issue is portability. The differences between bash v3 & v4 are much less then python 2.6 or 2.7. Presuming every OS did ship with python 3.6, we would then need to build a pex file to package our python script and dependencies.. test_running_server.js and package.json are used by npm test to start a azkaban-solo instance and confirms the web page renders.  \ntest.js is used by gradle test and only tests JavaScript functions return expected results.  A azkaban-solo instance is not started by gradle test.. Correct.  This is to prevent gradle test from running everything in the test directory.   Maybe it's better to reorg the directory tree?  \nsrc/web/js/azkaban/test/\n                        \u251c\u2500\u2500 test_running\n                        \u2514\u2500\u2500 test_static\nThis would allow us to keep the current args behavior of running all tests in the test directory, but still have separation between gradle & NPM tests.\n. By default Mocha by default looks for \"test/*js\", documentation here.  We are overriding default behavior by passing a directory path as an argument to mocha. \nTo answer your question, NPM test will run tests from both files.  I think this is okay because the few seconds spent testing components is much smaller then waiting for running tests to complete.   . Sounds good.  I'll submit a updated PR for the directory restructuring and remove the test dir.. ",
    "alloydwhitlock": "@sagarshimpi16, did you configure the Hadoop core-site.xml file with the proxy user and application settings?\n. ",
    "sagarshimpi16": "I checked and saw that proxy user in core-site.xml is set to *\nAlso i did kerberos related  settings in azkaban config files. Still no luck.\n. ",
    "IVANOPT": "@sagarshimpi16 \nHave you found out the reason? Could you share your experience about the cluster configuration and azkaban properties?. ",
    "nightwolfzor": "+1\n. ",
    "d3vnate": "My organization (sovrn) has leveraged azkaban as a mission critical component of our infrastructure for well over a year and we have a long wishlist items that we may end up developing and submitting back via PR.  It would definitely be great if development continued, or was handed off to folks able & willing to continue the coordination efforts necessary.\n. @hluu & @davidzchen here's some of our largely usability related wishlist items:\n- Pause a scheduled workflow (to do this now one has to remove/re-add a flow schedule)\n- Schedule one Project/Flow multiple times (currently overwrites).  To do this now you must schedule separate projects and upload the same flow to each.\n- Show on execution history whether a job was scheduled or ad-hoc \n- Show on execution history if additional override parameters were passed to the job run for ad-hoc jobs\n- Add 'resolved' status toggle to Action column in the UI History view (for failed jobs)\n- Flow view / graph of execution times\n- New view of scheduled / unscheduled flows\n- \"Archive\" project / flow ability\n- Show more records per page\n. ",
    "xiaogaozi": "@hluu Could you please let me know when 2.7 released?\n. @hluu Is there any documentation guide us to use the 2.7 release?\n@davidzchen Very excited about the new roadmap!\n. ",
    "ptalathi": "Thanks a lot for the post.\n@Sokrati (http://www.sokrati.com/), we are using Azkaban as our internal workflow manager and have been planning to implement multiple executor support. Here's a brief design description. Any suggestions/comments are most welcome. You may contact us at [farnoosh.azadi@, gaurav.shaha@, prachita.talathi@]sokrati.com.\nTable: executors\nPrimary key: host + port\nName -- Datatype -- NULLable\nhost -- varchar -- no\nport -- int -- no\nload --  int -- yes\nheartbeat   -- bigint -- yes\nstatus_type_id -- int --  no\nTable: server_status_types\nPrimary key: id\nName -- Datatype -- NULLable\nid -- int -- no\nname -- varchar -- no\nis_deleted -- tinyint -- no     \nid -- name -- is_deleted\n1 -- INITIALISING -- 0\n2 -- RUNNING -- 0\n3 -- STANDBY -- 0\n4 -- DOWN -- 0\nazkaban.properties for executor server:\nAs the executor server breaks after the no. of simultaneous executions pass 120-130, set the executor.flow.threads value in config to a safe limit of 100 for all executors. Set the executor.port to chosen port number.\nazkaban.properties for web server:\nAs the executor host & port information will be read directly from database, no need to mention those in the conf file. Add a new property for load.balancer as well as loading.factor.\nREST endpoints:\nAlter the status of an executor: \nPermissible: RUNNING->STANDBY, STANDBY->RUNNING\nMethod: GET\nRequest URL: /manager?ajax=alterStatus\nParameter Location: Request Query String\nParameter --  Description\nsession.id -- he user session id.\najax=alterStatus -- The fixed parameter indicating the current ajax action\nexecutorHost -- IP address of the executor server\nexecutorPort -- Port number of the executor server\nstatus -- String indicating new status \nAzkabanExecutorServer:\nAzkabanExecutorServer():\nAdd an entry to executors table with host, port information in not present, else mark the status as INITIALISING.\nstopServer():\nMark the status in executors table as DOWN.\nExecutorManager:\nsubmitExecutableFlow():\nUpon receipt of an executeFlow request, ask the load balancer to pick and send the executeFlow request to it.\nif failed to submit request, notify load balancer and ask to pick another executor.\nfinalizeFlows():\nFor a finished(failed/successful) job, decrement the load count of its executor.\nLoadBalancer:\nnumRunningExecutors \nloadingFactor\nmaxThreads = loadingFactor * numRunningExecutors * executorFlowThreads\nselectExecutor():\nPick the least loaded executor in RUNNING state. (Load = number of running flows)\nSend the executorReference.\nsubmissionSuccessful(executionReference):\nIncrement the load count for given executor.\nsubmissionFailed(attempts):\nselect the (n+1)th least loaded executor where n = attempts.\ngetExecutorStatus(executionReference):\nReturn executor status\nsetExecutorStatus(executionReference, status):\nSet executor status\nexecutorWatchdogThread:\nobtain the ListofExecutors from executors table\nrun()\nfor entry in ListofExecutors\nif status == INITIALISING, Create an updaterThread and change the status to RUNNING.\nelse if status == RUNNING, ping executor for status\nif no response, update status as DOWN.\nsleep;\nExecutingManagerUpdaterThread: \nEvery executor will have its own updaterThread.\nrun()\nif running == true\nlist = list of all running flows on executor\nif getExecutorStatus() == RUNNING\nFetch flow list for the executor\nfor flow: list\nFetch update\nif failed/successful, add to finishedFlows\nif executor unresponsive even after retries, notify ExecutorWatchdogThread.\nelse if getExecutorStatus() == DOWN\nfor flow:list\nDELETE entry from activeExecutingFlows table, UPDATE status as UNREACHABLE in execution_flows table.\nrunning = false\nStatus:\nAdd UNREACHABLE in job status types.\nJMX:\nAdd multiple executor support in JMX pages.\n. ",
    "winghc": "This is the solution what we are looking for. Like Hadoop Map/Reduce, there can be many mappers(executors),  when designing job workflow, one can assign which executor to run in order to balance the executors.   As RexGibson mentioned, is linkedin going to move manpower to oozie?\n. ",
    "BrianGallew": "Shouldn't this be closed now?\n. The canonical way to do this is \"you send email to localhost, and whatever MTA is configured on there will then send it where it should go\".\nMTAs pretty much exist so that every service ever written doesn't need to do anything but talk to localhost.\n. I've just had to build it myself.  That said, it's pretty clear that 3.0 hasn't been cut yet.  The release-3.0 branch is ... not 3.0.\n. Can we look at merging this?\n. I've rebased so there shouldn't be any merge conflicts now.\n. Is there any point in submitting PRs if one is not actively part of the Azkaban project?  This was a functional patch when I submitted it a year ago, but if you're not interested in community contributions, it's not clear that I am interested in helping out at all.. The Azkaban config file names a class which is used for authentication.  A\nclass.  That being the case, the only way to have multiple authentication\nhandlers would be to write an authentication class that encapsulates all of\nthe auth methods you want to use.\nIn my specific case, I want to use LDAP auth, but be able to fall back to\nXMLAuth when LDAP isn't available (i.e. define a \"root\" account that's\nalways accessible, or an account used for publishing new flows from\nJenkins).  The patch I provided allows specification of a comma-separated\nlist of authentication classes, each of which is tried, in order, until\neither a successful authentication occurs, OR all of the classes have\nfailed.  This precisely meets the use case described.  I'm sure Azkaban is\nvery, very special, but even a casual perusal of web-based technologies\nshows that it is quite common to allow multiple authentication methods, so\nthe reluctance to allow this seems more than a little bizarre.\nI'm not sure how this interferes with any planned features, but I can\npromise you that I can't be troubled to rewrite the patch again.  If you\nwant community participation, then you have to, you know, \"participate\".\nOn Wed, Jul 19, 2017 at 3:49 PM Ameya notifications@github.com wrote:\n\nHey Brian,\nThanks for following up. Few questions:\n\nCan we not use existing XML file based authentication?\nWe use headless accounts and add them to XML file for further API\n   authentication\n\nFinally in near-medium term we are adding a feature for all users to get\nsecret key which can be used for API authentication. Would that solve your\nproblem?\nSince there are these features in existing system and are on road map we\nare hesitant to merge this in right now.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/azkaban/azkaban/pull/629#issuecomment-316528298, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAXWSwuqSBS_7uXxmZvQszN_ate9enhcks5sPnnPgaJpZM4H56l1\n.\n. I'd have tagged this Enhancement, but that's not available.\n. \n",
    "xFaris": "how to use it?\n. Up vote. The whole system consists of many services, with different environment configuration, applications, and infrastructure.\nWe must build several azkaban system to support this.. help\uff01\n. ",
    "daksh-talwar": "\nDocumentation has been udpated\n\nHow can I access the documentation? Is the first comment on this issue the official doc for this feature? . ",
    "zzz24512653": "How can I tell Failed or Killed from failure status? \n\n. ",
    "ameyamk": "Unit tests?. Planned in 4.X design. . 4.0 won't have this feature but 4.x will have it. Here is the roadmap: https://github.com/azkaban/azkaban/wiki/Azkaban-4.x--Roadmap\n. We are now on 3.20 - soon releasing 4.0. Closing.. This is working. Please re-open if you encounter issues.. Not supported today. But is planned and is on road map for 2017. Unfortunately not available as a feature.\nHopefully you do not have to do this with #670 in progress.\n. we are in prod with 3.19 - and is a stable release. Hey Brian,\nThanks for following up. Few questions:\n1. Can we not use existing XML file based authentication?\n2. We use headless accounts and add them to XML file for further API authentication\nFinally in near-medium term we are adding a feature for all users to get secret key which can be used for API authentication. Would that solve your problem?\nSince there are these features in existing system and are on road map we are hesitant to merge this in right now.. This is possible with work being done on #670 . yes. we are now on 3.19. One thing I'd add to this is - we should make sure that single executor JVM can support multiple groups/pools. So we have many to many relationship here.\nAzkaban can have multiple executors, and all of them share \"executor groups/ pools\"\nAlso - we should make sure that we have default \"executor group/ pool\" - This way any flows submitted without group/ pool will land in this default pool.\n. We are super interested in this - @mukund-thakur - can we move forward on this one?. The current line of thinking is this will be done via decoupling Azkaban and Hadoop. This way we can launch jobs into multiple Hadoop clusters from the same executor. \nThis is going to take some time though. Above patch is (was) fully working - so you can pull that into your own build if this is urgent for you. Default solo server now runs with 500MB memmoery. Definitely useful feature - and many people do ask for this. \nSome questions to think about - \n1. When do you expect priority to kick in?\n2. Will priority always override schedule? e.g if flows f1 and f2 both are scheduled at  say 2 PM , I assume flow with higher priority will be started first.\nBut what if f1 was scheduled at 1 PM and f2 at 2 PM would you still kick start flow with higher priority first? \n3.  How would you resolve case when you starve flows? (i.e. in case of high contention flows with low priority may not run or would starve for really long time?)\n4. Should you also create config to automatically kill schedule/ bump priority in case starving is higher?\n5. how are priority guarantees managed in case of multiple executor environment?. @inoviavenkat still working on this feature? we will be happy to help . Planned and on roadmap. Likely will be prod ready in Q3 of 2017. Starting a spark streaming program from Azkaban will be easy - challenge is since this is \"never ending\" flow in theory - we need to add more sophistication/ reporting to handling streaming jobs.\nWhat is your use case? . doc is now updated. @suvodeep-pyne please verify and close the issue. Planned as part of the road map (perhaps around Q3). Take a look at this: http://azkaban.github.io/azkaban/docs/latest/#configuration\nYou can set retry attempts. What is this ghost commit? I do not see any diff. Also can we have comment in english please?. Hi Mukund - would you be interested in contributing this feature?. I am worried that this config may inadvertently delete project files. Reason being there is implicit contract on UI when user uploads project files - and this feature will override that contract - and to make it really safe we may need to create alerts etc. #NoOfProjectVersions seems more safe and manageable approach - which already exists today. In our production we just keep 1 old version - perhaps you can try that as well?. Yes this is a bug - @chengren311 has started working on fixing this bug. . Hi Mukund - this is good idea to have some design doc. As part of next work we are going to work on two things that should directly answer this questions\n1. As Ray mentioned we are working on scaling out web server. As initial step we will just move state out of web server, and provide distributed scheduler - this way you can run multiple web servers - effectively removing SPOF for web server.\n2. We will also be working on improved documentation - both should be ready and available in open source by mid July or so. Likely around August 2017. Roadmap here: https://github.com/azkaban/azkaban/wiki/Azkaban-4.x--Roadmap. I think I agree. -1/ unlimited is more sound default choice.\n@juhoautio you want to make a PR?. +1 for fixing solo server. We need this to work perfectly!. @chengren311 has started working on this feature. . Yes this feature in development right now\nOn Tue, Apr 4, 2017 at 8:06 PM Ruixia notifications@github.com wrote:\n\nCurrently, Azkaban supports the allocation of flow to the specified\nExecutor to perform. However, we have encountered a situation, and set the\nlabel to the Executor and flow. When the Executor's tag and flow's tag are\nthe same, flow will be assigned to the Executor. If Azkaban supports this\nfeature, it will help Azkaban's rolling upgrade\u3002Is Azkaban now having a\nplan to support this feature?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/968, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAOBuVIKQ189NCZo0uCsSDXxsXNVG053ks5rswU8gaJpZM4MzsWb\n.\n. Planned for Q2 - @chengren311 and mukund-thakur (https://github.com/mukund-thakur) have more details. This is currently not supported - however is on a roadmap.\nYou can now check condition is downstream node itself and chose to ignore processing as part of node logic.. We are not able to reproduce the bug - but to get you unblocked you can try and schedule flows via API. Scheduled time and actual run time bay differ by few seconds if server is loaded/ DB is slow etc. That might explain why actual run time of the job may be different than scheduled time. Yes. Can you consider contributing the necessary patch? . ok no problem - We will try and fix it. Btw which company are you from? Can you share how you use Azkaban. Would love to get more details. Also - please share if you have any product ideas.. Also this is 1000th pull request!. LGTM.\n\nFor meter based tests can we use more relaxed asserts? eg. instead of assertTrue(1.55 == value) use asertTrue(1< value && value < 2). We should probably update docs with this - I remember someone else also had this question in the past. @prokod @kunkun-tang  do you want to submit PR for updating docs?. End Date should be optional. We should have config/ policy from where we can enforce this. But as a default endDate should be optional. \n+1 to Ray.. Does it allow admin to upload projects?. This is a great idea. Would you like to submit PR?. Which version are you using?\nUse release 3.30.1 - its a stable release. We are not aware of Azkaban ambari integration. However - you can use Azkaban API's to easily integrate with third party systems. HA Web server is not supported in Azkaban. HA web server is not supported in Azkaban. I am sorry Juho. We are slammed right now.. Yes - we spent lot of time thinking if data dependency should be modeled as as a job - or should it be designed at a flow level. After lot of thinking we have decided to design this at a flow level. There are couple of reasons for this:\n\n\nWe feel data dependency is similar to any existing or future trigger we may have. Such as: schedule based triggers, manual triggers, flow-to-flow dependency trigger etc. While the actual flow is \"logic\" of the flow. Trigger is logic of how flow is \"triggered\". This separation of concepts makes it easy to handle entire flow as a simpler concept which can be moved around if needed.\n\n\nThis choice does make it harder to display this on UI - compared to if we just made it a simple job type. So we will spend sometime updating UI to reflect some of the key points you made earlier. \n\n\nOne other important change on the radar is - introducing \"flow\" as a concept at compile time. Today flow is purely \"run time\" concept. As a result only way to add \"flow\" level properties is via UI. eg. schedule, SLA etc. We want to take this opportunity and create \"flow\" as a compile time construct - so that config of the flow such as schedule, data dependancies, sla's can be defined at compile time as well.\n. You are running old version - please upgrade to latest one: https://github.com/azkaban/azkaban/releases. @juhoautio I am interested in understanding how we reach this state to begin with (ie. executors not responding correct state to the web server).\n\n\nWeb server not able to talk to executors when executors are actually up should be an extremely rare condition (network partition, or some sort of packet drop etc) - How did you manage to get into such a state?\nWhen such a state is reached. What should be the right behaviour?\nOptions are:\n1. Remove/ Evict execution, email owner of the failure - treat this is any other failure scenario and restart the flow execution\n\n\nRemove/ Evict execution, email owner of the failure - treat this as special failure case - and do nothing. \n\n\nOnly email owner of this special case situation\n\n\nAnything else?\n. I am not saying this cannot happen - but this should be arguably corner case and should be a rare occurrence. So I was curious if you are facing this more often in your production env.\nSecond, I was not clear which of those 3 options you prefer (or if you have 4th one in mind). ok - I agree with most of the above. We may need to have super admin switch to evict executions (not as a default but having the ability to do as admin). In our case, we have thousands of flows running at the same time. And in case of catastrophic failure - going into each job and cleaning may not be possible. It's much easier to kill all and restart from a clean slate.. I think it seems like we are mixing two separate issues:\nIssue 1:  Unless there is at least 6 GB memory free on executor web server is not dispatching executions to this executor and 6 GB is not configurable - this creates issues in smaller VM instances.\n(Which this PR attempts to solve)\nIssue 2: Dispatching logic in itself may not be optimal, and perhaps random assignment is one possible solution\n(Which this PR is not trying to solve)\nI think Issue 2 is a broad issue - and needs more discussion. I have created Issue #1739 to track this.\nI do not see why we should not fix issue 1 right now unless we have an alternative easier fix available.. +1 for 1 minute interval - starving systems for too long is generally not a good idea - besides checking memory usage should be inexpensive operation too. Any reason why we use System.out instead of logger?. please remove uncommented code.\n. This method works all ok - but usually its a good idea to try exponential/ fibonacci backoff in such cases\nThis is a good read: https://carlosbecker.com/posts/exponential-backoff-java8/\nThis as well: https://github.com/rholder/guava-retrying\nWe can keep it simple and not necessarily have to use external dependency - but this is a good example of using exponential backoff\n. why not log error as well?. can we add unit test to retry logic?. storageLocation perhaps?. other idea is storageLocatorKey ?. Can we have another module like tools or something where people can check in such tools? Not merging does not sound like the most optimal approach.\n(Something to think about). ",
    "evlstyle": "An Api used in the change doesn't belong to Java 1.6, which broke the build, will fix tomorrow.\n. LGTM\n. silent merging as we will have a massive review from master branch before the thing goes into the azkaban master. \n. LGTM\n. execute-as-user was a BRS that ws left over at development time by the author of the feature to A/B testing the feature and make sure in the case the new feature doesn't work we can quickly revert back without redeploying the code, he planned to remove this before he moved out from the team so removing/disabling this is the right move, and yes jobs should always run as user . \n. function name is misleading, actually the function here will fetch a project with a successful name match, no matter it is active or not .  Simple fix here is to check the project and make sure it is inactive before returning, therefore the function works as it's name indicates. \nSame comment for the function below, which gets the project by Id.\n. it goes to the job log in case there are no exceptions during the process, if for reason the process throws exception, the exception will go to Azkaban log (as I figured it doesn't make sense to try again to log to Job log when \"logging to job log\" is throwing exception, when that happens we just log the incident in the azkaban log and move on)\n. fixed in comment. \n. I think it is, once the iterator moves to the parent (which means the curr is now pointing to the parent) anything that previously has been defined by the child shouldn't be overwritten, the check in place is to make sure the rule is followed. Please let me know if I understand the concern correctly. \n. Good catch,  fixed in code.\n. thought it as well at the first place, we now depend on a job prop value to determine if the content should be print or not and for other props we may want to have different indicators to make this judge, so I would recommend ship the code as for now and  it is fairly an easy change if we have request to support more in a latter time. plz let me know if  this makes sense. \n.  The new one returns a set that is sorted by the key value, which the old one doesn't , plus the old function seems need some reflecting work as the logic seems not trivial therefore I created this new one.  Second thought I think it is a better idea to fix the old one rather than creating a new one . I'll fix that . \n. yep, it is a great idea to pull the keySet here as the implamentation does go recursively and gets all the keys from the hierarchy chain, however the concern for this implementation comes from the code to pull the value from the key, it seems like the props object only exposes  the function get(object) to fetch the value from the key, which furtunately does have the logic to go all the way up the chain when finding the value, however as the way it implements it need to go thru the chain each time to find a value for the key, it will be expensive if a value from the top parent is pulled for many times with this implementation. I agree the keySet route does have the benefit to avoid touching the props class, however I feel it might be nicer to provide this extra method, which caches the flatted key value pairs,  to fulfill the functionality demand of the feature and avoid potential performance draw backs.  Please let me know your idea. (btw, seems like jobProps.getkeySet returns only a HashSet, so it seems like we need to explictly initialize a TreeSet from the return of the getKeySet() call rather than assigning directly, let me know if I got it wrong :)  )  \n. yes as I see no point we need more than one instance of it . As this class need to extend the abstract class therefore we need to create instance of it, otherwise it is just a static helper class which handles the restful API communications. \n. I'll make a better wording for it,  it is just the instance that previously created. \n. sure I can clean up a little bit. \n. Either way works for me ( the talk we had haven't closed to an conclusion) I thought it might be better to keep the logic on how to deal with the Restful API apart from the ExecutorManager.  below are the two reasons - \na.  as the majority of logic on how to talk with Restful API now resides in this new class I think it doesn't make much sense to separate the logic and leave a portion in separate classes. \nb. as we have already made the decision to abstract out the API communication logic out of the Manager I think the talk to API should be transparent to the Manager (say for a specific request, the Manager should not need to worry about if a POST call instead of a GET call should be made to the RESTful api). \nWith that said I prefer to reside all the Restful API logic in this new class and expose only generic methods to the Manager (this callExecutorStats as an example).  Let me know if this makes sense to you, again,  I'm cool either ways. \n. In case if you missed, please take a look at the dispatcher class and pay attention to the filter logic.  the Flow info will be used there to filter out the \"invalid\" executors, let me know if that addresses (or partially  addresses :) ) your concern. \nAs per our design talk the Flows should be generic and should be treated the same and therefore not counted in the comparison  between the executors (the filter was also not talked during the design and I added it for good).  And per the current design I think it makes sense to keep the flow info apart when doing the comparison between two executors,  at the tome two executors enter the comparison logic, both of them have already passed the filtering logic, which means both are ideally suitable for executing the flow as per the definition,  so the comparator will try to finger out , based on a rule set defined by the system, when comparing executor A to B, which one is better ? and this is how the logic works.      For your concern, I think what you want (let me know if I get it wrong)  is  \"for this specific Flow tell me  whether executor A or executor B suits better ?\" I think this is different feature ask and was not what we planed, plus I think if we go that route it gives more chance for the user who defined the flow the flexibility to \"pick\" executors, which may not be what we want . \nbottom line -  if we do wish to take flow info in when doing the executor comparison (which I think is not a good idea), we can pass both the executorInfo and flow in as a Pair without changing any code, that is the benefit from the template based classes. \n. will do.\n. +1  \nin C# usually we assign the integers so that the enum supports \"|\" operation. Say item1(1) item2(2)  and when passing we do passedVal = item1(1)|item2(2)   when checking we do if (  item1  & passedVal  ) == item1 then ....      not sure if it works the same in Java  :) \n. Smart.  Will fix . \n. true,  the interface only selects a candidate to handle the work but does not actually put the task on to it . \nplease see a design pattern discussion thread below, in which the dispatcher classes does the similar @ http://www.javaworld.com/article/2075719/design-patterns/dispatcher-eases-workflow-implementation.html \n. sure, actually  this method was taken from the Manager class which was named as such. As per the discussion we will remove the method out from the class for now. \n. fixed the first comment by returning the empty list, added comment in document as well. \nfor the second comment as it is how the de-serializer returns result I would suggest leave as is. \n. as we discussed I'm commenting out this method from this class.\n. changed to tieBreak :) \n. yes actually there should be no condition that null value to be passed to this function, null value should be taken care off by the prior filtering logic . removed the check .\n. throwing IllegalArguementException instead. \n. fixed. \n. throws exception instead.\n. fixed.\n. hum.... the code actually doesn't cache it and does compute every time the method is called. And the reason not to cache is that we have the function to adjust the weight so it will be a little bit messy when the weight is changed and we need to update the cache.  please let me know if I get it right . \n. renamed to \"getComparisonScore\"\n. it is. the comparator will only return <0,0> result in the case two passed object are reference equals, as it is reference equals, there is no way to tell which one is \"better\" than the other, so it doesn't matter which side to return as they are the same thing. If the objects are same in value, they will flow down to the logic and will finally one side will be picked as an winner, and the logic is ideally to yield stable result. \n. fixed.\n. fixed.\n. function name changed to \"analyzeTarget\"  param names changed to \"filteringTarget\" and \"referencingObject\". documentation updated accordingly.\n. we allow null value here, please refer to the logic in \"public K getNext(List candidateList, V dispatchingObject) \"\n. actually I don't allow this intentionally. please let me know if there is a justification that we should allow negative values (negative values will be filtered out in the static creator function. )\n. fixed.\n. fixed\n. fixed\n. fixed\n. actually the intention of this function is to \"make the request complete\", if you noticed there are two function has the same name and does different things , but the goal is the same, to \"make the request complete\". Also this is a private function,  so I think the name might be ok. \n. reason to include the log at the first place is to give an idea how the log will look like and why the specific item is expected to be selected, as long as people got the idea I'm cool to remove the lines :) \n. added more test cases covering edge and negative. \n. Added more test to cover corner and negative test scenarios . \n. for this specific one I think it is fine coz the test just try out some cases against a single API, I will add boundary and negative tests in separate methods.\n. renamed to getBest.\n. seems like people have concerns about using  DailyRollingFileAppender and recommend using RollingFileAppender instead ? - \n@ https://logging.apache.org/log4j/1.2/apidocs/org/apache/log4j/DailyRollingFileAppender.html \nDailyRollingFileAppender extends FileAppender so that the underlying file is rolled over at a user chosen frequency. DailyRollingFileAppender has been observed to exhibit synchronization issues and data loss. The log4j extras companion includes alternatives which should be considered for new deployments and which are discussed in the documentation for org.apache.log4j.rolling.RollingFileAppender.\n. logic registering self as a new executor (in DB) I think is better  to be resided to the exeServer side  .  Here we should only load all the settings from the DB in multiExecutorMode or just add the local Executor to the executor list.\nIF (MultiExecutor) THEN \nload from db; \nELSE\ncreate on the fly and insert the executor into the executor queue. \nEND \n. seems like the activeExecutors list is built when the webserver is initialized, and after that seems no way to add a new executor to the list without bounce the webserver. I guess it will become a common user scenario to add a new executor to a specific environment and I think to avoid restarting the web box in such event will be really nice. \n. guess returning a copy of the list might be a better idea as the in memory list is your only  \"data of truth\",  you may not want the list to be messed up by the caller. \n. not sure if it is true but it seems like we no longer need this ExecutionReference any more, the new executor IS in the concept of this executionReference so wrapping up again the executor is a little bit over. \n. I really think we should create a new Class, or recycle some rarely used Class (say the executionReference) to represent this data structure so that we can replace the first and second call with some meaningful getter names. \n. where is the logic to remove the flow from the queuedFlow list after a successful dispatch ?\n. nicer place to increase the submissionNum might be in the block where a successful dispatch happened. \n. I think it is better to sync on the queuedFlows, it is actually a required change assuming you want to remove the item from the queue after a successful dispatching,  the logic of which seems to be missing right now in the code,  as Pair is immutable, so locking on the queuedFlows should provide no less security compared to locking on the returned object from queuedFlows.peek(). \n. fixed.\n. now I expose both the remainingFlowCapacity and the numberOfAssignedFlows which represent the percentage of flow capacity I think we are fine here,  I've already modified the comparator to use the numberOfAssignedFlows to judge the weight.\n. yes I haven't got a chance to clean it up and will do today. \n. total weight now doesn't have a cap (say you can have 100 or 1000 as weight) so I figured it doesn't make much sense to use double, int will be good enough. \n. fixed.\n. fixed. \n. actually there is a  bug here, when the comparator passed over to the Collections.max function is null and the type of the object to select from doesn't implement Comparable the function will throw exception instead of using any default comparators to get the job done, very nice finding,  fixed by restricting the object type to extend from Comparable. \n. fixed.\n. fixed.\n. fixed\n. fixed.\n. added..\n. fixed.\n. removed, as it will be logged when registered.\n. then I'll take the safe route :) plus seems like the Expected Exception will not work here coz here the case is that I don't expect exception.\n. changed to serverstatistics\n. fixed.\n. fixed.\n. I would recommend to follow with the design doc we have in hand, coz modify this will trigger a chained modification of quite a lot of places (comparator etc. )\n. fixed.\n. function is synchronized so it is guarded, and please see the logic in \"doGet\", the whole mechanism  is implemented in the classic \"double checked locking\" manner to ensure thread safety. \n. fixed.\n. actually the strings are only used within the method so I think it may not create a lot benefit to declare it at class level.\n. this is removed as we are not planning to populate during this release.\n. renamed to serverStatistics to align with the name of the RESTful API . Please let me know if  this looks better.\n. fixed, file name changed , please see the new code in ServerStatistics.java\n. fixed by using the Mapper directly rather than the JsonUtils,  also fixed the RestfulAPiClient to adopt the change. \n. object renamed to ExecutorInfo\n. if obj is null instanceof will return false, which is expected and we will return false here for the equals check. \nPlease refer to http://docs.oracle.com/javase/specs/jls/se7/html/jls-15.html#jls-15.20.2 for details.\n. seems no need to cache a copy of the reference here, you may just call ExecutorApiClient.getInstance().httpGet()\n. do we need a new instance of the selector each time selectExecutor is called ?\n. nit - executor.toString() writes out the executor hostname  but not the id . \n. nit - newFixedThreadPool() throws illigalArguementException if the input is <=0,  better to short cut if the activeExecutors is empty beforehead. \n. InterruptedException is raised when the current thread (the thread hosts the Executor) is terminated, it does not indicate that the threads in pool incurred timeout while awaited for finishing.  the function call  awaitTermination() actually returns a Boolean value which indicates if the wait time is expired. You may want to read that value and write log accordingly. also it might be nicer to tell which Executor timed out as it might be a key piece of data for debugging.\n. better to log if DB attempt also fails to find the executor. I see this condition is not logged in the upper stream. \n. You may want to state somewhere that padding must be enforced in the major/minor versions reach multi digits. otherwise this string comparison may fail.\n. alternatively,  as you have already tried to parse the integers, maybe it will be nicer to use the parsed integer(s) to do the comparison instead of using string.\n. Other than that that change looks good to me. \n. fixed.\n. removed.\n. removed.\n. the call to assignExecutor should be placed outside the try catch block, as if that thing fails the field in DB will not be updated with the executor id, therefore there is no need to reset it. \n. fixed.\n. fixed\n. done.\n. fixed\n. moved it out and does that only once during the class load. \n. I thought we will open a ticket on this .  Never mind I added the comment in code. \n. company code formatter forced to have the code in one line. \n. moved the existence check to the class init. Please check the latest iteration. \n. code follows the standards of the company formatter \n. updated the code to print the whole return content from the bash call on error.\n. thinking if we should change the user back after all the execution ? seems like the set_uid and set_gid actually modifies the file property, not sure if  modification is permanent or resets after session ends , if it is permanent  we'd better revert the change after use. \n. better to create a new constructor to take in these params, they should be ready only once the process is initialized. \n. you need to cast the getParam result to int here , otherwise getProject will regard it as name but id . \nOr call getIntParam() ...\n. intentional ? \n. guess you can do document.write , cleaner and easier,  if that triggered  you will only get what you write in the output . \n. just a side question,  do we have a way to turn escaping on at template level ?  if that is possible it will be really nice that we don't need to worry for all the properties. \n. do we need this ?  seems like we only used esc ? \n. ",
    "samtalasila": "Hey @orenmazor, not sure if this is the proper venue to do it, but I think something like this is needed.\n. ",
    "mukund-thakur": "We are also facing the same problems. How did you end up working around that? \n. @HappyRay \nThe real motivation behind this idea was:\nWe are having different class of linux machines having different configurations of memory, disk etc. Also at the same time we have different class of jobs like low/high priority jobs, test/production jobs. And now since we have multi executor support in Azkaban 3.0, we can leverage this executor grouping feature to submit different class of jobs to different executors thus isolating jobs execution based on business use cases. Even we can control the number of executors assigned to different class of jobs.\nWe have already implemented this by forking the latest azkaban 3.0 codebase and using it successfully in production in last 6 months.\n . @HappyRay \nHere is the design which i have implemented in our version:\nExecutors table will contain an extra column called (group) .Users can specify different group name to all executor hosts. User has to specify the groupName as parameter while submitting a flow. This parameter will be optional.\nBased on the group name executors will be filtered and flow will be submitted by performing load balancing among the filtered executors. If user doesn't specify the group name , whole flow will fall back to the current flow. If user specifies the wrong group name which is not present in executor table, the API will throw an exception with message saying group name is not valid.\nAny suggestions would be appreciated. . Hi @HappyRay ,\nHow is my design approach. Would you like me to start working on this and create a pull request on latest azkaban codebase. . @HappyRay \nThanks . Do let me know if i can contribute in any other enhancements.. @chengren311\nWe have an inhouse framework which creates a DAG of hadoop, hive jobs with dependencies and submits them to azkaban. We have azkaban 3.0 multi executor setup having one web server and 16 executors of four different pool( scheduled, adhoc, test, tagged) . Executors pools have different configurations. We almost run total 6000 jobs daily. This change was done around july 2016 and running perfectly fine from then till now.. Yeah, lets do this. I have already added this feature in our production azkaban code. Lets create new branch from master as base brach. I will cherry-pick my commits and then we can proceed further. \n@chengren311 can review my initial changes.. For Point 1: That makes sense. Will change the name to pool.\nFor Point 2: What benefit we are getting by putting the the pool name in executor property fine. It will just be a redundant value. The reason i am saying this is , its the web server which initialises the ExecutorManager which contains all the information about executors. The main point i am trying to convey here is how you guys are planning to use the value of pool from properties file.\nFor Point 3:  We can keep the default pool in the web server's property file. But if there is no executor present in the database with the default pool name , the flow having no pool specified will starve during submission. Also by doing this , we are forcing other azkaban user to use this executor pooling feature even if they don't want to. \nFor Point 4: Need to check the flow of history page. I will make any ajax api changes if required. I have no experience in UI , so need some help with that.. Edit For Point 2: Actually i was not aware of this insertExecutorEntryIntoDB(). Now i understand how we can use the value present in the properties file. \nBut i will point out a very serious problem in this one. Suppose one day some executors of an important pool went down because of some issue. And now since this is an important pool(say prod_pool)  , we would like to add executors of different pool(say stage_pool) to this prod_pool. For doing that through config file, we would need to restart the the executors of stage_pool which will lead to killing of all flows in stage_pool. But if we directly change just the pool name in the executor db and reload the executors, all the new prod_flows will go to executors of stage_pool. This will be like graceful degradation. \nI agree we shouldn't be directly accessing db in prod environments. But to solve that problem we can build api's and UI for executor related edits which admins can use.\nI would also suggest removing the dependency of properties files for executor server in future. This is in line with the same issue of all running flows getting killed if we have to change some properties like max concurrent jobs and restart the executor server. In my opinion we should keep all the executor properties in executor table only ( may be in json format) and provide an api to reload the properties just like reload executors.  . Yes, that is what we are doing currently in our prod cluster. But here also we have to access db directly. Anyways putting pool in executor server properties makes sense to make this call insertExecutorEntryIntoDB() compatible.. Yes , I am interested in contributing this feature. . Here is my design approach:\nprojects.retention.ms parameter will be accepted from the config similar to execution.logs.retention.ms.\nA thread will be started in ProjectManager during web server start and will run daily which will cleanup all the older projects. . Please find the response inline.\nHow do you decide which project to delete?\n-- We will get the list of projects to be purged based on projects.retention.ms config. Following query will be used \"select name from projects where active = 1 and modified_time < (current_timestamp - projects.retention.ms)  order by id limit.\nWhat does projects.retention.ms represent?\n-- Represents the retention time in milliseconds. We will delete all the older unmodified projects than this time. Default value of this can be 3 months.\nWhat do you think of a max size of the cache config?\n-- Please clarify which cache config are u talking about.. @HappyRay \nI will explain the real motivation behind this feature request. Recently we had shortage of disk in our azkaban mysql machine. After some initial debugging we found that project_files is taking too much of space ( 80 % of total db space). Then we found that azkaban has api's to delete and purge project files. We just wrote a simple program to do the cleanup but external programs are really difficult to maintain. Then i though this should be a feature in azkaban only which anybody can use based on configuration. \nYou are right about the modified_time. It is updated when a project is deleted or a newer version of it is created. Also the delete and purge api internally has some check. The cleaner feature will be using the implementation of these api's only of regular deletion.. @HappyRay  I don't really understand what does this ivy coordinates mean here. I think project files needs to be present in db as we have multi executors here. \nCurrently we keep 3 versions.\nThe delete and purge api makes sure that projects which is getting deleted is not being used. Also it just deletes the project files , project permissions and project properties not the entire project.\nAnyways , this feature will be configurable. If the user doesn't want to delete older projects he can set the values of projects.retention.ms parameter to a very high value.. Yes, i am talking about azkaban.project.ProjectManager#purgeProject . \nThis deletes all the versions of project files not just the oldest version.. @HappyRay \nIs there any complete design document of azkaban. It would be really helpful for us to build a good design for making azkaban HA. . I have two ideas to solve this.\nIDEA 1\nWe put all the in memory state of azkaban web server info( like runnableFlows etc )  in some data store(DS) , when active goes down send an event so that passive one gets everything in memory from DS. We can use the leader election algorithm provided by zookeeper recipes for sending the event to the passive node.\nIDEA 2 \nWe put all the in memory state of azkaban web server info( like runnableFlows etc )  in some data store(DS)  ,there will be multiple web servers which will directly read/write from this DS rather than in memory. Clients will connect to a load balancer which will be on top of all web servers.\nChoice of Data Store(DS)\nWe can evaluate between mysql, couchbase, kafka (as suggested by @HappyRay )  and decide which one to use.\n. This sounds great. . @HappyRay  I will try out the SLA feature. Thanks for the info.. @chengren311  is this configuration same for all flows. I was actually suggesting it to be passed during submission of flow [#960]. ",
    "onurkaraman": "I think I was hit by this issue yesterday. I had a line that does something like:\nlogger.info(\"abc: <xyz>.\")\nThe resulting page skipped the \"<xyz>\" chunk and just displayed:\nabc: .\nHowever, looking at the \"data\" field from the ajax response that fills in the Job Logs div shows:\nabc: <xyz>.\n. ",
    "antey86": "Hi Azkaban Team,\nI noticed nobody was assigned to it, so I'd be happy to try help out. \nBesides we've experienced the same issue, so this fix would be helpful\nApproach is straightforward - read gloabal.properties into some final globalProps at ExecutorManager class, and use global alert.type key in case if options.getFlowParameters() doesn't contain it\nThanks!. The fix https://github.com/azkaban/azkaban/pull/1727. The fix https://github.com/azkaban/azkaban/pull/1727. fixed. All notes were fixed, any reason to close this PR?. Changed! )\nThanks for the review!\nCould you please check one more PR and write your notes?\nhttps://github.com/azkaban/azkaban/pull/1727. done ). DevTeam, \nplease review this non code change. please review https://github.com/azkaban/azkaban/pull/2055/. ",
    "dmsolr": "What is different between 'flowParameters' and 'flow.props'.\nin my opinion, flowParameter should including the flow.props(global.properties).\nbut it's not.. ",
    "potaly": "Alerter doesn't recognise global.properties for alert.type  ... ",
    "WillCup": "got the same problem from 2.6.4.... memory is not enough, but the memCheck.enabled=false does not work either.....\nthere is nothing in my plugins dir, is it correct? I just run the hello word demo\n. ",
    "binhnv": "@WillCup There was a bug in previous version of Azkaban (<3.0) in JobTypeManager.buildJobExecutor which caused the memCheck.enabled=false has no effect. This is fixed in later version.\nYou just need to create a file named commonprivate.properties in plugins/jobtypes, add your setting and then restart executor server.\n. @fsi206914 How can this change break backward compatibility? Do you use this file to upgrade or install old version?\n. @fsi206914 Do you use create-all script for upgrading?\n. ",
    "SnailSjw": "Note:\u8fd9\u79cd\u65b9\u6cd5\u7684\u89e3\u51b3\u529e\u6cd5\u5c31\u662f\u5728  azkaban/exec-server/plugins/jobtypes/commonprivate.properties\u6587\u4ef6\u4e2d\u6dfb\u52a0memCheck.enable=false. ",
    "nomorogbe": "Pull Request: https://github.com/azkaban/azkaban/pull/502\n. ",
    "gvt": "+1 on rev 5bff69fa96 (master branch) \n. ",
    "ydp": "is this solved?. anyone solved this?. ",
    "jdkanani": "+1 Facing same issue.\n. Already exists #584 \n. ",
    "devangorder": "My team is also very interested in the Azkaban 3.0 release with support for multiple executors. Am I correct in that I should wait for it to come out, rather than downloading and building one of the branches available currently? I'm a little confused which is the one to go off of currently, between master, multipleexecutors, multipleexecutory_canary, release 3.0...\n. bump?\n. I ran into this issue recently too. After building 3.0 from the latest code in the repo, I had to run update.active_executing_flows.3.0.sql and update.execution_flows.3.0.sql after create-all-sql-3.0.0.sql to sort out the sql errors. It seems the create-all sql file is not entirely all-encompassing from scratch.\n. +1 on merging this!\n. any update on when this pull request can be merged? we'd love to see these features incorporated, especially the LDAP integration\n. Has anyone gotten a chance to review this yet? I built it from the fork, but haven't been able to successfully log into my LDAP yet and was curious on anyone else's experience.\n@inoviaazkaban @inoviavenkat @davidzchen @hluu @logiclord \n. Thanks for posting further detail on what each of these variables should be set to. I am now able to connect to my LDAP after adding the full string to the principal value, but I am still not seeing it map LDAP groups to the Azkaban roles I have specified in my groups.xml. I think this is due to the way my LDAP is set up, and the user.manager.ldap.attribute.group value. It seems my LDAP is set up with the opposite association as what you expect; we create a base group of Users, then create Groups and within the groups note what users belong to them. If I understand your approach right, it looks like you expect the Users to be mapped to Groups via attributes of the users themselves. Below is an example of how our OpenLDAP LDIF looks to give you better context:\n\nou=Users\n  cn=person1\n  cn=person2\n  cn=person3\nou=Azkaban_Groups\n  cn = azkaban_admin\n      - uniqueMember: cn=person1,ou=Users\n      - uniqueMember: cn=person2,ou=Users\n  cn = azkaban_readonly\n      - uniqueMember: cn=person3,ou=Users\nou=AnotherApp_Groups\n  cn = another_app_admin\n      - uniqueMember: cn=person1,ou=Users\n      - uniqueMember: cn=person2,ou=Users\n  cn = another_app_readonly\n\nWould you suggest adding 'group' attributes to each user that should have access to azkaban_admin or azkaban_readonly? Right now, anyone in the LDAP can log in with ADMIN permissions, so there is no role restriction.\n. Thanks for the further suggestions. I reworked my LDAP based on your suggestions above, and now see the LDAP group/Azkaban role association I was going for! Now, I just have one more problem. Anyone who is in the LDAP is able to login even if they're not in the specified Azkaban groups I created. Granted, they don't have any permissions to do anything within the Azkaban web interface, but they can still view the Scheduling, Executing, and History tabs that contain job names and such. Ideally if a User is not in one of the Azkaban_Groups, they wouldn't even be able to login at all. See below for my updated ldif:\n\nou=Users\ncn=person1\n- member: cn=azkaban_admin,ou=Azkaban_Groups,dc=,dc=com\n- member: cn=another_app_admin,ou=AnotherApp_Groups,dc=,dc=com\ncn=person2\n- member: cn=azkaban_admin,ou=Azkaban_Groups,dc=,dc=com\n- member: cn=another_app_admin,ou=AnotherApp_Groups,dc=,dc=com\ncn=person3\n- member: cn=azkaban_readonly,ou=Azkaban_Groups,dc=,dc=com\ncn=person4\nou=Azkaban_Groups\ncn = azkaban_admin\n- uniqueMember: cn=person1,ou=Users\n- uniqueMember: cn=person2,ou=Users\ncn = azkaban_readonly\n- uniqueMember: cn=person3,ou=Users\nou=AnotherApp_Groups\ncn = another_app_admin\n- uniqueMember: cn=person1,ou=Users\n- uniqueMember: cn=person2,ou=Users\ncn = another_app_readonly\n\nSo in this example, person1 and person2 can login with admin privileges as expected, as well as person3 with read only access. However, person4 can also login and navigate around the site, granted they don't have admin or full read access. Ideally person4 would not even be able to login at all. I tried setting my principal value to limit to only ou=Azkaban_Groups, but no one was able to login then. Below is what I had to set it to:\n\nuser.manager.ldap.security.principal=cn={0},ou=Users,dc=,dc=com\n\nDo you have any further suggestions of how I could limit login access to only those within the Azkaban_Groups (azkaban_admin, azkaban_readonly), and not everyone within Users?\n. I tried your suggestion above, but since we currently manage access to multiple applications through the same User base in our LDAP, users who were members of other groups were still able to login. For example, consider if person4 was actually this in the ldif above:\n\ncn=person4\n- member: cn=another_app_admin,ou=AnotherApp_Groups,dc=,dc=com\n\nEven though he's not in an Azkaban group, his group size is still greater than 0. So, I set it to the following:\n\nif ( ! (user.isInGroup(\"azkaban_admin\") || user.isInGroup(\"azkaban_readonly\")) ) {\n                              throw new AuthenticationException(username + \" does not belong to any valid LDAP groups\");\n                        }\n\nand it restricted access as desired. We may rework our user bases soon to match more of the style you expect above, and have one unique user base per application (in which case user.getGroups().size() would work fine). But I shared what I did above in case any one else has their LDAP set up in a similar structure. Not sure what is the better generic solution to commit.\n. If I understand your two fix options above correctly, Fix 1 will only add relevant LDAP groups to a User's definition if they correspond to an Azkaban Role within the groups.xml, whereas Fix 2 returns the Azkaban Roles of a User rather than their Groups. Either seems like it would work. Fix 1 seems like a better root cause fix to me, as we only pay attention to relevant Azkaban groups rather than other groups a user may belong to in the LDAP that we don't need to know about. Would you agree?\nAlso, when I made my change above I noticed the \" does not belong to any valid LDAP groups\" message was not displayed on the webserver when I tried to login with an account in the LDAP who was not in the Azkaban groups. It was still showing \"LDAP Authentication : Invalid Credentials\" which is not the proper error message for this scenario, so I updated the catch below as such:\n\ncatch (AuthenticationException e) {\n                        logger.debug(e.getLocalizedMessage());\n                        throw new UserManagerException(\"LDAP Authentication : \" + e.getMessage(), e);\n                }\n\nNot sure if you have a better idea for how to display that.\n. Ah, I like the idea of throwing a separate AuthorizationException as that seems more appropriate. It would also clean up the error message a little, as with my code above it will show \"Incorrect Login. LDAP Authentication : [LDAP: error code 49 - Invalid Credentials]\" instead of '\"LDAP Authentication : Invalid Credentials\"' when you try signing in with an incorrect password. We could format these two separate error messages distinct from each other if we threw and caught different exceptions. \n. Hey @inoviavenkat, have you been able to commit the revisions we discussed above to your fork? They look good to me and work when i edit them locally in my build.\n@inoviaazkaban @inoviavenkat @davidzchen @hluu @logiclord - can someone take another look at this pull request? I've been running of it for a few weeks and have not encountered any issues. I think it's ready to merge into master once someone with write access gives it a final look over. Thanks!\n. We are exploring this possibility by embedding the flow within a subflow that has a unique name. Then you can schedule multiple subflows, even with the same internal jobs, throughout the day\n. Yes, by setting the useExecutor flow override manually when launching a flow, or through the API when scheduling a flow. We still cannot pull this value from the job files.. I have only been able to successfully force execution to an executor by setting the 'useExecutor' flow override within the web interface when launching a job. Ideally, I'd like to be able to set this within the job files themselves when loading the project (see #656) but it doesn't seem to respect that configuration. \n. @logiclord is it possible to set useExecutor in the http request when scheduling with the API calls? can you provide an example if so?\n. I've been running my Azkaban installation off the latest version of MySQL (5.7.13) for a few weeks now and haven't ran into any issues yet. We haven't done enough extensive testing to determine its full compatibility, but I don't expect to run into any issues.\n. +1 - we have been struggling with the same issue as @cdonat for a while here. I never got this to work either, by putting the values inside azkaban.properties. Not sure if they should go in the job file definitions, or if this functionality doesn't work as a whole.\n. +1 on the HA Web Server set up. Currently I have our Azkaban implementation set up on 2 separate servers, with the MySQL database replicating from one to the other. I have installed the web server on both, but can only have the jvm up on the primary, as if it is up on the secondary as well it will corrupt the database. It would be great if we could have multiple web server instances online with a load balancer in front.. I'd love to, but unfortunately my hands are currently tied by legal at my company and I'm not allowed to publish any of my code back yet. From what I can tell, it would be a simple update to that one function within that one file, if anyone else wants to take a stab at it. Once I get approval from legal I'll submit a pull request. I thought it worthwhile to at least mention here until then.. Sure, we currently use Azkaban as our batch scheduler for all our Java Batch processing jobs. In preprod, we have several instances set up, each managing multiple environments. For example, we have one Azkaban instance for all our dev regions, a separate Azkaban instance for our test regions, and then a separate Azkaban instance for our performance test regions. Each of these instances manage multiple environments, sending jobs to the correct executor depending on which project it is launched from. When a job is launched, it compared the project name to values stored in the properties file to determine which executor ID to send it to (internal code enhancement we have developed). This allows us to manage multiple independent environments within the same Azkaban console, without the worry of sending jobs to the wrong executor.\nIn production, we have one Azkaban instance that we use to schedule our Java Batch jobs across multiple executors. Currently we predefine the exact executor every job runs on, but eventually we plan to move towards letting Azkaban perform the load balancing for us.\nWe have also developed an LDAP plugin extension that allows the use of a bind account when authenticating for more secure connections.\nWe have also developed an HA set up that we use in production with a replicating MySQL database and active-passive webserver instances. In the event of a disaster, we will shut down the primaries and fail over to the secondary instance which will then be brought online. The executors are then reconfigured to hook into the secondary instance. \nWe have also developed a python based scheduling script that we use to load our job schedule on a weekly basis from a json inventory we manage in our cmdb. We created a few new API's for this that allow us to schedule everything to our needs and retire projects/environments at ease.\nWe have many other small bug fixes and internal enhancements that we plan to release back to the open source community here once we receive approval from legal. We transitioned over to Azkaban from an enterprise scheduler last Fall, and have been pleased with our decision and the ongoing activity here ever since. Our team is actively working on improvements to the system that we think will benefit everyone! (once we are able to contribute back of course). 'ever' should be 'even' too. ",
    "prozach": "3.0 still looks missing from the downloads page.  Any update timeline here?\n. ",
    "lin375691011": "It's done\n. ",
    "sundy-li": "I found that command source is also not work in azkaban, is that any way to pass some properties dynamically? such as  from=date -d \"-1 days\" \"+%Y-%m-%dT00\"   but i could not use ${from} cause azkaban will look up into the .properties file to replace ${}\n. ",
    "aupadhyay0606": "Any update on this issue?\n. ",
    "Shubhirb": "Any update on how to pass parameters dynamically?. ",
    "yjmeng": "any update on this issue???. ",
    "mahmoudmahdi24": "any updates ?. ",
    "belbis": "Doesn't seem like this was ever resolved, but I was working with a similar issue working with time based jobs.\nexample storing variable:\ncommand='export dt=`date -d \"- 1 hours\"`; echo $dt'\nexample executing subshell:\ncommand='echo `date -d \"- 1 hours\"`'\nexample if you need to use variables across commands:\nbash\ncommand='echo `date -d \"-1 hours\"` > /tmp/date_persist.txt;'\ncommand.1='export dt=`cat /tmp/date_persist.txt`; echo $dt;'\ncommand.2='echo `cat /tmp/date_persist.txt`;'\ncommand.3='rm /tmp/date_persist.txt;'\nof course you can try to leverage JOB_OUTPUT_PROP_FILE for doing this, but I found the shell commands easier to navigate.\nhope this helps future stuck people.\n. ",
    "yanghaoAndroid": "@logiclord  @juhoautio    very exellent idea\uff0cbut the code of the master can support this funnction ? i  am very desire this  \" job priority \"   function . who can help???????????  \nthis may be a  solution:::::::\nhttps://github.com/hanip-ss/azkaban/releases    . ",
    "yduf": "Hi,\nis there a roadmap for that ?\nDo you think it would be complex to do that ? (assuming it can be contributed) \n. ",
    "zrudzionis": "That would be great!\n. ",
    "sowe": "Hi @davidzchen and @vikramkone  thanks for your comments \nzip name for first job -> basic_1st_command.job.zip\nzip name for second job -> basic_2nd_command.job.zip or basic_2nd_command.zip\nany problem for that ?\n. Hi @davidzchen\nOK, I got it , i thought i could to upload a single file with a new job .\n. ",
    "hhservice": "i build linkedin.rest.li , found pegasus-common.jar\n. i want to builde azkaban-3.0.0 with src, but found error . so i don't know what's run tests in debug ?\n. thanks\n. ",
    "mixalturek": "It's much simpler to execute it as \"exec spark-submit\", which replaces the shell without creating a new process. I didn't try to put it directly to \"command=\" but it nicely works in spark-submit wrapper script.\n. For those who have requirement to schedule in UTC independently to server location, client location and daylight saving times...\nDirty workaround is to configure timezone to UTC and optionally put a notification for the users to the page header. The select time dialog will then allow the users to choose between \"+00:00\" and \"UTC\" which are effectively same (\"UTC\" is broken and defaults to \"+00:00\" which is UTC too). Azkaban will then also show all times in UTC which also improves the user interface (user has no idea what the times mean without knowing configuration).\n```\nazkaban.properties\ndefault.timezone.id=UTC\nazkaban.name=Local\u00a0\u00a0\u00a0\u00a0All times use UTC timezone!\n```\nI have experimentally verified that this configuration change won't shift execution times of the existing jobs. Both time and time zone is stored to the database and the jobs will be executed at the expected times after change of default.timezone.id to UTC and restart.\nprivate static String INSERT_SCHEDULE =\n      \"INSERT INTO \"\n          + scheduleTableName\n          + \" ( project_id, project_name, flow_name, status, \"\n          + \"first_sched_time, timezone, period, last_modify_time, \"\n          + \"next_exec_time, submit_time, submit_user, enc_type, \"\n          + \"schedule_options) values (?,?,?,?,?,?,?,?,?,?,?,?,?)\";\n. ",
    "jeroenvlek": "I'm having the same NPE, while running in distributed mode, and I don't have azkaban-plugins installed. Does this mean that you do need azkaban-plugins? Even for a simple command type job?\nI used the sample command.zip:\ntype=command\ncommand=echo \"hello\"\ncommand.1=echo \"This is how one runs a command job\"\ncomnand.2=whoami\nAnd I get the same NPE:\n02-12-2015 05:51:40 PST command INFO - Starting job command at 1449064300160\n02-12-2015 05:51:40 PST command INFO - azkaban.webserver.url property was not set\n02-12-2015 05:51:40 PST command INFO - job JVM args: -Dazkaban.flowid=command -Dazkaban.execid=4 -Dazkaban.jobid=command\n02-12-2015 05:51:40 PST command INFO - Building command job executor. \n02-12-2015 05:51:40 PST command ERROR - Failed to build job executor for job commandnull\n02-12-2015 05:51:40 PST command ERROR - Failed to build job type\nazkaban.jobtype.JobTypeManagerException: Failed to build job executor for job command\n    at azkaban.jobtype.JobTypeManager.buildJobExecutor(JobTypeManager.java:371)\n    at azkaban.execapp.JobRunner.prepareJob(JobRunner.java:520)\n    at azkaban.execapp.JobRunner.run(JobRunner.java:439)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.NullPointerException\n    at azkaban.utils.Utils.getTypes(Utils.java:263)\n    at azkaban.utils.Utils.callConstructor(Utils.java:268)\n    at azkaban.jobtype.JobTypeManager.buildJobExecutor(JobTypeManager.java:366)\n    ... 7 more\n02-12-2015 05:51:40 PST command ERROR - Job run failed preparing the job.\n02-12-2015 05:51:40 PST command INFO - Finishing job command attempt: 0 at 1449064300211 with status FAILED\n. What puzzles me is that the NPE is caused by one of the args in the following being null:\n```\n  public static Class<?>[] getTypes(Object... args) {\n    Class<?>[] argTypes = new Class<?>[args.length];\n    for (int i = 0; i < argTypes.length; i++)\n      argTypes[i] = args[i].getClass();\n    return argTypes;\n  }\npublic static Object callConstructor(Class<?> c, Object... args) {\n    return callConstructor(c, getTypes(args), args);\n  }\n```\nLooking at the caller:\nUtils.callConstructor(executorClass, jobId, pluginLoadProps,\n              jobProps, logger);\nThis means that jobId, pluginLoadProps, jobProps or logger should be null. \njobId evaluates to 'command' and is logged via logger in the handling of the NPE, thus these both are not null.\npluginLoadProps is initialized in that same method and can't be null. That leaves jobProps. A bit lower in the stack, in prepareJob() there is a null check, but the member isn't final, so is it possible that it's set to null as caused by a race condition?\n. Props pluginLoadProps = pluginSet.getPluginLoaderProps(jobType);\n      if (pluginLoadProps != null) {\n        pluginLoadProps = PropsUtils.resolveProps(pluginLoadProps);\n      } else {\n        // pluginSet.getCommonPluginLoadProps() will return null if there is no plugins directory.\n        // hence assigning default Props() if that's the case\n        pluginLoadProps = pluginSet.getCommonPluginLoadProps();\n        if(pluginJobProps == null)\n          pluginJobProps = new Props();\n      }\nI don't understand: How can this code make pluginLoadProps null? \n// edit\nAhhhhh, I see it now:\nif(pluginJobProps == null)\n   pluginJobProps = new Props();\n}\nshould probably be:\nif(pluginLoadProps == null)\n     pluginLoadProps = new Props();\n}\n. @juhoautio Do you want to create the PR? I don't deserve it after that display of sloppy reading ;)\n. PR here: https://github.com/azkaban/azkaban/pull/585\n. On further inspection, it seems that the following is simply missing from create.execution_flows.sql:\nexecutor_id INT NOT NULL\n. Thanks for updating the online docs to 3.0!\n. PS: This was a vanilla install, not an upgrade from 2.7. You might want to clarify that in the documentation.\n. This includes the link to the Jetty SSL config, which leads to: https://www.codehaus.org/termination/\nThis seems a good alternative resource: http://www.eclipse.org/jetty/documentation/current/configuring-ssl.html\n. Hi guys, can you update or remove the downloads page. We're at 3.5 by now, and that still uses 2.5. Furthermore, I recommended this project to a client and they installed the old version, meaning that it causes headaches ;)\n. ",
    "todd-fritz": "I am receiving the same error when attempting to run a command job type in distributed mode.  My understanding is that the job plugin additions are not needed for the default job types.  \nCould someone please respond to this issue?\nWithin class:  JobTypeManager\njava\nprivate void loadDefaultTypes(JobTypePluginSet plugins) throws JobTypeManagerException {\n    logger.info(\"Loading plugin default job types\");\n    plugins.addPluginClass(\"command\", ProcessJob.class);\n    plugins.addPluginClass(\"javaprocess\", JavaProcessJob.class);\n    plugins.addPluginClass(\"noop\", NoopJob.class);\n    plugins.addPluginClass(\"python\", PythonJob.class);\n    plugins.addPluginClass(\"ruby\", RubyJob.class);\n    plugins.addPluginClass(\"script\", ScriptJob.class);\n}\n. I was able to work around the problem by adding defensive code (after reviewing the git history of changes).  Try after adding this code to JobTypeManager after line 364, immediately before the job is populated.\njava\n      if (pluginLoadProps == null) {\n        logger.info(\"...pluginLoadProps was null, assigning new empty Props().\");\n        pluginLoadProps = new Props();\n      }\n      if (pluginJobProps == null) {\n        logger.info(\"...pluginJobProps was null, assigning new empty Props().\");\n        pluginJobProps = new Props();\n      }\n. ",
    "rapidoo": "Sorry I miss to use the var in Context ...\n. replace by https://github.com/azkaban/azkaban/pull/579\n. Sure, please replace the var and the properties \nFred\n\nLe 24 nov. 2015 \u00e0 19:12, David Z. Chen notifications@github.com a \u00e9crit :\nIn azkaban-webserver/src/main/java/azkaban/webapp/AzkabanWebServer.java:\n\n@@ -759,6 +759,10 @@ public static void main(String[] args) throws Exception {\n     String staticDir =\n         azkabanSettings.getString(\"web.resource.dir\", DEFAULT_STATIC_DIR);\n     logger.info(\"Setting up web resource dir \" + staticDir);\n+\n-    String contextDir =\n-        azkabanSettings.getString(\"web.context\", \"/\");\n  How about web.site_root instead? That might be more descriptive.\n\n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "Kindaichi": "I have the same problem, and I had solve it.\nyou can add --info when running gradlew to get more error details.\nThe problem is the build process would use git command when create version file,but if you download the  tarball from https://github.com/azkaban/azkaban/archive/3.0.0.tar.gz, it is not  a git repo, so git would exit with non-zero value.\nTo solve this, all you need to do is git clone the azkaban repo, and checkout to the 3.0.0 tag.\n. ",
    "mikebaldinoiii": "I'm running into this as well. The answer is you do need to do a kinit within each job because its appending the flow/job information instead of the uid of the username: \n$ id\nuid=1665152075(azkaban)\nThis is the error: \nklist: No credentials cache found (ticket cache FILE:/tmp/krb5cc__test_project__test_job__test_job__31__azkaban)\nThis is where the ticket actually is: \nTicket cache: FILE:/tmp/krb5cc_1665152075\n. ",
    "girishnath": "@vikramkone +1 on this issue. \n. ",
    "ErikSchutte": "Hey guys, \nI've been using azkaban for some time now and would really like to use the global.properties functionality. Are you guys planning on resolving this issue? My current approach is to give each individual project a common.properties file that includes several values. But I'd like to do this from a single global.properties to reduce small operations for each individual project, or is there a higher abstraction layer I can use that I haven't figured out yet?\nKind regards,\nErik. ",
    "yannli": "so what is the difference between these two modes. \nrefer:\nhttp://stackoverflow.com/questions/37290368/how-azkaban-run-spark-job-calling-spark-task-type-command-by-the-shell-and-b\n. ",
    "r7raul1984": "@vikramkone   what is the difference between these two modes\uff1f. ",
    "Baurand": "my properties are set in conf/global.properties and seems to not be read\n. ",
    "younseunghyun": "u have to set that properties on executors at\nplugins/jobtypes/commonprivate.properties\n. Have you set a ip of executor's at db and invoke it?\n. you have to invoke azkabn webserve to recognize executor.\nthere is two method to invoke.\n1) restart\n2) api \napi is not in the documents.\nTo invoke, using this kinds of script\nplz modify azkaban url and id, password\nAZKABAN_URL=URLOfYourAzkaban\nSESSION_ID=$(curl -s -k -X POST --data 'action=login&username=ID&password=PASSWORD' $AZKABAN_URL | jq '.\"session.id\"')\nSESSION_ID=$(echo $SESSION_ID | sed 's/\"//g')\necho \"SESSINO_ID :\" $SESSION_ID\ncurl -s -X POST --data \"session.id=$SESSION_ID&ajax=reloadExecutors\" $AZKABAN_URL/executor\n. i hope it can help you.\ni struggle with this issue for a week ... \n. Ah.. delete the MinimumFreeMemory of filter. it check memory of executor and if memory is under 4GB, then return false.\nazkaban.executorselector.filters=StaticRemainingFlowSize,CpuStatus\n. I'm encountered that kinds of error, but project worked.\nProject flow isn't executed? \n. Well I haven't encountered this kinds of error ... \n. Above issue is due to memory contraint of azkaban.\nDefault executor setting need minimum free memory size to be over 3GB. To turn off the this property, put this property at plugins/jobtypes/commonprivate.properties at executor server\nmemCheck.enabled=false\n. why network time protocol issue is written here? any relation with this issue?. As i know, no or you have to update that job file directly to db\n. Information of project is stored in db. So, you just have to migrate data at db to other\n. ",
    "burgerkingeater": "@artem-garmash thanks for actively fixing this issue! My understanding of this PR is to \nShow queued jobs as well in the job list of the flow, previously it won't be shown.\nCan you explain how would it help making access to previous attempt logs more easily?. @HappyRay this looks useful, and i'm willing to review it. @bmsq would you mind updating the PR with latest master and make sure the build goes through? Thanks for the contribution.. @bmsq hi are you still interested in this PR. We are looking forward to it. And it seems we have a strong need for it. If you don't have time to get to this, I'm happy to take it over.\n@HappyRay I think we have a strong need for this. We are running into this issue when copying hard link for a project with few thousands of files:\nhttps://stackoverflow.com/questions/11289551/argument-list-too-long-error-for-rm-cp-mv-commands. @bmsq thanks for your contribution. It seems this PR contains thousands of changed files. I think you can open a new clean PR based on latest master with your change only. . @bmsq  thanks for your contribution! We have merged another similar PR(https://github.com/azkaban/azkaban/pull/1583) given the urgency to solve the issue.  Let me know if you have any feedback regarding this PR.. @mukund-thakur thanks for your suggestion. Can you share more details of your user case or production experience of this change? For example, executor host/group setup, number of jobs running on them daily, etc. Though our flow/job configuration might change in the future which might affect implementation details of the change, but we are very interested in learning the user experience.. @mukund-thakur Thanks for sharing those details. We are interested in taking this feature into the main branch. My plan is we set up a development branch which you and I can both contribute code to and review each other's code so that we can iterate faster. We will merge it into master once the PR is approved by other azkaban team members. What do you think? . @mukund-thakur thanks. I created a branch in my azkaban fork repo called executorpool_dev, and just sent you an invitation as collaborator.. We had a discussion in the team and here is the outcome of it:\n1. We should have a consistent name for the feature, initially we use executor pool internally and @mukund-thakur 's pull request uses executor group. I don't have strong preference between these two, but the minor issue of using \"group\" is it's a mysql keyword adding a bit complexity when we write SQL query.  So we think it's better to call it \"pool\".\n2. Executors' pool name should be configurable in executor's property file. \n3. We should have a default pool which execution goes to if its pool name is not specified. The default pool's name should also be configurable in web server's property file. If default pool name is not specified in config file, we will use a hardcoded name. If an executor doesn't have a pool name, then its name is default pool's name. \n4. In execution history page of azkaban UI(WEB_SERVER_URL:WEB_SERVER_PORT/executor), we should have one additional column tracking pool name of that execution.. @mukund-thakur Thanks for your input and I think your thoughts on point2 is valid concern. But to change pool name for executor doesn't necessarily require restarting executor. We can:\n1. change the pool name in executor db\n2. reload executors\n3. change the pool name in config file to make it consistent with what's in db.\n. @mukund-thakur for your thoughts on point 3, as we discussed in google hangout, if an executor is not specified a pool name, then its pool name should be default pool name.. @HappyRay i tested it locally as sole mode. Manually throws an exception in the db deletion method and verified it won't send any alerting emails.\n. addressed the comments. @HappyRay, @fsi206914 \nLooks good to you guys?. i tested in solo mode. @HappyRay updated . @kunkun-tang updated. @HappyRay  updated.\nHave you considered using a command \"cp -arl\" instead? \nThanks for suggestion! The current method works fine, and replacing it with new command requires extra overhead like testing/refactoring. So I will add it to todo item in the future if we want to refactor our code but for this time i think it's ok to stick with current one.\n. updated per comment @HappyRay . The reason we don't consider cp -arl is that the command doesn\u2019t work for mac, and mac doesn\u2019t have an easy way to do recursive hard linking. If we use cp -arl only, it would be infeasible to do local debugging. . @HappyRay updated the rb. just realized there's already \"executor.host\" property we can leverage here.. @kunkun-tang why do we need to know port here?. @kunkun-tang we do have the getPort() method in the same class AzkabanExecutorServer. I think we will need to make it singleton so that we can use getHost(), getPort() by doing like AzkabanExecutorServer.getInstance().getHost(). We can do it in a separate commit.. @kunkun-tang yes, we will backfill this property when deploying the config file to each host.. @HappyRay will update the change description before merge.. @HappyRay we can make the process hang with kill -STOP ${PID}\n. I will reduce the retry number from 5 to 3.. @HappyRay will add my test procedure in change description when merging the commits.. @iCoolchar how long have you waited? . @Codefor thanks for reporting this issue. How often does this happen? Does it happen intermittently? . @keiki1120 can you share the screenshot of your sla setup?. @keiki1120 i doubt the feature is not working. Is your email setup correct? Can you receive emails from azkaban on flow failure if you enable email notification? If you change SLA action to kill from email, would your flow be killed?. @keiki1120 does your azkaban executor's azkaban property file also contain email setting ?\n. @keiki1120 no, i mean azkaban executor's property file:  azkaban.properties. @keiki1120 you need to do that too. can you try add following properties to that file?\nmail.sender\nmail.host\nmail.user\n. @kunkun-tang \nRunning flow resides in old executor only.\nI manually started a bunch of flows locally and checked they were killed on time. \n. @HappyRay will add unit test later.. @juhoautio \n1. if the property is set to a number <= 0, then this feature is disabled. The reason we have default value as 10 days is we do want to kill flows running over long being unnoticed. \n2. it's documented http://azkaban.github.io/azkaban/docs/latest/ you can search azkaban.server.flow.max.running.minutes \n3. as you can see from document, it's set in executor's property file\n4. Yeah, we merged multiple constants class into one class.. @juhoautio the reason we want to have a max time on flow running time is in Linkedin there're non-trivial amount of flows that abandoned by their owners but keep occupying azkaban and hadoop resources. After talking to our users, we found 10 days are a reasonable number to us since generally no flow should actually run longer that 10 days. Why would 10 days seem too short to you?\nyou can check https://github.com/azkaban/azkaban/pull/1027 for the source\nThanks, it's a good idea to add this property in default prop file. We will follow up with that.. Hi @mukund-thakur thanks for the feature request. Actually this is a feature under active development. We will set a configurable TTL for flow running time. Thanks!. @sharks222 it's flow-level option, which can be specified as execution option. More details can be found in this commit which is still under development: https://github.com/chengren311/azkaban/commit/8555143efc9c9faf06d33cf739997b4e6c34388a. @devangorder \nwhat's your command to call the api, i tried this but not being able to see the issue.\ncurl  -X POST --data \"action=login&username=cheng.ren&password=XXXX\" http://localhost:8081. splitting this change into multiple PRs. closing this one. . @arumugarani, would you mind posting images of before and after UI so that we can view this change more easily?. @suvodeep-pyne \nadded the deprecated annotation. \nRegarding my testing strategy, mostly I tested it manually by setting up different types of SLA on schedules and checkin if it works as expected.\nCurrently SLA feature is not covered by any of our automation tests. We should definitely add it in our automation test framework. I will work with @jamiesjc on that.. we pushed a fix. can you try again with the latest master?. @juhoautio Suvodeep is on vacation. Currently there're some other high priority items team is working on, but I can take a look when I get a chance, most likely this weekend. . LGTM too. thanks!. @juhoautio i think it's a valid feature request. Thanks! I'm curious about how you would plan to implement setState and getState, and how do we define a state exactly?. no longer needed. @HappyRay what's wrong with \"Remove unused suppress warning annotation\"?. @HappyRay I'm reviewing this change.. @juhoautio sorry for the delayed response and thanks for your active contribution! I am keeping reviewing this PR and will work with you on getting this merged ASAP. Thanks!. @juhoautio also maybe i missed something from your PR, but where do we set job status from killing to killed?. also how would killing status work with concurrent execution options? . @juhoautio thanks for fixing this race condition!\nHow about FlowRunner's flowKilled? I suspect it has the same risk.. thanks for working on this. @juhoautio \ni'm going to close this PR as we are putting a long-term fix which is to fix the db schema. We will add flow id to the primary key set for execution_jobs.. @juhoautio flow id i mean, current table's key is (execution id, job id, attempt). \nSo it's a rare case since it only happens as an issue for two subflows contain two jobs with same name. And we are asking our DBA to push the schema change for us. . ./gradlew azkaban-common:cleanTest azkaban-common:test\nfor me test running time is increased from 33s to 18s with this change.. @HappyRay no, this is a patch of fix.. @HappyRay updated. @HappyRay added in the change description.. @reallocf thanks for doing this. What is the current way of cleaning execution dirs? As far as I could remember, they are cleaned up by cleaner thread inside flowrunnermannger. And it's a polling based mode which cleans up every 1 hour on directories not been modified for 1 day.\nWith this change, do you think we should remove this piece of logic?\nThis change will also add overhead of getting logs from db when accessing logs for a finished flow. The overhead will go away with @suvodeep-pyne 's hdfs change, right? but for now can we test how long the overhead would be? . @HappyRay as we introduced dynamic authentication mechanism(password is generated dynamically), longer cache TTL will reduce users' frustration of typing password again and again. Changing the default value is simpler than changing each installation's configuration file. PR of related doc change will follow up.. @shuzhang1989 currently it only uses around 1000 buckets out of 10000(default max).. @HappyRay we can talk offline. In a nutshell, trigger data is also kept in memory, it's very tricky to backfill to db only. Providing API and backfilling with API is safest and most convenient way I can think of. . @kunkun-tang agree, i will add DO NOT MERGE in the title of this PR.. @HappyRay is this necessary? it seems version is not mentioned anywhere in this doc.  Should this doc always refer to latest version?. downside is we change the convention/implication of this doc. If we do this, it will give users impression that If version is not specified, every az version works as documented. But it's not actually the case. Open source projects i know maintain doc pertaining to latest release only but keep user updated by release notes. . @HappyRay ok, do you have other comments regarding this PR?. could you help me understand better on use case of the api? or explain it in the change description. Thanks!. i'm curious about when it will be used.. @HappyRay @kunkun-tang added more explanation. But I do think the change is self-explanatory. . @HappyRay the issue surfaced when jobs were not killed successfully by SLA in occasion cases. It turned out it's killed by a non-active job runner returned by querying active job runner list by job id.. @HappyRay \nNo one cleaned the list up.\nWe can talk offline.\n. @HappyRay updated the description.. @HappyRay the old check was not checking the number of actions at all when updating SLA. The null check was used when uploading project logs.. @juhoautio hah, i missed the FlowRunnerTest2.java, thanks!. I'm wondering what the convention of static methods are? Should they all be put into an util class?. have we documented this feature?. @HappyRay do you have any other comment?. @HappyRay do you have other feedback?. @juhoautio @kunkun-tang Props is overly used everywhere. In this case we are trying to remove the dependency on Props for few reasons: 1. Props is too complicated for the user case here. Props's main purpose is for inherited properties, but here we just want key value map. 2. DependencyInstanceConfig will be used in external plugins. If they depends on Props, it will make us hard to evolve Props while keeping compatibility . . @acyouzi thanks for the PR. IMO, we should enforce package must have \"zip\" as the extension. This will make things easier.. @juhoautio yes it's under progress. UI part is still under progress. \n\nWhat happens to a pending data dependency trigger if azkaban is restarted while it's waiting for data?\n\nThe pending one will recover from db since all pending dependencies will be persisted into db.. this branch will used for development of data trigger feature. Will submit a series of PRs when it's ready. . @reallocf updated. Can we upload in-memory object to db instead of the raw file? Then when reading flow config from db, we don't need to do all of these processing(download to a temp file, converting the temp file to an object, then delete the temp file).. Hi, thanks for filing the issue. Unfortunately, this is not what we currently support. But it's a potential feature we might consider in the future. Would you mind telling us the concrete gains to distribute the flow to multiple servers in your use case? . hi, did the job get killed without retry? \nCan you share:\n1. Screeshot of the SLA setting for that job\n2. Job logs when the job was being killed.\n3. job properties. Which AZ version are your running? Seems you are running pretty old version.. thanks, will review it later.. @juhoautio  sorry for the late reply, i will try to review it this week.. hey, thanks for reporting this issue. I'm not able to reproduce this issue. Can you post the screen shot of your schedule/sla setup and the error message.. hi, you cannot remove SLA from this page. SLA can only be removed by removing the associated schedule. See https://github.com/azkaban/azkaban/issues/1347. \nin older versions when i remove all the values and save, similar to what i am doing now, then the SLA will get removed.\nNot sure how you managed doing this by removing all values since duration cannot be an empty value. Even though this is not the expected way to remove SLA.. hey, not able to get a reproduce either. Did you observe anything outstanding in the log?(e.x email sending failure). @yangxu1362850636 3.30.1 is pretty old. Please consider upgrading to latest. Also what's your email setting, did you configure your email setting correctly in your azkaban.properties file? Can the email address receive flow failure/success email? Did you observe anything outstanding in the log when job killing by SLA happens?. @yangxu1362850636 can you try latest version?. @HappyRay https://github.com/kirviq/dumbster just did some research on unit testing on sending emails, this could be helpful.. @HappyRay thanks, there're existing unit tests for that.. @reallocf that's a good idea. I added the related unit test.. @HappyRay  let me know if you have more feedback.. @jamiesjc thanks for reviewing, added more unit test.. @kunkun-tang seems they are lacking required quartz properties in azkaban property file. Do you want to add doc for that?. @ismailsimsek thanks for reporting the issue!\n- i see Quartz scheduler when i want to schedule a flow\nwhat did you see exactly.\nAlso the default value for the flag is false so you don't have to specify it if  you wanna disable quartz.\n@kunkun-tang should we document that quartz is still in development mode?. @ismailsimsek thanks for the contribution! would you mind posting an before-after screenshot?. @ismailsimsek thanks.. Thanks for the PR!\nSwitch to using POST with form params instead of GET with URL params, so that the number of execution ids passed can be longer.\nDo we know what will be the limit for POST? \n. Thanks, the change description doesn't mention the verification of the fix of #1653, would you mind adding how you verified it as well? Thanks. @juhoautio thanks!. @juhoautio\nwe have an issue with latest release:\n```\n2018/03/28 05:29:02.367 +0000 ERROR [RestfulApiClient] [Azkaban] unable to parse response as the response status is 405\n2018/03/28 05:29:02.367 +0000 ERROR [ExecutorManager] [Azkaban] Failed to update ExecutorInfo for executor : [*HOST*]:[PORT] (id: 369)\njava.util.concurrent.ExecutionException: org.apache.http.client.HttpResponseException: \n\n\nError 405 HTTP method POST is not supported by this URL\n\nHTTP ERROR 405\nProblem accessing /serverStatistics. Reason:\n Powered by Jetty://\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nat java.util.concurrent.FutureTask.report(FutureTask.java:122)\nat java.util.concurrent.FutureTask.get(FutureTask.java:206)\nat azkaban.executor.ExecutorManager.refreshExecutors(ExecutorManager.java:279)\nat azkaban.executor.ExecutorManager.access$1300(ExecutorManager.java:76)\nat azkaban.executor.ExecutorManager$QueueProcessorThread.processQueuedFlows(ExecutorManager.java:1810)\nat azkaban.executor.ExecutorManager$QueueProcessorThread.run(ExecutorManager.java:1778)\n\nCaused by: org.apache.http.client.HttpResponseException: \n\n\nError 405 HTTP method POST is not supported by this URL\n\nHTTP ERROR 405\nProblem accessing /serverStatistics. Reason:\n Powered by Jetty://\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nat azkaban.executor.ExecutorApiClient.parseResponse(ExecutorApiClient.java:52)\nat azkaban.executor.ExecutorApiClient.parseResponse(ExecutorApiClient.java:31)\nat azkaban.utils.RestfulApiClient.sendAndReturn(RestfulApiClient.java:133)\nat azkaban.utils.RestfulApiClient.httpPost(RestfulApiClient.java:125)\nat azkaban.executor.ExecutorApiGateway.callForJsonString(ExecutorApiGateway.java:123)\nat azkaban.executor.ExecutorApiGateway.callForJsonType(ExecutorApiGateway.java:87)\nat azkaban.executor.ExecutorManager.lambda$refreshExecutors$0(ExecutorManager.java:267)\nat java.util.concurrent.FutureTask.run(FutureTask.java:266)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\nat java.lang.Thread.run(Thread.java:745)\n\n2018/03/28 05:29:02.368 +0000 INFO [ExecutorManager] [Azkaban] Using dispatcher for execution id :277611\n2018/03/28 05:29:02.368 +0000 INFO [ExecutorManager] [Azkaban] Reached handleNoExecutorSelectedCase stage for exec 277611 with error count 0\n2018/03/28 05:29:02.368 +0000 INFO [ExecutorManager] [Azkaban] Using dispatcher for execution id :277611\n2018/03/28 05:29:02.368 +0000 INFO [ExecutorManager] [Azkaban] Reached handleNoExecutorSelectedCase stage for exec 277611 with error count 0\n```\ndo you think it's related to this PR?\n. thanks! If i understand your change description correctly, https://github.com/azkaban/azkaban/pull/1663 is a subset of this PR? so we will only need to review  this one?. an alternative approach is to wrap what's in the internal scripts into a function in user facing script.\nE.x:\n!/bin/bash\nfunction internal_start_executor(){\n .....\n}\ninternal_start_executor > out &\nOne advantage of this approach is less files to maintain making code navigation easier.. @senecaso-sf Thanks so much for the contribution!\n I'm curious about \n1. When loading a new project, what verification requires the flow traversal?\n2. What is the optimization and why does it reduce the time so much?\nIt would be good to detail them in the change description.  Thanks!. @senecaso-sf Thanks for the explanation. It looks very interesting. @jamiesjc might work on this piece. Do you want to review this PR?. @senecaso-sf do you think massive-flows.tar.bz2 contains too many files? Sometimes it might exceed the file handler limit of mac. . @senecaso-sf  thanks for reporting this issue. The fix(https://github.com/azkaban/azkaban/pull/1684) was put in and we will do a release soon. BTW quartz feature is still under development so we don't expect this to be used in production.. closed this PR as a better solution is presented(https://github.com/azkaban/azkaban/pull/1704/).. @juhoautio thanks for your continuous contribution. i will take care of it. . Thanks, took an initial look.\nIMO, we are reinventing the wheel by creating Emailer and EmailMessage. There're few well-tested and open source leverageable email client libs : \ne.x: https://commons.apache.org/proper/commons-email/userguide.html\nhttp://www.simplejavamail.org/#/about\nhttps://jodd.org/email/\nthis PR would help improve test coverage, but in the long term we should simplify email code and take advantage of reasonable 3rd party lib. i remember we have such plan, right @HappyRay? if so should we treat this piece as in maintenance mode and avoid significant change or still need to fix things here and there?. @kunkun-tang \n- I experimented embedded flow case, and same there.\nI don't think is true here. I have seen user reporting the issue for over long flow_id.. @juhoautio totally agree. \nSo max allowed varchar length is 767? It seems surprisingly low to me. If this is true, how about TEXT? . @juhoautio i see, thanks for explanation. IMO, we should 1. simplify the way we construct flow id for embedded flow. 2. Set a hard limit on flow id 3. when uploading the project check it against the hard limit. . @juhoautio it happened when using traditional flow format.. @juhoautio thanks for the fix. Would you mind adding the test methodology in the description?  . verified the fix in our cluster. thanks!. @HappyRay the PR to make job retry when memory is not enough: https://github.com/azkaban/azkaban/pull/937. thanks for the contribution!. @kunkun-tang thanks! . @antey86 Thanks for your request and sorry for the delayed response. \nfew questions:\n1. Would will you return exactly as fetchAllProjects/fetchAllScheduledFlows?\n2. How do you handle permission issue e.g calling user doesn't have read permission on some projects.\n. @antey86 thanks for your contribution! Would you add more context of this fix, like what's the behavior before and after. you can also post screenshot in change description for better illustration. . @kunkun-tang yes, since it requires the table scan, so it's always good to keep the table size smaller to limit the scan query time.. @juhoautio rebased.. @juhoautio let me know if you have more suggestions.  thanks!. @HappyRay i think my intellij setup was somehow messed. I reenabled the save plugin.\n@juhoautio i will review it after merging https://github.com/azkaban/azkaban/pull/1749. @HappyRay thanks.. @jh3155 thanks, would you mind adding header to flow execution page as well?\nhttps://AZ_URL:PORT/executor#currently-running . @jh3155 thanks.. @HappyRay HadoopJobUtils relies on this method to kill a hadoop job with application id.. actually I took it back, execution dir cleaning up will skip currently running executions. So until the execution is killed, the execution dir won't be deleted. \nazkaban.execapp.FlowRunnerManager\n```\n      for (final File exDir : executionDirs) {\n        try {\n          final int execId = Integer.valueOf(exDir.getName());\n          if (FlowRunnerManager.this.runningFlows.containsKey(execId)\n              || FlowRunnerManager.this.recentlyFinishedFlows.containsKey(execId)) {\n            continue;\n          }\n        } catch (final NumberFormatException e) {\n          logger.error(\"Can't delete exec dir \" + exDir.getName()\n              + \" it is not a number\");\n          continue;\n        }\n    synchronized (FlowRunnerManager.this.executionDirDeletionSync) {\n      try {\n        FileUtils.deleteDirectory(exDir);\n      } catch (final IOException e) {\n        logger.error(\"Error cleaning execution dir \" + exDir.getPath(), e);\n      }\n    }\n  }\n\n. @erwa thanks for the PR.\n In this case, user job should have a parameter for input data location. Overriding flow execution id itself seems a bit odd to me. azkaban runtime properties by concept are generated by azkaban platform and immutable to users. User job can leverage the value of those properties for their own usage but are not supposed to change them. The workaround you suggested is a more standardized way IMO. \n. Closing the PR for now. Another solution could be refresh the installedProjects when executor is set to active(#1824), and we could leverage the installProjects to keep disk usage data for each project. . @juhoautio i'm curious how did you encounter this issue since executor is not supposed to be stopped manually? The recommended way is to call shutdown api of the executor then it will go into the shutting down mode where it's no longer active to accept new flow execution,  all running flows will be killed in 10 days, and executor will shutdown itself when no flow is running on it. . @juhoautio \nlooks we have below error when running SOLO mode:\nException in thread \"main\" com.google.inject.ProvisionException: Unable to provision, see the following errors:\n1) Error injecting constructor, java.lang.NullPointerException\n  at azkaban.executor.ExecutorManager.(ExecutorManager.java:125)\n  at azkaban.executor.ExecutorManager.class(ExecutorManager.java:78)\n  while locating azkaban.executor.ExecutorManager\n    for the 3rd parameter of azkaban.webapp.AzkabanWebServer.(AzkabanWebServer.java:165)\n  at azkaban.webapp.AzkabanWebServer.class(AzkabanWebServer.java:122)\n  while locating azkaban.webapp.AzkabanWebServer\n    for the 1st parameter of azkaban.soloserver.AzkabanSingleServer.(AzkabanSingleServer.java:48)\n  while locating azkaban.soloserver.AzkabanSingleServer\nCaused by: java.lang.NullPointerException\n    at java.util.concurrent.ConcurrentHashMap.putVal(ConcurrentHashMap.java:1011)\n    at java.util.concurrent.ConcurrentHashMap.putAll(ConcurrentHashMap.java:1084)\n    at azkaban.executor.ExecutorManager.loadRunningFlows(ExecutorManager.java:450)\n```\nThe NPE is thrown from \nprivate void loadRunningFlows() throws ExecutorManagerException {\n    this.runningFlows.putAll(this.executorLoader.fetchActiveFlows());\n  }\nwhen this.executorLoader.fetchActiveFlows returns a hashmap which contains an entry with null value. Do you think it's related to this PR? I tried to reverted this commit and the error won't appear.. @juhoautio , seems something is still off. This is what we observed in solo mode.  It looks those execution will never get successfully finalized. \n2018/07/23 12:58:52.359 -0700 ERROR [ExecutorManager] [Azkaban] java.lang.NullPointerException\n2018/07/23 12:58:52.359 -0700 WARN [ExecutorManager] [Azkaban] Finalizing execution 2624. Executor id of this execution doesn't exist\n2018/07/23 12:58:52.359 -0700 WARN [ExecutorManager] [Azkaban] Finalizing execution 1724. Executor id of this execution doesn't exist\n2018/07/23 12:58:52.360 -0700 WARN [ExecutorManager] [Azkaban] Finalizing execution 2047. Executor id of this execution doesn't exist\n2018/07/23 12:58:52.362 -0700 ERROR [ExecutorManager] [Azkaban] java.lang.NullPointerException\n2018/07/23 12:58:52.363 -0700 WARN [ExecutorManager] [Azkaban] Finalizing execution 2624. Executor id of this execution doesn't exist\n2018/07/23 12:58:52.363 -0700 WARN [ExecutorManager] [Azkaban] Finalizing execution 1724. Executor id of this execution doesn't exist\n2018/07/23 12:58:52.363 -0700 WARN [ExecutorManager] [Azkaban] Finalizing execution 2047. Executor id of this execution doesn't exist\n2018/07/23 12:58:52.365 -0700 ERROR [ExecutorManager] [Azkaban] java.lang.NullPointerException\n2018/07/23 12:58:52.365 -0700 WARN [ExecutorManager] [Azkaban] Finalizing execution 2624. Executor id of this execution doesn't exist\n2018/07/23 12:58:52.365 -0700 WARN [ExecutorManager] [Azkaban] Finalizing execution 1724. Executor id of this execution doesn't exist\n2018/07/23 12:58:52.366 -0700 WARN [ExecutorManager] [Azkaban] Finalizing execution 2047. Executor id of this execution doesn't exist\n2018/07/23 12:58:52.368 -0700 ERROR [ExecutorManager] [Azkaban] java.lang.NullPointerException\n2018/07/23 12:58:52.368 -0700 WARN [ExecutorManager] [Azkaban] Finalizing execution 2624. Executor id of this execution doesn't exist\n2018/07/23 12:58:52.368 -0700 WARN [ExecutorManager] [Azkaban] Finalizing execution 1724. Executor id of this execution doesn't exist\n2018/07/23 12:58:52.368 -0700 WARN [ExecutorManager] [Azkaban] Finalizing execution 2047. Executor id of this execution doesn't exist\n2018/07/23 12:58:52.371 -0700 ERROR [ExecutorManager] [Azkaban] java.lang.NullPointerException. @juhoautio thanks, hope it helps. \nmysql> SELECT ex.exec_id exec_id, ex.enc_type enc_type, ex.flow_data flow_data, et.host host, et.port port, ex.executor_id executorId, et.active executorStatus FROM execution_flows ex LEFT JOIN  executors et ON ex.executor_id = et.id Where ex.status NOT IN (50, 60, 70);\n+---------+----------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+------+------------+----------------+\n| exec_id | enc_type | flow_data                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | host | port | executorId | executorStatus |\n+---------+----------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+------+------------+----------------+\n|   12820 |     NULL | NULL                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | NULL | NULL |       NULL |           NULL |\n|    1724 |        2 |        ?TMs?0?/{vS?\\?o\n                                             ??3??k\u0748\u0612??4??W??1?\u440b\u01eb]?{ow?{H???M???vo?t??^?k?? ?16?    >??WA?????H????Qx?c=Z???h1?_\u03d7QF???\n                                          3!w??????<?Y?)?8?@!???4? <6R\"?%?Ea??hsr?Y???  ?JOJ.$$UxrN\u0275??:??H??1*5?l??=???????~?<?L?M????T??%?d?Q??.R?a?w$?h!??    1?????6??)?X7?K??????x?w9V?\u0598\u5ea8?\u0361???\u037b???\u05b6???wz\u0408p?wg???=?R?w???\u064ed??7?\n                                ?f6\u0103????\u1bd0?*}cO?Oi\"u??S?\\??m?qL8=yKq????\\?\u0451????\"?,=?)?\ndml???o?p?>????ZT?????:??$????6??T\u054fK}]\n?&cWL?~?r-?I$/?dC????                 X\\\n8?v??5V??3)*%??p?o???XG?T?zK2?^?{D??@????????s??\u078aA??j??Z?v??W?x??.h?                                                                                                                                                                                                                                                                                  | NULL | NULL |       NULL |           NULL |\n|    2047 |        2 |        ?TKs?0?/{vSpy????2CM??!?aa?%??\ua4462??J??W??\ufc52???6?$M?9??f??\n??^?&?0)???j???\u01ad??\u012f@?q<~??,f?a<?<?f?8?? ?\n                                         3?6?L? 2?b ?,Z??;r?@?r?L???)D?r@\"Eb?Ba\n\\??T?z\niX???S\u068c\n.??k<&'?2WB?\n            $m??f?XO?Q)F?[R?,D??P?\u025a#-????D?\n*???eQ?\n\uf058?[??s?hu?V??k?A???r%?GiU??D?L?;???0W??\\W??0????5Gm?\\?UhC?)?j???1??;=+A?5?PGK?p*???????\u02a1a\"(,?,?uu0}?]??j?/e??????&xM|??u?*[?\u2a30?z\u049a[??r?]???Ywz?n??ej?\u045fV?\u736c??)???g??w?b??? ?I???;??????????\\/?\u07f4???r???f???c/?$R@??\\?> ??Sw~??0                                                                                                                                                                                                                                                                      | NULL | NULL |       NULL |           NULL |\n|    2624 |        2 |        ?TKs?0?/{vSp\\????z??\n???+al\u07bd?\u2c74????p??I\n??q??.?;??(?\u0487???|:f???r:\u03f24??XJ?<c???&\u0164?_\n?Q?e??\u07d0C? *V!g?(??y ??U\n??q\n{R??)?a?z\"FLi3??@R?q??X?????s?zX?d=yC???I????\\@?&+??^\\??'??hPyw6'%?4?;PH?TN\n\u0142Xn??   ??d+J\n             ????q'??N?|3?\n,+?????[?????p\u06f5??a?z????Y@?d? ????HYJq??P?Rx??6?\n?O??Z3????\\?6D??????f???g%?>??h?\n??2?????X:?#L?\u0156??.?\u00fb??? ?O?A?s?m?????K??_?!o??V??WOZs?Xl?+vU?S\u05b7q?\u05c4??????dE?U?]74?g??w??k??? ?I???;????d?'4????$^??i??y???h7?????????!????`??`??/????0                                                                                                                                                                                                                                                                                       | NULL | NULL |       NULL |           NULL |\n+---------+----------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+------+------------+----------------+\n4 rows in set (0.00 sec). @HappyRay plan to run a util program to generate the files before enabling this feature.. @HappyRay updated the PR, any more feedback?. @HappyRay updated.. Please add all necessary comment and java doc.  Well-documented code is very important for future developers to better understand the implementation of trigger dependency type.. @juhoautio i think so, thanks!. @shangwen thanks for reporting this issue. Sorry for the confusion, we are publishing more document around flow trigger feature. Are you trying to use flow trigger feature? . thanks! @juhoautio . @HappyRay this feature is intended for internal tableau users, so i will compose an internal doc before launch.  . @juhoautio thanks for this PR. IMO we have to distinguish between retriable & non-retriable errors in this PR. Otherwise this would be dangerous when dispatch fails with \"is already running\" and all other flows will hang there due to retrying on an already running flow. . @juhoautio thanks. \nI would still like to have this available as an experimental/use-at-your-own-risk feature before adding checks to detect retriable cases. After all, non-retriable dispatch errors seem very rare.\nSince once merged, we cannot turn on/off this feature, so i would not deem it as an experimental-able. \nWhat do you think of the complexity of implementing distinction between retriable & non-retriable errors? Since we are actually considering a new dispatching paradigm - \n1. web server pushes flow to dispatch to standalone dispatching queue(e.g mysql db as queue)\n2. executor pulls the flow from the queue when its resource is available. \nThe advantages would be\n1. dispatching logic is much simpler,e.g web server doesn't need to retry on failure.\n2. paves way for decoupling web server and executor\nlook forward to your opinion.\n. @juhoautio \nThere\u2019s no change in behaviour at all compared to previous version unless user specifically sets a high max retry in configuration.\nif i understand correctly about this change, in this version failed dispatch will keep retrying until it gets successfully dispatched, but previous version will retry up to a cap, am i right?. @juhoautio thanks, left some replies.. @juhoautio yes, once merged, reformatting the whole repo will be needed to be done. . @HappyRay actually class qualifier will be added if it's inside the inner class of declaring class.. @HappyRay some inner class are used just for encapsulation purpose, but for the inner classes in ExecutorManager, i think it makes more sense to separate them out as regular classes. . sure, @juhoautio FYI.. @zkdy thanks for reporting this issue. What do you need reportal for? In my impression reportal is not intended for public use yet. . valid concern. Executor host plus port is preferred IMO, are you interested in contributing a PR?. @juhoautio thanks for adding the test!. @HappyRay me either, @juhoautio can you elaborate more on the bug?. @juhoautio, sorry for the delay. We currently don\u2019t have enough bandwidth as some of us are on vacation. I will try to take a look when I have a chance. . @HappyRay tested on staging cluster, \n1. launch a flow\n2. shutdown executor\n3. watch web server log to see if there's exception when updating the flow status.\nEven if flowRunnerManager is shut down, executor is still able to respond to web server's updating request.. @juhoautio web server keeps a list of running flow and its corresponding executor. Even if the executor list is fresh, web server will still try to reach to inactive executor when iterating the running flow list. . @juhoautio, likely as #2020 though is long-term fix but it is tricky to do.. @juhoautio sorry for any confusion. This is to allow Azkaban executors to be upgraded without disruption to running flows and without keeping multiple instances running.\n we run multiple executor processes on the same instance. When starting a new azkaban executor process, we deactivate old one to prevent web server dispatching new flow execution to this executor process. Old executor processes will be solely responsible for finishing ongoing flows. Allowing multiple executor processes running adds complexity. E.g: duplicate metrics could be produced, or race condition could happen when two executor processes are cleaning up the shared project dir: https://github.com/azkaban/azkaban/pull/2017\n. @Kaoxyd hello, trigger plugin is designed to be extendible to meet custom data dependency need. I'm happy to discuss more about your use case and offer help if necessary. . @Kaoxyd great, i'm glad to see the trigger plugin is being adopted externally. thanks  @weidious for your kafka plugin BTW.\nI can help review your PR if you have any question regarding the implementation, but whether it could be merged with azkaban master is a different story depending on if the plugin will be helpful to others. \n . thanks @ypadron-in can you elaborate in the description which commit causes the issue and why?. can you reference the PR that making executor send alerting email?. Yes, you have to restart Azkaban to pick up new config. . @juhoautio can you help me better understand this PR? Why would it help the described issue?. according to https://github.com/azkaban/azkaban/pull/1231, enabling maxParallelForks should reduce the test running time, @juhoautio  have you compared setup without maxParallelForks specified? . @juhoautio  i did the experiment, it's strange with maxParallelForks = 1, ./gradlew cleanTest test failed for some tests and it failed in 2m 37s,  and maxParallelForks = 12 succeeded in  2m 10s. . @juhoautio sorry for the delayed response. It's strange that the test run time is increased with https://github.com/azkaban/azkaban/pull/1231. I also observed the same result https://github.com/azkaban/azkaban/pull/1231#issuecomment-469506796. Can you summarize our experiment and refer this PR to https://github.com/azkaban/azkaban/pull/1231, then I will merge it, thanks.. thanks!. @juhoautio why would this fix optimize the test slowness by adding the assert?? . @juhoautio 2nd commit: Fix mocking of overloaded method -> test passes quickly now do you know how much time save this fix brings and why?. @Augustinian can you elaborate more on motivation in the PR description? . @ypadron-in  please check  build failure . closing this PR as it's duplicate of https://github.com/azkaban/azkaban/pull/2130. would be great to call out that the time flow spends in preparing state is queue wait time + flow setup time. \nAlso someone might be confusing flow dispatch and flow submitting, worth calling that out as well.. you might need to resolve the conflicts first.. please resolve conflicts.. @ShubhamGupta29 can you elaborate more in the PR description on how this API would be helpful. The rest LGTM. . @HappyRay yes it is, given that Counter should be preferred since it is a native type in metrics lib. . @HappyRay let me know if you have more questions with this change.. Hello, unfortunately not anytime soon... hi @lecterqian\nTo activate an executor, one can just call \"executor host:executor port/executor?action=activate\" on executor host, and it doesn't require http request from web server.\nbut web-server will not call http request to exec-server ,  in fact web server will still need to talk to executor in the new design to fetch execution logs, kill executions, etc.. this is just exception in sending emails. logging the exception should be ok. If we raise the same exception,  the appropriate way to handle it by downstream handler is log it anyway. \n. sure, will do\n. it will be used in FlowRunnerManager's cleanup thread. Cleanup thread won't perform deletion when isActive returns false. can you point out relevant code?. can we put this \".jor\" to constants files btw ?. can we put this \"executor_id\" to the constants files?. shouldn't it return boolean?. same here. I think it's fine. IMO the class contains a few util method, and they are supposed to be declared as static as well. . updated. not sure why this's included... Set listeners maybe is better. if there's only one case here, why bother to use switch case?. we should use stringbuffer here. actually did you copy this code from somewhere? it seems to be duplicate of PatternLayoutEscaped.appendStackTraceToEvent. please avoid wildcard import. the name ai is confusing. why it's enum not class?. executor.host is used in executor manager only, which is inside web server.. can we compare Status like this, not equals?. change it to isFlowFinished to make it more explicit. do we also need to profile the time to getConnection()?. so web server shutdown fails here, deployment should also fail since starting another instance of web server is risky. But if the deployment fails because of this, we still have to manually kill the web server by doing kill -9. So I think we should have kill -9 as the final fallback in the script.. the two scripts will be in two different dirs and might even be in two different machines. Would it be possible to have them share one consolidated shell script?. probably we can, for example have the shared script in azkaban common, and when installing the RPM, the shared script will be put somewhere for these two scripts to refer to, but i don't think it's worth doing this, considering shutdown scripts are so rarely changed. . done. done. @li-afaris i think 'set -o errexit' might cause undesirable results. For example, killing a non-existing process will exit the shell with error code which might be captured by deployment script treating it as a deployment failure, but in this case we actually want to proceed deployment.. I will reduce maxattempt to 3, so that it can fail faster. But I don't think we should spend too much effort tweaking these numbers as long as they are reasonable.. drop \"the\". then it should be consistent with rest of the comments.. why this has to be runtime exception?. any particular reason we throw an exception when there's duplicate key? why not just return false? and if we check duplicate key, why don't we check for delete? . @devangorder good catch! thanks. this method returning true should only indicate memory is granted on request. Since we rely on the return value of this method to construct the retry logic.  If if memory check is not enabled,  it should throws an exception.. i think 1 min is too short, maybe 5 mins. Memory issue should't go away so soon. . Do we need to make getting max and update as one atomic operation? . will it cause overflow?. same here. upper case from to be consistent. why this has to be synchronized?. looks like the logic here is same as what's in addExecutor, can we consolidate the duplicate logic into one method? . quick question, isn't ProcessJob used by all job types? Then why is JOB_ID not found? . Discussed with @HappyRay  offline. We agreed that let's first start with short interval to avoid job long starving. We can adjust the parameter if we observe any outstanding issue.. updated. Might keep it as a separate change.. please avoid wildcard importing . why debug? not info?. log instead of print. then we can just kill the process, right?. fixed. public?. why make deleteDirectory independent of ProjectVersion? Make it as a shared util method? Then can we make it static?. the cleanup method is basically equivalent of FileUtils.deleteDirectory(execDir), maybe we can remove it?. just FileUtils.deleteDirectory(tempDir) will do, deleteDirectory already takes care of file non existing case.. it will trigger shutdown hook,  the executor will be shutdown there. updated . updated. thanks, will take a look. good catch. initialize projects. for (Project project : getProjects()), no need to introduce another variable . can you make the name more explicit? array doesn't indicate anything.. why do we need to introduce projects here? why not just for (Project project : getProjects()). getProject(id) != null simpler. log the project name as well.. resources is a list, can it be printed out in this way? Or we need to join together as a string?. talked with @suvodeep-pyne. Collection type supports this.   . updated. updated. updated. it's a minor event so i think it's ok. @suvodeep-pyne It would be helpful you can elaborate why it's hacky and less obvious. I did some research and the main issue people are going against this approach is because if more than one bit of code anywhere in the program synchronizes on intern strings,  it could lead to deadlock. But here I added a suffix to prevent it. An alternate solution I can think of is to have a hashmap whose key is combination of project name and flow name, value is its associated lock. Compared to the implementation complexity of this approach, I think tricky aspects of using string intern is acceptable. Plus this is temporary fix, since when we scale out to multiple web servers, we will keep the lock in the database.. +1. Will submit another PR for refactoring since there're multiple code pieces like this in this class. Just keeping them consistent for now.. The allowed max running time for a flow is usually very long, not sure if it makes sense to use ms. @HappyRay what do you think?. @suvodeep-pyne sorry I am supposed to put it in the commit message, but will do it when merging. So there're two threads: producer thread which puts flow to be executed into the waiting queue, and consumer thread which polls from the queue and dispatch for execution. There' a short gap between consumer polls an flow(runningCandidate in the code) from the waiting queue and dispatching it, during which the flow is neither in waiting queue and running queue. At that time, producer checks the same flow and finds that it's not in any of the queue, assuming it's not running, then puts it in the waiting queue. Then two same flow are going to be dispatched together. The fix is making the runningCandidate as shared variable so that it can be checked by producer as well.. updated. updated. updated. i think it will fix the race condition when  same flow is submitted by API and schedule at the same time.. thanks, updated the comment. checked the code a bit. runner.kill() calls job.cancel() which is implemented by jobtypes and does best effort killing, even if the cancel is not successful, runner.kill() marks the job as killed anyway. Similarly, the flow is marked as killed as long as user issues the kill command on it, but it doesn't guarantee the flow is actually killed.. discussed offline. We should handle these cases appropriately. If runner.kill() fails for some reason, we should handle it catch the failure and continue to kill the rest.. see discussion above.. @mukund-thakur we have flow/job level SLA feature. Maybe that's what you are looking for. Please let me know if that doesn't solve your problems.. updated. we just want to skip waiting for last attempt. will update the description. This requires moving ProcessJob and all its dependent class to executor package. I think it won't be that complicated since we can just move the files but keep the package name unchanged. But it's definitely a big change which should be in another commit. . updated. good idea, updated. How does createDataSource().getConnection() work internaly? Will it establish a new connection or just fetch one from existing connection pool? If establishing a new connection, will it be an issue when db fails, every thread which are querying the DB will try to establish a new connection? . yup, but will create another PR refactoring all of them.. updated. updated. updated. and we don't need such high retry limit if we use exponential backoff.. don't we need to remove the project version from installedVersions?. we can add chunk here as well.. Should we need to close the FileInputStream being constructed here?. should we make the constructor private since this class seems to be implemented as singleton. what is uploader here? why it's uploader a string?. shouldSkip here is never used after setting by this piece code. So I just removed it.. it's moved to ExecutionMonitorManager.java#addMonitor which is in executor.. I see. thanks. IMO this should be a fixed value, making it configurable exposes the complexity to user.. i don't think we are on the same page. Let's discuss offline.. We will deprecate old trigger when we have distributed scheduler ready. . why? what if we want to access those methods outside of azkaban-common?. should alerters be final as well?. also MBeanServer mbeanServer and triggerPlugins. why is getter not implemented? should we throw NotImplementedException or not UnsupportedOperationException  here?. i would prefer doing null check inside the method. thanks for reformatting this. maybe we will need to rely on intellij plugin to do this.. yes, it's on my plate.. I think validation of the argument inside the method is a better practice.. Can we make the name more explicit? It seems too general to me. . private or public? seems it's not being used from outside. catch throwable or exception? just curious about the difference. what is the problem of just storage.get(projectId, version) ?. Long or long?. should it swallow the exception or throw the exception. IMO throwing exception seems more reasonable.. is this necessary to create an interface here?.  i think it's better to put requireNonNull(queryRunner.getDataSource(), \"data source must not be null.\") before this.queryRunner = queryRunner.. it would be good to log something like db, table name... same here. log db/table name/query. same here. same here. upper case for this variable as well. maybe consider including ex as well? like what you did in previous methods. maybe consider including ex as well? like what you did in previous methods\n. maybe consider including ex as well? like what you did in previous methods\n. log instead of print. i don't think the exception here should be sql exception. maybe simpler:\nJSONUtils.parseJSONFromString(encType == EncodingType.GZIP ? GZIPUtils.unGzipString(data, \"UTF-8\") : new String(data, \"UTF-8\"));\n. or should we make this piece of code as util function? . are we migrating from slf4j to log4j? . do we have to checkTGTAndReloginFromKeytab before every operation? why?. multiple extra space here. nit: we should follow consistent order of printing targetPath, metadata in log.. updated. updated. updated. i think we can have those strings as constant variable in this class and use string.format . looks \"has encountered a failure on\" and \"has failed on\" are telling the same thing, but having inconsistent expression might cause friction for user to search those emails in their inbox. \nshould we have the same string template as a member variable for them?. why split into two lines?. lots of places in this code uses this pattern. created an independent refactor request to track.. triggermanager is better to serve the current purpose. But intention is to move all flow-related monitoring functionality here. I will call it trigger manager for now.. logger.error(\"Update execution failed. Ignored. \"\uff0c e);. since submituser is a required parameter.. yep, it's added in https://github.com/azkaban/azkaban/pull/1081. updated\n. updated. already updated in the other PR. updated. updated\n\n. discussed offline, i removed that private constructor and made fields without associated setters final.. final/static and upper case. maybe consider using duration ?. this piece of code is duplicate all over the place, can we make it a util? e.x it's also used in https://github.com/azkaban/azkaban/pull/1079. upper case. also using duration might be helpful. i think we should return an empty list instead of null here.. why not ofMins(10) ?. when a flow starts, add it's associated sla trigger to the trigger manager. i'm following legacy convention here for being consistent. I think action implementation needs to be refactor and type should be enum. but it will requires changes on multiple classes and would be too big to fit into this PR.. updated. updated. updated. agree, submitted an issue request for tracking https://github.com/azkaban/azkaban/issues/1098. udpated. right, open up a issue request https://github.com/azkaban/azkaban/issues/1099 for tracking, this should be another PR.. updated. removed isExpired from the class.. not necessary. All SLA checker tasks should be stopped when shutting down executor. . updated. can you suggest how?. updated. updated. updated. updated. consider this as a refactor of https://github.com/azkaban/azkaban/issues/1099. consider it as part of refactoring https://github.com/azkaban/azkaban/issues/1098. updated. +1. what does this method check?. why not remove it now?. space . when will the trigger be expired if you change it to pause?. ?. sorry, this is my mistake, comment needs to be fixed.. can we just remove this method?. break here?. what's your rationale to pick up this date?. space. break here?. space?. the name EndTimeChecker_1 is not self explanatory, can we give a better name?. this for loop looks similar to the one above. can we simplify them?. is this comment necessary?. using string containing to tell if it's endtimechecker is tricky. can we have a better way to handle this?\n. why pausing instead of expire?. is that possible we only use one constructor? EventData(ExecutableNode node)  ?. I slightly prefer making status volatile. . updated. license missing, actually it can be set up in intellij to auto filling license when creating a new file. I share it in README.. Thanks for catching this issue!\nCan we also refactor this method a bit?\ne.x: final ExecutorManagerException e instead of e1\nand log the exception message when catch the exception. . my bad, i intended to say \"i will share it in README\". maybe consider: \npublic static final long NON_EXPIRE_EPOCH_TIME =  Long.MAX_VALUE;\n. should we consider add deprecated annotation here?. also can we remove setUpdateTime if it's no longer used?. why not use ex.status in (running,....)? should be more straightforward.. same here . what do you think of using ImmutableMap https://google.github.io/guava/releases/21.0/api/docs/com/google/common/collect/ImmutableMap.html?\n. this is nice! thanks!. again i think just making ignoreCancel volatile or atomicboolean is sufficient, what do you think?. did you enable save plugin to auto reformat code? it should auto add new space before/after + here.. ok, i see. yeah you are right, let's keep it for now to be consistent and refactor it in a later commit.. isEqualToNormalizingWhitespace requires a base normalized string as argument. but here we don't have such string.. sorry,  assertThat(\"a  b\").isEqualToNormalizingWhitespace(\"a b\") works, but i'm not sure assertThat(read(\"successEmail.html\")).isEqualToNormalizingWhitespace(this.message.getBody()) fails. one line might be simpler:\nreturn numValMap.containsKey(x) ? numValMap.get(x) : READY;. maybe consider putting all of the three conditions into a method called notReadyToRun() ?. thanks for fixing this as well :). maybe change the comment accordingly. i'm curious why the performance gain is not so significant from 1 to 12 forks.\nalso maybe considering number of processor here could be more flexible:\ne.x:\nmaxParallelForks = Runtime.runtime.availableProcessors * 4\n. why do we need this? can we just remove this line?. i see, thanks. maybe put it in finally block?. yes. previously code was not formatted properly.. nope. is this change related with killing status or it's just a low hanging fruit of bug fix?. so this is interval between each updaterFunction? can you help me understand better why it's 30 secs? also comment says 20s. that's my mistake, updated in https://github.com/azkaban/azkaban/pull/1250. why Boolean not boolean?. i would prefer having allowedPostRequest inside logRequest so that we don't need add a boolean argument to logRequest.. we can use req.getParameter instead of searching for string to do this.. also this can be simplified in one line like:\nreturn condA && condB && condC;. req.getQueryString() != null is not necessary since same check is already done in allowedPostRequest. would you mind adding more description in comment on why req.getQueryString().contains(\"password\") is needed?. @reallocf i don't think it's necessary. It would make getProgress() return 0 instead 1 as expected when process finishes.. this is basically to simulate the scenario where job preparation is stuck. 200ms/1000ms is too short for this purpose but i think 3secs is a reasonable number. let me change it to 3secs. . updated. @suvodeep-pyne thanks for your input. I think we can simplify the life cycle further by having only 2 status: RUNNING, NOT_RUNNING and just let jobrunner to take care of other status like killed/complete/failed. . what do you mean?. progressGraph will be called repeatedly so it shouldn't be an issue.. order is already optimized by https://github.com/dubreuia/intellij-plugin-save-actions. We found it very helpful. Maybe have a try and adopt it in your team if you feel the same way.. why not deleting inside shutdown hook?. @HappyRay it's simpler, you can compare the old commit with the latest one with suggested change.. it's already deleted. why not removing it?. is the log correct, for useSsl case, should the port be sslPortNumber?. should we also add log here as in the IF block?. is the method parameter necessary? it's reading from this.props just like other properties being set in the method, right?. same question as below. maybe use WebServerStatus to be more specific?. i see, thanks. good point, PR: https://github.com/azkaban/azkaban/pull/1326. does this have to be abstract class given no abstract method is present here?. thanks. those change are done by save plugin.. not part of this PR, but I think FlowRunnerTestBase.java needs to be documented better and it's missing license.. i'm wondering why was old code doing this check. why does Connection getConnection()  has to be synchronized? Generally I think we should keep synchronize scope smaller especially getConnection will be potentially hanging for a long period, and given createDataSource().getConnection() is already synchronized, should we not mark this method synchronized?. consider https://google.github.io/guava/releases/19.0/api/docs/com/google/common/util/concurrent/Uninterruptibles.html#sleepUninterruptibly(long, java.util.concurrent.TimeUnit) ? . 1 minute. for last retry should we skip the hanging to save some time?. if it runs out of retries due to db is read-only, who is responsible for closing the connection?. also seems impl. of this method will catch all possible SQLException, when would this method throw SQLException? . if it keeps reconnecting for too long, how should we get alerted?. should it be (retryAttempt+1) to match with No.Attempt?. No need to reinvent the wheel. It's a bit nit. But if log shows No.attempt = 1, i think generally people will assume it's first attempt..  I think it would be better to fix it now than later because connection leak is hard to find out later.. why does it has to be interruptable? maybe we can talk offline.. createDataSource() is implemented in this PR as synchronized right? getConnection() i might miss it, but we can synchronize on createDataSource().getConnection() only. My point is synchronization on a method is enforcing an object-level lock, in case when getConnection() is hanging, all other synchronized methods(currently there is none, but we might have them in the future ) will be blocked as well. \nWhen multiple threads are trying to getConnection during DB failover, only one thread keep retrying. It made log very clear.\n\nyou can always grep the log with thread id, right?. retryAttempt <= AzDBUtil.MAX_DB_RETRY_COUNT. should AzkabanFlow be initialized from constructor? . same as above. same as above. better to warn here if it hits else block. why do we need sort here?. can you elaborate why this is needed? thanks!. hah, got it, thanks.. extra space, do you use save plugin?. why not this.suffix.length() <= length && this.prefix.length() <= length. if one table creation throws an exception, should the rest fail or proceed? I think it's better to proceed, right?. i don't think tables as member variable is necessary. . Do you think this is better so that we remove the tables from member variables?\nSet tables = collectAllTables();\ncreateTables(tables);\n. it hasn't been implemented yet. will add the unit test when ready.. Personally I'm in favor of addDependency(final Dependency dep) than passing a list because there's no need to create a list outside the constructor. But it's not something big deal, if you feel setDependencies(final List dependencies)  is more convenient for you when parsing the yaml, then feel free to go ahead and change it. . nope, since props is backed by hashmap which is a deterministic data structure.. it depends on where to put those classes. Previously I thought they should be in a package called trigger or something. but now if it needs to be in the same package as AzkabanFlow, then i will update the name.. i think you are right.  name and type will be simpler.. My thinking is to use fewer class member variables for simplicity. Given props already serves the purpose of holding properties, i don't think we need special class member variables for name and type for now.. updated. to put it in the same package as AzkabanFlow. but today it's handled by different code path. I envision we will onboard trigger before configurable schedule. If we are in that mid state, it doesn't make much sense of having a trigger without dependency.. you mean validate inside build()? What's the benefit?. new Props(this.props.getParent(), this.props) ?. isNotEmpty to be safer?. consider importing org.apache.commons.lang.StringUtils ?. maybe return flowName+\".\"+jobName if job name exists to be more clear?. please document these methods. i would prefer a more meaningful exception type, maybe like illegalargumentexception?. should cleanup be in finally block?. if you want them to be truly immutable, maybe consider this.flows =  Collections.unmodifiableMap(flows), same for jobPropsMap and propsList. why null?. Previously based on the name of the method, i thought isNotBlank simply checks the string is empty. But actually it has more checks than isNotEmpty. . updated. updated. updated. updated. updated. updated. i don't see style guide mention this. Any issue with the summary?. >Consider adding a common utility method to check for duplicates in a list.\nI can't find a standard library to do so with a quick google search.\n\nHave you considered overriding the FlowTriggerDependency's equals method and hashCode method so that you may use a generic duplicate checking method?\n\nThen we need to add one extra class to hold type and props, and this class is specifically for this purpose. I think the overhead outweighs the benefit. I just wrapped this piece into a separate method.. it's in grey area. I think either way is fine.. I think it's better to let the schedule class be consistent with the definition of schedule config in the yaml file. . updated. updated. updated. updated. updated. warn seems too relaxing for this kind of exception. maybe error?. why job1?. space before null. access modifiers?. It is still not clear to me the purpose of the method with the description.. then can we make job1 a constant? it seems it has multiple occurrences.. the comment is unnecessary.. should we start the scheduler in constructor or prepareAndStartServer()?. to separate preparation work from constructor. . when do we validate the config file?. should flowVersion 1.0 also fall into this case?. I don't see there will be multiple implementations for DependencyInstanceConfig.. I still haven't thought about the implementation detail yet. Will create an interface once I see a need.. I don't see there will be multiple implementations for it.\n. The change itself makes sense, but my concern is it's not backward compatible.. updated. updated. updated. updated. updated. why should we install here? this seems irrelevant to this method's intention.. updated. it will return null.. it's used to identify a dependency instance. Just like flow execution id.. maybe a more specific name?. this seems to be a property key name, so should it be a inside configurationkey.java?. why not just double instead of Double class?. just call FLOW_NODE_TYPE?. i think it's slightly better to add one more argument in AzkabanFlow constructor called type, and let builder handle the default parameter passing. . \"Uploading flow\"  + archive.getName + \" to db\". are we uploading flow or project here?. since builder is externally visible It would be more flexible if we want to pass the type from outside in the future. . should the naming convention be dot-separated?. consider ArrayUtils.isNotEmpty ?. who is responsible for closing the input stream?. should we have a default version if no version is specified?. isn't AZKABAN_FLOW_VERSION_2_0 more explicit?. might be better to put projectDir in the exception message to be more explicit.. might call it parsedProjectProperties or something, fitting purpose of this variable more?. based on https://docs.oracle.com/javase/7/docs/api/java/io/File.html#listFiles(java.io.FileFilter)\nreturning null means the input dir is not a dir or IO error happens, in this case should we still fall back to DirectoryFlowLoader ? . test dir without any yaml files?\n. List ? . why not while(rs.next()) {\n},\nthen we don't need to have the !rs.next() check in the first place.. MAX_FLOW_FILE_SIZE_IN_BYTES?. is 128 our convention?. nit: truncate should be faster than delete\nhttps://stackoverflow.com/questions/20559893/comparison-of-truncate-vs-delete-in-mysql-sqlserver. as discussed, maybe we should persist the name of the uploader as well.. one line?\nfor (final File file : projectDir.listFiles(new SuffixFilter(Constants.FLOW_FILE_SUFFIX))). flowName is not necessary as an additional method argument since it can be obtained from azkabanFlow.. should we set path instead of name as source?. one line:\naddAllFlowProperties(ImmutableList.of(new FlowProps(props)));. path or name?. flowNode? . What do you think of passing nodeBean inside instead of the original file? Otherwise, If one day we want to implement getFlowTriggerFromYamlFile, it will need to parse the yaml file again.. > Will getFlowTrigger be called together with getProps?\nNo\n\nAlso I think parsing the yaml file to NodeBean is straightforward and shouldn't be costly\n\nProbably, but the cost to optimize is trivial, so why not. lowercase credentials\n. grammer. thanks. renamed to VelocityUtil. why map?. int would be enough. can we handle the case of no triggerDependencies?\n. have you considered  keeping flowVersion in the flowObject?. it will throw index out of bound exception when data is empty when corresponding file is not found.. if getUploadedFlowFile of same flow file is being called concurrently, will the same file become an intertwine of multiple threads' result?\n  File.createTempFile() might be worth taking a look.\n. BTW, you can also do file.deleteOnExit(). . what do you think of the argument order like this (projectId, projectVersion, flowName, flowVersion)? since It's good to keep the consistency of argument order(id, version, id, version).. same here about the argument order.. flowName might be confusing since (flowName+\".flow\") is what it really means. Outside user without the context will pass a flowId or flowName based on the argument name but it will return nothing. Might be calling it flowFileName, and mention in the method doc that it has to have a suffix of  \".flow\" .. it's azkaban utils? I'm inclined towards using public OSS/JDK libs providing the method of the same purpose. They are more trustworthy and well tested.. would be good to add some comments explaining the motivation of creating a temp dir.. code piece duplicating as above. would be good to wrap the exception handling logic into a method.. when will the temp dir get deleted? It's not a good idea to just delete on exit since linux has hard limit on the number of dir/file contained in a dir.. we also need to cover case where temp dir fails to be created for any reason. In this case might just throw an IOexception?. can yaml parser handle empty file?. why is tempDir an argument for this method?. more clear logging: \"Sending email messages failed, attempt: \" + (attempt+1) . should we have a sleep interval between each retry?. auto formatted.. it's fine since there're in different class and different argument. In addition, I couldn't think of a better name than sendEmail :). we can still grep \"Sent email message\" from the log to debug.  . added logging message in sendSlaAlertEmail. any way to retrieve azkabanFlowVersion from Project object?. what's the default value for azkabanFlowVersion?. is AzkabanFlow only for flow 2.0? If so can we add the description for that to Java doc of AzkabanFlow?. if the method name is getPropertiesFromFlowFile , then argument should be a flow file.. passing the flow object is unnecessary, we only need project id, project version , flow id, flow version, source? Method can be more reusable if the arguments are limited to what is necessary inside the method.. Will the method be called by multiple threads? if so is it thread safe?. consider to put the check in the util class like FlowUtils? i guess it will be used in multiple cases? but not every one will remember to use Double.compare to compare two doubles. At least for me it's not occasionally to just use \"==\"  :). same as above, put the check in a util method. same here, we don't need the whole flow object.. same as above. what is \".jor\" ? can we make it as a constant variable a meaningful name?. if block and else block are exactly the same. Should it be uploadProjectProperty(project, oldProps)?. BTW, you can use \"? : \" to reduce the if else block to one liner.. shouldn't the default value be a valid version?\n. updated. can we add a unit test?. my personal feeling is it's slightly more convenient since no string concatenation needs to be done. I replaced a few of them to new API to get the taste of it but not all since there are too much existing usage of old API... would be great to log the temp dir full path as well.. might just call it cleanupdir since the method can be applied to any kind of  dir deletion.. when are the overrode properties becoming effective? Next execution of the flow or immediately?. can we make this configurable?. 30 in log message should be replace by AZKABAN_MAX_NUM_CONCURRENT_FLOW.. is 30 too high?. can we use something like getCurrentYear instead of hard coded year?. make 30 a variable. if a negative number or 0 is set, should we throw exception?. should it be AZKABAN_MAX_CONCURRENT_RUNS_ONEFLOW instead of the hard coded string?. should we change log4j to slf4j?. It's more like low hanging fruit given you are modifying this piece already. I can't think of any risk involved considering the usage of the logger in ExecutorServlet.. should we make level debug? Also just FYI, with debug level, we can add more detailed logging for better debuggability without concerning overwhelming logging message \n. thanks, updated.. thanks, updated.. actually i found this class is no longer used. so just removed the whole class :). same as above. it's required by the API. Though I think the API can be improved, but the temp dir is used to store the downloaded file and it's caller's responsibility to delete the dir. cc @jamiesjc . just want to verify when dependency instance becomes succeed, its execution status is persisted.. that's good idea i will add it to todo.. udpated. thanks, fixed.. yes, since props is a hashmap which is order agnostic.. sorry, i took it back, hashmap's printing order is not guaranteed, https://stackoverflow.com/questions/18778410/why-does-tostring-function-of-a-hashmap-prints-itself-with-a-different-order. thanks, updated. put 1 in constants, 2 is just the number of keys to be held, which is not a meaningful number, so i prefer to make it just a hard coded value here.. added validation for that.. updated. updated. updated. auto formatted by intellij plugin. good point, thanks. updated. added testcompile. It's just for testing without any specific purpose. . not sure what you mean here by stateless. let's discuss more in person.. she as the gender-neutral pronoun. since it will fail the azkaban web server startup if DEPENDENCY_PLUGIN_DIR is not specified in the config file. But once the corresponding DEPENDENCY_PLUGIN_DIR is created on az machines and specified in the config file, i will add null check here. . then how would quartz scheduler handle this case? E.x, how does quartz know which schedule is served by which web server? We can follow the same way.. sure, can i put it in todo?. added it to TODO.. will update, thanks. good catch. nope. why do we need to check it in constructor?. discussed offline. We are now at the stage where  quartz scheduler which is not fully productionalized and flow trigger co exists and flow trigger has to depend on quartz. Our conclusion is to use just one flag to enable/disable both quartz and flow trigger service as for now since quartz serves flow trigger only for simplicity.. it's needs to persisted by quartz.. this job will be scheduled when project is uploaded and run based on cron schedule.. schedule all flows with flow trigger. will do thanks.. - Do we remove normal schedule today when removing a project\n  Yes.. this part is to disallow manual scheduling flows with flow trigger. we can do it in next PR.. we can do it in next PR.. - should this move to the removeProject try catch block?\nLet me consolidate unschedule code together. good point, i will add check here to skip embedded flow. thanks for the suggestion.  I considered it initially, but the status is very unlikely to be changed so i would rather to keep the sql as a constant string.. updated. a flow with flow trigger defined is not allowed be scheduled from UI/API since schedule is part of config file if that's the case. . exec Id is the terminology i used initially to identify an execution of a flow trigger,  but was later changed to trigger instance id. updated the log.. updated to make it more readable.. currently no, but will add it in future.. removed. updated. updated. yeah, good catch. what do you think of reading quartz only properties with azProps.get() vs dumping every properties?\nalso i don't think we should specify mysql username/password twice in private property file. How about reading mysql username/password from azProps and convert them into quartz properties?\n. super.containsKey(key.toLowerCase())  ? given ConcurrentHashMap already provides containsKey. +1 \n- Favor composition over inheritance.\nhttps://github.com/azkaban/azkaban/blob/master/CONTRIBUTING.md. good catch. thanks for reporting. I agree it's slow. But the purpose of this test is to verify the use case where hard linking a very long dir won't cause issue which happened before in our production. The old code was using linux shell command to do the hard link which will generate excessively long command exceeding the argument limit size. . @HappyRay @juhoautio 's suggestion makes sense to me.. it's for UI display.. that's good question, actually it will only support dir/*.\nSince user shouldn't upload the jars they don't want to import\nthe reason for supporting dir/* only is to provide another packaging option which let user upload a dir of all required jars instead of one fat jar.. thanks, updated.. yeah, i think this class is too big to treated as inner class, move it out. Thanks. thanks, added the comment. this was autoformatted by save plugin. copyright.  the class's name seems suggesting it's used to create an EmailMessage, it seems to me createSender is the functionality independent of the class.. can we use assertj since it's our preferred assertion library?\nsee contributor guide:\nUse AssertJ as the assertion library in unit tests.\n. can you help me understand better of the purpose of this method? why do we need to wrap a method around JavaxMailSender(props)? . add todo. duplicate?. is /./ necessary?. updated. updated. updated. the unit tests covered the illegal case. Time length is trivial since it's just regular expression matching cost for a string.. agree, will do it in another PR.. add it as todo.. updated.. why for which part?. good point.. thanks, added.. my intellij's setting might mess up. Updated.. thanks, updated. thanks, updated. thanks, updated. readResouceFile to be more descriptive?. Thanks for sharing your thoughts. but it would be best to rename and letting intellij's refactor to do renaming is pretty much effortless. . thanks. LGTM. @HappyRay WDYT?. thanks, updated. thanks, updated. updated. why do you prefer adding nodes after Dag is constructed over passing node list to the constructor so that A dag is a complete graph with nodes when initialized?. should we have two separated status enum for dag and node each?. any example of node in blocked status?. why is public test method name separated by _? should we follow a consistent standard and document in the contributor guide?. system out?  actually there're multiple occurrences of system out in the PR.. updated. updated, thanks. updated, thanks. update copy right. copyright. thanks, this is intentional left for separation. . since immutable data structure is always thread safe.. yes, so the class contains multiple pieces iterating over activeExecutor, and code piece populating activeExecutors from database. activeExecutors should be immune to race condition when iterating and populating activeExecutors are in different thread context.. this just removes synchronized (this.activeExecutors). should we do existence check before builders.add(builder)?. Since it's an util class, why not make gracefulShutdown static? What's the advantage of making this class injectable?. it's a reasonable number.. Active projects are the one containing currently running flows. . sizeOfDirectory is not precise to get the read disk usage. E.g directory itself has disk usage but it doesn't count in sizeOfDirectory.. updated. updated in comment. yes, but this the frequency of doing it is once/30 mins. \nWhat do you mean by batch cleaning?. auto format change. it will only return new object only when projectId, version don't present in the hash map.\nfinal ProjectVersion projectVersion;\n    synchronized (this.installedProjects) {\n      projectVersion = this.installedProjects\n          .computeIfAbsent(new Pair<>(flow.getProjectId(), flow.getVersion()),\n              k -> new ProjectVersion(flow.getProjectId(), flow.getVersion()));\n    }\n    return projectVersion;. reduce it to 2 hours.\nSee my change description:\n- This PR also changes execution dir retention from 1 day to 2 hours. Since execution dir is hard linked to project dir, so disk space will be released only when no reference to project dir exists. That's why we want to shorten the execution dir retention time so that disk pressure can be alleviated sooner.\n. Some mocking lib allows mocking a static method.\nhttps://stackoverflow.com/questions/21105403/mocking-static-methods-with-mockito\n. Discussed offline, static method needs a non-standard way of injecting and test. With dependency injection, we can declare an util class as singleton, which serves the same as an util class containing only static methods.. high accuracy doesn't hurt, also FileUtils.sizeOfDirectory doesn't really indicate the real disk usage of the directory as size of a file is not equivalent of its associated disk cost. https://superuser.com/questions/94217/why-ls-and-du-show-different-size\n. Existing code doesn't handle synchronization.. it's auto formatted by save plugin.. updated  in https://github.com/azkaban/azkaban/pull/1812. updated in https://github.com/azkaban/azkaban/pull/1812. updated in #1812. updated in #1812. updated in #1812. updated in #1812. updated in #1812. thanks.. updated, thanks. FileUtils.sizeOfDirectory is a lot slower than running du -sh based on my experiment of reading 10000+ project dir. Plus, result shows size obtained by FileUtils.sizeOfDirectory is slightly different from du -sh (1% to 10% difference). The difference might come from the way  filesystem stores the file. But regardless, project cache size by definition is the max disk usage of project dir, so the disk estimation should align with this definition. . how about queueProcessor thread?. it's a good point. Actually it could happen when HDFS as project zip storage layer is down but mysql is up. Schedule is not the only thing that worth concerning if this is the case. Maintaining atomicity is complicated enough to fit into another PR. added todo here for record.  . is this an error? should we consider info?. why is this needed?  can you give an example of wrong case which might be caused by original sql . added. thanks.. good point, updated. thanks. removed. updated, thanks. updated, thanks. according to the doc of this class, Constants used in configuration files or shared among classes the variable it could keep doesn't necessarily need to be a user-facing API.\nEven if the variable is defined in the class where it's used, associated test class  still needs to access it. . updated. updated, thanks.. yeah, let's use warn.. this is automatically done by save plugin.. updated, thanks. . please create a module designated for trigger dependency plugin. And move your code to a subpackage inside that module.. do we need this?. do we need this?. what is this? we shouldn't expose a specific dir here.. why do we need this?. please verify the gradle script can build a fat jar successfully.. do we need this? KEY_STORE_FILE, KEY_STORE_PASSWORD, TRUST_STORE_FILE, TRUST_STORE_PASSWORD. do we need this? also please add comments in each key.. do we need this?. is this for test purpose only? If so, please move to test folder.. please add javadoc.. please delete this class if not used.. please add java doc.. private?. please mark all internal method as private unless they have to be exposed for testing purpose.. how about initializing executorService when declaring it and removing the default constructor?. why does this method need to return a boolean?. please avoid using Sets.newHashSet(https://google.github.io/guava/releases/19.0/api/docs/com/google/common/collect/Sets.html  Note for Java 7 and later: this method is now unnecessary and should be treated as deprecated. Instead, use the HashSet constructor directly, taking advantage of the new \"diamond\" syntax.) and use new HashSet instead. remove the extra line. remove the extra line. remove the extra line. do we need this?. the method naming shouldn't start with has unless it returns a boolean.. please remove all commented code.. it would be best to visualize the internal structure in comment.. please remove the debugging code. . please remove the debugging code. . why do we need this check?. should we use  kafka consumer of official version?. is the logging message necessary?. we should specify an unique group id, please refer to Dali dependency impl..  lower case. what is this class for?. what is this class for?. please add comment for better readability on this part.. first letter lower case.. please move this class and KafkaProducerTest to another package and document the purpose. . please separate this part into a method and write unit test for it.. please use sl4j. Please convert rule's type from string to pattern for stronger type.. do we need to declare a default constructor?. call it RecordMatcher to be more relevant? Also we need to make it explicit that this is for other developers to implement their own schema matching in java doc.. consider adding @VisibleForTesting ?. Thanks for sharing your thought. \nNo we don't have any build tool respecting the annotation, \nThe @VisibleForTesting annotation advertises to other developers (or reminds the code's author) when a decision was made for relaxed visibility to make testing possible or easier\nhttps://dzone.com/articles/two-generally-useful-guava\nThis annotation is for reminder purpose only, just like a line of comment, and the only reason here to relax the access level is for testing purpose, so I would imagine that the annotation would be helpful for other people who read this piece of code to understand why the inner class is not private, which worths explanation. I agree there's a maintenance cost as you said, but there's no other simpler alternative than it to let other developers know why we made such decision.\n. please comment the reason of leaving it blank here.. should it be testCompile as well?. should it be testCompile as well?\n. the format is better to be consistent \"group: name:version\". please remove debugging code.. does remove need to return a boolean?. grammer. please change group id to make sure each kafkaclient has different group id.. space?. change it to Pattern to have stronger-type check?. copyright and javadoc?. please remove the commented code.. please put the check inside add to avoid race condition in check and act.. please add synchronized to avoid stale read.. please add javadoc to those public methods.. please return empty set instead of null to avoid null pointer check on the caller side.. please return empty set instead of null to avoid null pointer check on the caller side.. please add synchronized to avoid stale read.. please import org.slf4j.Logger. please remove debugging code/comment.. please use import. is subscribedTopics  needed? can we just use depInstances?. add @visibleForTesting. please document the purpose of the class.. thanks, mentioned it in PR.. key stored in localStorage never expires until explicitly cleaning it. SessionStorage will last as long as the browser tab persists.. updated, i think removeItem would be better to avoid conflict of same key.. i see your point. After thinking, localstorage could be a better option in some sense.. please remove these internal resources as this document is mostly for providing know-hows and instructions on the feature for OSS users. . first letter uppercase. database. why optional. can be or have to be?. duplicate trigger.schedule?. the schedule to perform availability check?. Kafka Event based trigger. Azkaban supports launching flows via scheduling it or Ajax API.. triggering a flow on event arrival -> triggering a flow on kafka event arrival.  This concept enables users to define events that the flow depends on. Once all of the events become ready, a workflow will be triggered. \n. CHECK?. thanks. updated.. is this private or public? CONDITION_VARIABLE_REPLACEMENT_PATTERN is public. isValidVariableSubstitution as it returns a boolean?. _urlContents is the response from this._url, so it's a fixed set of value. . thanks, updated. updated.. @li-ygerchikov thanks and updated. Discussed with @HappyRay offline , the code is over complicated to reason around, but one side benefit of being synchronized i can think of is to prevent other threads hitting the job history server/metastore when the server is down or busy, which otherwise would make server even busier. Although it might not be the original motivation of being synchronized here.. FAILED TOO MANY TIMES or no more executors?. tried XX attempts instead of executors?. can we use for loop here? my concern for while(true) is it's exposed to the risk of infinite loop if some exit condition is not well defined somehow. . thanks.. thanks. i feel making this parameter as configurable exposes complexity to azkaban users. Can you think any situation where the parameter needs to be changed?. should this case count as dispatch failure?. i mean since the flow will still be dispatched in this case, still marking this as dispatch fail is a bit confusing. IMO we should distinguish retriable & non-retriable failure, and only mark dispatch failure for non-retriable cases. what do you think?. updated, thanks. do you have some examples of such setups?. Someone might set up alert on dispatching failure, like us. So we want to make sure alert indicates real dispatching failures. . they can be customized for unit tests default value (1 sec) would also work fine for unit test, isn't it? . updated, thanks. thanks, i don't have very strong opinion, so up to your preference.\nOne thing I want to add is we should add time unit in property name to avoid confusion.  . why do we need test parallel scenario?. is throws Exception necessary?. It might allow the shutdown api to return before invoking system.exit(), it's just speculation since the original author has left. . Consider string.format?. thanks for the refactor!. it's not just fetching override properties here, right? . yes.. please use slf4j. updated thanks. is millisecond over fine-grained?. consider Duration?. technically we won't need executor table any more with change. Are you considering eliminating this dependency?. nit: submitting. how about ScheduledThreadPoolExecutor ?. sorry for the confusion. My intention is https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ScheduledThreadPoolExecutor.html#schedule(java.lang.Runnable,%20long,%20java.util.concurrent.TimeUnit). it's not a thread anymore,  might give it another name?. poll ?. would this introduce code duplication? . year. why returning a string instead of a list?. same question as above.. should we close the reader at final?. Have you considered separating the alerting part out into another method? method with one single responsibility brings more simplicity and composability. . how about empty list?. ImmutableList?. consider isEmbeddedFlow to be more precise?. should we consider removing this line?. consider Duration instead of String?. Why do we need these?. consider builder pattern here?. shouldn't only one name is needed since SLAType has already indicate it's flow or job level SLA.. do we need this flag as this can be inferred from whether alerting email is empty or not.. consider immutable list to make the class immutable?. consider assertion to guarantee the valid state of the object? e.g  SLAoption should have at least one action(kill or alert). conceptually, SLAoption consists of 2 parts:\n1. Condition(Flow not succeeded in 1 min)\n2. Action to perform when condition is met(kill, email, or both)\nSo another impl.  is to make SLAOptions capture a condition and an action, which more corresponds to the conceptual model. \nI personally favor this one which is easier to reason about, what do you think?. consider this?: https://commons.apache.org/proper/commons-collections/apidocs/org/apache/commons/collections4/CollectionUtils.html#isNotEmpty-java.util.Collection-. nice refactoring. why is this not part of settings?. thanks for doing that. Can this be applied to other properties? If so, can we make this universal?. why not using null to be consistent with default value in db?. cannot default be null?. thanks for doing this.. consider string.format?. thanks for refactoring.. this method is created just for code dedup, i will add some explanation. . thanks, i will update the deletion part from single-threaded to parallel.. i don't have a number yet, but my estimation would be 5-10 secs for a large project(~thousands files), since it takes several seconds for an UMP flow to pass over preparation stage if the cluster is not busy.. good catch, thanks.. updated. runtime exception when mkdirs() ?. it's not possible given only one executor process is accessing this section.. good point, will update.. thanks, updated. updated, thanks. i don't have a number yet, that's why i added logging here to see if it worths further optimization.. added, thanks. do we need to set the default value here?. it's still better to set it explicitly 1. different DBMS might have different rules 2. being consistent with executor_id statement as above 3. easy for reader to know the default value of this column. . will add todo given poor testability of this class.. thanks updated.. https://github.com/azkaban/azkaban/issues/2134. created internally.. updated, thanks. thanks, added. updated. updated. added. updated. added, thanks. should flow-setup-timer be in the ExecMetrics?. explained in class comment.. updated, thanks. variable name swapped  with FLOW_SETUP_TIMER_NAME. any way to avoid sleep here?. we are using assertJ for assertion lib: https://github.com/azkaban/azkaban/blob/master/CONTRIBUTING.md. please fill in the PR id.. consider enum type? Then priority would be limited instead of any integer.\n. nit: *implements. is there any chance that priority-based dispatching cause starvation? Should we also take waiting time into consideration?. discussed offline, we agree to it's better to have a fixed shorter range for priority and \nenforce flow priority range limitation on application side. . if not specified, then cache clean up won't be enabled.. yes, i agree it would be best to have project id/version as the locking key and move the clean up to another thread.  Let me think about how to address this problem.. given the feature has been documented(https://github.com/azkaban/azkaban/issues/2095), I guess no one outside is using it. But it exposes the problem with our OSS release process - which version should we claim as production ready. Maybe we need to internally exercise the release first and then claim it to be stable version. . thanks!. ",
    "artem-garmash": "@HappyRay. we are definitely interesting to merge this in. I will try to fix it this week.. @HappyRay, the PR is up-to-date now.. @kunkun-tang, the PR has been rebased and doesn't have any conflicts.. ",
    "neilyooloil": "yes , i set the host port, active =1 at db .\nand I set this in azkaban.properties\nazkaban.use.multiple.executors=true\nazkaban.executorselector.filters=StaticRemainingFlowSize,MinimumFreeMemory,CpuStatus\nazkaban.executorselector.comparator.NumberOfAssignedFlowComparator=1\nazkaban.executorselector.comparator.Memory=1\nazkaban.executorselector.comparator.LastDispatched=1\nazkaban.executorselector.comparator.CpuUsage=1\n I thought I just need set the db and the properties .  But how l can invoke it? \nthank u!\n. thank u so much!  nice to meet u!\n. The webserver logs shows:\n INFO [ExecutorManager] [Azkaban] Successfully refreshed executor: 192.168.56.201:12321 (id: 3) with executor info : {\n  \"remainingMemoryPercent\" : 84.9490145958216,\n  \"remainingMemoryInMB\" : 846,\n  \"remainingFlowCapacity\" : 30,\n  \"numberOfAssignedFlows\" : 0,\n  \"lastDispatchedTime\" : 0,\n  \"cpuUsage\" : 0.0\n}\nINFO [ExecutorManager] [Azkaban] Successfully refreshed executor: 192.168.56.202:12321 (id: 4) with executor info : {\n  \"remainingMemoryPercent\" : 85.03095192356697,\n  \"remainingMemoryInMB\" : 847,\n  \"remainingFlowCapacity\" : 30,\n  \"numberOfAssignedFlows\" : 0,\n  \"lastDispatchedTime\" : 0,\n  \"cpuUsage\" : 0.0\n}\n INFO [ExecutorManager] [Azkaban] Using dispatcher for execution id :11\n INFO [ExecutorManager] [Azkaban] Reached handleNoExecutorSelectedCase stage for exec 11 with error count 0\nINFO [ExecutorManager] [Azkaban] Using dispatcher for execution id :11\n INFO [ExecutorManager] [Azkaban] Reached handleNoExecutorSelectedCase stage for exec 11 with error count 0\nThe web server have recognized executors.\nBut the jobs's status is still Preparing. It does not run....\nI have  restarted before. \nDid u meet the issue?\n. Thank u!\nI delete the MinimumFreeMemory of filter. The executor server has another exception......\njava.io.IOException: Stream closed\n        at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)\n        at java.io.BufferedInputStream.read(BufferedInputStream.java:325)\n        at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:283)\n        at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:325)\n        at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:177)\n        at java.io.InputStreamReader.read(InputStreamReader.java:184)\n        at java.io.BufferedReader.fill(BufferedReader.java:154)\n        at java.io.BufferedReader.readLine(BufferedReader.java:317)\n        at java.io.BufferedReader.readLine(BufferedReader.java:382)\n        at azkaban.utils.FileIOUtils$NullLogger.run(FileIOUtils.java:178)\nUploading flowId step1\nUploading flowId step1\nDo u know how to fix it .... thanks...\n. I execute the job. And the executor server has the exception....\nERROR [ExecutorServlet] [Azkaban] azkaban.executor.ExecutorManagerException: Running flow 20 not found.\n. I found the exception....\njava.lang.Exception: Cannot request memory (Xms 0 kb, Xmx 0 kb) from system for job step5\n    at azkaban.jobExecutor.ProcessJob.run(ProcessJob.java:86)\n    at azkaban.execapp.JobRunner.runJob(JobRunner.java:590)\n    at azkaban.execapp.JobRunner.run(JobRunner.java:443)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:744)\n19-02-2016 11:36:56 CST step5 ERROR - Cannot request memory (Xms 0 kb, Xmx 0 kb) from system for job step5 cause: null\n19-02-2016 11:36:56 CST step5 INFO - Finishing job step5 attempt: 0 at 1455853016337 with status FAILED\nMaybe the problem is about the memory\n. ",
    "vblvbl": "azkaban requires that you configure the Network Time Protocol (NTP) service on each machine in your cluster\n. How to solve the problem I have the same problem. ",
    "lizhenhuan": "I have that problem too.That is because exec server time is behind web server in mill seconds.\nWhen you click execute button on azkaban web page, web server will callExecutorServer and send an execute action to executor server by restful api. Executor server will start running this job and update execution_flows table to running status.\nThere is an thread in ExecutorManager class named QueueProcessorThread. This thread will check job status by send update request to executor server. Executor server will check the job updateTime from web server and updateTime from executor server. If the web server's updateTime is big than executor server's updateTime. Executor Server will ignore this update request and send no update data back to web server. And then web server will never update this job status from preparing to running.\nI think you can setup  Network Time Protocol (NTP) service on each machine in your cluster as @vblvbl  said or modify FlowRunner.updateFlow() method from \"updateFlow(System.currentTimeMillis())\" to updateFlow(System.currentTimeMillis() + 1000);. If the web server's updateTime is big than executor server's updateTime. Executor Server will ignore this update request and send no update data back to web server. \nThis web server's updateTime is System.currentTimeMills() in web server.\nThis executor server's updateTime is System.currentTimeMills() in executor server.\nIf there is no NTP it may has small time difference and web server is big than executor server, executor server will ignore web server's update request .\nNTP service will keep web server's System.currentTimeMills() equals executor server's System.currentTimeMills(). ",
    "moranrr": "I also encountered this problem, Does anyone know how to solve this problem?. ",
    "ogirardot": "nevermind, you can get the projectId from curl -k -XGET \"http://AZKABAN/manager?ajax=fetchprojectflows&project=MYPROJECT&session.id=SESSIONID\" | jq -r '.[\"projectId\"]'\nmaybe the doc should be updated.\n. ",
    "superwood": "I want update one job of project.  Some times,  add a job to a project  or  del a job from a project .  but I have to upload all of them\n. The right create-all-sql**.sh  in   version release-3.0   is create-all-sql-2.2.sql . \nThe  create-all-sql-3.0.0.sql  is not for release-3.0  . \nSee my issue \n      FETCH_ACTIVE_EXECUTABLE_FLOW is wrong in web-server #621\n     https://github.com/azkaban/azkaban/issues/621\n. Our team implement that thing. \nWe set a  var name \"SchduleTime\" for the scheduled work flow.   \n\nThe flow  which need be rerun  auto get the  \"SchduleTime\"  .  And We just need to click  \"Execute\"  to run again.\n\nJobs can  use the \"SchduleTime\" as env var  like    \ntime=$SchduleTime\necho  date +%Y%m%d -d '-1 day  $time'\n. ",
    "JabbaTheCoder": "I am currently running Azkaban 3.0 in a pre-production environment and I have a cron job that bounces the Azkaban web server once it consumes all the CPU available on the box and slows everything down. There is clearly a bug that causes gradual increase in CPU consumption over time. I enabled the JMX on the Azkaban web server, connected jvisualvm and was found out the following:\nOver time the number of NioProcessor threads grows from 0 to about 10. These threads are constantly consuming CPU eventually consuming all of it and requiring a restart of the Azkaban Web server.\nThe thread dump for these threads looks something like this:\njava.lang.Thread.State: RUNNABLE\n    at sun.nio.ch.IOUtil.drain(Native Method)\n    at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:90)\n    - locked <3e5de8a8> (a java.lang.Object)\n    at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)\n    - locked <1b60bc70> (a sun.nio.ch.Util$2)\n    - locked <3c55e39e> (a java.util.Collections$UnmodifiableSet)\n    - locked <1f30b1fa> (a sun.nio.ch.EPollSelectorImpl)\n    at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)\n    at org.apache.mina.transport.socket.nio.NioProcessor.select(NioProcessor.java:97)\n    at org.apache.mina.core.polling.AbstractPollingIoProcessor$Processor.run(AbstractPollingIoProcessor.java:1074)\n    at org.apache.mina.util.NamePreservingRunnable.run(NamePreservingRunnable.java:64)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nLocked ownable synchronizers:\n    - locked <7945192> (a java.util.concurrent.ThreadPoolExecutor$Worker)\n\"NioProcessor-1\" - Thread t@74\n   java.lang.Thread.State: RUNNABLE\n    at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)\n    at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)\n    at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79)\n    at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)\n    - locked <28189547> (a sun.nio.ch.Util$2)\n    - locked <77adfc> (a java.util.Collections$UnmodifiableSet)\n    - locked <3f0eda24> (a sun.nio.ch.EPollSelectorImpl)\n    at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)\n    at org.apache.mina.transport.socket.nio.NioProcessor.select(NioProcessor.java:97)\n    at org.apache.mina.core.polling.AbstractPollingIoProcessor$Processor.run(AbstractPollingIoProcessor.java:1074)\n    at org.apache.mina.util.NamePreservingRunnable.run(NamePreservingRunnable.java:64)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nLocked ownable synchronizers:\n    - locked <4ca4266d> (a java.util.concurrent.ThreadPoolExecutor$Worker)\n. The issue was caused by a defect in the LDAP plugin, not Azkaban itself. I have fixed the issue with the plugin, contributed it, and it was accepted. We have enough running Azkaban in production since then without any I'll effects. Basically, if you are using LDAP plugin for authentication, make sure to get the latest version and you will be fine.. I think the issue may be related to azkaban-ldap-usermanager plugin that I am using. This plugin uses org.apache.directory which in turn uses org.apache.mina. I will need to dig deeper to understand whether the bug is in the LDAP user manager or in the org.apache.mina library.. It appears that LDAP user manager plugin opens a LDAP connection inside a try block that has no matching finally block. The block is question is NOT a \"try with resources\" block, so even though the LdapConnection is AutoCloseable it doesn't do us  any good in this case. Essentially, every time an exception happens in getUser() or validateUser() methods a LDAP connection is leaked. This probably explains why the machine burns too much CPU running org.apache.mina code that is invoked by LDAP user manager via org.apache.directory.. Yes, I am referring to that project. I am testing a fix, if it works out I will contribute it. Otherwise I'll file a bug. In any event, I agree that this issue belongs in that project. When I filed the bug I didn't realize that the problem was caused by the plugin and not by Azkaban itself. I realized that that was the case after reading the code which took a little bit of time.. The fix seems to be working fine for me. I have not seen spurious high CPU consumption by NioProcessor threads after the fix was applied. I created the issue #8 in azkaban-ldap-plugin project, contributed the code and created a pull request.. I think we can close this issue.. ",
    "georgezhlw": "looks good.\n. looks good.\n. Juho, I think we could add flow status FAILED/KILLED to the error message. And it's not \"seems\", it's \"really\" :)\n. Should be HadoopShell\nSimilar changes are needed at few places following this line.\n. Add default value for these properties.\n. This zip file is wrong. It's a normal \"command\" job, not a \"HadoopShell\" job.\n. ",
    "bmsq": "No worries.\ngetTransformToElement() is not a valid function for an SVG node.  When the JavaScript hits this line, it raises an error and doesn't execute the remainder of the function which prevents auto pan and zoom from working as expected.  \nI was going to guess what the function was expected to do and implement a standards compliant equivalent. However, this function is called and assigned to a local variable which is redundant and never used.  The simple fix is to remove the variable and the broken call to getTransformToElement().\nWe auto generate a large flow containing +400 jobs with more than a 1,000 dependencies, so the search feature with auto pan and zoom is pretty critical for navigating the graph.\n. Um... this pull request has triggered a build failure (specifically on JDK1.8) but the test case which failed doesn't appear to have anything to do with my change: \nazkaban.execapp.event.BlockingStatusTest > testMultipleWatchers FAILED\nI'm more than happy to fix this CI issue but I have no idea how this is related to my change.  Anyone care to comment?\n. @HappyRay I created this pull request after porting Azkaban for use on Windows servers (we use it on multiple client sites). Unfortunately, the existing use of \"ln\" is not portable, hence the need for this PR.\nThis PR, along with several others that I raised at the time, have been sitting here for a year. I'm happy to update this PR to create a hard link in a platform independent way but I won't bother if you don't think anyone will ever review it.. No worries, i just didn't want to expend effort if it wasn't going to be useful. I'll see if I can sort this out over the weekend.. Sorry about the slow response on this, I've been busy at work and home.\nI've rebased with the latest master branch and updated to create hard links using NIO.  Unfortunately, I haven't been able to test this locally as the latest gradle scripts don't work on my windows machine (something about a node-linux dependencies) .  The Travis build suggest that this passes the related unit tests but you might want to verify before merge.\nI don't have time to resolve it now but I will report back about windows compatibility when I've had the time to update the gradle script to be cross platform.  . Ah, I must have done something stupid during the rebase. I'll get this sorted shortly.\nSorry about that. Hi\nevent.wheelDelta is specific to the DOMMouseScroll event that you are using.  This is not a standard browser event.\nSee MDN for details:\nhttps://developer.mozilla.org/en-US/docs/Web/Events/DOMMouseScroll\nThe standards compliant equivalent to this event is wheel.  This event has a slightly different structure which doesn't include event.wheelDelta but event.deltaY provides the same functionality.  \nOnce again, refer to MDN for details:\nhttps://developer.mozilla.org/en-US/docs/Web/Events/wheel\nAs for your question regarding jQuery, the code which registers for scroll events is registering directly with the browser rather than jQuery. A quick Google suggests jQuery doesn't provide any support for mouse wheel events without a 3rd party plugin.\nI hope that helps :)\n. I don't understand why conflicts were being reported, I was able to perform a git pull from upstream without any intervention.  Maybe I just don't understand how github/travis works?\nAnyway, all sorted now.  @HappyRay, over to you.\n. The older version does not work for IE. The change uses standard html mouse wheel events ensuring compatibility across all browsers that support the html standard.\nI work at a number of sites that force users to use IE (why do corporates do this? Especially for supposedly \"security\" reasons). Without this fix, these users can't easily view large flows because they are unable to zoom in.\nDoes azkaban not rely on a small(ish) cache max-age and the ETag validation token? I would have thought letting the client cache expire before picking up the new version would have been fine. \n. Perform out.close() before attempting FileUtils.deleteDirectory to avoid leaked file handle when deleteDirectory throws IOException.\n. ",
    "shadyxu": "search \"Execute-As-User\" on the documentation page.\n. ",
    "tsingker88": "hello, friend. I had the same problem. Now, I know that only the 3.0 version support Multiple Executor Mode, but the corresponding package has not been released. So let us just wait....\nI hope this can be helpful for you, though I cannot help you solve the problem.\n. ",
    "sampan-dong": "try to use tags 3.0.0 \n\"excutors\"  table is needed in mysql\n. ",
    "inoviavenkat": "You should provide the connection details to your ActiveDirectory/LDAP \nand some more mapping details in the file azkaban.properites, by editing the \nproperties below.\nuser.manager.ldap.provider.url=ldap://hostname:port\nuser.manager.ldap.security.principal={0}\nuser.manager.ldap.attribute.group=group\nuser.manager.ldap.groups.mapping.file=conf/groups.xml\nuser.manager.ldap.security.authentication=simple\nuser.manager.ldap.initial.context.factory=com.sun.jndi.ldap.LdapCtxFactory\nuser.manager.class=azkaban.user.LdapUserManager\nWhere\nuser.manager.ldap.provider.url - is the protocol, hostname and port number to your LDAP\nuser.manager.ldap.security.principal - can be {0}, if the complete LDAP DN(Distinguished Name) is used as the login-username on the Azkaban login page. Otherwise, it can be partial LDAP DN that has {0} as its substring at an appropriate position, which will subsequently be substituted by the user-id entered on the Azkaban login page. For instance, 'CN={0},OU=Development,OU=Technology,DC=XYZ,DC=com\", and {0} formatted to hold the user's login-id entered on the login-page\nuser.manager.ldap.attribute.group - is the LDAP attribute identifying all the LDAP group names a user belongs to\nuser.manager.ldap.groups.mapping.file - conf/groups.xml, the azkaban group configuration file, available at the given location in this git-commit\nuser.manager.ldap.security.authentication - simple, in most common configurations\nuser.manager.ldap.initial.context.factory  - com.sun.jndi.ldap.LdapCtxFactory, the default value in most common situations\nuser.manager.class - azkaban.user.LdapUserManager, the class implementing UserManager.java\n@devangorder @davidzchen @hluu @logiclord\n. Yes, what you assumed about the LDAP here is correct; Each user in the LDAP here has attributes named 'memberOf' and the value of this attribute is the DN of a group, the user belongs to.\nAnd my azkaban.properties property looks like\nuser.manager.ldap.attribute.group=memberOf\nBelow is the example LDIF snippet\nou=Sales\n\ncn = Customer1\ncn = Customer2\ncn = Customer3\n\nou=Marketting\n\ncn = SocialMedia\ncn = Promotions\n\nou=Users\n\ncn=person1\n\nmemberOf: cn=Customer1,ou=Sales\nmemberOf: cn=Customer2,ou=Sales\n\ncn=person2\n\nmemberOf: cn=Customer1,ou=Sales\n\ncn=person3\n\nmemberOf: cn=SocialMedia,ou=Marketting\nmemberOf: cn=Customer2,ou=Promotions\n\n\nTo, cater to your case, some implementation of the method\n  public User azkaban.user.UserManager.getUser(String username, String password)\nshould be changed.\nThe returned object azkaban.user.User, should be constructed such that \nazkaban.user.User.getGroups(), returns List_of_Strings, where each String represents a group. \nI populate this List from the LDAP attribute memberOf, and in your case, you should\nloop through all the groups the user logged in belongs to, and populate the List returned\nby azkaban.user.User.getGroups() with those groups.\nRest of the code can remain as is. The configuration file groups.xml could simply continue to map\nLDAP groups, to corresponding azkaban permissions.\n. You can add the following snippet of code as a last line in the try block of the method\nazkaban.user.LdapUserManager.getUser(...), and then a user who does not belong to\nany valid groups, will not be allowed to login.\npublic User getUser(String username, String password) throws UserManagerException {\n.\n.\n.\ntry {\n.\n.\n.\n//Last line of code in the try block\nif(user.getGroups().size() == 0) {\n    throw new AuthenticationException(username + \" does not belong to any valid LDAP groups\");\n} // close if\n} // close try\n// rest of the code follows as is\n...\n/Venkatesh\n. Yes! I just see that the fix I provided above to restrict users like 'person4' could not have worked, since\nuser.getGroups(), according the current implementation returns the count of groups the user belongs to defined in LDIF.  There are two possible generic fixes to this as below, either of them should work.\nFIX 1)\nWith a tiny check, we can create the user object to contain only those groups which s/he belongs to and also have some role mapping in the conf/groups.xml \nCODE_CHANGE in the private method as below\nprivate void addGroupsAndPermissionsToUser(DirContext dirContext, User user) throws Exception {\n//..\n//.. a few lines of code before you notice the while loop below\nwhile (neInner.hasMore()) {\n            Object neObject = neInner.next();\n            if (neObject != null) {\n                String neValue = neObject.toString();\n                groupName = fetchGroupCNfromDN(neValue);\n                if (isValid(groupName)) {\n                **// HERE WE CHECK THAT THE GROUP A USER BELONGS TO ALSO HAS SOME ROLE MAPPING**\n                    if(groupToPermissions.containsKey(groupName)) {\n                        user.addGroup(groupName);\n                        roleName = groupToPermissions.get(groupName);\n                        if (isValid(roleName)) {\n                            user.addRole(roleName);\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\nFIX 2)\nThis fix is very similar to the one I provided previously and which did not work, with a modification that\nwe check for user.getRoles().size() instead of user.getGroups().size(). So that we let the user login if he\nhas at least one azkaban role disregarding which group actually granted that role to him/her.\nCODE_CHANGE as below\npublic User getUser(String username, String password) throws UserManagerException {\n.\n.\n.\ntry {\n.\n.\n.\n//Last line of code in the try block\nif(user.getRoles().size() == 0) {\nthrow new AuthenticationException(username + \" does not belong to any valid LDAP groups\");\n} // close if\n} // close try\n// rest of the code follows as is\n...\n. Yes, I do agree that Fix 1 is more like a root cause fix. However I cannot imagine any new feature in future which would break Fix 2 alone, or some other requirement that might break Fix 1 alone. Well, both of them work fine and I cannot pick one upon the other since I have no good reason. Lets just go with Fix 1!\nThe ideal way to handle the Exception and error message display would be to add a new Exception named AuthorizationException, throw this when user.getRoles().size() is 0, and handle it in a third catch(AuthorizationException ae) block. On the other hand, what you have done is also good enough. Simpler code.\n. No, I have not performed any of these code changes we discussed above in my local development branch, since these changes are not required for the LDAP/ldif configuration we use here. \nAlso, I am not currently working on azkaban-customizations and into completely unrelated projects.\nBut, given that the changes have been tested to work in your local environment, you could probably mail me your local copy of LdapUserManager.java to venkatesh.nie@gmail.com, and I can just push the file as is to this branch which I have submitted for 'Pull Request'. However, I do not know if git would then automatically update this new file into this same 'Pull Request' which has already been submitted.\n. @ameyamk\nI have implemented this feature on a forked repository at : https://github.com/inoviaazkaban/azkabanfork/commits/master\nThere are 5 or 6 commits containing several changes for this feature, the latest of these being the Sep 13, 2016 commit of\nhttps://github.com/inoviaazkaban/azkabanfork/commit/ca9d4497cef243f02118b0334b47246660d92893\n(None of the subsequent commits occurring after this are related to this feature though, and can be ignored. The code will have to be manually merged to your master, if required. Good luck :) )\n\nFrom: Ameya notifications@github.com\nSent: Saturday, April 15, 2017 1:05:01 AM\nTo: azkaban/azkaban\nCc: Venkatesh Gowda; Mention\nSubject: Re: [azkaban/azkaban] [FeaturDevelopment] Stop/End date for Scheduled Jobs (#721)\n@inoviavenkathttps://github.com/inoviavenkat still working on this feature? we will be happy to help\n-\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHubhttps://github.com/azkaban/azkaban/issues/721#issuecomment-294252894, or mute the threadhttps://github.com/notifications/unsubscribe-auth/AQVHRdmU-47lbMgynjfn5SXsywX3Vp9yks5rv_udgaJpZM4J3G-H.\n. @ameyamk \nAre you Ameya K Shetty, who studied at NIE, Mysore? I just ask out of curiosity since it is a rare Indian name and I had a classmate long back with this name and he was a good programmer. Just wondering about the probablity of you being him..!. ",
    "inoviaazkaban": "Hi,\nCurrently, for an azkaban-job, the user can specify a start-date and the\nperiod-of-interval\nfor recurrent executions.\nIn addition to these, it would be a very helpful to specify an stop-date\ntoo, past which the job would\nno more be triggered/executed. The current job definition does not support\nan stop-date and I am\ntrying to implement it (picture attached)\nHowever, I am badly stuck with the implementation due to lack of\ndocumentation in the code and below\nare my specific questions.  Any ideas to move further from here or\nconnecting to me somebody who\nhas knowledge of these areas of code, would be much appreciated.\n1) The job details entered on the web-UI (attached page) are persisted as a\nblob\nin the column 'data' in the database table named 'triggers'. Which java\nclass\nreads this data further and translates them to equivalent\nthreads/processes. Is this\nblob further used by the ExecutorServer to create some other entries in a\ndifferent table?\n2) Which existing class/method is the best choice to modify with a tiny\ncheck to ensure that\ncurrent execution time is not past the stop-date.\nI am thinking it should be\nazkaban.trigger.builtin.BasicTimeChecker.eval()  \nAny better ideas?\n3) I did notice that\nazkaban.scheduler.TriggerBasedScheduleLoader.scheduleToTrigger(Schedule)\nis adding translating the schedule into a Trigger, which consists of a\nTriggerCondition\nand an ExpiryCondition, both of them composed of\nazkaban.trigger.builtin.BasicTimeChecker.\nHowever, they are almost identical, differing only with the id\nBasicTimeChecker_1 vs BasicTimeChecker_2.\nWhere are these two Condition actually called to perform the check?\nThanks in advance.\nVenkatesh\n+46707188865\n. ",
    "dumip": "An idea would be to allow the user to assign an unique name for each schedule he would create (default name would be job name). Would that be possible?\n. ",
    "antar88": "This would be a cool feature for us, because we are duplicating flows when we need to execute processes at some specific hours, for instance. \nAny idea if this will be done at some point?\nThanks!. ",
    "Anryg": "Anyobe else met this issue ? Thanks very much.\n. ",
    "wenxzhen": "Is this still an issue?. I set up the Azkaban on a machine with multiple executors on, but I still failed on azkaban 3.13.0\nAny hints?. I found the path: azkaban_executor/plugins/jobtypes\n. ",
    "mshafieluru": "hello.zip\n. I have solved this one.\nI have extracted the jobtype plugin with incorrect name into azkaban/plugins folder\ni have corrected the name and it is able to detect the job types and working fine\n. ",
    "vermamitesh87": "@devangorder I have gone through #667 . Were you able to force execution of a job to a particular executor ?. @logiclord I read previous comments that EXECUTOR_ID  is a flow parameter. But how can I force azkaban to run a job from a particular executor?. ",
    "akshayrai": "@rajagopr, can you post a snapshot of the UI where this button/link appears?\n. Great! LGTM\n. ",
    "rajagopr": "Attaching a snapshot for reference\n\n. Ok, I have pushed my recent changes. Please review.\n. Please review. I have made the required changes.\nPending: The UI tests. I will try to add this tomorrow.\n. Sure, I will wait until the UI test framework is merged in.\n. Thanks! I will add the test.\n. Please review, I have added the UI test.\n. Ok done. Please merge.\nNote: An unrelated test has failed on the CI build. Did not see an option to re-trigger the build without a push.\n:azkaban-execserver:test\nazkaban.execapp.event.BlockingStatusTest > testMultipleWatchers FAILED\njava.lang.AssertionError at BlockingStatusTest.java:127\n71 tests completed, 1 failed, 40 skipped\n:azkaban-execserver:test FAILED\n. Closing...\n. @ameyamk - It will!. @HappyRay - I have added additional tests which checks for the permissions. Please review.. @HappyRay - Have added tests for all the methods added - checked with the code coverage tool in IDE. Applied the 'Save Actions' plugin along with the recommended code style. Please review.. @HappyRay - I have made the fixes that you suggested. I will update the documentation once the change is merged.. @HappyRay - Updated with change description and other outstanding comments. Please merge if all looks good!. Tested the changes locally by starting the gh-pages server.. @HappyRay - Yes, I have done end-to-end tests and everything seemed to work fine. Especially the following were checked.\n1. Consumed the emitted kafka events and messages looked fine.\n2. Event reporter enabled/disabled scenario.\n3. Kafka broker down scenario\n4. Reporter enabled, but kafka brokers undefined in the config scenario\nI will get back with the suggested changes.. @HappyRay - I have made all the suggested changes except refactoring of the FlowRunner class which can be taken up separately.\nUpdating error-prone version to the latest (tried 2.1.1 and 2.1.0) did not work out well and I had to switch back to 2.0.15 to get the build going.\nPlease review.. @HappyRay - Excluded the unwanted modules from gobblin including lombok which fixed the compatibility issue with error-prone. Fixed other suggested changes. Performed the tests again and everything worked as expected. I was able to consume the emitted kafka messages.\nPlease review.. @HappyRay - I did notice your point. However, unblocking the release sounded pretty urgent and 'revert all' seemed the quick thing to do.. Dr. Elephant works with the full URL, other applications need not. I think this will require a change in Dr. Elephant. Let me know what you think. \n. Nope, Dr. Elephant will be the first button. The 'pull-right' bootstrap class will cause the first 'li' element to take the right most spot. As this is mentioned as the last line this will appear as the first button.\n. Currently there is a bug in the page with the natural tab order. Consider the following case.\n'Pause' and 'Resume' buttons are displayed on the page. The 'li' element 'Pause' appears before 'Resume' and hence takes the right most spot. So in the page we will see as follows.\n[Resume] | [Pause]\nLet's consider the tab order now. Let's say tab focus is on 'Stats'. When user presses tab again we will expect it to go to 'Resume' as that's the first button on the right. But tab focus goes to 'Pause' first and then to 'Resume' which will be annoying.\nNow, when Dr. Elephant is enabled this button will always be displayed and the tab order is broken which is not nice. I didn't find any elegant fix for this as of now. Hence, I have disabled tab focus on this button by setting tabindex=\"-1\"\nHope this explains :)\n. Done.\n. Done\n. Done\n. Planning to add a method named 'addExternalAnalyzer'\nI will separate out this method to a static utils class(ExternalAnalyzerUtils.java) and add a unit test for it. I hope this sounds good?\nHaving this method private in the same class will make it tricky to test. I will have to choose one of the four methods listed here. http://www.artima.com/suiterunner/privateP.html\nHence I suggest the above approach. Let me know what you think?\n. The simplest way to put this button without any CSS change was the below.\n<li class=\"nav-button pull-right\"><form target=\"_blank\"><button title=\"Analyze job in Dr. Elepahnt\" formaction=\"http://google.com/search?q=banana\" class=\"btn btn-info btn-sm\" id=\"analyzeLink\" type=\"link\">Dr. Elephant</button></form></li>\nNote the use of 'formaction' which is supported in HTML5. However, there's a bug in Chromium and webkit whenever there is a '?' in the url. This is explained in the following blog.\nhttp://tanalin.com/en/blog/2013/03/link-button/\nHence, I have chosen an anchor to represent this and attribute type=\"button\" will cause bootstrap to make\nit look like a button. Due to other overrides I had to define it on the ID.\nAlternately, I can write it as follows which will be using existing classes.\n.nav.nav-sm > li > a[type=\"button\"] {\n  padding: 5px 10px;\n  font-size: 12px;\n  line-height: 1.5;\n  border-radius: 3px;\n&:hover, &:focus {\n      color: #ffffff;\n      text-decoration: none;\n      border-color: #39b3d7;\n      background-color: #269abc;\n    }\n}\nI hope this is fine?\n. Done\n. I agree with your point that only execution ID is enough and is cleaner.\nHowever, I will have to check with the Dr. Elephant team on this. If it's too much work on Dr. Elephant side, will it be ok to have it like this for a while? Please let me know.\n. I discussed this with Shankar and found that a given execution ID is not unique across azkaban instances and hence they use the hostname in the url to distinguish between two flow executions. For simplicity, they used the URL. The portname itself is not required though.\nHe had another suggestion where-in we replace a pattern in the url instead of '%s'\nSample code:\nString link= \"http://elephant.linkedin.com:8080/search?flow-exec-id=%url\";\nString pattern = link.substring(link.indexOf('%'), link.length());\nswitch (pattern) {\ncase \"%flowExecId\": System.out.println(link.replaceFirst(pattern, \"100\")); break;\ncase \"%url\": System.out.println(link.replaceFirst(pattern, \"200\")); break;\ndefault: System.out.println(\"Pattern not found.\"); break;\n}\n}\nPlease let me know if you are fine with this approach.\n. Order by alphabetical order -> Done\nit appears to be testRuntime dependency -> './gradle distTar' seems to fail unless I have it as testCompile. \nPlease let me know if I'm missing something.\n. I did want to use Mockito. I was looking around in the project and didn't see mockito being used. I saw that 'azkaban.project' in azkaban-common is using Mock classes, hence I went with that approach. I will change it to Mockito.\n. I did not. I will check why this is showing this diff though.\n. Sure, I will take a look into that and implement the same.\n. Yes, that makes sense. I will implement this approach.\n. It will look like the following. Not too bad IMO.\nI will go ahead with this.\n\n. Done.\n. Done.\n. Nope.\nAs discussed in http://stackoverflow.com/questions/2222238/httpservletrequest-to-complete-url\n. 1. Setting lockdown.upload.projects to true will disable it for all, including admins\n2. You don't have to set the above global var and default behavior is only admins and persons with permission UPLOADPROJECTS can upload.\nHope this is clear.. Done.... Ok.... No, I did not. \"Linkedin Style\" is set in my IDE.. Ok, will keep it DRY.. Have made the method testable and tests are added.. This is done.. You have discovered a critical bug and want to disallow uploads until resolution. As multiple people are in the admins list, you want to prevent accidental uploads.\nIf you are saying, keep it simple, and ADMIN's can upload and non-admins can't. We can make it that way. I largely implemented it the way CREATEPROJECTS is implemented in this project. There can be an ops group which has UPLOADPROJECTS permission, in which case admins need not pitch in.\nLet me know your thoughts!\n. I will change the name and make it testable too.. Sure, I will send separate PR for that. . It's not currently package private.\nHowever, I will move it to azkaban.user in module azkaban-common.\n. Added javadoc.. Test ensures that the binary bit for UPLOADPROJECTS permission is not turned on by setting other permissions.. I have made changes to make it behave like lockdown.create.projects\ni.e.\n1. By default everyone can upload\n2. When 'lockdown.upload.projects=true', only admin users and users with uploadprojects permission can upload.\n. This is addressed.. done.. I'm inclined to take this up separately.. Immediately, I don't plan to make use of the finer grained control. But, I do foresee a case where we don't want to make everyone admin to be able to upload projects.. Thanks, 403 will be apt!. Done.. Accidental, I guess while I rebased. Will remove this.. Will remove this.. Done.. versions higher than 2.0.15 did not work and resulted in this issue. The suggested fix was to set to 2.0.15 version.. It's used in gobblin-metrics, I did not try using a lombok annotation directly in my class. I could run azkaban tests without anything extra.. Until I got this version, I was not able to build azkaban with gobblin metrics applied. Setting to this version solved this issue. I cross checked my local cache and could see this version.. kafka library used by gobblin metrics works fine within LinkedIn. We are using in metric store as well and did not observe any issues by using this.. Sure, will do.. Reporter(noun) does reporting(verb). The noun form felt more apt to me especially for the config defining the class. I agree with you for the consistency part. I can keep it all as reporting. Let me know.. Same as previous comment.. For the current usage, marking it with @singleton makes sense.. Ok, I will take a look at that.. Ok, will use that.. Yes, good point. I will change that.. Ok, I will work on that in a separate PR.. Yes, I did mean azkabanHost. Though it's possible to access the hostname via something like AzkabanExecutorServer.getApp().getHost(), I found it difficult to test the same. The getApp method is static and mockito doesn't allow mocking of static methods. I did not want to introduce another library for this. Let me know if there's a better way.. Metadata can be treated as a blackbox by the reporter.. Sure, will do.. I do not follow. Are you saying not to initialize FlowRunner with the event reporter in-case the reporter is null. Still, I would need to check if it's available or not while handling the event? Or, not to add the flowListener if the event reporter is null? Please let me know.. Ok, let me check on these. I will make the suggested changes.. Metadata can be treated as a black-box though.. gobblin metrics seems to bring in some dependencies which are all over the place. Had to add these find all the libraries.. Null case is handled at the beginning of the method and it shouldn't reach here if it's null.. Yea, that should be enough. Will change.... @HappyRay - I will check what's the alternate library to depend upon.. done.. done.. With the latest version of error-prone, this issue has gone away.. I have checked this with Aditya in the gobblin team and he confirmed that this is the right way to use it.. done.. done.. done.. done.. done.. We can do this refactoring as part of a separate PR.. done.. done.. Are you suggesting to use an interface with constants? This is generally considered a bad practice. Refer this. As part of the metadata consumers will get a map which is what we mentioned in the interface AzkabanEventReporter.. done.. Ok, I have created a separate event interface for this purpose and moved the event interface and AzkabanEventReporter interface to the azkaban.spi module.. done.. done.. Checked with aditya from the gobblin team and he confirmed that the usage is right.. done.. That was marked to fix as createAzkabanEventReporter had changes. It's fixed and enabled now.. I have referred to the constants and added @code marker. It's not possible to link to classes outside of a module using @link or @see.. Changed to use EventType directly. . ",
    "ebuildy": "It depends on the master, YARN / Mesos etc... What do you have?. As we plan the same thing, @ameyamk what do you recommend to develop a such thing? (clone existing plugin etc..) I could give some help on it.. ",
    "EdwardsBean": "@HappyRay \nUnit tests can reuse azkaban-common/../JdbcProjectLoaderTest\nIf the table was created using the original default character set (Latin1) and they can run this code to read from that table\nWhen use input content contains none latin support character, mysql  will not allow to insert(SQLException).\nRight now only project name and project descriptions suffer from the issue.\n. @HappyRay\nYou are right.\nWhen project name or project description contains non ASCII characters(project table with latin1), in azkaban project dashboard show messy code of non ASCII characters.\nChanging project table to UTF8 is really necessary for those languages none western world.\n. ",
    "McDulliBiBi": "Hi ,\nI want to use Chinese words in the job files , but I found that after inserting into the mysql db , the content of the job become messy, in table project_files and project_properties. How can I solve it ? \nThanks!. ",
    "JayMiao": "@logiclord \nBut where could I get the value of EXECUTOR_ID for a 'useExecutor' ?\n. ",
    "tk0485": "I'm trying to set the executor while scheduling the jobs. I added \"useExecutor\" to the curl command below for scheduling jobs but it doesn't seem to do anything? \ncurl -k https://localhost:8443/schedule -d  \"ajax=scheduleFlow&projectNme=testProject&flow=flowName&projectId=1&useExecutor=1&scheduleTime=7,00,am,PDT&scheduleDate=07/20/2016\"  -b azkaban.browser.session.id=6c96e7d8-4df5-470d-88fe-259392c09eea\nAlso, I'm wondering if I add seconds to the time for scheduling will have any impact on the scheduling time? \n. yes, I'm using a solo server and the port is configured. Other api calls work fine and I can get the session id fine too except for this call.\n. @KyleFung as you have already guessed .. its a copy paste from azkaban github page, I deleted the single quote when I used the curl command in my tests. . I found the reason for my issue. There is a missing dash from the --data in the curl command, the curl command should like:\ncurl -k --data \"session.id=34ba08fd-5cfa-4b65-94c4-9117aee48dda&ajax=getRunning&project=azkaban-test-project&flow=test\" https://localhost:8443/executor\ninstead of having a single dash leading \"data\", I also deleted the extra single quote before hostname. Could Azkaban team please update their documentation to reflect the correct command.. if I want to delete azkaban project I have to cancel all running flows and delete all scheduled one first before deleting the project. . ",
    "luoguohao": "how things progress? we also have some cases.. thanks a lot for your proposal,I will try if I need.. ",
    "mcanaleta": "Any plan for this? It becomes a bigger issue if there is a balancer in between which has more than 1 IP address :) (in google container engine for example).\nI guess this check is supposed to add extra security but I don't think its a common practice. At least, it could check the X-Forwarded-For header instead of the actual remote IP (but this would not solve @Vimos problem).\nI would make it configurable as @Vimos suggests.\nThanks!\n. ",
    "arumugarani": "it should also work, but it should be !recentlyfinished.isEmpty :)\nAnd more over in the place where recentlyfinished has been filled up has a\npossible value of null if nothing is there to dispaly and hence I made the\nsame check as if \"CurrentlyRunning\" tab\nOn Sun, Jul 24, 2016 at 10:38 AM, Liang Tang notifications@github.com\nwrote:\n\nIt works! We are not familiar with velocity. @arumugarani\nhttps://github.com/arumugarani , May I know why\nrecentlyFinished.isEmpty() doesn work? and what does !$null.isNull\nmean?\nThank you!\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/azkaban/azkaban/pull/683#issuecomment-234758141, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ARrChZbhCEP2FHyuGY6WwUQRlatrNYlFks5qYvMygaJpZM4JOoCP\n.\n. Please mark the bug #306 https://github.com/azkaban/azkaban/issues/306 as\nclosed\n\nOn Tue, Jul 26, 2016 at 4:38 AM, George (Liwen) Zhang \nnotifications@github.com wrote:\n\nMerged #683 https://github.com/azkaban/azkaban/pull/683.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/azkaban/azkaban/pull/683#event-734259760, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ARrChfyS3f8qwOgPsgeH0OI5qEClLiT3ks5qZUH8gaJpZM4JOoCP\n.\n. \n\n. Added the images. When will you merge this?. \n",
    "jamiesjc": "Yes, the two properties files can be removed.. Will pull a new request with more detailed comments. This one has unresolved conflicts.\n. The configuration for props doesn't seem to be common for most test cases. Even for these two similar test cases, they have different props like \"type\". It might not be necessary to create a new common setup method?\n. Yes, I've tried adding ${azkaban.job.id} in both shell and javaProcess. The exception is seen on both. It should happen to all job types.. We need to explicitly put it in jobProps so that it can be resolved:\n  props.put(CommonJobProperties.JOB_ID, this.jobId);. We'll definitely prioritize the web server HA work. \nThe first step of removing the cache on web server is already implemented but not enabled yet. Once web server becomes stateless, we can proceed with the next step of bringing up multiple web servers. \nThis needs to be carefully designed and tested though. Thanks for your patience and please expect more time from our side. . @chengren311 Project table has below data: | id | name                               | active | modified_time | create_time   | version | last_modified_by | description                          | enc_type | settings_blob. \nMoving cache info from web servers to DB might downgrade the performance a little bit. Currently the DB query takes about 0.02 sec. Consider our current scale and load, this shouldn't affect much. And we will have master-slave DB plan in the future to overcome potential issues. \n  . @suvodeep-pyne \nThe results of these methods are not cached. I'm planning to add some metrics to count how often these methods are called.. LGTM. Git revert the main code. Unit tests have some dependencies so did not revert. Just ignored some of the test cases. Did not revert Jdbc query for fetchActiveFlowByExecId() for future usage. Anyway this method is only called in test case for now so should be fine.. Thanks @HappyRay, I've updated previous doc with the SQL explain result. Also I'll make sure to highlight the DB update in the release note.  . In unit tests, I used local mysql db to test fetching active/queued flows covering both valid and invalid cases.\nI verified the sql query in azkaban DBs, also did some cleanup on the remaining inconsistent DB info.\nPlan to put the changes in testing cluster and see if web server can loadRunningFlows and loadQueuedFlows correctly when it starts.. @juhoautio Are you still interested in bringing back KILLING status?. @juhoautio Could you submit a new PR? We'll merge it and then deploy.. cc @HappyRay @chengren311 . LGTM. If you still need to use that API, we would like to keep it for your convenience. Thanks for removing the stats as well.. I've reviewed the change and it looks good. Will merge it now.. Even though TINYINT is not a standard sql type, it is still supported by MySQL as an extension. Both TINYINT and BIGINT are widely used in our db table already. I would prefer keeping the existing sql type since they are working properly, otherwise, we need to change everywhere that is using TINYINT and BIGINT.. @kunkun-tang has refactored unit tests for JdbcExecutorLoader (https://github.com/azkaban/azkaban/pull/1291/files) and I will add unit tests for writing all possible statuses into H2 DB on top of his new changes.. This fix won't work if azkaban.jobExecutor.ProcessJob#cancel is called, killed is set to true, and then process would skip azkaban.jobExecutor.utils.process.AzkabanProcess#run. Then azkaban.jobExecutor.utils.process.AzkabanProcess#awaitStartup will be waiting forever causing the problem. Need to figure out a better solution.. Actually there could be several race conditions when killing the flow. One is between ProcessJob#run and Process#cancel as you mentioned above. Also another problem is in FlowRunner#kill(), it could happen that the JobRunner hasn't been added to the activeJobRunners yet when it tries to kill. In that case, the job wouldn't be killed as well.. In azkaban.execapp.FlowRunner#runFlow, before progressGraph, azkaban.execapp.FlowRunner#runReadyJob will modify activeJobRunners, and it is not synchronized. azkaban.execapp.FlowRunner#kill() could happen during runReadyJob and cause the race condition mentioned above.  . @HappyRay I've created an issue in https://github.com/azkaban/azkaban/issues/1311\nI think adding the lock could solve the problem. I'll think about it and try it out, thanks! . @juhoautio When we kill the flow immediately after it starts in our integration test, it couldn't be killed due to some race condition. Users will see on the execution page that the job is in KILLING status but it actually never gets killed. And users cannot click kill button again during the KILLING period. \nAt the time when we kill, the process might not have started yet or the jobRunner has not yet been added to the activeJobRunners.\nYou can check more details in the PR description: https://github.com/azkaban/azkaban/pull/1289. We are still working on the fix.  . @juhoautio We really want to bring back your KILLING status change asap. If you are interested in working on the fix, we can discuss more details and share with you the integration test we have. . Here is an example of the test case to reproduce the problem. You need to replace the session.id, project and flow info to make it work.\ntestKillFlow.py\n```\nimport requests\nimport time\ndef execute_flow():\n    qparams = {'session.id': '92cbc945-6457-4ac1-a96e-7f575cd49359', 'ajax': 'executeFlow', 'project': 'az_acceptance_test',\n    'flow': 'IntegrationTest'}\n    headers = {'Accept': 'application/json'}\n    azk_target_exec_url = 'http://localhost:8081/executor'\n    jsonObj = requests.get(azk_target_exec_url, params=qparams, headers=headers, verify=True).json()\n    if 'error' in jsonObj or 'execid' not in jsonObj:\n        raise AzkabanError('Executing flows with concurrent option failed.')\n    print jsonObj\n    print \"Execution id is %s.\" % jsonObj['execid']\n    return jsonObj['execid']\ndef kill_flow(exec_id):\n    qparams = {'session.id': '92cbc945-6457-4ac1-a96e-7f575cd49359', 'ajax': 'cancelFlow', 'execid': exec_id}\n    headers = {'Accept': 'application/json'}\n    azk_exec_details_url = 'http://localhost:8081/executor'\n    jsonObj = requests.get(azk_exec_details_url, params=qparams, headers=headers, verify=True).json()\n    print jsonObj\n    if 'error' in jsonObj:\n        raise AzkabanError('Failed to kill the flow.')\nexec_id = execute_flow()\n// Modify the sleep time to reproduce different race condition scenarios\ntime.sleep(0.01)\nkill_flow(exec_id)\n```\n. Hi @juhoautio, @HappyRay has already proposed a fix for this race condition between jetty killing thread and jobRunner thread: https://github.com/azkaban/azkaban/pull/1310, also we've identified another potential race condition with killing thread and flowRunner thread https://github.com/azkaban/azkaban/issues/1311. Once the fix is done, we can work together to bring back you KILLING status change.. Yes, I agree. The status will be moved from KILLING to KILLED eventually. Currently, we don't have the status to indicate failure of killing. If we can make sure killing could always succeed, then we don't need to introduce the new status.. LGTM. I'll pull your changes and run some integration test to verify it as well.. I've run integration test repeatedly and verified the fix from the job logs.\nJob Logs\n07-08-2017 15:31:22 PDT IntegrationTest_jobCommand INFO - Starting job IntegrationTest_jobCommand at 1502145082031\n07-08-2017 15:31:22 PDT IntegrationTest_jobCommand INFO - azkaban.webserver.url property was not set\n07-08-2017 15:31:22 PDT IntegrationTest_jobCommand INFO - job JVM args: -Dazkaban.flowid=IntegrationTest -Dazkaban.execid=19248 -Dazkaban.jobid=IntegrationTest_jobCommand\n07-08-2017 15:31:22 PDT IntegrationTest_jobCommand INFO - Building command job executor. \n07-08-2017 15:31:22 PDT IntegrationTest_jobCommand ERROR - Kill has been called.\n07-08-2017 15:31:22 PDT IntegrationTest_jobCommand INFO - Memory granted for job IntegrationTest_jobCommand\n07-08-2017 15:31:22 PDT IntegrationTest_jobCommand INFO - 1 commands to execute.\n07-08-2017 15:31:22 PDT IntegrationTest_jobCommand INFO - effective user is: azktest\n07-08-2017 15:31:22 PDT IntegrationTest_jobCommand INFO - Command: sleep 90\n07-08-2017 15:31:22 PDT IntegrationTest_jobCommand INFO - Environment variables: {JOB_OUTPUT_PROP_FILE=/Users/jasun/AZNewDesign/azkaban/executions/19248/IntegrationTest_jobCommand_output_1600379015566666597_tmp, JOB_PROP_FILE=/Users/jasun/AZNewDesign/azkaban/executions/19248/IntegrationTest_jobCommand_props_1415711911832383526_tmp, KRB5CCNAME=/tmp/krb5cc__az_acceptance_test__IntegrationTest__IntegrationTest_jobCommand__19248__azktest, JOB_NAME=IntegrationTest_jobCommand}\n07-08-2017 15:31:22 PDT IntegrationTest_jobCommand INFO - Working directory: /Users/jasun/AZNewDesign/azkaban/executions/19248\n07-08-2017 15:31:22 PDT IntegrationTest_jobCommand INFO - The job is killed. Abort. No job process created.\n07-08-2017 15:31:22 PDT IntegrationTest_jobCommand INFO - Finishing job IntegrationTest_jobCommand attempt: 0 at 1502145082135 with status KILLED. @HappyRay Yes, I've tried delaying the kill command and it also succeeds. \nI have shared a test in https://github.com/azkaban/azkaban/pull/1300#issuecomment-320924658, which will kill the flow after it starts. And we can add delays in between to simulate different scenarios.  . I've read through the changes and descriptions. Correct me if I misunderstood anything. @juhoautio \nThe main problem here is that the kill thread is synchronized but the job run thread is not. And both threads will change the job status which causes the race condition. \nOne race condition happens in below scenario:\n1. jetty thread:\n    azkaban.execapp.JobRunner#kill\n    azkaban.executor.Status#isStatusFinished -> status is not finished, does not return\n2. switch to jobRunner thread:\n    azkaban.execapp.JobRunner#runJob\n    azkaban.execapp.JobRunner#changeStatus(azkaban.executor.Status) -> change status to SUCCEEDED\n    azkaban.execapp.JobRunner#fireEvent(azkaban.event.Event, boolean) -> fire JOB_FINISHED event\n3. switch back to jetty kill thread:\n    set this.killed to true\n    azkaban.jobExecutor.Job#cancel -> do the actual kill\n    azkaban.execapp.JobRunner#changeStatus(azkaban.executor.Status) -> change status to KILLED. The fix is mainly to synchronize the places where #changeStatus would modify the job status incorrectly from different threads, e.g. changing it to SUCCEEDED from jobRunner thread first and then to KILLED from jettry kill thread. I think the fix makes sense. But it's definitely not easy to understand and maintain in the future. I would vote for @HappyRay's suggestion of reducing the overall complexity of the code if this is something we want to move towards finally.\n\nI am thinking of refactoring the DAG processing engine to reduce the complexity and reduce the need for thread synchronization. e.g. if there is one thread that is responsible for the job/flow status transition, it would be easier to reason about.. One UI improvement suggestion:\nWhen users move their mouse on the banner, it's better to show something different so that they know they can click into it and redirect them to the GCN jira page.\nSomething like the hover selector https://www.w3schools.com/cssref/sel_hover.asp. Can you add more details regarding your plans on the future refactor work?\ne.g. Do you plan to move all execution_flows table related DB operations to this ExecutionFlowDBManager? Also do you plan to move some DB operations which involve multiple DB tables, e.g. FetchActiveExecutableFlows, to separate classes?. In the current azkaban-users.xml configuration, azkabanuser's role is admin. So it will always have the permission to access /jmx and /stats even without my change.. Thanks @reallocf and @HappyRay for the comments! I've fixed it using the suggested way. \nThis is probably something new in the errorProne bug pattern, so it only starts to show in the latest build.. Thanks for the fix! I was able to reproduce the same issue on my local branch.\nHere is my understanding of the issue and your fix. Correct me if I misunderstand it.\nIn testNormalFailure2, we explicitly fail joba1. Ideally all the remaining jobs should change status to CANCELLED. However, it doesn't always happen because we only wait for joba1 status to become FAILED and do not wait for the JOB_FINISHED event. \nThis event needs to be handled because it will add joba1 to finishedNodes, and in azkaban.execapp.FlowRunner#progressGraph, it will process the finishedNodes and set flowFailed to true. Once this flag is set, then the rest of the remaining jobs will become CANCELLED status in azkaban.execapp.FlowRunner#getImpliedStatus. \n. Flow 2.0 Stubs. Reading YAML flow files https://github.com/azkaban/azkaban/pull/1275\nFlow.2.0_part1_loadAzkabanFlowFromYamlFile[In progress] https://github.com/azkaban/azkaban/pull/1443\nRefactor uploading project https://github.com/azkaban/azkaban/pull/1466\nCreate directory flow loader for yaml files. https://github.com/azkaban/azkaban/pull/1500\nFlow 2.0 design - embedded flows https://github.com/azkaban/azkaban/pull/1525\nAddress comments in PR#1525. https://github.com/azkaban/azkaban/pull/1531\nFlow 2.0 design - Convert AzkabanFlow to Flow. Load project YAML file. https://github.com/azkaban/azkaban/pull/1534\nFlow 2.0 design - Create project_flow_files DB table. https://github.com/azkaban/azkaban/pull/1544\nFlow 2.0 design - Upload flow YAML files to DB. https://github.com/azkaban/azkaban/pull/1546\nFlow 2.0 design - Get props from flow YAML file. https://github.com/azkaban/azkaban/pull/1549\nFlow 2.0 design - Resolve properties for flow executions. https://github.com/azkaban/azkaban/pull/1554\nFlow 2.0 design - Load flow trigger from YAML file. https://github.com/azkaban/azkaban/pull/1558\nFlow 2.0 design - Override Job Properties. https://github.com/azkaban/azkaban/pull/1565\nFlow 2.0 design - Validate nodebean and check job properties. https://github.com/azkaban/azkaban/pull/1568\nAddress comments in PR# 1544 https://github.com/azkaban/azkaban/pull/1574\nAdd azkabanFlowVersion in executableFlow https://github.com/azkaban/azkaban/pull/1586. Hi @ismailsimsek We use Hadoop DSL internally to do the transition. It basically defines the workflow in gradle files and builds into either Flow 2.0 projects or 1.0 projects. See more info in https://github.com/jamiesjc/linkedin-gradle-plugin-for-apache-hadoop\nFor your use case, it might not worth that effort to totally switch to Hadoop DSL though. There is no other tool we provide to do the conversion directly. \nI'd like to know how you write the existing jobs and properties files? Is it done manually or is any tool used to generate that? . @ismailsimsek That looks great! Thanks for sharing the code. It would also benefit other users who have the same need if we build a tool on top of this. I think basic auto conversions provided by the tool with some manual changes should be sufficient for now. If you are interested in building and improving such a tool, feel free to do that.\n. @armisael @HappyRay This issue could be related to an old PR https://github.com/azkaban/azkaban/commit/d114439dbc1f5d7f948888f7240e9a92a7cc1661.\nIn azkaban.execapp.FlowRunner#prepareJobProperties,\nonly if a node is not an instance of ExecutableFlow, it will load the sharedProps for the node. In this scenario, the sharedProps are defined in the default.properties files and they are not populated into the node since it is an instance of ExecutableFlow, and thus fail to be resolved in azkaban.utils.PropsUtils#resolveProps, causing the failure.\nI tried removing if (!(node instanceof ExecutableFlowBase)) and the flow could run successfully. This might not be the ideal fix, but it points out where the issue locates.. @armisael Sure, you can go ahead and investigate on the solution. I might not have enough bandwidth to work on this issue, but I'll definitely review your change and provide feedback.. Thanks for the fix! @armisael \nI'm still trying to understand the whole idea. So what does it mean by \"use them when evaluating properties of the flow itself, but to ignore them in inner jobs.\" For .properties files, shouldn't they apply to all the flows and also jobs inside the flows?. @armisael Thanks for the detailed explanation. So if I'm understanding it correctly, the issue happens when the inner flow exists in a different folder than the job (with the type flow) which references it? I'm not sure if this is a valid scenario that we need to support currently. \n@HappyRay In the new YAML based representation, inner flows are embedded inside the same parent flow file, so there is no such issue.\n. @armisael I'd like to discuss how we define the scope of job properties, mainly on point 1 and 2. From 1st point, a job could inherit all the properties from .properties files in its current folder and parent folders. From 2nd point, a job could inherit all the properties from its parent flow. \nI can understand your intention of the fix, but I couldn't think of a use case where it could cause problems if the inner job inherits everything from its parent flow including the .properties files in the parent flow folder. It would be great if you could share any use case like this. The properties are resolved for the parent flow first and they should be part of the parent flow already. I don't think there is a need to over complicate the issue by hiding some of the properties for inner jobs when they inherit from the parent flow. Maybe I'm wrong, but I think the complicated logic is more prone to potential bugs and hard to maintain. \nToday Azkaban does not define per flow properties. Users have to create sub-folders to limit the scope of a flow and its properties as a workaround. This is a little nasty and could cause some problems like this one. We are working on the new flow level design which could solve this problem. At the same time, we'd like to support the current code by fixing critical bugs, but just to let you know this part of the logic would eventually be deprecated. . @armisael I did some experiments on that test case and also saw the scoping issue you pointed out. To be honest, the existing rule of property priority is really complicated and could cause confusion. You have a very deep understanding of the issue and your fix looks good to me. But I would prefer simplifying the current logic instead of applying more complicated fix on top of the existing code. \nIn the new flow YAML file, we would get rid of the shared properties files. Each flow will have its own flow properties defined inside. Sub-directories will not be needed. The tradeoff would be some duplications in the flow properties. Today we already have some internal tool to handle this duplication. For external users, we are trying to make it easy and convenient to migrate as well.  . What is the custom credential provider? Can you give a little more detail on what you are planning to do with this new interface?. @inramana Thanks for the comments. It would be ideal to split the two paths, however, in the current code, it might not be easy to achieve that because the two paths share most of the logic in flowRunner but differ only in some places when loading properties. So I chose to split the two paths inside loading properties. The idea is the same, just have to split them in a more detailed way in multiple places instead of splitting the entire code path.. @jakhani Thanks for the comment. Yes, we can pass the retry count from config. We can add that later if we want this to be configured differently for different clusters.. @Xycer Thanks for trying out the new Flow 2.0 design! We haven't fully enabled this feature yet. You are welcome to try it on localhost by enabling below code in azkaban.execapp.FlowRunner:\nthis.isAzkabanFlowVersion20 = checkAzkabanFlowVersion(); // This might be changed in the future.\nFeel free to report any new issue : ) . @kunkun-tang Updated the description, thanks!. @mtrna Thanks for contributing to Azkaban! I'm reviewing your code now.\nMeanwhile, please take a look at the style guides in contributing page: https://github.com/azkaban/azkaban/blob/master/CONTRIBUTING.md\nWe've been following some specific coding style. You can enable intellij's save actions plugin to auto-format your code.. Hi @mtrna, I've tried out your new template-based email changes locally and was able to view the emails in new contents. \nAs you mentioned, one of the main benefits of the template-based emails is that it is configurable by users. It seems to me that the new email templates are configured on the server side, not from the Azkaban user side. Can you elaborate more on how an Azkaban user can actually configure the email templates?\nIf a user can configure the email template as they want, will it cause security problems? Some companies have regulations on data privacy protection. If user misconfigures the email content which contains private user data, it might cause security issues. . I like the idea of separating email content from the code. And it benefits Azkaban admins if user requests any change in the email content. But so far we haven't had any request in the email content change yet. It is nice to have, but the overhead if that we need to deploy and maintain the email configuration on all servers. I'd like to understand your use case better and evaluate the impact of this feature. . @mtrna Sorry I didn't get a chance to review your PR this week. I think you're right, it would benefit users if we could provide them more detailed info about flow parameters and execution options in the email. We'd like to keep the current email content as default, but to provide the option of template-based emails. Users should have the freedom to choose their own.\nI'll continue reviewing your code when I have time, thanks for the patience!. Hi @HappyRay,  @mtrna and I had some discussions about moving the emailCreator from execution level to server level.\nI'm in favor of his proposal to decide the emailCreator on the level of executor during initialization step. If email templates are configured, we use template-based emailCreator, otherwise we use the default emailCreator. We don't have to support configuring emailCreator in ExecutionOptions since it's not supported anyway today on web UI. \nYou can check our past discussions for more details. I'd like to hear your advise as well, thanks!. @mtrna Sorry for not responding to your new change. I hope we can get your PR in asap. But now might not be the right timing since there is also some refactoring work going on recently on email part. We need time to fully understand the email part ourselves. I hope you are still interested in reopening this PR in the future. :). Hi @haknsahn, we're glad to know that you are interested in our new Flow 2.0 design!\nI've just written a wiki with some details on Flow 2.0 design. Let me know if you need more clarification. We are mostly done with the code. Welcome to test it and report any bug! :) \nUser guide: \nhttps://github.com/azkaban/azkaban/wiki/Azkaban-Flow-2.0-Design---User-Guide\nPRs:\nhttps://github.com/azkaban/azkaban/issues/1453. Thanks for the comment. I tested the change on localhost by manually deleting the properties from web UI.  . After the change, the executionOptions will display in below format:\n\n\n. @wyukawa Let me know if you have any concern about the change.. @HappyRay I did some research but haven't figured out an easy way to do that. We probably need to add the framework for UI testing which is currently missing.. Consider adding more test cases for validating schedules and dependencies?. @HappyRay Thanks for the comments!\nI've submitted new PRs to explicitly set Mysql DB to case insensitive and change the H2 DB for unit tests to case insensitive. I've updated the change description as well. \n. @kunkun-tang Thanks for the comments! It is possible that the entire DB is set to case insensitive but the specific columns or tables are case sensitive. I would suggest providing the info so that admins can check DB themselves and update according to their own case.. @HappyRay I've evaluated the project cache synchronization issue and submitted the new changes in the same PR.  Updated the change description with some details.. @HappyRay Do you have any other comments on this PR? Is it good to check in?. Hi @juhoautio , I can see your point that the eviction could potentially break the concurrent execution options. However, if the executions remain in running status, should azkaban admins finalize the flows manually in the DB? If the execution status is not finalized, I don't think users will be able to execute the same flow again with the default skip execution option. \nAlso when users try to fetch the flow/job log, it will call the executor to fetch it instead of fetching it from DB since the flow status is still running. But there is no response from the executor, so the log would always show empty. Even if we send emails to users, they still have no clue whether their job is actually still running or already failed.. @juhoautio Thanks for the detailed explanation. It makes sense to me as I read more about the previous discussions. Just want to confirm with you,\nIf an executor is removed from the DB entirely, also then azkaban-web should evict all running executions that are assigned to the non-existing executor.\nIf I remember it correctly, this logic has been implemented in your PR #1833 right? \n. @senecaso-sf Please check the style guides mentioned in contributing page. We enforce the google code style. You can enable \"save action\" to reformat your code automatically.\nhttps://github.com/azkaban/azkaban/blob/master/CONTRIBUTING.md. Thanks @senecaso-sf, the reason I'm asking is because I notice some places where the final keyword is not added for local variables. Just want to double check with you to see if the style change is applied properly.. Ok, maybe some options were not enabled in \"save action\"? FYI, I've attached my configurations below\n\n.. Overall your change looks good to me.\nHave you tried installing the \"save actions\" plugin: https://plugins.jetbrains.com/plugin/7642-save-actions? Can you give it another try? It would be helpful and save lots of reviewing time for the future commits. . Hi @senecaso-sf, \nDo you still remember the test case name which you mentioned before? I'd like to understand that particular case better.\n\nOriginally, I thought it would be unique as well. However, your unit tests quickly disproved that theory! It was happening when 2 different flows had jobs with the same name. I believe the conflict in the tests was innerJobA which appeared in multiple flows. \n\nAlso, how did you create that massive project flows .tar.bz2 file? Have you tested embedded flows?. Hadoop Job Log:\n\nSpark Job Log:\n\n. To improve this feature, I changed \"Hadoop Job Log\"/ \"Spark Job Log\" button color to red if the job fails or is killed. The button will be more noticeable and informative to users so that they are more likely to click the button to debug their jobs. \n\n\n. Edited the job URL examples in the comment in a new PR: https://github.com/azkaban/azkaban/pull/1708. @HappyRay  How about changing it to a drop-down button to show all the available application IDs to choose from? This would be an experimental feature. As @ameyamk suggests, we can introduce a \"Lab\" brand to mark this find of experimental features in the future. If needed, I can also add another jobhistory server link under the current web proxy link in the user log. . I agree with you. As I've mentioned in my previous comments:\nIf needed, I can also add another jobhistory server link under the current web proxy link in the user log.\nI think there was some miscommunication about the new feature at the time when I showed to Subu. Anyway we can ask users if they want the additional button feature. One way is to provide the feature for them to try and then collect the feedback. That's part of the reason I want to make it experimental. Also, as we discussed, it is not easy to catch incompatibility issue if there is a Hadoop side change. So I prefer to make it experimental. . Originally I was thinking about adding the job history server link below the original web proxy link for each application. However, Azkaban doesn't seem to have the info about when an application starts or completes. It only knows when the entire job completes. So we decide to add the links at the end of the job log for all applications. Disable the button for now since there is some concern about the compatibility with Hadoop.. @reallocf In our current code, the useExecutor parameter is only fetched from executionOptions (flow parameters UI page or API calls). azkaban.executor.ExecutorManager.QueueProcessorThread#getUserSpecifiedExecutor\nEven if we set it at yaml flow level in Flow 2.0, it cannot be picked up. . This is related to #1826 . @kunkun-tang Also String comparison is supported. E.g. condition: ${jobA:azkaban.server.name} == 'foo'. Hi @huaxuehuaxue, \n1. JOB_OUTPUT_PROP_FILE is an environment variable of a processJob (e.g., a command job). So it should be available to the job if you just reference it using $.\n2. I'm not sure how you use it. I'll attach a sample zip so that you can compare and see the difference.\nAlso, this feature is still under development, so we don't have a finalized wiki documentation yet. Sorry for the inconvenience now.\nArchive.zip\n. Hi @DoubleClickSixSixSix ,\nThe scheduled task will be skipped during the downtime of the web server. But when web server is up again, it will continue to be scheduled as before. \nIf it's multi-executor mode, the flow will be added to queuedFlows and retry if dispatch fails. But if it's solo server mode, it wouldn't retry if dispatch fails.. Is there any documentation on how users can use code coverage in their local environment?. Hi @juhoautio, I have a question regarding this PR. \nWhen an executor is shut down and removed from the DB table, the running flow cache could still remain the old executor info. It would skip the !executorOption.isPresent() check and not be added to finalizeFlows. The web server would still call that executor to fetch the flow status but it would fail to get the update from the executor since it's already shut down. As a result, an email will be sent instead of flow being finalized. \nWe recently observed such behavior on our server. I think it might require a web server restart so that the running flows cache could be refreshed and then this PR would take effect. \nCan you share your thoughts and let me know if I miss anything?. @juhoautio Ok thanks. It would be more convenient if we don't have to restart the web server for it to take effect. Currently we have shutdown api which would shut down an executor when all the flows have finished on that executor. However it seems there is some timing issue that the executor would be shut down early even before the web server could get the chance to update the flow status. I think we need a fix either for shutdown api @chengren311  or finalizing flows without matching executor. . @juhoautio From what we observed in the log, the executor was shut down first and then the web server still tried to connect to that executor to get an update and it failed. They happened almost at the same time, but the shutdown happened a little early before the flow status was updated, thus causing the issue.\nServer logs:\nexecutor shutdown: \nltx1-***exec14.grid.linkedin.com:\nazkaban-execserver.log:2018/09/29 08:22:54.130 +0000 WARN [FlowRunnerManager] [Azkaban] Shutting down FlowRunnerManager now...\nweb server get update from executor:\n2018/09/29 08:22:54.565 +0000 ERROR [ExecutorManager] [Azkaban] Failed to get update from executor ltx1-***exec14.grid.linkedin.com. @juhoautio Yes, the error log is irrelevant to your change. The concern is about the timing issue between shut down api action and finalizing flow status from web server. I would prefer fixing this issue since this is the root cause. One possible solution I can think of is to shut down the executor when there is no flow in the recently finished flow cache. All the finished flows will be moved from running flows cache to recently finished flow cache on executor and the recently finished flow cache will be cleaned up after 1~2 min. The web server should still have sufficient time to get flow status update from executor before the executor is shut down. Could this prevent the timing issue mentioned above? @chengren311 Let us know if you have any better suggestion on the shut down api behavior.\n@juhoautio For your proposed solution, does it mean the running flows cache on web server will be updated periodically as well? That could be a solution, but I'm not sure how much complexity it would add to the existing updater thread on web server side which is already complicated.\n . @juhoautio \n\nTo clarify, is the problem just that an error is logged? \n\nNo, the main problem is that the flow status is inconsistent now. They are showing up on running flows page but are actually finished already. Users won't be able to rerun the same flow if they choose \"skip\" execution option. \n\nIndeed that can be avoided, but note that error should be logged if the executor is still found in the DB but is not responding.\n\nIn this case, the executor is not found in the DB because they are shut down by the shutdown api call and we are still seeing the error before we restart the web server.\n\nI think a better option would be to always reload executors from the DB before the update loop.\n\nBy reloading, you mean reloading all the executors, not just the active executors, right? Why is it necessary to alwasys reload executors? It seems you only need to fetch the executor info from DB when the executor cannot be reached?\n\nAlso, if an executor still cannot be reached, check the list of executors immediately again. If the executor was removed, finalize the execution as usual. \n\nI understand that ExecutorManager#finalizeFlows will remove executions from running flows cache. If the new change could make sure that the flows are properly finalized, then that should be good. \nOne more thing I want to mention, we also have the plan to totally remove running flows cache from web server, and to make the updater thread much cleaner and easier to maintain in the future.\n. @juhoautio \n\nActually finished in what sense? Do you mean that they have some finished status in the DB, but azkaban-web still thinks they're running? If so, that's a corner case that is more about dispatching than about getting updates, and should be handled separately.\n\nYes, they have finished status in DB but on the \"Currently Running\" executing flows page, they show up as Running status. And when you click the execution, it shows as finished status. The root cause of this inconsistency is the getting updates. Even if users do not submit the flows again, the inconsistency issue itself still exists, visible from the UI page.\n\nThis way new executors are automatically taken into use without having to restart azkaban-web\nBut is it possible that people would not want this to happen in some cases? If so, it would be better to change executors so that they don't automatically activate themselves, because there could be other reasons to restart azkaban-web while not being aware that there are new executors in the DB that shouldn't be taken into use yet.\n\nRight, for example, when we do deployment, we have the last step to reload executors from DB (update activeExecutors cache), but only after the deployment is successful and integration tests run successfully. I think refreshing executors should not happen automatically.. Hi @juhoautio \n\nBut if there's too much delay currently (by the updater thread) maybe the page should be optimized to get the running executions directly from the DB somehow. \n\nThis is not just a matter of delay, the inconsistency of flow status remains all the time until the web server is restarted. This is also part of the reason why we prefer to totally remove the running flows cache and instead, getting it from DB directly. Anyway, this would require some changes in the updater thread.\n\nOk but wouldn't it be safer then that executors wouldn't automatically add themselves to the DB? Or they could add but as inactive only.\n\nTrue. I might not have explained it clearly. Actually when a new executor is deployed, we do the validation first and then set the executor to active, and finally reload the executors. It doesn't require restarting of web server.\nWe'll let you decide how to design and implement the changes since you already have much knowledge about it. It would be great if you could figure out a proper way to test the changes as well.  Thanks!. I added some Todo notes in the code about the remaining steps:\n1. Cancel all pending jobs before the flow is finalized and execturorService is shutdown. This is mainly to support ONE_SUCCESS and ONE_FAILURE conditions because the flow could potentially finish before all running jobs have finished. This would cause jobs to run forever if not canceled properly.\n2. Support conditions on embedded flows.\n3. Validation on conditions.. Yes, UI part will be added later when all the main logic has been implemented. \nUsers will be able to click the job and see the condition for that job like the current job properties.\nYou can see more details in the design doc: \nhttps://docs.google.com/document/d/1op_RPD1G65NpKsunAv04Rww5klU7AhbqnPMA0QunP0g/edit?usp=sharing. Thanks for fixing this NPE issue. I was about to submit a similar PR to fix this. In addition to this check, we might need other checks where the conditionOnJobStatus were used. I'll double check other places and fix them if necessary. . For this fix to get in, you might have to add a unit test, otherwise the code coverage check would fail and block the check-in.. Thanks. One thing to clarify, the end node doesn't have to define condition on job status. As long as there is node in the flow which has defined one_success or one_failed condition, this PR could apply.. This is part of the conditional workflow design - #1826. In phase one, we will roll out changes for condition on output props. Will see if there is any need for condition on job props to roll it out in the next step.. Hi @huaxuehuaxue, thanks for trying out this new feature.\nIs it the test case runFlowOnJobPropsCondition? I'm not able to reproduce the same error locally. How often do you see this and did you see it on the latest master?\nIt would be great if you could provide me more logs so that I can debug this issue. Thanks!. Hi @huaxuehuaxue, you can put the command echo {\"param1\":\"1\"} > $JOB_OUTPUT_PROP_FILE inside a shell script e.g., write_to_props.sh and change the original command section to command: bash ./write_to_props.sh. For the command job, it seems the redirect output function is not implemented in our process builder currently. So I would suggest using the shell script instead. I'll modify the documentation as well. I've attached a sample zip as well. \nwrite_to_output.zip\nLet me know if you see any other issue. Thanks again for trying out this new feature!\n   . Verified the changes on staging cluster and approved by the security team.. @HappyRay I remember last time we were talking about the upload project issue caused by inconsistency of project cache and DB table. \nI agree the project should be deleted instead of setting it to inactive. I couldn't think of the case where inactive projects will be needed.. @kunkun-tang I've thought about this and not sure if it has any use case now. If needed, we can always enable it later.. Approved by security team as well.. @HappyRay @juhoautio \nYes, I agree. It should be renamed to FlowRunnerYamlTest.\nFor this flaky test, I remembered fixing it before by extending the job runtime of jobC because the kill sometimes takes a long time. https://github.com/azkaban/azkaban/pull/1847\n I haven't seen this failure for a long time so I thought it was fixed. But anyway, thanks for pointing out this failure. Do you think we should extend the time more or any other better idea?. @juhoautio @HappyRay \nThanks for the comments. I've submitted a PR (https://github.com/azkaban/azkaban/pull/1923) to address those concerns.. @juhoautio Thanks for reporting this issue. When killing happens, jobC was not even added to activeJobRunners even though it was already submitted. We've seen this race condition in killing flows before and it would take much effort to completely fix it. I would disable this test for now to unblock the travis build. With the new DAG engine design, we should not see this kind of issue again. \n2018/09/06 14:02:37.544 +0000 INFO [FlowRunner-exec-116] [basic_flow] Submitting job 'jobC' to run.\n    2018/09/06 14:02:37.540 +0000 INFO [Test worker] [basic_flow] Kill has been called on flow 116\n    2018/09/06 14:02:37.544 +0000 INFO [Test worker] [basic_flow] Killing 0 jobs.\n    2018/09/06 14:02:37.545 +0000 INFO [JobRunner-jobC-116] [basic_flow] Created file appender for job jobC\n    2018/09/06 14:02:37.545 +0000 INFO [JobRunner-jobC-116] [basic_flow] Attached file appender for job jobC\n    2018/09/06 14:02:37.545 +0000 INFO [JobRunner-jobC-116] [basic_flow] Job Started: jobC. I think so. I remembered seeing a similar issue before in #1311.  . @juhoautio  Actually, I rethought about this and want to make some changes to this PR:\n1. If we want to use failJob() or succeedJob() in the InteractiveTestJob class, we need to wait for failJob() or succeedJob() to finish and call notify(). If we set the sleep to 0, it means no wait and the job could finish early even before calling failJob() or succeedJob(). The default sleep time is 10 seconds and it should be sufficient enough for the method call to finish. We don't need to worry about the sleep time here because it won't actually take that long. \n2. If we don't want to use failJob() or succeedJob(), and just want to wait for the job itself to complete, then we need to explicitly set the sleep time and the fail key in the config. E.g.:\nconfig:\n      fail: false\n      seconds: 0\nIt means the job will succeed in 0 seconds.\nSo I plan to remove the sleep time for the job which I will call failJob() or succeedJob(). Otherwise it might still cause problems in the future.. Thanks @HappyRay for the suggestion. I can definitely see the efficiency and convenience of the test cases for dag engine.\nI think the reason why the original InteractiveTestJob seems a little complicated is that it's trying to provide multiple options:\n1. Explicitly fail or succeed the job like what dag engine test does in markFailed or markSuccess.\n2. Also, it wants to allow the job itself to fail or succeed after a certain duration of time by providing the fail and seconds parameter in the job configuration.\nBecause of the second part, it adds the wait loop which complicates the logic a little bit. If we don't need the second part, I think it can be simplified. However we cannot get rid of it easily becasue many existing test cases are still using it. \nI agree for new tests it's preferable to apply some new test framework.   . @HappyRay, see my comments in #1921:\n\nWhen killing happens, jobC was not even added to activeJobRunners even though it was already submitted. We've seen this race condition in killing flows before and it would take much effort to completely fix it. I would disable this test for now to unblock the travis build. With the new DAG engine design, we should not see this kind of issue again. \n2018/09/06 14:02:37.544 +0000 INFO [FlowRunner-exec-116] [basic_flow] Submitting job 'jobC' to run.\n    2018/09/06 14:02:37.540 +0000 INFO [Test worker] [basic_flow] Kill has been called on flow 116\n    2018/09/06 14:02:37.544 +0000 INFO [Test worker] [basic_flow] Killing 0 jobs.\n    2018/09/06 14:02:37.545 +0000 INFO [JobRunner-jobC-116] [basic_flow] Created file appender for job jobC\n    2018/09/06 14:02:37.545 +0000 INFO [JobRunner-jobC-116] [basic_flow] Attached file appender for job jobC\n    2018/09/06 14:02:37.545 +0000 INFO [JobRunner-jobC-116] [basic_flow] Job Started: jobC\n\nYou might still remember the original race condition issue we discussed in #1311. I proposed a fix before but it could not completely resolve this issue so I aborted it. I think you might have some fix for that? Anyway, this would not be a problem once we change to the new DAG engine model. \nI can create a ticket to track this issue internally.\n. There were several potential race condition issues we discovered at that time.  #1310 addressed one of them. I think there is still one issue remaining as mentioned in the change description:\n```\nScope of the fix:\nThis fix only addresses the synchronization issue between the killing Jetty thread and the jobrunner thread. It doesn't address the potential synchronization issues between the killing thread and the flowrunner thread e.g. There may be still some other race condition that causes a kill action to not kill a running job.\n``\nI don't remember all the details. But I can take a look at it and try to refresh my memory. . @codedebuger Thanks for reporting this issue.\nCan you provide more details about this issue, maybe capture some exception logs? Also feel free to suggest any solution.. I think it makes sense to set some higher threshold for codecov.\ncc @kunkun-tang . How did you verify the change of log size reduce?. I agree it is not worth logging on WARN level for.jor is empty` since not all jobs have the override property. However, this also logs for normal job/properties file if they do not exist. Do you think it might be helpful for debugging or can be totally removed together? . What's the ultimate goal of detecting non-retriable errors?. Hi @juhoautio, I still have some questions: \n\nTo not accidentally dispatch the same execution multiple times in parallel (on different executors)\n\nCan you give an example of how this scenario could happen? \n\nFor the dispatching queue to not get stuck too long in trying to dispatch one problematic execution.\n\nBy default, azkaban.maxDispatchingErrors is set to the number of active executors, which is not a big number. I don't see a problem here at least for our system. Is it currently a concern for you guys?\n\nTo not give up dispatching an execution just because the executor that was tried is shutting down\n\nWeb server should always pick the best executor based on the capacity, CPU or memory info on all the available executors. If an executor is shut down, then the web server could not get any update from it and would switch to another executor and dispatch. Isn't that the current behavior?\n. > Now, to fix this properly, az-web should actually check the DB after a failed request\nDo you mean checking the flow status in the DB? It might still be in PREPARING status at the time when the check happens if there is any delay in starting the flow on the executor.\n\nThe other executor wouldn't know to return ALREADY_RUNNING any way, so having ALREADY_RUNNING doesn't help against protecting dispatching the same execution on multiple executors.\n\nTrue.\n\nBecause this way dispatching of scheduled executions won't be skipped if we have executor downtime that isn't resolved before a few hours. \n\nIf one executor is down, there are still other available executors ready for dispatching. If all of them are down in the worst case, the scheduled flows won't be executed during the downtime for sure. It reached handleNoExecutorSelectedCase and the flows will still be enqueued. Once the executors are brought back to normal, the missed executions can still be picked up from the queue. \n\nRelated issue is that az-web doesn't currently support catchup of scheduled executions if az-web itself has been down. \n\nRight, the scheduled executions will be missed during the downtime of az-web.\n\nFor completeness az-web should recognize that error type as \"forever retriable\" ie. keep trying to dispatch for next executor until it finds one that isn't shutting down :) \n\nEven if the error type is not specified, az-web will still try to dispatch for next executor until it finds the available one. If in the extreme case where all the executors are down and az-web still tries to dispatch to them, then the flow will be finalized in the end. I'm not sure if that's the scenario you are concerned about.\nWe've always wanted to simplify the dispatching logic and the updater thread behavior. If there are so many corner cases we need to consider and patch fixes on top, it might indicate that the original design itself needs to be changed towards some other direction.\n. @HappyRay\n\nI thought the scheduled executions were saved in DB and will resume after the web server is back. \n\nThis is true for the already scheduled executions (those already been added to queuedFlows but haven't been dispatched yet). The queuedFlows will be reloaded when web server is back. But during the downtime of web server, the scheduling piece is also down, who will actually do the work of triggering flow executions? If no flow execution is triggered, how can they be loaded back later?\ncc @kunkun-tang Correct me if I misunderstand it.\n. @juhoautio To be more specific, does the timing issue happens when azkaban.project.ProjectLoader#fetchProjectMetaData is called to fetch the project version but that specific version has already been deleted due to new project uploads? \nWe haven't seen this kind of issue before, but would like to know how often this would happen.. Hi @juhoautio, I have a few questions: \n\nIt only happens if there's a significant delay in dispatching (and on the other hand many project uploads in the meanwhile).\n\nWhat would cause the significant delay? Is it possible to solve the delay problem itself instead of fixing it in deleting project versions?\n\nWhat makes the issue more prominent in our setup is that we have implemented moving existing executions from an inactive executor to an active executor. \n\nBy inactive executor, do you mean the executor is still running but the active flag is set to false in DB? Why do you need to move executions from inactive executor to an active executor?. Sure, I'll include that info in the documentation. Thanks for answering that question. @HappyRay . After enabling the configuration of azkaban.use.multiple.executors on solo-server, it still cannot be started because of below exception:\n2018/10/23 16:15:53.933 -0700 INFO [AzkabanWebServer] [Azkaban] Azkaban Exec Server started...\n2018/10/23 16:15:53.933 -0700 INFO [ExecutorManager] [Azkaban] Initializing executors from database.\n2018/10/23 16:15:53.934 -0700 ERROR [ExecutorManager] [Azkaban] No active executors found\nException in thread \"main\" azkaban.executor.ExecutorManagerException: No active executors found\n        at azkaban.executor.ActiveExecutors.setupExecutors(ActiveExecutors.java:52)\n        at azkaban.executor.ExecutorManager.setupExecutors(ExecutorManager.java:243)\n        at azkaban.executor.ExecutorManager.initialize(ExecutorManager.java:156)\n        at azkaban.executor.ExecutorManager.start(ExecutorManager.java:181)\n        at azkaban.webapp.AzkabanWebServer.launch(AzkabanWebServer.java:231)\n        at azkaban.soloserver.AzkabanSingleServer.launch(AzkabanSingleServer.java:118)\n        at azkaban.soloserver.AzkabanSingleServer.main(AzkabanSingleServer.java:96)\nIn solo server mode, when launching the executor, it takes some time for the executor info to be inserted into DB. However before that happens, web server has already started to check active executors from DB and if fails with  No active executors found exception.\nNot sure why this happens now. @juhoautio I think you only refactored the executorManager but haven't changed the original logic right? Do you have any idea why this starts to fail now?. Closed this PR. Merged #2003 instead.. You can attach some screenshots to demonstrate what the UI looks like with the new change.\nAlso mention the new change will apply to both flow 1.0 and flow 2.0.. I think your first point is to address the case where an execution has been submitted successfully and is indeed running, but web server thinks it fails to dispatch due to some network error. In this case, I doubt it really makes any difference whether it throws an exception or just return OK because anyway web server cannot receive the response because of the network issue. And it will finally give up dispatching when it reaches max dispatching error.\nThe second point addresses the case where an execution is added to running flows cache but failed \n to be submitted to executorService. It doesn't make much difference to me that whether it throws an exception with \n\nExecution is already running\n\nor \n\nExecution is in runningFlows but not in submittedFlows\n\nOne thing to let you know beforehand, we are working on a new design of executor polling model instead of web server pushing model. I'll share with you the design doc once it's done. . Detailed design doc: https://docs.google.com/document/d/1sSH70fPBB1mnwIBAmJrGgT_PCOl1UEdJMJe9m_ouw80/edit?usp=sharing. Hi @seayoun, good question. In the poll model, executors poll from DB in a round-robin fashion. They don't calculate complicated factors before polling. The logic is simplified and proves to be working properly in our staging environment.\nWe have a section discussing this part in the design doc. Feel free to check it out: https://docs.google.com/document/d/1sSH70fPBB1mnwIBAmJrGgT_PCOl1UEdJMJe9m_ouw80/edit#heading=h.l6p0a36sbeth . Please also mention in the change description that this issue happens to embedded flows only. Also you can give some examples to explain the issue so that others could understand it better.. Since the current OOM issue can be temporarily relieved by restarting web server, I'll move the code in this PR to the ExecutionController module in the new AZ dispatching design without touching the current ExecutorManager code. . Yes, it will become obsolete if we switch to the new dispatching logic.. @burgerkingeater \n\nwhat if same flow's two executions get polled into two different executors and the flow is disallowing any concurrent run?\n\nIf the flow disallows concurrent run, web server won't be able to insert two executions into the DB as the check is done in submitExecutableFlow on web server side. . Thanks for adding this feature! Now the failed job lists will be expanded by default. Do we plan to support collapsing all the job lists as well?   . Overall LGTM. It'll be better to add some details in the change description, i.e., mentioning the original issue, any testing done, or action items after checking in this change. . @HappyRay I've removed the hardcoded year and replaced it with the current year. Can you explain a little more about your question?  . Thanks, updated the description with more details.. This is the expected behavior of the original design. The uploaded project zip is kept in storage and won't be overridden by any job/flow override action from web UI. . Good to know that applying the indexing on status solves the problem. \nFrom your result, there doesn't seem to be much difference between fetching full data and metadata. If that's the case, then it should be ok to just fetch the full data. . @seayoun \nThe PR checks failed because the code coverage decreases with the PR. Basically it is reminding you to add more unit tests.\n\n@@             Coverage Diff              @@\nmaster    #2099      +/-\n============================================\n- Coverage     33.52%   33.37%   -0.15%   \n+ Complexity     2758     2756       -2    . @burgerkingeater \nPR #2080 makes executors send alerting emails when flows finish. \n. Hi @seayoun , if azkaban.poll.model is off, it defaults to the current pushing model where web server is responsible for choosing an executor and dispatch the flow.\nAre you talking about handling executor failure when azkaban.poll.model is on? If yes, you can check out this PR #2098 and more details in the design doc #2038.. It is the user who can really decide whether they want to re-run the flow. For example, some Hadoop job applications might still be running in Hadoop cluster when the executor crash happens. If Azkaban relaunches the same flow automatically, it might cause conflict for the user jobs (Some jobs don't allow concurrent runs). Azkaban will be responsible for failure detection and flow status recovery(finalize the flow if its executor is removed from DB), but leave the choice to users whether to re-run the flow or not.. Do we need to test diffProperties?. The if clause starting in line 350 actually applies to both default and custom plugin jobtypes. If changed to if else structure, then for default jobtypes, this part will be skipped and jobProps will not be populated for default jobtypes.\n . In order to use ${azkaban.job.id} in job file or common.properties file, we need to resolve this variable when building job types. This happens earlier than configuring the JOB_ID in the jobProps. So at the time when it's building job types, it cannot find JOB_ID.\n\n. It is called in handlePurgeProject. A project is active means the boolean active is set to true in DB for that project. I'll add some comments about it.. loadAllProjectFlows() will set the Map flows for the project. getProject() is called in so many places, not able to enumerate them all...Most of them (>90%) will need to get the flow info, probably not all. . The output of System.out will be redirected to a local file. This is already implemented for all other unit tests. . Intellij gives this warning saying variable 'project' initializer null is redundant.  It will be assigned value later in project = projects.get(0); It there is any exception, then we don't even need to return project.. SELECT_ACTIVE_PROJECT_BY_NAME is used when creating a new project.\nI also doubt whether we really need to return inactive project. In the future we can probably change the logic to remove inactive projects totally and only return active one. But for now, I just keep the existing logic in case something is breaking.. Intellij will give some optimization suggestions like the initialization is redundant and should be removed.. It is used in handlePurgeProject() which will do the actual cleanup of the projects. If the project is still active, then it will return some error saying the project should be deleted before purging.. Different threads may be creating and deleting the same directory simultaneously, causing some inconsistency issues.. Thanks! This is very helpful. Seems much easier to implement. I'll give it a try.. For different tests, the project names and descriptions are different. Might not be easy to combine those together?. azkaban.project.JdbcProjectLoader#createNewProject(java.sql.Connection, java.lang.String, java.lang.String, azkaban.user.User) will throw the same exception.. I'll remove this after using the junit tempdir support.. Changed.. Removed.. Changed.\n. done.. It seems there is no 'update' sql. Do we still need to exclude that?. No, we don't have it. When a flow is inactive, we just remove it from DB. We don't keep inactive flows info in DB.. Yes. . Will this confuse with getExecutableFlows()? In the future, queuedFlows will be totally removed, so getRunningFlows will only return runningFlows.. Same comment as above.. It's called in getExecutableFlows().. Both web server and executor will update active_executing_flows.. You are right. fetchJobInfoAttempts is never used. Also I double checked fetchNumExecutableFlows. Actually fetchNumExecutableFlows(int projectId, String flowId) is used but fetchNumExecutableFlows() is not. I'll remove the unused ones. . Just curious what is the intention/benefit of launching from server instance instead of props here?. Should expireCondition be final? . Do we need to set the members to final like submitTime, submitUser ...? They are only used by getter method. . Fixed. Thanks!. Yes, tried reducing to 1s and it also works.. I agree. It's better to use Mockito to mock the executor loader. Currently this class is used in many test cases, but we can gradually retire it in the future.. Yes, I also noticed that. Plan to do it in a separate pull request.. This assert is not inside setupDB(). It's in a separate test case.. Yes, in order to run all these tests in JdbcExecutorLoaderTest class locally, we need to modify the database, user and password to match our local mysql setup. In Travis, all the tests will be disabled because DB is not set up. Once we change it to in-memory database later, this JdbcExecutorLoaderTest class will be refactored and the tests won't have this setup limitation.. Yes, from the return type it is able to figure out. If you explicitly put the type ArrayList, intellij will suggest you to remove it. . Yes it sounds better. For now I just want to keep consistent with the rest of naming in this class. It is good to rename them all together in the future.. I added this comment in case readers have doubt about the query performance. . Thanks! : ). Changed. Thanks!. Yes, I've tried using DateTimeUtils to set end time in the past, and it works. Thanks!\nIn line 890 within the same test, it is the positive scenario where it successfully fetches the recently finished flow. I will split the two tests for clarity.. I did not add this executor_id index. It's the same as the previous code. I guess it's showing as different because of the endline mark.. Changed. Thanks!. Changed to error(Object message, Throwable t). I think it's ok to just keep the existing behavior to return an empty list if it fails to fetch recently finished flows. What is the intention of returning a server error?. That's also an option. But I think it's a little hard to decide the exact number limit for all clusters. On some clusters we might want to display more? Also I guess users have already got used to look at the flows finished in last 10 mins?. I'll modify the comments. It's a little confusing I guess. So the executor mode will not be broken after this change. Before this change, the inconsistency issue already exists between active_executing_flows and executionf_flows table. After deprecating active_executing_flows table, this issue will be exposed in single executor mode when dispatch fails. So it is necessary to set the flow status to FAILED in execution_flows table when dispatch fails.. In this PR, I'm only making the change not to read updateTime from active_executing_flows table when fetching active/queued flows. Plan to do the actual removal in a separate PR. . Will fix it, thanks!. Because currently there are 13 statuses in total. 3 of them are finished statuses. So it's more concise in the query to just exclude the finished statuses.  . In updaterThread, the original intention of this code was to delete the .cache file for the flow when it succeeded. However, there was some bug and flow.getScheduleId() was always -1 and never updated correctly. So .cache file was never deleted once created. So I removed this code and simplified the logic in updaterThread.. Maybe also remove cancelNameNodeToken() in line 405 since it's not used?. Is there a reason why the submitUser is explicitly set to \"azkaban\"?. Yes, it will try 3 times with 30 sec timeout interval, so the total would be 90 sec.. We also get exceptions like \"java.net.SocketTimeoutException: Read timed out\". In this case, if we extend the timeout, it would increase the chance of a successful retry.. This method doesn't seem to be used. Could be removed later.. Same comment as above.. Same comment as above.. Should the string be \"Password\" with capital letter \"P\" ?. Why passwordPlaceholder is added in AbstractAzkabanServlet instead of LoginAbstractAzkabanServlet?. These metrics are for executorManager, and executorManager is in azkaban-common. Unless we refactor executorManager and put it in web server, I cannot think of a way to do that properly.. I agree. All the metrics should be refactored in a separate pull request. . Refactored using Guice, thanks!. Agree, thanks.. Thanks for the comments. I want to remove this method also because it's using clientHostname, clientPortName and usesSSL, which are props that don't have default values. Alternative way would be to provide default value for all those three props, but since this getReferenceURL is not used anywhere in the code, I think it's safe to remove. I've tested it on localhost and it works properly.. What does this serialVersionUID mean? Is it used anywhere?. What do you think of adding some errorMsg in the page if a user without ADMIN permission tries to access this page?. When will this throw TriggerManagerException?. If someone enters some invalid parameters in the API call, it will just remove the note right? For that reason, I think it would be better to verify else if (ajaxName.equals(\"removeNote\")). It seems we already have similar method which does the permission check: azkaban.server.HttpRequestUtils#hasPermission. Can we reuse it instead of creating a new method?. What would happen if update throws SQLException here?. Never mind. Just realized it was handled below.. Consider also comparing flow status? I think it's needed for testUpdateExecutableFlow.. Just add a note here:\nThis part of the code is duplicate in multiple places in the code base now. When you do future refactoring, can you also improve it?. In the new code, are we not doing loadTableInfo()? And inside updateDatabase(), it seems there is no updateTables(). Are they removed intentionally?. Should it be assignExecutor(1, flow.getExecutionId())? Also how do you know 1 is a non-existent executor?. Similar to above comment. Need to switch the two arguments.. Would you mind also adding the example for \"mail.jetty.port\"?. This part of the code is the same. Just moved it to a separate method.. It's a good idea to introduce Awaitility in the tests! . Is one second not long enough for the job to get into delayExecution()? I've never seen this test case failing in my local branch, so I'm wondering if this sleep time needs to be longer?. After increasing the sleep time to 2s, I can understand that (node.getStartTime - startTime) is changed, but why is (node.getEndTime - node.getStartTime) also affected?. I'm specifying the flow version here in case we have more versions in the future like AZKABAN_FLOW_VERSION_3_0.. Yes, this AzkabanFlow will only apply to flow.2.0, and we still need to keep backward compatibility. . Agree, thanks!. Probably not needed. I'm just following what the current code is doing for .properties files.. I agree with changing 1s to 2s in the sleep time. But the check in line 305 seems to be independent of this change. The job is configured to run for 1 sec in createJobRunner(1, \"testJob\", 1, false, loader, eventCollector);, so I think the original intention was to check whether the job finished within 1 sec. Also it seems it used to be Assert.assertTrue(node.getEndTime() - node.getStartTime() < 1000); from the link you shared?. Found one internal team is using this method. Will coordinate with them about the migration solution.. Do we need to specify the the prefix like dependency. or schedule. ? In the yaml file, I'm expecting it to look like this:\ntrigger:\n  schedule:                    \n    type: cron\n    value: 0 0 1 ? * * \n    max.wait.time:  \u2026. \n  dependencies:           \n    name: search-impression # an unique name to identify the dependency\n    type: dali-dataset\n    params:    \n        view : search_mp_versioned.search_impression_event_0_0_47 \n        delay :1\n. Do you think it's better to name it like DataDependency or TriggerDependency? Because we already have similar naming for some other concepts like job dependency or flow dependency. . I think it's better to print out the errorMessage for checkNotNull as well.. When converting yaml file to FlowTrigger, it would be convenient to have a setDependencies(final List dependencies) method. Do you mind if I add one later and change some of the code in the FlowTriggerBuilder? Or do you have any other suggestion?. Why don't we also have name and type fields for Dependency? Would that be more convenient than getting it from props every time?. Does it matter if the sequence of the props changes but the actual contents are the same? Will it be detected as duplicate?. Consider adding a test to validate schedule props?. Here prop doesn't have to be exactly the same. It can just inherit the parent prop. I think either way is fine. I didn't change the original implementation here, just moved it to a new method.. Actually, flows can be mutable. When uploading project in db, it will set the project id and project version for all the flows in the project. See azkaban.project.AzkabanProjectLoader#persistProject. With the new change, there won't be any default validator. Anyway it will return null if you try to get the default validator from validators map. We plan to deprecate getDefaultValidator() method.. I can put deleting temp directory to a finally block. But for cleaning up old project installations, it should happen only when uploading new project is successful. . I'll change it to ImmutableMap since only the value inside flow object will be modified, but the map itself won't be modified. Thanks!. Already discussed with the team and they agree to use the old azkaban common module jar while we are developing new features. When the Flow 2.0 DSL change is rolled out, they will migrate to the new implementation or we provide some external API to them depending on the number of use cases then. . Will change it, thanks!. I don't think it's a user-facing contract. It is used for displaying the error/warn messages to users when there is something wrong in uploading projects. It used to be: public static final String DEFAULT_VALIDATOR_KEY = \"Directory Flow\";. I just want to keep the same UI display.. Will remove, thanks!. Will remove it, thanks!. Since this method is overriding the one in ValidatorManager interface, we need to remove both together. Currently I put @Deprecated in azkaban.project.validator.ValidatorManager#getDefaultValidator, but I think it's ok to remove it entirely. . Will do, thanks!. This part is the same. Just moved the original code to a new method. . This part is the same, just moved to a new class.. It seems not recommended to use protected static class. If needed in the future, we can move this suffixFilter to a util class.\nhttps://stackoverflow.com/questions/24289070/why-we-should-not-use-protected-static-in-java . Different flow loader will be created runtime based on the manifest file inside project zip. It would be difficult to guicify it in AzkabanCommonModule.. In this test case, I just loaded one .flow file. I've added a new test case to load all .flow files from the directory.. Yes, for flowVersion 1.0, we don't need to specify the version. It will just be null. This is to keep consistent with current implementation. Only for flowVersion 2.0 onwards, we need to specify the flowVersion in manifest file.. We will validate the flow yaml file in FlowBeanLoader which loads the flowBean to azkabanFlow. azkaban.project.FlowBeanLoader#validate. This validation part will be implemented later.. Version_2_0 seems better, I'll change it.. Good idea, I'll move this logic into the loader class.. Sure, I'll change it.. Will change, thanks!. It is used to check the job properties like memory size, and job callback related properties. http://azkaban.github.io/azkaban/docs/latest/#common-configurations. We only need one FlowLoaderFactory instance, so I think it can be singleton. Any reason not to use singleton here? . Yes, I'll change it to \"dependedBy\" in a separate PR later.. I've enabled saveAction, but it doesn't seem to fix this automatically. I'll add the new line manually.. I've thought about using composition. However, I don't think it will benefit from using composition in this case. Flowloader does not actually have any major implementation of loading project flows. So even if we add it as a reference inside DirectoryFlowLoader and DirectoryYamlFlowLoader, it doesn't make any difference. I think the better way to do it would be to change FlowLoader to an interface with one loadProject method inside. Then DirectoryFlowLoader and DirectoryYamlFlowLoader can extend the interface and implement their own loadProject method. We can move some common method like addEmailPropsToFlow to some util class. What do you think of the new approach? We can discuss it offline.. The link is probably not necessary. I'll remove it. . Sure, I will add the heading.. We want to return as many validation results as possible to users, including the errors found in loading project. If there is any error during validation or loading project, we will just return the report and not save it to DB. So I think this should be safe.. This name has to match what is defined in the flow YAML file. Since a node can either be a job or a sub-flow, I think it would be ok to have a generic name here. . Originally I thought it was easy to implement because both parent flow and embedded flows could be loaded to azkabanFlow in the same way if we define the same structure. But I think from user's perspective, it would be redundant info if we put type flow here. Same as the flow name. I'll remove it in a separate PR, thanks!. Sure, I will add it in a separate PR.. @HappyRay Submitted the changes in another PR https://github.com/azkaban/azkaban/pull/1531. Can you take a look?. Yes you are right. I'll move it inside ConfigurationKeys class.. Will change to double, thanks!. What's the advantage of doing it?. Uploading flows to DB project_flows table. \narchive.getName is the project zip name. The logging message is not very clear.. Since the type of AzkabanFlow can only be \"flow\", is there a need for it to be passed from outside?. Good question. Several reasons why interface is a better option here:\n1. The two classes don't share common implementations. They need to implement their own method loadProjectFLow in their own different ways. So defining the method in the interface should be sufficient.\n2. Some variables might be common to the two classes but some are not. If we need to add a new type of FlowLoader, it won't necessarily share the same variables. In this case, making it abstract class for sharing common variables might not be flexible.\nActually in my previous PR, I used Abstract class first and then switched to interface. You can refer to the discussions below:\nhttps://github.com/azkaban/azkaban/pull/1500/commits/30744ec9e375f03ce12525e64b50d2c8b1899f21#diff-33dbf7e0198cf8b60e328d5fde7921acR35. Thanks for the suggestion. I'll consolidate the common check statements.. Actually it happens in two steps, parsing the YAML file to AzkabanFlow first and then converting AzkabanFlow to Flow object. In this case, parsing the YAML file is successful, so we can identify the nodes. However, when converting AzkabanFlow to Flow, we resolve the dependency and detect an error. The error will be returned back in the report showing something wrong in the flow to users.. Thanks! Will fix it.. There is no restrict naming convention for the YAML file. But I found \"key-name\", \"key_name\" and \"key name\" are valid formats from below links:\nhttps://learnxinyminutes.com/docs/yaml/\nhttp://ess.khhq.net/wiki/YAML_Tutorial\nhttps://bitbucket.org/asomov/snakeyaml/wiki/Documentation#markdown-header-yaml-syntax\nAlso I think \"azkaban.flow.version\" might be a little confusing since users might think it means the actual version of a flow file.. If listFiles returns null, we should throw Exception. I'll change it, thanks!. I will use try-with-resources to handle the closing of the input stream.. I don't think it's necessary to have a default version. If project YAML file exists but doesn't specify the version, then there should be something wrong with it and we should not arbitrarily parse it.. ProjectDir is a temp dir that's created to unzip the project zip and will be deleted after used. So I don't think we need to print it in the message.. Sure, I just submitted the changes to consolidate the test case. Thanks for the comment!. Added the test case, thanks!. 1. When we upload a new project zip, projectVersion will change.\n2. Say the project has two flow yaml files. If one yaml file changes and user uploads a new project zip, then flowVersion will change for both yaml files. If one yaml file is changed through UI override, then we only change the flowVersion for this yaml file and won't affect the other one.  . FlowVersion will not increase because the big file is not uploaded to DB. \nUser will first query DB to get the latest flow version (will be implemented in the next PR), and then call this method to upload new version of flow file to DB. This file length check happens before the uploading DB operation.. I've thrown ProjectManagerException here. What's your concern?. Yes, in our current DB table, flow_id/flow_name is 128.. The difference between the two approach is that one will return Collections.emptyList and the other will return new ArrayList<>() if the query result is empty. And there is some performance advantage of returning emptyList:\nhttps://stackoverflow.com/questions/5552258/collections-emptylist-vs-new-instance\nAlso, it is a commonly used approach in our current code, so I just followed the convention.. Thanks for sharing the knowledge. I think truncate is better in this case.. They don't have exactly the same arguments, but I'll try to align them.. The name of uploader is already persisted in project_versions DB table. See azkaban.project.ProjectLoader#changeProjectVersion.. Will make the change together with next PR.. For embedded flows, the flowName is encoded with delimiter \":\" internally and it's different from the azkabanFlow name itself which is mapped directly from the flow yaml file. For example, an embedded flow \"embedded_flow1\" inside parent flow \"simple_flow\" would have \"simple_flow:embedded_flow1\" as its flowName as compared to the azkabanFlow name \"embedded_flow1\". This is to distinguish embedded flows with same names inside different parent flow files.. I'll improve it, thanks!. Name is enough because all the flow yaml files are under the same project directory. And we can retrieve the flow file from DB based on their names. We don't need to support subdirectories in the new design so there is no need to specify the path. Even today we store .job and .properties file name as the source instead of the path.. Will change, thanks!. Yes, will rename.. Will getFlowTrigger be called together with getProps? If not, then we need to store the parsed nodeBean somewhere if you want to reuse it. But this might not work well if someone overrides the yaml file. I think reading the yaml file from DB and parsing the file is necessary since the file could potentially change. Also I think parsing the yaml file to NodeBean is straightforward and shouldn't be costly. Correct me if I'm wrong.. Where would this be configured? In azkaban.properties?. If it's really needed for optimization in the future, we can split this method into two parts. But again the main concern is the flow file itself might change, it is better to read from DB directly instead of caching the parsed value in nodeBean.. Name should be good.. Below code in the else condition is the same, just copied over.. Will change, thanks!. Thanks for the suggestion. I can remove \"set\" in the method name.. Because there are two key-value pairs for schedule in YAML file: \n  schedule:                  \n    type: cron\n    value: 0 0 1 ? * * \n . ok.  Yes I can add the support for no triggerDependencies. Also do we need to support no params case?. Yes, here it's job prop.. Because if prop is null, below method prop.getKeySet() at line 716 would throw null pointer exception.\n. Here this overrideProp is for job override to keep consistent with the current implementation. But you are right, we can support overriding flow properties in the same way as well.. Yes, we can store the actual flowVersion so that it can be extended to support future flow versions like azkabanFlowVersion30. . The content of this method remains the same, just moved from DirectoryFlowLoader to the common util class FlowLoaderUtils, which is used by both DirectoryFlowLoader and DirectoryYamlFlowLoader.. Agree. I'll change it to flowFileName.. FlowName actually refers to the flow file name, not the flowId. The name seems a little confusing here.. Thanks for pointing it out! I think creating a temp dir might be better because the file name has to be specified as the flow name which is used during parsing of the flow yaml file. . Good catch!. I'm ok with either order. I chose this argument order based on the sequence in the project_flow_fiels DB table. \nproject_id | project_version | flow_name | flow_version | modified_time | flow_file. Agreed. Changed to public jdk libs. \nAdded the exception handling for failure to create temp dir.\nThanks!. Refactored some of the code and handled the deletion of temp dir.. Yaml parser can handle empty file. But we still need to explicitly check the parsed result is not null.. I've refactored the code in a new commit. Thanks for all the comments!. This is to delete the tempDir after the returned flow file is no longer used. We cannot do the deletion inside this method because we still need to reference the flow file in the tempDir.. There are sleep intervals for mailTimeout and ConnectionTimeout:\n    final int mailTimeout = props.getInt(\"mail.timeout.millis\", 30000);\n    final int connectionTimeout =\n        props.getInt(\"mail.connection.timeout.millis\", 30000);. Would it be helpful to keep logging messages for sending sla email somewhere for debugging purpose?. We already have azkaban.utils.EmailMessage#sendEmail method. Consider another method name to avoid confusion?. As you mentioned, this would be a more general method used also in other places like the flow trigger. How could we distinguish whether the email message is for sla or flow trigger then? . 1. We need to create the separate temp directory for each flow file to avoid overwriting the same file by multiple threads concurrently. And the reason why I create temp directory instead of temp file is that the file name will be interpreted as the flow name. And a temp file name is basically some random string combination, so we cannot use.  I've left some comments in azkaban.project.JdbcProjectImpl#getUploadedFlowFile.\n2. Do you mean combining createTempDir and getPropsFromYamlFile in the same try-catch block? The reason I'm separating them out is for clear logging and debugging under different exceptions. But you are right they can be combined together, in this way, we will combine the logging message together as well.. I'm ok with either name.. Will consolidate the code, thanks!. Currently no, you need to retrieve it from Flow. Any reason you want to get it from Project?\nThe default value of azkabanFlowVersion is 0.0. Sure, I'll add that.. Actually one is upload the other is update if you look at the two methods carefully. Anyway, I just copied this part from the original code without any change. . I think it means job override. I can make it a constant variable.. Agree. \nHere source is the flow file name. I think it also makes sense to have flow file name as the argument. Probably I can change the argument name to flowFileName.. Sure.. Good question! Yes it will be called by multiple threads when overriding job properties. If two threads are writing flow files into DB with the same primary key (project id, project version, flow name, flow version), then the second thread would fail in DB insertion. This is better than adding synchronization, which is blocking and could be slow. It makes sense to explicitly fail the second thread so that the user is aware of the conflict in writing to the same file and could retry again.. It could be more reusable. But if we extract project id, project version, flow id, flow version from flow object, then the argument list would become relatively long (6 arguments in total), which might not be a good coding practice.\nWhen a function seems to need more than two or three arguments, it is likely that some of those arguments ought to be wrapped into a class of their own. (Excerpt From: Martin, Robert C. \u201cClean Code: A Handbook of Agile Software Craftsmanship.\u201d iBooks.). We could define a default value like 1.0, but I don't think it is necessary since there is no such azkabanFlowVersion concept in today's project flows and its value is not used either. The value only makes sense for Flow 2.0 design.. It depends on whether the particular job has already started in the current flow execution. If the override properties are set before the job starts to execute, then it will take effect immediately. If set after the job has started, then it will become effective in the next execution.. Sure.. The temp dir path would just be some random string. Any reason why we need to log it? . Actually, I think it's ok to delete this log message since it does not provide much useful info. . I don't think it's a good idea to change default value of mailCreator to \"template-based\". If templateBasedMailCreator is not registered, then when you get mailCreator, you are actually getting the defaultMailCreator, but the name would be \"template-based\", right?. Do you think it's necessary to print out all the templates in the server log? We can just view them in .html files, right?. Same comments as above.. There are some code duplication in load conf and load email. Can we consolidate the code?. I think it's better to check azkabanHome first. If it's null, then we don't create the new emailPath.. From my understanding, below is the logic in reading email templates:\n1. If email directory is passed in the argument list, read from the argument.\n2. If not, check the AZKABAN_HOME directory and if email directory is set, read from there.\n3. If not, do not register template-based mailCreator.\nThis seems to be the same logic as reading conf settings. But there could be some difference in conf and email settings. Do we really need to check \"AZKABAN_HOME\" directory for email? Do you think it's necessary to print out exception if email directory is not set?\n  . From my observation, if you register template-based mailCreator first and it is set in flow object and stored in DB. Next time when you restart the server and load the flow objects from DB, even if you don't register template_based mailCreator, the String mailCreator will still be \"template-based\".\nI would prefer simpler approach which is to keep mailCreator as \"default\". Only set it to template-based when user explicitly sets it in executionOptions from web UI.. Consider using lower case for logger?. This is per user request in ticket LIHADOOP-25204. It provides better instructions to users in case they couldn't find where to add the proxy user.. @mtrna Your proposal sounds reasonable to me. \nNow we don't have the UI support for users to specify emailCreator like other execution options. We could provide them with the flexibility to choose from a list of emailCreators in the future but I don't think it's quite necessary for now.\nYou are right the execution options only apply to the following execution once, and next time when you submit the flow again it will disappear. But if you schedule the flow instead, the execution options will persist with every scheduled execution.\nI'm in favor of the logic to decide the emailCreator on the level of executor during initialization step. If email templates are configured, then we use template-based emailCreator, otherwise we use the default emailCreator. \n@HappyRay Does it sound like a good approach?\n. Consider simplify some logging messages? Info like Constants.DEFAULT_CONF_PATH and Constants.DEFAULT_EMAIL_TEMPLATE_PATH  might not have to be printed out every time.. I don't fully understand why you need to introduce the recommendedCreator. \nIt seems everywhere this registerCreator method is called, the recommend flag passed is always true. In what scenario would you set the recommend flag to false? \nIf we could decide the creator during server initialization like you proposed, would it be possible to simplify the logic?. Currently only logging with level INFO or above will be printed out in our server. We have to change log4j configuration and do a server deployment to enable debug level logging. It might worth considering using log4j2 to dynamically switch logging levels in the future.. Agree. Thanks for the suggestion!. Thanks for the suggestion! I didn't realize that gson was so convenient to use. I'll push a new commit with the simplified code.. The original issue was that all the schedules shared the same data-target id. I added \"velocityCount\" to each id because it is basically the index of each schedule and it's unique, so it can be used to identify each data-target.. We first call handleGetAllSchedules to obtain all schedules. Then for the executionOptions in each schedule, we tag it with a unique id called \"executionOptions-${velocityCount}\", and then display it when clicking the show button. Not sure If I answered your question?. Since we are not very familiar with the UI part, I think it's necessary to fully document the details so that others can understand the intention of the code change.. The only way I can think of is to first convert the executionOptions to JSON for each schedule in the servlet call azkaban.webapp.servlet.ScheduleServlet#handleGetAllSchedules. Then return a new list of Objects which contain the converted results instead of the original schedules. I agree it's ideal to keep the template simple, but the additional complexity to the logic might not worth it. . Is this check duplicate of line 101?. If params for two deps have the same content but in different order, will the check here fail?. \"type\", \"cron\" and \"value\" are already defined in Constants.java. You can use them directly. . Define the numbers \"2\" and \"1\" in constants?. Do we need to check if type or params is null before comparing? Will it throw null pointer exception?. Do we need to check if type or params is null before comparing? Will it throw null pointer exception?. It is possible that getUploadedFlowFile throws ProjectManagerException. Do you plan to catch it as well?. Same comment as above.. What if there are errors in uploading the new project? Should we still schedule it?. Update the comments for groupName definition which should be \"projectID.flowName\" and start with number?. project.getFlows will return all the flows including embedded flows. If a user config flow trigger inside an embedded flow, do we need to support that?. Would it be better to pass the dependency status as the parameter into the SQL string? In case the enum value is changed in the future, we don't need to change the code here.. It seems triggerInst.getId() will return the trigger instance id, not the execution id?. Why don't you just select trigger_instance_id where dep_status = SUCCEEDED or CANCELLED here? Will the sql query be simplified?. Should it be (CredentialProvider) constructor instead of (CredentialProvider) constructors[1]? Otherwise there is no point in comparing the constructors in the loop.. Is it possible to check the parameter class type and make sure it includes the Logger as well?. Missing the part of shuffling.... This method was not used anywhere, so I removed it.. Yes, I've considered the existing CaseInsensitiveMap as well. But it is not synchronized and is not thread-safe. Since the project cache will be accessed by multiple threads, it is necessary to keep it synchronized.. https://docs.microsoft.com/en-us/sql/relational-databases/collations/set-or-change-the-database-collation:\nYou can change the collation of any new objects that are created in a user database by using the COLLATE clause of the ALTER DATABASE statement. This statement does not change the collation of the columns in any existing user-defined tables. These can be changed by using the COLLATE clause of ALTER TABLE.. No, this query only works for Mysql. H2 and Mysql have different syntax in setting collation (case sensitivity). . Yes. Mysql database is case insensitive by default.. Thanks for bringing up this discussion. \nConcurrentHashMap provides concurrent access for multiple threads to the project cache. ConcurrentHashMap is thread safe itself but multiple operations on the map might not be thread safe. (https://stackoverflow.com/questions/14947723/is-concurrenthashmap-totally-safe).\nI found two places in the code, in azkaban.project.ProjectManager#createProject, when two threads first check the project cache, the project might not exist yet. One thread puts the new project to the cache first and then might be overwritten by the other thread. \nAlso, when one thread is trying to get the project, another thread might call azkaban.project.ProjectManager#removeProject at the same time. The project returned in the first thread could be null. \nTo solve the above potential issue, we could add synchronized block on the operations. But there are some tradeoffs. For multiple threads, synchronization will have some effects on the performance. Also, we might have to reevaluate all other cache and see if they require additional synchronization. That might need a separate PR if we want to solve the cache synchronization issue completely.\nFor this particular PR, I would prefer still keeping the map as concurrent since it provides, even though not guarantee, thread safety compared to non-concurrent map. . Added the test for project cache.. Thanks @HappyRay! I totally agree with your point of fixing the current cache synchronization issue. Otherwise, it will ultimately bite us in the future. In this PR, I'll just focus on the consistency issue between project cache and DB. I'll submit another PR to address the cache synchronization issue and link to this one.. H2 DB has the option of setting case insensitive in the url. It is similar to using a collation with strength PRIMARY.\nhttp://www.h2database.com/html/grammar.html#set_ignorecase. The get method in the parent class requires Object as the argument. Here in the child class, I want to specify String type as the argument because the case-insensitive key comparison (toLowerCase()) only applies to String. . Previously I committed the wrong file by mistake and then fixed it. Sorry for the confusion. :). Sure, added the comment in the new commit.. Sure, added the class doc.. Updated, thanks!. Thanks for the suggestions! I've updated the PR.. Yes, I combined \"containsKey\" and \"get\" operations together so that we can rely on the concurrent map itself for thread safety without adding additional external synchronization.. Added unit tests in new commits, thanks!. Updated, thanks!. Sure, moved the constant back to original class.. Why do you need to use \"flowId:nodeId\" to identify the visitedEver nodes? Isn't node id unique already? . Why do you choose to compress the project flows in .tar.bz2? Can we just use the existing .zip and the existing method to zip/unzip the project?. It's better to move the test data to /test/execution-test-data/. See PR #1361 for details.\n (https://github.com/azkaban/azkaban/pull/1361). I see. For embedded flows, they could share the same inner job. I guess if you move visitedNodesEver inside the for loop, basically the same place as visitedNodesOnPath, then you probably don't need to use \"flowId:nodeId\" to distinguish the nodes.. Ok, it makes sense to me. . Node node -> final Node node?\nnodes -> this.nodes?\nAgain, these can be auto checked by \"save action\" plugin. :) . I'm not aware of the naming convention here. Thanks for pointing it out. \nThis is more like a prefix for constructing Azkaban job logs. It's not the specific link for resource manager or job history server. So I think it's necessary to add \"azkaban\" and \"job link\" in the variable name. The reason I'm not using full name simply because it would look too long, something like AZKABAN_SPARK_JOB_HISTORY_SERVER_JOB_LINK. But I'm ok with using the full name if it's easier to understand. \n. Since it's our internal configuration. I'm not able to give the details here. The value would look like: \nazkaban.rm.job.link=http://***rm***.linkedin.com:8088/cluster/app/\nazkaban.jhs.job.link=http://****jh***.linkedin.com:19888/jobhistory/job/job_\nazkaban.shs.job.link=http://***sh***.linkedin.com:18080/history/\nAs I said, it's a prefix for constructing the job log link. If naming it YARN, people still get confused whether the log is on resource manager or job history server. . Yes, I'm parsing the html content. I've discussed it with Min and we couldn't think of any better way to do it. If anything changes in Hadoop side, then yes we have to change our code accordingly.. Sure we can do that.. @HappyRay I notice we already use \"azkaban.server.external\" to name some external configurations, so probabaly no need for introducing the new name \"external_resources\"? In addition to my previous thoughts, I think it would be better to change the names to:\nAZKABAN_SERVER_EXTERNAL_RM_JOB_URL = \"azkaban.server.external.rm.job.url\";\nAZKABAN_SERVER_EXTERNAL_JHS_JOB_URL = \"azkaban.server.external.jhs.job.url\";\nAZKABAN_SERVER_EXTERNAL_SHS_JOB_URL = \"azkaban.server.external.shs.job.url\";\nI think using the full name would be a little too long. I've already added comments to clarify the names, so I think it should be easy to understand as well. \nLet me know if you have any concern. \n. For Spark jobs launched from Azkaban, the job link is:\nhttp://***sh**.grid.linkedin.com:18080/history/application_***_***/1/jobs/\nIt's kind of specific to Azkaban. If launched from other places, the link might vary a little. So I added the Azkaban prefix.  . But since this is the only place in our code which references that link and shouldn't cause confusion, I think it's ok to remove Azkaban prefix if it's too long.. Discussed offline and agreed on the naming convention. See updates in the new commit.. Yes, it's convenient to use javascript within velocity template.. I just followed the example from the apache website: https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/HistoryServerRest.html\nAlso, \"rm\" is not clear enough to users maybe so I choose the full name. . It is not guaranteed that the rest of the URL patterns will be the same for external users.. I found some related documentation but not exactly explain how the URL will look like. At least some of the URL patterns are not the same as ours.\nhttps://spark.apache.org/docs/2.1.2/monitoring.html\nhttps://archive.cloudera.com/cdh5/cdh/5/hadoop/hadoop-yarn/hadoop-yarn-site/WebServicesIntro.html. We can create a ticket to keep Hadoop team in the loop and notice us if anything changes related to Hadoop/Spark logs. Worst case would be the \"Hadoop Job Log\" button doesn't show up or the link is invalid. This is not affecting core Azkaban functionality and users still have other ways to find the job logs. This is a nice-to-have feature and has low risk. So I would say we do our best to communicate with Hadoop team to keep us updated with new changes. Let me know if you have any better suggestions.  . Of course we would not want a product with unreliable non-essential feature. I might not conveying myself clearly so that there is a misunderstanding here. The difficulty I have to admit is that this feature highly depends on Hadoop side unlike other Azkaban features which we could test before new Azkaban release. Today Azkaban doesn't have UI test framework, otherwise it would be easy to add a test for this hadoop log button. Also the test case is not easy if you want to catch all possible scenarios. For now, I would prefer the most straightforward way which is to just click the button and see if it works when there is any related Hadoop upgrade.  . I'm ok with your suggestions. . In the document it mentioned the endpoint for Spark job log is: /applications/[app-id]/jobs, in cluster mode, [app-id] will actually be [base-app-id]/[attempt-id], so the endpoint becomes /applications/[base-app-id]/[attempt-id]/jobs\nIn our server, the endpoint is /application_[base-app-id]/[attempt-id]/jobs\nYou can see there is slight different in the pattern.. Sorry about the confusion. The previous link I shared was the Rest API end point for spark job logs, not the web UI end point. I just checked with hadoop team and the URL pattern for is {{uiroot}}/history/{{id}}/{{attemptId}}/jobs/\">{{attemptId}} from the code:\nhttps://github.com/apache/spark/blob/master/core/src/main/resources/org/apache/spark/ui/static/historypage-template.html#L79\nIn most cases, the \"uiroot\" is hostname:port, but in proxy mode, the pattern could be different. For hadoop jobs, I couldn't find clear documentation about the URL format. I would prefer providing the entire URL link in the configuration in case any external users are using different URL patterns or anything changes in the hadoop code.. My bad, I forgot to include in the commit, thanks!. Insecure sounds better to me as well, thanks!. Good question. As discussed offline, normalize() does not handle ~. If there is ~ in the file name, it will just directly interpret as the folder name ~. \nE.g. if dest path is /user/foo and entry name is ~/bar.txt, after calling normalize(), fileDestinationPath would be /user/foo/~/bar.txt. It will still create the unzipped file in the current directory, which should not be a problem. \nnormalize()does not resolve symlinks. Our current unzipping method only handles files and directories. So even if there are evil symlinks, we will not be trapped.. I created the zip in the code using ZipOutputStream instead of uploading the actual zip. This would be clearer to the users what the content would look in the zip.. Updated in the comments, thanks!. Sure, will update, thanks!. Sure, thanks!. Sure, fixed it in a new PR https://github.com/azkaban/azkaban/pull/1785, thanks!. One for-loop is to traverse .flow files in the current directory, the other for loop is to traverse the subdirectories. . Inside azkaban.project.FlowLoaderFactory#checkForValidProjectYamlFile. Need to check .project file first when deciding whether to create directoryFlowLoader (Flow 1.0) or directoryYamlFlowLoader (Flow 2.0). The check happens before loading project flows.. The filter can only be applied to directories, not individual files. If we want to use the existing filter api, then we cannot avoid two for-loops. Otherwise, we need to list all the files first, and then implement our own filtering logic on each individual file inside the directory, which I don't think is quite necessary. . Can we use FileUtils.sizeOfDirectory to get the size directly?. Does getCreationTime sound better?. What's the intention of synchronizing on projectVersion here?. Is there any reason why we set the threshold between 0.8-0.9?. Do we define active projects as the projects that have currently running flows? What if they have scheduled flows? Should it also be considered as active?. Will it take a long time to calculate the project cache directory size since it's very big? And it will be called inside shouldKeepCleanup method which gets executed for every project version in the for loop. Would it be more efficient to do some batch cleaning?. In getProjectVersion(), it seems the projectVersion returned is a new object. Will the synchronization really work if they are synchronized on different objects here?. I was thinking if it might be possible to clean up like 10 projects at a time and then do the check in shouldKeepCleanup. But I'm not sure how much improvement this will have depending on how long it will take in calculating the directory size. If you think efficiency should not be a problem, then I'm ok with this implementation.. Why change it to 6 hours?. Maybe combine the if-else statement of tdEnd and tdElapse? Also do you need that var endTime = node.dependencyEndTime;?. If it throws exception at uploadProject step, the existing schedules will still be removed but not added back? . Should this be requireNonNull(dagProcessor, ?. The dependency check has already been done when loading the flow files: azkaban.project.DirectoryYamlFlowLoader#buildFlowEdges\nIs there any particular reason why this needs to be implemented again in building the DAG?. It seems to me that logic of creating Dag is similar to what has been done in DirectoryYamlFlowLoader. Would it be easier to just reuse the existing part? Do you plan to eventually integrate them together or keep them as separate paths?. We have _output_tmp and _props_tmp files. See azkaban.jobExecutor.AbstractProcessJob#createFlattenedPropsFile and azkaban.jobExecutor.AbstractProcessJob#createOutputPropsFile for the naming. These are basically temp files. Why do you think we need to change the naming?. Each test case has already included both jobs that satisfy the condition and those don't. So I think it should be sufficient to demonstrate. . Because the files are created using File.createTempFile, it makes sense to me having _tmp in the name, e.g., jobA_output_1416309822424015744_tmp. This can also be easily distinguished from user's files in the execution directory.. Sure, will add the comment.. The condition can be null. If it's null, it just follows our current flow execution logic. \nHowever the conditionOnJobStatus is all_success by default, so it won't be null. If no condition is specified, by default we just follow the current flow execution logic which is all_success.. Yes, when an executableNode is created, azkaban.executor.ExecutableNode#setParentFlow will be called.\nInstead of calling this.getExecutableFlow(), we should call node.getParentFlow() because for jobs inside an embedded flow, they should only have conditions on jobs that are also inside the same embedded flow. this.getExecutableFlow() would fetch the flow at root level whereas node.getParentFlow() would fetch the embedded flow.  Also I added a Null check for the target node. This part will be modified later to fully support condition for embedded flows. . Added the comment. Also changed the pattern to case insensitive.. It's not yet ready. Still need to add some changes to it, so will release it later.. In CRT deployment, uploadProject will be called inside azkaban.restli.ProjectManagerResource#deploy. Do we also need to add the same fix there?. What would the _urlContents look like? Is it possible to include \"Success\" or \"Error\" strings from user job query, which might cause some confusion to the result of indicatesSuccess or indicatesError?. Unit tests usually finish very soon, within 1-2 seconds. Is it possible to reduce the runtime of this test using some mocking method?. Why the return type is Boolean not boolean?. CONDITION_VARIABLE_REPLACEMENT_PATTERN is public because it's also used in another file as well. DIGIT_STRING_PATTERN is private and only used by this file.. Updated, thanks.. Do we need to check if pair is null?. It seems we only have one mailCreator per flow today. Do you think it's necessary to do the grouping here? . Maybe add more details in the java doc?. Consider the name testAlertOnFailedUpdate()?. Consider the name testCreateFailedUpdateMessage()?. Will users be flooded with alerting emails when the executor is unresponsive? UpdaterThread checks the executor status frequently and it might keep sending emails before we could take the action to remove the executor from DB.. The existing code actually checks null on line 1615. If you check other places in the existing code when getting the value from runningFlows, it does the check in most cases. I admit the existing code sometimes has some inconsistent behaviors. So I would prefer not making an assumption here that it would never fail simply based on what the existing code was doing.. Yes, this would be more reasonable, thanks.. Ok got it, thanks.. Good suggestion! I will update it.. Ok thanks.. Sure, I'll update the matcher name, thanks!. Please add the javadoc for all the new public class and methods.. I don't quite follow the TODO here. Do you intend to load all executors or just active executors?. Is it necessary to wrap runningExecutions inside a new class?. @juhoautio \n\nWhat I'm trying to say there is that one option would be call getFlowToExecutorMap() if executor can't be reached.\n\nCurrently, getFlowToExecutorMap() will only check the runningExecutions cache to get the result. However in the previous case we discussed where an executor was shut down first and the runningExecutions cache didn't get a chance to update, this would not solve the problem. \nHow about checking the executor info from DB directly if that executor cannot be reached? Then you wouldn't need to reload active executors.\n\nOutside of this class there's a need for updating active executors: for the dispatching side to take new executors into use without manually asking to refresh via API or restarting azkaban-web.\n\nThis would be an improvement but not necessarily the fix for the current issue. Also in our case, updating new executors is only required after new executor deployment, so I don't see much efficiency in updating frequently in the updater thread. \nCorrect me if I understand it wrong.. Do we need to add (\"error\", \"Flow does not exist\") in the executionMap first before mocking the update response for this scenario?\nAlso, better to use ConnectorParams.RESPONSE_ERROR instead of error.. Do we need to verify the returned value from updateExecutions? It should be different for updateExecutionsStillRunning and updateExecutionsFlowDoesNotExist right?. Consider adding the test for finished executions as well?. This comment is for maxConcurrentRunsOneFlow, please move it to the right place.. Why not remove EXECUTOR_PORT together with EXECUTOR_HOST?. +1  retiring this config.. ok makes sense.. I did a code search but didn't see where EXECUTOR_PORT is used on executor side. Can you point to me the location? If it is still needed, consider updating the comment for this property?. As you commented, BAD_REQUEST means the user request will never succeed and the user should give up trying. But users should still be able to wait some time for the current flow to finish and then submit the flow again. Why should this be considered as BAD_REQUEST since retry can still succeed?. Thanks for cleaning up the executor port.. The logging message here is not accurate, please update it to reflect \"executor is removed\".\n. Is it better to name it isExecutorRemoved?\n. Type -> Should. I think we are talking about different pieces of the code. Because originally the logger messages were the same for line 84 and line 152, I suggest changing the one on line 152 to reflect the reason \"executor is removed\" not line 84.  . I think they are still slightly different. The previous one checks whether the executor is null in the running executions cache. And this one checks if the executor exists in DB. For better debugging purpose, I would suggest keeping two different logging messages. . Consider changing from lower case to upper case: \"Collapse All Flows...\"?. Same: consider all upper cases.. Why node.gNodeis checked in collapseAllFlows but not expandAllFlows?. Why is necessary to check if (node.nodes && node.nodes.length > 0) in line 474 but not before line 482?. Thanks for the explanation.. Please change all the places to keep consistency.. Consider also moving this for-loop inside the if (node.type == 'flow' && node.gNode) check?. Have you checked if this method is currently used by any external user?. I've thought about creating a separate utility class to share the common methods between the new ExecutionController and old ExecutorManager. But since our plan is to deprecate ExecutorManager in the near future, I think this temporary duplication is ok for now.. Yes, as I mentioned in the \"todo\", after we add the implementation for start in the new class, we can remove this instanceof check. This would also require adding the start in the ExecutorManagerAdapter interface.. That's a good suggestion. Currently, I'm just following our existing style guide in CONTRIBUTING.md:  \n\ntodo username: todo details. Yes, you are right. I have left the metrics/jmx part for later implementation since there are quite some differences between the new module and the old one, which would require a separate PR change.. What is the benefit of using reflection here?. It is preferred to use something like logger.error instead of e.printStackTrace.\nhttps://stackoverflow.com/questions/10477607/avoid-printstacktrace-use-a-logger-call-instead. You might not need this assertNotNull check since it will be covered in the assertEquals check later.. Hi @juhoautio, I have a question regarding this change:\nLEFT JOIN will also include executions that are in PREPARING status and haven't been dispatched and assigned an executor yet. When a web server is restarted, it will call loadRunningExecutions and loadQueuedFlows. The flows in PREPARING status will be included in both runningExecutions and queuedFlows. They will be finalized in updateExecutions because the executor is null. They will again be dispatched by queueProcessor as well. We've noticed one incident from our current web server log. Although it doesn't impact users too much, I think it's still an issue since the runningExecutions definition doesn't quite match what is fetched from DB.. @juhoautio Thanks, the solution sounds good to me.. Sure, please go ahead with the fix. I'll review and merge it.. Updated, thanks!. Is it better to use the same name getProjectDirCacheHitRatio?. The comments in the test cases are not quite informative. Consider either adding more details or removing redundant ones?. This will change the flow link from the root flow to the immediate embedded flow, right?\nWhat is the reason of changing it?. Consider adding a simple example to illustrate the parsing logic? It will be better for others to understand.. What if jobPath.size() is 0?. You are right, jobPath.size() will be at least 1. I also saw many discussions about using assert in the code. I think it might not be necessary here since it will throw exception if the index is out of bound in the next line of code, which should never happen though.\nDifferent opinions on using assert, just for reference:\nhttps://softwareengineering.stackexchange.com/questions/137158/is-it-better-to-use-assert-or-illegalargumentexception-for-required-method-param\nhttps://www.yegor256.com/2016/06/17/dont-use-java-assertions.html\n. Sure, you can go ahead with the change. Just remember to document it well so that others would be aware of it.. thanks. getAllActiveExecutors is already defined in the public interface ExecutorManagerAdaptor which we don't want to change in case anything is broken.\nThis method is only called in azkaban/execapp/StatsServlet.java. As discussed offline, when it returns an empty list, this.execManagerAdapter.callExecutorStats(executors.iterator().next().getId(), might throw an exception. However, this exception would be caught and added to the errorMsg and shown on UI. I've verified this behavior on solo server. It should be fine.. Added an additional check for empty executor list in the new commit.. Most of the implementations remain the same as those in ExecutorManager. The only difference is that we are not enqueueing to queueFlows cache now and not adding new executions to active_executing_flows DB table which has been deprecated already.. The polling frequency will be adjusted based on how many flows are scheduled/executed at the same time. For example, if 100 flows are scheduled to run at the same time and we only have one executor, we might want to configure small polling intervals like 100 ms to reduce execution delays. In the future, it's very likely that we need to support more flows scheduled at the same time, so I think millisecond is a proper time unit for the polling interval.. I use the pollingIntervalMs only in wait(this.pollingIntervalMs);\nAnyway it has to be in long format, what's the benefit of converting it to Duration and then back to long again?. I don't think we will get rid of executor table. It is anyway used for fetching active executable flows, also for failure detection in the future.. What about KILLED jobs? Do we want to expand them as well or only FAILED ones?. What is changedNode?. Why do we need to pass node.nodes || [] to the function?. Consider adding the flow param in the javadoc as well?.  I can add a comment to explain the functionality of this new class. \nHowever I think the name PollingThread is relatively clear about what the thread mainly does. To me, ScheduledThreadPoolExecutor seems a little confusing and not easy to understand the actual functionality of this class.. will fix, thanks. Thanks for the suggestion. I'll consider using the ScheduledThreadPoolExecutor to do the polling instead.. Maybe PollingService?. ok. We want to ultimately deprecate ExecutorManager and replace it with ExecutionController. So I think it's ok to duplicate some code for now.. Most of the methods in this new class are moved from ExecutionFinalizer with some code refactoring. . Discussed offline. The entire canceling is synchronized to prevent two different threads finalizing the flow in DB as well as calling executor to cancel at the same time. To be safe, the second thread should wait for the first thread to finish canceling first.. The concurrency protection is done in the method which calls finalizeFlow.. We plan to ultimately remove all the cache from web server including the runningExecutions cache in order to achieve web server HA in the future. What do you think of injecting ExecutorLoader instead of runningExecutions here so that we can call fetchActiveFlowsto get the same running executions info later.. What about queued flows? As you mentioned, there might be a delay in dispatching to executors and the executions are queued on the web server. Should we exclude the project versions from being deleted for those queued flows as well? If that's the case, you can use this.executorLoader.fetchUnfinishedFlows which will include the queued flows.. Fixed, thanks!. The method names fetchUnfinishedExecutions and fetchUnfinishedFlows are too similar to each other. Would it be better to use the name fetchUnfinishedFlowsMetadata since you are only fetching metadata info about the flow?. Consider the name getExecutableFlowMetadataHelper?. Same comment about naming.. What about \"submit_user\"?. Maybe mention about excluding the versions of unfinished flows in the comment?. testFetchUnfinishedFlowsMetadata?. unfinishedFlows might not be the same as activeFlows. Will it cause confusion here?. Because today we are using string as the data type for JMX MBean:\n@DisplayName(\"OPERATION: getRunningFlows\")\n  public String getRunningFlows();\nIt calls:\npublic String getRunningFlows() {\n    return this.manager.getRunningFlowIds();\n  }\nTo keep consistent with the current behavior and to share the same interface, I chose the same return type. Other than that, I don't have a strong opinion against using list though.. @juhoautio Good point. I've tested the performance on local mysql DB with hundreds of running flows and didn't see significant degradation. I'm about to test it in our staging environment before enabling it in production. \nI agree we should fetch full flow data only when it's needed for better DB performance. Thanks for reminding me of this. I'll share any test result I get later. . Changed from string to list, thanks.. Since logger is not a constant, it should be fine with the lower case:\nhttps://stackoverflow.com/questions/1417190/should-a-static-final-logger-be-declared-in-upper-case. This ExecutorHealthChecker only has one single thread and is fairly lightweight, so in normal case, it should be ok to shutdown without the wait. However, using awaitTermination() might be better if this class contains more threads and becomes more heavyweight in the future.  . The return value is a json object, not sure how to be more specific. Any suggestions?. Good question. The frequency of this http call is relatively low (5 minutes interval per check), even if each http call takes long, it will still be acceptable in our use case though. For better monitoring, I think we can add some metrics to track the time it takes for each call to return. . Good point. I'll make the change to only alert on consecutive failures.. Will add that, thanks!. Sure.. Will fix it, thanks!. callWithExecutionId calls azkaban.utils.JSONUtils#parseJSONFromString which already does the serialization from String to JSON object. . Discussed offline and agreed on the future refactoring of current HTTP call return type. We can define more specific classes containing all the necessary fields instead of the generic Object type for better code readability and error prevention.. Thanks, will remove it in the next PR.. This method is moved from RunningExecutionsUpdater.java with slight modification.. Thanks for the suggestion. I've also considered separating the alerting part. However, alerting happens when the flow status is propagated to FAILED_FINISHING for the first time. So it anyway needs to recursively call getParentFlow to access the root flow status, which is the same as what propagateStatus is doing. Also to make sure we only alert once, a global variable might be needed to keep the info whether alerting has happened or not. Considering the efficiency and simplicity of the code, I would prefer combining them together, maybe changing the method name to better describe the purpose of this method.. Discussed offline and agreed on adding a new FLOW_STATUS_CHANGED event type and switching to the event-driven model in the future.. \n",
    "SurjitDas": "Hi, I also need support for postgresql as a backend datastore for my project in the organisation, when this is going to be released? What I can see is, the stated code changes has so far, not been pushed into the lastest 3.1 tag (or am I checking in the wrong tag?). Kindly suggest.\n. ",
    "huangfushun": "thanks.\nit will be great if we can support this feature .\nwe may think about making db as a plugin that can be easily replaced. so any project especially for an exiting production system that won't or hard to setup a new mysql db.\nclose this pr for now.\n. hi, the most different are sql statement and db ddl.  eg. merge/limit.   if we all use standard sql then it will be easy to change to different db source.. It should not rely on JexlEngine to resolve variable in $(), since it maybe a valid shell command.  it would be better to change expression key from $(a) to something like {{a}},\nand more directly way is  just log warning and let user choose to ignore or fix it.. azkaban current executor manager only can submit whole flow to execution server,  if we need to run different job on different executor server the only way is separate them into different flow. but next problem is azkaban  could not specify flow to run on specified server(node).   not sure if there is plan to enhance that?. Considering  some of jobs  require native resource like python/sftp/redis setup locally or because of limited  network(eg. job request external resource but only particular ip allow to access.) ,and if not all exec servers can fit  then we need to \"custom node \"  similar to Oozie\n. just think of  if azkaban can have a ' plugin'  like  custom node   , then invoke  another resource negotiator(like YarnRPC )  to launch job remotly?  it works if run outside of exec server , the only thing is we need to make sure remote host is  healthy.\n. have the same problem,  it seems caused by inconsistent host/port setting.  just try update \"active\" to 1 can work.. if so I would suggest more lables for executor servers(eg. hostname=ec1, ssd=1) and support more specs for jobs definition like \"node affniity\"  so schduler manager can choose which server is proper to schdule.. ",
    "rcalaba-ic": "Same issue here, have found - https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwirvLeIiMzOAhXJLSYKHZ1NDjUQFggeMAA&url=https%3A%2F%2Fgithub.com%2Ftbroyer%2Fgradle-errorprone-plugin%2Fissues%2F16&usg=AFQjCNH3MRu7e4EXpEicOnR7HaLmYZd3tg&sig2=iSjSkTzGOvsyfoYephq1bQ and https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwirvLeIiMzOAhXJLSYKHZ1NDjUQFggkMAE&url=https%3A%2F%2Fgithub.com%2Ftbroyer%2Fgradle-errorprone-plugin%2Fissues%2F14&usg=AFQjCNFNbw6iqjaQIS-qjPIL0Gxo_644xA&sig2=cQIvpp0Z4SgzuYWNYuj4fw\nBut do not know what is the resolution ... \n. ",
    "dirkdaems": "Before building, make sure you also install the openjdk-devel package: e.g. yum install java-1.8.0-openjdk-devel. That fixed my issue.\n. ",
    "rajivchodisetti": "HI , In which version this feature is going to be released , we are looking for this feature badly \n. thanks for the update @fsi206914 , it will solve lot of pain for us , right now if a job has to be skipped , we are hard coding all that logic in .sh file and all the .sh files are messed up with the hard coded schedules\n. HI @fsi206914 , Is this feature pushed to prod ?\n. Thanks for the update @fsi206914 \n. Am not using Solo server mode but trying to install stand alone executor and webserver , but am also running into the same issue , I haven't installed any plugins \nI don't need any plugins because all am going to run are shell scripts \n29-11-2016 17:02:49 IST dim_date ERROR - Job run failed!\nazkaban.utils.UndefinedPropertyException: Missing required property 'azkaban.native.lib'\n    at azkaban.utils.Props.getString(Props.java:478)\n    at azkaban.jobExecutor.ProcessJob.run(ProcessJob.java:120)\n    at azkaban.execapp.JobRunner.runJob(JobRunner.java:685)\n    at azkaban.execapp.JobRunner.run(JobRunner.java:537)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n29-11-2016 17:02:49 IST dim_date ERROR - Missing required property 'azkaban.native.lib' cause: null\n29-11-2016 17:02:49 IST dim_date INFO - Finishing job dim_date attempt: 0 at 1480419169261 with status FAILED. @kunkun-tang I have checked both 818 and 827 and there are related to solo server mode right , but anyhow have pulled the latest code and tried yesterday but still the error is same . Yes , I have installed both web and executor server separately . Is any one looking into it , am blocked on it :( . @kunkun-tang when I built the project using gradle from source , there isn't any plugin/jobtype directory created .\nAnd the link that you were referring to  refers to solo server mode where as I have installed webserver and exec server separately . thanks for the revert , will try and get back . I have tried passing value for concurrentOption parameter , but those values are not being obeyed \nPossible Values: ignore, pipeline, queue . ",
    "garyelephant": "Maybe The scheduler can be more flexible, let me take an example:\n(1) schedule flow by SLA, specify flow execution time range for everyday, such as we can specify the flow can be executed any time between 2 A.M. and 10 A.M. everyday.\n(2) schedule flow with consideration for the number of current running flows and system load of azkaban executors, if there are too many running flows currently or executors system load is too high, some flows can be delayed if the execution time not violating (1) \n. +1. +1. ",
    "JasonBian": "add NullPointException check for the ajax request fetchflowgraph\n. @fsi206914 when I use ajax api to invoke fetchflowgraph method, if I post invalid flowId, the fillFlowInfo method of the ProjectManagerServlet should check Flow flow = project.getFlow(flowId) is null or not.\n. ",
    "mycFelix": "I run create-all-sql-3.1.0.sql to create all tables,but failed to find the executor_id column.\n. @fsi206914 - Thank you for your tips\n. ",
    "KyleFung": "Fixed via commit 5d6d7e4\n. Issue fixed via commit 5d6d7e4\n. I messed up the merge. Please don't pull this code yet.\n. Had a problem with some files being renamed. It is resolved now.\n. Closed via #762 \n. Done via commit 62fc290\n. @HappyRay I believe that would require quite a few changes and is not the way log4j should be used. Log4j finds the file by itself, not Azkaban.\n@suvodeep-pyne Yes, we can. This patch updates the startup script of solo server, exec server and web server.\nEdit: @suvodeep-pyne I think I interpreted your question wrong. I think it would be useful to have this done for exec server because it allows us to easily customize the logger without needing to redeploy Azkaban or using some hacks.\n. If it's a runtime dependency, people who want to use the Kafka Appender should download the jar into their class path by themselves.\nClosing this issue as unnecessary.\n. The internal version of Kafka should be able to communicate with an external version of the Kafka client. I've also tested this using the external Kafka on our machines and they work fine.\n. Closing this as if people want to use Kafka at run time, they should include the runtime dependency in themselves.\n. There are many other problems similar to this that need to be addressed. The issue to fix that is filed at #795\n. Yeah I made it here: #795. I forgot to reference it in this pull request.\n. I was thinking we could centralize the information into one place, but I suppose users wouldn't really know those details and it'd waste their time to find them.\nWe can instead put them in the azkaban.properties of exec server.\n. Closing as change was merged (#805).\n. @HappyRay The external one overrides the default through the start shell script, or through the \"conf\" option in the command line. I believe that running tests does not invoke either of these, so no overrides will occur.\n@HappyRay the exception is a file not found exception. I believe it tries to create a logger to a file that does not exist during testing.\n@HappyRay If no log4j.properties file is provided, and we delete the default it will not log anywhere it seems, but it looks like it just spits everything into the console.\n. Actually it seems that solo-server relies on the config files that we want to delete. We should add a conf directory solely for the use of solo-server.\n. Due to some weird mess up with git, I am continuing this work at #814.\n. Due to some weird mess up with git, I am continuing the work from #806 here.\n. Closed via #822 . @HappyRay testing was done by logging messages containing these characters, confirming that they come out corrupted using the default PatternLayout, and then confirming that they work using the one created in this commit.. @HappyRay Unit tests added.. @tk0485 Maybe it's a copy paste error into github, but it seems your quotes don't match. Can you confirm this?\nJust before your host name you have a double quote followed by a single quote.\n. Fixed. Thanks for reporting.. Closed via #826 . Closed via #841 . I meant any messages that the server tries to relay to the outside world will be caught by log4j. This includes exceptions and stack traces.. It is not new logic. Previously, if the download or validation failed for some exception, we would delete the directory if it existed.\nNow, I separated the downloading part and the validation part of the project file. If there is some kind of exception during the download, we delete the file (as done before). If the download succeeds, we try to validate it. Regardless of validation failing or not, the directory will need to be deleted, so there is another directory delete under the try clause trying to validate the file.\n. This exception is caught so that I could be sure that an error message would be printed in the logs. However, upon further inspection, it seems that another part of the code will make a similar log entry, so I will remove this catch.\n. I agree that it should be private. If that's the case, should we keep these tests? Someone may change the implementation of this class later down the road and remove this method and these tests wouldn't work anymore.\n. I don't think we should search for the file in the Java code since the logger is instantiated before any code I write is run. We would create a logger using some configuration file in the classpath, and then reinitializing the logger again.\nI think we should try searching the directory specified in the conf parameter.\nI'll make a pull request for it.\n. It is impossible from here to tell if it is 400 or 500. I suppose we should err on the side of caution and return 500.\n. When we get to migration we will have to use one of the solutions found at\nhttp://logging.apache.org/log4j/2.x/manual/customconfig.html (under Programmatically Modifying the Current Configuration after Initialization). The problem with that is drawback 1 (from the link), as one of the reasons for using log4j2 is the ability to dynamically configure the logger.\nAnother possible solution is to programmatically rewrite the log configuration file at run time to make new appenders. I'm not too sure if that's possible so I'll look into that.\n. It could be possible to add more exception types.\nHowever we need to keep using Exception as a catch-all since we want any and all failures to silently happen (we shouldn't crash the application due to the logger failing).\n. It's pretty hard to tell. We could try to close and set null the appender in this catch clause to prevent invalid operations in the future.\n. Looking at the source code for removeAppender, it shouldn't be an issue if the appender is corrupt or non existent as it is just a remove operation from a Vector (won't blow up if it's not there).\n. Many of the literal strings in this file are not stored as constants somewhere. Would it look right to add this in?\n. That props is the properties object of the job itself. We want to configure the globalDisable variable at the server level (from azkaban.properties), which is accessed as above.\n. Why slf4j? Looking at the source for log4j2's PatternLayout class these will not be compatible. Also I believe that with log4j2, a scheme like this is not necessary.. It will throw an UndefinedPropertyException and fail. This exception is caught and handled so it will not crash the server.. You're right. This has been removed.. Yes, I think it would be useful to have a killswitch like this that users cannot override.. Done. A bit of refactoring of the job and flow runner classes had to be done.. Added to Constants.java. Done.. I believe this would have a lot of overhead and may not be worth it.. Yes, that was actually a typo on my part.. They are the same. I changed my mind on what to call it and switched all of them to azkabanProps but I guess I missed this one.. It seems you're right about the integer.. Latest version creates static instances of them.. Fixed by overriding a bunch of print/println functions. Unfortunately this was the only way, apart from overriding write(), but that option seemed very error prone and not as simple as overriding print/println.. I noticed messages were being sent out of order. Turning on sync send fixes this.. Yes, exceptions were being missed but using this layout instead made them appear.. Added a comment in the code specifying a reason for this.. Upon a second look this isn't possible since getURLForTopic will only extract the parameter from the properties map. It cannot set it as needed here.. Same thing as above.. This test already exists. I looked at how this is used in production and the use case and the test case are virtually the same.. Tests have been added.. ",
    "tolgakonik": "+1 on this. In absence of this, subcomponents run at independent schedules, leading to either latency or serious compute waste.\nwaiting is not a great solution because that prevents you from defining serious SLAs.\n. ",
    "cdonat": "We'd be very interested in such a feature as well. Our scenario is, that we have one daily flow and a monthly one, that should only start after the daily one has finished for the 1st of that month.. ",
    "roshfsk": "+1, appreciate if you could provide us with an update on the status of this enhancement. It is a much needed feature. . ",
    "peaksnail": "+1. ",
    "elonlo": "+1,we need this function too!. ",
    "DataScientistSamChan": "+1, we need this function too!!. ",
    "kanhaiyaagarwal": "any solution here ?\n. ",
    "zhangnew": "Yes, I tried set a password for user 'azkaban' by mysql. and set the password in the conf/azkaban.properties . it's ok.\nBut I think if the mysql user without password ,and set none password in the conf/azkaban.properties ,it should be ok.( I used the last released version 3.1 )\n. ",
    "mradamlacey": "How do you execute unit tests for the project?\nNot that familiar with gradle (sorry).  \n./gradlew test\nDoes that do the trick?\nAlso, for unit tests I'm thinking of just testing a utility class that implements the logic to parse out the client ip...  I don't think it's worth the effort to spin up the test infrastructure for a servlet which would be more of an integration test.  Let me know if you suggest another route.\n. Updated the pull request with the following:\n- Unit tests for ResourceContextUtils class (low level helper used to parse out the client IP)\n- Unit tests around AbstractLogin servlet - with necessary mocking to get a request to be successfully processed\nI didn't refactor the 'parse out the client IP and compare to session IP' bit, as the servlet vs. the REST service implementation was very different - I didn't see a ton of value having a common library that all it does compare two strings - would still need the calling context to decide to where to pull the strings from.\nLet me know your thoughts or what else you feel is needed for this PR.\n. Hi updated the pull request to refactor out a common method in WebUtils class to parse the real client ip.\nUpdated the spots in the Login servlet and the ResourceUtils class.\nUpdated unit tests.\nAddressed your other comment about adding license file.\nthanks!\n. Just updated to address your latest changes.  Let me know if anything else is needed.\n. Yes the comment is valid\n. ",
    "zxsimple": "This issue has already been discussed on google group, but no resolution.\nhttps://groups.google.com/forum/#!topic/azkaban-dev/2ZkL6FZg1KY\n. ",
    "dannypv05261": "Hi, All,\nAfter trial and error, I can upload the file to the project finally.\nI don't know if the document gets something wrong or not, since I make it works by comparing my request with the raw request in azkaban web and reading the source code.\nSo, there is something which is different from / does not mention in the document in my solution.\n1. The URL is /manger instead of /manager?ajax=upload\n2. Add field \"action\" with value \"upload\" in the body\n3. Add boundary in the Context-Type in request header\n4. Add boundary to separate each multipart parameters\nI also have a piece of code which uses Apache HttpClient library to make the request and I am using Groovy.\n  InputStream inputStream = new FileInputStream(\"$project.buildDir/azkaban/$project.name\" + \".zip\")\n  def entity = MultipartEntityBuilder\n          .create()\n          .setMode(HttpMultipartMode.BROWSER_COMPATIBLE)\n          .addBinaryBody(\"file\", inputStream, ContentType.create(\"application/x-zip-compressed\"), \"$project.name\" + \".zip\")\n          .addTextBody(\"session.id\", sessionId, ContentType.TEXT_PLAIN)\n          .addTextBody(\"project\", \"$project.name\", ContentType.TEXT_PLAIN)\n          .addTextBody(\"action\", \"upload\", ContentType.TEXT_PLAIN)\n          .setBoundary(\"----WebKitFormBoundary76hDprXdyeWQOqP6\")\n          .build()\n\n  def httpPost = new HttpPost(host + \"/manager\")\n  httpPost.setEntity(entity)\n  httpPost.setHeader(\"Content-Type\", \"multipart/mixed; boundary=----WebKitFormBoundary76hDprXdyeWQOqP6\")\n  httpPost.setHeader(\"Accept\", \"application/json\")\n\n  def response = client.execute(httpPost)\n\n. ",
    "diaowenyang": "@gunesh4u I met the error too.How to fix it ?. @gunesh4u Thanks \uff01\n\n[wherehows@mesos1 bin]$ 2017-11-17 16:08:59 INFO  LoginAbstractAzkabanServlet:169 - 10.129.3.1 azkaban \"GET /executor projectId=3&project=t3&ajax=executeFlow&flow=test_d3_azkaban&disabled=%5B%5D&failureEmailsOverride=false&successEmailsOverride=false&failureAction=finishCurrent&failureEmails=&successEmails=&notifyFailureFirst=false&notifyFailureLast=false&concurrentOption=skip HTTP/1.1\" browser\n2017-11-17 16:08:59 INFO  ExecutorManager:939 - Submitting execution flow test_d3_azkaban by azkaban\n2017-11-17 16:08:59 INFO  ExecutionFlowDao:72 - Flow given test_d3_azkaban given id 9\n2017-11-17 16:08:59 INFO  ExecutorServlet:115 - User  has called action execute on 9\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 - azkaban.executor.ExecutorManagerException: Error loading flow with exec 9\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at azkaban.execapp.FlowRunnerManager.submitFlow(FlowRunnerManager.java:324)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at azkaban.execapp.ExecutorServlet.handleAjaxExecute(ExecutorServlet.java:276)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at azkaban.execapp.ExecutorServlet.doGet(ExecutorServlet.java:124)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:401)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.Server.handle(Server.java:326)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\n2017-11-17 16:08:59 ERROR ExecutorServlet:279 - Error loading flow with exec 9\nazkaban.executor.ExecutorManagerException: Error loading flow with exec 9\n    at azkaban.execapp.FlowRunnerManager.submitFlow(FlowRunnerManager.java:324)\n    at azkaban.execapp.ExecutorServlet.handleAjaxExecute(ExecutorServlet.java:276)\n    at azkaban.execapp.ExecutorServlet.doGet(ExecutorServlet.java:124)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\n    at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)\n    at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:401)\n    at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\n    at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n    at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n    at org.mortbay.jetty.Server.handle(Server.java:326)\n    at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\n    at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)\n    at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)\n    at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n    at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n    at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)\n    at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\n2017-11-17 16:08:59 ERROR ExecutorManager:1378 - Rolling back executor assignment for execution id:9\nazkaban.executor.ExecutorManagerException: java.io.IOException: Error loading flow with exec 9\n    at azkaban.executor.ExecutorApiGateway.callWithExecutionId(ExecutorApiGateway.java:78)\n    at azkaban.executor.ExecutorApiGateway.callWithExecutable(ExecutorApiGateway.java:43)\n    at azkaban.executor.ExecutorManager.dispatch(ExecutorManager.java:1375)\n    at azkaban.executor.ExecutorManager.submitExecutableFlow(ExecutorManager.java:1013)\n    at azkaban.webapp.servlet.ExecutorServlet.ajaxExecuteFlow(ExecutorServlet.java:943)\n    at azkaban.webapp.servlet.ExecutorServlet.ajaxAttemptExecuteFlow(ExecutorServlet.java:903)\n    at azkaban.webapp.servlet.ExecutorServlet.handleAJAXAction(ExecutorServlet.java:175)\n    at azkaban.webapp.servlet.ExecutorServlet.handleGet(ExecutorServlet.java:95)\n    at azkaban.webapp.servlet.LoginAbstractAzkabanServlet.doGet(LoginAbstractAzkabanServlet.java:123)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:668)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:770)\n    at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)\n    at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:401)\n    at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\n    at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n    at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n    at org.mortbay.jetty.Server.handle(Server.java:326)\n    at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\n    at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)\n    at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)\n    at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n    at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n    at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)\n    at org.mortbay.jetty.security.SslSocketConnector$SslConnection.run(SslSocketConnector.java:713)\n    at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\nCaused by: java.io.IOException: Error loading flow with exec 9\n    at azkaban.executor.ExecutorApiGateway.callForJsonObjectMap(ExecutorApiGateway.java:106)\n    at azkaban.executor.ExecutorApiGateway.callWithExecutionId(ExecutorApiGateway.java:76)\n    ... 24 more\n2017-11-17 16:08:59 INFO  FlowRunnerManager:818 - # of executing flows: 0\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 - azkaban.executor.ExecutorManagerException: azkaban.executor.ExecutorManagerException: java.io.IOException: Error loading flow with exec 9\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at azkaban.executor.ExecutorManager.dispatch(ExecutorManager.java:1381)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at azkaban.executor.ExecutorManager.submitExecutableFlow(ExecutorManager.java:1013)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at azkaban.webapp.servlet.ExecutorServlet.ajaxExecuteFlow(ExecutorServlet.java:943)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at azkaban.webapp.servlet.ExecutorServlet.ajaxAttemptExecuteFlow(ExecutorServlet.java:903)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at azkaban.webapp.servlet.ExecutorServlet.handleAJAXAction(ExecutorServlet.java:175)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at azkaban.webapp.servlet.ExecutorServlet.handleGet(ExecutorServlet.java:95)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at azkaban.webapp.servlet.LoginAbstractAzkabanServlet.doGet(LoginAbstractAzkabanServlet.java:123)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at javax.servlet.http.HttpServlet.service(HttpServlet.java:668)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at javax.servlet.http.HttpServlet.service(HttpServlet.java:770)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:401)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.Server.handle(Server.java:326)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.jetty.security.SslSocketConnector$SslConnection.run(SslSocketConnector.java:713)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 - Caused by: azkaban.executor.ExecutorManagerException: java.io.IOException: Error loading flow with exec 9\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at azkaban.executor.ExecutorApiGateway.callWithExecutionId(ExecutorApiGateway.java:78)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at azkaban.executor.ExecutorApiGateway.callWithExecutable(ExecutorApiGateway.java:43)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at azkaban.executor.ExecutorManager.dispatch(ExecutorManager.java:1375)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    ... 22 more\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 - Caused by: java.io.IOException: Error loading flow with exec 9\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at azkaban.executor.ExecutorApiGateway.callForJsonObjectMap(ExecutorApiGateway.java:106)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    at azkaban.executor.ExecutorApiGateway.callWithExecutionId(ExecutorApiGateway.java:76)\n2017-11-17 16:08:59 ERROR StdOutErrRedirect:55 -    ... 24 more\n. @abigbigbird Have you fix it ? And how to fix it ?. It works,Thank you so much!. ",
    "gunesh4u": "Can you share error message/log?\nThanks,\nGp\nOn Fri, 17 Nov 2017 at 1:05 PM, Leno Bill notifications@github.com wrote:\n\n@gunesh4u https://github.com/gunesh4u I met the error too.How to fix it\n?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/773#issuecomment-345167688,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AV2-Wyy7RWuthUGTNB94FqZ4ZLEyttxjks5s3TcpgaJpZM4KaNUY\n.\n-- \nSent from Gmail Mobile\n. \n",
    "jwoschitz": "Hello,\nthis issue has been addressed in https://github.com/researchgate/azkaban-ldap-usermanager/commit/ce3201d017e2732c508f58b98e373d190e5a7763 by providing shadowed dependencies for the Apache Mina library.\nThe fix is also part of the 1.1.0 release of azkaban-ldap-usermanager\nThe changes should be compatible to any Azkaban version >= 2.5.0. We tested it with 3.0.0, 3.2.0 and 3.16.0 (latest) builds.. ",
    "dacoolbaby": "Thanks for replying.\nMy scenario is the parameters will be generated by other system or other scripts.\nIf there is a way that I can pass the parameters in the job context during the job is executing. \n. @scofier So far,  I used ajax api for executing the flow with customer parameters.. ",
    "scofier": "@dacoolbaby  did you solved this issues?. ",
    "moscovig": "++. curl -s -d \"ajax=setSla&scheduleId=${schedule_id}&slaEmails=&settings[0]=${schedule_id},SUCCESS,${sla_duration},false,true\" -b \"azkaban.browser.session.id=${SESSION_ID}\" \"${AZKABAN_HOST}/schedule\"\nwhere sla_duration is something like \"12:00\". ",
    "PettterPan": "I also met this problem, i am a freshbird to use the azkaban. could you tell me how to solve this problem in details . thx very mush @NaanProphet . ",
    "zouzou6321": "just fix it by fellow issues  628. ",
    "idelin": "@zouzou6321 \u6211\u6ca1\u6709\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u7136\u540e\u6211\u4f7f\u75282.6\u7248\u672c\u7684jobtype\u63d2\u4ef6\u53ef\u4ee5\u8dd1\uff0c\u6682\u65f6\u662f\u4f7f\u75282.6\u7248\u672c\u7684\u63d2\u4ef6\uff0c\u5f53\u7136\u6211\u4e5f\u5947\u602a\u4e3a\u4ec0\u4e482.6\u7248\u672c\u7684\u63d2\u4ef6\u53ef\u4ee5\u57283.0\u7684azkaban\u4e0a\u8dd1\u3002. ",
    "aranelofdoriath": "I have the same issue but caused by Spark plugin:\njava.lang.Exception: java.lang.Exception: Bad property definition! null\n    at azkaban.jobtype.HadoopSparkJob.run(HadoopSparkJob.java:230)\nAny updates on this?. ",
    "yutaosun209205": "I see, Thanks everyone\uff01\n. Got it\uff0cThanks\uff01\n. ",
    "ldzhjn": "I was following this guide to setup the solo server and I didn't install any plugins\nhttp://azkaban.github.io/azkaban/docs/latest/#solo-setup\n. ",
    "hderms": "I have the same issue\n. I was trying to evaluate whether to use Azkaban versus another workflow management tool but the fact that the example doesn't work is disconcerting\n. ",
    "lpe234": "see this pull request. pull/827\n. ",
    "pnats": "Im not using the solo server download. I am using tar from the build off the directory azkaban-master/azkaban-exec-server/build/distributions\nwhich I copied to another host to run as my executor.\n. Correct that fixed it.. ",
    "cquptEthan": "@kunkun-tang   plugins/jobtypes folder. ",
    "dmeijboom": "This looks very helpfull to me.. I didn't know there was a Python or Ruby job-type. Can this be merged?. Also maybe it would be nice to also state that if you want to use python3 on debian systems you can simply set the python variable in jobProps to python3 which then will be used as executable for python scripts.. Thanks!\nFor now I've fixed it by manually downloading momentjs to the old filename.. ",
    "NaanProphet": "@kunkun-tang Happy new year! Looks like this bug is in date.js rather than later.js. If you can confirm, maybe @jh3155 can create a pull request?. ",
    "mariacioffi": "@kunkun-tang You could reference issue #845 for an example.. I have added some test cases to test.js. Let me know if there is anything missing or any other modification I should make. Thanks.. ",
    "fwantastic": "@kunkun-tang Happy new year!\nI will make a pull request. Having the \"Advanced Filter\" on the scheduling page sounds great. I could be wrong, I believe they removed the scheduling table and basically triggers and schedules became interchangeable.. @chengren311 it has been added on the execution page as well. Names have been changed to follow the naming convention!. Thanks for the feedback. \nI do like what you suggested - azkaban.display.execution_page_size. I went for azkaban.page.size.xxx as if there's another page that will have non-execution rows and needs a different page size.\nI'll check out the SaveAction plugin, I thought it only supported intellij and I'm using eclipse but I guess I was wrong!. Installed intellij and applied the style sheet, though it didn't add a new line at the end so I manually added one. Also refactor - rename variable doesn't work properly so I had to rename them one by one as well!. keys were extracted to a constant.. hm not sure why the build is failing. any ideas?. @HappyRay the build seems to be fine, what do you think about those code coverages?. @HappyRay I'm happy to provide documentations for the changes. The last commit I made was for the merge conflicts that CI was flagging about. This PR's changes are pretty simple and straightforward. . to avoid any confusions, I've reverted the merge. . @HappyRay bump!. @kunkun-tang could you review the changes please?!. @kunkun-tang I've rebased the branch and should be ready for review. I accidently committed a blank file so I removed it in the last commit. hey @kunkun-tang, I've tested this manually on my machine but there's no test for it. was there any issues with this?. @kunkun-tang I cloned master but I'm unable to replicate the issue on my end. I'm running the solo server locally on win 10 + cygwin + h2. However, I think I found the issue.\nIn flow.js, the line you changed is actually not needed, it should be reverted to this:\nthis.model.set({page: 1, pageSize: this.pageSize});\nIn historypage.vm, this should be included in 'head' section, just like line 51 in flowpage.vm\nvar pageSize = \"${size}\";\nI've made these changes super long time ago on my old project, I think I tried to make the page size configurable on executions page as well and probably I missed to include it on historypage.vm on this pull request. But I really do not understand how it's working on mine. \nCould you please try this and let me know?. @kunkun-tang but that is already added in HistoryServlet's handleHistoryPage method\nat line 139:\npage.add(\"size\", pageSize);\nand pageSize is declared as\nfinal int pageSize = getIntParam(req, \"size\", getDisplayExecutionPageSize());. @kunkun-tang Oh I was dumb.. I thought you were talking about the history page this whole time. Yes I totally forgot that this PR covers the flow page as well and I shouldn't have removed the size property in abstract servlet class. You are correct.. @kunkun-tang they are quite large but I added screenshots for a better understanding. I'm also seeing the same error. The new 'Flow Trigger Schedule' page or http://localhost:8081/flowtrigger throws the NPE when running azkaban without modifying any properties after cloning from github. . Bump! any comments?. @kunkun-tang would you mind looking over this PR?. @kunkun-tang is there any updates on this? any comments?. @kunkun-tang That is correct. Would you want me to update that comment?. @HappyRay there was a merge conflict while I was updating my branch to master's head. Would it be better to close this PR and open a new one? . ",
    "ld000": "and i want know where the config files? It's not in the tar.gz package. ",
    "1102845913": "I met the same problem. ",
    "leven2012": "I met the same problem. ",
    "hy-wux": "I met the same problem. ",
    "hikoz": "create conf dir. put conf/log4j.properties\nlog4j.rootLogger=INFO,C\nlog4j.appender.C=org.apache.log4j.ConsoleAppender\nlog4j.appender.C.Target=System.err\nlog4j.appender.C.layout=org.apache.log4j.PatternLayout\nlog4j.appender.C.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n. ",
    "abigbigbird": "linux version:CentOS Linux release 7.2.1511 (Core)\njdk version:1.8.0_121\ni got the same error,but when i put conf/log4j.properties,got a new error\n`2017-04-26 20:49:32 INFO  AzkabanServer:65 - Loading azkaban settings file from ./azkaban-web-server/bin/../conf\n2017-04-26 20:49:32 INFO  AzkabanServer:112 - Loading azkaban properties file\n2017-04-26 20:49:32 INFO  WebServerProvider:47 - Setting up connector with stats on: true\n2017-04-26 20:49:32 INFO  WebServerProvider:56 - Setting up Jetty Https Server with port:8443 and numThreads:25\n2017-04-26 20:49:32 INFO  WebServerProvider:70 - Excluded Cipher Suites: []\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 - SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 - SLF4J: Defaulting to no-operation (NOP) logger implementation\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 - SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n2017-04-26 20:49:32 INFO  WebServerProvider:90 - Starting SSL server on port: 8443\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 - Exception in thread \"main\" \n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 - com.google.inject.ProvisionException: Unable to provision, see the following errors:\n1) Error injecting constructor, azkaban.utils.UndefinedPropertyException: Missing required property 'user.manager.xml.file'\n  at azkaban.webapp.AzkabanWebServer.(AzkabanWebServer.java:185)\n  at azkaban.webapp.AzkabanWebServerModule.configure(AzkabanWebServerModule.java:33)\n  while locating azkaban.webapp.AzkabanWebServer\n1 error\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 -    at com.google.inject.internal.InjectorImpl$2.get(InjectorImpl.java:1028)\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 -    at com.google.inject.internal.InjectorImpl.getInstance(InjectorImpl.java:1054)\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 -    at azkaban.ServiceProvider.getInstance(ServiceProvider.java:52)\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 -    at azkaban.webapp.AzkabanWebServer.launch(AzkabanWebServer.java:692)\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 -    at azkaban.webapp.AzkabanWebServer.main(AzkabanWebServer.java:687)\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 - Caused by: azkaban.utils.UndefinedPropertyException: Missing required property 'user.manager.xml.file'\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 -    at azkaban.utils.Props.getString(Props.java:478)\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 -    at azkaban.user.XmlUserManager.(XmlUserManager.java:82)\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 -    at azkaban.webapp.AzkabanWebServer.loadUserManager(AzkabanWebServer.java:269)\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 -    at azkaban.webapp.AzkabanWebServer.(AzkabanWebServer.java:191)\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 -    at azkaban.webapp.AzkabanWebServer$$FastClassByGuice$$81e0dd4a.newInstance()\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 -    at com.google.inject.internal.DefaultConstructionProxyFactory$FastClassProxy.newInstance(DefaultConstructionProxyFactory.java:89)\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 -    at com.google.inject.internal.ConstructorInjector.provision(ConstructorInjector.java:111)\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 -    at com.google.inject.internal.ConstructorInjector.construct(ConstructorInjector.java:90)\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 -    at com.google.inject.internal.ConstructorBindingImpl$Factory.get(ConstructorBindingImpl.java:268)\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 -    at com.google.inject.internal.ProviderToInternalFactoryAdapter$1.call(ProviderToInternalFactoryAdapter.java:46)\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 -    at com.google.inject.internal.InjectorImpl.callInContext(InjectorImpl.java:1092)\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 -    at com.google.inject.internal.ProviderToInternalFactoryAdapter.get(ProviderToInternalFactoryAdapter.java:40)\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 -    at com.google.inject.internal.SingletonScope$1.get(SingletonScope.java:194)\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 -    at com.google.inject.internal.InternalFactoryToProviderAdapter.get(InternalFactoryToProviderAdapter.java:41)\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 -    at com.google.inject.internal.InjectorImpl$2$1.call(InjectorImpl.java:1019)\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 -    at com.google.inject.internal.InjectorImpl.callInContext(InjectorImpl.java:1085)\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 -    at com.google.inject.internal.InjectorImpl$2.get(InjectorImpl.java:1015)\n2017-04-26 20:49:32 ERROR StdOutErrRedirect:55 -    ... 4 more`. ",
    "lx308033262": "@hikoz  thanks ,problem solved. ",
    "hkiran": "@kunkun-tang Thank you!!\n\n\nDo you know why it is happening randomly?\n\n\nSorry our actual dag looks like this:\n   JOB_A     JOB_B\n       \\     /   \n        JOB_C\n          |\n        JOB_D\n\nSo, Issue re-occurrence is dependent on JOB_B completion time and JOB_A failing time, which will result in JOB_C and JOB_D cancellation due to JOB_A failure. But the problem is JOB_A still in retry . If you need more details I can upload the sample flow using which we can reproduce the issue.\nI have raised pull request for the same  #867 . @HappyRay  Sorry for the delay in repose. \nYes. Your understanding is correct. Ideally the downstream jobs should only be cancelled after all the retries are exhausted.. ",
    "inieto": "In my company I have some vpn restrictions, not all domains are accessible. Therefore I need to share URL namespace with other apps which I do not own.\nI guess could try to set a reverse proxy like nginx on */azkaban/. and redirect it to *my-azkaban-server/.\nI wouldn't need that setup if only we could configure the contextPath.\nThanks!. ",
    "pgiu": "Hi, I'm still interested in seeing this feature in Azkaban. I know it's been open for more than 2 years, but I can't figure out the way of azkaban to share the path with other apps in the same server. \nThank you! . ",
    "YuanGunGun": "@juhoautio juhoautio help. @kunkun-tang I will do this. ",
    "armisael": "Did you set executor.metric.reports=true (and executor.metric.milisecinterval.default) in your azkaban.properties as stated in the documentation?. Hi,\nI worked on this today, and managed to write a fix. I'll push it later tomorrow, after a few more checks.\nI also took the chance to fix another small bug on the flow parameters input, I hope it won't be a problem if I push them together.. Sure, I'll open another bug then, and submit two PRs. Thanks. So, this broke the azkaban-solo-server... Could it be it broke also the azkaban-web-server and azkaban-exec-server? We are getting many java.lang.NoClassDefFoundError: org/apache/hadoop/conf/Configuration due to import of AzkabanCommonModule, which requires org.apache.hadoop.conf.Configuration.\nAre we supposed to provide our own version of apache hadoop now?. No problem, it was a quick fix.\n@kunkun-tang no, our team doesn't run any Hadoop job, that's why that error was weird to us. Then I noticed the commits, and understood what was going on.\nThe problem is that some common classes make use of hadoop-commons. Both azkaban-web-server and azkaban-exec-server fail when using the AzkabanCommonModule.\nThis is the web server:\njava.lang.NoClassDefFoundError: org/apache/hadoop/conf/Configuration\n at java.lang.Class.getDeclaredMethods0(Native Method)\n at java.lang.Class.privateGetDeclaredMethods(Class.java:2701)\n at java.lang.Class.getDeclaredMethods(Class.java:1975)\n at com.google.inject.internal.ProviderMethodsModule.getProviderMethods(ProviderMethodsModule.java:132)\n at com.google.inject.internal.ProviderMethodsModule.configure(ProviderMethodsModule.java:123)\n at com.google.inject.spi.Elements$RecordingBinder.install(Elements.java:340)\n at com.google.inject.spi.Elements$RecordingBinder.install(Elements.java:349)\n at com.google.inject.spi.Elements.getElements(Elements.java:110)\n at com.google.inject.internal.InjectorShell$Builder.build(InjectorShell.java:138)\n at com.google.inject.internal.InternalInjectorCreator.build(InternalInjectorCreator.java:104)\n at com.google.inject.Guice.createInjector(Guice.java:99)\n at com.google.inject.Guice.createInjector(Guice.java:73)\n at com.google.inject.Guice.createInjector(Guice.java:62)\n at azkaban.webapp.AzkabanWebServer.main(AzkabanWebServer.java:209)\nCaused by: java.lang.ClassNotFoundException: org.apache.hadoop.conf.Configuration\n at java.net.URLClassLoader.findClass(URLClassLoader.java:381)\n at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)\n at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n ... 14 more\nThis is the exec server:\njava.lang.NoClassDefFoundError: org/apache/hadoop/conf/Configuration\n at java.lang.Class.getDeclaredMethods0(Native Method)\n at java.lang.Class.privateGetDeclaredMethods(Class.java:2701)\n at java.lang.Class.getDeclaredMethods(Class.java:1975)\n at com.google.inject.internal.ProviderMethodsModule.getProviderMethods(ProviderMethodsModule.java:132)\n at com.google.inject.internal.ProviderMethodsModule.configure(ProviderMethodsModule.java:123)\n at com.google.inject.spi.Elements$RecordingBinder.install(Elements.java:340)\n at com.google.inject.spi.Elements$RecordingBinder.install(Elements.java:349)\n at com.google.inject.spi.Elements.getElements(Elements.java:110)\n at com.google.inject.internal.InjectorShell$Builder.build(InjectorShell.java:138)\n at com.google.inject.internal.InternalInjectorCreator.build(InternalInjectorCreator.java:104)\n at com.google.inject.Guice.createInjector(Guice.java:99)\n at com.google.inject.Guice.createInjector(Guice.java:73)\n at com.google.inject.Guice.createInjector(Guice.java:62)\n at azkaban.execapp.AzkabanExecutorServer.main(AzkabanExecutorServer.java:143)\nCaused by: java.lang.ClassNotFoundException: org.apache.hadoop.conf.Configuration\n at java.net.URLClassLoader.findClass(URLClassLoader.java:381)\n at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)\n at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n ... 14 more. As an embedded flow:\n```\ntype=flow\nflow.name=echo\nfoo=${foo.value}\n```\nYou can download the project and give it a try, it's linked in the issue description.. Thank you for looking into it!\nDo we know the rationale behind that PR? By reading #226 it doesn't seem like we had a real use-case in mind, it made sense to implement it that way, maybe because this idea of overriding parameters in different flows was not considered.\nDoes removing that condition break any test?. If you don't mind, we might try to spend some time on this and test your solution.. @jamiesjc let me know if something is not clear, thanks!. Hi @jamiesjc, thank you for taking the time to have a look.\n\nFor .properties files, shouldn't they apply to all the flows and also jobs inside the flows?\n\nThat's what I thought when I started working on this; to achieve this it was enough to remove the if statement you mentioned in #1522; there is a test, thought, that due to this change was failing, and it makes sense.\nSo, let's reason about this with the concept of \"scoping\". This is the current implementation of property scoping for a job:\n1) properties defined in .properties files in the job folders, and up;\n1) properties of the parent flow (if any);\n1) output properties from jobs on which the current job depends on;\n1) properties on the source of the job.\nNow, if we replace the 2nd point recursively, we get:\n1) properties defined in .properties files in the job folders, and up;\n1) properties of the parent flow (if any):\n   1) properties defined in .properties files in the parent job folders, and up;\n   1) output properties from jobs on which the parent depends on;\n   1) properties on the source of the parent.\n1) output properties from jobs on which the current job depends on;\n1) properties on the source of the job.\nThe reason that if statement was added is 2.i: if the parent job is in a different folder than the inner job, the properties coming from the parent .properties files are out of scope to the job itself, and should be taken out; indeed, that if statement was specifically removing them for nested flow nodes.\nThis lead to bug #1522 though: properties coming from those files should not be simply removed from any scope: they should be removed from the scope of inner flows only; they should still be used for evaluating properties of the flow node itself. Take the example shown in bug #1522: both do-echo-a and do-echo-b are nested flows, and both set foo=${foo.value}; foo.value is a variable defined in the default.properties file located in their folders; the inner job echo should therefore receive the value of foo, but not the value of foo.value (it is defined in a .properties file that is out of scope). We can't simply ignore reading default.properties, though, since its content is needed to evaluate foo=${foo.value}.\nWe had therefore to implement a new concept of \"visibility\" of properties: .properties files of a flow should be used only to evaluate properties on the flow node, and be ignored for inner jobs; in the code this is represented by the isPrivate flag: private properties are filtered out when reading properties from parent flows; to do so, we had to:\n- add a makePrivate method on Props;\n- add a getPublicKeySet method on Props, which is used inside PropsUtils.resolveProps to resolve only public properties;\n- add a clone method on Props that allows to specify whether to clone all the properties, or only the public ones (through the onlyPublic parameter): this is used in FlowRunner to get only the public properties of the parent flow.. @jamiesjc you are correct, this happens only when inner flow exists in a different folder.\n@HappyRay this is blocking our migration to azk 3.0, so it would be greatly appreciated.\nI understand you are developing a new way of representing flows; I guess you are not simply dumping the current .job-based flows, otherwise upgrading to the new azkaban with YAML support would be a big pain. This said, this issue will still be there, regardless of the new YAML implementation.\nThe real question is what @jamiesjc said: do you want to support this scenario? As stated in #1522, this is the only way to execute the same job/flow with different parameters in .properties files. This is not that unlikely, we are doing it quite a lot. Workarounds are possible, but quite nasty.. Thank you @jamiesjc for the answer, and sorry for the late reply, I've been away for a few days.\nI'm really curious to see the new YAML-based way of defining flows, I'm not a big fan of the current implementation, even if after so many years I got used to it. As soon as it's able to represent complex flows as we currently can, I think it will be a great addition (and I'm sure YAML composition with anchors will come in handy).\nAbout your question, there are some cases where the na\u00efve implementation (inheriting all the parent properties) fails; you can try it out: just get on master branch, comment the if statement of FlowRunner.java:652 and run the tests: one of those defined in FlowRunnerPropertyResolutionTest fails.\nThe problem is shown in execpropstest: job4 should get property props4=shared4 from subdir/shared.properties, but it gets props4=moo4 from moo.properties.\nThese are the properties read from every source:\n1. from properties files\n  key=props1 value=shared1\n  key=props2 value=shared2\n  key=props3 value=moo3\n  key=props4 value=shared4\n  key=props5 value=moo5\n  key=props6 value=shared6\n  key=props8 value=shared8\n2. from parent flow\n  key=props1 value=shared1\n  key=props2 value=shared2\n  key=props3 value=moo3\n  key=props4 value=moo4\n  key=props5 value=innerflow5\n  key=props6 value=innerflow6\n  key=props7 value=flow7\n  key=props8 value=innerflow8\n  key=props9 value=gjob9\n  key=props10 value=gjob10\n3. from output props of dependencies\n  key=props7 value=g2job7\n  key=props9 value=g2job9\n4. from job source\n  key=props8 value=job8\n  key=props9 value=job9\nAs you can see, at step 1 the property is correct: props4=shared4; at step 2, though, props4=moo4 overwrites the correct value; this is due to the fact that it is a property file of the parent flow, which gets (wrongly) priority over the property file of the inner flow.\nThis thing is a subtle variant of the \"scoping\" issue I stated before.\nHTH. Hi,\nI understand your point; it's sad because this makes impossible for us to migrate all of our flows without a strong intervention, but your code, your rules. The good thing of the current implementation is that when things don't work, they crash instead of silently passing bad properties. This at least will help us identifying where the issues are.\nThat said, I hope the new YAML-based flows will be expressive enough to represent complex structures; simplicity and readability are very important, but if the old way of defining flows is buggy, and the new one is not able to cover all the use cases, it would rule out azkaban for most users (properties duplication could be an issue is some cases, for example). I'm sure you considered analysing how others tackled the same issue (the first coming to my mind is Ansible, for example), so I'll wish you all the best, I'm really looking forward to seeing this new feature come alive.. @HappyRay the DSL looks for sure promising! Will it be included in the azkaban project, then?. Ah right! I forgot to mention it: yes, Job Editing had the same issue, I discovered it while checking the usages of the . editRow class. Since I was on it, I fixed it as well.. I'm not really familiar with jQuery as well, but as far as I understand, evt.target is what triggered the event (what you clicked on), while evt.currentTarget is the element on which the event is bound. Since the input is inside the span, when you click on the input evt.target points on it, while evt.currentTarget points to the span.\nI don't think clearing the input was the intended behaviour of the authors: when not in \"editing mode\" in the DOM there is no input, only the span, containing the value of the property; when you click on the span, an input is created to allow you to edit it. The authors here decided to copy the value onto the input, and clear the span, instead of simply hiding it.\nNow, since the input is created inside the span, and the event is bound on the latter, when clicking on the input the event is propagated to the parent, the trigger is fired again, and the procedure to create the input is re-executed: this time though, the span contains no value: the input is (re)created with an empty text, leading to this frustrating behaviour: you can't easily copy/paste part of the input by clicking on it.. Apparently the bug appears only if you close the dialog by clicking outside of it; if you hit Cancel instead, the properties correctly appear only once.. ",
    "shivakun": "\nDisable/Enable button before \"Execute Flow\" would be good.. ",
    "ragu101": "\n\"Disable/Enable\" button next to \"Remove Schedule\" would be better. \nCurrently we don't find any disable feature for the flows which are already scheduled. Please . If this function is already available, please guide us how to use it ?\nOr is it planned for upcoming releases ?. We feel this is a very important feature missing. Where tools like rundeck has this one already.  . We haven't got any update yet from the community.\nOn Thu, 3 May 2018, 6:04 PM duke, notifications@github.com wrote:\n\nWe met same problem, it is really an important feature. Any updates on\nthis? Or is it on the road map releases?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/azkaban/azkaban/issues/901#issuecomment-386247163,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AYceltnKI4sYBQO8EBdPtodobaTGMKYXks5tutY0gaJpZM4L6TOo\n.\n. \n",
    "sunghyuk": "May I submit a PR for this?\nI want to just edit properties files after building the package.. sorry for spam. typo in branch name.. sorry, I'm not native. fix please. ",
    "zhengxle": "the scene is that we package many jobs to a project, but when some jobs failed, we just rerun the unsuccessful jobs, but the headers of successful jobs will be brought with the failed jobs,even the successful jobs are disabled. how to filter? @kunkun-tang . ",
    "jessica0530": "how do you fix . I also meet this problem,how to fix it. ",
    "realman129942": "how do you fix. @ameyamk  I use the master's version. ",
    "smlHao": "expected too. expected too. import  azkaban source code to eclipse ,found this error too. ",
    "iCoolchar": "@chengren311  It never works. No matter how long I set the duration and how long I have waited. I think you can 100% reproduce it.... ",
    "keiki1120": "@chengren311 Has this bug been fixed?  My Azakaban version is 3.25.0.  It never works too.. @chengren311 . @chengren311 I can receive emails on flow failure. So I think my email setup is correct . I just test the kill function, the flow can be killed . But I still can't receive the email. If I enable email notification,, I can receive the failure email not the SLA email , when the flow has been killed.. \nI didn't configure the email setting in job file.. I didn't configure this file.. @chengren311  I just checked this file . I configured these properties already. .. ",
    "duanyixuan": "@kunkun-tang:\n you are right.  maybe i know how to do it.\nfirst, choose Run Concurrently   under Concurrent Execution Options,\nsecond,choose to do schedule setting.\ncrontab will follow Run Concurrently action\ni think , it is a better way to display current \"Concurrent Execution Options\" setting on every flow under the schedule.. ",
    "yxydde": "When can release ?. ",
    "goelrajat": "Hi. I have a query on implementation of HA being done. Do you plan to restart jobs in 'Running' status after HA is done? Currently, the Running jobs move to Failed state when server is manually restarted after crash.\nAlso, if I have a periodic scheduled job running say every 1 mins and current time is say 7:00. My Azkaban server crashes and it restarts at say at 7.10. Job instances between 7:00 and 7.10 will be missed. Do you plan to relaunch these instances as well after HA ?. Any updates on when this feature will be available?. ",
    "sellers": "Would stickyness be a factor that needs to be taken into account as well.   I have a user here who is deployed behind an AWS ELB and as a result losses sessions (client IP changed in the headers).   X-Forward-For may be a work-around?  . ",
    "steverding": "Any news here ? Roadmap says, azkaban 4.0 should have HA webservers and should have been released in Q2 2017. but there are only 3.xx versions available yet.. Hi,\nsorry, i am not a programmer, I just found out, that this is a problem when using azkaban.\n. ",
    "happyapple668": "I am looking forward to the HA to be released . six six six. pls close the issue. so what's your question?. now I forked the azkaban project at 2018.7.29 14:57 and prepare the maven format. at https://github.com/happyapple668/azkaban But it's not work good~. For the reason of network in my company, I can not download some jar. Is  parameter \"executor.port\" necessary in web-server/config/azkaban.properties , really???\nI comment the parameter \"executor.port\" in  web-server/config/azkaban.properties  and no error happens while starup.It's work good~. The source file web-server/config/azkaban.properties may not contain all the possible parameters.. based on memory and disk. More executors result in better performance. Now I solve the problem.But when I run the job using type=hive.Other error occurred, \n https://github.com/happyapple668/pics/blob/master/issue/azkaban/azkaban-hive-error.jpg. the error screenshot url:\nhttps://github.com/happyapple668/pics/blob/master/issue/azkaban/azkaban-hive-error.jpg. If I used the type=hive, the error always occurred . ref to https://github.com/azkaban/azkaban/pull/1423. \u8fd9\u4e5f\u6765\u63d0\u4e00\u4e2aissue\uff0c\u65e0\u8bed\u4e86\uff0c\u81ea\u5df1\u6539\u6210\u82f1\u8bed\u554a\u3002\u672c\u6765azkaban\u90fd\u662f\u56fd\u5916\u7684~~. hahaha  The same as #1872. \u4f60\u90fd\u542f\u52a8\u554a\uff0c\u542f\u52a8\u4e86\u4f1a\u67092\u6761\u7684. ",
    "gao634209276": "I am looking forward to the HA to be released\n. my azkaban version: 3.43.0\nI edit a command type job like this:\ntype=command\ncommand=sh test.sh\nand the test.sh write :\n#!/bin/bash env\nsource ~/.bashrc\ncat my_file\nmore my_file\n/bin/more my_file\ncount1=$(more my_file | wc -l)\necho ${count1}\nwhen azkaban run this job, the cat command work , but it will block forever when run more command\uff01\nIs there any problem?  Help me @rjurney @mtrna @jart @armisael @jkreps . my previous company use azkaban version 2.5.0\uff0cthey exec any command well. Hey  @reallocf :\nSorry, My example is not very good. If the text exceeds one page, more command will be blocked.\nas you said, this command count1=$(more my_file | wc -l),when  I use command line or set  crontab to run this subshell , it work good(what you imagine cat not explain this command).  but in azkaban it does work.  \nWhat is the difference between crontab and azkaban on run this command?. on this case, that one problem, There is another problem with this:\n shell script run count1=$(more my_file | wc -l) before, and the next command for example is curl url to do somthing.\nDue to azkaban run count1=$(more my_file | wc -l) being blocked, I kill the Job use Azkaban.\nbut I fount the next few commands run when I kill the job.\nHow did that happen\uff1f. @reallocf yeah, is not just a simple job, so I use azkaban resolve dependence, but I found this error when run count1=$(more my_file | wc -l), I mean: I want to know the difference at this case... \nthe case of killing a blocked job and still running remainning commands is difficult reappearance\uff0c\nThe content of the shell script is like this:\nsource ~/.bashrc\nhdfs -dfs -getmerge /hdfs/path my_file\ncount1=$(more my_file | wc -l)\nurl='server_url'\necho \"$url\"\nres=$(curl $url/key=$count1)\necho $res\n the server url is only request by me, I  check the server log, the date of killing azkaban job is exactly the same as the date of request server URL. And I have two issues at this case:\nIt's hard to find reason with this wrong message. can azkaban log more information? \nwhen flow scheduling fails, why can't send an alarm or try again ? . ",
    "avi-0107": "Any update here? what is the expected time for Azkaban HA release.\n@jamiesjc @hreview . ",
    "shuzhang1989": "@kunkun-tang i think these are valid thoughts. But for the old tasks stuck, do we need to have a gc like process to keep health check all tasks? . nice work @chengren311 !. please review all import orders are good. @chengren311 what is the current cache utilization? we may need to check the current number to decide the default value.. lgtm, but agreed with @HappyRay that we need some sort of format guide of writing docs.. +1 \n\u53ef\u4ee5\u628ademo share\u5230\u767e\u5ea6\u7f51\u76d8\uff1f\u5e94\u8be5\u6709LICENSE\u5c31\u53ef\u4ee5\u5427. \u53ef\u4ee5\u6539\u6210\u62fc\u97f3\u554a. +1, can i get a burger king if i finish this project?. @chengren311 +1, don't see the advantage. should we have a javabean?. fqdn name maybe. nit: empty line. i see, i thought for server configs was an unfinished sentence. thanks @HappyRay for the explanation :). add the unit into the variable name: MEMORY_CHECK_INTERVAL_MS. space between for and (. space between +. space between *. should we log when we got a double kill?. +1 for the good practice that one diff only does one thing. +1 preventing thundering herd . this.getSlaOptions().stream.foreach(s -> slaOptions.add(s.toObject());. is builder pattern preferred here?\npublic ExecutableFlow setSlaOptions() {\n   this.slaOptions = slaOptions;\n   return this;\n}. List slaOptions = slaOptionsObject.stream().map(s -> SlaOption.fromObject(s)).collect(Collector.toList). do we prefer logger.info(\"Doing expire actions for {} for {}\", action.getDescription(), t)? it makes code more readable. is Trigger::toString() implemented? what will be the output?. java util import should be in the first section?. extra line. log?. space between \"+\". swtich is a bit hacky here, should we use an TriggerActionFactory() for producing TriggerActions?. do you want to have a shutdown hook on logging / executing scheduled but not executed tasks?. these 2 ops are not transactional, how to deal with that?. order. what does it mean?. will t be null?. Order. builder pattern?. format.  + this.node.getStartTime();. remove this line. remove this line. extra line. i think here is not just for code reuse? Semantically inheriting an abstract class makes sense, users are free to pass in customized logic to build their own validator right?\nAnother example is rocksdb's CompactionFilter, which the db provides an interface, user can write their own compaction logic: https://github.com/facebook/rocksdb/blob/c364eb42b5fde3bf501e04c5a23f32c99ec4465c/utilities/blob_db/blob_compaction_filter.cc#L17. +1, we can do list->string serialization on the caller side. the function should provide behavior consistent with its name. . ",
    "zhuxt2015": "@HappyRay Assume I have thirty Executors , then create two tag A and B, the A have 15 Executors\uff0cand B have another 15 Executor,when upgrade Executors of A\uff0call flows set to B. vice versa.. ",
    "sharks222": "@HappyRay  If I have developed a new function for Executor, I need to test this feature in a production environment. Add a tag A to the Executors with new feature and  then assign the flow to the  this group of Executors with tag A. If flow can run stably, then use the Executors directly, otherwise return to the previous Executors.. @ameyamk How long  will this feature take?. @chengren311 \nhi,\nHow do you will  implement the Azkaban tag function?\nAdd the tag field to the executor and add the tag option to the job configuration.\nThen match the tag before selecting Executor.\nRight?. ",
    "jonathansp": "+1. ",
    "jirislav": "Sure, it's attached in the first comment :) .. it's just \"cron\": null, which is valid JSON. ",
    "hriviere": "Not solve the issue but we have a different error ! \nI delete all H2 files to restart from scratch and I configure azkaban with : \ndatabase.type=h2\nh2.path=/var/lib/azkaban/azkaban;DB_CLOSE_ON_EXIT=TRUE;FILE_LOCK=NO\nh2.create.tables=true\nAfter ~24 hours of run I got a azkaban crash (webserver UI is up but any sql query fails) : \n2017-05-03 10:30:17 jdbc[18]: exception\norg.h2.jdbc.JdbcSQLException: General error: \"java.lang.IllegalStateException: Reading from nio:/var/lib/azkaban/azkaban.mv.db failed; file length -1 read length 768 at 50986998 [1.4.193/1]\" [50000-193]\n        at org.h2.message.DbException.getJdbcSQLException(DbException.java:345)\n        at org.h2.message.DbException.get(DbException.java:168)\n        at org.h2.message.DbException.convert(DbException.java:295)\n        at org.h2.message.DbException.toSQLException(DbException.java:268)\n        at org.h2.message.TraceObject.logAndConvert(TraceObject.java:352)\n        at org.h2.jdbc.JdbcPreparedStatement.executeUpdate(JdbcPreparedStatement.java:151)\n        at org.apache.commons.dbcp2.DelegatingPreparedStatement.executeUpdate(DelegatingPreparedStatement.java:98)\n        at org.apache.commons.dbcp2.DelegatingPreparedStatement.executeUpdate(DelegatingPreparedStatement.java:98)\n        at org.apache.commons.dbutils.QueryRunner.update(QueryRunner.java:487)\n        at org.apache.commons.dbutils.QueryRunner.update(QueryRunner.java:403)\n        at azkaban.executor.JdbcExecutorLoader.updateExecutableFlow(JdbcExecutorLoader.java:154)\n        at azkaban.executor.JdbcExecutorLoader.updateExecutableFlow(JdbcExecutorLoader.java:126)\n        at azkaban.execapp.FlowRunner.updateFlow(FlowRunner.java:307)\n        at azkaban.execapp.FlowRunner.updateFlow(FlowRunner.java:301)\n        at azkaban.execapp.FlowRunner.progressGraph(FlowRunner.java:504)\n        at azkaban.execapp.FlowRunner.runFlow(FlowRunner.java:395)\n        at azkaban.execapp.FlowRunner.run(FlowRunner.java:223)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.IllegalStateException: Reading from nio:/var/lib/azkaban/azkaban.mv.db failed; file length -1 read length 768 at 50986998 [1.4.193/1]\n        at org.h2.mvstore.DataUtils.newIllegalStateException(DataUtils.java:765)\n        at org.h2.mvstore.DataUtils.readFully(DataUtils.java:435)\n        at org.h2.mvstore.FileStore.readFully(FileStore.java:98)\n        at org.h2.mvstore.Page.read(Page.java:190)\n        at org.h2.mvstore.MVStore.readPage(MVStore.java:1954)\n        at org.h2.mvstore.MVMap.readPage(MVMap.java:736)\n        at org.h2.mvstore.Page.getChildPage(Page.java:217)\n        at org.h2.mvstore.MVMap.binarySearch(MVMap.java:468)\n        at org.h2.mvstore.MVMap.binarySearch(MVMap.java:469)\n        at org.h2.mvstore.MVMap.get(MVMap.java:450)\n        at org.h2.mvstore.MVStore.getMapName(MVStore.java:2469)\n        at org.h2.mvstore.MVMap.getName(MVMap.java:945)\n        at org.h2.mvstore.db.TransactionStore$1.fetchNext(TransactionStore.java:555)\n        at org.h2.mvstore.db.TransactionStore$1.<init>(TransactionStore.java:530)\n        at org.h2.mvstore.db.TransactionStore.getChanges(TransactionStore.java:524)\n        at org.h2.mvstore.db.TransactionStore$Transaction.getChanges(TransactionStore.java:813)\n        at org.h2.engine.Session.rollbackTo(Session.java:751)\n        at org.h2.command.Command.executeUpdate(Command.java:282)\n        at org.h2.jdbc.JdbcPreparedStatement.executeUpdateInternal(JdbcPreparedStatement.java:160)\n        at org.h2.jdbc.JdbcPreparedStatement.executeUpdate(JdbcPreparedStatement.java:146)\n        ... 16 more\nCaused by: java.nio.channels.ClosedChannelException\n        at sun.nio.ch.FileChannelImpl.ensureOpen(FileChannelImpl.java:110)\n        at sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:721)\n        at org.h2.store.fs.FileNio.read(FilePathNio.java:74)\n        at org.h2.mvstore.DataUtils.readFully(DataUtils.java:421)\n        ... 34 more\n2017-05-03 10:30:17 jdbc[16]: exception\norg.h2.jdbc.JdbcSQLException: The object is already closed; SQL statement:\nINSERT INTO execution_jobs (exec_id, project_id, version, flow_id, job_id, start_time, end_time, status, input_params, attempt) VALUES (?,?,?,?,?,?,?,?,?,?) [90007-193]\n (...). For test purpose I relaunch the 3.20 instance  with the h2 jar of the 3.0.0 release (h2-1.3.170.jar in place of h2-1.4.193.jar). \nServer is booting, waiting to see if I arrive to reproduce the issue with this h2 version.... ",
    "simrandeep11": "@hriviere \nWere you able to solve the issue?. ",
    "xkrogen": "The change for this is quite simple. I wanted to write a unit test but HadoopSecurityManager_H_2_0 currently isn't really set up for that (e.g. being able to specify your own configuration, not using the execute-as-user binary); I would need to make some changes. Anyone have thoughts on whether I should just test manually or go ahead with changes to the security manager?. Hey @wininco, this isn't really the right place to ask about that. You may want to ask on the Google group: https://groups.google.com/forum/?fromgroups#!forum/azkaban-dev. Hey @kunkun-tang , I'm not sure if this is the right approach. Previously, if a user specified pig.additional.jars, they would still get all of the default JARs. I think it's probably common for people to use this setting to add only a few JARs, e.g. their custom UDFs. Now, if you specify additional JARs, you have to be sure to include the defaults as well.\nMy original thought was just to allow the user to additionally specify default.pig.additional.jars, which would allow them to override the system-provided defaults. I think this change is much safer, as users shouldn't really have been specifying default.pig.additional.jars in the past, whereas they certainly are using the pig.additional.jars property.. Extra space. Why a static initialization block instead of doing this on line 53? Also if it is a static final constant, shouldn't it be LOGGER?. Should have an empty line before @param. I wonder if there is a global working dir config defined somewhere else that can be used here instead of a custom one just for HadoopTuningSecurePigWrapper?. constant for this?. Should this be in TuningCommonConstants?. ",
    "wininco": "when i startup a azkaban use \"./bin/azkaban-web-start.sh \" , error:\nException: java.lang.StackOverflowError thrown from the UncaughtExceptionHandler in thread \"main\"\nwho can help me,thinks , I am chinese. OK thanks. network issues. ",
    "prokod": "See discussion here #1390\nIt might be related though no concrete solution has been found.\nThose are connected as the solution on Azkaban 3.0.0 was to use user.to.proxy: azkaban which in later versions triggers Exception\njava.lang.RuntimeException: Not permitted to proxy as 'azkaban' through Azkaban\n    at azkaban.jobExecutor.ProcessJob.run(ProcessJob.java:225)\n    at azkaban.execapp.JobRunner.runJob(JobRunner.java:745)\n    at azkaban.execapp.JobRunner.doRun(JobRunner.java:587)\n    at azkaban.execapp.JobRunner.run(JobRunner.java:548)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:748). Hi, Have you figured out maybe what exactly is the root cause ? We are running Azkaban 3.32.2.\nThx. Hi @kunkun-tang In our case we use two executors. I haven't though about the possibility to update active state through script prior to azkaban-web-server start. So in case that an executor is down from any reason it is being restarted and following it you run a script that updates state ? If so can you share this script ? Thx.. BTW, I looked at the documentation for executor setup. It is written \n\nConfigure executors for Multiple Executor Mode\n...\nInsert all executors into the mysql DB for executor setups\n\nWhy it is written so when in recent version the executor updates the DB when it starts up.\nI suppose that this lead me to believe that if the executor behaviour was modified to register itself in the executor table it is also activating itself with startup.. Yes it is. Thank you for taking the time to explain that.. How will you guys suggest us to do parameters passing between jobs then ? \nRight now I am facing an issue where a job that should write to JOB_OUTPUT_PROP_FILE and is being executed by a user other then azkaban is failing on permission to write the json file inside the execution dir which is owned by azkaban user.. @HappyRay @reallocf Just wanted to let you know that I was able to kinda fix that: The issue was we had copied project directories from azkaban 3.0.0 to azkaban 3.34.0 and this triggered the permission issue. Once we had a clean installation and a new deployment of one the previous failing projects we did not observe the permissions issue anymore.\nThis leaves me with one open issue which is how we should migrate the projects from 3.0.0 to recent version. It seemed to us that when trying to use 3.0.0 maintained DB with recent Azakaban web and exec there is some error message popping up when it tries to load the project to the exec from DB. We will try it soon and I will update whether this is true enough.. Hi @HappyRay so my previous statement that it works as expected was an incorrect one.\nIt appears I had set execute.as.user to false and this is why I did not have issues with the specific workflow I was testing.\nWhen I reinstated execute.as.user=true then some of the directories under the execution are created with user.to.proxy user as owner and then azkaban user cannot write to those directories for instance:\n07-09-2017 16:24:46 CEST preprocessing-hourly-forward ERROR - Could not open log file in executions/75/forwardFlow for job preprocessing-hourly-forward_calcCheck\njava.io.FileNotFoundException: /opt/azkaban-exec-server-3.34.0/executions/75/forwardFlow/_job.75.preprocessing-hourly-forward_calcCheck.log (Permission denied)\n    at java.io.FileOutputStream.open0(Native Method)\n    at java.io.FileOutputStream.open(FileOutputStream.java:270)\n    at java.io.FileOutputStream.&lt;init&gt;(FileOutputStream.java:213)\n    at java.io.FileOutputStream.&lt;init&gt;(FileOutputStream.java:133)\n    at org.apache.log4j.FileAppender.setFile(FileAppender.java:294)\n    at org.apache.log4j.RollingFileAppender.setFile(RollingFileAppender.java:207)\n    at org.apache.log4j.FileAppender.&lt;init&gt;(FileAppender.java:110)\n    at org.apache.log4j.RollingFileAppender.&lt;init&gt;(RollingFileAppender.java:79)\n    at azkaban.execapp.JobRunner.createFileAppender(JobRunner.java:317)\n    at azkaban.execapp.JobRunner.createLogger(JobRunner.java:266)\n    at azkaban.execapp.JobRunner.doRun(JobRunner.java:569)\n    at azkaban.execapp.JobRunner.run(JobRunner.java:552)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:748)\nIn this example forwardFlow dir owner is same as user.to.proxy which is different then azkaban user.\nAny ideas how to resolve that?. So here is the state of things:\n In Azkaban 3.34.0 we get a permission denied error between jobs (looking at the flowLog tab for the execution) and the details are in my last comment.\n In Azkaban 3.30.1 and 3.32.2 we do not see the above error, it passes this stage but within the job it fails on the following line:\necho \"{\\\"param.doRun\\\": \\\"$DO_RUN\\\", \\\"param.input.partitions\\\": \\\"$INPUT_PARTITIONS\\\", \\\"param.spark.app.sessionLookAheadCalc\\\": \\\"$SESSION_LOOK_AHEAD_CALC\\\"}\" > $JOB_OUTPUT_PROP_FILE\nwith the following error\n08-09-2017 09:25:40 CEST preprocessing-hourly-forward_calcCheck INFO - {\"param.doRun\": \"false\", \"param.input.partitions\": \"450\", \"param.spark.app.sessionLookAheadCalc\": \"true\"}\n08-09-2017 09:25:40 CEST preprocessing-hourly-forward_calcCheck INFO - /opt/azkaban-exec-server-3.32.2/executions/77/forwardFlow/../scripts/calcCheck.sh: line 286: /opt/azkaban-exec-server-3.32.2/executions/77/forwardFlow/preprocessing-hourly-forward_calcCheck_output_4944073578545338712_tmp: Permission denied\n08-09-2017 09:25:40 CEST preprocessing-hourly-forward_calcCheck INFO - Process completed unsuccessfully in 7 seconds.\nBtw, we are running Azkaban on CentOS 6. An example project is here:\npreprocessing-hourly_2.10_cdh5-0.11.9-SNAPSHOT-issue-1390.zip\nThis is  a stripped down one with only first two jobs, the second fails on our 3.30.1/3.32.2 installations\nThis example can be used also for the issue with 3.34.0 where 2nd job doesn't get executed even (see my previous two comments). @reallocf It is according to Azkaban 3 doc:\nchmod 6050\nownership root:azkaban. The permission-ing approach taken in this project has a hidden assumption which is a crucial one! The user azkaban-exec service is running under (usually azkaban) should have umask 002 which means that by default created file/dir will have also write permission set.\n@reallocf please correct me if I am mistaken or not being accurate.. Build with tests passes on local machine. In Travis unfortunately not. Closing it. Looking forward! Any hints ? UI design if any, integration with Gradle/Maven hadoop-plugin .... Hi @reallocf I have tested 3.36.0 on real flow and unfortunately it blows on-before-start of the second job in the flow because the permissions of the working dir were changed from azkaban:azkaban to user:azkaban while running the first job.\nNow this chain of events leads to an exception when trying to create a log file for the second job. Something like this:\njava.io.FileNotFoundException: /opt/azkaban-exec-server-3.36.0/executions/28/forwardFlow/_job.28.preprocessing-middomain-forward_calcCheck.log (Permission denied)\n    at java.io.FileOutputStream.open0(Native Method)\n    at java.io.FileOutputStream.open(FileOutputStream.java:270)\n    at java.io.FileOutputStream.&lt;init&gt;(FileOutputStream.java:213)\n    at java.io.FileOutputStream.&lt;init&gt;(FileOutputStream.java:133)\n    at org.apache.log4j.FileAppender.setFile(FileAppender.java:294)\n    at org.apache.log4j.RollingFileAppender.setFile(RollingFileAppender.java:207)\n    at org.apache.log4j.FileAppender.&lt;init&gt;(FileAppender.java:110)\n    at org.apache.log4j.RollingFileAppender.&lt;init&gt;(RollingFileAppender.java:79)\n    at azkaban.execapp.JobRunner.createFileAppender(JobRunner.java:317)\n    at azkaban.execapp.JobRunner.createLogger(JobRunner.java:266)\n    at azkaban.execapp.JobRunner.doRun(JobRunner.java:569)\n    at azkaban.execapp.JobRunner.run(JobRunner.java:552)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:748)\nI have fixed this on my local copy of the azkaban project by including in the finally block assignUserFileOwnership call with user 'azkaban', essentially reverting ownership. If you would like I can submit an MR for that, but it is simple as:\n} finally {\n        info(\"Reverting current working directory ownership\");\n        assignUserFileOwnership(\"azkaban\", getWorkingDirectory());\n        info(\"Process completed \"\n            + (this.success ? \"successfully\" : \"unsuccessfully\") + \" in \"\n            + ((System.currentTimeMillis() - startMs) / 1000) + \" seconds.\");\n      }\nin ProcessJob#run\nI hope this makes sense. I have it set up as follows\n$ cat /proc/version\nLinux version 3.10.0-514.26.2.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-11) (GCC) ) #1 SMP Tue Jul 4 15:04:05 UTC 2017\nIn systemd I start the exec server like this:\n[Unit]\nDescription=Azkaban executor service\n...\n[Service]\nType=forking\nUser=azkaban\nWorkingDirectory=/opt/azkaban-exec-server-3.36.0\n...\nExecStart=/opt/azkaban-exec-server-3.36.0/bin/azkaban-executor-start.sh\n...\nThe owner of the exec service is azkaban when psing  \nexec-as-user permissions\n$ ll execute-as-user \n---Sr-s---. 1 root azkaban 13688 Oct  4 21:50 execute-as-user\nThe permissioning of the exec directories/files inside the failed execution:\nFirst time created under executions the permissioning is azkaban:azkaban\nAfter projBuildInfo job is finished the working directory looks like this:\n$ pwd\n/opt/azkaban-exec-server-3.36.0/executions/28\n$ ls -la forwardFlow/\ntotal 48\ndrwxr-sr-x. 2 scheduler azkaban 4096 Oct  4 21:59 .\ndrwxr-sr-x. 3 azkaban   azkaban 4096 Oct  4 22:42 ..\n-rw-r--r--. 1 azkaban   azkaban 4035 Oct  4 21:59 _job.28.preprocessing-middomain-forward_projBuildInfo.log\n-rw-r--r--. 3 azkaban   azkaban  783 Oct  4 21:59 preprocessing-middomain-forward_calcCheck.job\n-rw-r--r--. 3 azkaban   azkaban  489 Oct  4 21:59 preprocessing-middomain-forward_common.properties\n-rw-r--r--. 3 azkaban   azkaban  888 Oct  4 21:59 preprocessing-middomain-forward_copyToAms.job\n-rw-r--r--. 3 azkaban   azkaban  133 Oct  4 21:59 preprocessing-middomain-forward.job\n-rw-r--r--. 3 azkaban   azkaban  651 Oct  4 21:59 preprocessing-middomain-forward_midDomainShuffle.job\n-rw-r--r--. 3 azkaban   azkaban  262 Oct  4 21:59 preprocessing-middomain-forward_projBuildInfo.job\n-rw-r--r--. 1 scheduler azkaban    0 Oct  4 21:59 preprocessing-middomain-forward_projBuildInfo_output_6921027372125729455_tmp\n-rw-r--r--. 1 scheduler azkaban 4040 Oct  4 21:59 preprocessing-middomain-forward_projBuildInfo_props_399184297853803228_tmp\n-rw-r--r--. 3 azkaban   azkaban  630 Oct  4 21:59 preprocessing-middomain-forward_results2hive.job\n-rw-r--r--. 3 azkaban   azkaban  365 Oct  4 21:59 preprocessing-middomain-forward_writeMetadata.job\nDo you see something wrong with the setup? Any other pointers?\n. Ok. so setting umask 002 did the trick for me.\nThx.. ",
    "yy1": "Hello,\nBut how we configure the job flows which execute on the separate execution servers? I mean how can we make the different jobs execute its own environment.\nThank you very much.\n. ",
    "m4h": "In scrot below can be seen:\n- executions 7011-7016 where run using 1 AZK web-server (1 per minute)\n- executions 7019-7026 after starting another AZK web-server  (2 per minute)\n\nThis is scheduler definition.\n\n. The use case is simple - keep high availability of AZK web service (scheduler, user access).\n. ",
    "justin-yan": "Hi there -\nI actually have a fork of Azkaban that has implemented Google SSO, and I've been trying to decide whether it would be worth the effort to get it upstreamed into Azkaban.\n\nIt's implemented as a UserManager plugin\nIt does require, however, modifying the front-end templates in order to add the SSO buttons, and adds a few new configuration parameters, which is why I didn't implement it purely as a plugin.\n\nMy main concern is that the logic for managing users is mostly hidden behind the usermanager interface, and as my fork is currently implemented, will introduce some logic that will sprawl beyond that (into the templates, etc.).\nIf Azkaban would be amenable to accepting such a contribution, I'd be happy to take the time to get it into a state where we could upstream this.. ",
    "likunbyl": "METRICS does the trick. ",
    "kris37": "i find I found the cause of the issue\uff0cin azkaban.properties if have two or more same key,the loader does't combin as one. ",
    "monkingmon": "Hello,I also Found this phenomenon.The old version provides this function. If you solved the problem?. Hi,I also meet this problem.I'm not sure whether to do so:\n1,put execute-as-user.c into /home/azkaban/azkaban/azkaban-exec-server/plugins/jobtypes\n2,gcc ${dirpath}/execute-as-user.c -o execute-as-user | chown root ${dirpath}/execute-as-user | chmod 6050 ${dirpath}/execute-as-user;dirpath=/home/azkaban/azkaban/azkaban-exec-server/plugins/jobtypes\n3,modify ${dirpath}/commonprivate.properties --execute.as.user=true,azkaban.native.lib=/home/azkaban/azkaban/azkaban-exec-server/plugins/jobtypes\nabove,I can run some jobs which type are command.\n. ",
    "boycode": "Hi ,\nFixed the issue .\nFew things needs to be taken care .\n\nwith the above setting only in the executor will solve this problem\nBetter to give the absolute path for the executor-as-user \nMake sure that linux user and the user from the azkaban user manager  are the same\nKeep only the commonprivate.prop in the jobtypes under exec. if you have any other plugin , need to setup it also clearly\nwhile starting better to start as Sudo user for azkaban-web /exec.\n\nThanks,\nVishnu. ",
    "wanghong1314": "please this issue already resolve?. ",
    "priyanshjain28": "@juhoautio Hi, this is exactly what we are looking forward to do. We process data in our jobs scheduled in azkaban. If azkaban goes down and comes up after a certain period of time, there is a data hole created for the jobs which did not run. Below example might clear this up:\nCase Scenario: A job is scheduled hourly in azkaban. Let's say the job takes 45 minutes for successful completion. Let the scheduled time for the job be:\n12pm -> 1pm -> 2pm -> 3pm -> 4pm and so on..\nLet's say azkaban went down at 12:30pm and came up at 2:30pm.\nCurrent Scenario: Azkaban will not restart the failed job (12pm job) or any missing instances in between. It will continue with its execution by running the next scheduled instance i.e. 3pm.\nExpected Scenario: Azkaban should run in replay mode and re-run the 12pm job and other missing jobs. Here we have 2 cases:\n1. Job was scheduled keeping concurrency on: Azkaban will launch all the missing instances together. Thus, at 2:30pm, three instances correponding to 12pm, 1pm and 2pm will be launched concurrently. Azkaban will continue with normal execution post this.\n2. Job was scheduled keeping pipeline feature on: Azkaban will launch the 12pm instance at 2:30pm. It will put other instances in a pipeline. Once the execution of 12pm instance(which was re-run at 2:30pm) is over at 3:15(45min is the processing time for one job), azkaban will launch the 1pm instance at 3:15pm. This way, azkaban will try to catch up the lag period. Once azkaban catches up, normal hourly execution would continue.\nAlso, if possible, could you let us know a time-period by which this feature might be available? Or if there has been any progress at your end? We can probably discuss the design, if you have one ready.\nBecause we are also planning on making the changes in source code for the same. Just want to avoid duplicate effort. \nAny help would be appreciated. :)\n. ",
    "swamisun": "@juhoautio thanks for initiating this. Ability for flows to withstand (rolling) restarts would be great to have, and we'd love to help realize this. Any progress more progress on this besides https://github.com/azkaban/azkaban/pull/1438?. ",
    "zwj-weijie": "@maven2016  Did you solved the question?how?thank you !. @monanik39 Did you solved the question ?How?thanks!. ",
    "abti": "Just stumbled upon this. It was quite useful to get me going on Idea. Thanks for doing it @juhoautio . Thanks @chengren311 @HappyRay . @burgerkingeater @li-ygerchikov please review.. ",
    "surajnayak": "Should the Process Job be independent of Kerberos? hadoopShell also has similar implementation. Also, does it make sense to cache ticket only to the duration of the job in the flow for a particular execution.?. ",
    "zhangxiaofeng112": "sync. ",
    "ranfengzheng": "\u6700\u8fd1\u540c\u6837\u9047\u5230\u4e86\u4e00\u6837\u7684\u95ee\u9898\uff0c\n\u6211\u7684\u89e3\u51b3\u65b9\u6848\u662f\u4fee\u6539\u6e90\u4ee3\u7801\uff08\u56e0\u4e3a\u914d\u7f6ejetty host\u662f\u65e0\u6548\u7684\uff09\u4f7f\u5176\u76d1\u542c\u5f3a\u5236\u4e3a127.0.0.1\uff0c\u8fd9\u6837\u5b50\u6211\u7528nginx \u53cd\u5411\u4ee3\u7406\u4e00\u4e0b   \u8f6f\u4ef6\u626b\u63cf \u5c31\u65e0\u6cd5\u626b\u63cf\u51fa\u8be5\u6f0f\u6d1e\u3002. ",
    "thiszyq": "hi, how did you solve this problem finally?. ",
    "dustinschultz": "I'd be interested in having this configurable as well. @li-afaris did you happen to get a chance to expose the memory comparator threshold in .properties?. ",
    "7Light": "@kunkun-tang I also meet this problem,size:5148842. ",
    "wazjzml": "\u8fd9\u4e2a\u95ee\u9898\u89e3\u51b3\u4e86\u5417\uff1f\u6c42\u5206\u4eab\u554a. ",
    "es1220": "I ran to fail When I built installDist and ran unziped file in build/distributions/\nFor running distribute mode, \nI had added missing configuration such as conf/azkaban.properties, conf/log4j.properties, conf/azkaban-users.xml and added build step, copy conf dir, on distributions\nThis configuration is similar solo mode configuration and added comment for distribution mode setting (e.g. db, multi executor). @suvodeep-pyne @HappyRay \nThank you for your explanation.\nThe first time I installed Distributed Mode, it was hard to know what the server was missing because there were no files. The special log4j file is not logged.\nIt would be easier to complete the configuration if you add the necessary files to the guide document.. ",
    "zxhfounder": "I met the same problem. It's realy shaming.. It's our test server. We have found the reason. Our executor used 3.31 version, different with the web server version 3.20.\nThanks a lot!. ",
    "Dshiv": "Sorry, It looks like there is a different issue with my setup a bit. I'm running the gradlew build installDist via docker with openjdk-8-jdk installed. At some point I was recieving errors saying that it could not download https://services.gradle.org/distributions/gradle-3.5.1-all.zip. I ran curl and saw the 302 HTTP response that that url gives. Closing.. I apologize for my lack of due diligence before opening a pull request.. ",
    "iberezovskiy": "@kunkun-tang, I was able to validate Mysql replication setup and everything works fine. I didn't face any issues in Azkaban functionality.. ",
    "monanik39": "Hi any help you received on this issue? We are facing same issue with our jobs.. PFA screenshot before restart\n\nAfter shutdown\n\nafter restarting\n\n. Yup but after every restart why is executor ID changing? In previous versions this behavior was not observed. Is any additional setting required to override this behavior. \nFor my setup once executors are inserted i do not wish to have their id changed due to restart.. is this feature of azkaban if you are using azkaban in multi executor mode?. @kunkun-tang -Yes currently we specify executor id in flow. Cause we want to use same executor for running job of 2 projects. So we have static executor mapping as per project. . @kunkun-tang Also recreated executors are inactive by default(active =0 in database). is there any property which will set active executor flag to 1  once it is recreated? Cause as per my understanding new entry will be created only if server is up so active flag can be 1 by default?. Thanks a lot for explanation.. . ",
    "yangxu1362850636": "sla . hi, i used azkaban sla to alert my job, but it did not works,only killed the job which timeout, but did not send any emails to me, my azkaban's version is 3.30.1 @chengren311 . @chengren311  thanksfor your reply, I'm sure my configuration of azkaban emails is correct,and , i can receive failure/success email from my azkaban, but , i can't receive any sla emails from sla,and The sla timeout  kill has no effect on the spark task submitted to yarn. I am very confused\n. i did not, this is about versions???. ",
    "LvTing": "When to release the new version?. ",
    "zoneyang": "expected too. ",
    "lhcg": "@HappyRay \n@kunkun-tang. ",
    "lijixiang123": "@lhcg i have the same issue as you ,are you sovled it? can you tail me the detail method?thx. @lhcg hi! i had solved this issue, modify the ProcessJob.java 204 line transfer ture for false\nfinal boolean isExecuteAsUser = this.sysProps.getBoolean(EXECUTE_AS_USER, false);\nin  this  azkaban-common-0.1.0-SNAPSHOT.jar. i solved this issue,because of properties file error,The configuration item ends with a space\nazkaban.default.servlet.path=/index\nweb.resource.dir=web/. ",
    "YapingWu": "I solved this problem by modifying the source code, specifying the MimeType of the message as \"text / html; charset = utf-8\" in the class file of azkaban-common \\ src \\ main \\ java \\ azkaban \\ utils \\ Emailer.java.\nHope you can make improvements,thanks.\n. ok,I get it,thank you very much.. I have ran the command configured in this azkaban job on linux,and the exit code was 1.. It's not related to azkaban.. ",
    "abhijith444": "Were you able to find a fix for this?. ",
    "tschutte": "\"Please follow the setup guide to set up and activate executors.\"\nIt would be helpful if the documentation highlighted this dependency ordering between the executor and web servers.. This is still an issue for me on v3.38.2 when placing the web server behind an AWS ELB.. ",
    "FourSpaces": "this is my solution\nfollow the setup guide to set up and activate the executive.\nin the case of activation of the program execution, there may be a problem with the database, and the data in the 'executors' table in the database needs to be modified\ne.g\n|    id  |   host                                   |   port     |   active\n|   1     |   localhost                           |  12321   |       1\n|   5     |   office-prod-bigdata-00  |   12321   |     0\nYou need to change the corresponding actuator's active to 1, you can run, execute the program. It seems that there are some bugs, you can't modify the database information in time.\n================\u4e2d\u6587=====================\n\u8bf7\u6309\u7167\u8bbe\u7f6e\u6307\u5357\u8bbe\u7f6e\u548c\u6fc0\u6d3b\u6267\u884c\u7a0b\u5e8f\n\u5728\u6fc0\u6d3b\u7a0b\u5e8f\u6267\u884c\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u53ef\u80fd\u662f\u6570\u636e\u5e93\u7684\u95ee\u9898\uff0c\u9700\u8981\u4fee\u6539 \u6570\u636e\u5e93\u4e2d 'executors' \u8868\u4e2d \u7684\u6570\u636e\n\u4f8b\u5982\n|    id  |   host                                   |   port     |   active\n|   1     |   localhost                           |  12321   |       1\n|   5     |   office-prod-bigdata-00  |   12321   |     0\n\u4f60\u9700\u8981\u5c06 \u5bf9\u5e94\u6267\u884c\u5668\u7684 active \u6539\u4e3a1\uff0c \u5c31\u53ef\u4ee5\u8fd0\u884c\uff0c\u6267\u884c\u7a0b\u5e8f \u597d\u50cf\u6709\u4e9bBUG\uff0c\u4e0d\u80fd\u53ca\u65f6\u4fee\u6539\u6570\u636e\u5e93\u7684\u4fe1\u606f. ",
    "zhangqingkai": "I have the seem question\uff0cwhen I run the ./bin/start-web.sh, it will report No active executor found, and I see the executors table, it is empty, I can't even modify the active status manually, anyone can help me? . ",
    "Ralnoc": "@HappyRay - Sorry, seems my last response was lost due to typing it on my phone.\nThe easiest way to reproduce the issue is to do the following:\n1) Setup the Azkaban Server\n2) Disable SSL using jetty.use.ssl=false\n3) Create an ELB (Or any Load Balancer Solution. HAProxy would work as well.) and put Azkaban behind port 443 on the load balancer with a cert installed for it.\n4) Attempt to navigate to the server and log in.\nAfter you log in, you will find yourself being redirected to HTTP instead of HTTPS. This continues through the rest of your use of the server behind the load balancer. You will regularly find yourself being redirected back to HTTP even though you are attempting to navigate the site on HTTPS.. Further testing has shown that the issue is specific links that appear to not be relative. I'm in the process of upgrading to the newest version of Azkaban. Once I get that deployed into our lab environment, I will update if this is a continuing issue or not.. Make sure you are running the start command in the azkaban-web-server-0.1.0-SNAPSHOT directory.. Azkaban will only mark a Job as failed if the command it is running exists with a non-zero return code, I believe. As long as the command the job is running exits with a zero, it will be marked as successful.. Interesting. I would look over how you have your job file constructed. Somehow, with the way you are starting the job, it is resulting in Azkaban receiving a successful exit return code.. ",
    "liweigong": "may I know which version this bug fixed?  the earlier realease didn't have a note.. ",
    "wu8685": "I encountered this problem on Azkaban 3.0.\nWill it be fixed ?. Adding the hook at the end of the flow as a cmd job can not guarantee that the hook is always triggered. If one of the previous jobs fails, the hook of cmd job will not run.\nIn my scenario, I want to be aware of the result of a flow execution. The hooks can be help to report the execution result. . Actually, the flow status is what I really need : )\n\"Cleanup job\" is a good idea to meet my requirement. Actually, finally job is more like what I want.\nTake your design as example, I hope the \"finally job\" to be put out of the workflow DAG. It is not a pre-node or next-node of any other jobs. The \"finally job\" could be run after the DAG finished with failure or success, just like the \"finally block\" is always invoked after \"try block\" finished in java.\nThe flow result could be carried in the environment variables before run the \"finally job\".. ",
    "dortegau": "Hi @reallocf,\nSeems to be ok in 3.37.0 version \ud83d\udc4d \nThanks!. ",
    "vladislav-sidorovich": "Hi @reallocf  thank you for answer!\nThe example on stackoverflow works :). And your example works as well.  And your example works as well. \nBut the  idea is to provide few property files (local, test, stage, prod) from developer's side because all these files will keep in Git. And it's more useful to have few files with different values of properties than keep one file and change the value of properties each time.\n@reallocf , what approach you used in linkedin for this case?\nThank you.. Thank you very much.. Try to add these configurations into *.job file. I deleted 1 line of code. How the code coverage can be decreased? :) . I will. \nThank you. @HappyRay could you please take a look at this pool request. . ",
    "samj24": "@chengren311 ,Thanks for the response.\nUse Case:\nA job flow contains 100+ jobs and each job can consume maximum 15g of memory and 15-40 mins to process. One job among 100+ jobs is dependent on all other jobs and it should start processing once all the other jobs are completed.\nProblem:\nProcessing single job flow on a single executor is impacting the scalability and performance as there are many other such job flows need to run.\nAdvantages of distributing a single workflow to multiple servers:\n1. Available servers and resources can be utilized efficiently\n2. Multiple job flows can run on scale and boost up performance\nAlternate approach:\nSend all the jobs in a single job flow excluding the job which is dependent on others and track the completion of sent jobs in the application. Once all the jobs are completed then send the last job which is dependent on other jobs to process. However, UI monitoring would be cumbersome to monitor thousands of jobs using this approach.Thoughts/Alternative?\nThanks. ",
    "forteph": "[Screenshots]\n\n\n[Logs]\n[TIME] [JOB_NAME] ERROR - Kill has been called.\n[TIME] [JOB_NAME] INFO - Process completed unsuccessfully in 125 seconds.\n[TIME] [JOB_NAME] ERROR - Job run failed!\njava.lang.RuntimeException: azkaban.jobExecutor.utils.process.ProcessFailureException\n    at azkaban.jobExecutor.ProcessJob.run(ProcessJob.java:165)\n    at azkaban.execapp.JobRunner.runJob(JobRunner.java:590)\n    at azkaban.execapp.JobRunner.run(JobRunner.java:443)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: azkaban.jobExecutor.utils.process.ProcessFailureException\n    at azkaban.jobExecutor.utils.process.AzkabanProcess.run(AzkabanProcess.java:131)\n    at azkaban.jobExecutor.ProcessJob.run(ProcessJob.java:159)\n    ... 7 more\n[TIME] [JOB_NAME] ERROR - azkaban.jobExecutor.utils.process.ProcessFailureException cause: azkaban.jobExecutor.utils.process.ProcessFailureException\n[TIME] [JOB_NAME] INFO - Finishing job [JOB_NAME] attempt: 0 at 1509942165182 with status KILLED\n(I processed screenshots and logs for security issues.)\nIn fact, I tested setting SLA rule for only 1 job out of 4 parallel jobs, but it ended up killing all 4 jobs at the same time not just retrying SLA-set-job, which caused the whole flow end with 'Killed' status. BTW, I got the notification mail though.. It's 3.1.0, however, I was noticed same thing happened in version 3.30.1. I don't think it's a version issue.. ",
    "glfbin": "30 seconds or more longger to dispatch  one flow. ",
    "encrylife": "I search the source code,I find it will add the -cp XXX as you mention above,  I add the class name after the command ,it work well ,so I add  jvm.args  AzkabanExample.when I add classpath it report failed again.I hava no idea ,can you help me? the command file:\nworking.dir = /home/ubuntu/Downloads/azkaban/azkaban-exec-server/job\nclasspath =fastjson-1.2.38.jar,springBootBaseService-1.0-SNAPSHOT.jar,springBootBaseService_fat.jar\njvm.args =AzkabanExample\ntype =javaprocess\njava.class =AzkabanExample\nthe error log:\nException in thread \"main\" java.lang.NoClassDefFoundError: com/front/baseService/entity/ESORequest\n.In the command line ,I delete the arg -D it work well in the command line as  java -cp .:fastjson-1.2.38.jar:springBootBaseService-1.0-SNAPSHOT.jar:springBootBaseService_fat.jar  AzkabanExample.You can reproduce the bug.\n. I had resolved the problem,via the error log,finally I modified command job file  as \nworking.dir=/home/ubuntu/Downloads/azkaban/azkaban-exec-server/job\nclasspath=.:fastjson-1.2.38.jar,springBootBaseService-1.0-SNAPSHOT.jar,springBootBaseService_fat.jar\ntype= javaprocess\njava.class= AzkabanExample.\n Thank you prompt reply !\n. ",
    "nimuyuhan": "I have the same problem. I find that logs \u2018No classpath specified\u2019.\nlogs:\n15-10-2018 21:26:21 CST hive-demo INFO - Error: A JNI error has occurred, please check your installation and try again\n15-10-2018 21:26:21 CST hive-demo INFO - Exception in thread \"main\" java.lang.NoClassDefFoundError: org/apache/hadoop/conf/Configuration\n15-10-2018 21:26:21 CST hive-demo INFO -    at java.lang.Class.getDeclaredMethods0(Native Method)\n15-10-2018 21:26:21 CST hive-demo INFO -    at java.lang.Class.privateGetDeclaredMethods(Class.java:2701)\n15-10-2018 21:26:21 CST hive-demo INFO -    at java.lang.Class.privateGetMethodRecursive(Class.java:3048)\n15-10-2018 21:26:21 CST hive-demo INFO -    at java.lang.Class.getMethod0(Class.java:3018)\n15-10-2018 21:26:21 CST hive-demo INFO -    at java.lang.Class.getMethod(Class.java:1784)\n15-10-2018 21:26:21 CST hive-demo INFO -    at sun.launcher.LauncherHelper.validateMainClass(LauncherHelper.java:544)\n15-10-2018 21:26:21 CST hive-demo INFO -    at sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:526)\n15-10-2018 21:26:21 CST hive-demo INFO - Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.conf.Configuration\n15-10-2018 21:26:21 CST hive-demo INFO -    at java.net.URLClassLoader.findClass(URLClassLoader.java:381)\n15-10-2018 21:26:21 CST hive-demo INFO -    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n15-10-2018 21:26:21 CST hive-demo INFO -    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)\n15-10-2018 21:26:21 CST hive-demo INFO -    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n15-10-2018 21:26:21 CST hive-demo INFO -    ... 7 more\n15-10-2018 21:26:21 CST hive-demo INFO - Process completed unsuccessfully in 0 seconds.\n15-10-2018 21:26:21 CST hive-demo ERROR - caught error running the job\n15-10-2018 21:26:21 CST hive-demo ERROR - Job run failed!\njava.lang.Exception: java.lang.RuntimeException: azkaban.jobExecutor.utils.process.ProcessFailureException\n    at azkaban.jobtype.HadoopHiveJob.run(HadoopHiveJob.java:110)\n    at azkaban.execapp.JobRunner.runJob(JobRunner.java:784)\n    at azkaban.execapp.JobRunner.doRun(JobRunner.java:600)\n    at azkaban.execapp.JobRunner.run(JobRunner.java:561)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.RuntimeException: azkaban.jobExecutor.utils.process.ProcessFailureException\n    at azkaban.jobExecutor.ProcessJob.run(ProcessJob.java:304)\n    at azkaban.jobtype.HadoopHiveJob.run(HadoopHiveJob.java:106)\n    ... 8 more\nCaused by: azkaban.jobExecutor.utils.process.ProcessFailureException\n    at azkaban.jobExecutor.utils.process.AzkabanProcess.run(AzkabanProcess.java:130)\n    at azkaban.jobExecutor.ProcessJob.run(ProcessJob.java:296)\n    ... 9 more. ",
    "qin4zhang": "The same problem occurred to me. How to solve it?. That's a good idea. . ",
    "jakhani": "Code change looks good to me. Just one question, why are we not passing retry count from config?. ",
    "dinusha00": "Hi, Thanks for the reply. Below is the screenshot when a user tries to remove the already existing SLA by removing the details. Or we have another way to remove the set SLA? Cannot find any other way to do this and in older versions when i remove all the values and save, similar to what i am doing now, then the SLA will get removed. But not in this version. Can you confirm if its not reproducible, then i have to recompile another latest version from the beginning and try these options.\n\n. Hi, I will try with newer version and will post if i was able to find anything from logs. thanks for the message. Closing the ticket, since its not reproducible for others. ",
    "leoChaoGlut": "You can activate an executor by hand: \ncurl http://${executorHost}:${executorPort}/executor?action=activate. ",
    "llbb2000go": "After checking error log, it turned out that the problem was that   yarn timeline service is enabled.\n15-12-2017 18:11:36 CST hadoopJava-wordcount INFO - at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.operateDelegationToken(TimelineClientImpl.java:462)\nOne approach to this issue is to set yarn.timeline-service.enabled=false, it is simple and effective in development environments.\nAnother is modify prefetchToken method, add timeline service token when yarn.timeline-service.enabled=true\nif (conf.getBoolean(YARN_TIMELINE_ENABLE, false)) {\n      logger.info(\"Yarn Config \" + YARN_TIMELINE_ENABLE + \" : \" + \"true\");\n      try {\n    TimelineClient timelineClient = TimelineClient.createTimelineClient();\n    String rmPrincipal = conf.get(YarnConfiguration.RM_PRINCIPAL);\n    String renewer = null;\n    if (rmPrincipal != null && rmPrincipal.length() > 0) {\n      String rmHost = conf.getSocketAddr(\n          YarnConfiguration.RM_ADDRESS,\n          YarnConfiguration.DEFAULT_RM_ADDRESS,\n          YarnConfiguration.DEFAULT_RM_PORT).getHostName();\n      renewer = SecurityUtil.getServerPrincipal(rmPrincipal, rmHost);\n    }\n\n    timelineClient.init(conf);\n    Token<TimelineDelegationTokenIdentifier> timelineToken = timelineClient\n        .getDelegationToken(renewer);\n    if (timelineToken == null) {\n      logger.error(\"Failed to fetch TimeLine token\");\n    }\n    logger.info(\"Created TimeLine token.\");\n    logger.info(\"Token kind: \" + timelineToken.getKind());\n    logger.info(\"Token service: \" + timelineToken.getService());\n    cred.addToken(timelineToken.getService(), timelineToken);\n  } catch (IOException e) {\n    final String message =\n        \"Failed to get timeline server token.\" + e.getMessage()\n            + e.getCause();\n    logger.error(message, e);\n    throw new HadoopSecurityManagerException(message);\n  } catch (YarnException y) {\n    final String message =\n        \"Failed to get timeline server token.\" + y.getMessage()\n            + y.getCause();\n    logger.error(message, y);\n    throw new HadoopSecurityManagerException(message);\n  }\n}.\n",
    "sridharpothamsetti": "Add this content in properties file\nexecutor.global.properties=conf/global.properties\nazkaban.project.dir=projects\nand create empty global.properties file in conf directory and give a try. ",
    "ezhouyang": "If you use mysql8 that you must use mysql-connector-java-8.0.11.jar put in extlib dir.\nPlease check you lib dir && remove mysql-connector-java-5.1.28.jar.\nDone it.\n. ",
    "mtrna": "Hi @jamiesjc ! Thanks for reviewing the pull request and link to the style guide!\nIf you don't mind I would wait until there is consensus about the functional part and update the formatting as the last step before the eventual merge. Would that work for you? :). fixed the tests for Travis. Hi @jamiesjc! You are right, only the users with access to the configuration of Azkaban can configure the templates. I have edited the original announcement, to avoid more confusion.\nRegarding security: all the data accessible via the email template is already available via GUI/REST. TemplateBasedMailCreator in this PR provides only data strictly relevant to the success/failure of a job. Email templates are not intended to carry any private data. Notifications can still be sent to any email address.. hi @jamiesjc ! Mailbox, unlike Azkabans themselves, can be accessed with lower security barrier in the environment where I work. I would like the emails to become a helpful source of information about the status of the jobs (before I start a more involved investigation). The information I am frequently lacking is the flow parameters, concurrency option and possibly others. I do not want to impose this change on other adopters of Azkaban though. I would prefer to have a reasonable default template available in the installation, and give others the freedom to chose whatever they find useful for their use case, e.g. inline guidelines, add links to their internal operation books, change the layout.. rebased to the latest master. rebased to the latest master.... updated the PR: mail creator settings are read from MailCreatorRegistry, instead of ExecutionOption\n@jamiesjc @HappyRay : please provide feedback ;). @jamiesjc No problem. I am still interested. :). @HappyRay : Answered via LinkedIn inbox. :). New: I have added test for SessionCache hits/misses. Rebased on the latest master. Fixed some more doc/typos found in the process.. Hi @HappyRay @ameyamk ! No problem about the delay. I have re-based the MR. It should be conflict free now. ;). reopened MR; rebased to the latest master; solo server can be started as ./azkaban-solo-server/build/install/azkaban-solo-server/bin/start-solo.sh; success/failure is logged to stdout. Hi @HappyRay ! I am interested, the MR is reopened here: https://github.com/azkaban/azkaban/pull/1685. @kunkun-tang Thanks for your feedback. W.r.t. the commit message: how about: \"UI fix: Graph > Job filter floats over the execution graph pane\" ?. @juhoautio : yeah, I noticed the DateTime.now() and System.currentTimeMillis provide different time. updated, rebased; PR is ready for another round of review. added a fix of the BasicTimeCheckerTest. resolved conflicts with master. that's a fair point, fixing.... correct; will change it to obtain most recent creator from the MailCreatorRegistry, ok?. fair point, adapting the code to what you are proposing. we can; updating.... hi @jamiesjc ! If I understand you correctly, we discuss the case when a user e.g. schedules a regular execution of a flow and the executor server somehow afterwards loses the emailCreator, is that correct? It seems UI option does not help in that case either (user can chose from a list of creators available at time T1, but the server alters its configuration at time T2>T1). What are our options?\nFrom the other side: is there a good reason for having emailCreator in an ExecutionOption? Maybe it should be decided on the level of the executor server once for all executions during the initialization step (and at the time of load of the email creators). Was it considered?\nMy intention was not to let executing user chose the layouts ad hoc, but rather to provide the tool to evolve the content of emails outside the code-base.. Session TTL is a final/immutable value per AZ instance, it has a default value that can be overridden by a prop.\nUse case for the TTL: once a client obtains a session id (token), it comes handy for the client to know how long the token is valid. E.g. not to to upload a large ZIP with an expired token (and be rejected, re-authenticate, and upload the ZIP again).\nE.g. linkedin-gradle-plugin-for-apache-hadoop could benefit from having such information.. It is extended. Client does not know what is the TTL though. As a client: do you login again or do you reuse a session token after an hour, five hours, twelve hours of inactivity? Think about session as a temporary token: if it is temporary, it is import to tell the client how long is it valid.. a. the benefit of using sessions is that the authentication is done when a session is not available/expires; what would be the benefit of having sessions when clients would authenticate before every action?\nb. this leads to waste; from my experience, in many cases upload is the only action clients are performing via the API; on a slow VPN connections, this creates an unnecessary long round-trip. @HappyRay : I was reacting to \"always login first\": it gives some space for interpretation.\nIn summary: what I find is missing on the client side is the information about whether the session token is still valid or not. Apparently we disagree on whether this information should be available to the clients of Azkaban. I am closing the PR then.. This message is logged during the loading of properties, which happens during the initialization of the AzkabanServer. I am updating the PR.. The discussion I can see here is about the clarity of intent/design. The AzkabanServer class is currently the only one that registers a mail creator. It is hard for me to foresee whether there can be another such component and what would be the desired logic to satisfy their potential claims. The flag is one way to give registering side some degree of control. A more straightforward approach would be that the last registered mail creator wins/is recommended for the rest of the system to use.\nI am updating the PR to show how this simpler approach would look.. Hi @HappyRay ! Sure, the follow up PR with doc/config update only: https://github.com/azkaban/azkaban/pull/1626. Hi @HappyRay ! sure, updated the PR. Thanks for the feedback. I have changed the import order.. fixed. Thanks for pointing it out; I have checked the other tabs an there was impact.\nMoved all the styling logic to div#graphView.container-fill, which is specific to the graph pane, and tested the updated version on chrome and firefox, it looks good to me now.. Sure, that is an interesting question. :) I posed that to myself and the result you can see in the updated PR. :). Hi @juhoautio ! It matters, since it allows to release the file descriptors. IOException thrown upon the exhaustion of file descriptors is the reason why this test frequently fails.. fair point, I will update the PR. DateTime.now() takes the milliseconds from the effective joda millis provider [1]. Since metrics use the system millis provider directly [citation needed :D], I suggest the MetricManagerTest use the system millis provider as well.\n[1] https://github.com/JodaOrg/joda-time/blob/master/src/main/java/org/joda/time/DateTimeUtils.java#L112. I agree, will update the PR later today. joda DateTime and minus/plusMinutes are used, though! :). reuse of existing code; but sure we can replace it as well :). ",
    "dhuaqiao": "i find it\nhttps://github.com/azkaban/azkaban/issues/610 . ",
    "huaxuechensu": "Thanks a lot man, I got that.. Is mysql.port ,mysql.database, mysql.user ... are fixed parameter ? How can I change these . Yes. I wanna change default database from MySQL to postgresql .\nThanks.  Please.  \n| |\ncharlie\n\u90ae\u7bb1\uff1ahua-xue21@163.com\n|\n\u7b7e\u540d\u7531 \u7f51\u6613\u90ae\u7bb1\u5927\u5e08 \u5b9a\u5236\nOn 02/14/2018 15:40, Liang Tang wrote:\nyes. May we know why do you need to change it?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.. hi, Is my request possible ? . ok\uff0cI got it. \nadd permit in doGet and doPost Method.. ",
    "rschmidtz": "Same here, I'm trying to install the solo server version using Ubuntu 16.04 on AWS and when I run:\ncd azkaban; ./gradlew build installDist\nThe build fails with the following exceptions:\n````\n\nTask :azkaban-common:test\n\nazkaban.project.JdbcProjectImplTest > classMethod FAILED\n    java.sql.SQLException: Table \"EXECUTION_LOGS\" already exists; SQL statement:\n    CREATE TABLE execution_logs (\n      exec_id     INT NOT NULL,\n      name        VARCHAR(128),\n      attempt     INT,\n      enc_type    TINYINT,\n      start_byte  INT,\n      end_byte    INT,\n      log         LONGBLOB,\n      upload_time BIGINT,\n      PRIMARY KEY (exec_id, name, attempt, start_byte)\n    ) [42101-193] Query: CREATE TABLE execution_logs (\n      exec_id     INT NOT NULL,\n      name        VARCHAR(128),\n      attempt     INT,\n      enc_type    TINYINT,\n      start_byte  INT,\n      end_byte    INT,\n      log         LONGBLOB,\n      upload_time BIGINT,\n      PRIMARY KEY (exec_id, name, attempt, start_byte)\n    ) Parameters: []\n        at org.apache.commons.dbutils.AbstractQueryRunner.rethrow(AbstractQueryRunner.java:363)\n        at org.apache.commons.dbutils.QueryRunner.update(QueryRunner.java:490)\n        at org.apache.commons.dbutils.QueryRunner.update(QueryRunner.java:376)\n        at azkaban.db.DatabaseSetup.runTableScripts(DatabaseSetup.java:102)\n        at azkaban.db.DatabaseSetup.createTables(DatabaseSetup.java:82)\n        at azkaban.db.DatabaseSetup.updateDatabase(DatabaseSetup.java:57)\n        at azkaban.test.Utils.initTestDB(Utils.java:36)\n        at azkaban.project.JdbcProjectImplTest.setUp(JdbcProjectImplTest.java:63)\nazkaban.project.JdbcProjectImplTest > classMethod FAILED\n    java.lang.NullPointerException\n        at azkaban.project.JdbcProjectImplTest.destroyDB(JdbcProjectImplTest.java:69)\n293 tests completed, 2 failed, 18 skipped\nFAILURE: Build failed with an exception.\n``\n. hi @kunkun-tang \nthe command:\n./gradlew :azkaban-common:test --tests azkaban.executor.ExecutorDaoTest\nreturns:\n```\nParallel execution with configuration on demand is an incubating feature.\nBuild cache is an incubating feature.\nBUILD SUCCESSFUL in 5s\n17 actionable tasks: 1 executed, 16 up-to-date\n```\n. ",
    "dave-r12": "I cloned and built the project on a fresh CentOS 7 host and it was successful. I'm running macOS on my laptop so there seems to be a difference between the 2.. I think I might have a lead here.. One difference I noticed is that on my local machine JdbcTriggerImplTest runs prior to azkaban.executor.ExecutorDaoTest. It appears it never closes the database. ExecutorDaoTest attemps to reuse the existing database and fails running the inserts.\nIf I add this to JdbcTriggerImplTest everything seems to pass:\njava\n  @AfterClass\n  public static void shutdown() {\n    try {\n      dataSource.close();\n    } catch (SQLException e) {\n      e.printStackTrace();\n    }\n  }\nIt also appers AzkabanConnectionPoolTest might be leaking it's connection as well.\nI wasn't able to find an easy way to run tests in specific order via gradle.. > You shouldn't have to. And I would recommend against that as long-term fix to fix issues in the tests.\nAhh right, I agree. I was just mentioning that in hopes you could also reproduce the issue.. ",
    "FreyaWhite": "Are you sure that there is  correct configuration of  jdk and jre over 1.8 in your Linux?\nif yes,Why not try to compile a new azkaban by git. ",
    "ggalves": "Sorry for the late to respond. I created a PR to fix it, can you review?\nThanks!. @reallocf Sure, I'm splitting into two PRs. Thanks!. @reallocf I've opened another PR #1741 with the download fix. I'm leaving the other fix for the issue you have opened\nI'm closing this PR. Thanks again!. Yes, it does. But I requested someone to restart azkaban and he had this problem and thought he had restarted (did not see the output). Things continued not to work. Took me some time to realize that the server did not restarted.\nNot a major issue, just pointing as I think this should improve.\nThanks!\n. You mean the role being null? \nThis check just avoids a NullPointerException that will be throwed if code gets to the next if condition, as it tries to call role.getPermission(), so i'm skipping to the next iteration of for loop if role == null\nIn pratice, the user would not have access to the page, but would receive an HTTP500 response, instead of a treated error. I agree, this should fail before. I just did this way as getRole method was documented \"Returns the user role. This may return null.\", so i thought that would be nice to make this check.. ",
    "saibalpatra": "I am using 3.40.0. works - I had issues with the downloaded jar files.. ",
    "itsSachin": "Actually I have many jobs scheduled on a web server. So as to clean up the ui I want that for a particular user login he should only see his scheduled jobs. Right now every user that logs in the to same web server is shown all the jobs scheduled.. ",
    "zuoshangs": "I got the same error .version is 3.43.0. ",
    "arcticOak2": "@haiyes can you please share the solution for this issue.. ",
    "scripter-win": "I have also got the problem. ",
    "codecov[bot]": "Codecov Report\n\nMerging #1661 into master will increase coverage by 0.05%.\nThe diff coverage is 70.76%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1661      +/-\n============================================\n+ Coverage     32.88%   32.93%   +0.05%   \n- Complexity     2650     2657       +7   \n============================================\n  Files           409      409            \n  Lines         29203    29257      +54   \n  Branches       3716     3721       +5   \n============================================\n+ Hits           9604     9637      +33   \n- Misses        18722    18738      +16   \n- Partials        877      882       +5\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...a/azkaban/viewer/reportal/ReportalMailCreator.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 45.02% <14.28%> (-0.04%) | 53 <0> (\u00f8) | |\n| ...java/azkaban/executor/mail/DefaultMailCreator.java | 88.95% <92%> (+0.55%) | 19 <2> (+2) | :arrow_up: |\n| ...an-common/src/main/java/azkaban/utils/Emailer.java | 61% <95.45%> (+9.71%) | 16 <8> (+8) | :arrow_up: |\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 66.66% <0%> (-3.04%) | 14% <0%> (-1%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.11% <0%> (-1.95%) | 85% <0%> (-3%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.09% <0%> (+0.13%) | 144% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 88240fc...4ffe7c1. Read the comment docs.\n. # Codecov Report\nMerging #1797 into master will increase coverage by 0.05%.\nThe diff coverage is 0%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1797      +/-\n============================================\n+ Coverage     32.88%   32.94%   +0.05%   \n+ Complexity     2633     2632       -1   \n============================================\n  Files           404      404            \n  Lines         29066    29068       +2   \n  Branches       3699     3699            \n============================================\n+ Hits           9557     9575      +18   \n+ Misses        18634    18614      -20   \n- Partials        875      879       +4\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| az-core/src/main/java/azkaban/Constants.java | 25% <\u00f8> (\u00f8) | 1 <0> (\u00f8) | :arrow_down: |\n| ...in/java/azkaban/webapp/servlet/HistoryServlet.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...azkaban/webapp/servlet/AbstractAzkabanServlet.java | 6.87% <0%> (-0.11%) | 6 <0> (\u00f8) | |\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 66.66% <0%> (-3.04%) | 14% <0%> (-1%) | |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 87.5% <0%> (-2.09%) | 16% <0%> (-1%) | |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 72.33% <0%> (-0.4%) | 59% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.62% <0%> (+0.43%) | 87% <0%> (+1%) | :arrow_up: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 69.79% <0%> (+20.83%) | 7% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d13ce99...4d94157. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@e9dfd50). Click here to learn what that means.\nThe diff coverage is 0%.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1813   +/-\n=========================================\n  Coverage          ?   32.47%         \n  Complexity        ?     2547         \n=========================================\n  Files             ?      390         \n  Lines             ?    28481         \n  Branches          ?     3616         \n=========================================\n  Hits              ?     9249         \n  Misses            ?    18365         \n  Partials          ?      867\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...kaban/flowtrigger/quartz/FlowTriggerScheduler.java | 5.76% <\u00f8> (\u00f8) | 2 <0> (?) | |\n| .../azkaban/webapp/servlet/ProjectManagerServlet.java | 0% <\u00f8> (\u00f8) | 0 <0> (?) | |\n| ...li/java/azkaban/restli/ProjectManagerResource.java | 20.27% <0%> (\u00f8) | 7 <0> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update e9dfd50...c301683. Read the comment docs.\n. # Codecov Report\nMerging #1824 into master will increase coverage by 0.03%.\nThe diff coverage is 33.33%.\n\n\n```diff\n@@             Coverage Diff             @@\nmaster   #1824      +/-\n===========================================\n+ Coverage     32.47%   32.5%   +0.03%   \n+ Complexity     2545    2542       -3   \n===========================================\n  Files           390     390            \n  Lines         28481   28483       +2   \n  Branches       3616    3617       +1   \n===========================================\n+ Hits           9248    9259      +11   \n+ Misses        18364   18351      -13   \n- Partials        869     873       +4\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 18.37% <33.33%> (-0.79%) | 5 <0> (-1) | |\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 66.66% <0%> (-3.04%) | 14% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.62% <0%> (\u00f8) | 87% <0%> (\u00f8) | :arrow_down: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (+16.66%) | 6% <0%> (-1%) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 151c505...a42a23c. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@4a847bb). Click here to learn what that means.\nThe diff coverage is n/a.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1830   +/-\n=========================================\n  Coverage          ?   32.43%         \n  Complexity        ?     2542         \n=========================================\n  Files             ?      391         \n  Lines             ?    28507         \n  Branches          ?     3615         \n=========================================\n  Hits              ?     9246         \n  Misses            ?    18389         \n  Partials          ?      872\n```\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 4a847bb...2e9d2cb. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@f8f47f8). Click here to learn what that means.\nThe diff coverage is 53.57%.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1833   +/-\n=========================================\n  Coverage          ?   32.48%         \n  Complexity        ?     2541         \n=========================================\n  Files             ?      390         \n  Lines             ?    28493         \n  Branches          ?     3621         \n=========================================\n  Hits              ?     9255         \n  Misses            ?    18363         \n  Partials          ?      875\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...main/java/azkaban/executor/ExecutorApiGateway.java | 23.68% <0%> (\u00f8) | 3 <0> (?) | |\n| ...n/java/azkaban/webapp/servlet/ExecutorServlet.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...main/java/azkaban/executor/FetchActiveFlowDao.java | 84.21% <100%> (\u00f8) | 3 <1> (?) | |\n| ...main/java/azkaban/executor/ExecutionReference.java | 68.18% <100%> (\u00f8) | 6 <1> (?) | |\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 42.15% <50%> (\u00f8) | 52 <0> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update f8f47f8...7e67ae1. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@c851948). Click here to learn what that means.\nThe diff coverage is 25%.\n\n\n```diff\n@@           Coverage Diff            @@\nmaster   #1835   +/-\n========================================\n  Coverage          ?   32.4%         \n  Complexity        ?    2538         \n========================================\n  Files             ?     390         \n  Lines             ?   28484         \n  Branches          ?    3617         \n========================================\n  Hits              ?    9230         \n  Misses            ?   18377         \n  Partials          ?     877\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../src/main/java/azkaban/trigger/TriggerManager.java | 15.51% <0%> (\u00f8) | 5 <0> (?) | |\n| ...java/azkaban/trigger/builtin/BasicTimeChecker.java | 77.17% <50%> (\u00f8) | 15 <0> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update c851948...9eda431. Read the comment docs.\n. # Codecov Report\nMerging #1846 into master will decrease coverage by 0.03%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1846      +/-\n============================================\n- Coverage     32.54%   32.51%   -0.04%   \n+ Complexity     2546     2542       -4   \n============================================\n  Files           390      390            \n  Lines         28475    28475            \n  Branches       3614     3614            \n============================================\n- Hits           9268     9259       -9   \n- Misses        18335    18341       +6   \n- Partials        872      875       +3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../main/java/azkaban/utils/ExecutorServiceUtils.java | 90% <0%> (-10%) | 4% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.76% <0%> (-1.95%) | 85% <0%> (-4%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.79% <0%> (-0.14%) | 144% <0%> (-1%) | |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 19.62% <0%> (+0.46%) | 8% <0%> (+2%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update c56a537...147f0f7. Read the comment docs.\n. # Codecov Report\nMerging #1847 into master will increase coverage by <.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1847      +/-\n============================================\n+ Coverage      32.5%   32.51%   +<.01%   \n  Complexity     2541     2541            \n============================================\n  Files           390      390            \n  Lines         28481    28481            \n  Branches       3616     3616            \n============================================\n+ Hits           9258     9260       +2   \n+ Misses        18347    18345       -2   \n  Partials        876      876\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../main/java/azkaban/utils/ExecutorServiceUtils.java | 90% <0%> (-10%) | 4% <0%> (-1%) | |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 72.33% <0%> (-0.4%) | 59% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.62% <0%> (+0.86%) | 87% <0%> (+2%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 5b075be...acbf344. Read the comment docs.\n. # Codecov Report\nMerging #1848 into master will increase coverage by 0.1%.\nThe diff coverage is 57.57%.\n\n\n```diff\n@@             Coverage Diff             @@\nmaster    #1848     +/-\n===========================================\n+ Coverage     32.47%   32.57%   +0.1%   \n- Complexity     2545     2561     +16   \n===========================================\n  Files           390      390           \n  Lines         28481    28525     +44   \n  Branches       3616     3628     +12   \n===========================================\n+ Hits           9248     9291     +43   \n- Misses        18364    18365      +1   \n  Partials        869      869\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| az-core/src/main/java/azkaban/Constants.java | 25% <\u00f8> (\u00f8) | 1 <0> (\u00f8) | :arrow_down: |\n| ...in/java/azkaban/execapp/AzkabanExecutorServer.java | 5.38% <0%> (+0.16%) | 3 <0> (\u00f8) | :arrow_down: |\n| .../src/main/java/azkaban/execapp/ProjectVersion.java | 80.95% <100%> (+3.17%) | 10 <2> (+2) | :arrow_up: |\n| ...er/src/main/java/azkaban/execapp/FlowPreparer.java | 77.21% <56.25%> (-0.91%) | 11 <1> (+2) | |\n| ...ommon/src/main/java/azkaban/utils/FileIOUtils.java | 31.1% <58.33%> (+1.65%) | 21 <2> (+2) | :arrow_up: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...main/java/azkaban/executor/ExecutorApiGateway.java | 23.68% <0%> (-1.32%) | 3% <0%> (\u00f8) | |\n| ...java/azkaban/trigger/builtin/BasicTimeChecker.java | 77.17% <0%> (-0.85%) | 15% <0%> (\u00f8) | |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 18.37% <0%> (-0.79%) | 5% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.19% <0%> (-0.44%) | 88% <0%> (+1%) | |\n| ... and 11 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 151c505...5bc5cb5. Read the comment docs.\n. # Codecov Report\nMerging #1851 into master will decrease coverage by 0.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1851      +/-\n============================================\n- Coverage     32.44%   32.42%   -0.02%   \n- Complexity     2541     2542       +1   \n============================================\n  Files           390      390            \n  Lines         28486    28486            \n  Branches       3618     3618            \n============================================\n- Hits           9241     9236       -5   \n- Misses        18372    18379       +7   \n+ Partials        873      871       -2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.54% <0%> (-1.3%) | 86% <0%> (-1%) | |\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 69.69% <0%> (+3.03%) | 15% <0%> (+1%) | :arrow_up: |\n| .../main/java/azkaban/utils/ExecutorServiceUtils.java | 100% <0%> (+10%) | 5% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 8e7f626...d9921d6. Read the comment docs.\n. # Codecov Report\nMerging #1852 into master will decrease coverage by 0.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1852      +/-\n============================================\n- Coverage     32.44%   32.42%   -0.02%   \n+ Complexity     2541     2540       -1   \n============================================\n  Files           390      390            \n  Lines         28486    28486            \n  Branches       3618     3618            \n============================================\n- Hits           9241     9237       -4   \n- Misses        18372    18376       +4   \n  Partials        873      873\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.76% <0%> (-1.08%) | 85% <0%> (-2%) | |\n| .../main/java/azkaban/utils/ExecutorServiceUtils.java | 100% <0%> (+10%) | 5% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 8e7f626...32a5c45. Read the comment docs.\n. # Codecov Report\nMerging #1854 into master will increase coverage by 0.22%.\nThe diff coverage is 87.5%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1854      +/-\n============================================\n+ Coverage      32.5%   32.73%   +0.22%   \n- Complexity     2542     2592      +50   \n============================================\n  Files           390      392       +2   \n  Lines         28486    28624     +138   \n  Branches       3618     3647      +29   \n============================================\n+ Hits           9260     9369     +109   \n- Misses        18351    18372      +21   \n- Partials        875      883       +8\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...-common/src/main/java/azkaban/executor/Status.java | 100% <100%> (\u00f8) | 13 <4> (+4) | :arrow_up: |\n| ...zkaban-common/src/main/java/azkaban/flow/Node.java | 62.22% <100%> (+1.75%) | 17 <2> (+2) | :arrow_up: |\n| .../java/azkaban/project/DirectoryYamlFlowLoader.java | 96.87% <100%> (+0.53%) | 26 <3> (+3) | :arrow_up: |\n| ...src/main/java/azkaban/executor/ExecutableNode.java | 76.62% <80%> (+0.04%) | 61 <2> (+1) | :arrow_up: |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 82.5% <82.5%> (\u00f8) | 20 <20> (?) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.61% <86.66%> (-0.19%) | 146 <6> (+2) | |\n| ...c/main/java/azkaban/flow/ConditionOnJobStatus.java | 87.5% <87.5%> (\u00f8) | 5 <5> (?) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 87.5% <0%> (-2.09%) | 16% <0%> (-1%) | |\n| ...main/java/azkaban/executor/ExecutorApiGateway.java | 23.68% <0%> (-1.32%) | 3% <0%> (\u00f8) | |\n| ... and 16 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 9f87c6a...25b7c28. Read the comment docs.\n. # Codecov Report\nMerging #1855 into master will increase coverage by <.01%.\nThe diff coverage is 73.07%.\n\n\n```diff\n@@             Coverage Diff             @@\nmaster   #1855      +/-\n===========================================\n+ Coverage      32.5%   32.5%   +<.01%   \n- Complexity     2542    2550       +8   \n===========================================\n  Files           390     390            \n  Lines         28486   28495       +9   \n  Branches       3618    3624       +6   \n===========================================\n+ Hits           9260    9263       +3   \n- Misses        18351   18358       +7   \n+ Partials        875     874       -1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...ava/azkaban/webapp/servlet/FlowTriggerServlet.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...mon/src/main/java/azkaban/project/FlowTrigger.java | 100% <100%> (\u00f8) | 14 <4> (+2) | :arrow_up: |\n| ...src/main/java/azkaban/project/FlowTriggerBean.java | 91.66% <100%> (+8.33%) | 8 <0> (+1) | :arrow_up: |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 72.72% <100%> (\u00f8) | 60 <0> (\u00f8) | :arrow_down: |\n| .../src/main/java/azkaban/project/NodeBeanLoader.java | 89.52% <100%> (+0.74%) | 35 <5> (+6) | :arrow_up: |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.76% <0%> (-1.08%) | 85% <0%> (-2%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.93% <0%> (+0.13%) | 145% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 9f87c6a...b2d577e. Read the comment docs.\n. # Codecov Report\nMerging #1856 into master will decrease coverage by 0.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1856      +/-\n============================================\n- Coverage      32.5%   32.49%   -0.02%   \n+ Complexity     2542     2541       -1   \n============================================\n  Files           390      390            \n  Lines         28486    28486            \n  Branches       3618     3618            \n============================================\n- Hits           9260     9256       -4   \n- Misses        18351    18355       +4   \n  Partials        875      875\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 85.41% <0%> (-4.17%) | 16% <0%> (-1%) | |\n| ...main/java/azkaban/executor/ExecutableFlowBase.java | 75.66% <0%> (-1.06%) | 47% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.62% <0%> (-0.22%) | 87% <0%> (\u00f8) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.93% <0%> (+0.13%) | 145% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 9f87c6a...4c3f952. Read the comment docs.\n. # Codecov Report\nMerging #1857 into master will increase coverage by 0.03%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\nmaster   #1857      +/-\n===========================================\n+ Coverage     32.46%   32.5%   +0.03%   \n- Complexity     2536    2544       +8   \n===========================================\n  Files           390     390            \n  Lines         28486   28486            \n  Branches       3618    3618            \n===========================================\n+ Hits           9249    9258       +9   \n+ Misses        18357   18356       -1   \n+ Partials        880     872       -8\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.93% <0%> (+0.13%) | 145% <0%> (+1%) | :arrow_up: |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.41% <0%> (+0.64%) | 88% <0%> (+3%) | :arrow_up: |\n| ...main/java/azkaban/executor/ExecutableFlowBase.java | 76.71% <0%> (+1.05%) | 48% <0%> (+1%) | :arrow_up: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 69.79% <0%> (+2.08%) | 7% <0%> (+1%) | :arrow_up: |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 89.58% <0%> (+6.25%) | 17% <0%> (+2%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 6dfee1f...e04eba7. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@79a6a1f). Click here to learn what that means.\nThe diff coverage is 0%.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1858   +/-\n=========================================\n  Coverage          ?   32.55%         \n  Complexity        ?     2595         \n=========================================\n  Files             ?      398         \n  Lines             ?    28817         \n  Branches          ?     3677         \n=========================================\n  Hits              ?     9380         \n  Misses            ?    18557         \n  Partials          ?      880\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../trigger/kafka/KafkaDependencyInstanceContext.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...java/trigger/kafka/KafkaDepInstanceCollection.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...src/main/java/trigger/kafka/KafkaEventMonitor.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...ava/trigger/kafka/RegexKafkaDependencyMatcher.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...trigger/src/main/java/trigger/kafka/Constants.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| .../main/java/trigger/kafka/KafkaDependencyCheck.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 79a6a1f...94732a5. Read the comment docs.\n. # Codecov Report\nMerging #1860 into master will increase coverage by 0.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1860      +/-\n============================================\n+ Coverage     32.69%   32.71%   +0.01%   \n+ Complexity     2593     2590       -3   \n============================================\n  Files           392      392            \n  Lines         28624    28624            \n  Branches       3647     3647            \n============================================\n+ Hits           9360     9363       +3   \n+ Misses        18385    18377       -8   \n- Partials        879      884       +5\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../main/java/azkaban/utils/ExecutorServiceUtils.java | 90% <0%> (-10%) | 4% <0%> (-1%) | |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 67.5% <0%> (-5%) | 15% <0%> (-1%) | |\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 66.66% <0%> (-3.04%) | 14% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.11% <0%> (-2.6%) | 85% <0%> (-4%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.74% <0%> (+0.13%) | 147% <0%> (+1%) | :arrow_up: |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 72.72% <0%> (+0.39%) | 60% <0%> (+1%) | :arrow_up: |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 18.83% <0%> (+0.46%) | 7% <0%> (+2%) | :arrow_up: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (+18.75%) | 6% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 02f8351...120fdce. Read the comment docs.\n. # Codecov Report\nMerging #1861 into master will increase coverage by <.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\nmaster   #1861      +/-\n===========================================\n+ Coverage     32.69%   32.7%   +<.01%   \n- Complexity     2593    2597       +4   \n===========================================\n  Files           392     392            \n  Lines         28624   28624            \n  Branches       3647    3647            \n===========================================\n+ Hits           9360    9361       +1   \n- Misses        18385   18388       +3   \n+ Partials        879     875       -4\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 66.66% <0%> (-3.04%) | 14% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.62% <0%> (-1.08%) | 87% <0%> (-2%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.74% <0%> (+0.13%) | 147% <0%> (+1%) | :arrow_up: |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 72.72% <0%> (+0.39%) | 60% <0%> (+1%) | :arrow_up: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 51.04% <0%> (+2.08%) | 7% <0%> (+1%) | :arrow_up: |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 82.5% <0%> (+10%) | 20% <0%> (+4%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 02f8351...30578a5. Read the comment docs.\n. # Codecov Report\nMerging #1862 into master will increase coverage by 0.05%.\nThe diff coverage is 100%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1862      +/-\n============================================\n+ Coverage     32.69%   32.74%   +0.05%   \n  Complexity     2593     2593            \n============================================\n  Files           392      392            \n  Lines         28624    28626       +2   \n  Branches       3647     3647            \n============================================\n+ Hits           9360     9375      +15   \n+ Misses        18385    18370      -15   \n- Partials        879      881       +2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...main/java/azkaban/executor/FetchActiveFlowDao.java | 90% <100%> (+5.78%) | 3 <0> (\u00f8) | :arrow_down: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.54% <0%> (-2.16%) | 86% <0%> (-3%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.74% <0%> (+0.13%) | 147% <0%> (+1%) | :arrow_up: |\n| ...aban-db/src/main/java/azkaban/db/EncodingType.java | 80% <0%> (+10%) | 5% <0%> (+1%) | :arrow_up: |\n| ...-common/src/main/java/azkaban/utils/GZIPUtils.java | 95.45% <0%> (+13.63%) | 7% <0%> (+1%) | :arrow_up: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (+18.75%) | 6% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 02f8351...db58aaf. Read the comment docs.\n. # Codecov Report\nMerging #1863 into master will decrease coverage by 0.08%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1863      +/-\n============================================\n- Coverage     32.76%   32.67%   -0.09%   \n  Complexity     2595     2595            \n============================================\n  Files           392      392            \n  Lines         28624    28624            \n  Branches       3647     3647            \n============================================\n- Hits           9378     9353      -25   \n- Misses        18366    18394      +28   \n+ Partials        880      877       -3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 48.95% <0%> (-18.76%) | 6% <0%> (\u00f8) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.97% <0%> (-1.73%) | 87% <0%> (-2%) | |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 18.37% <0%> (-0.47%) | 5% <0%> (-2%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.61% <0%> (-0.14%) | 146% <0%> (-1%) | |\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 69.69% <0%> (+3.03%) | 15% <0%> (+1%) | :arrow_up: |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 77.5% <0%> (+10%) | 19% <0%> (+4%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 23a5fe7...9183d8f. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@79a6a1f). Click here to learn what that means.\nThe diff coverage is 58.51%.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1865   +/-\n=========================================\n  Coverage          ?   32.66%         \n  Complexity        ?     2598         \n=========================================\n  Files             ?      398         \n  Lines             ?    28873         \n  Branches          ?     3684         \n=========================================\n  Hits              ?     9431         \n  Misses            ?    18560         \n  Partials          ?      882\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| az-core/src/main/java/azkaban/Constants.java | 25% <\u00f8> (\u00f8) | 1 <0> (?) | |\n| .../src/main/java/azkaban/execapp/ProjectVersion.java | 80.95% <\u00f8> (\u00f8) | 10 <0> (?) | |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 19.59% <30.76%> (\u00f8) | 6 <1> (?) | |\n| ...er/src/main/java/azkaban/execapp/FlowPreparer.java | 80.16% <78.18%> (\u00f8) | 10 <1> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 79a6a1f...8de9a83. Read the comment docs.\n. # Codecov Report\nMerging #1867 into master will increase coverage by 0.02%.\nThe diff coverage is 0%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1867      +/-\n============================================\n+ Coverage     32.51%   32.54%   +0.02%   \n- Complexity     2590     2596       +6   \n============================================\n  Files           398      398            \n  Lines         28817    28817            \n  Branches       3677     3677            \n============================================\n+ Hits           9370     9378       +8   \n+ Misses        18563    18560       -3   \n+ Partials        884      879       -5\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 42.15% <0%> (\u00f8) | 52 <0> (\u00f8) | :arrow_down: |\n| .../main/java/azkaban/utils/ExecutorServiceUtils.java | 90% <0%> (-10%) | 4% <0%> (-1%) | |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 72.72% <0%> (+0.39%) | 60% <0%> (+1%) | :arrow_up: |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.97% <0%> (+0.86%) | 87% <0%> (+2%) | :arrow_up: |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 82.5% <0%> (+10%) | 20% <0%> (+4%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d43c783...425acf3. Read the comment docs.\n. # Codecov Report\nMerging #1868 into master will decrease coverage by 0.04%.\nThe diff coverage is 50%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1868      +/-\n============================================\n- Coverage     32.51%   32.46%   -0.05%   \n- Complexity     2590     2593       +3   \n============================================\n  Files           398      398            \n  Lines         28817    28818       +1   \n  Branches       3677     3678       +1   \n============================================\n- Hits           9370     9356      -14   \n- Misses        18563    18583      +20   \n+ Partials        884      879       -5\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...src/main/java/azkaban/executor/ExecutableNode.java | 76.29% <50%> (-0.34%) | 61 <0> (\u00f8) | |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 51.04% <0%> (-16.67%) | 7% <0%> (+1%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.74% <0%> (+0.13%) | 147% <0%> (+1%) | :arrow_up: |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 72.72% <0%> (+0.39%) | 60% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d43c783...d62ae3b. Read the comment docs.\n. # Codecov Report\nMerging #1869 into master will increase coverage by 0.08%.\nThe diff coverage is 100%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1869      +/-\n============================================\n+ Coverage     32.48%   32.56%   +0.08%   \n- Complexity     2592     2596       +4   \n============================================\n  Files           398      398            \n  Lines         28817    28818       +1   \n  Branches       3677     3677            \n============================================\n+ Hits           9360     9385      +25   \n+ Misses        18578    18552      -26   \n- Partials        879      881       +2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...src/main/java/azkaban/executor/ExecutableNode.java | 77.58% <100%> (+0.96%) | 63 <2> (+2) | :arrow_up: |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.74% <0%> (+0.13%) | 147% <0%> (+1%) | :arrow_up: |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.84% <0%> (+1.07%) | 87% <0%> (+2%) | :arrow_up: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (+16.66%) | 6% <0%> (-1%) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update c6509ee...b3e4d9b. Read the comment docs.\n. # Codecov Report\nMerging #1871 into master will decrease coverage by 0.05%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1871      +/-\n============================================\n- Coverage     32.64%   32.58%   -0.06%   \n- Complexity     2593     2594       +1   \n============================================\n  Files           398      398            \n  Lines         28875    28875            \n  Branches       3685     3685            \n============================================\n- Hits           9426     9409      -17   \n- Misses        18562    18583      +21   \n+ Partials        887      883       -4\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 51.04% <0%> (-16.67%) | 7% <0%> (+1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.76% <0%> (-0.44%) | 85% <0%> (-1%) | |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 89.58% <0%> (+2.08%) | 17% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 1ab387b...0aabac1. Read the comment docs.\n. # Codecov Report\nMerging #1873 into master will increase coverage by 0.01%.\nThe diff coverage is 71.42%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1873      +/-\n============================================\n+ Coverage     32.64%   32.65%   +0.01%   \n- Complexity     2595     2603       +8   \n============================================\n  Files           398      398            \n  Lines         28875    28909      +34   \n  Branches       3685     3689       +4   \n============================================\n+ Hits           9427     9441      +14   \n- Misses        18563    18589      +26   \n+ Partials        885      879       -6\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...a/azkaban/viewer/reportal/ReportalMailCreator.java | 0% <\u00f8> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...main/java/azkaban/executor/JdbcExecutorLoader.java | 27.27% <0%> (-0.42%) | 7 <0> (\u00f8) | |\n| ...java/azkaban/executor/mail/DefaultMailCreator.java | 88.4% <100%> (+1.85%) | 17 <0> (+3) | :arrow_up: |\n| ...an-common/src/main/java/azkaban/utils/Emailer.java | 51.28% <30%> (-3.8%) | 8 <0> (\u00f8) | |\n| ...c/main/java/azkaban/executor/ExecutionFlowDao.java | 58.46% <60%> (+0.6%) | 13 <1> (+1) | :arrow_up: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 48.95% <0%> (-18.76%) | 6% <0%> (\u00f8) | |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 87.5% <0%> (-2.09%) | 16% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.19% <0%> (-0.44%) | 86% <0%> (-1%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 63.09% <0%> (+2.38%) | 13% <0%> (\u00f8) | :arrow_down: |\n| ... and 2 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update c4d2187...a71d125. Read the comment docs.\n. # Codecov Report\nMerging #1875 into master will increase coverage by <.01%.\nThe diff coverage is 50%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1875      +/-\n============================================\n+ Coverage     32.72%   32.72%   +<.01%   \n  Complexity     2604     2604            \n============================================\n  Files           398      399       +1   \n  Lines         28909    28912       +3   \n  Branches       3689     3688       -1   \n============================================\n+ Hits           9460     9461       +1   \n  Misses        18568    18568            \n- Partials        881      883       +2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 63.09% <\u00f8> (\u00f8) | 13 <0> (\u00f8) | :arrow_down: |\n| ...-common/src/main/java/azkaban/jobExecutor/Job.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.25% <100%> (-0.37%) | 86 <0> (-1) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.93% <37.5%> (+0.32%) | 144 <3> (-2) | :arrow_down: |\n| ...src/main/java/azkaban/executor/ExecutableNode.java | 76.66% <57.14%> (-0.59%) | 66 <3> (+3) | |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 85.41% <0%> (-4.17%) | 16% <0%> (-1%) | |\n| ...main/java/azkaban/executor/ExecutableFlowBase.java | 75.66% <0%> (-1.06%) | 47% <0%> (-1%) | |\n| ... and 3 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 1e33654...c2db027. Read the comment docs.\n. # Codecov Report\nMerging #1876 into master will decrease coverage by 0.02%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\nmaster   #1876      +/-\n===========================================\n- Coverage     32.72%   32.7%   -0.03%   \n+ Complexity     2604    2602       -2   \n===========================================\n  Files           398     398            \n  Lines         28909   28909            \n  Branches       3689    3689            \n===========================================\n- Hits           9460    9454       -6   \n- Misses        18568   18572       +4   \n- Partials        881     883       +2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 60.71% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.76% <0%> (-0.87%) | 85% <0%> (-2%) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 1e33654...5de9c84. Read the comment docs.\n. # Codecov Report\nMerging #1880 into master will increase coverage by 0.03%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1880      +/-\n============================================\n+ Coverage     32.72%   32.75%   +0.03%   \n- Complexity     2604     2607       +3   \n============================================\n  Files           398      398            \n  Lines         28909    28909            \n  Branches       3689     3689            \n============================================\n+ Hits           9460     9469       +9   \n+ Misses        18568    18561       -7   \n+ Partials        881      879       -2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 77.5% <0%> (-5%) | 19% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 71.05% <0%> (+0.43%) | 88% <0%> (+1%) | :arrow_up: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 69.79% <0%> (+2.08%) | 7% <0%> (+1%) | :arrow_up: |\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 69.69% <0%> (+3.03%) | 15% <0%> (+1%) | :arrow_up: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 66.66% <0%> (+3.57%) | 13% <0%> (\u00f8) | :arrow_down: |\n| ...src/main/java/azkaban/jobExecutor/AbstractJob.java | 37.93% <0%> (+6.89%) | 5% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 78f30ac...b258c40. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@3527d30). Click here to learn what that means.\nThe diff coverage is n/a.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1881   +/-\n=========================================\n  Coverage          ?   32.67%         \n  Complexity        ?     2603         \n=========================================\n  Files             ?      398         \n  Lines             ?    28909         \n  Branches          ?     3689         \n=========================================\n  Hits              ?     9445         \n  Misses            ?    18585         \n  Partials          ?      879\n```\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 3527d30...b113c60. Read the comment docs.\n. # Codecov Report\nMerging #1882 into master will decrease coverage by 0.03%.\nThe diff coverage is 100%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1882      +/-\n============================================\n- Coverage     32.72%   32.68%   -0.04%   \n+ Complexity     2604     2598       -6   \n============================================\n  Files           398      398            \n  Lines         28909    28909            \n  Branches       3689     3689            \n============================================\n- Hits           9460     9450      -10   \n- Misses        18568    18573       +5   \n- Partials        881      886       +5\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...java/azkaban/executor/mail/DefaultMailCreator.java | 88.4% <100%> (\u00f8) | 17 <0> (\u00f8) | :arrow_down: |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 72.5% <0%> (-10%) | 16% <0%> (-4%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 60.71% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.76% <0%> (-0.87%) | 85% <0%> (-2%) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 78f30ac...62998bb. Read the comment docs.\n. # Codecov Report\nMerging #1883 into master will increase coverage by 0.25%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1883      +/-\n============================================\n+ Coverage     32.72%   32.97%   +0.25%   \n- Complexity     2604     2668      +64   \n============================================\n  Files           398      404       +6   \n  Lines         28909    29910    +1001   \n  Branches       3689     3937     +248   \n============================================\n+ Hits           9460     9864     +404   \n- Misses        18568    19143     +575   \n- Partials        881      903      +22\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 60.71% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 17.91% <0%> (-1.68%) | 9% <0%> (+3%) | |\n| ...n/src/main/java/azkaban/jobtype/HadoopJavaJob.java | 0% <0%> (\u00f8) | 0% <0%> (\u00f8) | :arrow_down: |\n| ...n/src/main/java/azkaban/jobtype/HadoopHiveJob.java | 0% <0%> (\u00f8) | 0% <0%> (\u00f8) | :arrow_down: |\n| ...in/src/main/java/azkaban/jobtype/HadoopPigJob.java | 0% <0%> (\u00f8) | 0% <0%> (\u00f8) | :arrow_down: |\n| ...rypto/src/main/java/azkaban/crypto/CryptoV1_1.java | 100% <0%> (\u00f8) | 5% <0%> (?) | |\n| az-crypto/src/main/java/azkaban/crypto/Crypto.java | 92.3% <0%> (\u00f8) | 10% <0%> (?) | |\n| ...z-crypto/src/main/java/azkaban/crypto/Version.java | 83.33% <0%> (\u00f8) | 5% <0%> (?) | |\n| ...ypto/src/main/java/azkaban/crypto/Decryptions.java | 0% <0%> (\u00f8) | 0% <0%> (?) | |\n| ...-crypto/src/main/java/azkaban/crypto/CryptoV1.java | 100% <0%> (\u00f8) | 5% <0%> (?) | |\n| ... and 8 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 78f30ac...70b986c. Read the comment docs.\n. # Codecov Report\nMerging #1885 into master will not change coverage.\nThe diff coverage is n/a.\n\n\n```diff\n@@           Coverage Diff            @@\nmaster   #1885   +/-\n========================================\n  Coverage      32.7%   32.7%         \n+ Complexity     2601    2599    -2   \n========================================\n  Files           398     398         \n  Lines         28909   28909         \n  Branches       3689    3689         \n========================================\n  Hits           9455    9455         \n+ Misses        18570   18569    -1   \n- Partials        884     885    +1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 72.5% <0%> (-10%) | 16% <0%> (-4%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.62% <0%> (+0.86%) | 87% <0%> (+2%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 25b41f4...4e114dc. Read the comment docs.\n. # Codecov Report\nMerging #1889 into master will increase coverage by 0.03%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\nmaster   #1889      +/-\n===========================================\n+ Coverage     32.67%   32.7%   +0.03%   \n  Complexity     2603    2603            \n===========================================\n  Files           398     398            \n  Lines         28909   28909            \n  Branches       3689    3689            \n===========================================\n+ Hits           9445    9455      +10   \n+ Misses        18585   18572      -13   \n- Partials        879     882       +3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 66.66% <0%> (-3.04%) | 14% <0%> (-1%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 60.71% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.19% <0%> (-1.08%) | 86% <0%> (-2%) | |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 72.33% <0%> (-0.4%) | 59% <0%> (-1%) | |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 20.04% <0%> (+0.45%) | 8% <0%> (+2%) | :arrow_up: |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 77.5% <0%> (+5%) | 19% <0%> (+3%) | :arrow_up: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (+16.66%) | 6% <0%> (-1%) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 34bf82c...eb310f5. Read the comment docs.\n. # Codecov Report\nMerging #1890 into master will increase coverage by 0.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1890      +/-\n============================================\n+ Coverage      32.7%   32.72%   +0.01%   \n- Complexity     2602     2605       +3   \n============================================\n  Files           398      398            \n  Lines         28909    28909            \n  Branches       3689     3689            \n============================================\n+ Hits           9456     9461       +5   \n+ Misses        18570    18568       -2   \n+ Partials        883      880       -3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 77.5% <0%> (-5%) | 19% <0%> (-1%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.74% <0%> (+0.13%) | 147% <0%> (+1%) | :arrow_up: |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 71.05% <0%> (+1.29%) | 88% <0%> (+3%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 9bf61c0...71ef71f. Read the comment docs.\n. # Codecov Report\nMerging #1891 into master will decrease coverage by 0.05%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1891      +/-\n============================================\n- Coverage      32.7%   32.65%   -0.06%   \n  Complexity     2602     2602            \n============================================\n  Files           398      398            \n  Lines         28909    28909            \n  Branches       3689     3689            \n============================================\n- Hits           9456     9441      -15   \n- Misses        18570    18588      +18   \n+ Partials        883      880       -3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 48.95% <0%> (-18.76%) | 6% <0%> (\u00f8) | |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 72.5% <0%> (-10%) | 16% <0%> (-4%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 60.71% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 71.27% <0%> (+1.51%) | 88% <0%> (+3%) | :arrow_up: |\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 69.69% <0%> (+3.03%) | 15% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 9bf61c0...17593a6. Read the comment docs.\n. # Codecov Report\nMerging #1892 into master will decrease coverage by 0.1%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1892      +/-\n============================================\n- Coverage     32.72%   32.62%   -0.11%   \n+ Complexity     2606     2598       -8   \n============================================\n  Files           398      398            \n  Lines         28909    28909            \n  Branches       3689     3689            \n============================================\n- Hits           9461     9432      -29   \n- Misses        18569    18594      +25   \n- Partials        879      883       +4\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 48.95% <0%> (-18.76%) | 6% <0%> (\u00f8) | |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 67.5% <0%> (-10%) | 15% <0%> (-4%) | |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 85.41% <0%> (-4.17%) | 16% <0%> (-1%) | |\n| ...main/java/azkaban/executor/ExecutableFlowBase.java | 75.66% <0%> (-1.06%) | 47% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.62% <0%> (-0.44%) | 87% <0%> (-1%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.61% <0%> (-0.14%) | 146% <0%> (-1%) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 9b9c032...6e53be0. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@1c379d1). Click here to learn what that means.\nThe diff coverage is n/a.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1893   +/-\n=========================================\n  Coverage          ?   32.69%         \n  Complexity        ?     2598         \n=========================================\n  Files             ?      398         \n  Lines             ?    28909         \n  Branches          ?     3689         \n=========================================\n  Hits              ?     9452         \n  Misses            ?    18571         \n  Partials          ?      886\n```\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 1c379d1...e80f64a. Read the comment docs.\n. # Codecov Report\nMerging #1894 into master will increase coverage by 0.43%.\nThe diff coverage is 45.35%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1894      +/-\n============================================\n+ Coverage     32.71%   33.14%   +0.43%   \n- Complexity     2603     2660      +57   \n============================================\n  Files           398      411      +13   \n  Lines         28914    29286     +372   \n  Branches       3690     3728      +38   \n============================================\n+ Hits           9458     9708     +250   \n- Misses        18574    18680     +106   \n- Partials        882      898      +16\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...in/src/main/java/azkaban/jobtype/HadoopPigJob.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...gin/src/main/java/azkaban/jobtype/pig/PigUtil.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| .../azkaban/jobtype/HadoopTuningSecurePigWrapper.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...n/java/azkaban/jobtype/pig/PigCommonConstants.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...n/java/azkaban/jobtype/HadoopSecurePigWrapper.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...n/java/azkaban/jobtype/tuning/TuningException.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...a/azkaban/jobtype/HadoopConfigurationInjector.java | 73.21% <71.42%> (+73.21%) | 11 <2> (+11) | :arrow_up: |\n| ...ban/jobtype/HadoopTuningConfigurationInjector.java | 83.33% <83.33%> (\u00f8) | 2 <2> (?) | |\n| ...a/azkaban/jobtype/tuning/TuningParameterUtils.java | 84.54% <84.54%> (\u00f8) | 10 <10> (?) | |\n| ...va/azkaban/jobtype/tuning/TuningErrorDetector.java | 95% <95%> (\u00f8) | 5 <5> (?) | |\n| ... and 25 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d2db592...c808ef4. Read the comment docs.\n. # Codecov Report\nMerging #1896 into master will decrease coverage by 0.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\nmaster   #1896      +/-\n===========================================\n- Coverage     32.72%   32.7%   -0.02%   \n+ Complexity     2604    2600       -4   \n===========================================\n  Files           398     398            \n  Lines         28909   28909            \n  Branches       3689    3689            \n===========================================\n- Hits           9460    9455       -5   \n- Misses        18568   18569       +1   \n- Partials        881     885       +4\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 72.5% <0%> (-5%) | 16% <0%> (-3%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 60.71% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.84% <0%> (-0.22%) | 87% <0%> (-1%) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update ebfb731...bfc654b. Read the comment docs.\n. # Codecov Report\nMerging #1898 into master will decrease coverage by <.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1898      +/-\n============================================\n- Coverage     32.72%   32.71%   -0.01%   \n+ Complexity     2604     2602       -2   \n============================================\n  Files           398      398            \n  Lines         28909    28909            \n  Branches       3689     3689            \n============================================\n- Hits           9460     9459       -1   \n+ Misses        18568    18567       -1   \n- Partials        881      883       +2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../main/java/azkaban/utils/ExecutorServiceUtils.java | 90% <0%> (-10%) | 4% <0%> (-1%) | |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 72.5% <0%> (-5%) | 16% <0%> (-3%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.84% <0%> (-0.22%) | 87% <0%> (-1%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.74% <0%> (+0.13%) | 147% <0%> (+1%) | :arrow_up: |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 20.04% <0%> (+0.45%) | 8% <0%> (+2%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update ebfb731...caab240. Read the comment docs.\n. # Codecov Report\nMerging #1903 into master will decrease coverage by 0.03%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1903      +/-\n============================================\n- Coverage     32.72%   32.68%   -0.04%   \n+ Complexity     2605     2598       -7   \n============================================\n  Files           398      398            \n  Lines         28909    28909            \n  Branches       3689     3689            \n============================================\n- Hits           9460     9450      -10   \n- Misses        18569    18573       +4   \n- Partials        880      886       +6\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 67.5% <0%> (-15%) | 15% <0%> (-5%) | |\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 66.66% <0%> (-3.04%) | 14% <0%> (-1%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 60.71% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 19.59% <0%> (-0.46%) | 6% <0%> (-2%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.19% <0%> (+0.21%) | 86% <0%> (\u00f8) | :arrow_down: |\n| .../main/java/azkaban/utils/ExecutorServiceUtils.java | 100% <0%> (+10%) | 5% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 34d6010...942d649. Read the comment docs.\n. # Codecov Report\nMerging #1904 into master will decrease coverage by 0.05%.\nThe diff coverage is 40%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1904      +/-\n============================================\n- Coverage      32.7%   32.65%   -0.06%   \n- Complexity     2602     2606       +4   \n============================================\n  Files           398      398            \n  Lines         28909    28929      +20   \n  Branches       3689     3692       +3   \n============================================\n- Hits           9456     9447       -9   \n- Misses        18570    18602      +32   \n+ Partials        883      880       -3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...n/src/main/java/azkaban/jobtype/HadoopHiveJob.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...n/src/main/java/azkaban/jobtype/HadoopJavaJob.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...in/src/main/java/azkaban/jobtype/HadoopPigJob.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| .../src/main/java/azkaban/jobtype/HadoopJobUtils.java | 41.57% <100%> (+1.9%) | 21 <3> (+3) | :arrow_up: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 48.95% <0%> (-18.76%) | 6% <0%> (\u00f8) | |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 85.41% <0%> (-4.17%) | 16% <0%> (-1%) | |\n| ...main/java/azkaban/executor/ExecutableFlowBase.java | 75.66% <0%> (-1.06%) | 47% <0%> (-1%) | |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 19.37% <0%> (-0.22%) | 6% <0%> (\u00f8) | |\n| ...er/src/main/java/azkaban/execapp/FlowPreparer.java | 80.16% <0%> (\u00f8) | 10% <0%> (\u00f8) | :arrow_down: |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.62% <0%> (+0.86%) | 87% <0%> (+2%) | :arrow_up: |\n| ... and 2 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update f03c51d...7342d59. Read the comment docs.\n. # Codecov Report\nMerging #1906 into master will decrease coverage by <.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\nmaster   #1906      +/-\n===========================================\n- Coverage      32.7%   32.7%   -0.01%   \n+ Complexity     2602    2601       -1   \n===========================================\n  Files           398     398            \n  Lines         28909   28909            \n  Branches       3689    3689            \n===========================================\n- Hits           9456    9454       -2   \n- Misses        18570   18571       +1   \n- Partials        883     884       +1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 77.5% <0%> (-5%) | 19% <0%> (-1%) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update f03c51d...c2763c6. Read the comment docs.\n. # Codecov Report\nMerging #1909 into master will increase coverage by <.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\nmaster   #1909      +/-\n===========================================\n+ Coverage      32.7%   32.7%   +<.01%   \n+ Complexity     2601    2600       -1   \n===========================================\n  Files           398     398            \n  Lines         28909   28907       -2   \n  Branches       3689    3688       -1   \n===========================================\n  Hits           9454    9454            \n+ Misses        18571   18570       -1   \n+ Partials        884     883       -1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...java/azkaban/trigger/builtin/BasicTimeChecker.java | 78.88% <\u00f8> (+1.71%) | 15 <0> (\u00f8) | :arrow_down: |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 72.5% <0%> (-5%) | 16% <0%> (-3%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 60.71% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...main/java/azkaban/executor/ExecutableFlowBase.java | 76.71% <0%> (+1.05%) | 48% <0%> (+1%) | :arrow_up: |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 89.58% <0%> (+4.16%) | 17% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 7c4854d...1f6bb80. Read the comment docs.\n. # Codecov Report\nMerging #1910 into master will decrease coverage by 0.04%.\nThe diff coverage is 100%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1910      +/-\n============================================\n- Coverage      32.7%   32.66%   -0.05%   \n  Complexity     2601     2601            \n============================================\n  Files           398      398            \n  Lines         28909    28913       +4   \n  Branches       3689     3689            \n============================================\n- Hits           9454     9443      -11   \n- Misses        18571    18590      +19   \n+ Partials        884      880       -4\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 42.4% <100%> (+0.25%) | 52 <1> (\u00f8) | :arrow_down: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 48.95% <0%> (-18.76%) | 6% <0%> (\u00f8) | |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 72.5% <0%> (-5%) | 16% <0%> (-3%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.41% <0%> (-0.22%) | 87% <0%> (\u00f8) | |\n| ...main/java/azkaban/executor/ExecutableFlowBase.java | 76.71% <0%> (+1.05%) | 48% <0%> (+1%) | :arrow_up: |\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 69.69% <0%> (+3.03%) | 15% <0%> (+1%) | :arrow_up: |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 89.58% <0%> (+4.16%) | 17% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 7c4854d...8b664bc. Read the comment docs.\n. # Codecov Report\nMerging #1911 into master will increase coverage by 0.01%.\nThe diff coverage is 29.41%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1911      +/-\n============================================\n+ Coverage      32.7%   32.72%   +0.01%   \n- Complexity     2601     2604       +3   \n============================================\n  Files           398      398            \n  Lines         28909    28914       +5   \n  Branches       3689     3690       +1   \n============================================\n+ Hits           9454     9461       +7   \n  Misses        18571    18571            \n+ Partials        884      882       -2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 19.37% <0%> (-0.22%) | 6 <0> (\u00f8) | |\n| ...er/src/main/java/azkaban/execapp/FlowPreparer.java | 80.16% <71.42%> (\u00f8) | 10 <1> (\u00f8) | :arrow_down: |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.84% <0%> (+0.21%) | 87% <0%> (\u00f8) | :arrow_down: |\n| ...main/java/azkaban/executor/ExecutableFlowBase.java | 76.71% <0%> (+1.05%) | 48% <0%> (+1%) | :arrow_up: |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 89.58% <0%> (+4.16%) | 17% <0%> (+1%) | :arrow_up: |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 82.5% <0%> (+5%) | 20% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 7c4854d...95bc703. Read the comment docs.\n. # Codecov Report\nMerging #1912 into master will increase coverage by 0.01%.\nThe diff coverage is 50%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1912      +/-\n============================================\n+ Coverage     32.71%   32.72%   +0.01%   \n- Complexity     2603     2607       +4   \n============================================\n  Files           398      398            \n  Lines         28914    28926      +12   \n  Branches       3690     3693       +3   \n============================================\n+ Hits           9458     9466       +8   \n- Misses        18574    18581       +7   \n+ Partials        882      879       -3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...n/java/azkaban/soloserver/AzkabanSingleServer.java | 13.15% <0%> (-1.55%) | 2 <0> (\u00f8) | |\n| ...in/java/azkaban/execapp/AzkabanExecutorServer.java | 5.28% <0%> (-0.1%) | 3 <0> (\u00f8) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.62% <90%> (\u00f8) | 146 <0> (\u00f8) | :arrow_down: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 59.52% <0%> (-3.58%) | 13% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 71.05% <0%> (+0.43%) | 88% <0%> (+1%) | :arrow_up: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 69.79% <0%> (+2.08%) | 7% <0%> (+1%) | :arrow_up: |\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 69.69% <0%> (+3.03%) | 15% <0%> (+1%) | :arrow_up: |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 82.5% <0%> (+5%) | 20% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d2db592...d7788df. Read the comment docs.\n. # Codecov Report\nMerging #1913 into master will increase coverage by <.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\nmaster   #1913      +/-\n===========================================\n+ Coverage     32.69%   32.7%   +<.01%   \n- Complexity     2604    2605       +1   \n===========================================\n  Files           398     398            \n  Lines         28929   28929            \n  Branches       3692    3692            \n===========================================\n+ Hits           9459    9461       +2   \n+ Misses        18586   18585       -1   \n+ Partials        884     883       -1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../main/java/azkaban/utils/ExecutorServiceUtils.java | 90% <0%> (-10%) | 4% <0%> (-1%) | |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 72.72% <0%> (+0.39%) | 60% <0%> (+1%) | :arrow_up: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 69.79% <0%> (+2.08%) | 7% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 2be255d...2b9a976. Read the comment docs.\n. # Codecov Report\nMerging #1914 into master will increase coverage by 0.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1914      +/-\n============================================\n+ Coverage     32.69%   32.71%   +0.01%   \n- Complexity     2604     2605       +1   \n============================================\n  Files           398      398            \n  Lines         28929    28929            \n  Branches       3692     3692            \n============================================\n+ Hits           9459     9463       +4   \n+ Misses        18586    18582       -4   \n  Partials        884      884\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 77.5% <0%> (-5%) | 19% <0%> (-1%) | |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 85.41% <0%> (-4.17%) | 16% <0%> (-1%) | |\n| ...main/java/azkaban/executor/ExecutableFlowBase.java | 75.66% <0%> (-1.06%) | 47% <0%> (-1%) | |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 72.72% <0%> (+0.39%) | 60% <0%> (+1%) | :arrow_up: |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 71.27% <0%> (+1.51%) | 88% <0%> (+3%) | :arrow_up: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 63.09% <0%> (+2.38%) | 13% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 2be255d...2291460. Read the comment docs.\n. # Codecov Report\nMerging #1915 into master will increase coverage by 0.19%.\nThe diff coverage is 50%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1915      +/-\n============================================\n+ Coverage     32.65%   32.85%   +0.19%   \n- Complexity     2607     2629      +22   \n============================================\n  Files           398      404       +6   \n  Lines         28929    29057     +128   \n  Branches       3692     3697       +5   \n============================================\n+ Hits           9447     9546      +99   \n- Misses        18604    18628      +24   \n- Partials        878      883       +5\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...to/src/main/java/azkaban/crypto/EncryptionCLI.java | 0% <\u00f8> (\u00f8) | 0 <0> (?) | |\n| ...z-crypto/src/main/java/azkaban/crypto/Version.java | 83.33% <\u00f8> (\u00f8) | 5 <0> (?) | |\n| ...-crypto/src/main/java/azkaban/crypto/CryptoV1.java | 100% <\u00f8> (\u00f8) | 5 <0> (?) | |\n| ...rypto/src/main/java/azkaban/crypto/CryptoV1_1.java | 100% <\u00f8> (\u00f8) | 5 <0> (?) | |\n| ...ypto/src/main/java/azkaban/crypto/Decryptions.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| az-crypto/src/main/java/azkaban/crypto/Crypto.java | 92.3% <100%> (\u00f8) | 10 <2> (?) | |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 72.5% <0%> (-10%) | 16% <0%> (-4%) | |\n| ... and 9 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 0c6e46a...66869c8. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@86b63c6). Click here to learn what that means.\nThe diff coverage is 0%.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1916   +/-\n=========================================\n  Coverage          ?   32.81%         \n  Complexity        ?     2628         \n=========================================\n  Files             ?      404         \n  Lines             ?    29075         \n  Branches          ?     3702         \n=========================================\n  Hits              ?     9542         \n  Misses            ?    18649         \n  Partials          ?      884\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../azkaban/webapp/servlet/ProjectManagerServlet.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...li/java/azkaban/restli/ProjectManagerResource.java | 19.48% <0%> (\u00f8) | 7 <0> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 86b63c6...cf0b26b. Read the comment docs.\n. # Codecov Report\nMerging #1918 into master will increase coverage by 0.17%.\nThe diff coverage is 91.52%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1918      +/-\n============================================\n+ Coverage     32.82%   32.99%   +0.17%   \n- Complexity     2630     2644      +14   \n============================================\n  Files           404      404            \n  Lines         29069    29112      +43   \n  Branches       3700     3713      +13   \n============================================\n+ Hits           9541     9605      +64   \n+ Misses        18645    18623      -22   \n- Partials        883      884       +1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.95% <\u00f8> (+0.2%) | 143 <0> (-4) | :arrow_down: |\n| .../java/azkaban/project/DirectoryYamlFlowLoader.java | 93.66% <91.52%> (-3.22%) | 40 <19> (+14) | |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 87.5% <0%> (-2.09%) | 16% <0%> (-1%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 59.52% <0%> (-1.2%) | 13% <0%> (\u00f8) | |\n| ...li/java/azkaban/restli/ProjectManagerResource.java | 19.48% <0%> (-0.79%) | 7% <0%> (\u00f8) | |\n| ...azkaban/webapp/servlet/AbstractAzkabanServlet.java | 6.87% <0%> (-0.11%) | 6% <0%> (\u00f8) | |\n| az-core/src/main/java/azkaban/Constants.java | 25% <0%> (\u00f8) | 1% <0%> (\u00f8) | :arrow_down: |\n| ...mon/src/main/java/azkaban/project/FlowTrigger.java | 100% <0%> (\u00f8) | 14% <0%> (\u00f8) | :arrow_down: |\n| ...in/java/azkaban/project/FlowTriggerDependency.java | 91.66% <0%> (\u00f8) | 5% <0%> (\u00f8) | :arrow_down: |\n| ...on/src/main/java/azkaban/project/CronSchedule.java | 50% <0%> (\u00f8) | 3% <0%> (\u00f8) | :arrow_down: |\n| ... and 8 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 9bcbcb2...17f0c96. Read the comment docs.\n. # Codecov Report\nMerging #1919 into master will increase coverage by 0.05%.\nThe diff coverage is 66.66%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1919      +/-\n============================================\n+ Coverage     32.82%   32.87%   +0.05%   \n- Complexity     2630     2632       +2   \n============================================\n  Files           404      404            \n  Lines         29069    29075       +6   \n  Branches       3700     3701       +1   \n============================================\n+ Hits           9541     9559      +18   \n+ Misses        18645    18635      -10   \n+ Partials        883      881       -2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 45.05% <66.66%> (+2.65%) | 53 <0> (+1) | :arrow_up: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 48.95% <0%> (-18.76%) | 6% <0%> (\u00f8) | |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 72.5% <0%> (-5%) | 16% <0%> (-3%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.62% <0%> (-0.14%) | 146% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.62% <0%> (+0.86%) | 87% <0%> (+2%) | :arrow_up: |\n| ...ommon/src/main/java/azkaban/executor/Executor.java | 58% <0%> (+4%) | 14% <0%> (+1%) | :arrow_up: |\n| ...n/src/main/java/azkaban/metrics/CommonMetrics.java | 76.92% <0%> (+7.69%) | 6% <0%> (+1%) | :arrow_up: |\n| ...main/java/azkaban/executor/ExecutionReference.java | 77.27% <0%> (+9.09%) | 7% <0%> (+1%) | :arrow_up: |\n| ...ava/azkaban/executor/ExecutorManagerException.java | 83.33% <0%> (+11.11%) | 1% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 9bcbcb2...76890c1. Read the comment docs.\n. # Codecov Report\nMerging #1922 into master will decrease coverage by 0.01%.\nThe diff coverage is 78.12%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1922      +/-\n============================================\n- Coverage     32.95%   32.94%   -0.02%   \n+ Complexity     2656     2655       -1   \n============================================\n  Files           409      409            \n  Lines         29257    29258       +1   \n  Branches       3721     3721            \n============================================\n- Hits           9643     9640       -3   \n- Misses        18731    18734       +3   \n- Partials        883      884       +1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 44.97% <78.12%> (-0.05%) | 53 <0> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.76% <0%> (-0.87%) | 85% <0%> (-2%) | |\n| .../main/java/azkaban/utils/ExecutorServiceUtils.java | 100% <0%> (+10%) | 5% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update b20d5d0...21c596a. Read the comment docs.\n. # Codecov Report\nMerging #1923 into master will increase coverage by 0.09%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1923      +/-\n============================================\n+ Coverage     32.82%   32.91%   +0.09%   \n- Complexity     2630     2631       +1   \n============================================\n  Files           404      404            \n  Lines         29069    29066       -3   \n  Branches       3700     3699       -1   \n============================================\n+ Hits           9541     9568      +27   \n+ Misses        18645    18618      -27   \n+ Partials        883      880       -3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...li/java/azkaban/restli/ProjectManagerResource.java | 19.48% <0%> (-0.79%) | 7% <0%> (\u00f8) | |\n| .../azkaban/webapp/servlet/ProjectManagerServlet.java | 0% <0%> (\u00f8) | 0% <0%> (\u00f8) | :arrow_down: |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.16% <0%> (+0.41%) | 144% <0%> (-3%) | :arrow_down: |\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 45.05% <0%> (+2.65%) | 53% <0%> (+1%) | :arrow_up: |\n| ...ommon/src/main/java/azkaban/executor/Executor.java | 58% <0%> (+4%) | 14% <0%> (+1%) | :arrow_up: |\n| ...n/src/main/java/azkaban/metrics/CommonMetrics.java | 76.92% <0%> (+7.69%) | 6% <0%> (+1%) | :arrow_up: |\n| ...main/java/azkaban/executor/ExecutionReference.java | 77.27% <0%> (+9.09%) | 7% <0%> (+1%) | :arrow_up: |\n| ...ava/azkaban/executor/ExecutorManagerException.java | 83.33% <0%> (+11.11%) | 1% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 9bcbcb2...e63e0c6. Read the comment docs.\n. # Codecov Report\nMerging #1924 into master will increase coverage by <.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1924      +/-\n============================================\n+ Coverage     32.82%   32.82%   +<.01%   \n+ Complexity     2630     2629       -1   \n============================================\n  Files           404      404            \n  Lines         29069    29054      -15   \n  Branches       3700     3696       -4   \n============================================\n- Hits           9541     9537       -4   \n+ Misses        18645    18639       -6   \n+ Partials        883      878       -5\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.02% <\u00f8> (+0.27%) | 143 <0> (-4) | :arrow_down: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 59.52% <0%> (-1.2%) | 13% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.62% <0%> (+0.86%) | 87% <0%> (+2%) | :arrow_up: |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 82.5% <0%> (+5%) | 20% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 9bcbcb2...1bb201d. Read the comment docs.\n. # Codecov Report\nMerging #1927 into master will increase coverage by 0.06%.\nThe diff coverage is 33.33%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1927      +/-\n============================================\n+ Coverage     32.82%   32.88%   +0.06%   \n+ Complexity     2630     2626       -4   \n============================================\n  Files           404      404            \n  Lines         29069    29067       -2   \n  Branches       3700     3698       -2   \n============================================\n+ Hits           9541     9558      +17   \n+ Misses        18645    18627      -18   \n+ Partials        883      882       -1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 78.57% <0%> (+1.07%) | 12 <0> (-7) | :arrow_down: |\n| ...c/main/java/azkaban/flow/ConditionOnJobStatus.java | 85.71% <100%> (-1.79%) | 5 <0> (\u00f8) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-3.58%) | 13% <0%> (\u00f8) | |\n| ...li/java/azkaban/restli/ProjectManagerResource.java | 19.48% <0%> (-0.79%) | 7% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.11% <0%> (-0.65%) | 85% <0%> (\u00f8) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.62% <0%> (-0.14%) | 146% <0%> (-1%) | |\n| .../azkaban/webapp/servlet/ProjectManagerServlet.java | 0% <0%> (\u00f8) | 0% <0%> (\u00f8) | :arrow_down: |\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 45.05% <0%> (+2.65%) | 53% <0%> (+1%) | :arrow_up: |\n| ...ommon/src/main/java/azkaban/executor/Executor.java | 58% <0%> (+4%) | 14% <0%> (+1%) | :arrow_up: |\n| ...n/src/main/java/azkaban/metrics/CommonMetrics.java | 76.92% <0%> (+7.69%) | 6% <0%> (+1%) | :arrow_up: |\n| ... and 2 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 9bcbcb2...a1d08dc. Read the comment docs.\n. # Codecov Report\nMerging #1928 into master will increase coverage by 0.04%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1928      +/-\n============================================\n+ Coverage     32.88%   32.92%   +0.04%   \n+ Complexity     2633     2628       -5   \n============================================\n  Files           404      404            \n  Lines         29066    29066            \n  Branches       3699     3699            \n============================================\n+ Hits           9557     9569      +12   \n+ Misses        18634    18615      -19   \n- Partials        875      882       +7\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 72.5% <0%> (-10%) | 16% <0%> (-4%) | |\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 66.66% <0%> (-3.04%) | 14% <0%> (-1%) | |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 87.5% <0%> (-2.09%) | 16% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.19% <0%> (\u00f8) | 86% <0%> (\u00f8) | :arrow_down: |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.16% <0%> (+0.13%) | 144% <0%> (+1%) | :arrow_up: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (+18.75%) | 6% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d13ce99...5f2b0e7. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@65cfd11). Click here to learn what that means.\nThe diff coverage is 2.89%.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1929   +/-\n=========================================\n  Coverage          ?   32.87%         \n  Complexity        ?     2653         \n=========================================\n  Files             ?      409         \n  Lines             ?    29201         \n  Branches          ?     3716         \n=========================================\n  Hits              ?     9599         \n  Misses            ?    18725         \n  Partials          ?      877\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...ain/java/azkaban/viewer/reportal/ReportalType.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...n/java/azkaban/jobtype/ReportalTeradataRunner.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| .../java/azkaban/viewer/reportal/ReportalServlet.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| .../main/java/azkaban/reportal/util/ReportalUtil.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...ain/java/azkaban/jobtype/ReportalPrestoRunner.java | 5.88% <5.88%> (\u00f8) | 1 <1> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 65cfd11...e0c74fb. Read the comment docs.\n. # Codecov Report\nMerging #1930 into master will increase coverage by 0.06%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1930      +/-\n============================================\n+ Coverage     32.88%   32.94%   +0.06%   \n  Complexity     2633     2633            \n============================================\n  Files           404      404            \n  Lines         29066    29066            \n  Branches       3699     3699            \n============================================\n+ Hits           9557     9575      +18   \n+ Misses        18634    18613      -21   \n- Partials        875      878       +3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 66.66% <0%> (-3.04%) | 14% <0%> (-1%) | |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 87.5% <0%> (-2.09%) | 16% <0%> (-1%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.16% <0%> (+0.13%) | 144% <0%> (+1%) | :arrow_up: |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.62% <0%> (+0.43%) | 87% <0%> (+1%) | :arrow_up: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (+18.75%) | 6% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d13ce99...5ab4af0. Read the comment docs.\n. # Codecov Report\nMerging #1932 into master will increase coverage by 0.04%.\nThe diff coverage is 20%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1932      +/-\n============================================\n+ Coverage     32.88%   32.93%   +0.04%   \n- Complexity     2635     2644       +9   \n============================================\n  Files           404      408       +4   \n  Lines         29068    29137      +69   \n  Branches       3699     3704       +5   \n============================================\n+ Hits           9560     9597      +37   \n- Misses        18635    18659      +24   \n- Partials        873      881       +8\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...ain/java/azkaban/reportal/util/tableau/Result.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...ain/java/azkaban/viewer/reportal/ReportalType.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| .../java/azkaban/reportal/util/tableau/Countdown.java | 100% <100%> (\u00f8) | 4 <4> (?) | |\n| ...ava/azkaban/reportal/util/tableau/URLResponse.java | 25% <25%> (\u00f8) | 4 <4> (?) | |\n| ...in/java/azkaban/jobtype/ReportalTableauRunner.java | 8.33% <8.33%> (\u00f8) | 2 <2> (?) | |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 77.5% <0%> (-5%) | 19% <0%> (-1%) | |\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 66.66% <0%> (-3.04%) | 14% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.76% <0%> (-0.87%) | 85% <0%> (-2%) | |\n| ... and 7 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update b98fbc5...37c1f19. Read the comment docs.\n. # Codecov Report\nMerging #1933 into master will increase coverage by 0.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1933      +/-\n============================================\n+ Coverage     32.92%   32.93%   +0.01%   \n- Complexity     2629     2634       +5   \n============================================\n  Files           404      404            \n  Lines         29066    29066            \n  Branches       3699     3699            \n============================================\n+ Hits           9569     9574       +5   \n  Misses        18615    18615            \n+ Partials        882      877       -5\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...on/src/main/java/azkaban/project/CronSchedule.java | 50% <\u00f8> (\u00f8) | 3 <0> (\u00f8) | :arrow_down: |\n| ...in/java/azkaban/project/FlowTriggerDependency.java | 91.66% <\u00f8> (\u00f8) | 5 <0> (\u00f8) | :arrow_down: |\n| ...mon/src/main/java/azkaban/project/FlowTrigger.java | 100% <\u00f8> (\u00f8) | 14 <0> (\u00f8) | :arrow_down: |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 77.5% <0%> (-5%) | 19% <0%> (-1%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 60.71% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.16% <0%> (+0.13%) | 144% <0%> (+1%) | :arrow_up: |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.62% <0%> (+0.86%) | 87% <0%> (+2%) | :arrow_up: |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 89.58% <0%> (+2.08%) | 17% <0%> (+1%) | :arrow_up: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 69.79% <0%> (+2.08%) | 7% <0%> (+1%) | :arrow_up: |\n| .../main/java/azkaban/utils/ExecutorServiceUtils.java | 100% <0%> (+10%) | 5% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update c5f3a3d...3784411. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@cc3e12c). Click here to learn what that means.\nThe diff coverage is 31.7%.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1937   +/-\n=========================================\n  Coverage          ?   32.96%         \n  Complexity        ?     2688         \n=========================================\n  Files             ?      415         \n  Lines             ?    29360         \n  Branches          ?     3727         \n=========================================\n  Hits              ?     9679         \n  Misses            ?    18800         \n  Partials          ?      881\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...n/java/azkaban/webapp/servlet/ScheduleServlet.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...c/main/java/azkaban/scheduler/ScheduleManager.java | 34.52% <86.66%> (\u00f8) | 11 <6> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update cc3e12c...099365c. Read the comment docs.\n. # Codecov Report\nMerging #1938 into master will decrease coverage by 0.07%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1938      +/-\n============================================\n- Coverage     32.97%   32.89%   -0.08%   \n+ Complexity     2652     2650       -2   \n============================================\n  Files           408      408            \n  Lines         29167    29167            \n  Branches       3713     3713            \n============================================\n- Hits           9617     9595      -22   \n- Misses        18669    18693      +24   \n+ Partials        881      879       -2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 48.95% <0%> (-20.84%) | 6% <0%> (-1%) | |\n| .../main/java/azkaban/utils/ExecutorServiceUtils.java | 90% <0%> (-10%) | 4% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.97% <0%> (-0.22%) | 87% <0%> (\u00f8) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 462962f...da5c307. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@7f64655). Click here to learn what that means.\nThe diff coverage is n/a.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1939   +/-\n=========================================\n  Coverage          ?   32.85%         \n  Complexity        ?     2648         \n=========================================\n  Files             ?      409         \n  Lines             ?    29201         \n  Branches          ?     3716         \n=========================================\n  Hits              ?     9595         \n  Misses            ?    18727         \n  Partials          ?      879\n```\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 7f64655...e811bf4. Read the comment docs.\n. # Codecov Report\nMerging #1941 into master will decrease coverage by <.01%.\nThe diff coverage is 0%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1941      +/-\n============================================\n- Coverage     32.86%   32.85%   -0.01%   \n- Complexity     2647     2648       +1   \n============================================\n  Files           409      409            \n  Lines         29201    29203       +2   \n  Branches       3716     3716            \n============================================\n- Hits           9597     9595       -2   \n- Misses        18724    18729       +5   \n+ Partials        880      879       -1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...azkaban/webapp/servlet/AbstractAzkabanServlet.java | 6.76% <0%> (-0.11%) | 6 <0> (\u00f8) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.95% <0%> (-0.14%) | 143% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.97% <0%> (+0.21%) | 87% <0%> (+2%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 5e06652...49c335f. Read the comment docs.\n. # Codecov Report\nMerging #1943 into master will decrease coverage by 0.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1943      +/-\n============================================\n- Coverage     32.88%   32.87%   -0.02%   \n+ Complexity     2650     2648       -2   \n============================================\n  Files           409      409            \n  Lines         29203    29203            \n  Branches       3716     3716            \n============================================\n- Hits           9604     9600       -4   \n- Misses        18722    18724       +2   \n- Partials        877      879       +2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 66.66% <0%> (-3.04%) | 14% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.62% <0%> (-0.44%) | 87% <0%> (-1%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.95% <0%> (\u00f8) | 143% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 88240fc...af1022d. Read the comment docs.\n. # Codecov Report\nMerging #1944 into master will increase coverage by 0.01%.\nThe diff coverage is 36.36%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1944      +/-\n============================================\n+ Coverage     32.95%   32.96%   +0.01%   \n  Complexity     2659     2659            \n============================================\n  Files           409      409            \n  Lines         29270    29273       +3   \n  Branches       3725     3726       +1   \n============================================\n+ Hits           9645     9649       +4   \n  Misses        18742    18742            \n+ Partials        883      882       -1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...a/azkaban/viewer/reportal/ReportalMailCreator.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...java/azkaban/executor/mail/DefaultMailCreator.java | 88.95% <0%> (\u00f8) | 19 <0> (\u00f8) | :arrow_down: |\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 44.98% <47.05%> (+0.33%) | 53 <1> (\u00f8) | :arrow_down: |\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 66.66% <0%> (-3.04%) | 14% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.62% <0%> (+0.43%) | 87% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d4cf5b9...258b795. Read the comment docs.\n. # Codecov Report\nMerging #1945 into master will not change coverage.\nThe diff coverage is n/a.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1945   +/-\n=========================================\n  Coverage     32.92%   32.92%         \n  Complexity     2654     2654         \n=========================================\n  Files           409      409         \n  Lines         29257    29257         \n  Branches       3721     3721         \n=========================================\n  Hits           9632     9632         \n  Misses        18740    18740         \n  Partials        885      885\n```\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update fd56124...eec2c7e. Read the comment docs.\n. # Codecov Report\nMerging #1946 into master will decrease coverage by 0.02%.\nThe diff coverage is 0%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1946      +/-\n============================================\n- Coverage     32.95%   32.93%   -0.03%   \n+ Complexity     2656     2655       -1   \n============================================\n  Files           409      409            \n  Lines         29257    29259       +2   \n  Branches       3721     3721            \n============================================\n- Hits           9643     9635       -8   \n- Misses        18731    18740       +9   \n- Partials        883      884       +1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../azkaban/security/HadoopSecurityManager_H_2_0.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.11% <0%> (-1.52%) | 85% <0%> (-2%) | |\n| .../main/java/azkaban/utils/ExecutorServiceUtils.java | 100% <0%> (+10%) | 5% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update b20d5d0...3af7c4b. Read the comment docs.\n. # Codecov Report\nMerging #1948 into master will increase coverage by <.01%.\nThe diff coverage is 0%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1948      +/-\n============================================\n+ Coverage     32.95%   32.96%   +<.01%   \n- Complexity     2656     2657       +1   \n============================================\n  Files           409      409            \n  Lines         29257    29258       +1   \n  Branches       3721     3722       +1   \n============================================\n+ Hits           9643     9644       +1   \n- Misses        18731    18732       +1   \n+ Partials        883      882       -1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../azkaban/webapp/servlet/ProjectManagerServlet.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| .../main/java/azkaban/utils/ExecutorServiceUtils.java | 100% <0%> (+10%) | 5% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update b20d5d0...0db56f6. Read the comment docs.\n. # Codecov Report\nMerging #1953 into master will decrease coverage by 0.08%.\nThe diff coverage is 79.31%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1953      +/-\n============================================\n- Coverage     33.03%   32.95%   -0.09%   \n+ Complexity     2685     2655      -30   \n============================================\n  Files           415      409       -6   \n  Lines         29321    29260      -61   \n  Branches       3724     3721       -3   \n============================================\n- Hits           9686     9642      -44   \n+ Misses        18752    18734      -18   \n- Partials        883      884       +1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| az-core/src/main/java/azkaban/Constants.java | 25% <\u00f8> (\u00f8) | 1 <0> (\u00f8) | :arrow_down: |\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 45.09% <79.31%> (+2.95%) | 53 <0> (+12) | :arrow_up: |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.76% <0%> (-0.87%) | 85% <0%> (-2%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.82% <0%> (-0.25%) | 142% <0%> (-2%) | |\n| .../azkaban/security/HadoopSecurityManager_H_2_0.java | 0% <0%> (\u00f8) | 0% <0%> (\u00f8) | :arrow_down: |\n| ...n/java/azkaban/webapp/servlet/ExecutorServlet.java | 0% <0%> (\u00f8) | 0% <0%> (\u00f8) | :arrow_down: |\n| ...a/azkaban/viewer/reportal/ReportalMailCreator.java | 0% <0%> (\u00f8) | 0% <0%> (\u00f8) | :arrow_down: |\n| .../azkaban/webapp/servlet/ProjectManagerServlet.java | 0% <0%> (\u00f8) | 0% <0%> (\u00f8) | :arrow_down: |\n| ...ava/azkaban/executor/RunningExecutionsUpdater.java | | | |\n| ...rc/main/java/azkaban/executor/ActiveExecutors.java | | | |\n| ... and 8 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update cd075f2...c7dc387. Read the comment docs.\n. # Codecov Report\nMerging #1959 into master will increase coverage by 0.05%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1959      +/-\n============================================\n+ Coverage     32.86%   32.91%   +0.05%   \n+ Complexity     2654     2652       -2   \n============================================\n  Files           409      409            \n  Lines         29261    29261            \n  Branches       3723     3723            \n============================================\n+ Hits           9616     9631      +15   \n+ Misses        18762    18742      -20   \n- Partials        883      888       +5\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 71.42% <0%> (-7.15%) | 11% <0%> (-1%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.82% <0%> (-0.14%) | 142% <0%> (-1%) | |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (+18.75%) | 6% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 609d4d8...be548dd. Read the comment docs.\n. # Codecov Report\nMerging #1961 into master will decrease coverage by 0.02%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1961      +/-\n============================================\n- Coverage     32.95%   32.92%   -0.03%   \n+ Complexity     2659     2657       -2   \n============================================\n  Files           409      409            \n  Lines         29270    29269       -1   \n  Branches       3725     3725            \n============================================\n- Hits           9645     9636       -9   \n- Misses        18742    18748       +6   \n- Partials        883      885       +2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...java/azkaban/execapp/event/JobCallbackManager.java | 5.26% <\u00f8> (+0.04%) | 2 <0> (\u00f8) | :arrow_down: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.11% <0%> (-1.52%) | 85% <0%> (-2%) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update b70ee97...94f6f3d. Read the comment docs.\n. # Codecov Report\nMerging #1962 into master will decrease coverage by 0.02%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1962      +/-\n============================================\n- Coverage     32.95%   32.92%   -0.03%   \n+ Complexity     2659     2656       -3   \n============================================\n  Files           409      409            \n  Lines         29270    29275       +5   \n  Branches       3725     3726       +1   \n============================================\n- Hits           9645     9639       -6   \n- Misses        18742    18751       +9   \n- Partials        883      885       +2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.11% <0%> (-1.52%) | 85% <0%> (-2%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.06% <0%> (-0.14%) | 144% <0%> (-1%) | |\n| ...n/java/azkaban/webapp/servlet/ExecutorServlet.java | 0% <0%> (\u00f8) | 0% <0%> (\u00f8) | :arrow_down: |\n| ...a/azkaban/viewer/reportal/ReportalMailCreator.java | 0% <0%> (\u00f8) | 0% <0%> (\u00f8) | :arrow_down: |\n| .../azkaban/webapp/servlet/ProjectManagerServlet.java | 0% <0%> (\u00f8) | 0% <0%> (\u00f8) | :arrow_down: |\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 44.98% <0%> (+0.33%) | 53% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update b70ee97...472c694. Read the comment docs.\n. # Codecov Report\nMerging #1963 into master will decrease coverage by 0.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1963      +/-\n============================================\n- Coverage     32.95%   32.93%   -0.02%   \n+ Complexity     2659     2656       -3   \n============================================\n  Files           409      409            \n  Lines         29270    29270            \n  Branches       3725     3725            \n============================================\n- Hits           9645     9640       -5   \n- Misses        18742    18744       +2   \n- Partials        883      886       +3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.76% <0%> (-0.87%) | 85% <0%> (-2%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.06% <0%> (-0.14%) | 144% <0%> (-1%) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update b70ee97...cd86334. Read the comment docs.\n. # Codecov Report\nMerging #1967 into master will decrease coverage by 0.03%.\nThe diff coverage is 0%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1967      +/-\n============================================\n- Coverage     32.96%   32.93%   -0.04%   \n+ Complexity     2658     2655       -3   \n============================================\n  Files           409      409            \n  Lines         29273    29275       +2   \n  Branches       3726     3726            \n============================================\n- Hits           9650     9641       -9   \n- Misses        18739    18748       +9   \n- Partials        884      886       +2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../azkaban/webapp/servlet/ProjectManagerServlet.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...n/java/azkaban/webapp/servlet/ExecutorServlet.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...src/main/java/azkaban/jobExecutor/AbstractJob.java | 31.03% <0%> (-6.9%) | 4% <0%> (-1%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 59.52% <0%> (-3.58%) | 13% <0%> (\u00f8) | |\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 66.66% <0%> (-3.04%) | 14% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.76% <0%> (-0.44%) | 85% <0%> (-1%) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 88553b5...cc47e65. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@d7a8ba4). Click here to learn what that means.\nThe diff coverage is 57.83%.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1971   +/-\n=========================================\n  Coverage          ?   33.03%         \n  Complexity        ?     2684         \n=========================================\n  Files             ?      415         \n  Lines             ?    29317         \n  Branches          ?     3723         \n=========================================\n  Hits              ?     9685         \n  Misses            ?    18748         \n  Partials          ?      884\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../main/java/azkaban/executor/RunningExecutions.java | 100% <100%> (\u00f8) | 2 <2> (?) | |\n| ...main/java/azkaban/executor/ExecutionFinalizer.java | 50% <50%> (\u00f8) | 8 <8> (?) | |\n| ...ava/azkaban/executor/RunningExecutionsUpdater.java | 52.51% <52.51%> (\u00f8) | 11 <11> (?) | |\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 42.13% <57.14%> (\u00f8) | 41 <8> (?) | |\n| ...rc/main/java/azkaban/executor/ActiveExecutors.java | 75.75% <75.75%> (\u00f8) | 9 <9> (?) | |\n| ...kaban/executor/RunningExecutionsUpdaterThread.java | 79.31% <79.31%> (\u00f8) | 7 <7> (?) | |\n| .../azkaban/executor/ExecutorManagerUpdaterStage.java | 80% <80%> (\u00f8) | 2 <2> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d7a8ba4...31c17b7. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@26bc42c). Click here to learn what that means.\nThe diff coverage is 60%.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1974   +/-\n=========================================\n  Coverage          ?   33.02%         \n  Complexity        ?     2683         \n=========================================\n  Files             ?      415         \n  Lines             ?    29317         \n  Branches          ?     3723         \n=========================================\n  Hits              ?     9682         \n  Misses            ?    18750         \n  Partials          ?      885\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../main/java/azkaban/executor/RunningExecutions.java | 100% <100%> (\u00f8) | 2 <1> (?) | |\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 42.13% <57.14%> (\u00f8) | 41 <0> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 26bc42c...8919aa5. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@cc3e12c). Click here to learn what that means.\nThe diff coverage is 93.75%.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1975   +/-\n=========================================\n  Coverage          ?   33.06%         \n  Complexity        ?     2689         \n=========================================\n  Files             ?      415         \n  Lines             ?    29321         \n  Branches          ?     3723         \n=========================================\n  Hits              ?     9696         \n  Misses            ?    18749         \n  Partials          ?      876\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...main/java/azkaban/executor/ExecutorApiGateway.java | 71.42% <100%> (\u00f8) | 8 <2> (?) | |\n| ...ava/azkaban/executor/RunningExecutionsUpdater.java | 78.57% <80%> (\u00f8) | 20 <0> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update cc3e12c...a1059f9. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@6c9fb2b). Click here to learn what that means.\nThe diff coverage is n/a.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1976   +/-\n=========================================\n  Coverage          ?   33.28%         \n  Complexity        ?     2703         \n=========================================\n  Files             ?      415         \n  Lines             ?    29698         \n  Branches          ?     3804         \n=========================================\n  Hits              ?     9885         \n  Misses            ?    18918         \n  Partials          ?      895\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...main/java/azkaban/executor/ExecutableFlowBase.java | 83.33% <\u00f8> (\u00f8) | 48 <0> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 6c9fb2b...25ff163. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@6c9fb2b). Click here to learn what that means.\nThe diff coverage is 0%.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1977   +/-\n=========================================\n  Coverage          ?   32.97%         \n  Complexity        ?     2685         \n=========================================\n  Files             ?      415         \n  Lines             ?    29321         \n  Branches          ?     3724         \n=========================================\n  Hits              ?     9668         \n  Misses            ?    18772         \n  Partials          ?      881\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...ain/java/azkaban/jobtype/ReportalPrestoRunner.java | 5.26% <0%> (\u00f8) | 1 <0> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 6c9fb2b...fbe67e0. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@cc3e12c). Click here to learn what that means.\nThe diff coverage is n/a.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1978   +/-\n=========================================\n  Coverage          ?   32.78%         \n  Complexity        ?     2671         \n=========================================\n  Files             ?      415         \n  Lines             ?    29323         \n  Branches          ?     3722         \n=========================================\n  Hits              ?     9615         \n  Misses            ?    18834         \n  Partials          ?      874\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...-common/src/main/java/azkaban/utils/Md5Hasher.java | 87.5% <\u00f8> (\u00f8) | 3 <0> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update cc3e12c...9213804. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@cc3e12c). Click here to learn what that means.\nThe diff coverage is 100%.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1979   +/-\n=========================================\n  Coverage          ?   32.87%         \n  Complexity        ?     2671         \n=========================================\n  Files             ?      415         \n  Lines             ?    29323         \n  Branches          ?     3722         \n=========================================\n  Hits              ?     9639         \n  Misses            ?    18807         \n  Partials          ?      877\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...main/java/azkaban/project/DirectoryFlowLoader.java | 73.74% <100%> (\u00f8) | 36 <0> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update cc3e12c...8eac6c1. Read the comment docs.\n. # Codecov Report\nMerging #1980 into master will decrease coverage by 0.08%.\nThe diff coverage is 22.22%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1980      +/-\n============================================\n- Coverage     33.03%   32.94%   -0.09%   \n+ Complexity     2685     2683       -2   \n============================================\n  Files           415      415            \n  Lines         29321    29317       -4   \n  Branches       3724     3724            \n============================================\n- Hits           9686     9659      -27   \n- Misses        18752    18776      +24   \n+ Partials        883      882       -1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 18.42% <22.22%> (-0.95%) | 6 <0> (\u00f8) | |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 48.95% <0%> (-18.76%) | 6% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.76% <0%> (-0.87%) | 85% <0%> (-2%) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update cd075f2...2d48e40. Read the comment docs.\n. # Codecov Report\nMerging #1982 into master will decrease coverage by 0.25%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1982      +/-\n============================================\n- Coverage     33.03%   32.77%   -0.26%   \n+ Complexity     2685     2668      -17   \n============================================\n  Files           415      415            \n  Lines         29321    29321            \n  Branches       3724     3724            \n============================================\n- Hits           9686     9611      -75   \n- Misses        18752    18832      +80   \n+ Partials        883      878       -5\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...kaban/flowtrigger/FlowTriggerExecutionCleaner.java | 80% <0%> (-20%) | 4% <0%> (-1%) | |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 48.95% <0%> (-18.76%) | 6% <0%> (\u00f8) | |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.94% <0%> (-17.79%) | 48% <0%> (-12%) | |\n| ...n/java/azkaban/flowtrigger/DependencyInstance.java | 92.3% <0%> (-7.7%) | 13% <0%> (-1%) | |\n| .../azkaban/flowtrigger/TriggerInstanceProcessor.java | 89.7% <0%> (-4.42%) | 12% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.76% <0%> (-0.87%) | 85% <0%> (-2%) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update cd075f2...a610224. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@cc3e12c). Click here to learn what that means.\nThe diff coverage is n/a.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1983   +/-\n=========================================\n  Coverage          ?   33.17%         \n  Complexity        ?     2718         \n=========================================\n  Files             ?      415         \n  Lines             ?    30254         \n  Branches          ?     3972         \n=========================================\n  Hits              ?    10038         \n  Misses            ?    19292         \n  Partials          ?      924\n```\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update cc3e12c...1a0e82c. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@cc3e12c). Click here to learn what that means.\nThe diff coverage is 100%.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1985   +/-\n=========================================\n  Coverage          ?   32.83%         \n  Complexity        ?     2668         \n=========================================\n  Files             ?      415         \n  Lines             ?    29325         \n  Branches          ?     3722         \n=========================================\n  Hits              ?     9628         \n  Misses            ?    18817         \n  Partials          ?      880\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.24% <100%> (\u00f8) | 85 <1> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update cc3e12c...e1d60ed. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@cc3e12c). Click here to learn what that means.\nThe diff coverage is 92.85%.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #1986   +/-\n=========================================\n  Coverage          ?   32.85%         \n  Complexity        ?     2670         \n=========================================\n  Files             ?      415         \n  Lines             ?    29293         \n  Branches          ?     3717         \n=========================================\n  Hits              ?     9625         \n  Misses            ?    18798         \n  Partials          ?      870\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| az-core/src/main/java/azkaban/Constants.java | 25% <\u00f8> (\u00f8) | 1 <0> (?) | |\n| ...in/java/azkaban/execapp/AzkabanExecutorServer.java | 5.28% <0%> (\u00f8) | 3 <0> (?) | |\n| ...rc/main/java/azkaban/executor/ActiveExecutors.java | 100% <100%> (\u00f8) | 6 <4> (?) | |\n| ...in/java/azkaban/execapp/ExecJettyServerModule.java | 100% <100%> (\u00f8) | 6 <0> (?) | |\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 45.29% <96%> (\u00f8) | 48 <15> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update cc3e12c...7c6dd2e. Read the comment docs.\n. # Codecov Report\nMerging #1990 into master will decrease coverage by <.01%.\nThe diff coverage is 0%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1990      +/-\n============================================\n- Coverage     32.86%   32.85%   -0.01%   \n- Complexity     2670     2672       +2   \n============================================\n  Files           415      415            \n  Lines         29323    29323            \n  Branches       3722     3722            \n============================================\n- Hits           9636     9635       -1   \n- Misses        18809    18812       +3   \n+ Partials        878      876       -2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...src/main/java/azkaban/project/JdbcProjectImpl.java | 63.33% <0%> (\u00f8) | 58 <0> (\u00f8) | :arrow_down: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.97% <0%> (-0.65%) | 87% <0%> (\u00f8) | |\n| ...main/java/azkaban/executor/ExecutableFlowBase.java | 76.71% <0%> (+1.05%) | 48% <0%> (+1%) | :arrow_up: |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 89.58% <0%> (+4.16%) | 17% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update cefb483...425f32d. Read the comment docs.\n. # Codecov Report\nMerging #1991 into master will decrease coverage by 0.02%.\nThe diff coverage is 0%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1991      +/-\n============================================\n- Coverage     32.86%   32.83%   -0.03%   \n+ Complexity     2670     2669       -1   \n============================================\n  Files           415      417       +2   \n  Lines         29323    29338      +15   \n  Branches       3722     3722            \n============================================\n- Hits           9636     9634       -2   \n- Misses        18809    18825      +16   \n- Partials        878      879       +1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 18.42% <0%> (\u00f8) | 6 <0> (\u00f8) | :arrow_down: |\n| ...src/main/java/azkaban/execapp/ExecutorServlet.java | 1.55% <0%> (-0.03%) | 2 <0> (\u00f8) | |\n| ...rc/main/java/azkaban/executor/ConnectorParams.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...kaban/executor/ExecutorResponseErrorException.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 71.42% <0%> (-7.15%) | 11% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.76% <0%> (-0.87%) | 85% <0%> (-2%) | |\n| ...main/java/azkaban/executor/ExecutableFlowBase.java | 76.71% <0%> (+1.05%) | 48% <0%> (+1%) | :arrow_up: |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 89.58% <0%> (+4.16%) | 17% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update cefb483...dc24cde. Read the comment docs.\n. # Codecov Report\nMerging #1992 into master will decrease coverage by <.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1992      +/-\n============================================\n- Coverage     32.86%   32.85%   -0.01%   \n+ Complexity     2670     2669       -1   \n============================================\n  Files           415      415            \n  Lines         29323    29323            \n  Branches       3722     3722            \n============================================\n- Hits           9636     9635       -1   \n  Misses        18809    18809            \n- Partials        878      879       +1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...rc/main/java/azkaban/executor/ActiveExecutors.java | 75.75% <\u00f8> (\u00f8) | 9 <0> (\u00f8) | :arrow_down: |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.76% <0%> (-0.87%) | 85% <0%> (-2%) | |\n| ...main/java/azkaban/executor/ExecutableFlowBase.java | 76.71% <0%> (+1.05%) | 48% <0%> (+1%) | :arrow_up: |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 87.5% <0%> (+2.08%) | 16% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update cefb483...76e0815. Read the comment docs.\n. # Codecov Report\nMerging #1993 into master will increase coverage by 0.06%.\nThe diff coverage is 50%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1993      +/-\n============================================\n+ Coverage     33.06%   33.12%   +0.06%   \n- Complexity     2688     2693       +5   \n============================================\n  Files           415      415            \n  Lines         29321    29262      -59   \n  Branches       3723     3709      -14   \n============================================\n  Hits           9694     9694            \n+ Misses        18750    18705      -45   \n+ Partials        877      863      -14\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| az-core/src/main/java/azkaban/Constants.java | 25% <\u00f8> (\u00f8) | 1 <0> (\u00f8) | :arrow_down: |\n| ...ain/java/azkaban/project/AzkabanProjectLoader.java | 77.14% <100%> (\u00f8) | 15 <0> (\u00f8) | :arrow_down: |\n| ...src/main/java/azkaban/project/JdbcProjectImpl.java | 63.11% <42.85%> (-0.22%) | 59 <0> (+1) | |\n| ...main/java/azkaban/executor/JdbcExecutorLoader.java | 21.21% <0%> (-6.07%) | 3% <0%> (-4%) | |\n| ...kaban/executor/RunningExecutionsUpdaterThread.java | 75.86% <0%> (-3.45%) | 6% <0%> (-1%) | |\n| ...n/java/azkaban/soloserver/AzkabanSingleServer.java | 10.63% <0%> (-2.52%) | 2% <0%> (\u00f8) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (-2.09%) | 6% <0%> (-1%) | |\n| ...c/main/java/azkaban/executor/ExecutionFlowDao.java | 57.37% <0%> (-1.1%) | 13% <0%> (\u00f8) | |\n| .../src/main/java/azkaban/trigger/TriggerManager.java | 15.31% <0%> (-0.2%) | 5% <0%> (\u00f8) | |\n| ... and 16 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 3fdb3da...9fa1e8d. Read the comment docs.\n. # Codecov Report\nMerging #1994 into master will increase coverage by 0.14%.\nThe diff coverage is 86.36%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1994      +/-\n============================================\n+ Coverage     33.21%   33.35%   +0.14%   \n- Complexity     2735     2743       +8   \n============================================\n  Files           417      417            \n  Lines         29616    29658      +42   \n  Branches       3763     3766       +3   \n============================================\n+ Hits           9837     9893      +56   \n+ Misses        18896    18877      -19   \n- Partials        883      888       +5\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...main/java/azkaban/executor/JdbcExecutorLoader.java | 20% <0%> (-0.29%) | 3 <0> (\u00f8) | |\n| ...li/java/azkaban/restli/ProjectManagerResource.java | 19.48% <0%> (\u00f8) | 7 <0> (\u00f8) | :arrow_down: |\n| .../src/main/java/azkaban/project/ProjectManager.java | 14.63% <0%> (\u00f8) | 7 <0> (\u00f8) | :arrow_down: |\n| ...src/main/java/azkaban/project/JdbcProjectImpl.java | 63.68% <100%> (+0.56%) | 61 <3> (+2) | :arrow_up: |\n| ...c/main/java/azkaban/executor/ExecutionFlowDao.java | 59.22% <100%> (+0.19%) | 15 <0> (\u00f8) | :arrow_down: |\n| ...main/java/azkaban/executor/FetchActiveFlowDao.java | 86.02% <88.88%> (-1.48%) | 11 <6> (+3) | |\n| ...ain/java/azkaban/project/AzkabanProjectLoader.java | 77.87% <90%> (+0.73%) | 18 <4> (+3) | :arrow_up: |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.15% <0%> (-0.8%) | 46% <0%> (-2%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.94% <0%> (+0.13%) | 145% <0%> (+1%) | :arrow_up: |\n| ... and 2 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d617f7d...27ec042. Read the comment docs.\n. # Codecov Report\nMerging #1995 into master will increase coverage by 0.03%.\nThe diff coverage is 100%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #1995      +/-\n============================================\n+ Coverage     33.05%   33.08%   +0.03%   \n- Complexity     2687     2690       +3   \n============================================\n  Files           415      415            \n  Lines         29291    29296       +5   \n  Branches       3718     3720       +2   \n============================================\n+ Hits           9682     9693      +11   \n+ Misses        18739    18734       -5   \n+ Partials        870      869       -1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...ava/azkaban/executor/RunningExecutionsUpdater.java | 79.38% <100%> (+0.81%) | 22 <0> (+2) | :arrow_up: |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.76% <0%> (+0.64%) | 85% <0%> (\u00f8) | :arrow_down: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 59.52% <0%> (+2.38%) | 13% <0%> (\u00f8) | :arrow_down: |\n| .../main/java/azkaban/utils/ExecutorServiceUtils.java | 100% <0%> (+10%) | 5% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update f450b65...72dfb5d. Read the comment docs.\n. # Codecov Report\nMerging #2000 into master will decrease coverage by <.01%.\nThe diff coverage is 0%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2000      +/-\n============================================\n- Coverage     33.09%   33.08%   -0.01%   \n+ Complexity     2690     2689       -1   \n============================================\n  Files           415      415            \n  Lines         29280    29280            \n  Branches       3714     3715       +1   \n============================================\n- Hits           9689     9688       -1   \n  Misses        18724    18724            \n- Partials        867      868       +1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...ava/azkaban/trigger/builtin/ExecuteFlowAction.java | 44% <0%> (+1.28%) | 12 <0> (\u00f8) | :arrow_down: |\n| .../src/main/java/azkaban/trigger/TriggerManager.java | 15.31% <0%> (-0.2%) | 5 <0> (\u00f8) | |\n| ...kaban/executor/RunningExecutionsUpdaterThread.java | 75.86% <0%> (-3.45%) | 6% <0%> (-1%) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update ee6e229...632e43a. Read the comment docs.\n. # Codecov Report\nMerging #2002 into master will decrease coverage by 0.04%.\nThe diff coverage is 0%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2002      +/-\n============================================\n- Coverage     33.11%   33.06%   -0.05%   \n+ Complexity     2694     2687       -7   \n============================================\n  Files           415      415            \n  Lines         29280    29286       +6   \n  Branches       3714     3714            \n============================================\n- Hits           9696     9684      -12   \n- Misses        18721    18732      +11   \n- Partials        863      870       +7\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...n/java/azkaban/soloserver/AzkabanSingleServer.java | 11.36% <0%> (-1.8%) | 2 <0> (\u00f8) | |\n| .../main/java/azkaban/utils/ExecutorServiceUtils.java | 90% <0%> (-10%) | 4% <0%> (-1%) | |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 85.41% <0%> (-4.17%) | 16% <0%> (-1%) | |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (-2.09%) | 6% <0%> (-1%) | |\n| ...main/java/azkaban/executor/ExecutableFlowBase.java | 82.18% <0%> (-1.15%) | 47% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.11% <0%> (-0.87%) | 85% <0%> (-2%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.06% <0%> (-0.14%) | 144% <0%> (-1%) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 4a224d3...033a640. Read the comment docs.\n. # Codecov Report\nMerging #2003 into master will decrease coverage by 0.02%.\nThe diff coverage is 10.52%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2003      +/-\n============================================\n- Coverage     33.11%   33.08%   -0.03%   \n+ Complexity     2694     2691       -3   \n============================================\n  Files           415      415            \n  Lines         29280    29284       +4   \n  Branches       3714     3714            \n============================================\n- Hits           9696     9690       -6   \n- Misses        18721    18728       +7   \n- Partials        863      866       +3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...in/java/azkaban/execapp/AzkabanExecutorServer.java | 5.24% <0%> (-0.05%) | 3 <0> (\u00f8) | |\n| ...n/java/azkaban/soloserver/AzkabanSingleServer.java | 12.19% <0%> (-0.97%) | 2 <0> (\u00f8) | |\n| ...src/main/java/azkaban/execapp/ExecutorServlet.java | 1.62% <0%> (+0.05%) | 2 <0> (\u00f8) | :arrow_down: |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 18.14% <0%> (-0.29%) | 6 <0> (\u00f8) | |\n| ...ommon/src/main/java/azkaban/executor/Executor.java | 58% <100%> (\u00f8) | 14 <1> (\u00f8) | :arrow_down: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (-2.09%) | 6% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.11% <0%> (-0.87%) | 85% <0%> (-2%) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 4a224d3...80751f7. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@0904033). Click here to learn what that means.\nThe diff coverage is 0%.\n\n\n```diff\n@@           Coverage Diff            @@\nmaster   #2004   +/-\n========================================\n  Coverage          ?   33.1%         \n  Complexity        ?    2692         \n========================================\n  Files             ?     415         \n  Lines             ?   29286         \n  Branches          ?    3714         \n========================================\n  Hits              ?    9694         \n  Misses            ?   18726         \n  Partials          ?     866\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...in/java/azkaban/execapp/AzkabanExecutorServer.java | 5.28% <0%> (\u00f8) | 3 <0> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 0904033...dec631e. Read the comment docs.\n. # Codecov Report\nMerging #2006 into master will decrease coverage by 0.01%.\nThe diff coverage is 0%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2006      +/-\n============================================\n- Coverage      33.1%   33.08%   -0.02%   \n+ Complexity     2691     2689       -2   \n============================================\n  Files           415      415            \n  Lines         29290    29294       +4   \n  Branches       3714     3715       +1   \n============================================\n- Hits           9695     9692       -3   \n- Misses        18729    18734       +5   \n- Partials        866      868       +2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...in/src/main/java/azkaban/jobtype/HadoopPigJob.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 85.41% <0%> (-4.17%) | 16% <0%> (-1%) | |\n| ...kaban/executor/RunningExecutionsUpdaterThread.java | 75.86% <0%> (-3.45%) | 6% <0%> (-1%) | |\n| ...main/java/azkaban/executor/ExecutableFlowBase.java | 82.18% <0%> (-1.15%) | 47% <0%> (-1%) | |\n| ...in/java/azkaban/execapp/AzkabanExecutorServer.java | 5.17% <0%> (-0.07%) | 3% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.19% <0%> (+0.43%) | 86% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update c564f24...7327f36. Read the comment docs.\n. # Codecov Report\nMerging #2007 into master will decrease coverage by 0.01%.\nThe diff coverage is 0%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2007      +/-\n============================================\n- Coverage      33.1%   33.08%   -0.02%   \n  Complexity     2691     2691            \n============================================\n  Files           415      415            \n  Lines         29290    29293       +3   \n  Branches       3714     3714            \n============================================\n- Hits           9695     9692       -3   \n- Misses        18729    18735       +6   \n  Partials        866      866\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...in/java/azkaban/execapp/AzkabanExecutorServer.java | 5.17% <0%> (-0.07%) | 3 <0> (\u00f8) | |\n| ...kaban/executor/RunningExecutionsUpdaterThread.java | 75.86% <0%> (-3.45%) | 6% <0%> (-1%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.06% <0%> (-0.14%) | 144% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.97% <0%> (+0.21%) | 87% <0%> (+2%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update c564f24...fc47545. Read the comment docs.\n. # Codecov Report\nMerging #2008 into master will decrease coverage by 0.03%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\nmaster   #2008      +/-\n===========================================\n- Coverage     33.13%   33.1%   -0.04%   \n+ Complexity     2694    2693       -1   \n===========================================\n  Files           415     415            \n  Lines         29293   29293            \n  Branches       3714    3714            \n===========================================\n- Hits           9705    9696       -9   \n- Misses        18723   18732       +9   \n  Partials        865     865\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...src/main/java/azkaban/jobExecutor/AbstractJob.java | 31.03% <0%> (-6.9%) | 4% <0%> (-1%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-5.96%) | 13% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.19% <0%> (-0.65%) | 87% <0%> (\u00f8) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.06% <0%> (-0.14%) | 144% <0%> (-1%) | |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 69.79% <0%> (+2.08%) | 7% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 883ec32...66d4ea7. Read the comment docs.\n. # Codecov Report\nMerging #2009 into master will decrease coverage by 0.05%.\nThe diff coverage is 0%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2009      +/-\n============================================\n- Coverage     33.13%   33.07%   -0.06%   \n+ Complexity     2694     2689       -5   \n============================================\n  Files           415      415            \n  Lines         29293    29293            \n  Branches       3714     3714            \n============================================\n- Hits           9705     9688      -17   \n- Misses        18723    18737      +14   \n- Partials        865      868       +3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...an-common/src/main/java/azkaban/utils/Emailer.java | 61% <0%> (\u00f8) | 16 <0> (\u00f8) | :arrow_down: |\n| ...src/main/java/azkaban/jobExecutor/AbstractJob.java | 31.03% <0%> (-6.9%) | 4% <0%> (-1%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-5.96%) | 13% <0%> (\u00f8) | |\n| ...kaban/executor/RunningExecutionsUpdaterThread.java | 75.86% <0%> (-3.45%) | 6% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.11% <0%> (-1.73%) | 85% <0%> (-2%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.06% <0%> (-0.14%) | 144% <0%> (-1%) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 883ec32...70b80f3. Read the comment docs.\n. # Codecov Report\nMerging #2011 into master will decrease coverage by 0.01%.\nThe diff coverage is 0%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2011      +/-\n============================================\n- Coverage     33.08%   33.06%   -0.02%   \n- Complexity     2688     2689       +1   \n============================================\n  Files           415      415            \n  Lines         29294    29260      -34   \n  Branches       3715     3707       -8   \n============================================\n- Hits           9691     9674      -17   \n+ Misses        18734    18723      -11   \n+ Partials        869      863       -6\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 19.37% <\u00f8> (+1.23%) | 6 <0> (\u00f8) | :arrow_down: |\n| ...er/src/main/java/azkaban/execapp/FlowPreparer.java | 80.16% <0%> (\u00f8) | 10 <0> (\u00f8) | :arrow_down: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 48.95% <0%> (-18.76%) | 6% <0%> (\u00f8) | |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 78.57% <0%> (+7.14%) | 12% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update e1c401f...bc5a480. Read the comment docs.\n. # Codecov Report\nMerging #2012 into master will increase coverage by 0.04%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2012      +/-\n============================================\n+ Coverage     33.08%   33.12%   +0.04%   \n- Complexity     2688     2689       +1   \n============================================\n  Files           415      415            \n  Lines         29294    29257      -37   \n  Branches       3715     3707       -8   \n============================================\n+ Hits           9691     9692       +1   \n+ Misses        18734    18699      -35   \n+ Partials        869      866       -3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 19.51% <\u00f8> (+1.37%) | 6 <0> (\u00f8) | :arrow_down: |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 87.5% <0%> (-2.09%) | 16% <0%> (-1%) | |\n| ...kaban/executor/RunningExecutionsUpdaterThread.java | 79.31% <0%> (+3.44%) | 7% <0%> (+1%) | :arrow_up: |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 78.57% <0%> (+7.14%) | 12% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update e1c401f...4838891. Read the comment docs.\n. # Codecov Report\nMerging #2016 into master will increase coverage by 0.01%.\nThe diff coverage is 94.73%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2016      +/-\n============================================\n+ Coverage     33.14%   33.15%   +0.01%   \n- Complexity     2693     2696       +3   \n============================================\n  Files           415      415            \n  Lines         29262    29273      +11   \n  Branches       3709     3711       +2   \n============================================\n+ Hits           9698     9705       +7   \n- Misses        18701    18704       +3   \n- Partials        863      864       +1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...ava/azkaban/executor/RunningExecutionsUpdater.java | 80.29% <94.73%> (+1.72%) | 23 <2> (+3) | :arrow_up: |\n| ...kaban/executor/RunningExecutionsUpdaterThread.java | 75.86% <0%> (-3.45%) | 6% <0%> (-1%) | |\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 66.66% <0%> (-3.04%) | 14% <0%> (-1%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.97% <0%> (\u00f8) | 87% <0%> (+1%) | :arrow_up: |\n| .../main/java/azkaban/utils/ExecutorServiceUtils.java | 100% <0%> (+10%) | 5% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update cf940c6...6bd7dfd. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@d33e82e). Click here to learn what that means.\nThe diff coverage is 86.51%.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #2017   +/-\n=========================================\n  Coverage          ?   33.25%         \n  Complexity        ?     2701         \n=========================================\n  Files             ?      415         \n  Lines             ?    29281         \n  Branches          ?     3714         \n=========================================\n  Hits              ?     9737         \n  Misses            ?    18678         \n  Partials          ?      866\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 19.46% <\u00f8> (\u00f8) | 5 <0> (?) | |\n| ...ommon/src/main/java/azkaban/utils/FileIOUtils.java | 33.33% <100%> (\u00f8) | 24 <4> (?) | |\n| .../src/main/java/azkaban/execapp/ProjectVersion.java | 81.48% <83.33%> (\u00f8) | 13 <4> (?) | |\n| ...er/src/main/java/azkaban/execapp/FlowPreparer.java | 80.51% <85.33%> (\u00f8) | 12 <5> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d33e82e...9215020. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@d33e82e). Click here to learn what that means.\nThe diff coverage is 5.05%.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #2018   +/-\n=========================================\n  Coverage          ?   33.15%         \n  Complexity        ?     2695         \n=========================================\n  Files             ?      415         \n  Lines             ?    29275         \n  Branches          ?     3711         \n=========================================\n  Hits              ?     9707         \n  Misses            ?    18704         \n  Partials          ?      864\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...kaban/flowtrigger/quartz/FlowTriggerScheduler.java | 5.66% <5.05%> (\u00f8) | 2 <2> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d33e82e...050851e. Read the comment docs.\n. # Codecov Report\nMerging #2019 into master will decrease coverage by 0.04%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2019      +/-\n============================================\n- Coverage     33.13%   33.08%   -0.05%   \n- Complexity     2693     2695       +2   \n============================================\n  Files           415      415            \n  Lines         29275    29275            \n  Branches       3713     3713            \n============================================\n- Hits           9700     9687      -13   \n- Misses        18709    18726      +17   \n+ Partials        866      862       -4\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 48.95% <0%> (-18.76%) | 6% <0%> (\u00f8) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.2% <0%> (+0.13%) | 145% <0%> (+1%) | :arrow_up: |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.19% <0%> (+0.21%) | 87% <0%> (\u00f8) | :arrow_down: |\n| ...main/java/azkaban/executor/ExecutableFlowBase.java | 83.33% <0%> (+1.14%) | 48% <0%> (+1%) | :arrow_up: |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 87.5% <0%> (+2.08%) | 16% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d399897...6b47ab3. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@d33e82e). Click here to learn what that means.\nThe diff coverage is 0%.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #2022   +/-\n=========================================\n  Coverage          ?   33.14%         \n  Complexity        ?     2694         \n=========================================\n  Files             ?      415         \n  Lines             ?    29275         \n  Branches          ?     3713         \n=========================================\n  Hits              ?     9702         \n  Misses            ?    18708         \n  Partials          ?      865\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../azkaban/webapp/servlet/ProjectManagerServlet.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...n/java/azkaban/webapp/servlet/ExecutorServlet.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d33e82e...0ddc98c. Read the comment docs.\n. # Codecov Report\nMerging #2026 into master will increase coverage by 0.1%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\nmaster    #2026     +/-\n===========================================\n+ Coverage     33.13%   33.23%   +0.1%   \n- Complexity     2693     2701      +8   \n===========================================\n  Files           415      415           \n  Lines         29275    29281      +6   \n  Branches       3713     3714      +1   \n===========================================\n+ Hits           9700     9732     +32   \n+ Misses        18709    18683     -26   \n  Partials        866      866\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 19.46% <0%> (-0.06%) | 5% <0%> (-1%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.2% <0%> (+0.13%) | 145% <0%> (+1%) | :arrow_up: |\n| ...er/src/main/java/azkaban/execapp/FlowPreparer.java | 80.51% <0%> (+0.35%) | 12% <0%> (+2%) | :arrow_up: |\n| .../src/main/java/azkaban/execapp/ProjectVersion.java | 81.48% <0%> (+0.52%) | 13% <0%> (+3%) | :arrow_up: |\n| ...ommon/src/main/java/azkaban/utils/FileIOUtils.java | 33.33% <0%> (+2.23%) | 24% <0%> (+3%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 5044552...6cb39dc. Read the comment docs.\n. # Codecov Report\nMerging #2027 into master will decrease coverage by <.01%.\nThe diff coverage is 0%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2027      +/-\n============================================\n- Coverage     33.25%   33.24%   -0.01%   \n  Complexity     2700     2700            \n============================================\n  Files           415      415            \n  Lines         29281    29289       +8   \n  Branches       3714     3710       -4   \n============================================\n  Hits           9736     9736            \n- Misses        18678    18686       +8   \n  Partials        867      867\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../azkaban/security/HadoopSecurityManager_H_2_0.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 1d251bc...9a2786d. Read the comment docs.\n. # Codecov Report\nMerging #2028 into master will increase coverage by 0.01%.\nThe diff coverage is 0%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2028      +/-\n============================================\n+ Coverage     33.23%   33.25%   +0.01%   \n- Complexity     2699     2701       +2   \n============================================\n  Files           415      415            \n  Lines         29289    29290       +1   \n  Branches       3710     3710            \n============================================\n+ Hits           9733     9739       +6   \n+ Misses        18688    18685       -3   \n+ Partials        868      866       -2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../azkaban/security/HadoopSecurityManager_H_2_0.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...kaban/executor/RunningExecutionsUpdaterThread.java | 75.86% <0%> (-3.45%) | 6% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.62% <0%> (+0.86%) | 87% <0%> (+2%) | :arrow_up: |\n| ...main/java/azkaban/executor/ExecutableFlowBase.java | 83.33% <0%> (+1.14%) | 48% <0%> (+1%) | :arrow_up: |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 87.5% <0%> (+2.08%) | 16% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 106d177...f841c7b. Read the comment docs.\n. # Codecov Report\nMerging #2030 into master will increase coverage by 0.03%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2030      +/-\n============================================\n+ Coverage     33.19%   33.22%   +0.03%   \n  Complexity     2703     2703            \n============================================\n  Files           415      415            \n  Lines         29290    29254      -36   \n  Branches       3710     3708       -2   \n============================================\n- Hits           9722     9719       -3   \n+ Misses        18707    18673      -34   \n- Partials        861      862       +1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../azkaban/security/HadoopSecurityManager_H_2_0.java | 0% <\u00f8> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...zkaban/security/commons/HadoopSecurityManager.java | 0% <\u00f8> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 48.95% <0%> (-2.09%) | 6% <0%> (-1%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.06% <0%> (-0.14%) | 144% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.19% <0%> (+0.43%) | 87% <0%> (+2%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update bcbb639...365373c. Read the comment docs.\n. # Codecov Report\nMerging #2031 into master will increase coverage by 0.03%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2031      +/-\n============================================\n+ Coverage     33.19%   33.22%   +0.03%   \n+ Complexity     2703     2700       -3   \n============================================\n  Files           415      415            \n  Lines         29290    29290            \n  Branches       3710     3710            \n============================================\n+ Hits           9722     9731       +9   \n+ Misses        18707    18692      -15   \n- Partials        861      867       +6\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...kaban/executor/RunningExecutionsUpdaterThread.java | 75.86% <0%> (-3.45%) | 6% <0%> (-1%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.11% <0%> (-0.65%) | 85% <0%> (\u00f8) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.06% <0%> (-0.14%) | 144% <0%> (-1%) | |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (+16.66%) | 6% <0%> (-1%) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update bcbb639...481b120. Read the comment docs.\n. # Codecov Report\nMerging #2032 into master will decrease coverage by 0.02%.\nThe diff coverage is 52.94%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2032      +/-\n============================================\n- Coverage     33.19%   33.16%   -0.03%   \n+ Complexity     2703     2701       -2   \n============================================\n  Files           415      415            \n  Lines         29290    29310      +20   \n  Branches       3710     3713       +3   \n============================================\n  Hits           9722     9722            \n- Misses        18707    18723      +16   \n- Partials        861      865       +4\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...ommon/src/main/java/azkaban/utils/FileIOUtils.java | 33.94% <100%> (+0.61%) | 24 <0> (\u00f8) | :arrow_down: |\n| ...er/src/main/java/azkaban/execapp/FlowPreparer.java | 77.16% <42.85%> (-3.36%) | 12 <1> (\u00f8) | |\n| ...kaban/executor/RunningExecutionsUpdaterThread.java | 75.86% <0%> (-3.45%) | 6% <0%> (-1%) | |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 48.95% <0%> (-2.09%) | 6% <0%> (-1%) | |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 18.96% <0%> (-0.51%) | 5% <0%> (\u00f8) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update bcbb639...555256b. Read the comment docs.\n. # Codecov Report\nMerging #2035 into master will decrease coverage by 0.02%.\nThe diff coverage is 66.66%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2035      +/-\n============================================\n- Coverage     33.27%   33.24%   -0.03%   \n+ Complexity     2701     2696       -5   \n============================================\n  Files           415      416       +1   \n  Lines         29264    29322      +58   \n  Branches       3709     3715       +6   \n============================================\n+ Hits           9737     9749      +12   \n- Misses        18661    18699      +38   \n- Partials        866      874       +8\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...ver/src/main/java/azkaban/execapp/ExecMetrics.java | 41.66% <0%> (-8.34%) | 2 <0> (\u00f8) | |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 18.91% <0%> (-0.05%) | 5 <0> (\u00f8) | |\n| ...er/src/main/java/azkaban/execapp/FlowPreparer.java | 78.03% <83.33%> (-2.49%) | 12 <0> (\u00f8) | |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 83.33% <0%> (-6.25%) | 15% <0%> (-2%) | |\n| ...main/java/azkaban/executor/ExecutableFlowBase.java | 82.18% <0%> (-1.15%) | 47% <0%> (-1%) | |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.15% <0%> (-0.8%) | 46% <0%> (-2%) | |\n| ...src/main/java/azkaban/webapp/AzkabanWebServer.java | 15.62% <0%> (-0.18%) | 5% <0%> (\u00f8) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.06% <0%> (-0.14%) | 144% <0%> (-1%) | |\n| .../src/main/java/azkaban/jobtype/HadoopSparkJob.java | 0% <0%> (\u00f8) | 0% <0%> (\u00f8) | :arrow_down: |\n| ...ava/azkaban/trigger/builtin/ExecuteFlowAction.java | 44% <0%> (\u00f8) | 12% <0%> (\u00f8) | :arrow_down: |\n| ... and 13 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 4f2f631...2dfa650. Read the comment docs.\n. # Codecov Report\nMerging #2036 into master will increase coverage by 0.03%.\nThe diff coverage is 100%.\n\n\n```diff\n@@             Coverage Diff             @@\nmaster   #2036      +/-\n===========================================\n+ Coverage     33.27%   33.3%   +0.03%   \n  Complexity     2701    2701            \n===========================================\n  Files           415     415            \n  Lines         29264   29233      -31   \n  Branches       3709    3708       -1   \n===========================================\n  Hits           9737    9737            \n+ Misses        18661   18630      -31   \n  Partials        866     866\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 47.8% <100%> (+2.21%) | 49 <3> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 4f2f631...1d064a2. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@35382d6). Click here to learn what that means.\nThe diff coverage is 10.81%.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #2039   +/-\n=========================================\n  Coverage          ?   33.26%         \n  Complexity        ?     2706         \n=========================================\n  Files             ?      416         \n  Lines             ?    29308         \n  Branches          ?     3714         \n=========================================\n  Hits              ?     9749         \n  Misses            ?    18694         \n  Partials          ?      865\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| az-core/src/main/java/azkaban/Constants.java | 25% <\u00f8> (\u00f8) | 1 <0> (?) | |\n| ...main/java/azkaban/webapp/servlet/StatsServlet.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...n/java/azkaban/soloserver/AzkabanSingleServer.java | 10.63% <0%> (\u00f8) | 2 <0> (?) | |\n| ...in/java/azkaban/webapp/servlet/HistoryServlet.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...n/java/azkaban/webapp/servlet/ExecutorServlet.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...in/java/azkaban/webapp/servlet/JMXHttpServlet.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...ain/java/azkaban/executor/ExecutionController.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...a/azkaban/viewer/jobsummary/JobSummaryServlet.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| .../java/azkaban/viewer/reportal/ReportalServlet.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| .../azkaban/webapp/servlet/ProjectManagerServlet.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ... and 6 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 35382d6...40c3f09. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@35382d6). Click here to learn what that means.\nThe diff coverage is 0%.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #2041   +/-\n=========================================\n  Coverage          ?   33.34%         \n  Complexity        ?     2733         \n=========================================\n  Files             ?      416         \n  Lines             ?    29508         \n  Branches          ?     3738         \n=========================================\n  Hits              ?     9838         \n  Misses            ?    18799         \n  Partials          ?      871\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...java/azkaban/execapp/event/JobCallbackManager.java | 4.68% <0%> (\u00f8) | 2 <0> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 35382d6...47f026e. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@35382d6). Click here to learn what that means.\nThe diff coverage is 16.66%.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #2042   +/-\n=========================================\n  Coverage          ?   33.33%         \n  Complexity        ?     2701         \n=========================================\n  Files             ?      415         \n  Lines             ?    29221         \n  Branches          ?     3708         \n=========================================\n  Hits              ?     9742         \n  Misses            ?    18613         \n  Partials          ?      866\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...rc/main/java/azkaban/flow/CommonJobProperties.java | 0% <\u00f8> (\u00f8) | 0 <0> (?) | |\n| .../src/main/java/azkaban/jobtype/HadoopSparkJob.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...in/src/main/java/azkaban/jobtype/HadoopPigJob.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...gin/src/main/java/azkaban/jobtype/HadoopShell.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...n/src/main/java/azkaban/jobtype/HadoopJavaJob.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...n/src/main/java/azkaban/jobtype/HadoopHiveJob.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.96% <100%> (\u00f8) | 87 <0> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 35382d6...6af705c. Read the comment docs.\n. # Codecov Report\nMerging #2043 into master will decrease coverage by <.01%.\nThe diff coverage is 100%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2043      +/-\n============================================\n- Coverage     33.33%   33.33%   -0.01%   \n+ Complexity     2702     2701       -1   \n============================================\n  Files           415      415            \n  Lines         29231    29232       +1   \n  Branches       3710     3710            \n============================================\n  Hits           9745     9745            \n- Misses        18619    18620       +1   \n  Partials        867      867\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...main/java/azkaban/executor/FetchActiveFlowDao.java | 90.24% <100%> (+0.24%) | 3 <0> (\u00f8) | :arrow_down: |\n| ...kaban/executor/RunningExecutionsUpdaterThread.java | 75.86% <0%> (-3.45%) | 6% <0%> (-1%) | |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.15% <0%> (-0.8%) | 46% <0%> (-2%) | |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 89.58% <0%> (+2.08%) | 17% <0%> (+1%) | :arrow_up: |\n| .../main/java/azkaban/utils/ExecutorServiceUtils.java | 100% <0%> (+10%) | 5% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update a1b0978...307a4f2. Read the comment docs.\n. # Codecov Report\nMerging #2044 into master will increase coverage by 0.01%.\nThe diff coverage is 100%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2044      +/-\n============================================\n+ Coverage     33.33%   33.34%   +0.01%   \n- Complexity     2702     2747      +45   \n============================================\n  Files           415      417       +2   \n  Lines         29231    29675     +444   \n  Branches       3710     3768      +58   \n============================================\n+ Hits           9745     9896     +151   \n- Misses        18619    18894     +275   \n- Partials        867      885      +18\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...rc/main/java/azkaban/webapp/WebServerProvider.java | 64.4% <100%> (+14.4%) | 9 <3> (+3) | :arrow_up: |\n| ...common/src/main/java/azkaban/utils/LogGobbler.java | 0% <0%> (-56.25%) | 0% <0%> (-6%) | |\n| ...on/src/main/java/azkaban/utils/CircularBuffer.java | 0% <0%> (-47.06%) | 0% <0%> (-3%) | |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 48.95% <0%> (-18.76%) | 6% <0%> (\u00f8) | |\n| ...ver/src/main/java/azkaban/execapp/ExecMetrics.java | 41.66% <0%> (-8.34%) | 2% <0%> (\u00f8) | |\n| ...main/java/azkaban/executor/FetchActiveFlowDao.java | 86.02% <0%> (-3.98%) | 11% <0%> (+8%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...aban/jobExecutor/utils/process/AzkabanProcess.java | 51.04% <0%> (-2.17%) | 12% <0%> (+1%) | |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 17.37% <0%> (-1.6%) | 5% <0%> (\u00f8) | |\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 46.45% <0%> (-1.35%) | 47% <0%> (-2%) | |\n| ... and 25 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update a1b0978...1158993. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@d2d87ef). Click here to learn what that means.\nThe diff coverage is 100%.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #2045   +/-\n=========================================\n  Coverage          ?   33.34%         \n  Complexity        ?     2732         \n=========================================\n  Files             ?      416         \n  Lines             ?    29494         \n  Branches          ?     3737         \n=========================================\n  Hits              ?     9835         \n  Misses            ?    18786         \n  Partials          ?      873\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../main/java/azkaban/executor/ExecutableJobInfo.java | 61.22% <100%> (\u00f8) | 12 <1> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d2d87ef...961d8ff. Read the comment docs.\n. # Codecov Report\n:exclamation: No coverage uploaded for pull request base (master@d2d87ef). Click here to learn what that means.\nThe diff coverage is 75.86%.\n\n\n```diff\n@@            Coverage Diff            @@\nmaster    #2046   +/-\n=========================================\n  Coverage          ?   33.27%         \n  Complexity        ?     2704         \n=========================================\n  Files             ?      415         \n  Lines             ?    29253         \n  Branches          ?     3711         \n=========================================\n  Hits              ?     9734         \n  Misses            ?    18653         \n  Partials          ?      866\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...main/java/azkaban/executor/JdbcExecutorLoader.java | 20.58% <0%> (\u00f8) | 3 <0> (?) | |\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 47.31% <25%> (\u00f8) | 47 <0> (?) | |\n| ...main/java/azkaban/executor/FetchActiveFlowDao.java | 87.5% <87.5%> (\u00f8) | 8 <6> (?) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d2d87ef...8d5283a. Read the comment docs.\n. # Codecov Report\nMerging #2048 into master will decrease coverage by 0.03%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2048      +/-\n============================================\n- Coverage     33.28%   33.25%   -0.04%   \n+ Complexity     2704     2701       -3   \n============================================\n  Files           416      416            \n  Lines         29322    29322            \n  Branches       3715     3715            \n============================================\n- Hits           9761     9751      -10   \n- Misses        18694    18701       +7   \n- Partials        867      870       +3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...kaban/executor/RunningExecutionsUpdaterThread.java | 75.86% <0%> (-3.45%) | 6% <0%> (-1%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.24% <0%> (-1.51%) | 85% <0%> (-2%) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 05ab2fe...59f38ac. Read the comment docs.\n. # Codecov Report\nMerging #2050 into master will decrease coverage by 0.02%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2050      +/-\n============================================\n- Coverage     33.28%   33.26%   -0.03%   \n+ Complexity     2704     2703       -1   \n============================================\n  Files           416      416            \n  Lines         29322    29322            \n  Branches       3715     3715            \n============================================\n- Hits           9761     9754       -7   \n- Misses        18694    18700       +6   \n- Partials        867      868       +1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...kaban/executor/RunningExecutionsUpdaterThread.java | 75.86% <0%> (-3.45%) | 6% <0%> (-1%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.24% <0%> (-1.51%) | 85% <0%> (-2%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.2% <0%> (+0.13%) | 145% <0%> (+1%) | :arrow_up: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 69.79% <0%> (+2.08%) | 7% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 05ab2fe...1c60118. Read the comment docs.\n. # Codecov Report\nMerging #2051 into master will decrease coverage by 0.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2051      +/-\n============================================\n- Coverage     33.28%   33.27%   -0.02%   \n+ Complexity     2704     2701       -3   \n============================================\n  Files           416      416            \n  Lines         29322    29322            \n  Branches       3715     3715            \n============================================\n- Hits           9761     9756       -5   \n- Misses        18694    18696       +2   \n- Partials        867      870       +3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...kaban/executor/RunningExecutionsUpdaterThread.java | 75.86% <0%> (-3.45%) | 6% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.89% <0%> (-0.87%) | 85% <0%> (-2%) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 05ab2fe...9633153. Read the comment docs.\n. # Codecov Report\nMerging #2052 into master will decrease coverage by 0.02%.\nThe diff coverage is 25%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2052      +/-\n============================================\n- Coverage     33.28%   33.26%   -0.03%   \n+ Complexity     2704     2702       -2   \n============================================\n  Files           416      416            \n  Lines         29322    29322            \n  Branches       3715     3715            \n============================================\n- Hits           9761     9755       -6   \n- Misses        18694    18698       +4   \n- Partials        867      869       +2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...a/azkaban/trigger/builtin/KillExecutionAction.java | 12.5% <\u00f8> (\u00f8) | 2 <0> (\u00f8) | :arrow_down: |\n| ...ava/azkaban/trigger/builtin/ExecuteFlowAction.java | 44% <\u00f8> (\u00f8) | 12 <0> (\u00f8) | :arrow_down: |\n| ...java/azkaban/trigger/builtin/ExecutionChecker.java | 4.44% <\u00f8> (\u00f8) | 1 <0> (\u00f8) | :arrow_down: |\n| ...main/java/azkaban/webapp/servlet/StatsServlet.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...in/java/azkaban/webapp/servlet/HistoryServlet.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...n/java/azkaban/webapp/servlet/ExecutorServlet.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...in/java/azkaban/webapp/servlet/JMXHttpServlet.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...a/azkaban/viewer/jobsummary/JobSummaryServlet.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| .../java/azkaban/viewer/reportal/ReportalServlet.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| .../azkaban/webapp/servlet/ProjectManagerServlet.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ... and 6 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 05ab2fe...0b8fd7f. Read the comment docs.\n. # Codecov Report\nMerging #2055 into master will decrease coverage by 0.01%.\nThe diff coverage is 0%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2055      +/-\n============================================\n- Coverage     33.28%   33.26%   -0.02%   \n- Complexity     2702     2703       +1   \n============================================\n  Files           416      416            \n  Lines         29323    29334      +11   \n  Branches       3715     3718       +3   \n============================================\n- Hits           9760     9759       -1   \n- Misses        18694    18707      +13   \n+ Partials        869      868       -1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../azkaban/webapp/servlet/ProjectManagerServlet.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.89% <0%> (-0.87%) | 85% <0%> (-2%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.2% <0%> (+0.13%) | 145% <0%> (+1%) | :arrow_up: |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.94% <0%> (+0.79%) | 48% <0%> (+2%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 358234c...4392778. Read the comment docs.\n. # Codecov Report\nMerging #2057 into master will increase coverage by 0.08%.\nThe diff coverage is 43.96%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2057      +/-\n============================================\n+ Coverage     33.26%   33.35%   +0.08%   \n- Complexity     2700     2727      +27   \n============================================\n  Files           416      416            \n  Lines         29322    29496     +174   \n  Branches       3715     3736      +21   \n============================================\n+ Hits           9755     9839      +84   \n- Misses        18697    18784      +87   \n- Partials        870      873       +3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...main/java/azkaban/webapp/servlet/StatsServlet.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...main/java/azkaban/executor/JdbcExecutorLoader.java | 20.58% <0%> (-0.63%) | 3 <0> (\u00f8) | |\n| ...ain/java/azkaban/executor/ExecutionController.java | 27.23% <31.61%> (+27.23%) | 20 <17> (+20) | :arrow_up: |\n| ...main/java/azkaban/executor/FetchActiveFlowDao.java | 87.5% <87.5%> (-2.75%) | 8 <6> (+5) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.2% <0%> (+0.13%) | 145% <0%> (+1%) | :arrow_up: |\n| .../src/main/java/azkaban/jobtype/JobTypeManager.java | 64.28% <0%> (+0.18%) | 23% <0%> (\u00f8) | :arrow_down: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 63.09% <0%> (+3.57%) | 13% <0%> (\u00f8) | :arrow_down: |\n| ...src/main/java/azkaban/jobExecutor/AbstractJob.java | 37.93% <0%> (+6.89%) | 5% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 0451edc...33d320c. Read the comment docs.\n. # Codecov Report\nMerging #2058 into master will decrease coverage by 0.07%.\nThe diff coverage is 100%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2058      +/-\n============================================\n- Coverage     33.26%   33.18%   -0.08%   \n+ Complexity     2700     2699       -1   \n============================================\n  Files           416      416            \n  Lines         29322    29323       +1   \n  Branches       3715     3715            \n============================================\n- Hits           9755     9732      -23   \n- Misses        18697    18723      +26   \n+ Partials        870      868       -2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../src/main/java/azkaban/jobtype/JobTypeManager.java | 64.28% <100%> (+0.18%) | 23 <0> (\u00f8) | :arrow_down: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 48.95% <0%> (-18.76%) | 6% <0%> (\u00f8) | |\n| ...kaban/executor/RunningExecutionsUpdaterThread.java | 75.86% <0%> (-3.45%) | 6% <0%> (-1%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.24% <0%> (-0.65%) | 85% <0%> (\u00f8) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 0451edc...fb84ab1. Read the comment docs.\n. # Codecov Report\nMerging #2065 into master will decrease coverage by <.01%.\nThe diff coverage is 77.77%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2065      +/-\n============================================\n- Coverage     33.28%   33.28%   -0.01%   \n- Complexity     2702     2729      +27   \n============================================\n  Files           416      416            \n  Lines         29323    29498     +175   \n  Branches       3715     3737      +22   \n============================================\n+ Hits           9760     9817      +57   \n- Misses        18694    18809     +115   \n- Partials        869      872       +3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...er/src/main/java/azkaban/execapp/FlowPreparer.java | 77.71% <77.77%> (-0.33%) | 15 <2> (+3) | |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 48.95% <0%> (-18.76%) | 6% <0%> (\u00f8) | |\n| .../main/java/azkaban/utils/ExecutorServiceUtils.java | 90% <0%> (-10%) | 4% <0%> (-1%) | |\n| ...main/java/azkaban/executor/FetchActiveFlowDao.java | 87.5% <0%> (-2.75%) | 8% <0%> (+5%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.89% <0%> (-0.87%) | 85% <0%> (-2%) | |\n| ...main/java/azkaban/executor/JdbcExecutorLoader.java | 20.58% <0%> (-0.63%) | 3% <0%> (\u00f8) | |\n| ...main/java/azkaban/webapp/servlet/StatsServlet.java | 0% <0%> (\u00f8) | 0% <0%> (\u00f8) | :arrow_down: |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.94% <0%> (+0.79%) | 48% <0%> (+2%) | :arrow_up: |\n| ...ain/java/azkaban/executor/ExecutionController.java | 27.23% <0%> (+27.23%) | 20% <0%> (+20%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 358234c...86e46e5. Read the comment docs.\n. # Codecov Report\nMerging #2066 into master will decrease coverage by 0.03%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2066      +/-\n============================================\n- Coverage     33.34%   33.31%   -0.04%   \n- Complexity     2731     2732       +1   \n============================================\n  Files           416      416            \n  Lines         29494    29494            \n  Branches       3737     3737            \n============================================\n- Hits           9834     9825       -9   \n- Misses        18787    18799      +12   \n+ Partials        873      870       -3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 48.95% <0%> (-18.76%) | 6% <0%> (\u00f8) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.06% <0%> (-0.14%) | 144% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.96% <0%> (+1.72%) | 87% <0%> (+2%) | :arrow_up: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 59.52% <0%> (+2.38%) | 13% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 495c2c4...0cb39d0. Read the comment docs.\n. # Codecov Report\nMerging #2067 into master will increase coverage by 0.04%.\nThe diff coverage is 46%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2067      +/-\n============================================\n+ Coverage     33.34%   33.38%   +0.04%   \n- Complexity     2731     2741      +10   \n============================================\n  Files           416      416            \n  Lines         29494    29588      +94   \n  Branches       3737     3753      +16   \n============================================\n+ Hits           9834     9879      +45   \n- Misses        18787    18828      +41   \n- Partials        873      881       +8\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| az-core/src/main/java/azkaban/Constants.java | 25% <\u00f8> (\u00f8) | 1 <0> (\u00f8) | :arrow_down: |\n| ...main/java/azkaban/executor/JdbcExecutorLoader.java | 20.28% <0%> (-0.3%) | 3 <0> (\u00f8) | |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 17.25% <7.5%> (-1.66%) | 5 <0> (\u00f8) | |\n| ...c/main/java/azkaban/executor/ExecutionFlowDao.java | 59.02% <72.72%> (+1.64%) | 15 <2> (+2) | :arrow_up: |\n| ...ain/java/azkaban/executor/ExecutionController.java | 33.6% <72.97%> (+6.37%) | 25 <6> (+5) | :arrow_up: |\n| ...main/java/azkaban/executor/ExecutionFinalizer.java | 50% <0%> (-2.33%) | 8% <0%> (-1%) | |\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 46.7% <0%> (-1.1%) | 49% <0%> (\u00f8) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.06% <0%> (-0.14%) | 144% <0%> (-1%) | |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.94% <0%> (+0.79%) | 48% <0%> (+2%) | :arrow_up: |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.32% <0%> (+1.07%) | 86% <0%> (+1%) | :arrow_up: |\n| ... and 3 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 495c2c4...77f0bfc. Read the comment docs.\n. # Codecov Report\nMerging #2070 into master will increase coverage by 0.02%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\nmaster   #2070      +/-\n===========================================\n+ Coverage     33.27%   33.3%   +0.02%   \n- Complexity     2730    2737       +7   \n===========================================\n  Files           416     416            \n  Lines         29494   29588      +94   \n  Branches       3737    3753      +16   \n===========================================\n+ Hits           9815    9853      +38   \n- Misses        18808   18855      +47   \n- Partials        871     880       +9\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...main/java/azkaban/executor/ExecutionFinalizer.java | 50% <0%> (-2.33%) | 8% <0%> (-1%) | |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 17.25% <0%> (-1.66%) | 5% <0%> (\u00f8) | |\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 46.7% <0%> (-1.1%) | 49% <0%> (\u00f8) | |\n| ...main/java/azkaban/executor/JdbcExecutorLoader.java | 20.28% <0%> (-0.3%) | 3% <0%> (\u00f8) | |\n| az-core/src/main/java/azkaban/Constants.java | 25% <0%> (\u00f8) | 1% <0%> (\u00f8) | :arrow_down: |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.2% <0%> (+0.13%) | 145% <0%> (+1%) | :arrow_up: |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.89% <0%> (+0.64%) | 85% <0%> (\u00f8) | :arrow_down: |\n| ...c/main/java/azkaban/executor/ExecutionFlowDao.java | 59.02% <0%> (+1.64%) | 15% <0%> (+2%) | :arrow_up: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 59.52% <0%> (+2.38%) | 13% <0%> (\u00f8) | :arrow_down: |\n| ...ain/java/azkaban/executor/ExecutionController.java | 33.6% <0%> (+6.37%) | 25% <0%> (+5%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 96d8c9a...8d476d5. Read the comment docs.\n. # Codecov Report\nMerging #2071 into master will increase coverage by 0.03%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2071      +/-\n============================================\n+ Coverage     33.27%   33.31%   +0.03%   \n  Complexity     2730     2730            \n============================================\n  Files           416      416            \n  Lines         29494    29494            \n  Branches       3737     3737            \n============================================\n+ Hits           9815     9825      +10   \n+ Misses        18808    18794      -14   \n- Partials        871      875       +4\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...main/java/azkaban/executor/ExecutionFinalizer.java | 50% <0%> (-2.33%) | 8% <0%> (-1%) | |\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 46.7% <0%> (-1.1%) | 49% <0%> (\u00f8) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.2% <0%> (+0.13%) | 145% <0%> (+1%) | :arrow_up: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (+18.75%) | 6% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 96d8c9a...efbc01d. Read the comment docs.\n. # Codecov Report\nMerging #2073 into master will increase coverage by 0.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2073      +/-\n============================================\n+ Coverage     33.34%   33.36%   +0.01%   \n+ Complexity     2738     2737       -1   \n============================================\n  Files           416      416            \n  Lines         29588    29588            \n  Branches       3753     3753            \n============================================\n+ Hits           9867     9871       +4   \n+ Misses        18838    18834       -4   \n  Partials        883      883\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.15% <0%> (-0.8%) | 46% <0%> (-2%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.2% <0%> (+0.13%) | 145% <0%> (+1%) | :arrow_up: |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.89% <0%> (+0.64%) | 85% <0%> (\u00f8) | :arrow_down: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 59.52% <0%> (+2.38%) | 13% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 8a48857...5555877. Read the comment docs.\n. # Codecov Report\nMerging #2074 into master will increase coverage by 0.02%.\nThe diff coverage is 46.53%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2074      +/-\n============================================\n+ Coverage     33.34%   33.37%   +0.02%   \n- Complexity     2738     2740       +2   \n============================================\n  Files           416      417       +1   \n  Lines         29588    29626      +38   \n  Branches       3753     3759       +6   \n============================================\n+ Hits           9867     9887      +20   \n- Misses        18838    18849      +11   \n- Partials        883      890       +7\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 46.45% <\u00f8> (-0.26%) | 47 <0> (-2) | |\n| ...ava/azkaban/executor/RunningExecutionsUpdater.java | 80.29% <100%> (\u00f8) | 23 <0> (\u00f8) | :arrow_down: |\n| ...an/executor/selector/ExecutionControllerUtils.java | 37.17% <37.17%> (\u00f8) | 9 <9> (?) | |\n| ...main/java/azkaban/executor/ExecutionFinalizer.java | 79.41% <60%> (+29.41%) | 4 <0> (-4) | :arrow_down: |\n| ...ain/java/azkaban/executor/ExecutionController.java | 36.64% <81.25%> (+3.03%) | 27 <3> (+2) | :arrow_up: |\n| ...kaban/executor/RunningExecutionsUpdaterThread.java | 75.86% <0%> (-3.45%) | 6% <0%> (-1%) | |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.15% <0%> (-0.8%) | 46% <0%> (-2%) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 8a48857...511d4f9. Read the comment docs.\n. # Codecov Report\nMerging #2075 into master will decrease coverage by 0.03%.\nThe diff coverage is 36%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2075      +/-\n============================================\n- Coverage     33.32%   33.28%   -0.04%   \n+ Complexity     2743     2736       -7   \n============================================\n  Files           417      417            \n  Lines         29626    29609      -17   \n  Branches       3759     3761       +2   \n============================================\n- Hits           9872     9856      -16   \n+ Misses        18869    18868       -1   \n  Partials        885      885\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...xecutor/utils/process/ProcessFailureException.java | 100% <100%> (+33.33%) | 1 <1> (\u00f8) | :arrow_down: |\n| ...aban/jobExecutor/utils/process/AzkabanProcess.java | 51.04% <33.33%> (-2.17%) | 12 <1> (+1) | |\n| ...common/src/main/java/azkaban/utils/LogGobbler.java | 0% <0%> (-56.25%) | 0% <0%> (-6%) | |\n| ...on/src/main/java/azkaban/utils/CircularBuffer.java | 0% <0%> (-47.06%) | 0% <0%> (-3%) | |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 71.42% <0%> (-7.15%) | 11% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.32% <0%> (+1.07%) | 87% <0%> (+2%) | :arrow_up: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (+18.75%) | 6% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update e20c886...661351f. Read the comment docs.\n. # Codecov Report\nMerging #2078 into master will increase coverage by 0.82%.\nThe diff coverage is 100%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2078      +/-\n============================================\n+ Coverage     33.32%   34.14%   +0.82%   \n- Complexity     2743     2867     +124   \n============================================\n  Files           417      418       +1   \n  Lines         29626    30412     +786   \n  Branches       3759     4004     +245   \n============================================\n+ Hits           9872    10384     +512   \n- Misses        18869    19120     +251   \n- Partials        885      908      +23\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../src/main/java/azkaban/jobExecutor/ProcessJob.java | 56.6% <100%> (+0.2%) | 28 <0> (\u00f8) | :arrow_down: |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.15% <0%> (-0.8%) | 46% <0%> (-2%) | |\n| ...ava/azkaban/executor/ExecutionControllerUtils.java | 37.17% <0%> (\u00f8) | 9% <0%> (?) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.96% <0%> (+1.72%) | 87% <0%> (+2%) | :arrow_up: |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 18.97% <0%> (+1.72%) | 8% <0%> (+3%) | :arrow_up: |\n| ...ava/azkaban/executor/RunningExecutionsUpdater.java | 82.19% <0%> (+1.9%) | 46% <0%> (+23%) | :arrow_up: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 59.52% <0%> (+2.38%) | 13% <0%> (\u00f8) | :arrow_down: |\n| ...ain/java/azkaban/executor/ExecutionController.java | 40.48% <0%> (+3.84%) | 54% <0%> (+27%) | :arrow_up: |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 78.85% <0%> (+4.78%) | 202% <0%> (+58%) | :arrow_up: |\n| ...main/java/azkaban/executor/ExecutionFinalizer.java | 86.95% <0%> (+7.54%) | 8% <0%> (+4%) | :arrow_up: |\n| ... and 1 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update e20c886...592f958. Read the comment docs.\n. # Codecov Report\nMerging #2079 into master will increase coverage by 0.05%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2079      +/-\n============================================\n+ Coverage     33.32%   33.37%   +0.05%   \n+ Complexity     2743     2741       -2   \n============================================\n  Files           417      417            \n  Lines         29626    29626            \n  Branches       3759     3759            \n============================================\n+ Hits           9872     9888      +16   \n+ Misses        18869    18849      -20   \n- Partials        885      889       +4\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.15% <0%> (-0.8%) | 46% <0%> (-2%) | |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (+18.75%) | 6% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update e20c886...646d2c2. Read the comment docs.\n. # Codecov Report\nMerging #2080 into master will decrease coverage by 0.01%.\nThe diff coverage is 40%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2080      +/-\n============================================\n- Coverage     33.33%   33.31%   -0.02%   \n- Complexity     2741     2742       +1   \n============================================\n  Files           417      417            \n  Lines         29626    29631       +5   \n  Branches       3759     3760       +1   \n============================================\n- Hits           9875     9873       -2   \n- Misses        18865    18872       +7   \n  Partials        886      886\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 17.45% <100%> (+0.19%) | 5 <0> (\u00f8) | :arrow_down: |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.94% <25%> (-0.13%) | 145 <0> (+1) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.24% <0%> (-0.65%) | 85% <0%> (\u00f8) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update c20f219...02cd5c2. Read the comment docs.\n. # Codecov Report\nMerging #2081 into master will increase coverage by 0.01%.\nThe diff coverage is 100%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2081      +/-\n============================================\n+ Coverage     33.37%   33.38%   +0.01%   \n- Complexity     2739     2742       +3   \n============================================\n  Files           417      417            \n  Lines         29631    29631            \n  Branches       3760     3760            \n============================================\n+ Hits           9888     9891       +3   \n  Misses        18851    18851            \n+ Partials        892      889       -3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...ava/azkaban/executor/RunningExecutionsUpdater.java | 80.29% <\u00f8> (\u00f8) | 23 <0> (\u00f8) | :arrow_down: |\n| ...main/java/azkaban/executor/ExecutionFinalizer.java | 79.41% <\u00f8> (\u00f8) | 4 <0> (\u00f8) | :arrow_down: |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.94% <\u00f8> (+0.13%) | 145 <0> (+1) | :arrow_up: |\n| ...ain/java/azkaban/executor/ExecutionController.java | 36.64% <\u00f8> (\u00f8) | 27 <0> (\u00f8) | :arrow_down: |\n| ...ava/azkaban/executor/ExecutionControllerUtils.java | 37.17% <100%> (\u00f8) | 9 <1> (?) | |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 89.58% <0%> (+2.08%) | 17% <0%> (+1%) | :arrow_up: |\n| ...kaban/executor/RunningExecutionsUpdaterThread.java | 79.31% <0%> (+3.44%) | 7% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 16ba1f3...f596d36. Read the comment docs.\n. # Codecov Report\nMerging #2082 into master will decrease coverage by 0.02%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2082      +/-\n============================================\n- Coverage      33.4%   33.37%   -0.03%   \n+ Complexity     2743     2741       -2   \n============================================\n  Files           417      417            \n  Lines         29631    29631            \n  Branches       3760     3760            \n============================================\n- Hits           9897     9890       -7   \n- Misses        18845    18851       +6   \n- Partials        889      890       +1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.15% <0%> (-0.8%) | 46% <0%> (-2%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.24% <0%> (-0.65%) | 85% <0%> (\u00f8) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 9fefb9a...ee6c1e1. Read the comment docs.\n. # Codecov Report\nMerging #2085 into master will decrease coverage by <.01%.\nThe diff coverage is 0%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2085      +/-\n============================================\n- Coverage      33.4%   33.39%   -0.01%   \n  Complexity     2743     2743            \n============================================\n  Files           417      417            \n  Lines         29631    29633       +2   \n  Branches       3760     3761       +1   \n============================================\n- Hits           9897     9895       -2   \n- Misses        18845    18849       +4   \n  Partials        889      889\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 17.37% <0%> (-0.09%) | 5 <0> (\u00f8) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.15% <0%> (-0.8%) | 46% <0%> (-2%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.32% <0%> (+0.43%) | 87% <0%> (+2%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 9fefb9a...ecbf082. Read the comment docs.\n. # Codecov Report\nMerging #2088 into master will increase coverage by 0.16%.\nThe diff coverage is 47.22%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2088      +/-\n============================================\n+ Coverage     33.21%   33.38%   +0.16%   \n- Complexity     2735     2746      +11   \n============================================\n  Files           417      417            \n  Lines         29616    29674      +58   \n  Branches       3763     3767       +4   \n============================================\n+ Hits           9837     9906      +69   \n+ Misses        18896    18880      -16   \n- Partials        883      888       +5\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 46.45% <\u00f8> (\u00f8) | 47 <0> (\u00f8) | :arrow_down: |\n| ...src/main/java/azkaban/webapp/AzkabanWebServer.java | 15.58% <0%> (-0.05%) | 5 <0> (\u00f8) | |\n| .../main/java/azkaban/jmx/JmxExecutionController.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...ain/java/azkaban/executor/ExecutionController.java | 38.79% <73.91%> (+2.14%) | 30 <5> (+3) | :arrow_up: |\n| ...main/java/azkaban/executor/FetchActiveFlowDao.java | 86.02% <0%> (-1.48%) | 11% <0%> (+3%) | |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.15% <0%> (-0.8%) | 46% <0%> (-2%) | |\n| ...main/java/azkaban/executor/JdbcExecutorLoader.java | 20% <0%> (-0.29%) | 3% <0%> (\u00f8) | |\n| ...li/java/azkaban/restli/ProjectManagerResource.java | 19.48% <0%> (\u00f8) | 7% <0%> (\u00f8) | :arrow_down: |\n| .../src/main/java/azkaban/project/ProjectManager.java | 14.63% <0%> (\u00f8) | 7% <0%> (\u00f8) | :arrow_down: |\n| ... and 6 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d617f7d...fb6e117. Read the comment docs.\n. # Codecov Report\nMerging #2089 into master will increase coverage by 0.15%.\nThe diff coverage is 60%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2089      +/-\n============================================\n+ Coverage     33.21%   33.36%   +0.15%   \n- Complexity     2735     2748      +13   \n============================================\n  Files           417      418       +1   \n  Lines         29616    29706      +90   \n  Branches       3763     3783      +20   \n============================================\n+ Hits           9837     9912      +75   \n+ Misses        18896    18891       -5   \n- Partials        883      903      +20\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...ugin/src/main/java/azkaban/jobtype/JdbcSqlJob.java | 60% <60%> (\u00f8) | 15 <15> (?) | |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.15% <0%> (-0.8%) | 46% <0%> (-2%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.89% <0%> (+0.64%) | 85% <0%> (\u00f8) | :arrow_down: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 59.52% <0%> (+2.38%) | 13% <0%> (\u00f8) | :arrow_down: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (+18.75%) | 6% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d617f7d...ee9f2e0. Read the comment docs.\n. # Codecov Report\nMerging #2093 into master will increase coverage by 0.2%.\nThe diff coverage is 72.34%.\n\n\n```diff\n@@             Coverage Diff             @@\nmaster    #2093     +/-\n===========================================\n+ Coverage      33.3%   33.51%   +0.2%   \n- Complexity     2744     2764     +20   \n===========================================\n  Files           417      419      +2   \n  Lines         29658    29752     +94   \n  Branches       3766     3779     +13   \n===========================================\n+ Hits           9879     9970     +91   \n+ Misses        18894    18884     -10   \n- Partials        885      898     +13\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...on/src/main/java/azkaban/user/AzkabanIniRealm.java | 68.18% <68.18%> (\u00f8) | 6 <6> (?) | |\n| ...n/src/main/java/azkaban/user/ShiroUserManager.java | 73.61% <73.61%> (\u00f8) | 13 <13> (?) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.24% <0%> (-1.08%) | 85% <0%> (-2%) | |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.94% <0%> (+0.79%) | 48% <0%> (+2%) | :arrow_up: |\n| ...zkaban-common/src/main/java/azkaban/user/User.java | 28.75% <0%> (+8.75%) | 6% <0%> (\u00f8) | :arrow_down: |\n| ...zkaban-common/src/main/java/azkaban/user/Role.java | 85.71% <0%> (+14.28%) | 3% <0%> (+1%) | :arrow_up: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (+18.75%) | 6% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update abdf691...a2222be. Read the comment docs.\n. # Codecov Report\nMerging #2094 into master will increase coverage by 0.17%.\nThe diff coverage is 50%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2094      +/-\n============================================\n+ Coverage      33.3%   33.48%   +0.17%   \n- Complexity     2744     2752       +8   \n============================================\n  Files           417      417            \n  Lines         29658    29675      +17   \n  Branches       3766     3764       -2   \n============================================\n+ Hits           9879     9936      +57   \n+ Misses        18894    18848      -46   \n- Partials        885      891       +6\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...aban/jobExecutor/utils/process/AzkabanProcess.java | 53.21% <47.22%> (+2.16%) | 11 <0> (-1) | :arrow_down: |\n| ...xecutor/utils/process/ProcessFailureException.java | 66.66% <66.66%> (-33.34%) | 1 <1> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.89% <0%> (-0.44%) | 85% <0%> (-2%) | |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.94% <0%> (+0.79%) | 48% <0%> (+2%) | :arrow_up: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 59.52% <0%> (+2.38%) | 13% <0%> (\u00f8) | :arrow_down: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (+18.75%) | 6% <0%> (\u00f8) | :arrow_down: |\n| ...on/src/main/java/azkaban/utils/CircularBuffer.java | 47.05% <0%> (+47.05%) | 3% <0%> (+3%) | :arrow_up: |\n| ...common/src/main/java/azkaban/utils/LogGobbler.java | 56.25% <0%> (+56.25%) | 6% <0%> (+6%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update abdf691...4d5a343. Read the comment docs.\n. # Codecov Report\nMerging #2098 into master will increase coverage by 0.09%.\nThe diff coverage is 70%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2098      +/-\n============================================\n+ Coverage     33.52%   33.62%   +0.09%   \n- Complexity     2758     2767       +9   \n============================================\n  Files           417      418       +1   \n  Lines         29691    29770      +79   \n  Branches       3765     3776      +11   \n============================================\n+ Hits           9953    10009      +56   \n- Misses        18850    18864      +14   \n- Partials        888      897       +9\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 46.45% <\u00f8> (\u00f8) | 47 <0> (\u00f8) | :arrow_down: |\n| az-core/src/main/java/azkaban/Constants.java | 25% <\u00f8> (\u00f8) | 1 <0> (\u00f8) | :arrow_down: |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 17.37% <0%> (\u00f8) | 5 <0> (\u00f8) | :arrow_down: |\n| ...src/main/java/azkaban/webapp/AzkabanWebServer.java | 15.62% <0%> (+0.04%) | 5 <0> (\u00f8) | :arrow_down: |\n| ...src/main/java/azkaban/execapp/ExecutorServlet.java | 1.62% <0%> (\u00f8) | 2 <0> (\u00f8) | :arrow_down: |\n| ...ain/java/azkaban/executor/ExecutionController.java | 38.24% <36.36%> (-0.55%) | 29 <1> (-1) | |\n| ...n/java/azkaban/executor/ExecutorHealthChecker.java | 77.63% <77.63%> (\u00f8) | 14 <14> (?) | |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 85.41% <0%> (-4.17%) | 16% <0%> (-1%) | |\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 66.66% <0%> (-3.04%) | 14% <0%> (-1%) | |\n| ... and 6 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 684ea89...11c7939. Read the comment docs.\n. # Codecov Report\nMerging #2099 into master will decrease coverage by 0.14%.\nThe diff coverage is 0.93%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2099      +/-\n============================================\n- Coverage     33.52%   33.37%   -0.15%   \n+ Complexity     2758     2756       -2   \n============================================\n  Files           417      421       +4   \n  Lines         29691    29795     +104   \n  Branches       3765     3775      +10   \n============================================\n- Hits           9953     9945       -8   \n- Misses        18850    18960     +110   \n- Partials        888      890       +2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 46.45% <\u00f8> (\u00f8) | 47 <0> (\u00f8) | :arrow_down: |\n| ...a/azkaban/execapp/metric/NumFinishedJobMetric.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...azkaban/execapp/metric/NumSucceededFlowMetric.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| .../src/main/java/azkaban/jmx/JmxExecutorManager.java | 17.64% <0%> (-1.11%) | 1 <0> (\u00f8) | |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 17.2% <0%> (-0.17%) | 5 <0> (\u00f8) | |\n| ...in/java/azkaban/execapp/AzkabanExecutorServer.java | 4.83% <0%> (-0.34%) | 3 <0> (\u00f8) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 73.55% <0%> (-0.39%) | 145 <0> (\u00f8) | |\n| .../azkaban/execapp/metric/NumFinishedFlowMetric.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| .../azkaban/execapp/metric/NumSucceededJobMetric.java | 0% <0%> (\u00f8) | 0 <0> (?) | |\n| ...n/java/azkaban/webapp/servlet/ExecutorServlet.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ... and 8 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 684ea89...8b96128. Read the comment docs.\n. # Codecov Report\nMerging #2104 into master will decrease coverage by 0.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2104      +/-\n============================================\n- Coverage     33.52%   33.51%   -0.02%   \n+ Complexity     2758     2756       -2   \n============================================\n  Files           417      417            \n  Lines         29691    29691            \n  Branches       3765     3765            \n============================================\n- Hits           9953     9950       -3   \n- Misses        18850    18851       +1   \n- Partials        888      890       +2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 66.66% <0%> (-3.04%) | 14% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.89% <0%> (-0.22%) | 85% <0%> (-1%) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 684ea89...e139cd6. Read the comment docs.\n. # Codecov Report\nMerging #2105 into master will increase coverage by 0.05%.\nThe diff coverage is 56.25%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2105      +/-\n============================================\n+ Coverage     33.57%   33.62%   +0.05%   \n- Complexity     2769     2772       +3   \n============================================\n  Files           418      418            \n  Lines         29770    29780      +10   \n  Branches       3776     3779       +3   \n============================================\n+ Hits           9994    10015      +21   \n+ Misses        18885    18867      -18   \n- Partials        891      898       +7\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...n/java/azkaban/executor/ExecutorHealthChecker.java | 77.63% <\u00f8> (\u00f8) | 14 <0> (\u00f8) | :arrow_down: |\n| ...ava/azkaban/executor/RunningExecutionsUpdater.java | 89.34% <0%> (+9.05%) | 23 <0> (\u00f8) | :arrow_down: |\n| ...main/java/azkaban/executor/ExecutionFinalizer.java | 79.41% <100%> (\u00f8) | 4 <0> (\u00f8) | :arrow_down: |\n| ...ava/azkaban/executor/ExecutionControllerUtils.java | 36.45% <36.84%> (-0.73%) | 10 <1> (+1) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.31% <90.9%> (+0.37%) | 149 <1> (+4) | :arrow_up: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.24% <0%> (-1.73%) | 85% <0%> (-2%) | |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (+18.75%) | 6% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update ea49bae...c8ae513. Read the comment docs.\n. # Codecov Report\nMerging #2111 into master will increase coverage by 0.11%.\nThe diff coverage is 64%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2111      +/-\n============================================\n+ Coverage     33.58%   33.69%   +0.11%   \n- Complexity     2774     2782       +8   \n============================================\n  Files           418      419       +1   \n  Lines         29782    29789       +7   \n  Branches       3779     3780       +1   \n============================================\n+ Hits          10001    10037      +36   \n+ Misses        18887    18855      -32   \n- Partials        894      897       +3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| az-core/src/main/java/azkaban/utils/Utils.java | 44.97% <\u00f8> (-0.53%) | 44 <0> (\u00f8) | |\n| .../main/java/azkaban/jobExecutor/JavaProcessJob.java | 50.72% <0%> (+2.77%) | 13 <0> (\u00f8) | :arrow_down: |\n| ...core/src/main/java/azkaban/utils/MemConfValue.java | 100% <100%> (\u00f8) | 7 <7> (?) | |\n| ...src/main/java/azkaban/project/FlowLoaderUtils.java | 63.41% <50%> (-0.82%) | 23 <0> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.02% <0%> (-0.22%) | 85% <0%> (-2%) | |\n| ...main/java/azkaban/executor/ExecutableFlowBase.java | 83.33% <0%> (+1.14%) | 48% <0%> (+1%) | :arrow_up: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 60.71% <0%> (+3.57%) | 13% <0%> (\u00f8) | :arrow_down: |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 89.58% <0%> (+4.16%) | 17% <0%> (+1%) | :arrow_up: |\n| ...src/main/java/azkaban/jobExecutor/AbstractJob.java | 37.93% <0%> (+6.89%) | 5% <0%> (+1%) | :arrow_up: |\n| ... and 1 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 28a27f3...b012741. Read the comment docs.\n. # Codecov Report\nMerging #2112 into master will increase coverage by 0.05%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2112      +/-\n============================================\n+ Coverage     33.58%   33.63%   +0.05%   \n+ Complexity     2774     2773       -1   \n============================================\n  Files           418      418            \n  Lines         29782    29782            \n  Branches       3779     3779            \n============================================\n+ Hits          10001    10018      +17   \n+ Misses        18887    18867      -20   \n- Partials        894      897       +3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.37% <0%> (-0.86%) | 85% <0%> (-2%) | |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.15% <0%> (-0.8%) | 46% <0%> (-2%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.44% <0%> (+0.13%) | 150% <0%> (+1%) | :arrow_up: |\n| ...main/java/azkaban/executor/ExecutableFlowBase.java | 83.33% <0%> (+1.14%) | 48% <0%> (+1%) | :arrow_up: |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 89.58% <0%> (+4.16%) | 17% <0%> (+1%) | :arrow_up: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (+18.75%) | 6% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 28a27f3...7d1f62c. Read the comment docs.\n. # Codecov Report\nMerging #2113 into master will increase coverage by <.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2113      +/-\n============================================\n+ Coverage     33.63%   33.63%   +<.01%   \n- Complexity     2770     2773       +3   \n============================================\n  Files           418      418            \n  Lines         29782    29782            \n  Branches       3779     3779            \n============================================\n+ Hits          10016    10018       +2   \n- Misses        18866    18867       +1   \n+ Partials        900      897       -3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.37% <0%> (-0.65%) | 85% <0%> (\u00f8) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.44% <0%> (+0.13%) | 150% <0%> (+1%) | :arrow_up: |\n| ...main/java/azkaban/executor/ExecutableFlowBase.java | 83.33% <0%> (+1.14%) | 48% <0%> (+1%) | :arrow_up: |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 89.58% <0%> (+4.16%) | 17% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d39ff37...b5ef4ab. Read the comment docs.\n. # Codecov Report\nMerging #2115 into master will increase coverage by <.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2115      +/-\n============================================\n+ Coverage     33.63%   33.63%   +<.01%   \n- Complexity     2770     2773       +3   \n============================================\n  Files           418      418            \n  Lines         29782    29782            \n  Branches       3779     3779            \n============================================\n+ Hits          10016    10018       +2   \n- Misses        18866    18867       +1   \n+ Partials        900      897       -3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.37% <0%> (-0.65%) | 85% <0%> (\u00f8) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.44% <0%> (+0.13%) | 150% <0%> (+1%) | :arrow_up: |\n| ...main/java/azkaban/executor/ExecutableFlowBase.java | 83.33% <0%> (+1.14%) | 48% <0%> (+1%) | :arrow_up: |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 89.58% <0%> (+4.16%) | 17% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d39ff37...77521e3. Read the comment docs.\n. # Codecov Report\nMerging #2116 into master will increase coverage by 0.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2116      +/-\n============================================\n+ Coverage     33.63%   33.65%   +0.01%   \n  Complexity     2773     2773            \n============================================\n  Files           418      418            \n  Lines         29782    29782            \n  Branches       3779     3779            \n============================================\n+ Hits          10018    10023       +5   \n+ Misses        18867    18862       -5   \n  Partials        897      897\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.02% <0%> (+0.64%) | 85% <0%> (\u00f8) | :arrow_down: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 59.52% <0%> (+2.38%) | 13% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 9dcab99...61e5ec6. Read the comment docs.\n. # Codecov Report\nMerging #2117 into master will decrease coverage by 0.02%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2117      +/-\n============================================\n- Coverage     33.63%   33.61%   -0.03%   \n- Complexity     2773     2775       +2   \n============================================\n  Files           418      418            \n  Lines         29782    29782            \n  Branches       3779     3779            \n============================================\n- Hits          10018    10012       -6   \n- Misses        18867    18876       +9   \n+ Partials        897      894       -3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 48.95% <0%> (-18.76%) | 6% <0%> (\u00f8) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.31% <0%> (-0.14%) | 149% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 71.09% <0%> (+1.71%) | 87% <0%> (+2%) | :arrow_up: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 60.71% <0%> (+3.57%) | 13% <0%> (\u00f8) | :arrow_down: |\n| ...src/main/java/azkaban/jobExecutor/AbstractJob.java | 37.93% <0%> (+6.89%) | 5% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 9dcab99...2080039. Read the comment docs.\n. # Codecov Report\nMerging #2119 into master will increase coverage by 0.05%.\nThe diff coverage is 100%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2119      +/-\n============================================\n+ Coverage     33.59%   33.64%   +0.05%   \n+ Complexity     2773     2772       -1   \n============================================\n  Files           418      418            \n  Lines         29782    29782            \n  Branches       3779     3779            \n============================================\n+ Hits          10005    10020      +15   \n+ Misses        18883    18864      -19   \n- Partials        894      898       +4\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.02% <100%> (\u00f8) | 85 <0> (\u00f8) | :arrow_down: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-2.39%) | 13% <0%> (\u00f8) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.31% <0%> (-0.14%) | 149% <0%> (-1%) | |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (+18.75%) | 6% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update c68e1a3...240f8a3. Read the comment docs.\n. # Codecov Report\nMerging #2120 into master will increase coverage by 0.05%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2120      +/-\n============================================\n+ Coverage     33.59%   33.65%   +0.05%   \n+ Complexity     2773     2772       -1   \n============================================\n  Files           418      418            \n  Lines         29782    29782            \n  Branches       3779     3779            \n============================================\n+ Hits          10005    10022      +17   \n+ Misses        18883    18862      -21   \n- Partials        894      898       +4\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.31% <0%> (-0.14%) | 149% <0%> (-1%) | |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (+18.75%) | 6% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update c68e1a3...88b7beb. Read the comment docs.\n. # Codecov Report\nMerging #2121 into master will increase coverage by 0.41%.\nThe diff coverage is 34.63%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2121      +/-\n============================================\n+ Coverage     33.72%   34.14%   +0.41%   \n- Complexity     2801     2847      +46   \n============================================\n  Files           421      425       +4   \n  Lines         29835    29879      +44   \n  Branches       3774     3767       -7   \n============================================\n+ Hits          10063    10202     +139   \n+ Misses        18877    18769     -108   \n- Partials        895      908      +13\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| az-core/src/main/java/azkaban/utils/Utils.java | 44.97% <\u00f8> (\u00f8) | 44 <0> (\u00f8) | :arrow_down: |\n| ...mmon/src/main/java/azkaban/scheduler/Schedule.java | 0% <\u00f8> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...c/main/java/azkaban/scheduler/ScheduleManager.java | 11.59% <\u00f8> (\u00f8) | 2 <0> (\u00f8) | :arrow_down: |\n| .../main/java/azkaban/jobExecutor/JavaProcessJob.java | 50.72% <\u00f8> (\u00f8) | 13 <0> (\u00f8) | :arrow_down: |\n| ...n-common/src/main/java/azkaban/flow/FlowUtils.java | 61.53% <0%> (+7.3%) | 5 <1> (\u00f8) | :arrow_down: |\n| ...n/java/azkaban/webapp/servlet/ScheduleServlet.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| .../azkaban/scheduler/TriggerBasedScheduleLoader.java | 6.25% <0%> (+0.05%) | 2 <0> (\u00f8) | :arrow_down: |\n| ...src/main/java/azkaban/server/HttpRequestUtils.java | 15.17% <0%> (-0.14%) | 9 <0> (\u00f8) | |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 17.69% <0%> (-0.04%) | 5 <0> (\u00f8) | |\n| ...an-common/src/main/java/azkaban/utils/Emailer.java | 62.24% <0%> (+1.24%) | 16 <0> (\u00f8) | :arrow_down: |\n| ... and 24 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 774cfaa...1a92b73. Read the comment docs.\n. # Codecov Report\nMerging #2122 into master will decrease coverage by 0.04%.\nThe diff coverage is 0%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2122      +/-\n============================================\n- Coverage     33.65%   33.61%   -0.05%   \n+ Complexity     2775     2772       -3   \n============================================\n  Files           418      418            \n  Lines         29782    29761      -21   \n  Branches       3779     3773       -6   \n============================================\n- Hits          10023    10004      -19   \n+ Misses        18863    18862       -1   \n+ Partials        896      895       -1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../azkaban/webapp/servlet/ProjectManagerServlet.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 48.95% <0%> (-18.76%) | 6% <0%> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.02% <0%> (-0.43%) | 85% <0%> (-2%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.31% <0%> (-0.14%) | 149% <0%> (-1%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 59.52% <0%> (+2.38%) | 13% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 3e5693a...d678fc2. Read the comment docs.\n. # Codecov Report\nMerging #2123 into master will decrease coverage by 0.06%.\nThe diff coverage is 28.57%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2123      +/-\n============================================\n- Coverage     33.65%   33.58%   -0.07%   \n+ Complexity     2775     2774       -1   \n============================================\n  Files           418      418            \n  Lines         29782    29787       +5   \n  Branches       3779     3779            \n============================================\n- Hits          10023    10005      -18   \n- Misses        18863    18886      +23   \n  Partials        896      896\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...er/src/main/java/azkaban/execapp/FlowPreparer.java | 76.11% <28.57%> (-1.61%) | 15 <4> (\u00f8) | |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 48.95% <0%> (-18.76%) | 6% <0%> (\u00f8) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.31% <0%> (-0.14%) | 149% <0%> (-1%) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 3e5693a...8cf3f25. Read the comment docs.\n. # Codecov Report\nMerging #2128 into master will increase coverage by 0.07%.\nThe diff coverage is 80.5%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2128      +/-\n============================================\n+ Coverage     33.57%   33.65%   +0.07%   \n- Complexity     2772     2788      +16   \n============================================\n  Files           418      419       +1   \n  Lines         29782    29809      +27   \n  Branches       3779     3775       -4   \n============================================\n+ Hits           9999    10031      +32   \n+ Misses        18888    18885       -3   \n+ Partials        895      893       -2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../src/main/java/azkaban/metrics/MetricsManager.java | 55.17% <100%> (+3.32%) | 7 <2> (+2) | :arrow_up: |\n| ...n/src/main/java/azkaban/metrics/CommonMetrics.java | 84.61% <100%> (+7.69%) | 11 <6> (+5) | :arrow_up: |\n| ...java/azkaban/execapp/ProjectDirectoryMetadata.java | 90.47% <100%> (\u00f8) | 11 <3> (?) | |\n| ...ain/java/azkaban/executor/ExecutionController.java | 39.1% <100%> (+0.85%) | 29 <0> (\u00f8) | :arrow_down: |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 17.47% <15.38%> (+0.1%) | 5 <0> (\u00f8) | :arrow_down: |\n| ...ommon/src/main/java/azkaban/utils/FileIOUtils.java | 32.25% <33.33%> (-1.69%) | 22 <2> (-2) | |\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 46.63% <75%> (+0.17%) | 47 <0> (\u00f8) | :arrow_down: |\n| ...er/src/main/java/azkaban/execapp/FlowPreparer.java | 82.07% <82.05%> (+4.36%) | 14 <13> (-1) | :arrow_down: |\n| ...main/java/azkaban/execapp/ProjectCacheCleaner.java | 87.32% <87.32%> (\u00f8) | 15 <15> (?) | |\n| ...kaban-common/src/main/java/azkaban/utils/Pair.java | 46.66% <0%> (-10%) | 8% <0%> (-1%) | |\n| ... and 3 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update e8e531c...c805816. Read the comment docs.\n. # Codecov Report\nMerging #2129 into master will increase coverage by 0.03%.\nThe diff coverage is 72.22%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2129      +/-\n============================================\n+ Coverage     33.72%   33.76%   +0.03%   \n+ Complexity     2798     2797       -1   \n============================================\n  Files           420      420            \n  Lines         29799    29809      +10   \n  Branches       3771     3772       +1   \n============================================\n+ Hits          10050    10065      +15   \n+ Misses        18858    18847      -11   \n- Partials        891      897       +6\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...main/java/azkaban/executor/JdbcExecutorLoader.java | 20% <0%> (\u00f8) | 3 <0> (\u00f8) | :arrow_down: |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 17.51% <0%> (+0.04%) | 5 <0> (\u00f8) | :arrow_down: |\n| ...c/main/java/azkaban/executor/ExecutionFlowDao.java | 60.36% <81.25%> (+1.14%) | 15 <2> (\u00f8) | :arrow_down: |\n| ...src/main/java/azkaban/jobExecutor/AbstractJob.java | 31.03% <0%> (-6.9%) | 4% <0%> (-1%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-5.96%) | 13% <0%> (\u00f8) | |\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 66.66% <0%> (-3.04%) | 14% <0%> (-1%) | |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 87.5% <0%> (-2.09%) | 16% <0%> (-1%) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.37% <0%> (-1.08%) | 85% <0%> (-1%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.44% <0%> (+0.13%) | 150% <0%> (+1%) | :arrow_up: |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.94% <0%> (+0.79%) | 48% <0%> (+2%) | :arrow_up: |\n| ... and 1 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update ce8191b...a682f48. Read the comment docs.\n. # Codecov Report\nMerging #2130 into master will increase coverage by 0.11%.\nThe diff coverage is 80.98%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2130      +/-\n============================================\n+ Coverage     33.57%   33.69%   +0.11%   \n- Complexity     2772     2786      +14   \n============================================\n  Files           418      419       +1   \n  Lines         29782    29779       -3   \n  Branches       3779     3775       -4   \n============================================\n+ Hits           9999    10033      +34   \n+ Misses        18888    18854      -34   \n+ Partials        895      892       -3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...java/azkaban/execapp/ProjectDirectoryMetadata.java | 90.47% <100%> (\u00f8) | 11 <3> (?) | |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 17.52% <20%> (+0.15%) | 5 <0> (\u00f8) | :arrow_down: |\n| ...ommon/src/main/java/azkaban/utils/FileIOUtils.java | 32.25% <33.33%> (-1.69%) | 22 <2> (-2) | |\n| ...er/src/main/java/azkaban/execapp/FlowPreparer.java | 82.07% <82.05%> (+4.36%) | 14 <13> (-1) | :arrow_down: |\n| ...main/java/azkaban/execapp/ProjectCacheCleaner.java | 87.32% <87.32%> (\u00f8) | 15 <15> (?) | |\n| ...kaban-common/src/main/java/azkaban/utils/Pair.java | 46.66% <0%> (-10%) | 8% <0%> (-1%) | |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.94% <0%> (+0.79%) | 48% <0%> (+2%) | :arrow_up: |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.66% <0%> (+1.28%) | 87% <0%> (+2%) | :arrow_up: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 59.52% <0%> (+2.38%) | 13% <0%> (\u00f8) | :arrow_down: |\n| ... and 2 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update e8e531c...06294ee. Read the comment docs.\n. # Codecov Report\nMerging #2131 into master will increase coverage by <.01%.\nThe diff coverage is 0%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2131      +/-\n============================================\n+ Coverage     33.57%   33.58%   +<.01%   \n- Complexity     2772     2774       +2   \n============================================\n  Files           418      418            \n  Lines         29782    29786       +4   \n  Branches       3779     3780       +1   \n============================================\n+ Hits           9999    10003       +4   \n- Misses        18888    18889       +1   \n+ Partials        895      894       -1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../azkaban/webapp/servlet/ProjectManagerServlet.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...java/azkaban/execapp/ConditionalWorkflowUtils.java | 71.42% <0%> (-7.15%) | 11% <0%> (-1%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.44% <0%> (+0.13%) | 150% <0%> (+1%) | :arrow_up: |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.44% <0%> (+1.07%) | 87% <0%> (+2%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update e8e531c...9e72d55. Read the comment docs.\n. # Codecov Report\nMerging #2133 into master will decrease coverage by 0.01%.\nThe diff coverage is 1.29%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2133      +/-\n============================================\n- Coverage     33.71%   33.69%   -0.02%   \n- Complexity     2796     2798       +2   \n============================================\n  Files           420      420            \n  Lines         29809    29834      +25   \n  Branches       3772     3775       +3   \n============================================\n+ Hits          10051    10054       +3   \n- Misses        18864    18887      +23   \n+ Partials        894      893       -1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...main/java/azkaban/executor/JdbcExecutorLoader.java | 19.44% <0%> (-0.56%) | 3 <0> (\u00f8) | |\n| ...c/main/java/azkaban/executor/ExecutionFlowDao.java | 58.22% <0%> (-2.15%) | 15 <0> (\u00f8) | |\n| ...src/main/java/azkaban/execapp/ExecutorServlet.java | 1.62% <0%> (\u00f8) | 2 <0> (\u00f8) | :arrow_down: |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 17.14% <6.25%> (-0.37%) | 5 <0> (\u00f8) | |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.94% <0%> (+0.79%) | 48% <0%> (+2%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update c1f2503...791e0d8. Read the comment docs.\n. # Codecov Report\nMerging #2136 into master will increase coverage by 0.07%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2136      +/-\n============================================\n+ Coverage     33.72%   33.79%   +0.07%   \n- Complexity     2797     2798       +1   \n============================================\n  Files           420      420            \n  Lines         29809    29809            \n  Branches       3772     3772            \n============================================\n+ Hits          10052    10074      +22   \n+ Misses        18863    18839      -24   \n- Partials        894      896       +2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.15% <0%> (-0.8%) | 46% <0%> (-2%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.44% <0%> (+0.13%) | 150% <0%> (+1%) | :arrow_up: |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 71.09% <0%> (+1.07%) | 87% <0%> (+2%) | :arrow_up: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (+18.75%) | 6% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 87b4cb3...1c629a6. Read the comment docs.\n. # Codecov Report\nMerging #2137 into master will increase coverage by 0.11%.\nThe diff coverage is 81.48%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2137      +/-\n============================================\n+ Coverage     33.67%   33.79%   +0.11%   \n- Complexity     2795     2802       +7   \n============================================\n  Files           420      421       +1   \n  Lines         29834    29835       +1   \n  Branches       3775     3774       -1   \n============================================\n+ Hits          10046    10082      +36   \n+ Misses        18893    18856      -37   \n- Partials        895      897       +2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...ver/src/main/java/azkaban/execapp/ExecMetrics.java | 100% <100%> (+58.33%) | 3 <1> (+1) | :arrow_up: |\n| ...er/src/main/java/azkaban/execapp/FlowPreparer.java | 81.81% <100%> (-0.26%) | 14 <1> (\u00f8) | |\n| ...a/azkaban/execapp/metric/ProjectCacheHitRatio.java | 100% <100%> (\u00f8) | 4 <4> (?) | |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 17.73% <42.85%> (+0.58%) | 5 <0> (\u00f8) | :arrow_down: |\n| ...in/java/azkaban/execapp/AzkabanExecutorServer.java | 4.78% <50%> (-0.39%) | 3 <0> (\u00f8) | |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.02% <0%> (+0.64%) | 85% <0%> (\u00f8) | :arrow_down: |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.94% <0%> (+0.79%) | 48% <0%> (+2%) | :arrow_up: |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 59.52% <0%> (+2.38%) | 13% <0%> (\u00f8) | :arrow_down: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (+18.75%) | 6% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update ecc7606...d28b5ab. Read the comment docs.\n. # Codecov Report\nMerging #2138 into master will increase coverage by 0.01%.\nThe diff coverage is 80%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2138      +/-\n============================================\n+ Coverage     33.72%   33.74%   +0.01%   \n- Complexity     2801     2804       +3   \n============================================\n  Files           421      421            \n  Lines         29835    29835            \n  Branches       3774     3774            \n============================================\n+ Hits          10063    10068       +5   \n+ Misses        18877    18875       -2   \n+ Partials        895      892       -3\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...n/src/main/java/azkaban/metrics/CommonMetrics.java | 83.78% <\u00f8> (-0.84%) | 10 <0> (-1) | |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 17.73% <0%> (\u00f8) | 5 <0> (\u00f8) | :arrow_down: |\n| ...ver/src/main/java/azkaban/execapp/ExecMetrics.java | 100% <100%> (\u00f8) | 4 <1> (+1) | :arrow_up: |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 70.87% <0%> (+0.85%) | 87% <0%> (+2%) | :arrow_up: |\n| ...c/main/java/azkaban/execapp/event/FlowWatcher.java | 89.58% <0%> (+2.08%) | 17% <0%> (+1%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 774cfaa...4a94f88. Read the comment docs.\n. # Codecov Report\nMerging #2139 into master will decrease coverage by 0.08%.\nThe diff coverage is 60%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2139      +/-\n============================================\n- Coverage      33.8%   33.72%   -0.09%   \n+ Complexity     2804     2799       -5   \n============================================\n  Files           421      421            \n  Lines         29835    29815      -20   \n  Branches       3774     3772       -2   \n============================================\n- Hits          10086    10055      -31   \n- Misses        18853    18866      +13   \n+ Partials        896      894       -2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...c/main/java/azkaban/executor/ExecutionFlowDao.java | 58.22% <\u00f8> (\u00f8) | 15 <0> (\u00f8) | :arrow_down: |\n| ...n/java/azkaban/webapp/servlet/ExecutorServlet.java | 0% <0%> (\u00f8) | 0 <0> (\u00f8) | :arrow_down: |\n| ...xecutor/utils/process/ProcessFailureException.java | 80% <100%> (+13.33%) | 2 <2> (+1) | :arrow_up: |\n| ...aban/jobExecutor/utils/process/AzkabanProcess.java | 50.96% <100%> (-2.25%) | 11 <0> (\u00f8) | |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 48.95% <0%> (-18.76%) | 6% <0%> (\u00f8) | |\n| ...src/main/java/azkaban/jobExecutor/AbstractJob.java | 31.03% <0%> (-6.9%) | 4% <0%> (-1%) | |\n| ...on/src/main/java/azkaban/utils/CircularBuffer.java | 41.17% <0%> (-5.89%) | 2% <0%> (-1%) | |\n| ...common/src/main/java/azkaban/utils/LogGobbler.java | 53.12% <0%> (-3.13%) | 5% <0%> (-1%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 59.52% <0%> (-1.2%) | 13% <0%> (\u00f8) | |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.15% <0%> (-0.8%) | 46% <0%> (-2%) | |\n| ... and 1 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 3d13a95...5a6e519. Read the comment docs.\n. # Codecov Report\nMerging #2140 into master will decrease coverage by 0.04%.\nThe diff coverage is 100%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2140      +/-\n============================================\n- Coverage      33.8%   33.76%   -0.05%   \n  Complexity     2804     2804            \n============================================\n  Files           421      421            \n  Lines         29835    29831       -4   \n  Branches       3774     3773       -1   \n============================================\n- Hits          10086    10072      -14   \n- Misses        18853    18868      +15   \n+ Partials        896      891       -5\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...rc/main/java/azkaban/executor/ExecutorManager.java | 46.71% <100%> (+0.08%) | 47 <0> (\u00f8) | :arrow_down: |\n| ...c/main/java/azkaban/executor/ExecutionFlowDao.java | 59.91% <100%> (+1.68%) | 17 <0> (+2) | :arrow_up: |\n| ...ain/java/azkaban/executor/ExecutionController.java | 39.31% <100%> (+0.2%) | 29 <0> (\u00f8) | :arrow_down: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 48.95% <0%> (-18.76%) | 6% <0%> (\u00f8) | |\n| ...src/main/java/azkaban/jobExecutor/AbstractJob.java | 31.03% <0%> (-6.9%) | 4% <0%> (-1%) | |\n| ...on/src/main/java/azkaban/utils/CircularBuffer.java | 41.17% <0%> (-5.89%) | 2% <0%> (-1%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 57.14% <0%> (-3.58%) | 13% <0%> (\u00f8) | |\n| ...common/src/main/java/azkaban/utils/LogGobbler.java | 53.12% <0%> (-3.13%) | 5% <0%> (-1%) | |\n| ...aban/jobExecutor/utils/process/AzkabanProcess.java | 50.96% <0%> (-2.25%) | 11% <0%> (\u00f8) | |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.15% <0%> (-0.8%) | 46% <0%> (-2%) | |\n| ... and 11 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 3d13a95...1c88e00. Read the comment docs.\n. # Codecov Report\nMerging #2143 into master will decrease coverage by 0.02%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2143      +/-\n============================================\n- Coverage      33.8%   33.78%   -0.03%   \n+ Complexity     2804     2800       -4   \n============================================\n  Files           421      421            \n  Lines         29835    29835            \n  Branches       3774     3774            \n============================================\n- Hits          10086    10080       -6   \n- Misses        18853    18857       +4   \n- Partials        896      898       +2\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| ...src/main/java/azkaban/jobExecutor/AbstractJob.java | 31.03% <0%> (-6.9%) | 4% <0%> (-1%) | |\n| ...n/java/azkaban/jobExecutor/AbstractProcessJob.java | 59.52% <0%> (-1.2%) | 13% <0%> (\u00f8) | |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.15% <0%> (-0.8%) | 46% <0%> (-2%) | |\n| ...rver/src/main/java/azkaban/execapp/FlowRunner.java | 74.31% <0%> (-0.14%) | 149% <0%> (-1%) | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 3d13a95...e10469e. Read the comment docs.\n. # Codecov Report\nMerging #2144 into master will increase coverage by 0.08%.\nThe diff coverage is 100%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2144      +/-\n============================================\n+ Coverage      33.7%   33.79%   +0.08%   \n- Complexity     2799     2805       +6   \n============================================\n  Files           421      421            \n  Lines         29815    29816       +1   \n  Branches       3772     3772            \n============================================\n+ Hits          10050    10077      +27   \n+ Misses        18871    18845      -26   \n  Partials        894      894\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| .../src/main/java/azkaban/metrics/MetricsManager.java | 56.66% <100%> (+1.49%) | 8 <1> (+1) | :arrow_up: |\n| ...n/src/main/java/azkaban/metrics/CommonMetrics.java | 89.18% <100%> (+5.4%) | 11 <3> (+1) | :arrow_up: |\n| ...erver/src/main/java/azkaban/execapp/JobRunner.java | 69.8% <0%> (+0.42%) | 86% <0%> (+1%) | :arrow_up: |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.94% <0%> (+0.79%) | 48% <0%> (+2%) | :arrow_up: |\n| ...n/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 69.69% <0%> (+3.03%) | 15% <0%> (+1%) | :arrow_up: |\n| ...azkaban/execapp/event/JobCallbackRequestMaker.java | 67.7% <0%> (+18.75%) | 6% <0%> (\u00f8) | :arrow_down: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 2e5d3ab...779c610. Read the comment docs.\n. # Codecov Report\nMerging #2147 into master will increase coverage by 0.03%.\nThe diff coverage is 80.55%.\n\n\n```diff\n@@             Coverage Diff              @@\nmaster    #2147      +/-\n============================================\n+ Coverage      33.7%   33.73%   +0.03%   \n- Complexity     2799     2801       +2   \n============================================\n  Files           421      421            \n  Lines         29815    29826      +11   \n  Branches       3772     3772            \n============================================\n+ Hits          10050    10063      +13   \n+ Misses        18871    18870       -1   \n+ Partials        894      893       -1\n```\n| Impacted Files | Coverage \u0394 | Complexity \u0394 | |\n|---|---|---|---|\n| az-core/src/main/java/azkaban/Constants.java | 25% <\u00f8> (\u00f8) | 1 <0> (\u00f8) | :arrow_down: |\n| ...er/src/main/java/azkaban/execapp/FlowPreparer.java | 82.35% <100%> (+0.53%) | 14 <0> (\u00f8) | :arrow_down: |\n| ...c/main/java/azkaban/execapp/FlowRunnerManager.java | 17.73% <25%> (\u00f8) | 5 <0> (\u00f8) | :arrow_down: |\n| ...main/java/azkaban/execapp/ProjectCacheCleaner.java | 88.6% <84%> (+1.28%) | 15 <4> (\u00f8) | :arrow_down: |\n| az-core/src/main/java/azkaban/utils/Props.java | 61.06% <0%> (\u00f8) | 84% <0%> (\u00f8) | :arrow_down: |\n| ...n/java/azkaban/flowtrigger/FlowTriggerService.java | 54.94% <0%> (+0.79%) | 48% <0%> (+2%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 2e5d3ab...98b9010. Read the comment docs.\n. \n",
    "coveralls": "Pull Request Test Coverage Report for Build 4033\n\n48 of 65 (73.85%)  changed or added relevant lines in 4 files are covered.\n4 unchanged lines in 2 files lost coverage.\nOverall coverage increased (+0.08%) to 36.071%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/executor/mail/DefaultMailCreator.java | 24 | 25 | 96.0%\n| az-reportal/src/main/java/azkaban/viewer/reportal/ReportalMailCreator.java | 0 | 4 | 0.0%\n| azkaban-common/src/main/java/azkaban/executor/ExecutorManager.java | 2 | 14 | 14.29%\n | **Total:** | **48** | **65** | **73.85%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 1 | 72.73% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 76.03% |\n | **Total:** | **4** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4026: |  0.08% |\n| Covered Lines: | 10502 |\n| Relevant Lines: | 29115 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3990\n\n0 of 3 (0.0%)  changed or added relevant lines in 2 files are covered.\n2 unchanged lines in 2 files lost coverage.\nOverall coverage increased (+0.07%) to 36.082%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/HistoryServlet.java | 0 | 1 | 0.0%\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/AbstractAzkabanServlet.java | 0 | 2 | 0.0%\n | **Total:** | **0** | **3** | **0.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 1 | 72.73% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 1 | 77.11% |\n | **Total:** | **2** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3982: |  0.07% |\n| Covered Lines: | 10437 |\n| Relevant Lines: | 28926 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3826\n\n1 of 3 (33.33%)  changed or added relevant lines in 1 file are covered.\n9 unchanged lines in 4 files lost coverage.\nOverall coverage increased (+0.05%) to 35.687%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 1 | 3 | 33.33%\n | **Total:** | **1** | **3** | **33.33%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 1 | 78.13% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 1 | 72.73% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 2 | 77.11% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 5 | 21.63% |\n | **Total:** | **9** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3823: |  0.05% |\n| Covered Lines: | 10115 |\n| Relevant Lines: | 28344 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3816\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n6 unchanged lines in 1 file lost coverage.\nOverall coverage decreased (-0.02%) to 35.696%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 6 | 76.67% |\n | **Total:** | **6** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3815: |  -0.02% |\n| Covered Lines: | 10117 |\n| Relevant Lines: | 28342 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3822\n\n0 of 0   changed or added relevant lines in 0 files are covered.\nNo unchanged relevant lines lost coverage.\nOverall coverage increased (+0.007%) to 35.703%\n\n\n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3821: |  0.007% |\n| Covered Lines: | 10119 |\n| Relevant Lines: | 28342 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3847\n\n20 of 33 (60.61%)  changed or added relevant lines in 4 files are covered.\n533 unchanged lines in 14 files lost coverage.\nOverall coverage increased (+0.1%) to 35.732%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/AzkabanExecutorServer.java | 0 | 2 | 0.0%\n| azkaban-common/src/main/java/azkaban/utils/FileIOUtils.java | 8 | 12 | 66.67%\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowPreparer.java | 9 | 16 | 56.25%\n | **Total:** | **20** | **33** | **60.61%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| az-core/src/main/java/azkaban/Constants.java | 1 | 25.0% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 1 | 78.13% |\n| azkaban-common/src/main/java/azkaban/project/FlowTriggerBean.java | 1 | 91.67% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-common/src/main/java/azkaban/trigger/builtin/BasicTimeChecker.java | 3 | 83.7% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 76.46% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutionReference.java | 4 | 68.18% |\n| azkaban-common/src/main/java/azkaban/executor/FetchActiveFlowDao.java | 5 | 86.84% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutorApiGateway.java | 12 | 28.95% |\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/FlowTriggerServlet.java | 20 | 0.0% |\n | **Total:** | **533** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3823: |  0.1% |\n| Covered Lines: | 10143 |\n| Relevant Lines: | 28386 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3832\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n9 unchanged lines in 2 files lost coverage.\nOverall coverage decreased (-0.02%) to 35.595%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 7 | 76.24% |\n | **Total:** | **9** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3830: |  -0.02% |\n| Covered Lines: | 10090 |\n| Relevant Lines: | 28347 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3833\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n4 unchanged lines in 1 file lost coverage.\nOverall coverage decreased (-0.01%) to 35.605%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 4 | 76.67% |\n | **Total:** | **4** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3830: |  -0.01% |\n| Covered Lines: | 10093 |\n| Relevant Lines: | 28347 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3851\n\n113 of 120 (94.17%)  changed or added relevant lines in 7 files are covered.\n542 unchanged lines in 13 files lost coverage.\nOverall coverage increased (+0.3%) to 35.931%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/flow/ConditionOnJobStatus.java | 15 | 16 | 93.75%\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 38 | 40 | 95.0%\n| azkaban-common/src/main/java/azkaban/executor/ExecutableNode.java | 8 | 10 | 80.0%\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunner.java | 28 | 30 | 93.33%\n | **Total:** | **113** | **120** | **94.17%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ProjectVersion.java | 1 | 95.24% |\n| azkaban-common/src/main/java/azkaban/project/FlowTriggerBean.java | 1 | 91.67% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutionReference.java | 4 | 68.18% |\n| azkaban-common/src/main/java/azkaban/executor/FetchActiveFlowDao.java | 5 | 86.84% |\n| az-core/src/main/java/azkaban/Constants.java | 5 | 25.0% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutorApiGateway.java | 12 | 28.95% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowPreparer.java | 14 | 78.48% |\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/FlowTriggerServlet.java | 20 | 0.0% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutorManager.java | 86 | 48.63% |\n | **Total:** | **542** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3834: |  0.3% |\n| Covered Lines: | 10235 |\n| Relevant Lines: | 28485 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3842\n\n19 of 26 (73.08%)  changed or added relevant lines in 5 files are covered.\nNo unchanged relevant lines lost coverage.\nOverall coverage increased (+0.01%) to 35.689%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/FlowTriggerServlet.java | 0 | 7 | 0.0%\n | **Total:** | **19** | **26** | **73.08%** | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3834: |  0.01% |\n| Covered Lines: | 10120 |\n| Relevant Lines: | 28356 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3841\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n2 unchanged lines in 2 files lost coverage.\nOverall coverage remained the same at 35.679%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/FlowWatcher.java | 1 | 93.75% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutableFlowBase.java | 1 | 80.42% |\n | **Total:** | **2** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3834: |  0.0% |\n| Covered Lines: | 10114 |\n| Relevant Lines: | 28347 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3844\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n5 unchanged lines in 2 files lost coverage.\nOverall coverage increased (+0.004%) to 35.676%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 76.67% |\n | **Total:** | **5** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3843: |  0.004% |\n| Covered Lines: | 10113 |\n| Relevant Lines: | 28347 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3858\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n399 unchanged lines in 9 files lost coverage.\nOverall coverage increased (+0.3%) to 35.872%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ProjectVersion.java | 1 | 95.24% |\n| azkaban-common/src/main/java/azkaban/project/DirectoryYamlFlowLoader.java | 2 | 97.92% |\n| az-core/src/main/java/azkaban/Constants.java | 5 | 25.0% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowPreparer.java | 14 | 78.48% |\n| azkaban-common/src/main/java/azkaban/flow/Node.java | 15 | 66.67% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutableNode.java | 40 | 80.52% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/AzkabanExecutorServer.java | 98 | 5.38% |\n| azkaban-common/src/main/java/azkaban/utils/FileIOUtils.java | 103 | 37.32% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunner.java | 121 | 80.21% |\n | **Total:** | **399** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3846: |  0.3% |\n| Covered Lines: | 10218 |\n| Relevant Lines: | 28485 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3860\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n13 unchanged lines in 4 files lost coverage.\nOverall coverage increased (+0.03%) to 35.914%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 1 | 72.73% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 1 | 90.0% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 9 | 76.03% |\n | **Total:** | **13** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3853: |  0.03% |\n| Covered Lines: | 10230 |\n| Relevant Lines: | 28485 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3856\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n7 unchanged lines in 2 files lost coverage.\nOverall coverage decreased (-0.01%) to 35.875%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 1 | 72.73% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 6 | 77.11% |\n | **Total:** | **7** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3853: |  -0.01% |\n| Covered Lines: | 10219 |\n| Relevant Lines: | 28485 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3868\n\n3 of 3 (100.0%)  changed or added relevant lines in 1 file are covered.\n10 unchanged lines in 2 files lost coverage.\nOverall coverage increased (+0.06%) to 35.943%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 8 | 76.24% |\n | **Total:** | **10** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3853: |  0.06% |\n| Covered Lines: | 10239 |\n| Relevant Lines: | 28487 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3876\n\n0 of 1 (0.0%)  changed or added relevant line in 1 file are covered.\nNo unchanged relevant lines lost coverage.\nOverall coverage increased (+0.01%) to 35.707%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/executor/ExecutorManager.java | 0 | 1 | 0.0%\n | **Total:** | **0** | **1** | **0.0%** | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3875: |  0.01% |\n| Covered Lines: | 10240 |\n| Relevant Lines: | 28678 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3877\n\n2 of 2 (100.0%)  changed or added relevant lines in 1 file are covered.\n21 unchanged lines in 1 file lost coverage.\nOverall coverage decreased (-0.07%) to 35.629%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 21 | 57.29% |\n | **Total:** | **21** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3875: |  -0.07% |\n| Covered Lines: | 10218 |\n| Relevant Lines: | 28679 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3879\n\n2 of 2 (100.0%)  changed or added relevant lines in 1 file are covered.\n1 unchanged line in 1 file lost coverage.\nOverall coverage increased (+0.09%) to 35.737%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 1 | 78.13% |\n | **Total:** | **1** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3878: |  0.09% |\n| Covered Lines: | 10249 |\n| Relevant Lines: | 28679 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3883\n\n17 of 17 (100.0%)  changed or added relevant lines in 1 file are covered.\n4 unchanged lines in 2 files lost coverage.\nOverall coverage increased (+0.1%) to 35.865%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 1 | 78.13% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 3 | 63.1% |\n | **Total:** | **4** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3882: |  0.1% |\n| Covered Lines: | 10312 |\n| Relevant Lines: | 28752 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3887\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n22 unchanged lines in 2 files lost coverage.\nOverall coverage decreased (-0.07%) to 35.757%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 1 | 76.67% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 21 | 57.29% |\n | **Total:** | **22** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3884: |  -0.07% |\n| Covered Lines: | 10275 |\n| Relevant Lines: | 28736 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3889\n\n26 of 35 (74.29%)  changed or added relevant lines in 4 files are covered.\n23 unchanged lines in 2 files lost coverage.\nOverall coverage decreased (-0.01%) to 35.812%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/executor/JdbcExecutorLoader.java | 0 | 1 | 0.0%\n| azkaban-common/src/main/java/azkaban/executor/ExecutionFlowDao.java | 3 | 5 | 60.0%\n| azkaban-common/src/main/java/azkaban/utils/Emailer.java | 4 | 10 | 40.0%\n | **Total:** | **26** | **35** | **74.29%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 2 | 76.89% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 21 | 56.25% |\n | **Total:** | **23** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3888: |  -0.01% |\n| Covered Lines: | 10303 |\n| Relevant Lines: | 28770 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3891\n\n13 of 18 (72.22%)  changed or added relevant lines in 4 files are covered.\n8 unchanged lines in 5 files lost coverage.\nOverall coverage increased (+0.007%) to 35.891%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/executor/ExecutableNode.java | 6 | 7 | 85.71%\n| azkaban-common/src/main/java/azkaban/jobExecutor/Job.java | 0 | 1 | 0.0%\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunner.java | 5 | 8 | 62.5%\n | **Total:** | **13** | **18** | **72.22%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/FlowWatcher.java | 1 | 93.75% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutableFlowBase.java | 1 | 80.42% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunner.java | 1 | 80.32% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 2 | 76.94% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 3 | 66.67% |\n | **Total:** | **8** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3890: |  0.007% |\n| Covered Lines: | 10327 |\n| Relevant Lines: | 28773 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3896\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n4 unchanged lines in 2 files lost coverage.\nOverall coverage decreased (-0.01%) to 35.871%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 64.29% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 2 | 76.67% |\n | **Total:** | **4** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3890: |  -0.01% |\n| Covered Lines: | 10320 |\n| Relevant Lines: | 28770 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3898\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n1 unchanged line in 1 file lost coverage.\nOverall coverage increased (+0.02%) to 35.909%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 1 | 92.5% |\n | **Total:** | **1** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3897: |  0.02% |\n| Covered Lines: | 10331 |\n| Relevant Lines: | 28770 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3899\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n6 unchanged lines in 4 files lost coverage.\nOverall coverage decreased (-0.01%) to 35.874%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/FlowWatcher.java | 1 | 93.75% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutableFlowBase.java | 1 | 80.42% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 2 | 90.0% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 64.29% |\n | **Total:** | **6** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3897: |  -0.01% |\n| Covered Lines: | 10321 |\n| Relevant Lines: | 28770 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3900\n\n1 of 1 (100.0%)  changed or added relevant line in 1 file are covered.\n5 unchanged lines in 3 files lost coverage.\nOverall coverage decreased (-0.02%) to 35.867%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 1 | 92.5% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 64.29% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 2 | 76.67% |\n | **Total:** | **5** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3897: |  -0.02% |\n| Covered Lines: | 10319 |\n| Relevant Lines: | 28770 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3925\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n648 unchanged lines in 9 files lost coverage.\nOverall coverage increased (+0.1%) to 35.991%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 64.29% |\n| azkaban-common/src/main/java/azkaban/trigger/builtin/BasicTimeChecker.java | 2 | 84.44% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowPreparer.java | 16 | 80.99% |\n| az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/HadoopJavaJob.java | 22 | 0.0% |\n| az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/HadoopHiveJob.java | 52 | 0.0% |\n| az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/HadoopJobUtils.java | 60 | 49.47% |\n| az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/HadoopPigJob.java | 72 | 0.0% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 162 | 22.72% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutorManager.java | 260 | 48.85% |\n | **Total:** | **648** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3897: |  0.1% |\n| Covered Lines: | 10408 |\n| Relevant Lines: | 28918 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3904\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n1 unchanged line in 1 file lost coverage.\nOverall coverage increased (+0.003%) to 35.881%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 1 | 92.5% |\n | **Total:** | **1** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3903: |  0.003% |\n| Covered Lines: | 10323 |\n| Relevant Lines: | 28770 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3917\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n1 unchanged line in 1 file lost coverage.\nOverall coverage increased (+0.007%) to 35.885%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 1 | 92.5% |\n | **Total:** | **1** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3915: |  0.007% |\n| Covered Lines: | 10324 |\n| Relevant Lines: | 28770 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3918\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n24 unchanged lines in 3 files lost coverage.\nOverall coverage decreased (-0.06%) to 35.815%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 1 | 92.5% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 64.29% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 21 | 56.25% |\n | **Total:** | **24** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3915: |  -0.06% |\n| Covered Lines: | 10304 |\n| Relevant Lines: | 28770 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3923\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n26 unchanged lines in 5 files lost coverage.\nOverall coverage decreased (-0.09%) to 35.794%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/executor/ExecutableFlowBase.java | 1 | 80.42% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/FlowWatcher.java | 1 | 93.75% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 1 | 90.0% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 2 | 77.11% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 21 | 56.25% |\n | **Total:** | **26** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3919: |  -0.09% |\n| Covered Lines: | 10298 |\n| Relevant Lines: | 28770 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4082\n\n406 of 789 (51.46%)  changed or added relevant lines in 43 files are covered.\n41 unchanged lines in 13 files lost coverage.\nOverall coverage increased (+0.6%) to 36.432%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/HadoopTuningConfigurationInjector.java | 5 | 6 | 83.33%\n| az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/pig/PigCommonConstants.java | 0 | 1 | 0.0%\n| az-reportal/src/main/java/azkaban/jobtype/ReportalTeradataRunner.java | 0 | 1 | 0.0%\n| az-reportal/src/main/java/azkaban/viewer/reportal/ReportalServlet.java | 0 | 1 | 0.0%\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/HistoryServlet.java | 0 | 1 | 0.0%\n| az-crypto/src/main/java/azkaban/crypto/Crypto.java | 24 | 26 | 92.31%\n| az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/HadoopConfigurationInjector.java | 5 | 7 | 71.43%\n| az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/tuning/TuningException.java | 0 | 2 | 0.0%\n| az-reportal/src/main/java/azkaban/viewer/reportal/ReportalType.java | 0 | 2 | 0.0%\n| azkaban-common/src/main/java/azkaban/executor/mail/DefaultMailCreator.java | 25 | 27 | 92.59%\n | **Total:** | **406** | **789** | **51.46%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/HadoopPigJob.java | 1 | 0.0% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/FlowWatcher.java | 1 | 93.75% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/AzkabanExecutorServer.java | 1 | 5.29% |\n| azkaban-common/src/main/java/azkaban/project/DirectoryYamlFlowLoader.java | 1 | 96.24% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutableFlowBase.java | 1 | 80.42% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 1 | 92.86% |\n| az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/HadoopSecurePigWrapper.java | 1 | 0.0% |\n| az-reportal/src/main/java/azkaban/viewer/reportal/ReportalType.java | 1 | 0.0% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunner.java | 1 | 80.59% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutorManager.java | 2 | 51.46% |\n | **Total:** | **41** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3945: |  0.6% |\n| Covered Lines: | 10692 |\n| Relevant Lines: | 29348 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3928\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n6 unchanged lines in 3 files lost coverage.\nOverall coverage decreased (-0.003%) to 35.881%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 1 | 92.5% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 64.29% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 77.54% |\n | **Total:** | **6** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3924: |  -0.003% |\n| Covered Lines: | 10323 |\n| Relevant Lines: | 28770 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3929\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n4 unchanged lines in 2 files lost coverage.\nOverall coverage increased (+0.003%) to 35.888%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 1 | 92.5% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 77.54% |\n | **Total:** | **4** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3924: |  0.003% |\n| Covered Lines: | 10325 |\n| Relevant Lines: | 28770 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3949\n\n6 of 15 (40.0%)  changed or added relevant lines in 4 files are covered.\n203 unchanged lines in 6 files lost coverage.\nOverall coverage decreased (-0.07%) to 35.811%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/HadoopHiveJob.java | 0 | 3 | 0.0%\n| az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/HadoopJavaJob.java | 0 | 3 | 0.0%\n| az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/HadoopPigJob.java | 0 | 3 | 0.0%\n | **Total:** | **6** | **15** | **40.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/executor/ExecutableFlowBase.java | 1 | 80.42% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/FlowWatcher.java | 1 | 93.75% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 67.86% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowPreparer.java | 16 | 80.99% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 21 | 56.25% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 162 | 22.72% |\n | **Total:** | **203** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3933: |  -0.07% |\n| Covered Lines: | 10310 |\n| Relevant Lines: | 28790 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3936\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n2 unchanged lines in 1 file lost coverage.\nOverall coverage decreased (-0.007%) to 35.871%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 2 | 90.0% |\n | **Total:** | **2** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3933: |  -0.007% |\n| Covered Lines: | 10320 |\n| Relevant Lines: | 28770 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3939\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n3 unchanged lines in 2 files lost coverage.\nOverall coverage decreased (-0.001%) to 35.873%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 1 | 92.5% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 64.29% |\n | **Total:** | **3** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3938: |  -0.001% |\n| Covered Lines: | 10320 |\n| Relevant Lines: | 28768 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3940\n\n5 of 5 (100.0%)  changed or added relevant lines in 1 file are covered.\n24 unchanged lines in 3 files lost coverage.\nOverall coverage decreased (-0.06%) to 35.817%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 1 | 92.5% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 2 | 76.89% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 21 | 56.25% |\n | **Total:** | **24** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3938: |  -0.06% |\n| Covered Lines: | 10306 |\n| Relevant Lines: | 28774 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3944\n\n5 of 17 (29.41%)  changed or added relevant lines in 2 files are covered.\n3 unchanged lines in 2 files lost coverage.\nOverall coverage increased (+0.01%) to 35.885%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowPreparer.java | 5 | 7 | 71.43%\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 0 | 10 | 0.0%\n | **Total:** | **5** | **17** | **29.41%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 1 | 22.72% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 2 | 77.54% |\n | **Total:** | **3** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3938: |  0.01% |\n| Covered Lines: | 10326 |\n| Relevant Lines: | 28775 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3947\n\n10 of 18 (55.56%)  changed or added relevant lines in 3 files are covered.\n4 unchanged lines in 2 files lost coverage.\nOverall coverage increased (+0.002%) to 35.877%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/AzkabanExecutorServer.java | 0 | 4 | 0.0%\n| azkaban-solo-server/src/main/java/azkaban/soloserver/AzkabanSingleServer.java | 0 | 4 | 0.0%\n | **Total:** | **10** | **18** | **55.56%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/AzkabanExecutorServer.java | 1 | 5.29% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 3 | 63.1% |\n | **Total:** | **4** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3945: |  0.002% |\n| Covered Lines: | 10328 |\n| Relevant Lines: | 28787 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3954\n\n0 of 0   changed or added relevant lines in 0 files are covered.\nNo unchanged relevant lines lost coverage.\nOverall coverage increased (+0.003%) to 35.87%\n\n\n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3952: |  0.003% |\n| Covered Lines: | 10327 |\n| Relevant Lines: | 28790 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3955\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n3 unchanged lines in 3 files lost coverage.\nOverall coverage increased (+0.01%) to 35.881%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/FlowWatcher.java | 1 | 93.75% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutableFlowBase.java | 1 | 80.42% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 1 | 92.5% |\n | **Total:** | **3** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3952: |  0.01% |\n| Covered Lines: | 10330 |\n| Relevant Lines: | 28790 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3962\n\n2 of 4 (50.0%)  changed or added relevant lines in 2 files are covered.\n264 unchanged lines in 4 files lost coverage.\nOverall coverage increased (+0.2%) to 36.005%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| az-crypto/src/main/java/azkaban/crypto/Decryptions.java | 0 | 2 | 0.0%\n | **Total:** | **2** | **4** | **50.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 1 | 78.13% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 1 | 92.5% |\n| azkaban-common/src/main/java/azkaban/trigger/builtin/BasicTimeChecker.java | 2 | 84.44% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutorManager.java | 260 | 48.85% |\n | **Total:** | **264** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3957: |  0.2% |\n| Covered Lines: | 10412 |\n| Relevant Lines: | 28918 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4002\n\n57 of 59 (96.61%)  changed or added relevant lines in 1 file are covered.\n267 unchanged lines in 8 files lost coverage.\nOverall coverage increased (+0.2%) to 36.148%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/project/DirectoryYamlFlowLoader.java | 57 | 59 | 96.61%\n | **Total:** | **57** | **59** | **96.61%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/project/DirectoryYamlFlowLoader.java | 1 | 96.48% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 3 | 63.1% |\n| azkaban-common/src/main/java/azkaban/project/CronSchedule.java | 4 | 50.0% |\n| az-core/src/main/java/azkaban/Constants.java | 4 | 25.0% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutorManager.java | 6 | 51.57% |\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/ProjectManagerServlet.java | 63 | 0.0% |\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/AbstractAzkabanServlet.java | 66 | 7.63% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunner.java | 120 | 80.4% |\n | **Total:** | **267** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3965: |  0.2% |\n| Covered Lines: | 10472 |\n| Relevant Lines: | 28970 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3969\n\n7 of 9 (77.78%)  changed or added relevant lines in 1 file are covered.\n22 unchanged lines in 2 files lost coverage.\nOverall coverage increased (+0.05%) to 36.021%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/executor/ExecutorManager.java | 7 | 9 | 77.78%\n | **Total:** | **7** | **9** | **77.78%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 1 | 92.5% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 21 | 56.25% |\n | **Total:** | **22** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3965: |  0.05% |\n| Covered Lines: | 10423 |\n| Relevant Lines: | 28936 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4046\n\n28 of 35 (80.0%)  changed or added relevant lines in 1 file are covered.\n7 unchanged lines in 2 files lost coverage.\nOverall coverage decreased (-0.03%) to 36.063%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/executor/ExecutorManager.java | 28 | 35 | 80.0%\n | **Total:** | **28** | **35** | **80.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 5 | 76.03% |\n | **Total:** | **7** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4040: |  -0.03% |\n| Covered Lines: | 10500 |\n| Relevant Lines: | 29116 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3983\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n189 unchanged lines in 3 files lost coverage.\nOverall coverage increased (+0.09%) to 36.063%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/executor/ExecutorManager.java | 6 | 51.57% |\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/ProjectManagerServlet.java | 63 | 0.0% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunner.java | 120 | 80.46% |\n | **Total:** | **189** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3965: |  0.09% |\n| Covered Lines: | 10431 |\n| Relevant Lines: | 28924 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3974\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n4 unchanged lines in 2 files lost coverage.\nOverall coverage decreased (-0.01%) to 35.961%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunner.java | 1 | 80.46% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 3 | 63.1% |\n | **Total:** | **4** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3965: |  -0.01% |\n| Covered Lines: | 10398 |\n| Relevant Lines: | 28915 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3981\n\n3 of 3 (100.0%)  changed or added relevant lines in 2 files are covered.\n76 unchanged lines in 5 files lost coverage.\nOverall coverage increased (+0.06%) to 36.035%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 1 | 92.86% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 76.03% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 3 | 60.71% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutorManager.java | 6 | 51.57% |\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/ProjectManagerServlet.java | 63 | 0.0% |\n | **Total:** | **76** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3965: |  0.06% |\n| Covered Lines: | 10423 |\n| Relevant Lines: | 28925 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3984\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n3 unchanged lines in 3 files lost coverage.\nOverall coverage increased (+0.07%) to 36.074%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 1 | 72.73% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 1 | 92.5% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 1 | 76.89% |\n | **Total:** | **3** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3982: |  0.07% |\n| Covered Lines: | 10434 |\n| Relevant Lines: | 28924 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3988\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n2 unchanged lines in 2 files lost coverage.\nOverall coverage increased (+0.07%) to 36.081%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 1 | 72.73% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 1 | 77.11% |\n | **Total:** | **2** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3982: |  0.07% |\n| Covered Lines: | 10436 |\n| Relevant Lines: | 28924 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4001\n\n16 of 70 (22.86%)  changed or added relevant lines in 5 files are covered.\n4 unchanged lines in 3 files lost coverage.\nOverall coverage increased (+0.07%) to 36.079%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| az-reportal/src/main/java/azkaban/viewer/reportal/ReportalType.java | 0 | 2 | 0.0%\n| az-reportal/src/main/java/azkaban/reportal/util/tableau/Result.java | 0 | 6 | 0.0%\n| az-reportal/src/main/java/azkaban/reportal/util/tableau/URLResponse.java | 6 | 20 | 30.0%\n| az-reportal/src/main/java/azkaban/jobtype/ReportalTableauRunner.java | 4 | 36 | 11.11%\n | **Total:** | **16** | **70** | **22.86%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 1 | 72.73% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 1 | 92.5% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 2 | 76.67% |\n | **Total:** | **4** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4000: |  0.07% |\n| Covered Lines: | 10461 |\n| Relevant Lines: | 28995 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 3993\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n3 unchanged lines in 2 files lost coverage.\nOverall coverage remained the same at 36.074%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 1 | 92.5% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 64.29% |\n | **Total:** | **3** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 3989: |  0.0% |\n| Covered Lines: | 10434 |\n| Relevant Lines: | 28924 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4014\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n26 unchanged lines in 2 files lost coverage.\nOverall coverage decreased (-0.08%) to 36.028%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 4 | 76.46% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 22 | 56.25% |\n | **Total:** | **26** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4006: |  -0.08% |\n| Covered Lines: | 10457 |\n| Relevant Lines: | 29025 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4025\n\n0 of 2 (0.0%)  changed or added relevant lines in 1 file are covered.\nNo unchanged relevant lines lost coverage.\nOverall coverage increased (+0.004%) to 35.983%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/AbstractAzkabanServlet.java | 0 | 2 | 0.0%\n | **Total:** | **0** | **2** | **0.0%** | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4022: |  0.004% |\n| Covered Lines: | 10457 |\n| Relevant Lines: | 29061 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4034\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n2 unchanged lines in 2 files lost coverage.\nOverall coverage increased (+0.01%) to 36.0%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 1 | 72.73% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 1 | 77.11% |\n | **Total:** | **2** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4026: |  0.01% |\n| Covered Lines: | 10462 |\n| Relevant Lines: | 29061 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4077\n\n11 of 22 (50.0%)  changed or added relevant lines in 3 files are covered.\n4 unchanged lines in 3 files lost coverage.\nOverall coverage increased (+0.007%) to 36.092%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/executor/mail/DefaultMailCreator.java | 1 | 2 | 50.0%\n| az-reportal/src/main/java/azkaban/viewer/reportal/ReportalMailCreator.java | 0 | 3 | 0.0%\n| azkaban-common/src/main/java/azkaban/executor/ExecutorManager.java | 10 | 17 | 58.82%\n | **Total:** | **11** | **22** | **50.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 1 | 72.73% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 1 | 77.11% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutorManager.java | 2 | 51.46% |\n | **Total:** | **4** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4076: |  0.007% |\n| Covered Lines: | 10514 |\n| Relevant Lines: | 29131 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4038\n\n0 of 0   changed or added relevant lines in 0 files are covered.\nNo unchanged relevant lines lost coverage.\nOverall coverage remained the same at 36.064%\n\n\n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4036: |  0.0% |\n| Covered Lines: | 10500 |\n| Relevant Lines: | 29115 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4043\n\n0 of 2 (0.0%)  changed or added relevant lines in 1 file are covered.\n11 unchanged lines in 3 files lost coverage.\nOverall coverage decreased (-0.03%) to 36.068%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-hadoop-security-plugin/src/main/java/azkaban/security/HadoopSecurityManager_H_2_0.java | 0 | 2 | 0.0%\n | **Total:** | **0** | **2** | **0.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-hadoop-security-plugin/src/main/java/azkaban/security/HadoopSecurityManager_H_2_0.java | 4 | 0.0% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 5 | 76.03% |\n | **Total:** | **11** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4040: |  -0.03% |\n| Covered Lines: | 10502 |\n| Relevant Lines: | 29117 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4055\n\n0 of 3 (0.0%)  changed or added relevant lines in 1 file are covered.\n69 unchanged lines in 4 files lost coverage.\nOverall coverage decreased (-0.02%) to 36.08%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/ProjectManagerServlet.java | 0 | 3 | 0.0%\n | **Total:** | **0** | **3** | **0.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/ProjectManagerServlet.java | 1 | 0.0% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 2 | 76.89% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutorManager.java | 26 | 51.24% |\n| azkaban-hadoop-security-plugin/src/main/java/azkaban/security/HadoopSecurityManager_H_2_0.java | 40 | 0.0% |\n | **Total:** | **69** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4040: |  -0.02% |\n| Covered Lines: | 10506 |\n| Relevant Lines: | 29119 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4115\n\n27 of 31 (87.1%)  changed or added relevant lines in 1 file are covered.\n8 unchanged lines in 3 files lost coverage.\nOverall coverage decreased (-0.0006%) to 36.162%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/executor/ExecutorManager.java | 27 | 31 | 87.1%\n | **Total:** | **27** | **31** | **87.1%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/executor/ExecutorManager.java | 1 | 48.53% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 5 | 76.03% |\n | **Total:** | **8** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4109: |  -0.0006% |\n| Covered Lines: | 10554 |\n| Relevant Lines: | 29185 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4051\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n7 unchanged lines in 3 files lost coverage.\nOverall coverage decreased (-0.02%) to 36.063%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 1 | 72.73% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 4 | 76.03% |\n | **Total:** | **7** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4048: |  -0.02% |\n| Covered Lines: | 10500 |\n| Relevant Lines: | 29116 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4052\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n4 unchanged lines in 4 files lost coverage.\nOverall coverage decreased (-0.01%) to 36.073%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 1 | 72.73% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/FlowWatcher.java | 1 | 93.75% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutableFlowBase.java | 1 | 80.42% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 1 | 76.67% |\n | **Total:** | **4** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4048: |  -0.01% |\n| Covered Lines: | 10503 |\n| Relevant Lines: | 29116 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4058\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n22 unchanged lines in 1 file lost coverage.\nOverall coverage decreased (-0.08%) to 36.004%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 22 | 56.25% |\n | **Total:** | **22** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4060: |  -0.08% |\n| Covered Lines: | 10484 |\n| Relevant Lines: | 29119 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4063\n\n33 of 40 (82.5%)  changed or added relevant lines in 4 files are covered.\nNo unchanged relevant lines lost coverage.\nOverall coverage increased (+0.08%) to 36.075%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/flow/Flow.java | 11 | 13 | 84.62%\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/ProjectManagerServlet.java | 0 | 5 | 0.0%\n | **Total:** | **33** | **40** | **82.5%** | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4061: |  0.08% |\n| Covered Lines: | 10508 |\n| Relevant Lines: | 29128 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4065\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n1 unchanged line in 1 file lost coverage.\nOverall coverage increased (+0.07%) to 36.066%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 1 | 89.29% |\n | **Total:** | **1** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4061: |  0.07% |\n| Covered Lines: | 10502 |\n| Relevant Lines: | 29119 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4069\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n7 unchanged lines in 2 files lost coverage.\nOverall coverage decreased (-0.02%) to 36.063%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 5 | 76.03% |\n | **Total:** | **7** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4067: |  -0.02% |\n| Covered Lines: | 10504 |\n| Relevant Lines: | 29127 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4091\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n602 unchanged lines in 6 files lost coverage.\nOverall coverage decreased (-0.02%) to 36.066%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 5 | 76.03% |\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/ExecutorServlet.java | 30 | 0.0% |\n| az-reportal/src/main/java/azkaban/viewer/reportal/ReportalMailCreator.java | 66 | 0.0% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutorManager.java | 244 | 51.46% |\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/ProjectManagerServlet.java | 255 | 0.0% |\n | **Total:** | **602** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4067: |  -0.02% |\n| Covered Lines: | 10507 |\n| Relevant Lines: | 29133 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4073\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n2 unchanged lines in 1 file lost coverage.\nOverall coverage decreased (-0.007%) to 36.079%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 2 | 76.67% |\n | **Total:** | **2** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4067: |  -0.007% |\n| Covered Lines: | 10509 |\n| Relevant Lines: | 29128 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4086\n\n0 of 3 (0.0%)  changed or added relevant lines in 2 files are covered.\n8 unchanged lines in 5 files lost coverage.\nOverall coverage decreased (-0.03%) to 36.076%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/ExecutorServlet.java | 0 | 1 | 0.0%\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/ProjectManagerServlet.java | 0 | 2 | 0.0%\n | **Total:** | **0** | **3** | **0.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 1 | 72.73% |\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/ExecutorServlet.java | 1 | 0.0% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 1 | 76.67% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractJob.java | 2 | 31.03% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 3 | 63.1% |\n | **Total:** | **8** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4078: |  -0.03% |\n| Covered Lines: | 10510 |\n| Relevant Lines: | 29133 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4112\n\n4 of 18 (22.22%)  changed or added relevant lines in 1 file are covered.\n23 unchanged lines in 2 files lost coverage.\nOverall coverage decreased (-0.09%) to 36.072%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 4 | 18 | 22.22%\n | **Total:** | **4** | **18** | **22.22%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 2 | 76.67% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 21 | 56.25% |\n | **Total:** | **23** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4109: |  -0.09% |\n| Covered Lines: | 10524 |\n| Relevant Lines: | 29175 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4114\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n80 unchanged lines in 6 files lost coverage.\nOverall coverage decreased (-0.3%) to 35.889%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-web-server/src/main/java/azkaban/flowtrigger/DependencyInstance.java | 2 | 92.31% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 2 | 76.67% |\n| azkaban-web-server/src/main/java/azkaban/flowtrigger/FlowTriggerExecutionCleaner.java | 3 | 80.0% |\n| azkaban-web-server/src/main/java/azkaban/flowtrigger/TriggerInstanceProcessor.java | 3 | 89.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 21 | 56.25% |\n| azkaban-web-server/src/main/java/azkaban/flowtrigger/FlowTriggerService.java | 49 | 60.47% |\n | **Total:** | **80** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4109: |  -0.3% |\n| Covered Lines: | 10472 |\n| Relevant Lines: | 29179 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4135\n\n0 of 1 (0.0%)  changed or added relevant line in 1 file are covered.\n5 unchanged lines in 2 files lost coverage.\nOverall coverage decreased (-0.01%) to 35.962%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/project/JdbcProjectImpl.java | 0 | 1 | 0.0%\n | **Total:** | **0** | **1** | **0.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 76.46% |\n | **Total:** | **5** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4131: |  -0.01% |\n| Covered Lines: | 10494 |\n| Relevant Lines: | 29181 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4134\n\n0 of 1 (0.0%)  changed or added relevant line in 1 file are covered.\n7 unchanged lines in 2 files lost coverage.\nOverall coverage decreased (-0.02%) to 35.955%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/project/JdbcProjectImpl.java | 0 | 1 | 0.0%\n | **Total:** | **0** | **1** | **0.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 5 | 76.03% |\n | **Total:** | **7** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4131: |  -0.02% |\n| Covered Lines: | 10492 |\n| Relevant Lines: | 29181 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4136\n\n0 of 26 (0.0%)  changed or added relevant lines in 4 files are covered.\n4 unchanged lines in 3 files lost coverage.\nOverall coverage decreased (-0.02%) to 35.95%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/executor/ConnectorParams.java | 0 | 4 | 0.0%\n| azkaban-common/src/main/java/azkaban/executor/ExecutorResponseErrorException.java | 0 | 7 | 0.0%\n| azkaban-exec-server/src/main/java/azkaban/execapp/ExecutorServlet.java | 0 | 7 | 0.0%\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 0 | 8 | 0.0%\n | **Total:** | **0** | **26** | **0.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 1 | 89.29% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 1 | 21.8% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 2 | 76.67% |\n | **Total:** | **4** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4131: |  -0.02% |\n| Covered Lines: | 10496 |\n| Relevant Lines: | 29196 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4137\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n2 unchanged lines in 1 file lost coverage.\nOverall coverage remained the same at 35.972%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 2 | 76.67% |\n | **Total:** | **2** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4131: |  0.0% |\n| Covered Lines: | 10497 |\n| Relevant Lines: | 29181 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4174\n\n4 of 8 (50.0%)  changed or added relevant lines in 2 files are covered.\n771 unchanged lines in 16 files lost coverage.\nOverall coverage increased (+0.03%) to 36.195%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/project/JdbcProjectImpl.java | 3 | 7 | 42.86%\n | **Total:** | **4** | **8** | **50.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 1 | 78.13% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutableFlowBase.java | 1 | 87.93% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutionFlowDao.java | 1 | 65.57% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 76.46% |\n| azkaban-common/src/main/java/azkaban/executor/JdbcExecutorLoader.java | 4 | 21.21% |\n| az-core/src/main/java/azkaban/Constants.java | 5 | 25.0% |\n| azkaban-common/src/main/java/azkaban/flow/Node.java | 15 | 67.02% |\n| az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/HadoopPigJob.java | 25 | 0.0% |\n| azkaban-solo-server/src/main/java/azkaban/soloserver/AzkabanSingleServer.java | 25 | 10.64% |\n | **Total:** | **771** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4138: |  0.03% |\n| Covered Lines: | 10540 |\n| Relevant Lines: | 29120 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4306\n\n60 of 65 (92.31%)  changed or added relevant lines in 6 files are covered.\n1 unchanged line in 1 file lost coverage.\nOverall coverage increased (+0.2%) to 36.468%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/executor/JdbcExecutorLoader.java | 0 | 1 | 0.0%\n| azkaban-common/src/main/java/azkaban/project/ProjectManager.java | 0 | 1 | 0.0%\n| azkaban-common/src/main/java/azkaban/executor/FetchActiveFlowDao.java | 42 | 45 | 93.33%\n | **Total:** | **60** | **65** | **92.31%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-web-server/src/main/java/azkaban/flowtrigger/FlowTriggerService.java | 1 | 60.08% |\n | **Total:** | **1** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4288: |  0.2% |\n| Covered Lines: | 10764 |\n| Relevant Lines: | 29516 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4144\n\n8 of 8 (100.0%)  changed or added relevant lines in 1 file are covered.\nNo unchanged relevant lines lost coverage.\nOverall coverage increased (+0.03%) to 36.17%\n\n\n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4141: |  0.03% |\n| Covered Lines: | 10545 |\n| Relevant Lines: | 29154 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4148\n\n0 of 9 (0.0%)  changed or added relevant lines in 2 files are covered.\n1 unchanged line in 1 file lost coverage.\nOverall coverage remained the same at 36.169%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/trigger/builtin/ExecuteFlowAction.java | 0 | 3 | 0.0%\n| azkaban-common/src/main/java/azkaban/trigger/TriggerManager.java | 0 | 6 | 0.0%\n | **Total:** | **0** | **9** | **0.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/trigger/builtin/ExecuteFlowAction.java | 1 | 49.0% |\n | **Total:** | **1** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4147: |  0.0% |\n| Covered Lines: | 10539 |\n| Relevant Lines: | 29138 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4151\n\n0 of 6 (0.0%)  changed or added relevant lines in 1 file are covered.\n6 unchanged lines in 5 files lost coverage.\nOverall coverage decreased (-0.02%) to 36.155%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-solo-server/src/main/java/azkaban/soloserver/AzkabanSingleServer.java | 0 | 6 | 0.0%\n | **Total:** | **0** | **6** | **0.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 1 | 78.13% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutableFlowBase.java | 1 | 87.36% |\n| azkaban-solo-server/src/main/java/azkaban/soloserver/AzkabanSingleServer.java | 1 | 11.36% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/FlowWatcher.java | 1 | 93.75% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 2 | 76.03% |\n | **Total:** | **6** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4150: |  -0.02% |\n| Covered Lines: | 10537 |\n| Relevant Lines: | 29144 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4152\n\n2 of 19 (10.53%)  changed or added relevant lines in 5 files are covered.\n5 unchanged lines in 4 files lost coverage.\nOverall coverage decreased (-0.02%) to 36.164%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/AzkabanExecutorServer.java | 0 | 2 | 0.0%\n| azkaban-exec-server/src/main/java/azkaban/execapp/ExecutorServlet.java | 0 | 2 | 0.0%\n| azkaban-solo-server/src/main/java/azkaban/soloserver/AzkabanSingleServer.java | 0 | 3 | 0.0%\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 0 | 10 | 0.0%\n | **Total:** | **2** | **19** | **10.53%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 1 | 78.13% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ExecutorServlet.java | 1 | 1.63% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/AzkabanExecutorServer.java | 1 | 5.24% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 2 | 76.03% |\n | **Total:** | **5** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4150: |  -0.02% |\n| Covered Lines: | 10539 |\n| Relevant Lines: | 29142 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4167\n\n0 of 14 (0.0%)  changed or added relevant lines in 1 file are covered.\n106 unchanged lines in 3 files lost coverage.\nOverall coverage decreased (-0.008%) to 36.166%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/HadoopPigJob.java | 0 | 14 | 0.0%\n | **Total:** | **0** | **14** | **0.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/executor/ExecutableFlowBase.java | 1 | 87.36% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/FlowWatcher.java | 1 | 93.75% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/AzkabanExecutorServer.java | 104 | 5.17% |\n | **Total:** | **106** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4156: |  -0.008% |\n| Covered Lines: | 10543 |\n| Relevant Lines: | 29152 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4159\n\n0 of 6 (0.0%)  changed or added relevant lines in 1 file are covered.\n7 unchanged lines in 3 files lost coverage.\nOverall coverage decreased (-0.01%) to 36.16%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/AzkabanExecutorServer.java | 0 | 6 | 0.0%\n | **Total:** | **0** | **6** | **0.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/AzkabanExecutorServer.java | 2 | 5.17% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 76.46% |\n | **Total:** | **7** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4156: |  -0.01% |\n| Covered Lines: | 10541 |\n| Relevant Lines: | 29151 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4162\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n10 unchanged lines in 3 files lost coverage.\nOverall coverage increased (+0.05%) to 36.17%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractJob.java | 2 | 31.03% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 76.89% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 5 | 60.71% |\n | **Total:** | **10** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4160: |  0.05% |\n| Covered Lines: | 10544 |\n| Relevant Lines: | 29151 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4164\n\n0 of 1 (0.0%)  changed or added relevant line in 1 file are covered.\n10 unchanged lines in 3 files lost coverage.\nOverall coverage increased (+0.04%) to 36.153%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/utils/Emailer.java | 0 | 1 | 0.0%\n | **Total:** | **0** | **1** | **0.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractJob.java | 2 | 31.03% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 76.03% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 5 | 60.71% |\n | **Total:** | **10** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4160: |  0.04% |\n| Covered Lines: | 10539 |\n| Relevant Lines: | 29151 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4180\n\n19 of 19 (100.0%)  changed or added relevant lines in 1 file are covered.\n6 unchanged lines in 3 files lost coverage.\nOverall coverage increased (+0.01%) to 36.223%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 1 | 72.73% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 76.67% |\n | **Total:** | **6** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4175: |  0.01% |\n| Covered Lines: | 10552 |\n| Relevant Lines: | 29131 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4192\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n23 unchanged lines in 2 files lost coverage.\nOverall coverage decreased (-0.06%) to 36.151%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 2 | 76.89% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 21 | 56.25% |\n | **Total:** | **23** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4189: |  -0.06% |\n| Covered Lines: | 10532 |\n| Relevant Lines: | 29133 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4194\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n279 unchanged lines in 4 files lost coverage.\nOverall coverage increased (+0.1%) to 36.312%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ProjectVersion.java | 2 | 92.59% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowPreparer.java | 26 | 82.47% |\n| azkaban-common/src/main/java/azkaban/utils/FileIOUtils.java | 84 | 39.35% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 167 | 22.67% |\n | **Total:** | **279** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4193: |  0.1% |\n| Covered Lines: | 10581 |\n| Relevant Lines: | 29139 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4197\n\n0 of 97 (0.0%)  changed or added relevant lines in 1 file are covered.\n1 unchanged line in 1 file lost coverage.\nOverall coverage decreased (-0.01%) to 36.319%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-hadoop-security-plugin/src/main/java/azkaban/security/HadoopSecurityManager_H_2_0.java | 0 | 97 | 0.0%\n | **Total:** | **0** | **97** | **0.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-hadoop-security-plugin/src/main/java/azkaban/security/HadoopSecurityManager_H_2_0.java | 1 | 0.0% |\n | **Total:** | **1** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4195: |  -0.01% |\n| Covered Lines: | 10586 |\n| Relevant Lines: | 29147 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4199\n\n0 of 17 (0.0%)  changed or added relevant lines in 1 file are covered.\n5 unchanged lines in 1 file lost coverage.\nOverall coverage increased (+0.01%) to 36.325%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-hadoop-security-plugin/src/main/java/azkaban/security/HadoopSecurityManager_H_2_0.java | 0 | 17 | 0.0%\n | **Total:** | **0** | **17** | **0.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-hadoop-security-plugin/src/main/java/azkaban/security/HadoopSecurityManager_H_2_0.java | 5 | 0.0% |\n | **Total:** | **5** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4198: |  0.01% |\n| Covered Lines: | 10588 |\n| Relevant Lines: | 29148 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4202\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n7 unchanged lines in 4 files lost coverage.\nOverall coverage increased (+0.04%) to 36.287%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 1 | 56.25% |\n| azkaban-hadoop-security-plugin/src/main/java/azkaban/security/HadoopSecurityManager_H_2_0.java | 1 | 0.0% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 76.89% |\n | **Total:** | **7** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4201: |  0.04% |\n| Covered Lines: | 10564 |\n| Relevant Lines: | 29112 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4203\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n6 unchanged lines in 3 files lost coverage.\nOverall coverage increased (+0.05%) to 36.301%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 1 | 78.13% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 76.03% |\n | **Total:** | **6** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4201: |  0.05% |\n| Covered Lines: | 10581 |\n| Relevant Lines: | 29148 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4206\n\n11 of 17 (64.71%)  changed or added relevant lines in 2 files are covered.\n160 unchanged lines in 2 files lost coverage.\nOverall coverage decreased (-0.01%) to 36.238%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowPreparer.java | 8 | 14 | 57.14%\n | **Total:** | **11** | **17** | **64.71%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 1 | 56.25% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 159 | 22.08% |\n | **Total:** | **160** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4201: |  -0.01% |\n| Covered Lines: | 10570 |\n| Relevant Lines: | 29168 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4227\n\n10 of 15 (66.67%)  changed or added relevant lines in 3 files are covered.\n515 unchanged lines in 18 files lost coverage.\nOverall coverage decreased (-0.004%) to 36.347%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 0 | 1 | 0.0%\n| azkaban-exec-server/src/main/java/azkaban/execapp/ExecMetrics.java | 0 | 2 | 0.0%\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowPreparer.java | 10 | 12 | 83.33%\n | **Total:** | **10** | **15** | **66.67%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/HadoopPigJob.java | 1 | 0.0% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutableFlowBase.java | 1 | 87.36% |\n| az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/HadoopShell.java | 1 | 0.0% |\n| az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/HadoopJavaJob.java | 1 | 0.0% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/FlowWatcher.java | 1 | 93.75% |\n| azkaban-web-server/src/main/java/azkaban/flowtrigger/FlowTriggerService.java | 1 | 60.08% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackManager.java | 1 | 5.26% |\n| az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/HadoopSparkJob.java | 1 | 0.0% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ExecMetrics.java | 1 | 41.67% |\n| azkaban-common/src/main/java/azkaban/executor/FetchActiveFlowDao.java | 2 | 90.24% |\n | **Total:** | **515** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4208: |  -0.004% |\n| Covered Lines: | 10606 |\n| Relevant Lines: | 29180 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4211\n\n5 of 5 (100.0%)  changed or added relevant lines in 1 file are covered.\nNo unchanged relevant lines lost coverage.\nOverall coverage increased (+0.04%) to 36.389%\n\n\n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4208: |  0.04% |\n| Covered Lines: | 10586 |\n| Relevant Lines: | 29091 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4220\n\n2 of 2 (100.0%)  changed or added relevant lines in 1 file are covered.\n1 unchanged line in 1 file lost coverage.\nOverall coverage decreased (-0.001%) to 36.421%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-web-server/src/main/java/azkaban/flowtrigger/FlowTriggerService.java | 1 | 60.08% |\n | **Total:** | **1** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4219: |  -0.001% |\n| Covered Lines: | 10595 |\n| Relevant Lines: | 29090 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4310\n\n17 of 17 (100.0%)  changed or added relevant lines in 1 file are covered.\n1183 unchanged lines in 27 files lost coverage.\nOverall coverage increased (+0.02%) to 36.447%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-web-server/src/main/java/azkaban/flowtrigger/FlowTriggerService.java | 1 | 60.08% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ExecMetrics.java | 2 | 41.67% |\n| az-core/src/main/java/azkaban/Constants.java | 4 | 25.0% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutionFinalizer.java | 4 | 88.24% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 5 | 76.99% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutableJobInfo.java | 9 | 61.22% |\n| azkaban-web-server/src/main/java/azkaban/webapp/AzkabanWebServerModule.java | 9 | 83.64% |\n| azkaban-common/src/main/java/azkaban/executor/RunningExecutionsUpdater.java | 9 | 86.13% |\n| azkaban-common/src/main/java/azkaban/utils/CircularBuffer.java | 10 | 0.0% |\n | **Total:** | **1183** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4219: |  0.02% |\n| Covered Lines: | 10764 |\n| Relevant Lines: | 29533 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4230\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n2 unchanged lines in 1 file lost coverage.\nOverall coverage increased (+0.07%) to 36.34%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 2 | 76.13% |\n | **Total:** | **2** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4228: |  0.07% |\n| Covered Lines: | 10604 |\n| Relevant Lines: | 29180 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4232\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n2 unchanged lines in 1 file lost coverage.\nOverall coverage increased (+0.07%) to 36.343%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 2 | 76.13% |\n | **Total:** | **2** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4228: |  0.07% |\n| Covered Lines: | 10605 |\n| Relevant Lines: | 29180 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4235\n\n3 of 12 (25.0%)  changed or added relevant lines in 8 files are covered.\n3 unchanged lines in 2 files lost coverage.\nOverall coverage increased (+0.08%) to 36.35%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| az-jobsummary/src/main/java/azkaban/viewer/jobsummary/JobSummaryServlet.java | 0 | 1 | 0.0%\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/ExecutorServlet.java | 0 | 1 | 0.0%\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/HistoryServlet.java | 0 | 1 | 0.0%\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/JMXHttpServlet.java | 0 | 1 | 0.0%\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/ProjectManagerServlet.java | 0 | 1 | 0.0%\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/StatsServlet.java | 0 | 1 | 0.0%\n| az-reportal/src/main/java/azkaban/viewer/reportal/ReportalServlet.java | 0 | 3 | 0.0%\n | **Total:** | **3** | **12** | **25.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-web-server/src/main/java/azkaban/flowtrigger/FlowTriggerService.java | 1 | 60.08% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 2 | 76.99% |\n | **Total:** | **3** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4228: |  0.08% |\n| Covered Lines: | 10607 |\n| Relevant Lines: | 29180 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4250\n\n0 of 13 (0.0%)  changed or added relevant lines in 1 file are covered.\n6 unchanged lines in 2 files lost coverage.\nOverall coverage decreased (-0.02%) to 36.346%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/ProjectManagerServlet.java | 0 | 13 | 0.0%\n | **Total:** | **0** | **13** | **0.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/ProjectManagerServlet.java | 3 | 0.0% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 76.77% |\n | **Total:** | **6** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4249: |  -0.02% |\n| Covered Lines: | 10610 |\n| Relevant Lines: | 29192 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4251\n\n95 of 207 (45.89%)  changed or added relevant lines in 4 files are covered.\n29 unchanged lines in 3 files lost coverage.\nOverall coverage increased (+0.1%) to 36.435%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/executor/JdbcExecutorLoader.java | 0 | 2 | 0.0%\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/StatsServlet.java | 0 | 2 | 0.0%\n| azkaban-common/src/main/java/azkaban/executor/FetchActiveFlowDao.java | 42 | 48 | 87.5%\n| azkaban-common/src/main/java/azkaban/executor/ExecutionController.java | 53 | 155 | 34.19%\n | **Total:** | **95** | **207** | **45.89%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/executor/JdbcExecutorLoader.java | 1 | 20.59% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutionController.java | 2 | 29.11% |\n| azkaban-common/src/main/java/azkaban/jobtype/JobTypeManager.java | 26 | 71.43% |\n | **Total:** | **29** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4236: |  0.1% |\n| Covered Lines: | 10695 |\n| Relevant Lines: | 29354 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4252\n\n9 of 9 (100.0%)  changed or added relevant lines in 1 file are covered.\n218 unchanged lines in 6 files lost coverage.\nOverall coverage decreased (-0.01%) to 36.354%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 76.77% |\n| azkaban-common/src/main/java/azkaban/executor/FetchActiveFlowDao.java | 8 | 87.5% |\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/StatsServlet.java | 10 | 0.0% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 21 | 56.25% |\n| azkaban-common/src/main/java/azkaban/executor/JdbcExecutorLoader.java | 39 | 20.59% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutionController.java | 137 | 29.11% |\n | **Total:** | **218** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4249: |  -0.01% |\n| Covered Lines: | 10672 |\n| Relevant Lines: | 29356 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4259\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n21 unchanged lines in 1 file lost coverage.\nOverall coverage decreased (-0.04%) to 36.379%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 21 | 56.25% |\n | **Total:** | **21** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4256: |  -0.04% |\n| Covered Lines: | 10678 |\n| Relevant Lines: | 29352 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4266\n\n54 of 100 (54.0%)  changed or added relevant lines in 4 files are covered.\n7 unchanged lines in 2 files lost coverage.\nOverall coverage increased (+0.06%) to 36.484%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/executor/JdbcExecutorLoader.java | 0 | 1 | 0.0%\n| azkaban-common/src/main/java/azkaban/executor/ExecutionFlowDao.java | 19 | 22 | 86.36%\n| azkaban-common/src/main/java/azkaban/executor/ExecutionController.java | 31 | 37 | 83.78%\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 4 | 40 | 10.0%\n | **Total:** | **54** | **100** | **54.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/executor/ExecutionFinalizer.java | 1 | 62.79% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutorManager.java | 6 | 51.41% |\n | **Total:** | **7** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4256: |  0.06% |\n| Covered Lines: | 10743 |\n| Relevant Lines: | 29446 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4268\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n320 unchanged lines in 7 files lost coverage.\nOverall coverage increased (+0.04%) to 36.392%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/executor/ExecutionFinalizer.java | 1 | 62.79% |\n| azkaban-common/src/main/java/azkaban/executor/JdbcExecutorLoader.java | 1 | 20.29% |\n| az-core/src/main/java/azkaban/Constants.java | 4 | 25.0% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutorManager.java | 6 | 51.41% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutionFlowDao.java | 10 | 67.8% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutionController.java | 99 | 36.84% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 199 | 20.33% |\n | **Total:** | **320** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4261: |  0.04% |\n| Covered Lines: | 10716 |\n| Relevant Lines: | 29446 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4264\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n7 unchanged lines in 2 files lost coverage.\nOverall coverage increased (+0.05%) to 36.396%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/executor/ExecutionFinalizer.java | 1 | 62.79% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutorManager.java | 6 | 51.41% |\n | **Total:** | **7** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4261: |  0.05% |\n| Covered Lines: | 10683 |\n| Relevant Lines: | 29352 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4269\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n1 unchanged line in 1 file lost coverage.\nOverall coverage increased (+0.01%) to 36.463%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-web-server/src/main/java/azkaban/flowtrigger/FlowTriggerService.java | 1 | 60.08% |\n | **Total:** | **1** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4267: |  0.01% |\n| Covered Lines: | 10737 |\n| Relevant Lines: | 29446 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4270\n\n62 of 101 (61.39%)  changed or added relevant lines in 4 files are covered.\n1 unchanged line in 1 file lost coverage.\nOverall coverage increased (+0.04%) to 36.494%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/executor/ExecutionController.java | 14 | 16 | 87.5%\n| azkaban-common/src/main/java/azkaban/executor/selector/ExecutionControllerUtils.java | 41 | 78 | 52.56%\n | **Total:** | **62** | **101** | **61.39%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-web-server/src/main/java/azkaban/flowtrigger/FlowTriggerService.java | 1 | 60.08% |\n | **Total:** | **1** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4267: |  0.04% |\n| Covered Lines: | 10760 |\n| Relevant Lines: | 29484 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4274\n\n11 of 25 (44.0%)  changed or added relevant lines in 2 files are covered.\n31 unchanged lines in 3 files lost coverage.\nOverall coverage decreased (-0.03%) to 36.393%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/jobExecutor/utils/process/AzkabanProcess.java | 10 | 24 | 41.67%\n | **Total:** | **11** | **25** | **44.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ConditionalWorkflowUtils.java | 1 | 89.29% |\n| azkaban-common/src/main/java/azkaban/utils/CircularBuffer.java | 10 | 0.0% |\n| azkaban-common/src/main/java/azkaban/utils/LogGobbler.java | 20 | 0.0% |\n | **Total:** | **31** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4273: |  -0.03% |\n| Covered Lines: | 10724 |\n| Relevant Lines: | 29467 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4284\n\n1 of 1 (100.0%)  changed or added relevant line in 1 file are covered.\n363 unchanged lines in 6 files lost coverage.\nOverall coverage increased (+0.07%) to 36.501%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-web-server/src/main/java/azkaban/flowtrigger/FlowTriggerService.java | 1 | 60.08% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutionFinalizer.java | 2 | 88.24% |\n| azkaban-common/src/main/java/azkaban/executor/RunningExecutionsUpdater.java | 9 | 86.13% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutionController.java | 68 | 40.08% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunner.java | 107 | 80.42% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 176 | 20.52% |\n | **Total:** | **363** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4273: |  0.07% |\n| Covered Lines: | 10764 |\n| Relevant Lines: | 29490 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4277\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n1 unchanged line in 1 file lost coverage.\nOverall coverage increased (+0.07%) to 36.494%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-web-server/src/main/java/azkaban/flowtrigger/FlowTriggerService.java | 1 | 60.08% |\n | **Total:** | **1** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4273: |  0.07% |\n| Covered Lines: | 10760 |\n| Relevant Lines: | 29484 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4279\n\n3 of 5 (60.0%)  changed or added relevant lines in 2 files are covered.\n5 unchanged lines in 2 files lost coverage.\nOverall coverage decreased (-0.01%) to 36.427%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunner.java | 2 | 4 | 50.0%\n | **Total:** | **3** | **5** | **60.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 76.13% |\n | **Total:** | **5** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4278: |  -0.01% |\n| Covered Lines: | 10742 |\n| Relevant Lines: | 29489 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4281\n\n1 of 1 (100.0%)  changed or added relevant line in 1 file are covered.\nNo unchanged relevant lines lost coverage.\nOverall coverage remained the same at 36.498%\n\n\n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4280: |  0.0% |\n| Covered Lines: | 10763 |\n| Relevant Lines: | 29489 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4283\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n6 unchanged lines in 3 files lost coverage.\nOverall coverage decreased (-0.02%) to 36.498%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-web-server/src/main/java/azkaban/flowtrigger/FlowTriggerService.java | 1 | 60.08% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 76.13% |\n | **Total:** | **6** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4282: |  -0.02% |\n| Covered Lines: | 10763 |\n| Relevant Lines: | 29489 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4285\n\n0 of 2 (0.0%)  changed or added relevant lines in 1 file are covered.\n7 unchanged lines in 4 files lost coverage.\nOverall coverage decreased (-0.009%) to 36.509%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 0 | 2 | 0.0%\n | **Total:** | **0** | **2** | **0.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 1 | 20.42% |\n| azkaban-web-server/src/main/java/azkaban/flowtrigger/FlowTriggerService.java | 1 | 60.08% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 76.99% |\n | **Total:** | **7** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4282: |  -0.009% |\n| Covered Lines: | 10767 |\n| Relevant Lines: | 29491 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4309\n\n18 of 36 (50.0%)  changed or added relevant lines in 3 files are covered.\n270 unchanged lines in 7 files lost coverage.\nOverall coverage increased (+0.2%) to 36.493%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-web-server/src/main/java/azkaban/webapp/AzkabanWebServer.java | 1 | 6 | 16.67%\n| azkaban-common/src/main/java/azkaban/executor/ExecutionController.java | 17 | 23 | 73.91%\n| azkaban-common/src/main/java/azkaban/jmx/JmxExecutionController.java | 0 | 7 | 0.0%\n | **Total:** | **18** | **36** | **50.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-web-server/src/main/java/azkaban/flowtrigger/FlowTriggerService.java | 1 | 60.08% |\n| azkaban-common/src/main/java/azkaban/executor/FetchActiveFlowDao.java | 11 | 88.17% |\n| azkaban-common/src/main/java/azkaban/project/AzkabanProjectLoader.java | 15 | 86.73% |\n| azkaban-common/src/main/java/azkaban/executor/JdbcExecutorLoader.java | 25 | 20.0% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutionFlowDao.java | 35 | 67.96% |\n| azkaban-common/src/main/java/azkaban/project/JdbcProjectImpl.java | 87 | 67.34% |\n| azkaban-common/src/main/java/azkaban/project/ProjectManager.java | 96 | 17.89% |\n | **Total:** | **270** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4288: |  0.2% |\n| Covered Lines: | 10777 |\n| Relevant Lines: | 29532 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4308\n\n70 of 90 (77.78%)  changed or added relevant lines in 1 file are covered.\n275 unchanged lines in 9 files lost coverage.\nOverall coverage increased (+0.3%) to 36.594%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/JdbcSqlJob.java | 70 | 90 | 77.78%\n | **Total:** | **70** | **90** | **77.78%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/javautils/Whitelist.java | 1 | 78.13% |\n| azkaban-web-server/src/main/java/azkaban/flowtrigger/FlowTriggerService.java | 1 | 60.08% |\n| az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/HadoopJobUtils.java | 4 | 35.26% |\n| azkaban-common/src/main/java/azkaban/executor/FetchActiveFlowDao.java | 11 | 88.17% |\n| azkaban-common/src/main/java/azkaban/project/AzkabanProjectLoader.java | 15 | 86.73% |\n| azkaban-common/src/main/java/azkaban/executor/JdbcExecutorLoader.java | 25 | 20.0% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutionFlowDao.java | 35 | 67.96% |\n| azkaban-common/src/main/java/azkaban/project/JdbcProjectImpl.java | 87 | 67.34% |\n| azkaban-common/src/main/java/azkaban/project/ProjectManager.java | 96 | 17.89% |\n | **Total:** | **275** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4288: |  0.3% |\n| Covered Lines: | 10834 |\n| Relevant Lines: | 29606 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4311\n\n78 of 94 (82.98%)  changed or added relevant lines in 2 files are covered.\n4 unchanged lines in 1 file lost coverage.\nOverall coverage increased (+0.2%) to 36.646%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/user/AzkabanIniRealm.java | 18 | 22 | 81.82%\n| azkaban-common/src/main/java/azkaban/user/ShiroUserManager.java | 60 | 72 | 83.33%\n | **Total:** | **78** | **94** | **82.98%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 4 | 76.13% |\n | **Total:** | **4** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4307: |  0.2% |\n| Covered Lines: | 10851 |\n| Relevant Lines: | 29610 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4312\n\n22 of 42 (52.38%)  changed or added relevant lines in 2 files are covered.\n5 unchanged lines in 2 files lost coverage.\nOverall coverage increased (+0.2%) to 36.603%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/jobExecutor/utils/process/ProcessFailureException.java | 4 | 6 | 66.67%\n| azkaban-common/src/main/java/azkaban/jobExecutor/utils/process/AzkabanProcess.java | 18 | 36 | 50.0%\n | **Total:** | **22** | **42** | **52.38%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/jobExecutor/utils/process/AzkabanProcess.java | 1 | 58.72% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 4 | 76.77% |\n | **Total:** | **5** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4307: |  0.2% |\n| Covered Lines: | 10810 |\n| Relevant Lines: | 29533 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4319\n\n67 of 90 (74.44%)  changed or added relevant lines in 5 files are covered.\n16 unchanged lines in 5 files lost coverage.\nOverall coverage increased (+0.1%) to 36.752%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/ExecutorServlet.java | 0 | 1 | 0.0%\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 0 | 1 | 0.0%\n| azkaban-web-server/src/main/java/azkaban/webapp/AzkabanWebServer.java | 0 | 1 | 0.0%\n| azkaban-common/src/main/java/azkaban/executor/ExecutionController.java | 4 | 11 | 36.36%\n| azkaban-common/src/main/java/azkaban/executor/ExecutorHealthChecker.java | 63 | 76 | 82.89%\n | **Total:** | **67** | **90** | **74.44%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 1 | 72.73% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutableFlowBase.java | 1 | 87.36% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/FlowWatcher.java | 1 | 93.75% |\n| azkaban-web-server/src/main/java/azkaban/webapp/AzkabanWebServer.java | 1 | 16.48% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutionController.java | 12 | 41.4% |\n | **Total:** | **16** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4314: |  0.1% |\n| Covered Lines: | 10889 |\n| Relevant Lines: | 29628 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4322\n\n1 of 107 (0.93%)  changed or added relevant lines in 10 files are covered.\n7 unchanged lines in 4 files lost coverage.\nOverall coverage decreased (-0.1%) to 36.482%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/executor/ExecutionController.java | 1 | 2 | 50.0%\n| azkaban-common/src/main/java/azkaban/jmx/JmxExecutorManager.java | 0 | 1 | 0.0%\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunner.java | 0 | 4 | 0.0%\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 0 | 4 | 0.0%\n| azkaban-exec-server/src/main/java/azkaban/execapp/metric/NumFinishedFlowMetric.java | 0 | 9 | 0.0%\n| azkaban-exec-server/src/main/java/azkaban/execapp/metric/NumFinishedJobMetric.java | 0 | 9 | 0.0%\n| azkaban-exec-server/src/main/java/azkaban/execapp/metric/NumSucceededJobMetric.java | 0 | 10 | 0.0%\n| azkaban-exec-server/src/main/java/azkaban/execapp/metric/NumSucceededFlowMetric.java | 0 | 11 | 0.0%\n| azkaban-exec-server/src/main/java/azkaban/execapp/AzkabanExecutorServer.java | 0 | 16 | 0.0%\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/ExecutorServlet.java | 0 | 41 | 0.0%\n | **Total:** | **1** | **107** | **0.93%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 1 | 72.73% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/AzkabanExecutorServer.java | 1 | 4.84% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 76.13% |\n | **Total:** | **7** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4314: |  -0.1% |\n| Covered Lines: | 10818 |\n| Relevant Lines: | 29653 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4323\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n1 unchanged line in 1 file lost coverage.\nOverall coverage decreased (-0.003%) to 36.627%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 1 | 72.73% |\n | **Total:** | **1** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4314: |  -0.003% |\n| Covered Lines: | 10823 |\n| Relevant Lines: | 29549 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4328\n\n21 of 32 (65.63%)  changed or added relevant lines in 4 files are covered.\n5 unchanged lines in 2 files lost coverage.\nOverall coverage increased (+0.1%) to 36.764%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/executor/RunningExecutionsUpdater.java | 0 | 1 | 0.0%\n| azkaban-common/src/main/java/azkaban/executor/ExecutionControllerUtils.java | 9 | 19 | 47.37%\n | **Total:** | **21** | **32** | **65.63%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 76.13% |\n | **Total:** | **5** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4324: |  0.1% |\n| Covered Lines: | 10896 |\n| Relevant Lines: | 29638 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4331\n\n17 of 25 (68.0%)  changed or added relevant lines in 3 files are covered.\n2 unchanged lines in 1 file lost coverage.\nOverall coverage increased (+0.1%) to 36.823%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/project/FlowLoaderUtils.java | 4 | 6 | 66.67%\n| azkaban-common/src/main/java/azkaban/jobExecutor/JavaProcessJob.java | 0 | 6 | 0.0%\n | **Total:** | **17** | **25** | **68.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 2 | 76.87% |\n | **Total:** | **2** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4330: |  0.1% |\n| Covered Lines: | 10917 |\n| Relevant Lines: | 29647 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4332\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n3 unchanged lines in 2 files lost coverage.\nOverall coverage increased (+0.07%) to 36.768%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-web-server/src/main/java/azkaban/flowtrigger/FlowTriggerService.java | 1 | 60.08% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 2 | 76.23% |\n | **Total:** | **3** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4330: |  0.07% |\n| Covered Lines: | 10898 |\n| Relevant Lines: | 29640 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4334\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n3 unchanged lines in 1 file lost coverage.\nOverall coverage decreased (-0.003%) to 36.768%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 76.23% |\n | **Total:** | **3** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4333: |  -0.003% |\n| Covered Lines: | 10898 |\n| Relevant Lines: | 29640 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4335\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n3 unchanged lines in 1 file lost coverage.\nOverall coverage decreased (-0.003%) to 36.768%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 76.23% |\n | **Total:** | **3** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4333: |  -0.003% |\n| Covered Lines: | 10898 |\n| Relevant Lines: | 29640 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4337\n\n0 of 0   changed or added relevant lines in 0 files are covered.\nNo unchanged relevant lines lost coverage.\nOverall coverage increased (+0.02%) to 36.785%\n\n\n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4336: |  0.02% |\n| Covered Lines: | 10903 |\n| Relevant Lines: | 29640 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4338\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n21 unchanged lines in 1 file lost coverage.\nOverall coverage decreased (-0.03%) to 36.738%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 21 | 56.25% |\n | **Total:** | **21** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4336: |  -0.03% |\n| Covered Lines: | 10889 |\n| Relevant Lines: | 29640 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4341\n\n1 of 1 (100.0%)  changed or added relevant line in 1 file are covered.\n2 unchanged lines in 1 file lost coverage.\nOverall coverage increased (+0.06%) to 36.778%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n | **Total:** | **2** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4340: |  0.06% |\n| Covered Lines: | 10901 |\n| Relevant Lines: | 29640 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4342\n\n0 of 0   changed or added relevant lines in 0 files are covered.\nNo unchanged relevant lines lost coverage.\nOverall coverage increased (+0.07%) to 36.785%\n\n\n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4340: |  0.07% |\n| Covered Lines: | 10903 |\n| Relevant Lines: | 29640 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4390\n\n177 of 462 (38.31%)  changed or added relevant lines in 19 files are covered.\n36 unchanged lines in 13 files lost coverage.\nOverall coverage increased (+0.5%) to 37.31%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| az-reportal/src/main/java/azkaban/reportal/util/Reportal.java | 0 | 1 | 0.0%\n| azkaban-common/src/main/java/azkaban/scheduler/TriggerBasedScheduleLoader.java | 0 | 1 | 0.0%\n| azkaban-common/src/main/java/azkaban/trigger/builtin/ExecuteFlowAction.java | 5 | 6 | 83.33%\n| azkaban-common/src/main/java/azkaban/sla/SlaType.java | 17 | 19 | 89.47%\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 0 | 2 | 0.0%\n| azkaban-common/src/main/java/azkaban/server/HttpRequestUtils.java | 0 | 3 | 0.0%\n| azkaban-common/src/main/java/azkaban/executor/DisabledJob.java | 36 | 40 | 90.0%\n| azkaban-common/src/main/java/azkaban/utils/Emailer.java | 0 | 4 | 0.0%\n| azkaban-common/src/main/java/azkaban/flow/FlowUtils.java | 1 | 7 | 14.29%\n| azkaban-common/src/main/java/azkaban/trigger/builtin/SlaAlertAction.java | 0 | 7 | 0.0%\n | **Total:** | **177** | **462** | **38.31%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-common/src/main/java/azkaban/server/HttpRequestUtils.java | 1 | 18.75% |\n| azkaban-common/src/main/java/azkaban/executor/ExecutableFlowBase.java | 1 | 87.36% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/TriggerManager.java | 1 | 17.65% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/FlowWatcher.java | 1 | 93.75% |\n| azkaban-common/src/main/java/azkaban/trigger/builtin/SlaChecker.java | 1 | 0.0% |\n| azkaban-common/src/main/java/azkaban/scheduler/Schedule.java | 1 | 0.0% |\n| azkaban-common/src/main/java/azkaban/scheduler/ScheduleManager.java | 2 | 11.59% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 2 | 60.71% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/JavaProcessJob.java | 2 | 57.97% |\n| azkaban-common/src/main/java/azkaban/trigger/builtin/SlaAlertAction.java | 3 | 0.0% |\n | **Total:** | **36** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4382: |  0.5% |\n| Covered Lines: | 11095 |\n| Relevant Lines: | 29737 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4348\n\n0 of 25 (0.0%)  changed or added relevant lines in 1 file are covered.\n27 unchanged lines in 3 files lost coverage.\nOverall coverage decreased (-0.04%) to 36.74%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/ProjectManagerServlet.java | 0 | 25 | 0.0%\n | **Total:** | **0** | **25** | **0.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/ProjectManagerServlet.java | 2 | 0.0% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 4 | 76.87% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 21 | 56.25% |\n | **Total:** | **27** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4343: |  -0.04% |\n| Covered Lines: | 10882 |\n| Relevant Lines: | 29619 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4346\n\n4 of 7 (57.14%)  changed or added relevant lines in 1 file are covered.\n21 unchanged lines in 1 file lost coverage.\nOverall coverage decreased (-0.07%) to 36.714%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowPreparer.java | 4 | 7 | 57.14%\n | **Total:** | **4** | **7** | **57.14%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 21 | 56.25% |\n | **Total:** | **21** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4343: |  -0.07% |\n| Covered Lines: | 10884 |\n| Relevant Lines: | 29645 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4369\n\n15 of 18 (83.33%)  changed or added relevant lines in 3 files are covered.\n12 unchanged lines in 4 files lost coverage.\nOverall coverage increased (+0.06%) to 36.893%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/executor/ExecutionFlowDao.java | 15 | 16 | 93.75%\n| azkaban-common/src/main/java/azkaban/executor/JdbcExecutorLoader.java | 0 | 1 | 0.0%\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 0 | 1 | 0.0%\n | **Total:** | **15** | **18** | **83.33%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/jmx/JmxJobMBeanManager.java | 1 | 72.73% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractJob.java | 2 | 31.03% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 4 | 76.23% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 5 | 60.71% |\n | **Total:** | **12** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4366: |  0.06% |\n| Covered Lines: | 10945 |\n| Relevant Lines: | 29667 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4375\n\n1 of 77 (1.3%)  changed or added relevant lines in 4 files are covered.\n3 unchanged lines in 1 file lost coverage.\nOverall coverage decreased (-0.02%) to 36.811%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-common/src/main/java/azkaban/executor/JdbcExecutorLoader.java | 0 | 2 | 0.0%\n| azkaban-common/src/main/java/azkaban/executor/ExecutionFlowDao.java | 0 | 8 | 0.0%\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 1 | 16 | 6.25%\n| azkaban-exec-server/src/main/java/azkaban/execapp/ExecutorServlet.java | 0 | 51 | 0.0%\n | **Total:** | **1** | **77** | **1.3%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 3 | 20.04% |\n | **Total:** | **3** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4373: |  -0.02% |\n| Covered Lines: | 10930 |\n| Relevant Lines: | 29692 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4360\n\n1 of 14 (7.14%)  changed or added relevant lines in 1 file are covered.\n4 unchanged lines in 2 files lost coverage.\nOverall coverage increased (+0.05%) to 36.769%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 1 | 14 | 7.14%\n | **Total:** | **1** | **14** | **7.14%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 1 | 20.18% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 76.23% |\n | **Total:** | **4** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4359: |  0.05% |\n| Covered Lines: | 10902 |\n| Relevant Lines: | 29650 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4371\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n1 unchanged line in 1 file lost coverage.\nOverall coverage increased (+0.08%) to 36.92%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-web-server/src/main/java/azkaban/flowtrigger/FlowTriggerService.java | 1 | 60.08% |\n | **Total:** | **1** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4370: |  0.08% |\n| Covered Lines: | 10953 |\n| Relevant Lines: | 29667 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4379\n\n22 of 27 (81.48%)  changed or added relevant lines in 5 files are covered.\nNo unchanged relevant lines lost coverage.\nOverall coverage increased (+0.1%) to 36.918%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/AzkabanExecutorServer.java | 1 | 2 | 50.0%\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 3 | 7 | 42.86%\n | **Total:** | **22** | **27** | **81.48%** | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4376: |  0.1% |\n| Covered Lines: | 10962 |\n| Relevant Lines: | 29693 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4386\n\n4 of 5 (80.0%)  changed or added relevant lines in 2 files are covered.\nNo unchanged relevant lines lost coverage.\nOverall coverage increased (+0.007%) to 36.854%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 0 | 1 | 0.0%\n | **Total:** | **4** | **5** | **80.0%** | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4382: |  0.007% |\n| Covered Lines: | 10943 |\n| Relevant Lines: | 29693 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4388\n\n3 of 5 (60.0%)  changed or added relevant lines in 3 files are covered.\n31 unchanged lines in 7 files lost coverage.\nOverall coverage decreased (-0.09%) to 36.842%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/ExecutorServlet.java | 0 | 2 | 0.0%\n | **Total:** | **3** | **5** | **60.0%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-web-server/src/main/java/azkaban/webapp/servlet/ExecutorServlet.java | 1 | 0.0% |\n| azkaban-web-server/src/main/java/azkaban/flowtrigger/FlowTriggerService.java | 1 | 60.08% |\n| azkaban-common/src/main/java/azkaban/utils/LogGobbler.java | 1 | 59.38% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractJob.java | 2 | 31.03% |\n| azkaban-common/src/main/java/azkaban/utils/CircularBuffer.java | 2 | 47.06% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 3 | 63.1% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/event/JobCallbackRequestMaker.java | 21 | 56.25% |\n | **Total:** | **31** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4387: |  -0.09% |\n| Covered Lines: | 10932 |\n| Relevant Lines: | 29673 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4403\n\n9 of 9 (100.0%)  changed or added relevant lines in 3 files are covered.\n94 unchanged lines in 15 files lost coverage.\nOverall coverage decreased (-0.06%) to 36.869%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-web-server/src/main/java/azkaban/flowtrigger/FlowTriggerService.java | 1 | 60.08% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/utils/process/ProcessFailureException.java | 1 | 80.0% |\n| azkaban-common/src/main/java/azkaban/utils/LogGobbler.java | 1 | 59.38% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractJob.java | 2 | 31.03% |\n| az-core/src/main/java/azkaban/utils/Props.java | 2 | 67.56% |\n| azkaban-common/src/main/java/azkaban/utils/CircularBuffer.java | 2 | 47.06% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 3 | 60.71% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/JobRunner.java | 3 | 76.23% |\n| az-core/src/main/java/azkaban/Constants.java | 4 | 25.0% |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowPreparer.java | 6 | 85.29% |\n | **Total:** | **94** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4387: |  -0.06% |\n| Covered Lines: | 10946 |\n| Relevant Lines: | 29689 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4391\n\n0 of 0   changed or added relevant lines in 0 files are covered.\n6 unchanged lines in 3 files lost coverage.\nOverall coverage decreased (-0.01%) to 36.914%\n\n\n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| azkaban-web-server/src/main/java/azkaban/flowtrigger/FlowTriggerService.java | 1 | 60.08% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractJob.java | 2 | 31.03% |\n| azkaban-common/src/main/java/azkaban/jobExecutor/AbstractProcessJob.java | 3 | 63.1% |\n | **Total:** | **6** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4387: |  -0.01% |\n| Covered Lines: | 10961 |\n| Relevant Lines: | 29693 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4395\n\n6 of 6 (100.0%)  changed or added relevant lines in 2 files are covered.\nNo unchanged relevant lines lost coverage.\nOverall coverage increased (+0.09%) to 36.914%\n\n\n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4394: |  0.09% |\n| Covered Lines: | 10954 |\n| Relevant Lines: | 29674 |\n\n\ud83d\udc9b  - Coveralls\n. ## Pull Request Test Coverage Report for Build 4399\n\n30 of 36 (83.33%)  changed or added relevant lines in 3 files are covered.\n2 unchanged lines in 1 file lost coverage.\nOverall coverage increased (+0.03%) to 36.852%\n\n\n|  Changes Missing Coverage | Covered Lines | Changed/Added Lines | % |\n| :-----|--------------|--------|---: |\n| azkaban-exec-server/src/main/java/azkaban/execapp/FlowRunnerManager.java | 1 | 4 | 25.0%\n| azkaban-exec-server/src/main/java/azkaban/execapp/ProjectCacheCleaner.java | 22 | 25 | 88.0%\n | **Total:** | **30** | **36** | **83.33%** | \n|  Files with Coverage Reduction | New Missed Lines | % |\n| :-----|--------------|--: |\n| az-core/src/main/java/azkaban/utils/Props.java | 2 | 67.56% |\n | **Total:** | **2** |  | \n|  Totals |  |\n| :-- | --: |\n| Change from base Build 4394: |  0.03% |\n| Covered Lines: | 10939 |\n| Relevant Lines: | 29684 |\n\n\ud83d\udc9b  - Coveralls\n. ",
    "senecaso-sf": "I think this can be done by adding the \"maven\" plugin into the gradle scripts and adding some sort of parameterized repo config.  If this is something you would be interested in supporting, I can look at working on it and providing a PR.. The bulk of the performance problems comes from azkaban.project.DirectoryFlowLoader#constructFlow which is called by azkaban.project.DirectoryFlowLoader#loadProjectFlow, which is called when a project is uploaded to Azkaban (either via the UI or the AJAX endpoint).  The optimization here is to keep track of the nodes which you have already visited and simply not reprocess them if they have previously been processed.  \nThe second optimization is in azkaban.flow.Flow#initialize.  This code also does a traversal of the DAG in order to set the edges and the levels of the nodes, and again the solution here was optimize the traversal to ensure that we dont reprocess nodes which have previously been processed.  This was done using a breadth first ordering so that the nodes from each level are only visited once.  A node could exist at multiple levels and will be traversed multiple times in this case, but that is expected behaviour since we want the node's level to be the MAX level it exists at in the flow.\nLet me see if I can update the PR to include this information. updated.  Let me know if anything else is required.. @jamiesjc I have now applied the style template and reformatted the changes. Let me have another look.  I thought you were referring to code formatting via intellij, which is what I applied.  I will reread your style guide and apply any missing final keywords.. As far as I can tell, the style changes have been properly applied.  However, final was not added to a few places, as you pointed out, so I have manually added them.  Let me know if there are any other issues.. I wonder if this has something to do with the fact that I am running on Linux.  I dont have \"Other Settings\" or \"Save Actions\" anywhere that I can find.  I have even tried searching for \"Add final to local variable\" and didnt turn anything up.  I have tried restarting intellij and reimporting the included XML, but nothing seems to be changing.\nAre there other specific problems you have found?  Perhaps I can just manually make the changes?. Ah, I didnt realize there was a separate plugin required for this.  I must have missed that in the instructions somehow.  I'll make sure I install it for future commits.. I dont remember exactly which test I was using, but I'm pretty sure it was one of the ones in FlowRunnerTest2.  That said, pretty much every single Flow related test was failing without that change, so you could pick just about any test and it would have had the issue.\nThe massive test was generated by taking one of our exiting workflows and anonymizing it.  Beyond the existing tests there are today for Azkaban, I have done nothing specific to test embedded flows, but there are already existing unit tests to cover that.\nWhen I get some time, I will install the \"Save Action\" plugin and update the PR.  Swamped at the moment, so it may be a while.. You can control that by setting the appropriate ulimit, but you are correct that the number of files does cause problems with default settings.  Perhaps Azkaban should be changed to not keep every file open?  I haven't checked the project loading code, but it probably only needs to open one file at a time, and the could immediately close it.  If that's the case, then it was resolve this issue as well.\nWorst case, the number of files in the test project could be reduced, but that would make the original problem less obvious.  Perhaps this test could be entirely removed as well, since its not really testing anything except timing.. Perfect, thanks!. Originally, I thought it would be unique as well.  However, your unit tests quickly disproved that theory!  It was happening when 2 different flows had jobs with the same name.  I believe the conflict in the tests was innerJobA which appeared in multiple flows. Although, this may imply that visitedEver is simply not being reset between flows or something.. the file is 51kb using BZ2 and 3MB using ZIP or tar/GZ.  I felt it was better to not put a 3mb ZIP file into git, so I went with BZ2.  I can change it to ZIP if you prefer though.. I'll take a look at that.  Thanks!. If I understand you correctly, moving the declaration of visitedNodesEver into the for loop would result in the contents of visitedNodesEver being identical to visitedNodesOnPath which would defeat the purpose.  I think we need to keep the declaration where it is and simple fully qualify the node id with the flow id (as it is now) in order to safely ensure that we only visit a node once. My bad.  I took another look at it, and your suggestion will work.. ",
    "wilson-lauw": "initial effort: https://github.com/wilson-lauw/azkaban\n. https://github.com/azkaban/azkaban/pull/1714. duplicate with https://github.com/azkaban/azkaban/pull/1638/files. seems like its duplicate with https://github.com/azkaban/azkaban/pull/1638/files. I will close this one.. ",
    "aycaacar": "Hi Charlie,\nIn the existing hive plugin, hive-cli is used to connect to hive. We want\nto connect to hiveserver2 instead.\nWhen running in secured environments, obtaining tokens from hivemetastore\nis enough for hive-clie.  But for hiveserver2 we need to obtain hiveserver2\ntokens. We added this function, this is basically the purpose of this\nchange.\nThis version has been running on a production environment for more than one\nmonth. I tried to write unit tests for this one, but I couldn't find a way\nto run unit tests in a secured environment.\nIs it possible that you give me some information on how to do this, or may\nbe send me some examples? We are planning to contribute more, we have\ndevelopments such as an impala plugin going on. So we will need to run unit\ntests for secured environments in other cases too.\nThanks\nayca\nOn Wed, Mar 14, 2018 at 12:26 AM, Charlie Summers notifications@github.com\nwrote:\n\nHey @aycaacar https://github.com/aycaacar can you explain a little more\nabout this change? What's the purpose? How have you tested it?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/azkaban/azkaban/pull/1688#issuecomment-372823979, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AGEIRpRHUgWgHneYRQUmYWLBj19wegS-ks5teDltgaJpZM4So8f3\n.\n\n\n-- \n[image: Global Maksimum Data & Information Tech]\nAy\u00e7a Acar / Expert Software Engineer\nayca.acar@globalmaksimum.com\nGlobal Maksimum Data & Information Tech\nOffice: +902162663555 / Fax: +902162663401\nFSM Mahallesi Poligon Caddesi Buyaka Kule 2 Sitesi\nNo:8/C Blok Kat 16 34771 Istanbul T\u00fcrkiye\nhttps://htmlsig.com/signatures/0001CX49SG\n. Fixed in the new commit.. I enabled the save actions plugin and turned on all the options (except the one mentioned in the guide) as the contribution guide says. These two options of the save actions plugin cause these changes:\n - Add class qualifier to static member access\n - Remove unnecessary final to local variable or parameter.\nI'll change the code according to your comment, but i think the contribution guide needs to be updated.. Contribution guide says:\nInstall and enable the intellij's save actions plugin to reformat/refactor code automatically:\nPlease turn on all the options except\n - Remove unused suppress warning annotation\nI think this should be updated as follows:\nPlease turn on all the options except\n - Remove unused suppress warning annotation\n - Add this to method access\n - Add class qualifier to static method access\n - Remove unnecessary this\n - Remove unnecessary final to local variable or parameter\n\n. The screenshot belongs to Save Actions plugin. \nThe contribution guide tells us to check all the options (except one)in Save Actions plugin. But if we do it so, the code produced is not the way it is wanted. For example, it adds class qualifiers to static members which is not the desired behaviour. So I suggest that the contribution guide should be updated so that related options in Save Actions plugin are not required to be checked.\n. I have version 0.26 of the plugin.. ",
    "sonncui": "Help us a lot. Thanks very much for your reply.. ",
    "jatinderjawanda": "Indeed, this works !! \nThank You !!. ",
    "ashahab": "What I meant was, instead of relying on the users to know that no-fork is\nadvisable when running in a container, can you detect that the script is\nrunning in a container and accordingly set no-fork as a default? That would\nstop users from running without no-fork in a container and seeing\nunpredictable shutdown behavior.\nOn Sat, Apr 7, 2018, 11:03 AM Shawn Xu notifications@github.com wrote:\n\n@xunnanxu commented on this pull request.\nIn azkaban-common/src/main/bash/internal/startup-shared.sh\nhttps://github.com/azkaban/azkaban/pull/1715#discussion_r179923743:\n\n+#                          the vars won't be correctly exported to the child process, which is why\n+#                          it does not attempt to return the value via stdout.\n+# args:                    the name of the var to set final command to, the original command\n+#---\n+function parse_args {\n+  local target_arg=\"$1\"\n+  shift\n+  local final_command=''\n+  for arg in \"$@\"\n+  do\n+    case \"$arg\" in\n+      -f | --foreground)\n+      # azkaban will run as a foreground process\n+      export RUN_IN_FOREGROUND='true'\n+      ;;\n+      --no-fork)\n\nHi @ashahab https://github.com/ashahab, hmm I'm not quite sure if you\nare proposing something new here or just repeating my suggestion in this\nPR. In fact I think \"no fork\" should be the default option (see new\ndiscussion in #1669 https://github.com/azkaban/azkaban/pull/1669).\nHOWEVER, the current default behavior is to run it in background. I don't\nwant to change that because users might be relying on that behavior already\nso it's not something we should be changing in 3.x. This PR just gives\nother users (like me) an option to run stuff differently.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/azkaban/azkaban/pull/1715#discussion_r179923743, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAqJPdWWIlhlqORTUGfUSYPpluleQIoAks5tmP9XgaJpZM4TCrYT\n.\n. @xunnanxu --no-fork should be required if you are planning to run this in a containerized environment. \nThe reason is, if you are forking, sigterms from docker or other containers would go to the parent process, and it would be entirely up to the parent process to decide whether to propagate the signal to the children. \nFor example, bash does not pass signal to children. If you send a sigterm to bash, it will simply exit, and send a sigkill to the children. This prevents the actual forked process(JVM or others) to get gracefully shutdown.\n\nComing up with a nice parent process that handles all the different signals and orphaned subprocesses is difficult. OS init(pid 1) does that, but it's not advisable to run init in a container. There are alternative implementations, such as dumb_init from Yelp and my_init from baseimage-docker, but both have some cons, and as you say in your comments, this would put additional burden on the users.\n--no-fork on the other hand gives the user a very simple model. Container starts the main java process as the main process, and sends it all the signals, and container dies when the java process dies.\nIMHO we should start with that simple model and let the user community decide if a more complex model is necessary.. @xunnanxu I am not partial to either Python or Bash, but both scripts can get overly complicated unless you minimize their role(and let the called process do most of the work). Case in point is the Hadoop launch scripts upto 2.7, after which they had to be rearchitected to ensure users understand how arguments are going to be interpreted.. ",
    "gerashegalov": "Hi @HappyRay I created a little PR for this issue https://github.com/azkaban/azkaban/pull/1719 . Yes, absolutely.  It's actually one of the problems I was thinking of solving. Once the JobRunner started consuming the child process output it should stop applying its own conversion pattern on top of it. Otherwise multiline logging statements such as stack traces and pretty-printed jsons from the child process appear to be broken single-line statements and confuse log parsers of log  analyzers.. @kunkun-tang thanks for reviewing, added tests. Closing/reopening PR to trigger travis. Hi @kunkun-tang, thanks for checking, test code added!. Thanks for reviewing and committing this PR, @kunkun-tang ! \n@HappyRay one failure was https://api.travis-ci.org/v3/job/363278283/log.txt\n```\nFAILURE: Build failed with an exception.\n\nWhat went wrong:\nExecution failed for task ':azkaban-web-server:compileTestJava'.\njava.lang.reflect.InvocationTargetException\n```. \ud83d\udc4d . build passed finally. \n\n\n",
    "Jason-Song": "l install azkaban in my VMWare machine,and there's guava-21.0.jar in the lib directory.But always throw this exception when l start the azkaban-web-server.. no\uff0cl give up. ",
    "mohitjain012": "I am also facing the same issue. For me Hadoop and other software have guava-11.0.2.jar. How to override this to use guava-22.0.jar I downloaded in Azkaban?. Hi, I found two versions of guava in azkaban/azkaban-solo-server/build/install/azkaban-solo-server/lib. When I removed older one from there then error is gone.. ",
    "yangzhixiao": "I have the same issues.. @aiwotantan your English is very six !!!. ",
    "aman94": "Did you find the solution?. ",
    "RoryLiuwenxuan": "This error is azkaban can't communicate with mysql, Even if you set user:azkaban can remote login already.\nI got this erro too when I installed mysql by yum.\nchange DB to maria-db fix it.\nstep-1\nlinux shell> vi /etc/yum.repos.d/MariaDB.repo\nMariaDB.repo\n   [mariadb]\n   name = MariaDB\n   baseurl =http://yum.mariadb.org/10.2/centos7-amd64\n   gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDB\n   gpgcheck=1\n\nstep-2\nlinux shell>yum install MariaDB-server MariaDB-client -y\nlinux shell>systemctl start mariadb\nlinux shell>systemctl enable mariadb\nstep-3\nlinux shell>mysql\nmysql> CREATE USER'azkaban'@'\uff05'IDENTIFIED BY 'azkaban';\nmysql> GRANT SELECT,INSERT,UPDATE,DELETE ONazkaban.* to 'azkaban'@'%' WITH GRANT OPTION;\nmysql> use azkaban\nstep-4\nmysql> source/software/azkaban-master/azkaban-db/build/sql/create-all-sql-0.1.0-SNAPSHOT.sql\nmysql> insert into executors(host,port)values(\"ip1 or hostname1\",12321);\nmysql> insert into executors(host,port)values(\"ip2 or hostname2\",12321);\nstep-5(important)\nmysql> update executos set active=1;\nnow ,restart azkaban-web-server and azkaban-executor-server.\nWish you success.\nYou can refer to the installation part of DB in my microblog.\nhttps://blog.csdn.net/weixin_39445556/article/details/79944117. can you login mysql by execut \u201cmysql -hyourIP -uazkabanUser -pazkabanPassWord\u201d,if you can\u2019t,please try my way. \nA few minutes of trying to change a chance of success.\ngood luck. ",
    "vasuonweb": "Where the test.sh should be placed?\nI have a usecase where i  defined a shell script in a folder and azkaban job has to trigger it.\ninputs needed..plz help. ",
    "balajinima": "/src/test/java/azkaban/dag/DagTest.java\n\nfinal Node node = TestUtil.createNodeWithNullProcessor(name, this.testFlow);\nthis.testFlow.addNode(node);\n\nadd node to testFlow twice\u3002. ",
    "whyuds": "@jamiesjc @reallocf \n    Thanks. it sames one execution could only run in one executor even we could assign by useExecutor\n    Is there any solution for my demand--Like i want to run a job in all my executors and then run other job. (daily)\n    . ",
    "abha10": "Could be a memory related issue.\nCheck issue #610. Might help. \nBasically it says to remove 'MinimumFreeMemory' filter from azkaban.properties file.. ",
    "SuZhiBai": "My current case is like this:\nEach project corresponds to a type of task, which may be a mapreduce task, a spark task, or other asynchronous task. I use api batch post task to azkaban server, each task corresponds to a running flow, I want to control the number of running flow in each project, because the back-end computing resources are limited.\nIn addition, in each project, if the running flow queue is full, it can set the priority in the waiting flow.In other words, if there is a gap in the queue, the highest priority in the waiting flow will be scheduled.\nDo you have any other better suggestions for this case? Thank you. ",
    "VemberZhang": "how to setup a project depend another project in job config file?. ",
    "oliverhu": "What's the point of providing the capability to override azkaban.flow.execid ?. Not a big fan of adding \"ignored\", I don't think anyone would bother running the ignored tests. I'm curious what is the actual logic we're trying to test. From the code and conversation, we're not actually testing to logic in createDeepHardlink(..) but creating a scenario to make sure the createDeepHardlink(..) method works. I suggest:\n1) figure out the part of logic that has the possibility of causing regression and guard only that part, proper mocking would make it much faster.\nor\n2) move these scenario based tests out and create another test suite of integration test to validate scenarios.. I'm not sure if we want to piggyback on this tho, what if user intentionally wants to kill the exec_id he overrides with?. ",
    "huaxuehuaxue": "@jamiesjc \nhi buddy,    your conditional_workflow.flow doesn't work well . \nREASON:\nfirst of all:    Azkaban don't know what  $JOB_OUTPUT_PROP_FILE   is .\nsecond:       command: echo {\"param1\":\"1\"} > $JOB_OUTPUT_PROP_FILE     doesn't work well,  please check it.. good question. but diffcult to make it . . @happyapple668  hi buddy. seriouslly , no \u201cexecutor.port\u201d in web-server/config/azkaban.properties , detail:URL. Hi @jamiesjc , thanks for replying. I followed this instruction page:  https://github.com/azkaban/azkaban/pull/1825          , and I am using exactly the same example  as below:\n##########################start\nnodes:\n - name: JobA\n   type: command\n   config:\n     command: echo {\"param1\":\"1\"} > $JOB_OUTPUT_PROP_FILE \n\n\nname: JobB\n   type: command\n   config:\n     command: echo {\"param2\":\"6\"} > $JOB_OUTPUT_PROP_FILE \n\n\nname: JobC\n   type: command\n   dependsOn:\n\nJobA\nJobB\n   config:\n command: echo \u201cThis is JobC.\u201d\n   condition: ${JobA:param1} == 1 && ${JobB:param2} > 5\n\n\n\n##########################end\nI checked the code related while running , I found out the reason why \"JobC\" cancelled on my MAC is \"command: echo {\"param2\":\"6\"} > $JOB_OUTPUT_PROP_FILE \" didn't work out.  here is the log:\n\nand the further reason is: there is nothing execution tmp file.. Thanks for replying very much. \n\" echo 'Hello world!' \"  works fine,  complex expression with \"echo\" works not fine.\nThis problem can be avoided in your way ,  we can solve it completely by enhance process builder later . \nthanks again.. hi, In my option , it is not working as you thought above. \none flow only can be execute by one executor at the same time, so the jobs can't jump out the executor.. hi mittalnanu , bhatiakartik\nflow is the minimal allocation unit which given to one executor , so jobs in this flow can't jump out the executor. By breaking large horizontally scale jobs into same flows manually may break the executor resource limit.\nand I'm sorry for can't provide more useful information.\n. \u5de5\u7a0b\u540d\u79f0\u4e0d\u53ef\u4ee5\u7528\u4e2d\u6587,\u4f46\u662fjob\u662f\u53ef\u4ee5\u7684. \u9700\u8981\u6570\u636e\u5e93\u662futf-8\n\nChinese name is not Acceptable , but job name works well with Chinese name.  your database character need to be 'utf-8' . ",
    "weidious": "Created by mistake. Check out Event trigger PR #1858 for more information. ToDo note is added into .rst file already for the future needs.. Some properties within the table weren't highlighted as the original document. Otherwise LGTM.. A figure is missing. . Shouldn't this userManager exist above useAzkaban? . True, since they are in the table by their own already. . Is this the right order? I'm not sure about where should we put the event trigger doc. . ",
    "aiwotantan": "good good study,day day up!. @HappyRay @kunkun-tang @weidious @chengren311 . ",
    "kezhenxu94": "@aiwotantan use javaprocess instead. ",
    "chris9692": "The cause of this error might be in bin/internal/internal-start-executor.sh. I was able to make it work with following tweaks. \nif [ \"$HADOOP_HOME\" != \"\" ]; then\n        echo \"Using Hadoop from $HADOOP_HOME\"\n        #CLASSPATH=$CLASSPATH:$HADOOP_HOME/conf:$HADOOP_HOME/\n_CLASSPATH=$CLASSPATH:$HADOOP_HOME/conf:$HADOOP_HOME/:$HADOOP_HOME/share/hadoop/common/:$HADOOP_HOME/share/hadoop/common/lib/:$HADOOP_HOME/share/hadoop/hdfs/:$HADOOP_HOME/share/hadoop/hdfs/lib/:$HADOOP_HOME/share/hadoop/yarn/:$HADOOP_HOME/share/hadoop/yarn/lib/:$HADOOP_HOME/share/hadoop/mapreduce/:$HADOOP_HOME/share/hadoop/mapreduce/lib/_\n        JAVA_LIB_PATH=\"-Djava.library.path=$HADOOP_HOME/lib/native/Linux-amd64-64\"\nelse\n        echo \"Error: HADOOP_HOME is not set. Hadoop job types will not run properly.\"\nfi. ",
    "xujiapei": "thx. ",
    "mittalnanu": "Hi huaxuehuaxue, \nthanks for the response. Agreed that is how it is not working. The question is there a vision to build this capability? If not, want to understand what is the drawback?\nWon't it be nice if azkaban itself can logically break executions of big dags and horizontally scale when it comes to number of resources available for execution instead of being limited to one executor's resource at any point in time.\nWith this feature missing, we need another layer on top of azkaban that breaks big dag, to smaller dags so that we can parallelize execution beyond what one executor can provide. \nIs there any fundamental flaw in asking azkaban to have such a feature?. ",
    "bhatiakartik": "Hi huaxuehuaxue\nThat is the entire point why can't jobs jump out of the single executor and work on multiple executors in parallel. This will help in scaling azkaban horizontally. @HappyRay Any suggestions?\nConsider this as a feature ask. Do you see any hinderance/blocker/anti-pattern with this approach of running jobs in parallel on multiple executors? . ",
    "subash247": "gradlew build installDist\njuz run this command alone. ",
    "dmvieira": "I see same error. We solved here following these steps to enable kafka:\n\nAdd to azkaban.properties it:\n```\nazkaban.server.schedule.enable_quartz=true\nazkaban.dependency.plugin.dir=plugins/dependency\n\norg.quartz.dataSource.quartzDS.driver = com.mysql.jdbc.Driver\norg.quartz.dataSource.quartzDS.URL = jdbc:mysql://your_mysql_host:3306/your_mysql_database\norg.quartz.dataSource.quartzDS.user = your_mysql_user\norg.quartz.dataSource.quartzDS.password = your_mysql_password\norg.quartz.threadPool.threadCount = 3\norg.quartz.jobStore.class=org.quartz.impl.jdbcjobstore.JobStoreTX\norg.quartz.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.StdJDBCDelegate\norg.quartz.jobStore.tablePrefix=QRTZ_\norg.quartz.jobStore.dataSource=quartzDS\n```\n\n\nCreate a folder called kafka inside plugins/dependency folder\n\n\nAdd to kafka folder dependency.properties file as specified here: https://azkaban.readthedocs.io/en/latest/eventTrigger.html#event-based-trigger-plugin-configuration\n\nyou need to build kafka-event-trigger and  az-flow-trigger-dependency-plugin jars\n\nkafka-event-trigger and  az-flow-trigger-dependency-plugin jars should be inside classpath specified\n\n\nFollow steps here: https://azkaban.readthedocs.io/en/latest/eventTrigger.html\n\n\nI hope it helps ;). same problem here. @xianyouQ I solved here... Do you need to say quartz to store data in mysql. Follow these instructions here: https://github.com/azkaban/azkaban/issues/1917#issuecomment-437350461. ",
    "jackjianguo": "I'm also seeing the same error. I checked the memory and found that there was not enough. I solved here following\nAZKABAN_OPTS=\"-Xmx1G\" in bin/internal/internal-start-executor.sh. ",
    "zzlove": "\u6ca1\u6709\u5b9a\u4e49pageSize\u5bfc\u81f4\u7684\nazkaban-web-server/src/web/js/azkaban/view/flow.js\nthis.model.set({page: 1, pageSize: this.pageSize});\n\u4fee\u6539\u4e3a\nthis.model.set({page: 1, pageSize: 16});. ",
    "Lqlsoftware": "@kunkun-tang Thx, bro\nBut sometimes we don't want to edit any code or something to modify my company's workflows.\nLazy aha. Your solution is very elegant, but a non-coder cannot figure it out in a shortly time.. ",
    "kyrill007": "This issue has a valid and open pull request. https://github.com/azkaban/azkaban/pull/1961. It would be good to merge it into the main branch as it is a very valid issue.. Dear Azkaban maintainers, what does it take to get this pull request merged into the main branch? We're facing the same issue and it is fairly critical for us. This fix does it. Thank you! Note that this pull request fixes issue https://github.com/azkaban/azkaban/issues/1950.. Would it be possible to prioritize merging of this pull request? I verified it locally and it works. This is pretty important for our project. Thank you so much!!!. ",
    "AriesMg": "\u6211\u77e5\u9053\u6539\u6210\u82f1\u6587\u554a\uff0c\u95ee\u9898\u662f\u57fa\u4e8e\u8fd9\u4e2a\u505a\u4e8c\u6b21\u5f00\u53d1\uff0c\u4efb\u52a1\u660e\u53ea\u80fd\u6570\u5b57\u548c\u82f1\u6587\u4e0d\u592a\u53cb\u597d\u554a. > Could you please dive into the details? I'm also curious to learn the which side generates the restriction, Mysql/h2 or java Character settings. @AriesMg\nwhen I upload zip file include some job file named by chinese \uff0cfor example\n\nwhen the file uploaded to linux \uff0cfile with Chinese name appear unrecognizable characters.\n\nI guess the proplem is that HTTP Encoding is error setting when upload file through http \n@kunkun-tang . > ## \u5de5\u7a0b\u540d\u79f0\u4e0d\u53ef\u4ee5\u7528\u4e2d\u6587,\u4f46\u662fjob\u662f\u53ef\u4ee5\u7684. \u9700\u8981\u6570\u636e\u5e93\u662futf-8\n\nChinese name is not Acceptable , but job name works well with Chinese name. your database character need to be 'utf-8'\n\n\u8ddf\u8fd9\u4e2a\u6ca1\u5173\u7cfb\uff0c\u4e0a\u4f20\u6587\u4ef6\u7684\u65f6\u5019\uff0c\u4e2d\u6587\u5df2\u7ecf\u4e71\u7801\u4e86. > \u6700\u540e\u89e3\u51b3\u4e86\u554a\uff1f\n\u6ca1\u6709\u89e3\u51b3\uff0c\u5e94\u8be5\u662fazkaban\u4e0a\u4f20\u6587\u4ef6\u5bfc\u81f4\u6587\u4ef6\u540d\u4e71\u7801\u4e86. ok,thanks. ",
    "shengjianjia": "\u6700\u540e\u89e3\u51b3\u4e86\u554a\uff1f. but my mysql charater encode is utf-8. I cehck the execution_logs table setting  is utf8. I also have this problem.Have you solved it yet?. There is still this problem.. ",
    "li-ygerchikov": "Not caused by flaky tests. (Other build failures are. Not the last two.)\nThis one is caused by failed Gradle dependency checking:\n```\n:az-core:compileJava FAILED\n[...]\nFAILURE: Build failed with an exception.\n* What went wrong:\nFailed to capture snapshot of input files for task ':az-core:compileJava' property 'classpath' during up-to-date check.\n\nError snapshotting jar [log4j-1.2.16.jar]\n``\nSeems reproducible. Trying to rerun with--stacktraceor--debugor--scan`. Also, may need to reach to Gradle experts.. Traced failures to a corrupt build cache, likely due to Travis infra hiccup / intermittent connectivity issue. Deleted and rebuilt cache, verified that builds are passing. Restarted failed builds.\nNot sure what we can do to prevent this in the future, or to recover automatically. May need some extra thought if we never want to see this type of failure again.. > How did you verify the change of log size reduce?\n\n@jamiesjc Good question. I compared the actual log file size. Raw build logs are available for download from Travis. E.g. for build https://travis-ci.org/azkaban/azkaban/builds/442314960 the complete log is available via https://api.travis-ci.org/v3/job/442314961/log.txt. It's a fine idea. I just wonder if this is the best spot to log the message. If another client calls prefetchToken from somewhere else, wouldn't it be nice if we logged that as well? I think you are trying to log before we enter the synchronized method, in case that blocks. That's understood.  Would it be too much trouble to make prefetchToken an unsynchronized wrapper around the (private) do_prefetch...? \nSorry, I think this was meant to be a quick change -- please feel free to ignore.. This is what happens when IDE is trying to be too smart... The formatting/whitespace changes are courtesy of IntelliJ. Sorry about that, I can try and undo or isolate them.. Correct -- no --info for coveralls task. If anyone knows a better way to change logging level for just one task in a bigger gradle run, please let me know -- this could shave a few seconds off the execution time.. Does this run everything under src/web/js/azkaban/test/?. Does this change mean \"run only the old test under this task\"?. I guess I am still not sure how npm test knows to run test_running_server.js but not test.js when its parameter only specifies the (entire?) directory. Will it not run both? Or maybe it will, and it's ok?. I like it. Or maybe just src/web/js/azkaban/test_running and src/web/js/azkaban/test_static, no need for (empty?) src/web/js/azkaban/test?. Many methods of this class duplicate identical methods of ExecutorManager verbatim. What would be a good way to avoid this?. Often instanceof check is considered anti-pattern. What if we had yet another, third implementation of ExecutorManagerAdapter that is not ExecutorManager but behaves more like it than like the new ExecutionController?\nCould we delegate and trust the implementation to do the right thing? In this case, could we call start unconditionally here, but make start implementation a noop in the new class?. Aside: some people like to add date (along with the author name) to their todos, so that readers can identify which era the todo comes from.. I hope this is temporary, predicated on the above todo. Obviously, this cast will fail when executorManagerAdapter is an ExecutionController. Is this just to postpone addGauge refactoring to accept ExecutorManagerAdapter instead of ExecutorManager?. ",
    "zengqingjun": "Setting Finish All Possible still does not take effect. ",
    "codedebuger": "this big bug\uff0cshould fix\uff1f. ",
    "luckyxiang2017": "yes\uff0cThis is the same problem as yours @juhoautio \nI have solved the problem\nI define a class that inherits Logger\nthen\uff0clike this\nlogger = new JobLogger(loggerName);\nso\uff0cthe logger is not created by Hierarchy\uff0cand it is not in the Hashtable\n. ",
    "xianyouQ": "maybe because flow trigger can be paused and it isn't inappropriate restarting after webserver restart? but in my case I didn't pause flow trigger and it didn't restart after restart webserver, I had to reupload project to trigger  it.. @dmvieira  emmm\uff0cit maybe work\uff0cthanks . \u9ed8\u8ba4\u53d6hostname,port\u505a\u4e3adb\u7684\u6570\u636e(\u552f\u4e00\u6027\u7ea6\u675f)\uff0c\u5982\u679c\u591a\u53f0\u673a\u5668hostname,port\u4e00\u6837\uff0c\u90a3\u4e48\u540e\u8d77\u6765\u7684\u673a\u5668\u662f\u63d2\u4e0d\u8fdbdb\u7684\uff0c\u6240\u4ee5\u53ea\u6709\u4e00\u53f0\u673a\u5668\u6ce8\u518c\u4e86\u3002\u4f60\u53ef\u4ee5\u7528azkaban.server.hostname=xxx\u6307\u5b9a\uff0c\u800c\u4e0d\u662f\u53d6\u5230localhost. ",
    "Kaoxyd": "It is because flows are not rescheduled when the webserver start. \nIn file azkaban/webapp/AzkabanWebServer.java:243\n```java\nwebServer.projectManager.getProjects()\n    .forEach(project ->\n        {\n          try {\n            webServer.getScheduler().scheduleAll(project, \"system\");\n          } catch (SchedulerException e) {\n            logger.error(\"Cannot schedule trigger job\", e);\n          }\n        }\n    );\n\n```\nThis should to the tricks. Hello,\nFor the use case, in my company, most of the treatments are done by batch. On each VM, a cron job is schedule to check periodically if a new file is available, and if it so, get it on the remote host. Each batch file are named following a specific pattern that describe the app that emit the file, the date that describe when the export has been done, and if it is a partial or a total export.\nFor example, one of the batch receive is used to update technical incidents on clients cases. \nQuartz allow these kinds of trigger for example (https://stackoverflow.com/questions/26381695/schedule-jobs-dynamically-in-quartz-by-watching-a-folder)\nI already develop a plugin that trigger a job using the native Java API to do it (WatchService) based on the already existing Kafka plugin. Few ajustements are necessary to clean the cache, but it is working like a charm. Can do a PR if you are interested in.. You should compile the kafka-event-trigger plugin first. Then, a bit of configuration is needed\nazkaban.properties\n```\nazkaban.server.schedule.enable_quartz=true\nazkaban.dependency.plugin.dir=plugins/deps\norg.quartz.dataSource.quartzDS.driver=org.h2.Driver\norg.quartz.dataSource.quartzDS.URL=jdbc:h2://.h2/quartzDS\norg.quartz.threadPool.threadCount=4\n```\n(Enabling Quartz seems mandatory in that case. Change the jdbc driver following your database kind)\nThen, your plugin dir must be containing something like \n- plugins\n--- deps\n----- kafka\n------- dependency.properties\n------- kafka-plugin.jar\n--- jobtypes\n----- ...\nThe kafka-plugin.jar must be the jar compiled before (that you can find in the project, build/libs/kafka....-fat.jar). Then, your dependency.properties must contain\ndependency.class=trigger.kafka.KafkaDependencyCheck\ndependency.classpath=plugins/deps/kafka/kafka-plugin.jar\nThat's enough I think\n. ",
    "marknorkin": "Our DevOps team currently also looking at extending the file format, providing some wrappers around it etc. In whatever approach will be chosen it is an extra work.\nThe benefit of this feature is that it will have clear usage, no customized instruments built on top of it which would require maintenance.\nWhat issues do you see here, can you elaborate, please ?. Yes, sorry if I wasn't clear. This is about feature request. Initially I just wasn't sure if this was already implemented, which would mean that I just missed it in the documentation.. ",
    "prantaaho": "+1 \nHow you are supposed to implement staging/production setup without this? Write completely separate staging.flow and production.flow files where actually only config parameters differ?. ",
    "modeyang": "issue solved!  need java-openjfx jre lib.  related issue java.lang.ClassNotFoundException: javafx.util.Pair. ",
    "jacksonKhUA": "Hi @juhoautio \nI have release-3.43.0 version on production. Do you know, this problem already fixed in latest versions?Looks like in this e85075cd1ac90d27aba6737c89cbf41e096fb6b4 commit it was fixed, don't you?\nThank you in advance. Ok, i'll try to apply this one commit above my release-3.43.0 version without all new releases. I can't apply all new releases, cause a lot of new releases was already done.\nThanks for help, @juhoautio. ",
    "ypadron-in": "\nYou can attach some screenshots to demonstrate what the UI looks like with the new change.\nAlso mention the new change will apply to both flow 1.0 and flow 2.0.\n\nPR description updated. I updated the PR description. > Thanks for adding this feature! Now the failed job lists will be expanded by default. Do we plan to support collapsing all the job lists as well?\nAs we discussed, let's have the collapse behavior that is right now on the page for now.. > Thanks for cleaning this up! Is there more information about AzkabanProcess and LogGobbler? There's some comments about \"Output is read by separate threads to avoid deadlock and logged to log4j loggers.\" I know this is very old code, so most likely the information is lost, but am curious about the issues.\nNo problem :). \nSorry, I don't know if there is more info about AzkabanProcess and LogGobbler.. > Could you please check the query plan, for the new select with flow_priority, if not done already?\nDo you mean this?\nmysql> EXPLAIN EXTENDED SELECT exec_id from execution_flows where status = 20 and executor_id is NULL and flow_data is NOT NULL and use_executor is NULL ORDER BY flow_priority DESC, submit_time ASC, exec_id ASC LIMIT 1 FOR UPDATE;\n+----+-------------+-----------------+------+----------------------------+----------------+---------+-------+------+----------+-----------------------------+\n| id | select_type | table           | type | possible_keys              | key            | key_len | ref   | rows | filtered | Extra                       |\n+----+-------------+-----------------+------+----------------------------+----------------+---------+-------+------+----------+-----------------------------+\n|  1 | SIMPLE      | execution_flows | ref  | executor_id,ex_flows_staus | ex_flows_staus | 2       | const |    1 |   100.00 | Using where; Using filesort |\n+----+-------------+-----------------+------+----------------------------+----------------+---------+-------+------+----------+-----------------------------+\n1 row in set, 1 warning (0.01 sec)\nThis DB has over 10 million rows in execution_flows table. > Yes, thanks. How does the explain plan change if an index is added on (flow_priority, submit_time), or (flow_priority, submit_time, exec_id)? Each executor is polling with this query, so it's getting executed very frequently.\n\nhttps://dev.mysql.com/doc/refman/8.0/en/order-by-optimization.html\n\nHere is the EXPLAIN output after adding (flow_priority, submit_time) index:\nmysql> ALTER TABLE execution_flows ADD INDEX priority_submit (flow_priority DESC, submit_time ASC);\nmysql> EXPLAIN EXTENDED SELECT exec_id from execution_flows WHERE status = 20 and executor_id is NULL and flow_data is NOT NULL and use_executor is NULL ORDER BY flow_priority DESC, submit_time ASC, exec_id ASC LIMIT 1 FOR UPDATE;\n+----+-------------+-----------------+------+----------------------------+----------------+---------+-------+------+----------+-----------------------------+\n| id | select_type | table           | type | possible_keys              | key            | key_len | ref   | rows | filtered | Extra                       |\n+----+-------------+-----------------+------+----------------------------+----------------+---------+-------+------+----------+-----------------------------+\n|  1 | SIMPLE      | execution_flows | ref  | executor_id,ex_flows_staus | ex_flows_staus | 2       | const |    7 |   100.00 | Using where; Using filesort |\n+----+-------------+-----------------+------+----------------------------+----------------+---------+-------+------+----------+-----------------------------+\n1 row in set, 1 warning (0.00 sec)\nHere is the output if we dropped index (flow_priority, submit_time) and create instead an index on (flow_priority, submit_time, exec_id)\nmysql> ALTER TABLE execution_flows ADD INDEX priority_submit_execid (flow_priority DESC, submit_time ASC, exec_id ASC);\nmysql> EXPLAIN EXTENDED SELECT exec_id from execution_flows WHERE status = 20 and executor_id is NULL and flow_data is NOT NULL and use_executor is NULL ORDER BY flow_priority DESC, submit_time ASC, exec_id ASC LIMIT 1 FOR UPDATE;\n+----+-------------+-----------------+------+----------------------------+----------------+---------+-------+------+----------+-----------------------------+\n| id | select_type | table           | type | possible_keys              | key            | key_len | ref   | rows | filtered | Extra                       |\n+----+-------------+-----------------+------+----------------------------+----------------+---------+-------+------+----------+-----------------------------+\n|  1 | SIMPLE      | execution_flows | ref  | executor_id,ex_flows_staus | ex_flows_staus | 2       | const |    7 |   100.00 | Using where; Using filesort |\n+----+-------------+-----------------+------+----------------------------+----------------+---------+-------+------+----------+-----------------------------+\n1 row in set, 1 warning (0.00 sec)\n. sure, I will change it.. ok. variable 'nodes' in line 481 refers to all nodes (or flows) in the graph. Uploading an empty workflow to Azkaban will generate an error so I guess is guaranteed variable 'nodes' will exist but adding an extra check will not hurt. Let me know what you prefer.. In expandAllFlows is not needed because this method actually triggers the creation of gNode, which is a JavaScript object containing info about the html tag that represents the node visually. This gNode is accessed in collapseAllFlows to hide the element so it needs to exist at this point. \nIf we remove this check we get an error whenever we try to collapse before ever expanded because we iterate over all nodes when doing collapsing but some of them, the embedded ones, don\u2019t have a gNode yet.. Done, thanks. correct. It prevents us from having to create a get method in JobRunner class to access its private property 'job'. It prevents us from breaking encapsulation for testing purposes.. I'll remove that e.printStackTrace(); line, it's not needed anyway, thanks.. Before the changes it was kind of confusing: job.flowId contains a potentially long string following this pattern flowRootName[,embeddedFlowName:embeddedFlowPath]* that's not really useful/meaninful to the user in my opinion. If the user clicks that string would be redirected to the root flow page where the job in question won't be shown at first glance if it's embedded, user would need to unfold flows to find it. If the job is inside the root flow users would be able to locate it easily.\nIdeally in my mind the logic behind clicking the flow name would be a redirection to the root flow but the job would be highlighted and all flows unfolded if it's embedded.\nI thought as half to paradise solution to show the job's immediate flow and redirect on click to the immediate flow view where users would be able to see the job directly. At the top of that page there is a breadcrumb that can lead them to the root flow if they want to.\nLet me know if we proceed or not with this changes.. I'll add it. Right now Azkaban doesn't allow the user to upload a project with no flows so jobPath is guaranteed to have at least one element, but since changes to this behavior would mean a contract violation I believe it would make sense to rewrite it like this:\nAssert.assertFalse(\"There most be at least one flow in project\", this.jobPath.isEmpty());\nthis.immediateFlowId = this.jobPath.get(this.jobPath.size() - 1).getSecond();\nFor reference:\nhttps://stackoverflow.com/questions/2440984/assert-a-good-practice-or-not. sure, thanks. Is the object containing the nodes data. It has also a reference to a DOM object(what gets rendered ultimately) for each node. We are using the DOM object to programmatically expand/collapse flows.. With this we are passing an empty array whenever there is no nodes property in node or it has null value. We are doing this to prevent \"Cannot read property 'length' of undefined/null\" error in the for loop. It\u2019s mainly \"just in case\" and it can be removed if we wanted because Azkaban doesn\u2019t allow to have an empty flow.. they are going to be expanded as well, thanks for thinking about that!. I changed the if condition to use the utility method isNotEmpty(). Thanks. Added \"visiblePages\" to settings object to keep consistency. I'll change default value to NULL, thanks! @li-ygerchikov also pointed out a few performance and space benefits of defaulting to NULL.. will change it. using it now.. I don't see why it would be necessary. It's the only synchronized method in the class so it doesn't protect any private attributes, it's only preventing concurrent calls to this method but there is nothing in there that would be a problem in those cases. I'll remove it in a separate PR, thanks.. I don\u2019t see how we could avoid creating a string every time because the parameters to the query are not known at compile time. What I can do is to replace the string concatenations with String.format. \nBTW, this query string will likely get even more parameters when we implement the flow priority feature, which is why I still prefer to use an auxiliary method instead of constant strings.. no need to set it explicitly, default is NULL. I understand that creating a new string every time means they have to be garbage collected, but that's not worse than using a string constant with \"?\" in it I believe: a new string has to be created anyways to substitute those ? with the actual values because strings are immutable so because some elements of the query are not known at compile time there's no way to avoid creating a new string every time. The only difference is whether that new string is created by us or by the JDBC driver, but I don't think that's significant difference.. ok, but we might want to specify it for the rest of the columns as well.. I changed the query strings to be constant strings using \"?\" to define parameters. It looks Java delegates parameter resolution to the Mysql connector. Thanks.. Marked for deletion here: https://github.com/azkaban/azkaban/pull/2129#discussion_r259039490. This method duplicated work done in ajaxExecuteFlow(..) and is not used anywhere else.. This info should be in the logs already. Also, it wasn't used before because toString/getMessage methods of ProcessFailureException were not overwritten.. yes, will do. MySQL ENUM type? I think it will artificially limit what we can do with priorities in the future or make it hard to maintain at least. There have been comments around setting priorities based on groups. For example: groupA could set priorities from 1-10, groupB from 11-20, etc. Thanks! It is possible right now. I'll modify the query to prevent starvation. . Talked about this topic offline. We decided to not rollout a fix to prevent starvation of low priority executions right now. \"flowPriority\" feature is only available to Azkaban admins and we consider it's not very used. \nWe will monitor the polling of executions to detect the moment when starvation becomes a real issue to take into consideration.\nIf anyone in the open source community needs a fix sooner, please refer to this commit\nhttps://github.com/ypadron-in/azkaban/commit/0c0fe3aa2f03ad5e96b3291a20ea8937776b1f77. ",
    "PhilosophyBuns": "\n\u4f60\u90fd\u542f\u52a8\u554a\uff0c\u542f\u52a8\u4e86\u4f1a\u67092\u6761\u7684\n\n\u6211\u90fd\u542f\u52a8\u4e86\u4f46\u662f\u53ea\u6709\u4e00\u6761. > \u9ed8\u8ba4\u53d6hostname,port\u505a\u4e3adb\u7684\u6570\u636e(\u552f\u4e00\u6027\u7ea6\u675f)\uff0c\u5982\u679c\u591a\u53f0\u673a\u5668hostname,port\u4e00\u6837\uff0c\u90a3\u4e48\u540e\u8d77\u6765\u7684\u673a\u5668\u662f\u63d2\u4e0d\u8fdbdb\u7684\uff0c\u6240\u4ee5\u53ea\u6709\u4e00\u53f0\u673a\u5668\u6ce8\u518c\u4e86\u3002\u4f60\u53ef\u4ee5\u7528azkaban.server.hostname=xxx\u6307\u5b9a\uff0c\u800c\u4e0d\u662f\u53d6\u5230localhost\n\u975e\u5e38\u611f\u8c22. > \u9ed8\u8ba4\u53d6hostname,port\u505a\u4e3adb\u7684\u6570\u636e(\u552f\u4e00\u6027\u7ea6\u675f)\uff0c\u5982\u679c\u591a\u53f0\u673a\u5668hostname,port\u4e00\u6837\uff0c\u90a3\u4e48\u540e\u8d77\u6765\u7684\u673a\u5668\u662f\u63d2\u4e0d\u8fdbdb\u7684\uff0c\u6240\u4ee5\u53ea\u6709\u4e00\u53f0\u673a\u5668\u6ce8\u518c\u4e86\u3002\u4f60\u53ef\u4ee5\u7528azkaban.server.hostname=xxx\u6307\u5b9a\uff0c\u800c\u4e0d\u662f\u53d6\u5230localhost\n\u8fd9\u4e2a\u662f\u5728\u54ea\u91cc\u914d\u7f6e azkaban.properties\u5417. > it dosn't use qrtz table\n\u611f\u8c22\u56de\u590d\uff0c\u90a3\u5b83\u4e3a\u4ec0\u4e48\u4f1a\u6709qrtz\u8868\u5462. ",
    "zhouyejoe": "@kunkun-tang @chengren311 @jamiesjc . ",
    "ycvbcvfu": "every 3 days at 1:00\n0      1     */3       *       *\n. @leozhangzhang right?. ",
    "Light-Gao": "Got the same confusion...\nIt seems Azkaban becoming bigger and bigger. And it doesn't tarball which could be deployed immediately after downloading. There are only source code files. I would be easier to deploy for people who do not code, if the author could prepare released tarballs.. ",
    "seayoun": "in the poll mode(ExecutionController), how to choose the executor, I looked the code , however I didnot saw some choose factor, what I saw is an exclusive lock on mysql, does it grab the lock\uff1f. you can call reload as follow \ncurl -d ajax=reloadExecutors -d session.id= http://localhost:8081/executor?ajax=reloadExecutors. @kun\n@suvodeep-pyne \n@jamiesjc \nwhy my pr is always 'some checks were not successful'\nplease look at this question and review my pr if possible. > @seayoun\n\nThe PR checks failed because the code coverage decreases with the PR. Basically it is reminding you to add more unit tests.\n\n@@             Coverage Diff              @@\nmaster    #2099      +/-\n============================================\n\n\nCoverage     33.52%   33.37%   -0.15%\n\n\nComplexity     2758     2756       -2\n\n\n\n\nok, thanks you. 1. add executor heart beat\n2. redispatch the flows on the executor which has crashed or has a long time not to hearbeat.\n3. modify executor executo logic, if azkaban.poll.model is off, check wheather the flow belongs to itself, run it if the flow belongs to it's.. add flow fault tolerant if azkaban.poll.model is off. > Hi @seayoun , if azkaban.poll.model is off, it defaults to the current pushing model where web server is responsible for choosing an executor and dispatch the flow.\n\nAre you talking about handling executor failure when azkaban.poll.model is on? If yes, you can check out this PR #2098 and more details in the design doc #2038.\n\nI means if flow run failed on an executor, why don't redispatch the flow on another executor?. What was the original intention design like this if the flow failed and not to redispatch it ?. @jamiesjc \n@HappyRay \n@kunkun-tang \n@juhoautio . the situation on which the azkaban.poll.model is off. if the flow has been running or finished however the flow runs on another executor again, the executor won't begin, but the executorService will not shutdown and it will fall in a sleep loop.. @kunkun-tang \nI looked you want to Todo kunkun-tang: use a common method to transform stringData to data. on method updateExecutableFlow. ",
    "gzm55": "@juhoautio Consider an hourly flow, the input data is at /input/<date>/<hour>, and the output /output//, and the  and  is calculated from the flow.start.timestamp. When an hourly scheduled execution of this flow fails for some reasons, after fixing the problem in many hours, we have to re-run the failed execution, but the new execution cannot get the correct input path.\n1192 is enough, but that issue is not updated for over one year. What I described in this issue has already been used in an internal maintained production azkaban cluster for at least 4 years. So I think this feature should be a quick solution before the whole backfill coming out. . what we do now is something like adding the property flow.base.timestamp=${flow.start.timestamp} in each job definition and getting the value when run by scheduler, but override by the previous failed executions.\nWhen do a re-try, if we treat the original execution as a special parent of the new one, then cloning the input properties which can be override again by user specified new parameters, could be widely accepted. That is,  just add an new source for preparing the properties, shared --> parent --> output --> job source --> [original]. ",
    "Jacob201311": "https://github.com/azkaban/azkaban/issues/1917. ",
    "xiaohui0318": "What plugins are you using to edit azkaban online \uff1fI want to do the same.If you really want to edit online, you'll need to update the project zip content in the database. Take a look at the startup log to see if the executor is really alive, and judging from the error messages, the connection did time out when web connection exec was reconfirmed after the selection. Is the log level debug or info?. ",
    "archongum": "timeout -k 5 120 [command] just fine.\n\ntimeout sends TERM signal after the 120 seconds. If command didn't respond to TERM then sends KILL signal after 5 more seconds. > @archongum my flow config like this:\nconfig:\n  failure.emails: myemailname@xxxx.net\n  failure.action: FINISH_ALL_POSSIBLE\n\nyeah. It works in azkaban-flow-version: 2.0 mode. \nUnfortunately it doesn't work in old version by setting failure.action=FINISH_ALL_POSSIBLE . emm, it works by just changing Failure Options and then schedule.\n\n\n\n. ",
    "xiangtao": "it dosn't use qrtz table . > > it dosn't use qrtz table\n\n\u611f\u8c22\u56de\u590d\uff0c\u90a3\u5b83\u4e3a\u4ec0\u4e48\u4f1a\u6709qrtz\u8868\u5462\n\ndefault value is trun off .\nwhen you use flow trigger feature , you need trun on azkaban.server.schedule.enable_quartz=true. must azkaban 3.X. maybe executor  is down. > use azkaban to update table \nwhat does you mean ?. > When we upload a job with Chinese parameters, it will be messy code on web page after uncompress. We need pass a Chinese parameters like \u201c\u5730\u7406\u4f4d\u7f6e\u8868\u201d as a table comment,but it will be meesy code on web page like \"\u00e2\ufffd\ufffd\u00e5\ufffd\u00b0\u00e7\ufffd\ufffd\u00e4\u00bd\ufffd\u00e7\u00bd\u00ae\u00e8\u00a1\u00a8\u00e2\ufffd\ufffd\", and the table will be created with the messy code.\nok, can you check if your database is utf-8 encoding ? . ",
    "jacyyu1988": "Thanks you for your help. according to your description, I have solved my problem.thank you very much.. ",
    "Augustinian": "@abti hi, could I get someone to review this one, please?. > @Augustinian can you elaborate more on motivation in the PR description?\n\n\nObviously this is confusing. ",
    "edwinalu": "\nIs this still being actively worked on?\nI haven't had a chance to look at the change in details yet. I am not sure I follow the PR description. I can use some help in understanding the goal of this change.\n\nYes, this is still being actively worked on. Let's discuss in person, and I can also add more details to the description.. Could a unit test be added? It's a race condition so harder, but an option would be to create 2 threads which move to the same dir a few times.. Add the following new metrics:\n* submit flow success, fail and skip\n* queue wait time (time between when a flow is submitted, to when an executor starts executing)\n* flow setup time (time to setup a flow, before executing).\n\nThe time that a flow spends in PREPARING state is queue wait time + flow setup time. These metrics will help give more insight into how much time is spent in preparing state, and in which phases.\nFlow submission is when a user requests a flow to be executed, or when a flow is scheduled to run. Flow submission will add the flow to the queue. Flow dispatch is when the flow is assigned to an executor; currently this time also includes the time to setup the flow.. Could you please check the query plan, for the new select with flow_priority, if not done already?. Yes, thanks. How does the explain plan change if an index is added on (flow_priority, submit_time), or (flow_priority, submit_time, exec_id)? Each executor is polling with this query, so it's getting executed very frequently.\nhttps://dev.mysql.com/doc/refman/8.0/en/order-by-optimization.html. Thanks for checking the query plan for the different index variations. As you had mentioned, it is choosing to use the more selective index on status, and the additional index is not being used. . Should awaitTermination() be called, or not needed?. Could the return value for callWithExecutionId be more specific? With Map, anything could be stored as a value, so it is difficult for callers to know what to expect, or how to parse or handle.. Should we only alert if the failure to contact the executor is consecutive? If Azkaban is up for a long time, then it's likely there could be intermittent failures to contact the executor, and these could eventually add up to 6, but the last failure could have been a few days ago. . Since static, change to LOGGER.. Are there any concerns with the call taking a long time to return? How about if there are a lot of executors to process?. Please add some comments for parameters and return value.. Would it be better to set to 2, to test the counting?. Thanks for the reference. For references for logger, could you please remove \"this.\"? It's a bit confusing, since it looks like an object reference: https://docs.oracle.com/javase/tutorial/java/javaOO/classvars.html.. Metrics sound good, just for general monitoring and debugging purposes as well.. Could Object be replaced by a type, which could still be serialized to JSON?. nit: extra newline.. The null is indicating that it is a job (and name is job name). If confusing, I can add a type, or a subclass.. Yes, ImmutableList is better, will change.. Will replace.. Woops, yes.. Yes -- it is used as ReadablePeriod currently. Move away from Joda Time? . The first set (ACTION_, ALERT_) is being used in TriggerManager and SlaAlertAction right now, and are the names of the old keys from the old SlaAction, now SlaActionDeprecated. It would be good to get rid of these. I'd rather move away from code referencing SlaActionDeprecated, so did not want to use the constants from that class. Could TriggerManager and SlaAlertAction be safely changed to not use these?\nFor the WEB_* constants, these are currently used to populate the web object. When the UI code has been refactored, perhaps as part of the REST API work, ideally these would be removed.. I'll add a builder.. There is some code in Emailer that needs both flow name and jobName. Emailer does not have a pointer back to the flow. Ideally the logic for constructing the email message should be moved out of Emailer, which could then be a class for sending emails, and the email text could be constructed by an object that has more context into what the message is about.. Agreed, but currently, email is populated for all SlaOptions, even if the only action is kill. If the user entered in emails, but only had kill type option, we would lose the information. Ideally the email would be stored separate from the individually SlaOptions, since the same emails are used for all alerts. Right now it is also needed for serializing to SlaOptionDeprecated, which is still the storage format in the database for triggers and execution_flows. Similar for emails. If we can refactor Emailer, add columns for ExecutionOptions, etc. to execution_flows, and move scheduling to Quartz, these extra fields could be removed (or moved for emails) then.. Yes, will change.. Yes.. Having the SLA also handle the Condition makes sense. Let's discuss in person to see what this would involve.. Is it possible that the other thread, which downloaded the same project directory, could delete the directory before this thread has a chance to hard link?. We're just eating the exception -- does it make sense to re-thow it, or add some comments explaining?. From disk cleanup, it looks like it takes ~1 hour (up to 2 hours) to remove ~1000 project directories. Removing 1 directory would then be about 3.6 seconds, if this scales.. Recursively creating the hard links may be expensive as well. Do you know how much time it takes on average?. Not related to this change, but does this function need to be synchronized?. Should deletion only be on exception, since the tempDir would have been moved to the project directory otherwise?. Return sizeInByte instead, if available.. Could the tempDir only be created if the project doesn't already exist.. It looks like this should be IOException? Can we use the more specific Exception?. Please add comments for the new methods.. It's possible that another process could have downloaded and moved to the project directory already. Should this check for existence first?. Please add comments for the methods.. In this case, if an execution dir still exists pointing to a project, deleting the directory would not free up disk space. Could you please add some comments.. Do you know how long this takes? Thanks for adding the logging, to get the information. If this is expensive, the executor could also store the information, and update as directories are created and used.. The check to see if the project directory already exists, and then download the project to a tmp dir is outside the synchronized block. 2 threads could check for project directory existence and start downloads. Then 1 thread would go into the synchronized block and move to the project directory. The 2nd thread would then enter the synchronized block, and also attempt the move.. Another option is to have cleaning done in a separate thread. It could check if the usage has exceeded some threshold (perhaps 85%), and start removing project directories if so. It could remove directories until 50% of the space is free. This would move the work (and time) of deletion out of flow preparation, so that flows could start execution sooner. Cleanup would be done offline as needed.\nAlso, it should be possible to safely remove older versions for projects -- only the latest one is saved in Azkaban, and executed for newer executions.. Add unit test for deleteDirectorySilently?. The time in the synchronized block can still be pretty long, at several seconds to delete, move and create hard links. Longer term, it will still make sense to parallelize the setup process for independent projects.. Deleting the files in parallel will help speed up the process. Longer-term, moving the cleanup out of the setup process, such as a separate cleanup thread, will speed things up further.. Change \"will return until every thread in {@link#createFlowRunner} to finish\" to \"will wait to return until every thread in {@link#createFlowRunner}  has finished\".. Interrupts should be re-raised.. It looks like active state is also tracked by Executor. Is it possible for the state to be stored in one place, instead of both Executor and FlowRunnerManager? There would be less chance of the states getting out of sync (if Executor is set but not FlowRunnerManager for example, or just before FlowRunnerManager is set) if there is just one state.. With the new dispatch logic, in pollExecution(), active is checked before selectAndUpdateExecution() and then submitFlow() is called. submitFlow() increments preparingFlowCount, so there could be some lag, and in this amount of time, it's possible that there could be a call to inactivate the executor, and preparingFlowCount would be zero.\nWith the original dispatch logic, I wasn't able to find a check for if the executor is active before the flow is submitted from ExecutorServlet.handleAjaxExecute().\n. This is creating a new String each time the function is called. Can this return a constant String, either one which would handle use_executor, or one of 2 depending on use_executor?. You can use \"?\" for the parameters. Some information at https://docs.oracle.com/javase/tutorial/jdbc/basics/prepared.html. Also examples in uploadFlowFile() and updateChunksInProjectVersions().\nAllocating new String each time means that they will need to get garbage collected. Also, It will need to be re-parsed for the query. The earlier link also mentions reusing a PreparedStatement, although the current code doesn't use this.\nSome databases do query caching, in which case having the same String can help find a cache hit, but it looks like this was removed in MySQL 8.0: https://mysqlserverteam.com/mysql-8-0-retiring-support-for-the-query-cache/. One option is to add an additional check to see if it is active after incrementing preparingFlowCount. If inactive, then skip execution and decrement preparingFlowCount. Might need to update the row in the db, so that it can be picked up by another executor for the new dispatch logic, or return an error, or some status saying the flow was not executed, with the original dispatch logic.. If the text of the String does not need to change, then we can create a constant (final static), and return this constant String. This would avoid allocating memory for each call. It's highly unlikely that a String substituting the \"?\" would be created. The query with the \"?\" can be executed on the database directly, with the bind variables specified.. More info: https://www.ibm.com/developerworks/library/j-jtp05236/index.html. Discussed offline, and Executor is a representation of the db row, and only used in this method, so would not be available in other code looking at isActive.. Why isn't it OK for the sleep to be interrupted?\nPlease add a constant for the 5.. Could a unit test be added.. Could you please also file a JIRA ticket for tracking?. Having the increment for preparingFlowCount here means that it is blocking for the select from the database as well, which is not needed. In general it's better to keep synchronized/blocking code as minimal and as fast as possible, so that more work can be done in parallel, and to minimize the amount of waiting.\nSince this code is not called by the original dispatch logic, the original dispatch logic is still not safe (could still end up preparing flows when inactive).. Please add some comments for the method.. nit: extra newline.. nit: extra newline.. This would also need an else case to call \"this.executorLoader.unsetExecutorIdForExecution(execId);\". It would be possible to skip the outer \"if (this.active)\" check, since this is checked again after the increment, and would save the additional else clause, so would be more concise. . The if check also needs to check if use executor has been set for the flow, and still execute if true.. Please add some comments for isExecutorSpecified(flow).. calls seems unnecessary. How about just having one SlidingWindowReservoir, which is updated with 1 on a hit, and 0 on a miss. Then for calculating the ratio, Snapshot.getMean() could be used.. 100 seems small, for cases where there are a few thousand executions per day. It would be good if this is a configurable parameter (at some point, it would be good to be able to deploy configurations without a complete Azkaban deployment), or if it is time-based (last hour, etc.).. Woops, thanks!. It's a timer, so the test is trying to wait for some time to elapse. I could change to 10ms, to shorten the time.. Updated the tests to use assertJ.. Is there a default value?. Should we update documentation to indicate that azkaban.project_cache_max_size_in_mb has been removed? What is the impact on open source users? An option could be to use percentage if specified, and otherwise max size, although this is more complicated.. I think I already mentioned in an earlier PR, but longer term it would be good to move cache cleanup to a different thread. This can be expensive and time-consuming, and isn't necessary as part of flow preparation itself. Moving cleanup out of flow preparation would help speed up dispatch.\nOne option would be to have a ConcurrentHashMap with key as  and value as a Lock. The lock would then be at the project/version level, so flows accessing different projects would not need to block on each other. The lock would be gotten as part of flow preparation and cleanup for the project.\nThe lock could also be done as a ReentrantReadWriteLock, but if the time in the synchronized section is small (would usually just be the time to hardlink), then this may not add a lot of value. In this case flow preparation would get a read lock (creating the lock if it does not exist) and check if the project directory already exists. If the directory does not exist, then upgrade to a write lock, check again for directory existence,  create the project directory if needed, then downgrade to write lock. Cleanup would get the write lock, and delete the directory. It would be good for cleanup to remove the lock from the hashmap as well, but this would be trickier with concurrent readers, so we'd want to do some testing.\nNote that this would only handle concurrency within the same JVM. For upgrade, when there may be 2 executors (old and new), then we would need to be careful that they are not both modifying the cache (creating new project directories or removing them) at the same time, such as your PR to wait during executor invalidation. The old executor should also be prevented from cleaning up the cache. \nAnother option could be to use directories and files within the project directory. There could be a .lock directory, and each thread could create a file with its . Cleanup would remove the empty .lock directory.\nWe could have 2 parameters, max and min -- the cleaner would delete which the max threshold has been hit, and delete enough to get to min. Note that min is not necessarily the min cache size, since it can hold less. The reduces the number of times the cleaner would be doing and ls and computing the sizes for the shared cache directory, which has some cost.. Agreed that it would be good to have a more official release process, so that it is clear which versions are still in development and subject to change, and which are production ready. . I'm planning to move the flow preparation logic to the execution thread, and will need some of the same data structures, so can take this up.. ",
    "lcaaaat": "It seems there is not enough resource(e.g. memory) to dispatch flow.  Could show me the value of \"azkaban.executorselector.filters\" and \"azkaban.executorselector.comparator.xxx\" in conf/azkaban.properties?. The free memory of azkaban executor server must be more than 6G if you enable \"MinimumFreeMemory\". If not, web server will not dispatch flow. So, you can solve it by \nremoving \"MinimumFreeMemory\" in \"azkaban.executorselector.filters\" or using another server which has more free memory to deploy azkaban executor server.. ",
    "zak000": "Hello all,\nThe name of the plugin was not correct, i changed it to match exactly the name of plugin (hadoopJava) and now it works.\nThank you. I was able to solve the issue by exporting HADOOP_HOME and conf dir.\n. ",
    "BodhiFlower": "\nTake a look at the startup log to see if the executor is really alive, and judging from the error messages, the connection did time out when web connection exec was reconfirmed after the selection\nmaybe executor is down\n\nThe problem was solved temporarily, but not in a reasonable way:\nI had no intention of trying to process the request: http://node151:12321/executor? Activate action=activate this address so that all my tasks can run as normal.\nI tried again and again, but the error was not resolved when the execution port was not fixed.\nIs this because something is not configured properly?\n. > \n\nIs the log level debug or info?\n\nINFO. ",
    "lecterqian": "property active in class FlowRunnerManager is false default, there should be true by some way,This value can only be set true by method 'handleRequest' whtin class \u2018ExecutorServlet\u2019 . it confuse me ,too.  I use exec server with polling model in new desgin. . @burgerkingeater \n1. thanks,I modify column \"active\" from 0 to 1 in table \"executors\" in old desgin ,and method \"createFlowRunner\" do not need \"active\",used in 3.69.0.\nBecause i think one executor data have been inserted,it should be active,and it troubles by using this call \"executor host:executor port/executor?action=activate\",may be web-server can show all executors, then user can choose executor to enable,after all, may be some user is not  programmer,and they do not know commands like \"curl\".And do commands manually,you should call command again when executor from up to down,and then up or there are many executors.\n2. Database lock used in new desgin, \"select for update\" used like Quartz, I find do much for realse db lock in Quartz, why do not use other distributed lock, and if use db lock, db server will grow pressures when have much jobs to schedule, because web-server and executor-server will do much with db.\nwhy do not save not complete flow and job in db like redis, when flow complete then save to database,db just save flow and job info and final status of them like sucess  or fail. Memory db can be queue,and save the flow other status exclude final status.\n. ",
    "FsecureSamiTikka": "We had this problem. We run in ECS with one container called azkaban-webserver and another called azkaban-executor. In our db there is only one executor named \"azkaban-executor\". We suspect during upgrade the old azkaban-executor must have marked the executor inactive in database.\nAs a workaround we changed our container entrypoint to start azkaban-executor and then call curl http://localhost:port/executor?action=activate to make sure the new executor is active.. ",
    "LightSunshine": "When we upload a job with Chinese parameters, it will be messy code on web page after uncompress. We need pass a Chinese parameters like \u201c\u5730\u7406\u4f4d\u7f6e\u8868\u201d as a table comment,but it will be meesy code on web page like \"\u00e2\u0080\u009c\u00e5\u009c\u00b0\u00e7\u0090\u0086\u00e4\u00bd\u008d\u00e7\u00bd\u00ae\u00e8\u00a1\u00a8\u00e2\u0080\u009d\", and the table will be created with the messy code. . yes, MySQL is utf-8 encoding . ",
    "abcfyk": "\nconfirm the MySQL charset configurations :\n\n\n1.1 if not, copy below configs to your mysql config file, normally /etc/my.cnf\n```\n[client] \ndefault-character-set = utf8mb4 \n[mysql] \ndefault-character-set = utf8mb4 \n[mysqld] \ncharacter-set-client-handshake = FALSE \ncharacter-set-server = utf8mb4 \ncollation-server = utf8mb4_unicode_ci \ninit_connect='SET NAMES utf8mb4'\n````\n1.2 restart mysql\nservice mysqld restart\n\nchange azkaban db and its tables' charset to utf8\n``\nALTER DATABASEazkabanCHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;\nALTER TABLEproject_flows` CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci; \n````. \n",
    "tigerpeng2001": "I think it would be better to have links point to old versions.\n. ",
    "superpaul": "merged updates on a separate files instead.\n. ",
    "sengelbert": "Updated the PR. Git commit comments cannot be changed as far as I know.\n. ",
    "flowbehappy": "ok\n. ",
    "vvii": "Right, you did a better job if considered other bugs like this.\nBut, it seems no necessary to call the statement\n\nmessage.setTLS(tls)\n\nat the public method sendFirstErrorMessage and sendErrorEmail in azkaban-common/src/main/java/azkaban/utils/Emailer.java based on your fixes.\nI don't know why the previously submit did this things. maybe you can remove the statement from the method sendFirstErrorMessage and the other likely method in azkaban-common/src/main/java/azkaban/utils/Emailer.java in your fixes? \nOr just use the fixes in this issue to keep consistency with previously submit code ?\n. ",
    "nntnag17": "This seems to be a very old version. Can't we use the latest version?\n. Latest is 1.4.192 in mavenCentral.\nhttps://mvnrepository.com/artifact/com.h2database/h2/1.4.192\n. ",
    "gaofan0905": "please update the comment \"Internal username used to perform SLA action\". Normally static final param name should all be capitalized according to LinkedIn coding convention. \nAlso please check if this one need to be public or not.. objType might be null? Better to use type.equals(objType) instead to avoid NPE. The description can be improved to make it more helpful. ",
    "sbeeram": "Did you consider making HiveConf a parameter to create()? That way you can work with just one Factory instance.. It seems odd that cancelHiveToken is a local cluster operation. Do you know why thats the case?. Use Javadoc format for method level comments; it would be better to say, \"Method to create a metastore client that retries on failures\". Update the method name to be createRetryingMetastoreClient. The comment is misleading; what you could say is \"Custom hook-loader to return a HiveMetaHook if the table is configured with a custom storage handler\". ",
    "herrlich": "Yes, it seems that we only have META_TABLE_STORAGE under that should be imported. But intellij auto-imported it as \"org.apache.hadoop.hive.metastore.api.hive_metastoreConstants.*\". Should I change that and start a new pull request?. Yes that solves the problem. Already updated the code. Sorry forgot that. Copied the unit test template from another file, will modify that.. In this way, I think hive will throw an exception.. Discussed offline. ",
    "eogren": "Should this take the Credentials object as an explicit parameter?. I'd probably call this CredentialProvider or something like that. ",
    "fitzlchen": "Hi @kunkun-tang , thanks for reply. Actually, there is no proxy check before executing flow. And the bug can be reproduced.\nFollowing are my steps:\n1.Before doing an experiment, I created a user who only has read permission. The conf/azkaban-users.xml looks like this.\n```\n\n\n\n\n\n\n\n\n```\n2.start Azkaban-web-server and login in as read.\n3.create a project and execute flow. Before executing flow, set user.to.proxy property to azkaban. \n4.Azkaban completes the job successfully.\n\n\n. ",
    "hungj": "Thanks for the review @kunkun-tang, yes it will be used by spark. \nAlso I added some unit tests for this function.. Thanks for the pointer @HappyRay , updated the PR. ",
    "mkumar1984": "Removed. . Removed static block. . Changed.. Yes, used AbstractProcessJob's constant. . Added a constant. . Yes, moved to TuningCommonConstants. . "
}