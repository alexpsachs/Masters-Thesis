{
    "treeder": "I think this is done, need to double check. \n. I added a content-type one for routes, but that should probably change to the full header support. \n. Noticed we're buffering the entire response, we probably need to stream it so we don't run out of memory. https://github.com/iron-io/functions/blob/d8733575dac56a2e6dfb0b11857cd6b89824e46c/api/server/runner.go#L131\n. cc @edsrzf @pedronasser \n. Closed by #80 \n. Dupe #61 \n. There should be some code for this in Titan we can use. \n. PR for this is at #62, but it is WAY too slow. If this can't return quicker, we should remove it.\nI notice you're doing a full image pull @henriquechehad  on this: https://github.com/iron-io/titan/blob/42f6860c289d446e90195f23ddf3b026fe76d2e8/runner/drivers/docker/docker.go#L510\nWe can't do that.\n. #83 is 1000x better than before, but still slow. Maybe still too slow, but we'll leave it for now and can decide if we should move it elsewhere later. \n. Dupe #61 \n. Should essentially do this for each directory: https://github.com/iron-io/functions/tree/master/examples/hello#building-image\nAnd also register the update image with the route. \n. I'm going to merge this, but can you update the README with information about how to run this with the different datastores, see Titan's README's for info. \n. This obviously requires documentation updates due to the API changing. Please be sure to document things very well, if it's not documented it doesn't exist and breaking documentation is probably the worst bug we can have. \n. This should all be in managed repo, not open source repo. \n. Can you redo this one, these PR's are so big, hard to review. I think this will be smaller now that the others are merged. \n. @pedronasser  This isn't what I had in mind, each package should be fairly independent and reusable. The globals should be in in main, not in the packages themselves, you have:\ngo\napi.Config.DatabaseURL = os.Getenv(\"DB\")\n    api.Start()\n    router.Start(api.Router)\n    api.Router.Run()\nThis should be something like:\n``` go\nvar api api.Api\nvar db db.Datastore\nfunc main() {\n  config := ...\n  db = db.New(dbUrl)\n  api = api.New(config, db)\n  api.Start()\n...\n}\n```\nI'm just doing that off the top of my head, so it's probably not totally correct, but you get the idea. \n. @henriquechehad please update ALL examples, not just the hello one. \n. @henriquechehad where's the PR addressing this issue?\n. @edsrzf @pedronasser thoughts on this?\n. Let's implement this with #52 for now, that's useful for various things including the query params. \n. Can bring this back at a later date. \n. @henriquechehad needs a rebase, can't merge. \n. Working on #10 first in order to get wait times... \n. Neither, just log it.\nOn Fri, Sep 2, 2016, 4:53 PM Henrique Chehad notifications@github.com\nwrote:\n\n@treeder https://github.com/treeder about the counts, save it in\ndatabase or just in variable memory?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/issues/61#issuecomment-244512214,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAEoMhhd_gVDoRTJ61ZjyL8lrdaAfH2eks5qmLbwgaJpZM4JqRQK\n.\n. This is WAY too slow. If this can't return quicker, we should remove it. \n\nI notice you're doing a full image pull on this: https://github.com/iron-io/titan/blob/42f6860c289d446e90195f23ddf3b026fe76d2e8/runner/drivers/docker/docker.go#L510\nWe can't do that. \n. I think this PR is for #7 ?  I'll add this comment there too. \n. @derekschultz can we get this out now?  The murano package, the runbook and how about a blog post too?\n. Can you reference why you are closing these @pedronasser ?\n. So we can run containers and not care what's in them. \n. We do have constraints and they are very simple:\n- Must be an executable container (ie: one with an ENTRYPOINT)\n- Input is via STDIN, in whatever format we decide\n- Some extra values provided via ENV vars (user and system provided)\n- Output is via STDOUT\n- Logging is via STDERR\nIt's essentially the same constraints as a program running on an OS. What's inside the container doesn't matter, that's the beauty of it. We can provide higher level libraries like iron-io/lambda or somebody else could build something even better as additional tools, but we don't need to force a specific way on any of us. And doing that doesn't provide us any benefit other than more things to maintain. \nThis also ensure no lock-in and that these things are portable. \n. I get what you're saying, but we did the same thing with IronWorker. Started with an enforced API with libraries for languages and we ended up just letting people do whatever they wanted in their own containers in the long run. I'm not against making something like the lambda library be something we put in our docs and what not, but the lower level stuff will be exposed regardless as it's an open source project. \nI think if we can define those few baseline things that will hopefully never change (or very rarely), then we don't have the issues you describe. We can get some early feedback during beta that will allow us to change it before going GA and hopefully give us a chance to get it right. \nReally, I think the only thing in that list that requires discussion at this point is the format of the input and what ENV vars will be provided by the system.\n. And to add to that, we need to get that underlying stuff correct anyways since the wrapper libraries will be locked into whatever we decide, as we can't change people's images after they've been built. \n. Also, it may not be hard to version these things so if we do get it wrong in the beginning and we want to update something like the input format, we can while still being backwards compatible. An image can be registered to use different versions and the system will pass in different formats based on the version. \n. 1) Depends on your definition of FaaS. The powers that be say: \"Fundamentally FaaS is about running back end code without managing your own server systems or your own server applications.\" - http://martinfowler.com/articles/serverless.html#unpacking-faas and \"If your PaaS can efficiently start instances in 20ms that run for half a second, then call it serverless.\" - https://twitter.com/adrianco/status/736553530689998848?ref_src=twsrc%5Etfw . Even if you look at the definition of function, what we're doing in 1 is still valid. \"In mathematics, a function is a relation between a set of inputs and a set of permissible outputs with the property that each input is related to exactly one output.\" - https://en.wikipedia.org/wiki/Function_(mathematics) \"Functions are \"self contained\" modules of code that accomplish a specific task. Functions usually \"take in\" data, process it, and \"return\" a result. Once a function is written, it can be used over and over and over again. Functions can be \"called\" from the inside of other functions.\" http://www.cs.utah.edu/~germain/PPS/Topics/functions.html\nI'm not sure if you've found some different definitions that would make you say this has nothing to do with FaaS?  You even define a function in your argument against it: \"These containers want input in some way and output will be to stdout. \"\n2) I don't disagree with most of your points about using HTTP format, but there are some important things to consider. \n- Where do we put things like configs and other IronFunctions related values?\n- We can't add or modify it after we've chosen it (well, we could, but then we'd break the spec anyways)\n- It's not exactly the easiest thing to parse, json and other more well defined formats would be a lot better\n- This assumes we'll only ever support HTTP. What if we add gRPC/protobuf support? Or any other protocol?  The functions themselves shouldn't really care what protocol is used. \n. For reference, the inputs to a function are the following:\n1. App level configuration - good place for credentials, etc\n2. Function level configuration - config specific to a particular function, maybe credentials, maybe an s3 bucket name, etc.\n3. Request input - the HTTP request body + headers\n. Hah, that's interesting and funny. Hadn't thought of that, but ya, I guess it is sort of a new CGI. \nDoes it need another pipe if we're using stdout as the outgoing pipe?\n. The answer to the question asked in this issue is a yes, so I'm closing it. \n. LGTM\n. Added https://github.com/iron-io/functions/issues/77 to follow up on the route lookups. \n. Some comments.\n1. Please link to related issue (ie: #40 ) or if this closes an issue, say Closes #X. \n2. I still see payload env var here: https://github.com/iron-io/functions/blob/0067a27aa920141d11998be468f75d1416cbd3bb/api/server/runner.go#L120\n3. Link to required related tickets, eg: https://github.com/iron-io/titan/pull/325 . This one is most definitely required before this ticket can be merged. \n4. You called it InputStream, but then used a string?\n. Needs rebase and description needs updating. \n. @pedronasser can you review this PR please, thanks. \n. @henriquechehad I've got this one. \n. Added user_log=true too, just to flag these lines as user logs. \n. @pedronasser can you go here: http://docs-new.iron.io/docs/calling-functions , click Suggest Edits and add info on this for users. All of these types of features need accompanying documentation. \nOtherwise LGTM\n. cc @rdallman @nikhilm Assume these are part of the Docker driver?\n. For review @pedronasser @nikhilm \n. This may have been when I surf to an app/route that doesn't exist. In fact, might be a completely empty database. \n. @seiflotfy make another issue for that?\n. Is anyone getting this?  Going to close since it seemed like a one time thing. \n. LGTM\n. LGTM\n. I mean does anything like graphite or influx have a \"time\" metric?  I've never seen it. I think you wanted a gauge metric for durations. \n. @henriquechehad @pedronasser's blog example should use this, I haven't had a chance to review it yet though. https://github.com/iron-io/functions/pull/87\nIt's in the example, but not in the docs, can you add how this works to README?\n. I think we should hold off on this until we figure out how to properly query these things. See https://github.com/iron-io/functions/issues/142\n. LGTM\n. So I was thinking about how this could work on a single binary/machine (instead of separate runners), and had this idea:\n- a request comes in\n- if sync, put in sync channel - implemented (partially?) here #92 \n- if async, put in message queue\nThen we just have a single go routine that does the following:\n- read off channel, if task exists, fire up go routine to execute it, write the results to the HTTP response. If no sync tasks:\n- read off message queue, if task exists, fire up go routine to execute it (probably nearly the exact same way as above, except we don't write any results\nOr maybe those are two go routines, but the second one pauses until resources are available. \n@seiflotfy @pedronasser \n. Ya, good point. Shouldn't starve it completely, but sync has to take priority for the most part. Also, starvation shouldn't happen often as autoscale should kick in. Perhaps you could start boxes that only deal with async too (ie: not behind LB)?\n. @rdallman prepare is not the same as ensuring the image exists. You're doing a lot of stuff here that takes too long and is not required for this check, in particular pulling the image. \nThe point of doing this when adding a route is for a good user experience, they get immediate feedback that they did something wrong, rather than waiting until sometime in the future and then having to go debug through logs to figure out what went wrong. \n. Sounds good. \n. Dupe of #112 \n. I believe @rdallman has something like this for IronWorker, we could probably make use of the same code here. \n. - https://github.com/iron-io/functions_go\n- https://github.com/iron-io/functions_js -> https://www.npmjs.com/package/iron_functions\n- https://github.com/iron-io/functions_ruby -> https://rubygems.org/gems/iron_functions\n. Current docs in README for reference:\nAdding a route with URL params\nYou can create a route with dynamic URL parameters that will be available inside your function by prefixing path segments with a :, for example:\nsh\n$ curl -H \"Content-Type: application/json\" -X POST -d '{\n     \"route\": {\n         \"path\":\"/comments/:author_id/:num_page\",\n         \"image\":\"IMAGE_NAME\"\n     }\n}' http://localhost:8080/v1/apps/myapp/routes\n:author_id and :num_page in the path will be passed into your function as PARAM_AUTHOR_ID and PARAM_NUM_PAGE.\nSee the Blog Example.\n. @ccirello @seiflotfy @pedronasser ready for review. \n. Well it takes like 10-20 seconds to shutdown with no async tasks running, so that's not really the issue. \n. Actually, it may have to do with the timeouts I'm seeing from the async worker. \n. Is that really 1.83 minutes?\n. I wonder if Docker has a lock/mutex while doing these operations so only one can run at a time...?\n. For docs and client libs. Which is what swagger was made for. How do you think we're misusing it?\n. @pedronasser you can copy this one over, it's mostly done, would need to change to read stdin though: https://github.com/treeder/slackbots/pull/6\n. Guys, let's not have dependencies that aren't publicly available on github or some open repo. Please remove the cirello.io/supervisor dependency.\n. Well, it's already defined on the route so we know whether it's sync or async. This ticket is about using the same runners for sync and async, rather than separate like they are now. Per the comment in the link above. \n. I'm pretty sure this isn't done. Async is still totally separate from sync from what I can tell. . Ok, thanks for link. . @seiflotfy @ccirello @pedronasser \n. Nice, this is showing how to trigger a function from ceiliometer right? Maybe we should create a triggers directory...\n. Why don't we put this in examples/triggers/openstack-ceilometer ?\n. Actually, maybe let's make triggers/ a top level directory?  I think this stuff will be important.\n. @seiflotfy @ccirello \n. Regarding contributing docs, yes, but let's just make new PR's. \n. Is NewTask part of the API?  Seems like it shouldn't be. \n. @ccirello there's never been delayed task support, that was in Titan. \n. We can automate it, but let's keep it in a script in this repo like it was, so we can modify it via git. There's nothing private about it. \n. There's no documentation in here how to use this. Let's make a docs/lambda.md and put a lambda quickstart in there. \n@rdallman should use your new cli tool for that doc. \n. Still should try to fix this, the default way this runs is with dind. \n. Not a critical thing though, don't spent too much time on it right now, can deal with it later. \n. I believe this is fixed now? I don't think it shows up anymore. \n. @ccirello @seiflotfy @pedronasser \n. Please don't remove any of the docs related things, I plan on finishing all these before launch. \n. We don't, it's alpha, that doc is how you'd run it in production if you want. \n. Probably best to leave this up to the load balancer. \n. gin automatically uses the \"PORT\" env var, so we don't need to do anything. \n. See #90 for prior discussion.\n. Turns out rkt is quite a bit slower. rkt is about 3x slower than Docker for both rkt images and docker images (rkt can run Docker images). \nThe times below are pretty consistent over consecutive runs, these were run on a CoreOS machine on Digital ocean with 2GB of RAM (nothing else happening on the machine).\nrkt running Docker images:\n``` sh\ntime sudo rkt --insecure-options=image run docker://treeder/hello:sh\nimage: using image from local store for image name coreos.com/rkt/stage1-coreos:1.14.0\nimage: using image from local store for url docker://treeder/hello:sh\nnetworking: loading networks from /etc/rkt/net.d\nnetworking: loading network default with type ptp\n[  864.586438] hello[5]: Hello World!\nreal    0m0.877s\nuser    0m0.546s\nsys    0m0.171s\n```\nrkt running rkt images:\n``` sh\ntime sudo rkt run quay.io/coreos/alpine-sh --exec /bin/echo -- \"Hello World\"\nimage: using image from local store for image name coreos.com/rkt/stage1-coreos:1.14.0\nimage: using image from local store for image name quay.io/coreos/alpine-sh\nnetworking: loading networks from /etc/rkt/net.d\nnetworking: loading network default with type ptp\n[ 1459.130368] alpine-sh[5]: Hello World\nreal    0m0.862s\nuser    0m0.525s\nsys    0m0.204s\n```\nDocker on CoreOS:\n``` sh\ntime docker run iron/hello\nHello World!\nreal    0m0.329s\nuser    0m0.013s\nsys    0m0.007s\n```\n. Oh sweet, I'll give it a try.\nOn Sun, Oct 23, 2016, 4:57 PM C Cirello notifications@github.com wrote:\n\nIt takes stdin, returns result as stdout. And you can pipe in the shell.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/issues/196#issuecomment-255623788,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAEoMta9Hls153OZzxN1RXqkEbKjDFxOks5q2_ROgaJpZM4KeSj0\n.\n. I created http://get.iron.io/fnctl , but won't really work until this is public. \n. Don't think this should be in the docs yet since none of it exists. Maybe move it into an issue for later discussion. \n. I'm going to reopen this for Alpha 2, to ensure we get the rest of the languages. \n. Can we close this?. What does this mean exactly?\n. @ccirello can you check now. \n. Probably a lot of overlap/conflicts here from #228 that was just merged, can you merge master into this and go through it again. \n. merge conflict now too. \n. @seiflotfy suggested every major PR requires an update to CHANGELOG.md. . @noqcks do those changes resolve this issue?\n. @pedronasser quick review on this?\n. @ccirello I found a bunch of places you missed, did you search to find all the places where DB= and MQ= were used?\n. @ccirello please review/merge #261 \n. Probably don't need app here, just image, version and runtime. We don't know the app name nor is it required for building or pushing. \n. Regarding the size of this PR, it's the smallest I could do it to make something useful and this is only for two languages! Still needs more for all the other languages. I think this whole thing can be simplified quite a bit by removing all the scanning/walking as the default behavior, just work off one directory by default. Also, the language helpers can deal with a lot of things particular to a language rather than scattering those things throughout, like acceptableFnRuntimes and fileExtToRuntime for instance. Just lookup the helper, get the LangHelper interface and use the same methods for all languages. \n. Conversation about convention over configuration: https://open-iron.slack.com/archives/functions/p1479141666000091\n. Ready for review @ccirello @pedronasser @seiflotfy \n. Created a separate issue for dns/ssh install. #304 \n. @ccirello @seiflotfy @pedronasser \n. Do any of these changes require swagger update?\n. re #276 \n. @ccirello can you review\n. Conversation: https://open-iron.slack.com/archives/functions/p1479513871000630\n. Cosmetic issue. \n. Dupe of #197 \n. Yes, we probably should at some point. \n. hi @savaki , did you see the diagram here? https://github.com/iron-io/functions/blob/master/docs/operating/production.md\n\nLifecycle diagram would be a good idea. \n. Related: #151 . Couple questions @ccirello:\n- The work done in #10 should have made it bound to the max number of runners, with a small buffer (100 requests), then the rest get rejected. Unless that didn't get implemented like the issue description? cc @pedronasser \n- What's the point of resizing the number of runners?  There's always some fixed limit to the memory available right at the start. We can't go above it and there's no loss for keeping them running when below. \n. Should be able to use sleeper image: https://github.com/iron-io/functions/tree/master/examples/sleeper to test this. \n. @denismakogon exposing ports and running your own API inside IronFunctions defeats the whole purpose and as Carlos said, that's not how Lambda works either. Have you even tried IronFunctions?  It's got the API gateway built in. The quickstart gets you up and running with an API endpoint as the very first example. . @jezell how would you distribute the images to the cluster of functions nodes in a \"never pull\" scenario?\nOr would it just be on you to ensure those images are on every machine before hand?\n. Document custom registry: https://github.com/iron-io/functions/issues/357. I think fn publish should work something along these lines:\nfn publish APP_NAME\n\nRecurse through all subdirectories\nIf there is a func.yaml file or a Dockerfile, build the function and push it\nUpdate route with IronFunctions server. Route path being the route defined in the func.yaml file or the directory name. (should route be changed to path in func.yaml?). App name being APP_NAME. \n. Maybe we should change the name of this command too, since it's really only for bulk deploy. . Let's fork this example: https://github.com/bfirsh/serverless-docker-voting-app and get it working with IronFunctions, it's a good example for this exact thing. . I agree, we should probably remove app_name from any per function things, the app is defined while executing fn commands and one function may be used in many apps, doesn't make too much sense to hard code it to a function. . Added a follow up issue with checklist to resolve this. . Is there an endpoint to tell it to stop?. Should also have a timeout on the routes too, so we're sure that it gets updated if something changes. \n\n. Just curious about the comments here, the route key should only contain what we can get from the user request, not everything about the route. Which basically means the key should just contain the app name and the path.\n. @pedronasser looks like I didn't answer your question, the IRON_TOKE N iss there because that's what all Iron users use right now. . @pedronasser can you fix conflicts, then I'll review. . @pedronasser conflicts?. @pedronasser are you going to update the names of those functions?. This broke the docs: https://github.com/iron-io/functions/blob/2a09a1c2a2ddc7e1192b316083726478d81e49a8/docs/operating/extending.md\nStill has ifaces in it. \n. I believe this is because files made inside docker have the wrong permissions, we probably have to run a chmod on the bolt file that is created. I had to do this for everything created inside docker in another project as you can see here: https://github.com/treeder/dj/search?utf8=%E2%9C%93&q=chmod\n. I think this makes sense, but currently we don't keep track of any task status, other than outputting it to the logs. We probably do need to have this for async tasks, otherwise there's no way to check if a task was successful or not (other than parsing logs). \nBut how does this relate to #528?\n . Probably makes sense to store each request in the database along with a state/status column, as @seiflotfy said above. \nI think middleware and/or listeners are going to be a great testing/proving ground for a lot of features. Then as they stabilize and/or become something everyone wants, we can make them part of core. \n. You're right, probably related to this issue then: https://github.com/iron-io/functions/issues/420\n. We need load balancer before we can do this, i'll move this to beta 2. . This is cool, but let's wait until it's officially supported in Go and works on all platforms. . @ccirello this isn't recursive, just deploying a single function. The purpose of this issue is that I wasn't able to update the route with the new version. fn update route ... doesn't exist (or didn't when I created this issue). Will have to try again to see if this has been fixed. . @pedronasser is thie one done now with your recent changes?. Does this run glide install for every build @ccirello ?. @martinpinto nice!  Could you make a pull request here?  Maybe put the files under /fn/chocolatey directory. . Or share the repo you have. . We'll probably have to do the initial upload though so we can own chocolatey package name if you don't mind?. Regarding response bodies, agree, we should try to make every response a JSON response, with appropriate information in the json error message, as we do with other errors. \nThat said, it really depends on the error as to what we return to the user. The user shouldn't know about a backend database error or something. Some things should just be logged and return an internal server error to the user. Similar to a website, where it says to try again later. Errors like 4XX errors should return helpful messages, but 5XX errors may not be appropriate to return to the user. \n. This looks like a lot of changes to the commands. Can you provide examples of the changes in the description of this PR?\n. @pedronasser do your new changes fix this?. I can see the benefit of the smaller interfaces from a user perspective, but also felt more complex, more things to know about. And this is only for apps, we'll need the same thing for routes and whatever else a user will be able to do in the future. \n. @ccirello @seiflotfy @pedronasser could someone review this please. . What if we do something along the lines of heroku style configs? https://devcenter.heroku.com/articles/config-vars. config:set and config:unset. Are there any docs that go along with this?  Would like to see examples of these changes. . Yes, that's great. Can you add that to the docs, that's actually a lot more clear than what's currently there: https://github.com/iron-io/functions/blob/master/fn/README.md\n. Hi @cruxnet , yes, we'll definitely be providing ways to add authentication/rights management in a future release. By next release (beta 2), we'll have the middleware and listeners all fleshed that will enable plugging in auth providers and what not. You can see that branch here and see how to use it: https://github.com/iron-io/functions/pull/474\nWe're using that to implement authentication in our internal Iron.io cluster. \nFeedback welcome. \n. @wujianlin run make dep to install dependencies into the vendor directory. . Thanks!. I think this would be awesome. . Per https://github.com/iron-io/functions/pull/490#discussion_r97586942, were you going to provide a fix @jmank88 ?. @ccirello link on fn call would probably have to be different since the link would have to be made while starting the iron/functions container. So really link is only valid on fn run for testing. With regards to rocket and others, I don't really see a way around not having the link to do local testing so may have to have it regardless of future tech we support. \n. Thanks @jmank88 !. Hi @jakepearson noticed you closed this, did you figure out the issue?. The README has the -L option already in -sSL so it should have already worked if that was the issue. \ncurl -sSL http://get.iron.io/fn | sh\nMaybe it's something else?\n. Closing, #532 replaces this. \n. The fn part of this is a dupe of #501 . . Ya, we've been assuming people will be using Docker for Mac going forward - https://docs.docker.com/docker-for-mac/ - which handles localhost properly. Perhaps we need a troubleshooting page with all the little gotchas. . Need to somehow test the docs or something. We're not updating docs along with code very well. . I don't see why we couldn't allow this via a port, could be an option. But I think long term (few months), people would typically use a wrapper lib to handle most of the plumbing for hot functions, so may not really matter from a user perspective. \n. Great stuff!  Keep in mind we'll probably want to support other databases in the future too so techniques that apply to any database preferred. I suspect what you do with Bolt may solve that problem though. . @jmank88 seeing as how this is a very large PR and hard to fully grok, could you provide more insight as to how you solved this in the generic case that doesn't have features like regex queries?  \n\n. Updated.. The check I removed on creating and updating the routes should probably be removed regardless, it makes that API call too slow. I'm thinking it should just be done at run time now (which I believe is already the case). \n. Can I get an approval or what?. I meant to choose \"request changes\"\n. thanks!. Do you mean an explicit/manual pause or automated?  \nCurrently the default without hot functions is essentially what you are talking about, isn't it?\n. Oh, looks like we need to merge a PR: https://github.com/iron-io/functions/pull/526\nOnce that's in, this should be fixed. . Hmmm, that sounds right, 5XX of some sort is probably most appropriate. \n. Hi @adelevie , you should be able to do this already with make run-docker.\nhttps://github.com/iron-io/functions/blob/master/Makefile#L34\n. oh, need to run glide install -v, give me a minute, I have a docker image for glide we can do that with to make it so you don't need go at all. . Pull request here: https://github.com/iron-io/functions/pull/545\n. Try make docker-dep in that branch. . Oops, try that again. . I changed them all to docker-, so now it's docker-dep, docker-build, docker-run and docker-test. \n. Did it work ok?. Yes, you're probably right. I'm sure that could be accomplished with another docker run on a go container. Want to take a stab at getting it all working?  . Oh, ok. I'm thinking the runner probably shouldn't be logging that, it's up to the caller to decide what to do with the error. And what if at some point in the future, the runner decides to stop logging that?  Then it's lost in the void and turns into a debugging nightmare. cc @rdallman \nRecent Twitter thread I noticed on this: https://twitter.com/peterbourgon/status/834350104043741184. No, not a big deal at all, just saying we should log it too, just in case runner decides to not log it in the future and the error disappears into the void at that point. . Maybe we start here with global docker credentials, then once we add some authentication middleware, those could also have per user credentials. . @BupycHuk has some conflicts here. \n. Thanks @jmank88 !. Is this only for async functions?  We named them call_id in reference to a \"functions calls\", not sure we should have task_id and call_id. . The main thing that bugs me about this is having different names for essentially the same thing. We should choose one or the other across the board. . I think someone must have been broken in some recent commits. That should work and I just verified and got the same error. \ncc @pedronasser @seiflotfy . @seiflotfy it used to read the image name from func.yaml, now it doesn't seem to work. . Should be fixed now, get latest cli and try again. . Thanks!. Could we change that line to use a Go image, eg: docker run ..... go:alpine sh -c 'go list ./... | grep -v vendor | grep -v examples | grep -v tool | grep -v fn | grep -v datastore' ?. CircleCI isn't updating these statuses very well lately. . Thanks again @jmank88 !  These are awesome contributions. . @jconning can you verify this is fixed now?  re: #580 \n. @mikeball can you test latest after #572 fix?\n. fnlb needs a lot of work still... Saw your test harness for it, nice work. #573 . @jconning this is awesome!  Will review shortly. . Need docs for this: #596 . This looks great!  But looks like there may be some overlap with #547, which adds an fn docker login command. I have a feeling these can coexist as yours appears to take env vars whereas #547 stores the auth in the database (which may make more sense when we have support for authenticating different users and they use their own registry credentials). \nAlso, could you add some docs for this?. @rcarmo this would be great, we've been talking with the https://www.packet.net/ guys about getting this running on their Type 2A server (96 physical cores), would love to make it happen. We could probably build in an ARM flag for the cli that built functions on the correct base images to make it pretty painless (thinking out loud). \ncc @vielmetti . This is more than just building the functions binary, that part is easy. The hard part is enabling users to run their functions on an ARM machine which requires different images for their functions which I believe @rcarmo is referring to when he created this ticket. \n\nAlthough it would require bootstrapping a new set of base containers, it would be nice to have armhf support.\n\nOr maybe not?  But we'd need to make it easy for users to create ARM functions regardless. It's possible to run functions without dind (mount the docker socket), but it would be nice to support it. \nHow does this look as a full checklist for what we need:\n\n[ ] An ARM functions build - image name iron/functions:arm - preferably with dind support, but could start without dind\n[ ] A set of ARM base default base images that fn tool can use. \n[ ] Implement a --arm flag for the fn tool to build using the ARM base images - user/image:X.Y.Z-arm\n[ ] Implement a --arm flag for fn push (?)\n[ ] See if we could push multiple architectures at the same time to the Docker registry and use the multi-arch manifest support - see https://github.com/iron-io/functions/issues/577#issuecomment-286313028\n\nDoes that sound like everything we'd need?\n. Official ARM images: https://hub.docker.com/u/aarch64/\n. And multi-arch issue: https://github.com/docker-library/official-images/issues/2289\n. Looks like we can do the same with armhf: https://hub.docker.com/u/armhf/\n. Should just be able to connect to the remote host on whatever port the container is bound to  regardless of what IP the container has on the host. Regular users would use the DB_URL env var. \n. Do tests really need to test against a remote datastore?\n. Are you trying to build int the root dir of the iron-io/functions repo? Make a fresh new directory and with nothing in it and start there. . cc @jmank88 . I think we can ditch all the other lambda related commands (except import) as long as these special runtimes will cover it using the regular functions workflow. \n. Generally looks good, but can we call it IdleTimeout instead of InactivityTimeout ?. The docs should be part of this PR, agree with @ccirello . Not complete without docs. . @ccirello ok now with docs?. This probably won't use projects, probably just appname, or perhaps appname.user_id/org_id. GitHub style naming would be nice, eg: myapp.treeder.ironfunctions.com .\n. Should mention Microcontainers so people try to make the smallest images possible. \n. This would be limited by the size of the servers. We probably need an LRU type thing for the docker image cache. \n. Autoscale to hopefully always have enough capacity, small in memory queue to wait for capacity if the server is full, 503's after that. \n. Don't put these in a hack folder. \n. Why did you remove the env file and privileged?  privileged is required for dind. \n. The user needs to create an app first?\n. Keep these here, I want to add these to the cli. Maybe just add TODO \n. Put the link in the paragraph body, not the header. \n. Let's keep all of these things under the operations header. \n. Why did you do this instead of just calling build.sh?\n. Actually, you can drop the env-file thing, that's fine, but privileged is still required, not sure how it's working otherwise. \n. Shouldn't be called a job. \n. There is no job id\n. This shouldn't write to a file\n. Shouldn't need Titan's models I wouldn't think. \n. There are no jobs?\n. Is environment used in Titan?  I think we could throw this out in Titan and here. \n. Change this to runner.Run(ctx)\n. Context should have been created earlier, outside this Start() method, not here. \n. We should not be writing and reading files. \n. This shouldn't be here. \n. Could this be in the Titan drivers package?  driver.New(conf) similar to mq.New() and db.New() in Titan. Drop environment unless it's used, but I don't think it is. \n. I don't think the datastore or the config should be in the context, they are ok as global vals since they don't change. The context is useful for things that are valid for a particular request, but not for global things. \n. Why did you change this?\n. We don't want the datastore in the context. \n. Do we need both?  Probably only need routes filtered by app. \n. This shouldn't return a mock if the driver isn't found. Imagine we deploy this to production and it starts using the mock. \n. Should still return nil right?\n. Don't we have a global of this?\n. This will overwrite your STDIN. \n. This will screw up your output, use STDERR for logging. \n. Why is InputStream taking a string?\n. I don't think we'll ever need to print this to the logs. Payload could be huge. \n. Is time a metric that anything can use?\n. Lot's of repeated code here, this can be pull out into a single function, eg logMetric(ctx, name, type, value\n. And I don't mean replace these with that one, I mean have these each call  that one. \n. I like these more defined methods, rather than making the user think about what the metric is called. What if they get it wrong?\n. Should probably sleep in here briefly to not churn on the CPU. \n. Ya, let's make these clear. r.ml.LogCount(name, value) for instance. \n. This should only be called once at startup probably to get the available memory for the container, not every time we run a job. Let's say the available memory at startup is 2GB, we save that as the memory we have available.  And we know exactly how much memory per job so we can substract and add to some usedMemory variable to find out how much we have. \n. spelling. \n. Just default to sync maybe?\n. This shouldn't be level 5 header, why would you make it inconsistent?\n. Change this to: \"You can create a route with dynamic URL parameters that will be available inside your function by prefixing path segments with a :, for example:\"\nCURL COMMAND HERE \nThen: \":author_id and :num_page in the path will be passed into your function as PARAM_AUTHOR_ID and PARAM_NUM_PAGE.\"\nKeep the link to the blog example. \n. We don't need this, kind of pointless. \n. Don't think we need Group anymore, Route's take its place now I think?\n. Same as above. \n. Same\n. None of this status stuff is necessary anymore right?\n. Not required?\n. Not required\n. I think the sync and async stuff needs to be aware of each other in order to manage resources.  See https://github.com/iron-io/functions/issues/104 for an idea. \n. Should probably only sleep if it gets nothing back from the queue. \n. We should return json even if no messages exist, just makes it cleaner. The Titan format was probably good:\njson\n{ \"tasks\": [ ] }\n. Why aren't we using the MQ libs from titan/worker?  This looks very limiting. IronMQ for instance needs auth, Redis isn't HTTP, etc. \n. Sorry, disregard. \n. Should pass ctx along to all these methods. \n. Use the common.LoggerWithFields to ensure the ctx logger gets update with the new fields. \n. eg: ctx, log := common.LoggerWithFields(ctx, logrus.Fields{\"call_id\": reqID})\n. Do we need to suck in and discard the body on get requests too to clear up connections (like: https://github.com/iron-io/functions/pull/111/files#diff-e180f07f5c320b82004c2bb065eedef0R55)?  I can't remember. @rdallman do you know?\n. Why aren't you logging this?\n. is tasksrv the URL?  Let's keep it consistent and use API_URL. \n. You're mixing contributors and users into the same guide. The Quickstart isn't for developers of IronFunctions, it's for users, so they don't need to run any of these steps, they just need to do the docker run iron/functions\n. Use API_URL or SOMETHING_URL. \n. This is the address of the functions API, not the MQ right?\n. NUM_ASYNC to be more clear. Also, I think this should be dynamic like the sync functions. Maybe for now just split the machine in half until we can just use the same for both sync and async. \n. What's this for?\n. That would be better. Or better yet, just check if it's a supported OS and do it automatically. \n. Let's just check the OS: https://golang.org/pkg/runtime/#GOOS\nLess stuff the user has to think about, the better. \n. ya, could probably drop it here to keep it simpler since it's the default. Also, can you copy all the contents from here: https://github.com/iron-io/worker/blob/master/jobserver/README.md to address all the options properly. Put it in the docs dir: https://github.com/iron-io/functions/tree/master/docs and link to it from this README, maybe in the table below. \n. Should these tests be in a test_file ?\n. this is required, won't build without it. \n. Says docker swarm. And probably don't want to call it a \"as a scheduler\"?\n. I don't think strip-vcs is a valid option anymore @ccirello and @pedronasser \n. @seiflotfy I skipped this test for now, wondering if there's a better way to do this without adding back in the anonymous functions we seem to have in various places. \n. No, swagger is out of date. These aren't actually generated anymore, I think it was just a copy from titan.  @seiflotfy  right?\n. Let's leave it for now, I don't actually like ignoring this error, because it may actually be invalid json. Have to think of a better way to deal with it. \n. WithError() doesn't print anything, need to actually have a print function like Fatalln\n. Done. \n. Done\n. Oh, I see what you're saying, yes, equivalent, so can change later. \n. I just copied this over directly, if it's a concern, make another ticket to follow up on it. \n. The Ruby one is now tagged iron/hello:ruby\n. This basically doesn't do any part of release.sh. Why get rid of the scripts?\n. This should have at least a task wrapper. I'd recommend it stays as a task wrapper to return an array of tasks in case we want to allow more than one returned at a time. \n. functions doesn't support priority yet. \n. functions doesn't support timeout yet. \n. functions doesn't support retries yet. \n. functions doesn't support retries delay yet. \n. functions doesn't support delay yet. \n. Change this sentence to something like \"To get the best performance, you'll want to ensure that Docker is configured properly.\"\n. Just add this as number 3 to the list.\n. Copy the Iron CLI installer, we can't assume people have Go installed. \n. Can we somehow keep both here?  I think it's good to show people that this is all a simple API. Or perhaps a second page (curl.md) that does the same quickstart with curl commands?\n. Do we do the same on route create?  And if so, I think it would be better to reject invalid routes, rather than reformatting them for the user. \n. Off topic: should we change the name of the main container to iron/fn instead of iron/functions?\n. Just use sh\n. What's this entrypoint.sh doing?\n. Ok, should probably be strict about rejecting routes during create rather than trying to clean them later, but it's something we can do later.  Maybe make a follow up issue so we don't hold this one. \n. Why are all the release scripts removed?\n. This makes the image too big, the previous way is much better. \n. Let's use the release scripts or fnctl to do these things. \n. That's not for iron images, it's for whoever is making it. They'd have to edit the USERNAME of course. Although, maybe we should change all of these to use fnctl anyways?  Eg: fnctl build then fnctl push or something. \n. Let's make a new issue for that topic. \n. Yes, actually this whole section could be updated with how to do it with fnctl. But let's do it after. \n. Stick to the 3 ticks plus a language hint for code examples, as we have everywhere else. \n. Why aren't we using iron/node?\n. Make this file the README.md in this directory. \n. Why is the getting started example executing another process?  Why not just a hello world?  How about we copy the exact code from the Lambda getting started guide: http://docs.aws.amazon.com/lambda/latest/dg/get-started-create-function.html\n. Three ticks with sh for shell commands. \n. Why did you add the extra lines here?\n. Same question here. \n. Oh, please convert that to markdown bullets then, which is number dot space, eg:\n1. hi\n2. there\n3. ben\n. Guys, let's try to be consistent here, use API_URL environment variable just like we do everywhere else. \n. Would it make sense to make this more heroku like, where setting configs is a separate command? https://devcenter.heroku.com/articles/config-vars#setting-up-config-vars-for-a-deployed-application\n. Any reason we prefix this?   Can we just give the user the key the way they set it? \n. Ya I know, maybe shouldn't change it though, i'll make another issue for it. \n. @ccirello i don't think we should expect or ask users to do something like that just to name their app. The 30 limit is arbitrary, I don't see anything wrong with increasing a bit bigger, to another arbitrary number as the UUID is a valid case. How about 40 to keep it a clean number?\n. Doesn't this just do the current directory now?  Only with -r will it scan more directories right?\n. Add ruby to this. \n. They shouldn't put the tag in the name, we should probably even enforce that they don't. \n. What were these for?  Random stuff was showing up at the very end of each command. \n. I think the opposite, the more options (that are really unnecessary options) just adds confusion. And we can never remove things, we can only add so it's always better to start with less. \n. Why would you ever have go files and ruby files together?  And if you did, you can't really guess properly anyways. \nAlso, this is for one function, not for an entire app. A single function can't be multiple languages. \nSpeaking of, I'd like to refactor how this walks through all sub directories by default, it makes all the code really hard to follow. There is really only a couple of commands that should support the recursive flag -- push and publish. \n. How?  While keeping it readable. \n. Why is that better?\n. Note to self, add this curl command back in. \n. Why pull in the ssh lib just for that?  See:  http://stackoverflow.com/questions/22744443/check-if-there-is-something-to-read-on-stdin-in-golang . Although, I don't really care, end result is probably the same. \n. Need to update this mapping before merge. \n. Need a new release and version bump. \n. Mapped it to: https://raw.githubusercontent.com/iron-io/functions/master/fn/install.sh\nThat correct?\n. What do you mean by pending routes?. Does this just mean it has routes?. ./release.sh probably better?\n. We should still support the default, single request protocol that is in place now. . I thought we were discussing that deploy would be more of a bulk operation only, for when you setup an entire app structure?  What path would be used here?. Should these say fn build and fn push instead of docker?. This should still be push and routes create, not deploy. . Same. @ccirello removed the C and I didn't feel like adding them back. ;)  Can figure out how we want to name the constants later. . I know some of our examples need updating to the cli commands, but could you change the README to be like the helloworld examples that use the cli (much simpler).  Like this: https://github.com/iron-io/functions/tree/master/examples/hello/go\nEven if just for the build, push, bump so you can get rid of the .sh files and simplify things a bit. . I like both of these changes/fixes (adding --link and fixing bug). If you make a new PR separate from this one, that would be great!. Can you verify we're not expecting this behavior anywhere else?  I think you're right that we shouldn't create an app when getting a route, but want to make sure anything using this method is ready for the change. . Ya, good call, changing. . Agree with you on that, I'll have to think of an example. Closing this to create a PR against master. . I'll remove special handlers in another PR. . Cleaning up, thanks. . Ya, maybe put the run command above this, then For more information, see:. See #501, the -sSL already has -L in it, I'm not sure why this didn't work for you. cc @rdallman . Please don't add these types of things to the context, I removed all of them to avoid inappropriate use of the context. This is what the RequestController is for isn't it?. Do internal methods need the RequestController?  Can't they just use the gin context?. The context has the logger, why get it from the RequestController?. Why did you add wrapHandlers instead of just using the one middleware?. I think @denismakogon is right, can we remove both of the logger methods?  Use context for the logger like it was. . Why can't we just have the full App here?. Same for Route?. What if they need more information about the App?  Or want to set config/env vars, etc. \n. I believe you can patch configs, so it shouldn't be a complete replace. Eg: fn apps update --config DB_URL=http://example.org/ myapp . That will update DB_URL only and leave the rest as is. \nRegarding the rest of these things, why not return nil if the app doesn't exist like it used to?  An app that doesn't exist isn't really an error. \nAlso, What's the difference between a nil app and a ErrAppsNotFound?\n. Ya, we could. I'm not sure if it would be used much though, it really slows down the call, seconds instead of milliseconds. \n. Fixed. . Fixed. . Fixed.. Good call. Testing what happens when we don't check and an image exists.... Going to make a new issue to follow up on this. Currently if the image isn't found, the response to the user is a blank 200. Created #540 to follow up on this. . @pedronasser my pull requests filled them in properly, copy from there. . Because, that's not what context is for (I really hope we can put that discussion to rest at some point). And we're passing the App itself along now (the entire reason for doing this was to remove things from the context) so why would they ever use this in the context?\n. sure, leave it for now. . I think we remove these, the logger is optional in the middleware and I don't think we want to lock ourselves into these functions on the interface forever (unless we're 100% sure, which we're not). \n. It's documented in the main help. Optional now. . We need to log this so the error isn't lost and someone can figure out what's wrong. . @adelevie what do you think of this instead?. Using the API_URL in this change is not the correct URL. But why is c.Request.URL.String() not returning the full URL?  Might have to use Request.Host or Request.RequestURI or something. . I think hot is assumed if format is not default so probably don't need the extra var. . Makes sense, changing. . Removed. . ",
    "henriquechehad": "Fixed here:\nhttps://github.com/iron-io/functions/pull/83\nhttps://github.com/iron-io/titan/pull/327\n. @treeder Twitter example PR: https://github.com/iron-io/functions/pull/96\n. @treeder https://github.com/iron-io/function-fork-me/pull/1\n. https://github.com/iron-io/functions/pull/75\nhttps://github.com/iron-io/titan/pull/325\n. @treeder pls give me write access to do it\n. @treeder about the counts, save it in database or just in variable memory?\n. PR: https://github.com/iron-io/functions/pull/88\n. New metric in PR: https://github.com/iron-io/functions/pull/89\n(execution time total (all apps))\n. Metrics: wait time total and reserved memory: https://github.com/iron-io/functions/issues/61\n. @treeder fixed here:\nhttps://github.com/iron-io/titan/pull/327\nhttps://github.com/iron-io/functions/pull/83\n. PR: https://github.com/iron-io/functions/pull/98\n@pedronasser can you review pls?\n. Depends on: https://github.com/iron-io/titan/pull/327\n. @treeder @pedronasser \n. PR: https://github.com/iron-io/functions/issues/90\n. It already works by default in gin, closing the PR.\nhttps://github.com/gin-gonic/gin#using-get-post-put-patch-delete-and-options\n. @treeder need a function example too or just the docs?\n. PR: https://github.com/iron-io/functions/pull/102\n. Issue: https://github.com/iron-io/functions/issues/17\n. @treeder haha... right, I will replace by empty \"drivers.Drive\"\nIn this case of driver not found only the \"err\" matters, is verified here: https://github.com/iron-io/functions/pull/58/files/068c2409fd1af0e3d5b8d99861ec8bdf46780995#diff-cb6540f116cb83dede7783108eb736dfR66\n. @treeder yes, changed here https://github.com/iron-io/functions/commit/0950c9f4029379705b2a0551ee965c6ba801b922\n. @treeder there is some time duration metrics in the issue #61, I think it can handle\n. @treeder changed\n. ",
    "seiflotfy": "Is this not closed by #33 ?\n. @Nyarum @treeder is there a branch currently in progress related to this issue?\n. Will close this, every example to follow should be its own issue\n.  Fix bug #48\n. I think we are good this can be closed\n. testing it\n. Trying to find a way to set up DC/OS in a sane manner. Looking for some sort of minimal dev env installation.\n. deferring for now. setting up DC/OS is not straight forward.\n. @ccirello  brought up that container performance degrades over time and would not increase or improve performance! How do we proceed? \n. LGTM but needs to be resolved!\n. squashed and resolved conflicts at https://github.com/iron-io/functions/pull/111!\n. This error does not happen anymore, however the connection from the client side is never dropped!\n.  Add PORT env var to optionally change ports. #90\n. going to try it out myself, if it works then +1\n. LGTM\n. sync functions are small by default so it should not be a problem that they execute quickly and hopefully release resources quickly too. That being said async are more for heavy duty functions.\nI'd like to keep them separated completely (at least for the alpha release) where sync and async run in parallel with no knowledge of each others resources.\nAfter that I'd like to also use the 60/40 execution chance. Eventually I'd like this to be something configurable!\nBut for this release let's keep it very very simple, what do you think?\n. ill just add the tests on top of this\n. We can link it to #140 \nSo I think it makes sense still \n. crap! I removed the tag but somehow that did not go through! :/ thanks for reopening :D\n. @pedronasser good job! please squash those commits into one!\n. Got it moving things over, sorry about that\n. On it\nOn Thu, Oct 6, 2016 at 12:54 AM Travis Reeder notifications@github.com\nwrote:\n\n@treeder commented on this pull request.\nIn README.md\nhttps://github.com/iron-io/functions/pull/122#pullrequestreview-3020062:\n\n+Default (8080), sets the port to run on.\n+\n+\n+MQ\n+Default (\"bolt://$cwd/worker_mq.db\"), also supports (\"redis://) and (\"memory\").\n+\n+\n+API_URL\n+Address (http://) of the primary functions api to pull tasks from (the address is that of another running functions process).\n+\n+\n+NUM_ASYNC\n+Default (4), sets the number of async runners.\n+\n+\n+IGNORE_MEMORY\n\nLet's just check the OS: https://golang.org/pkg/runtime/#GOOS\nLess stuff the user has to think about, the better.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/pull/122#pullrequestreview-3020062,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAHMTcdXK40Vgc32-EL6wl5XZUB4bMi8ks5qxCqPgaJpZM4KOQlB\n.\n. LGTM\n. LGTM\n. Testing :D\n. having trouble setting up kubernetes. this might take some time here\n. tried on AWS, but a normal ubuntu instance is not allowing me to do anything really. We need to specify that kvm would not work and kubectl complaining about known host hvm\n. Trying to install minikube on ec2 which requires VirtualBox, getting:\n\nTrying to register the VirtualBox kernel modules using DKMS ...done.\nStarting VirtualBox kernel modules ...failed!\n  (Running VirtualBox in a Xen environment is not supported)\nProcessing triggers for ureadahead (0.100.0-16) ...\nI don't think I should be reviewing this since I can't replicate on EC2, but on a local machine here I am having an issue with not being able to send POST request without a timeout to functions.  Will try again later.\n. yet its in https://github.com/iron-io/functions/tree/master/examples/hello-go\n. LGTM\n. This looks good, I will do a double check then close it\n. Found a first problem, no description of NewTask\n. This is my first usage of swagger, but just from a superficial perspective, it doesn't seem right to take generated code and change it. It seems to me that this is exactly what we have done here. Generated code should rather be embedded in other structs or added code should be in a different file. I am not very happy with this, if we are going to follow the principal of not mixing responsibilities and logics (the way we decided to do with the gin routes handling) then I think we need to follow the same principal with generated code.\n. I am fully confused now, are we using swagger to generate code or generate docs or generate client side stuff or all. To me it seems like we are misusing swagger.\n. I retract this statement. I thought we are using it for also building models used inside the api code\n. I like the idea, to determine if it is to be executed sync or async on of the following should be the trigger:\n- add a field in the path to \n- add a property in the body\n- add a field in the header\nWDYT?\n. I am still trying to go through the swagger part. the swagger.yml was not\ncompiling without this. That is why I added it. However we do have tasks.\nOn Mon, Oct 17, 2016 at 8:37 PM Travis Reeder notifications@github.com\nwrote:\n\nIs NewTask part of the API? Seems like it shouldn't be.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/pull/175#issuecomment-254294414,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAHMTRtmr9PTeyoUDmOwvsm0hCL-gjB_ks5q08BggaJpZM4KXs05\n.\n. updated! @ccirello moving the \"purging delay references\" to another PR\n. I will put it back in under make. However I am not really a fan of having\nrelease process in a public repo, but rather in a private repo\n\nOn Mon, Oct 17, 2016 at 8:39 PM Travis Reeder notifications@github.com\nwrote:\n\n@treeder requested changes on this pull request.\nCan't remove release script.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/pull/178#pullrequestreview-4532759,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAHMTZR_iAvLZcfoUIZkBNeQgEkSzSLtks5q08DhgaJpZM4KXt_D\n.\n. however @ccirello brought up a valid point that when we are releasing we are not just releasing a new version of the functions code, but rather we are also releasing a docker/image! @pedronasser I'd love to automate that somehow maybe circleCI :P\n. missing https://github.com/iron-io/functions/pull/264\n. I can confirm that this is a DinD issue\n. I like the HowTo but we can't claim production. We should not mention we are production ready\n. Up for review\nhttps://github.com/Homebrew/homebrew-core/pull/10479/files. I think this can be closed now\n. @jotes that would be great. I can meet you on the slack channels and we do it together :)\n. I have a Google Home, I can take over this. Feel free to resolve the conflict and merge. Feel free to resolve the conflict and merge. looks good, please resolve conflict. No more skipped tests. @ccirello in reference to the second point. The same route but with different settings should be considered as 2 different routes?. Will test it on Linux in a bit. Thanks for the catch :D. I gave this a second thought, I already proposed my idea to @treeder but I think its worth bringing it out there again. I was thinking of having a \"middle-ware\" that just tracks the logs output... It would work as follows in the middle-ware:\n Upon async request store request ID in DB and state \"init\"\n Monitor logs for state change (the runner and functions spit out when something is about to run or finished running with that request-id), and update DB accordingly\nPretty simple and not intrusive. WDYT? @ccirello . Agree, sounds like a better way of doing it. Now as Derek mentioned where\ndo we track the state and for how long do we keep the state after\ncompletion.\n\nOn Fri, Mar 3, 2017 at 11:45 AM Derek Schultz notifications@github.com\nwrote:\n\nI agree with @Gouthamve https://github.com/Gouthamve in that it seems\nmore appropriate to do this via a RunnerListener rather than through a\nlog monitoring mechanism making a request to DB. But, I guess the question\nwith regard to state tracking is where to store state, whether it be in\ncache or DB. More generally, this is applicable to the whole functions\nevent lifecycle, which I think needs some further thought.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/issues/415#issuecomment-284021353,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAHMTWVXrTOfU-XW1iR-M58UGeOy-2mLks5riFG7gaJpZM4LKBUr\n.\n. sweet, where should the 100 node cluster be launched?. Go 1.8 is not even out yet :D lets wait a bit. Also I heard that they might drop plugins from Mac :). looks good, please resolve and feel free to merge . Really nice work! LGTM! . Why not just use the digitalocean docker setup and deploy iron-functions there?. @jconning can you try updating pip install --upgrade pip. wait you need to add a requirements.txt by hand\nin the same folder as the one with func.py. Fixing it\n\nOn 21 Feb 2017, 22:55 +0100, jconning notifications@github.com, wrote:\n\nSeems like a bug to me. Following the instructions in hello/python/README.md doesn't work.\nhttps://github.com/iron-io/functions/tree/master/examples/hello/python/README.md\nDon't we want the examples to work, as documented, so new people have a good experience?\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub, or mute the thread.\n. @jmank88 can you open new issues with the TODO?. There was a reason we had the _ ? Trying to find out why again. LGTM can you check for any documentation that needs changing.. This would require pausing a container then resuming it, which would defeat the purpose of hot containers really. I think it should be 404 since the image does NOT EXIST. @Gouthamve ok you are right, its still registered, which is ok as long as calling it returns 200 AFAICT. @Gouthamve I agree it should return 500, the path is registered so 404 is not ideal. @Gouthamve WDYT?\n. @jmank88 you lovely person \u2764\ufe0f . So I am pretty ok with that change, we are not 1.0 and I like the changes to the docs.\nI'd like to have a +1 from @pedronasser @treeder @ccirello\nThen lets push it through. Also can you make sure you add a note in the changelogs?. I don't see whats broken....\nfn routes create myapp /hello iron/go\nthe image is missing and it has to be accessible via docker or locally. Can you make sure that empty val should trigger delete when possible,\nrather than storing an empty value. Then we are good\n\nOn Thu, Mar 2, 2017 at 10:39 AM Jordan Krage notifications@github.com\nwrote:\n\nThings resolved by the validator (but that could still use tests):\nUpdateApp:\n\nmock wasn't checking for nil app or empty app.Name\npostgres was returning the wrong error for nil app and not checking\n   for empty app.Name\n\nGetRoutesByApp:\n\nmock, bolt and postgres were all missing empty app name checks\n\nInsertRoute/UpdateRoute:\n\npostgres wasn't checking for empty route.AppName or route.Path\n\nThings noticed but unresolved:\nPut:\n\nempty val should trigger delete when possible, rather than storing\n   an empty value.\n\nGetApps:\n\nmock: doesn't apply the app filter, indicating the test case is weak\n   (it passes by returning all)\n\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/pull/565#issuecomment-283706176,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAHMTYxWKvaje0_It0HfJXk8aP4lbWOeks5rhvCngaJpZM4MRKyr\n.\n. I think CLA is broken on this one. testing it in a bit. @mkubarycz could you add some docs?. There lambda import support is missing I am working on that now. this is not needed anymore.... a small sleep would be good even if just 1ms\n. the 5seconds was for debugging replacing with a 10ms sleep\n. on it\n. yeah will fix that in the queue\n. GET only returns 1 task at a time\n\njson\n{ \"tasks\": [ ] }\ndoes it make sense to return a list. I'd say lets return just a task\n. I can only see https://github.com/iron-io/worker/blob/master/jobserver/api/api.go ?\nCan't find the client side connection to it though?\n. So enqueue is defined as follows\ngo\nfunc (s *Server) handleRunnerRequest(c *gin.Context) {\n    enqueue := func(task *models.Task) (*models.Task, error) {\n        c.JSON(http.StatusAccepted, map[string]string{\"call_id\": task.ID})\n        return s.MQ.Push(task)\n    }\n    handleRequest(c, enqueue)\n}```\nThe scope around it already knows about the context, is it needed. Should I pass it to the s.MQ.Push(task)?\n. So this can be done in a next cycle as a low-hanging-fruit for new developers to contribute\n. We start with capitals in the log. So please use \"Push\" or better yet \"Pushed to MQ\" it would also be nice to have the Queue Type in there (but not a must)\n. We start with capitals in the log.\n. No need for this. We can Just go with Deleted or Failed to Delete in case of failure...\n. We start with capitals in the log.\n. We start with capitals in the log.\n. NICE\nSO SO NICE\n. API URL is very vague... Let's use TASKS_URL instead?\n. this can be used to stop all async work! I can make it default to -1 which will be dynamic! WDYT @treeder \n. This is to ignore the statsd memory profiling. This does not work on Mac! I could rename it to IGNORE_PROFILING \n. its to allow unit tests to check the async is working right https://github.com/iron-io/functions/pull/131/files\n. should that not be \"/:\"\n. Can't we break after the first match? since later on \n+  found := routes[0]\n. ok cool\n. done\n. the MQ implementation I ported over begs to differ \ud83c\udfb1 \n. but yeah we can't control it, should we clean up the MQs and get rid of all the delay stuff?\n. I added TaskWrapper but not TasksWrapper\n. so get rid of flags and follow that order?\n. somehow gofmt and goimport remove it if I just go with lambda\n. Can't you combine this with test instead, its identical\n. change to USERNAME\n. Nit picking change to \npython\nprint \"Hello\", name, \"from Python!\"\nto be consistent with other examples\n. Nit picking\nphp\necho \"Hello \", $payload['name'],\" from php!\\n\\n\";\n. same here\n. good call\n. its used in lambda.go. Can we turn this into a flag --check-image-exists instead. Then lets just remove the blocks completely? much cleaner!. We can address this in an another PR. Yeah maybe we should define more strict rules since I was able to create routes such as \"///\" and \"/?\". I think this can be dealt with in another issue.... +1 on the validator. And again this can be done in a different PR . GetRoute and GetRoutes should return the same thing and have the same logic and be verbose about it. If the \"App\" is missing then return ErrAppsNotFound else return RoutesNotFound. So I think returning an ErrAppsNotFound is better IMHO when trying to update the config of an app that is not found. For now I think its good to idea to just send in an empty array value for deletion... Nice one. its already in the logs from the runner AFAICT\nERRO[0003] Failed to pull image                          action=\"server.handleRunnerRequest)-fm\" app=myapp call_id=357e93d0-af46-5cbb-83c6-7f8628fb2344 error=\"API error (404): {\\\"message\\\":\\\"repository iron/notexist not found: does not exist or no pull access\\\"}\\n\" image=\"iron/notexist\" registry=\"https://registry.hub.docker.com\" route=\"/lol2\" username=. Done!. since Redis is a dictionary based DB you need to keep track of all the existing \"sets\" so you can iterate through them later... check GetRoutes. no its just an index of what apps I have, I could have gotten it via HKEYS on \"apps\".... maybe you got a point. Got rid of them. Yeah I like that one more....  I think @treeder would have some good input there. Else I really like it \ud83d\udc4d . can't this logic be moved into a new PR?. while you are at it! Why not?. ",
    "pedronasser": "@seiflotfy That PR was closed. But this is getting covered by my latest PR #92 \n. @treeder Isn't this done? This was implemented on the PR #74.\nAm I missing something?\n. I would love to make this with Caddy\n. LGTM\n. @treeder Can you test if this bug is still happening?\n. Recreating PR\n. I like the idea of starting simple.\n. I agree with @seiflotfy, the would be better to not keep the release script in this repository.\nAlso would be nice to have an automated release process.\n. @seiflotfy Could we use ACME support?\n. See @ccirello  this was a total reorganization of examples and their tests. I think is not that hard to review this. But it requires to test and review it one by one locally.\nIf its too bad to review like that I could try break it.\n. LGTM\n. I'll create new issue explaining the proposal\n. @treeder Is this really for alpha2?. @treeder Any idea of how we are going to store those logs?. We can improve this in another PR.\nLGTM. I think the Timeout should be configured in the route/apps configuration and even maybe via a Header. If no timeout is specified use the default. (like @denismakogon suggested)\n. @ccirello I agree that making routecache public would add the responsibility to explain what's it works and what is its objective in the IronFunctions workflow.\nIn this case the routecache has the mission to prevent the runner to query for the route every request, so when the requested route is already in the hotroutes cache the datastore will not receive the query.\nSo when the user wants to change any kind of behavior in the datastore, he expects that everything will be requested for the datastore, but in the cases that the datastore is not consulted (eg. in this case), that behavior will not be correct. And that's the reason I'm trying to make the routecache pluggable.\nIMHO we need to build IronFunctions in a form that the only things not replacable are the API and the Runner. Everything else should be injectable in order to create a platform that the users can easily modify to the use they need.. Deferred.\nThis change can be done later.. This is something we've been discussing for a while.\nThe first idea is to check first for local images before checking for remote registries.\nThen we can move to support a custom registry.\nThis is in our TODO list.. @denismakogon Update what exactly?. @denismakogon The route's AppName is defined as the name used in the URL param :app.\nSo yes, the route.AppName in the request body is just ignored.\nBut also, the correct field for AppName is app_name and not appname.. @ccirello @treeder @seiflotfy I'm thinking on an alternative for these SpecialHandlers.\nI think there's a better way to handle that.. I'll add a documentation for this.. @ccirello The idea of this PR is define the future.. Deferred. @ccirello IMHO we can't defer this to BETA1 or later.\nI think this is an foundation problem of this project and needs to be solved now, so we can easily understand how we are going to build next features without disrespecting the project organization . Deffered. @treeder \nCould we replace IRON_TOKEN for just AUTH_TOKEN, or maybe FN_TOKEN?\nI guess some enterprise users would like to have their own authentication and might want to use that environment var as well.. @treeder fixing it. @treeder Waiting for #476 to be merged . @nikhilm \nThe idea of the PR is to check if the image exists locally.\nRight now we are checking only against the registry.\ndriver.CanExecuteFast, would serve for that case?\nhttps://github.com/iron-io/runner/pull/24. @nikhilm Look that PR https://github.com/iron-io/runner/pull/24. @ccirello Thanks for the suggestion.\nI agree that the name may be wrong for some cases. \nI think it's a problem of semantics, but I liked your idea of using the names BeforeDispatch and AfterDispatch.\nThose names seem more qualified for their roles.. @treeder done. Is this bug still valid?. I think adding plugins support (for 1.8 only) is not much a problem. And I see benefit from start working on how plugins will be used in the functions (although this should be not a priority until 1.8 out of beta).\n. Merged docs. @treeder But there must be some situation/case that the developer want to get the error (even internal) inside the function response body, or not?\nNot all functions will be done for public users, may exists functions for internal uses as well.. @ccirello Agreed. But the issue here is not how the runner handle the container status (surely that need to be improved).\nThis issue is about letting the user (some how) configure if the container will output the container stderr inside the response body.\nI've suggested exactly that: the container could handle any exception (like database) and send that to the stderr in order to send it to the functions logs. But that doesn't solve the problem of the user receiving any container logs in the response body.. @ccirello you mean like this?\nfn routes set image myapp /hello iron/hello\nfn routes get image myapp /hello. This issue is solved.\nI've just checked using the latest master.\n. @ccirello right now should be like this: fn apps update --config myconf=\nBut that looks not so good.\nHow about like this? Any suggestion?\nfn apps update --config \"-myconf\"\nEDIT:\nConfirmed, not is not working\nEDIT2:\nFixed. @treeder \nA command just to set and unset the config?\nCouldn't it be like this?\nfn apps update myapp --config:set myconf --config:unset myconf2. I added config set and config unset back.. @treeder Is this enough? https://github.com/iron-io/functions/issues/467. Closed by #480 .  Agreed with @treeder . @sheerun Actually if you check the hotcontainer implementation and the protocols package (https://github.com/iron-io/functions/tree/master/api/runner/protocol), you'll see that HTTP is just one protocol. Other protocols can be implemented.\nFeel free to PR with a new protocol proposal.. @treeder is anyone currently working on this?. @WTFKr0, when you say parameter do you mean a route configuration?\nI agree in making the hot functions timeout configurable. . I'm actually working on that fix at this moment.. @mkubarycz I've taken the liberty of sending a PR to your fork, adding a different way of getting credentials. Please check it.\nBeside that IMO this PR looks good.\nI agree the ideal state would have been adding this to the iron/runner. But since we currently only supporting Docker and the code related to it is quite modular, in the future we can separate it from this repo.\nI think this PR is a start towards supporting private registries and this can be improved in the future\ncc @treeder @seiflotfy . Making a new PR to continue this PR. @cmdhema \nTo build it from the source you can just execute:\nmake dep\nmake build. Good point, we should make some kind of routine that checks for image updates and without stopping the old version containers, the runner would start new containers with the new version and just redirect the requests for the new group of containers, then it can stop old containers.\n@treeder @seiflotfy what do you think?. Fixed in the latest release.. Trying to clean th code.\nRemoved this dependency: github.com/iron-io/titan/runner/configloader\n. @treeder \nThe need of this GetRoute not binded with the application name is required for searching all routes using an specific image (for example)\n. That's not really a test.\nJust a test helper.\nShould it be?\n. Sorry, forgot to remove its comment\n. Can you help me find what error exactly it's handling?\n. To convert X-Whatever header (for example) to HEADER_X_FUNCTION.\nShould we handle that in a different way?\n. Forgot to handle it.\nFixing...\n. @ccirello \nShould I rename it to helpers_test.go?\nOr move that to server_test.go?\n. Just using http.CanonicalHeaderKey wouldn't convert X-Function to X_FUNCTION.\nBut I see you point of getting a function to do that.\n. Well I can revert it if there's a big problem.\nBut as I see, if the user tries to run an unknown route or with different parameters the route will not be matched and that will be handled here: https://github.com/iron-io/functions/blob/c023940e44a4a780553a9e71f946ff559e281da3/api/server/runner.go#L184-L185\nOkay, I forgot to replace that return to a break, makes sense?\n. Good point. Changing it.\n. Like @seiflotfy said. Would be better to have a release script (for iron images) in a separated repo.\nReally need a release script here?\n. Fixing it.\n. This print should be here?\n. Not understanding what is this for.\n. Sorry, missed that\n. Because glide nv doesn't get the list of all packages.\nIn the test-docker I had to ignore the datastore package.\nIn this command we could continue using glide nv but I think is good to use the same.\n. Not anymore, I'll remove it\n. @ccirello Can we do that in another PR?\nI'm also thinking about moving theses tests inside their directories.\nLike: moving postgres_test.go to postgres dir.\n. This is ugly but we can improve it later.. Oops, forgot to use it.. @ccirello Check the previous impl of getCfg() and you'll see that we was sending the output to the stderr used to log. What is the benefit of logging the async result?\nWe can change this behavior later when we start having triggers.. Oh my bad.\nI'll describe it better.. @ccirello Reverted. I thought it better and I kept the sending the stdout from async task to the stderr. I think is better to log it than discarding. The user could (for now) create their own FuncLogger to handle their async tasks outputs.. I'm not sure what you mean with this. I mean, with this interface the ower should do whatever they want.. Agreed. Agreed, LRUCache would be a better name for that. Is not only for databases, but our current implementation load routes from the database in order to build the PrimeCache.. Sure, makes sense. Fixing it.. Makes sense.. Missing json gem. 60 or 30 seconds?. Removing it. Yeah that is the name. I'll change it.. Good point.. Just a tag example. Maybe could be something important for the user.. Sure. Updating. Oh okay. Good point. This dependency is used?. Agreed, I'll remove it. Okay. I'll describe each better. @ccirello I don't see why this change really prevent intercepting the communication between server and runner. Like you you've noticed the channel is still visible and can be easily replaced externally. \nIf you take a look on tasks no change has been done to the test it self, we are currently testing the same way as before, but the channel creation is no longer exposed.\nI see this as benefit because all packages the were using this channel also uses the runner and this channel is very related to the runner. So why not embedding that to it?\nI think hiding this channel inside the runner you keep the intercept-ability but also reduce the complexity for the user when he wants to creates his own custom IronFunctions server.. Yes, I agree we need a solution for that Api global variable. But we are actually refactoring that right now?\nI mean, we could also refactor that in this PR and solve all that problem. But I think that wouldn't change the objective of this PR that is simplify and make the server instantiation simpler, mainly for users.\nThis PR is just fixing part of the problem, but we could also refactor everything to solve the hole problem.. Like I said the idea of this PR is just make it simple and clean.\nWe need to remember that the idea of IronFunctions is planned to be an customizable/extensible server. So if we have an API that embeds many other components (current situation, can probably get worse), the user creating its own server will have provide each other component to the API Server in its instantiation.\nI agree we need to make server package smaller. But still the server will be the main component on this server and it must have access to other replaceable components.\nI agree solution this adds the problem of having to assert if all components has been correctly provided in the server.Component (easy thing to solve IMO)\nSo to solve all these problems you are proposing to pass just a channel to the API?\nRemember: we still needs to think about the UX from the user that will be creating its own custom IronFunctions server.. > Shouldn't code be closed for modification and open for extension? Or putting differently, if you are exposing an internal part like this, you are also saying for future customizers of IronFunction that a) Tasks can be replaced at any time (which his not true); b) Tasks do not need any protection when being changed (channel itself is safe, but if you can just replace the channel with something else, then you could have a race condition here).\nWell, the task channel was exposed either way. I still think that it could be created and kept inside the runner and we could easily test its functionality during runner tests.\nI still don't understand why do you think keeping the task channel inside the runner prevent us from testing it correctly.\n\nThat's not true - or I might have read your changes incorrectly. With the external channel, there were mocks that pretended that tasks had been consumed. In this PR, you are just running these tasks in the Docker again, no?\n\nI afraid you are correct. Reviewing my changes I confirm I forgot to reproduce that behavior of mocking in most of the cases but one particular case.\nBut still think even with these changes, that mocking can be done with the tasks embedded in the runner.\n\nI clearly failed to convey my concern, and I apologize. You are just stating that your change is better (embedding), but I did not see anywhere why before was worse. You essentially took a channel that was meant to link together two different components, and put in one of them - in practice defeating the meaning of it being external: show the connection of two independent executing processes.\nCould you please elaborate on this? It seems something important. Perhaps some example?\n\nIMO the task channel belongs to the runner and all components that were dependant to the task channel were also dependant to the runner. So why really keep both separated?\nI agree we can improve it more by, for example, not embed the runner inside the server and just pass a channel for communication. Same for other comments that would decentralize things and keep it more simple.\nDo you think we should proceed that direction?. What kind of abstraction you are referring?\n. If DefaultFormat is empty this condition will not work correctly:\nhttps://github.com/iron-io/functions/pull/404/files#diff-1e508e75f470efdd06b4bf58edef75a2R348. Nothing bad will happen. And if they update their route once, their format will be updated correctly.. Oh, I forgot to check that.\nWe could add:\ncase \"\":\n        return &DefaultProtocol{}, nil\nWould that solve the problem?. I've searched for that constant and there's no other case.\nI've just committed that change.. The async job receives it through the task object.\nNo other place in the code do a c.Get(\"reqID\"). That's not a valid route.\nThat falls in SpecialHandlers.. Thinking again. Makes sense. I thought using that method was not guarantee that the target request has that param, but thinking again, that wont be a problem.\nI'm changing.. Thanks. My bad. Doing it. Shouldn't have a loop somewhere here? Or the idea here really not show that part of the code?. Should we inform that default max_concurrency is 1 by default?. Is this the best solution to load plugins?\nCouldn't we just add an env var pointing to a directory location from where all (valid) plugins would be loaded?\nWhat do you think?. Missing fn push somewhere, isn't it?. guppy2?. Lol, how I missed it?!? haha. I don't think that's really a problem here.\nThe switch is there not only to check which languages is supported but also what are their specific configurations.. Is really necessary to add this to the server instance?\nCan't this work almost like a plugin added in the main package?. I think this can generate confusion because of the method name.\nI suggest using some name more descriptive like CountEnqueue() or something. Like I said before I think special handlers is not required.. How can the user use the models.App to change the API behavior?. I think we should have a example that uses the models.App to change the API behavior.. Why these doesn't have C prefix?. @ccirello Fixed. Wouldn't be more descriptive to use the name NewFromEnv?. Should this be removed?. @treeder I haven't changed so many things here. @ccirello checked like that, and I just increase one more argument validation.\nBut just validate the length is a better solution.. @treeder @denismakogon \nSince logger is kind an important request-unique value, I thought would be a good practice to make it visible to the middleware instead of making the user to find the logger from the context. Value (and receive an interface{})\nThe Logger() and SetLogger() methods are just wrappers, they are doing exactly what you said with the context.. Why really have a full app here? I mean, the full App struct has just name a config. The config is really necessary for this situation? \nThis objects holds request required information and the only two information I think right now is required for the request is appName and routePath.\nMake sense?. Same response from above. @treeder since right now we are using gin.Context as the main request context and if you check gin.Context implementation (https://github.com/gin-gonic/gin/blob/master/context.go), you will se that it stores any context value using Set() and get using Get().\nSo why not use it?\nWhen I set the api.AppName value here, any middleware will be able to get that value using ctx.Value(api.AppName).(string)\nI limited that use just for this situation. Yeah, we can use just gin.Context, but is it that bad to use it? And I think it provides clearly what kind of information an API request handler can have.\nShould we remove it?. Same response from above. Oh, I think we can revert it to middleware.\nI was using wrapper because I using it to the background context to the request, but since we are just using gin.Context, is not needed anymore.\nI'll revert it. @treeder If you follow the request flow there's no App (unless its name) and Route (unless its path)  information until the request reaches the final request handler. So from where would, that information, come from?\nAs far as I know, there's no database before the final handler, maybe inside middlewares.\nAre you thinking about middlewares doing those database calls, and writing that App/Route struct so in the final handler, instead of calling the database again, it would just use the struct?\nSorry I'm not understanding the need of a App/Route struct in this situation. ",
    "edsrzf": "That's fine. I guess I have to figure out how to fit them together then? And the endpoint can stay, but the Papertrail stuff should be abstracted behind and interface, right?\n. The Node one doesn't. (I admit I didn't actually look at the Java one.) str here is unused: https://github.com/iron-io/lambda/blob/master/images/node/bootstrap.js#L70\n. The point is that ideally we don't want to have to provide tools or libraries for every language under the sun. We want a simple protocol that people can understand and easily use with any language. I think the current protocol accomplishes that, but it also has shortcomings that I've pointed out here.\nSo the question is, do we give up the ideal and admit that we're probably going to have to supply tooling for each language we want to support? We'd still document the protocol so that people whose languages aren't supported won't be completely stuck, but we'd end up in the business of having to maintain and support something for a bunch of different languages, which isn't great.\n. I'd intended the answer to be more or less \"everything above\", but yeah, a more explicit answer might be a good idea.\n. ",
    "nikhilm": "There are some kube scripts in the older titan repo that allowed setting up titan. Should be very similar.\n. Some useful info here https://aws.amazon.com/blogs/compute/container-reuse-in-lambda/\nThis is unrelated to runner rotation really. I agree waiting on this is a good idea.\n. Does the user create docker images or do we create them? I think if this is going to be the base then we should insert tiny shims between the user and code. The problem of course is having to have code for each of these languages, which will suck. Will think about this more\n. The major downside I see with locking functions (the user/customer exposed aspects and not whatever we do underneath) to expecting/allowing input straight from STDIN is that we have created a big API surface area and locked ourselves out of ever being able to get out of that. Which is why I'm against allowing user code to use stdin as the input mechanism. I'd like to see a really compelling use case for that.\n. I mean from the POV of users. Yes it is nice to just run containers, but we\nopen ourselves up too much and lose a lot of flexibility when it will come\nto scaling, keeping containers running to serve multiple requests and so\non. The smaller we can keep the API that code in the containers relies on,\nthe less we've to break.\nOn Thu, Aug 25, 2016 at 10:32 AM, Travis Reeder notifications@github.com\nwrote:\n\nSo we can run containers and not care what's in them.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/issues/72#issuecomment-242474146,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAEzWtNwwJyBwT8yp0z0olcFVuXs5yWJks5qjdGVgaJpZM4JslYN\n.\n. To quote 1:\nWith any outsourcing strategy you are giving up control of some of your system to a 3rd-party vendor. Such lack of control may manifest as system downtime, unexpected limits, cost changes, loss of functionality, forced API upgrades, and more. Charity Majors, who I referenced earlier, explains this problem in much more detail in the Tradeoffs section of this article:\n[The Vendor service] if it is smart, will put strong constraints on how you are able to use it, so they are more likely to deliver on their reliability goals. When users have flexibility and options it creates chaos and unreliability. If the platform has to choose between your happiness vs thousands of other customers\u2019 happiness, they will choose the many over the one every time \u2014 as they should.\n-- Charity Majors\n. I agree with the benefits you list. Unfortunately being so bare-metal means\nwe have very limited flexibility when it comes to provisioning or\ninstrumenting these containers to be more efficient, re-usable and so on.\nE.g. the advantages that make containers+FaaS useful for us as vendors. I\nfeel like we don't have enough information to find edge cases, which is why\nI'm not a fan of such a broad API being exposed to users right of the bat.\n\nIf we are expecting users to upload functions as containers, I lean towards\nhaving an enforced API. It can either conform to Lambda, or something else.\nIf we are expecting users to upload code, then it is easy to write a PID-1\nlike thing that can wrap the user code and be the entry point for code in\nany language and normalize stdin and do the processing before passing stdin\non to user code.\nIn any case, since this is the MVP I don't have strong preferences. But if\nwe are shipping this as stable, then I would strongly advise against this.\nOn Thu, Aug 25, 2016 at 3:39 PM, Travis Reeder notifications@github.com\nwrote:\n\nWe do have constraints and they are very simple:\n- Must be an executable container (ie: one with an ENTRYPOINT)\n- Input is via STDIN, in whatever format we decide\n- Some extra values provided via ENV vars (user and system provided)\n- Output is via STDOUT\n- Logging is via STDERR\nIt's essentially the same constraints as a program running on an OS.\nWhat's inside the container doesn't matter, that's the beauty of it. We can\nprovide higher level libraries like iron-io/lambda or somebody else could\nbuild something even better as additional tools, but we don't need to force\na specific way on any of us. And doing that doesn't provide us any benefit\nother than more things to maintain.\nThis also ensure no lock-in and that these things are portable.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/issues/72#issuecomment-242566692,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAEzWnD01I_JU3lUtVBA1EN-rg0ds_y-ks5qjhmlgaJpZM4JslYN\n.\n. > Really, I think the only thing in that list that requires discussion at this point is the format of the input and what ENV vars will be provided by the system.\n\nThis project actually mingles 2 layers:\n1) A platform that can run synchronous docker containers (vs IronWorker which is async). This is a complement to IronWorker, which had historically been async, but has nothing to do with FaaS (We have chosen to confuse the nomenclature by calling this entire system IronFunctions). These containers want input in some way and output will be to stdout. For all practical purposes these can rely on the same primitives as Titan/IronWorker, which is a few env vars (I support https://github.com/iron-io/titan/issues/297 here). This is reasonable. \nIn this layer we agree that the things you outlined in https://github.com/iron-io/functions/issues/72#issuecomment-242566692 are reasonable. There are no requirements on the stdin format and the env vars are only used to describe the runtime, things like memory available etc.\nIt is very easy to build various higher level things on this, like SNS based execution, or web hook based execution and so on.\nUsers who create synchronous containers can stop reading at this point.\n2) What the industry knows as FaaS, which is essentially defined by Lambda. Much of my \"bare metal\" and \"API lock in\" concerns are related to this layer.\nThis is a platform that can run time-bound containers in response to an HTTP endpoint, an API gateway, and a little bit of magic in the \"runtime\" that calls a function written in a certain language with the right parameters. In this case, we have slight specialization, where we want to pass the following special things to the container:\n- HTTP headers\n- streaming HTTP body\nThe containers created to operate with this gateway have special requirements above layer 1.\nThis is where I think having these \"special requirements\" be HTTP right now (instead of #78) is the way to go because:\n1. Plays well with layer 1 above. Looking at it from the API gateway point of view, the API gateway is just running a synchronous container, and the \"input\" to the container is the HTTP request the gateway received, and it will consider the output as the HTTP response. \n2. Standard and easy to parse. Users can:\n   1. use some kind of library we provide, or a similar wrapper (say our lambda base images) so that there \"function\" runs directly, and gets access to these fields via the event object, AWS Lambda style. The library runs a small http parser that deals with all this.\n   2. do all the parsing themselves, similar to how they'd do it for any non-FaaS type application. The cool thing about sending in the stdin is that they can use their native language capabilities, such as go's ReadRequest, by just pointing it to stdin. So they could use any framework/middleware etc.\n3. Doesn't require us to define our own ad-hoc format for how the container should read out these parameters. We aren't locking ourselves into any APIs we dreamt up. We pretty much say that if you don't use our libraries (1.1 above), your container ENTRYPOINT must expect a plain HTTP request on stdin. We can even punt on libraries for now. If and when we decide to implement libraries, we can discuss whether we adopt the AWS Lambda API, the GCF API or something else.\n4. Easy testing: It is also very easy for devs to take the same images and test them locally very easily, by just having curl + netcat or similar pipe requests in to the running container. For things like https://github.com/iron-io/functions/issues/71 instead of having the user's code, or our shim code, have to go pluck through env vars, they can just parse using a standard parser.\n5. The API gateway could do interesting things like: If the container and the gateway run in the same process, just attach the socket's FD to the container's stdin - possibly zero copy streaming!\n6. Things like chunked encoding work out of the box.\nThis does have the disadvantage that the HTTP request beginning gets parsed twice, once at the gateway to determine which function to invoke and then the whole thing being parsed at the destination. But this is no worse than having to parse something else from stdin any way and saves on the translation step.\nWhat do you think?\n. Also, I'll live happier knowing I kept another ad-hoc format from arising :)\n. 1) You got me :)\nBut in this generic model of functions as docker container executables, we don't care about \"parameters\" and \"payloads\" and things. We just provide stdin.\n2) This is the platform on top of (1) where we are providing more higher level abstractions over the container-as-a-function model. Here, we can do what the existing FaaS solutions do, which is to have wrappers, in which case it doesn't matter what format we use internally. But focusing on the raw aspect.\n\nWhere do we put things like configs and other IronFunctions related values?\n\nWhat kind of values for example? The environment specific things like IronWorker already does, can go in env vars. The per request specific things will already have all information sent by the function invoker in the HTTP request to the API gateway. Extra stuff like credentials to access a storage service or something could be passed using X-IronFunction-Foo or similar headers.\n\nWe can't add or modify it after we've chosen it (well, we could, but then we'd break the spec anyways)\nand\nThis assumes we'll only ever support HTTP. What if we add gRPC/protobuf support? Or any other protocol? The functions themselves shouldn't really care what protocol is used. \n\nWell whatever protocol the API gateway speaks to clients doesn't matter. It is going to have to translate to whatever the container speaks any way. Right now if we make up our own format, it has to do HTTP <-> custom transforms, and in the future it will do gRPC <-> custom transforms.\n\nIt's not exactly the easiest thing to parse, json and other more well defined formats would be a lot better\n\nThere are 2 reasons I like HTTP over these:\n1. Streaming capability for things like video processing. You could come up with some format where the first N bytes are a JSON blob and then the body follows as raw bytes, but that is just HTTP in JSON clothing :(\n1. Defining our own custom thing over these other wire formats means that we have to think carefully about the fields we want to introduce and their semantics. HTTP is already very well defined, headers and response codes have great semantics and it has several high quality parsers in all languages. Plus every language out there that has json support also has HTTP support, so I don't think any developer is actually going to write code to manually parse HTTP.\nSmall downside is that there are some languages where these primitives are not exposed nicely, but the situation should improve, or can be improved by contributions.\nAlso, going hand in hand with this is how these containers send response meta-data back. i.e. container produces some output, API gateway receives it, translates it in some way to HTTP to send back to the client.  But what about error codes? Will the response be required to be HTTP too, or do we map from process exit status to error codes?\n. Happened to be thinking about something else and noticed a similarity.\nThis is essentially a re-implementation of CGI on top of containers. The scripts are containers and the server is the function gateway. Relevant standards linked to from Wikipedia.\nIn addition, UNIX pipes support sending file descriptors over stdin. I'm not sure if a direct one-one mapping is possible via the APIs available to us via Docker, but what I'm referring to is that the function container can expect stdin to be a pipe, on which it receives a socket file descriptor for the HTTP request and then interact with it directly.\nBoth of these rely on us providing a bootloader image similar to our lambda images that the user can build on top of. Not language agnostic. But we can define the spec and provide a few standard base images.\n. For the file descriptor approach? No, so the TCP socket's fd is sent over\nstdin (opened as a pipe to be able to transfer fds). So the worker process\njust uses that as a normal TCP socket and would write HTTP responses to it.\nOn Tue, Oct 4, 2016 at 12:44 PM, Travis Reeder notifications@github.com\nwrote:\n\nHah, that's interesting and funny. Hadn't thought of that, but ya, I guess\nit is sort of a new CGI.\nDoes it need another pipe if we're using stdout as the outgoing pipe?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/issues/72#issuecomment-251491961,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAEzWq0keD1fhhNcH4257slwEGogupMeks5qwqyugaJpZM4JslYN\n.\n. We put in some silencing code. Unfortunately there is a small window where it is hard to sync between container shutdown and stats streaming.\nReed, perhaps we should create another context that is cancelled before we call stop container and pass that to stats. Will come up with something in a bit.\u00a0\n\nNikhil\nSent from a tiny keyboard.\nOn Mon, Aug 29, 2016 at 10:40 PM -0700, \"Travis Reeder\" notifications@github.com wrote:\ncc @rdallman @nikhilm Assume these are part of the Docker driver?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. I believe @rdallman has some numbers on overlay vs btrfs (the latter being\nreally slow).\nOn Wed, Oct 12, 2016 at 6:09 PM, Travis Reeder notifications@github.com\nwrote:\n\nSee: \u201cThe Overhead of Docker Run\u201d @treeder https://github.com/treeder\nhttps://medium.com/travis-on-docker/the-overhead-of-docker-\nrun-f2f06d47c9f3\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/issues/156, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAEzWsBH5e4WRnNSS8-3JnmWLC3s7PM0ks5qzYS4gaJpZM4KVYWN\n.\n. Yes, adding reading from stdin support sounds like a good idea.\n\nOn Sat, Oct 15, 2016 at 2:43 PM, Travis Reeder notifications@github.com\nwrote:\n\nMaybe check PAYLOAD_FILE to support worker, then read STDIN if it doesn't\nexist.\n- Add STDIN support to iron-io/lambda\n- Add some documentation to this repo for how to use it\ncc @nikhilm https://github.com/nikhilm\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/issues/179, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAEzWkhH8C_-_zA4DfpbtJ8pnfwv7jdQks5q0UjmgaJpZM4KX0pQ\n.\n. iron-io/lambda#61\n. Those images just expect a JSON blob in the style of AWS Lambda to be sent in via stdin. If the API gateway does that, not sure what else is to be documented.\n. How does functions discriminate between 200 and other status codes? Right now our lambda wrappers only print out direct output from console.log() and so on. How would they inter-op with this?\n. Superseded by just creating a fn or similar tool that doesn't have Iron cruft.\n. Yes. what i meant is we should call it deploying at scale or similar.\n\nOn Thu, Oct 20, 2016 at 2:54 PM, Seif Lotfy \u0633\u064a\u0641 \u0644\u0637\u0641\u064a \nnotifications@github.com wrote:\n\nI like the HowTo but we can't claim production. We should not mention we\nare production ready\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/issues/190#issuecomment-255210580,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAEzWqlCGeb0dgm2O1EhS9tyVy6uXVXAks5q18cFgaJpZM4KciMj\n.\n. Guess you are right. Could use some refactoring to move the mutex into the cache. We already have well tested lrucache in some other code. Not urgent.. You would have to write that function ;)\n\nBest,\nNikhil\nOn Wed, Dec 7, 2016 at 2:19 PM -0800, \"Pedro Nasser\" notifications@github.com wrote:\n@nikhilm\nThe idea of the PR is to check if the image exists locally.\nRight now we are checking only against the registry.\ndriver.CanExecuteFast, would serve for that case?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Is their a good reason for this, considering we already have the infrastructure? I agree that IronWorker runners and swapi aren't suited for this, but with the gorunner/titan runner refactoring and the ability to plug in custom taskers, you could have the function server and then 'runners' which could talk to this function server. Rather than a FIFO-ish task dispenser like swapi, the function server would try to be fast about dispensing a job and getting the result back. Granted, having the thing on the same machine means low latency, but what about when the load picks up?\n. Our lambda images do write to stdout.\n. If we already know which images people are using, should be easy enough to have a docker registry proxy that can download registered images as soon as they are registered. May be even run our own registry, and as part of 'create a new function', we populate our registry. servers can then pull from this registry.\n. Why so? I assume the function interface will be something like\nfunction myFoo(context) {\n}\nWe could transparently wrap user code into a container that includes a tiny HTTP server and sort of CGIs their script. This is CGI after all. We can do whatever we want as long as our context object contracts are explicit. Note that Lambda like APIs don't even provide normal stdout (as in, they don't explicitly say where console.log output goes, just that it is available to you somewhere).\n. So what is needed for the MVP?\n. All these flag validation functions and usage flags should be replaced by their urfave/cli equivalents as with the other fn commands. Only the logic in Run() is independent. Some of these functions do some extra validation over just type-checking, so will want to move that over too.\n. I believe the urfave/cli way is not to print and exit, but to return an error.\n. Don't need this logic. urfave/cli has subcommand capabilities.\n. These are remnants from ironcli where they are used to differentiate between lambda commands that need a function name and those that do not (only import). Not useful here.\n. Our common.Context has nothing to do with context.Context.. ",
    "ucirello": "@derekschultz deferred to GA. if I recall correctly, it might be slightly more complicated that. Their API was changing a lot and I don't remember whether we figured out the correct architecture. I would propose to postpone this to at least alpha2.\n@treeder @derekschultz ?\n. It does improve the performance, because it wouldn't involve the cost of starting the container - but the tradeoff is that eventually the docker daemon degrades. That's what the rotation is all about, in the end no?\n. My first intuition is to say that we shouldn't do it. But I think we'd better to think a little longer about the idea. Also there's the problem of the shared state between executions within the scope of the same container.\n. See #214 \n. https://github.com/iron-io/functions/pull/332 fixes this. Does this still make sense?\n. Should we expect the user to build this image? If not, then I would suggest to set Dockerfile to use FROM scratch - that's as small as can be at the cost of a slightly more complicated build.\n. @seiflotfy @pedronasser @treeder \n. Fixes #114 \n. LGTM\n. Runners are self-regulated.\n. @treeder @seiflotfy @pedronasser - please review. Extra attention to gramatical and orthographic mistakes. \n. LGTM\n. @treeder @seiflotfy @pedronasser\n. @seiflotfy did you use get-kube to start the kubernetes cluster? We must not conflate problems to configure a proper Kubernetes clusters with the instructions to get this running.\n. It waits also for the completion of async workers. When you filed this issue, was that the case?\nPerhaps we shouldn't do a hard exit if that's the case. Alternatively, we can add a message saying something along the line: \"Hold still while async workers finish their work\".\nAnd exit after a specified timeout.\n. OK. Fixing it then.\n. That what I would expect. Regarding sync workers, the termination is immediate. The async workers, it would hold for a while.\n. Is this PR still needed?\n. @seiflotfy @treeder @pedronasser \n. @treeder \n. @treeder @seiflotfy @pedronasser \n. @seiflotfy I know you're working on a demo case for Facebook bot. Is this similar somehow?\n. @pedronasser any news on this?\n. cirello.io/supervisor is a vanity URL for a github repo. It is public and it is on an open repo. \n. I am not sure I understand your definition of publicly available on github or some open repo. Do you understand that this is a vanity URL for github.com/ccirello/supervisor? It is on github and it is publicly available. \n. Interacts with https://github.com/iron-io/functions/issues/134\nIf we move the async/sync flag from the route to the invokation, this should become easier to accomplish. And more in line with what we've got in the industry.\n. Done in #314 . How sure are you sure? Because I am pretty confident that I have unified sync and async jobs to use the same workers.. Check https://github.com/iron-io/functions/blob/master/api/runner/async_runner.go#L130 -- as you can see, it talks to tasks channel - which is the same channel that takes in sync tasks. So they were separated stuff, not anymore. Moving convo to slack.. @treeder -- the dependency now is on a explicitly open repo and publicly available. As the import url mask could have led to this interpretation problem. I am therefore just updating to use github.com import link instead.\n. @pedronasser @seiflotfy @treeder \n. Actually it was a result of a corrupted datafile. Retracting.\n. See: https://github.com/iron-io/functions/pull/198\n. @seiflotfy @treeder -- ready to review\n. I feel half-hearted about this idea. For sure, it would be very handy to have this feature implemented in Functions, thus facilitating one very common use case. On the other hand, it opens a Pandora Box of hard decisions:\n1 - Where should we store the output? I am tempted to say that it shouldn't be in the datastore. Perhaps add a support for services like S3 and Minio? If using Minio, should we embed it as we do with BoltDB?\n2 - Some design pain points:\n     a) How long should the each result be stored? \n     b) Supposing results may expire, where do we set their expiration time? When the code is added or when the code is executed? \n     c) Should we add an API extension to manipulate these stored results? (Of course, the user could just operate the storage service, still he would have a hard time telling stale from useful results).\n     d) Is this API extension part of a future Open Functions Standard? \n     e) Is this orthogonal to a future workflow support? Is this orthogonal to Functions itself? (In the sense this could be developed as a long running function instead of a built-in feature?)\nI think it is a good idea and we should debate it more thoroughly. \n. This could relate to https://github.com/iron-io/functions/pull/200\n. @seiflotfy are we done with this?\n. @treeder do you have a step by step to reproduce this error? I have tried here in many ways, but I get a different error.\n. I grep'd the code for \"Handler for\", and it turns out it is a Docker daemon error message. It is either here or here. Either case it is Docker printing, not IronFunctions. Were you running it in DinD? If so, that could be reason. \n. I think so.\n. @treeder @rdallman \n. duplicate with https://github.com/iron-io/functions/issues/134\n. @treeder @rdallman it ain't complete, but it is worth checking. It won't compile unless you manually fix the generated functions_go. @seiflotfy is fixing it. The whole problem is that route creation uses RouteWrapper and swagger.yml has in it to use RoutesWrapper.\nTake a special look at README.md, there is the proposal for the bulk of automatic updates. \n. +1 leaving it to the load balancer.\nEventually it will be nice to have some SSL support so to enable HTTP/2.\n. Just tested. All is working fine @seiflotfy - perhaps, what's missing is that, if you are changing the PORT env var, you will need to also change API_URL in order to let async tasks to work properly. Or disable them altogether.\n. @treeder @seiflotfy \n. This probably means writing a new driver on runner repo. I suggest tagging this for alpha2 or later. \n. Isn't it what the current run is doing? I think I have implemented it already, @treeder\n. It takes stdin, returns result as stdout. And you can pipe in the shell. \n. https://github.com/iron-io/functions/pull/211\n. curl -sSL http://get.iron.io/fn | sh just works. @treeder @seiflotfy what you say? merge or abandon?\n. @pedronasser I wonder whether it would be possible to break this PR down into smaller PRs? So the chunks that get approved are not held by the chunks that need review?\n. > If its too bad to review like that I could try break it.\nDon't worry - when I see big PRs, I just make a point about their size. I will review as it is, no problem.\n. Helpful reference:\nhttp://choosealicense.com/licenses/\nEdit:\nhttp://choosealicense.com/appendix/\n. #208 \n. LGTM\n. @pedronasser @treeder @seiflotfy \n. @treeder @pedronasser @seiflotfy \nFor now, Go, PHP, Python and Node to start - we can add more languages later. \n. Missing: test command for Java, and aws-import. Being addressed in the next related PR\n. @treeder - is this what you had in mind?\n. @pedronasser @seiflotfy \n. see #69 \n. Hi @japsu - thanks for the suggestion. All options are on the table right now, including FastCGI. We should definitely consider it. . https://github.com/iron-io/functions/pull/332 - introduces HTTP stream.. Moved to Beta1. TODO:\n\nJSON-HTTP protocol\nAdd more examples in other programming languages. This seems to be a non-issue. The AWS lib already parses the environment variable AWS_REGION. Could you please be more specific?\n. We might need to defer it due to their rules of acceptance:\n\nhttps://github.com/Homebrew/brew/blob/master/docs/Acceptable-Formulae.md#niche-or-self-submitted-stuff\n. @treeder @derekschultz \n. @seiflotfy @pedronasser @treeder \n. @treeder @seiflotfy @pedronasser \n. LGTM - you might want other people to check it too.\n. We still need to understand how we want to deliver triggers - postponing this.. I see some value out of that, and could be automatically generated from the git log.\n. We've got CHANGELOG.md file. . There is no unified coverage metrics for the standard Go tools. I know coveralls offer something similar, but sometimes their metric system fails. It would be nice to get this number though.\n. >  ./fnctl routes run myapp /hello\nThis is a documentation error. fnctl routes does not have run command anymore.\nsh\n$ grep -RHin \"routes run\" *\nREADME.md:137:fnctl routes run myapp /hello\nREADME.md:152:echo '{\"name\":\"Johnny\"}' | fnctl routes run myapp /hello\n. @treeder @seiflotfy @pedronasser \n//cc @noqcks \n. @treeder @seiflotfy @pedronasser\n//cc @noqcks\n. @pedronasser @treeder @seiflotfy \n. @treeder @pedronasser @seiflotfy \n. Update and merge after https://github.com/iron-io/functions/pull/247\n(also add env var expansion for app configuration)\n. With #287 it can be closed.\n. I really dispute that 409 is the correct response. First, 4xx are client errors - this is clearly a server-side issue; secondly, assuming that 4xx is the correct error class (which I give in for discussion purposes), I also do not believe 409 is the correct answer. 409 Conflict is to reveal a concurrency problem in competing updates. In this case, we are trying to block a request that shouldn't have taken place anyway - meaning that 400 Bad Request would be a more appropriate response in my opinion.\n. I really dispute that 409 is the correct response. First, 4xx are client errors - this is clearly a server-side issue; secondly, assuming that 4xx is the correct error class (which I give in for discussion purposes), I also do not believe 409 is the correct answer. 409 Conflict is to reveal a concurrency problem in competing updates. In this case, we are trying to block a request that shouldn't have taken place anyway - meaning that 400 Bad Request would be a more appropriate response in my opinion.\n. https://github.com/iron-io/functions/pull/256#discussion_r87299369\n. Expanding on the command I wrote in the PR. \nBesides the increase index price (20% if I haven't got the math wrong) - I see this space adequate enough for the specific case of UUIDs. They can be stored in 16 bytes, which you can see here: https://github.com/satori/go.uuid/blob/master/uuid.go#L128\n. Check this, @denismakogon :\nQED:\n``` python\n\n\n\nprint(len(uuid.uuid4().bytes.encode('base64').rstrip('=\\n').replace('/', '_')))\n22\n```\n. @treeder @pedronasser @seiflotfy \n. > I found a bunch of places you missed, did you search to find all the places where DB= and MQ= were used?\n\n\n\nI used grep with some grep -v's I might have removed some important in the process.\n. I guess it will come naturally as we evolve towards stable v1. I wouldn't dare making predictions about usage for now... People can get very creative in many ways of using functions.\n. > Explain what bump does.\nhttps://github.com/iron-io/functions/blob/master/fnctl/README.md#build-bump-push\nit seems no-op for me, what's missing?\n. @treeder \n. One extra comment about this PR: too big. I was lucky to go through it rather quickly because I am most familiar with all the code changes. Stil, in the future it might get tricky to understand what we've done here and what our intentions were. Smaller commits are easier to review, bisect and revert; and also helps preventing blockage among different commits. I might be mistaken but now it seems that https://github.com/iron-io/functions/pull/273 is blocked because of this one.\n. Regarding the runtime and entrypoint detection, I should like to suggest \"Convention over Configuration\" approach. Here.\nAs much as we look for function.yaml, for fnctl init, we could agree on few rules:\n1 - func.{lang} is the file from which we'll detect the language and look for entry points.\n2 - The entrypoint will always be func, func.{lang}, func.{langpackage} (Java's func.jar, PHP's func.phar).\nWhat you say? It would be the whole thing much simpler.\n. > the language helpers can deal with a lot of things particular to a language rather than scattering those things throughout, like acceptableFnRuntimes and fileExtToRuntime for instance. Just lookup the helper, get the LangHelper interface and use the same methods for all languages.\n:+1:\n. I believe we could introduce batched consumption in the future. I see this as a bug of the API as it is:\nhttps://github.com/iron-io/functions/blob/master/docs/swagger.yml#L296-L302\nEven if we add it later, I suggest removing it for now.\n. This is more adequate to iron-io/dockers repo. Opening there. Closing here.. https://github.com/iron-io/dockers/issues/56. My take on this is that when the application gets complex enough, that's when our bootstrap tools go away from the scene and the advanced documentation kicks in. If you have a sufficiently complex application, you should be probably be using custom func.yaml and Dockerfile.\n. With the advent of package lang and PreBuild() call, this is rather trivial now.. > Do any of these changes require swagger update?\nNo they don't - but the latest changes in the server made some parts of the API crippled. Refer to https://github.com/iron-io/functions/issues/288\n. cc @pedronasser \n. cc @denismakogon \n. Commenting these lines out: https://github.com/iron-io/functions/blob/master/fnctl/routes.go#L340-L342\nAnd running:\n./fnctl routes config set myapp hello key1 value1\n./fnctl routes config set myapp hello key2 value2\nthe key2/value2 pair will not be there. \nIn the logs, you should get a \"error=Route already exists\"\n. I am testing it...\n. It might have fixed something, but definitely it did not help with https://github.com/iron-io/functions/issues/288\n. This did not help with #288 - but I think I see the point of this change. In the end, this change would be necessary to ensure that route updates work. So partial route updates, ie the ones that are not changing the image, still go through.\n. Proposal rejected.\n. I wonder whether we couldn't convert this to Go sometime.\n. The dockerworker example is already there.\n328 fixes the fn init.. @treeder now that I have the information that the runner regulates itself, there's no need for max runners. I am going to remove this extra mechanism.\n. Refer to #333 . Thanks @sks \n. Depends on #325 . @pedronasser Thanks for taking a look at this PR.\n\nIMHO adding more and more complexity to the IronFunctions workflow with more and more internal components dictating how the user of IronFunctions should use the platform and not letting them to extend or change those components behavior.\n\nIndeed, I haven't added yet any extension points to the clockwork running Cold/Hot containers. I would rather wait for the actually extension need to arise than adding an extension point that become just another burden of maintenance and documentation.\nHowever, you do have a point regarding complexity. Hot containers implementation is really more complex than cold containers. And I am open to suggestions on how to make it simpler, if you have any.\n\nI think a good practice is to let new components with big responsibilities to be replaceable, so the user can configure their behavior the way they want.\n\nCare providing citation for this statement? Shouldn't components be small, sweet and to the point?\n\nLike I said before, I think the only two parts that must be irreplaceable are the API and the Runner. We must decide what kind of open source project we are building.\n\nI think this is a valid debate for Slack. . @seiflotfy . I believe it is intended that IronFunctions works this way. Containers can either be short-lived, ie they do not sit long enough to be any use as daemons; or they can be long-lived, and in that case, their purpose is to interact with standard I/O to get workload from IronFunctions daemon. \nHowever, you might be uncovering an unforeseen use case. What's the goal here? Why would you need to bind a port? Or, in different terms, why do you need IronFunctions to deploy a container whose role seems to be of a daemon?. @denismakogon I am afraid there is a miscommunication issue here. I am very well versed on the use cases you put forward. Incidentally, none of them provide a way to bind TCP or UDP port to work. So again, why do you need to expose TCP/UDP ports of a container?. Discussion follow-up https://open-iron.slack.com/archives/functions/p1480014779000961. This is a bug. The problem is that there is a hard-coded 30s timeout in the source code.\nhttps://github.com/iron-io/functions/blob/c14bc323f97f4c8d11628b27496903f80dab962e/api/server/runner.go#L172\n@treeder @pedronasser @seiflotfy - what would the appropriate fix? Is the timeout an attribute of the route or the task call?. > would be the right fix to set execution timeout through API?\nI don't see any other place to land the fix. :) It must be in the API - the only you way you can interface with IronFunctions daemon. \nHowever, is this an attribute of the route (PUT /v1/apps/{app}/routes/{route}) or the task (POST /r/{app}/{route})? . > In this case the routecache has the mission to prevent the runner to query for the route every request, so when the requested route is already in the hotroutes cache the datastore will not receive the query.\n\nSo when the user wants to change any kind of behavior in the datastore, he expects that everything will be requested for the datastore, but in the cases that the datastore is not consulted (eg. in this case), that behavior will not be correct. And that's the reason I'm trying to make the routecache pluggable.\n\nThis is wrong. For every route modification, there is a cache invalidation. And if it is missing, then it is a bug that must be fixed.\nWRT Cache being pluggable, you can make an extension point to Cache. And make sure that all caches, being internal or not, comply to this interface, and put all requests through this cache stack before actually checking Datastore.\nThe important part is to ensure that any app or route change to invalidate the cache, no matter what it is.\nMy line of thought derives from Open/Close principle.\n. > So, here the thing, we need to have persisted models definitions out of code in order to have good enough user experience during upgrades from version X to version Y.\n\nAnother question, if i would create a route before this patch and then will upgrade functions API up to this patch how this code will handle cases where model wouldn't have Timeout attribute.\n\nIdeally, we shall have stable model definition by v1, and from there backward compatible changes only. This hasn't been discussed yet. We are still in the Alpha cycle where we all expect things to break often.\nCurrently, routes whose configuration has Timeout zero, will no longer have any timeout. Coding something around expected timeouts is a big mistake. Thus, it should impact no one doing it right - and it will create a minor nuisance for those using it.\n\nAlong with that, this code doesn't actually validate if Timeout fits integer range.\n\nIndeed it doesn't. But also this PR is WIP. I shall align integer sizes once I regenerate client libraries.. Open an issue with the TODO debt, please.\nLGTM. @seiflotfy @treeder @pedronasser . @treeder @pedronasser @seiflotfy I have extensively checked and updated the documentation on this change. \nPlease review, critique and merge if OK.. In HEAD, this is handled correctly. See the validation message in the example below:\nShellsession\n$ curl -X POST -d '{\"route\":{\"type\": \"asynca\", \"path\": \"/hello-sync2\", \"image\": \"iron/hello\", \"format\": \"http\", \"max_concurrency\":2 }}' localhost:8080/v1/apps/testapp/routes\n{\"error\":{\"message\":\"validation failure list:\\nvalidation failure list:\\nInvalid route Type\"}}. Check https://github.com/iron-io/functions/pull/359/files for checkbox 2 and 3. Check https://github.com/iron-io/functions/pull/370/files for checkbox 1. @pedronasser @treeder @seiflotfy @denismakogon . Must update glide.yaml/glide.lock after merge.. @pedronasser can we make it for the alpha2 cycle? or should defer to beta1?. @treeder @pedronasser @seiflotfy @denismakogon . @pedronasser @seiflotfy @treeder . @treeder @seiflotfy @pedronasser . @treeder @seiflotfy @pedronasser. @pedronasser @seiflotfy @treeder . @seiflotfy @pedronasser @treeder . In HEAD, it is working correctly:\ncurl -s -X GET localhost:8080/v1/apps/testapp/routes/hello-sync2 | jq\n{\n  \"message\": \"Successfully loaded route\",\n  \"route\": {\n    \"app_name\": \"testapp\",\n    \"path\": \"/hello-sync2\",\n    \"image\": \"iron/hello\",\n    \"memory\": 128,\n    \"type\": \"async\",\n    \"format\": \"http\",\n    \"max_concurrency\": 2,\n    \"timeout\": 30,\n    \"config\": null\n  }\n}. Could you please double check? I am pretty confident we've have guarded the LRU cache with mutexes. Refer to https://github.com/iron-io/functions/blob/2c56e7975d5ea469384eb6d4dae97c4652bdb459/api/server/server.go#L133. @nikhilm @seiflotfy . @pedronasser @treeder \n. Wrt iron-io/runner#19 we can always choose to upgrade again.. All right! :) . The problem with the current implementation seems to be that the libraries we wrote to enable the use of lambda functions with IronFunctions does not know how to handle the permanent I/O stream. They'll need to be modified in a such a way that on the conclusion of its execution it reads from stdin and run the next incoming call. . @treeder @seiflotfy @pedronasser . I believe this is done already: https://github.com/iron-io/functions/commit/aa12f3c724223f884f1e6e467738c0fbef7ade4f\nwhat are you suggesting as an addition?. @pedronasser @treeder @seiflotfy . @seiflotfy @pedronasser @treeder . @pedronasser I would like a lot to see such refactor made for alpha2. But from my perspective here, if we do it, we throw our deadline by the window. This PR will force a domino effect of other refactorings, among them making server smaller, adding abstractions to help customizing the server part of the code and whatnots.\n. @pedronasser @treeder . @seiflotfy - all route information: image name and tag, configuration and whatnots.. @seiflotfy do we have a PR for this?. The PR is restricted to app name and route path. . @seiflotfy @pedronasser @treeder . LGTM with one style suggestion.. @nikhilm what you say of this PR? Shouldn't this be part of iron-io/runner perhaps?. I am not sure whether the phrasing could be improved as I am not an native speaker. It does LGTM however.. LGTM. done @pedronasser . hi @Gouthamve - thanks for reporting this. Could you please confirm the installed version you are using? \n$ fn --version. I am sorry, the usefulness it not evident for me. Could you please put forward a concrete case in which this is a superior replacement for the current flow?. @denismakogon what's the intent here? I am afraid I do not follow your reasoning. The worker alone should be the entity talking to /tasks endpoint. And it must be able to read the task it's been assigned to. Why do you need to have this entrypoint? Which component will be talking to it, and do you expect this component to achieve with the payload that, in theory, only interests to the worker?. This is a compelling idea. We need to investigate, though, a way of making it happen in a way that's driver agnostic. . @derekschultz Can we merge this?. Confirm the version please. I just tried it, and it worked just fine:\n\u279c  myrubyapp git:(master) ../fn init --runtime ruby treeder/guppy\nfunc.yaml created.. @treeder It is using conditional compilation for Go1.8. It is backward-compatible. So I strongly advise to have it merged anyway. . LGTM. Done at https://github.com/iron-io/functions/pull/204. wrt: last two paragraphs ~ it feels non-recursive fn deploy all over again.. @treeder no. Only if a glide file exists.\nhttps://github.com/iron-io/functions/pull/441/files#diff-4070a885e260010d742e6f48147e4c2dR30\n. As I'm not an Iron employee anymore, and not really into signing the CLA, I suggest you open a new PR instead. . It seems that is slightly more complicated than what's being talked here.\nIn this particular switch block, an 500 error is a sort of catch-all handler. And the driver itself, has more states than the ones handled. Check https://github.com/iron-io/runner/blob/master/drivers/driver.go#L67\nI am not sure that an output will always be available in case of execution failure - and keep in mind that this error is at container-driver level; not application level. It means that the application should be able to detect its own errored state and print it somehow either to stdout or stderr - which in this case will be a 200 with a proper response body.. Addresses https://github.com/iron-io/functions/issues/151\n//cc: @treeder . Closing this for now. Looks good, but I am afraid it conflicts with https://github.com/iron-io/functions/issues/250. @treeder - any suggestion on how to handle security for this endpoint?. OK. AppListener. From my perspective, this is a long story. It starts as a single interface for all Listeners types, and then iteratable through all Listeners. Sometime ago, I believe in https://github.com/iron-io/functions/pull/412 , @pedronasser changed it - by my suggestion - to break into smaller interfaces, and only iterate each Listener type. This PR is reverting it.\n@pedronasser any insights on this change? . how do you do config unset? . If setting a configuration key to empty removes it, how do you set empty values? . @treeder that's how it was before, but I am giving Pedro some room to think about this change. It was like you're suggesting, but this PR changes this. . We actually use glide. Take a look at:\nhttps://github.com/iron-io/functions/blob/master/Makefile#L5-L6\n. Thanks for this PR. I do see a problem with it, however. You are adding a new parameter (--link) for running functions locally - but it lacks the implementation on the Docker driver. It is important that fn run and fn call both be feature parity. \nAlso, I believe in the long term, we aspire for an agnostic approach to the containers. I wonder how this would reflect on other possible drivers down the road, such rkt. \nAny ideas on this @seiflotfy @pedronasser @treeder ?. @treeder makes sense.. @treeder the hot functions implementation offers the plumbing to the creation of libraries that simplify its use. Ideally, we would have iron-lambda libraries to be hot-functions aware and the whole point of this issue and #215 would be essentially solved. That's why I opened #386 .\nIf everyone is OK, I think we should mark this as closed and focus on evolving with #214 and #386.. It seems @jmank88 is taking the gradual approach to this PR. Closing this as it is on a conflicting state. This can be revived later in other PRs. . For certain aspects of the UX, we do prefer things to be easy rather than simple. I suspect this could be done on client-side, however, with proper scripting - as a stop gap. Not most efficient way ever, but would assure a quick delivery. And not polute unrelated PRs.. Refer to https://github.com/iron-io/functions/pull/431 for an historical perspective of such proposal.. A good merge message covering on the reason and consequences of this change is a must. Regarding everything else, LGTM.. @denismakogon - makes sense to a point.\n\nSo, yes, there are two timeouts, and it doesn't look like something bad or confusing. \n\nWithout context, I doubt people will know the difference between timeout and idle_timeout. This could be easily addressed with documentation though - as of now, however, docs are missing.\n\nYou're saying that it was not thought through, i tend to disagree on this, because it's not clear why hardcoded 30s timeout is exact timeout that every hot function should wait without processing requests before becoming \"cold\".\n\nIndeed, it is not clear the reason behind 30s. However, whenever we change a constant to a variable, we are changing the behavior of the system. So what you are saying is that the user needs it - which I am fine with - and that this reason alone is enough to justify this change as it is right now.\nI did not see anywhere any consideration of the consequences of this change: it does not define min and max boundaries, does not explain the consequence of too short or too long idle timeouts, it seems to address the zero case implicitly (for instance, it is not self-evident for me what happens if this idle_timeout is zero); also I do not see in the source code the interaction between this field being updated in the DB while the hot functions are still running. \nAgain, I am not against the goal of this change - but this implementation of this change is lacking in many aspects. \nA middle-way here would be to merge this as it is, and open a batch of tickets addresses its deficiencies. . @denismakogon @treeder LGTM. No need to consume the body anymore, as long as we using Go1.7, http package will do it.\nhttps://golang.org/src/net/http/server.go#L1062\n. done\n. done\n. done\n. Done\n. Done\n. I am not sure whether we should add the DB variable here. By the way, I see some cognitive problem between the roles (MQ and DB) versus the possible drivers. For instance, we think of Bolt (which is a DB), but actually Bolt is used both for MQ and DB. \nThat's why I am suggesting removing this -e DB...... So it could be addressed properly later.\n. changing to num_async here also forces to update down the file. Near tasksURL, port, nasync := viper.GetString(\"tasks_url\"), viper.GetString(\"port\"), viper.GetInt(\"nasync\")\n. api_url too\n. No it is not. IGNORE_MEMORY is the flag that disable job memory limitation.\nCompare:\nhttps://github.com/iron-io/functions/blob/makefile/api/runner/runner.go#L244\nvs\nhttps://github.com/iron-io/functions/blob/master/api/runner/runner.go#L243\n. Do not ignore the error here.\n. what's the intention of this strings.Replace?\n. Why this error block has been removed?\n. If this is not going to be used, please remove.\n. Yes\n. IMHO to runner_async_test.go\n. Personally I see this is a typical use case for http.CanonicalHeaderKey(...). \nEven if it isn't the case, then I would suggest to encapsulate this into a function meaningfully named. \n. I could, judging by the error ErrRunnerRunRoute- it seems it would be some sort of protection for when a client tries to run an unknown route, or with different than the expected parameters.\nThe issue here is different, however. Do you need to touch this part of the code for this PR to be executed properly? If not, then, this change could be reverted.\n. OK - my only point is to keep the changeset as small as possible. If it is dead code, then keep it deleted.\n. Yeah - now that I realized that it translated HTTP Headers into environment variables.\n. b953cea264b1a5a2db46beeaa73f495c19207e51\n. oops\n. fixed.\n. Why returning drivers.RunResult here if in every use of runTask it is not used? \n. Ditto\n. Ditto\n. Ditto\n. Has this file been regenerated by Swagger?\n. If this comment block is no longer necessary, please remove.\n. Task complete: -> Task complete (remove the unnecessary colon)\n. Please, remove the unneeded tests here. \n. I was the one that added the anonymous function. I believe it is time to separate async machinery into its own struct. So these injections could be replaced with mocks. Not in this PR, but soon enough.\n. Could we go simpler then? \njson.NewDecoder(os.Stdin).Decode(input)\n(remove the if block...)\n. .Fatalln() ? (it will work the same than printing an empty string)\n. I wasn't able to convey what I wanted to say.\nlog.WithError(err).Fatalln(\"\") and log.WithError(err).Fatalln() are equivalent, no?\n. If the slash was there, it would be \"/:\" (because: \"/myapp/route/:param1/:param2\") and etc. It turns out that the most simple test is just look for colon, not only it works well with the obvious cases, but also malformed ones (\"/ :aaaa\" - note the space before colon).\n. We can't. The method signature is GetRoutesByApp(appName string, routeFilter *models.RouteFilter) ([]*models.Route, error). If we do what you propose, then we would not being accurate with the interface intention, leading exactly to the error I fixed in this change.\n. Do we want to let this mutex to be accessible from outside? It is protecting a private entity (msgAssoc), so I think it should be private too.\nGo\n        ...\n        mu sync.Mutex // Protects msgAssocMap\n        msgAssoc map[string]*assoc // job id to {msgid, reservationid}\n}\n. done\n. done\n. Is aufs official? I thought it was a sort of Ubutu's juryrig... Gonna update that. \n. It is reconfiguring docker's /etc/host to ensure it works with its default configuration. Otherwise it'll try to connect to container's localhost instead of the host one. \n. No we don't do it on route create. I am struggle to find a correct and elegant solution to this problem. The real issue here is iron/functions_go swagger generated library. Everyone expects to feed routes with a leading slash, but then this leading slash is dragged along all the request. \nMore precisely, here is the problem: https://github.com/iron-io/functions_go/blob/master/routes_api.go#L178 \nSwagger does not sanitize what it puts in the URLs.\nIt is an ugly workaround and I am open to alternatives. \n. I think both can coexist in the same document. Restoring them. \n. Done\n. I wouldn't oppose it.\n. done\n. Are these two constants being used anywhere?\n. Nit: I guess it would be more consistent with the rest of the code if this was private. \n. This whole set of flags seems pointless to me. Everywhere in *nix ecosystem, mandatory params do not take flags, eg, cp, mv, cat &c... \nOr putting differently, what's the default for \"function-name\"? And for \"runtime\"? And for \"handler\"? \nI would prefer to keep this ecosystem style, than import ironcli's into here. That is:\nfnctl lambda create-function <funcname> <runtime> <handler> <file> [files...]\nLess keystrokes for day-to-day use, coherent with *nix ecosystem, and imho better.\n. Nit: this extra line is not really necessary.\n. why the alias?\n. For now, this is OK, but ideally we should be able to code these restrictions/logic in a separate and injectable logic. Nowadays we support nodejs, python2.7 and java8 - but we can in a future this being expanded, and this if block growing.\n. Perhaps this could be more concisely described? Personally, I didn't understand AWS LambdaImpl part. This if functions, and not AWS Lambda. Am I getting something wrong?\n. Wouldn't be a good idea to return the err in the message? So the use would know what went wrong?\n. Ditto.\n. Where's the rest of this? \n. done\n. done\n. good catch.\n. gonna extract and address that in a comment.\n. Nit: this could be one import block.\n. ditto\n. ditto.\n. What kind of error could go wrong with Close(), I am not sure there's an error to catch here.\n. 2 is a Magic constant. This is bad. \nAlso, I have the impression the best approach here is to simply extract this if block into a function, and handle the exceptions in a structured manner.\n. ditto\n. ditto\n. renamed api.md to options.md below, but didn't update here.\n. Worth noting that Content-Length is mandatory? So the consumer knows when to stop between incoming requests?\n. To be decided later - but in my opinion this can be solved with the use of a magic number (similar to UTF-8), if the first 3 bytes is a certain sequence of non-printable bytes, then the input is read like HEADER until BLANK LINE. Otherwise it is just body.\nActually, two magic constants: one that indicates header is coming, the other indicate binary is coming. So users that need to return binary content wouldn't be harmed by it.\n. When invoking from fnctl, environment variables are sent as headers...\n. Is it worth mentioning the functions.json/yaml files? \n. --download-only? (double dashes)?\n. --profile? (double dashes)?\n. --version? (double dashes)?\n. the use of single quotes here would improve the readability\n. I would emphasize STDIN as a primary device of payload injection.\n. Ditto\n. done.\n. you've used everywhere:\nif err := ...; err != nil {\nWhy is this one different?\n. recusively -> recursively\n. I think it is worth mentioning here something about incremental build.\n. mention how this interacts with -r\n. s/servlerless/serverless\n. s/ssection/section/\n. few couple of what? (reason, I assume)\n. missing sh after triple tick.\n. ditto\n. spacing\n. spacing\n. The prefix is done by the server, not the fnctl. Check: \nhttps://github.com/iron-io/functions/blob/master/api/server/runner.go#L129-L147\n. Yes, I guess it is. Perhaps in a separate PR?\n. done\n. I am not entirely opposed to raising from 30 to 36. But I should like to see some reasoning around this number. Because there will always be someone needing extra space. The logic here is that UUID4 needs more digits - which forces me to ask why not drop the dashes and convert to hex and store in a smaller space.\nUnder the big load, every index byte counts. So 20% in index cost is not something to take lightly, IMO.\n. It is perfectly possible to store UUIDs in 16 bytes: https://github.com/satori/go.uuid/blob/master/uuid.go#L128\n. QED:\n``` python\n\n\n\nprint(len(uuid.uuid4().bytes.encode('base64').rstrip('=\\n').replace('/', '_')))\n22\n``\n. What does it happen when two competing requests execute the same request in this case? \n. How would the client libraries react to409`? Have you tested fnctl? I think it might need some extra tests there to handle 409 responses.\n. I am not sure whether this is the best way to handle this situation. The way it is, we simply cannot test this code later down the road. I would take the file handler as parameter instead, and just write data to it.\n. I guess the problem here is that is always assumes that the function file will create having the current working directory as the root of the whole process. Is this a valid assumption always?\n. Right - but I will fix this mistake in the upcoming PR about documentation... I am trying to keep concerns separated in this case.\n. if you are passing explicitly below, these exports are not really needed - correct?\n. you can only do that if you remove the tag from the image name. Othewise:\n\n\n\nfuncfile.Name = \"owner/reusedimage:tag\"\nfunction.Version = \"\"\nwill become:\nfuncfile.Name = \"owner/reusedimage:tag\"\nfunction.Version = \"0.0.1\"\nFor the sake of correctness, either this if must remain, or funcfile.Name must be normalized.\n. If you are not going to print this, remove the else-block.\n. ditto\n. ditto\n. why is this a public function?\n. These seem to be gratuitous changes. I should like to see at least some reason about not helping users with small mistakes. \nThis seems to push towards the singular inflection - but the name of the project is on plural. It is just guessing from my side, but we could help people by being more tolerant than being more strict.\n. why is NewNotFoundError public?\n. cannot this be rewritten without the else-block?\n. Could this comment be moved closer to where the actual entrypoint detection is made?\n. A double :-1: for me.\nRationale:\nIf the OS happens to return the wrong file, it will do a wrong detection. For instance, if in the root there are Ruby and Go files, and the project itself is Go - but with one small ruby script, it can derail the whole detection. What does it constitute the language of a project? The logic of the majority has the downside of taking too long to process, but getting higher accuracy rate. I could give him here preventing filepath.Walk into diving into subdirectories. But still, we can also hit the situation in which a root is full of scripts, and the application living in a deeper subdir is actually something else. This change seems to assume that our beginners will do mostly single language applications. I can see several cases that it wouldn't be true. One could argue \"if the application is too complex, the user should be using Dockerfiles anyway\", which I am mandated to counter with: \"People code in one language, but have script assistance with others\". All in the root.\n. Please, keep cyclomatic complexity under control. This can be rewritten without the need for a if-in-if.\n. ditto regarding cyclo\n. ditto wrt cyclo.\n. This can be handled better through check on stdin's FD. Pretty much what's done with:\nhttps://godoc.org/golang.org/x/crypto/ssh/terminal#IsTerminal\n. Just to make it explicit: \nfuncfile.Name = \"owner/reusedimage:tag\"\nfunction.Version = \"0.0.1\"\nwill have for FullName: \"owner/reusedimage:tag:0.0.1\"\n. A double :-1: for me.\nRationale:\nIf the OS happens to return the wrong file, it will do a wrong detection. For instance, if in the root there are Ruby and Go files, and the project itself is Go - but with one small ruby script, it can derail the whole detection. What does it constitute the language of a project? The logic of the majority has the downside of taking too long to process, but getting higher accuracy rate. I could give him here preventing filepath.Walk into diving into subdirectories. But still, we can also hit the situation in which a root is full of scripts, and the application living in a deeper subdir is actually something else. This change seems to assume that our beginners will do mostly single language applications. I can see several cases that it wouldn't be true. One could argue \"if the application is too complex, the user should be using Dockerfiles anyway\", which I am mandated to counter with: \"People code in one language, but have script assistance with others\". All in the root.\n. Why the replacement between glide and go list?\n. ditto\n. Is this a necessary comment?\n. ditto for the comment\n. any reason for not using ioutil.TempFile?\n. if err == sql.ErrNoRows {\n        return nil, models.ErrAppsNotFound\n    } else if err != nil {\n        return nil, err\n    }\n. This provides appropriate coverage, although it is just a very long test. We're Go1.7 now, could we perhaps refactor it into subtests? \n. Is this a necessary comment?\n. Is this used anywhere?\n. > In this command we could continue using glide nv but I think is good to use the same.\nIf we could, then again, why change?\n. glide nv will list all (n)on-(v)endored dependencies... See previous comment.\n. Sure.\n. So we need this fix, either in this PR; or an issue reminding us to have this fixed.\n. These were for tabwriter output. all these commands were meant to be bulk updates, and have been perverted into single directory calls. \n. Makes sense. \n. I suggest mention the logic of this change in the commit message.\n. It is actually more readable having to parse one level into our heads than made. Compare:\nif err == io.EOF {\n    return rt, nil\n} else if err != nil {\n    return \"\", fmt.Errorf(\"file walk error: %s\\n\", err)\n}\nFirst, we are not communicating EOF as an error (which get implied when embedded into a if-err block); second, we are putting the most common case first - with the upside you can get to the hot path with one check instead of two (the if-err then if-err==EOF).\n. For the simple reason that window version will not return an error and it will not lead to the discard of an error. \nmore simply and easily with:\nfd := int(os.Stdin.Fd())\nif !terminal.IsTerminal(fd) {\n    cmd.Stdin = os.Stdin\n}\n. True. Let's keep this implementation as it is. No extra imports. If it proves to be problematic, we can address it later. \n. refer to Convention over Configuration debate cited below.\n. done\n. I guess we can inline that back at some point.. > Does this just mean it has routes?\nGonna improve the name.. Done. done. It is. Check:\nhttps://github.com/iron-io/functions/pull/332/files#diff-c68879dad563371d9aa7e11002087e18R99. Where is this being used?. s/Makse/Make/. Go builds?. done\n. Is the intention really to discard Stdout? I understand that stderr is being plugged later down the process, but stdout not.\ngetCfg() is used by startAsyncRunners() in order to connect both stdout and stderr. Could you please check that this behavior hasn't been changed?. > What is the benefit of logging the async result?\nSo you can actually inspect what an async is doing. Or putting differently, this is a subtle change that I wouldn't mind as long as we make clear that this is the intention.. @treeder is this change OK? I know you have a more informed view on what to do with async stdout output.. Shouldn't the owner of the cache the one deciding what to do with it? Not only would ensure concerns were separated, would also untangle this from models.Datastore. Now that you are converting this into an interface, you could also make the identifiers short yet meaningful:\nGet(ctx context.Context, appname, path string) (*models.Route, bool)\nRefresh(ctx context.Context, appname, route *models.Route)\nReset(ctx context.Context, appname string, delta int)\nMore importantly - now this is a public and reusable interface, it also deserves a detailed documentation of intentions and desired behavior. E.g.: what happens with context cancellations (or in this cases, what contexts are for), what happens in case of null pointers and so on.. This is not an interface, why the Cacher in the name? Should it not be DefaultCache?\nAlso Default is not really a descriptive name. What default is this? I know that the idea is that it is used when nothing else is used, still there is no qualifier. \nConsider some alternatives: LRUCache or MemoryCache.. Why is this here? Is this cache only for Datastores? Or in different terms, isn't DefaultCache overloaded with responsibilities?. this sync.Mutex was a hat. Could you please reorganize to make its intention clear again?\nhttps://dmitri.shuralyov.com/idiomatic-go#mutex-hat. IMHO, this is wrong in many levels. Going from shallow to deep.\nProbably, this made in into routescache because of cacheParetoThreshold. Otherwise, how would the cache know how to prime itself? If that's the line of reasoning here, then it is an inversion of responsibility. Cache is meant to be used - and not to use (except, of course, for its underlying driver). Caches are not a subset/superset of databases on which you could have some sort of  \"cache-level\" stored procedure.\nHowever, therein lies a deeper problem: What is this cache for? This cache was created as a way to prevent unnecessary DB conns during HTTP server /r/ calls. This cache does hold routes - but it has nothing to do with the rest of the request service life cycle - it does not know of DB calls, it does not know of singleflights and etc.\nThink about the inversion: if you accept that you can pull some sort of HTTP/Router logic into the Cacher interface - you suddenly have two problems: a) it also means you can pull logic into other parts, such as single flight and DB drivers., how would you decide when one starts and other ends? b) how would you handle the situation on which two parts could have competing views of the same pulled logic? \nFrom what I see, PrimeCache should not exist - and should be reverted to the place it was before, operating the now injected Cacher.. Right - I wrote assuming a context I haven't laid down.\nIMHO, the issue here is PrimeCache... It is the role of the server to prime the cache, and not that the cache should prime itself.. Exactly, so probably it should be the Serve running a primecache function internally, that would call the plugged caches.. These listeners are now dealt individually. Is this being used anywhere else? If not, what do you say about removing it?. it should actually be 30, because that what it was before. I am reducing the default in the other package.. done. You're right. fixing it.. Build is used in of fn build. If we put fn build then it would become a recursive explanation. . done. I guess this is name right?. Why not use regular maps in YAML? . What you say of making it clear that is per function per node?. What is private?. Oh... could you please then use a more example-like name? Because it felt it was some sort of IronFunctions attribute for me.. If nothing to write here, perhaps remove this section?. What do you think of adding a diagram or perhaps longe explanation for these interfaces? So people understand better exactly which part of the request cycle is being affected.. if tasks are internal to package runner, why are you making it visible? Also consider that, once you make this channel something internal to package runner, you are also removing from test procedures to actually intercept the communication between server and runner. Is this what you want? If so, could you please elaborate what are the advantages in terms of testing of not having the possibility to intercept the communication? \nIn the current test suite, we actually intercept the communication - it makes the tests faster, and prevents unnecessary interfacing with the testing docker, thus helping with separation of concerns during test execution.. Another consequence of this change. We are now relying even more on something that we are trying to avoid: the Api global variable. https://github.com/iron-io/functions/blob/master/api/server/server.go#L23-L25\n// Would be nice to not have this is a global, but hard to pass things around to the\n// handlers in Gin without it.\nIs this the path we want to be going to? . I am very skeptical of this change. We are just instituting that Server has too many responsibilities: operate datastore, message queueing, container running and etc. \nAnd worse, this is not really handling the case in which Components is passed on incomplete. \nThis seems to me a rather gratuitous change - that in attempting to solve an aesthetic issue, it is actually adding more issues, and more importantly, it is not solving the underlying problem of concentration of responsibilities.\nI think we might be barking to the wrong tree here.\nWhat do you think of actually making package server smaller? We could use concurrent programming to compose this package better, IMO. \nFor the sake of exercise, I would try to refactor server with just a thin machinery comprising: a channel for job enqueuing and datastore.\nOut of this job enqueuing job, either direct the load to a *Runner (also connected through a channel), or to the MessageQueue (perhaps also connected through a channel).\nWith this approach, Server will become significantly smaller - will have fewer dependencies, and this function signature problem will be solved as a side effect.. > Like you you've noticed the channel is still visible and can be easily replaced externally.\nShouldn't code be closed for modification and open for extension? Or putting differently, if you are exposing an internal part like this, you are also saying for future customizers of IronFunction that a) Tasks can be replaced at any time (which his not true); b) Tasks do not need any protection when being changed (channel itself is safe, but if you can just replace the channel with something else, then you could have a race condition here).\n\nIf you take a look on tasks no change has been done to the test it self, we are currently testing the same way as before, but the channel creation is no longer exposed.\n\nThat's not true - or I might have read your changes incorrectly. With the external channel, there was mocks that pretended that tasks had been consumed. In this PR, you are just running these tasks in the Docker again, no?\n\nSo why not embedding that to it?\n\nI clearly failed to convey my concern, and I apologize. You are just stating that your change is better (embedding), but I did not see anywhere why before was worse. You essentially took a channel that was meant to link together two different components, and put in one of them - in practice defeating the meaning of it being external: show the connection of two independent executing processes.\n\nalso reduce the complexity for the user when he wants to creates his own custom IronFunctions server.\n\nCould you please elaborate on this? It seems something important. Perhaps some example?. > we are actually refactoring that right now?\nOnce you add another use for it, then yes. If the whole refactoring did not have this line changer, I wouldn't bother. But you are adding another use for something we should be actually be trying either to get rid off or prevent.. > if we have an API that embeds many other components (current situation, can probably get worse), the user creating its own server will have provide each other component to the API Server in its instantiation.\nAren't what abstractions for? \n\nBut still the server will be the main component on this server and it must have access to other replaceable components.\n\nIt seems that again I failed to make my point. If you have the design I proposed, the only components it will need is a channel of enqueueing events (bi-directional, for the sake of async) and datastore. No need to peg the runner, the mq or anything. Namely because all of these will be running separately somewhere else - serving server through this channel.\nAnd, if the initialization is the problem, perhaps the solution is to create an abstraction to help anyone customizing IronFunctions.. (Continuing from above).\nOne package/struct that bind all together, and use this package as an extension point for customization. . I know I am being a sort of blocker. In the end, I will support you on whatever you decide. I am just trying to spark reasoning about changes.\n\nSame for other comments that would decentralize things and keep it more simple.\n\nIn my mind, we would benefit a lot of having smaller components that are easier to reason about, than one big component with lots of not-so-obvious internal relationships.\nThe downside, is that you have more dots to connect. (See comment below about that).. What happens with old routes which format is empty? . That's not what I asked. I asked what will happen to routes already in the database, whose format is default because the field format is empty. Do you see the problem?. I am not so sure: check https://github.com/iron-io/functions/blob/master/api/runner/protocol/factory.go#L33. It would probably fix this particular case... I propose, though, a longer check of the source code for other use cases. Perhaps, grep for the constant in the code.. Go tip:\nGo\ncase Default, Empty:\n(https://play.golang.org/p/hi1GhzW4Nv). Why was this test removed?. Isn't this used for async jobs?. Please, remove the comment too.. Why not use https://godoc.org/github.com/gin-gonic/gin#Params.ByName ?. Bump version please.. I should mention above this block. But in this segment, the idea is only to tell about the reading part.. Good catch.. Typo?. Perhaps:\nGo\nif err == models.ErrRoutesNotFound {\n...\n} else if err != nil {\n...\n}\nSo to avoid if-within-if situation?. It is a good idea!. Good catch!. Actually no. The fn push is right above this line. Check again.. Fixed. Tiny typo. . Loop with a switch inside. It seems we'd be better use a map here, instead of testing for all languages against the subset that the switch block represents. . Why the addition of --privileged?. In the end, this will be addressed by https://github.com/iron-io/functions/issues/462. Never mind, this is correct.. Why the duplication here?. function description is missing.. Is this comment really necessary? it seems quite self-evident for me that Refresh will push the new route to the front of the list.. Why add a C prefix first off? This is not a go idiomatic standard.. Still duplicated.... Please organize this import blog.. This is all wrong. srv.AddFunc should be managing individual services. Here it is managing all of them together. \ud83d\udc4e . if I understand correctly, runner.RunAsyncRunner is blocking already. No need for go plus reading the ctx.Done() channel.. ditto.. Why did you remove this?. How is this terminated after context cancelation? http.Serve is blocking and it is never going to be stopped, unless it panics or fails binding the port. And in that case, also you are not catching the error.... perhaps adding t.Skip()?. Is this necessary? Or perhaps could be replace with logrus?. Ditto.. No. I don't think we need it.. ",
    "derekschultz": "Working on packaging IronFunctions into a Murano app for the OpenStack community app catalog.\n. Murano app here: https://github.com/iron-io/ironfunctions-murano/, see PR for details.\nOnce IronFunctions is launched we just submit this Murano package to the OpenStack community app catalog. Note, we're just submitting a .zip and md5sum, so there is no need to make the ironfunctions-murano repo public.\n@treeder - regarding docs on how to run this on OpenStack, what are your thoughts on just linking to the runbook from within the docs dir? See related issue: https://github.com/iron-io/ironfunctions-murano/issues/2\n. Screenshots of Murano package with Kubernetes. Note that these will be included in the runbook document.\n\n\n\n\n\n. Yep, just got the logo this morning. Will get that into the Murano app today and take necessary screenshots to add to runbook. I can have it ready to submit to OpenStack app catalog by tomorrow. Runbook may take another day or so. Blog post is a good idea.\n. IronFunctions Murano app pushed to app-catalog: https://review.openstack.org/#/c/407223/\nRepo here, will make public unless anyone objects: https://github.com/iron-io/ironfunctions-murano\nClosing issue.. I had a naive (incomplete) driver for the Diego runtime in a branch for Worker, when that was a thing. It just needs some love for IronFunctions to utilize the driver.\n. Agreed, I don't have the bandwidth to get this in for the initial Alpha. It could be ready for Beta, but do we have milestone for that yet? Moving to Alpha2 for now.\n. @treeder per request, I moved this to examples/triggers/openstack-ceilometer. Anything else or we good to merge?\n. Note, we also need this for other integrations where the Docker daemon is on a remote host and communicates over TLS. Happy to work on this (when bandwidth permits) if nobody beats me to it.\n. I agree with @Gouthamve in that it seems more appropriate to do this via a RunnerListener rather than through a log monitoring mechanism making a request to DB. But, I guess the question with regard to state tracking is where to store state, whether it be in cache or DB. More generally, this is applicable to the whole async functions event lifecycle, which I think needs some further thought.. @ccirello - we can merge. One thing to note that we can come back to when the Picasso repo is public (this Fri), is would it be helpful to link somewhere in the functions repo to the Picasso example? The reason I bring this up is because I know we had this whole idea of a /triggers directory in functions, and this PR gets rid of that, so a user browsing the functions repo will not be aware that there's an OpenStack integration, therefore let's direct them to Picasso, the OpenStack FaaS. Again, something we can come back to next week. Just raising it now. Otherwise, this is fine to merge, as the example was a little outdated anyway.. incomplete sentence... inside the VM?\n. reword: Login to Vagrant instance and start IronFunctions\n. s/Don'ts/Don't/\n. reword: This is an example of using OpenStack Ceilometer notifications as an event source for IronFunctions.\n. reword: Can you remove the \"execution file\" part? A little confusing. We can simplify this and just say run go build \n. reword: Trigger the alarm we created in the previous step by adding load to the instance.\n. s/IronFunction/IronFunctions/\n. Should we link to the Vagrant-devstack repo here? \n. nit: reword to \"Start a Nova compute instance inside OpenStack\"\n. nit: reword to \"Use the OpenStack Ceilometer CLI to create an alarm threshold\"\n. reword: Login to Nova compute instance we created in previous step.\n. Can we change the alarm threshold period to a shorter interval for this example?\n. nit: s/called/triggered/\n. unnecessary double quote at end of header\n. can these commented lines be removed?\n. re-word: In 5-10 minutes the Ceilometer alarm will trigger an HTTP callback to the IronFunctions route we created earlier, and this can be seen from the IronFunctions API server log.\n. ",
    "carimura": "i'm not following the technical differences of this conversation, but related to Nikhil's comment above we most definitely need (on the short term roadmap) to keep containers running to serve multiple requests. \n. probably applies to all commands..\n. thoughts? Received this request/idea from multiple enterprise users.. ",
    "jmank88": "I came up with a scheme for postgres that at least pushes all the work to the server, so all the routes don't come over the wire each time, though I'm still not sure how to index it efficiently.\nIf the routes are stored with parameter names removed (Example: /blogs/:blog_id/comments/:comment_id -> /blogs/:/comment/:), then fairly simple regex queries can be used by matching on either the whole word or the colon character at each path component. Example: /blogs/123/comments/456 -> ^/(blogs|:)/(123|:)/(comments|:)/(456|:)$\n```sql\nCREATE TABLE routes (\n  route TEXT,\n  raw_route TEXT\n);\n-- Register routes\nINSERT INTO routes (route, raw_route) VALUES \n('/blogs/:blog_id/comments/:comment_id', '/blogs/:/comments/:'),\n('/blogs/:blog_id/comments', '/blogs/:/comments'),\n('/blogs/:blog_id','/blogs/:'),\n('/blogs','/blogs');\n-- Query for '/blogs/123/comments/456'\nSELECT route FROM routes WHERE raw_route ~ '^/(blogs|:)/(123|:)/(comments|:)/(456|:)$'\n```\nIn theory, the same general approach could translate to BoltDB as well - store by nameless route components in nested buckets, and then search for matches one component at a time.. I implemented a prefix-scanning solution for BoltDB: https://godoc.org/github.com/jmank88/nuts#hdr-Path_Prefix_Scans\nIt is much more simple and elegant than the nested buckets approach, and the code (just two functions) can be run against the existing schema.  I was able to test/bench up to 1,000,000 routes.. I put up #490. I haven't tested enough yet, but in theory I didn't do anything new from the redis example that I initially cloned.. Yes, I'll have a fix up soon. . @treeder @pedronasser  I posted some comments that I could use input on before cleaning up the last few open items.. @seiflotfy @treeder This is in a fairly stable state now. Would you prefer issues for these //TODOs be written up now? Or are the comments record enough?. @seiflotfy I believe everything is accounted for between those two and #528 . I had an insight this morning that could greatly simplify and speed up the bolt implementation.  I originally dismissed the idea of using a single flat bucket with some sort of composite keys, but now I think that with the right path encoding we can use prefix scans to crawl the route tree. TBD - but something like url-encoded ASCII, with '/' replaced by a byte that sorts first or last, and other tricks if ':' and '*' are allowed as 'regular' path chars.  If this works out, then the abstract tree.go stuff may no longer be necessary, and both bolt and mock would be much smaller and straightforward.. No actionable update, but for posterity I wanted to note that I resolved the merge conflicts and the diff is much cleaner/smaller now (down from +2600/-1400 to +1800/-600) and there is still more to cherry pick out.  The current test failures are expected, since the new Redis datastore does not support the dynamic routes used in the common tests.. This just came up while working on #523.  I can make the changes there if this is the desired behavior.. I just noticed that this check is performed by calling Datastore.GetRoutesByApp and confirming len==0, which is O(n) in the number of routes.  It can instead be O(1) if done from inside RemoveApp (better for db consistency too), or with a new method like HasRoutes() bool.\nOn the other hand, if this check is completely going away (not becoming optional), then that usage will just be removed.. Is some prefix necessary to prevent clashes with vars like METHOD and ROUTE?. I just noticed that the only usage (besides tests) of Datastore.GetApps is by api/server/apps_list.go, which always passes in an empty filter.  Should this handler be pulling an optional query param into the filter's Name field or something like that?  Or can the filter be removed entirely, and the method simplified?. All current models.RouteFilter usages (actual, and tests-though not all cases covered) assume that fields are static matches, and switching to interpret them all as LIKE queries would break things.  Should this filter be left to static match?  Or are there cases (like routes_list.go) where users need/want to query for some/image:% or /some/path/prefix/%?. ### Things resolved by the validator (but that could still use tests):\nUpdateApp:\n- mock wasn't checking for nil app or empty app.Name\n- postgres was returning the wrong error for nil app and not checking for empty app.Name\nGetRoutesByApp:\n- mock, bolt and postgres were all missing empty app name checks\nInsertRoute/UpdateRoute:\n- postgres wasn't checking for empty route.AppName or route.Path \nThings noticed but unresolved:\nPut:\n- empty val should trigger delete when possible, rather than storing an empty value.\nGetApps:\n- mock: doesn't apply the app filter, indicating the test case is weak (it passes by returning all). > Can you make sure that empty val should trigger delete when possible,\nrather than storing an empty value. Then we are good\nSo the only related usage is:\n\nPut(ctx, []byte(\"test\"), nil)\n\nWhich then confirms that Get returns a nil/empty value. So getting something that doesn't exist isn't an error, it just returns nil/empty anyways. So doing a delete behind the scenes would just be for efficiency, and wouldn't be visible through the API.\n. It looks like you may have cloned off an out dated version of the postgres package.\nI wonder if most of this code could be shared between the two.  Are there any other differences besides the table schema?  It would be nice to have a base sql package with specific behavior overridden or plugged in.. @denismakogon That particular line is actually a bug anyways. A duration is passed (int(time.Minute)), but the method takes seconds, not nanoseconds. It has been fixed in #581.. I'm curious how the benchmarks from #523 would perform against real DB instances, so remote datastores make some sense in that case.  Can the tests can just be rigged to check DB_URL?. Can you try passing the keys you want to clear with null or empty values? \"config\": {\"format\": \"\"}. Headers are multi-value, so they are a bit un-intuitive to patch.  Did you try passing a null or empty array for the header key? That should delete all values for a key. \"headers\": { \"key\": []}. Cannot detect VCS sounds like it cannot find git\nAre you able to run go get golang.org/x/crypto?. Fixed the CI on this one. Was it working previously?\nCREATE TABLE IF NOT EXISTS apps... should be executed each time the Datastore code connects, so a restart might get it going again.. I nearly have this converted to the simpler CLI format, but I'm having trouble converting these into 'fn run' commands.  Does 'fn run' support linking containers?  Or is there another way to expose the postgres container to the function?. I modified my local 'fn run' to support passing through '--link' flags, although this feature is apparently deprecated, so this may not be the right approach.\nI also believe I found a bug here, where kv[1] should be used in place of os.Getenv(). (Or perhaps a check for kv[1], with a fallback to lookup)\nAre either of these changes desired?  If so, should I push the changes here, or open new PRs and keep things organized?. Note that I didn't add test support, though it might be pretty trivial from what I saw. I'm not sure if that alone would be sufficient to allow example/postgres/test.sh to be a 'fn test' configuration instead (since those exist in the func.yaml, which isn't checked in), but there may be other compelling reasons.. I'll update this PR after #495 and #496 are merged.  Unfortunately, relying on 'fn init /hello' gets in the way of using 'fn test' in place of test.sh, but there may still be a way to unravel that... (w/o passing an image override param to every command?).. Is there existing documentation on what exactly is a valid path?. Looking at this again, it seems like Config should be completely replaced. Otherwise, in order to delete fields, some sort of empty/null/nil-value-means-delete would have to be devised.\nWhatever is decided here also likely applies to UpdateRoute as well.. This seems straightforward. Any reason not to include with this PR? #528 . Any preference?. Similar question to UpdateApp.  Additionally, do empty string route fields indicate 'set field empty', or 'do not update this field`.. I'm guessing LIKE query since that's much more useful.. I'm thinking that datastoreutil.validator should have centralized/shared path validation, and maybe it makes sense to include cleaning there as well.  Part of validation would be to reject an un-cleaned path anyways.. Patching should be doable. (The current postgres impl for this and UpdateRoute both currently act as 'setters', but shouldn't become too complicated to fix).\nThe distinction between nil and not found is regarding the app parameter vs. App the type - a nil parameter is an illegal argument, while trying to update an App by name that doesn't exist will result in that particular App not being found.  Maybe it's confusing for the doc to reference the param name as app, would `app` make it more clear?\nWhen you say like it used to, which implementation are you referring too?  Most of these error docs are just documenting existing behavior, or trying to guess at which is correct between inconsistent implementations or method behavior (for example, the postgres impl already returned ErrAppsNotFound when no rows were updated).  Without a broader perspective on how this API fits into the project (or even if it's public?) I don't have strong opinions either way, and these TODOs are sort of the points where I couldn't align the impls without deciding one way or the other, so whatever you think is best.. The CI build brought some more tests to my attention that might resolve some of these.. Patching map[string]string types is straightforward, since empty string values can signal deletes.  However, Route.Header is map[string][]string, so assuming we patch the values by calling Headers.Add for each element, what would be the protocol for deleting keys or individual value array elements?\nI suppose an empty array value could signal Headers.Del, but it would be unfortunate to have to nuke a key and reinsert all but one array element in order to remove a single element.\nAm I overlooking something simple?\nEdit: Updated after playing with Headers API. Maybe this is just the way it is?. This can be a separate PR. The service layer prohibits it anyways. . Separate PR?. No problem waiting for another issue, though both inserting and querying these sorts of routes could have very strange behavior in the mean time.  Especially characters significant to regexp. (those regexps may need some additional escaping depending on what is allowed). Should this be patching reply with route's fields?. Does this call remove the whole set of routes for the app?. Maybe I'm misunderstanding. Isn't routes a set of names of per app route sets, in the form of routes:<appName>? If so, doesn't this operation make the route set for this app inaccessible when iterating over routes?  In other words, doesn't it leave an inconsistent state unless we happen to be removing the last route from this app?. Right, that's what I meant. The app is dropped from the index, even if this isn't the last route for that app.. This may not be necessary.. Does anyone have experience with the proper way to handle these transactions?\n@seiflotfy and I are wondering if we need to account for the situation where f(tx) panics (L616).  If the process will terminate anyways, then we may not need to worry about an explicit Rollback() here.  On the other hand, if we expect something to recover higher up in the stack, then we should probably defer recover and take care of it.. Here is an alternative:\ngo\nfunc (ds *PostgresDatastore) Tx(f func(*sql.Tx) error) (err error) {\n    var tx *sql.Tx\n    if tx, err = ds.db.Begin(); err != nil {\n        return\n    }\n    defer func() {\n        if r := recover(); r != nil {\n            _ = tx.Rollback()\n                        // panic(r) ?\n        } else if err != nil {\n            _ = tx.Rollback()\n        } else {\n            err = tx.Commit()\n        }\n    }()\n    err = f(tx)\n    return\n}. Yeah.  I'll pick out all the server stuff today.. Any reason not to add this now?. #566 . Unused. Redundant. Can anyone explain this one?  Why must the headerStr field be populated?  Why is this seemingly bad-data reported the same as a route not being found?  Note that it is not only called from GetRoute but GetRoutes as well, which does some questionable error discarding.. Additionally, this headerStr check was happening before checking the Scan err.. I haven't looked everywhere, but generally the caller of Datastore methods handles the logging (with api/server/error_response.go or something similar).. I would like to wrap most of the errors (the random, non-static ones) across the Datsatore with more context, but I didn't want to break local style too much.. Extra import. Redundant nil/empty checks. #579 removed these from the postgres package, and most of it's other changes still apply here too.. Unchecked error. Not necessarily?\nIs there a mysql specific error that can be checked for like with postgres?. Unchecked error. Coding a SELECT * seems like risky business. This looks strange to me.  Does it make sense for rows.Next() to return true and continue the loop if scan is going to return sql.ErrNoRows?  I would expect the loop to break, and this error to be returned from rows.Err().\nThe docs actually say ErrNoRows is returned by Scan when QueryRow doesn't return a row, suggesting this error will never be returned from Query() anyways.. Not necessarily?. ErrRoutesNotFound should be caught above, so affecting 0 rows might be worth logging here since it would indicate something pretty severely wrong like a bug or DB integrity problems. . I mentioned this elsewhere, but it's worth pointing out in context: scanRoute() errors are tossed here.  Although it might make sense to return a best effort to the users, the error is probably worth logging since it's likely bad data or buggy scanning.. Same as above. Redundant import?. Oh I just meant to include the literal column names in the query, so that scanApp doesn't depend on the set or order of the columns returned by *. . That sounds like sql.ErrNoRows. Can that be checked for explicitly, and the actual err returned otherwise?. I think these still need to continue also, so the errored route is not appended.. Won't this miss the case where res.RowsAffected() returns 0, nil now?. Can this log and continue, just like with routes?. Some more of the changes from #579 still apply to the above and below methods.. Was this reply meant for another comment?\nOriginal comment still applies.. This no longer handles the 0, nil case.. More changes from #579 apply here. . This should still continue after logging, to skip the append (and probably use logrus?). Same as above. Should this Close() call be deferred up around ~165?  Though it may not matter in the big picture, since something like a Must() panic would terminate the process anyways.. Remove?. ",
    "jan-g": "If you're happy with an algorithm linear in length of path (however, this has as many DB round-trips) then for /blogs/123/comments/456 you can look up blogs/ (and failing that, :/). Then look for blogs/123 (or blogs/:). Then blogs/:/comments. Then blogs/:/comments/456 (and blogs/:/comments/:` - which returns the final route).\nWith careful caching of a next-key-set in the trie path you can probably halve the number of round trips that this requires. The cost is updating the trie on route creation and deletion. Other \"optimisations\" might include caching complete patterns over a particular part of a sub-trie and returning those when there are fewer than some threshold number - ie, short-circuiting the complete trie traversal.\nNote, this approach favours early parts of the path being matched over later ones - however, I don't think that that's too high a price to pay in practice.. ",
    "rdallman": "yea, the client library also has some logs unfortunately. it seems like something we should be able to scrub out if we want to and commit to fsouza. one of those log lines is ours. we could suppress the stats logs altogether but it would be nice not to so that if a task shows up w/o stats we can at least see what's going on so that we might fix it. hopefully don't have to add too much machinery just to suppress a log line, our context tree is already pretty crazy, but I could see how these are a bit jarring to see.\n. Starves async... Would be better to pick a probability like 60/40 to\nservice one or the other to prevent even the chance of starving a whole\nclass of tasks.\nOn Sep 22, 2016 9:00 AM, \"Travis Reeder\" notifications@github.com wrote:\n\nSo I was thinking about how this could work on a single binary/machine\n(instead of separate runners), and had this idea:\n- a request comes in\n- if sync, put in sync channel - implemented (partially?) here #92\n  https://github.com/iron-io/functions/pull/92\n- if async, put in message queue\nThen we just have a single go routine that does the following:\n- read off channel, if task exists, fire up go routine to execute it,\n  write the results to the HTTP response. If no sync tasks:\n- read off message queue, if task exists, fire up go routine to\n  execute it (probably nearly the exact same way as above, except we don't\n  write any results\nOr maybe those are two go routines, but the second one pauses until\nresources are available.\n@seiflotfy https://github.com/seiflotfy\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/issues/104#issuecomment-248947222,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ACzJR72tmLyNs_tSKr3kiMu_tydQ6NuSks5qsqYTgaJpZM4KEDmR\n.\n. @nikhilm \n. @treeder makes sense. we've since moved the functionality of checking against any registry out of the driver, I'll change this patch to keep the same functionality accordingly (outside of the driver). \n. after https://github.com/iron-io/worker/pull/360 is merged we can re-vendor the worker package and then merge this. this will get rid of the tasker import too. cc @seiflotfy @treeder \n. updated but now blocked on the move to the runner repo... will try to keep this up to date even though the patch is rather small \n. much cleaner than payload file thing, i like it (thought we were always doing it in functions, actually), and won't break compat with legacy stuff, we can still write out the file and have this\n. check it out, btrfs (left) vs overlay2 on our default cluster, each data point is the mean of 1 hour (ran for few hours):\n\n\n\n\n\n. damn those images suck... redoing:\n\n\n\n\n. stop container isn't a good data point really, the process inside can take a while, but there's still a large disparity due to docker being slow w/ btrfs\n. Well it ain't Photoshop\nOn Mon, Oct 17, 2016, 7:55 AM Travis Reeder notifications@github.com\nwrote:\n\nIs that really 1.83 minutes?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/issues/156#issuecomment-254231342,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ACzJR_TgAvSsqIr1ZImdzmrBPl2a3-zBks5q04xSgaJpZM4KVYWN\n.\n. thanks @ccirello \n. can't mergy. rebase?\n. i'd recommend waiting a few minutes :). Hi @Gouthamve thanks for filing, I'm having trouble reproducing this issue (specifically as it pertains to being a bug in running in a linux environment) as outlined. It seems to be a simple permissions issue but it could be something sneaky with docker filesystem drivers or such. It seems like at a minimum whichever user you are running the command as (and maybe the docker user / group) needs to own the directory /home/goutham/gocode/src/github.com/iron-io/functions and its children, ala $ chown -R $user:$group ..  I think we need more info, perhaps if I post my info something will stick out as different from yours and will help you debug your system. If you could post some additional information about your directory you linked /home/goutham/gocode/src/github.com/iron-io/functions and your docker version we may be able to help further debug here. Here is my system info:\n\nfunctions(master) \u2717: uname -a\nLinux debian 4.8.0-2-amd64 #1 SMP Debian 4.8.11-1 (2016-12-02) x86_64 GNU/Linux\nfunctions(master) \u2717: groups reed\nreed : reed cdrom floppy sudo audio dip video plugdev netdev bluetooth docker\nfunctions(master) \u2717: ls -alh\ntotal 37M\ndrwxr-xr-x 12 reed reed 4.0K Dec 28 18:36 .\ndrwxr-xr-x 20 reed reed 4.0K Dec  4 22:02 ..\ndrwxr-xr-x  7 reed reed 4.0K Dec 28 18:34 api\n-rw-r--r--  1 reed reed  626 Dec 28 18:34 build.ps1\n-rw-r--r--  1 reed reed 1.3K Dec 28 18:34 circle.yml\ndrwxr-xr-x  2 reed reed 4.0K Dec 28 18:34 clients\n-rw-r--r--  1 reed reed 1.3K Dec 28 18:34 CONTRIBUTING.md\ndrwxr-xr-x  2 reed reed 4.0K Oct 20 12:12 data\n-rw-r--r--  1 reed reed  811 Dec 28 18:34 doc.go\n-rw-r--r--  1 reed reed   87 Dec 28 18:34 Dockerfile\ndrwxr-xr-x  9 reed reed 4.0K Dec 28 18:34 docs\ndrwxr-xr-x 16 reed reed 4.0K Dec 28 18:34 examples\ndrwxr-xr-x  3 reed reed 4.0K Dec 28 18:34 fn\ndrwxr-xr-x  5 reed reed 4.0K Dec 28 18:34 fnctl\n-rwxr-xr-x  1 reed reed  17M Sep 30 12:01 functions\n-rwxr-xr-x  1 root root  20M Dec 28 18:36 functions-alpine\ndrwxr-xr-x  8 reed reed 4.0K Dec 28 18:47 .git\n-rw-r--r--  1 reed reed  209 Oct 18 09:50 .gitignore\n-rw-r--r--  1 reed reed 8.9K Dec 28 18:34 glide.lock\n-rw-r--r--  1 reed reed  972 Dec 28 18:34 glide.yaml\n-rw-r--r--  1 reed reed  12K Dec 28 18:34 LICENSE\n-rw-r--r--  1 reed reed 2.6K Dec 28 18:34 main.go\n-rw-r--r--  1 reed reed 1.1K Dec 28 18:34 Makefile\n-rw-r--r--  1 reed reed 9.7K Dec 28 18:34 README.md\n-rwxr-xr-x  1 reed reed  846 Dec 28 18:34 release.sh\n-rw-r--r--  1 reed reed  270 Dec 28 18:34 THIRD_PARTY\ndrwxr-xr-x  3 reed reed 4.0K Dec 28 18:34 triggers\ndrwxr-xr-x  5 reed reed 4.0K Dec 28 18:35 vendor\nfunctions(master) \u2717: docker info\nContainers: 1\n Running: 0\n Paused: 0\n Stopped: 1\nImages: 280\nServer Version: 1.12.5\nStorage Driver: devicemapper\n Pool Name: docker-8:1-662746-pool\n Pool Blocksize: 65.54 kB\n Base Device Size: 10.74 GB\n Backing Filesystem: ext4\n Data file: /dev/loop0\n Metadata file: /dev/loop1\n Data Space Used: 8.153 GB\n Data Space Total: 107.4 GB\n Data Space Available: 2.631 GB\n Metadata Space Used: 13.48 MB\n Metadata Space Total: 2.147 GB\n Metadata Space Available: 2.134 GB\n Thin Pool Minimum Free Space: 10.74 GB\n Udev Sync Supported: true\n Deferred Removal Enabled: false\n Deferred Deletion Enabled: false\n Deferred Deleted Device Count: 0\n Data loop file: /var/lib/docker/devicemapper/devicemapper/data\n WARNING: Usage of loopback devices is strongly discouraged for production use. Use `--storage-opt dm.thinpooldev` to specify a custom block storage device.\n Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata\n Library Version: 1.02.137 (2016-11-30)\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins:\n Volume: local\n Network: host bridge overlay null\nSwarm: inactive\nRuntimes: runc\nDefault Runtime: runc\nSecurity Options: seccomp\nKernel Version: 4.8.0-2-amd64\nOperating System: Debian GNU/Linux stretch/sid\nOSType: linux\nArchitecture: x86_64\nCPUs: 1\nTotal Memory: 1.957 GiB\nName: debian\nID: 3XYF:K5X3:NOD2:25IM:3WYV:QKFS:DLQ4:5LLC:36E5:ZNPJ:3J4P:EWPB\nDocker Root Dir: /var/lib/docker\nDebug Mode (client): false\nDebug Mode (server): false\nUsername: rdallman\nRegistry: https://index.docker.io/v1/\nWARNING: No swap limit support\nInsecure Registries:\n 127.0.0.0/8. Hi @Gouthamve I have good news, I'm able to reproduce this with a fresh copy (and \u2615\ufe0f ). Since I was unable to reproduce it with a prior version of the functions docker image (d'oh) it seems like this is just a simple regression then. Going to look over the code, I expect it's something in initialization that has since changed. . hmm, thanks for the link. it's a little strange that it worked with an older version of the docker image. think it's fixed now, some details in #471 . @treeder we log and return the same error, wrt text we slightly improve the error before returning it so they're not the same value, but it's the same contextually. I don't really find twitter posts from some random guy as principles (yes i know who he is, we're all random guys). there are multiple cases in the runner where we want to log the error and it may also end up getting returned, due to the nature of retrying a lot of the docker calls, where we really do want to log it at the source. that being said, libraries that don't log stuff are ideal, but sometimes it's impractical. it would probably be nice to let callers specify some kind of logger output object in case they don't want logs, but at the same time this driver imo will never be used outside of our own devices. tl;dr doesn't really seem like a big deal ?. nit: in keeping with the theme Stdin io.Reader would be slightly more fitting imo\n. ubuntu w/ aufs actually is okay too (default config, convenient too)\n. basically only ubuntu has aufs, can leave this as is :)\n. intentionally leaving this in the patch ;). ",
    "denismakogon": "@seiflotfy Do we really think that Kafka looks like desired MQ option? There are couple reasons:\n- you can't delete messages from topic (there's message retention timeout, around 7 days)\n- you can't rewrite message because broker will increase message offset\nSo, how would we implement reservation and deletion?\n. As discussed with @seiflotfy Kafka doesn't look like good MQ candidate due to its specialities. \nReopen this if necessary.. @ccirello I believe that IronFunctions can integrate with Logstash for storing logs because S3 is cloud-locking, so no way to support, let's say, OpenStack Swift, Mimio is not designed to work with logs specifically rather than with files/objects.. @ccirello In any case, i'm not setting up name from go code, but from Python, and the only thing is available is  https://docs.python.org/3/library/uuid.html#module-uuid and as far as i know you can't limit size to 16 bytes except cutting up string to meet current server constants.\n. @ccirello as i can see entropy of the result is lover, so collision probability is higher. So, it is not the case.\n. No longer valid.\n. @ccirello here's the thing. Main reason why AWS lambda gained popularity in enterprise is that AWS lambdas are capable to run microservices without need to manage them through their lifecycle (deploying, scaling, re-configuring). There are tons of articles about turning regular self-hosted API services (daemons, basically) to lambdas, here's one of them.\nSo, the reason behind running functions as daemons is to enable microservices architecture without need to self-host them on baremetal or VMs. Also consider use ase of horizontal scaling, when your set up API services are facing high load, so you need to scale them in fast to eliminate down time and scale down in matter of seconds (i.e. scale on-demand).\nExisting serverless technologies that are running web servers as functions/lambdas:\n\nhttp://cloudacademy.com/blog/serverless-framework-aws-lambda-api-gateway-python/\nhttp://mark.stosberg.com/blog/tech/review-of-nodejs-lambda-serverless/\n\nI do understand that IronFunctions were not designed to run daemons, that it is a good thing to have for platform that names itself as serverless.\n. There are a lot examples of AWS Lambdas and API gateway to run web services, here's an example: https://github.com/Miserlou/Zappa. @ccirello would be the right fix to set execution timeout through API? There are three cases possible:\n1. No timeout specified - use default 60 seconds (or whatever it be)\n2. Timeout specified - run within timeout\n3. Run until not finished\ncc @treeder @pedronasser @seiflotfy . @ccirello as i can see, it should be a part of routers API (POST /v1/apps/{app}/routes/{route}). Because in route payload we explicitly saying which functions we want to run along with route config instance, so it is a right place.. @pedronasser to what kind of headers you're referring to?. We already have config object in payload, can't we just check on the API side if timeout was specified or not. In such case we have very small API impact (AFICS, only doc/swagger impact).. @pedronasser Yeah, i also mentioned that if image is available locally, functions complaining that image was not found.. So, here the thing, we need to have persisted models definitions out of code in order to have good enough user experience during upgrades from version X to version Y.\nAnother question, if i would create a route before this patch and then will upgrade functions API up to this patch how this code will handle cases where model wouldn't have Timeout attribute.\nAlong with that, this code doesn't actually validate if Timeout fits integer range.\nMentions: https://open-iron.slack.com/archives/functions/p1480362602001126. +1 LGTM. Would you mind to update swagger doc?. sorry, swagger doc already includes delete request to /apps/{app}. LGTM. @pedronasser indeed, but problem still there.. @pedronasser from user perspective misleading redundancy will be confusing, don't you think so?\n. LGTM. LGTM +1. LGTM +1. Agreed with @ccirello seems like a part of runner lib. And there's obvious reason for this, all container-type specific API is encapsulated in runner to provide high-level abstraction. So, having explicit requests to Docker API would bring certain inconsistency.. @ccirello current there's no way to get info on specific task, in order to accomplish task retrieving it is required to iterate over all existing tasks, for some cases it would take some time to get proper one. Isn't it a valid reason to have new route?. @ccirello The idea was to provide capability to get exit status of a function to users, since task payload includes exit status, we can get it and send back to users as part of response to status check for async function execution by its call_id and then i've faced with problem - i can get all tasks (assume that IronFuntions is shared between multiple users in OpenStack, in my particular case - 6 users trying to run their functions). So, that's why i created this issue - for simplifying process of getting task status. Am i missing something or using /tasks in wrong way?. @treeder @seiflotfy @pedronasser @derekschultz guys, may i ask you for an input on this topic? We still don't have a mechanism for IronFn users to track their async executions and may be increase time to keep task data for a specific execution a bit longer?. Related to https://github.com/iron-io/functions/issues/528. @treeder assume that you want to delete an app with routes and async functions that is in progress right now. So in order to delete that route we need to clarify that executions already finished. So we can solve this in two ways - give to users an ability to track their async executions using /tasks/{call_id} or enable app deletion (with routes, for now API return HTTP 403 when attempting to delete an app with routes) if there's no active executions on each route.. @cruxnet you can always put API service behind Nginx as reverse proxy, would that work for your case?. @tianluoqi here are some related issues to your topic:\nhttps://github.com/iron-io/functions/issues/506\nhttps://github.com/iron-io/functions/issues/348. @sheerun i'm kinda curious which PL you're referring to?\nMain intention of IronFunctions is not re-implementing a CGI web server, i.e. by design each functions is a short-term container, but not daemon container. So, function is not a daemon, hot function allows function container live a bit longer that regular \"cold\" container until there are no more concurrent connections.\nWith help of hot functions feature you can make function act as a daemon until there's no concurrent requests approaching hot function.\nCan function be a daemon (web server, RPC service)? - No. Here some thoughts about what serverless should be:\n\ntends involve invoking short-lived functions (Lambda has a default 1-sec timeout)\ndoes not publish TCP services - often accesses third-party services or resources\ntends to be ad-hoc/event-driven such as responding to webhooks\nshould deal gracefully with spikes in traffic\ndespite name, runs on servers backed by a fluid, non-deterministic infrastructure\n\nSee more at http://blog.alexellis.io/functions-as-a-service/. So if you need something that you can talk over TCP and have a web server at the backend, you might take a look at Kubernetes or Swarm.. @sheerun as far as I know without exposing ports on container you are to able to talk to it over any L3 protocols, so runner does not exposes ports on containers and it wouldn't be enough to write a new interface implementing as @pedronasser suggested (correct me if I'm wrong).. @treeder i assume you're referring to a features like Go has for reading HTTP request from STDIN? If so, it would be nice to have a spec that'll be used for development of libs no matter which language developer would pick.. @jmank88 route validation might be covered by URL parsing from net/url package as most valid way to confirm that route is being considered by valid URL part.. Hello @WTFKr0. So, here's the thing, IMHO using Docker images as function source makes functions execution more stable and predictive (see AWS Lambda problems with invalid ELF header).\nMeanwhile you can create a function that will accept URL to a source file and execute it. But what about dependencies, what is an entry point, etc.\nI tend to agree that having a capability to create functions from source packages (assume package is a *.tar file with all dependencies, etc.) would be a useful feature, what do you think @seiflotfy @pedronasser @treeder? Having Docker as the only way to create functions brings a lot limitations like:\n\nDocker image should be available on DockerHub or on local registry\n\nAs developer developer without Docker i can build/deploy a function\netc.\n. @treeder the thing is that Async execution returns call_id, but I need to query /tasks to get info on it. So, for implementing /tasks/{task_id} we need to clarify what we return to a users, would it be call_id or taks_id that can be tracked via /tasks. @seiflotfy @pedronasser @treeder Guys, can we make certain decision on this one?. @treeder isn't task_id fits better here rather than call_id?. @WTFKr0 I assume there's only one way to define timeout:\n\n\nextend HTTP Post to /{app}/routes to include new parameter (let's say, inactivity_timeout), but make it optional (similar to other optional parameter we maintain right now)\n\n\nWould that make sense @pedronasser @seiflotfy @treeder ?. @jconning it appears that https://github.com/iron-io/functions/blob/fae66764b4d34d3b15bb4688dc691637375df7ce/api/server/runner.go#L184 Request.Header from Gin context does not include Host header, that's why it's not available on function side as HEADER_HOST.. Submitting patch. Tested manually with denismakogon/os.environ image. See execution logs:\n```\ncurl -v -X POST localhost:8080/r/testapp/env\n   Trying ::1...\n TCP_NODELAY set\n* Connected to localhost (::1) port 8080 (#0)\n\nPOST /r/testapp/env HTTP/1.1\nHost: localhost:8080\nUser-Agent: curl/7.51.0\nAccept: /\n< HTTP/1.1 200 OK\n< Date: Thu, 09 Mar 2017 22:03:18 GMT\n< Content-Length: 474\n< Content-Type: text/plain; charset=utf-8\n< \nenviron({'GPG_KEY': '97FC712E4C024BBEA48A61ED3A5CA953F73C700D', 'HOME': '/root', 'PYTHONUNBUFFERED': '1', 'HEADER_ACCEPT': '/', 'HEADER_USER_AGENT': 'curl/7.51.0', 'METHOD': 'POST', 'ROUTE': '/env', 'PYTHON_VERSION': '3.5.3', 'HOSTNAME': 'Deniss-MacBook-Pro-2.local', 'PATH': '/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'PYTHON_PIP_VERSION': '9.0.1', 'LANG': 'C.UTF-8', 'REQUEST_URL': '/r/testapp/env', 'HEADER_HOST': 'localhost:8080'})\n Curl_http_done: called premature == 0\n Connection #0 to host localhost left intact\n```. Closed via #578 . I guess, this issue will no longer be critical once we'd have fix for #567 merged, right @jconning ?. @jconning ok, will submit PR soon.. @jconning see #580 . Closed via #580. @mazamats have you tried hot functions? This feature will prevent from running N similar containers per each request for one function. Hot function keeps container up until there's no more requests to process.. See https://github.com/iron-io/functions/blob/master/docs/hot-functions.md. @mazamats @matthewmueller Hey, folks, were you able to try hot functions?. So, @matthewmueller. In order to turn function into hot you need to create function with two additional parameters:\n\n\nformat (there are two options: http and json), this option allows to pass raw HTTP request via STDIN into a function (if you'd pick http), if you'd pick json you'll get only data from HTTP request (basically, JSON that you'd send during function execution.\nmax_concurrency, this option stands the number of simultaneous hot functions for this functions.\n\nSo, term hot means that container will remain launched for some period of time unless no connection and will be suspended by idle timeout.. @martinpinto according to test logs, there's problem accessing mysql inside test environment in CircleCI. So, in order to fix that, it is recommended:\nAt this point, you\u2019ll want to create your database, load it with your schema, and (possibly) preload it with data. If you use MySQL or Postgres, you can use the circle_test database and the ubuntu user rather than creating the database yourself. No password is required for any database.\nSee https://circleci.com/docs/1.0/manually/#databases. Hello @rcarmo. Can you please elaborate which part IronFunctions you'd like to see supported on ARM?. @rcarmo ok, i see. But my question makes sense, because in repo we have couple projects like fn tool, API server, fnlb. But i do understand what you're saying. So, let's try to define list of smaller tasks we'd like to do in a pursuit of supporting ARM v5 (or greater). Would that make sense?. Recently i tried to build project for ARMv5 and got this issue:\n```\nDeniss-MacBook-Pro-2:functions denismakogon$ GOARCH=arm GOARM=5 go build -o functions\ngithub.com/iron-io/functions/api/mqs\napi/mqs/ironmq.go:117: constant 60000000000 overflows int\n``. @jmank88 can we extract fix for smaller patch to get build/release job for ARMv5 (or greater)?. So, @rcarmo @vielmetti we've fixed small issue and we were able to build binaries (API service) for ARM successfully.\nThere's PR i made to ensure that we are not breaking compatibility with ARM for server. The last thing we need to clarify that we can buildfn` tool too if it works fine i'll close this issue.\nThoughts?\ncc @treeder . @vielmetti actually I was able to build  IronFunctions for all platforms that go cross-compiling supports including ARMv8 (arm64).. @rcarmo you can pull latest master branch and build it with go flags like GOARCH, GOARM for specific ARM version including v8(arm64). I assume you're aware of how to build go code. Once you have binary I'd recommend to follow Getting started guide to try it out. If you're facing problems let me know.. Please note that you need latest Go 1.8 binaries.. @WTFKr0 I assume you're talking about all-in-one installation of IronFunction + Docker (Docker-in-Docker use case), right? I'd think about mounting volume to an image will config files with desired options configured as you like. Would that be the case for you?. @treeder maybe i wasn't clear with explanation. Current datastore tests are failing for me because i don't have Docker running locally and all containers that tests are creating are bound to remote Docker host.\nSo, tests are expecting that Docker and its containers are accessible via localhost, see 1, 2, 3.\nIn order to make tests pass it is necessary to pull out container IP address once container is up and running to form connection string instead of expecting to have containers running on localhost/127.0.0.1 (expect that datastores are available via localhost).. closed via #589 . Confirming, can build executable on:\nLinux ubuntu 4.4.0-53-generic #74-Ubuntu SMP Fri Dec 2 15:59:10 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\nusing:\nGOARCH=arm GOARM=6 go build -o functions-api-${GOARCH}v${GOARM}\nGOARCH=arm GOARM=7 go build -o functions-api-${GOARCH}v${GOARM}\nGOARCH=arm64 go build -o functions-api-${GOARCH}\n. \n@cmdhema recent master branch requires Go 1.8, so install it first and then use following commands:\nmkdir -p ~/go/src/github.com/iron-io\ngit clone https://github.com/iron-io/functions.git ~/go/src/github.com/iron-io/functions\nexport GOPATH=~/go\ncd ~/go/src/github.com/iron-io/functions\nmake dep build\nThen you'll be able to find executable functions. See docs for further configuration.\nThen you can start API service using following command:\nmake run. @treeder Sure, why not.. @ccirello So, yes, there are two timeouts, and it doesn't look like something bad or confusing. One timeout is for function call, and the idle timeout defines for how long to keep hot function around without serving requests for it. You're saying that it was not thought through, i tend to disagree on this, because it's not clear why hardcoded 30s timeout is exact timeout that every hot function should wait without processing requests before becoming \"cold\".\nFrom user perspective, if i have a workload that comes each 1m, and i don't want to spend time to wait until function will be started (+ overhead of function itself, like pulling out data from 3rd party services, etc.) rather than setting idle timeout for 2m, so with such workload my hot function will be more effective in terms of faster requests serving.\nDoes it make sense?\ncc @treeder @seiflotfy @pedronasser . @ccirello I agree on documentation as well as with edge cases. I'll make next PR with docs that explicitly describes all possible cases for idle time and its combinations with regular timeout.. @treeder doc is already here. Check last 2 commits.. @treeder sure, will do soon.. @mytototo as far as i know, you can integrate one as DB layer.. this also needs to go away.\n. @ccirello UUID4 without dashes is 32 symbols, so still doesn't fit to 30 eventually.\n. Here's small Py script:\n```\nimport uuid\nprint(len(uuid.uuid4().hex))\nprint(len(str(uuid.uuid4()))\n``\n. Should middleware be able to override logger?. @treeder @Gouthamve \nAnother use cases - if have a header that represents a user ID (X-Project-ID), and i want to restrict user from accessing other apps by passing list of apps (that are stored in DB, in mapping user_id ---> app) to include/exclude. So that'll be very useful with App(s) objects (at least i suppose so).\n. Shouldn't we include some logging here?. same here, it would be useful at least at DEBUG level.. MySQL container exposes port 3306, please fix it to3307:3306`. Should be fatal error.. Should be fatal error.. If you're defining this constant you need to use it as connection URI everywhere you're trying to create a connection.\nAlso, on the host you will have port 3307, but not 3306.. This exec should be extended to make container actually running\n```\n    mustRun(fatalf, \"start mysql container\", exec.Command(\n        \"docker\", \"run\", \"--name\", \"iron-mysql-test\", \"-p\", \"3307:3306\", \"-e\",\n        \"MYSQL_DATABASE=funcs\", \"-e\", \"MYSQL_USER=mysql\", \"-e\", \"MYSQL_PASSWORD=secret\",\n        \"-e\", \"MYSQL_ROOT_PASSWORD=root\", \"-d\", \"mysql\"))\n. use `tmpMysql` instead of `\"mysql:secret@/\"`. would be no longer needed if you'd use `-e MYSQL_DATABASE=funcs`. would be no longer needed if you'd use combination of `\"MYSQL_DATABASE=funcs\", \"-e\", \"MYSQL_USER=mysql\", \"MYSQL_PASSWORD=secret\"`. tmpMysql instead of `\"mysql:secret@/funcs\"`. mysql container takes a lot time to start, i recommend to use next values:\n    maxRetries := 5\n    wait := 4 * time.Second\n. Also, this wouldn't work if you'd run tests against remote Docker (obviously, my case, when you can't access containers via localhost). Consider to use\ndocker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' iron-mysql-test\nto get container IP address.. I was able to get container up and running with MySQL using next call:\n    mustRun(fatalf, \"start mysql container\", exec.Command(\n        \"docker\", \"run\",\n        \"-p\", \"0.0.0.0:3307:3306/tcp\",\n        \"--expose\", \"3306\",\n        \"--name\", \"iron-mysql-test\",\n        \"-e\", \"MYSQL_DATABASE=funcs\",\n        \"-e\", \"MYSQL_USER=mysql\",\n        \"-e\", \"MYSQL_PASSWORD=secret\",\n        \"-e\", \"MYSQL_ROOT_PASSWORD=root\",\n        \"-d\", \"mysql\"))\nFirst i thought there's problem in users/passwords and network access overall, but not. I was able to run\ntelnet 192.168.2.3 3307\nTrying 192.168.2.3...\nConnected to 192.168.2.3.\nEscape character is '^]'.\nJ\n5.7.17([``\nWhere192.168.2.3is Docker host and obviously container bridged IP address (192.168.2.3:3307  ----> 172.17.0.2:3307`).\nBut still not able to get connection established via sql.Open and do ordinary db.Ping().  Unfortunately, there's no way to get more verbose answer from underlying libs, so still no clear to me what's going on.\n@seiflotfy @pedronasser thoughts?. \"root:root@tcp(%v:3307)/funcs\"\n. fmt.Sprintf(\"root:root@tcp(%v:3307)/\", datastoretest.GetContainerHostIP()). fmt.Sprintf(\"root:root@tcp(%v:3307)/\", datastoretest.GetContainerHostIP()). fmt.Sprintf(tmpMysql, datastoretest.GetContainerHostIP()). ",
    "ekalinin": "@derekschultz ^\n. Thanks!\n. I've added links to Vagrant and devstack projects.\nBut i'm not sure about link to the Vagrant-devstack repo.\nBecause i've added all needed files in the example directory (Vagrantfile, devstack.sh)\n. Fixed.\n. Yep. Fixed.\n. Fixed.\n. Fixed.\n. Fixed.\n. Fixed.\n. Fixed.\n. Fixed.\n. Fixed.\n. Fixed.\n. Fixed.\n. I'm not sure. 10 minutes \u2014\u00a0is a default interval in devstack. I'll explore it.\nBut it seems like we'll need to write a much bigger instruction for changing that option.\n. Fixed.\n. Sure.Fixed.\n. Done.\n. ",
    "japsu": "Why not use the FastCGI protocol for this? It's an industry standard protocol with existing client libraries for almost any runtime one could hope for.. I hereby rescind my above comment about FastCGI.\nFastCGI has been superseded by proxying ordinary HTTP requests almost everywhere.\n@sheerun's proposal of using HTTP over a standard port is superior. It requires no special SDK, client library or proprietary protocol support and it provides the easiest possible upgrade path from traditional applications to serverless.\nWhile not as trivial re: library support, ordinary HTTP can also be done over UNIX domain sockets.. ",
    "sheerun": "fyi implementation of this would be no brainer (basically simple forwarding), if implementations talked with http through standard tcp port: #520\nby using http through stdio you burden yourselves with translation between tcp and stdin/stdout. Allright, I didn't see this one: https://github.com/iron-io/functions/blob/master/docs/hot-functions.md. Hey! Let me clarify: I don't mean I want to use long-running server for hot functions.\nI mean to preserve everything you designed in hot functions but change the way of injecting payload into script from reading HTTP request from STDIN, to reading HTTP request from TCP sockets like any web server does. Doing so will make hot functions far easier to implement.\nYou could say that for hot functions \"web server\" would be created for each request, so it isn't in any way a long-living entity. It is exactly the same as current hot functions, but with more convenient transport that is very easy to implement in most languages (rather than hacking HTTP requests and responses on top of stdio). I hope you understand.. I'm afraid it's not possible to implement it with current runner interface as factory has only access to in io.Writer, out io.Reader that afaik are by default bound to stdin and stdout. This means probably the change needs to be implemented somewhere else, so in io.Writer, out io.Reader  are bound to tcp socket instead.\nAlso, unfortunatelly I'm not a go-lang programmer, so I cannot send the PR.. I think by \"expose\" you mean \"publish\", so runner doesn't need to publish any ports from containers. It just needs to bind to hot container on given port, so it can talk through TCP port.\nIMO betting on HTTP through STDIO makes you reinvent the wheel in many cases.. Load balancers, streaming, functions implementation, probably a lot more in the future.. ",
    "jezell": "gRPC seems to be on its way to becoming the defacto standard for server side communication when people care about perf and want something cross platform. Considering that the sole reason for introducing this is perf... why not gRPC?. Seems like a pull policy for the function similar to kubernetes pods would be the best approach to handle this type of thing instead of hard coding behavior. Locally you often never want a registry to be involved since you don't have a registry running and aren't going to be pushing to one. In scenarios where you are pre-pulling or building images locally, you also don't want to run the risk of pulling things from a registry unintentionally when it's not your intention to ever use a registry.. So for local dev it's very useful because generally you are building the images here. The thinking behind NeverPull in Kubernetes was to handle any sort of scenario that pulling images wasn't directly supported by Kubernetes. For example, let's say a new 3rd party registry comes out with a different API, or the authentication used by your docker registry is custom, NeverPull is designed as a fallback for any scenario where kubernetes doesn't know how to pull the image automatically and leaves the problem of getting the image on the machine to the user.. ",
    "noqcks": "@treeder merged master and fixed \n. @treeder fixed\n. yeah\n. without lines: \n\nwith lines: \n\nsee here https://github.com/iron-io/functions/blob/master/docs/docker.md\n. @treeder ^\n. ",
    "thousandsofthem": "well, i think there shouldn't be that much apps/routes to make pagination useful. thoughts?\nneed one for tasks etc though (if planned some API for that)\n. https://monosnap.com/file/zCViyyf7cwGsGrS1edYziqZIiB13Qi.png\n1) appname in real api, app_name in the docs\n2) config in real api, headers in the docs\n3) related to ticket: according to swagger there are cursor param for pagination (page size is not specified though)\n. \ud83d\udc4d . @treeder updated. ",
    "vadan-cs": "Are there plans to add an HTTP endpoint to https://github.com/iron-io/functions/blob/master/api/server/server.go to retrieve function logs? . ",
    "CLAassistant": " All committers have signed the CLA.\n.  All committers have signed the CLA.\n.  All committers have signed the CLA.\n.  All committers have signed the CLA.\n.  All committers have signed the CLA.\n.  All committers have signed the CLA..  All committers have signed the CLA..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.You have signed the CLA already but the status is still pending? Let us recheck it..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you all sign our Contributor License Agreement before we can accept your contribution.1 out of 2 committers have signed the CLA.:white_check_mark: treeder:x: CircleCICircleCI seems not to be a GitHub user. You need a GitHub account to be able to sign the CLA. If you have already a GitHub account, please add the email address used for this commit to your account..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you all sign our Contributor License Agreement before we can accept your contribution.2 out of 3 committers have signed the CLA.:white_check_mark: pedronasser:white_check_mark: treeder:x: CircleCICircleCI seems not to be a GitHub user. You need a GitHub account to be able to sign the CLA. If you have already a GitHub account, please add the email address used for this commit to your account.You have signed the CLA already but the status is still pending? Let us recheck it..  All committers have signed the CLA..  All committers have signed the CLA..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.Travis Reeder seems not to be a GitHub user. You need a GitHub account to be able to sign the CLA. If you have already a GitHub account, please add the email address used for this commit to your account..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you all sign our Contributor License Agreement before we can accept your contribution.2 out of 3 committers have signed the CLA.:white_check_mark: jmank88:white_check_mark: treeder:x: skwashdYou have signed the CLA already but the status is still pending? Let us recheck it..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you all sign our Contributor License Agreement before we can accept your contribution.1 out of 2 committers have signed the CLA.:white_check_mark: c0ze:x: alnutileYou have signed the CLA already but the status is still pending? Let us recheck it..  All committers have signed the CLA..  All committers have signed the CLA..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you all sign our Contributor License Agreement before we can accept your contribution.1 out of 2 committers have signed the CLA.:white_check_mark: c0ze:x: dandersondanderson seems not to be a GitHub user. You need a GitHub account to be able to sign the CLA. If you have already a GitHub account, please add the email address used for this commit to your account.You have signed the CLA already but the status is still pending? Let us recheck it..  All committers have signed the CLA..  All committers have signed the CLA..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.You have signed the CLA already but the status is still pending? Let us recheck it..  All committers have signed the CLA..  All committers have signed the CLA.. ",
    "jotes": "It looks like iron.io supports only python2... would you be interested in support for python3? I could help with that.. ",
    "westlakem": "+1 any updates?. ",
    "ptone": "This is more than just a documentation issue no?\nLooking at the FIXME at the bottom of \nhttps://github.com/iron-io/functions/blob/master/api/runner/task.go\nIt seems like there has been an admirable effort to avoid a giant bag of global configuration - but this is a case where you would need something analogous to the gitconfig byHost entries - so that from a fully qualified image path - you could reference globally configured credentials per registry.\nIs the stop-gap to have a AppCreateListener watch for route additions and pre-fetch the image using a custom docker client?. Also will be good to consider how credentials can be registered as hooks at runtime so that registries using short term credentials can be dynamic:\nhttps://cloud.google.com/container-registry/docs/advanced-authentication. ",
    "jconning": "@ccirello my understanding is that functions that run with Hot Containers need to be written to read from stdin and write to stdout in chunks.  Lambda doesn't have such functionality.  How do you envision that Lambda-imported functions will work with Hot Containers?. I got confused and thought that -sSL was supposed to be --ssl.  Seriously I saw \"sSL\" and immediately thought SSL, secure sockets layer.  It didn't occur to me that it was actually -s -S -L.\nFalse bug report!  But my eyes would be more pleased if it were -s -S -L or -LSs.\n@treeder @derks . These are both valid curl commands that do different things:\ncurl -sSL\ncurl --ssl\nMaybe I'm the only nutcase who would ever be confused by this but what the heck I changed it to be curl -LSs.. I changed the curl flags to curl -LSs. Seems like a bug to me.  Following the instructions in hello/python/README.md doesn't work.\nhttps://github.com/iron-io/functions/tree/master/examples/hello/python/README.md\nDon't we want the examples to work, as documented, so new people have a good experience?. Gotcha. @denismakogon Yes that's right but the docs say that REQUEST_URL should contain the FULL url and @treeder indicated that it should.. Here are results for the same configuration but with 1000 calls to a single route rather than 10 calls.  55-70% of the calls get routed to two nodes, with the remainder spread out across the remaining eight nodes.\nJims-MacBook-Pro:lbtest jimc$ go run main.go\nDiscovering container ids for every node (use Docker's HOSTNAME env var as a container id)...\n  54.175.27.185:8080 a0a9784ebd2b\n  54.175.27.185:8081 98ce598c4359\n  54.175.27.185:8082 e1d0903cb040\n  54.175.27.185:8083 73fb13e4476b\n  54.175.27.185:8084 c9a8c48476c6\n  54.175.27.185:8085 2211e69e4922\n  54.175.27.185:8086 a56ac820919f\n  54.175.27.185:8087 c88470355491\n  54.175.27.185:8088 de9ce5b86d5e\n  54.175.27.185:8089 5dffdef038fc\nQuick function: generate primes up to 1000\nCalling a single route 1000 times (through the load balancer)...\nResults (executions per node):\n  54.175.27.185:8082 32\n  54.175.27.185:8083 26\n  54.175.27.185:8086 31\n  54.175.27.185:8084 40\n  54.175.27.185:8087 32\n  54.175.27.185:8085 341\n  54.175.27.185:8080 41\n  54.175.27.185:8089 58\n  54.175.27.185:8081 24\n  54.175.27.185:8088 370\nLonger function: generate primes up to 1M\nCalling a single route 1000 times (through the load balancer)...\nResults (executions per node):\n  54.175.27.185:8082 52\n  54.175.27.185:8081 51\n  54.175.27.185:8083 37\n  54.175.27.185:8084 63\n  54.175.27.185:8088 309\n  54.175.27.185:8087 38\n  54.175.27.185:8086 30\n  54.175.27.185:8089 75\n  54.175.27.185:8080 57\n  54.175.27.185:8085 280\nEven longer function: repeat primes calculation 100 times (primes <= 1M)\nCalling a single route 1000 times (through the load balancer)...\nResults (executions per node):\n  54.175.27.185:8084 72\n  54.175.27.185:8082 49\n  54.175.27.185:8087 45\n  54.175.27.185:8086 45\n  54.175.27.185:8080 65\n  54.175.27.185:8083 44\n  54.175.27.185:8088 292\n  54.175.27.185:8085 255\n  54.175.27.185:8081 54\n  54.175.27.185:8089 79. I'll be addressing the code review comments soon!. @seiflotfy I have made the changes you requested.. Good catch, @denismakogon.. My bad.  I saw \"-sSL\" and immediately thought secure sockets layer, so I typed \"--ssl\".. fn bump is actually not required when a new function is being built for the first time.  This section of the quickstart is only covering the case of a new function, not editing an existing function.  The way this is written the first version of the function will be 0.0.2.\nfn bump is required when the code of an existing function is edited.. Looks good.. \"bump, build and push\" should actually be \"build and push\".. Error message doesn't match logic.  Logic is checking app name and route path only.  But error message also mentions image name as required.. ",
    "gouthamve": "I built it from the latest source: fn version 0.1.39. Yep, I am still able to reproduce after a fresh clone.\nHere is my system info:\n\u279c  functions git:(master) uname -a\nLinux beast 4.8.13-1-ARCH #1 SMP PREEMPT Fri Dec 9 07:24:34 CET 2016 x86_64 GNU/Linux\n\u279c  functions git:(master) groups goutham\nwheel docker goutham\n\u279c  functions git:(master) ls -alh\ntotal 20M\ndrwxr-xr-x 11 goutham goutham 4.0K Dec 29 09:52 .\ndrwxr-xr-x  3 goutham goutham 4.0K Dec 29 09:49 ..\ndrwxr-xr-x  7 goutham goutham 4.0K Dec 29 09:50 api\n-rw-r--r--  1 goutham goutham  626 Dec 29 09:50 build.ps1\n-rw-r--r--  1 goutham goutham 1.3K Dec 29 09:50 circle.yml\ndrwxr-xr-x  2 goutham goutham 4.0K Dec 29 09:50 clients\n-rw-r--r--  1 goutham goutham 1.3K Dec 29 09:50 CONTRIBUTING.md\ndrwxr-xr-x  2 root    root    4.0K Dec 29 09:52 data\n-rw-r--r--  1 goutham goutham  811 Dec 29 09:50 doc.go\n-rw-r--r--  1 goutham goutham   87 Dec 29 09:50 Dockerfile\ndrwxr-xr-x  9 goutham goutham 4.0K Dec 29 09:50 docs\ndrwxr-xr-x 16 goutham goutham 4.0K Dec 29 09:50 examples\ndrwxr-xr-x  3 goutham goutham 4.0K Dec 29 09:50 fn\n-rwxr-xr-x  1 root    root     20M Dec 29 09:52 functions-alpine\ndrwxr-xr-x  8 goutham goutham 4.0K Dec 29 09:54 .git\n-rw-r--r--  1 goutham goutham  209 Dec 29 09:50 .gitignore\n-rw-r--r--  1 goutham goutham 8.9K Dec 29 09:50 glide.lock\n-rw-r--r--  1 goutham goutham  972 Dec 29 09:50 glide.yaml\n-rw-r--r--  1 goutham goutham  12K Dec 29 09:50 LICENSE\n-rw-r--r--  1 goutham goutham 2.6K Dec 29 09:50 main.go\n-rw-r--r--  1 goutham goutham 1.1K Dec 29 09:50 Makefile\n-rw-r--r--  1 goutham goutham 9.7K Dec 29 09:50 README.md\n-rwxr-xr-x  1 goutham goutham  846 Dec 29 09:50 release.sh\n-rw-r--r--  1 goutham goutham  270 Dec 29 09:50 THIRD_PARTY\ndrwxr-xr-x  3 goutham goutham 4.0K Dec 29 09:50 triggers\ndrwxr-xr-x  5 goutham goutham 4.0K Dec 29 09:51 vendor\n\u279c  functions git:(master) docker info\nContainers: 5\n Running: 3\n Paused: 0\n Stopped: 2\nImages: 13\nServer Version: 1.12.3\nStorage Driver: overlay2\n Backing Filesystem: extfs\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins:\n Volume: local\n Network: null bridge host overlay\nSwarm: inactive\nRuntimes: runc\nDefault Runtime: runc\nSecurity Options: seccomp\nKernel Version: 4.8.13-1-ARCH\nOperating System: Arch Linux\nOSType: linux\nArchitecture: x86_64\nCPUs: 8\nTotal Memory: 23.31 GiB\nName: beast\nID: 6OCP:VJ5C:L2T4:AGMZ:N7KP:75TF:7FUM:JTN7:EIKR:J4KV:6RHA:VMTW\nDocker Root Dir: /var/lib/docker\nDebug Mode (client): false\nDebug Mode (server): false\nRegistry: https://index.docker.io/v1/\nInsecure Registries:\n 127.0.0.0/8\nI see that the folder data (created by make run-docker) is owned by root in my case while its owned by your user in your case. No clue why its happening.\n. @seiflotfy Instead of complicating it by adding log monitoring, can we not realize this by using listeners?. Instead of removing the check entirely, can we check the local images and then query the registry images and fail if the image doesn't exist in both places?. Yep! Just verified it. It is being handled at runtime. It is also picking up the local-image if available. This is good!. Umm, I think the error should be 500. Because the docker client is probably not authorised and not the client making the request.. Umm, the route exists (its mapped to an image and is registered). But the server internally is not able to run the image and errors out.\n404 is for routes that are not even registered. But again, this is just minor and I guess we can go with 404 also for now.. Yep! This sounds good!. A little misleading? As only the API endpoints are wrapped by middleware not the functions invokers: https://github.com/iron-io/functions/blob/ce26f665ea2b1e83ce093ba0f9fe86d27b055e11/api/server/server.go#L252-L271\nOr is it supposed to encapsulate the functions endpoints too?. Can Run Middlewares take the task.Config as a parameter? I mean if we are middlewaring the runner, we would want to change the config right?\nOr is there way to map the context to the task config?. Okay. I was thinking this was a middleware for the runner. Why are we using it on the special handler?\nDid I just get the whole intention wrong?. I agree with @treeder about passing down the populated App initially itself.\nUsecase: suppose I have a middleware that based on the caller (identified from a HEADER) wants to change the limits (Memory/Timeout) of the container. This cannot be done via the middleware now.. Does this mean I cannot update a route without the funcfile?. Shouldn't these also come from the funcfile?. These as in Memory/Time.. Need to pick up the image from the flag. The third argument is undocumented.. ",
    "alnutile": "@ucirello Any reason this was Closed? \nWithout this fix I could not get a basic PHP example to work.\nThanks btw!. thanks!. ",
    "vasilev": "+1 , these changes are useful.. Thank you @mdvacca for interest. We'd appreciate your review of this patch.. ",
    "crissilvaeng": "[![Slack Status](https://open-iron.herokuapp.com/badge.svg)](http://get.iron.io/open-slack)\nBadge and redirect are working to me.\n\ud83d\ude15 . ",
    "martinpinto": "Hi @treeder, I've created an installer package using the documentation from chocolatey and taken into consideration all rules. I've tested it and it successfully installed it on my windows machine. In order for me to push this to chocolatey, I have to create a key and push it from the console. But before I do, I wanted to check with you guys. I will gladly post a link to the repo for review purposes if required.. I created a new PR #564 as requested. In order to create the package and test it a choco pack functions.nuspec command is required.. That is a good idea, since there aren't any differences besides the sql schema. I will start refactoring the code and do a new commit.. Done, removed it. Done, removed these to stay consistent with the postgres package.. Done, added check.. Done, added check.. what do you suggest how we could improve this?. You're right, it doesn't make much sense. Added a break and the error will be returned by rows.Err().. well, the MySQL exception I get is sql: no rows in result set, which imho translates to ErrAppsNotFound.. Done, ErrRoutesNotFound was caught above and added logging.. Done, removed continue and added logging.. Done, removed import.. oh yes of course! Changed * with name, config. Thank you!. Added check for sql.ErrNoRows.. ",
    "nii236": "Creating an environment variable at app creation works:\n$ fn apps create --config DB_URL=http://example.org/ myapp\n$ fn apps config view myapp\nmyapp configuration:\nDB_URL: http://example.org/\nBut when I actually want to access the environment variable the key is _DB_URL, not DB_URL. \nI still can't set or unset anything as well.\n```\n$ fn apps config view myapp\nmyapp configuration:\nDB_URL: http://example.org/\n$ fn apps config unset myapp DB_URL\nmyapp removed DB_URL\n$ fn apps config view myapp\nmyapp configuration:\nDB_URL: http://example.org/\n```. Yes please! I tried doing it myself but kept hitting blockers with regards to app configuration as seen at #464. ",
    "cruxnet": "I am considering using Iron Functions as the basis for an internal corporate FaaS. So I could put Nginx in front of the API but that would not give me fine grain control over creating, modifying, and deleting applications and routes. I know I can front fn with a web application that will manage access to the API but am wondering if that is something being considered as a feature in a future release so that using Iron Functions inside an enterprise is a turn key solution.\n. What you describe is what I was looking for. Much appreciated. Thanks!. ",
    "zephinzer": "any updates on this? i can't seem to find relevant documentation on how to do this. ",
    "c0ze": "@zephinzer \nYes, with 0.2.70 release, we introduced Authentication via JWT tokens. This uses the middleware approach treeder mentioned above. If you would like to use another scheme, that is also possible.\nPlease check it out and let us know your thoughts !. Hello,\nThere is actually support hot functions\nhttps://github.com/iron-io/functions/blob/master/docs/hot-functions.md\nThis is little bit dated, but should still work. We would really appreciate any input !. It is on by default. You can set container type by format parameter. \n\nformat (mandatory) either \"default\" or \"http\". If \"http\", then it is a hot container. @Tofull we have a new release 0.2.65 which should fix this issue ! Please let us know if this works for you ! . LGTM. Hello there, and thanks for checking Iron Functions out !\n\nRecently, iron.io was acquired by Xenon Ventures. Some of the original developers are not with us anymore. So far, we've focused on the main Iron Suite (IronMq and IronWorker) but Iron Functions is going to get attention and an uplift too. So please bear with us until we get up to speed !. Yes, fn tool is used to build a container which hosts your local function/application.\nIt doesn't really make sense to use a remote docker host with fn build, because your local files will need to be copied there as well. Therefore the recommended way to provision and deploy your function is to use a container registry (Dockerhub, or ECR, or your own). The flow should be something like this :\n\ninit & develop in your local\nbuild\npush the container to some CR\npull & run at your production node which is running the functions container (you can do this via docker remote host)\n\nIf you have an idea for an alternative flow, please let us know !\nHmm, thinking about this, (and checking the documentation for docker build) it seems it is possible to specify a git repository. In that case, it should be possible to build via docker remote API if the project is in a repo.. It seems you are right, thank you for the clarification !\nI'm checking the fn source code, it seems fn tool is executing docker as a shell command.\nhttps://github.com/iron-io/functions/blob/d8871d1562c0e30fcf43f7e02b19a706f366eafb/fn/common.go#L95\nThe proper solution to this would be to re write fn tool using docker golang bindings, but as a short term solution, I am wondering if you could get this to work by passing DOCKER_HOST to fn build ? ie\nDOCKER_HOST={your docker host here} fn build. Hello again,\nI've checked into this issue, it seems the problem is with \nhttps://github.com/iron-io/functions/blob/master/fn/langs/go.go#L29\nwhich tries to mount your local dir to the remote host via the -v flag.\nhttps://github.com/moby/moby/issues/4023\nwhich doesn't work. As a work-around, you can create your own Dockerfile, which would prevent this prebuild step.\nI'm linking an example project which has a known working Dockerfile for remote building.\nhttps://bitbucket.org/coze/query/src/dff81a3ab0a39f1c586efe394a377a382065ed0d/?at=custom-dockerfile\nThis one uses glide for dependency management, but feel free to use another one if you like.\nPS: you also need the .dockerignore to prevent your local vendor directory being copied over to the host.\n. I created a new issue for that. Please close this one if the Dockerfile solves your problem.. Hello, thanks for all the reports !\nThis is interesting, it seems fn doesn't get the response it expects.\nhttps://github.com/iron-io/functions/blob/master/fn/apps.go#L148\nI'll try to replicate your environment and check for the issue, in the mean time, would it be possible for you to try without https ? (just a hunch, also in light of  #634 ). thank you, I will look into this.. @prologic sorry for the long delay ! We just released a new version of the fn tool which should solve SSL issues. Please give it a try and let us know if this works for you !\nThanks !. closing this for now, please feel free to open again if still not working for you \ud83d\udc4d . We released a new version on sept 28th.\nhttps://github.com/iron-io/functions/pull/650\nYou need to update your fn tool and iron/functions container to get the new version.\nseems to be working (duplicate issue closed by OP)\nhttps://github.com/iron-io/functions/issues/649. Thank you for the report. It seems builds got broken after the docker/moby renaming. \nThe project was also in the process of migrating to go dep tool.\nI'll update this issue once we fix the issue(s).\nLast successful CI build is from 4 months ago. It was working then.\n. sorry this is still not working, I'll try again soon. Hello there,\nCurrently this is not happening because of the terrible mess caused by logrus/sirupsen Our fixed vendor deps work (make dep), so please use that if you would like to contribute. \nWe will try to fix this as people move on to the lower case convention, or maybe we will discard logrus all together and go for something like zap. In the mean time I will close this issue.. @zzaarrgg if possible, can you please sign the CLA on this one ? Thanks !. Hello there,\nI'm not sure this is a problem about iron functions. My advice would be to update your installation (14.04 is getting old) and preferably update your setup so that you don't need to use sudo. . @kunihiko-t when you have a chance, could you have a look into this please ?\nthanks !. thank you for the report ! This is an issue we are working on, hopefully it will be resolved soon !\nhttps://github.com/iron-io/functions/pull/650. @wrsuarez we just released a new version of the fn tool which should solve this issue. Please give it a try and let us know if this works for you ! Thanks !. we also need https://github.com/iron-io/functions_go/pull/6 for this to work.. it's because maybe functions provides headers to the function as env vars ?\nhttps://github.com/iron-io/functions#passing-data-into-a-function\nSo that function can distinguish which env var comes from the request (As header).. Thanks !. thank you !. hello @wrsuarez !\nThank you for the report ! Iron base containers are configured to be minimal, to make them take as little space as possible.\nHowever, you don't have to keep to using Iron provided base containers. By default, fn tool tries to be smart, and provide you with a default container & Dockerfile based on your application. However, you can also use any configuration you like if you provide a custom Dockerfile.\nIn this case, the base Dockerfile fn tool presumes is :\npython:2-dev\nAdding some necessary dependencies for paramiko,  a Dockerfile like below should solve your problem :\n```\nFROM iron/python:2\nRUN apk update && apk upgrade\nRUN apk add --no-cache curl python pkgconfig python-dev openssl-dev libffi-dev musl-dev make gcc\nRUN curl -sS https://bootstrap.pypa.io/get-pip.py | python\nWORKDIR /app\nADD . /app\nRUN pip install -U setuptools\nRUN python -m pip install --upgrade pip\nRUN pip install -t packages -r requirements.txt\nENTRYPOINT [\"python\", \"func.py\"]\n```\nOr, checking dockerhub for paramiko, you can use another base container which includes all these deps and end up with a cleaner Dockerfile:\n```\nFROM eduardoshanahan/paramiko\nWORKDIR /app\nADD . /app\nRUN pip install -t packages -r requirements.txt\nENTRYPOINT [\"python\", \"func.py\"]\n```\nIn this case, the base container doesn't seem to contain pip, so this doesn't work. But the point is there might be other containers out there serving your needs built by other people, so you can base your app on these containers as well. You are not confined to Iron provided containers.\nI hope this solves your issue, let us know how it works !. closing this for now, please feel free to open if something is not clear. \ud83d\udc4d . hello @heww ,\nAssuming you are following mysql docs . \nIt is difficult to diagnose a problem with so little information, but it seems your problem is about indexing a UTF8 field in MySQL. I would advise checking stackoverflow for similar problems.  If you have identified this as a IronFunctions specific problem, please share some information.\nThanks !. Thanks for the feedback ! Glad that it worked for you ! \ud83d\udc4d \nHere are a few pointers to get you started :\nhttp://blog.lwolf.org/post/how-to-run-functions-in-your-kubernetes-cluster/\nhttps://github.com/iron-io/functions/tree/master/docs/operating\nhttps://github.com/kunihiko-t/jwt-example\nSorry some of these resources are somewhat outdated, so may need some tuning. Running on K8s or Docker Swarm is definitely on the roadmap, so we will go over these and update the docs soon ! Stay tuned ! (If you notice any issues with the documentation, you are more than welcome to contribute too !). Oops, sorry actually there are some diffs I forgot to check, just a sec.. Sorry, I just made some changes (moved image commands into a sub folder).\nThis should now be ok to review. Sorry for the long diff, maybe it is better to checkout and check / test locally.. @kunihiko-t thank you ! I am merging this then !\nIf possible, can you rebase jwt_proposal to new master ?\nIn the mean time, I will consult KG team for iron-io/functions_go#7 .\n(I can merge it, but I want to make sure it doesn't break anything for them.). @kunihiko-t iron-io/functions_go#7 is merged !. ok, I updated the Dockerfiles. I also fixed the path at example in readme.\nBtw, when I run with fn run, I get\n/usr/lib/ruby/2.3.0/uri/rfc3986_parser.rb:67:in `split': bad URI(is not URI?): http://www.sourcecertain.com/img/Example.png (URI::InvalidURIError)\nWhen running with curl, there is no error, and it works perfectly. (Same URI)\nAny ideas ? @vasilev @kunihiko-t  ? Thank you !\nEDIT: ok never mind it seems I need to strip STDIN input of whitespace chars. Now it works ok.. This should be ready to go now.. @kunihiko-t thanks for the feedback !\nHmm, yes in that case it won't clash, so that's good news ! I am still looking for a good way to test this...\nYeah, I think IRON_TOKEN was somekind of experimental feature which we can remove.. @kunihiko-t I modified FullStackTest to test jwt authentication (with valid and invalid tokens).\nNow I'm looking for some kind of integration testing with the fn tool.. hello @vasilev @kunihiko-t ,\nI added integration tests to this PR. I would appreciate if you could take a look !\nThis is necessary for #663 because I am planning to use a similar testing harness, so would like to merge this in first.\nThank you !\n. @kunihiko-t \nThank you for the review !\nInstead of writing a big review, can you please mention individual problems inline with the changes ? I think it is the usual github review procedure. I will give you an example.. About test tags, actually, I think I will remove server tag. I introduced full_stack and integration tags to test quickly, but I don't think there is need for a server tag.. @kunihiko-t I removed full_stack tag instead of server tag. Now you can run both and also with no tags and everything should be passing. What do you think ?. there is a leftover file at /tmp/func_test_bolt.db after tests are run. It is not a big problem , but little bit annoying.\n\nIf you run make test file is there.\nIf you run with server tag, it is not there (I modified teardown functions to destroy it)\nIf you run with integration tag, it is also there.\n\nprobably the teardown function is not being called somewhere (or overwritten ? but it is not possible in Go I think) I'm not sure what's going on, hmmm .... @kunihiko-t  I see, thank you for the analysis.\nHowever, I don't agree with your proposal. tmpBolt is local to server tests, so it's creation and disposal should be handled in the same file, server_test.\nInstead, I will try to find why it is being created in the first place, when tests are called without server tag. I think it is better approach.. ok, I found it. It was being created in one of the datastore tests.. @kunihiko-t @vasilev \nThanks ! Yes I am looking at providing some test coverage. Might take a while !. @kunihiko-t @vasilev \nI added tests for setting idle_timeout (and every other param) from fn tool ! I would appreciate if you could take a look !\nRegarding the test I posted go code above, it actually tests hot functions spin down behaviour, which is beyond the scope of this PR. This PR only deals with setting idle_timeout from fn tool.. @sss0350 Thanks for the response !\nYes, this is actually ready to go, so setting idle_timeout from fn will be available in a few moments. (it will be version 0.2.72, so dont forget to update !)\nRegarding UI, we already added it but it is not released yet. We will combine a couple of feature requests for UI and release a new version soon (hopefully in a couple of weeks) !. Yes, it should be alive for the duration of idle timeout. You can see if it's being killed in the server logs. Can you see anything there? . Hello,\nThank you for your interest in our platform !\nfn tool itself shouldn't require internet connectivity. If the functions service is running on another machine, you need to supply API_URL env when making fn calls though. Please check :\nhttps://github.com/iron-io/functions/blob/3c4261ae37accf6c51a6aee6b216f58c84621d6c/docs/operating/options.md#L16\nlike this :\nAPI_URL=192.168.10.11:4000 fn apps list\nhope this helps ! \ud83d\udc4d . @sss0350 thanks for checking and the feedback ! Yes, in your initial message you linked to 0.2.71 so I thought you already had the latest version. I'm glad that updating fixed your issue !\nPlease let us know if you run into any other problems !. hello @sss0350 ,\nAll headers should be available as ENV variables in your function, with the following format :\nHEADER_{HTTP Header, uppercase, `-` replaced by `_`}\nHEADER_ACCEPT_LANGUAGE\nHEADER_AUTHORIZATION\netc.\nfunctions inputs\nHope this helps !. hello @sss0350 !\nI'm glad that you were able to access request headers ! You can use route configuration to add static headers as described here. Unfortunately there is no way to add headers dynamically at this point as you would need to in a cookie based authentication. What you can do is maybe write / add a server cookie to response object, and read it from the body (as opposed to from headers) from the client side. . @sss0350 sorry for the late response ! Unfortunately, we don't have an exact solution to your problem this time, as openshift is something we haven't really worked on. We can just say that you don't have to create any schema for Postgres. If there is any progress on this issue, we would appreciate if you could keep us informed !. just one thing, can you try with\nexport IRON_FUNCTION=$(kubectl get -o json svc functions | jq -r '.status.loadBalancer.ingress[0].ip'):8080\ninstead of \nexport IRON_FUNCTION=$(kubectl get -o json svc functions | jq -r '.status.loadBalancer.ingress[0].hostname'):8080\n(change hostname to ip). bolt is a file storage db, and it does not allow more than one process access a single file AFAIK. Bolt is meant to quickly test / evaluate in a dev environment, not really thought for a production / staging deployment. So we would recommend configuring one of the supported DBs.. @zephinzer thanks for the report !\nUsing private repositories is something we are currently working on atm, so unfortunately there is no official way to do this.\nUntil we enable this functionality, I believe you can circumvent the issue by doing docker login from the host where you are running your Iron functions service. Does this work for you ?\ndocumentation on docker login in case you need to explore your options.. thanks for the report !\nIf possible can you please provide your fn tool version, and if its not latest (0.2.72) can you please try updating it ?. @JosephShering \ncan you try API_URL=http://127.0.0.1:8082 fn\n(yeah http protocol prefix is necessary.)\nAlso, have you checked your version ? fn version  ? . @raky35 can you please provide little bit more information ? Your system, fn tool version, your application context etc ? (which command you run when you get the message etc ? what are API_URL env variables if passed ?)\nAs a side note, ethereum source is not referenced anywhere in the IF code base. I think your problem is not related to iron functions.. @sss0350 the normal work flow with IF, you bump the image version with fn bump when you want release a new image. this will iterate the version and also assign latest tag to it. Is there anything that is preventing you from using fn bump ?. sorry, can you please change to cd docs/operating/kubernetes and try again ? It seems the documentation is outdated.. yes, it seems you need to run port forwarding running in the background. Please open a new tab, run kubectl port-forward functions-65c64ddf68-ml9nz 8080 and let it run. Then in another panel, run fn command.\nI'll check if it is possible to make port forwarded by default.\n. ok. while you are doing this, did you try fn command ?. ok, it seems it worked, now if you do fn apps list you should see your app listed.. Yes, you can use any language that you can run inside a docker container.\nPlease check PHP Hello example.. I'm sorry, I don't understand what you mean by \"Running on Kubernetes directly\".\nKubernetes is a container orchestration platform, so you will need to use some kind of containerization technology to run your function.\nAt the moment, Iron Functions support only Docker containers. It is possible to support other containerization platforms, but currently there are no projects underway.. Sorry, at this moment there is no resource usage info.. Hello there,\nYou are not doing anything wrong. It seems only 4.3 is supported atm.\nhttps://github.com/iron-io/functions/blob/e1c0012d04897a0c204e0dafb3ede689cf445f83/fn/commands/lambda.go#L154\n6.10 seems to have been introduced last may.\nhttps://aws.amazon.com/about-aws/whats-new/2017/03/aws-lambda-supports-node-js-6-10/. hello @sss0350 , sorry for taking time to get to this. Were you able to get config vars ?. Unfortunately, there is no concept of users or fine grained access control. You can secure global API by issuing JWT tokens, please check the Authentication docs for more information. For fine grain control, you can set route level JWT tokens, and distribute to your users maybe.. You don't need to write any middleware. You just need to pass an ENV when starting the functions server. You also need to pass the same token when you are issuing commands via the fn tool (or accessing the API in any way). Please check the documentation I provided before. \nIf you need to modify the implementation (write your own middleware etc), please check the following PRs, they may give you ideas. Thank you !\nhttps://github.com/iron-io/functions/pull/662\nhttps://github.com/iron-io/functions/pull/660\n. does this help ?\nAs for users, I am afraid that is not in the roadmap. If you are willing to help though, of course we would appreciate your input !. oops ! thank you !. thank you !. @TaekminKwon unfortunately I couldn't fix the issue, and these days I cant have the time to attempt a fix.\nWould like to give it a try ?. yes. up unto a certain point, we were able to build the package by using the dep manifest in the repo by doing make dep.\nRight now, I am not sure if it works any more. So we need to rebuild dependencies from scratch I think.. ",
    "jakepearson": "I did. Last night, it failed this morning, it all worked. I'm guessing it might be related to opening a new shell. Thanks for getting back to me.. ",
    "derks": "Tested on latest macOS Sierra, and the original command curl -sSL ... does work just fine.  Not sure if that is an issue with cURL on Yosemite specifically... maybe providing output of the failing command might help?. ",
    "robputt796": "Hi @ucirello,\nBy \"client side\" are you suggesting this will be done as part of the Picasso API?\nBest Regards,\nRob. ",
    "narg95": "Great !. ",
    "adelevie": "Huh. I tried that and got this error:\n\u279c  functions git:(master) make run-docker\nset -ex\ndocker run --rm -v /home/adelevie/iron-io/functions:/go/src/github.com/iron-io/functions -w /go/src/github.com/iron-io/functions iron/go:dev go build -o functions-alpine\napi/server/init.go:10:2: cannot find package \"github.com/Sirupsen/logrus\" in any of:\n    /go/src/vendor/github.com/Sirupsen/logrus (vendor tree)\n    /go/src/github.com/Sirupsen/logrus (from $GOROOT)\n    /gocode/src/github.com/Sirupsen/logrus (from $GOPATH)\napi/datastore/bolt/bolt.go:16:2: cannot find package \"github.com/boltdb/bolt\" in any of:\n    /go/src/vendor/github.com/boltdb/bolt (vendor tree)\n    /go/src/github.com/boltdb/bolt (from $GOROOT)\n    /gocode/src/github.com/boltdb/bolt (from $GOPATH)\napi/server/server.go:15:2: cannot find package \"github.com/ccirello/supervisor\" in any of:\n    /go/src/vendor/github.com/ccirello/supervisor (vendor tree)\n    /go/src/github.com/ccirello/supervisor (from $GOROOT)\n    /gocode/src/github.com/ccirello/supervisor (from $GOPATH)\napi/runner/task.go:8:2: cannot find package \"github.com/fsouza/go-dockerclient\" in any of:\n    /go/src/vendor/github.com/fsouza/go-dockerclient (vendor tree)\n    /go/src/github.com/fsouza/go-dockerclient (from $GOROOT)\n    /gocode/src/github.com/fsouza/go-dockerclient (from $GOPATH)\napi/mqs/redis.go:13:2: cannot find package \"github.com/garyburd/redigo/redis\" in any of:\n    /go/src/vendor/github.com/garyburd/redigo/redis (vendor tree)\n    /go/src/github.com/garyburd/redigo/redis (from $GOROOT)\n    /gocode/src/github.com/garyburd/redigo/redis (from $GOPATH)\napi/server/apps_create.go:7:2: cannot find package \"github.com/gin-gonic/gin\" in any of:\n    /go/src/vendor/github.com/gin-gonic/gin (vendor tree)\n    /go/src/github.com/gin-gonic/gin (from $GOROOT)\n    /gocode/src/github.com/gin-gonic/gin (from $GOPATH)\napi/models/app_wrapper.go:3:8: cannot find package \"github.com/go-openapi/errors\" in any of:\n    /go/src/vendor/github.com/go-openapi/errors (vendor tree)\n    /go/src/github.com/go-openapi/errors (from $GOROOT)\n    /gocode/src/github.com/go-openapi/errors (from $GOPATH)\napi/models/complete.go:3:8: cannot find package \"github.com/go-openapi/strfmt\" in any of:\n    /go/src/vendor/github.com/go-openapi/strfmt (vendor tree)\n    /go/src/github.com/go-openapi/strfmt (from $GOROOT)\n    /gocode/src/github.com/go-openapi/strfmt (from $GOPATH)\napi/models/id_status.go:10:2: cannot find package \"github.com/go-openapi/swag\" in any of:\n    /go/src/vendor/github.com/go-openapi/swag (vendor tree)\n    /go/src/github.com/go-openapi/swag (from $GOROOT)\n    /gocode/src/github.com/go-openapi/swag (from $GOPATH)\napi/models/id_status.go:13:2: cannot find package \"github.com/go-openapi/validate\" in any of:\n    /go/src/vendor/github.com/go-openapi/validate (vendor tree)\n    /go/src/github.com/go-openapi/validate (from $GOROOT)\n    /gocode/src/github.com/go-openapi/validate (from $GOPATH)\napi/mqs/memory.go:11:2: cannot find package \"github.com/google/btree\" in any of:\n    /go/src/vendor/github.com/google/btree (vendor tree)\n    /go/src/github.com/google/btree (from $GOROOT)\n    /gocode/src/github.com/google/btree (from $GOPATH)\napi/mqs/ironmq.go:15:2: cannot find package \"github.com/iron-io/iron_go3/config\" in any of:\n    /go/src/vendor/github.com/iron-io/iron_go3/config (vendor tree)\n    /go/src/github.com/iron-io/iron_go3/config (from $GOROOT)\n    /gocode/src/github.com/iron-io/iron_go3/config (from $GOPATH)\napi/mqs/ironmq.go:16:2: cannot find package \"github.com/iron-io/iron_go3/mq\" in any of:\n    /go/src/vendor/github.com/iron-io/iron_go3/mq (vendor tree)\n    /go/src/github.com/iron-io/iron_go3/mq (from $GOROOT)\n    /gocode/src/github.com/iron-io/iron_go3/mq (from $GOPATH)\napi/mqs/bolt.go:17:2: cannot find package \"github.com/iron-io/runner/common\" in any of:\n    /go/src/vendor/github.com/iron-io/runner/common (vendor tree)\n    /go/src/github.com/iron-io/runner/common (from $GOROOT)\n    /gocode/src/github.com/iron-io/runner/common (from $GOPATH)\napi/runner/task/task.go:8:2: cannot find package \"github.com/iron-io/runner/drivers\" in any of:\n    /go/src/vendor/github.com/iron-io/runner/drivers (vendor tree)\n    /go/src/github.com/iron-io/runner/drivers (from $GOROOT)\n    /gocode/src/github.com/iron-io/runner/drivers (from $GOPATH)\napi/runner/runner.go:21:2: cannot find package \"github.com/iron-io/runner/drivers/docker\" in any of:\n    /go/src/vendor/github.com/iron-io/runner/drivers/docker (vendor tree)\n    /go/src/github.com/iron-io/runner/drivers/docker (from $GOROOT)\n    /gocode/src/github.com/iron-io/runner/drivers/docker (from $GOPATH)\napi/runner/runner.go:22:2: cannot find package \"github.com/iron-io/runner/drivers/mock\" in any of:\n    /go/src/vendor/github.com/iron-io/runner/drivers/mock (vendor tree)\n    /go/src/github.com/iron-io/runner/drivers/mock (from $GOROOT)\n    /gocode/src/github.com/iron-io/runner/drivers/mock (from $GOPATH)\napi/datastore/postgres/postgres.go:13:2: cannot find package \"github.com/lib/pq\" in any of:\n    /go/src/vendor/github.com/lib/pq (vendor tree)\n    /go/src/github.com/lib/pq (from $GOROOT)\n    /gocode/src/github.com/lib/pq (from $GOPATH)\napi/server/runner.go:22:2: cannot find package \"github.com/satori/go.uuid\" in any of:\n    /go/src/vendor/github.com/satori/go.uuid (vendor tree)\n    /go/src/github.com/satori/go.uuid (from $GOROOT)\n    /gocode/src/github.com/satori/go.uuid (from $GOPATH)\napi/server/init.go:12:2: cannot find package \"github.com/spf13/viper\" in any of:\n    /go/src/vendor/github.com/spf13/viper (vendor tree)\n    /go/src/github.com/spf13/viper (from $GOROOT)\n    /gocode/src/github.com/spf13/viper (from $GOPATH)\nMakefile:13: recipe for target 'build-docker' failed\nmake: *** [build-docker] Error 1\nIs golang somehow a host dependency?. That'd be fantastic!. Taking a look.. Just got\n\u279c  functions git:(make-update) make docker-dep\nmake: *** No rule to make target 'docker-dep'.  Stop.. make docker-dep and make docker-build seemed to work fine. make test-docker and make run-docker didn't though. \n\u279c  functions git:(make-update) make test-docker \n/bin/sh: 1: go: not found\ndocker run -ti --privileged --rm -e LOG_LEVEL=debug \\\n-v /var/run/docker.sock:/var/run/docker.sock \\\n-v /home/adelevie/iron-io/functions:/go/src/github.com/iron-io/functions \\\n-w /go/src/github.com/iron-io/functions iron/go:dev go test \\\n-v \n?       github.com/iron-io/functions    [no test files]\n\u279c  functions git:(make-update) make docker-run\nmake: *** No rule to make target 'build-docker', needed by 'docker-run'.  Stop.. Sweet, trying those now.. hey @treeder, sorry. \nworks:\n- make docker-dep\n- make docker-build\ndoesn't work:\n- make docker-run\n- make docker-test\nTo get make docker-run working, rewrite line 27 to docker-run: docker-build. I still can't get make docker-test working though.. The output of make docker-test is:\n\u279c  functions git:(make-update) \u2717 make docker-test\n/bin/sh: 1: go: not found\ndocker run -ti --privileged --rm -e LOG_LEVEL=debug \\\n-v /var/run/docker.sock:/var/run/docker.sock \\\n-v /home/adelevie/iron-io/functions:/go/src/github.com/iron-io/functions \\\n-w /go/src/github.com/iron-io/functions iron/go:dev go test \\\n-v \n?       github.com/iron-io/functions    [no test files]. Could it be that shell go list is expecting go available on the host?. I'll try, but I might come back to ask for some hand-holding.. I'd be happy to take a stab at this at some point. I'm newish to golang though. What does go list do in this context? e.g. why do we need this volume?. I also just noticed the test folder is empty. Could there be more documentation as to how tests work here?. ",
    "BupycHuk": "@treeder \nI'm going to encrypt docker credentials using AES or RSA.\nDo you think this is enough?. @treeder i have fixed conflicts and add new tests, could you take a look, pls. @treeder could you take a look, please?. ",
    "itamarhaber": "@seiflotfy :heart: . ",
    "WTFKr0": "Thanx for reply\nIt's not a problem for us at the moment\nWe plan to use other CI tool to build our functions and store them on our private registry\nThen we can create routes to publish them. Yep route configuration. I use the iron/functions:latest image\nBefore, it was working good without dind mode (I bind moutn the docker sock of host)\nBut in latest, function tried to launch dind even with the bind mount.\nSo I tried the dind mode, but fall into this issue. OK I solve my problem with non dind mode (mounting docker socket)\nThe problem was I run the service in mode global. ",
    "mikeball": "Tested and all works as expected.. ",
    "mazamats": "@matthewmueller I ran into something similar.\nIt seems executing a docker container per HTTP/function request isn't a good strategy since it will try to start thousands of docker containers per second.\nThere should be a way to keep functions \"warm\" somehow, or to remove the need for wrapping every function in a docker container.\nI was hoping to build a rest backend with iron but I'll be sticking with Lambda for HTTP concurrency.. Got it to work, results below:\nP.S. I initially tried to add format: http in the config section on the Functions UI since there wasn't an field to change the format. This caused some initial confusion, I eventually got it by updating format with postman\nNormal Function\nRunning 10s test @ http://10.0.0.10:8080/r/coldapp/cold\n  2 threads and 10 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency     1.70s   209.48ms   2.00s    75.00%\n    Req/Sec     4.14      3.25    10.00     64.29%\n  47 requests in 10.10s, 5.92KB read\n  Socket errors: connect 0, read 0, write 0, timeout 15\nRequests/sec:      4.65\nTransfer/sec:     600.36B\nHot Function\nRunning 10s test @ http://10.0.0.10:8080/r/myapp/hello\n  2 threads and 10 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency     8.55ms   27.40ms 293.43ms   97.55%\n    Req/Sec     1.10k   164.30     1.40k    75.51%\n  21407 requests in 10.01s, 7.59MB read\nRequests/sec:   2138.85\nTransfer/sec:    777.00KB. @jmank88 That works for the config, I can change the value and delete it if its clear. However, it doesn't work for the headers\nIf I try to update a header to a new value, it will just append it to an array. Nice, that seemed to work too.\nI guess this is mainly an issue with the Functions-UI, I was copying the API data it sent.. ",
    "matthewmueller": "@denismakogon tried briefly, but couldn't figure out how to configure it. from the docs:\n{\n    \"route\":{\n        \"app_name\": \"myapp\",\n        \"path\": \"/hot\",\n        \"image\": \"USERNAME/hchttp\",\n        \"memory\": 64,\n        \"type\": \"sync\",\n        \"config\": null,\n        \"format\": \"http\",\n        \"max_concurrency\": \"1\"\n    }\n}\nis that just a func.yaml in json format?. ",
    "rcarmo": "Erm... that question doesn't really make sense, because I'd like to run all of it.\nI've started doing my own armhf version of iron/dind off an armhf Alpine container, but building the service itself seems to depend on a lot of x64 containers.\n. @vielmetti I have a repo where I made a start at my build of dind: https://github.com/rcarmo/iron-io-dind-armhf \nHaven't had much time to follow up on this because I keep moving around (need to pack a Pi 3 to go), but it doesn't seem impossible.. Wow, thanks, guys. How do you suggest I get started testing this? maybe we could hold the issue open while we tally any documentation/teething issues?. @denismakogon Seems straightforward enough. I'll wipe a large SD card, grab the Go binaries and try it over the weekend.. Any chance of armhf?\n. ",
    "vielmetti": "Thanks @treeder - there is also support in Docker manifests to have an image automatically select the right architecture based on the manifest (so called \"fat manifest\" or \"multiarch\" support). The one project that's gotten the furthest on this is portainer and their details on how they did multiarch are at https://github.com/portainer/portainer/issues/285 using https://github.com/estesp/manifest-tool .\nThere's still the small matter of having an ARM build of iron/dind but once you have that the multiarch stuff lets you pick up the right architecture as you need it.. @denismakogon - this looks like good progress on armhf support. Full support for ARMv8 (aarch64, arm64) will require a parallel set of work, since ARM 32-bit binaries don't always run on 64-bit systems.. ",
    "cmdhema": "I use glide 0.12.3\ngo 1.8.1\nubuntu 14.04 lts\nMaster branch irconfunctions\nThank you for your reply @pedronasser @denismakogon \nAfter 'make dep build' I got some info messages, below examples \n...\n[INFO]  --> Found desired version locally github.com/amir/raidman c74861fe6a7bb8ede0a010ce4485bdbb4fc4c985!\n[INFO]  --> Found desired version locally github.com/asaskevich/govalidator 7b3beb6df3c42abd3509abfc3bcacc0fbfb7c877!\n[INFO]  --> Found desired version locally github.com/aws/aws-sdk-go 90dec2183a5f5458ee79cbaf4b8e9ab910bc81a6!\n....\nBut I got below errors\n[INFO]  --> Found desired version locally github.com/urfave/cli 0bdeddeeb0f650497d603c4ad7b20cfe685682f6!\n[INFO]  --> Fetching golang.org/x/crypto.\n[INFO]  --> Fetching gopkg.in/go-playground/validator.v8.\n[INFO]  --> Fetching golang.org/x/sys.\n[INFO]  --> Fetching golang.org/x/text.\n[INFO]  --> Fetching gopkg.in/mgo.v2.\n[INFO]  --> Fetching gopkg.in/yaml.v2.\n[INFO]  --> Fetching golang.org/x/net.\n[WARN]  Unable to checkout golang.org/x/crypto\n[ERROR] Update failed for golang.org/x/crypto: Cannot detect VCS\n[WARN]  Unable to checkout golang.org/x/net\n[ERROR] Update failed for golang.org/x/net: Cannot detect VCS\n[WARN]  Unable to checkout golang.org/x/text\n[ERROR] Update failed for golang.org/x/text: Cannot detect VCS\n[WARN]  Unable to checkout golang.org/x/sys\n[ERROR] Update failed for golang.org/x/sys: Cannot detect VCS\n[WARN]  Unable to checkout gopkg.in/yaml.v2\n[ERROR] Update failed for gopkg.in/yaml.v2: Cannot detect VCS\n[WARN]  Unable to checkout gopkg.in/mgo.v2\n[ERROR] Update failed for gopkg.in/mgo.v2: Cannot detect VCS\n[WARN]  Unable to checkout gopkg.in/go-playground/validator.v8\n[ERROR] Update failed for gopkg.in/go-playground/validator.v8: Cannot detect VCS\n[ERROR] Failed to install: Cannot detect VCS\nCannot detect VCS\nCannot detect VCS\nCannot detect VCS\nCannot detect VCS\nCannot detect VCS\nCannot detect VCS\nmake: *** [dep] Error 1\nHow can I download golang.org/x/crypto, x/net...... ?\nI have several attempts to do this, but failed.\nThanks. I solved my another machine. Thankyou. ",
    "mdvacca": "+1, how can I help to merge this into master?. ",
    "wjimenez5271": "@jmank88 yep, a restart fixed it. . Hmm, now after creating a new app\n$ fn apps create myapp\nmyapp created\nI get\nError: unexpected end of JSON input. ",
    "prologic": "I did some empirical testing and I'm finding the performance around ~600-700ms for a simple \"Hello World!\" function written in Go. I suspect some low hanging fruit for optimizations here.. I also suspect much of the performance gains can be made by keeping a pool of containers for \"warm\" runs of functions as ~400ms comes from \"cold\" start of the simplest of container:\n```#!bash\n$ time dki -t --rm busybox echo 'Hello World'\nHello World\nreal    0m0.431s\n```.  This feature must not be on by default correct?\nOn Fri, Aug 18, 2017 at 00:56 Arda Karaduman notifications@github.com\nwrote:\n\nHello,\nThere is actually support hot functions\nhttps://github.com/iron-io/functions/blob/master/docs/hot-functions.md\nThis is little bit dated, but should still work. We would really\nappreciate any input !\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/issues/626#issuecomment-323286476,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABOv-rYEbWCKvMNpBuwTiWTK4j5JUjdVks5sZUOjgaJpZM4NFvhn\n.\n-- \n\nJames Mills / prologic\nE: prologic@shortcircuit.net.au\nW: prologic.shortcircuit.net.au\n. I see; in that case do we still expect the kind of latency I posted earlier?\nJames Mills / prologic\nE: prologic@shortcircuit.net.au\nW: prologic.shortcircuit.net.au\nOn Tue, Aug 22, 2017 at 5:47 PM, Arda Karaduman notifications@github.com\nwrote:\n\nIt is on by default. You can set container type by format parameter.\nformat (mandatory) either \"default\" or \"http\". If \"http\", then it is a hot\ncontainer\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/issues/626#issuecomment-324189895,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABOv-h75C8HHqoQWImiOMq1dZMhYQmb7ks5sa3aqgaJpZM4NFvhn\n.\n. And... I think I know why:\n\n#!bash\n$ fn build -v\nbuilding /Users/prologic/faas-test/func.yaml\nRunning prebuild command: docker run --rm -v /Users/prologic/faas-test:/go/src/github.com/x/y -w /go/src/github.com/x/y iron/go:dev go build -o func\ncan't load package: package github.com/x/y: no buildable Go source files in /go/src/github.com/x/y\nerror running docker build: exit status 1\nfb build makes a really silly assumption. It assumes the Docker host is local to where you run fn from. This is almost never the case for full production systems. All my Docker nodes are remote to me.. Hmm ... AFAIK docker build itself copies the contents of the cwd into\nwhat's called a \"context\", shoves that to the remote api, unpacks it, then\nruns the build instructions in the Dockerfile\nI feel like fb needs to have the same/similar capability -- either that or\nre-use the docker build api somehow?\nJames Mills / prologic\nE: prologic@shortcircuit.net.au\nW: prologic.shortcircuit.net.au\nOn Wed, Aug 9, 2017 at 11:11 PM, Arda Karaduman notifications@github.com\nwrote:\n\nYes, fn tool is used to build a container which hosts your local\nfunction/application.\nIt doesn't really make sense to use a remote docker host with fn build,\nbecause your local files will need to be copied there as well. Therefore\nthe recommended way to provision and deploy your function is to use a\ncontainer registry (Dockerhub, or ECR, or your own). The flow should be\nsomething like this :\n\ninit & develop in your local\nbuild\npush the container to some CR\npull & run at your production node which is running the functions\n   container (you can do this via docker remote host)\n\nIf you have an idea for an alternative flow, please let us know !\nHmm, thinking about this, (and checking the documentation for docker build\nhttps://docs.docker.com/engine/reference/commandline/build/#usage) it\nseems it is possible to specify a git repository. In that case, it should\nbe possible to build via docker remote API if the project is in a repo.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/issues/631#issuecomment-321460371,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABOv-iSYaZfXK_-2oA4V2830sSNmM2f1ks5sWp74gaJpZM4OsEnW\n.\n. I'll try that...\n\nJames Mills / prologic\nE: prologic@shortcircuit.net.au\nW: prologic.shortcircuit.net.au\nOn Thu, Aug 10, 2017 at 1:07 AM, Arda Karaduman notifications@github.com\nwrote:\n\nIt seems you are right, thank you for the clarification !\nI'm checking the fn source code, it seems fn tool is executing docker as\na shell command.\nhttps://github.com/iron-io/functions/blob/d8871d1562c0e30fcf43f7e02b19a7\n06f366eafb/fn/common.go#L95\nThe proper solution to this would be to re write fn tool using docker\ngolang bindings, but as a short term solution, I am wondering if you could\nget this to work by passing DOCKER_HOST to fn build ? ie\nDOCKER_HOST={your docker host here} fn build\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/issues/631#issuecomment-321481916,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABOv-nnL3Dn248RgzQo96UzmeLJW7ayzks5sWrpEgaJpZM4OsEnW\n.\n. Yeah that doesn't work I'm afraid :/\n\n#!bash\n$ DOCKER_HOST=tcp://10.0.0.10:2376 fn build -v\nbuilding /Users/prologic/hello-faas/func.yaml\nRunning prebuild command: docker run --rm -v /Users/prologic/hello-faas:/go/src/github.com/x/y -w /go/src/github.com/x/y iron/go:dev go build -o func\ncan't load package: package github.com/x/y: no buildable Go source files in /go/src/github.com/x/y\nerror running docker build: exit status 1\nI think the main issue is the lack of using the Docker build API itself and sending context (contents of the working directory) up to the remote host as part of the image build. IIUC fn build should really be wrapping docker build right? Using the API proper will probably fix this.. Meanwhile my only work-around is to spin up a Docker machine on my Mac which is unideal as its woefully underpowered :) (tiny 11\" Macbook) -- hence the whole reason I have an entire cluster of machiens more grunty!. I see! I'll check this out and report back.\nDo we still want to keep this issue open to track making appropriate\nchanges to the build step so it doesn't assume a local Docker engine?\nJames Mills / prologic\nE: prologic@shortcircuit.net.au\nW: prologic.shortcircuit.net.au\nOn Mon, Aug 14, 2017 at 3:20 AM, Arda Karaduman notifications@github.com\nwrote:\n\nHello again,\nI've checked into this issue, it seems the problem is with\nhttps://github.com/iron-io/functions/blob/master/fn/langs/go.go#L29\nwhich tries to mount your local dir to the remote host via the -v flag.\nmoby/moby#4023 https://github.com/moby/moby/issues/4023\nwhich doesn't work. As a work-around, you can create your own Dockerfile,\nwhich would prevent this prebuild step.\nI'm linking an example project which has a known working Dockerfile for\nremote building.\nhttps://bitbucket.org/coze/query/src/dff81a3ab0a39f1c586efe394a377a\n382065ed0d/?at=custom-dockerfile\nThis one uses glide https://glide.sh/ for dependency management, but\nfeel free to use another one if you like.\nPS: you also need the .dockerignore to prevent your local vendor directory\nbeing copied over to the host.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/issues/631#issuecomment-322154543,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABOv-oNoudybU6P6bLtivgh-8HVF2VJeks5sYB9ugaJpZM4OsEnW\n.\n. Seems to work:\n\n#!bash\nprologic@Jamess-MacBook\nWed Aug 16 21:58:10\n~/hello-faas\n 0\n$ fn build\nBuilding image prologic/hello-faas:0.0.1\nSending build context to Docker daemon  4.096kB\nStep 1/8 : FROM golang:alpine\n ---> 310e63753884\nStep 2/8 : ENTRYPOINT /func\n ---> Running in 0582d30bb55a\n ---> dbb47fc13237\nRemoving intermediate container 0582d30bb55a\nStep 3/8 : RUN apk add --update git &&     rm -rf /var/cache/apk/*\n ---> Running in 717a21df83e0\nfetch http://dl-cdn.alpinelinux.org/alpine/v3.5/main/x86_64/APKINDEX.tar.gz\nfetch http://dl-cdn.alpinelinux.org/alpine/v3.5/community/x86_64/APKINDEX.tar.gz\n(1/5) Installing libssh2 (1.7.0-r2)\n(2/5) Installing libcurl (7.55.0-r0)\n(3/5) Installing expat (2.2.0-r1)\n(4/5) Installing pcre (8.39-r0)\n(5/5) Installing git (2.11.3-r0)\nExecuting busybox-1.25.1-r0.trigger\nOK: 23 MiB in 17 packages\n ---> 7c2b194a58f2\nRemoving intermediate container 717a21df83e0\nStep 4/8 : RUN mkdir -p /go/src\n ---> Running in d47c377284d1\n ---> 96746ddf0dea\nRemoving intermediate container d47c377284d1\nStep 5/8 : WORKDIR /go/src\n ---> ac4dcefcf6ed\nRemoving intermediate container 9367fd70cbe8\nStep 6/8 : COPY . /go/src\n ---> 1bbf130cc55e\nRemoving intermediate container cf4dfd502619\nStep 7/8 : RUN go get -v -d\n ---> Running in 08e16dabdf8a\n ---> 621aa64f1887\nRemoving intermediate container 08e16dabdf8a\nStep 8/8 : RUN go build -o /func .\n ---> Running in 12c3b6bf8dc7\n ---> b43cefdc021c\nRemoving intermediate container 12c3b6bf8dc7\nSuccessfully built b43cefdc021c\nSuccessfully tagged prologic/hello-faas:0.0.1\nFunction prologic/hello-faas:0.0.1 built successfully.\nContents of Dockerfile and tree output:\n``#!bash\nprologic@Jamess-MacBook\nWed Aug 16 21:58:26\n~/hello-faas\n 0\n$ tree\n.\n|-- Dockerfile\n|-- func.go-- func.yaml\n0 directories, 3 files\nprologic@Jamess-MacBook\nWed Aug 16 22:00:34\n~/hello-faas\n 0\n$ cat Dockerfile\nFROM golang:alpine\nENTRYPOINT [\"/func\"]\nRUN \\\n    apk add --update git && \\\n    rm -rf /var/cache/apk/*\nRUN mkdir -p /go/src\nWORKDIR /go/src\nCOPY . /go/src\nRUN go get -v -d\nRUN go build -o /func .\n```. I believe it did. Closing.... Yeah I can't think of any good reasons why DinD should be the default here\nor why you'd want functions to run inside Docker inside Docker.\nIt also means if you want to scale those functions you'd have to scale the\nDinD environment too Uggh\nJames Mills / prologic\nE: prologic@shortcircuit.net.au\nW: prologic.shortcircuit.net.au\nOn Thu, Sep 7, 2017 at 9:12 AM, Dylan Stamat notifications@github.com\nwrote:\n\n@prologic https://github.com/prologic I believe the original motivation\nof using DinD is explained here\nhttps://github.com/iron-io/functions/blob/3c4261ae37accf6c51a6aee6b216f58c84621d6c/docs/operating/options.md.\nIt looks like there is a way to run directly, but the default being DinD is\ndefinitely a talking point.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/issues/632#issuecomment-327846545,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABOv-v-t9f9t_q0gc5_8WO_RjRe1nEYiks5sgBSIgaJpZM4O0cvQ\n.\n. It helps if you have a non-broken LB; restarting Traefik fixed things (separate issue why Traefik was playing up): Now I get a working API:\n\n#!bash\n$ curl -s -q -o - https://f.mydomain.com/ | jq '.'\n{\n  \"goto\": \"https://github.com/iron-io/functions\",\n  \"hello\": \"world!\"\n}. Without https eh? Okay sure I'll try to figure out how to not make my env secure :D. Okay so your hunch was right :)\n#!bash\n$ API_URL=http://node1.mydomain.com:18080/ fn apps create myapp\nmyapp created\nI'll retitle the issue. Let's fi this broken SSL support please :). NB: This is:\nLB (traefik) -> functions service\n      HTTPS  ->            whatever. Also the current situation sucks because my environment redirects all http traffic to https and there is no way to turn this off specifically (lack of exclusion rules support) for a particular service/endpoint so functions/faas will not play nicely right now.. Will do!\nOn Thu, Sep 28, 2017 at 18:12 Arda Karaduman notifications@github.com\nwrote:\n\n@prologic https://github.com/prologic sorry for the long delay ! We\njust released a new version of the fn tool which should solve SSL issues.\nPlease give it a try and let us know if this works for you !\nThanks !\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/issues/635#issuecomment-333004396,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABOv-lNVE1jCoKfYXJyqK2xkv1Q8HFZTks5snEP7gaJpZM4O5yyo\n.\n-- \n\nJames Mills / prologic\nE: prologic@shortcircuit.net.au\nW: prologic.shortcircuit.net.au\n.  What was done to fix this?\nOn Wed, Nov 1, 2017 at 19:08 Arda Karaduman notifications@github.com\nwrote:\n\nclosing this for now, please feel free to open again if still not working\nfor you \ud83d\udc4d\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/issues/635#issuecomment-341297034,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABOv-m6PkGdi-YKSEYze8rjRa1euJtGaks5sySQmgaJpZM4O5yyo\n.\n-- \n\nJames Mills / prologic\nE: prologic@shortcircuit.net.au\nW: prologic.shortcircuit.net.au\n. Cool \ud83d\ude00\nOn Wed, Nov 1, 2017 at 19:17 Arda Karaduman notifications@github.com\nwrote:\n\nWe released a new version on sept 28th.\n650 https://github.com/iron-io/functions/pull/650\nYou need to update your fn tool and iron/functions container to get the\nnew version.\nseems to be working (duplicate issue closed by OP)\n649 https://github.com/iron-io/functions/issues/649\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/issues/635#issuecomment-341298250,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABOv-ra4KVzz2OSBdIGq1NTCrkIE5ivBks5sySZKgaJpZM4O5yyo\n.\n-- \n\nJames Mills / prologic\nE: prologic@shortcircuit.net.au\nW: prologic.shortcircuit.net.au\n. go build is failing similarly:\n#!bash\n$ go build .\napi/server/server.go:15:2: code in directory /Users/prologic/go/src/github.com/ccirello/supervisor expects import \"cirello.io/supervisor\"\napi/runner/task.go:12:2: cannot find package \"github.com/docker/docker/cli/config/configfile\" in any of:\n    /usr/local/Cellar/go/1.8.3/libexec/src/github.com/docker/docker/cli/config/configfile (from $GOROOT)\n    /Users/prologic/go/src/github.com/docker/docker/cli/config/configfile (from $GOPATH). I guess the Circle CI badge is a lie :( -- Or assumptions are made about the environment that are non-standard :/. \ud83d\ude10\nOn Thu, Aug 17, 2017 at 01:07 Arda Karaduman notifications@github.com\nwrote:\n\nThank you for the report. It seems builds got broken after the\ndocker/moby renaming\nhttps://blog.docker.com/2017/04/introducing-the-moby-project/.\nThe project was also in the process of migrating to go dep tool.\nI'll update this issue once we fix the issue(s).\nLast successful CI build is from 4 months ago\nhttps://circleci.com/gh/iron-io/functions/2064. It was working then.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/iron-io/functions/issues/636#issuecomment-322999449,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABOv-go-Ul6_s-gIdFgRPF3UNuE5PAIfks5sY_S4gaJpZM4O5y1x\n.\n-- \n\nJames Mills / prologic\nE: prologic@shortcircuit.net.au\nW: prologic.shortcircuit.net.au\n. ",
    "mytototo": "I was thinking about service discovery and configuration for functions, more than as a database layer.. ",
    "dmportella": "It should be possible with a lot of changes. ",
    "Tofull": "Hi there,\nIf you want an active development serverless project, you can use the openFaaS one (https://github.com/alexellis/faas) as an alternative to ironFunction. \nFaaS is working on multi cloud (public and private) and kubernetes as well.\nIt provides synchronous functions as a service. And asynchronous ones too (where ironFunction failed see my issue).\nYou can make a  or start reading the python tutorial here.. @rkononov of course ironWorker is working well for async processing, as the process is queued and de-queued when an ironWorker is available and the function is also deferred. But it's bugged when you try to pass data into it. Otherwise, please give me an explanation about my issue.\nI am sure ironFunction is a enterprise-useful project. It is really simple to use, and your cli allows a lot of good features (building an app from scratch only by managing routes like LEGO\u00ae is especially powerful). @dylanz Thanks for the informations. Great blog article ! Keep working hard. I won't be surprised of the ironFunctions' success for Machine Learning community. ;). ",
    "rkononov": "IronWorker is perfect for async processing, even for enterprise level projects (CNN/Philips/Veritone). In IronWorker you could pass payload using this approach - http://dev.iron.io/worker/reference/payload/\nNo idea about IronFunctions.. ",
    "dylanz": "@Tofull We're ramping up development on IronFunctions and you should see a lot of improvements coming soon.  We're highly focused on keeping the project open and modular (for example, you may want to collect metrics somewhere else, and not be tied to Prometheus).  So, stay tuned!\nIn regard to deep learning, we recently started supporting GPU instances on AWS via IronWorker (but of course that's our async, non-open source product).\nThanks for checking in!. @elitan Good Q!  We reached a point with the project we're happy with so we ended up stopping active development on it (we have a few production installs that suite us fine at the moment).  That said, we're still planning on actively maintaining things and pull requests are definitely welcome.. @prologic I believe the original motivation of using DinD is explained here.  It looks like there is a way to run directly, but the default being DinD is definitely a talking point.. John!  It should definitely be an open Slack channel and I'm trying to figure out how to make it open as we speak :). Hello!  You should be able to integrate directly into Docker Swarm or Kubernetes.  Some more information found here (the bottom of this page):  https://github.com/iron-io/functions/blob/master/docs/README.md. Hello!  You could definitely run containers directly on ECS and not need to manage actual instances if you used Fargate (otherwise you'd need to manage the instances).  You might want to check that out if you'd like to go the Docker route.  Let me know if you have any questions!. ",
    "elitan": "Question still relevant. Any update?. ",
    "alexellis": "To the point raised by @Tofull OpenFaaS also supports asynchronous workloads. See the hands-on labs for more: https://github.com/openfaas/workshop . ",
    "TaekminKwon": "I think I have the same issue.\nI can't install  github.com/moby/moby/cli/config/configfile\n. I was searching, I saw the same issue posted in last Nov. \nContributor seemed to try to fix the issue.\nHow is it going on? I wonder when branch, fix-deps is going to merge with master state and that issues are closed?\n. @c0ze I downloaded ironfunctions by brew install command. And I confirmed it works well. (tried Quick start)\nHow does it work with the issue?\n. ",
    "JJ": "Seems to be a problem with Ubuntu 14.04 https://github.com/opencontainers/runc/issues/16\nNot too clear what to do about it. Seems to have been patched a long time ago. . ",
    "wrsuarez": "I should add that setting the export for the API URL on my laptop to anything but 8080 doesn't work. Using https, http with port 80, all result in the same error. @coze I'll check it out right now\n. @c0ze call this one closed. Thank you! \ud83d\udc4d . ",
    "kunihiko-t": "@c0ze Thanks \ud83d\udc4d . Thanks! Let me check it out.. Thank you!. Hi, Arda!\nYes, we need \"Bearer\" at the beginning of Authorization header.\nPlease refer following line.\nhttps://github.com/iron-io/functions/blob/c3d25a9c11c284b9e94cd0f5f7643c7ebd8668ec/fn/commands/routes.go#L265\nRegard to client side, how about having JWT_AUTH_KEY in the configuration file?\ne.g. ~/.ironfconfig.yml when the user has ~/.ironfconfig.yml override the former.\n. Hi, @c0ze.\nI think I had misunderstood about what you asked.\nAs for two token clash,  middleware authenticates /v1/* access using with \u201cJWT_AUTH_KEY\u201d env variable.\nFor app authentication, it works using with \u201cjwt_key\u201d in YAML file specified by user, and authenticate the request which doesn\u2019t have /v1/ prefix.\nSo I think it won\u2019t clash. But to avoid confusion, we need to consider an env variable name. \nIn addition What do you think about removing IRON_TOKEN?\nIt will clash with jwt token because both of them using same header.\nI searched source files, but I cannot find any function using IRON_TOKEN.\nI also sent a message in Slack :). Hello, @c0ze.\nGreat!!\nI've tried to run some test with make test-tag command and I caught errors.\nI think /api/server/server_test.go should have\n// +build server full_stack\ninstead of \n// +build full_stack\n// +build server\nAccording to this document, multiple lines represent AND condition\nhttps://golang.org/pkg/go/build/#hdr-Build_Constraints\nRegarding test with server tag, /api/server/server_auth_test.go needs server tag for required functions.\nAlso /api/server/apps_test.go needs full_stack tag for include setLogBuffer function.\nSo I think following files should have // +build server full_stack on top.\napi/server/apps_test.go\napi/server/runner_test.go\napi/server/server_auth_test.go\napi/server/server_test.go\nBut If we change those files, make test TAG=server will run some full stack tests.\nSo should we move https://github.com/iron-io/functions/blob/93150609f175292b93d9b705bdb164ada4b379ea/api/server/server_auth_test.go#L59 to another file?\nThanks :)\n. @c0ze It works! Thanks!\nRegarding /tmp/func_test_bolt.db,  teardown func which has os.Remove is here ( https://github.com/iron-io/functions/blob/b5623941e73fc3546a338a344a34ec67a86993e2/api/server/server_test.go#L131\n ) and it has server tag.\nTherefore it is called when we run make test-tag TAG=server .\nWhen we run with make test-tag TAG=integration or make test  it won't be included on test.\nSo I think os.Remove should be put on the another file.. ",
    "reiz": "@c0ze Many thanks! That helps me a lot. . ",
    "sss0350": "I'm checking your hotfunction example and trying to make it running on my environment.\n(https://github.com/iron-io/functions/tree/master/examples/hotfunctions/http)\nBut it seems the idle_timeout is not possible setting from fn cmd.\nI set it in func.yaml ( ex: idle_timeout:30 ) , and inpect it using fn routes inspect. But it always get 0.\nAnd find this post , it seems you guys are working on it . Let me know when there's a patch of fn cmd.\nAnd will be really nice if user can set on function-ui.\nJust let you guys know my result.  Thanks again.\n. I just get it a quick try this afternoon at my office, I can set idle_timeout from cmd. \n1. fn routes update xxx xxx --idle_timeout=30s\n2. fn routes inspect xxx xxx (can see idle_timeout set to 30s) \nAnd trigger your hot function examples ( https://github.com/iron-io/functions/tree/master/examples/hotfunctions/http ), but find the containers still not keep alive within 30s. \nAfter trigger function , and I check this hot function container thru docker ps | grep myfnname , \nit seems this container still be killed immediately after trigger. It should be alive within 30s , right? \nDid I misunderstand anything here? Or any other steps should be done to make a hotfunction?\n. Hello @c0ze,\nThanks for your quick reply!  At first, I'm getting some trouble to make it work. fn command still can't get API_URL from my environment variables. \nAnd then I find your release page , there's a bug fix about API_URL.... 3 days before.... \nAnd I download it, put it to /usr/local/bin , it works like a charm! \nI'll detail testing all other functions tmr , thank you!. Hey @c0ze,\nI can get http header with System.getenv(\"HEADER_X\") in java as you provided.\nBut how to I get cookies values ? I can't find a way to get it , since we need to rely on cookie to do some authorization. Could you give me a hint?. Kubernetes-quick stack on openshift Origin , can't really persist bolt db data after restart pod. \nSo I try to mount app/data to OS persistent volume (like NAS) , should be able to access across cluster nodes. It works when I start only one iron-function pod, but will fail when I try to simultaneously create two pods. One pod will fail to start and show \"Error on bolt.Open\" , I think it might be some kind of lock , when another pod try to access bolt DB. Is this a bug? I think somehow iron need to persist data on cluster environment. (over 2 running pods, need data sync). Thanks , per your suggestion , I try to deploy kubernates production stacks as following,\n1) change configmap value to: \nMQ_URL: redis://redis-master\nDB_URL: postgres://postgres:mysecretpassword@postgresql-master/?sslmode=disable\n2) Add some openshift setting , edit yaml file (add service account) , add openshift privilege setting to service account ,and finally mount a persistent volumes to make db storage persistent after restart.\n3) Add routes to function pod , to make function expose url static everytime.\nI now can successfully running 3 pods on my project , function , redis and postgreSQL. And deploy function on it also. \n. I saw a similar discussion onopenwhisk  project (https://github.com/apache/incubator-openwhisk-deploy-kube/issues/110), it seems there are two approaches of creating containers 1) DockerContainerFactory 2) KubernetesContainerFactory , does it mean ironfunction might use DockerContainerFactory way to create containers?. Looks like the same issue I ask before , check it out: \nhttps://github.com/iron-io/functions/issues/665. Hi @eugenegwon,\nLet me clarify a bit here , I know how to specify a \"new\" version number when route creating. And how to check docker image version.\nThe thing is , during developing period, we will build docker images again and again using the same version number (ex: 0.0.1) When local node already load this docker images, ( ex: test-imageName:0.0.1 ) it won't try to pull images again since it's already exist in this node repo. I know this is normal , but docker images actually can specify \"latest\" string as version number , to pull images if any update happened.\nMy question is , is there any similar way to let iron pull images \"only\" when images update.  It seems I can't use \"latest\" as version number thru iron command or UI.\nThank you for help.. Thanks , I'll give a try. \nBut local node will be occupied with lots of docker function images I think :0 \nWon't it be nice if we can specify latest as version number ? . ",
    "JosephShering": "It's similar sure, but I tried to change the API_URL with no avail. I get a parse error for 127.0.0.1:8082. ",
    "raky35": "panic: runtime error: invalid memory address or nil pointer dereference\n[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x46a74b0]\ngoroutine 120 [running]:\ngithub.com/ethereum/go-ethereum/eth/filters.(*EventSystem).eventLoop(0xc42186ac80)\n    /Users/travis/gopath/src/github.com/ethereum/go-ethereum/eth/filters/filter_system.go:434 +0x330\n. ",
    "sekullbe": "This is an old issue, but I found it googling for a solution to a panic crash while running 'fn apps create myapp' as well.  I had the container running on a different port and specifying a correct API_URL fixed the problem.\nJust hoping to help the next person who comes along :). ",
    "eugenegwon": "you can specify docker image version using Iron Function's API. such like this : \ncurl -ss -X PATCH --header 'Content-Type: application/json' --header 'Accept: application/json' -d '{\"route\":{\"image\":\"DOCKER_IMAGE_URL:NEW_VERSION_NAME\"}}' http://IRON_FUNCTION_SERVER:8080/v1/apps/APP_NAME/routes/ROUTE_NAME\nso... simply call the Iron Function's API after build job finished.\nIf you want to check the current version of docker image, then call API like this :\ncurl -ss http://IRON_FUNCTION_SERVER:8080/v1/apps/APP_NAME/routes/ROUTE_NAME. ",
    "meysam001": "@c0ze  thank you it worked.. I have run kubectl port-forward functions-65c64ddf68-ml9nz 8080 agian, then I have wait for 30 minutes. But it was not happening.\n\n. I ran again fn command  a few seconds before, the output was changed : \n\nHas the problem been solved?\n. It worked! Thanks a lot @c0ze. You are a great man :100: . I'd like to run it on Kubernetes directly.\nIs it possible to run on Kubernetes without docker container? . I have create the func.yaml file: \nname: my_docker_username/hello\nversion: 0.0.1\npath: /hello\nbuild:\n- docker run --rm -v \"$PWD\":/worker -w /worker iron/php:dev composer install\nWhen I had run fn build, I gave the error:\nerror running command docker run --rm -v \"$PWD\":/worker -w /worker iron/php:dev composer install (exit status 1)\nWhat is wrong?. ",
    "si458": "is the anyway for you to update functions to support nodejs6.10? \nas its been around for a year now, \nand its sorta mainstream as 4.3 is now past its sell by date. ",
    "imacks": "good to know. to have access control to /v1/apps (deploying and updating apps),  what kind of middleware will i need to write? is there a guide somewhere?. hmm i can't find the name of the env...help pls? \nfor my use case, i would really need a per-user jwt token as described before. Is this already on your roadmap? I would certainly like to help on this feature if you think it's a good idea.. tks that certainly helps. I'll try to implement users then.... ",
    "hurnhu": "my current work around was editing the docker file to the following\n```\nFROM python:latest\nWORKDIR /function\nADD . /function/\n ENTRYPOINT [\"python3\", \"hello.py\"]\nRUN pip3 install -t packages -r requirements.txt\n```\n. ",
    "ouchiko": "https should be possible with Caddy straight out of the box.  Define the iron hosts and proxy via Caddy.\nhttps://github.com/iron-io/functions/tree/master/examples/caddy-lb\nEdit the Caddyfile and it'll auto-generate via letsencrypt so you're SSL cert is done?. ",
    "auyer": "The failed tests are unrelated to the PR. All tests in the master branch are failing since pull/669\nThe CLA assistant Bot seems to be unconfigured. I got the link from a different PR, but there is no other mention of the CLA in the Project. A link to it should be included in the CONTRIBUTING.md.. "
}