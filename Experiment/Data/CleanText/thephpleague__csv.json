{
    "nyamsprod": "Implementing these changes would break the API and the added values is not worth it.\n. Hi, \nAs it stands the library was not design to validate CSV. So detecting CSV controls is out of the scope of the library, for now.\nCSV documents come in essentially 2 forms, those you create and those you import from outside your controlled environment.\n- The first type, I imagine you do know how they are build so the current behavior is not an issue. \n- The second type is to be checked and validated against what the provider documents when being used by the library.\nThis means that whoever is providing you some data using CSV should tell which controls is being used and how the CSV is being construct just like with any other data transfer format. If the information is not given you should contact the provider and ask him/her to give it to you!\nSo you end up with the first situation where you do know the CSV constrols without processing the document. If processing fails then it's either a bug in the library or the API documentation is wrong!!\n\nJust grabbing the first line and counting occurences of valid delimiters for a csv file should cover 95% of the cases. Open office lists tab, comma, semicolon and space as valid delimiters for csv\n\nWhat processing software like Open office do is giving you hint or suggestion, the final decision is always made by you because sometimes (often I may say) they are incorrect.\n. @MarcusDalgren \nI have flag your issue as enhancement and I'm working on adding your feature request but I have some questions and maybe you could help me shaping the feature with your feedback. \nI've created a function called detectDelimiter and it works like this: \nphp\n$nb_rows = 5; //the numbers of rows to parse to detect the delimiter by default $nb_rows = 1;\n$additional_delimiters = [\"\\s\", \"|\"]; //additional_delimiters (\",\", \";\", \"\\t\") are already considered\n$csv = new Reader('/path/to/my/csv/file');\n$res = $csv->detectDelimiter($nb_rows, $additional_delimiters);\nNow the crucial part is what the return value $res will be. I have selected 2 options which are the following:\nIn the first option $res return a scalar value.\n- $res is equals to null if no delimiter is found;\n- $res is equals to false if the CSV is inconsistent meaning the CSV uses more than 1 delimiters; \n- $res is equals to a single character which is the uniquely found delimiter;\nusing this first option you can do something like this \nphp\nif (is_null($res)) {\n    echo 'no delimiter detected';\n} elseif (false === $res) {\n    echo 'the CSV is inconsistent it uses several different delimiters';\n} else {\n    $csv->setDelimiter($res); \n}\nIn the second option $res return an array. \nThis array will contained the founded delimiters.\n- If no delimiter is found then the array will be empty. \n- The more delimiters found the more value will be in the array. So an inconsistent CSV will have an array which size will be greater than 1.\n- The delimiters in the array are sorted depending on the number of rows found\nphp\n$nb_delimiters = count($res);\nif ($nb_delimiters == 1) {\n    $csv->setDelimiter($res[0]);\n} elseif ($nb_delimiters > 1) {\n    echo 'the CSV uses ', implode(' ', $res). ' delimiters'; \n} else {\n    echo 'no delimiter detected';\n}\nCan you tell me which version you prefer and why ? Of course if you have a better solution it is more than welcomed :+1: \nOf note: \n- the more rows and/or additional delimiters you had, the more time consuming the method will be!\n- If the CSV contains only 1 column, this method will return null or an empty array.\n- this method result should definitely be use as a hint and the developer should be aware of it before using it, My first comment is still valid even thought this method cover your 95% cases.\n- this method still depend on the CSV enclosure and escape properties. This means that you may end up with different results if you change those properties.\n. Hi,\nI have just push the branch with the method in it. As of this writing it uses the array syntax. \n- about the \\s this is an example. I don't think someone would use that really ? :) \n- about the exception since this is a hint I thought throwing exception for a hint method is too much. But I can be wrong. This is the same tought that I had that's why I did not want to implement something like a  getLastErrorCode/getLastErrorMessage \n. This is a first attempt on introducing generators. \n- I still don't know how to test the \\Generator::send method behavior in regards to the yieldAll method. \n- How can we make the test pass in PHP 5.4 since we introduced the yield key which is not recognized in PHP 5.4 ?\n- it would seems that in hhvm we also stumble on a error ?\nany clue, advice ?\n. http://3v4l.org/8SsXj\nI think the problem is not PHPUnit but the yield construct which is not recognized before PHP5.5 so until the required version is not set to PHP 5.5 the parse error will remain whatever strategy we use to load the method.\n. @philsturgeon This should be resolve in upcoming version 8 with the League\\Url deprecating PHP5.4 support. The bug is re-open but will be tackle when League\\Csv v8 will be in coding stage\n. After discussion on issue #131 regarding the use of generator for the package I came to the conclusion that using generators will not add any value to the current package as it is so I'll close once again this issue\n. The feature is now merge into the master\n. Hi,\ncould you change you pull request and add this ? so that the latest phpunit version is always downloaded\njavascript\n    \"require-dev\": {\n        \"phpunit/phpunit\" : \"*\"\n    },\n. Hi,\nThanks for using this library.\nAre you sure that the client is providing you with a CSV since: \n- A CSV requires the 3 controls to be different otherwise it is not a CSV. \n- Usually the delimiter is the only CSV controls that really differs from one provider to another.\nForm what I understand, it would seem to me that you need something like SplFileObject::fscanf to correctly parse you data.\nEven thought I would not recommend it I think you can safely use the library by setting each CsvControls to a empty string too \nphp\n$reader->setDelimiter(\"\\s\");\n$reader->setEnclosure(\"\\s\");\n$reader->setEscape(\"\\s\");\n. Hi,\nI've made a single change from \"\\s\" to \" \"  and It would seem to be working for me\nphp\n$reader = Reader::createFromString($csv);\n$reader->setDelimiter('|');\n$reader->setEnclosure(\" \");\nI got this as output\n``` php\n array (size=3)\n  'company' => string '2446277' (length=7)\n  'person' => string '930 5554' (length=8)\n  'job' => string '_ A' (length=3)\narray (size=3)\n  'company' => string '2446\"542' (length=8)\n  'person' => string '9642\"096' (length=8)\n  'job' => string 'fdsa\\fdsafas' (length=12)\narray (size=3)\n  'company' => string '244\"6542' (length=8)\n  'person' => string '9642'096' (length=8)\n  'job' => string 'fdsaf\n' (length=6)\n```\nNotice the return carrier in the last line :8ball:\n. @dakira I believe you can have a safe workaround using this technique \nhttp://nyamsprod.com/blog/2015/qa-enforcing-enclosure-with-leaguecsv/\n. yes you could use stream filters for instance to achieve this\n. Once again this is not a library limitation but a PHP limitation \ud83d\udc4d \nhttp://php.net/manual/en/splfileobject.setcsvcontrol.php\n. @jsandeo glad to hear you found a stable solution to your problem :+1: \n. @ezintz since I don't know what I'm wrong about I can't help you. FWIW  this issue has been resolved in v9 so I don't really know what we are still discussing about.. @dakira no you can not omit them, please read PHP documentation link in my previous comment, if you omit them PHP will use default values. \nFor the fix again read the v9 documentation there are filters to help with interoperability. They do not resolve all PHP's shortcoming but they get around pretty much the most significant ones.\n. @ezintz sorry to bring this to you but your are wrong the only thing the documentation tells you is that by default if no specific control is given PHP will fallback to the one discribed \n[ string $delimiter = \",\" [, string $enclosure = \"\\\"\" [, string $escape = \"\\\\\" ]]]\nSo not specifying them does not mean they are not set it only means that PHP will use the default value.\n. a simple workaround is to extends SplFileObject and write your own SplFileObject:fputcsv method using SplFileObject::fwrite.  this is simple and clean... anything else will lead to unexpected errors... my 2 cents... or use another library that does not rely on PHP's native function to write CSV to the file.. Good remark but how would you want the library to deal with null value ?\nAs of now if you use the the Reader class method the null value is used as a filled data with no special meaning.\nSo taking your example we could:\n- skip the value and have the resulting CSV line contain only 3 variables.\n- convert null value into an empty string so we do keep 4 cells but the third cell will be empty.\n- or just keep the current behavior that do require you to sanitize your data before conversion.\nOf note: if you re-import the CSV data in the first 2 cases the resulting import data won't be equals to the original one so in thoses cases you end up with data cohersion!!\n. I've just added a new branch to deal with your issue. Because everyone will want to deal differently with the null value. I'm letting the developer choose how the library should handle the value by introducing: setNullHandling and getNullHandling methods into the Writer class. the setter method will take one of the newly introduced constants:\n- Writer::NULL_AS_EXCEPTION the default/legacy behavior that throw the exeception;\n- Writer::NULL_AS_EMPTY the method will convert null value into empty string;\n- Writer::NULL_AS_SKIP_CELL the will filter out each null item found;\nSo for your behavior to work you will be able to do something like this in the near futur.\nphp\n$writer->setNullHandling(Writer::NULL_AS_EMPTY);\n$writer->insertOne([\"one\", \"two\", null, \"four\"]); // the null value will be automatically converted into an empty string\nFor Backward compatibility, by default if the setNullHandling method is not use the class will behave with the Writer::NULL_AS_EXCEPTION mode on meaning that a RuntimeException will be thrown.\nTell me what you think and depending on your feedback I'll merge the solution into the master branch.\n. A quick follow up just to say that in the upcoming v7 this functionality is removed from the Writer class and is now implemented as a pluggable system. Please check the migration guide for more information\n. tl;dr: This is not a bug or an issue, this is expected behavior.\nTo better understand what I mean let's issue a simple MySQL SQL statement:\nphp\n$stmt = $dbh->prepare(\n    \"SELECT id, email, name\n    FROM `users`\n    WHERE `id` % 3 = 0\n    ORDER BY id ASC\n    LIMIT 10 OFFSET 3\");\n$stmt->setFetchMode(PDO::FETCH_ASSOC);\n$stmt->execute($query);\n$res = $stmt->fetchAll();\nThe LIMIT and OFFSET are applied on the SQL search result not on the whole table data. So OFFSET 3 means that the third result row will be the first to be return, it does not indicate that the table third row is the first one to be return.\nThe Reader query options were build with the same approach. If the table content was contained in a CSV data, the following code would yield the same results as the SQL query above assuming that:\n- the first column contains the user id;\n- the fourth column contains the user email;\n- the second column contains the user name;\nphp\n$reader = new Reader('/path/to/users.csv');\n$reader\n    ->addFilter(function($row){\n        return $row[0]%3 == 0; \n    })\n    ->addSortBy(function($rowA, $rowB){\n        if ($rowA[0] > $rowB[0]) {\n            return 1;\n        } elseif ($rowA[0] < $rowB[0]) {\n            return -1;\n        }\n        return 0;\n    })\n    ->setOffset(2) // because offset starts at 0 not 1!\n    ->setLimit(10);\n$res = $reader->fetchAll(function($row){\n        return [\n            'id' => $row[0],\n            'email' => $row[3],\n            'name' => $row[1],\n        ];\n    });\n- The addFilter behave like a SQL's WHERE clause\n- The addSortBy behave like a SQL's ORDER clause\n- The setOffset behave like a SQL's OFFSET clause\n- The setLimit behave like a SQL's LIMIT clause\nTo be totally complete there's another difference between using the Reader::query and the Reader::fetch* methods apart from the fact that the first method returns an iterator and the later an array. \nThe Reader::fetch* re-index the result, not the Reader::query method. So in your case this means that the third result row index if using the Reader::query method may well be 600. It really depends on you filters and on your CSV row numbers.\n. Stream Filter API is added in version 6.0\n. Hi,\nthanks for the typo, it will be corrected as soon as the new bug fix version is out.\n. the documentation has been updated accordingly. thanks\n. Hi,\nthanks for using the library. As it stands row consistency check is possible in the Reader class using both the fetchOne and the addFilter methods. In the example below, I'm not throwing Exception but I'm skipping the invalid rows, you can, of course change this behaviour to have the callable attached to the addFilter throws exception if it does not return true.\nphp\n$reader = new League\\Csv\\Reader('path/to/csv');\n$nbColumns = $reader->fetchOne();\n$reader->addFilter(function($row) use ($nbColumns) {\n    return count($row) == $nbColumns;\n});\n$reader->fetchAll(); //only the valid rows will be return\nAs for the Writer class this check is not so difficult to implement. \nI'm going to look at it but only for the Writer class but you can also make a pull request since you have already work on a similar feature on your own.\n. I have a question though... Following your implementation we agree that for backward compatibility. The Writer class is by default in non strict mode. \nSo let's look at the code below, how would you handle it ?\nphp\n$writer = new \\League\\Csv\\Writer('/path/to/csv');\n$writer->insertOne(['cell1', 'cell2', 'cell3']);\n$writer->setStrictMode(true);\n$writer->insertOne(['cell1', 'cell2']); //this should work or not ?\n$writer->setStrictMode(false);\n$writer->insertOne(['cell1', 'cell2', 'cell3', 'cell4']);\n$writer->setStrictMode(true);\n$writer->insertOne(['cell1', 'cell2']); //this should work or not ?\nIn other word when is $column_count set/reset is it:\n- after each $strict_mode change ?\n- or when the first insert is done ?\nTo remove any ambiguity would it be more simple to just set the $strict_mode AND the $column_count ?\n. Yes the code is updated in the consistency branch to simplify the use. IMHO The strict mode setter and getter by itself does not provide enough informations to help the developer control the CSV insertion mechanism.\nThe property in itself is not enough clear, what is strict ? The column count, the column type, many things could be strict ? the term in itself is vague. What we are really looking for is to set and fix the column count during row insertion. So the best way to do this is to enable a setter/getter that only affect this property.\nphp\n$writer = new \\League\\Csv\\Writer('/path/to/csv');\n$writer->setColumnCount(3);\n$writer->insertAll([\n    ['cell1', 'cell2', 'cell3'],\n    ['cell1', 'cell2'],  //will throw an InvalidArgumentException\n]);\nBy default and for backward compatibility the $column_count property is set to -1.  So at any given time a developer can set or remove the column count check by setting the property to a number equals or greater that -1.\nI think this approach is simpler as :\n- it is straightforward;\n- it removes needles restrictions imposed by the library;\n- it gives full control of the writing process back to the developer;\nThe only drawback is that this solution requires the developer to know before hand the column count, which in my view he/she should know.\nAnd remember this restriction is only applicable on newly inserted rows. It does not in any way affected already inserted rows.\n. Yes this is insane but it is insane because of a bad/mad developer not because of a bad library :+1:  \nYour example is a edge case I think the library does not need or require to handle. When creating a League\\Csv\\Writer object you as a developer can set/get many properties and nothing prevents you from modifying theses properties because of your script logic, whatever that logic may be. If you restrict these changes then it would mean that the library is imposing a certain coding style to your work, which is not a good.\nIf you look at the SplFileObject::fputcsv nothing prevents you from setting different CSV controls for each row entered, but a normal developer would settle on one type of controller and stick to it until writing is finish. So it's a developer responsibility. \nThis is the same with SQL injection. PDO provides tools to reduce them but a bad developer can still use PDO so badly that SQL injections work.\n. I have some reservations about the boolean values... in PHP having true equals or meaning 0 hurts my eyes :D . \nThat being said, \n\n0 could have a special meaning too: set the column count to the first inserted row's column count.\n\nI though about this, and I had even implemented that then I removed it because I was uneasy with it, but I could be wrong about it. The question I asked myself is: What if the developer really wants an array with a length equals to 0. How would you be able to give that to him ? \nOnce again it's an edge case. But one that you would be unable to solve if you change 0 meaning. on the other hand a length of -1 for an array is impossible and if you look at other PHP classes or functions usually -1 means limitless (ie: the $count argument on the LimitIterator class). \n. > Well, an array with a length of 0 should be skipped. This array means a row with 0 elements, so if you translate it into CSV it equals to an empty line.\nExactly ... and a empty line into a CSV is not forbidden so even thought no sane developer would allow it the library should not disallow it. Otherwise will be back to square 1\n\nIf you restrict these changes then it would mean that the library is imposing a certain coding style to your work, which is not a good.\n\nYour boolean use is like trying to combine the strict mode behavior with the column count getter/setter methods. (setting and getting is one clear action). the boolean value does something entirely different they set a lazy column count \nSo maybe what you want is this \nphp\n$writer = new \\League\\Csv\\Writer('/path/to/csv');\n$writer->setLazyColumnCount();\n$writer->insertAll([\n    ['cell1', 'cell2', 'cell3'],\n    ['cell1', 'cell2'],  //will throw an InvalidArgumentException\n]);\nThe method will set the $column_count property according to the next inserted row and therefore will also validate the next line whatever length it has no matter the current $column_count property value.\nBut it that case you need to understand that issuing later on a setColumnCount may still change the $column_count property.\n. So let me implement setLazyColumnCount and get over with this then :+1: \n. Everything is merge and in the master branch unless a bug is found I'll put it in production before friday. In the meantime, you can test it by downloading the dev-master branch from packagist. I'll close the ticket when the new version 5.4.0 is release.\n. The version 5.4.0 has been released, I'm closing this issue\n. A quick follow up just to say that in the upcoming v7 this functionality is removed from the Writer class and is now implemented as a pluggable system. Please check the migration guide for more information\n. Tentatively accepting this; I reserve the right to reorganize as needed. Thanks! #34 \n. I think you may find an answer to your question by looking at #24 for empty  space. Or you can set the delimiter as follow:\nphp\n$reader->setDelimiter(\"\\t\");\n. Hi could you update your master branch and submit again your pull request ?\n. I must say that when I was developing the library I thought about including directly those filters into the library. But, after considerations, I choose to keep theses add-ons apart from the library because:\n- They are totally independent of the library (they only depend on PHP stream filter functions).\n- Someone could implement them differently (ie: The transcode filter for instance can be written to work with PHP intl or iconv extension)\nSo I would suggest creating a repo dedicated to these add-ons and suggest in its composer.json to install the league\\CSV to use them. What do you think ?\n. I understand your point, like I said, at some point in the dev... the extensions/add-ons where in the library...\nI forgot to mention that there's another major drawback to have theses extensions/add-ons directly into the library. Every time we will want to add/update/remove/bugfix an add-on without changing the library core functionalities we will have to update the library version.. which is a non-sense. Updating of fixing extensions/add-ons should not increase the library version number. \nThat's why putting them into an extension library is better. the extension could be added into the library documentation, even into the library composer.json suggest part and we keep a maximum of flexibility.\nI know it means requiring 2 repos in your project composer.json or downloading 2 libraries but it's worth it IMHO.\n. Lately I've been busy on the League\\Url repo. But now that the version 3 is out, I'll focus back on League\\Csv. Version 5.5 has been on the master for 2 months now without much bug reports :) so it's up to you... you can go ahaed and create another repo for the \"add-ons/extensions\" as I'm on vacation this week.\n. in the next major version the following filters will be bundle (version 9.0)\n\nCharsetConverter : to convert using the mbstring extension CSV document\nRFC4180Field: to improve CSV document interoperability . Hi,\n\nThanks, for you interest in the library. Adding a count wrapper is not as easy as it seems because we are basically using PHP stream capabilities. A CSV can be very small or extremely large. Attempting to count the actual rows can easily consume more memory than intended because the CSV must be stored completely in memory. That's the main reason the library has no count method.\nA simple or better solution would be to add this information in some metadata included in the CSV. Since they're no such specification in CSV it comes down to:\n- the CSV producer to write down this specification \n- the CSV consumer to develop a wrapper using the above specification and the current library.\nJust like with any other transport format (ie: JSON with, HAL-JSON or JSON-API for example)\n. What your are suggesting is already present in the library. I would suggest using the each method as it returns the number of rows iterate over as a result.\nphp\nuse League\\Csv\\Reader;\n$csv = new Reader('/path/to/your/csv/file.csv');\n$count = $csv->each(function() {\n    return true;\n});\nYou can of course attach all the querying options available in the library before calling the each method.\n. Alas no there is no quicker way ... or less memory intensive one. maybe something like \nphp\nuse League\\Csv\\Reader;\n$csv = new Reader('/path/to/your/csv/file.csv');\n$count = iterator_count($csv->query());\nBut I have some doubt... you could make some benchmark if you want ... but yes you can close as works for me :+1:\n. @dereuromark @motin adding the Countable Interface is a WIP in the next major release you can  have more information with PR #178 and the proposed API for v9\n. the Countable interface has been added to the Reader class in the upcoming version 9.0 . Hi,\nThanks for using the League\\Csv library. I think the problem is linked with the way the initial CSV was generated. The CSV controls are not set properly.\nI've made a simple test using the following code:\n``` php\nrequire 'vendor/autoload.php';\nuse League\\Csv\\Reader;\nuse League\\Csv\\Writer;\n$test = [\n    [\"superS3cret\"],\n    [\"S3cret with spaces\"],\n    ['SpecialChars\\!\"\\'@#$$%^&&*()@\\///\\\"'],\n    ['\"Secretstartingwithquotes'],\n    [\"'Secretstartingwithsinglequote\"],\n    [\"'Twosinglequotes'\"],\n    [\"S3cretwithsinglequote'init\"],\n    [\"S3cretwithcomma,init\"],\n    ['S3cretwithdoublequote\"init'],\n];\n//using the Writer object with the default CSV controls setting\n// we output the generated CSV \n// check how CSV controls are set for each examples\n$csv = new Writer(new SplTempFileObject);\n$csv->insertAll($test);\necho '', PHP_EOL, $csv, PHP_EOL; \n//using the Reader object we get the passwords back into a single dimension array\n$reader = $csv->getReader();\nvar_dump($reader->fetchCol()); //will output the password\n```\nIf you run this code you'll see that everything is fine.\n. Hi,\nThanks for using the library. You should have a look at the documentation example specifically at the Reader::each method, it will answer your question.\nOf note:\n- the library helps you import, export, parse, save, update CSV data but it's up to you to make the CSV available to the library through its classes constructors. \n- The library uses iterators to limit memory usage so memory is not a issue here.\n. starting with version 6.0 HHVM 3.2+ is supported\n. Thanks for the typo fixes ... I think there are more in the documentation :+1: \n. done\n. Could you elaborate with a gist containing your full code because I'm failing at trying to reproduce the bug\n. Okay understood... this is not a bug per se from the library. This is in CSV implementation. \nYou are using the [space] as the enclosure but according the CSV RFC if the enclosure is found in the CSV content to remove any ambiguity it is double.\n\nIf double-quotes are used to enclose fields, then a double-quote  appearing inside a field must be escaped by preceding it with another double quote.\n\nThis explain the result of having double space.\nHope this will help\n. The feature looks good. I have some suggestions to improved it:\n- rename the isValidArray into isToArrayObject\n- moveisToArrayObject into the League\\Csv\\Writer class since this method will only be used there and nowhere else.\n- make sure your follow the contributions rules\n. Another thing to consider is backward compatibility. \nImagine a class which supports __toString and toArray() methods. Which method do you think should be used first. \n- If we first use toArray() we introduce BC break meaning that we move from version 6.0.0 to 7.0.0.\n- On the other hand if we consider toArray() method for class that do not have the __toString method then we only make a 6.1.0 upgrade. \nWhatever we decide must be weighted carefully. Thoughts ? \n. The main problem with any approach is that toArray is a userland tacite agreement. It is not a PHP construct per se which is the case of __toString. So unless a toArray method is made available in a PHP interface its behavior is left to the implementor decision. \nSome developers use toArray to recursively created array from their object properties. So nothing prevent a user from using toArray with Writer::insertAll method for instance. On the other hand __toString behavior is documented by PHP itself.\nI would say that a way to circumvent this pitfall is to extends the Writer class and add the correct wrapper to takle the toArray method as a per project basis in the meantime ?\n. Ok as per the documentation there are several ways to instantiate the object I think you've just combined many of them. The problem may be related to that. I would suggest, simplify your code like below:\nphp\n$filepath = '/path/to/my/csv/file.csv';\n$csv = League\\Csv\\Writer::createFromPath($filepath, 'w');\n$csv->insertAll($csv_data);\nNothing more... it will work and the empty line should disappear. You do not need to use fopen first. by using the w open mode the library will try to open or create the file if it does not succeed a RuntimeException will be thrown.\n. The end line is put because of SplFileObject::fputcsv as per documentation: \n\nfputcsv() formats a line (passed as a fields array) as CSV and write it (terminated by a newline) to the specified file handle. \n. No need to PR this, there's a quick workaround for that:\n\nphp\nfunction outputWithoutEndingEOL(League\\Csv\\AbstractCSV $csv)\n{\n    return  rtrim($csv->newReader());\n}\n. As stated in the documentation the method only gives you a hint;\n- the detection depends on how you defined the other CSV controls;\n- the detection depends on how well formed your CSV is;\nOf note, by just looking at the line given I can not state which delimiter is the right one, both can be equally used. since the escape character seems to be wrongly used \n. You are missing the point, the method only gives you a hint and will never be bulletproof as detecting the one true real delimiter is almost impossible. This was discussed prior to adding the feature into the library. That is why the hint aspect of the method is clearly stated in the documentation.\n. you can make a pull request, I'll review it and merge it. I have no problem with that at all :+1: \n. > Next step would be how the library process the possible valid delimiters based on the amount of occurences we get now!? Do you have any (better) idea?\nRight now, what the library just do is sorting the found delimiters and returning them with the most found delimiter being the first one in the returned array. I don't see why you would want to change this behavior. A CSV is either consistent using only one delimiter or inconsistent using more delimeters. \nIn the first case, the current behavior is not a problem. In the second case, the library should not choose for the developer which delimiter is correct since they could all be correct or wrong. The CSV provider is the only person who knows the correct answer. You can not decide by applied your own subjective algorithm which delimiter is correct. A CSV is consistent or not that it. Any other situations should be handle in a case by case manner. IMHO, This is a developer responsibility nothing more, nothing less.\n. I understand your point of view but keep in mind that if the CSV is inconsistent the best solution is to ask the provider for the CSV true delimiter. \nAnd adding the delimiter \"weight\" information in the returned array would create a BC break \n. a BC break has been introduced in League/csv so it will go 7.0 hopefully next week or the week after. So we could take this opportunity to add the \"weigh\" information. We have 2 possibilities:\n- major BC break the return array looks like this\nphp\n[ \"'\" => 123, \"\\t\" => 12]\n//the key represents the the delimiter,  the value number of delimiter found.\nor\n- less BC break the return array looks like this\nphp\n[ 123 => \"'\",  12 => \"\\t\"]\n//the key represents the number of delimiter found, the value the delimiter\nI'm in favor of the latter as it brings less breakage... the code provided by the documentation for instance would still work. The only breakage would be the key index and meaning\nThought ?\n. great so its a done deal then as it is already fixed that way in the dev-master  :+1: I'll re-close this issue then \n. Indeed your right :+1: . How do you propose we resolve this issue ?  The only sane way to do so is to use the previous suggested output\nphp\n[ \"'\" => 123, \"\\t\" => 12]\n//the key represents the the delimiter,  the value number of delimiter found.\nthe only problem is that it brings BC break :-1:  What we can do in the meantime is document this bug and then fix it properly with a new version. Hopefully after I finish with 7.1 a 8.0 version will be introduced with this bug fix and a rewrote Reader class. What do you think about this roadmap ?\n. Another solution which would be less BC break would be to have the following output:\nphp\n[ \n    123 => \"'\",\n    12 => \"\\t\",\n     3 => [\",\", \";\"],\n]\n//the key represents the number of delimiter found, the value the delimiter\n//in case a of same occurence we return an array of delimiters\nThought ?\n. @stof @Heart1010 @cordoval \nAfter a good week-end thinking over this bug I think I found a fix ... so here's what I propose which won't even need a BC break :+1:\nWhen for the same occurence we get multiple answers then we will get a \"word\" instead of a single character this his how it will look like:\nphp\n$reader = Reader::createFromPath('/path/to/your/csv/file.csv');\n$delimiters_list = $reader->detectDelimiterList(10, [' ', '|']);\n//let's pretend that \"|\" appears as often as the \";\" delimiters will get the following result.\n$delimiters_list = [\n...\n     5 => \";|\",\n...\n];\nWe can take advantage of the language constructs and do the following:\nphp\n$list_all_delimiters_found = str_split($delimiters_list[5]);\nIf you are only interested in having only one result you can do as follow:\nphp\n$delimiter = array_shift($delimiters_list)[0]; //which will always return the first character found\nWhat's great with this last piece of code is that if we decide to switch from a word to a real array in v8 this code will still work out of the box.\nIf you like this fix please respond here ASAP so I can implement it and release v7.1\n. @stof hmm I don't think so as it does not alter the return type per se. You do expect a string anyway ? so the method signature is not changed IMHO.\nThe only change is the string length... for some potential array keys. And as it is stated in the documentation this method only returns hint so what it returns may not work out of the box anyway\n. @stof Okay I get your point. So here's what I propose then:\n@Heart1010 @cordoval \n- I will leave the current behaviour as it is right now and document it properly on the CSV documentation website.\n- I will release 7.1.\n- A patch improving the method will land in v8 with a BC break (with full documentation and a migration code attached to it as I always do).\n- This issue will remain open until a patch is released in v8.\nAs a reminder, this method has been stated from the beginning as giving hints, as such it can be wrong and has been improved since its introduction in v5. So in v8 it will be improve again.  As a side note, I  would question the CSV provider if I were given the task to parse such CSV (this is in no way a justification for not patching the method).\nThought ?\n. The documentation website is updated http://csv.thephpleague.com/properties/#detecting-csv-delimiter\n. The address this bug without BC break a new method has been created fetchDelimitersOccurrence and the current detectDelimiterList method will be deprecated in the next release 7.2.0 and remove in the next major release 8.0. The changes are already effective in the master. If you want to test the new method.\n. This issue is fixed in the master branch\n. Assuming your are getting a CSV in a different locale as yours, you should first try to use the stream filtering capabilities as explained in the documentation and in the example. \nYou should also look at the FilterTranscode class as a example on how to transcode on the fly your CSV.\nHope it will help\n. Hi I think you should split your pull request as you are addressing two different problems even if those problems affect the same feature.\n- The first problem refers to how we should count the number of valid fields found (essentially a bug fix). Not tests need to be changed and I would gladly accept the resulting pull request;\n- The second problem is how the library process the possible valid delimiters. This is where we disagree as you have not convinced me of the need to change the current behavior; \n. No problem you should run the PHPUnit locally before sending your pull request next time :+1: \n. Please refer to the documentation . The package relies on the behaviour of the SplFileObject class. You need to adjust your code accordingly. For instance in your case you should add the following code:\nphp\n$csv = Reader::createFromPath('/path/to/your/csv/file.csv');\n$csv->setFlags(SplFileObject::READ_AHEAD|SplFileObject::SKIP_EMPTY);\nforeach ($csv as $row) {\n    print_r($row);\n}\n. Hi I've made a couple of changes to your pull request that I will explain below. The feature is great but I had some reservations:\n- you were using Reader::fetchOne directly in the  Reader::fetchAssoc. This would cause a bug If someone would use filters before calling Reader::fetchAssoc as they would be reset by the Reader::fetchOne call.\n- the filter that removed the header row from the resultset was applied only once so calling twice Reader::fetchAssoc would result in the missing row showing up on the second call;\n- Giving a empty array should not mean anything else, so the Reader::fetchAssoc signature was changed from \nphp\npublic function fetchAssoc(array $keys, callable $callable = null);\n//only accept arrays\nto \nphp\npublic function fetchAssoc($keys = 0, callable $callable = null);\n//accept arrays and integer\n- When you give an non empty array you get the legacy behavior (i.e. the current behavior)\n- When you give an integer you're telling the method to use the data of the corresponding row index and your are automatically removing the selected row from the resultset.\n- By default $key = 0 (just like with Reader::fetchOne) it means you are selecting the first row\nThe only tradeoff is that the header is no longer cache like in your pull request.\nTell me what you think about those changes ?\n. Ok I'll prepare for a 6.1 release sometimes this week. Unless a bug is found. \n. Hi @CWSpear ,\nAbout Reader::fetchAssoc, this is not a quirk but the intended behavior. To understand it you should try to think of Reader::fetchAssoc as being similar to the behavior of PDO::FETCH_ASSOC. The method returns an array indexed by column name as returned in your result set. \nThe $callable argument is applied on the CSV content before generating the final result set so it is expected that when you do print_r in your closure no re-indexation is shown as it has not occurred yet.\nIMHO, you should use Reader::each or Reader::query to achieve what want something like this:\n``` php\nuse League\\Csv;\n$indexes = [\n    \"first column\",\n    \"second column\",\n    \"third column\",\n    ...\n];\n$res = [];\n$csv = Reader::createFromPath('/path/to/my/file.csv');\n$nb_iterations = $csv->each(function ($row) use ($indexes, &$res) {\n    $item = array_combine($indexes, $row);\n    //add here your business logic...\n    $res[] = $items;\n    return true; //required otherwise the loop will stop!\n});\n```\nHope this will help.\n. Hi @CWSpear \ncould you please open another issue related to your needs has this issue has been closed and you seems to need some other features. I'll respond into this new issue\n. Thanks for the pull request. Tentatively accepting this; I reserve the right to reorganize as needed. Thanks!\n. Hi @duncan3dc and thanks for the patch. I have to say I have mix feeling about it. Not that I am against it but I think you are solving only half of the problem. \nWhat happens when the line endings inside the row also exhibit another format than the one requested ? \nIMHO, I would suggest using Stream Filtering for that and browsing the internet I saw people using this approach to solve this exact problem. Stream filtering should definitely be the way to go to add this kind of behavior Thought ?\n. > What happens when the line endings inside the row also exhibit another format than the one requested?\nA simple example\nphp\n$row = [\n\"Lorem ipsum dolor sit amet, \nconsectetur adipiscing elit.\",\n\"In vehicula, purus \nnon sodales blandit\", \n\"urna nulla rutrum purus\",\n \"non facilisis.\", \n];\n$csv->insertOne($row);\n- The following row has line ending inside a cell. So they must also be converted.\nThe feature if done using stream filter won't be accepted for the same reason I did not include the FilterTranscode in the package. The reason behind this decision is simple. Filter just extend League\\Csv through composition but:\n- They can be used outside the League\\Csv\n- If they were bundle with the league package any change/upgrade/bc break would mean upgrading the full package while the core functionality would not have changed.\nWhat could be done, on the other hand, is to create a second repository something like League\\CSV\\Helpers were your class along the FilterTranscode class and others would be submitted to be easily found and/or improved without affecting the package core functionnality.\n. > The feature if done using stream filter won't be accepted for the same reason I did not include the FilterTranscode in the package.\nYou missunderstood what I was trying to say, since english is not my primary language this is bad communication from my part. I did not reject your patch, I was trying to understand it and test it against many cases. In my view, I thought you wanted to changed all line ending sequences to match the one used by the client and your response, clarification says the opposite. So now that this is clear I think we could work on it ? Thought\n. I was wondering if we should not move the method to the Writer class and renamed it set/getNewline() since this feature only relate to the Writer class. I think this feature is more related to Writer::setNullHandlingMode than to Config::setDelimiter\n. Basically what you suggesting is adding the following methods : \nphp\nLeague\\Csv\\AbstractCsv::setOutputBOM($use_bom_on_output); //$use_bom_on_output is a boolean\nLeague\\Csv\\AbstractCsv::hasOutputBOM(); // returns true or false\nBecause we don't want any BC break by default: \nphp\nLeague\\Csv\\AbstractCsv::hasOutputBOM(); returns false\nTo be clear this will only have an effect on the League\\Csv\\AbstractCsv::output method. \nIf you have a better names they are welcomed\n. Since it will work on output.. it will be available on both classes Reader and Writer\n. The dev-master branch now supports BOM on output you can test it and if everything is good for you it will be release hopefully next week as version 6.3\n. After more researchs on the BOM issue I realize that to really resolve this issue you need  to know the BOM sequence specific to the CSV encoding charset. I think we should change the signature of the setBOMOnOutput method. This method should accept a BOM sequence or a Class constant which refers to the available BOM sequence.\nThe developer who wants to handle BOM would require to set the proper encoding AND the proper BOM sequence attached to it.  This is more verbose but less error prone (Of note I'm using the stream capability as League/Csv default encoding charset is UTF8.)\nHere's a example code:\n``` php\nuse League\\Csv\\Reader;\n$csv = new Reader::createFromPath('/path/to/my/file.csv');\n$csv->setBOM(Reader::BOM_UTF16LE);\n$csv->appendStreamFilter('convert.utf16encode');\n$csv->output('file.csv');\n```\nThoughts ? \nYou can look here for more information\n. No I did not, first I don't have a Mac ... and I don't use MS Excel at all :8ball: That being said, implementing this way should do it. The only tradeoffs are:\n- You need to know which client is going to open you CSV prior to downloading \n- There's the extra work of providing the stream to convert on the fly your UTF-8 encoded CSV into UTF-16 (if your document is do be opened in MS Excel Mac if I follow correctly)\n. The changes are done. Now the new methods are :\n``` php\nuse League\\Csv\\Reader;\n$csv = new Reader::createFromPath('/path/to/my/file.csv');\n$bom_sequence = $csv->getBOMOnOutput(); // returns '';\n$csv->setBOMOnOutput(Reader::BOM_UTF16LE);\n$bom_sequence = $csv->getBOMOnOutput(); // returns \"\\xFF\\xFE\"\n$csv->appendStreamFilter('convert.utf16encode');\n$csv->output('file.csv');\n```\ndon't forget to implement the stream filter converter otherwise the output will be in UTF-8 which defeat the BOM sequence addition. you can use the FilterTranscode class from the example for instance to do so.\n. no problem I can wait :+1: \n. Streams do not work with createFromFileObject because SplFileObject poorly supports PHP stream\nyou can make it work using:\nphp\n$writer = Writer::createFromPath('/my/path/to/my/file.csv');\n//or\n$writer = Writer::createFromPath('php://output');\n. Here's what I did to test on my computer the file is located in the examples directory.\n``` php\nerror_reporting(-1);\nini_set('display_errors', '1');\nuse League\\Csv\\Reader;\nuse League\\Csv\\Writer;\nuse lib\\FilterTranscode;\nrequire '../vendor/autoload.php';\nstream_filter_register(FilterTranscode::FILTER_NAME.\"*\", \"\\lib\\FilterTranscode\");\n$csv = Reader::createFromPath(DIR.'/data/prenoms.csv');\n$csv->setBOMOnOutput(Reader::BOM_UTF16_LE);\n$csv->appendStreamFilter(FilterTranscode::FILTER_NAME.\"UTF-8:UTF-16LE\");\n$csv->output('test.csv');\n```\nHope it helps\n. The delimiter can be adjust using setDelimiter method\n. it's because the tabulation is still in UTF-8 :-1: you should use the UTF-16 tabulation character instead \n. Great!!\nI've added a method to detect the BOM in the Input CSV so we will end up having:\n- getBOMOnInput   (detect and return the BOM sequence used on the input CSV if any)\n- setBOMOnOutput (set the BOM sequence to prepend on output methods (ie: output and __toString)\n- getBOMOnOutput  (get the BOM sequence that will be prepended on output methods)\nRemoving the Input BOM is already possible with the existing extract methods.\nWhen this is stable and bug free I think we will have a complete new and nice feature.\nThoughts ?\n. I think @RomeroMsk could write that section, since like I said I'm no MS Excel expert :) . Let me add everything in the source and we will update the documentation when all is done and stable\n. http://csv.thephpleague.com/bom/  <- the documentation you can improve it directly via pull request if needed.\n. the stable release version 6.3 was released with the stable feature. Of note the methods names have been changed.\n. This is normal behavior all outputting methods are not affected by the extracting methods.\n. But a quick update on the package could allow such behaviour now could mean BC break  also\n. I didn't say the lib wouldn't do it ... I've just implemented it on my local dev. It took me less than 5 min. to do it But it's a BC break for sure.\n. If you download the dev-master the feature is now on the package. You can make some feedback on it if you want. Of note: the dev-master alias is now 7.0-dev\n. this issue is resolved and will be made public on the next release. Please read the changelog or the documentation for more information\n. Hi @codeliner , thanks for the PR.\n I'm just wondering since the MapIterator is an internal class which is never exposed in the public API. And the only class which uses it is the Reader class which only interacts with Iterators objects what would be the package gain of making the MapIterator working with Traversable object ?\n. @codeliner Just for your information in the upcoming v7 the MapIterator has moved places. Another reason to not use class tagged internal :+1: . That being said I first merge your PR but I had to rollback to the previous implementation due to scrutinizer not liking your version of MapIterator\n. According the CSV specification enclosure are only needed when space or in case the enclosure character is used inside your cell. When the latter situation is encounter the specification specifies that the enclosure must be double to prevent misinterpretation of the cell content.\nIn your exemple you are forcing the enclosure on each cell which:\n- is not require for the CSV to be valid.\n- forces the addition of second enclosure character by the PHP fputcsv function.\n. Hi @joostshao \nI don't understand your question. In what context are your talking about ? Can you be more specific ?\n. What you are asking is out of scope for the library out of the box. I suggest you look at the reading documentation page Where you will find informations to help you achieve that using for instance the Reader::fetchAll method for example.\n. Hi @teplolog,\nThis bug has been corrected in the coming 7.0 version which should be release next week. In the meantime you can simply do this\n``` php\nrequire_once 'vendor/autoload.php';\nuse League\\Csv\\Reader;\n$reader = Reader::createFromString(\"a,b\".PHP_EOL.\"3,11\");\n$reader->setFlags(SplFileObject::DROP_NEW_LINE);\n$result = $reader->fetchAll();\nvar_export($result)\n``\n. Hi @barroca,\ncan you provide your PHP/HHVM version please as I fail to reproduce this issue\n. okay, I get it ..it's a change in PHP behavior so the result depend on PHP version \nlook at this results which mimic what you are experimenting\nhttp://3v4l.org/c56KM\nSo it's not a package bug per se. Let see what we can do to mitigate this \n. A way to mitigate this changed behaviour is to **NOT** use theDROP_NEW_LINE` constant. Like this\n``` php\nrequire_once 'vendor/autoload.php';\nuse League\\Csv\\Reader;\n$reader = Reader::createFromString(\"a,b\\n3,11\");\n$reader->setFlags(SplFileObject::READ_AHEAD|SplFileObject::SKIP_EMPTY);\n$result = $reader->fetchAll();\nvar_export($result)\n```\nlike shown here: http://3v4l.org/oqmvp\n. yes maybe I'll change with a new major version I don't know yet\n. @donnykurnia It is documented but I'll make it more obvious then. Or better yet do you want it to be documented elsewhere ? you can make a PR I'll review it and update the documentation\n. @donnykurnia agree but doing so would be consider BC Break that's why this issue is stated to be tackle with the 8.0 release when I start working on it see #105 \n. Hi,\nthanks for using the League\\Csv. The branch you are currently using is the dev-master branch. So this can happen when some features are not enough stable and I have to make some git stash/rebase. \nI would recommend using the dev-master branch only for testing purpose and not for production code.\nThe code will be freeze today for release hopefully next week.\n. the stable release of 7.0.0 is out !!\n. This is a limitation due to poor support from SplFileObject of stream filters. There's a open bug about this and it has not yet been resolve. When adding stream filter support I even blogged about a way to resolve it\n. In the meantime, nothing prevents you from modifying the FilterTranscode class to use iconv extension instead. I understand it is frustrating but if this bug was resolved a even more powerful package could be made and It would also remove the need for isActiveStreamFilter in the package.\n. Yep there's nothing, a omission from my part. But you can make a pull request against the gh-pages branch to add the warning. \n. I've just updated the documentation by adding a warning section on top of the stream filter documentation page.\n. @zerocrates you are totally right seems I had overlooked this one. I've just create a PR with the fix in it. This one will be included in the next release :+1: \n. bug fix is merged in master branch\n. @spagu could you provide more information as this bug is related to an unsupported version of the library. It would be best to open a new thread with an example so I could investigate your issue.\nthanks in advance. nope a typo you may fork and fix it :+1: \n. Yep I think this issue is resolved\n. I don't think there's a easier way. \nOf note starting with v7:\n- setNullHandlingMode does not exist anymore and no extra code is needed to treat null as empty\n- you could simplify your code as follow:\nphp\n$writer = Writer::createFromFileObject(new SplTempFileObject());\n$writer->setOutputBOM(Reader::BOM_UTF8);\n$writer->insertAll($data);\nfile_put_contents('file.csv', $writer->newReader());\n. In your case I would say try to fetch the header first and validate it prior to do Reader::fetchAssoc this is the easiest thing to do.\nAdding more exception classes/level is IMHO not required. Do remember that Reader::fetchAssoc also accepts array, like stated in the documentation so this kind of situation should solve itself quite nicely.\n. you shouldn't use Reader::fetchAssoc  as it returns a multidimentional array. For big files I would recommend using Reader::query() as you directly use an Iterator which will use less memory. This is explain in the documentation\n. Since I don't know exactly what you are trying to do I can only do something like this. Hope it will help\n``` php\n    public function convertItemsFile($files)\n    {\n        $itemsFileName = 'items_file.csv';\n    $items = $this->fileExists($files, 'shortname', $itemsFileName);\n\n    if (! $items) {\n        return;\n    }\n\n    $inputCsv = Reader::createFromPath($items[0]['name']);\n    $inputCsv->setDelimiter(\",\");\n\n    $outputCsv = Writer::createFromPath($this->_csvFilesPath.'vp-'.$items[0]['shortname'], 'w');\n    $outputCsv->insertOne($inputCsv->fetchOne());\n\n    $inputCsv->setOffset(1);\n    $inputCsv->addFilter(array($this,'filterItemsByStyleCodes'));\n\n    $callable = function(array $row) {\n        return [\n            $row['company'],\n            $row['item-number'],\n            $row['description'],\n            $row['style-code']\n        ];\n    };\n\n    $outputCsv->insertAll($inputCsv->query($callable));\n}\n\n``\n. like I said I don't have enough info to help you out :( . \n Bottom line:\n- I don't get why you are using touch since I used thewopen mode;\n- you should useReader::querybecause an Iterator will consume less memory that usingReader::fetchAssocwhich uses internallyiterator_to_arraywhich is a no goner as all the data is dump into memory for array conversion.\n- The callable thingy on theReader::query`could be as well drop if your are just \"copying\" from one CSV to another.\n- If you insist in using the callable on the query method the row can not be indexed with names they are indexeb by number since non array combination has taken place (this is a typo from me)\nAnyway all of this is explain in the documentation. So I don't see what I can do more\n. thanks, these are the kind of typo I can not catch :+1: \n. What you are referring to is a known SplFileObject bug reported here. The reason the package uses the DROP_NEW_LINE flag is because otherwise the last empty line would be added when making a simple  foreach. \nA workaround could be to enable the removal of the DROP_NEW_LINE flag when using the setFlags method.\nHaving said that, either way this should be documented. It depends on how much user friendly we want the package to be.\n. Since I can not directly fix the SplFileObject bug. I've updated the code to give the possibility to the user to remove the DROP_NEW_LINE flag. I have updated the documentation as well. When I finish code review for possible breakage I'll make a 7.0.1 bug fix release, today or tomorrow. In the meantime the code is already present in the dev-master branch, if you want to review it yourself.\n. the version 7.0.1 is out adding the ability to remove the DROP_NEW_LINE to tackle SplFileObject bug.\n. Why can't you just do\nphp\n$csv = League\\Csv\\Writer::createFromPath(\"result.csv\", \"w\");\n$csv->insertAll($data);\nBy specifying the open mode parameter as detailed in the documentation your destination file is created if PHP is able to create a file in the destination directory. Just like with PHP fopen function :)\n. Of note starting with version 7.0 nothing prevents you from using the formatter capabilities of the Writer class to transcode your data in another encoding without using the stream filter api.\n. @gabidavila please read the documentation from Csv::output method.\n. Hi,\nthanks for using the league\\csv library. The csv you are using in encoded in UTF-16. You should transcode it's content in UTF-8 in order to view correctly your data. You should use the library stream filter capabilities to do this as explained with a concrete example in the documentation\n. Hi,\nthanks for using the package. I'm afraid that yes it is up to the developer to manually remove it. As the  Reader can not modify the CSV. you can do that using for instance the callable argument of any Reader::fetch* methods.\n. I understand your concern but stripping even a single bite of a CSV document with the Reader class is simply not acceptable. As per definition a Reader class should not be allowed to change the nature of the object it interacts with. So in our case we're left with two options:\n- option 1: As stated in the documentation. Use the extract methods $callable argument to remove them.\n- option 2:: Re-download your CSV and remove the BOM sequences using the BOM methods.\nI understand completely that dealing with BOM sequences can be a pain, but unless we come out with a solution that respect the Reader contract. I'm afraid the current behavior will stay.\n. I see your point but your are mistaking the underlying mechanism. the decorators helps selecting rows, They do not in anyway interacts with them. The only way to remove effectively the BOM sequence is through the use of the $callable argument. Remembers that each decorators is cleared between extraction. Bottom line, in the current codebase this is not possible. Maybe you can submit a PR and I'll review it. Like I said I'm open for any solution that do not alter the CSV document.\n. The next major release (v9.0) will automatically remove the BOM on CSV document read. The patch landed on the master branch.. Hi @paslandau ,\nWhy can't you just write directly to the test3.csv file ? That being said there's a easy answer to your problem :) .\nphp\nfunction writeFile($file, League\\Csv\\Writer $writer)\n{\n    $spl = Writer::createFromPath($file, 'w');\n    $spl->insertAll($writer);\n    $spl = null;\n}\nI'm sure you'll get a drop in memory usage. And yes since Writer is a iterator you can passed it directly to another Writer object :+1: \n. This is a good start. I think you could improve the PR by:\n- adding a property and its setter/getter methods that would default to not removing the BOM sequence so that we do not introduces meaningless BC break\n. I would prefer the code being added on a StripBomModifier but that customisation :) let's make the thing work first :+1: \n- test\n- code (PSR-2)\nthen at the end re-organization if needed\n. @Richtermeister are you still working on this feature or not ?\n. @Richtermeister If you are too busy I can take over this feature it won't be too difficult for me as you already laid out the foundation for a solution, thought ?\n. I've just push my modification to the master branch I'll close this pull request. You can pull from the master branch to see if it works like you want.\n. When you have time could you review the changes I've made to the package to add your feature please.\nI've already updated the documentation\n- If you have other wishes this is the time to make them or I'll considered 7.1 feature/fix completed\n- you can also look at the CHANGELOG to see the others changes in the package.\n. @Richtermeister did you have some time to review the feature... I'm waiting for your review to release 7.1 \n. version 7.1 is released with the stripBom method\n. Could you show me a example code on how this works ?\n. I think the next iteration of the package will throw away arrays in favor of generator. I could not do it before because PHP5.5 adoption rate was not good but since PHP 5.4 will be EOL is 6 months or so when the new version will be release this problem will be resolved itself.\n. @Richtermeister no problem but first just send me a example so I can understand the implication as a gist for example. As I said this can be dealt with Generator in a next major release or using the Reader::query method using a well written callable.\n. Hi,\nIMHO this is a bit too much. Personally I'm currently able to do all this without the use of grunt or node.js by setting my text editor to run the tests and checks on saves. I'm using SublimeText for that but I'm sure the same can be done with NetBean, PHPStorm, Zend Studio to name more powerful IDEs. \nI'm sure that if a developer is able to setup correctly a node.js/io.js environment he/she will have no difficulty to set up his/her IDE of choice to do the same.\nI think a better place to ask for feedback for you proposition is the group mailing list as this would also impact all other league projects if accepted.\n. Hi @panique \nI think this \"bug\" should be related to the use of output buffer in Yii. You should look at it. \n. This is not a problem with the package but on how you are using the script. PHP is trying to load a class that does not exist in App\\Http\\Controllers\\ namespace.\n. Hi,\nThanks for using the package, what you are looking for is documented in the extracting data documentation page using the Reader::fetchAssoc method.\n``` php\n$reader = \\League\\Csv\\Reader::createFromPath('/file.csv');\nforeach ($reader->fetchAssoc(0) as $row) {\n    //here row is an array with names from the first line\n}\n```\n. Understood,\nThis method was created when PHP 5.5 Generator where not around. I plan to update this behavior in a upcoming release when PHP 5.4 will be EOL. In the meantime you can achieve the same result using Reader::query method in association with Reader::fetchOne. \n``` php\n$reader   = \\League\\Csv\\Reader::createFromPath('/file.csv');\n$header   = $reader->fetchOne();\n$iterator = $reader->setOffset(1)->query(function($row) use ($header) {\n    return array_combine($header, $row);\n});\n//you are using an iterator so the memory usage shouldn't be a issue anymore\nforeach ($iterator as $row) {\n    //here row is an array with names from the first line\n}\n```\nThis is a crude example of an alternative but I'm sure you get the idea. When Reader::fetchAssoc will be updated then this code can easily be remove or updated.\nThis is one of the reason the Reader::query is in the public API so that people can play around with it and come up with specific output to fullfill their own requirements :+1: \n. @alexdesignworks This is why this method is being removed in the next major release. That being said whatever the method argument the returned type was always an Iterator.\n. @philsturgeon maybe you can remove the wiki from the league\\csv package\n. I'm not promising I'll do it right away but I'll try for futur contribution\n. the master is tag/alias as 7.1.x-dev on packagist \n. @cordoval  sorry but I don't understand your request :( \n. @cordoval The master was about to be tagged and release as 7.1 because a new method has been added to the package but in the meantime bug #55 was reported so depending on its resolution I'm delaying the 7.1 release\n. @cordoval version 7.1 is released\n. Hi @paslandau,\nI've just looked at your code and after some digging I've found the bug ... I'll release a patch version tomorrow. \n. I've push the bug fix in the master repo. So if you download the master branch you can test your code against a patch version. The 7.0.1 behaviour is the correct one. Tell me if all is good for you.\nI'll try to incorporate your test into the CSV test suite.\nBy the way It would benefit everyone if you have other complementary tests to make a PR and add them to the package test suite\n. version 7.1.1 is released which correct this bug\n. @paslandau I have a question regarding League\\Csv\nRight now out of the box the reader uses SplFileIObject::DROP_NEW_LINE which is a bug \nI want to switch this to SplFileObject::READ_AHEAD|SplFileObject::SKIP_EMPTY do you consider this as being a BC break or just a patch ?\n. @paslandau \nAbout semver, no public API is changed so if I were to strictly follow semver then this is not a BC break :+1: .  Moreover this change is really a bug fix has using SplFileIObject::DROP_NEW_LINE by default is a bug \nI have publish a roadmap for v8.0 which takes into account this bug fix\n. you should use Reader::query($callable) method directly it's the best option for now \n. you can see one in the examples or in the documentation\n. what's preventing you from using it with Symfony2 ?\n. http://symfony.com/doc/current/components/class_loader/psr4_class_loader.html \naccording to the symfony documentation there's nothing to do. If you are using composer then the library is already present and loaded you just need to call it in your symfony based script\n. @onema thanks for reporting the bug. A patch was made available on the master branch. After review and testing a patch release will be made next week. In the meantime you can test that the dev-master branch fix works for you\n. Quoting the docs you are referring to:\n\nAfter an extract/conversion method call, all query options are cleared;\n\nThis includes the stripBom method which is nothing more than a query option.\nI know it may seems strange but this is a trade-off I choose when implementing the solution. Stripping BOM sequence is only useful when the first cell of the first row is expected in the result set. In all others situations you don't want to add another layer of Iterator when it is not needed.\n. The patch release 7.1.2 is released with the bug fix\n. The bug that needed this rewrite has been fixed in the master. The feature is no longer necessary\n. Hi @JoeDawson,\nThanks for using the library. Like stated in the documentation for the output method \n\nSince version 7.0, the method returns the number of characters read from the handle and passed through to the output.\n\nThis was done to match PHP native function fpassthru\nThe real question is why are you using output to save your CSV, this method is meant to be used to download the CSV, no return is needed 99% of the time :) .\n. Sorry but I don't understand the issue ? could you be more explicit. For what is worth str_getcsv is not used to parse the CSV at all.\n. again I'm not using str_getcsv to parse the CSV . Please read the code source before stating this :+1: \n. @dakira thanks for submitting your pull request. Regarding the enclosure delimiter I think the package already follow the RFC4180 which states\n\nDue to lack of a single specification, there are considerable differences among implementations.  Implementors should \"be conservative in what you do, be liberal in what you accept from  others\"\n\nThe Writer class just does that by enforcing the use of an enclosure to ensure that the output CSV always have a enclosure defined for interoperability.\nFurthermore, PHP's function and method to create a CSV document requires an enclosure to be set. If no enclosure is set, the default enclosure \" will be use. So your patch won't work at all.\nTo work around this PHP \"limitation\" (which is not IMHO) I've seen people use the \\0 byte character as the enclosure character. This hack which already works on the package assumes:\n- that no null byte are used inside the CSV field. Because if a null byte is present you will corrupt the CSV data by introducing double null byte (see RFC4180).\n- the software that will read the generated CSV trim/not take into account any null byte sequence in the CSV data. Again this can lead to data corruption.\nTL;DR: Even thought, the enclosure character is optional most of the time in CSV export, it is required in some situations. Adding the ability to create an enclosure-less CSV would degrade the package quality and interoperability.\n. to match PHP's fpassthru behavior :+1: \n. Hi @tzfrs Using the library on a Mac is covered in the library documentation \n. Maybe you should just simply remove your set_time_limit from the loop and from the script. This is in not a League\\Csv problem \n. Hi @paslandau I think you made a mistake in your feature request... the problem is not the escape character but the enclosure character :+1: \nThis feature (along with completely removing the enclosure #109) has been requested several times but I always refused to implement it without a proper PR has is would degrade the package quality. That being said, I think it is possible to force an enclosure on every field using the plugins features of the package.\n. Because answering on an issue would have taken too much time ... I wrote  a blog post about the solution hope you'll get the information you need there :+1: http://nyamsprod.com/blog/2015/qa-enforcing-enclosure-with-leaguecsv/\n. @roberttolton 9.1 is yet to be released. Still being tested but the API is stable. There was a typo in the v9 documentation. The class name is EncloseField. If you really need this feature you can use the master branch.. Hi @ryzr sorry But I fail to reproduce this behavior on my personal laptop or on a remote server must be a configuration problem outside of the package scope \n. Type conversion from null to empty string was indeed made out of the box in version 7.0 \n. @rbruhn Well stream filters are a feature of PHP itself not restricted to League\\Csv. And yes you can use stream filters to convert with the Csv\\Reader class your CSV content prior to exporting it. Just look at the documentation around stream filters where the mechanism and examples of how to use them with the package are explained.\n. hi @HeyRatFans thanks for submitting your PR but I think that you are dealing with 2 problems:\n- converting your CSV newlines (this problem is for the Csv::writer class)\n- creating a good stream filter name\nFor the first problem you could simply use the setNewline method :) . And as far as I am aware PHP's SplFileObject has no problem handling correctly the newline sequence while reading the CSV files, unless you are using a Mac based computer or a CSV that was generated on a Mac based computer for which you can simply set a specific ini value.\nFor the second problem PHP stream filter name have some restrictions for instance using \"new line characters or \"invisible\" ones in them is forbidden\" so using \\r or \\n or even \\0 (the null byte) will trigger a Fatal error when using them. If you had included some tests with your PR like it is recommend by the contribution guidelines you would have stumble on this issue for sure.\nIf you still want to use stream filter to achieve your goal you need to think of an workaround to specify you input but I can not accept your PR.\n. Okay so you want to change the line terminators inside the cell okay got it :) \nhere's a blog post I made about enforcing CSV delimiters using stream filters. Hope you'll find what you want in there.\nhttp://nyamsprod.com/blog/2015/qa-enforcing-enclosure-with-leaguecsv/\nIMHO in your case you should create a \"simple\" filter with a fixed filtername. Since you already know what you want to change and with what you want to change it with. The code will be much simpler\n. I understand what you are trying to do but the main issue is not really League\\Csv. To illustrate, I'll use your stream filter and SplFileObject:\n``` php\nuse lib\\FilterReplace;\nrequire 'FilterReplace.php';\nstream_filter_register(FilterReplace::FILTER_NAME.'*', FilterReplace::class);\n$streamPath = 'php://filter/read='.FilterReplace::FILTER_NAME.\"\\r\\n:\\n\".\"/resource=\".DIR.\"/test.csv\";\nnew SplFileObject($streamPath); //SplFileObject will throw a RuntimeException\n``\n- I've register your filter\n-League\\Csvwill keep a registry of the registered filter (this is what your added test just verify)\n- League\\Csv uses lazy loading, so the SplFileObject is only created when needed (when usingforeach) . Onforeachcall  the object generates thestreamPathand feed it to SplFileObject constructor since this is [the only way to apply stream filtering to a SplFileObject](https://bugs.php.net/bug.php?id=44392). \n- Because you've added\\r,\\nand other characters that have a numerical value < 32SplFileObjectwill throw aRuntimeException` because you've submitted an invalid path.\nTL;DR: Removing the path trimming will not resolve you issue.\n. Could you please:\n- Open an issue related to this PR\n- Make a PR from one of your a dedicated branch and not from your master branch.\n- Remove the fgetcsv test which does not test the package per se.\n- Once this is done I'll accept your PR but I reserve the right to change/adapt some of your code to make it pass the HHVM.\n- Open a distinct issue for the one you just found so I can work on it separately.\nExcept for the tests changes, what I'm asking is written in the CONTRIBUTING to make it easier for any maintainer and future users to quickly find references to bugs in the issue tracker. \nAs your patch boils down to removing the usage of the trim function on the stream filter name I'm ok with it :+1: .\n. This issue is resolved in the master branch\n. Ok... I think I know the source of this bug but alas it will be fix in v8.0.0 because it will cause BC break otherwise. The problem is by default League\\CSv uses the SplFileObject::DROP_NEW_LINE constant instead of the SplFileObject::SKIP_EMPTY one. changing this default settings affect many usage of the package. \nThis issue is partially solved with issue #99 \nHere's a simple workaround\nphp\n$csv = Reader::createFromPath('path/to/file.csv');\n$csv->setFlags(SplFileObject::READ_AHEAD|SplFileObject::SKIP_EMPTY);\nThis is one reason I want to completely remove the SPL flags in version 8 see issue #105 \n. This bug is fixed in the master and will be part of the next release version\n. Hi @BardiaAfshin thanks for your interest in the library. I think the documentation website answers all your questions. To summarize:\n- Yes and No, you can not delete column but you can generate a modified version of your input CSV  using the package formatter feature\n- Yes you can, just use the package filtering features.\nHope this will help\n. This PR fixes two bugs related to SplFileObject flags used in the library\n- The default flags are now SplFileObject::READ_AHEAD|SplFileObject::SKIP_EMPTY. So that using foreach will return the expected data even when multiple lines are presents in CSV fields\n- the __toString method needs to normalize the flag usage to output correclty the file. Flags were badly applied which led to missing rows in the output\n. @JonoB that's what Reader::fetchAssoc does out of the box   check the documentation :+1:\n. @assertchris @frankdejonge the library is based on SplFileObject which his an PHP iterator optimized for files. I don't see how using a Generator would make the code use less memory unless I missed something. I recall this blog post by Anthony Ferrara where he states similar things. If I understand it correctly\n. @Heart1010 this article is about fopen not SplFileObject in fact I would go as far as to say that 90% of what's in this article could have been done using the current CSV package :+1: And yes if I were to parse a CSV with fopen I would definitely use generators :) . The problem is not the use of generators but its use combined with an already instantiated Iterator which is the case for every usage of the current library\n. @assertchris Thanks for the input. I had came to the same conclusions as yours and I fully agree with your assessment about generators vs iterators.\n. All the changes for v8 have landed on the dev-master branch. you can download and try it using composer:\ncomposer require league/csv:dev-master\nIf no critical BC break or bug are found. The new version will be released December 3rd 2015 exactly 2 years after the first stable version of the library :+1: \nTL;DR:\nNew features and BC breaks are covered in the documentation website\n- new upgrade page \nTHE CHANGES\nOf note: the new version only runs on PHP5.5+ and feature a completely rewrote Reader class. All other functionalities remain the same.\nThe Library classes no longer allow settings the inner SplFileObject flags. This will allow to have a consistent experience in PHP and HHVM as well as disabled badly set flags. See https://3v4l.org/5ZFKe \nThe Reader class now exposes a 2 new methods requested by many fetchPairs and fetchPairsWithoutDuplicates to associate two CSV column values.\nThe optional callable argument to manipulate the extract methods results have been updated to be more specific to each extract method to ease their overall usage.\nReader::fetchAssoc and Reader::fetchColumn will return an Iterator instead of the default Array result set.\nOther small BC breaks have also been introduced for consistency. \n. @davesouthey Not at all. Too much work right now.. The v8 will be released this week .\n. @davesouthey help accepted :+1:  If you are a genius in scrutinizer (ie: better than me which is not very difficult) then you may be able to explain and/or fix a simple bug why does scrutinizer thinks that the complexity is 65 when on local PHPUnit gives 24 \n. @davesouthey the folks from scrutinizer have replied to my tweet . TL;DR this is a bug in their engine. So we'll have to wait until the fix is in production\n. version 8.0.0 is out\n. Hi @rwitchell,\nThanks for reporting this bug. As a matter of fact, this one is being fixed as part of the 7.2.0 release that will be out hopefully this week if I still have time or next week. The change will be in the master branch anyway. This is fixed as part of resolving  SplFileObject flags bugs see #131 \nThe $newline parameter is being deprecated from the createFromString method and will be remove completely in the next major release.\n. This issue is fixed in the master branch\n. hi @enriquemanuel the library does supports TSV but you wrote it wrong you need to use the \" in PHP to make sure correctly submitted the tab character.\n. @larsbo the Reader does not alter your CSV content I think this is an encoding problem did you try http://csv.thephpleague.com/filtering/\n. @larsbo This is a case where you need to get more infos around the source CSV encoding itself before determining what to do. The problem is not at the package level but the lack of info around the CSV you are trying to process.\n. Have you tried to open the CSV file to have a look at it ? maybe the answer is there. A CSV file is nothing more than a file exchange format. if I send you a XML or a Json file without telling you in which encoding the file is ? You may assume it is in UTF-8 like the CSV package does but that is only an assumption the only person who knows the real encoding is the one who encoded the file. \nBottom line:\n1\u00b0) Open the file and try to figure it out by yourself \n2\u00b0) If you can't then yes you have to ask the CSV provider (in your case Paypal) for help \nThere's no other workaround.\n. In this case then It's still not a library problem since through the use of filter you can virtually encode/transcode any character set in UTF-8. IMHO as you did not know the source encoding you were only guessing the file encoding did you try http://php.net/manual/fr/function.mb-detect-encoding.php for instance on the raw file to try to detect the encoding ?\nThis is again pure speculation It would have been great to see in which encoding Paypal did send you the CSV to begin with \n. Hi @litan1106 \nTo understand your problem I need more informations:\n- your OS\n- your PHP version\n- your League/csv version\n- what you were expecting, and what you did get (ie what was the value of $count for instance) \nand other informations that could help me understand your problem. With the current info I am unable to reproduce your bug if it is a bug to begin with ?\nIf you look at the examples folder there's a script that just use the same code you gave me and works as intended\n. @litan1106 did you try to set correctly your CSV file controls (delimiter, enclosure, escape) characters to match your CSV file ? Please check the documentation for that \n. @litan1106 did you fix your problem ? If so can you close this issue please.\n. @ssfinney optional parameters to condition return type value is a recipe for disaster... I'd rather have two methods than one with a mixed return type depending on parameters\n. Thanks to all your inputs a PR #137 has been done with the new methods which hopefully will solve the Reader::fetchPairs issue. Please review the changes in this PR for more informations \n. There are 2 main reasons for that:\n- All previous version of the library returned an array (So for a BC perspective it makes sense IMHO)\n- Changing the return type of a method is something that I would not advocate to begin with. If I had to choose I'd always return a Iterator and do a full BC break. but in this case this is a trade-off. People expressed that having both return type could be beneficial when dealing with all sorts of CSV (small vs large). \nSo Instead of creating 3 new methods\n- fetchAssocIterator($offset_or_keys = 0, callable $callable = null) Iterator\n- fetchColumnIterator(int $columnIndex = 0, callable $callable = null) Iterator\n- fetchPairsIterator(int $offsetColumnIndex = 0, (int $valueColumnIndex = 1, callable $callable = null) Generator\nor adding a extra argument to each method like having \n- fetchAssoc($offset_or_keys = 0, callable $callable = null, $returnType = Reader::TYPE_ARRAY)\n- fetchColumn(int $columnIndex = 0, callable $callable = null, $returnType = Reader::TYPE_ARRAY);\n- fetchPairs(int $offsetColumnIndex = 0, (int $valueColumnIndex = 1, callable $callable = null, $returnType = Reader::TYPE_ARRAY);\nI choose instead to enable return type changes with a specific method.\nBy resetting this behavior on each call you requires the user to explicitly state what return type he/she expects when using the method. This way whenever you receive a Reader object you have full control over what it can return.\n. > You're working on new major version, right? So isn't it totally okay to get BC broken?\nThe main reason for the BC breakage is the modification of the callable signature on two Reader extract methods (fetchAssoc and fetchColumn). Everything else is just added features. By minimizing BC breakage even between major versions you improve your library code while helping its adoption rate.\n\nIt's totally unclear, that by setting a property you're going to affect only one future method call.\n\nOn contrary this is how the Reader class query options have always worked since version 4.0 :) . Quoting the documentation\n\nAfter an extract/conversion method call, all query options are cleared;\n\nYou should think of the Reader as a double purpose object :\n- a CSV accessor which returns a result set of CSV rows\n- a CSV Query builder which defined this result set further \nIn v8 the query builder will have a new feature which is to defined its result set type using the new including the  setReturnType method. At least this is how I view this method\n. After some discussions on thephpleague mailing list  the following changes were made:\n- the setReturnType method was removed\n-  Methods return Iterator where applicable (i.e.: fetchAssoc, fetchColumn, fetchPairs) \n- The fetchPairs method will always preserve the offset keys and their correspondant value.\n- The fetchPairsWithoutDuplicates was added. The method returns an array where duplicates offset have their value overwritten.\nHope these changes will satisfy you. They are already present on the master branch. Documentation update will be done shortly\n. Documentation is updated could you close this issue if all is good. Thanks in advance\n. @repat thanks for using the library.\nYour problem is explained in the documentation.\nFor the open mode to be taken into account with the newWriter method you need to have instantiated your CSV object with the named constructor createFromPath.\nThe open mode only applies on a CSV object which was instantiated \u00e0 la fopen \n. Yes your code is very complicated indeed :+1: here's how I would do it. \n``` php\nuse League\\Csv\\Reader;\nuse League\\Csv\\Writer;\n$filename = 'test.csv';\n$cellIndex = 3; //the cell index you want to format\n$updateCsv = function ($row, $rowIndex) use ($cellIndex) {\n    if (0 === $rowIndex) {\n        return $row; //we do not change the header\n    }\n    if (!isset($row[$cellIndex])) {\n        $row[$cellIndex] = ''; //in case the cellIndex does not exist\n    }\n    $row[$cellIndex] = 'PREFIX_'.$row[$cellIndex];\n    return $row;\n};\n//we loop and format the Input CSV\n$csv = Reader::createFromPath($filename, 'r');\n$iterator = $csv->fetch($updateCsv);\n//we create a temporary CSV file\n$tmpPath = '/tmp/csv-temp-file.csv';\n$tmpFile = Writer::createFromPath($tmpPath, 'w');\n$tmpFile->insertAll($iterator);\nunset($csv, $tmpFile); //we destruct both CSV objects because we are extra-cautious :)\nrename($tmpPath, $filename);\n```\nThat being said, you are free to extends the Writer class to add an extra argument to the insertAll method to help you improve your code.\n. Hi,\n@wesleyvicthor Please refer to issue #113 \n. Hi,\nPlease read carefully the documentation, $db->prepare is out of scope from the current library\n. @DixxieFlatline your problem has already been asked and respond to in the issue tracker #113 \n. Hi,\nDo you see this behavior as a bug ? If so could you please fill a proper bug report as stated in the guidelines So that I can look into it further. \nIn any case I would suggest you reading the documentation before you do so.\nthanks in advance\n. Not a problem I'm glad the exception thrown was the correct one :+1: \n. Reader::fetchAssoc returns an Iterator since version 8.0 has stated in the documentation. So using a simple foreach on the result of the method call should return the expected results.\nI can update the example to highlight that. It's a legacy of version 7.0 :+1: \n. the documentation examples have been updated to highlight the change of return type.\n. Hi @cosecantt ,\nI don't get what your are saying you are already able to save the CSV when using the Writer class on a given path. What would your proposed save method add ? \n. php\n$csv = Writer::createFromPath('/path/to/the/final.csv');\nWhatever you create or append it will be saved at /path/to/the/final.csv so I don't understand your question unless you have a concrete exemple ?\nEverything else will always at some point involve this code :+1: \n. please, read my answer and the full documentation on the writer class as I have already respond to your question.\n. Since I don't know exactly what you are trying to do I can not assist you. Keep in mind that this is an issue not a support thread. The library and its documentation won't always answer all the questions regarding any specific case. In your case I'm betting that you need to take into account many factors that are out of scope from the library.\n. Have you tried the latest version ? Since 2 new versions where released since 7.1.2\n. great to hear about this :+1:  I'll close this issue since it is not related to the library in itself\n. @mjordan It would seems you encounter this PHP bug. Since this package is based on PHP's internal engine for parsing a CSV. There's not much I can do to fix that at the moment. We can make a PR on the gh-pages to document it. \n. @mjordan you may be able to work around the bug using the package stream features though. Look at the examples in the documentation\n. I've updated the documentation website to highlight this bug. \n- http://csv.thephpleague.com/properties/\n- http://csv.thephpleague.com/7.0/properties/\n. A Stream Filter has been added to CSV v9.0 codebase to fix this issue. This is the expected behaviour according to the documentation so I don't understand the issue ? \n. What you are requesting is not possible because of the way PHP reads a CSV. The document is treated as a stream so you can write a new one or append an existing one but you can not update selected rows without at least a temporary file. \nI would be more than happy to review a PR with your feature request if you can preserve the file cursor position between updates.\n. @abrahammontas I did not take it as a critique I've only highlighted the issues with your proposed feature. \nAs for submitting a PR, you don't need to be part of the phpleague to contribute to the library, just submit your work following the rules explained it the contribution guide and I'll be more than happy to review it\n. @vlakoff indeed you are correct it is a typo and the deprecation message was changed in the master. :+1: \nI should point out that I had a hard time finding this discussion since the comment was made on an already closed PR\n. TL;DR\nSo you are basically enabling Writer::insertOne to handle any type of argument as long as you provide the formatter that go along with it\n- by relaxing the formatter definition\n- moving the Writer::insertOne usage of str_getcsv into a formatter and applying it by default to avoid BC break.\nQuestion/Issue \nBy relaxing the formatter definition you are adding a BC break in any currently working formatter. Because They are all build knowing that they will receive an array. With your change the order in which they are register become important and may break the formatting. \n. > Only when the clearFormatters() method is called before any other formatter is added, this default formatter will be removed. \nBut the documentation does states:\n\nThe Writer class will see if the row is an array, if not it will try to convert it into a proper array;\n\nSo you are indeed introducing a BC on expectations.\nAlso according to the documentation around formatters the signature is \nphp\nfunction(array $row): array\nSo you are indeed changing a public API signature even if you are relaxing it, so to me this is also a BC break. It may not be obvious but the formatters goals is to format an already created/pushed array. It is not to generate this array to begin with. So here's what I would have done with your example. (I only kept the important parts).\n``` php\nfunction convertModelToArray(Iterator $iterator)\n{\n    foreach ($iterator as $model) {\n        yield $model->toArray();\n    }\n}\n$writer = Writer::createFromFileObject(new SplTempFileObject());\n$writer->insertAll(convertModelToArray($repository->all()));\n```\nThere's also a reason behind the current formatter signature. By expecting an array and returning an array you can more easily use the Pipeline pattern, which is the strength of using formatters. \nNow to be totally honest I do feel that the str_getcsv portion of Writer::insertOne should be removed in the next major release to enforce the array typehint on the method. Enforcing rules are better for maintenance that relaxing ones and it is the way forward even in PHP7.\n. To tell the truth I'm torn because the idea is good (the part where you remove str_getcsv was a eye opener to me) but the consequences makes me hesitant :( .\nYes the League pipeline is not that strict because it needs to be general purpose I guess. When I adapted it in League/Uri the first thing I did was to enforce typechecking on input and output.\nSo yes I'm gonna reject the PR even if it has great part in it that will definetly be added in futur versions of the lib.\nThanks anyway.\nPS: I see that you live in Belgium just like me, I'm in Brussels!! (damn I should go to more PHP groups in belgium but I always fail to find time for that) \n. @ILunie thanks for using this library.\nThe library is specialized in CSV manipulation. Adding CSV conversion to XLS is not plan as it would require a dedicated transcoder engine. I would recommend using a library dedicated to XLS instead. You can find many of them on Packagist\n. Hi @Lidbetter this question was already raised and answered to on the following issue #107 .\nPS: what RFC are you referring to ? \n. The return type is clearly documented using docblock.\nWhat I would rather propose is improve the documentation around this method on the documentation website by making a PR against the gh-pages. \n. @eXorus thanks for using the library.\nYou should read the library documentation. It may help you solve your issue.\n. I never tried this but you could use the library stream capabilities to replace the delimiter on the fly. If this works I'd like to see a blog post about how you did it as it may help other people in your situation.\n. I'm sorry I can not be of more help as this is not an issue per se there's not much I can do.\n. @jandayanan thanks for using the library.\nYou should refer to the library documentation website where you will find all the information needed to solve your issue.\n. @rosstuck This is not a bug it is expected behavior but it seems I removed the info in the documentation for v8. \nThis is documented in v7 documentation.\n\nAfter an extract/conversion method call, all query options are cleared;\n. The missing information is added to v8 documentation\n. in that case then you need to use the fetch method like so:\n\nphp\n$reader->setOffset(50);\nforeach ($reader->fetch() as $row) {\n  //starts at the 51th row...\n}\n. @piwi91 You can not simply move the limitIterator to the top as you will loose the \"SQL like\" nature of the query. \nIn SQL you first make the selection and then you apply the limits. your PR is doing the opposite, you first apply a limit and then make selection on it.\n. Looking at Spl documentation I would say that the 2 culprits are ArrayObject and CallbackFilterIterator.\n- ArrayObject can be replace by ArrayIterator and inherit the SeekableInterface. This change is trivial.\n-  CallbackFilterIterator is the real buttlenek as we can not simply remove or replace it and by definition this class can not implement the SeekableInterface unless you can come up with a better alternative.\n. @piwi91 I've changed ArrayObject -> ArrayIterator into the master branch. Did you find another solution for CallbackFilterIterator or could you close this PR ? \n. Did you read the documentation  ?\n. @jbehrouzi as a hint you could use the stream filter capabilities as explain in the documentation\n. @dersonsena the library does support large files through the use of SplFileObject\n@coreation the library does support TSV you just need to change the delimiter using \"\\t\"\nAll this is well explained in the documentation website.\n. @dersonsena the library does support large files it depends on how you use the library. This is a issue tracker not a support channel.\nYou should:\n- read the documentation\n- see if this question was not already answered in the issue tracker/pull requests\n- check the source code (the master)\n- or ask advises on stack overflow for instance\nIf you think that you are experiencing a bug or that a feature is missing then please fill in a bug following the CONTRIBUTING recommendation so that I could investigate your issue further.\n@coreation your issue/question is independent from @dersonsena so please follow the same advices.\nthanks,\n. @dersonsena if you use Reader::fetch instead of Reader::fetchAll for instance you can use the library. I use the lib with CSV with more than 1 Millions rows without any problem\n. Hi @Britic, thanks for the report. From your code I fail to see how you can be sure that the behaviour you are reporting comes from the League\\Csv package ?\nphp\nreturn \\Response::download($exportFilePath);\nyou seems to give your exportFilePath to a download method both of which are not produced by the package. Since I don't know how these (methods/functions) works I can not debug your issue maybe try to do what you've describe using only the package functionnalities then I'll be able to fix what needs to be fix ... if the issue still remains.\n. hmm what your are doing is very complicated. \nThere's a simple article on how to use League\\Csv  with Laravel you shoud check.\nI hope it does answer your question.\n. > In file https://github.com/thephpleague/csv/blob/master/src/Config/Output.php at line 209, there is an echo() statement. I don't think it's intended and should be removed.\nYes it is intended ... for the purpose of handling BOM sequence.\n\nThus, there is method called getInputBOM() but its real signature is getInputBom(). \n\nAs a matter of fact its real signature is getInputBOM because it is related to BOM :+1:  This will be patch in a bug fix release. thanks for the report.\n. in the meantime you can also submit a PR to correct this its easy to fix\n. thanks for the PR \ud83d\udc4d \n. Hi @andjelicsasa this issue is not related to League\\Csv but on how SplFileObject works. Before deleting your file you need to free any resource attached to it the easiest solution is\nphp\n$inputCsv = Reader::createFromPath($filepath);\n$inputCsv = null;\n//now you can delete your file\nFor a complete explanation please check here\n. @andjelicsasa this means that you have other resources pointing to this file elsewhere in your code. Just google for Text file busy php.\n. @mahngiel \nCould you submit the CONTRIB changes in another PR please as these changes should be decoupled with the current PR ?\n. @dequis \n\nWhich is something one would expect to decode the file on the fly, but for some reason it's asymmetrical and only applies to conversion, not reading or writing.\n\nIt's asymmetrical because stream support is limited on SplFileObject the underlying object used by the package. This means that registering a stream filter is not always possible.\nOf note, since version 8.1.0 you can simply do:\n``` php\n<?php\nuse League\\Csv\\Reader;\n$reader = Reader::createFromPath('/path/to/my/iso8859.csv');\n$reader->appendStreamFilter('convert.iconv.ISO-8859-1/UTF-8//TRANSLIT');\nvar_dump($reader->fetchAll());\n```\nusing PHP's built-in iconv stream filters which simplifies stream filter usage.\n. @dequis I've re-started working on league v9 and I was wondering does setting the input encoding really means that you should automatically transcode the CSV into utf-8 ? the setInputEncoding method was originally created to ease CSV transcode into XML or Json (which requires UTF-8 to work well), it is not meant to be use to transcode on the fly the CSV document while manipulating it. \n. > I do think that target encoding should implicitly be UTF-8 in all cases, but that's more of an opinion.\nThat's what it does with transcoding to XML or Json \ud83d\udc4d \nI'm strongly thinking of removing the setInputEncoding from the Reader/Writer object and move it to the RecordSet object so that it does not mislead the user into thinking that any translation is done automagically. However the naming still suggests that the Record are transcoded so maybe a name change also will be needed to clarify the method intent.\nand yes the only real way of autoconversion is through stream filter. \nOnce I've figured this out ... I'll make a PR referencing this issue \nthanks\n. To convert the input CSV document you are required to use the stream filters capabilities like explained in the documentation.\nin v9 see #210  setInputEncoding will be renamed setConversionInputEncoding. By renaming the method we should resolve the misunderstandings in its usage. \nHope this resolve your issue.. I'm going to close this issue has no fix can be done in v8 about it and v9 fix this by changing the method name. > If you have a UTF-16 encoded document CSV with \u3b2c (U+3B2C) in it, the csv splitter see two bytes ,;, pick one of those as the delimiter, add an extra unwanted column to the csv, and the cell-oriented transcoder won't even hear about one of those chars, probably throwing a truncated data error. So the stream filters should be used whenever possible.\nThe latest commit to the PR just does that \ud83d\udc4d . It uses stream whenever possible or else fallback to cell by cell conversion.\n\nWould it be a bad idea to keep (partial) compatibility with the \"old\" api as a __call method that creates a new Query and calls the corresponding method in that object? For example $csv->setOffset(10) doing return (new Query())->setOffset(10) transparently. Might be too much magic for your taste.\n\nAs you mentioned it would be partial compatibility and too much magic IMHO \n\nInstead of $query = (new Query()), how about $query = $csv->query()?\n\nThe goal is to have the Query being totally decoupled from the Csv so that if I have to treat 100 files at once I would to something like this \n``` php\nuse League\\Csv\\Query;\nuse League\\Csv\\Reader;\nuse League\\Csv\\Records;\n$query = (new Query())\n    ->setOffset(3)\n    ->setLimit(12)\n    ->addFilter($callable)\n;\nforeach ($csv_list as $csv) {\n    $data = $csv->getRecords($query)->fetchAssoc();\n    ....\n}\n```\n\nThe Query object could be initialized with a reference to the reader, like new Query($csv) or $csv->query() calling new Query(this). This way, the Query object could have a get() method.\n\nAgain this goes against the decoupling. And looking at your chaining one could easily loose what is returned when ? What the new API provide is an alternative like this:\n``` php\nuse League\\Csv\\Query;\nuse League\\Csv\\Reader;\n$query = (new Query())\n    ->setOffset(3)\n    ->setLimit(12)\n    ->addFilter($callable)\n;\n$csv = new Reader::CreateFromPath('/path/to/file.csv')\n    ->setDelimiter(\";\")\n    ->setInputEncoding(\"ISO-8859-1\")\n;\n$records = new Records($csv, $query);\n```\nAnd yes $csv->getRecords($query) is an alias of  new Records($csv, $query)\n. @frankdejonge the other option would maybe be 'Filter', I don't know... naming thing is hard :)\n. @frankdejonge @dequis @cordoval how about renaming the classes as follow\n-  Query to Statement to mimic how things are named in SQL language\n- Records to RecordSet since the Csv RFC calls each row a record.\n- AbstractCsv::getRecords to  AbstractCsv::select\nWhich would gives the following result:\n``` php\n<?php\nuse League\\Csv\\Reader;\nuse League\\Csv\\Statement;\n$csv = Reader::createFromPath('/path/to/your/iso8859-1.csv');\n$csv->setInputEncoding('iso-8859-1');\n$csv->setHeader(0); //specify the record to be use as header - can be an array too\n$stmt = (new Statement())\n    ->addFilter($filter)\n    ->setOffset(10)\n    ->setLimit(3);\n$records = $csv->select($stmt); \n$records = $stmt->process($csv); //or to enable the use of the same statement on different CSV objects\nforeach ($records as $row) {\n    $row; //converted into UTF-8\n}\n$res = $records->fetchAll();  //converted into UTF-8 with the header fields combined\n$col2 = $records->fetchColumn(2);  //converted into UTF-8\n$xml = $records->toXML();  //converted into UTF-8\n``\n. @dequis @frankdejonge I've reconsidered your idea of using__call` and implemented it on the Reader class. to view the full v9.x proposed new API you can look at this gist\n. This PR is closed in favor of PR #210 . This PR has been merge into the #205 so I'll close it. there's no example as it is trivial IMHO but maybe @frankdejonge will tell you otherwise\n. Without any actual code I can not be of any help. For what is worth the package uses stream filter whenever possible so you should be able to consume any large CSV without any problem.\n. > Has it been tried before to enter a lot of row at one time?\nUsually lot of rows means exporting Database rows using PDO or using a Generator. This works as I've been doing this with more than 100K+ rows. For me this is the recommended ways in term of memory usage and all, using a 90K rows array seems strange to me.\n. you're getting 90K data from a straight call to Google API's ? \n. So you do stock your data somewhere in between calls right ? This somewhere being a File or a DB. You can access it using an Iterator or a Generator and you'll be able to create your CSV without any problem.\n. @harikt there's nothing wrong with the library. By default the library thinks you are using a UTF-8 document. In your case the document is not UTF-8. Here's what I did:\n``` php\nrequire 'vendor/autoload.php';\nuse League\\Csv\\Reader;\n$file = DIR.\"/file.csv\";\n$reader = Reader::createFromPath($file);\n$input_bom = $reader->getInputBOM();\n//in your case $input_bom === Reader::BOM_UTF16_LE\n//so I've just added this following line (I assume that the iconv extension is installed on your server)\n$reader->appendStreamFilter('convert.iconv.UTF-16/UTF-8'); //converting to UTF-8\n$reader->stripBOM(true);\necho \"\";\n//get the first row, usually the CSV header\n$headers = $reader->fetchOne(0);\n$rows = $reader->setOffset(1)->fetchAssoc($headers); //Simpler than using the Reader::addFilter method\nforeach ($rows as $row) {\n    echo json_encode($row, JSON_PRETTY_PRINT), PHP_EOL;\n}\n```\n. @harikt strange I failed to reproduce this bug and I'm also using the 16.04 LTS\n``` php\n<?php\nerror_reporting(-1);\nini_set('display_errors', '1');\nrequire 'vendor/autoload.php';\nuse League\\Csv\\Reader;\n$file = DIR.\"/test.csv\";\n$reader = Reader::createFromPath($file);\n$reader->appendStreamFilter('convert.iconv.UTF-16/UTF-8');\n$reader->stripBOM(true);\necho \"\";\nforeach ($reader->fetchAssoc(0) as $row) {\n    echo json_encode($row, JSON_PRETTY_PRINT), PHP_EOL;\n}\n```\n. @harikt thanks I found the issue ... I'll release a patch to fix this when I have time :+1: \n. > Also in the case as I mentioned when calling $reader->getInputBOM() the ID was null on json_encode data.\nI've looked into this issue and in fact again there's no issue. The thing is if you use stream filter you don't need to explicitly call the stripBOM method.\nThe conversion is done prior to generate the array row from the CSV document so the BOM sequence is already removed.  (I didn't know this, since I've never really used the stream filter on BOM document). \nSo the code should be:\n``` php\n<?php\nerror_reporting(-1);\nini_set('display_errors', '1');\nrequire 'vendor/autoload.php';\nuse League\\Csv\\Reader;\n$file = DIR.\"/file.csv\";\n$reader = Reader::createFromPath($file);\n$input_bom = $reader->getInputBOM();\nif ($input_bom === Reader::BOM_UTF16_LE || $input_bom === Reader::BOM_UTF16_BE) {\n    $reader->appendStreamFilter('convert.iconv.UTF-16/UTF-8');\n}\nforeach ($reader->fetchAssoc(0) as $row) {\n    echo json_encode($row, JSON_PRETTY_PRINT), PHP_EOL;\n}\n```\nThe stripBOM method should only be used if stream filter can not be used to convert your CSV document to UTF-8.\nI should document this into the library documentation.. or you could do it \ud83d\udc4d \n. version 8.1.2 is released with the fix\n. @eusonlito you can already do this with the Reader::fetchAssoc method.\nThe feature is already in discussion for the next major release see #178\n. @pezzetti please refer to the documentation the createFromPath named constructor accepts the same arguments as fopen . So the answer is yes\n. @markitosgv Thanks for using this library. \nWhat you are describing is not a bug, the library works in UTF-8 so the easiest way for you to resolve this issue is to convert your new rows into UTF16 prior to adding them to your CSV document. The setOutputBOM method job is to prepend the correct BOM sequence to the downloaded document, it does not guarantee that your data is correctly encoded.\n. @Sat02 what is your PHP/HHVM version and your version of the library ? I suspect you are using a incompatible versions\n. @GaryJones thanks for using the library.\nAbout your issue since CSV document are treated as stream, there's no other way of doing it than how you describe your proposed solution.\n. here's what I did \n``` php\nuse League\\Csv\\Writer;\n$writer = Writer::createFromFileObject(new SplTempFileObject());\n$writer->insertOne([1, '01', '001']);\necho $writer, PHP_EOL;\n```\nAnd I do get this\n1,01,001\nSomething else must be wrong in your settings.\n. @vrubiella thanks for using the library but I don't get your problem. The library comes bundles with a test suite that does test for named constructors, so why trying to mock the named constructors ?\nLast but not least what you are suggesting was implemented in earlier versions of the library and led to too many issues that were all resolve with the use of named parameters. \n. @vrubiella if you are on PHP7 I'd suggest using anonymous class or I would change the function signature to \nphp\nfunction loadDataFromCSV(Reader $csvPath)\nThis would ensure that your fonction does not do multiple things and enable your function to work with all possible range of CSV source IMHO\n. if you are so afraid of touching the filesystem then maybe use this https://packagist.org/packages/mikey179/vfsStream \ud83d\udc4d . . Hi @WebSpanner,\nThanks for using and submitting this PR. Unfortunately, this issue has been raised and answered in the past see #147 . @IgnitedCoder please provide an actual PHP code as I can not reproduce your issue and thus determine if it is a bug or a misusage of the library.\n. your file is not a real tab separated file if each row starts with a '\"'. That's the issue.. If no values inside the row uses the '\"' you could use the stream filter to remove the '\"' prior to reading. Please use the template to describe and submit some snippets otherwise I will be difficult to address your issue. Please remember that only issue related to the library features will be answered. There are other better place to help you manipulate CSV files.. This is not a bug but the behavior will be decoupled from the Reader class in the next major so that the limit parameter is not reset between calls see #178 . This issue is resolved in the master branch ... rejoice my friend as the answer is being review for release. No you did not miss anything ... BOM is only added if you output the data somewhere using the __toString is one method to do so. This is explained in the documentation. The v9 public API is almost complete. One or Two methods names may change and one method may be dropped but everything else is there.. these hint will be put into the documentation when the upgrading pages for the next major release are written.. @JC5 yes indeed it is marked as deprecated because work has started on the next major release and Reader::fetch will be indeed removed from the public API in the next major release. This is the reason it is marked as deprecated. There's no alternative right now for its usage but marking it like that is a hint to users that this method will be removed. AFAIK this does not in any way prevents anyone from using the method right now.\nHope this answer your question as it is similar to #206 . @joshbrw Please refer to PHPdoc documentation. > If it is superceded by another method\nthere's a If at the start of the sentence :). yes and having a @deprecated in the docblock does not mean that the method won't work anymore.. it is an indication about where the package will go next. Really I don't see the problem with this ? This is informative only. . > I guess it all depends on your view of what deprecated means\nNope. The definition of @deprecated is the one PHPdoc put out and this is the one I'm following. I could rephrase that by saying that It depends on how PHPStorm interprets it :) .. At everyone, I had a discussion off record with other leaguers and I decided to make a patch release which will remove most of the @deprecated. Once the others bug fixes are reviewed the patch will be released later this week or next week. . version 8.2.1 is out with the fix. @mbrodala this question has already been raised and answered please #206 . @Gabriellpweb Thanks for the PR but I don't get the reasoning for this feature ? The file is already saved to the disk when using the Writer class ? What's the added value ?. But if you use the Writer class the file is saved to the disk\n```php\n<?php\nrequire 'vendor/autoload.php';\n$csv = Writer::createFromFileObject(new SplFileObject('path/to/file.csv', 'w'));\n$csv->insertAll($data_to_insert);\n$csv = null;\nif you look into `path/to/file.csv` the data is inserted. So I don't understand your PR.\n. @ewistrand you can look into the [examples](https://github.com/thephpleague/csv/tree/8.x/examples) folder. @shadowhand it works because the latter uses `SplTempFileObject` while the first example uses a userland `StreamIterator` to enable `Writer::createFromStream`. I'll review your fix and merge it since I have to release a patch version with other fixes hopefully later this week or next week.. @shadowhand while waiting for the patch in your code if you change\n$write = Writer::createFromStream(fopen('php://temp', 'r+'));\n//by\n$write = Writer::createFromFileObject(new SplTempFileObject());\n```\nIt will work. . @shadowhand the PR #215 should fix your code could you try it please if it's ok for you I'll release the patch. version 8.2.1 is out with the fix . this PR is superseded by #215 so I'll close it . I believe there is no getCsvDocument in any stable version of the package. The master which is stable should not be use in production has it expose an intermediary API to enable working on the next major stable version. \nTL;DR: getCSvDocument will be remove in the final v9 API and does not exist in v8 AFAIK\nI would rather use the getIterator object to get access to the inner Iterator object.\nand since you are using a SplTempFileObject .. you will never get the file path.. @stephenvicino\n- why adding twice the HTTP header if you want to have specific header for that ? Maybe the error comes from that ?\n- have you checked the data you are inserting ?. > why adding twice the HTTP header if you want to have specific header for that ? Maybe the error comes from that ?. http://csv.thephpleague.com/basic-usage/#outputting-the-csv it is explained in the documentation. then it means you have a problem with your contents :)\n```php\n$csv = Writer::createFromFileObject(new SplTempFileObject());\n$csv->insertOne(['head 1', 'head 2', 'head 3']);\n$csv->insertAll([\n    ['a', 'b', 'c'],\n    ['e', 'f', 'g'],\n]);\nheader('content-type: text/csv; charset=utf-8');\nheader('content-disposition: attachment; filename=\"User-List-'.date(\"Y-m-d\").'.csv\"');\n$csv->output();\n```\nThis works for me as expected. If it does then it means it's your data at fault. This means that you are already outputting a blank line prior to using the output method in your script. The blank line is not added by the library. I'm closing this issue as it is not related to the package in itself.. I fail to reproduce your bug with the file you are providing I get the following result:\nphp\n$csv = Reader::createFromPath('withbom.txt', 'r');\n$csv->setDelimiter(';');\n$csv->stripBom(true);\nforeach ($csv->fetchAssoc() as $row) {\n    var_dump($row);\n}\necho $csv, PHP_EOL;\nphp\narray(3) {\n  'ID' => //no BOM found on the ID key\n  string(1) \"1\"\n  'NAME' =>\n  string(2) \"Me\"\n  'EMAIL' =>\n  string(14) \"me@example.com\"\n}\n\"ID\";NAME;EMAIL  //the BOM is still present\n1;Me;me@example.com\nAre you sure about the issue ??. To be complete if you do the following\nphp\n$csv = Reader::createFromPath('withbom.txt', 'r');\n$csv->setDelimiter(';');\n$csv->stripBom(true);\nforeach ($csv as $row) {\n    var_dump($row); //the BOM sequence IS NOT removed\n}\nThe BOM sequence won't be stripped  because your are calling the inner Iterator without any extraction. Instead you are require to use one of the extract methods to enure the stripping mechanism is used:\nphp\n$csv = Reader::createFromPath('withbom.txt', 'r');\n$csv->setDelimiter(';');\n$csv->stripBom(true);\nforeach ($csv->fetch() as $row) {\n    var_dump($row); //the BOM sequence is removed\n}\nThis is by design and won't be fixed in the 8.x series as it would introduce some BC breaks. The next release will correct this behavior as BOM stripping is done automatically everytime.. @cdarken no it should not matter. And yes Reader::fetchAssoc is a extracting method.. @cdarken Ok I understand now. You must always call stripBOM before each extract method call. This is why I changed the behavior in the upcoming version because having to call the stripBOM method each time is kind of stupid :) .. @cdarken yes it is specified... \nyou can still access the docs on the master branch. Here's the relevant part\nhttps://github.com/thephpleague/csv/blob/master/docs/query-filtering.md#query-filters\n\nThe query options methods are all chainable except when they have to return a boolean;\n    The query options methods can be called in any sort of order before any extract/conversion method;\n    After an extract/conversion method call, all query options are cleared;\n. @rbruhn Having Json into CSV records is a recipe for disaster :) . Anyway how is you Reader object configure ? Did you change the escape character ? The problem may be raised by that. IMHO this is not a bug.. I believe there's a conflict between the CSV characters control and Json characters controls for instance the default CSV controls are all used and have meaning in JSON specification. Unless your CSV uses original control characters you are bound to have so type of mismatch IMHO this is because the CSV was badly produced to begin with. So there's not much to do to work around this. You should check on SO for help.\n. you could use the stream filters but I won't guarantee the result. I'll close this as this is not a issue more a general question on how to parse a specific content for a specific CSV.. > . using double quote '\"' as the escape character resolved my issue.\nAs I thought it was a problem of finding/choosing the correct character controls \ud83d\udc4d . @yupe Thanks for the reported bug... as I'm still working on v9 this will be fix in the next commit.\n\nAs a side note in your example you have created a CSV file with the w open mode flag and then used the ouput method on it. This is not recommended because the method will reset the CSV document pointer and anything written will be truncated as per w expected usage. This is true in v8 as well. An alternative would be to use w+ instead, for instance.. The bug fix has landed on the master branch I'll close this issue.. following your remark.. I've added a new method AbstractCsv::chunk to v9 to hopefully ease framework integration when creating a Response object. \nV9 is in review period if you have other remarks now would be the perfect time :+1: . HI @php- did you read the documentation as this is well explained there.  see http://csv.thephpleague.com/8.0/inserting/ . \nOf note:\n- the Writer behavior strongly depends on the CSV document open_mode you have chosen.\n. Well since I don't know what you are trying to accomplish I can't help you what I can tell you is what's written in the documentation :\n- the Writer is constructed to work with a single file at once \n- the Writer relies on stream and SplFileObject meaning you can't use cloning\n- the Writer actions are based on the open_mode arguments from fopen (to be simple)\nSo:\n    - cloning the Writer is not possible since cloning a stream resource ou SplFileObject is not possible\n    - iterate over a Writer object is highly discourage because of cursor pointer loss and open_mode choice (may erase your CSV document on rewind for instance)\nAgain this information is present in the documentation so I don't know what else you need.. The code you are using is for League\\Csv 9.+ which is documented on http://csv.thephpleague.com/9.0\nThe current stable version is League\\Csv 8.x which is documented on http://csv.thephpleague.com/8.0 and whose public API does not contains the Reader::setHeaderOffset method.\nWith the next major version being released soon the documentation website has  been updated for that released. @PsychicCat why do you want to remove it ? the output method works like php fpassthru you should just die after using it. @Dumk0 nothing is wrong with the documentation. v9 will be released soon, so the website has been updated accordingly. On the link you've provided you have access to all documentation for each version (v9, v8 and even the no-longer supported v7). @youvtr that's because you still have a reference to the file in your $reader instance yous should do this instead.\n```php\n <?php\n$fileUploadedPath = '/path/to/file.csv';\n$reader = Reader::createFromPath( $fileUploadedPath );\n// do some stuff with csv from reader api\n$reader = null;  //this line make sure that the internal reference to the file is removed\nunlink( $fileUploadedPath ); //unlink should work now.\n```\nThis is a PHP limitation not a CSV library bug.. Then it only means that somewhere else in your script you still have a resource or a reference present. But it is not a League\\Csv issue per se. Please refer to #173 . @baj84 this question has been asked several times on this issue tracker. Please read the documentation where AbstractCSV::output is explained.. @pardalsalcap this question has already been answered in the issue tracker please refer to #113 . @gerald27 League\\Csv 7.* is not supported anymore do you get the same result with League\\Csv 8.x ?. @gerald27 could you provide the source data or a small part of if so that I could reproduce the bug, if it is a bug If I can't reproduce it I can investigate it :). I believe this is not a bug could you change your code to this \n```php\n<?php\n$reader = Reader::createFromPath($file->getRealPath());\nreturn $reader->stripBOM()->fetchAll();\n```\nLeague v8 and before does not remove automatically the BOM string from the first field of the first record. You need to explicitly call the stripBOM method. before any call to any extract method. \nBy the way this behaviour will be fix in the next major release \ud83d\udc4d . The file I received was in iso-8859-1 so I did the following:\nphp\n$csv = Reader::createFromPath('test.csv', 'r');\n$csv->appendStreamFilter('convert.iconv.ISO-8859-1/UTF-8//TRANSLIT');\nvar_dump($csv->fetchAll());\nNo extra characters was shown, before and after but the data was correcly converted to UTF-8. if you are importing from SQL to CSV then you are using the Writer class :) . If you are using the Writer class then you can use the Writer::addFormatter to convert NULL to the empty string check the documentation for that.\nif you are exporting from CSV to SQL using the Reader class. When using for instance the Reader::each method nothing prevents you to format your data prior to inserting it in the database.. The Reader enables you to access your data, how you choose to format or transform the returned CSV records is up to your script/business logic and therefore is out of scope for this library.  . no you can directly format or transform your record as the Reader returns it using a function which accepts the returned record and transform it according to your needs. this has nothing to do with version 8.0. v8 requires PHP5.5. It must be another package.. > Maybe you should try it to your self sir,\nThis package has been developed in PHP5. Please look at your composer.json and stop making assumption without testing. This package is tested from PHP5.5 -> PHP7.1. @Fabbio86 I believe the issue is that you have downloaded the master instead of downloading one the release tag. I've updated the documentation website with that information.\nHope this answer your question.. @shakisha did you try your script on a standalone page... because it is working for me. Maybe something else in your script is causing the memory error. >  but instead of downloading, its showing 301 redirect in console\nif you have a redirection it is not an issue with the library here's what Writer::output ... as you can see there are no redirection involved... if you are using a framework you should not use output directly ... http://csv.thephpleague.com/8.0/basic-usage/#outputting-the-csv \ncheck the section about integration in a framework. Hi @joskfg thanks for the submitted PR. I have some reservation if this is necessary in the library. Here's my thought.\n\nThe library should be and is still really agnostic in how it should be used and you are suggesting adding an opinionated way on how to deals with remote streams.\nI fail to see how is this not already covered by the createFromStream named constructor added in 8.2 and still present in v9 ?\nLast but not least IMHO your solution belongs in an independent package which should then suggests using league/csv or if you can create such package in time before v9 is out the other way around. For instance, I have such factory library for instance to deal with PSR-7 but for the same reasons given above I did not included it in the main league/csv package.\n\n. @joskfg you are absolutely right, in a ideal world league CSV should need only one constructor which accepts a (stream and a SplFileObject object. But let's be realistic, the current API covers more than 80% of the average construction possibilities. And the missing alternative are easily manageable using the current API.\nThe PR on itself does not add anything to the CSV parsing and manipulation. It only offers a new way to access a CSV document and only partially as you can not use this technique for writing to a CSV  document. So we are introducing a new layer of difficulty for the developer who will have to consume the library for a partial gain. \nIf this PR is accepted on what ground will I refuse for instance a PR for handling PSR-7 objects or HttpFoundation response/request ? This is just opening a trend which IMHO will only add maintenance burden on a fairly simple package.\nOn the other hand providing these solutions as separate plugins to the main package would give a better choice to the community without having to maintain them on the main package.\nMy 2 cents.. Since you are building a Factory, you can look at this example https://github.com/bakame-php/psr7-csv-factory you could even fork it and improve it if you want.    I'm not asking to use PSR7 you can use this repo as an example for adding new factory method that's all.. I will close this PR as you will be working on a factory package for the stream wrapper.. This is strange are you sure about your CSV document integrity? There are no limit at all in the library. Hi this issue has been raised before see #24 you can't just do that using native php functions, the only correct way to achieve empty enclosure is to use the library stream filter capabilities or to develop your own userland CSV parser . @alperyazgan thanks for reporting this bug a fix is on its way \ud83d\udc4d . Yes all CSV controls are fixed in the patch . It is taking a bit of time because github has some issues right now. I'll put it on prod ASAP.. version 9.0.1 is released. \n@alperyazgan  Of note, in your example the RFC4180Field filter may not work as intended as you are setting your delimiter after adding the filter. You should add the filter once you have sets your CSV controls otherwise the results may be unexpected.. This is a documentation issue that has been resolved by improving the documentation. a quick workaround would be to use a stream of a SplFileObject and once you have all your data use directly fread on them instead of  using the league object something around these lines. You should adapt the code \ud83d\udc4d \n```php\n<?php\n$file= new SplTempFileObject();\n$csv = Writer::createFromFileObject($file);\n$csv->insertAll($data);\n$csv = null;\n$file->rewind();\nwhile (!$file->eof()) {\n echo $file->fread(1024);\n}\n````\n. This is a documentation is bug fixed thanks for reporting the typo. @AC-TimRourke thanks for the PR but I have one major objection for this as stated on the documentation website:\n\nOnce a new major version is released, the previous stable release remains supported for six more months through patches and security fixes.\n\nSince AbstractCsv::chunk is not a patch nor a security fix I can not merge your PR in the 8.x branch.\nHaving said that, your PR also as a bug. You are assuming that AbstractCsv::getIterator will always return an object which exposes the fread method, which is not true since 8.2 and the introduction of stream support. So What I would suggest is either fork 8.x (since you are guaranted that no new features will land on it) or use the proposed workaround.\n. This is fixed on the master branch you can clone it and see if you still get the error. If no error is shown I'll close this issue.. don't worry it was ok for me that you've close it \ud83d\udc4d . thanks for the typo fix \ud83d\udc4d . In the last stable release the each method has been removed, use the getRecords or the getIterator method. If you want the sanitize your data before saving it you can use the addFormatter method or the stream filter API on the writer object. All of this is well explained in the documentation website. @graemedewe everything I said for v9 is still relevant for v8. Just read the documentation :). @nwhitt League CSV and Flysystem are two independent packages so they do not follow the same exception mechanism :) .\nHaving said that I failed to reproduce your error with you given code I get this:\nPHP Fatal error:  Uncaught League\\Csv\\Exception: fopen(/does/not/exist.csv): failed to open stream: No such file or directory in ....\nThere's already a test to validate this output in the test suite. Are you sure about the error ? Maybe there's something else at play here\n. Good catch this is a easy fix. I'll try to release a patch this week or the next one...  or you can submit a PR with the fix if you want. @garygreen The version bump was done to take into account a bug fix in PHP's CSV implementaton see http://www.php.net/ChangeLog-7.php#7.0.10. @Bilge I believe the method behaviour is sane and predictable as it is clearly documented. I don't get the problem with the current method signature. Unless you show me how it could be misleading ?. @Bilge have you read the documentation ? If so you should already have an answer to your question ? Just use the correct open mode. \n\nIf that's your honest response, then excuse me for saying, but it seems you don't have a very good understanding of file permissions. \n\nAgain if you have taken time to read the documentation we would not have this conversation. As everything is explained there with examples.. @paulcanning have you read the documentation ? especially about the Reader object ?. So you have all the informations needed I don't understand what's missing ? you want me to show you how to validate a CSV ? I believe this is a per project mechanism. . > I just want a simple validation of the file. There must be a simple yes or no validation method, right?\nNo . You are responsible for validating your CSV. Because each CSV has its own rules . Again I don't know use the filter API or the reader methods it depends on what you want to validate the API provides different hooks use the one that can help you.. @paulcanning Can I close this issue?. #256 was closed because of no real issue and poor remarks from your part. If you found the documentation lacking please provide a PR to improve them or at least be constructive. Same with this issue. Instead of complaining please provide a PR as I found no issue with the current API which is documented. I don't tolerate poor remarks or attitude on open source projects that I maintain. If your don't like the current API you are still free to fork the project and do as you please but orherwise I would request that you calm down.. @bilge submit a PR it will be reviewed and if it is found useful it will be merged. Thanks. Yes but it will have to wait until the next major release. Since : \n\nv9 has been recently released \nthere's more or less 18 months between v8 and v9\nand it would require real major improvement (which is the case between both version)\n\nCurrently I can not anwser this question.. I understand your frustration but I too don't find the need to release a major release just to fix something which is IMHO not broken.. After reading the documentation it becomes \nphp\n(League\\Csv\\Reader::createFromPath('foo.csv', 'r'))->fetchOne();\nEt voil\u00e0 !\n. Can we agree to disagree. I understand the changes you want to make but I don't think releasing a new major release just because someone refuse to read the doc is compelling argument either. Yes a new version will improve its settings thanks to your remarks but in the meantime if one read the doc, the solution is crystal clear.\nAgain, if you don't want to wait for a new major release you have plenty of solutions by using SOLID principals or by forking the package. . @Bilge \n\nDid I refuse to review any of your suggestions: NO\nDid I said that any future version won't benefit from your input : NO\nDoes reading the documentation provides enough information to fix your issue : YES\nDid you propose a PR to improve the doc : NO\nDid you propose a PR to fix issue : NO\nDo I find fixing this issue important enough to release a major release now : NO\n\nAnd as an extra:\n\nDo I find you stupid : NO\nDid I try to have a constructive conversation with you regardless of your remarks : YES\n\nAm I wrong maybe but as the maintainer of this package I have to make the final call on things to fix and how they will be fixed/merged. \nUnless I get a PR for this, this issue will stay open and mark as enhancement for the next major release.. @btmash thanks for trying to resolve this issue but it has been tagged for the next major release because patching it like you did introduces a tiny BC break and since we are following SEMVER bumping to a new major version just because people don't want to read the documentation seems to be overkill. I believe even using a IDE will typehint and inform the user about the missing parameters (but I may be wrong). Anyway, I would suggested improving the documentation for now and improve the constructor signature for the next major release whenever this one will come around.. like stated there are no real schedule to release a new major version It depends on enhancement on PHP front or on dropping old PHP versions or coming up with new ways to improve CSV process. So the best bet is improving doc if there are not enought clear at the moment.. @pboethig what do you mean ? I don't understand your request :'( . . The reader does not modify the CSV so \"adding\" columns is not possible per se. \nHaving said that nothing prevents you to add each field of your column inside a foreach\n```php\n<?php\n$csv = Reader::createFromPath('file.csv');\n$new_column_fields; // should be an array or an ArrayAccess object\nforeach ($csv as $offset => $record) {\n    $record['new_column'] = $new_column_fields[$offset] ?? null;\n}\n```\nIf this is something you are doing frequently you could even use and IteratorIterator object to improve this workflow.\nLast but not least, if this change must be made permanently you are required to use a Writer object to create a new CSV file with the added column.. @pboethig can I close this ticket?. This issue as already been reported and explained in issue #254 . @Bilge correct me if I'm wrong but it is the same code right ? So it should fall in the same category since this code is covered by the same test in the test suite like explained in #254 . @Toilal thanks for submitting this enhancement. Don't forget to update the documentation too. As this means that a non seekable CSV can not use any of the output methods. FWIW you could have gone with \nphp\n$csv = Writer::createFromFileObject(new SplFileObject('php://output', 'w'));\n$csv->insertOne(['a', 'b', 'c']);\nIt works as expected but it will trigger an Warning instead of a Error if you try to use any output method. Maybe we could do something about that too ? I don't know\n. @Toilal just for your information I've just push a commit to enable non seekable stream. This feature is stable but will be release with version 9.1.0 ... when I have time . yes it will be updated on the next patch release along with other patches in the pipe. already done on my local branch but thanks for this offer \ud83d\udc4d . @Toilal could you show me a test code when that happens ? . Wouldn't that return a TypeError before even getting to __debugInfo ??. The more I think about it the more I'm thinking the seekable property should also be present on the AbstractCsv class too. So that the check is done once ? What do you think ? . @Toilal If the trick works as expected then yes adding a note somewhere in the documentation is a good enough solution for me. If you can submit a PR with the added info in the documentation I'll gladly merge it. . Yes, use the master there are still some ironing that needs to be applied before releasing 9.1.0. Hopefully if I get some free time 9.1.0 will be release next month.. @btmash usually I update the doc when a feature is complete otherwise I forgot about it because the doc is on the master it get updated when the new feature land. It's easier for me to maintain the library like that. \nIn the meantime as far as I remember nothing prevents you from copying the EncloseField class and use it with the current stable release. This is just enhancement so nothing is update elsewhere in the code.. @klaude For what I understand about csv injection, you do not need to add anything to league csv to make it work. as we talk the package already allow adding some sanity/escaping check prior to inserting your data to the CSV document. So what you really need is provide a clean implementation of csv injection prevention in form of a Formatter and/or a StreamFilter. Depending on your work I may found it useful, maintainable and thus incorporate it but I would reserve my final thought upon seeing the PR... not before.. @klaude having read in more depth the article you linked I have to wonder if this is a job to be shipped with League CSV. Basically the article stress that this is not a CSV issue per se but a Spreadsheet one and instead of fixing spreadsheet software we are about to pseudo fix a CSV document without the knowledge of how and who is going to use it. That a pretty dangerous decision to make ... In some regards this reminds me of PHP's escaping data model which was broken to begin with. Merge into the master branch I'll close this issue \ud83d\udc4d . @klaude here's a POC which works so it was simple to add But I'm still skeptical in its usefulness and/or binding it to the package. @marksparrish strange \n\nMaybe missing in autoloader?\nFunction is not referenced in the use statements like bom_match is the AbstractCsv.php file\n\nfunctions are loaded by composer.json maybe something is wrong in your autoloader ? . Normal they're define in the same file. this is expected behavior please read the documentation to select the appropriate open mode.. It is written in the documentation. But if you find the documentation unclear you are free to submit improvement in PR. @csiszarattila I've updated your PR by using PHP7 null coalescence operator. There was another occurrence of error_get_last in the codebase so I've applied your fix their too and improved the test suite. thanks for the contribution. \ud83d\udc4d . @matheusdelima please refer to the documentation where this is explained. Strange attempt 1 should work or else the test suite would fail \ud83d\ude22. Could you provide a CSV snippet or at least the first rows so I can replicate your bug because right now I can't reproduce it. @ddinchev I understand the issue ... it's because the Statement object is an immutable value object  so you should do this \nphp\n$csv = \\League\\Csv\\Reader::createFromPath(__DIR__ . '/test.csv', 'r');\n$stmt = new \\League\\Csv\\Statement();\n$stmt = $stmt->offset(2); //note the re-assignment a better solution is shown below \n//or $stmt = (new \\League\\Csv\\Statement())->offset(2);\nforeach ($stmt->process($csv) as $record) {\n    print_r($record);\n}. The problem is not in the library but on how Users:all is created. You should try to use a Iterator or a generator like shown on the documentation website. using LimitIterator does not work as it uses the broken seek method.. patch landed on master... . @ryanmortier thanks for using the library. Out of the box .. the library treats the CSV as a stream as such you should not have any memory issue. But like stated in the documentation some operation are memory intensive like doing a count on the records because you force the library to iterate over the full CSV. So unless your CSV is short or counting is required you should avoid such operation. Please refers to the documentation for other methods/operation that may introduce a memory penalty.. Please refers to the documentation website where everything is explained. @sentientsolutions as indicated in the CHANGELOG.md and on the documentation website the functionnality is now on a separate function defined in the League\\Csv namespace.  http://csv.thephpleague.com/9.0/connections/controls/#detecting-the-delimiter-character. yes please squash them \ud83d\udc4d . thanks for the PR \ud83d\udc4d \ud83c\udf89 . @scottgrayson the solution is described in the README file. @Jalle19 thanks for your PR. Indeed when 9.0.0 was released this bug on the return type of all the named constructors methods was introduced. The issue that I have is that your resolution may be  considered a BC break by some. If it's not a BC break then you also need to fix the other named constructor return type (ie all the createFrom* methods) ? \nBottom line, if you can convince me that this is not a BC break and if you complete the PR by fixing the other named constructors I'll gladly merge your PR.. @Jalle19 TBH I too don't think it is BC break since removing the return type does not restrict or change the current public API. So IMHO we can move on with your PR once finalized ... unless someone disagree  :+1: . let's merge this .. I'll release a new CSV patch version later in the week if I forgot just ping me here again \ud83d\udc4d . @landsman thanks for using the library. Your issue has nothing to do with the library please refer to mbstring documentation to find out which encoding your require and how to write it. . Bug fixed in the master branch .. a patch version will be released later this week with the bug fix.. thanks for reporting and submitting a PR to resolve to bug :+1: . @strarsis why do you consider this to be a bug ? For your CSV to be valid you need to escape the enclosure ... with another enclosure character as per CSV rules. So if your CSV is wrongly formatted the output too will be wrong.. @strarsis making the parser more tolerant is a recipe for disaster. As it is, the parser is already extremely tolerant IMHO as it does not out of the box follow CSV parsing as per the RFC \ud83d\ude04  ... and that on itself is a debate on its own. \nHaving said that if you can come up with such a mechanism I'm open to reviewing it and even merging it if your solution works. In the mean time I would encourage the easiest path which is always to validate your input prior to submitting it to any third party or library like league/csv. You can use stream filters for that see https://csv.thephpleague.com/9.0/connections/filters/. The other alternative would be to provide a way to switch from fputcsv to fwrite. But it is not possible right now with the current API. @judgej the character break is always \\n to change it I use fwrite. So you should not worry about that.\nhttps://github.com/thephpleague/csv/blob/9c8ad06fb5d747c149875beb6133566c00eaa481/src/Writer.php#L188-L191. @jagDanJu Are you sure your CSV is an correctly UTF-8 encoded ? The fact that the library remove the BOM sequence does not mean that it also convert back the CSV content to UTF-8 you must still do it manually. Here's a simple example of how to do it. \nOf course your CSV must supports stream filters.\n```php\nuse League\\Csv\\CharsetConverter;\nuse League\\Csv\\Reader;\nfunction csv_to_utf8(Reader $reader)\n{\n    if (!$reader->supportsStreamFilter()) {\n        return $reader;\n    }\n$input_bom = $reader ->getInputBOM(); //returns the BOM sequence if any\nif (in_array($input_bom, [Reader::BOM_UTF16_LE, Reader::BOM_UTF16_BE], true)) {\n    return CharsetConverter::addTo($reader, 'utf-16', 'utf-8');\n    //return $reader->addStreamFilter('convert.iconv.UTF-16/UTF-8'); //if iconv extension is installed\n}\n\nif (in_array($input_bom, [Reader::BOM_UTF32_LE, Reader::BOM_UTF32_BE], true)) {\n    return CharsetConverter::addTo($reader, 'utf-32', 'utf-8');\n    //return $reader->addStreamFilter('convert.iconv.UTF-32/UTF-8'); // if iconv extension is installed\n}\n\nreturn $reader;\n\n}\n$csvData = Reader::createFromPath($path);\ncsv_to_utf8($csvData);\n$csvData->getHeaders();\n. @purplekrayons you can use the `League\\Csv\\Statement` class for instance. Please refer to the documentation website for more informations or options.. https://csv.thephpleague.com/9.0/reader/statement/#processing-a-csv-document or you can simply use the foreach construct and format the record keys whatever suits your logic . you are complicating things for no reason :smile:php\n<?php\nuse League\\Csv\\Reader;\n$csv = Reader::createFromPath('/path/to/file.csv');\n$csv->setHeaderOffset(0);\n$headers = array_map('trim', $csv->getHeader());\nforeach ($csv->getRecords($headers) as $record) {\n    //done;\n}\n```. @hillelcoren thanks for using the library do you have a snippet code I can test to try to reproduce your issue. Otherwise there is no way for me to investigate and/or resolve your issue.. did you set the delimiters ? . did you try this ?  https://github.com/thephpleague/csv#configuration\nAlso reading fopen documentation page I stumble upon this \n\nWindows offers a text-mode translation flag ('t') which will transparently translate \\n to \\r\\n when working with the file. In contrast, you can also use 'b' to force binary mode, which will not translate your data. To use these flags, specify either 'b' or 't' as the last character of the mode parameter. . @inquisitive-stha thanks for using the library.\nHow can you be certain this issue is from the library and not any other part of your code. I'm asking because I've just tried your code on a 7M+ records CSV and I had no memory issue at all.\nAre you sure your issue does not come from your upload script ? . Again delimiter has nothing to do with your issue. And like I said I'm working with a 7M+ records CSV and have no memory issue. the library uses stream internally to reduce memory usage. That's why I'm asking hw can you tell this memory usage is coming from the library ... try your script with a file already present on the server if it work .... and it should then it means that the issue is not related to the library but to how you upload your file.. > It is successfully uploading the file. However, it takes quite a lot of time to upload the file, so I am checking it by directly passing the uploaded file path.\n\nThat's already raises some concern IMHO. You are trying to parse a file which is not complete. Which leads to unexpected behaviour.\n. You could try using Reader::createFromFilObject  instead and see the error still occurs if yes then it's not the lib. If no then it's the stream object which behave strangely. You do understand that the delimiter is not the issue. The issue is with your file. You set whatever delimiter you want with the setter method. Once set the delimiter does not change. The question no becomes What is the size of each record? Do you have thousand of fields or just a few? But as stated in the beginning today's I have worked with a 7M+ CSV without any memory issue using your provided code . The easiest solution is to try to parse your CSV data using native PHP functions fopen or SplFileObject which is what this library is using under the hood. If you can not succeed with those this library won't help either.. No I did not . @inquisitive-stha this is what I've been telling you all along it is an issue with your file not the library. There's nothing I or the library can do to solve that \ud83d\ude22 . @inquisitive-stha I simply don't know . If it was a bug in the library I would look into it but since it is not I can only give you advices which are use directly PHP functions and if they fail then try to look into the file to see what is wrong with it.. What you've just did is written on the front page of the library https://github.com/thephpleague/csv/blob/master/README.md#configuration so you just need to do the same. @augz thanks for using the library. Did you try to detect and update the CSV encoding charset before using the fetchAll method? Please refer to the documentation https://csv.thephpleague.com/9.0/converter/charset/. I've given you a link to the documentation for v9 seems you are using v8 but the basic premise is still the same the reader does not change nor update the CSV encoding unless told too. So you have to make sure the CSV is in the correct charset before feeding it to the reader. SetEncoding won't help you I'm afraid \u2639\ufe0f. No can't do. To transcode from one charset to another you need to know the charset on both ends alas what you can do is try to detect the encoding if you CSV contain BOM sequences see #293 apart from that I don't see how you could do that. Anyway from my point of view this is not a bug from the lib. You should report it to the package maintainer or make a PR to that library. @otzy thanks for reporting this issue but this was already reported and fix on version 9.0.1 see #244. Hi  @rktyt this is expected behaviour ... you should close the stream after you've destroy the Reader instance not before. If you close the resource when the Reader object is still around you will get a segfault indeed.\n```php\nuse League\\Csv\\Reader;\nuse League\\Csv\\RFC4180Field;\n$stream = fopen('/path/to/file', 'r');\n$reader = Reader::createFromStream($stream);\nRFC4180Field::addTo($reader);\n///do what you want\nunset($reader);  //this is crucial\nfclose($stream);\n```\n. @jcrawford thanks for using the library did you try to update your PHP ini configuration https://github.com/thephpleague/csv#configuration ? Or change the file open mode ?. @tom-d-77 thanks for submitting your bug report indeed I was able to reproduce the bug.\nAfter some digging I found the source of the issue but resolving it won't be as simple as I thought. The main issue is that PHP fputcsv is broken beyond repair and can never generate a valid RFC4180 compliant CSV. My patch works in 80% of cases but not in 100%. So I was wondering if it woudn't be much simpler to just add a switch parameter to the Writer class so that if someone wants a true RFC4180 compliant CSV the engine would not use fputcsv at all. \nI've been toying around that concept lately If I can come up with a decent implementation then it will land on the next minor release as I won't break any existing code. \nIf that solution is ok with you then the question becomes what to do with the RFC4180Field class ? Well I would deprecate the class and issue a warning in the documentation ? Thoughts ?. Seems that fgetcsv does not suffer from the same issue so I will only patch the Writer class as only fputcsv is broken. \nI will have to double check this but If this is true then my patch will need some ironing (adding the appropriate tests) but is aleady done. when my PR is ready I'll let you know so that you could test it with your own data that way I'll be sure I've done it correctly or maybe you'll find other subtle bugs I haven't thought about \ud83d\udc4d\nOf course this will be done/finished when I have some spare times \ud83d\ude22 . @tom-d-77 I've toying with a local dev that fix this issue but before submitting a PR I'd like your opinion on 2 possible implementations\nUsing a dedicated setter/getter method\n```php\n<?php\nuse League\\Csv\\Writer;\n$writer = Writer::createFromString('');\n$writer->getWritingMode(); //returns Writer::MODE_PHP \n$writer->insertOne($arr); //the record is added using fputcsv\n$writer->setWritingMode(Writer::MODE_RFC4180); //the new RFC4180 compliant writing mode\n$writer->insertAll([$arr]); //the records are added using RFC4180 rules\n```\nUsing an optional argument on the insertXXX methods\n```php\n<?php\nuse League\\Csv\\Writer;\n$writer = Writer::createFromString('');\n$writer->insertOne($arr, Writer::MODE_PHP);  //the record is added using fputcsv\n$writer->insertAll([$arr], Writer::MODE_RFC4180); //the records are added using RFC4180 rules\n```\nIn both implementations, if no mode is set Writer::MODE_PHP will be used to avoid BC break.\nI'm leaning towards the second solution. Thoughts and comments ?. @tom-d-77 even thought most of the other setters uses the setter/getter option I believe I want to make a exception for that rule here as choosing the right engine is important and the dev should really be in control of what he wants to do. The second option forces the developer to choose wisely which is a good thing IMHO.. I can do that as it would be BC break .. the parameter needs to be optional ... but should be required in the next major release it's the only tradeoff I see. @theodorejb thanks for the input. When I say that\n\nAfter some digging I found the source of the issue but resolving it won't be as simple as I thought. The main issue is that PHP fputcsv is broken beyond repair and can never generate a valid RFC4180 compliant CSV.\n\nIt's because I did the same research as yours but we differ on the solution. I can not change the default settings of the lib otherwise:\n\nit is a major BC break so change to null byte is not a solution.\nIn addition, changing to the null byte is essentially a hack what happens if you CSV document contains such character ? \n\nBottom line, I've submitted a PR #309 which fix this issue and also allow broader support for RFC4180 in the library. The only downside is deprecating RFC4180Field filter and for those using it we will update the documentation and provide guidance between upgrading to the new release OR changing the espace delimilter to the null bytes otherwise if possible.\n. @theodorejb the following PR #309 contains the fix TL;DR it falls back to using fwrite instead of fputcsv.\n\nIt's still possible that the issue could be fixed in PHP by allowing a blank string to be set as the escape character. In the meantime before PHP allows this, perhaps this library could special-case calling setEscape(''), which would switch to a writing mode that doesn't use fputcsv.\n\nIndeed if  the upstream code in fputcsv was patch I would no longer need the optional parameter. But since I can not 100% guarantee that this is how the patch will land (using an empty string) I'd rather not rely on a fix which has not yet land, what if the patch uses null or false instead of the empty string ?\n\nI'm not entirely convinced that adding a new writing mode parameter is the best solution, however. \n\nThe issue is not with how the patch works but how it is triggered. Should it be triggered by a special input for the escape character OR should it be triggered by a optional argument on the insertXXX methods.\nIMO using an optional argument is the best approach for the following reason If PHP was to fix the escape parameter bug\n\nv9.2.0 introduced the Writer::MODE_RFC4180 relying on fwrite (see #309);\nPHP patchs fputcsv;\na patch release for League\\Csv is released which switch internally to fputcsv on all modes but still uses fwrite for legacy PHP version;\nthe next major release drops the Writer::MODE_RFC4180 constant and just relies on fputcsv behavior;\n\nThis is clean simple and reliable. On the other hand if we use the \"escape\" parameter switch and the PHP patch is done differently (let's hope not \ud83d\ude04 ) then we will have to directly release a v10 because of potential bugs. Not to mention that nothing is said for fgetcsv will it be patch too to ignore the escape parameter using the same empty string \ud83e\udd14 \nI've seen your post on the PHP internal mailing list \ud83d\udc4d  . Let's hope this boost the release of a patch quickly!!\n\nAlso, how does the new writing mode perform compared to the native PHP function?\n\nI suppose that benchmark using fwrite decrease insertion speed, but it should depend on the record content length \ud83e\udd14 You can benchmark the PR to see the difference.. > Are there any other important differences in the RFC4180 writing mode other than ignoring the escape character? \nyes there's one fputcsv adds enclosures in presence of the white spaces in a record field, RFC4180 does not. \nBut to me that's a minor issue since having more enclosed field gives less error prone conversion than the other way around (not having enclosure at all anytime around record fields).. @tom-d-77 @theodorejb you may review the PR .. I think the added methods in the Writer class and the documentation with them fully explain what is being introduced and I think I've done it in a way which is not BC break at all but you may find something I may have overlooked.\nIf you could test the branch on your own input to see if all is good it would help me a lot \ud83d\ude09 \n. @theodorejb @tom-d-77 should we wait for the patch to land ? \nIf it lands for PHP7.2 and PHP7.1  we will be able to get rid of the flag all together and only fallback to my implementation for version which do not support the empty string. (ie.. this code would never be called in PHP7.3+ for instance)\nThis would be IMO better because it would be transparent for the end user and provide polyfill for PHP version that do not support the empty string while taking advantage of the patch when possible.. I've updated the patch to get rid of the flag... But I also saw the response on the internals about the patch landing in min. 1 year with PHP 7.4 ... Currently the patch works but I'm not sure about the fgetcsv patch which just replace the escape character with the null byte ... Any suggestions?. @theodorejb patching the PR so that it escape \"like\" fputcsv patched is easy ... patching fgetcsv is another daunting task as it means it means creating a equivalent of fgetcsv in full userland PHP minus the escape bug... I'll see what can be done I don't like having to use the null byte hack. @soukupm2 thanks for using this library. Did you should check to see if stream filters are supported before using them in your case ? This is documented on the documentation website http://csv.thephpleague.com/8.0/filtering/#stream-filter-api . \n. @theodorejb I've added a new class RFC4180Iterator in the PR to polyfill the behavior with the Reader class it was easier than I thought anyway. Could you give it a spin .. I've try to keep the behavior as close to fgetcsv as I could.\nAlso the patch for fputcsv is more in line with fputcsv. I Just need to figure out how to test my polyfill with the PHP src patch to see if the end result is the same.\n. @theodorejb indeed the test suite should be improved I kept improving the parsing using local data. I will update them. This is a first implementation and it uses fgetc which is slow but accurate maybe I can improve it by switching to fgets but I wanted first to have an accurate code before optimization. @theodorejb I've rewritten the parser to properly use fgets. It should be faster now at least I hope . @theodorejb waouw that's more than a simple boost :100:  The big difference it that I no longer iterate over each character but instead explode the line using the delimiter and/or the enclosure character. Did you also check the CSV integrity ? did you get some data loss or not ? I've updated the Test Suite so technically you should not get any data loss but if you can confirm that we will then only need to check this PR result against the PHP patch.. @theodorejb understood you had some chances with your file then :smile:  because the poly fill mimics fputcsv in that it add enclosure if an space character is found in a field content. This means that your CSV does not contains spaces or that they are already quoted. Using your test script with a CSV containing more than 50000 records, a simple md5_file returns false because of that but a check record by records validate that the documents contains the same data. :+1: . I'll let this PR as it is right now and merge it to the master branch hopefully next week.. We could keep the current parser behavior if we follow the Robustness principle, \n\nBe liberal in what you accept, and strict in what you produce \n\nAs long as we document this behavior. What do you think ?. Yes fgetcsv supports this but the resulting field content is different. I'd say that the custom parser results are more predicable than fgetcsv results \n```php\n<?php\nuse League\\Csv\\Reader;\n$csv = Reader::createFromString('\"foo\"bar\",foo\"bar');\nvar_dump(iterator_to_array($csv));\n// [['foobar\"', 'foo\"bar']]\n$csv->setEscape('');\nvar_dump(iterator_to_array($csv));\n// [['foo\"bar', 'foo\"bar']]\n``\n. After some digging I've managed to reproducefgetcsvbehavior using my code so once I've commit my changes this issue will be resolved.. @neradp this is explain in the documentation website see http://csv.thephpleague.com/8.0/inserting/#handling-newline. @neradp you do realize that\";\\r\\n\"is not a valid new line sequence ? I would suggest using stream filtering like explain in the document or a simple mapper function. . Please refer to the documentation website where it is explained. This is expected behavior as explain in PHP documentation for PHP I/O stream wrappers\nsee http://php.net/manual/en/wrappers.php.php#wrappers.php.input\nTL;DR aphp://inputmay be seekable but every time you rewind the stream you loosephp://input` content so you are required to re-open the stream which the library will never do.\nSo you can either use you solution with file_get_contents or use stream_copy_to_stream as shown below:\nin test.php\n```php\n<?php\nuse League\\Csv\\Reader;\nrequire 'autoload.php';\necho \"==== using file_get_contents ====\", PHP_EOL;\n$data = file_get_contents('php://input');\n$csv = Reader::createFromString($data);\nvar_dump(iterator_to_array($csv));\necho \"==== fgetcsv before rewind ====\", PHP_EOL;\n$rsrc = fopen('php://input', 'r');\nvar_dump(stream_get_meta_data($rsrc));\nwhile (false !== ($record = fgetcsv($rsrc))) {\n    var_dump($record);\n}\n$res = rewind($rsrc);\nvar_dump($res);\necho \"==== fgetcsv after rewind ====\", PHP_EOL;\nwhile (false !== ($record = fgetcsv($rsrc))) {\n    var_dump($record);\n}\nfclose($rsrc);\necho \"==== copy stream ====\", PHP_EOL;\n$tmp = tmpfile();\nstream_copy_to_stream(fopen('php://input', 'r'), $tmp);\n$data = Reader::createFromStream($tmp);\nvar_dump(iterator_to_array($csv));\nfclose($tmp);\n```\nThen you can simply call this script using cURL with the following command line:\nbash\n$ curl -d \"foo,bar,baz\" -X POST http://localhost/csv/test.php\n. @komarnicki \nphp\n$csv = Reader::createFromPath($path, 'r'); // works but I don't want facades because they look ugly\nThis is not a Laravel Facade aka (the proxy pattern), this is a named constructor which is something entirely different.\nTL;DR ... use the createFrom* named constructors they exist for that purpose. \ud83d\ude09  . @nickescobedo I don't quite understand your question. The named constructors are the correct and only way to instantiate the object what's the issue with having to use them ?. @frankeg a CSV is a plain text document since the type casting is done by PHP if you need to format your cells you should formatted them as string so that on CSV creation your formatting is kept unchanged.. @mgralikowski thanks for using the library. At first I thought too that this was an issue but while trying to debug this behavior I thinking more and more that this is an expected behaviour and not a bug. On the other hand the documentation should be updated to better express your concern.\nBecause your are reading a CSV, conversion must be done PRIOR to iteration and not after like explained in the documentation so you should use the following code instead:\n```php\n$reader = Reader::createFromPath('/path/to/my/file.csv');\nif (Reader::BOM_UTF16_LE === $reader->getInputBOM()) {\n    CharsetConverter::addTo($reader, 'UTF-16LE', 'UTF-8');\n}\nforeach ($reader as $record) {\n    dd($record);\n}\n``\ntheCharsetConverter::convert` method is more suited for data insertion in case of any iterable object already correctly parse into CSV fields.\nNote: I'm using the createFromPath named constructor because CSV object created with the createFromFileObject can not register any stream filter\n. If you can convert the uploaded file into PHP stream then you can use the stream filter mechanism. Nope there are essentially the same. @mgralikowski can you close this issue if the reason for it being opened in the first place has already been answered ? . Good catch thanks \ud83d\ude09\ud83d\udc4d. @roberto-aguilar thanks for using the package. \nAt first glance there's a huge BC looming in your proposal how do you make the distinction between missing field (currently returned as null value) and empty field which are empty string ?\nAlso what your proposal only deals with your special case only and leaving every other cases to be dealt by the developer. \nIMHO, the better approach would be to create a PHP middleware between the Reader and your insertion operation which would make any necessary transformation according to your own business logic simple, intuitive and easily maintainable something along the line of this pseudo code. \n```php\n$reader = League\\Csv\\Reader::createFromPath('/path/to/csv/file.csv');\n$modifier = new MySpecificModifier(); //contains your business specific transfo/logic)\nforeach ($modifier->transform($reader) as $row) {\n  //insert your data in your DB backend\n}\n//with a simple signature for your transform method following this\npublic function MySpecificModifier::transform(Reader $reader): iterable\n```\nWhat do you think ?\n. @roberto-aguilar this is explained in the documentation http://csv.thephpleague.com/9.0/reader/#records-normalization (ie: when a CSV is malformed normalization is done by appending null value to the record. @tomkyle thanks for using the package.\nCurrently there are no method or simple way to get the target file and the reason is simple. Depending on how the writer was created you may or may not have this information your current workaround is the best alternative IMHO. Another approach would be to expose the document object which means exposing the class internal state which is not a good idea as it is an implementation detail that should not be exposed in the first place.. @tomkyle if you can demonstrate that SplFileObject::gePathname is equal to the result of stream_get_meta_data (ie: you'd have to check PHP src code) then I'm open to adding such method with a PR from you. So you get full credit for the added behaviour \ud83d\ude09 . Yes it's C but I was able to navigate through even thought I have no good understanding of C \ud83d\ude09 . Don't worry about the time just submit the PR and we will try to make it right. I just want to make sure you're credited for the addition . @tomkyle after looking into your proposition I believe a simple PHPUnit test should do the trick instead of going to look into the php source code \ud83d\ude09 .\nYou just need to be sure that the following test does not fail.\n```php\n/\n\n * @dataProvider getPathnameProvider\n /\npublic function testCsvGetPathName($path, $expected)\n{\n    self::assertSame($expected, Reader::createFromPath($path)->getPathname());\n    self::assertSame($expected, Reader::createFromFileObject(new SplFileObject($path)->getPathname());\n}\npublic function getPathnameProvider()\n{\n    return [\n        'absolute path' => [\n            'path' => dirname(DIR).'/data/foo.csv',\n            'expected' => dirname(DIR).'/data/foo.csv',\n        ],\n        'relative path' => [\n            'path' => './../data/foo.csv',\n            'expected' => './../data/foo.csv',\n        ],\n        'tmp file' => [\n            ....\n        ],\n        'external uri' => [\n            ....\n        ],\n    ];\n}\n```\n. well that's not our concern the return value is the correct one it may not be of any help but that's another issue altogether. As far as I'm concern the same thing happens if you create two instances of SplTempFileObject so it's predicable and expected.. Here's the complete test I think .. that will covers your need. to be added to the CsvTest.php file.\n```php\n/**\n * @covers ::getPathname\n * @covers League\\Csv\\Stream::getPathname\n * @dataProvider getPathnameProvider\n */\npublic function testGetpathname($path, string $expected)\n{\n    self::assertSame($expected, Reader::createFromPath($path)->getPathname());\n    self::assertSame($expected, Reader::createFromFileObject(new SplFileObject($path))->getPathname());\n}\n\npublic function getPathnameProvider()\n{\n    return [\n        'absolute path' => [\n            'path' => __DIR__.'/data/foo.csv',\n            'expected' => __DIR__.'/data/foo.csv',\n        ],\n        'relative path' => [\n            'path' => 'tests/data/foo.csv',\n            'expected' => 'tests/data/foo.csv',\n        ],\n        'external uri' => [\n            'path' => 'https://raw.githubusercontent.com/thephpleague/csv/8.x/test/data/foo.csv',\n            'expected' => 'https://raw.githubusercontent.com/thephpleague/csv/8.x/test/data/foo.csv',\n        ],\n    ];\n}\n\n/**\n * @covers ::getPathname\n * @covers League\\Csv\\Stream::getPathname\n */\npublic function testGetPathnameWithTempFile()\n{\n    self::assertSame('php://temp', Writer::createFromString('')->getPathname());\n    self::assertSame('php://temp', Writer::createFromString(new SplTempFileObject())->getPathname());\n}\n\n```. @tomkyle do you think you can submit a PR or should I proceed and implement this. You'll still get referenced in the changelog. But I want to finish/release 9.2.0 before the holidays :wink: . this feature will be release in version 9.2.0 following the acceptance of PR #321 . I've just updated the documentation https://csv.thephpleague.com/9.0/connections/instantiation/#accessing-the-csv-document-path\nNow I just need one confirmation from the PHP internals and 9.2.0 will be released \ud83d\ude09  thanks for the contribution. I've referenced it on the CHANGELOG.md file too. @kumar1010sumit I've just copy/paste your code on a Ubuntu with league/csv 9.1 and I've failed to reproduce your bug :cry: . https://github.com/thephpleague/csv/issues/217#issuecomment-283701299\nLike I explained there... It means your script is already outputting something prior to calling the output method. https://csv.thephpleague.com/9.0/connections/output/#using-a-response-object-symfony-laravel-psr-7-etc. Again there's a entry for that in the documentation. @paulcanning thanks for using the library. Have you read the documentation website ? All information are there I believe. yes it does ... now that you have the reader you should be able to do what you want :+1: What you want to do with is is up to your dev skills :wink: . @paulcanning I need the full code and if it is a bug report could you please provide more information like explain/stated in the bug template so that I can investigate/replicate and maybe fix the bug if it is one \nthanks in advance . which version of PHP are you using ?\nwhich OS too ?\nI need these infos too\nThe more info, context you give me the easier  reproducing the issue will be. So I've use the following code on PHP7.0 -> PHP7.3\n~~~php\n<?php\nerror_reporting(-1);\nini_set('display_errors', '1');\nuse League\\Csv\\Reader;\nrequire 'vendor/autoload.php';\n$reader = Reader::createFromPath(DIR.'/file.csv', 'r');\n$reader->setHeaderOffset(0);\nvar_dump($reader->count());\nvar_dump(count($reader));\n~~~\nin all versions I got an int and no warning I'm using a Ubuntu version :cry: \nSince the Reader implements PHP's Countable Interface I'm wondering are you sure the League\\Csv package is responsible for the warning :thinking: . @Zyles thanks for the bug report but I fail to reproduce your issue using your code. Did you manage to solve it in the meantime ? because looking at your code I don't get why nginx would be affected by the library... I need more detail to investigate. @Zyles is it possible to get the command used only those related to League\\Csv so I get try to reproduce the bug. The bug is about getContent and you seems to have resolve it using Statement but internally both method uses the same code so I have to wonder \ud83e\udd14 .\n- Do you use a separate file or the CSV is produced from a stream \u2753 \n- Is it build from or on a Mac OS \u2753 \n- Does you nginx supports PHP buffering \u2753\nHaving acces to the script would help in knowing if it is a bug or a misconfiguration of the library. . @working-name thanks for using the library. FWIW, I believe it is an issue with how the library is used. You should check how your PHP/Servers settings are. In any case, this is not related to the library or PHP. Sorry for not being more helpful \ud83d\ude22 .. @petarvasilev91 the CharsetConverter follow the naming convention of PHP's mbstring extension as describe in the documentation website. . Yes please refer to the documentation website where all is clearly explained about stream usage . if $position is equal to 0 then your code $this->offset is equal at 1 in the loop and end up being equal to 0 after the loop \ud83d\ude09 . why won't it enter the loop ??? . yes but we don't really care because the current() method does not use the offset property which will be incremented to 0 when next() is used. I'll look into it after work but yeah there should not be any issue in how the Stream class is used in the package. Since the class is marked as @internal  we are safe but I can look into it to see if some use cases may end up in error. If you could provide such example It would be easier to investigate/fix but I don't see an instance where this could come up \ud83e\udd14 . seems to be easy to fix... I'm in the process of releasing 9.2.0... I'll create a small branch with the fix and add it to the release. The way the Stream class is used in the package is not impacted by this bug but fixing it is still possible and will be addressed. If you prefer to submit a PR you are welcomed to do it also in the meantime \ud83d\ude09 . could you:\n- add the tests in StreamTest.php \n- use Yoda style in the if condition \nand I'll merge your fix\nthanks in advance. You should check your PHP version this has nothing to do with the library I'm afraid. @tebaly thanks for using the library.\nPlease refers to the documentation website as this is expected behaviour. \nphp\n<?php\n$csv->setHeaderOffset(0);\n$records = $csv->getRecords(); // indexed from #1\nSince the first record is used as the CSV header it is removed from iteration hence iteration starts at #1 .\nphp\n<?php\n$record = $csv->fetchOne(1); // indexed from 0, return record #2\nThe ResultSet does not re-order the CSV so using fetchOne(1) means your are fetching the nth_records starting from the first row (ie: you start at 1 and search for the nth_record from 1 = you are getting the second index.. as expected.\nRemember your are using a StreamIterator that's why we are not re-indexing everytime the index to preserve index loss between objects.\n. @tebaly you Can found the info for how fetchOne works using this link https://csv.thephpleague.com/9.0/reader/resultset/#selecting-a-specific-record. I think that hhvm is more strict that php you should had this line prior to looping into the newly csv\nphp\n$this->csv->setFlags(SplFileObject::READ_AHEAD|SplFileObject::SKIP_EMPTY);\n. How about moving the code prior to applyIteratorFilter line ? This is an open question I don't know if it would change something or not ?\n. By moving it Up you ensure that the BOM sequence will be indeed remove from the First line of the document. After the filters have been applied you may be remove a valid BOM sequence inside the CSV\n. I believe the strip_bom property should not be attached to AbstractCsv class. This property should be only usable on the Reader class. \nIMHO to make the code as much flexible as possible you should add the strip bom capability directly in the Modifier/QueryFilter.php trait and reset the status to false between calls. \nPros:\n- the BOM stripping is restricted to the Reader class\n- the BOM stripping can be set per queries (so stripping is only made when needed).\nCons:\n- the BOM stripping can be set per queries. The dev must not forget to use it\nSecondly keep in mind that the fetchAssoc method can be affected if the strip_bom is set to true  and the column names are taken from the first row (which is the default behavior).\nLast but not least, when exporting to XML, HTML and/or Json. the property must too be taken into account\n. I was in the mood for snake case :) . Seriously I did this to match $input_bom and $output_bom which are already in snake case. I should probably review all the codebase and make a clear decision between both coding style. Of note none of them are in contradiction to PSR2 if I recall but yes the code needs consistency.\nI'll will check the codebase for consistency in property name after this PR is merge\n. This description adds more confusion ... there's not may !! The method signature is very strict \n. yes indeed ... /me over checking \ud83d\udc4d . well after review .. I need this check since the method can take a resource or a StreamIterator and I don't want to create 2 named constructors for this otherwise you could create a CSV object from a path \ud83d\udc4e . it should be part of bugfix because it aligns the StreamIterator to how SplFileObject and fputcsv works. StreamIterator must be align to SplFileObject and it did no align.. StreamIterator is marked as @internal so anyone using it in public API exposes himself to harm.. no $row is always an array otherwise an exception is triggered. yep typo error from my part.. I'll correct that. I don't think you need to add this check here... not being able to seek should not prevent setting the newline. This is to be consistent with for instance providing a non writable CSV document to the Writer class. on its own it is not forbidden but you'll get an error on insertion. It should be the same with a non seekable document.. I would prefer the property to be called is_seekable since it will hold a boolean value.. This introduces a tiny BC break you can't just correct it like . I'd rather write \nphp\n<?php\n        if (false !== $bytes) {\n            return $bytes + $this->consolidate();\n        }\n        throw CannotInsertRecord::triggerOnInsertion($record);\nsince fputcsv returns false on error but may also return 0. while I understand this notation I believe it is as incomplete as the one you are trying to fix for instance does your notation covers this usage ?\n```php\n$csv = Writer::createFromString('');\n$csv->insertOne([\n    new class {\n        function __toString() {\n            return 'foo';\n        }\n    },\n    'bar',\n]);\necho $csv->getContent();\n``. I'd rather usearrayand specify in the doc bloc that flat array consisting of scalar null and object which implements __toString values can be used IMHO mixed is just too permissive. no it's not that why I'm leaning toward just using the default typehint which isarray` and explain in the docblock exactly what is expected. ",
    "MarcusDalgren": "Hi,\nFirst of all, thank you for doing this! \nI got the impression that you weren't that interested in the feature so it came as a really nice surprise to see you doing this. I'm more than willing to help out if you've got this in a branch that I can try out and send PRs for.\nHow about using exceptions? Either an InconsistentDelimiterException and a NoDelimiterException or a more generic CSVParseException that tells you what the problem is in a message or a method. I think that's more clear than keeping track of the different meanings for null and false in your first option. If you end up getting an exception odds are that reading the file wouldn't give you a good result anyway.\nAnother question is if \\s really should be considered as a valid delimiter considering that you'd have to switch the parsing strategy. Using \\s really only works if the text is in enclosures so you'd have to keep track of that, you can't just split the string on \\s and then count the results. I'm willing to help out with these kinds of special scenarios so that you don't have to spend time on it.\nIs this stuff in a branch that I can check out and help you with?\nThanks again!\n. ",
    "philsturgeon": "The feature would be an optional method, so fetchIterator() or yield() would be available. If PHP 5.4 users try using it then they'll get an error, so maybe the method could be documented or a simple error message added based on the results of version_compare()?\n. I imagined it would be a simple case of marking as required but if the syntax wont compile PHPUnit suggests using test suites: http://phpunit.de/manual/3.7/en/appendixes.configuration.html#appendixes.configuration.testsuites\nLooks like a bit of an arse but at least it'll work.\n. Done!\n. ",
    "lucasmichot": "Done @nyamsprod \n. ",
    "coveralls": "\nCoverage remained the same when pulling b311ed3d328f538038bb363c920d59831c461634 on lucasmichot:patch-1 into caed05894f71ed5fc706e6df02d2847ebc01825e on thephpleague:master.\n. \nCoverage decreased (-6.82%) when pulling 18ae4e08bcdd4f6d25d386473f79d858985c71b3 on dereuromark:develop into c5240b896c70235f1f2a730a0e45b627014e2ef8 on thephpleague:master.\n. ",
    "andersonamuller": "Yes, I know that CSV has those controls, it is something based on a CSV, it uses a | (pipeline) to separate fields. I was using the your library for all clients and it works great. thank you for that! So I wanted to keep using the same, since it's the same project, so the only difference it's the config per client. It correctly parses the file, but when I write the file (it's a import / export process) I don't want to write the quotes.\n. Hi, I tried using the \"\\s\" but it's throwing the same exception as if I try to pass ''. \nphp\n Uncaught exception 'InvalidArgumentException' with message 'The enclosure must be a single character'\nHere is a sample script I'm using to test.\n``` php\n$csv = <<<CSV\n2446277|930 5554|_ A\n2446\"542|9642\"096|fdsa\\fdsafas\n244\"6542|9642'096| fdsaf\nCSV;\n$csvFieldMapper = [\n    '0' => 'company',\n    '1' => 'person',\n    '2' => 'job'\n];\n/* @var \\League\\Csv\\Reader $reader /\n$reader = \\League\\Csv\\Reader::createFromString($csv);\n$reader->setDelimiter('|');\n$reader->setEnclosure(\"\\s\");\nforeach ($reader->fetchAssoc($csvFieldMapper) as $row) {\n    var_dump($row);\n}\n```\n. ",
    "dakira": "@nyamsprod Hi. I'd like to re-open this bug. I need to be able to write CSV with no enclosures. I have no control over the importing app and the latter won't work with CSV files using enclosures.\nWhile RFC 4180 exists, there is no official standard for writing CSV. Also, RFC 4180 defines the usage of enclosures as a SHOULD requirement which allows for not using them.\n. @nyamsprod maybe just a mixup, but in this comment you stated that enclosures cannot be empty because PHP enforces them to be one character. What @ezintz is trying to say is that you can just omit enclosure and escape parameters (they're optional).\nThat said: Do I understand it correctly that your merged stream filter PR adds enclosures where they are missing to make stream data valid CSS before it gets parsed by the library?. I understand. Thanks for taking so much time to reply! I guess in my edge-case I'll just use a distinct enclosure and filter that out while I ask the software vendor to patch their stuff.\n. ",
    "jsandeo": "It is not a requirement of the CSV standard to have a field enclosed just because there are whitespaces in it:\nSee how \"Grand Cherokee\" is represented in this example\nIs there a way to tell a writer not to enclose a field just because it has whitespaces?\n. I just switched to https://github.com/parsecsv/parsecsv-for-php\nKISS\n. ",
    "edgreenberg": "It should be noted that once you change the delimiter (to a TAB for instance) there is no need for enclosure around spaces or quote marks.    \nTab delimited files are pretty common, and it'd be nice to be able to write them (easily).\n. ",
    "underdpt": "I too think that it should allow for empty enclosures, it's simpler than having to write a workaround with streamfilter.\n. ",
    "neilcrookes": "Does anyone know of an example stream filter that results in values not being enclosed if they have a space?\n. ",
    "ezintz": "@nyamsprod I guess that you might be wrong. It does not seem to me to be a limitation of PHP..\nphp\n/**\n         * Set the delimiter and enclosure character for CSV\n         * @link http://php.net/manual/en/splfileobject.setcsvcontrol.php\n         * @param string $delimiter [optional] <p>\n         * The field delimiter (one character only).\n         * </p>\n         * @param string $enclosure [optional] <p>\n         * The field enclosure character (one character only).\n         * </p>\n         * @param string $escape [optional] <p>\n         * The field escape character (one character only).\n         * </p>\n         * @return void \n         * @since 5.2.0\n         */\nIf I change the method call to to only pass a delimiter everything works fine.. Just to recap, if I visit the PHP documentation website at http://php.net/manual/en/splfileobject.setcsvcontrol.php I can see that the parameters are placed in brackets which usually means I do not need add them to the function call.\nYou are probably right and it is pretty easy to write my own parsing functions to achieve the same result but somehow it feels wrong.... If there is a function in MySQL that I can use I will not add my own procedure to it because of various reasons.. ",
    "nozavroni": "I don't know why you rely on PHP's functions anyway... you could get around this issue pretty easily by writing your own.. ",
    "jaykravetz": "This seems to be an optimal solution being as it allows users to utilize the library to handle nulls rather than forcing them to. Thank you for another extraordinary package, you've done some really great work.\n. ",
    "eymengunay": "Thank you for taking your time and explaining this. For some reason I thought offset was calculated on whole csv data. \nHope this helps someone else as distracted as myself :)\n. ",
    "sagikazarmark": "Ok, I go for it.\nAs for the Reader, it is not so crucial, I find your solution better, as preventing an inconsistent file from being read does not make much sense.\n. In my implementation after a line is written, the object gets into Frozen state, which means you cannot change any options after that. Maybe this could be implemented here as well, since the same problem appears, if someone modifies eg. the delimiter after some lines are written (or read in the Reader).\n. But to answer your questions: when the first insert is done and yes.\n. I see you updated my code, but the issue I mentioned still exists:\nphp\n$writer = new \\League\\Csv\\Writer('/path/to/csv');\n$writer->insertOne(['cell1', 'cell2', 'cell3']);\n$writer->setDelimiter(','); //this should work or not ?\n$writer->insertOne(['cell1', 'cell2']); //this should work or not ?\n. Yeah, I got the point of the modifications and I tend to say this way makes more sense, but the issues you and I mentioned still exists, but in a different form:\nphp\n$writer = new \\League\\Csv\\Writer('/path/to/csv');\n$writer->insertOne(['cell1', 'cell2', 'cell3']);\n$writer->setColumnCount(2); //this should work or not ?\n$writer->insertOne(['cell1', 'cell2']);\n$writer->setColumnCount(3); //this should work or not ?\n$writer->insertOne(['cell1', 'cell2', 'cell3', 'cell4']);\n$writer->setColumnCount(-1); //this should work or not ?\n$writer->insertOne(['cell1', 'cell2']);\nThe problem: if you set either the column count, delimiter, escape char, etc, then the file will be inconsistent. You probably don't want to modify the delimiter nor the column count after any rows are inserted, but if you do, you will get a useless file. This is why I mentioned my original solution of this: after the first row is written, the object becames immutable, and the settings cannot be modified.\nExample:\nphp\n$writer = new \\League\\Csv\\Writer('/path/to/csv');\n$writer->insertOne(['cell1', 'cell2', 'cell3']);\n$writer->setDelimiter(','); //this should work or not ?\n$writer->insertOne(['cell1', 'cell2']);\nAnd the result:\ncell1;cell2;cell3\ncell1,cell2\nSee, this is insane. This is an exceptional case, and should be handled accordingly.\n. I didn't say it is not the developer's fault, and I can accept this answer. I tend to create more foolproof applications. ;)\nOne more thing related to the consistency check: -1 has a special meaning, do not check anything.\n0 could have a special meaning too: set the column count to the first inserted row's column count.\nAlso, boolean values could be applied here: false => -1, true => 0\n. Well, an array with a length of 0 should be skipped. This array means a row with 0 elements, so if you translate it into CSV it equals to an empty line.\nBut look at this: boolean value (false: do nothing, true: autodetect length) and integer value (x>0) can be assigned to the column count. This might not be the best, as the two datatypes can be easily casted into each other, but should worth a try.\n. This is obvious. It is just to autodetect the column count.\n. Thanks. I am officially shutting down my own package, and will place a\nlink to yours, to use that instead.\n. Thanks for letting me know\n. Of course, use at your will.\n. ",
    "GrahamCampbell": "You mean you want me to rebase? Sure...\n. Done.\n. It might be an idea to squash these commits.\n. ",
    "dereuromark": "Well, its WIP, so CS and test cases are also not in proper order yet.\nJust wanted to get some quick feedback first - what you think.\nThen I can fix it up and squash.\n. That could also work. It would just have been more convenient in most cases to use sane default filters provided.\nAnd if you don't want to use them and write your own (based on other extensions) you can always do so anyway. No one forces you to use the stream one :)\nBut 90% of all devs have already enough on their plate so they are more than glad if they can simply use the provided without having to invent sth themselves. As me^^ Just wanted to have a proper and quick way of using non-utf8 csv files.\nSo it is not bad practice to include some slightly opinionated best practice filters in /Filter IMO that just work TM.\n. Valid point. OK - Sounds good :)\n. Will you start on this? Or shall I?\nWhat other filters can you think of?\n. @nyamsprod I was more thinking in iterating over the content and raising a $count field.\ncount = 0;\nwhile (read each row) {\n    count++;\n}\nThis way the memory would not be the issue, only speed.\nIf we store it in a protected attribute we can also re-use it in that instance.\n. Ah ok, and there is probably no quicker way to read all rows.\nWould it be justified to get its own convenience wrapper? Or should we close as works-for-me?\n. ",
    "NoMan2000": "Here's how I did it in a class, this gets both the columns and the rows, and makes sure that the rows are filled.  I've found that both CSV and XLS files will mark a row filled if it once had data and it's quick deleted.  Passing count in by reference, you can see the difference between the rows that are marked as existing but have no values stored in the first element, (or however you wish to pass this.)\n```\nprotected function countRows($reader)\n{\n    $count = 0;\n    $countRows = $reader->each(function ($rows) use (&$count) {\n        if ($count === 0) {\n            $this->columns = count($rows);\n        }\n        $count++;\n    if (!empty($rows[0])) {\n        return true;\n    }\n    if (empty($rows[0])) {\n        return false;\n    }\n});\nunset($count);\nreturn $countRows;\n\n}\n```\n. ",
    "motin": "Here is a sample benchmark: Counting the rows in a 8,8mb csv file with 52401 rows took 3.29s when running on a recent Macbook Pro.\n. ",
    "alexjose": "+1\n. ",
    "rubenheymans": "thanks, but I used this to solve this:\n$sql = \"\n            LOAD DATA LOCAL INFILE 'uploads/{$fileName}'\n            REPLACE INTO TABLE `order`\n            FIELDS\n                TERMINATED BY '\\t'\n            LINES\n                TERMINATED BY '\\r\\n'\n            IGNORE 1 LINES\n            (product_id, `date`, quantity)\n            \";\n. ",
    "mfrost503": "I\u2019ll take a look and see if anything stands out to me in the documentation later this week.\nThanks!\n--\u00a0\nMatt Frost\nOn September 2, 2014 at 10:46:05 AM, ignace nyamagana butera (notifications@github.com) wrote:\nThanks for the typo fixes ... I think there are more in the documentation  \n\u2014\nReply to this email directly or view it on GitHub.\n. ",
    "stevenmusumeche": "here it is: https://gist.github.com/stevenmusumeche/605a1b1c7a1819ac1710\n. Using the space as a workaround was what was suggested for tab delimited files with no enclosure.  I would like to use no enclosure but that is not possible without throwing an Exception.\n. ",
    "dyelton": "@stevenmusumeche I had to deal with this issue as well. My workaround was to set the enclosure to \\x1f\n. ",
    "tstuttard": "I am not sure what is causing the hhvm test to fail.\nIs there a way of installing hhvm with phpenv locally?\nRight now the only way I can test is through pushing commits, then wait until travis tests it.\nBesides from getting the test to pass what else from the contribution rules have I missed out?\n. > I think that hhvm is more strict that php you should had this line prior to looping into the newly csv \n\n$this->csv->setFlags(SplFileObject::READ_AHEAD|SplFileObject::SKIP_EMPTY);\n\nCheers, I will add this change then commit to the pull request.\nI am caught in two minds on which method we should check for first.\nOn one hand I found implementing the toArray() method more straight forward as it is relatively easy to generate an array, using php array methods like array_pop() or array_push() to add columns, and return it. Implementing a __toString() method seemed a bit clunky as you either had to concatenate your columns together along with the separators and quotes around those columns like this:\nphp\n    return  \"\\\"$column1\\\",\\\"$column2\\\",\\\"$column3\\\",\\\"$column4\\\"\";\nor this:\nphp\n    return '\"'.$column1.'\",'.'\"'.$column2.'\",'.'\"'.$column3.'\",'.'\"'.$column4.'\"';\nor with a loop like this:\n``` php\n    $columns = [$colum1, $column2, $column3, $column4];\n$columnString = '';\n$i = 0;\nforeach($columns as $column) {\n    if ($i == 0) {\n        $columnString .= \"\\\"$column\\\"\";\n        continue;\n    }\n\n    $columnString .= \",\\\"$column\\\"\";\n}\n\nreturn $columnString;\n\n```\nor you  have to use something similar to this http://stackoverflow.com/a/16353448/2204928\nOn the other hand if you we are going to introduce a BC break and increase the version number for one quite small change then it doesn't seem quite worth it unless there were other pull requests that would also be used in 7.0.0.\n. Yeah I looked into see if there was even an official PHP Interface ( like the Iterator Interface ) but sadly only in Laravel's Contracts there is an Arrayable Interface. http://laravel.com/api/4.2/Illuminate/Support/Contracts.html\nBut that wouldn't prevent the issue you have outlined above.\nExtending the Writer class is a good solution as it allows the user to decide which method takes precedence. I will do this in my current project and maybe there will be a PHP internal for implementing toArray or atleast creating an interface for it in later versions of PHP.\nThanks for the help, it's much appreciated.\n. ",
    "garethellis36": "Thanks for your response. I was trying something similar but the missing piece was the \"w\" in the second argument to create the file. \nAnyway, it's still putting an empty line at the end of the CSV file.\nCode is now:\n$csv = League\\Csv\\Writer::createFromPath($filepath, \"w\");\n$csv->insertAll($csv_data);\n. Is it worth doing a PR to have an option which doesn't include the newline?\n. ",
    "Heart1010": "ok, but also when using a csv line like this\n\"Surname\";\"Name\";;;;;\"3316157\";\"12360000\";\"Bank name\";\"DE49123600000003316157\";\"GENODIF1DIR\";\"12,456\"\ndetectDelimiterList() don't find the correct one (;).\nSo why not add COUNT_RECURSIVE to the fetchRowsCountByDelimiter method (when we use default $nb_rows = 1 value we always get 1 as a result here otherwise which doesn't make much sense, do it?).\nphp\n//return count(iterator_to_array($iterator, false));\nreturn count(iterator_to_array($iterator, false), COUNT_RECURSIVE);\nand then let detectDelimiterList method return the most used one\nphp\n// arsort($res, SORT_NUMERIC);\n// return array_keys(array_filter($res));\nreturn array_search(max($res), $res);\n(return the most used one can also be finetuned so it only reports THE delimiter when it's occurence is twice/triple/... the value of the second most used delimiter if you like.)\nWhat do you think?\n. With these 2 small changes I mentioned it's not bulletproof but correct 98% of all times (instead of now way below these 98%).\nWhen you add that mentioned \"fine tune filter\" you can reach >99,8% correctness. So why not adding/changing it?\n. Ok, I think you're right. Now the occurrences are counted correct so if anyone wants to take the highest counted one he could use \nphp\n$delimiters_list = $inputCsv->detectDelimiterList();\n    if (!$delimiters_list) {\n        //no delimiter found\n    } else {\n        $delimiter = $delimiters_list[0];\n    }\n...or something like that.\nThe only \"unaesthetic\" thing is, we have actually a delimiter count (from the fetchRowsCountByDelimiter method) but can't use it right now (for \"fine tuning of the decision\" if we should take the first one or not) because detectDelimiterList method don't return it.\n. Thanks for bringing this up again.... the latter is also my favorite :+1: \n. I'm fine with this approach!\nThe doc (http://csv.thephpleague.com/properties/) should be enhanced with this info or better show a \"use out of the box example\" which first checks if there are more than one delimiters found with same occurence and so on...\n. Ok, added a new pull request with only the COUNT_RECURSIVE mode added.\n(sorry for that CsvTest spam)\n. @RomeroMsk Do \nphp\n$bom = chr(239).chr(187).chr(191);\nwork for you (which os? It should work on MS Excel Win but not an Mac?)? I've read this as \"best solution\" for Excel http://stackoverflow.com/questions/155097/microsoft-excel-mangles-diacritics-in-csv-files/1648671#1648671 which uses\nphp\n/**\n   * Export an array as downladable Excel CSV\n   * @param array   $header\n   * @param array   $data\n   * @param string  $filename\n   */\n  function toCSV($header, $data, $filename) {\n    $sep  = \"\\t\";\n    $eol  = \"\\n\";\n    $csv  =  count($header) ? '\"'. implode('\"'.$sep.'\"', $header).'\"'.$eol : '';\n    foreach($data as $line) {\n      $csv .= '\"'. implode('\"'.$sep.'\"', $line).'\"'.$eol;\n    }\n    $encoded_csv = mb_convert_encoding($csv, 'UTF-16LE', 'UTF-8');\n    header('Content-Description: File Transfer');\n    header('Content-Type: application/vnd.ms-excel');\n    header('Content-Disposition: attachment; filename=\"'.$filename.'.csv\"');\n    header('Content-Transfer-Encoding: binary');\n    header('Expires: 0');\n    header('Cache-Control: must-revalidate, post-check=0, pre-check=0');\n    header('Pragma: public');\n    header('Content-Length: '. strlen($encoded_csv));\n    echo chr(255) . chr(254) . $encoded_csv;\n    exit;\n  }\n```\nPHP can input and output Unicode, but a little different from what Microsoft means: \nwhen Microsoft says \"Unicode\", it unexplicitly means little-endian UTF-16 with \nBOM(FF FE = chr(255).chr(254)), whereas PHP's \"UTF-16\" means big-endian with \nBOM. For this reason, PHP does not seem to be able to output Unicode CSV file for \nMicrosoft Excel. Solving this problem is quite simple: just put BOM infront of \nUTF-16LE string.\nExample:\n$unicode_str_for_Excel = chr(255).chr(254).mb_convert_encoding( $utf8_str, 'UTF-16LE', 'UTF-8');\n```\nAnother problem is that excel opens the csv in one line... \n```\nUTF-16LE solution for CSV for Excel by Eugene Murai works well:\n$unicode_str_for_Excel = chr(255).chr(254).mb_convert_encoding( $utf8_str, 'UTF-16LE', 'UTF-8');\nHowever, then Excel on Mac OS X doesn't identify columns properly and its puts each \nwhole row in its own cell. In order to fix that, use TAB \"t\" character as CSV delimiter \nrather than comma or colon.\n```\nWhich encoding opens CSV files correctly with Excel on both Mac and Windows? see http://stackoverflow.com/questions/6588068/which-encoding-opens-csv-files-correctly-with-excel-on-both-mac-and-windows\n=> So using UTF-16LE with BOM and tab delimiter should \"the best way\" to store the csv file (for MS Excel).\n. ...see my comment above. MS Excel \"wants\" tab as delimiter.\n. Yes :+1: \n...and make a section for that infos -also regarding MS Excel- in your documentation page would be helpful imho :-)!\n. See our discussion about that here on the BOM topic #65 and there is also a summary in the csv doc about BOM http://csv.thephpleague.com/bom/ section \"MS Excel on Windows\"\nphp\n$writer->setOutputBOM(Reader::BOM_UTF8);\n. @nyamsprod Is this $reader-> in the doc ok?!\n\n. you were faster :+1: \n. @nyamsprod when I only want to store a newly generated csv file to the server (with a BOM) because I want to add that csv file to a zip archive afterwards for example how do I do that the best way? Because the BOM is only written when calling the output() or the __toString() method, isn't it? \nSo do I have to write the file like\nphp\n$writer = Writer::createFromPath('/tmp/tmp.csv', 'w');\n$writer->setNullHandlingMode(Writer::NULL_AS_EMPTY);\n$writer->insertAll($data);\nand then I have to switch to the reader object, set BOM and save the file contents as file again (with standard php function)?\nphp\n$csv = $writer->newReader();\n$csv->setOutputBOM(Reader::BOM_UTF8);\nfile_put_contents('file.csv', $csv->__toString());\nor is there an easier way?\n. Perfect, thank you :+1: \n. Eventually the article from yesterday is also a good read!?\nMemory Performance Boosts with Generators and Nikic/Iter\n. ",
    "stof": "@nyamsprod using the occurence of the delimiter as key hasa big drawback: keys must be unique. If 2 delimiters have the same occurence, you will loose one of them in the output.\n. @nyamsprod returning a word is also a BC break as it changes the API too. There is no way to fix it without any BC break\n. @nyamsprod currently, values in the returned arrays are always potential delimitors. After your proposal, ;| is not a potential delimitor; ; and | are.\nso any code using this method to find a delimitor would become broken. Currently, they will just miss one candidate. With your proposal, they will miss 2 candidates until they update their code.\n. ",
    "ghost": "Thank you!\nTomasz Kalinowski\ntomasz.kalinowski@icloud.com\nOn 05 Nov 2014, at 17:31, ignace nyamagana butera notifications@github.com wrote:\n\nAssuming your are getting a CSV in a different locale as yours, you should first try to use the stream filtering capabilities as explained in the documentation and in the example. \nHope it will help\n\u2014\nReply to this email directly or view it on GitHub.\n. Hi,\n\nafter further analyses I detected the error in the file (my side). Your Library is working very well \ud83d\udc4d !\nThanks!. ",
    "IGitSylvia": "It was pilot error! I had this issue:\nhttps://getcomposer.org/doc/articles/troubleshooting.md#-the-system-cannot-find-the-path-specified-windows-\n:)\n. ",
    "RobinDev": "Perfect !\nThank you.\n. ",
    "CWSpear": "Does it make sense for the callable in the fetchAssoc method to pass in the associative array?\ni.e. With this CSV:\ncsv\nname,email,age\nBob,bob@builder.com,12\nand with this code:\nphp\n$reader->fetchAssoc(0, function ($row) {\n  print_r($row);\n});\nI would expect this output:\narray\n(\n  [name]  => Bob\n  [email] => bob@builder.com\n  [age]   => 12\n)\nbut I actually get this:\narray\n(\n  [0] => Bob\n  [1] => bob@builder.com\n  [2] => 12\n)\nUltimately, what I'm trying to do, is figure out a way to iterate over a very large CSV file where the first row are the keys. It is large both in number of columns and rows, so I want to take it just one row at a time (like, I really want to do an each or via query, but in an associative manner so I don't have to manage matching the keys up myself).\nIt seems like this isn't able to do this at all (and I don't think fetchAssoc is gonna do it anyway, cuz I'm going to run into memory issues as it grows...).\nHope I'm making sense...\n. I guess I have two issues here, and I re-read what I wrote and it's a bit confusing. In trying to process a large first-row-keys CSV file, I was looking at fetchAssoc, and noticed this quirk about the callback. I realize now fetchAssoc isn't going to be the answer either way.\n. I was thinking more along the lines of this: https://github.com/surgeforward/csv/commit/d7b6fbd4cc0530c1230eb513d6d7ede955817ebf\nThat turns this:\n``` php\n$keys = $reader->fetchOne(0);\n$reader->each(function ($row, $index) use ($keys) {\n    if ($index === 0) {\n        return true;\n    }\n$row = array_combine($keys, $row);\n\necho $row['email'];\n\n});\n```\ninto this:\nphp\n$reader->eachAssoc(function ($row, $index) {\n    echo $row['email'];\n});\n. ",
    "duncan3dc": "Thanks @nyamsprod .\nJust to be clear, you're happy to accept the feature, if the implementation uses stream filtering?\nAnd for info, can you elaborate on What happens when the line endings inside the row also exhibit another format than the one requested? I'm not sure what you mean\n. OK thanks for the explanation @nyamsprod \nIn your example I would not want the line endings inside the data to be converted, the data should not be interfered with as it is the data we are trying to transfer, manipulating that should never be a function of data transfer.\nIt's a shame this feature will not be included, as it seems to perfectly fit the project's goal of not requiring high levels of bootstrap, and exceeding the usefulness of existing core functions. Applying stream filters, and adding extra packages seems over the top for this feature\n. Sorry for the misunderstanding.\nI'm happy to work on the patch to get it accepted. I see this feature as similar to specifying a delimiter.\n. ",
    "RomeroMsk": "Ok, you can make it as you wish :)\n. These names are ok for me.\n. Checked, it works. Thanks a lot!\n. It works for me on Windows and doesn't work on Mac. But we decide to leave this problem as is.\nI think, you can try to convert encoding of content to UTF-16LE, add BOM and change delimeter - now Writer allows all of this, I belive.\n. Looks good for me. Did you try to open UTF-16 encoded file with right BOM sequence in MS Excel on Mac and Win?\n. I can ask my collegue to check the file on Mac if you generate it with UTF-16LE + BOM.\n. Sorry, out of my working place now. Can check changes only after weekend.\n. Hello. I can't make Writer to use filter. Can you help me?\nI've got FilterTranscode example class and changed only namespace. Then I tried to use it like this:\nphp\n    stream_filter_register(FilterTranscode::FILTER_NAME . '*', '\\common\\components\\FilterTranscode');\n    $writer = Writer::createFromFileObject(new \\SplTempFileObject);\n    $writer->appendStreamFilter('convert.transcode.UTF-8:UTF-16LE');\n    $writer->setBOMOnOutput(Writer::BOM_UTF16_LE);\n    $writer->insertOne($content);\n    $writer->output($fileName);\nand got The stream filter API can not be used LogicException. What am I doing wrong?\n. Now I'm getting Cannot rewind file php://filter/write=convert.transcode.UTF-8:UTF-16LE/resource=php://output\n. Ok, I've got a result with $writer = Writer::createFromPath('/my/path/to/my/file.csv').\nMS Excel on Windows didn't recognize a separators in CSV (just loaded entire lines), but with right encoded symbols.\nWaiting for collegue to test it on Mac...\n. Yes, I know. But after manipulations with encoding MS Excel is not recognizing delimiters correctly.\nWith UTF-8 everything is ok, but with UTF-16LE - not.\nThe same situation is on Mac.\n. But I'm using ; as delimiter, beacuse MS Excel is awaiting it in CSV files.\n. Ok, with setDelimiter(\"\\t\") it works.\n. For me sounds good, thanks for your help!\n. I'm not an expert too :) Also my English is not very good.\n. Checked 6.3, everything is fine, thanks! :+1: \n. ",
    "hervehobbes": "it's a shame if the library is not doing it and could be a good enhancement.\nThanks for your answer.\n. Excellent !\nThank you very much\n. ",
    "codeliner": "Hi @nyamsprod, I use a similar MapIterator in my library (inspired by your version) and ran into trouble with it. I thought it is a good idea to fix the same problem in your version even if it is only used internally.\nWe are working with PHP so no package visibility. Sure you have this internal flag in the doc block but this doesn't prevent my IDE to suggest me your MapIterator when the package is installed. \nLong story short, it is no real improvment for your lib, just a hint. It does not affect the behaviour, but if you don't want to merge it then it is fine, too.\nBtw. thanks for this great library. I use it in my workflow system. I love the iterator filters.\n. @nyamsprod Thanks. No problem. Like mentioned before I use my own version of the map iterator. I'm wondering that scrutinizer didn't like my changes. What was the problem?\nHowever, it's working for you. Just keep in mind that your implementation won't work with all kinds of \\Traversable objects but it excepts all \\Traversable objects as valid constructor arguments. For me the internal usage would not be a valid reason for a error-prone implementation but if it is more important for you that scrutinizer like it then it's fine, too.\n. ",
    "joostshao": "\nclick the google text, it will open my default browser and locate to google.com\n. ",
    "barroca": "This issue is still present on 7.0 and 7.1. \narray (\n  0 => \n  array (\n    0 => 'a',\n    1 => 'b',\n  ),\n  1 => \n  array (\n    0 => '3',\n    1 => '11',\n  ),\n  2 => \n  array (\n    0 => NULL,\n  )\n. php version 5.6.9, I'm using a vagrant box with CentOS Linux release 7.1.1503\nThanks.\n. I see, so for now will you keep the package with the same behavior? \nThank you for the help! :)\n. ",
    "donnykurnia": "I got the same issue using fetchAssoc. I think this issues should be put into the documentation. I'm parsing 26k rows of data and getting the incorrect reading at the end of process is not a good sign. \n. Hi @nyamsprod \nI missed the flags because I follow the example page: http://csv.thephpleague.com/examples/\nI think setting the obvious flags every time is easily missed steps. Why not make the flags as default flag, still let the user change the flags later, but without any flags setting, it will assume the default flags (SplFileObject::READ_AHEAD|SplFileObject::SKIP_EMPTY) ?\n. Great @nyamsprod \nI'll try to help as much as I can within my spare time.\n. ",
    "snipe": "(I needed 7.0 because it was not parsing my CSV line breaks correctly without $csv->setNewline(\"\\r\\n\"); )\n. ",
    "nsitbon": "thanks for your comments, if you can't do anything about that I'll wait for the fix in the SPL.\nI spend some time in the documentation but cannot find if this behaviour is documented, can you tell me if there is something about this in the documentation. I'm sure there is nothing in the tests because I checked.\n. thank you much Ignace.\n. That's really cool guys thanks @zerocrates for pointing the fix and thanks @nyamsprod for implementing it ;-)\n. ",
    "zerocrates": "FYI, the php://filter stream filter support does appear to work with filters that contain slashes, as long as you percent-encode the slashes, i.e.\nphp://filter/read=convert.iconv.UTF-8%2FASCII%2F%2FTRANSLIT/resource=...\nThe linked open PHP bug report in the docs and @nyamsprod's earlier comment indicates this doesn't work, but it appears that the filter URI support was fixed to urldecode filter specifications back in August 2008, a little bit after the still-open bug about exposing the underlying resource was filed.\nIt might be worth revising the warning in the documentation about this, at least as it relates to iconv filters specifically.\n. ",
    "mrfinrod": "I have the same problem.\nException thrown here\nif($input_bom === Reader::BOM_UTF16_LE || $input_bom === Reader::BOM_UTF16_BE) {\n$reader->appendStreamFilter('convert.iconv.UTF-16/UTF-8');\n}\nWhat is the solution of the problem?\n. ",
    "landsman": "Same problem here .... ",
    "spagu": "and here.. ",
    "huglester": "wow. thanks @Heart1010 it works. Thanks for such a fast response :)\n. ",
    "tmoitie": "If not should I be approaching this problem from a different tack? Should I be validating the first row independently of the library?\n. ",
    "josoroma": "Thank you @nyamsprod\nNow I am going to improve my code using Reader::query\nHave a nice day!\n. Sorry but I still dont get it right!\nCould you please share an small example?\nThanks.\n. Your example looks very useful!\nThanks!\n. Update: My first version, using the associative array works nice but only incrementing following values directly in the php.ini:\nmax_input_time = 60\nmemory_limit = 512M\nsafe mode is off. \nThen I tried the code you suggest, using query and a callable method, but the behavior gets worse, running out of memory:\n``` php\n    public function convertItemsFileCallable($files)\n    {\n        $itemsFileName = 'items_file.csv';\n    $items = $this->fileExists($files, 'shortname', $itemsFileName);\n\n    if ($items) {\n        // echo 'HERE'; die;\n\n        $input = $items[0]['name']; // The absolute path of items_file.csv\n\n        $inputCsv = Reader::createFromPath($input);\n        $inputCsv->setEncodingFrom('UTF-8');\n        $inputCsv->setDelimiter(\",\");\n\n        $output = $this->_csvFilesPath . 'vp-' . $items[0]['shortname'];\n\n        @unlink($output);\n        touch($output);\n\n        $outputCsv = Writer::createFromPath($output, 'w');\n\n        $headers = $inputCsv->fetchOne();\n\n        $outputCsv->insertOne($headers);\n\n        $inputCsv->setOffset(1);\n        $inputCsv->addFilter(array($this,'filterItemsByStyleCodes'));\n\n        $callable = function(array $row) {\n            return [\n                $row['company'],\n                $row['item-number'],\n                $row['description'],\n                $styleCode\n            ];\n        };\n\n        $outputCsv->insertAll(\n            $inputCsv->query($callable)\n        );\n\n    }\n}\n\n```\nNote: The csv file has 100.000 records.\nThanks for all your previous support @nyamsprod.\n. ",
    "paslandau": "Works as promised. Thanks for linking to the bug and \"fixing\" this really quickly - highly appreciated :)\n. True.. that solves problem 1 :)\nAs for the encoding part: I guess http://csv.thephpleague.com/filtering/#example answers the question \n```\nPlease review the stream filtering example and the attached FilterTranscode Class to understand how to use the filtering mechanism to convert a CSV into another charset.\nThe FilterTranscode class is not attached to the Library because converting you CSV may depend on the extension you choose, in PHP you can use the following extensions :\nThe mbstring\nThe iconv\nThe intl\n\n```\nAlthough I feel this is kind of a very basic functionality and should be more prominently shown. Especially since I feel that the setEncodingFrom method is very misleading as it does not do anything in terms of encoding conversion.\n. Hey @nyamsprod ,\nfeeling really stupid right now.. but I honestly did not now that insertAll will actually write the content to the file. I was always thinking the writer would somehow \"internally\" store the rows in memory and I'd have to call some sort of method to write it to disk.\nTo be true, the docs did not really explain my simple use case (writing a csv file to disk) anywhere ;)\nAnyway, thanks a lot!\n. Hey @nyamsprod,\njust updated to the current dev-master and it works as expected. Thanks for the fix!\nFor the sake of completeness, here's the dev-master output of the script in the op.\n3 lines [1st, 2nd, <null>]  for NONE\n3 lines [1st, 2nd, <null>]  for READ_AHEAD\n3 lines [1st, 2nd, <null>]  for READ_AHEAD | DROP_NEW_LINE\n2 lines [1st, 2nd]  for READ_AHEAD | SKIP_EMPTY\n2 lines [1st, 2nd]  for READ_AHEAD | DROP_NEW_LINE | SKIP_EMPTY\n3 lines [1st, 2nd, <null>]  for DROP_NEW_LINE\n2 lines [1st, 2nd]  for DROP_NEW_LINE | SKIP_EMPTY\n2 lines [1st, 2nd]  for SKIP_EMPTY\nThe output is identical to v7.0.1.\nMy tests are currently part of my utility package for file based operations (tests are over here) and somewhat deeply integrated. But I'll check if parts of them can be extracted to extend the current league/csv test suite.\n. Great, thx!\n. Hey @nyamsprod \nDepends.. SemVer states that the \"public API must  not change within a patch/minor release\". Did you specifiy the exact behaviour anywhere in the docs? If not, a patch might be okay - on the other hand, that might be a missing piece in the docs :)\nI personally would bump up the major version because it might unexpectedly break existing code.\nCheers\nPascal\n. Hey @nyamsprod ,\nyou're right, I was talking about the enclosure character. Thanks for clearing that up ;)  \nI don't really see how adding an option like that decreases package quality, but I understand that the implementation is not trivial when fputcsv is used internally, since there's no option for adding the enclosure regardless of necessity on that function. I was just hoping there would be a workaround.\nCan you elaborate on \n\nI think it is possible to force an enclosure on every field using the plugins features of the package \n\n? Or point me to the corresponding page in the docu? I don't really understand to what you're referring as a \"plugin\".\nThx\nPascal\n. Haha, seems like a good trade off for me :)\nThanks for taking the time to write an in-depth article about the topic. I'll give it a try.\nCheers\nPascal\n. ",
    "gabidavila": "So, I did this:\n```\n<?php\n        $file = 'output/region.csv';\n    $csv = Writer::createFromPath($file);\n    $csv->setDelimiter(\";\"); //the delimiter will be the tab character\n    $csv->setNewline(\"\\r\\n\"); //use windows line endings for compatibility with some csv libraries\n    $csv->setOutputBOM(Writer::BOM_UTF8); //adding the BOM sequence on output\n\n    $csv->insertOne(['region_name', 'state_id_fk']);\n    $csv->insertAll($this->getAlldata());\n\n    $csv->output($file);\n\n?>\n```\nWhy still outputs on my terminal? Is there something I am missing?\n. ",
    "jcisio": "FYI, I had the same problem with @gabidavila. The last line is not necesary. And to flush the cache you can use $csv = NULL. So, that method is correct, but if you don't have the CSV created, then look elsewhere (permission etc. like stat(): stat failed for .../file.csv). In my case I have a strange behavior that I can't reproduce independantly. So here is the fix:\n$filename = 'private://data/out.csv';  \n$destination = Writer::createFromPath($filename, 'w');\nfile_put_contents($filename, '');\n// The previous line prevents from a \"stat(): stat failed for ...\" exception.\n$destination->insertOne(...);. ",
    "donaldallen": "Thank you so much! That worked flawlessly.\n. ",
    "maurocasas": "Really sorry to bring this up, but would you mind sharing how you did this?\nI'm having a hard time understanding how to transcode from UTF-16 to UTF-8 using Stream Filters.\nThanks!. ",
    "Richtermeister": "Sorry to bump this, I just fell into this trap as well, had some string comparison fail because of BOM present at first field of first row. Hard to debug..\nHaving to check/remove this character reduces much of the elegance of using this library, and I cannot imagine a case where one would not want this character removed. Would this not be better automatically stripped as part of the reading process?\n. I am not implying that the reader should alter the underlying file it reads. Clearly that would be unacceptable. \nHowever, just like the reader produces a transformed representation of that file (turning delimited to array, filtering, sorting, limiting, etc) I think it would be a simple matter of registering one more internal filter, to strip the BOM character from the first field of the first row before handing this data back to userland code. As it is the Reader registers several Iterator decorators already, this would just be one more.\n. Style question, are you ok with this code inline, or would you prefer a separate StripBomModifier, to enhance readability/testability?\n. Yes, apologies, got distracted. Will push update tonight.\n. WIP - Still working on tests.\n. @nyamsprod Absolutely, have at it, thank you.\nJust to explain the approach I took.. I was trying to implement the BOM-stripping very transparently across all csv access functions (once explicitly enabled via stripBom(true)), including the fetchOne method.. this is why I tried to customize the behavior of the getIterator method. The reason is that getRow() is used when you work with associative keys, and this is where my original problem with the BOM character occurred.\nLet me know if this makes sense or not :) Happy to elaborate. And thank you for the help, I really enjoy this library, you did a great job on it.\n. @nyamsprod Yes, awesome, I will check it out on the weekend.\n. @nyamsprod Yes, I did. We have a winner! :+1: Nice work man, works exactly right. Thank you very much!\n. Very cool! Upgraded :+1: \n. @nyamsprod I apologize for not being very responsive, as I am very busy at work, but I would like to pursue this idea further and I believe it makes your library better and more user-friendly. It's ok if this functionality will be obsoleted in 6 months, but that is still a long time down the road. Would you mind keeping this ticket open for me?\n. Ah yes, we want to respond to the original set, not the filtered one. Will implement.\n. ",
    "swarajgiri": "I kind of do the same, in sublime.\nFaced the tedious task of replicating the entire environment for an intern who i am trying not to harass :p\nWill post it in the groups, closing it here.\nThanks. \n. ",
    "panique": "@nyamsprod Thanks! For everybody else interested in this, this already seems to be an issue in Yii: https://github.com/yiisoft/yii2/issues/7529\n. FYI this is indeed a bug in Yii framework: https://github.com/githubjeka/yii2-rest/issues/3\n. ",
    "Tjoosten": "Any idea how i can fix this?\n. ",
    "wonzbak": "If I change the creation line\nphp\n$writer = CSV\\Writer::createFromPath(new \\SplFileObject($csvFilename, 'r'), 'w');\nby \nphp\n$writer = CSV\\Writer::createFromPath($csvFilename, 'w');\nIt works.\n. ",
    "cdekok": "@nyamsprod Yes i saw that one, only this will load one huge array which will cause memory problems on larger csv files, it would be nice if it would just return an iterator with assoc.\n. @nyamsprod static analyzers don't like it either and any ide.. if there is no alternative it's not nice to mark it as deprecated.. ",
    "itjunkii83": "I am using the above code and it is making an array with spaces added to the end of each key - I verified the CSV does not have a space - also I can't seem to access value when using the key.\n[\ufeffTracking ID ] => 724423122750\nAny Idea where I am going wrong?. ",
    "alexdesignworks": "@nyamsprod The fact that this method works differently based not only on the type of the first argument, but also whether it is provided or not, makes it really confusing to use. TBH, I've rarely seen such behaviour controlled by one argument. \nI was expecting a behaviour like this: if not provided = defaults to 0 and retrieves the header, if array - maps keys from array. But I would never expect it to return an IteratorMap.\nI'm not sure what can be done, but it is really confusing.. ",
    "cordoval": "yeah and thanks again for your work man :+1: \n. @nyamsprod thanks for your hard work, no need for a big release, our request is for at least a minor number bump.\n. i think perhaps what i was asking earlier was about a bump to 7.0.2 if you consider it right\n. again i am not asking for 7.1\n. ",
    "chicag0": "Any chance you can provide an example how I can use this?\n. ",
    "onema": "Awesome! will update and be testing it today.\n. I just tested the master branch and fetch* methods work as long as I call stripBom(true) before each call. It threw me off a bit, but looking at the code it seems this is the intended behavior; I didn't see anything related to this in the docs. Is this the intended behavior?\nphp\n$csv = '\ufeff\"Paret name\",\"Child name\",\"Title\"\n\"parent 1\",\"child 1\",\"title\"\n\"parent 2\",\"child 2\",\"title\"\n';\n$csvReader = Reader::createFromString($csv);\n$csvReader->stripBom(true);\n$assoc = $csvReader->fetchAssoc();\n$all = $csvReader->fetchAll();\n$assoc\nArray (\n    [0] => Array (\n            [Paret name] => parent 1\n            [Child name] => child 1\n            [Title] => title\n        )\n    [1] => Array (\n            [Paret name] => parent 2\n            [Child name] => child 2\n            [Title] => title\n        )\n)\n$all\nArray (\n    [0] => Array (\n            [0] => \"Paret name\"\n            [1] => Child name\n            [2] => Title\n        )\n    [1] => Array (\n            [0] => parent 1\n            [1] => child 1\n            [2] => title\n        )\n    ...\n)\n. :+1: thank you for your work on this. \n. ",
    "jjanvier": "@nyamsprod any idea how to achieve this? I'm facing the same problem in one of my project\n. ",
    "JoeDawson": "Oops, thanks @nyamsprod!\nWasn't aware that the return wasn't needed. Thank you very much!\n. ",
    "dopesong": "http://php.net/manual/en/function.fgetcsv.php#68213 - this example runs little bit faster :)\n. My mistake it's used only in one place, but not in query: https://github.com/thephpleague/csv/blob/633aad5203d7001ae1323a432129a79e91560cf4/src/Reader.php#L247\nI did. :+1:. It was my mistake, but still as I said that simple example a little bit faster (in some milisecs)\n. ",
    "adrian-schnell": "problem is solved - sorry it was an error caused by MAMP... :/\n. ",
    "ebuildy": "For those who came here from a search engine, solution is available from version 9.1: http://csv.thephpleague.com/9.0/interoperability/enclose-field/. \nEncloseField::addTo($outputWriter, \"\\t\\x1f\"); (small typo in the doc). Do you have version 9.1 ? It's open-source, so you can browser your vendor directory to find the class yourself ^^. ",
    "roberttolton": "What's the right class to be using? I'm getting:\nClass 'League\\Csv\\EncloseField' not found\nand:\nClass 'League\\Csv\\EnclosureField' not found. Thanks guys, yeah I noticed it was only on the 9.1 release, so I'm using \"league/csv\": \"^9.1@dev\" in my composer file now, and seems to work fine.. ",
    "ryzr": "Worth noting, adding a micro sleep in the loop usleep(100); normalized CPU usage to around 10%, for many different sized CSVs. The higher the sleep interval, the lesser the CPU usage.\n. ",
    "postalservice14": "Looks like this might be fixed in version 7.  I can't seem to reproduce it with the latest version.\n. ",
    "james-daddies": "I'll run a composer update and test again.\nOn Wed, Sep 16, 2015, 6:20 PM John Kelly notifications@github.com wrote:\n\nLooks like this might be fixed in version 7. I can't seem to reproduce it\nwith the latest version.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/thephpleague/csv/issues/116#issuecomment-140938333.\n. \n",
    "HeyRatFans": "Hi,\nIsn't the setNewLine method used to specify the line-terminator? This isn't intended to change that, but instead alter the text in the fields, i.e.: 1,\"two\",3,\"new\\r\\nline\" would become 1,\"two\"3,\"new\\nline\" (note the change in new line the 4th field), which we cannot otherwise change using Writer.\nWe need to do this to normalise the new-lines in the data we export, which unfortunately we can't alter at source and for speed I am using PDO and passing a statement directly into Writer, which is what attracted me to this library in the first place.\nDo you have a source for using invisible characters in a filter name? I had no problem creating a stream filter which does exactly as described above with the modified StreamFilter.php I have submitted and I did not encounter any errors, fatal or otherwise.\nApologies for not contributing a test, I have now added one to test the filter name, but not the actual functionality. Do you need one for this?\nThanks.\n. I had seen your blog entry previously, which actually gave me the idea of using a StreamFilter in the first place! :)\nI did originally start with a simpler filter that did just line-endings, but I have other use cases where a generic str_replace stream filter would be more useful than multiple classes and not just with this library.\n. What exception are you're seeing? I was seeing this:\nPHP Fatal error:  Uncaught exception 'RuntimeException' with message 'SplFileObject::__construct(): unable to create or locate filter \"convert.replace.\\r\\n:\\n\"'\nWhich was entirely my mistake as I hadn't commit the latest version of the FilterReplace class. The version submitted previously wasn't correctly matching \"\\r\\n:\\n\" which caused the onCreate method to return false and the above Exception to be raised.\nI'm not getting any other exceptions with your code snippet now.\nThanks.\n. I have updated the tests to show that the stream filter does work to replace \\r\\n with \\n with Writer. No exception is throw by writing the file! I have double checked this on both Ubuntu and Windows 7.\nHowever, I have discovered an interesting issue using Reader to read back the written data. If I use PHP's native fopen and fgetcsv I can verify the data is written successfully, but using Reader the data in my \"new line\" field appears to be stripped of all new lines, including both \\r\\n and \\n and I can't determine where or why this is occurring. This happens regardless of whether FilterReplace is attached to the Reader.\nHopefully you'll know better :)\nThanks.\n. Closing in favour of #123.\n. ",
    "frankdejonge": "@assertchris There a question about Generators, so I ping you because you are the expert.\n. @nyamsprod this looks like a nice improvement! One thing that feels a little out of place, is the Query name. But I'm not sure with what else it could be replaced.\n. @nyamsprod it seems more like a specification of some sort... right?\n. And yeah, naming things is really hard.\n. @philippfrenzel hi, an easy example is this:\nphp\n$filesystem = new Filesystem(new Local($rootDirectory));\n$contents = $filesystem->read($relativePath);\n. Oh wait, shit. This is a different project.\n. @philippfrenzel just a sec, will type up an example for you. Thought this was just \"how to read something from flysystem\".\n. @philippfrenzel ok, so it's fairly simple, you can just create a reader from a string:\nphp\n$filesystem = new Filesystem(new Local($rootDirectory));\n$contents = $filesystem->read($relativePath);\n$reader = Reader::createFromString($contents);\n. /gif party time. /gif happy face!. @Bilge please remember this is an open source project, people are requested to act kindly. If you come out of the gate with saying things are a \"terrible design flaw\" and \"misleading\", people are not going respond well. When this is addressed people are not \"completely missing the point and taking this too personally\". Maintainers can disagree with you, that does not mean they \"refuse to see any flaws\". I could go on, but I think the point is clear. The language you use is filled with rude comments and insults. I ask you kindly to refrain from doing so, otherwise we'll refrain from giving your issues any attention in the future.. I'd suggest to negate this check and throw this block, keeping the happy path alive.. ",
    "JonoB": "One thing I'd love to see (don't know if I've missed it before) - use the CSV column headings as array keys.\n. ",
    "assertchris": "The only way generators are better than iterators is in reducing the code to implement iterators. If you require 5.5 then you can use generators, but if you already get iterators from your code then porting that stuff over to exclusively use generators only benefits people looking at your implementation code.\nGenerators are iterators with less code and some structure for sending data/exceptions back into them.\nAbout that post - the purpose was to illustrate a use case for nikic/iter. I could have used this package for that, but that would be missing the point. It's also an interesting take on relating csv data, and where generators help with that. I don't think it's relevant to this discussion at all.\nEdit: @Heart1010 thank you for reading it, and being inclined to mention it here. That statement wasn't meant to discourage you. Rather to agree with @nyamsprod on the relevance of porting iterator usage to generator usage.\n. ",
    "davesouthey": "Has the official release of v8 been postponed?\n. @nyamsprod Okay, great. Just wondered as your previous post said the aim was the 3rd. I'm not putting pressure on, just offering to help if there is anything holding it back.\n. I'm certainly no scrutinizer genius and documentation around complexity seems rather sparse but I am think scrutinizer is taking into account all functions within the class whereas some other cyclomatic complexity calculations will ignore functions that aren't used within the class file.\nThe following aren't used within the class:\ninitstreamfilter, isactivestreamfilter, setstreamfiltermode, getstreamfiltermode, appendstreamfilter, prependstreamfilter, hasstreamfilter, removestreamfilter, clearstreamfilter, getstreamfilterpath.\n. Their fix has gone up :)\n. ",
    "larsbo": "@nyamsprod Yes, I know. I'm very sure that the file has some encoding issues.\nI tried some filtering with the Transcode library, e.g.\nphp\n$csv->appendStreamFilter(FilterTranscode::FILTER_NAME.\"UTF-8:UTF-16LE\");\nand any other combination of encodings but nothing worked.\nIs it even possible to solve such encoding problems with League\\Csv or should I use another library to fix it?\n. Oh, ok. \nSo you cannot safely determine what encoding the author of the csv file has tried to use if there is something wrong?\nSo if that were the case I have to convince PayPal that they doing it wrong? :-)\n. Yes, of course. When I open it with Sublime Text I can see the data without any problems.\nAfter saving it as a new file or just overwrite the original one and load it again with League\\Csv the encoding problem has gone and everything look fine.\nThis was the reason why I started this issue because I thought maybe there is some kind of special encoding thing that the library cannot handle properly.\n. ",
    "litan1106": "OS: Ubuntu 14.04\nPHP: 5.5.9\nLeagure/csv: 7.20\n$csvPath is the path of the csv file which it has 20 rows of data. $count was used to get the number of rows.\n. ",
    "ssfinney": "Why not both? Include an optional parameter for returning a generator. Returning the array here seems the \"safest\" option (no duplicate offsets), so add an optional parameter to return a generator for increased performance.\n. @nyamsprod I can understand that.\nI guess my point is that I see the benefit in both options (for different use cases) so I would like to choose between the two depending on my situation.\nHowever, maybe I'm off base and the user should make his project fit the implementation, not the other way around.\n. ",
    "gietos": "Oh, now I see, that is expected, there's even test for that (testReturnTypeResetBetweenCallToArray)\nWhy, then?\n. > BC perspective\nYou're working on new major version, right? So isn't it totally okay to get BC broken?\n\nBy resetting this behavior on each call you requires the user to explicitly state what return type he/she expects when using the method. This way whenever you receive a Reader object you have full control over what it can return.\n\nHere you've got object's state being changed implicitly. User sets property of an object, she expects that object configured respectively, not a method. It's totally unclear, that by setting a property you're going to affect only one future method call. If you choose to go with the property, just don't reset it after call.\n. :+1: thanks a lot for your work!\n. ",
    "repat": "Ok, thanks for the clarification. But I can't seem to figure out how to do the task I was describing above properly, which is:\n1. Get the data\n2. Change something in the data\n3. Write the data back to the same file\nThis code works but it seems rather complicated. Would it be possible to give insertAll() a $withHeaders flag in one of the next releases? A lot of the CSV files we generate have to have headers.\n``` php\n$filename = 'test.csv';\n$file = new SplFileObject($filename, \"r\");\n$reader = Reader::createFromFileObject($file);\n$header = $reader->fetchOne();\n$rows = $reader->fetchAssoc(0);\nunlink($filename);\n$file = new SplFileObject($filename, \"w+\");\n$writer = Writer::createFromFileObject($file);\n$writer->insertOne($header);\n$formatter = function ($row) {\n  $row[\"columnName\"] = \"PREFIX_\" . $row[\"columnName\"];\n  return $row;\n};\n$writer->addFormatter($formatter);\n$writer->insertAll($rows);\n```\n. ",
    "wesleyvicthor": "yeah, just noticed the setEnclosure method but, unfortunately I am not allowed to set a empty one.\n. ",
    "DixxieFlatline": "Oh sorry, I'm new to Github and didn't saw the closed issues tab.\nThanks.\n. Hello again and thanks for your support.\nI detected the exception was thrown because of the aray_unique() method used in validateKeys(), so doing a further exam on the headers I've seen that there is really a repeated one wich I didn't saw before (and it wasn't supposed to be on the doc).\nThanks and sorry for the unconvenience I could have caused for my error.\n. ",
    "gabiudrescu": "I ended up here after searching on Google Use a flat array with unique string values because the CSV I had was manipulated with Excel and ended up with a header like this:\npv.code,pv.images,,,\nthough in Excel nothing appeared to be wrong, opening the .csv file with Sublime helped me better understand the error message.\nI'm leaving this here so others might understand how to debug such errors in the future.. ",
    "cosecantt": "Oh my. I missed that part. Works fine. Thank you for your response.\n. I mean I want to save the created CSV file directly to the server under uploads folder. Is it possible with this current version? If yes would you mind give some tips. Thank you.\n. I want to pull data from database and save it to the server.\n$sth = $dbh->prepare(\"SELECT firstname, lastname, email FROM users LIMIT 200\");\n$sth->setFetchMode(PDO::FETCH_ASSOC);\n$sth->execute();\n$csv = Writer::createFromFileObject(new SplTempFileObject());\n$csv->insertOne(['firstname', 'lastname', 'email']);\n$csv->insertAll($sth);\nNow instead of \n$csv->output('final.csv');\nI want to save it to the server\n$csv->save('path/to/the/final.csv');\nIn this case how it is possible? Thank you.\n. Ok thank you for your answer. It was a little bit confusing. My apology. Now saving worked fine.\nBut I am having issues with UTF-8 characters. Whenever I read from database and write it to csv it does not recognize the UTF characters. Or vice versa. If I import a csv that contains UTF-8 characters that fields are not recognized. \nI looked at the documentation and tried everything mentioned there but failed all. It would be better if you could provide more examples on the documentation.\nAnything I am missing? Thank you.\n. ",
    "meharunnisashaik": "@cosecantt\ncan you please give the smaple code how you saved csv in to folder. my code is \n$data=\"data i want to show\"\";\n $csv = \\League\\Csv\\Writer::createFromFileObject(new \\SplTempFileObject());\n $csv->insertOne(['firstname', 'lastname', 'email']);\n$csv->insertAll($data);\n$csv->output('final.csv');\nfile is getting downloaded..but i want to save the file in laravel public/downloads folder..\ni tried to use save method but might be syntax error file not saving in the downloads folder..\n. ",
    "lightmed": "@meharunnisashaik \nIf you want to import data to file, this is the correct way:\n$csv = Writer::createFromPath('/path/to/the/final.csv');\n$csv->insertOne(['firstname', 'lastname', 'email']);\n$csv->insertAll($data);\n. ",
    "hskrasek": "So an update here, I found out the code that was written to write the CSV data to file was not using an SplFileObject, but an SplTempFileObject and then writing this data to file in another manner. To get the contents of the Writer, the code was triggering it's __toString method which uses ob_start and ob_get_clean. The second we moved the code away from using the output buffer, our corruption issue was resolved.\n. ",
    "mjordan": "OK, thanks for looking into this. I'll try the stream feature.\n. ",
    "abrahammontas": "is not an issue just a new feature.\n. sorry if I misspoke, my comment was just to try to improve the library.\nDo not think that I did a critique. On the contrary, I used the library many times and it works very well for me.\nI just said my opinion to express what could be ideal. I would love to be part of the contributors, i am willing to try and join your list. :) @nyamsprod \n. ",
    "hannesvdvreken": "For example this would enable me to do this:\n``` php\n$this->writer = Writer::createFromFileObject(new SplTempFileObject())\n    ->clearFormatters()\n    ->addFormatter(function ($row) {\n        // Formatter to transform every ORM object to array.\n        if ($row instanceof Model) {\n            return $row->toArray();\n        }\n    return $row;\n})\n->addFormatter([$transformer, 'transform']);\n\n// Insert all data\n$writer->insertOne($transformer->getHeaders());\n$writer->insertAll($repository->all()); // This returns a generator that yields every orm object\n// When done, make a response or something.\nreturn new Response((string) $writer);\n``\n. You're concerned about BC and rightfully so.\n- I think, as thestr_getcsvformatter is added in the constructor, it will always go first.\n- Only when theclearFormatters()method is called before any other formatter is added, this default formatter will be removed. This is a risk, cause some people might call this \"just to be sure\". In the documentation there is nothing stating there are no formatters when a writer is constructed.\n- About the formatters accepting arrays: when they pass something different to theinsertOne` method, this would throw an error. There is no automatic casting to arrays in PHP (afaik) because of array type hinted function arguments. So nobody will be passing it something else than arrays, thus formatters will not complain because of the relaxation (it's not defined in an interface). Logically I don't think this is a BC break.\n. I'll make sure to send a PR to adjust this too if you decide to accept this PR:\nhttps://github.com/thephpleague/csv/blob/gh-pages/inserting.md#csv-formatter\n. Fair enough :wink: \n\nSo here's what I would have done with your example.\n\nGood suggestion! Very clean and efficient.\n\nBy expecting an array and returning an array you can more easily use the Pipeline pattern\n\nThe php league's pipeline doesn't have a restriction on what is piped or what one stage might expect, though: https://github.com/thephpleague/pipeline\nI feel you're not inclined to merge this. I'm ok with this PR being closed.\n. No problem, it was worth the try. Thanks for your help as well. Hope to see you at this meetup in 2 weeks?\n. just curious: why snake_case instead of camelCase?\n. > I was in the mood for snake case\n:smile: \n\nnone of them are in contradiction to PSR2\n\nYou're right\n. It's deprecated sinde 4.1, and will be removed in the next major version.\n. ",
    "Lidbetter": "Thanks, I was returning the output from my controller, rather than just calling output.\nCommon Format and MIME Type for Comma-Separated Values (CSV) Files:\nhttps://tools.ietf.org/html/rfc4180\n. ",
    "medbenhenda": "Sorry, The composer contains this requirement\n. ",
    "eXorus": "Sorry but I don't see anything how to manage delimiter with more than one characters ?\nCould you help me ?\n. Thanks I will try to do it and give you an example.\n. ",
    "rosstuck": "Thanks for the quick response! To be clear, in my code snippet above, I'm not running those two pieces of code one after the other, it was just meant to show that each() respects the offset, whereas the version relying on IteratorAggregate does not.\nIf the same holds true though, I'm still confused about using the API with each() because it only returns a single row.\nMy use case is that I'm trying to read a large CSV file, streaming, and occasionally would like to start it from a particular row number (for example, resuming a test job). Can you help me understand what the best way to do this is? I'm a bit confused because each() only returns one row (even with limit explicitly set to all) and IteratorAggregate returns all but doesn't respect the offset.\n. Okay, I'll give that a shot, thanks!\nOn May 26, 2016 5:32 PM, \"ignace nyamagana butera\" notifications@github.com\nwrote:\n\nin that case then you need to use the fetch method like so:\n$reader->setOffset(50);foreach($reader->fetch() as $row) {  //starts at the 51th row...}\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/thephpleague/csv/issues/165#issuecomment-221906603\n. \n",
    "piwi91": "@nyamsprod I have used another solution to import the CSV data (I load the data into the MySQL database first, this is done in a few seconds).\nI will close this PR\n. ",
    "jbehrouzi": "yes of course ! \nthis is my file \nhttp://s7.picofile.com/file/8259232850/lessons.csv.html\n. ",
    "coreation": "You can also pass that file handle to the fgetcsv() function of PHP btw, @nyamsprod am I correct in seeing that this library does not support tabs as a delimiter? I checked the controls file and see that the mb_..len should be equal to one. \n. If your question is \"how should I do it in this library?\" Not sure, I use this library in parts of my application, but because it doesn't support tabs (afaik) I just used fopen with fgetcsv(), and it works just fine.\n. Hi @nyamsprod thanks for answering, however when I used setDelimiter(\"\\t\") it throws an error that the delimiter isn't valid. Am I using this incorrectly?\n. @dersonsena just use the fopen() and fgetcsv() functions instead of this library then, although I'm sure you can do streamed reading with this library as well. \n. thanks @nyamsprod for answering however I could either reply here or reply on https://github.com/thephpleague/csv/issues/161, the documentation only uses examples with delimiters of 1 character. Which immediately will violate this line. So using something like \\t does not work. This is just based on the delimiter documentation and the code that checks for valid Csv Controls, I'm sorry if I missed something else.\n. ",
    "dersonsena": "Thanks for your feedback @coreation. And as you would be done it in the library? Could you give an example?\n. I'm reading a CSV file of over 100 thousand lines and giving a memory overflow. As I said at the beginning, some people suggested that script.\nSo I asked if he had a way to change the reading. Perhaps, implementing some interface or some method overloading.\n. It's all right @coreation. The problem is that my application is using, and well, that library. For I refactor it would be a very hard work, so I'm wondering if there is that possibility.\n. Sorry, friend @nyamsprod . Just wondered if would to modify the shape file read as documentation (which I read many times) did not see anything related to this.\nThere was a big mistake when you said I was wanting something related to support.\nDo not worry, I will not bother you more. Embraces the whole team.\n. ",
    "Britic": "Thanks for your response.\nreturn \\Response::download($exportFilePath); is a Laravel function for returning the file for download. I understand that's not under your control, but even ignoring that, the file on the server remains completely blank.\nWhen I replace any use of writer with the native functions, I get the expected file download with all of the data.\n```\npublic function questionsExport()\n{\n    $exportFilePath = $this->createExportFile('questions');\n    $handle = fopen($exportFilePath, 'w+');\n    //$writer = Writer::createFromPath($exportFilePath);\n$headings = [\n    'Campaign Name',\n    'Location Name',\n    'Address 1',\n    'City',\n    'State',\n    'Zip',\n    'Assessment Date',\n    'Question',\n    'Answer'\n];\n//$writer->insertOne($headings);\nfputcsv($handle, $headings);\n\n$questionsData = $this->getQuestionsExportData();\n\nforeach ($questionsData as $data) {\n\n    $dataRow = [\n        $data->campaignName,\n        $data->locationName,\n        $data->locationAddress,\n        $data->locationCity,\n        $data->locationState,\n        $data->locationZip,\n        $data->completed,\n        $data->questionText,\n        $data->answerText,\n    ];\n    //$writer->insertOne($dataRow);\n    fputcsv($handle, $dataRow);\n}\n\n$headers = array(\n    'Content-Type' => 'text/csv',\n);\n\nreturn \\Response::download($exportFilePath, null, $headers);\n\n}\n```\nIf you want to close this issue as I can't confirm where the error lies, then that's no problem. Thanks for writing the package and responding to the issue.\n. ",
    "hhamon": "Done here: https://github.com/thephpleague/csv/pull/171\n. ",
    "andjelicsasa": "Thanks for the explanation @nyamsprod , I will look more into it.\nSetting the variable to null doesn't work as well as unset().\nIf I find a solution I will post it here, for others.\n. @nyamsprod yep you're right, I had a QueryFilter instance.\n$rows = $inputCsv->setOffset($hasHeaders ? 1 : 0)->fetch();\nThanks!\n. ",
    "mahngiel": "@nyamsprod done. see https://github.com/thephpleague/csv/pull/176\n. ",
    "dequis": "Thanks for the reply. Could you expand on the limitations of stream support on SplFileObject? Is the stuff in this post still accurate?\nI see that the code implements the php://filter/ hack, so if i'm interpreting this right the limitation is that you can't apply stream filters when AbstractCsv is created from an existing SplFileObject instance instead of the path. Is that correct, or am i missing something?\nBut in those cases, the failure mode seems to be to silently skip stream filters (either in getIterator() or in functions that read through other methods, if any). Considering this, I don't think it wouldn't be too bad to add a transcoding stream filter to setInputEncoding, but it could also be any other (new) method.\nThe iconv method is nice, certainly an improvement. I see that example is present in the docs, just presented in a way that isn't very clear, after a code block that registers that MyLib\\Transcode, and the \"example\" section at the bottom suggests the FilterTranscode thing.\n. Oh whoops i only saw the referenced commit after submitting that comment (because I had the browser a tab open for four days). Thanks for that. I'll comment stuff specific to that implementation in #178 \n. Hmm, I guess PHP doesn't have the concept of \"unicode strings\" so decoding doesn't mean anything without a target encoding. I do think that target encoding should implicitly be UTF-8 in all cases, but that's more of an opinion.\nI haven't considered the use case of manipulating CSV files (reading and writing back), I guess in those cases it may be desirable to keep the file in its source legacy encoding, but then it matters more to make it explicit.\nAnyway all I wanted from this issue was a quick no-frills no-thinking way to read files with any legacy encoding and work with them with a sane one internally. From the outside, without knowing the implementation details, setInputEncoding seemed to promise that.. Well that counts as fixed for me, really. Thanks!. Thanks! Using setInputEncoding that way looks much more comfortable, and the immutable query object is neat.\nOne potential issue I see with the cell-oriented transcoding method (which isn't introduced by this PR but wasn't used by everything before) is that it does splitting by ascii bytes first, and not all encodings are ascii compatible.\nIf you have a UTF-16 encoded document CSV with \u3b2c (U+3B2C) in it, the csv splitter see two bytes ,;, pick one of those as the delimiter, add an extra unwanted column to the csv, and the cell-oriented transcoder won't even hear about one of those chars, probably throwing a truncated data error.\nSo the stream filters should be used whenever possible.\nOther API ideas:\n1. Would it be a bad idea to keep (partial) compatibility with the \"old\" api as a __call method that creates a new Query and calls the corresponding method in that object? For example $csv->setOffset(10) doing return (new Query())->setOffset(10) transparently. Might be too much magic for your taste.\n2. Instead of $query = (new Query()), how about $query = $csv->query()?\n3. The Query object could be initialized with a reference to the reader, like new Query($csv) or $csv->query() calling new Query(this). This way, the Query object could have a get() method that does `$this->csv->getRecords($this).\nSo you could go from:\nphp\n$query = (new Query())\n    ->addFilter($filter)\n    ->setOffset(10)\n    ->setLimit(3);\n$records = $csv->getRecords($query);\nTo:\nphp\n$records = $csv->query()\n    ->addFilter($filter)\n    ->setOffset(10)\n    ->setLimit(3)\n    ->get();\n. ",
    "philippfrenzel": "Ok, until then I can easily follow, but what reader from CSV->reader() do I use then?\nThanks for your support!\n\nOn Sep 15, 2016, at 12:40 PM, Frank de Jonge notifications@github.com wrote:\n@philippfrenzel https://github.com/philippfrenzel hi, an easy example is this:\n$filesystem = new Filesystem(new Local($rootDirectory));\n$contents = $filesystem->read($relativePath);\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub https://github.com/thephpleague/csv/issues/182#issuecomment-247294691, or mute the thread https://github.com/notifications/unsubscribe-auth/ACNmEv4b8xJXvHeVRQc9ggRebwBpOHoyks5qqSCegaJpZM4J9J5v.\n. Don\u2019t worry - I use flysystem in production and it works wonderfull!\nSo sadly I\u2019m only a home made coder why from time to time I\u2019m stuck in potentially easy issues :)\n\nYour support is highly appreciated!\n\nOn Sep 15, 2016, at 12:44 PM, Frank de Jonge notifications@github.com wrote:\n@philippfrenzel https://github.com/philippfrenzel just a sec, will type up an example for you. Thought this was just \"how to read something from flysystem\".\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub https://github.com/thephpleague/csv/issues/182#issuecomment-247295481, or mute the thread https://github.com/notifications/unsubscribe-auth/ACNmEt2ejclGE4KXav9Hxpfz7cZgUBjSks5qqSGggaJpZM4J9J5v.\n. Ok, so if this will do the job - that's great! ;) Thanks! \n. \n",
    "RomainGoncalves": "I'm sorry, I wasn't clear.\nI actually have a PHP array of 90K+ lines of processed data. Then I try to input that in a CSV using the library. \nCode looks like this:\n``` php\n// $end = [ ['12-03.2015', 'event #1', '1', '2,', '1'], ....];\n$writer = Writer::createFromFileObject(new SplTempFileObject()); //the CSV file will be created using a temporary File\n        $writer->insertOne([\"date\", \"event\", \"Total Events\", \"Unique Events\", \"Event Value\", \"Avg Event Value\"]);\n        $writer->insertAll($end);\n        return $writer->output('events.csv');\n```\n65535 lines are written properly, but it stops there.\nThanks for your help.\n. hello @zf2timo \nthanks for your reply.\nYes my $end has the 90K array entries, I made sure of that.\nHas it been tried before to enter a lot of row at one time?\n. well, I get lots of data from Google's API and need to write it into a csv. No PDO or generator.\nWhat sort of generator?\n. No. I call the API many times over in order to get all the data I need, otherwise it gets sampled.\n. Do you think I should write the CSV as I receive the different calls?\n. For now, I do all the calls at once, I don't store the results in DB. Just in an array while the calls are being made.\n. OK i've tried implementing the CSV within a loop, so that my $end never has 90K anymore, more like 5k rows each iterations. But the final CSV is still limited to 65535 lines...\nI don't get it.\nBTW, I'm on a Mac, El Capitan, php7 if that helps...\n. OK my (huge..?) mistake. Happens that, the file is actually written properly! However Numbers (mac equivalent of Excel) does not display more than 65535 rows... I inputted the file within Google Spreadsheets, and I see all rows up to 90K+.\nSooo that's that.\nThanks for your help and I will close this thread.\n. ",
    "zf2timo": "65535 looks interesting -> 32bit\nMaybe there is an error with 32Bit somewhere?\nDoes your $end variable really all the expected 90k entries?\n. ",
    "harikt": "@nyamsprod Thank you for your quick help.\nA few things I noticed are \n``` php\nrequire 'vendor/autoload.php';\nuse League\\Csv\\Reader;\n$file = DIR.\"/file.csv\";\n$reader = Reader::createFromPath($file);\n$reader->appendStreamFilter('convert.iconv.UTF-16/UTF-8');\n$reader->stripBOM(true);\n$headers = $reader->fetchOne(0);\n```\nAdding $reader->appendStreamFilter('convert.iconv.UTF-16/UTF-8'); creates a warning as below.\n```\nPHP Notice:  Uninitialized string offset: 0 in /var/www/projects/vendor/league/csv/src/Modifier/QueryFilter.php on line 225\nNotice: Uninitialized string offset: 0 in /var/www/projects/vendor/league/csv/src/Modifier/QueryFilter.php on line 22\n```\nAlso closely looking the id keys got missing. See below.\n{\n    \"\": \"17\",\nThank you\n. I hope you could re-produce this now. This is when you call $reader->getInputBOM(); .\n``` php\n<?php\nerror_reporting(-1);\nini_set('display_errors', '1');\nrequire 'vendor/autoload.php';\nuse League\\Csv\\Reader;\n$file = DIR.\"/test.csv\";\n$reader = Reader::createFromPath($file);\n$input_bom = $reader->getInputBOM();\nif ( $input_bom === Reader::BOM_UTF16_LE || $input_bom === Reader::BOM_UTF16_BE ) {\n    echo \"BOM UTF-16 \" . PHP_EOL;\n    $reader->appendStreamFilter('convert.iconv.UTF-16/UTF-8');\n}\n$reader->stripBOM(true);\nforeach ($reader->fetchAssoc(0) as $row) {\n    // echo json_encode($row, JSON_PRETTY_PRINT), PHP_EOL;\n}\n```\n. Good to hear you was able to reproduce the same.\nAnd thank you very much for the valuable support you have provided.\nI wasn't able to find the reason to send a PR. Sorry about that :( .\n. Also in the case as I mentioned when calling $reader->getInputBOM() the ID was null on json_encode data.\n. Thank you @nyamsprod .\nI will look into sending a PR regarding the same. Please give me some time.\nThank you.\n. ",
    "eusonlito": "Thanks :+1: \n. ",
    "markitosgv": "Well I'm encoding with:\n$text= iconv(\"UTF-8\",\"UTF-16//IGNORE\", \"\u0646\u0648\u062f \u0627\u0639\u0644\u0627\u0645\u0643\u0645 \u0628\u0623\u0646 \u0627\u0644\u0645\u0643\u062a\u0628 \u0627\u0644\u0635\u062d\u064a \u0633\u064a\u0643\u0648\u0646 \u0645\u063a\u0644\u0642 \u0645\u0646 \ud83d\ude04\");\nBut is not working. When I save in UTF-8 and then converting with sublime to uf16-le then it works.\nWhen I inspect file --mime when I export with BOM_UTF16_LE I get:\n55bc9ff3182f5b165c0041a9_1475756668_1.csv: ERROR: line 22: regexec error 17, (illegal byte sequence); charset=utf-16le\n. Ok thanks I achieve with Excel for Mac example: http://csv.thephpleague.com/bom/\nThanks! My mistake.\n. ",
    "sathwikram": "Thank you so much\nIt's because of PHP version\n. Thank you so much\nIt's because of PHP version\n. ",
    "GaryJones": "Thanks for the confirmation :-)\n. ",
    "vrubiella": "@nyamsprod maybe i'm wrong, but, I don't like create class wrappers only for testing purposes.\nFor example, I have a method that loads CSV data to database, csv path:\n``` php\nfunction loadDataFromCSV(string $csvPath)\n{\n  // ... code here\n  $csvObj = Reader::createFromPath($csvPath);\n//... code here\n}\n```\nWhen I was testing (unit testing) loadDataFromCSV method, I just test that createFromPath method is called with $csvPath, I don't want execute Reader method.\nSomething like these:\nphp\n $this->createMock('Reader')->expects($this->once())\n->method('createFromPath')\n->with($csvDummyPath)\n->willReturn($dummyReader);\nMaybe there are another way to do this test unit ? (without creating a wrapper class containing Reader calls)\n. @nyamsprod so, this solutions it's good for solve problem in \"loadDataFromCSV\", but externalices the problem to method who calls to \"loadDataFromCSV\". \nIn my opinion, testing we shouldn't acces to real filesystem or real files.\n. ok, closing issue.. ",
    "AndrewFeeney": "No problems, I obviously missed that in the documentation. I will close this PR.. ",
    "IgnitedCoder": "Absolutely... I think it might just be user error, that would be good news. :)\n$dataFile = $this->template->filePath . $this->template->fileName;\n        $this->fileReader = Reader::createFromPath($dataFile);\n        $this->fileReader->setDelimiter('    '); //Tab delimited character.\n        $this->fileReader->setEnclosure('\"');\n        $this->fileReader->setEscape('\\');\nNote this works when I remove the double quote enclosures.. . yeah I guess, each row is enclosed in double quotes and is tab seperated. Any ideas? I would very much like to continue using the CSV Lib.. ",
    "alxy": "Thanks, that looks promising!. ",
    "ZWalrus": "OK. Thank you for the answer! I like this tool, very cool!. ",
    "mbrodala": "Thanks for the heads up. Maybe a hint on every deprecation in the could could be useful here.. ",
    "JC5": "It does, apologies. I am used to deprecation after the new method has been presented. :wink: . I appreciate the change, @nyamsprod !. ",
    "joshbrw": "I came here for this exact reason. Shouldn't the method be deprecated once an alternative is available?. @nyamsprod Surely these methods are going to be superceded by some other method? The PHPDoc documentation states If it is superceded by another method it is RECOMMENDED to add a @see tag in the same PHPDoc pointing to the new element., which is what I'd have expected.. Of course. But surely you're always going to need to fetch data from the CSV, no?. I guess it all depends on your view of what deprecated means. My IDE (PHPStorm) throws up a usage warning if the method is used.. @cdekok I don't think we're going to get our way with this one, but I whole-heartedly agree with you.. Thanks @nyamsprod - appreciate it!. ",
    "alexeyshockov": "Agree with @joshbrw. When I see a deprecated method, I always try to refactor the code. But in this case I'm unable to do that.\nBy using @deprecated just to notify users, you push them to pay less attention to really deprecated things (because they cannot fix all @deprecated issues from now). And after some time with a bunch of such issues unresolved you just stop paying attention to them.\n\nIf it is superceded by another method\n\nOf course, you are right that providing an alternative is not required. But Reader is the only class to read content from a CSV file (in the library), and, deprecating of its main methods without providing an alternative, you deprecate the whole task of reading CSV.\nSo I'm puzzled now, because I want to read a CSV file, but I don't know how to do it properly (with league/csv).\nJust my 5 cents.. Thanks, @nyamsprod!. ",
    "Gabriellpweb": "I need the file on disk, but the output method only provides download. So I've implemented a method to only save in the disk.. You're right! Sorry =s! Closing!. ",
    "shadowhand": "For whatever reason, the following code works:\n```php\nforeach ($reader->fetch() as $row) {\n    $write->insertOne(array_intersect_key($row, $columns_to_extract));\n}\n$reader = Reader::createFromString((string) $write);\n``. My \"fix\" appears to break other things. :) I'll trust you can sort it out.. Just confirmed that this fix works. Thanks!. You removed the$escape` type hint, but the param is still available in the method.. This changes the public interface and should not be part of a bugfix.. The expected return value for this method is an array, and now appears to be a string.. ",
    "drjonnicholson": "Ahh, yes different version of code to the package installed. Didn't think to check!\nQuite right about the SplTempFileObject, and we just resolved our issue in another way anyway making our issue moot. Thanks for the feedback, closing the issue.. ",
    "stephenvicino": "I meant for the $header to be the headers for the CSV.\nI have checked the data I am inserting; $header is set as Array\n(\n    [0] => Email\n    [1] => First Name\n    [2] => Last Name\n    [3] => Phone Number\n    [4] => Company\n    [5] => DOB\n    [6] => Tags\n    [7] => Address\n    [8] => Address 2\n    [9] => City\n    [10] => State\n    [11] => Zip\n)\n. Where is it being added twice? I am a bit confused on this.. I revised my code but still having the issue:\n$csv = Writer::createFromFileObject(new SplTempFileObject());\n$csv->insertOne($header);\n$csv->insertAll($contents);\nheader('Content-Type: text/csv; charset=UTF-8');\nheader('Content-Disposition: attachment; filename=\"User-List-'.date(\"Y-m-d\").'.csv\"');\n$csv->output();. I copied your code and I still got a blank first row.\n. ",
    "kumar1010sumit": "I have same issue. And its a real issue. I used Ubuntu 18.04. @nyamsprod but its a genuine issue. Someone was also faced this kind of issue #217 But unfortunately there was no solution.. @nyamsprod  my colleague also try this one. But having same issue. We are using laravel 5.7.. @nyamsprod temporarily solved the problem using ob_end_clean(); before $csv->output(file.csv);. Thanks for your support @nyamsprod . Finally solved my issue through this link.\nThis is not a package issue. If any pure php file contain closing tags (?>), then there is a possibility to send the space, new line, etc by your editor. So make sure, your pure php file doesn't contain any php closing tags. . ",
    "cdarken": "Thanks for the response. Yes, I'm pretty sure. But give me a minute to just create a simple test outside of my project where I encountered the error.. I'm using fetchAssoc() as I specified. That classifies as an extract method, right?\nThe thing is, in a fresh test, just using league/csv, the BOM is stripped. But in my project, even though I use exactly the same code, it isn't. Does it matter if it's an uploaded file? It shouldn't, right?. Umm, if I call fetchOne before calling fetchAssoc, the stripping will not happen on the second call? Because I think that's the case.. Ok. Got it. Is it specified in the docs that now we should call it each time? If so, I have no way of knowing because the phpleague site is down.\nThanks for the help.\nPS: Congrats on zero issues open on the project. You're doing a great job!. ",
    "rbruhn": "Hi.... no it's not a bug... definitely just a question.. lol\nI've been using the reader set up like this for ordinary csv files:\n$this->reader = Reader::createFromPath($file);\n$this->reader->setDelimiter(',');\n$this->reader->setEnclosure('\"');\n$this->reader->setEscape('\\\\');\nI actually added the setEscape in an attempt to get around this issue.\nThe CSV file has other regular columns and data. There are just a couple columns that have the JSON strings. They are exported that way from an API I'm dealing with.\nAny suggestions?. So there isn't a way to strip the slashes or anything while reading the data? I did try using a function to do that while using \"fetch\" but it didn't seem to do anything.. Just to update in case someone stops by.... using double quote '\"' as the escape character resolved my issue.. ",
    "bs-thomas": "At the repository https://github.com/aws/aws-sdk-php/ at AWS end, I got assistance from @jeskew and got the following working code.  Thank you!\n```\n// Create the stream wrapper\n$s3Client = \\Aws\\S3\\S3Client::factory(array(\n            'version' => 'latest',\n            'region' => $region,\n            'credentials' => array(\n                'key'    => $key,\n                'secret' => $secret,\n            ),\n        ));\n$s3Client->registerStreamWrapper();\n$context = stream_context_create(array(\n    's3' => array(\n        'seekable' => true\n    )\n));\n$stream = fopen($filePath, 'r', false, $context);\n$reader = \\League\\Csv\\Reader::createFromStream($stream);\n```. ",
    "fernandocoronatomf": "@bs-thomas Thanks, it worked for me as well. But does anybody have any idea why? I don't understand why seekable => true allows me to stream the first line. ",
    "php-": "I could not find it, thats why I asked you.\nOn 27 Apr 2017 03:13, \"ignace nyamagana butera\" notifications@github.com\nwrote:\nHI @php- https://github.com/php- did you read the documentation as this\nis well explained there.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/thephpleague/csv/issues/225#issuecomment-297631462,\nor mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AJlb1aPpuGUq7SKM2_vfeGHaTTe62Xw1ks5r0EARgaJpZM4NJN5a\n.\n. Thanks a lot, that's what I needed.\nlove you:*\nOn 27 Apr 2017 8:59 am, \"ignace nyamagana butera\" notifications@github.com\nwrote:\n\nWell since I don't know what you are trying to accomplish I can't help you\nwhat I can tell you is what's written in the documentation :\n\nthe Writer is constructed to work with a single file at once\nthe Writer relies on stream and SplFileObject meaning you can't use\n   cloning\nthe Writer actions are based on the open_mode arguments from fopen\n   (to be simple)\n   So:\ncloning the Writer is not possible since cloning a stream\n  resource ou SplFileObject is not possible\niterate over a Writer object is highly discourage because of\n  cursor pointer loss and open_mode choice (may erase your CSV document on\n  rewind for instance)\n\n\n\nAgain this information is present in the documentation so I don't know\nwhat else you need.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/thephpleague/csv/issues/225#issuecomment-297706016,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJlb1YQKv1enCVahffdvnLezviW7feJoks5r0JEegaJpZM4NJN5a\n.\n. \n",
    "joao-gsneto": "Thanks @nyamsprod  but installing via composer\ncomposer require league/csv\nby default installs the 8.x version and this make the confusion.\nInstall with\ncomposer require league/csv:9.x-dev\nsolves this problem.. ",
    "PsychicCat": "@nyamsprod It's ending up as an extra row on my CSV file. Am I doing something wrong? \n$csv = Writer::createFromFileObject(new \\SplTempFileObject());\n            $csv->insertOne(array_keys(get_object_vars($report[0])));\n            foreach ($report as $row) {\n                $csv->insertOne(get_object_vars($row));\n            }\n            return $csv->output();\nedit: ok it does go away if I exit; instead of return. . ",
    "Dumk0": "Okay, my bad. I was looking into FEATURES block I didn't scroll to the end to see that there are links to different version documentation. IMHO from UX point of view it would be better to show links to documentation on top of web page and have the link to correct version of docs in the README.md. ",
    "youvtr": "@nyamsprod Thanks for your help but even after implementing your suggestion the same error happens.. ",
    "omer-sds": "sorry had to use absolute path for saving the file used \nrealPath ( Yii::$app->basePath . '/../' .Yii::$app->params['upload_path'] . '/' ) to fix the issue , closing it now . now it is creating a file but there is no data inside it :( , the new updated code looks like this \n```\n$subscribers = Subscriptions::find ()->where ( ['=' , 'DATE(created_on)' , date ( 'Y-m-d' ) ] )->asArray ()->all ();\n    //absolute path for the files \n    $filePath = realPath ( Yii::$app->basePath . '/../' .Yii::$app->params['upload_path'] . '/' ) ;\n    $fileName   =   $filePath.'/'.'new-subscribers.csv';\n    //we create the CSV into memory\n    $csv    =   Writer::createFromPath($fileName,'w');\n\n    // The PDOStatement Object implements the Traversable Interface\n    // that's why Writer::insertAll can directly insert\n    // the data into the CSV\n    $csv->insertAll ( $subscribers );\n\n    // Because you are providing the filename you don't have to\n    // set the HTTP headers Writer::output can\n    // directly set them for you\n    // The file is downloadable\n    $csv->output ();\n\n```. sorry again had to change the file mode :D to write in the data. ",
    "pardalsalcap": "Yes thats a solution. Thanks!\nAnyway I think that the setEnclosure() method should be mandatory. I mean if setEnclosure('\"') all fileds must have \"xxxx\", \"cccc\", \"aaaaa\" \nBut maybe I'm missing something.\nThanks anyway. ",
    "gerald27": "@nyamsprod yes still the same result using League\\Csv 8.x.. I have change my code to that but still the same issue. \nResult:\n\nCsv: https://www.dropbox.com/s/0z651wlnpada44d/list3.csv?dl=0\nThanks.. Thanks for the help, it's working great now.. ",
    "davidbonachera": "Sorry I haven't been clear. I mean that I got my csv after my SQL request then I have to parse this csv with the reader class and then I do some transformation.. So to be clear, in the case where the Reader sees a NULL in a csv row, it should read it as a \"NULL\" string ? \nAnd in your opinion, my script should first clean the CSV and those \"NULL\", then it should use the Reader, then it should process the data ?\nAn interesting idea from another CSV package could be to define an array of nulls values : \nhttps://github.com/databricks/spark-csv/issues/333\n. ",
    "arnacmj": "Maybe you should try it to your self sir,\n\"league/csv\": \"8.0\",\nYour requirements could not be resolved to an installable set of packages.\nProblem 1\n    - This package requires php >=7.1 but your PHP version (7.0.10) does not satisfy that requirement.\n. Im wondering in documentation required minimum version of PHP 5.5 in version 8.0?. I've changed my php version to 7.1.16 and everything works fine,. Anyways @nyamsprod  thank you for immediate response.. ",
    "hakobsharabkhanyan": "Hi @nyamsprod . This is happening where there is about 1000 rows . The interesting thing that Logs reaching to the 'Downloading csv' , but instead of downloading, its showing 301 redirect in console . We tried also putting headers for forcing system to understand that its download and in csv format, but did not help .\nThanks for response. Oh i see . thank you so much . . ",
    "shakisha": "Thank you guys! :-). ",
    "joskfg": "Hi @nyamsprod, thanks for reviewing the PR. It tries to give a solution to the fact that PHP doesn't support seek for remote streams. This means that if you want to use the library, you need to create a seekable stream that it is local and it is not easy to do.\nAs you refers, it can be solved with the createFromStream. I suggested to give the functionality out of the box because the remote files usage is common. Maybe there are more solutions but this is the best I found and it is based in the solution used in makeFromString.\nFinally, you are right it can be an external package because all you need is createFromStream, but the library is already implementing helping methods like createFromPath or createFromString that can be easily done with createFromStream using createFromStream(fopen('/path/to/file.csv', 'r+'));, so I thought that this new helper could be a good solution.\nRegards. Any idea/base about how to do a plugin?. I won't use PSR-7 because PSR-7 is just for HTTP and this work for a lot of protocols like for example FTP (see http://php.net/manual/en/wrappers.php).\nRegards. Yes, I just wanted to clarify that the PR has a wider scope :-).\nThanks. This is needed because the fake information was not right, so the stream_copy_to_stream didn't work. I could hardcode the 60 as size to pass the specific test but it could produce problems in future tests.. ",
    "alperyazgan": "And the enclosure has the same problem ... . Thanx. ",
    "AC-TimRourke": "Thanks so much @nyamsprod! That really clears things up. :). @nyamsprod I have a follow-up question. I'm stuck on the 8.x branch because I must support PHP 5.6. Your example references a method, AbstractCsv::chunk, but that method does not exist in version 8.x. Is there a way to accomplish the same chunked output without using a generator?\nhttps://github.com/thephpleague/csv/blob/9.0.0/src/AbstractCsv.php#L277. Thanks again @nyamsprod! I made a PR to backport AbstractCsv::chunk to 8.x to make this simpler and line up with the Symfony StreamingResponse example you shared. \nhttps://github.com/thephpleague/csv/pull/248. Update: this seems to work just fine for smaller exports, testing an extremely large export now to make sure this will not consume an inappropriate amount of memory.. \ud83d\udc4d  thanks for the heads up, I'll go ahead and close this. I'm hoping to support PHP7+ in the project I intend to use this in, so I'd prefer the 9.x branch anyway. Appreciate the feedback, and the warning about the bug!. @nyamsprod I just discovered that no method called valid exists on the object returned by AbstractCsv::getIterator. Is something like this an acceptable workaround?\nphp\nwhile (!$document->eof()) {\n    // etc.\n}. Never mind, looks like AbstractCsv::getIterator always returns either League\\Csv\\Modifier\\StreamIterator, or SplFileObject, both of which would allow calling ::valid for this use case.. ",
    "theodorejb": "It looks like this is the commit that broke it: https://github.com/thephpleague/csv/commit/87bc1aab2cced42710435dffaf4b1b9c4cffa053#diff-a88754023d30e0f85dd47cb54f5de942R319. I ran into this exact same issue when trying to insert arbitrary text from a database, where some of the rows contain backslashed double quotes, commas, and newlines. Here's a code example:\n```php\n$csv = Writer::createFromFileObject(new SplTempFileObject());\n$exampleText = <<<'EOD'\n\"Some text with \\\"backslashed\\\" double quotes\"\nAnother line with \"double\" quotes, and a comma\nEOD;\n$rows = [\n    ['a' => 'row 1', 'b' => 'column b'],\n    ['a' => $exampleText, 'b' => 'row 2, column b'],\n    ['a' => 'row 3', 'b' => 'column b'],\n];\n$csv->insertAll($rows);\n$csv->output('escape_bug.csv');\n```\nWhen I open the CSV in Excel, it's completely broken:\n\nThe double quotes are messed up, the newline created a new row, and the comma split the text into another column!\nActual CSV contents\n\"row 1\",\"column b\"\n\"\"\"Some text with \\\"backslashed\\\" double quotes\"\"\nAnother line with \"\"double\"\" quotes, and a comma\",\"row 2, column b\"\n\"row 3\",\"column b\"\nExpected CSV contents\n\"row 1\",\"column b\"\n\"\"\"Some text with \\\"\"backslashed\\\"\" double quotes\"\"\nAnother line with \"\"double\"\" quotes, and a comma\",\"row 2, column b\"\n\"row 3\",\"column b\"\nI dug into the code for the Writer class and traced the issue back to the fputcsv PHP function, which takes an $escape_char argument defaulting to a backslash. Apparently any enclosure characters (double quotes) preceded by the escape character aren't escaped.\nIt turns out there is a thread on PHP internals about this problem here: https://externals.io/message/100729. The issue could be fixed in PHP by allowing a blank string to be passed to fputcsv for the escape character.\nI was able to work around the bug by adding the following line before the call to $csv->insertAll:\nphp\n$csv->setEscape(\"\\0\");\nPerhaps this library could also work around the issue by simply changing the default escape character to a null byte.. @nyamsprod You're right that using a null byte as the default escape character would be a BC break, and it's somewhat of a hack that may not work in every situation.\nI'm not entirely convinced that adding a new writing mode parameter is the best solution, however. It's still possible that the issue could be fixed in PHP by allowing a blank string to be set as the escape character. In the meantime before PHP allows this, perhaps this library could special-case calling setEscape(''), which would switch to a writing mode that doesn't use fputcsv. In the next major version of League/Csv, this could be the default. Then if PHP eventually supports a blank string as the escape character, the separate writing mode could be removed.\nAre there any other important differences in the RFC4180 writing mode other than ignoring the escape character? If so, I'm concerned that it might be a bigger BC break than just allowing a blank escape character but keeping the rest of the fputcsv behavior. Also, how does the new writing mode perform compared to the native PHP function?. There is now a pull request to fix this in PHP: https://github.com/php/php-src/pull/3515.. @nyamsprod Indeed, it sounds like the PHP patch won't land until 7.4, so a polyfill will be needed for previous versions.\nI'm not sure about the fgetcsv approach, either. I don't really like the inconsistency it creates between reading and writing. Conceivably someone could write a CSV containing a null byte before the enclosure character, and then not be able to read it back properly. I feel that it would be better to either use a custom RFC4180-compliant reader, or replace an empty string with a null byte when both reading and writing with the native PHP functions.\nPersonally I think the latter approach would be fine in practice, since needing to read/write a null byte followed by a double quote seems extremely unlikely compared to reading/writing backslashed quotes.\nIf a custom writer is used, it also seems like it should match PHP's behavior of always surrounding fields with the enclosure character, so that this behavior won't change when upgrading to PHP 7.4.. I tested out this branch and as far as I can tell it is working as expected. I diffed a file output using the new writing mode with a file output using the old mode and a null byte as the escape character, and the only noticeable difference is that the new writing mode doesn't add enclosures around every field.\nFor me the new writing mode performed about the same as before when exporting a somewhat large CSV (over 23K rows).\n@nyamsprod Thanks for your work on this!. I tested the branch again and did some benchmarking. The good news is that it seems to be working reliably! I was able to output a large CSV, read it into memory, and write it back again with zero loss of data.\nI compared the performance of native reading/writing (passing a null byte to setEscape) with the polyfills (passing a blank string) on an 11MB, ~24K row CSV.  Here are the results (averaged over 5 runs):\n| Action                   | Average time (sec) | Percent slower |\n| ------------------------ | ------------------ | -------------- |\n| native read native write | 4.552              | N/A            |\n| native read custom write | 5.008              | 10%            |\n| custom read native write | 7.496              | 65%            |\n| custom read custom write | 7.960              | 75%            |\nWhile the custom writer is almost as fast as the native function, the custom reader is noticeably slower. \ud83d\ude22 Correct results are more important than performance, though, and maybe the custom reader can be optimized more in the future.\nFrom reviewing the patch diff, it looks like the custom reader unit tests are just checking that the number of rows is correct. Shouldn't they also verify that the row contents match what is expected?. It doesn't seem that fgets is any faster - maybe even a bit slower. With the latest commit it now takes an average of 8.6 seconds to parse and output my CSV.. Fantastic work! The empty string polyfill is now (significantly) faster at reading my 24K row CSV than the native function. I ran the same benchmark as before and got the following results:\n| Action                   | Average time (sec) | Percent change |\n| ------------------------ | ------------------ | -------------- |\n| native read native write | 4.01               | N/A            |\n| native read custom write | 4.22               | +5%            |\n| custom read native write | 1.53               | -62%           |\n| custom read custom write | 1.71               | -57%           |. @nyamsprod For reference here's the code I used for testing:\n```php\nuse League\\Csv{Reader, Writer};\nrequire 'vendor/autoload.php';\n$start = microtime(true);\n$csv = Reader::createFromPath('test.csv');\n$csv->setEscape(\"\");\n$copy = Writer::createFromPath('test_copy.csv', 'w');\n$copy->setEscape(\"\");\n$copy->insertAll($csv->getRecords());\necho 'took ' . (microtime(true) - $start) . ' sec';\n```\nI verified that test_copy.csv is byte-for-byte identical to the original file by checking its SHA-256 hash. I'm sure there are edge cases in reading CSVs that my file doesn't cover, though, so hopefully the League/CSV unit tests will catch all of them.. Does fgetcsv also support reading those invalid fields without warnings? If so, I think the custom parser should continue supporting it, so that files readable with the native function will also be readable via the custom parser. And in general I think it's good to follow the Robustness Principle.. ",
    "0l1v3r5": "everything is ok. Good job. Sorry for closing. I had to let you close it. my bad. . thank you.. ",
    "graemedewe": "I need to sanitise uploads and downloads, any suggestions for how to apply this in the Reader mode? and due to being stuck on php5.6, for now, I can only use 8.2.2. thanks. thanks, found the right documentation now. ",
    "nwhitt": "It must be in the error handling of my symfony package with suppression, as I get green on unit tests. I'll close this issue until I have more information.. ",
    "IllyaMoskvin": "I had this exception happen because the user under which PHP was running (e.g. apache) did not have permissions to do anything except read the target file, which did indeed exist.\nI fixed it by adding the 'r' mode to my createFromPath call (cf. fopen mode):\nReader::createFromPath('/file/that/actually/exists.csv', 'r');\nI know it's somewhat off-topic, but this issue is the top result in Google for that error message, so maybe this will help someone. . ",
    "csiszarattila": "You can reproduce this error if you have a set_error_handler() somewhere in your code.\nA custom set_error_handler() emits errors, and error_get_last() returns null, hence the exception throwing not working in this line, it will generate an error:\nhttps://github.com/thephpleague/csv/blob/6418c1c5872e9ea9464330531f7b63232e58c496/src/Stream.php#L177-L178\nThe error easily reproducable with this code:\n```\nset_error_handler(function($errno, $errstr) {\n    var_dump($errno, $errstr);\n});\n@fopen(\"test.cvs\", 'r');\nvar_dump(error_get_last());\n--- outputs: \nint(2)\nstring(65) \"fopen(test.cvs): failed to open stream: No such file or directory\"\nNULL\n```\nI think error_get_last()['message'] needs to be checked, and return a general message if its empty.. ",
    "garygreen": "Oh ok, makes sense. Really have to get a better host at some point \ud83d\ude04 . ",
    "Bilge": "If that's your honest response, then excuse me for saying, but it seems you don't have a very good understanding of file permissions. In the case that I have my CSV hosted in a read-only environment, trying to open it with redundant write permissions will result in an access violation. That is, a fatal error will occur trying to open a read-only CSV with Reader::createFromPath(). It should strike you as obvious that a class called reader should only require permission to read; if it does not I do not have high hopes for the future of this project.. @nyamsprod You are completely missing the point and taking this too personally. This has nothing to do with documentation; it is a design flaw with the defaults you have chosen for file access modes for the Reader class. The default file access mode should not include the write attribute. This cannot be fixed with documentation, it can only be fixed in code.. It will be a BC break because it requires changing the default file access\nmode. Are you OK with that?\nOn 11 Sep 2017 17:22, \"ignace nyamagana butera\" notifications@github.com\nwrote:\n\n@Bilge https://github.com/bilge submit a PR it will be reviewed and if\nit is found useful it will be merged. Thanks\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/thephpleague/csv/issues/258#issuecomment-328582083,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAcuYnzSbeTybNMMSwNWXYQQWxkMAh06ks5shV5HgaJpZM4PTTJE\n.\n. Yes of course. What is the earliest you would be willing to release the\nnext major?\n\nOn 11 Sep 2017 17:38, \"ignace nyamagana butera\" notifications@github.com\nwrote:\nYes but it will have to wait until the next major release\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/thephpleague/csv/issues/258#issuecomment-328586383,\nor mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAcuYq3idPUE3_Zg58yttgtnEPM9ivXCks5shWH9gaJpZM4PTTJE\n.\n. I don't find any of those points compelling. What is the problem with releasing a new major version tomorrow? Nobody is forced to upgrade; they do so at their convenience. However, if you're committing to not releasing the fix for 18 months I will not write one since you are actively discouraging me from doing so.. I cannot understand how you can possibly think it's not broken. Allow me to demonstrate with a proof of concept.\n\ntouch foo.csv\nchmod a-w foo.csv\nnamei -m foo.csv\n-r--r--r-- foo.csv\n\n\n(League\\Csv\\Reader::createFromPath('foo.csv'))->fetchOne();\n\n\nPHP Fatal error:  Uncaught RuntimeException: SplFileObject::__construct(foo.csv): failed to open stream: Permission denied in /srv/wa-api/vendor/league/csv/src/AbstractCsv.php:271\nStack trace:\n\n0 /srv/wa-api/vendor/league/csv/src/AbstractCsv.php(271): SplFileObject->__construct('foo.csv', 'r+')\n1 /srv/wa-api/vendor/league/csv/src/AbstractCsv.php(253): League\\Csv\\AbstractCsv->setIterator()\n2 /srv/wa-api/vendor/league/csv/src/Modifier/QueryFilter.php(160): League\\Csv\\AbstractCsv->getIterator()\n3 /srv/wa-api/vendor/league/csv/src/Reader.php(119): League\\Csv\\AbstractCsv->getQueryIterator()\n4 {main}\nthrown in /srv/wa-api/vendor/league/csv/src/AbstractCsv.php on line 271\n. You are completely missing the point. The default behaviour for a class called Reader must not require write permissions in order to work. This betrays user expectations and is therefore wrong. Just because you have documented facility to override the default (incorrect) behaviour does not make this acceptable.. You must think I'm absolutely stupid; I'm not waiting for you to release a new version, we'd already pushed a \"fix\" by overriding the default before this ticket was ever created. This ticket was created solely as a gift to you and your project, to show you a flaw that you could fix to improve the library's quality, as recompense for your efforts putting it together. But you refuse to see any flaws, instead pretending that documented workarounds - not that they are even presented as such - somehow justify incorrect behaviour. You will be the death of your own project with an attitude like this.. Please stop tagging me in this issue. @nyamsprod has demonstrated repeatedly that he does not understand this issue by iterating nonsense like this:\n\njust because people don't want to read the documentation\n\nFurthermore, he thinks version numbers are an endangered resource in need of conservation and would refuse to release a fix even if one was made. There is no possible way forward with someone with such limited understanding, and for that reason, this issue is terminated effective immediately.\nI shall not be using this library again.. That issue does not match this one; it claims that either:\n\nThe wrong exception is thrown, or\nA fatal error is encountered.\n\nAs this ticket reports, neither actually happens: the Reader object is created successfully with no exception or error raised.. ",
    "amcsi": "But isn't it that always with a reader you would need to read the file only? The default seems unreasonable to me. It's led to bugs that were tricky to debug a few times.. ",
    "paulcanning": "I have read the Reader object documentation for v8.X and cannot see anything about validation in there.. No I don't have all the information.\n\nI have read the Reader object documentation for v8.X and cannot see anything about validation in there.\n\nI just want a simple validation of the file. There must be a simple yes or no validation method, right?. OK, so what methods should I look at for validation? Again, the documentation for the Reader object (8.X) is void of such topics.. @nyamsprod That doesn't answer my query.\nI can get the header, but I need to check it has certain (column) header values.. $reader = Reader::createFromPath($file, 'r');\n$reader->setHeaderOffset(0);\n$records = $reader->getRecords();\n$recordCount = $reader->count();. Sorry,\nPHP 7.2.5,\nmacOS 10.13.6 . How odd, I just tried again and my original code works :/. ",
    "btmash": "The tone in this issue is pretty...toxic to put it lightly. As a complete outsider to the project and a relative newbie to contributing to (non-Drupal) php projects, I want to say (and I really don't mean to come off as condescending/insulting and apologize if I do) :\n\nThank you @Bilge for creating the issue. Its something that bit me as well.\nThank you @nyamsprod for this project. As someone that maintains open source projects as well, I appreciate the work that goes into creating an maintaining a project in the long haul. It takes an immense amount of effort.\nThank you @frankdejonge for your words. Its easy to forget that we're dealing with real people who are taking the time to make something better and online back-and-forth can make it really easy to escalate a situation out of hand.\n\nI've added a pull request to override the static function and make a Reader class have a default 'r' open mode. Not sure if my approach is the best but am very open to making it a better out-of-the-box experience for this amazing library.. My problem was due to using atom which didn't typehint the default \ud83d\ude1e\nSince this has been tagged for the next major release...I guess something like this wouldn't go into master then but would it go into a separate branch or would you just keep the PR open (and we apply tags to it)? I guess I want to understand how implementing PRs for next major releases works for your project so I know how to best contribute to it.\nI'll take a look at the documentation and see what I can improve on it in the meanwhile.. Cool, thanks for the clarification. Should the docs for this be updated so it can say 'feature is available in master and upcoming 9.1.0 release'? Its not a long while away so its not a dealbreaker but figure might as well be accurate if possible.. Ah, ok. It makes sense \ud83d\ude04 Again, thanks for the clarification. Will close out the issue.. Since you'd mentioned this would potentially go in a 10.0 release (which is likely to be atleast a year away), I approached it with that in mind. Is there another way I should approach this PR?. ",
    "pboethig": "Hi,\nI ment, that I want to be able to add new columns to the csv row during reading.\nSomethng like that $reader->getHeader()->addColumns(['new column'=>'new column1']);\nKind regards\nPeter\n. ",
    "shameerc": "Shouldn't we also update this exception message as it now supports non seekable streams? :). Happy to make a PR, if it's not done already.. ",
    "Toilal": "I tried to give a SplFileObject to Writer::createFromStream() (instead of createFromFileObject).. Do you think this PR really adds value ? It seems to add complexity without adding much value. \nMaybe adding a note in docs to tell user about this trick is enough ? I'm using it in my project and it works like a charm.. I'll do, thanks :). ",
    "klaude": "That's a good call, @nyamsprod. It makes a lot more sense than a parameter bag. I'll come up with something and get you a PR. Thanks!. I agree. That's why it makes sense to leave injection handling to the user's discretion. I feel the library should provide it so users get an easier security option. \nThere are plenty of valid use cases for formulae in a CSV. I don't think execution is a bug in spreadsheet programs, but it's often overlooked as a source for injection, way more often than something like JavaScript or SQL injection. For instance, consider a user who signs up for a service with the first name =(2+2). \nIt's probably not the end of the world your work in #269 is bundled with the library or made a standalone package, but the article got me thinking. . That looks good to me. I think the only difference between this and what I was envisioning was a constructor argument to say which columns to escape, but this suits my purposes at work just fine.. ",
    "marksparrish": "no not my autoloader.  I think the packages.  Take a look at the functions_include.php file.  Not reference the is_nullable_int only bom_match.. ",
    "fcorbi": "Open writer with flags \"a+\" resolve the problem, but i think that this has to be more clear in the first page of docs. Thanks anyway. ",
    "Taluu": "Nevermind, didn't see all the createFrom... in the AbstractCsv class.. ",
    "ddinchev": "I prepared a repo with the minimum possible code to replicate the case:\nhttps://github.com/ddinchev/league-csv-bug\nAgainst my understanding of how these few lines should work, the record loop always goes through all the records, regardless of offset being set. I haven't tried to debug this at all - I'll try to make some time today and trace the problem.\n  . ",
    "JohnnyWalkerDesign": "The solution, for anyone else with the same problem, was this:\n    $allUsers = User::take(1)->get()->toArray();\n\n    $header = array_keys($allUsers[0]);\n\n    $csv = Writer::createFromString('');\n\n    $csv->insertOne($header);\n\n    User::chunk(10000, function($users) use ($csv) {\n\n        $csv->insertAll($users->toArray());\n\n    });\n\n    $csv->output('users_'.date(\"Y-m-d\").'.csv');.\n",
    "ryanmortier": "I removed the count but still had issues. Then I completely bypassed league/csv and just did a while (($row = fgetcsv($handle)) !== FALSE) { but I still encountered memory issues so I give up. I'll just up the memory limit.. ",
    "gyaan": "it would be great if you specify which specific section to check.. ",
    "lookyman": "Ok, I fixed the issues. I can squash the commits if you want... Hmm maybe it should just be mixed[] then?. Will do.. I don't think that is possible to express in the typehint though... Right, I got ya.. ",
    "Jalle19": "I guess I'll be fixing the other createFrom methods too then. I have a hard time coming up with a scenario where this would break anything, if I do I can mention it here.. @nyamsprod I removed all the relevant static return type-hints. Thanks!. The return type-hint here is wrong. You're returning new static so the return type should be Reader. While upgrading from 9.0.1 to 9.1.2 I started getting errors like these from Phan:\napp/Legacy/Console/Commands/AbstractCsvImportCommand.php:77 PhanUndeclaredMethod Call to undeclared method \\League\\Csv\\AbstractCsv::setHeaderOffset. ",
    "strarsis": "@nyamsprod: Yes, the CSV is technically invalid. \nBut it would be nice if the parser could be made somehow more tolerant.. ",
    "judgej": "I guess it is the ability to add an output filter that I'm looking for...? Not even a filter - an output renderer. Even just being able to switch fputcsv() to implode() would be great, with custom filters handling all the enclosing and escaping. It's that very last fputcsv() that puts the spanner in the works here.. Doesn't a stream, filter literally filter the unstructured stream? At that stage, it's too late to be able to manipulate and format individual fields. Or am I misunderstanding what the stream filters do?. Okay, I've run out of time on this one, so I'll knock up some custom code for my use-case instead. Thanks for your help.. Digging into the code further, I realised the PHP function fputcsv() is only called for streams, and not the SPL file object. The SPL file object has its own fputcsv() method, and that is very easy to override:\n```php\n<?php\nnamespace My\\Namespace;\nuse SplTempFileObject;\nclass MySplTempFileObject extends SplTempFileObject\n{\n    public function fputcsv($fields, $delimiter = null, $enclosure = null, $escape = null)\n    {\n        // Very naive CSV format, no enclosing and no escaping\n        return $this->fwrite(implode($delimiter, $fields) . \"\\n\");\n        //return parent::fputcsv($fields, $delimiter, $enclosure, $escape);\n    }\n}\n```\nI need to work out where fputcsv() is getting its line break characters from, then I have full control of how every field is escaped and enclosed. By passing in field names as the keys to insertOne(), those keys can be used to identify the fields that need special treatment.. Thanks - the PHP docs implied this, but did not make that point explicit.. ",
    "jagDanJu": "@nyamsprod I am not completely sure that the file is correctly UTF-8 encoded. The file ist from an external source.. \nAnyway, your function works pretty well.. Thanks Guy!. ",
    "purplekrayons": "Sorry, I have a very hard time navigating your documentation.\nAre you able to advise which section of your documentation this applies to?\nAlso, I've been at this for 45 minutes now. Can you please put a search function in your documentation?\n```\nGETTING STARTED\nOverview\nInstallation\nCONNECTIONS SETTINGS\nOverview\nDocument Loading\nCharacters Controls\nBOM Sequences\nStream Filters\nDocument output\nINSERTING RECORDS\nWriter Connection\nBundled Helpers\nSELECTING RECORDS\nReader Connection\nConstraint Builder\nResult Set\nINTEROPERABILITY\nOverview\nDocument Encoding\nRFC4180 Field\nForce Enclosure\nFormula Injection\nCONVERTING RECORDS\nOverview\nCharset Converter\nXML Converter\nHTML Converter\n```. Cheers. Thanks mate.. Upon further reading, I don't see how this can be used to clean up the headers. As per your documentation:\n\nThis method processes a Reader object and returns the found records as a ResultSet object.\n\nand\n\nThe League\\Csv\\Statement class is a constraint builder to help ease selecting records\n\nI'm not looking to filter or sort anything, im looking to remove whitespace from the headers.\nInspecting the Statement class, there's nothing in here that seems workable. Every single record will already contain the bad headers (headers with whitespaces) by this point. I don't want to return some subset of records, I need all records, but with cleaned up the headers before the reader object is returned.\nManually mapping headers is not a workable solution in my case. This is only one example of a CSV. I have others with 100+ columns of data, which is simply too messy to map manually.\nI can accomplish what i'm after by adding: $header = array_filter(array_map('trim', $header)); to the computeHeader() function.\nIE:\n```php\nprotected function computeHeader(array $header)\n{\n    if (empty($header)) {\n        $header = $this->getHeader();\n    }\n$header = array_filter(array_map('trim', $header));\n\nif ($header === array_unique(array_filter($header, 'is_string'))) {\n    return $header;\n}\n\nthrow new Exception('The header record must be empty or a flat array with unique string values');\n\n}\n```\nThe result:\njson\n{\n  \"store_grp_cd\": \"BCF\",\n  \"itm_cd\": \"JCK3000BB\",\n  \"action_cd\": \"D\",\n  \"reg_prc\": \"1529.97\",\n  \"promo_prc\": \"1232\",\n  \"prc_cd\": \"O9E\",\n  \"prc_eff_dt\": \"04-MAY-18\",\n  \"prc_end_dt\": \"18-MAY-18\",\n  \"srt_cd\": \"BW1\"\n}\nBut I don't want to have to hack up your library to do it.\nAny other ideas?\nI'm continuing to work on this -- it looks like your library doesn't do any kind of whitespace cleaning at all. I just noticed I've also got values with whitespace. The CSV's i have to work with are poorly formatted unfortunately.\nThe foreach results only affect the values themselves:\n```\n$csv = Reader::createFromPath($filepath);\n$csv->setHeaderOffset(0);\n$out = [];\nwith each csv line\nforeach ($csv as $record) {\n    $out[] = array_filter(array_map('trim', $record));\n}\necho json_encode($out);\nreturn;\n```. Thanks for the help :). ",
    "Spartacus2018": "to resolve us this code : \nu have o add : \n$csv->setDelimiter(';');\n```\n<?php\n//Chargement librairie flystem (gestion des fichiers en php)\nrequire '/var/www/html/Projet_28_ScriptFnmfv2/vendor/autoload.php';\nuse League\\Csv\\Reader;\nuse League\\Csv\\Statement;\n$csv = Reader::createFromPath('Fichier_A.csv', 'r');\n$csv->setHeaderOffset(0);\n$csv->setDelimiter(';');\nforeach ($csv as $record) {\nvar_dump($record);\n}\n```. ",
    "hillelcoren": "This is the code I'm using:\n$csv = Reader::createFromPath($fileName, 'r');\n$stmt = new Statement();\n$data = iterator_to_array($stmt->process($csv));`\n\nHere's a sample file sample.csv.zip (GitHub wouldn't allow .csv so I needed to zip it). It opens correctly in LibreOffice but the library sees it as a single line.\n. Is there a line ending option? \nThanks for your help btw. . Sorry for answering your question with a question :)\nI assume you mean in the PHP code? I'm not setting anything other than the code posted. The delimiter (a comma) seems to be working correctly. \nThanks again! . Perfect, thanks! That fixed it :). ",
    "inquisitive-stha": "Yeah, it was working fine on other small file. Was it because of delimiter issue? I get stucked here.. Ok, let me explain it in detail.\n1) It is successfully uploading the file. However, it takes quite a lot of time to upload the file, so I am checking it by directly passing the uploaded file path.\n2) Why I am thinking it is delimiter issue. Below is the code snippet:\nif (($handle = fopen($path, \"r\")) !== FALSE) {\n            while (($data = fgetcsv($handle, 1000, \",\")) !== FALSE) {\n                $num = count($data);\n                print_r($data);\n                exit();\n            }\n            fclose($handle);\n        }\nhttp://php.net/manual/en/function.fgetcsv.php <- URL from where I copy code snippet.\nWhile trying it with above code. It get exhausted as usual. But if I replace that comma delimiter \",\" with \"\\r\". Now, it shows data as:\n[0] => name,address,xx,xxx,xxx,xxx,xxx\n    [1] => shrestha, saroj, new road,xx,xx,xxx,xxx,xxx\n    [2] => 544770,47,Park,WILLIAMS,WILLIAM,J,,\"WILLIAMS, WILL\nAlso, if I tried with \\n it shows data but all in 0 index. Now, let me know what might be the issue.\nNote, There is also (comma) , in data itself. Example: Single name column has last_name, first_name\nBut, I also tired with setting \n$csv->setDelimiter(\"\\r\");\n$delimiter = $csv->getDelimiter();\necho $delimiter;\necho \"==\";\nexit();\nBut, it does not show \"\\r\" neither it push === to next line. Now, what do you think what might be the issue. If you are there, I am ready to get help with screen sharing too.\n\n. Yeah, it take some extra minutes on server but on localhost it uploads quite faster. But, am 200% sure on uploading. As only after uploading, it redirects to another controller and then this process get started there. Also, to make you more confident about this, I just tried by copying the original file directly to the location. And tried with that, but same error. :( . Is that \n$csv = Reader::createFromFileObject(new \\SplFileObject($path));\nShowing same error but at different function\n```\n protected function seekRow(int $offset)\n    {\n        $this->document->setFlags(SplFileObject::READ_CSV | SplFileObject::READ_AHEAD | SplFileObject::SKIP_EMPTY);\n        $this->document->setCsvControl($this->delimiter, $this->enclosure, $this->escape);\n        $this->document->rewind();\n    //Workaround for SplFileObject::seek bug in PHP7.2+ see https://bugs.php.net/bug.php?id=75917\n    if (PHP_VERSION_ID >= 70200 && !$this->document instanceof Stream) {\n        while ($offset !== $this->document->key() && $this->document->valid()) {\n            $this->document->next();\n        }\n\n        return $this->document->current();\n    }\n\nSo, what should I do, How to check which delimiter is set at the time.\n. Ok, now I have tried with some small file size. On those records, it displays both header and fetchOne row but not in case of big file. \nCould you try with this file https://drive.google.com/open?id=19nIZxrxzxETKOttKE1LDO_BlAUJlqWql this is where I am facing problem. And let me know what should I do.. @nyamsprod Did you check with the file I have provided? Does it run on yours or get exhausted?. @nyamsprod could you please check with that, I feel that it is the issue related to file.\n. @nyamsprod I am not saying anything bad to you and your library, I really appreciate you guys's hard work. I also, tried with other file with more rows. They work fine. But not with this file. I really appreciate your time and effort on helping me. If you can't help me I don't think any other could help me, that's the only reason I am bothering to you. Sorry, for bothering you a lot. But, could you show me a way how can I get rid from this :(. @nyamsprod Ok I figured out why this is not working. Whenever I tried directly with php functions fopen with ,(comma) delimiter and unlimited length it keeps on getting exhausted but after adding auto_detect_line_endings to deal with Mac line endings I am able to deal with that.\nini_set('auto_detect_line_endings',TRUE);  //ADDEDD LINE\n$handle = fopen('/path/to/file','r');\nwhile ( ($data = fgetcsv($handle) ) !== FALSE ) {\n//process\n}\nini_set('auto_detect_line_endings',FALSE);\n```\nSo, in case of phpleague how can I do this. Is there something I am missing.. @nyamsprod Thank you for your time and effort :). ",
    "augz": "Just a side note here, I tinkered with the parent package's composer.json to allow the latest install of this library, the bug is still present.. @nyamsprod Well this is kind of embarrassing, I'm using another package that is referencing your project, I have a preview of the code block below. The gist of it is that some items coming back from Amazon API (which is in a CSV) contain an em dash but is supposed to be UTF-8. So this returns no errors but just an empty string when an offending character is met. I am not too familiar with your package yet.\nI tried $csv->setInputEncoding(\"UTF-8\"); but it still returns an empty string when an em dash is present.\n/**\n * Get a report's content\n * @param string $ReportId\n * @return array on succes\n */\npublic function GetReport($ReportId)\n{\n    $status = $this->GetReportRequestStatus($ReportId);\n    if ($status !== false && $status['ReportProcessingStatus'] === '_DONE_NO_DATA_') {\n        return [];\n    } else if ($status !== false && $status['ReportProcessingStatus'] === '_DONE_') {\n\n        $result = $this->request('GetReport', [\n            'ReportId' => $status['GeneratedReportId']\n        ]);\n        if (is_string($result)) {\n            $csv = Reader::createFromString($result);\n            $csv->setDelimiter(\"\\t\");\n            $headers = $csv->fetchOne();\n            $result = [];\n            foreach ($csv->setOffset(1)->fetchAll() as $row) {\n                $result[] = array_combine($headers, $row);\n            }\n        }\n\n        return $result;\n\n    } else {\n        return false;\n    }\n}\n\nhttps://github.com/meertensm/amazon-mws/blob/master/src/MWSClient.php#L1088. Without being able to predict the input string, is there a way to tell the reader from the start to force encoding to UTF-8?. Go ahead and close this issue, I reported this bug to that library first and cross referenced this issue just in case there was something missed. I added my own recursive function to fix encoding for now:\npublic static function parseEncoding($arr)\n{\n    $result = [];\n    foreach($arr as $key => $item)\n    {\n        $result[$key] = (is_array($item))\n            ? self::parseEncoding($item)\n            : mb_convert_encoding($item, \"UTF-8\");\n    }\n    return $result;\n}. ",
    "LogIN-": "I just now realized that this $header is not used for \"filtering\" ..... ",
    "otzy": "sorry, my fault. I copied install command from this site https://csv.thephpleague.com/9.0/installation/ and did not check that there are already newer versions released. ",
    "rktyt": "@nyamsprod thanks.\nI understood that well.. ",
    "jcrawford": "Thanks that did the trick, I couldn't find anything about that in the docs, didn't think about checking the README.. ",
    "deepexcel": "It worked with \n```\n$csv = Reader::createFromString( $s3->read($filePath ), 'r');\n```. ",
    "tom-d-77": "@nyamsprod We put an empty space at the end of strings with a doubled backslash. This solved the issue for us for now - as far as we could verify it. We have huge CSV files with many combinations of escaping chars in it. We already assumed that the fputcsv is the \"real\" problem. I think to deprecate the RFC4180Field is okay, so people who are using it know that there is an issue with it.. @nyamsprod : Sounds like a question of taste. I also would go with the secound solution, because it is less code. In my opinion there should not be to much parameters in methods - but with 2 parameters it is not to much.\nBut i only have seen the writing part of the library, if in general the first solution is already implemented more often, i would stay with that one.\nHope this helps a little to get a decision.. @nyamsprod I think you are right - the developer should know which \"writer mode\" is used. One more thought about it: If the second parameter has a default value, developers tend to use the default value (this is also true for me). So it may be a good decision, to set no default value to it, and throw a self explaning Error if it is not set.. @nyamsprod It was just a additional thought from me - i think your solution is valid in terms of a coding view. . ",
    "neradp": "Sorry ..i need that functionality for reader.. not writer... I do.. thanks.... ",
    "nickma42": "Understood - thanks for the quick reply and the great explanation :). ",
    "komarnicki": "Is it because Reader extends AbstractCsv which is abstract therefore it cannot be instantiated by Laravel?. ",
    "nickescobedo": "@nyamsprod is there a way to inject this in a parameter with a blank object without having to use the create from?. ",
    "frankeg": "@nyamsprod weird I swear I saw no leading zeros in a text editor.\nnow they're their\nthanks. ",
    "mgralikowski": "Yes, i could not use filters ($reader->supportsStreamFilter() - false) so what is the best option to pass file to Your library and use filters as well? Converting uploaded file to a string and assigning to variable (I use Laravel)?. $reader = Reader::createFromPath($request->file('file')->getRealPath());\n$reader = Reader::createFromStream(fopen($request->file('file')->getRealPath(), 'r+'));\nBoth solutions loading properly file. Is any preferred (faster or sth)? \n. ```php\n$reader = Reader::createFromPath($request->file('file')->getRealPath());\n$delimiters = delimiter_detect($reader, [\"\\t\", \",\", \";\"]);\n$reader->setDelimiter(array_keys($delimiters, max($delimiters))[0]);\nif ($reader->getInputBOM() === Reader::BOM_UTF16_LE)\n    CharsetConverter::addTo($reader, 'UTF-16LE', 'UTF-8');\nif ($reader->getInputBOM() === Reader::BOM_UTF16_BE)\n    CharsetConverter::addTo($reader, 'UTF-16BE', 'UTF-8');\n// detect win-1250 (ms excel)\n$records = $reader->getRecords();\nforeach ($records as $record) {\n    dd($record);\n}\n```\nThis is my final code. I am going to make totally universal loader. I have problem with detecting MS Excel file (windows-1250). Any methods in Your library can help me or need I do it manually ? \n. I counted on little help with above but you are right - primary reason is answered. . ",
    "roberto-aguilar": "Thanks for the quick response, @nyamsprod!\nMy current approach is to use this kind of middleware between the reader and my insertions, so yeah, i agree with you in this point.\nI didn't know about the missing field vs empty field problem, can you help me understand it a little bit more? how a record with a missing field looks like in a csv? If they are already returning null i can work with that too.. Thanks for the link, now i understand \ud83d\ude04 \nIf this can be a BC and we both agree on the workaround, i can go live with the current behavior.\nThanks for taking the time, @nyamsprod \ud83e\udd18 \n. ",
    "tomkyle": "Thank you for your fast reply! I see your point with object state which ideally should not be exposed. But the same goes with getDelimiter and getEnclosure which both are public, and nobody would doubt their usefulness. Please let me propose another public method getPathname to team up with the first two. Here's why (and how):\nAbstractCsv's ctor argument $document is either SplFileObject or Stream, and anything other than SplFileObject is internally converted to a Stream instance which mimicks the SplFileObject's CSV-related behaviour and internally works with resource types.\nThe Stream class internally uses PHP's stream_get_meta_data function for checking if the resource in question \u201cis_seekable\u201d. The return array of this function also contains an 'uri' element as well \u2013 which perfectly exposes the URI/filename associated with this stream, e.g. php://temp or /path/to/myfile.csv. \nSo my proposal is to introduce a public getPathname method in AbstractCsv. It is part of the SplFileObject API already, and for Stream class, it can be easily implemented using the uri key from stream_get_meta_data:\nphp\n// class Stream:\npublic function getPathname() : string\n{\n    $stream_meta = stream_get_meta_data( $this->stream );\n    return $stream_meta['uri']; \n}\nNow both SplFileInfo and Stream class have the getPathname method in common. Implementation now is easy:\nphp\n//  class AbstractCSV:\npublic function getPathname() : string\n{\n    return this->document->getPathname();\n}\nThis way, no document object and no internal state would be exposed. \n. @nyamsprod Challenge accepted \u2013 well, nearly\u2026 I'm not sure about the PHP source code. Was it C? ;-) Please give me a few days, as I'm still contributing too seldom and certainly have to setup a proper testing.. Thx for your ideas, that's half of the testing. After sleeping one night, I'm afraid we could get intro trouble: Consider a user creating a Stream instance via createFromString from two different strings \u2013 IMHO their stream URIs will both be php://temp \u2026 uniqueness? we'll see.. Yep, that's possible :). It was a pleasure :-). ",
    "Zyles": "Well I don't know, it just keeps timing out. Not sure how to debug it any further.\nI went with the statement solution instead which works for me.. ",
    "petarvasilev91": "@nyamsprod I tried using UTF-8 but it broke my code.... ",
    "chalasr": "PHPCSFixer failure fixed, this should be ready.. ",
    "HaozhouChen": "If $position is equal to 0, then it won't enter the loop, so $offset-- after $this->offset is -1.\n. $this->rewind() result return $this->offset = 0, so $this->key() === $position,so won't enter the loop.\ud83d\ude1d. Yes, this problem has no impact on the use of the basic, but if the user use key() may cause a little ambiguity, so, I submitted a PR , \ud83d\ude1d. ",
    "tebaly": "Link works. But where is it written about? I have not found any references or descriptions.\n//by setting the header offset we index all records\n//with the header record and remove it from the iteration\nThere is not written about the indexes. After all, you can remove headers and rewrite indexes starting from 0, But you do not do it\nThe problem is different\nIt is expected that you did not change the indexes again. But you do it\n$csv = Reader::createFromPath($filePath, 'r');\n        $csv->setHeaderOffset(0); // REMOVE HEADERS, Index [0]\n        $record = $csv->fetchOne(1); // Fetch FIRST record, expected\nAfter setHeaderOffset(0) expected same index behavior. \nI thought.. ",
    "vlakoff": "since version 4.1? should be 8.x.x (to be released)\n. same here\n. I thought of some typo / old PR. Okay then, I trust you :)\n. "
}