{
    "seanmonstar": "ssl support for the client exists, still lacking server support\n. @cactorium I'd be delighted if this showed up as a PR :D\nSome notes: I'd imagine adding a pub fn https(ip: IpAddr, port: Port, cert: Path, key: Path) or something similar. The paths to the cert and key can be Options on the Server. The HttpListener would probably need to become an enum similar to HttpStream, and the Https variant accepting those Paths.\n. @veeti see http://hyperium.github.io/hyper/hyper/client/struct.Client.html#method.set_ssl_verifier\n. @veeti you can set a verifier function on Client. I guess a default could be similar to Python or nodejs. \n. Looking through the spec, it does seem like its an optional thing, as opposed to chunked which the spec says a server MUST understand chunked to 1.1 compatibile.\n. A header of \"Accept-Encoding: identity\" means the user agent is\nspecifically requesting no compression. Does that help your case?\nOn Sat, Jan 23, 2016, 11:22 AM Markus Unterwaditzer \nnotifications@github.com wrote:\n\nSee also\nhttps://stackoverflow.com/questions/8364640/how-to-properly-handle-a-gzipped-page-when-using-curl\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/2#issuecomment-174213929.\n. I'm not so certain that this is a decision that hyper should default to. As you noticed in 7231, sending no header is valid, and implies no preference. If a user of hyper hasn't stated otherwise, I don't think we can assume a preference.\n\nA higher level Client wrapper would probably be the place to be more opinionated, methinks.\n. Again, does asking for identity fix the issue? \n. @Trolldemorted not in hyper. Such a feature does exist in reqwest, though!. Should it be the case that the http server just spews out new tasks for all incoming requests?\nWhat if the Handler trait received an 'incoming\u2019 function, with a default implementation to stay single tasked? \nFrom: Jonathan Reem\nSent: \u200eSaturday\u200e, \u200eSeptember\u200e \u200e06\u200e, \u200e2014 \u200e11\u200e:\u200e58\u200e \u200eAM\nTo: seanmonstar/hyper\nIt appears to me that parallel connections block on handler.handle here https://github.com/seanmonstar/hyper/blob/master/src/server/mod.rs#L55.\nThis seems weird to me. I would much rather Handler: Clone, and for Handler to simply be copied for each request. That way, downstream users of this library have maximum control of what concurrency forms they want.\n\u2014\nReply to this email directly or view it on GitHub.\n. As alluded to in the code comments, I'd love to come up with a solution that tracks this statically. Such that once headers have been written, the status code and headers are no longer mutable, and the compiler will error if tried to mutate.\nI've considering something like:\n``` rust\nstruct Request {\n  pub headers: Headers,\n  pub status: StatusCode,\n}\nstruct InFlightRequest {\n  headers: HeadersView, // can look at headers, but no set/remove methods.\n  // something similar with status. or maybe it just becomes a getter function\n}\n// ..\nfn handle(req: Request, res: Response) {\n  req.headers.set(Foo);\n  let body = req.start();\n  body.headers.set(Bar); // No method set\n}\n``\n. Hm, oh right! The hyper server uses those headers internally to meet the spec, and if someone wants a completely different struct of handle TransferEncoding or something, then theTypedreturn value would be wrong (I think currently that would be a downcast to the wrong type), and there'd be no moreRaw` to rebuild a different format.\nI'm starting to think that design in teepee (keeping raw around even after parsing) makes more sense... I just was hoping to save on memory.\n. What convenience methods do you mean?\nAlso, I'd forgotten to update the benchmarks since adding the use of BufferedWriter and BufferedReader, which dropped hyper's ns/iter to ~170000. I'll update the readme.\n. Hrm, I did reach that number a few days ago, but current benchmarks are back around ~230k...\n. Still, what is meant by \"client ergonomics\" in this issue?\n. My thoughts are that the http\ue1ealibrary should provide the basic blocks,\nhaving an efficient api using Writers. Then, I considered the main module\nto have a nice request builder interface, for doing simple requests. But\nthe building blocks are still there for people to extend on.\nOn Sep 10, 2014 11:28 AM, \"Jonathan Reem\" notifications@github.com wrote:\n\nI personally prefer the method chaining API offered by curl, considering\nthat most requests are made and sent all at once and not modified by a\nlarge number of different functions like a server request.\nI have a rough sketch of this API in one of my branches, I'll probably\nmake a PR later today.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/seanmonstar/hyper/issues/11#issuecomment-55160105.\n. I've considered possibly having a RequestBuilder pattern for the client, exposed from hyper::request()... but it also seems like something a higher level library could do. With the raw Request/Response blocks exposed, different APIs can be built, regardless.\n. Hrm, you're right, that should be a dangling pointer... does it manage to work because HashMap stores the hash u64, instead of the actual &str, and so when checking later, it looks up by u64?\n. Looks great. Just the one question.\n. I'm thinking keying with SendStr would be best. Keeping the header_name fn\nreturning static slices is ergonomic, and internally it can be wrapped into\na Slice. No need to allocate those strings for every single request. And no\nuser has to touch that HashMap, as it's Internal.\n. I think having it be unsafe is best. While technically, everything inside the function is \"safe\" as far as rustc knows, it has the potential to mess with the typed representations. Plus, I'm of the opinion that most use cases should use the typed interface instead, so the unsafe may scare people off?\n. Yea, both of those problems crop up. Is there some other way to do this?\n. So, make everyone deal with the generics?\n\nIt's probably worth comparing benches... the only other way would be to accept a Box<Reader> and Box<Writer> in the constructors, right? I have not looked into DST at all, but that recently landed, and allows having Trait objects without indirection...\n. Yea, I've wondered at the noise level on those benchmarks. I've been attributing it to the variable time taken for the system tcp sockets to connect/read/write.\nIt'd be neat if there were a way to mock out the underlying tcp bits for all of them. I know its possible we hyper and http, but not sure about curl.\n. I thought it was RequestWriter<Connecter>, so I could use a connecter that just connects some MemStream...\n. So, adjusting the curl benchmark to use a URL of file:///home/sean/something.txt brought the noise down to +-808ns, a whole lot better than ~100k of the others. I'm not sure how equivalent curls file protocol handler is to its tcp one...\n. With curl going to a file, and http/hyper still using tcp:\nrunning 3 tests\ntest bench_curl  ... bench:    108608 ns/iter (+/- 808)\ntest bench_http  ... bench:    315872 ns/iter (+/- 96407)\ntest bench_hyper ... bench:    246374 ns/iter (+/- 99827)\n. Ok, I've merged together a local branch that has curl using file://, http using a MockConnecter, and hyper using a MockStream thanks to #17. This is what I get from the benchmarks now.\nrunning 3 tests\ntest bench_curl  ... bench:     86316 ns/iter (+/- 1743)\ntest bench_http  ... bench:     85946 ns/iter (+/- 655)\ntest bench_hyper ... bench:     40991 ns/iter (+/- 1180)\n. Yea, the numbers are just about the same after 4 runs...\n. I really quite like this idea. I want the compiler to catch when you try to set a header after writing. Dynamic is slower, and has errors show up in actual programs instead.\nIf I merge this and #17, then Response's will be generic over 2 things, right? Does this feel painful as a framework dev?\n. rebase?\n. I'll have to review the code in the morning, but what is gained? Why have a server listen to many ports, instead of just using multiple Server objects?\n. Okay, make sense. Besides the errors comment above, this would need a rebase to use the generic NetworkStream stuff.\n. cargo test already builds the docs and runs the doc tests.\nAlso, having the benchmarks run on travis would mean I couldn't merge in #22...\n. When you run cargo test, you don't see the \"Doc tests\" section after the unit tests?\n. Retrying Travis...\n. I haven't tried wrk, but apache bench worked for me...\n. Ah, woops, nice catch.\n. cool, needs a rebase\n. manually merged\n. Doh, I wasn't checking my email while I wrote it.\n. That makes sense. Seems \"hyper\" is already a user...\nHave you started a branch of iron using hyper?\n. I didn't love any of the hyphenated names, and snagged @hyperium...\n. I don't follow. The raw data is kept to parse a new header if the type is\ndifferent.\n. Oh I see. So, you think we should stick with the enum, and return None if\nthe typeids don't match?\nOn Sep 14, 2014 11:07 PM, \"Jonathan Reem\" notifications@github.com wrote:\n\nI can set the value of a header's typed representation, then parse it\nunder a new representation and I won't get the updated value.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/seanmonstar/hyper/pull/36#issuecomment-55555367.\n. In that case, it's possible that a previous representation dropped some\ndata...\nOn Sep 14, 2014 11:23 PM, \"Jonathan Reem\" notifications@github.com wrote:\nI've got a branch somewhere with most of a representation that just\nconverts to the raw representation if you ask it for a different type. I'll\nprobably PR later tonight or tomorrow.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/seanmonstar/hyper/pull/36#issuecomment-55556064.\n. Yea, I have a branch ready with the library changes, but need to find support being an ssl server. It doesn't seem like rust-openssl exports the needed parts to bind over https. I filed an issue there.\n. The broken test is one I had just added to make sure it was possible to use different Header impls for the same field. This PR specifically forbids that. \n. Another crappy downside: if a library or middleware uses a private! Header implementation, then there's no way to get to the data.\n\nThe code in master currently handles this. The data would be lost if a library did headers.set(SomePriv), since it sets raw to an empty vec... I'd think the solution in this case is to not give the library a mutable reference to headers. \nOn the other hand, not allowing a second Header representation at first seems like moving to a looser model is backwards-compat, where as the inverse isn't true.\n. Well, anyways, as I said, this means we can later add in support for multiple header accesses backwards compatibly, so I'm inclided to merge.\nOnly other concern is rely on a bunch of small crates. As they're yours, I'm confident they will be updated frequently as rustc changes. Though, looking at rust-typeable, it seems that get_type could be #[inline(always)]ed, to keep it fast.\n. As the docs for variants point out, a target server should only need the\nAbsolutePath. The others are used mostly by proxies.\nhttp://seanmonstar.github.io/hyper/hyper/uri/type.RequestUri.html\nOn Sep 17, 2014 12:19 AM, \"Jonathan Reem\" notifications@github.com wrote:\n\nI've found the current version unergonomic to work with in downstream\nlibraries without just ignoring certain variants. Not sure right now what's\nbetter, but I'll think about it.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/seanmonstar/hyper/issues/39.\n. Though, we could add some convenience methods to get to the path.\n\nAlso, I've been thing that it might be cool to have a stronger typed value\nthan just a String in there...\nOn Sep 17, 2014 2:53 PM, \"Jonathan Reem\" notifications@github.com wrote:\n\nThat's what we do in Iron. I guess that's really the best we can do.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/seanmonstar/hyper/issues/39#issuecomment-55966143.\n. Yea I wanted to use a Path from rust-url, but there isn't one yet. I tried\nasking for one in https://github.com/servo/rust-url/issues/14, but since I\ncould only offer hypotheticals, it was closed. Maybe you could give\nconcrete needs for Iron.\n. I guess I missed that. I'd need to look into it. It looks like it validates that the value is a proper path, but otherwise returns a String.\n\nWould it be doing too much if hyper transformed a Path + Query into something, or perhaps having a Decodable fn for getting a query? Perhaps that's better left to library land.\n. server side is done\n. @winding-lines this would be useful (ignore the httpbin part, I mean adding unit tests) . You could look at the coveralls report to see where some test cases are missing... \n. what do you think of this going in lib.rs instead? A brief description in the README to convince someone it's worth their time to check the doc pages, and then the rest can be part of the docs. This way, any code fences stay up-to-date, since cargo test runs doctests.\n. @reem awesome. thanks so much for this. wanna fix that stray quote and merge?\n. Oh right, because it needs to be mutable internally. Maybe Headers could\nkeep a RefCell of the HashMap. It's mutability is just an implementation\ndetail, and shouldn't concern users.\nThat would also improve fighting the borrowck in matches.\n. I can review in a couple hours, though, what's the reason from moving to\n*const instead of &?\n. Based on your last comment, you sound unsure about merging this.\nI'll continue to think about how a safe interface can be exposed. I find runtime errors to be the devil, so I'm quite against them. That's why I use Rust in the first place.\n. Alright, sweet. r+ from me, but of course, the case insensitive stuff I merged in made this need a rebase.\n. Additionally, while for most use-cases, the Typed API should be preferred, Servo has a legitimate reason for accessing all the Raw headers: providing the JS methods xhr.getResponseHeader() and family. In JavaScript, you can pass any string, and Servo cannot possibly know ahead of time (and so use compiled in types) which strings may be used. Also, the result passed to JS must a be a String. So, in those bindings, accessing raw headers (and many of them, thanks to xhr.getAllResponseHeaders()).\n\nThose restraints mean that we cannot do what is currently done: we must keep the raw bytes around even if accessed as a Typed value.\nThe steps I think we need are: \n1. We go back to struct Item { raw: Vec<Vec<u8>>, typed: Box<Header> }. We provided headers.get_raw(key: &str) -> Option<&[Vec<u8>]. mut isn't needed, since it doesn't require any transforming to get the raw bytes.\n2. The get(&mut self) still takes mut, and the compiler prevents a mutable borrow while there exists immutable borrows.\n3. Request<W>.headers() returns a &mut HeadersView that only provides get, get_ref, and has methods.\n4. Request<Fresh>.headers_mut() returns a &mut Headers, as it does normally.\nAlternatives: instead of a &mut HeadersView, we could use a phantom type like with Request, such as &mut Headers<Fresh> and &mut Headers<Frozen>.\n. Any reason to receive a SendStr as an argument instead of a &str?\n. Sorry about the late response, work gets in the way some days.\nI'd like to take a second to map out exact objectives, so the end goal is clearer. I'll probably update the initial comment with the points.\n. Here's a crazy idea. What if we didn't store the typed version after\nparsing? How often does someone get the same header multiple times, thus\npaying the cost more than once?\nInstead, by not storing the typed value, we don't need a mutable borrow to\nparse. You can safely access get_raw, since the only way to change it is\nwith set(), and that takes a mutable borrow.\nGetting a different type for the same header would still have required a\nnew parse, so that's no different, except it wouldn't invalidate any\nreferences.\n. Yea, cloning would be faster than reparsing. Still, I can't imagine needing\nto get a header more than once in most cases. So by optimizing the small\ncase, we make it more painful by requiring a mutable borrow.\nAnyway, I'm trying it in a branch and we can see benchmarks.\n. This is mostly dealt with. Specific pain points can become new issues, if needed.\n. Considering that reads and writes for Requests require the programmer to explicitly write(msg) or read(buf), what is the actionable item here?\n. After an irc chat with @mcmanus, it seems the things that can be reasonably done:\n1. For Http 1.x, prioritization has to be done in the client layer. If a new request comes up with a higher priority, some Rust code that's writing to other sockets need to be able to write(msg) less.\n2. Http 2 introduces priorities as part of the protocol, such that the server will handle and respond to requests with a higher priority first.\n. This can be implemented in a Handler.\n. Which pieces are desired?\n- DNS time?\n- Connect time\n- Write time\n- Read time\n. For reference:\ninterface PerformanceTiming {\n  readonly attribute unsigned long long navigationStart;\n  readonly attribute unsigned long long unloadEventStart;\n  readonly attribute unsigned long long unloadEventEnd;\n  readonly attribute unsigned long long redirectStart;\n  readonly attribute unsigned long long redirectEnd;\n  readonly attribute unsigned long long fetchStart;\n  readonly attribute unsigned long long domainLookupStart;\n  readonly attribute unsigned long long domainLookupEnd;\n  readonly attribute unsigned long long connectStart;\n  readonly attribute unsigned long long connectEnd;\n  readonly attribute unsigned long long secureConnectionStart;\n  readonly attribute unsigned long long requestStart;\n  readonly attribute unsigned long long responseStart;\n  readonly attribute unsigned long long responseEnd;\n  readonly attribute unsigned long long domLoading;\n  readonly attribute unsigned long long domInteractive;\n  readonly attribute unsigned long long domContentLoadedEventStart;\n  readonly attribute unsigned long long domContentLoadedEventEnd;\n  readonly attribute unsigned long long domComplete;\n  readonly attribute unsigned long long loadEventStart;\n  readonly attribute unsigned long long loadEventEnd;\n};\n. I imagine checking the clock several times when you don't want it would cause slow down. I'm thinking these could be events that can receive closures to echoed anything. By default, there's no closure. So you only pay for what you use. \n. Oh, that's not much time. I thought at some point someone told me that getting the date for the date header was showing up in profiles. \n. Oh right, NetworkStream needs an unwrap method as well.\n. Yea I know, this time I forgot to include it in the commit message.\n. @reem I turned Response.unwrap() into an unsafe message, and downcast out of the box into the declared type. So you can now completely unwrap the response and get the underlying stream back.\n. @reem indeed, once I finally figured out how to get downcasting to work, I've done that.\nNow, res.unwrap() returns a Box<NetworkStream>. This will be useful for implementing KeepAlive, as the boxed stream can just be passed to another request without allocating a new box.\nThen, Box<NetworkStream> can be downcasted, and derefed to access the unboxed stream object, like: let stream = *res.unwrap().downcast::<HttpStream>().unwrap();\n. Yea, but it's no longer legal on master.\n. Huon suggested it. I suspect the underscores are to dodge the dead code\nlint.\nOn Sep 25, 2014 12:53 PM, \"Jonathan Reem\" notifications@github.com wrote:\n\nCool. You can also do trait IsSend: Send and then impl IsSend for Request\n{} etc. but this works too. I doubt the underscores are necessary since\nthis isn't exported.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/61#issuecomment-56873962.\n. I've been thinking that a Request Builder should be provided, to ease\nmaking simple requests. Something like rust-curl's interface.\n. I have a branch that starts to build a proper Client. It would use Request\nunderneath of course. But I'd expect it to have RedirectPolicy, KeepAlive,\nSslVerifier, etc.\n\nWe could collaborate on that...\nOn Fri, Nov 21, 2014, 10:51 AM Jakob Gillich notifications@github.com\nwrote:\n\nI've started writing a higher-level library called request\nhttps://github.com/jgillich/rust-request (based on hyper's Request -\nyeah I suck at naming things). It has an builder interface, handles\nredirects and probably more things in the future. Usage looks like this:\nlet result = Request::with_url(\"http://example.com\").header(Accept(...)).get();\nThe code is a bit awkward (like using clone too often) so if anyone has\nany ideas on how to improve it, I would love to hear them. It is however\nmore of a learning project, I might decide to abandon it one day if\nsomething better comes up (or I will just continue to improve it until it\nbecomes something better).\nAbout hyper's Request, it feels too low level for \"regular\" applications.\nHandling redirects manually would mean you'd have to write a wrapper around\nRequest, essentially what my request library is.\nHowever, when it comes to writing wrappers around it, it is actually too\nhigh-level. One example is setting the headers - it makes the most sense to\nstore your headers in a Headers struct, but when you overwrite\nRequest.headers, you wipe the Host header that it defined in its\nconstructor.\nAs somebody who never wrote a HTTP library nor a browser engine from\nscratch, my naive proposal would be to take the low-level parts of Request,\nput them in a module where you can simply say \"here are my headers, url,\nmethod, send pls\", and then write a high-level module on top of it. And\nmaybe one in between for browser engines and similar applications.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/62#issuecomment-64018154.\n. @jgillich see the client branch for the work I started. I just rebased it to master, but I'm not sure that means it actually works currently.\n\nI was thinking of some sort if AsBody trait, to make Client::post(url, body) able to take a &str, or Reader, or something.\nAlso, to prevent so much cloning of the Headers and everything, I was looking into if Request could just take a &mut Headers and such, or perhaps pop the headers back out before destroying the request. That's a bit of work, though...\n. Could you run them with RUST_BACKTRACE=1 RUST_LOG=hyper=debug and paste\nthe results?\nOn Sep 27, 2014 12:43 AM, \"Dimitar Kostov\" notifications@github.com wrote:\n\nWhen I create new cargo project and try to run the server from the\nexamples directory it gives me this error after successful compilation:\ntask '' has overflowed its stack\n[1]    14646 illegal hardware instruction  ./target/demo\nSame thing when I run the benchmarks in the hyper project repo\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/64.\n. Hm, useless. Could you try running in gdb?\n. Hm, I'm getting it now also. Will dig in.\n. It seems the implementation of read on Box<NetworkStream> is recursing until overflow. Something in rustc must have changed regarding how it derefs.\n. I wonder if it's related to this: https://github.com/rust-lang/rust/pull/17464\n. Thanks!\n. The Url type is a sufficient type to represent this variant.\n. Great, thanks!\n\nSeems fine with a String for now. When going through and marking various headers as stable, the Location header should likely be an AbsoluteUri, as the spec says.\n. Sweet! A few nits, and then we can merge.\n. Fow now, this provides a usable interface. I'm going to merge, but as this library is still experimental, if there's a better way to do it, it's just PR away.\n. The dependencies of cookie-rs are already dependencies in hyper, so that's okay.\nI'd definitely like to have a Cookie type, with decent typed interface to set various properties of a cookie. My only hesitation is the cookie signing that is in jar.rs. Signing is good, but it seems extra for an http library. @alexcrichton what do you think?\n. I'm working on adding support for headers that must output on multiple\nlines.\n. @s-panferov I know you've done a lot of work in this PR, and thank you for that! I want to fix up being able to have multiple header lines, otherwise SetCookie is kind of useless on it's own. I've been busy this week, but I've just finally gotten permission to work on this 1 day out of the work week, so I can do more than just nights/weekends.\n. @s-panferov just wanted you to know that I haven't forgotten. Adjust the Header trait to support this has been filed in #80. I've been waiting on associated items to be more fully implemented in rustc before tackling.\n. @s-panferov I was actually working on this PR today. I'm going to add in a hacky way to produce multiple lines, as so far, this is the only header that needs it, and I want to unblock people.\n. closing in favor of #106 \n. If that gets merged into a rust-url, I'd be happy to use it. Until then, I'll just submit a fix to unblock you (or anyone else) right now.\n. I've fixed this on master again, sorry for the bugs!\n. It was the first commit in my many branch, but being stumped at how to allow Headers to have many lines, I figured this should merge anyways.\n. updated with nits\n. Ok. I wish the experimental attribute would be enough of a hint. \n. This was done in 0.11, Header::fmt_header now receives a header::Formatter that has a fmt_line method.. I'd emphasize the typed API, as it's cleaner and safer. Using it means less\ncrashes for everyone. I'd recommend that you provide both APIs, so that\npeople who want the safety can use it.\nHowever, as @reem mentioned, we do want to provide a raw interface, when\nit's not possible to know headers at compile time. Main driver is Servo,\nexposing things like xhr.getResponseHeader(\"foobaz\") in the DOM.\n. There exists headers.set_raw(&str, Vec<Vec<u8>>).\n. Perhaps Authorization could wrap a generic, so that it can support various schemes, such as Basic, Bearer, Hawk, etc.\n. Don't worry about it. Learning is fun, and you're helping us freely.\n. So, looking at the Authorization header RFCs, there are 2 expected formats (the first is \"deprecated\", as in no new scheme should use it):\n- Authorization: <scheme> <b64token> - offenders being Basic and Bearer.\n- Authorization: <scheme> <param>=\"<value>\",*, like Hawk sig=\"asdf\", id=\"1234\", ....\nThe raw instance is covered by get_raw(). We could either allow people to implement new Header types for whatever scheme they want (actually, this is still true even if we got with option2), or we could have Authorization be something sort of enum for the 2 formats above.\nExample of Option 2:\n``` rust\nenum Authorization {\n  // naming things is hard\n  OldFormat(T), // where T impls FromStr\n  NewFormat(T) // where T impls Decodable\n}\nstruct Basic {\n  user: String,\n  password: Option\n}\nstruct Hawk {\n  id: String,\n  sig: String,\n  nonce: u64,\n  timestamp: Tm\n}\nlet basic: Authorization = req.headers.get();\nlet hawk: Authorization = req.headers.get();\n```\nNow that I look at it, the enum might not be a fun experience... @reem what did I overlook?\n. Sigh, of course, it took seeing after hitting the post button to notice.\nIt'd probably need to be struct Authorization<T>(pub T); where T implements some sort of AuthScheme.\nWith associated types, it could be:\n``` rust\ntrait AuthScheme {\n  static scheme: &'static str;\n  static decode_trait: FromStrOrDecodable;\n}\nimpl AuthScheme for Hawk {\n  static scheme: &'static str = \"Hawk\";\n  static decode_trait: FromStrOrDecodable = Decodable;\n}\n```\n. Sure. I just figured there's 2 ways that the Authorization header should be decoded, and they should all include a scheme, so it'd be cool to have a Decoder they can use.\n. @gtolle just filed #94 that builds off your work and heads in the direction I was mentioning. I'm closing this in favor of that. Thanks for the base!\n. What I get on my older laptop:\nOn master:\ntest http::tests::bench_read_method ... bench:       228 ns/iter (+/- 6) = 35 MB/s\nThis PR:\ntest http::tests::bench_read_method ... bench:       192 ns/iter (+/- 2) = 41 MB/s\n. And if the port is 80 or 443, is it omitted? Probably should have a test also. \n. I'll make some adjustments, starting with this branch. I'll convert the\nHost header into a struct with host name and port, and the formatting can\nhappen in there.\nOn Oct 22, 2014 9:36 AM, \"Hanno Braun\" notifications@github.com wrote:\n\nAnd if the port is 80 or 443, is it omitted? Probably should have a test\nalso.\nNo, it isn't. I believe that always adding the port, even if it is the\ndefault one, is correct behavior:\nhttp://tools.ietf.org/html/rfc7230#section-5.4\nHowever, I've added more test cases to ensure that Host header is correct,\nif the port in the URL is omitted.\nOf course we could omit the port if it is the default one, but since it\nworks as is and I wanted to get on with my other work, simplicity won out\nin this case :)\nDo you want me to omit default ports, or will you merge this as is?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/89#issuecomment-60114551.\n. Merged manually. Thanks @hannobraun!\n. Curious, whats the gain over using std::io::net::tcp?\n\nAlso, fwiw, it's possible to prototype this as lib, implementing NetworkStream, and then using Request::with_stream::<PicoStream>.\n. It's not something that I think hyper should pursue. Support can be added with an external crate by implementing Transport and Connect on some picoTCP types.\n. Not in the nightly yet?\n. @gtolle @s-panferov will this work for you guys?\n@reem r?\n. thanks!\n. Yea, I noticed the slowdown when I added that header. strftime is not too fast in libtime. I filed https://github.com/rust-lang/rust/pull/18556 to try to fix this.\n. Ah, would that be because of the tm.to_utc() call?\n. Yea, so to_utc calls Tm.to_timespec(), which is calling rust_timegm: http://doc.rust-lang.org/src/time/home/rustbuild/src/rust-buildbot/slave/nightly-linux/build/src/libtime/lib.rs.html#327\n. It seems like it's a waste of calls. The Tm is already in UTC, since the default is calling time::utc_now(). It notices the gmt_offset is 0, so it seems like it could just return itself quickly without touching the C function...\n. While that should be fixed in libtime, I could try checking for tm_gmtoff == 0 myself, and if so, no need to call to_utc().\n. The TmFmt patch was merged 2 days ago. With that and the #100 patch, does this improve things noticeably?\n. The parsing is happening here, and that code is run inside the hyper acceptor task.\nWe can't assume the user of the library wants to spawn a new task per connection (most reasonable servers would likely want to use a task pool with a limit).\n\nWhat if a handler were to spawn a task before calling incoming.next(). That should move the parsing into a separate task, right? Can that be safely/easily done? I haven't looked too hard.\n. Alternatively, the Incoming could return some sort of \"request/response\" future, so that once it's been passed to a destination task, the parsing could happen there.\n. The more I think about it, the more I like returning a Future<(Request, Response<Fresh>)>. \n. No it doesn't. There is Future::from_fn, which does not execute on a new task.\n. This allows the parsing to be deferred until the Future is on whichever task will be handling the Request, and reduces the overhead of an Arc and Mutex.\n. fixed with #110\n. Was there a noticeable effect on the profiling?\nOn Thu, Nov 6, 2014, 7:43 PM Jonathan Reem notifications@github.com wrote:\n\nMerged #100 https://github.com/hyperium/hyper/pull/100.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/100#event-189729415.\n. Yep, tests are failing because of rust-http not updated. No problem. Thanks!\n. Dupe of #55 ?\n. There's a ChunkedReader and a ChunkedWriter. They are used automatically depending on if the presence of a Content-Length or Transfer-Encoding header.\n. @s-panferov ok, rebased in those changes.\n. can you run your server with RUST_LOG=hyper=debug?\n. Hm, it may not even be getting through the TCP layer.\n\nDoes the example in the TCP docs work? http://doc.rust-lang.org/std/io/net/tcp/struct.TcpListener.html\n. I believe so!\n. Oh ok. So, the request with curl just says connection refused, but the server doesn't crash nor output any more info?\n. So, it should either output DEBUG: incoming stream or an ERROR: connection failed: https://github.com/hyperium/hyper/blob/master/src/server/mod.rs#L103\nIf it's not getting there, I'm left wondering if the error is happening inside rust-intertwine...\n. I'm able to access the example server with cargo run --example server and can curl it.\n. Whew. Glad it's worked out.\nOn Mon, Nov 10, 2014, 11:30 AM Simon Ask Ulsnes notifications@github.com\nwrote:\n\nAlright, I had the same issue with the example, but then I tried curl\nwith a Rails app I had lying around, and it gave the same result.\nApparently curl fails on all requests to localhost on my machine. wget\nand browsers work without issue. I have no clue as to why I'm seeing this\nbehaviour, but the problem seems to be with curl, and neither Rust nor\nHyper.\nIt seems I had the following line in my /etc/hosts:\n::1        localhost\nwhich caused curl to attempt an IPv6 connection to localhost, which\nneither Rust nor Ruby were listening on.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/109#issuecomment-62440018.\n. awesome!\n. I don't have one yet. I had simply reverted out the interwining commit to compare the benchmarks.\n. Needs to remove the extern crate intertwine lines in lib.rs.\n. failure in benches/client.rs, since it accesses listening.sockets.\n. Yea, we can use [breaking-change]. I just got into the habit of using BREAKING CHANGE, since we recently started using that in fxa to get nice changelogs.\n. Did you try the wrk benchmark on it? Curious how close it gets to Iron.\n\n\nAlso, I noticed that doing this with a task pool slowed down the benches/server.rs, since there's overhead dealing with tasks and pools and channels, but it's not being used because its only ever 1 connection at a time.\nThat made me think of:\n1. Perhaps removing that bench completely, since it's not a particularly useful bench. Better to know how to the server handles under load.\n2. Or, if threads is 1 or 0, don't use a task pool, and just handle the connection in the acceptor task, like before. Would people want a single threaded server like that?\n. just rebased\n. i still need to move the threads to a new method, such as listen_threads(Handler, uint)\n. I think that's the only change left...\n. Fixed that too. Travis failure is something to do with openssl...\n. I've updated to use the new taskpool in libstd, but it's not in latest nightly, so travis fails.\n. I fixed the conflicts and pushed, running rustup so I can test locally.\n. Alright, tested locally, fixed.\n. its green! merging before something can mess that up.\n. There's an error about too many time crates. I don't recall how to fix this. Maybe it's to change to dependencies.cargo_time and then extern crate \"cargo_time\" as time;?\n. It's needed for a redirect loop in servo, and likely in our own redirect loop eventually.\n. We could take a look at doing something like that. It'd be a little faster than cloning and letting Request consume them. However, there are any number of use cases for cloning the Headers struct. Unless there's an obvious flaw, I'd rather add this in, and consider removing it if Clone is too much of a bear.\n. Yes, servo wants it.\nAlso yes, it's just a reminder that parse_header cannot ignore multiple lines, like many other headers can.\n. Thanks a lot for fixing this!\nThis is also exactly why I didn't want to keep code samples in the README. I'll remove it in the future, and have links to the examples/hello.rs and docs.\n. @reem not sure what you mean. It looks like this refers to variants like\n'StatusCode::Ok'.\nOn Tue, Nov 18, 2014, 10:44 PM Jonathan Reem notifications@github.com\nwrote:\n\n@seanmonstar https://github.com/seanmonstar Do we want to do this or\nwould we like to refer to variants by their new namespace names throughout\nhyper?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/123#issuecomment-63599134.\n. Yea, I'd rather not use the globs feature.\n\nWe don't need to do away with the modules, since it's nice to contain them in separate files, but perhaps it makes sense to re-export the enums in lib.rs. such as pub use method::Method;.\n. Yep, looks like #123 may take care of this.\nOn Wed, Nov 19, 2014, 8:49 AM Paul Woolcock notifications@github.com\nwrote:\n\nLooks like it is related to the namespaced enums that landed earlier this\nweek\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/125.\n. fixed by #127 \n. The desired goal is to utilize the HTTP protocol over a Unix stream instead of a TCP stream? It should mostly just need an implementation of net::NetworkStream/NetworkConnector. Not sure if the use of Url will cause any issues...\n. As for whether it makes sense in hyper, I don't know. How about other languages/httplibs? Do they include a Unix stream option?\n\nUnless they do, my gut feeling is this could be a separate crate, so as to not add more maintenance required for hyper.\n. I wouldn't expect hyper to explicitly include a UNIX socket implementation. It's already possible to just use any external implementation by using a custom Connect in the Client. hyper's goal is provide HTTP, and be generic over whatever the transport is underneath.\nBeing built in to a client would make sense for a more batteries-included kind of library, and for this exact feature, see https://github.com/seanmonstar/reqwest/issues/39. I do expect Server to have a generic type for the incoming stream in 0.12. On master, there is Serve which is already this, and will likely evolve and replace the current Server as the tokio reform stuff is completed.\nI don't think this issue itself needs to be opened for that, as this was around building in UDS support by default, instead of allowing it to be used.. @portstrom Both hyper's client and server allow providing any custom connector or listener, so you can plug in UDS easily, as others have shown.\nDoes it really seem so common to use UDS that it should actually be built in to hyper directly? If it is, at this point, it wouldn't be that much work to provide a hyper::client::connect::UdsConnector and a listener for the server. If it seems common enough, @portstrom would you be interested in adding it, so others aren't \"surprised\" in the future?. Thinking more, it really doesn't seem that common. I'm fine with it being a separate thing.. looks good to me. rust nightlies broke several things, I think fixing find_equiv can be a separate PR.\n. Travis failure is use of str::from_str in a bench file.\n. IT'S GREEN! \\o/\n. I don't understand. crates.io still doesn't resolve for me. And, crates in the registry can't point a git dependencies?\n. Aha, I did this earlier, and forgot to make a PR of the branch. Just filed it as #133. The ICE should be fixed in rustc, but it's also our error because the write! macro changed to take a &mut Writer. Those changes are in my PR.\n. oh right. I reworded it, because you can just do println!(\"status = {}\", status as u16)\n. I've been following https://github.com/angular/angular.js/blob/master/CONTRIBUTING.md#commit\nWhich supposedly would allow generating a nice changelog.\n. There's no status_mut for this, this is in the client. Changing the status\non a response doesn't make any sense.\nOn Thu, Nov 20, 2014, 8:35 PM Jonathan Reem notifications@github.com\nwrote:\n\nMy biggest gripe here is that this means there are two sources of truth\nfor the Response status. This could be mitigated by going from status_mut\nto set_status (or using modifiers, if we want to accept the conceptual\noverhead) and also setting raw_status whenever status is set.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/135#issuecomment-63923522.\n. Being a SendStr would be nice, but also seemingly difficult to do...\n. Also, I considered making StatusCode wrap around these raw pieces, but then it would no longer be Copy, and I didn't like that.\n. Some stats on speed:\n\nWith current PR:\ntest http::tests::bench_read_status ... bench:       484 ns/iter (+/- 4) = 26 MB/s\nWith code that tries to use a SendStr if the phrase matches the defaut from status.canonincal_reason():\ntest http::tests::bench_read_status ... bench:       412 ns/iter (+/- 2) = 36 MB/s\n. That is using a static buffer. [0u8, ..32]. The longest default phrase is 31 characters.\n. I push a rebased version, but having compiling issues with some crates being on crates.io, and some on git, and double openssls, oh my!\n. Rebased, finally green.\n. Part of me is excited, cause yay crates.io! And another part of me is worried, since rust is still causing breaking changes left and right, that depending on crates.io instead of git will mean things are slower. I'm not in love with bumping the patch version every couple days just because an internal API was tweaked.\nBut oh wells, crates.io!\n. Also, tests failing because something is using a different openssl crate.\n. Does the version you have build and test locally? I'm having trouble doing so.\n. hrm, so then we can't really merge this until dev-dependencies are figured out?\n. Thanks for the fix, but I just looked at this, and the method is incorrect. The spec says a valid method is all tokens, so it just needs to call is_token. This is_valid_method function can be completely removed.\nWould you mind making that change? And adding a test that get parses as ExtensionMethod(\"get\".to_string())?\n. Actually, that can be called in read_until_space, making sure every byte is a token, and if not, returning HttpMethodError.\n. @barosl Nice! You rock!\n. Certainly, the base functionality would be in a separate crate from hyper. Quick searches suggest TransmitFile is a Windows equivalent.\n. This is tricky with non-blocking IO, and doesn't work over HTTPS or with HTTP/2. I don't believe the gains are worth the effort. Still, if someone wished to do this in their Handler, it should be possible to do if Encoder were to implement AsRawFd. It'd then just be sendfile(file.as_raw_fd(), encoder.as_raw_fd()).\n. Solution that was proposed in #298 will be done.\n. Doesn't this also require Hash? \n. wonderful! more tests is greatly desired: #43 \n. Thanks for the contribution! If you could address the one comment, I'll merge.\n. done!\n. I'd hope that crates.io evolves tags, or similar, that could help find\nthings like this.\nIn the meantime, it makes sense to me if we start a wiki page in this repo,\nso that it doesn't require pull requests just to list a compatible trait.\nOn Tue, Nov 25, 2014, 1:08 PM Austin Bonander notifications@github.com\nwrote:\n\nThis is only a humble request.\nMy multipart https://github.com/cybergeek94/multipart extension, while\nnot feature-complete, adds support for multipart/form-data requests on\nthe client and server, and works as far as I've tested it. Really the only\nfeature missing is multiple files in a single field, and I'm confident I\ncan implement that in a backwards-compatible way.\nI'm concerned that it might be hard for Hyper users to discover it, and\nthey would spend time on their own implementation that they could have\nspent on their original project instead. I'm open to competing solutions,\nof course, I'm not asking for endorsement or exclusivity, but I'd like\npeople to be aware of this approach.\nI'm also open to merging it if it proves useful and reliable. It works\nfine as a separate crate, as I designed it to work against the public API.\nMaybe this could expand to a list of projects built against or designed to\nmesh with Hyper, so new users can get an idea of the ecosystem that exists\nalready and what's available.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/149.\n. Nice, looks great!\n\nAnd yea, I meant hopefully the crates.io interface starts to show tags or keywords as links, and then the hyper crate can include the keyword hyper, and clicking it would show other projects that have tagged themselves as working with hyper. Maybe. Shrug.\n. Thanks! I included your commit along with another needed to fix changes of MaybeOwned.\n. Are these changes necessary? The code works currently against current nightly. \n. This should be possible today: use hyper::header::common::UserAgent;.\nThough, I can agree. I think it'd be nice to re-export header::common::* in header.\n. :beers: I completely agree with only taking a borrow. Thanks!\n. Yup. Definitely want this. Last I tried, unboxed closures were causing\nICEs, so I've just been waiting.\nOn Fri, Nov 28, 2014, 7:49 PM Austin Bonander notifications@github.com\nwrote:\n\nIt would be really nice if hyper::server::Handler was implemented for\nunboxed closures of the type Fn(Request, Response) + Send + Sync, which\nwould also extend to the current static function impl.\nWhile unboxed closures are still feature gated, they are inevitable; I\nthink we need to be forward-thinking on this, though it is trivial to\nimplement a workaround\nhttp://rust-ci.org/cybergeek94/multipart/doc/multipart/server/handler/struct.UnboxedHandler.html\n.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/160.\n. This actually happened a few commits ago: https://github.com/hyperium/hyper/commit/84b49cb364cb608f777dbc42384ee297a6408108\n. @reem you were right! one transmute removed!\n. @reem i think that's all addressed.\n. I think it actually makes good sense, since these headers are just newtypes around the underlying type, with some parsing/fmting. Better to be able to do transfer_encodings.contains(Chunked) directly.\n. this was fixed\n. nice, could you rebase once more, this PR includes the rust upgrade commit a second time.\n. and also with the rebase, squash it into a single commit?\n. awesome, thanks!\n. That would be much easier for us, but much harder for anyone who wants ssl cert checking.\n\nI'd hope for:\nrust\npub struct Client {\n    pub ssl_verifier: Option<SslVerifier>,\n    pub redirect_policy: RedirectPolicy,\n    // ...\n}\n. I was thinking that would be nice, so then people could continue to use HttpStream, and just provide new constructors.\nSo, I would then use 2 different connectors for the Client? Not sure how I could pass the SslVerifier to the different implementation, if it stays a static method.\n. @reem updated with the newer design.\n. and its green!\n. @reem i'd likewise like it if we could do the same with Connection, since it can refer to other headers.\n. @wenderen as for the representation, I'd use just an enum:\nrust\npub enum Vary {\n    Any,\n    Headers(Vec<String>) // or maybe CaseInsensitive? or maybe something cooler like reem wants\n}\nThis allows one to write req.headers.set(Vary::Any).\n. closed via #193\n. @jamougha does https://github.com/servo/rust-url not satisfy the requirements?\nIt's what's currently used for hyper::uri::RequestUri and such.\n. RFC 7230 says:\n\nUnless otherwise indicated, URI references are parsed relative to the effective request URI.\n\nSince the spec doesn't say otherwise for the Referer header, then a partial must be relative to the request URI.\n. Closing for the same reason as #243 \n. You're correct, I pasted the wrong section link.\nWe should adhere to the spec. Any simplification is a bug that should be improved on.\n. The exact version used in a specific project should be manageable via\nsetting the revision in the local Cargo.lock file.\nOn Wed, Dec 3, 2014, 11:01 PM Artem notifications@github.com wrote:\n\nSo, when one project uses a crates version of openssl and another uses a\ngit version, the build using both projects is broken. When one project uses\nan upstream version and another uses a fixed version (\nblackbeam/rust-mysql-simple@06edff7\nhttps://github.com/blackbeam/rust-mysql-simple/commit/06edff7ea454b9c52e845bae69452d63ce6b03cb),\nthe build using both projects will be broken very soon.\nHow do we coordinate this?\n(I'm going to open this bug in multiple projects).\nblackbeam/rust-mysql-simple#7\nhttps://github.com/blackbeam/rust-mysql-simple/issues/7\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/175.\n. Oh yea, it's no longer needed now that we don't use find_equiv in the hashmap. Thanks!\n. I'd venture to say that that test itself is broken. The XHR spec itself says that if a status is not within 200-599, then to throw a RangeError: https://fetch.spec.whatwg.org/#concept-response-response\n. Because by being an enum, it limits the values you might pass.\n\nOn Sat, Dec 13, 2014, 2:20 PM Dawid Ci\u0119\u017carkiewicz notifications@github.com\nwrote:\n\nWhy is StatusCode an enum? When I see around 400 lines of:\n/// 132 (unregistered)\n  Code132 = 132,\nIt seems to me it should be struct StatusCode { u16 } with some helpers /\nstatic constants for common codes.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/177#issuecomment-66893869.\n. @dpc hm, i'm coming around to that design. I'd likely change from_code to unregistered(), and also add Deref<u16> to it...\n. Actually we can't. It's currently a c-enum, and they can't also have variants containing values. \n. Yea, the suggestion for Deref was because the current enum allows you to do StatusCode::Ok as u16.\n. Thery currently do. They just use Options, which is a minor speedbump.\n. Ps, my experiment with using a newtype around u16 stalled. I wanted to keep\nsimilar usage to the enum now, but can't have a mod and a struct with the\nsame name. Associated constants would be needed to finish that.\n\nOn Sun, Jan 25, 2015, 12:05 PM Pyfisch notifications@github.com wrote:\n\nI think it is hopeless [image: :joy_cat:]\nTwo more interesting facts:\n- Both Chromium and Firefox understand 42 and 1024\n- Only Chromium understands 2147483647, firefox thinks it is 200\nWho wants to test IE, Safari and Opera?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/177#issuecomment-71389889.\n. @Manishearth try to impl StatusCode and everything goes to hell.\n. @pyfisch here's the associated constants issue.\n\nWith the constants, I'd implement like so:\npub struct StatusCode(u16);\nimpl StatusCode {\n    pub const Ok = StatusCode(200);\n    // ...\n}\nWithout that, I'm against the newtype, because it causes these issues:\n- as a newtype, the registered codes must be in ALL_CAPS (to make the lint happy)\n- if not all caps, the lint is trigger everywhere they are used\n- mistyping one of the registered constants screws up matches\nrust\n  match code {\n      Ok => (), // triggers lint about wrong-capped constant\n      MovedTemporaraly => (), // becomes catch-all, like _\n  }\n- except if you use them like enums currently\nrust\n  match code {\n      StatusCode::Ok => (), // lint is all happy\n      StatusCode::MovedTemporaraly => (), // error as undefined value\n  }\n\nSo, until associated constants are implemented, the enum with an Unregistered(u16) seems best.\n. @mdbooth this is your first Rust? It looks really good. No obvious first-time goofs that I usually see.\nHowever, this header is a little more complicated than the parsing handles. Would you be interested in getting it to match the spec?\n. Thanks! If you have any questions on design or how to do something, ask here or on IRC. \n. Closing for inactivity. \n. We could make Request only take a reference, but that will make it so you\ncannot send the request to another thread for any reason, because it will\nno longer be Send...\nOn Fri, Dec 5, 2014, 4:38 AM mdbooth notifications@github.com wrote:\n\nHadn't noticed the url object ends up wholesale in the request object.\nOk, I guess that makes sense.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/179#issuecomment-65784408.\n. Thanks for getting this started! \n\nWould you be able to fill in the missing parts from the spec? You can find a link to it in the issue you referenced. Specifically, the weak indicator needs to be stores on the struct, and the value must be inside quotation marks. \n. Don't worry if the tests fail for another reason. That's pretty normal with rustc changing a little every day. \n. Excellent! This is looking really close. Also, could you remove the println!s? If you need any for debugging, use debug!(), and set the env var RUST_LOG=hyper::header::common::etag=debug to see them.\n. One last nit, and I think this is good to go. Also, could you squash this into a single commit? git rebase -i master.\nI was trying to decide if it'd be better to have this as an enum Etag { Weak(String), Strong(String) }, or to use a struct with a weak field, as you've done. I can't decide, so the way you've done it seems fine to me.\n. Seems odd. You can do '\\u0080'.\n. Thanks for wrapping this up! Looks great.\n. @reem updated\n. Yep, that's exactly what I was working on right now.\n. @reem like that?\n. finally green!\n. What test was failing? \n. Could it be that it's parsing \"\" into Extension(\"\".to_string())?\nCan't wait https://github.com/rust-lang/rfcs/pull/504\n. We should have the test that the vec is empty. That it's parsing into an Extension sounds like a bug in http::read_method.\n. Sorry, wrong place. The bug is here: https://github.com/hyperium/hyper/blob/master/src/method.rs#L82\n. woo! thanks\n. Hm, Yea. I could make 3 sub crates, hyperc, hyperd, and hyperp, or\nwhatever, and bundle them all as hyper.\nI don't think I want them in separate repos and such, though.\nOn Wed, Dec 10, 2014, 9:09 AM Richard Diamond notifications@github.com\nwrote:\n\nrust-ppapi maintainer here. rust-ppapi needs to be able to handle header\nformats correctly, but doesn't need all of Hyper (ie doesn't need the\nserver + client parts). I'd like to have rust-ppapi just depend on the\nheader portions of hyper, because the Pepper API has it's own http client\nAPI.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/189.\n. Yea I figured hyperclient -> hyperc, hyperserver -> hyperd (daemon), and hyperp for hyper protocol, since it would include more than just headers. This is because the headers depend on HttpError, Method, etc.\n. This will be done as part of the 0.12 release. When the rest of the types are replaced with http types, that means things by default will be using http::HeaderMap.\n\nThis will mean a change to the API is likely needed, perhaps as just a way to get and set typed values by taking &/&mut HeaderMap.\nAlso needs a name. Some ideas:\n\nheaders (currently exists, but looks like it may have just been an experiment. Perhaps Ashley would be interested in a transfer?)\nhelmet (protecting your head(ers)?)\nvisor (enhancing your head(ers)?). http_headers is also currently claimed (perhaps abandoned?).. Update: I've made https://github.com/hyperium/headers that pulls the 0.11.x typed headers into its own crate. The name is provisional, the purpose is just to try to consolidate effort and conversations in a single place.. oh dangit, i forgot to feature gate the attributes\n. It seems the error is 2-fold:\nMost all clients don't send a chunked message when there really isn't a body. The client interface was trying to guess if it was chunked. The newer Client struct should properly set Content-Length: 0 when there is no body.\nEven so, if the server handler does not read the whole request body (if a client did POST data), and ignores it, then the data will still be in the pipe. The keep alive loop will read on the socket again to see if the connection has continue, and will find the rest of the POST body. This part means that the server perhaps needs to be adjusted somehow to make sure the full request is read, even if the Handler doesn't do it.\n. sweet thanks!\n. Thanks, fantastic!\n\nI'm not ignoring this, I've been thinking about the design here. I might say that we merge this and refine the design if a better one is thought of...\n. wow. i started this a couple days ago, but didn't have time to finish, as it was a lot of work. thanks!\n. Why split into 5 packages? client and server are obvious. why not just 1 other crate, protocol or something?\n. @reem ping, since this is a big change. love your thoughts also\n. @reem wait what, really? I didn't think that'd be the case... It looks like rust-openssl points at itself instead of the crates.io version for openssl-sys https://github.com/sfackler/rust-openssl/blob/master/Cargo.toml\n. Um, wow. I didn't realize that. I'd hoped it could still be one published\ncrate that provided many.\nIs there an issue in cargo for this to happen, or is it by design?\nOn Thu, Dec 18, 2014, 5:46 PM Jonathan Reem notifications@github.com\nwrote:\n\nOk, so that clarifies the situation a bit - it is possible to use path for\ndevelopment, but it still does require uploading and maintaining crates.io\nversions for all the sub packages.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/200#issuecomment-67587656.\n. @alexcrichton any future plans to support something like this, or bad idea?\n. @DiamondLovesYou server and client are in this package as that is expected by most developers. Think of hyper as http in nodejs or Python. They include basic, functional, fast implementations that work for small things, and can be built upon, such as what Iron does.\n\nAs for this PR, I'm not against it, and think it may be worthwhile, but only after cargo supports it better.\n. Sorry for the rough edges, this was fixed in #137 \n. Thanks! \n. That seems backwards. The source of std::thread shows that when JoinGuard drops, it implicitly joins... \n. Yep, things moved around. I'm fixing for latest nightly currently.\n. Yep, see #206. Waiting on rust-url to update as well.\n. @cactorium indeed, not a bother! excuse the lapse of attention. I feel like vacation has me more busy than when I have work.\n. @cactorium alright, i had a chance to think this through over the weekend. I think an approach similar to how the Client works, by using a NetworkConnector instance. In this case, instead of using a static bind function, Server could accept a NetworkListener, and call an instance method to start everything up.\nSo, something along these lines:\n``` rust\npub struct Server {\n    // ...\n    listener: Box,\n}\nimpl Server {\n    pub fn http(...) -> Server {\n        Server::with_listener(..., box HttpListener::Http)\n    }\npub fn https(..., key, cert) -> Server {\n    Server::with_listener(..., box HttpListener::Https(key, cert))\n}\n\npub fn with_listener(ip, port, listener: Box<NetworkListener>) -> Server {\n    Server { ... }\n}\n\n}\n```\nThat means the server would no longer determine what kind of stream to use at listen(), but instead at construction.\nThen, the HttpListener could look like this:\nrust\npub enum HttpListener {\n    Http,\n    Https(Path, Path),\n}\nThis would also require changing NetworkListener's bind method to be fn bind<To: ToSocketAddr>(self, addr: To) -> IoResult<Self>, I think...\n\n. I'm currently switching the traits over to use associated types. I think that will ease this is in.\n. Example:\nrust\ntrait NetworkListener {\n    type Acceptor: NetworkAcceptor;\n    // ...\n}\n. @cactorium I recently redesigned those traits as I said I would, can you where to plug in the Ssl pieces? \n. True! It seems like in read_header should trim the OWS.\n. Thanks! Failure is from rustc changes, will be fixed in another commit.\n. This looks outstanding!\n. Excellent work! I'm going to toy with a IntoQualityItem trait to see how that looks, but that doesn't stop this. Just needs a rebase and I can merge it in.\n. @pyfisch I merged this manually, cleaning up the commits, as it seems somehow the commit history in this PR duplicated at some point.\n. Thanks!\n. Why use mark_dead instead of handling this outside of the Request class?\nOn Thu, Jan 1, 2015, 6:47 PM Jonathan Reem notifications@github.com wrote:\n\n@jamwt https://github.com/jamwt I'm going to wait and let @seanmonstar\nhttps://github.com/seanmonstar merge this since he's worked on the\nclient more and has a better idea of if this is appropriate.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/220#issuecomment-68506420.\n. Just published 0.0.20\n. Will need a rebase since I merged in @pyfisch's PR.\n. I just bumped Travis, and serialize errores again... \n. Oh, seems something is explicitly depending on an older version. \n. @reem just checked again, Travis errors in hyper now. \n. thanks!\n. This is amazing work. Thanks!\n. I don't think the unsafety can happen because of MuCell, but instead because the value is stored inside a Cell, but we return just a plain reference to it. Once you've received the Option<&Foo>, it's lifetime is no longer connected to the Headers struct. The compiler will allow you to modify the value internally, and you'll have a dangling pointer.\n\nThe safe fix would be to create some sort of H smart pointer, and return that instead of a transmuted &T.\n. This looks mostly awesome. Just a couple concerns around ease of use.\n- use hyper::header::LastModified feels nicer than use hyper::header::common::LastModified.\n- Encoding and ConnectionOption should be importable from the same place as their headers. One should be able to do use hyper::header::{Connection, ConnectionOption} or similar. Instead of one to common and another to shared.\n. Me neither. No need for suffixes or prefixes when they come from a header module.\n. Amazing! I've been working on it too, but converting to associated types. I'll merge this, so that people can build, and then rebase against my assoc types work.\n. This was taken care of as part of a larger rust upgrade. Thanks for the intent, tho! \n. I dropped it myself in my current branch.\nOn Sat, Jan 10, 2015, 10:24 AM Jonathan Reem notifications@github.com\nwrote:\n\n@seanmonstar https://github.com/seanmonstar would you be against just\ndropping curl from the benches to make our builds more reliable until 1.0?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/234#issuecomment-69466072.\n. I'll merge this, so the header exists. Changing to a Url should happen the same time as Location.\n. @reem this is mostly it, I need to clean up the benches to not use curl, and write the commit message, but I'm on my phone, so it'll have to wait till I get home. \n. The site in question has another version enabled?\n. @shaleh hm, i wonder if these improved options would help? https://github.com/hyperium/hyper/tree/openssl-opts\n. @shaleh so, the issue in this case was connecting to https://my-proxy:8080 when my-proxy doesn't support SSL?\n. SSL was removed from hyper, see #985.. Excellent! Along with fixing the nits, mind adjusting the commit message to match the new guidelines? https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nIt'll help me produce a nice changelog from now on.\n. Doh! Thanks for the fix. Mind adding a simple test in that same module testing that adding a UserAgent to a Headers and then checking the to_string() to be correct? \nAnd also, adjusting the commit message to match https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md ? In this case, it'd be something like fix(headers): don't use Show to write UserAgent header.\n. The most common case that would help is having access to the Url of the request/response. This would help with parsing the Location, Referer, SetCookie, etc headers.\nSome other headers may benefit from accessing the status code, method, or other headers. However, until we have a concrete use case, I'd be wary of adding unknown things. Since the internals of the Header API only affect hyper itself, and anyone implementing custom headers, and not the public Client or Server interface, I'm fine with breaking changes that show up later.\nThat said, I'd be fine with Header::parse_header accepting a &Url, or &C where C: HttpContext, and HttpContext only implements get_url(&self) -> &Url.\n. I'm not sure anymore that always trying to convert the Location header (and similar headers) into a Url is correct. I'm going to close, but I could entertain the idea of instead have the header be an enum, such as:\nrust\nenum Location {\n    Absolute(Url),\n    Relative(String),\n}\nDepends on of if that separation is useful to people, or if they'd rather just decide that for themselves.\n. Makes sense to me!\nOn Mon, Jan 12, 2015, 10:37 AM Manish Goregaokar notifications@github.com\nwrote:\n\nCurrently we use a VerifyCallback, however there's a lot of in built\nverification in SslContext (eg you can just provide it with a root CA\nfile and it does the rest). Making HttpConnector take a fn(&mut\nSslContext) would be more useful (one can still attach verify callbacks\ndirectly, so no functionality is lost)\nI have a pre-unboxed closure patch here\nhttps://github.com/Manishearth/hyper/commit/a815cddecfa1d1ac86b436bf1456c87b6ed06552,\nif its design feels okay I can\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/244.\n. I'm in the mountains the next couple days, but I'll try to find some down time to look. \n. Looks good. Definitely since we implementing headers the same way, a macro would help here. \n. Could you Rebase all the commits into 1?\n\nOn Wed, Jan 14, 2015, 1:39 PM Pyfisch notifications@github.com wrote:\n\nGitCop is finally happy [image: :grin:]\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/245#issuecomment-69997220.\n. I have heard the same a couple times now in rust-webdev. I've been thinking\nof changing to a Clone bounds instead of Sync...\n\nOn Tue, Jan 13, 2015, 2:33 PM Jonathan Reem notifications@github.com\nwrote:\n\nSender is not Sync, and is instead meant to be Cloned for every\nconcurrent user. Right now, hyper doesn't expose a way to make this happen,\nand instead forces you to use a Mutex> which is subpar.\nMy first attempt to fix this was to write a copy-on-access wrapper that\nlifts types from Clone to Sync, but this is actually unsafe since for non-\nSync types like RefCell or Rc calling clone concurrently causes bad\nbehavior.\nThe immediate resolution I see here to is to just bound by Send + Clone\ninstead of Send + Sync, after which you could recover the current\nbehavior by using Arc inside of your type. Alternatively, we could add a\nseparate method for Send + Clone handlers and Send + Sync handlers,\nwrapping them in an Arc or not depending on which method is used.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/248.\n. We talked through this on IRC. Simple synopsis is that if it were Clone, users could easily have state on their handler that they think is modified with each request, but instead, it would have been cloned several times and not modify what they hoped. Instead, it's better force the user to make sure their state is synchronized.\n. I don't understand what you mean. I'd likely let set_ssl_verifier be generic over Fn, and then store it as  Box.\n. I can't restart it on my phone, the Travis site sucks on mobile. The button\ndoesn't even render.\n\nI can give it a kick when I get home.\nOn Mon, Jan 19, 2015, 1:12 PM Pyfisch notifications@github.com wrote:\n\nCan someone please rerun this on Travis, or do I need to change something\nin the code?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/251#issuecomment-70561632.\n. Apparently, it doesn't work on desktop either. Try opening a new PR.\n. I guess a benchmark (of hyper) using both mucell and refcell would be useful to know if it's worth using something outside of std.\n. I'm not sure about difficulty, but it must happen. It's a goal that you can\nhave multiple requests running at the same time, but current design impedes\nthat.\n\nOn Sun, Jan 18, 2015, 7:14 AM derekdreery notifications@github.com wrote:\n\nHow difficult would it be to make the request builder sendable, so a user\nof the lib could create a request builder and then send it to a helper task\nwhile it blocks on network io?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/254.\n. It's not currently built into the Client. You could do so manually, using\nRequest and Response. But my next planned feature is a keepalive in the\nClient.\n\nOn Sun, Jan 18, 2015, 4:09 PM jkleint notifications@github.com wrote:\n\nRe-using a Client and adding the KeepAlive header doesn't seem to do it.\nIf this is possible, can anybody share the basic idea or a quick example?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/255.\n. This will be deferred to the user's Handler, as described in #881 \n. Thanks! \n. awesome!\n. Looks great. Could you change the commit message to end with \"BREAKING CHANGE: desc\"? \n. If that's not mentioned in contributing, I'll update it. It is part of the angular changelog scheme, which will generate a nice list including breaking changes.\n. I wonder if this is an example of https://github.com/rust-lang/rfcs/pull/738 ?\n. @flubba86 don't keep those issues to yourself! We wanna fix em. \n. There's still deconstruct on Request, that yiels an HttpReader. You can use unwrap on that (should be renamed to into_inner), to get the &Reader. From there, you can downcast, no?\n. master no longer uses a thread pool at all. It is up to the user to spawn any threads they want.\n. I need to publish a new version to cargo first. \n. :+1:\n. Er, looks like travis is finding problems. \n. No problem, I'll pull your commit and fix the rest.\n. Filed all the fixes in #287 . Thanks!\n. True, the scope isn't checked for specific values. The ones in that list are suggested, as they will cover most cases.\n. Also, I'd use rustup personally.\n. Thanks for this. The PR #287 includes this and the test fixes as well.\n. > Header reparsing (accessing it as multiple types) is not permitted, which while being more restrictive in corner cases does simplify various things.\n\nI took the road of \"we don't need it yet, and it grossly complicates things. Let's not have it for now, and if that's a terrible thing, people will file issues.\"\n\nTo the author or authors of all this code: your license to use the unsafe keyword and more importantly the transmute function has been revoked for 30 days and you will be on probation for 180 days thereafter.\n\nThis was the theatrics I mentioned. The rest of the critique is perfectly fine.\n\nInjudicious usage of transmutation has left the header representation subsystem with notable memory safety bugs.\n\nThe unsafety is not as dire as it seems. Parsing can only happen once, and so the &H received cannot be changed from under you. The only way to change the value is by using a &mut method, which the borrow checker secures for us.\nIf an actual example of the unsafety can be shown, I'd love to learn from it.\n\nI have not extensively assessed the impact of this PR, but I do know that my judgement on the issue is that the entire header module needs careful auditing and probably rewriting and I believe all unsafe code should be removed from the module with prejudice for the moment.\n\nAt this point, the unsafe code that exists at this point is: a) downcast_unchecked, b) OptCell, exposing a safe exterior, and c) one lifetime transmute to handle an annoyance with HashMap<CowString<'static>, V>.\n\nBear in mind also that this OptCell is not a safe type; a reference may exist through Deref when set is called. set should therefore be marked an unsafe function.\n\nset() can only be called once. An assertion exists that the Option.is_none() before setting. You could take a reference to the None, but we don't. The only references returned are if the value is Some.\nAny mutable access to the reference requires both an &mut method, and resetting the opposite value (raw or typed) so they stay in sync.\n. Merging since this doesn't change the semantics of the design, makes things faster and safer, and doesn't prevent #293. r=Manish\n. Updated to count characters instead of headers.\n. Hm, I guess it could be configurable by passing it as an argument to from_raw...\n. Wow. :beers:. I was waiting for the url crate to be fixed, cause I couldn't compile past that.\n. Just published url, seems to compile locally, poking travis.\n. Almost perfect. Seems there the core feature was no longer needed in a benchmark. I've fixed that, amended your commit, and pushed it as #291.\n. I'm not particularly worried about the performance of Rc. My concern instead is that I'd rather not return any kind of smart pointer, if possible. I was experimenting with Rc myself, and found that it ruined match statements.\nTake this simple example:\nrust\nmatch headers.get() {\n    Some(Host { port: Some(3000), .. }) => something(),\n    Some(Host { port: Some(9000), .. }) => something_else(),\n    _ => ()\n}\nWith a smart pointer, it becomes:\nrust\nmatch headers.get() {\n    Some(host) if host.port == Some(3000) => something(),\n    Some(host) if host.port == Some(9000) => something_else(),\n    _ => ()\n}\nTake a look at this branch that adds reparsing. It's encapsulated all of it's unsafeness into internal modules, and uses a safe API to do everything. The performance impact is minimal, and it allows return &T instead of Ref<T>.\n. thanks!\n. @ok32 thanks a lot for this! Unfortunately, it looks like the timeout methods are going away for a little while, as seen in the std::net RFC: https://github.com/rust-lang/rfcs/pull/807\nAs such, I'm hesitant to add an API that will soon disappear. Once it's re-added std::net, I'd certainly welcome the addition!\n. What's another example of a header needing an entity tag?\n. Fair enough! I'm sold. Just the deref nit and I'll merge.\nOn Fri, Feb 6, 2015, 2:27 PM Josh Matthews notifications@github.com wrote:\n\nIf-Match?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/296#issuecomment-73324633.\n. Yes please!\n. Maybe having accessors on the Request would be for the best:\n- fn path(&self) -> Option<&str>\n- fn query(&self) -> Option<&str>\n. Filed issues to do this in #896 and #897 \n. What's the issue with equality? The floats? \n. It seems there's an issue with Eq in this PR...\n\nOn Sat, Feb 14, 2015, 8:38 AM Pyfisch notifications@github.com wrote:\n\nMerge this now. I will update language-tags at a later date.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/299#issuecomment-74381810.\n. I'd prefer stronger typed also, but that list is quite long. Can either keep as String for now, or try an enum with 5-10 of the most common, and then a Ext(String) variant.\n. 24 can fit in hyper. I made mime a separate crate as it seemed useful for others.\n. Oh nice. That'd be rad if we could integrate that, since we already depend on encoding (via rust-url). @lifthrasiir thoughts about a type that we could use in the headers? A label?\n. @lifthrasiir yep, that sounds exactly what would be best here...\n. merged manually\n. @SBSTP oh! i see what you mean, since to_ascii_uppercase() is called just before it. I was quite confused at first, since it's Shift-JIS in both from_str and name.\n. Sure. Though, if the name is supposed to mixed case like that, then the fix\nmust be about using to_uppercase. If it's not supposed to, then your\nsuggestion works perfectly.\n\nOn Tue, Mar 3, 2015, 9:15 PM Simon Bernier St-Pierre \nnotifications@github.com wrote:\n\nDo you want me to PR a fix?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/300#issuecomment-77098555.\n. Mind squashing into a single commit? No real need to include \"fixes\" in the changelog for something that came in a feature in the same release.\n. Thanks! \n. Test failure was in a doctest, that StatusCode wasn't imported.\n. I fixed up a couple tiny nits, and pushed this as #311 \n. I don't see a specific stopper to implementing it with the blocking API.\nHowever, we are exploring using async io for hyper before hyper 1.0.\n\nOn Sun, Feb 22, 2015, 11:01 AM Pyfisch notifications@github.com wrote:\n\nIs it possible with current blocking design to write a good HTTP/2\nimplementation?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/304#issuecomment-75442077.\n. @stepancheg wow, exciting! I admit to not having much time to review all of it.\n\nI encourage you to keep working on it, including the list you provided. hyper is far too close to a 0.11 release to try to squeeze in such a huge change. But we can definitely see how the project goes!. Yes, we're working on the h2 crate at the moment, and hyper 0.12 will be released with the h2 built in.. We wish to group together the breaking changes, and with tokio going through a reform, that is the current blocker.. We are using the h2 crate in an internal project, allowing us to flesh it out as the project needs more HTTP2 features, and take care of bugs we find. Once the needs of the internal project are more satisfied, we will have time to polish and publish h2, and then get hyper using it internally.\nNo promises, but it's possible this could appear in hyper in about a month or two.\n\none of the reasons of rapid Go adoption (although I do not like Go at all), was \"solid\" HTTP and networking stack.\n\nWe're working on it! :D\n. An update: we've release h2 v0.1!\nNow then, HTTP/2 support in hyper:\n\nhyper v0.11 has a minimum Rust dependency of 1.18.\nThe h2 crate depends on the http crate, which requires associated constants, needing Rust 1.20.\nI've tried very hard to keep it so that patch releases of hyper don't break compilation for a user, and so don't require new compilers.\nSo, by trying to do that, it seems likely that using the h2 crate will require a breaking change to hyper 0.12 (and can happen at the same time as #1317).\nHowever, there are some upcoming breaking changes due to the tokio-reform, and it seems like it could be a good idea to group those 2 breaking releases into 1, just 0.12.\n\nWith just that, it'd seem like HTTP/2 support is still a little ways out. However, I think there's something we can do to get HTTP/2 into hyper v0.11:\n\nThere is already the compat cargo feature which adds conversions to hyper types from types from the http crate.\nWe can add internal usage of the h2 crate, by putting it behind an http2 cargo feature as well.\nThis means current users of hyper v0.11 can freely cargo update and it still compiles.\nAnd users who want HTTP/2 can opt-in, knowing they need a newer compiler version, but setting hyper = { version = \"0.11\", features = [\"http2\"] }.\nBesides opting in, there wouldn't be a need to do anything else: the client and server would both be able to speak HTTP/2 automatically.\nIt does mean that users of hyper v0.11 don't get HTTP/2 support automatically, which is a bummer, but 0.12 isn't that far away.\n\nDoes this seem like the right plan?. There is a working proof-of-concept in #1432. The small test suite passes, so if anyone wants to try it out, have fun \ud83d\udc09. It only works with HTTP2 Prior Knowledge so far.\nIt might be that by the time its confident enough to merge, the breaking changes in tokio and futures will have released and we'll be making hyper 0.12, in which case this wouldn't even need a feature flag.... #1432 was merged into master, providing HTTP/2 support for both the server and client. At first, it requires opting in, and only supports HTTP2 Prior Knowledge.\nI'm going to open other issues that are more specific around more support, such as with ALPN, HTTP1 upgrades, and defaulting on.\n\ud83c\udf89 \ud83c\udf8a \ud83c\udf88 \u2728 . This could also happen to the client, right? Perhaps the logic would be best in lift_ssl_error? Also, looking in that function, I see ConnectionAborted being used. Perhaps that'd be a better error here as well, instead of OtherIoError?\n. Looks good to me.\n. Awesome work, thank you! Just waiting on travis to go green.\n. Good catch. I've also noticed that for requests that should have a body, such as POST, and the user doesn't read it out, it bleeds into the next request also. \n. cc #197 \n. The patch was reverted, so not fixed. \n. The approach I've taken in the async branch is that if a request claims a body, such as using a Content-Length header, you can read it. If a request claims a body, and you have not read it, then the socket will not be marked keep-alive (as the unread body ruins parsing the next request). The body will not be automatically read, so as to give the option to the user.\n. In HTTP/1.x, keep-alive determines whether an additional request/response can occur on the same socket. So, if hyper decides that a connection should not be kept alive, then it will close the socket after the last response is written. A client would then have to arrange a new connection to send another message.\n\nThe stream isn't necessarily read yet. hyper doesn't perform tcp reads until the user asks for it, when calling request.read(). So when a request is dropped, hyper can check to see if the amount of bytes that have been read from the socket match the Content-Length header. If it does not, then there are still bytes on the wire. Reading until the end would require more socket reads. And what if the Content-Length is something ridiculous, like 2GB. If the user didn't want to read that data, then it's a complete waste of time and bandwidth for hyper to read 2 gigs of bytes to be dropped into the ether.\nSo then you're left with wondering what is the correct limit that hyper should use to decide if it can \"fast forward\" or not? Likely, that would be up to the user. Now we have yet another knob to fiddle with. Better to stay explicit: if the user doesn't read the data, hyper doesn't read.\n. > It is the user's responsibility to handle the request's body by either reading it or discarding it and closing the connection. Note that by default, Hyper uses a pool of connections with keep-alive behavior, which means that if a request has a body that is not read, the socket is reused and the next request is parsed incorrectly.\nWhile that's true in the current blocking IO code, but it is not that way in the async branch. If a request body is not completely read (in async branch), hyper will drop the socket, not try to parse a new one on it.\n. This has been solved in master.\n. @untitaker this was part of the \"async\" commit, https://github.com/hyperium/hyper/commit/d35992d0198d733c251e133ecc35f2bca8540d96\nThe specific logic is here: https://github.com/hyperium/hyper/blob/d35992d0198d733c251e133ecc35f2bca8540d96/src/http/conn.rs#L623-L629\n. Fixing this in 0.9 wasn't wasy to figure out, thanks to the internal design. The rewrite that is included in (not release) 0.10 made fixing this possible.\n. @reem fixed the draining logic. I just use copy to a NullWriter.\nSwitching to new io will just require changing NullWriter to Sink. The EOF logic is handled inside copy, so nothing to screw up.\n. Oh dang, good catch. I'll look at nodejs for inspiration.\nOn Sat, Feb 14, 2015, 3:12 PM Jonathan Reem notifications@github.com\nwrote:\n\nActually, this is a horrible idea security-wise, I think. I may start\nreading a request body, see it's super long, and quit. I do not expect\nhyper to silently read the other 40 GB of that request.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/310#issuecomment-74396165.\n. 15% sounds excellent.is that due to a difference here vs TaskPool, or because of moving the acceptor into multiple threads? \n. I see, another nice improvement is only using the channel for panics. I'm sure that's a nice boost as well. \n. r+ with BREAKING CHANGE added\n. Indeed, and we had a PR offering timeouts, but the IO reform currently means there is no API to do so for TcpStreams.\n. Link?\n\nOn Wed, Apr 1, 2015, 2:13 PM Jonathan Reem notifications@github.com wrote:\n\nThere is now going to be a stable way to timeout on condition variables,\nso we could implement something.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/315#issuecomment-88633538.\n. I see. So, to support a timeout using those, I imagine having to kick off 2 threads, one that is parked for X ms, the other that tries to read(), and we use a select! {} on the 2 receivers.\n\nDoesn't sound cheap...\n. Yep! I'd like to try to start nowish on an API, and put it behind a Cargo feature timeouts. Then anyone could use it if they're using a nightly rustc, and we can maybe provide feedback after trying real use. I've just been busy on other parts, but PRs always welcome!\n. ``` rust\nuse hyper::Client;\nfn main() {\n    let mut client = Client::new();\n    let res = client.post(\"https://example.domain/path\")\n            .body(\"foo=bar\")\n            .send();\n    match res {\n        Ok(res) => println!(\"Response: {}\", res.status),\n        Err(e) => println!(\"Err: {:?}\", e)\n    }\n}\n```\nSee more about the Client: http://hyperium.github.io/hyper/hyper/client/index.html\n. Yep, your slice doesn't live long enough, because you don't store the backing String in a variable on the stack. Try:\nrust\nlet body = form_urlencoded::serialize(params.into_iter());\nbuilder.body(&body)\n. Hm, I assumed the deref coercions would work for that. You could use &*body. *String gives you a str, and then add & to get a &str.\nYou can use as_slice(), but I believe that is going away in favor of using deref or slicing syntax &body[].\n. I don't think this is much of a problem.\nOn Sun, Mar 1, 2015, 5:36 AM Pyfisch notifications@github.com wrote:\n\nI propose to keep them in hyper but to make them opt-in using cargo\nfeatures.\nThere could be the following groups of opt-in header fields:\n- [RFC7231: Semantics and Content#Content Negotiation]; negotiation\n- RFC7232: Conditional Requests http://tools.ietf.org/html/rfc7232;\n  conditionals\n- RFC7233: Range Requests http://tools.ietf.org/html/rfc7233; ranges\n- RFC7234: Caching http://tools.ietf.org/html/rfc7234; caching\n- RFC7235: Authentication http://tools.ietf.org/html/rfc7235;\n  authentication\n- RFC6265: State Management Mechanism\n  http://tools.ietf.org/html/rfc6265; cookies\n- CORS http://www.w3.org/TR/cors/; cors\nThe headers folder can be reorganised to represent the optional header\nfields. We can discuss if any of these groups should be included in the\ndefault compilation. There are still some non-essential header fields that\nremain in default like Server or Referer, maybe we can also make them\noptional.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/317#issuecomment-76591331.\n. @soc The only dependency in cookie that would bring in unicode stuff is url, and that is already a dependency of hyper.\n\n\nIf there are specific headers that don't belong in hyper because practically no one uses them, I'd approve their removal. However, I'm going to close this issue because of its broadness.\n. Some test failures. \n. Tried against master? I think a fix for this was merged in this morning (so\nhasn't been published via cargo yet).\nOn Tue, Feb 17, 2015, 12:34 PM maximih notifications@github.com wrote:\n\nI am trying to implement a custom HTTP header using impl_header macro from\nhyper crate but it seems it cannot resolve the hyper::header module.\nHere is my code:\n[macro_use] extern crate hyper;\nuse hyper::header;\nstruct CustomHeader(String);\nimpl_header!(CustomHeader, \"name\", String);\nAnd here is the compiler error:\n:11:14: 11:20 error: unresolved import header::HeaderFormat. Maybe a missing extern crate header?\n:11 Result { use header:: HeaderFormat ; self . fmt_header ( f ) } } }\n                           ^~~~~~\n:1:1: 11:67 note: in expansion of impl_header!\nlib.rs:4:1: 4:45 note: expansion site\nerror: aborting due to previous error\nCould not compile macro_issue.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/323.\n. An error about IntoCow, it looks like? And all those warnings about the\nchanged slice syntax will be errors in 'cargo test'...\n\nOn Fri, Feb 20, 2015, 11:58 PM Jonathan Reem notifications@github.com\nwrote:\n\nLooks like good work, but there is still another error.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/324#issuecomment-75356068.\n. @renato-zannon This is awesome, thanks! I realize this can be tedious work (updating for syntax changes).\n\nI've fixed the last remaining thing, and will merge the new PR that includes your commits and mine. I feel like the commits are sufficiently separated that they can be merged as-is, without squashing.\n. Merged as #329 \n. Excellent!\n. Good call, this would be needed to support XHR's removeHeader method.\n. See #324\nOn Sat, Feb 21, 2015, 9:32 AM maximih notifications@github.com wrote:\n\nI guess the note: write[..]instead are due to rust-lang/rust#22502\nhttps://github.com/rust-lang/rust/pull/22502.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/328#issuecomment-75374064.\n. As mentioned in #330, we should provide a method that accepts a float and creates a Quality. I'd even say that the implementation should be hidden from the user. There's no need to confuse someone that we use an integer to represent a rational. \n. That's fair, but it should be the \"for experts or performance needs\", not\nthe way we show everyone in the docs. It could be confusing that Quality(1)\nis not q=1, but instead q=0.001.\n\nOn Sat, Feb 28, 2015, 10:00 AM Pyfisch notifications@github.com wrote:\n\nAdded methods for float.\n@seanmonstar https://github.com/seanmonstar: I think we should provide\na method for the user to create Quality directly with an u16 since\nconverting to float costs a little time.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/332#issuecomment-76529342.\n. The 'Respone' argument is missing a mut keyword...\n\nOn Sun, Feb 22, 2015, 5:51 PM Aaron Miller notifications@github.com wrote:\n\nHere is what I am trying to compile (note the changes from what is in the\nreadme at present):\nextern crate hyper;\nuse hyper::status::StatusCode;use hyper::server::Server;use hyper::server::request::Request;use hyper::server::response::Response;use hyper::net::Fresh;use hyper::IpAddr::Ipv4Addr;\nfn hello(_: Request, res: Response) {\n    *res.status_mut() = StatusCode::Ok;\n    let mut res = res.start().unwrap();\n    res.write(b\"Hello world!\");\n    res.end().unwrap();\n}\nfn main() {\n    let server = Server::http(Ipv4Addr(127, 0, 0, 1), 1337);\n    server.listen(hello).unwrap();\n}\nThis gives the following error:\n$ cargo run\n   Compiling hypertest v0.0.1 (file:///home/rawr/dev/rust/hypertest)\nsrc/main.rs:11:6: 11:9 error: cannot borrow immutable local variable res as mutable\nsrc/main.rs:11     *res.status_mut() = StatusCode::Ok;\n                    ^~~\nerror: aborting due to previous error\nCould not compile hypertest.\nTo learn more, run the command again with --verbose.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/333.\n. I don't want to make the mock module part of the public API (I'd hate that improving hyper tests might be a breaking change). Also, since there's already a crate that provides this functionality published, I'll just close this.\n. Only possible thing I can think of is that you need to put extern crate rules inside your lib.rs (or main.rs if an executable).\n. We specifically haven't made that more ergonomic. It exists for the cases\nthat MUST use it, like in Servo to provide XMLHttpRequest. Otherwise, it's\nsafer to use the typed API. Mistakes will be caught at compile time.\n\nOn Tue, Feb 24, 2015, 12:04 AM Simon Bernier St-Pierre \nnotifications@github.com wrote:\n\nIs there a particular or technical reason why the API of set_raw takes a\nVec>? It would be a lot nicer to use if it also accepted strings.\nThis is something I'm willing to create a pull request for (with guidance),\nif you're interested in it.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/336.\n. You can easily create a simple header type using the impl_header! macro.\n\nOn Tue, Feb 24, 2015, 10:18 PM Simon Bernier St-Pierre \nnotifications@github.com wrote:\n\nPeople are probably going to use it anyway, it would be nice for it to\nhave a clean API. People should know the risks taken by using this method.\nFor instance, I'm currently working on a tiny library that gets your\nexternal ip address using UPNP. There is a mandatory header called\n\"SOAPAction\" whose value never changes. I have to take a &'static str and\nconvert it into a vector, and then put that inside another vector. I could\nalso create a custom header, but that would generate a lot boilerplate\nwhich is for the most part, unnecessary.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/336#issuecomment-75898501.\n. @reem that wouldn't change this particular issue. This issue would just be\nasking for a more ergonomic implementation of a Raw marker.\n\nOn Wed, Feb 25, 2015, 11:52 PM Jonathan Reem notifications@github.com\nwrote:\n\nI think we should move to marker types and get rid of this distinction.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/336#issuecomment-76122268.\n. I'd have put \"docs(readme)\" myself :) \n. At the moment, std::net::TcpListener has lost the ability to closed, which is what used to power this functionality. In order fix this, we would likely need some sort of channel that would send(Close), and the ListenerPool would need to recv on this channel to determine if it should continue listening. It would also need to close the listening port.\n. It now does do something on master.\n. The 0.10 branch is no longer seeing development. A way to shutdown servers that works is in 0.11. Fixing this is non trivial, and so likely won't be fixed. If someone would like to submit a change that fixes this in 0.10, a new release could be made.. Merged manually. \n. Looks great. If you could update the commit message to fix(rustup): str.split and associated types changesor similar, I'll merge. \n. Fixed via #340 \n. Needs a rebase\n. Well, perhaps not a rebase, but it uses older code (not passing a &mut NetworkStream).\n. Closing as stale.\n. Thanks, but this was fixed in #340 .\n. I just published 0.2.1 :)\n\nOn Fri, Feb 27, 2015, 8:58 AM Sebastian Thiel notifications@github.com\nwrote:\n\nBesides, would it be possible for you to publish a new release ? I am\nsuffering from this bug https://github.com/rust-lang/cargo/issues/1215\n:(.\nThank you\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/343#issuecomment-76397808.\n. I took a look at that site, here's what happening. It sends a response with\nSet-Cookie that is also a Redirect to /cookies. Since Client doesn't yet\nmanage a cookie jar for you, the cookies aren't sent to the redirected\npage, and are thus lost.\n\nFor now, you'd need to change the redirect policy, and read the cookies\nbefore following the redirect.\nEventually, having cookie jar support in the Client is desired.\nOn Fri, Feb 27, 2015, 4:08 AM \u262fneko notifications@github.com wrote:\n\nextern crate hyper;use hyper::Client;\nfn main() {\n    let mut session = Client::new();\n    let mut res = session.get(\"http://httpbin.org/cookies/set?k1=v1&k2=v2\").send().unwrap();\n    println!(\"{}\", res.read_to_string().unwrap());\n    println!(\"{}\", res.headers);\n}\n\u256d\u2500mindcat@mindcat-linux-pc ~/workspace/nekoneko  \u2039master*\u203a\n\u2570\u2500\u27a4  cargo run\n   Compiling nekoneko v0.0.1 (file:///home/mindcat/workspace/nekoneko)\n     Running target/nekoneko\n{\n  \"cookies\": {}\n}\nContent-Type: application/json\nContent-Length: 20\nAccess-Control-Allow-Credentials: true\nConnection: keep-alive\nDate: Fri, 27 Feb 2015 09:05:49 GMT\nAccess-Control-Allow-Origin: *\nServer: nginx\nNow, where is my cookies? :S\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/344.\n. @Byron sorry, I didn't mean to just shrug this off. I read @pyfisch's response and felt it was sufficient.\n\n\nAs for this specific case, I don't think Client nor RequestBuilder require traits. I don't believe they need to be generic over something. I'll show how I would imagine adding an Auth (and any other kind of extension) to the Client.\nSimilar in nodejs, where there is the request package on npm, and http as a standard module, I'd imagine people could build specialized clients on top of the one hyper provides. For instance, with request, you can write:\n``` js\nvar request = require('request');\nrequest.post({\n  url: 'https://example.domain/path',\n  auth: someAuthValue\n}).pipe(process.stdout);\n```\nI'd imagine a specialized client looking like this:\n``` rust\nstruct Client {\n    inner: hyper::Client,\n    auth: String\n}\nimpl Client {\n    fn request(&mut self, method: hyper::Method, url: url::Url) -> hyper::client::RequestBuilder {\n        self.inner.request(method,url)\n            .header(hyper::header::Authorization(self.auth.clone()))\n    }\n}\n```\nYou could imagine any sorts of options that a specialized client could handle, such as oauth, json, tunnel, gzip, hawk, multipart, etc. Actually, there is already a multipart crate using hyper.\n. I see. That's no fun carrying around that generic, since you don't care about it. Client could be changed to have Client { connector: Box<NetworkConnector>, .. } instead of being generic. That would mean dynamic calls instead of static dispatch for everyone, though.\n. Though, we already do this for Request and Response, for the exact same reason: so people don't have worry about the exact type of the Stream underneath... and it doesn't seem to be a source of slowness.\n. @reem i'm just about done with the patch. I found out from sfackler that the change was coming, and started working on it right away.\n. @reem yes progress. Everything compiles, just fixing up a couple broken tests. Should have PR shortly.\n. @John-Nagle Read is the new trait replacing Reader. You need to import std::io::Read, as it isn't part of the prelude. Then, you can use methods read, read_to_end, and read_to_string.\n. You can quite easily edit the Cargo.toml to set the openssl/cookie\nversions. This is how Servo handles things before upgrading rust versions.\nOn Sat, Feb 28, 2015, 4:44 AM Sebastian Thiel notifications@github.com\nwrote:\n\nThank you :) ! My change shouldn't even conflict with anything you cooked\nup in the meanwhile. If you merge, you'd just have to remember to undo my\nchanges to track the latest openssl. Seems doable, let's see what\n@seanmonstar https://github.com/seanmonstar thinks about that.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/348#issuecomment-76519305.\n. Sorry, I meant Cargo.lock\n\nOn Sat, Feb 28, 2015, 12:24 PM Sebastian Thiel notifications@github.com\nwrote:\n\nClosed #348 https://github.com/hyperium/hyper/pull/348.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/348#event-243788889.\n. You can edit the lock file, as I said that's what Servo does. You however\ncannot use 'cargo update' with it.\n\nOn Sat, Feb 28, 2015, 12:39 PM Sebastian Thiel notifications@github.com\nwrote:\n\nThat I tried in the very beginning - cargo would keep overwriting the\nfile, it seems it's not really supposed to be edited.\nCargo.toml works fine though.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/348#issuecomment-76536407.\n. Standard way is usually with some sort of 'new' method, which does exist.\nHowever, it doesn't hurt to add a Default impl.\n\nOn Sat, Feb 28, 2015, 7:56 AM Sebastian Thiel notifications@github.com\nwrote:\n\nTo my mind, the standard way in Rust to instantiate something without any\narguments is handled by the Default trait. Types implementing it can be\naggregated, allowing the aggregator to simply use #[derive(Default)].\nI think Client should implement it, and there might be other hyper-types\nwhich would need such an implementation as well.\nVec::default()\nhttp://doc.rust-lang.org/collections/vec/struct.Vec.html#method.default\nmight be a good starting point for this.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/351.\n. 1. The 'a lifetime means that the value needs to live at least as long as some time 'a. The time period is not the lifetime of the entire Client. A Client can make many requests, and doesn't need to keep around a body forever. The body only needs to live as long as it takes for the Client to write it into the request body. So, you'd be best confining the lifetime to a function, where some borrowed body (like &str) can live for as long as the function executes, writing the body to the request, and then releasing the borrow.\n\nI recommend reading up on ownership and lifetimes. I'd also recommend asking questions such as these on StackOverflow, as they are more general about Rust, and there are more people around to provide you an answer more quickly.\n2. If feasible, you should create one Client, and use it for all requests (unless you need clients with different behavior). Once #41 is completed, the Client will include a ConnectionPool that will allow subsequent requests to use the same connection, making things much faster.\n. @reem rebased.\nInteresting to note: speed improvements with the client_mock_tcp bench is over 500%.\n```\nBEFORE\ntest bench_mock_hyper ... bench:    280059 ns/iter (+/- 62609)\nAFTER\ntest bench_mock_hyper ... bench:     50152 ns/iter (+/- 5771)\n``\n. If there's no real problems, I'd like to merge so we can unbreak people on crates.io...\n. Alright, I updated the REAME to work, and renamed that odd function. Once travis hits green, I'll merge. (sorry those using git rev's, I probably broke you because of my force-push)\n. Needs a rebase. Closing for now.\n. Good point!\n. Ah, it seems Github doesn't use\\r\\nfor line endings. Shame on Github, spec says they should. Shame on hyper, spec says it should be robust enough to accept just\\n`.\nI've been working on a new parser that already handles this.\n. The design of hyper is such that you can provide a custom connector or listener (client or server), which helps specific app needs, but also allows testing implementations to exist. Perhaps multiple mocking crates will exist at some point.\nFor now, the mock module in hyper isn't exported because I wasn't sure it was any good. I certainly didn't want to stabilize on it (and have people's libraries break if I change it). I'm undecided which way is better.\n. If I were to expose the the mock module and remove the #[cfg(test)], then rustc would compile it. However, llvm (or the linker) should kill dead code, so I wouldn't worry about that myself.\nMy concern is: I'm certain I'll want to add things to mock as hyper grows/matures, and eventually adding more things will make me want to refactor some of it. If it's part of a public API, then I have to worry about breaking people's tests. I don't want to feel hesitant to improve the testing of hyper itself.\nIn the mean time, @Byron has published a crate of the current mock module that you can use: https://crates.io/crates/yup-hyper-mock\n. cc @jamwt \n. blocks #41 \n. Is it difficult to match the Url with the error? It's a sync function\ncall...\nAlso, perhaps that information could be included in std::net?\nOn Sun, Mar 8, 2015, 9:36 AM Josh Matthews notifications@github.com wrote:\n\nIt would be nice if printing out an HttpIoError showed the problem\naddress: HttpIoError(IoError { kind: OtherIoError, desc: \"unknown error\",\ndetail: Some(\"Name or service not known\") })\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/364.\n. Closed?\n. This isn't a bug in hyper; this is the Rust compiler trying to tell you that you have a dangling pointer somewhere.\n\nLooking in your code, I notice that you take a reference to the String inside AbsoluteUri, and then create a Uri that contains &strs pointing at that String. The original String lives in the orig_uri variable on the stack of that function. Once the function terminates, returning the Request, the orig_uri is destroyed, and your Uri would be left with invalid pointers.\n. The current IO doesn't provide a way to specify a timeout, which makes this harder.\n. Timeouts won't be supported by TcpStreams until Rust 1.1, which would be\nmid June. To support timeouts in hyper earlier, we'd need to explore using\nan additional thread, but it's performance may suffer too much.\nIn the mean time, I suggest putting nginx in front of your server, which\nhandles this well.\nOn Sat, Apr 18, 2015, 10:24 AM Young Woo notifications@github.com wrote:\n\nWhen will this bug be fixed? timeout should be an urgent feature.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/368#issuecomment-94184696.\n. I'm thinking of turning keep-alive off by default for hyper 0.6 servers, which is probably the right thing to do, and let people who have a solution turn it back on. However, that's a logical breaking change, even though code will continue to compile...\n\nThinking of adding something like this to keep the current behavior:\nrust\nServer::http(addr).unwrap().keep_alive().listen(handler)\n. @juanibiapina the best solution is asyncio, tracked in #395. With synchronous IO, your only options are  1) set a timeout, which can be done currently, but still means the connection could block to the full length of the timeout, or 2) don't try to read on kept-alive connections.\n. I'm going to try the way Apache does it: if you want keep-alive, a timeout will be used when trying to read on the kept-alive connection. This is really the only thing that is possible on blocking sockets.\nrust\nserver.keep_alive(Duration::from_secs(5));\nserver.listen(...)\nOf course, this will require activating the timeouts feature in hyper, and requires rustc v1.4 or greater.\n. Proposed fix is in https://github.com/hyperium/hyper/issues/661\n. On IRC, @reem pointed out to me that it's possible to do a little more in this area. With the timeout solution, a scenario is still possible that all the threads are used to each deal with a connection that is using keep-alive, and even though they aren't blocked by a stalled connection, while they are active no other connections can be handled.\nI'm not sure if this scenario should still be considered part of this bug, or more of a general improvement. Also, once non-blocking io is merged, this issue goes away automatically.\nA solution here would be to have an acceptor thread, and a work queue. The acceptor would push all TcpStreams into the queue, and the workers would process 1 request/response pair. If keep-alive is true, that Stream could be placed at the back of the work queue.\n. Hmm. Hyper is using a BufReader, which by default uses 64kbs. Is it significantly bigger than that?\n. Could you try using String::with_capacity(1024) or whichever the size is, and see if that affects things. i'm trying to think where in hyper it might be doing something.\n. Also, would be neat to see actual time values. 1000 bytes can be the size of packet in some cases, so it could just be doing an additional sys call to read the end.\n. Thanks for finding out the real issue! To fix this, I'd imagine adding a check_continue method to the Handler trait, with a default implementation of just writing continue, and checking for an Expect header in the server loop. This allows it to just work, and allows someone to override the behavior if they need to.\n. @reem according to RFC7231:\n\nAn origin server MUST, upon receiving an HTTP/1.1 (or later)\n   request-line and a complete header section that contains a\n   100-continue expectation and indicates a request message body will\n   follow, either send an immediate response with a final status code,\n   if that status can be determined by examining just the request-line\n   and header fields, or send an immediate 100 (Continue) response to\n   encourage the client to send the request's message body.  The origin\n   server MUST NOT wait for the message body before sending the 100\n   (Continue) response.\n. What do you mean they are rewritten as normal dependencies?\n. It could be an Option on the Client struct. Default is Some(\"hyper\"), and a set_user_agent method could be used to change it. \n. Looking through Clients in other languages (nodejs, Python, Go, libcurl), a default user agent is not sent. To send one, the user must be explicit about it.\n. Thanks! \n. I don't think an extensions or whatever map needs to be on Client. Any extensions desired can be handled by a higher level Client, as https://github.com/hyperium/hyper/issues/346#issuecomment-82574384 states.\n\nModifiers may make creating a new Client more ergonomic, as opposed to one-off methods like set_redirect_policy, but without an extensions map to edit, they lose much of their worth.\n@pyfisch The goal is to provide a fast, correct, and safe implementation of HTTP. I'm less interested in including specializations that only some people need (when I look at npm's request package and see hawk and aws options, I shudder). It should be ergonomic to use, such that if someone thinks \"Hey, I need to make some HTTP requests\", they can use hyper without wanting to faceroll their keyboard.\n. RequestBuilder is no more (on master).\n. @reem done\n. It seems the removal of std::net::IpAddr was a mistake, and they're adding it back in...\n. Seems I forgot the last step of pushing the version to github.\nOn Sat, Mar 21, 2015, 11:53 AM Nathan Fuchs notifications@github.com\nwrote:\n\n0.3.2 in crates.io\n0.3.1 in github\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/385.\n. Oh awesome!! \n. Found the bug in libtime, PR going out.\n\nOn Sat, Mar 21, 2015, 1:52 PM Jonathan Reem notifications@github.com\nwrote:\n\nCrash:\ntest header::common::date::asctime::bench_format                    ... thread '' panicked at 'called Option::unwrap() on a None value', /Users/rustbuild/src/rust-buildbot/slave/nightly-dist-rustc-mac/build/src/libcore/option.rs:362\nstack backtrace:\n   1:        0x106790d1b - sys::backtrace::write::hadb1455a57ee2267A7C\n   2:        0x106794ef0 - panicking::on_panic::hb14107ef264d170efXI\n   3:        0x10677e8c9 - rt::unwind::begin_unwind_inner::h8da2f07c00df904aZFI\n   4:        0x10677ed6e - rt::unwind::begin_unwind_fmt::h4dcac22814383ddeAEI\n   5:        0x1067948bd - rust_begin_unwind\n   6:        0x1067b5605 - panicking::panic_fmt::h0cef144388ee69a7fXA\n   7:        0x1067b4c24 - panicking::panic::h0e23dba589607f39MVA\n   8:        0x1066d576c - header::common::date::asctime::bench_format::h6bb8790420198935qvf\n   9:        0x10674adec - run_test::h74d8a6e95a77932bpWb\n  10:        0x10673b49d - run_tests_console::h5c31b6e8434b20dewFb\n  11:        0x10673763d - test_main::hf14c6d56f0996c7co1a\n  12:        0x10673e51d - test_main_static::h49536edee5bf0e77Z3a\n  13:        0x10670931b - __test::main::hd9bb0629fdb2cbdcNrp\n  14:        0x106796348 - rust_try_inner\n  15:        0x106796335 - rust_try\n  16:        0x1067958bd - rt::lang_start::h4ae346b42cf882d8XRI\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/387.\n. They should work now with time updated. \n. True, I was hoping that the BufReader would fill it's entire buffer before yielding, which by default is 64kb. Is the test server head bigger than this? Or BufReader is yielding earlier?\n. We agree. We're actively looking into it. Mio looks promising. We also need\na Windows library, and a wrapper combining the two.\n\nOn Tue, Mar 24, 2015, 6:06 AM Jarred Nicholls notifications@github.com\nwrote:\n\nHyper would be far more powerful of a client & server if it was based on\ntraditional event-oriented I/O, single-threaded or multi-threaded. You\nshould look into https://github.com/carllerche/mio or a wrapper around\nlibuv or something of that sort.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/395.\n. I don't have a vision; I haven't looked that hard into how mio works. I'd love to hear suggestions.\n. I've been investigating mio support, and fitting it in was actually pretty simple (in a branch). I may continue the branch and include the support with a cargo feature flag, but I can't switch over completely until Windows support exists.\n. Not yet. It doesn't use an event loop yet, I simply switched out usage of\nstd::net with mio::tcp. Which works fine for small requests that don't\nblock...\n\nOn Mon, Jul 27, 2015, 8:56 AM Tal Levy notifications@github.com wrote:\n\n@seanmonstar https://github.com/seanmonstar is this branch public\nsomewhere?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/395#issuecomment-125253301.\n. That actually sounds quite feasible. I'll think more on the relationship between the 2nd and 3rd crates. But the first crate sounds simple enough: method, uri, status, version, and headers. Need a proper name, and to figure out the least annoying way to publish multiple crates at a time.\n. I'd like to push a branch up with a mio feature. To start, I think hyper should be agnostic to what sort of IO abstraction is used, whether it's with callbacks, promises, streams, or whatever. To do that, I imagine this list is what I need to implement (still reading mio docs, so help would be appreciated):\n- Evented for server::{Request, Response, Server}\n- Evented for client::{Request, Response}\n- trait NetworkStream: Evented (+ others) {}\n\n\nHyper does do some reading and writing uncontrolled by the user, such as parsing the a request head, before handing it to server::Handler. So perhaps internally hyper will need to pick a way to handle async reads/writes.\n. The adventurous can try out the mio branch. The 2 server examples work, but a ton is missing. Also, just to get things moving, I chose to use eventual to provide the asynchronous patterns.\nMissing:\n- Keep alive\n- timeouts\n- the entire Client\n. @Ogeon no, but alexcrichton has been working on windows support in mio, so it's coming. https://github.com/carllerche/mio/commits/master?author=alexcrichton\n. @Ogeon I'm sure you will (bump into problems). :)\n. @tailhook \n1. The strategies of using blocking io and an event loop are quite different, and so supported both is complicated. It's a whole lot easier to implement a sync API using the event loop, by just blocking on the Future. Also, I'm currently just trying to get it working, and worrying about the rest after.\n2. How are you benchmarking? Also, so far, this version of the Server is only using 1 thread, whereas the Server in 0.6 uses threads that scale to your cores. Using more threads (and more event loops) could probably help. However, my super simple ab checking hasn't showed such a slow down (though my test machine has 1 core, so it doesn't use multiple threads in the sync version).\n. Update: current mio branch no longer using futures, and seeing a significant performance improvement. My linux box has horrible specs, so I won't post benchmarks from it.\n. Ah, woops. I've been doing all this work on nightly, and that syntax is allowed on nightly, but not stable yet. I'll try to push soon such that it builds on stable.\n. @tailhook \n\nI'm curious why the difference is so drastic without futures? Is it because of inlining, or because of the different structure of the code? Is it just overhead of lambdas? \n\nI never profiled, so I can't say for certain. Some things I can guess about: eventual::Future has to store the callbacks as Box<Fn> internally, which means allocations (likely tiny), and dynamic dispatch (likely medium). Additionally, the core of the Future uses atomics to keep it in sync, which makes sense, but just wasn't necessary in the event loop, where it was all on a single thread.\nThis isn't to say Futures are bad, just that they aren't a cost-free abstraction, and the abstraction wasn't worth the cost in this case. I'm still considering exposing higher-level methods on Request and Response that use a Future, such as req.read(1024).and_then(|bytes| { ... }), which would have the Future tying into the events in the event loop.\n\nBy the way code looks super-similar to what I've written about and working on. And it would be nice to join the effort. So have you seen that? Does you see any inherent flaws in what I'm doing? Or does the absence of documentation is the main cause that stopped you from using my library?\n\nMy main inspiration when writing the tick crate was Python's asyncio. I did see that rotor seemed to in a similar vein, but I wrote tick for these reasons:\n- This branch has been all about fast prototypes to test ideas, and so I wanted to be able to tweak the event loop design as needed.\n- I wanted the ability to pause transports, which I see is a TODO in greedy_stream :)\n- The amount of generics I saw trying to read rotor's source left me often confused.\nI'm sure our efforts could be combined in this area. My main reason here was to be able to prototype while understanding what's going on internally, instead of needing to ask on IRC.\n. @tailhook actually, I think there could be some performance gains if some reading and writing directly to the stream could be overridden. (From tick's perspective).\nrust\ntrait On<T: Read + Write> {\n    fn on_readable(&mut self, socket: &mut T) -> io::Result<bool>;\n    fn on_writable(&mut self, socket: &mut T) -> io::Result<()>; \n}\nI know in hyper, implementing this instead of Protocol::on_data would prevent a copy, since hyper still needs to parse the data as possibly chunked, and could skip the intermediary buffer that Protocol provides. Likewise when writing, since hyper may need to wrap the data in \"chunks\".\nThe cool part about all this stuff, is that I believe it can be contained in the event loop and hyper's http module, without affecting user-facing API in Request/Response. It would just get faster.\n. Yea! I'll be meeting with @carllerche tomorrow to discuss my WIP integration, and hope to have usable versions soon after.\n. @tailhook very cool! The rotor-http state machines look very similar to what I'm developing for hyper. One difference I have is giving direct read and write access to the underlying socket, since that's a requirement another use case has for eeking out as much control as possible.\n\nFor hyper, I'd settled on an internal state machine, with callback-style Request and Response APIs to interact with it. You can see it in the current mio branch. The examples/hello.rs fairs much better in benchmarks than master.\nHowever, on my machine, it was still performing at around 60% of my ideal target (a super simple state machine that ignores https semantics). I want hyper to be a low level HTTP library for Rust. People shouldn't be skipping hyper because it's not fast enough. At a recent Mozilla work week, others expressed interest in building a reverse proxy that could actually compete with nginx. If hyper cannot help to do that, then someone will just have to re-implement HTTP all over again, but with less costs.\nThis does mean the ergonomic API for Request and Response will have to become a little less ergonomic, but don't fret! I've prototyped similar APIs on top of this state machine approach, and it wasn't hard at all to do. Even blocking IO was quite simple to emulate, using threads and channels.\n. @tailhook \n\nCurrent rotor core library gives direct access to the socket. \n\nOh neat! I hadn't really noticed you split the code into rotor and rotor-stream. I'll have to take a look at the split. I had mostly looked through rotor-http when writing my last comment.\n\nCould you give some insight on a use case you are talking about?\n\nYep. The WebPush team at Mozilla has to run servers where every single instance of Firefox must keep an open socket to the Push server. They want to reduce cost, and are thinking Rust can help do that. They want as little memory usage as possible for every connection, so that means controlling every allocation, including buffers used to read and write.\n\nWell, that script linked gives 600k requests per second on my laptop, comparing to 65k for nginx.\n\nHa, well then I'm sure part of it is the terrible machine I'm running these benchmarks on. I'm using a small Linode VM with 1 core and 1GB of RAM. When running the Tick example, i get around 18,000 requests per second. The hello server in hyper's mio branch gets me around 12,000. I'd love to bench on my desktop with all its cores, but I use Windows, and wrk won't run on that...\n\nI doubt that blocking IO for servers is something useful.\n\nI agree. Blocking servers is almost never useful. I've just seen people beg that the option still be there. And I meant also that it's not hard for a callback API, or Futures, or whatever to be built on top.\n. Here is the current hello.rs and server.rs examples in the wip branch. It doesn't look as elegeant as a blocking, synchronous API, but it does give the performance. On my terrible build server, a wrk bench shows ~9% more requests per second than the branch using callbacks.\nAnd again, it's possible to build higher level APIs on top of this. This just gives the performance to those who need it.\n. I've (force) pushed to the mio branch, which has the server examples working. I've also been following rotor's development, and feel like it and my current branch are at a point that I could switch out the internal use of 'tick' to 'rotor', with basically no change to the exposed API. This would just reduce duplicate effort in state machine development.\n. @alubbe yes, hyper is probably going to stop guessing at how many threads to use, and instead let the user decide to run servers in as many threads as they'd like. I could add that to the hello.rs server example, I suppose.\n\nSwapping in rotor was actually pretty quick work (besides the time I've spent reading the source of rotor to understand it's concepts). As I said, it didn't change the Server api at all.\nOne thing that I noticed, but it could be just my terrible test machine: the swap to rotor meant my benchmark lost ~1-2% in requests per second. Maybe a proper production machine wouldn't notice this. If it did, I imagine the difference is that perhaps some function didn't get inlined, or something else minor that I'm sure we can fix. If you wish to look yourself, you can compare the current mio branch with the current mio-rotor branch.\n. Excellent. Like I said, it's probably that my test Linux box is complete\njunk.\nWell, I couldn't find the docs hosted, so I had to resort to the source.\nBut, even with docs, I like reading source. I'm a weirdo who likes to pick\nmodules from the rust repo for some good-night reading in bed.\nOn Mon, Feb 1, 2016, 4:41 PM Alberto Leal notifications@github.com wrote:\n\n@tailhook https://github.com/tailhook A state diagram to visualize the\nrotor API might be a good start. On earlier iterations of rotor, I had to\ndraw out state diagrams to grok the API.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/395#issuecomment-178274584.\n. @yazaddaruvala there's 2 ways that may appear. If it occurs while waiting for readable or writable, then the event loop will notice. hyper will call Handler::on_error(Error::Io(e)). If the socket has already triggered a readable or writable event, and thus the handler is trying to read or write, then that will likely trigger an io::Error during read or write.\n. @Ogeon there were no side effects to them being changed, I've just seen people in IRC make changes to the Request when they meant to change the Response, and were left confused why nothing happened. The change to making the fields private was to prevent people from doing things that did nothing.\n\nI'm surprised you need to inject the Host header into requests. HTTP/1.1 is pretty clear that clients must include the Host header.\nPerhaps a deconstruct method would be warranted, that would return a tuple of the internal fields. That should be clear that modifying it won't do anything, but still allow you to do so if you really want?\n. @Ogeon hyper does not check for the Host header. \n\nWhat happens with the request body if the handler decides to return Next::end() before reading it? Will Hyper take care of it automatically?\n\nIf the Handler ends, no more reading is done. (Reading only happens when the handle calls decoder.read() anyways). If there is still bytes waiting (determined by whether there was a Content-Length header, or if chunked, if there was a 0\\r\\n\\r\\n sequence already read), then the socket will not be used for keep-alive.\n. @Ogeon hyper has not automatically read the body. The problem with that is what to do when someone POSTs a 4GB file to your server. If hyper were to automatically read the whole body, that'd block the server for a while, and waste bandwidth. Deciding on a proper maximum size to automatically read is difficult, so hyper has so far chosen that all reading must be done by the user.\n. Have you updated recently? I hit a similar error this morning, and fixed it\n(at least in my case), and pushed.\nOn Sat, Mar 26, 2016, 12:51 PM Erik Hedvall notifications@github.com\nwrote:\n\n@seanmonstar https://github.com/seanmonstar I have bumped into a\nproblem with zero sized response bodies. I don't know if it's intentional,\nbut it seems like I have to call encoder.write(...) at least once for the\nresponse to be properly sent. It will otherwise result in \"empty response\"\nerrors.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/395#issuecomment-201919390\n. @Ogeon I believe I've not fixed this on the branch.\n. @Ogeon As I should have done, I've added a test in the server tests for that exact instance, and I can now say it is fixed.\n\nAs for read errors, you mean errors printed by env_logger from hyper (that the socket closed?), or the read errors reported directly from wrk? The former, I've fixed (it was a useful error log when first working on the branch). The latter, I haven't seen in a long time.\n. Hm, read errors from wrk are reported each time 'read(fd)' returns -1. Does\nthat mean the sockets may be closing before having written the end of the\nresponse?\nI don't see this in the hello world server example in hyper. What response\nare you writing? Headers and body?\nOn Thu, Mar 31, 2016, 3:54 AM Erik Hedvall notifications@github.com wrote:\n\n@Ogeon https://github.com/Ogeon As I should have done, I've added a\ntest in the server tests for that exact instance, and I can now say it is\nfixed.\nAh, nice! I can confirm that it works now.\nAs for read errors, you mean errors printed by env_logger from hyper (that\nthe socket closed?), or the read errors reported directly from wrk? The\nformer, I've fixed (it was a useful error log when first working on the\nbranch). The latter, I haven't seen in a long time.\nIt's directly reported from wrk. It can look like this for my hello_world\nexample, after a run with 456888 requests:\nSocket errors: connect 0, read 456873, write 0, timeout 0\nIt looks like it's not one for each request, so I'm not really sure what\nwould trigger them. Could it be something I have missed, when?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/395#issuecomment-203876959\n. @Ogeon hm, I am able to reproduce if I wait() and spawn a thread to call ready(), as you say. When I make a tiny Rust program to open a tcp stream, write a request, and read a response, I don't get any io errors, or reads of 0. Can you see something else here that would make wrk goto error: https://github.com/wg/wrk/blob/master/src/wrk.c#L426-L448\n. It looks like they forgot to check errno in sock_read to return RETRY, and\nso the EAGAIN error is being reported as a read error.\n\nOn Sat, Apr 2, 2016, 4:03 AM Erik Hedvall notifications@github.com wrote:\n\nHard to say. The error conditions seems to be either a network error\n(return -1), a 0 read before finishing the response, or some failure in\nhttp_parser_execute. There shouldn't be anything to read (unless the\nerrors appears when data is finally received), so the only logical failures\nwould be the network error or the 0 read, given that http_parser_execute\nreturns the number of parsed bytes. It's quite complex\nhttps://github.com/wg/wrk/blob/master/src/http_parser.c#L627, though,\nso it's hard to say exactly what happens. Either way, 0 reads will still\ncause problems.\nIf it does read something, then the problem should be caused by something\nin http_parser_execute. It's huge and has many jumps to error\nhttps://github.com/wg/wrk/blob/master/src/http_parser.c#L2069, but it\nlooks like it would report those errors to the user.\nI tried to pass the --timeout 10s option, but that didn't make a\ndifference. That should show up in the timeout counter, instead, so I\ndidn't really expect anything.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/395#issuecomment-204694576\n. It may help to edit the async example to spawn a server in several threads, so as to compare to the master example which is using 1.25 threads per cpus.\n. @Ogeon It was indeed a bug. I added the use of an AtomicBool to reduce the amount of usage on the mio's bounded queue (to reduce errors from it being full), and had an incorrect if check. Fixed.\n. @Ogeon ah, I hadn't noticed that the OpensslStream type wasn't being exported. Just doing that should be enough, right? Then for https, (if you wish to utilize only openssl), you could use HttpsStream<OpensslStream<HttpStream>>.\n. @erikjohnston yep, I know about it. I haven't handled it yet, as I slowed down trying to design a generic way for the Transport trait to report it, and moved on to other pieces that were missing. I won't ship the version without getting that in place, however.\n\n\nBasically, my initial thoughts were something like this:\n``` rust\ntrait Transport {\n    // ... \n    fn blocked(&self) -> Option {\n        // default implementations assume nothing special\n        None\n    }\n}\nenum Blocked {\n    Read,\n    Write,\n}\n```\nThe blocked method could be checked by the event loop when deciding what events to listen for. If the result is Some, the event will be added to the event list.\nSo an implementation for openssl could do something like this:\n``` rust\nstruct OpensslStream {\n    stream: openssl::SslStream,\n    blocked: Option,\n}\nimpl Read for OpensslStream {\n    fn read(&mut self, buf: &mut [u8]) -> io::Result {\n        match self.stream.ssl_read(buf) {\n            Ok(n) => Ok(n),\n            Err(openssl::Error::WantWrite(io)) => {\n                self.blocked = Some(Blocked::Write);\n                return Err(io);\n            },\n            // ...\n        }\n    }\n}\n```\nDoes this seem like it would work for any other transport implementation, like schannel or security-framework? @sfackler @frewsxcv \n. @sfackler well, the stream is present to the Handler as T: Read or T: Write, so user code would be using those traits. This design was to hopefully remove the need for a Handler to notice if the underlying stream protocol needed to read, even if the user just wants Next::write() a bunch.\n. I can't merge this? Did you start from an older master?\n. I've included this in #403 \n. Excellent, thanks!\n. Thanks! it looks like a fair amount of .as_slice() and .to_vec() need to be changed as well.\n. Yes please.\n. Excellent, thank you!\n. What do you mean cache it? Travis wipes it out at some point?\n. Thanks! I wonder, if slice_patterns aren't going to be stable for beta/1.0,\nwe should probably not use them. I think they're only used in the\nauthorization header, and shouldn't be too hard to switch it to a few if\nclauses.\nOn Sun, Mar 29, 2015, 9:18 AM Florian Hartwig notifications@github.com\nwrote:\n\nAmended commit message to make gitcop happy.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/404#issuecomment-87435032.\n. With beta this week, those comments don't assure me. If you could remove\nthe patterns, awesome. Or I can a little later.\n\nOn Sun, Mar 29, 2015, 9:57 AM Florian Hartwig notifications@github.com\nwrote:\n\nrust-lang/rust#23121 https://github.com/rust-lang/rust/issues/23121\nsays that they hope to have it ready for the beta release, but I'm not sure\nif that still applies. I can re-write the function to avoid slice patterns\nif you like.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/404#issuecomment-87443730.\n. Hm. So, it can't be as simple as client.get(\"*\"), since the Url is currently used to find the address to connect on. Before worrying about the Client, and just thinking of about Request, it could probably use a set_uri method, that would allow adjust which RequestUri was used when building the request line. This would enable:\n\nrust\nlet mut req = Request::new(Method::Unregistered(\"M-SEARCH\"), \"http://239.255.255.250:1900\");\nreq.set_uri(RequestUri::Star);\n. @pyfisch This is superb! Just one minor comment.\n. It seems it's a target specific dependency in openssl:\nhttps://github.com/sfackler/rust-openssl/blob/master/openssl-sys/Cargo.toml\nOn Mon, Mar 30, 2015, 12:36 PM Jonathan Almeida notifications@github.com\nwrote:\n\nI'm curious to know how others are building hyper or if I've done\nsomething wrong in my build process.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/411#issuecomment-87801910.\n. Could you run again with RUST_BACKTRACE=1?\n\nOn Tue, Mar 31, 2015, 7:15 AM Coda Hale notifications@github.com wrote:\n\n\nhyper 0.3.6\nrustc 1.0.0-nightly (6cf3b0b74 2015-03-30) (built 2015-03-31)\nLinux 3.14.35-28.38.amzn1.x86_64 #1\n  https://github.com/hyperium/hyper/issues/1 SMP Wed Mar 11 22:50:37\n  UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\nwrk @ a209691\n\nI\u2019m using the hello-world example from the examples dir. This only\nhappens with release builds, and it only happens after a number of\nsuccessful requests:\nthread '' panicked at 'Vec::reserve: usize overflow', /home/rustbuild/src/rust-buildbot/slave/nightly-dist-rustc-linux/build/src/libcore/option.rs:332\nthread '' panicked at 'child thread None panicked', /home/rustbuild/src/rust-buildbot/slave/nightly-dist-rustc-linux/build/src/libstd/thread/mod.rs:797\nthread '' panicked at 'child thread None panicked', /home/rustbuild/src/rust-buildbot/slave/nightly-dist-rustc-linux/build/src/libstd/thread/mod.rs:797\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/412.\n. Perhaps fixed in 0.3.7?\n. I love it.\n. So, something happened with the last rustup. My benchmarks are all ~10x faster. I can't explain why. The changelog in cargo and rust don't easily show a reason.\n\nAnyway, Before/After is 35524/37852.\n. Yep, the removal of timeouts from std means we don't have an easy way to do this. cc #315 \n@jimmycuadra as for debugging, you could set up a logger (such as env_logger, or log4rs). With env_logger, you could use RUST_LOG=hyper to get the full firehose of logs.\n. Thanks!\n. Sweet! And also, the change in docs: wtf. (I know it's not your fault).\n. Oh, also, the commit syntax is actually BREAKING CHANGE:, without the underscore.\n. can't merge\n. There was a problem?\n. Also cc @Byron \n. Yea, I didn't want to Box in Request if the Stream was already boxed in Client. It works out in the end.\n. Thanks! \n. When will this fix be included into beta?\n. This failure is actually cause cookies is hardfixed to an older openssl version...\nI still want to make a cookies lib that doesn't depend on crypto (that should be a lib added on top).\n. Yep, this a duplicate of #368. You have 1 thread handling connections, and our current keep-alive loop will keep trying to read on the socket until a Connection: Close header is received, or EOF. It's common of browsers to open a connection to a server, and keep it alive for several minutes for any additional requests that may be needed. This means that 1 thread is busy trying to read on the 1 connection, until the browser closes it, and then the server can handle all the other requests that piled up.\n@reem has been working on a Queue of sorts that will still have keep-alive support, but will try new incoming requests before continuing to read from a keep-alive connection.\n. Im going to close this as a dupe, but it's definitely a real bug that we wish to fix!\n. I would like to do this, definitely. I wonder if we'll break many people with the removal of the cookie jar support. I know servo has a bunch of cookie code, but looking through it, I think they can simply change extern crate cookie to use hyper::header::shared::Cookie (@jdm right?).\nThough, ultimately, I'd like to put this in the cookies crate.\n. Indeed. Mostly, I've just wanted the Cookie parts, and leave the cookie signing to another crate.\n@alexcrichton Would you be interested in having cookie-rs broken up? If you, we could work together on that, and not do this. If you'd rather keep cookie-rs the way it is, that's fine too.\n. Just restarted travis.\n. Thanks for this!\n. Any more details? This test case in hyper https://github.com/hyperium/hyper/blob/master/src/client/response.rs#L140 should mean that the chunked reader works...\n. Looking at the python some more, I don't think it's outputting proper chunked data.\n1. It's including the ending CRLF as part of the chunk size, but that's not what the spec says.\n2. It's reporting the chunk size as a decimal, but it's supposed to hexidecimal. So, when it claims the 3rd line is 27, hyper reads that as 0x27.\n. This is a bug in web-platform-tests. See https://github.com/w3c/web-platform-tests/pull/1736\n. The main point is that to you, implementing fmt::Display for Headers seems wrong, since Headers doesn't always contain UTF-8? This may be true, but I'd like to see farther into the design of how to support non-UTF-8 printing before making a merge like this.\n. The idea makes a fair amount of sense. I'll recap:\n- Headers from new Clients and Servers today should use only ASCII.\n- Some existing implementations may exist that use non-ASCII headers.\n- When writing Headers in hyper, we 99% of the time writing explicit Headers set by the user, and they should know better to use ASCII.\n- When we receive Headers, it's not a requirement that they be in ASCII. It is possible to inspect non-ASCII headers via the raw representation.\n- The only time we should be needing to write back out non-ASCII headers is in proxying situations: The proxy has received some headers that include non-ASCII, and we must write the Header exactly as we received it, not losing data.\n- Because of this 1 scenario, we cannot use fmt::Display to do so, since that library type is required to output UTF-8 Strings; the header could be any encoding.\nOne thing I'd like to solve in this proposed design is encoding to Vec<Vec<u8>>. This means 2 allocations for every header, that will be promptly thrown away. Perhaps we could pass a &mut std::io::Write or something. Most Headers could continue to use write!(wrt, \"{}\", self), since std::io::Write includes a write_fmt method. The few outliers could use write(&[u8]).\n. Reem and I were just talking about this last night, and I want to press on\nit. Still trying to think of a good way to handle Set-Cookie.\nOn Sat, May 16, 2015, 4:02 AM Pyfisch notifications@github.com wrote:\n\nClosed #442 https://github.com/hyperium/hyper/pull/442.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/442#event-306438577.\n. Thanks!\n. Forgot a colon feat(net): in commit message. GitCop said it, not me!\n. Specifically, I see that scoped threads join will panic, where spawned threads join returns a Result.\n. What do you mean? This issue should be fixed. Is another panic occurring?\n\nOn Mon, Dec 7, 2015, 1:49 PM Evgeniy OZ notifications@github.com wrote:\n\nI'm not sure if it's hyper's issue,but maybe somebody will be kind enough\nto show code how to catch that Poisoning Error? Would be awesome to kill\njust one thread and let others to work. Or terminate, at least.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/447#issuecomment-162639099.\n. So excite. \n. @mlalic sorry, been busy. I'll look it over again today.\n. @mlalic I know Servo uses Request::with_connector, cause the XHR spec defines some fun rules slightly different than standard HTTP. /cc @Manishearth \n\nI have a Pool implementation in #486. That would allow keeping the requests around, and having h1 -> h2 upgrade functionality.\nWhat did you think of my previous suggestion of keeping Client, Request, and Response as opaque structs, and having the trait be a HttpMessage, implemented by http1 and http2? I'd like to think this would ease implementing on the server as well...\n. I'll expore in a branch to show what I mean.\n. Pretty much exactly. As long as such a trait could work for http2, of\ncourse.\nOn Mon, May 25, 2015, 3:56 PM Marko Lalic notifications@github.com wrote:\n\n@seanmonstar https://github.com/seanmonstar I have an experiment over\non this branch\nhttps://github.com/hyperium/hyper/compare/master...mlalic:http-message\n(forked off the current master HEAD, not this PR) refactoring the\nHTTP/1.1-specific parts of Request/Response into an implementation of an\nHttpMessage trait, such as what you described.\nIs this sort of what you had in mind for the HttpMessage API?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/448#issuecomment-105331881.\n. Sorry, I was camping this weekend (so no Internet), but this looks exciting!\n. Just curious, from the example: \"Host\": \"http2bin.org,http2bin.org\",, is it supposed to have the host doubled like that?\n. @mlalic woo! thanks for this herculean effort!\n. Found the reason why. Since we moved to container-based testing, the part pushing the docs (which used sudo) was not longer working. I've updated it to use a --user install, and it's updating now.\n. Yep, there's Method::Extension(String) for extension methods: http://hyperium.github.io/hyper/hyper/method/enum.Method.html\n. I'm not sure what you mean. Hyper Request and Response objects implement\nstd::io::Read and Write, and so operate as a stream of bytes. How you deal\nwith the bytes is up to you.\n\nOn Mon, Apr 13, 2015, 7:24 AM Nicholas Young notifications@github.com\nwrote:\n\n@seanmonstar https://github.com/seanmonstar Awesome. Thanks for the\nlink to documentation. Do you have opinions or links on how to handle\nbinary data transfer?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/450#issuecomment-92377110.\n. num_cpus v0.2.1 published, fixing this.\n. Fixed with num_cpus v0.2.1\n. Ohh! Thank you for this, now I see the issue.\n. I handled this a little differently, by using an io::ErrorKind::ConnectionAborted error, and just checking for that in handle_connection. I wasn't sure yet about adding a HttpClosed variant. Still, thank you for filing this, as I was having trouble seeing where the actual error was.\n. I guess this needs travis.yml to be updated to pass the feature for cargo build and cargo test as well?\n. updated\n. updated again\n. Just holding on merging till I've completed some other breaking changes, and they can all be part of 0.4\n. See #459 \n. Ah, when I meant example usage, I meant showing in a rust code fench how to\ncreate a header to to send in a Request/Response.\n. I don't think there was a breaking change... It could be you're using\nbeta1, and need to upgrade to beta2.\n\nOn Tue, Apr 21, 2015, 3:35 AM GitCop notifications@github.com wrote:\n\nThanks for contributing! Unfortunately, I'm here to tell you there were\nthe following style issues with your Pull Request:\n- Commit: 704f78a\n  https://github.com/hyperium/hyper/commit/704f78a470b03783cf9eadf289d76201959d8ed9\n  - Commits must be in the following format: %{type}(%{scope}):\n    %{description}\nGuidelines are available at\nhttps://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\nThis message was auto-generated by https://gitcop.com\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/470#issuecomment-94739042.\n. @mikedilger I'm not sure I follow. In listen_threads, the Server is taken by value. You can move the context out of the Server in this method.\n. Ohhh, I see what you mean. Ok, so the with_listener method takes self, but it only needs to access self.handler. What about creating a private free function with_listener, that the method calls as with_listener(self.handler, listener, threads). Then, listen_threads can skip the internal method, and just move out both the ssl and the handler in the same function. Make sense?\n. The issue here is that hyper needs to pick something by default.\n\nIt's already possible to do it yourself with Client.set_ssl_verifier().\n. @tarcieri I don't know what presented identifiers means in this context.\n. Ah, I have no idea. That would be in the openssl lib, no?\nOn Sun, Apr 26, 2015, 2:21 PM Tony Arcieri notifications@github.com wrote:\n\n@seanmonstar https://github.com/seanmonstar the subjectAlternativeNames\n(SANs) or Common Names (CNs) in certificates\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/472#issuecomment-96436564.\n. > mainly related to use on machines not connected to internet\n\nJust noticed this, it seems like in this case it may be a waste to use TLS at all. If talking over a local network that you own and control, you can get performance improvements by not encrypting everything. Unless there are others on your local network that you want to protect yourself from, I guess?\n\nHyper should be flexible enough to support these use cases. Defaults can be to enable most secure options but give the user the possibility to configure hyper according to his/her needs.\n\nThis is exactly the current case. Default is to be secure. If one wants to alter away from the defaults, you can utilize the Client::with_connector(HttpsConnector::new(some_configured_openssl)). You can pick all the ciphers, protocol versions, and validation you want or don't want.\n. Cargo update?\nOn Sat, Apr 25, 2015, 8:19 AM Pyfisch notifications@github.com wrote:\n\nCompiling hyper v0.3.14 (file:///home/michael/Dokumente/git/hyper)\nsrc/http.rs:381:23: 381:48 error: wrong number of lifetime parameters: expected 1, found 2 [E0107]\nsrc/http.rs:381 impl<'a> TryParse for httparse::Request<'a, 'a> {\n                                      ^~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/http.rs:402:23: 402:49 error: wrong number of lifetime parameters: expected 1, found 2 [E0107]\nsrc/http.rs:402 impl<'a> TryParse for httparse::Response<'a, 'a> {\n                                      ^~~~~~~~~~~~~~~~~~~~~~~~~~\nerror: aborting due to 2 previous errors\nCould not compile hyper.\nTo learn more, run the command again with --verbose.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/478.\n. Thanks!\n. I don't understand what the action is for this issue. Does the Upgrade header need to be changed?\n. Wow, this is looking awesome (viewing on my phone atm)\n\nOn Sun, Apr 26, 2015, 12:51 PM Pyfisch notifications@github.com wrote:\n\nThis PR is complete now.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/481#issuecomment-96428176.\n. This was actually using Sslv23 by default, which is Ssl v2, v3, and Tls v1. It seemed like by default it would make the most amount of the web work. If I'm wrong, I'd love to know!\n\nHowever, I recently merged in #479, which allows you to create a SslContext yourself. Would that serve your purposes?\n(side note: I'd consider a change like this to be feat(server), and probably a breaking change, since servers upgrading would silently be dropping Ssl v2 and v3 support.)\n. Oh, I see. This also affects HttpConnector (I misread and though this was server only).\nIf we make this change, does this mean the Client no longer works (by default) against servers that only use SSL instead of TLS?\n. Fixed via https://github.com/hyperium/hyper/commit/f01cecbc068546c2a1d5ef280820f7d33993f361\n. @pyfisch wip, so don't merge?\n. Ignore, was just fiddling with a service. Stick to irc.\n. I'd say this was an oversight. We shouldn't have made a breaking change. A reason making it easier to miss is that all of our internal uses do include a test function.\nI think part of a fix so as to make sure we don't break the exported header! macro in the future is to use it in the examples/ directory. \n. @pyfisch can't the macro be written such that without the test pattern, a dummy empty one is created?\nrust\nmacro_rules! header {\n  ( $foo:ty $bar:ty ) => ( header! { $foo $bar test_dummy {} } )\n}\n. Oh Woops, that was me experimenting.\nOn Fri, May 1, 2015, 1:33 AM Pyfisch notifications@github.com wrote:\n\n[image: :+1:] but you should not make deref! private.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/492#issuecomment-98077075.\n. Oh excellent!\n\nThere should be a way to install locally to the user, instead needing sudo, right?\n. This is true. Before, it was possible when Client was generic over the NetworkConnector. Perhaps such a method set_ssl_verifier should be added to the NetworkConnector trait...\n. I'm sorry, I don't follow that well. You have a data: &[u8] already? Or you wish to receive one from a response?\n. I suppose some code of what you're trying to do would help.\nOn Fri, May 1, 2015, 7:27 PM Ulysse Carion notifications@github.com wrote:\n\ndata is what would have been written to a NetworkConnector -- in hyper's\nmock.rs, it corresponds to the contents of this variable:\nhttps://github.com/hyperium/hyper/blob/master/src/mock.rs#L9\nI have this already, and what I want to get is the response of the remote\nHTTP server.\nSorry for the imprecise wording; I don't really know what things are\ncalled here.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/496#issuecomment-98293021.\n. With all of that, you could just use plain TcpStreams.\n\nHave you seen the Client API, to take over this for you?\n. Oh, so you want to see the raw bytes, not have hyper handle them using hyper::Client. Reading from the hyper::client::Response will only read the body; the status-line and headers are available on the Response as status, version, and headers properties.\nReading your proposed fetch_http function, it looks like it should all work. What wasn't, specifically?\n. Oh, that could be the case.If you want to use Response's readers (which handle chunked and content-length correctly), you could just read from Response.\nrust\nlet mut raw = Vec::new();\nlet mut res = Response::new(stream);\nwriteln!(&mut raw, \"{} {}\", res.version, res.status);\nwrite!(&mut raw, \"{}\", res.headers);\nio::copy(&mut res, &mut raw);\n. Though, that will copy the decoded body (in case you need to replay the body encoded in chunks, you'd need to do figure something else out).\n. src/header/parsing.rs, line 12 [r1] (raw file):\nEither way seems fine to me. Or rather, if the \"almost certainly\" is in fact \"absolutely always\", then cool. Otherwise, we've done the check above, and a comment reminding anyone about the invariant, so the unsafe looks safe to me as well.\n\n\nComments from the review on Reviewable.io\n Sent from Reviewable.io \n. Reviewed files:\n- src/header/common/accept.rs @ r1\n- src/header/common/access_control_allow_headers.rs @ r1\n- src/header/common/access_control_allow_methods.rs @ r1\n- src/header/common/access_control_max_age.rs @ r1\n- src/header/common/access_control_request_headers.rs @ r1\n- src/header/common/access_control_request_method.rs @ r1\n- src/header/common/allow.rs @ r1\n- src/header/common/authorization.rs @ r1\n- src/header/common/cache_control.rs @ r1\n- src/header/common/connection.rs @ r1\n- src/header/common/content_type.rs @ r1\n- src/header/common/cookie.rs @ r1\n- src/header/common/etag.rs @ r1\n- src/header/common/host.rs @ r1\n- src/header/common/if_range.rs @ r1\n- src/header/common/last_modified.rs @ r1\n- src/header/common/mod.rs @ r1\n- src/header/common/pragma.rs @ r1\n- src/header/common/set_cookie.rs @ r1\n- src/header/internals/item.rs @ r1\n- src/header/mod.rs @ r1\n- src/header/parsing.rs @ r1\n- src/header/shared/charset.rs @ r1\n- src/header/shared/encoding.rs @ r1\n- src/header/shared/entity.rs @ r1\n- src/header/shared/language.rs @ r1\n\nComments from the review on Reviewable.io\n Sent from Reviewable.io \n. Hrm, seems reviewable is noisier than I was hoping. Oh well, don't worry about it. Just playing with toys, and this was a larger PR, so seemed opportune.\n. Well, the Handler needs to be Send and Sync. That includes any references it has. This is because the Handler is shared among multiple threads. Perhaps with the recent-ish Send changes, it doesn't have to be 'static, but it may need to be.\n. @reem you tend to know more about these kinds of things\n. Handler on master does not require 'static.\n. A single request? Can you paste the raw request message? That server works\non my Ubuntu...\nOn Tue, May 5, 2015, 3:15 AM Dennis Schneider notifications@github.com\nwrote:\n\nHello there,\nWhen binding the server to 0.0.0.0:8000, a response takes either very\nlong to come back or it times out. I experienced this problem on Ubuntu\n14.04, 64 Bit. It runs without problems on Mac OS X 10.10.4. I created a\nGist to illustrate the problem:\nhttps://gist.github.com/dschneider/2f845820ce1f5afc8c77\nThe code also includes an example of a small echo server that works\nwithout any problems on Ubuntu. I also tested it with a small web server\nwritten in Ruby that was bound to 0.0.0.0:8000 and it worked without any\nproblems.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/505.\n. @reem yea, i'd like that too, but I assume there will be a solution by the time hyper hits 1.0.\n. Thanks!\n. Would you mind added env_logger (or similar) and collecting logs from\nhyper? (with env_logger, you'd set RUST_LOG=hyper).\n\nOn Tue, May 5, 2015, 10:25 PM Wesley Moore notifications@github.com wrote:\n\nSure, doesn't look all that helpful though. I can tell you that it's the\nunwrap on send .send().unwrap(); that is panicking though:\nstack backtrace:\n   1:        0x1050720df - sys::backtrace::write::h0f2fc53eb11eb814gWr\n   2:        0x105075464 - panicking::on_panic::hd617a4042e8486fciUv\n   3:        0x10506b245 - rt::unwind::begin_unwind_inner::hd84dfec22ac3667d1Bv\n   4:        0x10506bad6 - rt::unwind::begin_unwind_fmt::h5bb6fa95bd57b24bFAv\n   5:        0x105074d3c - rust_begin_unwind\n   6:        0x1050949d5 - panicking::panic_fmt::hea516303ab7688d0lwy\n   7:        0x104fad606 - result::Result::unwrap::h5683422046223242116\n   8:        0x104fad22c - main::ha0a39c096ced901bjaa\n   9:        0x105076f88 - rust_try_inner\n  10:        0x105076f75 - rust_try\n  11:        0x105075c68 - rt::lang_start::h04063553a12d35edNOv\n  12:        0x104fd7b1e - main\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/508#issuecomment-99327290.\n. Hmm. Hyper is now calling shutdown because of the Connection: Close header.\nAfter writing the end, it calls shutdown(Write). I wonder if there's a\ndifference in the way Mac and Linux handle libc::shutdown.\n\nOn Tue, May 5, 2015, 10:52 PM Wesley Moore notifications@github.com wrote:\n\nSure, happy to help any way I can:\nRunning `target/debug/request`\nTRACE:hyper::client: send Get Url { scheme: \"http\", scheme_data: Relative(RelativeSchemeData { username: \"\", password: None, host: Domain(\"files.wezm.net\"), port: None, default_port: Some(80), path: [\"testpodcast.xml\"] }), query: None, fragment: None }\nTRACE:hyper::client: host=\"files.wezm.net\"\nTRACE:hyper::client: port=80\nDEBUG:hyper::net: http scheme\nDEBUG:hyper::client::request: request line: Get \"/testpodcast.xml\" Http11\nDEBUG:hyper::client::request: headers=Headers { Connection: close, Host: files.wezm.net, }\nTRACE:hyper::buffer: slicing (0, 1408, 4096)\nTRACE:hyper::header: raw header: \"Server\"=[110, 103, 105, 110, 120, 47, 49, 46, 54, 46, 51]\nTRACE:hyper::header: raw header: \"Date\"=[87, 101, 100, 44, 32, 48, 54, 32, 77, 97, 121, 32, 50, 48, 49, 53, 32, 48, 53, 58, 53, 48, 58, 51, 52, 32, 71, 77, 84]\nTRACE:hyper::header: raw header: \"Content-Type\"=[116, 101, 120, 116, 47, 120, 109, 108]\nTRACE:hyper::header: raw header: \"Last-Modified\"=[77, 111, 110, 44, 32, 49, 54, 32, 70, 101, 98, 32, 50, 48, 49, 53, 32, 48, 52, 58, 52, 51, 58, 48, 57, 32, 71, 77, 84]\nTRACE:hyper::header: raw header: \"X-Varnish\"=[50, 57, 56, 52, 57, 51, 32, 50, 57, 56, 52, 57, 49]\nTRACE:hyper::header: raw header: \"Age\"=[52, 51]\nTRACE:hyper::header: raw header: \"Via\"=[49, 46, 49, 32, 118, 97, 114, 110, 105, 115, 104, 45, 118, 52]\nTRACE:hyper::header: raw header: \"Transfer-Encoding\"=[99, 104, 117, 110, 107, 101, 100]\nTRACE:hyper::header: raw header: \"Connection\"=[99, 108, 111, 115, 101]\nTRACE:hyper::header: raw header: \"Accept-Ranges\"=[98, 121, 116, 101, 115]\nDEBUG:hyper::client::response: version=Http11, status=Ok\nDEBUG:hyper::client::response: headers=Headers { Transfer-Encoding: chunked, Via: 1.1 varnish-v4, Accept-Ranges: bytes, Date: Wed, 06 May 2015 05:50:34 GMT, Server: nginx/1.6.3, X-Varnish: 298493 298491, Age: 43, Content-Type: text/xml, Connection: close, Last-Modified: Mon, 16 Feb 2015 04:43:09 GMT, }\nTRACE:hyper::client::pool: PooledStream.drop, is_closed=true, is_drained=false\nthread '' panicked at 'called Result::unwrap() on an Err value: HttpIoError(Error { repr: Os(57) })', /Users/rustbuild/src/rust-buildbot/slave/beta-dist-rustc-mac/build/src/libcore/result.rs:729\nAn unknown error occurred\nTo learn more, run the command again with --verbose.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/508#issuecomment-99331851.\n. @wezm If it's related to shutdown, this is the smallest case that would test it (I think...):\n\n``` rust\nuse std::io::{Read, Write};\nuse std::net;\nfn main() {\n    let mut stream = net::TcpStream::connect(\"rust-lang.org:80\").unwrap();\n    stream.write_all(b\"GET / HTTP/1.1\\r\\nHost: rust-lang.org\\r\\n\\r\\n\").unwrap();\n    stream.shutdown(net::Shutdown::Write).unwrap();\nlet mut s = String::new();\nstream.read_to_string(&mut s).unwrap();\nprintln!(\"{}\", s);\n\n}\n``\n. @wezm what if you comment out theConnection: closeheader from the hyper example? If it still fails, we can look elsewhere.\n. @wezm if it works without the Connection close, try the tcp example with your own url (don't forget to edit theHost:` part of the byte string.\n. Hm, what if you change the tcp example to call shutdown twice?\nrust\n// ...\nstream.shutdown(net::Shutdown::Write).unwrap();\nstream.shutdown(net::Shutdown::Write).unwrap();\n// ...\n. Aha! So, seems Linux has no problem with that, but Mac does.\nHyper calls shutdown if there's Close header in the request. The response is also sending a Close header, and so shutdown is called a second time in the response. I assumed it'd be a no-op if it was already closed...\n. I'm skeptical that coveralls and/or kcov is correctly reporting coverage, but certainly, more tests are always good!\n. @Ryman what do you mean? That flush was called on the MockStream?\n. @Ryman ah sure. Though, since it's a chunked the response, that last chunk written before flushing must be the 0\\r\\n\\r\\n chunk, which the tests are checking for.\n. Go for it!\nOn Sat, Jun 6, 2015, 11:50 PM Jake Scott notifications@github.com wrote:\n\nI don't mind having a go at getting this setup if nobody else has already\nvolunteered :)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/513#issuecomment-109705403.\n. I'm thinking along the lines of what I did for the mime! macro, until https://github.com/rust-lang/rust/issues/25003 is fixed.\n. See #523 \n. Excellent, thank you!\n. The changes to do here is to change the &'a NetworkStream in hyper::server::Request to be &'a (NetworkStream + Send).\n. Ah yes, we could duplicate the definition for impl NetworkStream (grumble grumble)...\n. The second one would be easier. The first would be preferred if there's a need to send that trait object to another thread...\n. So, is it only in some cases it should be a String, or in all?\n. Well, according to that test, is should be considered illegal. The test expects xhr.send() to throw an error.\n\nFail    Disallow origin: \\0http://w3c-test.org\nassert_throws: send function \"function () { client.send() }\" did not throw\n. @reem ok, refactored that function...\n. I don't, as I still find the coverage report confusing and inaccurate.\n. @reem they do the same thing, but ToOwned uses an associated type, so it doesn't require inference to figure out it's output. \n. CloneTcpStream was removed, and now HttpStream(pub TcpStream) exists, and is public.\n. Is there a place where you could access it? I thought I made into_inner()\nskip the wrapper.\nOn Fri, May 15, 2015, 7:50 AM Antonio Petrelli notifications@github.com\nwrote:\n\nResolves #529 https://github.com/hyperium/hyper/issues/529\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/530#issuecomment-102419635.\n. Ahhh, I see. Hm, I find CloneTcpStream a wart that I'd rather remove.\n\nQuestion though: would proxy support in the Client be useful, or you're using the connectors directly?\n. No, there isn't proxy support in Client, yet. However, it should. And that'd be the best way, since it doesn't really require another connector.\n. @apetrelli ive opened #531 where we can discuss exactly how it should work.\nI'm going to close this for now, as I'd rather find a way to remove CloneTcpStream, and making that property public may mean more code breaks when I finally do give it the axe.\n. @mattnenterprise an api suggested by @shaleh looks fine. It'd likely require adding a method to Request to change the RequestUri, since the full url is needed instead of just the path.\n. There's a PR for this at #639, if others interested in this feature could help looking it over. \n. My focus is entirely on the async branch, which makes this easy:\n``` rust\nstruct ProxiedHandler(hyper::Method, &'static str);\nimpl Handler for ProxiedHandler {\n    fn on_request(&mut self, req: &mut Request) -> Next {\n        req.set_method(self.0);\n        req.set_uri(RequestUri::AbsoluteUri(self.1.parse().unwrap());\n        Next::read()\n    }\n    // ...\n}\nclient.request(\"http://proxy.server\", ProxiedHandler(GET, \"http://target.domain/path\")); \n```\nI can try to add in some support to the sync branch, such that if the Request.url does not match the Host header, then assume it is a proxied request and send the full URI...\n. See #771 to add simple support to the sync branch. This will be released in hyper 0.9.2.\n@shaleh this doesn't add support for lists, or Proxy-Authorization or the like. I believe those can be handled outside of hyper. The parts fixed in this PR were things that could not be done without hyper's help.\n. @JeffBelgum possibly. When exactly should the header be sent, as part of the normal request, or as part of the CONNECT tunnel request?. Then it seems that would require a new NetworkConnector, as the current Proxy doesn't have a way to customize the headers sent: https://github.com/hyperium/hyper/blob/0.10.x/src/client/proxy.rs#L47\nIt probably should, and I think it can be done in a backwards compatible way, by adding a method to ProxyConfig, and then making use of that in the Proxy.. @JeffBelgum for increased flexibility, I'd probably suggest allowing the ProxyConfig to accept a Headers struct, that is applied to each CONNECT request.\nSome proxies use different headers for auth, and may or may not require other headers like User-Agent. Best to just let people configure any header.. @mfarrugi broken? seemed there was an unused_mut warning, which has been fixed in https://github.com/hyperium/hyper/commit/b98662ab6db6b65b8310dc0f76374cdc8fc9c627, but I don't otherwise see them broken...\n. Closing in favor of #805 \n. Yes, this seems like a reasonable default to me.\n. Client can't be Copy: it has a Box<NetworkConnector>, are Box<T> is not Copy. Send and Sync aren't implemented like most traits.\n. This is a pull request, it's already been merged :)\n. I don't get why you want to use Error::Value here, instead of Error::Header. A Value could be from just about anything, no?\n. Optionally, a specific header could have it's own error types. Such as if there are multiple specific things that can go wrong during parsing it...\n. @AAG81 \n``` rust\n[macro_use] extern crate mime;\nextern crate hyper;\nuse std::io::Read;\nuse hyper::header::ContentType;\nuse hyper::Client;\nfn main() {\n    let mut client = Client::new();\n    let res = client.post(\"http://127.0.0.1\")\n        .header(ContentType(mime!(Application/WwwFormUrlEncoded)))\n        .body(\"caller=09121571&callee=502&uid=234567\")\n        .send()\n        .unwrap();\n    assert_eq!(res.status, hyper::Ok);\n}\n```\n. You may want UDP instead of TCP/HTTP, in that case.\n\nHowever, this isn't quite a help forum. It's a place to file bugs and feature requests regarding hyper. If you have general questions, I'd recommend the #rust IRC channel, or StackOverflow, as you'll get quicker answers from more people.\n. That looks odd to me. As you can see in the various examples in hyper's\ndocs, I chain the methods until I get a Response...\nOn Tue, May 19, 2015, 1:54 AM Jimmy Cuadra notifications@github.com wrote:\n\nNever mind... I'm an idiot. The commit I linked to was about the server\nand does not affect the client. What I needed to do was create a let\nbinding to the Request before calling send on it:\nfn request(method: Method, url: String) -> HyperResult {\n    let mut client = Client::new();\n```\nlet request = client.request(method, &url);\nrequest.send()\n```\n}\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/539#issuecomment-103403384.\n. Yea, something wonky with the borrow checker.\n\n``` rust\nfn request(url) -> Result {\n    let mut client = Client::new();\n    client.get(&url).send() // borrowck\n}\nfn request(url) -> Result {\n    let mut client = Client::new();\n    let res = client.get(&url).send();\n    res // um ok\n}\n```\n. Looks like https://github.com/hyperium/hyper/issues/309\n. Closing as dupe\n. Closed via #577 \n. I agree, let's not remove cookie entirely. We can turn just turn on or off cookie's usage of openssl.\nI seem room for improvement in cookie's feature usage though: the jar could still be provided, and just have the signing methods and types conditional inside jar.rs, but oh well.\n. Besides those comments, this looks great! I'd been thinking of providing this at some point, but never got around to it. Thanks for the effort!\n. This was actually merged in #577.\n. Excellent!\n. Looks like this contains a commit from master. Would you rebase? While\ndoing so, you could squash the commits into 1, using 'git rebase -i\nupstream/master'.\nOn Sun, May 24, 2015, 8:06 AM Coveralls notifications@github.com wrote:\n\n[image: Coverage Status] https://coveralls.io/builds/2638398\nChanges Unknown when pulling 4ba3033\nhttps://github.com/hyperium/hyper/commit/4ba3033a49119a6744c932cabf7c104db938f81b\non winding-lines:more-tests into * on hyperium:master*.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/544#issuecomment-105023120.\n. Perfect, thank you!\n. Great, thanks!\n. Sorry about that, I had merged a fix into master already, but haven't published a new version yet. I'll do that right away.\n. I'll merge this, since it also tests the cause() part, which is a good idea. If there was a way to pass to kcov to ignore all fns inside a #[cfg(test)] mod, that would greatly help reduce inflated \"lines missed\" values.\n. Thanks!\n. Nice catch.\n. \\o/\n. Get a string for your own socket? Help me understand a little more... what are you using a Client for if you're managing your own sockets?\n\nAlso, getting a String would probably be hard, since anything added as body() can be plain bytes. For debugging, I could see an implementation of fmt::Debug being added to RequestBuilder.\n. Hm, this doesn't seem like the solution then. If you just wish to use hyper::{headers, status, version}, then I'd build the outgoing message manually.\n. rust-void looks nice, but I don't think I need any more that just an empty enum and an empty match.\n. Woo, thanks! I'll look this over. Also pinging @pyfisch, since he's done a ton of work on the headers.\n. This looks good to go. Thanks! Would you mind squashing into a single commit? The changelog only really needs to report 1 new feature: added the Range header.\n. Excellent work! Thanks for sticking with it.\n. :dancers:\n. Ah yes, I haven't yet published the changes including Sync to crates.io.\nYou can add a git dependency, or I'll likely publish a new version soon\n(trying to lump expected breaking changes together).\nOn Tue, Jun 16, 2015, 8:13 AM Varentsov notifications@github.com wrote:\n\nHello, I'm trying to use examples from documentation\nhttp://hyper.rs/hyper/hyper/client/index.html and some of them isn't\ncompiles, for example\nextern crate hyper;use hyper::Client;\nuse std::thread;use std::sync::{Arc, Mutex};\nfn main() {\n    let client = Arc::new(Client::new());\n    let clone1 = client.clone();\n    let clone2 = client.clone();\n    thread::spawn(move || {\n        clone1.get(\"http://example.domain\").send().unwrap();\n    });\n    thread::spawn(move || {\n        clone2.post(\"http://example.domain/post\").body(\"foo=bar\").send().unwrap();\n    });\n}\nAnd I have these errors\nCompiling concur v0.1.0 (file:///home/nikon/RustProjects/concur)\nsrc/main.rs:14:5: 14:18 error: the trait core::marker::Sync is not implemented for the type hyper::net::NetworkConnector<Stream=Box<hyper::net::NetworkStream + Send>> + Send [E0277]\nsrc/main.rs:14     thread::spawn(move || {\n                   ^~~~~~~~~~~~~\nsrc/main.rs:14:5: 14:18 note: hyper::net::NetworkConnector<Stream=Box<hyper::net::NetworkStream + Send>> + Send cannot be shared between threads safely\nsrc/main.rs:14     thread::spawn(move || {\n                   ^~~~~~~~~~~~~\nerror: aborting due to previous error\nCould not compile concur.\nTo learn more, run the command again with --verbose.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/568.\n. Good idea. Excellent on the implementation, thanks!\n. This is waiting on the development of https://github.com/sfackler/rust-native-tls. It looks like releases are happening in the past couple days, but there were bad bugs until then. \n. Probably not, other than all focus is on master, using async IO (and thus probably something like tokio-tls).\n. Ah correct! TLS is no longer in hyper, see #985 for details.. Which operating system did you see this on?\n\nAlso, if you could enable logging, that would greatly help find where it\nstops. Easiest may be using the env_logger crate.\nOn Wed, Jun 17, 2015, 12:11 AM Douman notifications@github.com wrote:\n\nWhile learning a bit of hyper i made simple script:\nhttps://github.com/DoumanAsh/collectionScripts/tree/master/rust/vim_updater\nWhen i builds it with opt-level 2 or 3 the produced executable is not\nalways work properly.\nSometimes it can stuck forever and only interrupt can stop it.\nOn other hand without or with opt-level 1 it works just fine.\nSome dude tried to reproduce it on Linux, but it works fine with any\noptimization.\nYou can find all used flags for release:\nhttps://github.com/DoumanAsh/collectionScripts/blob/master/rust/vim_updater/Cargo.toml\nAnd application itself:\nhttps://github.com/DoumanAsh/collectionScripts/blob/master/rust/vim_updater/src/main.rs\nFor openSSL i used 1.02c and gcc was used 4.9.2\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/574.\n. Oh, if you use something like env_logger, you can turn on hyper's logging.\n\nOn Wed, Jun 17, 2015, 9:31 AM Douman notifications@github.com wrote:\n\nWindows 8.1. x64\nWhat sort of logging do you need?\nIt's easy to add prints at each step :)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/574#issuecomment-112870106.\n. Yep, debug would be the most useful. After adding env_logger::init().unwrap() into your main function, you can set some env variables and then run the executable.\n\nIf you're using Powershell, it'd be set $env:RUST_LOG=\"hyper=debug\".\n. Yea, that's quite odd. The \"normal\" case is when run with opt-level < 2? Even weirder.\nI assume you're using hyper v0.5.2 from crates.io. Would you mind trying a run using the latest commit? That'd be a change in your Cargo.toml to have:\n[dependencies.hyper]\ngit = \"https://github.com/hyperium/hyper\"\n. Additional weirdness:\nThe first debug line about redirect outputs the whole line, but the rest are all chopped.\nDEBUG:hyper::client: redirect code MovedPermanently for https://tuxproject.de/projects/vim\n...\nDEBUG:hyper::client: redirect code\n. Hrm, no idea. Try the rust-openssl repo?\nOn Wed, Jun 17, 2015, 8:24 AM Marius notifications@github.com wrote:\n\nI am getting an undefined symbol related to openssl when I try to compile\nthe latest on OS X. More detail below.\ngit log\ncommit e5dfb8233f25a4c57f2c6a68e8a7a854e42295b6\nMerge: 41823ca edf6ac2\nAuthor: Sean McArthur sean.monstar@gmail.com\nDate:   Tue Jun 16 22:51:13 2015 -0700\n```\nMerge pull request #572 from giftcards/master\nfeat(headers): add bearer token support\n```\nrustc version\nrustc -V\nrustc 1.0.0 (a59de37e9 2015-05-13) (built 2015-05-14)\nOS X version\nsw_vers\nProductName:    Mac OS X\nProductVersion: 10.10.3\nBuildVersion:   14D136\nLibssl\nls -l /usr/lib/libssl.*\n-rwxr-xr-x  1 root  wheel  400608 Sep  9  2014 /usr/lib/libssl.0.9.7.dylib\n-rwxr-xr-x  1 root  wheel  616512 Mar 19 19:16 /usr/lib/libssl.0.9.8.dylib\nlrwxr-xr-x  1 root  wheel      18 Feb 22 00:56 /usr/lib/libssl.dylib -> libssl.0.9.8.dylib\nActual error.\n\u279c  cargo clean\n\u279c  cargo test\n   Compiling traitobject v0.0.1\n   Compiling gcc v0.3.8\n   Compiling pkg-config v0.3.5\n   Compiling lazy_static v0.1.11\n   Compiling rustc-serialize v0.3.15\n   Compiling httparse v0.1.4\n   Compiling unicase v0.1.0\n   Compiling regex-syntax v0.1.2\n   Compiling libc v0.1.8\n   Compiling matches v0.1.2\n   Compiling typeable v0.1.2\n   Compiling bitflags v0.1.1\n   Compiling time v0.1.26\n   Compiling openssl-sys v0.6.2\n   Compiling memchr v0.1.3\n   Compiling log v0.3.1\n   Compiling num_cpus v0.2.6\n   Compiling aho-corasick v0.1.3\n   Compiling mime v0.0.11\n   Compiling hpack v0.2.0\n   Compiling regex v0.1.35\n   Compiling openssl v0.6.2\n   Compiling solicit v0.2.0\n   Compiling env_logger v0.3.1\n   Compiling url v0.2.35\n   Compiling cookie v0.1.21\n   Compiling hyper v0.5.2 (file:///Users/user/oss/hyperium/hyper)\nerror: linking with cc failed: exit code: 1\nnote: \"cc\" \"-m64\" \"-L\" \"/Users/user/.multirust/toolchains/stable/lib/rustlib/x86_64-apple-darwin/lib\" \"-o\" \"/Users/user/oss/hyperium/hyper/target/debug/examples/client\" \"/Users/user/oss/hyperium/hyper/target/debug/examples/client.o\" \"-Wl,-force_load,/Users/user/.multirust/toolchains/stable/lib/rustlib/x86_64-apple-darwin/lib/libmorestack.a\" \"-Wl,-dead_strip\" \"-nodefaultlibs\" \"/Users/user/oss/hyperium/hyper/target/debug/libhyper.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/libtypeable-10065b0bbdf3bed9.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/libunicase-29c711cff0d04b16.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/libsolicit-cd95e739c5df31f7.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/libmime-e3d384f950d18291.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/libhttparse-7ecdaf5da0017654.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/libhpack-0002de409367b417.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/libnum_cpus-d64cdaf0c78cf4e8.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/libtraitobject-dc1e70e5c4501fdd.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/libenv_logger-63352e48193fbb80.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/libregex-8de7cf8d3c57f864.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/libregex_syntax-8db057a1d27b1529.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/libaho_corasick-02c11d7f79c63f6b.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/libmemchr-ce56c6a379c614cd.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/liblog-54cf393d3c69686f.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/libcookie-ac7973d866daef44.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/liburl-a4f53e129e04fc84.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/librustc_serialize-0e2cbfb69293d88f.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/libtime-f08bec52f4924e95.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/libmatches-68db25b520030534.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/libopenssl-a36d86f1beea2185.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/libbitflags-518ea12e21428edd.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/liblazy_static-7e1b752366784e2f.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/libopenssl_sys-5040130ff99796a0.rlib\" \"/Users/user/oss/hyperium/hyper/target/debug/deps/liblibc-2eda841eb12a3090.rlib\" \"/Users/user/.multirust/toolchains/stable/lib/rustlib/x86_64-apple-darwin/lib/libstd-4e7c5e5c.rlib\" \"/Users/user/.multirust/toolchains/stable/lib/rustlib/x86_64-apple-darwin/lib/libcollections-4e7c5e5c.rlib\" \"/Users/user/.multirust/toolchains/stable/lib/rustlib/x86_64-apple-darwin/lib/libunicode-4e7c5e5c.rlib\" \"/Users/user/.multirust/toolchains/stable/lib/rustlib/x86_64-apple-darwin/lib/librand-4e7c5e5c.rlib\" \"/Users/user/.multirust/toolchains/stable/lib/rustlib/x86_64-apple-darwin/lib/liballoc-4e7c5e5c.rlib\" \"/Users/user/.multirust/toolchains/stable/lib/rustlib/x86_64-apple-darwin/lib/liblibc-4e7c5e5c.rlib\" \"/Users/user/.multirust/toolchains/stable/lib/rustlib/x86_64-apple-darwin/lib/libcore-4e7c5e5c.rlib\" \"-L\" \"/Users/user/oss/hyperium/hyper/target/debug\" \"-L\" \"/Users/user/oss/hyperium/hyper/target/debug/deps\" \"-L\" \"/usr/lib\" \"-L\" \"/Users/user/oss/hyperium/hyper/target/debug/build/openssl-sys-5040130ff99796a0/out\" \"-L\" \"/Users/user/oss/hyperium/hyper/target/debug/build/time-f08bec52f4924e95/out\" \"-L\" \"/Users/user/.multirust/toolchains/stable/lib/rustlib/x86_64-apple-darwin/lib\" \"-L\" \"/Users/user/oss/hyperium/hyper/.rust/lib/x86_64-apple-darwin\" \"-L\" \"/Users/user/oss/hyperium/hyper/lib/x86_64-apple-darwin\" \"-lssl\" \"-lcrypto\" \"-lz\" \"-lc\" \"-lm\" \"-lSystem\" \"-lpthread\" \"-lc\" \"-lm\" \"-Wl,-rpath,@loader_path/../../../../../../.multirust/toolchains/stable/lib/rustlib/x86_64-apple-darwin/lib\" \"-Wl,-rpath,/usr/local/lib/rustlib/x86_64-apple-darwin/lib\" \"-lcompiler-rt\"\nnote: ld: warning: directory not found for option '-L/Users/user/oss/hyperium/hyper/.rust/lib/x86_64-apple-darwin'\nld: warning: directory not found for option '-L/Users/user/oss/hyperium/hyper/lib/x86_64-apple-darwin'\nUndefined symbols for architecture x86_64:\n  \"_TLSv1_2_method\", referenced from:\n      ssl::SslMethod::to_raw::h7b8cbd53c0831aeeOLc in libopenssl-a36d86f1beea2185.rlib(openssl-a36d86f1beea2185.o)\nld: symbol(s) not found for architecture x86_64\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/575.\n. I'm surprised actually. @reem develops on a macbook, and I must assume it's\nbeen working for him...\n\nOn Thu, Jun 18, 2015, 8:32 PM Marius notifications@github.com wrote:\n\n@sfackler https://github.com/sfackler thanks for the pointers! The\nhyper library is intended to be used by other people, so I don't feel that\njust installing a different openssl library on my computer is sufficient.\nIt's unclear to me how to use features, I tried the following but I get\nthe same error.\n[dependencies.openssl]\nversion = \"0.6\"\nfeatures = [\"tlsv1_1\"]\nIt feels to me that the best approach would be to detect which library is\navailable and then enable one feature or the other.\nDo you know of any client of your library doing something similar.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/575#issuecomment-113357344.\n. I've actually been working a bunch on a patch that changes up the design of Ssl usage, to facilitate using different ssl libraries, and disabling ssl altogether. I hope to have that finished tomorrow.\n. The new ssl merged, so if it's causing issues, you can disable the \"feature\".\n. Nice catches, fixed.\n. Sure. I'll bump the version to 0.6 as well, since it has breaking changes.\n\nOn Sat, Jun 20, 2015, 7:02 PM Jonathan Reem notifications@github.com\nwrote:\n\n@seanmonstar https://github.com/seanmonstar give me a heads up before\npublishing a new version including these changes please.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/577#issuecomment-113851507.\n. I haven't published a version with Range yet, as I'm trying to wrap up the current set of breaking changes before publishing 0.6.\n. Unregistered is used frequently in other headers and for StatusCodes, as many use a \"registry\", though sometimes that registry is just the original spec and who cares....\n. The actual http2 bits are from the solicit crate, not actually hyper itself.\n. It is not removed, just requires that you pick a Ssl implementation\nyourself. You can use the Openssl one, and it includes a function to accept\na cert and key. http://hyper.rs/hyper/hyper/net/struct.Openssl.html\n\nOn Fri, Jun 26, 2015, 9:20 PM Josh Leverette notifications@github.com\nwrote:\n\nHas the option to run an https server off of hyper been removed in the\nlatest version because of all of the SSL restructuring? You used to simply\nbe able to specific a certificate and a key and have an https server\nrunning. It was pretty convenient. If it has been removed, is it planned to\nbe added back in soon?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/586.\n. Yea, travis-cargo didn't exist when I fiddled around and made the build matrix and docs uploading work. I'm not too worried about it's current messiness, but am not opposed to cleaner things as long as the following can be handled:\n1. kcov can be used without sudo, but travis-cargo doesn't yet do that.\n2. I'm working on uploading docs to a path based on the minor version, and no longer destroying the gh-pages on each push.\n. Have been working on a per-version doc upload script, so I'll just close this.\n. Impressive work! I'll look through this, but seems travis is reporting this doesn't build on stable...\n. I appreciated the design of the StsParser, it seems well designed to handle many different directives. However, I have 2 concerns.\n1. There's only 2 possible directives that are defined and understood for this header.\n2. Several Strings are allocated through the parsing process, including ones that are discarded immediately, such as from pop_whitespace. Parsing could be done with less allocations, which would make it faster and use less memory.\n\nI'd recommend a parsing strategy that splits on ;, and then again on =. That, along with a trim(), could be compared with max-age and includeSubdomains. An example can be seen in the Range header.\n. The usage of tuple structs is usually for when it's a single value, and so something like ContentLength(100) reads better than ContentLength { value: 100 } (at least, in my opinion).\nAnd, nice catch on it being valid to have foo=\"bar; baz\", which is different from foo=bar; baz. While in the current case, any instance where there is a ; inside a quoted string means it's a value that no directive knows, I'm not against future-proofing. If that check is kept, I'd prefer if the parser could just work on an Iterator<Item=u8>, such as raw.iter(), and then instead of pushing bytes into temporary Strings, the positions could just be recorded instead, since only a &str slice is needed for the matching.\n. I noticed a few other details, which I tried to just fix myself in the parser (duplicate directives should be an error, some unwrap()s I'd rather not have, and bounds checks after already checking self.eof()), and I ended up just rewriting the parsing to use splits as I had mentioned earlier in this thread. Please don't take this the wrong way, I greatly appreciate the work and PR that you sent. I simply felt there were a couple flaws that made me feel I was fighting the parser when I tried to correct them.\nI've rebased my fixes onto your commit, and merged manually as https://github.com/hyperium/hyper/commit/7c2e5124e6678a5806f980902031e6f01652d218\n. It'd be worth knowing what version of openssl you have installed on your machine. As for solutions, I can think of 2:\n1. I noticed that https://github.com/sfackler/rust-openssl has seen a few commits after v0.6.3 regarding hmac, so you could try pinning to the git version using .cargo/config, and/or reporting errors on the openssl repo.\n2. Also, if you do not with to use openssl at all, you can disable the ssl feature: https://github.com/hyperium/hyper/blob/990819a6d667161f494882117af243cdd1fcdf3a/Cargo.toml#L43\n. Looking more, it seems likely the header files aren't installed. See the README regarding building openssl.\n. I believe https://github.com/hyperium/hyper/pull/705 fixed this as well.\n. Aha, it was a specific bug in httparse, when the status-reason was followed \\n. It would incorrectly consume 1 too many bytes, and that threw off all the rest of the parsing. Fixed in httparse 0.1.5, so all that is required is cargo update.\n. Sure, I went and bumped the threshold decrease to 2% (seems like a large enough to mean that new functions forgot tests). In this case, I think the decrease was in introducing From<FromUtf8Error> without adding to tests. However, the error.rs tests don't seem to report correctly, which is quite frustrating.\n. No, as Http 1.0, it should close the connection unless keepalive was passed\nby the client. It's a bug in the should_keep_alive function.\nOn Sun, Jul 5, 2015, 12:34 PM Jonathan Reem notifications@github.com\nwrote:\n\nIf we immediately closed the connection then the client may not be able to\nfully read the final response, as noted in the spec.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/596#issuecomment-118657965.\n. It's the commit message. You could fix it with git commit --amend. Try docs(CONTRIBUTING): link to open easy issues.\n. Perfect, thanks!\n. I'm going to guess that in the newest nightly, the missing_docs lint got\nslightly stricter and is now noticing those consts.\n\nOn Tue, Jul 7, 2015, 9:52 PM Simon Bernier St-Pierre \nnotifications@github.com wrote:\n\nI'm trying to compile hyper 0.6.2 right now, but it fails to compile\nbecause of missing docs. Am I doing something wrong?\n/home/simon/.cargo/registry/src/github.com-0a35038f75765ae4/hyper-0.6.2/src/http/h1.rs:735:1: 735:25 error: missing documentation for a constant\n/home/simon/.cargo/registry/src/github.com-0a35038f75765ae4/hyper-0.6.2/src/http/h1.rs:735 pub const SP: u8 = b' ';\n                                                                                           ^~~~~~~~~~~~~~~~~~~~~~~~\n/home/simon/.cargo/registry/src/github.com-0a35038f75765ae4/hyper-0.6.2/src/lib.rs:2:9: 2:21 note: lint level defined here\n/home/simon/.cargo/registry/src/github.com-0a35038f75765ae4/hyper-0.6.2/src/lib.rs:2 #![deny(missing_docs)]\n                                                                                             ^~~~~~~~~~~~\n/home/simon/.cargo/registry/src/github.com-0a35038f75765ae4/hyper-0.6.2/src/http/h1.rs:736:1: 736:26 error: missing documentation for a constant\n/home/simon/.cargo/registry/src/github.com-0a35038f75765ae4/hyper-0.6.2/src/http/h1.rs:736 pub const CR: u8 = b'\\r';\n                                                                                           ^~~~~~~~~~~~~~~~~~~~~~~~~\n/home/simon/.cargo/registry/src/github.com-0a35038f75765ae4/hyper-0.6.2/src/lib.rs:2:9: 2:21 note: lint level defined here\n/home/simon/.cargo/registry/src/github.com-0a35038f75765ae4/hyper-0.6.2/src/lib.rs:2 #![deny(missing_docs)]\n                                                                                             ^~~~~~~~~~~~\n/home/simon/.cargo/registry/src/github.com-0a35038f75765ae4/hyper-0.6.2/src/http/h1.rs:737:1: 737:26 error: missing documentation for a constant\n/home/simon/.cargo/registry/src/github.com-0a35038f75765ae4/hyper-0.6.2/src/http/h1.rs:737 pub const LF: u8 = b'\\n';\n                                                                                           ^~~~~~~~~~~~~~~~~~~~~~~~~\n/home/simon/.cargo/registry/src/github.com-0a35038f75765ae4/hyper-0.6.2/src/lib.rs:2:9: 2:21 note: lint level defined here\n/home/simon/.cargo/registry/src/github.com-0a35038f75765ae4/hyper-0.6.2/src/lib.rs:2 #![deny(missing_docs)]\n                                                                                             ^~~~~~~~~~~~\n/home/simon/.cargo/registry/src/github.com-0a35038f75765ae4/hyper-0.6.2/src/http/h1.rs:738:1: 738:27 error: missing documentation for a constant\n/home/simon/.cargo/registry/src/github.com-0a35038f75765ae4/hyper-0.6.2/src/http/h1.rs:738 pub const STAR: u8 = b'*';\n                                                                                           ^~~~~~~~~~~~~~~~~~~~~~~~~~\n/home/simon/.cargo/registry/src/github.com-0a35038f75765ae4/hyper-0.6.2/src/lib.rs:2:9: 2:21 note: lint level defined here\n/home/simon/.cargo/registry/src/github.com-0a35038f75765ae4/hyper-0.6.2/src/lib.rs:2 #![deny(missing_docs)]\n                                                                                             ^~~~~~~~~~~~\n/home/simon/.cargo/registry/src/github.com-0a35038f75765ae4/hyper-0.6.2/src/http/h1.rs:739:1: 739:46 error: missing documentation for a constant\n/home/simon/.cargo/registry/src/github.com-0a35038f75765ae4/hyper-0.6.2/src/http/h1.rs:739 pub const LINE_ENDING: &'static str = \"\\r\\n\";\n                                                                                           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/home/simon/.cargo/registry/src/github.com-0a35038f75765ae4/hyper-0.6.2/src/lib.rs:2:9: 2:21 note: lint level defined here\n/home/simon/.cargo/registry/src/github.com-0a35038f75765ae4/hyper-0.6.2/src/lib.rs:2 #![deny(missing_docs)]\nI also tried downgrading to 0.6.1, same error. I'm using the rust-nightly\nfrom the rust ppa.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/600.\n. I assume it's related to 1) no timeouts #368, and 2) the use of synchronous IO, which pretty much just makes No. 1 hurt more.\n. No, it's still open. Just several issues referencing it are closed.\n\nFor timeouts, see #315. For async IO, see #395.\n. Hm, interesting question. Looking at the TcpStream docs, it doesn't seem to\nbe exposed any way. Worth a look around in here to see what would be\nneeded, and propose an RFC to rust-lang\nhttps://github.com/rust-lang/rust/blob/master/src/libstd/sys/common/net.rs\nOn Fri, Jul 10, 2015, 10:14 AM muja notifications@github.com wrote:\n\nIf I am connected to the internet with multiple network interfaces, I want\nto be able to specify which one hyper should use - basically, which local\naddress it should use to connect to the web.\nIs this possible already?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/602.\n. This can be done thanks to #622 \n. Not an issue. Most examples include calling the send() method, which is\nwhat returns the Response.\n\nOn Sat, Jul 11, 2015, 9:58 AM Douman notifications@github.com wrote:\n\nIt is not actually doc issue, but function signature issue i suppose?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/605#issuecomment-120627547.\n. fwiw, I've pull this change into the 'mio' branch, since that branch is already full of breaking changes.\n. Also, if you don't want https support (or at least, from openssl), you can\ndisable the 'ssl' feature.\n\nOn Tue, Jul 14, 2015, 6:37 AM Artem notifications@github.com wrote:\n\nIt's not about the OpenSSL installation!\nMind this message above: \"failed to execute command: The system cannot\nfind the file specified.\"\nThe message says that gcc tried to execute something and failed.\nIf you run with cargo build --verbose and then manually repeat the gcc\ncommand with an extra -v flag then you'll see gcc trying to execute cc1\nand there's no cc1 in the Rust installation.\nsmolny:~/AgaSleep$ gcc -v -O0 -c -ffunction-sections -fdata-sections -mwin32 -m64 -fPIC -I c:/spool/OpenSSL-Win64/include C:/spool/cygwin/home/Artem/.cargo/registry/src/github.com-0a35038f75765ae4/openssl-sys-0.6.4/src/openssl_shim.c -o C:/spool/Promo/projects/AgaSleep/target/debug/build/openssl-sys-765ddf9de3c5179c/out/src/openssl_shim.o\nUsing built-in specs.\nCOLLECT_GCC=C:\\spool\\Rust\\bin\\rustlib\\x86_64-pc-windows-gnu\\bin\\gcc.exe\nTarget: x86_64-w64-mingw32\nConfigured with: ../../../src/gcc-4.9.1/configure --host=x86_64-w64-mingw32 --build=x86_64-w64-mingw32 --target=x86_64-w64-mingw32 --prefix=/mingw64 --with-sysroot=/c/mingw491/x86_64-491-win32-seh-rt_v3-rev1/mingw64 --with-gxx-include-dir=/mingw64/x86_64-w64-mingw32/include/c++ --enable-shared --enable-static --disable-multilib --enable-languages=ada,c,c++,fortran,objc,obj-c++,lto --enable-libstdcxx-time=yes --enable-threads=win32 --enable-libgomp --enable-libatomic --enable-lto --enable-graphite --enable-checking=release --enable-fully-dynamic-string --enable-version-specific-runtime-libs --disable-isl-version-check --disable-cloog-version-check --disable-libstdcxx-pch --disable-libstdcxx-debug --enable-bootstrap --disable-rpath --disable-win32-registry --disable-nls --disable-werror --disable-symvers --with-gnu-as --with-gnu-ld --with-arch=nocona --with-tune=core2 --with-libiconv --with-system-zlib --with-gmp=/c/mingw491/prerequisites/x86_64-w64-mingw32-static --with-mpfr=/c/mingw4\n 91/prerequisites/x86_64-w64-mingw32-static --with-mpc=/c/mingw491/prerequisites/x86_64-w64-mingw32-static --with-isl=/c/mingw491/prerequisites/x86_64-w64-mingw32-static --with-cloog=/c/mingw491/prerequisites/x86_64-w64-mingw32-static --enable-cloog-backend=isl --with-pkgversion='x86_64-win32-seh-rev1, Built by MinGW-W64 project' --with-bugurl=http://sourceforge.net/projects/mingw-w64 CFLAGS='-O2 -pipe -I/c/mingw491/x86_64-491-win32-seh-rt_v3-rev1/mingw64/opt/include -I/c/mingw491/prerequisites/x86_64-zlib-static/include -I/c/mingw491/prerequisites/x86_64-w64-mingw32-static/include' CXXFLAGS='-O2 -pipe -I/c/mingw491/x86_64-491-win32-seh-rt_v3-rev1/mingw64/opt/include -I/c/mingw491/prerequisites/x86_64-zlib-static/include -I/c/mingw491/prerequisites/x86_64-w64-mingw32-static/include' CPPFLAGS= LDFLAGS='-pipe -L/c/mingw491/x86_64-491-win32-seh-rt_v3-rev1/mingw64/opt/lib -L/c/mingw491/prerequisites/x86_64-zlib-static/lib -L/c/mingw491/prerequisites/x86_64-w64-mingw32-static/lib '\nThread model: win32\ngcc version 4.9.1 (x86_64-win32-seh-rev1, Built by MinGW-W64 project)\nCOLLECT_GCC_OPTIONS='-v' '-O0' '-c' '-ffunction-sections' '-fdata-sections' '-mwin32' '-m64' '-fPIC' '-I' 'c:/spool/OpenSSL-Win64/include' '-o' 'C:/spool/Promo/projects/AgaSleep/target/debug/build/openssl-sys-765ddf9de3c5179c/out/src/openssl_shim.o' '-mtune=core2' '-march=nocona'\n cc1 -quiet -v -I c:/spool/OpenSSL-Win64/include -iprefix C:/spool/Rust/bin/rustlib/x86_64-pc-windows-gnu/bin/../lib/gcc/x86_64-w64-mingw32/4.9.1/ -U_REENTRANT C:/spool/cygwin/home/Artem/.cargo/registry/src/github.com-0a35038f75765ae4/openssl-sys-0.6.4/src/openssl_shim.c -quiet -dumpbase openssl_shim.c -mwin32 -m64 -mtune=core2 -march=nocona -auxbase-strip C:/spool/Promo/projects/AgaSleep/target/debug/build/openssl-sys-765ddf9de3c5179c/out/src/openssl_shim.o -O0 -version -ffunction-sections -fdata-sections -fPIC -o C:\\spool\\cygwin\\tmp\\ccZSgpmE.s\ngcc.exe: error: CreateProcess: No such file or directory\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/607#issuecomment-121210986.\n. Closing as this seems to be an openssl issue, and it seems to have been fixed-ish.\n. I've sometimes thought of the Client having a default_headers field, that\ncould accomplish this. But, I also noticed that most other http libraries\ndon't have this, so I've so far felt that this could be provided per app,\nor perhaps in a separate crate...\n\nOn Sun, Jul 12, 2015, 3:13 PM Jonathan Reem notifications@github.com\nwrote:\n\n@arnm https://github.com/arnm you could probably apply most of the\nthings iron does on the server to a client, namely modifiers, an extensions\nmap, etc. A Modifier that you apply to every request basically does what\nyou want.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/608#issuecomment-120758944.\n. Those last few bits should also trigger a rebuild on travis, and once it's green, and assuming @pyfisch doesn't disagree, it'd be good to go!\n. Woops, I don't know how long ago you address this. I don't get notifications when a force push happens. Thanks sticking it out!\n. I squashed the commits into 1, and merged manually into master: https://github.com/hyperium/hyper/commit/af062ac954d5b90275138880ce2f5013d6664b5a\n. What headers do you receive back? What is the body of the response? An\nimage or file of some sort?\n\nOn Tue, Jul 14, 2015, 5:31 AM WebTogz notifications@github.com wrote:\n\nOk, my bad - I not used headers(...) but header(...)... (newbie here)\nBut, with that custom header, i don't receive again any UTF-8 response...\n:-/\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/610#issuecomment-121195934.\n. They are the same thing. std reexports from collections.\n\nIn this case, the client doesn't need to take ownership of the String,\nsince it creates a Url from it and doesn't need it longer. You can pass\n&url, or construct the Url yourself and pass that.\nOn Sun, Jul 19, 2015 at 9:06 PM Alexei Nunez notifications@github.com\nwrote:\n\nrustc 1.3.0-nightly (98dcd5e10 2015-07-11)\nI want to wrap some of hyper's functionality for usability's sake. Every\ntime I do a get I want to always send some default headers. This is the way\nI currently have it working:\n```\nfn get<'a, U: IntoUrl>(&'a self, url: U) -> RequestBuilder<'a, U> {\n    let mut headers = Headers::new();\nheaders.set(\n    Authorization(\n        Token { token: self.token.clone() }\n    )\n);\n\nheaders.set(ContentType::json());\nself.client.get(url).headers(headers)\n\n}\n```\nBut the implementation which defines this method knows what the domain of\nthe URL is so instead of passing in the fully qualified URL into that\nmethod I would only like to pass in the path of the URL. Something like\nthis (doesn't compile):\n```\nfn get<'a>(&'a self, path: &'a str) -> RequestBuilder<'a, String>\n{\n    let url = self.url(path); // builds fully qualified url as String\n    let mut headers = Headers::new();\nheaders.set(\n    Authorization(\n        Token { token: self.token.clone() }\n    )\n);\n\nheaders.set(ContentType::json());\nself.client.get(url).headers(headers)\n\n}\n```\nThe problem is that I keep getting the following error:\nthe trait hyper::client::IntoUrl is not implemented for the type collections::string::String\nAny ideas on how I could do this? I don't know what the difference is\nbetween std::string::String and collections::string::String. I import\nstd::string::String directly.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/612.\n. Ah, yes, that's the issue. If you look here in the docs, you'll see what IntoUrl is implemented for. You can switch your function signature to return RequestBuilder<'a, &'a str>, and inside the function call self.client.get(&*url).\n. @paomian just pass a reference to your String, by doing client.get(&url)...\n\nI could implement IntoUrl for String, but I don't actually need to take ownership of the String to parse it, a reference it sufficient.\n. I've changed the example to download rust-lang.org.\n. This could just use the derive attribute, couldn't it?\nOn Tue, Jul 21, 2015, 12:25 PM H\u00e5var N\u00f8vik notifications@github.com wrote:\n\nImplment the Hash trait for the StatusCode enum.\nResolves issue #614 https://github.com/hyperium/hyper/issues/614\nYou can view, comment on, or merge this pull request online at:\nhttps://github.com/hyperium/hyper/pull/615\nCommit Summary\n- feat(status): implement Hash for StatusCode\nFile Changes\n- M src/status.rs\n  https://github.com/hyperium/hyper/pull/615/files#diff-0 (7)\nPatch Links:\n- https://github.com/hyperium/hyper/pull/615.patch\n- https://github.com/hyperium/hyper/pull/615.diff\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/615.\n. Thanks!\n. Ah bummer, I didn't notice that the net2 crate uses an unstable feature. This prevents me from merging this in hyper as-is. I could consider a possible cargo feature flag to include this, but the best would be to stabilize duration in libstd.\n. I'm going to close this, since the better #622 was merged.\n. I think this can be solved using the TcpBuilderConnector that is in #618. I've restarted those tests, and will merge once green.\n. Seems fine. Also note that before this is published in a new version, you could create the TcpListener or TcpStream and then manually wrap it HttpListener(TcpStream::from_raw_fd(fd)).\n. Interesting. I haven't looked to see how timeouts are implemented on TcpStreams. Seems something conflicts with the optimizations openssl is doing? @sfackler\n. @softprops yep, if you turn off the ssl feature, then the DefaultConnector is HttpConnector. I believe you can override the path of the openssl using .cargo/config.\n. According to http://doc.crates.io/config.html\n\npaths = [\"../openssl\"] in a .cargo file next to your Cargo.toml.\nYou can put it anywhere, and adjust the path.\nOn Sat, Aug 8, 2015, 7:33 PM doug tangren notifications@github.com wrote:\n\nI can't seem to the right combination of cargo config options make this\nhappen. Can you provide an example?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/626#issuecomment-129095583.\n. @softprops according to http://linux.die.net/man/7/socket a timed out read will report the error EAGAIN/EWOULDBLOCK (they're the same constant, as you've noticed).\n. I don't yet know what the best solution is. It may be worth discussion in internals about whether TcpStream should map WouldBlock to TimedOut iff the socket has a timeout set. Socket timeouts are still unstable, so these details may not have had enough testing.\n. I tried asking in the original RFC: https://github.com/rust-lang/rfcs/pull/1047#issuecomment-129299967\n. @sfackler certainly not an expert in openssl's source, but my browsing found this: https://github.com/openssl/openssl/blob/master/ssl/ssl_lib.c#L2391\n\nI couldn't find a check for the os error, so it could be completely ignored? Either way, it'd be nice if the returned error was the same as that from a TcpStream. I supposed I can add a check in Request and Response to translate WouldBlock into TimedOut, since I know (for now) that the socket is in blocking mode.\n. To make it consistent, I'd be fine with hyper matching WouldBlock and\nreturning TimedOut inside Request and Response (unless that'd somehow seem\nweird to Linux users).\nOn Mon, Aug 10, 2015, 8:08 PM Steven Fackler notifications@github.com\nwrote:\n\nThe Os error isn't visible in the API. io::Error has a kind() method\nwhich will return an io::ErrorKind variant that you can look at, though\non Linux it'll be WouldBlock rather than TimedOut.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/626#issuecomment-129687643.\n. @softprops is what something that could be stabilized?\n. @softprops after lots of reading man pages and stack overflow questions, it seems the standard is this:\n- On Unixy systems, read() with a timeout will return EAGAIN, which in Rust is ErrorKind::WouldBlock.\n- On Windows, read() with a timeout will return WSAETIMEDOUT, which in Rust is ErrorKind::TimedOut.\n\nPick what you need. It may be worth filing an issue on the rust repo to include that in the documentation of timeouts, but it might not.\n. To be sure, you need to check the SslContext from within Handler::handle?\n. I'm guessing you want to access http://sfackler.github.io/rust-openssl/doc/v0.6.4/openssl/ssl/struct.SslStream.html#method.get_peer_certificate\nPerhaps adding a downcast_ref sort of function to Request, so that you could get a &SslStream (assuming you're using openssl).\n``` rust\npub fn downcast_ref(&self) -> Option<&T> {\n}\n``\n. @GildedHonour the examples of headers are specifically only for how to create headers. You might be creating them for aclient::Request, or for aserver::Response`. How to pass the headers along is the in the documentation for the relevant sections (client and server).\nI don't see an actionable bug here, so I'm going to close this. If I'm wrong, let me know.\n. Ah good point, it won't be possible to get AsRef<str> working for Url, since it's split the data among multiple Strings. There's no way to get a simple reference, since there's no contiguous String.\n. Thanks!\n. The SslStream from openssl has a type parameter. Try SslStream.\nOn Fri, Aug 21, 2015, 11:12 AM Andrew Gross notifications@github.com\nwrote:\n\nHaving some issues getting access to the SSL Stream for an HTTPS request.\nI am using the example code, though it still seems to be unhappy.\nOn Rust 1.2, hyper = \"0.6.9\"\nfn doc_ssl(req: hyper::server::Request) {\n    let maybe_ssl = req.ssl::();\n}\nsrc/main.rs:105:31: 105:40 error: wrong number of type arguments: expected 1, found 0 [E0243]\nsrc/main.rs:105     let maybe_ssl = req.ssl::();\n                                              ^~~~~~~~~\nIt seems no matter how many type annotations I give, and how I try to\nmatch that it refuses to accept it. Due to recent addition of this\nfeature, I am not sure if is a bug, or if I am just unable to implement it\ncorrectly. Apologies if this is a trivial issue, I am still quite new to\nrust.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/633.\n. That's what the use of UniCase is for. However, I think the issue is in the parsing of the Connection header, in this case. Instead of being parsed as the KeepAlive variant, it's the ConnectionHeader variant.\n. Specifically, this method: https://github.com/hyperium/hyper/blob/master/src/header/common/connection.rs#L28\n\nInstead, it should do a couple comparisons instead of a match.\nrust\nif s == KEEP_ALIVE {\n// ...\n} else if s == CLOSE {\n// ...\n}\nWith the constants being UniCase(\"keep-alive\") and UniCase(\"close\").\n. :+1:\n. That's part of OpenSSL. You have 2 options resolving this:\n1. Trying to get rust-openssl to properly compile.\n2. Disable openssl in hyper, by adjusting your Cargo.toml to have hyper = { version = \"0.6\", no-default-features = true }.\n. Hm, that does seem gross. A brief glance in the docs doesn't show an\nalternative. I'd recommend filing an issue on the Url repo:\nhttps://github.com/servo/rust-url\nOn Fri, Aug 28, 2015, 8:24 AM Craig M. Brandenburg notifications@github.com\nwrote:\n\nUsing Url::path_mut() to set path components individually doesn't result\nin a percent-encoded URI. For example:\nlet mut u = hyper::Url::parse(\"http://www.example.com/\").unwrap();\nu.path_mut().unwrap()[0] = \"foo/bar\".to_string();\nprintln!(\"{}\", u);\nu.path_mut().unwrap()[0] = \"foo?bar\".to_string();\nprintln!(\"{}\", u);\nOutput:\nhttp://www.example.com/foo/barhttp://www.example.com/foo?bar\nI expect to see:\nhttp://www.example.com/foo%2Fbarhttp://www.example.com/foo%3Fbar\nMaybe I'm missing something here, but I don't see any workaround for this\nproblem except to explicitly percent-encode path components in my own code.\nlet mut u = hyper::Url::parse(\"http://www.example.com/\").unwrap();\nu.path_mut().unwrap()[0] = \"foo%2Fbar\".to_string();\nprintln!(\"{}\", u);\nu.path_mut().unwrap()[0] = \"foo%3Fbar\".to_string();\nprintln!(\"{}\", u);\nYuk!\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/638.\n. I think the task of getting the proxy settings should be outside of hyper. The configuration could come from anywhere (environment variables, command line arguments, config files, hard coded, etc). Instead, hyper should accept the parameters in the Proxy constructor.\n\nFor instance: \nrust\nclient.set_proxy(Proxy::Http {\n    host: env::var(\"HTTP_PROXY_HOST\").unwrap(),\n    port: env::var(\"HTTP_PROXY_PORT\").unwrap(),\n})\n\nAlso, it is possible to build a Proxy entirely outside of this crate, and use a hyper Client internally.  That's why I've mentioned trying not to adjust too much of the internal http protocol modules. The Client (and Request) just need to be able to use all the parts of RFC7230, such as the CONNECT method and alternate RequestUri formats. I'd rather if the logic to use those was contained in the Proxy type.\n. Ideally some of this work can be brought over to the async world, as I hope to merge async io soon. It may even be that since the async version of hyper is a little lower level, using a proxy may be easier.\n. Looking in the spec, redirection of methods should only be done automatically for 'safe' methods, which PUT is not.\nSo, this would require config to explicitly redirect the method and payload even if method.is_safe() is false. Perhaps a modification to the RedirectPolicy enum. Also, this might be tricky with the body being a Reader. Once the body has been copied into the request body, it probably can't be re-read again...\n. I agree on both accounts: the behavior should be adjusted, and document should be updated to reflect that adjustment.\nIt'd probably also be useful to improve the design of FollowIf, to provide enough information to implement a sort of FollowUnsafe that one requires. That'd need the Method, Url, and anything else?\n. The FollowIf policy would actually need mutable access to headers as well. The RedirectPolicy cannot be used in servo yet, since depending on the method, some headers must be removed or added. They also keep track of every Url seen, so that redirect loops can be detected and aborted. But that's probably worth a separate issue, so the action here is a FollowSafe policy.\n. I'm removing RedirectPolicy in the async branch.\n. This seems like an acceptable situation while async support is worked out. Thanks!\n. Yep, try updating hyper, this was fixed in a patch.\nOn Fri, Sep 4, 2015, 12:26 AM Jo\u00e3o Neves notifications@github.com wrote:\n\nAs noted in this other (closed) issue: #365\nhttps://github.com/hyperium/hyper/issues/365\nWhen receiving empty response data, hyper consistently panics with:\nthread '' panicked at 'thread 'Http11Message lost its underlying stream somehow.', /home/jneves/.cargo/registry/src/github.com-0a35038f75765ae4/hyper-0.6.10/src/http/h1.rs:270\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/646.\n. @mlalic It's possible to add ?w=1 on the end of diff URLs, and it will ignore whitespace changes :D\n. I haven't determined if unsound yet, but this unsafe worries me. If the\nclosure panics, then there will have existed 2 streams, duplicates of each\nother.\n\nThat'd mean the destructor would run on both of them.\nOn Sun, Sep 6, 2015, 6:02 AM Marko Lalic notifications@github.com wrote:\n\nTIL :)\nThough I'm not really surprised as it's just git diff -w\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/648#issuecomment-138083377.\n. I like it! \n. Nice!\n. Sounds fine to me.\n. @tabac sure!. Is this in common use? I've never used it myself, and when checking the dev consoles, I notice neither Firefox nor Chrome set that header while browsing.\n. Ah yes, quite true. I had forgotten.\n. Go for it!\n\nOn Thu, Nov 19, 2015 at 4:56 AM Martin Feckie notifications@github.com\nwrote:\n\n@seanmonstar https://github.com/seanmonstar Is anyone working on this?\nIf not I'd be interested in giving it a go\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/651#issuecomment-158049297.\n. The current type in rust-url is an enum with an OpaqueOrigin variant, which is not needed in the header. So, I'm thinking we do something like this:\n\n``` rust\npub struct Origin(String, String, Option);\n// support default ports\nimpl PartialEq for Origin {\n    fn eq(&self, other: &Origin) -> bool {\n        if self.0 == other.0 && self.1 == other.1 {\n            self.2.or_else(|| default_port(&self.0)) == other.2.or_else(|| default_port(&other.0))\n        }\n        false\n    }\n}\nfn default_port(scheme: &str) -> Option {\n    match scheme {\n        \"http\" => Some(80),\n        \"https\" => Some(443),\n        _ => None,\n    }\n}\n```\n. @puhrez since the Origin header only makes in CORS requests, may as well use the definition from the most up-to-date spec governing them: https://fetch.spec.whatwg.org/#origin-header\nIn that spec, the Origin is only ever 1 value.\nYes, a header needs to implement Header (and HeaderFormat in the 0.9x branch. If possible, the header! macro handles this merge of traits).\nA u16 means unsigned, so a bit isn't dedicated to the sign. This means it's range is 0-65535, which is the full range of possible ports.\n. I imagine this occurs because the string {} is being posted as the request body, and then it's not being read in the hello handler. Hyper then wrongly continues the next request starting from those bytes.\n. Yep, just browsed the code, this is the case. See https://github.com/hyperium/hyper/issues/309\n. Looks great! If you could squash the commits into 1, I'll merge!\n. I don't mean to be argumentative, I really do appreciate the PRs.\nI just want to talk through this first. It seems like a tiny amount of code, who cares, but it slowly expands the surface area of the API (and the documentation). So, is it awkward to have to use client.request(Method::Patch, ...)? I must say, in my years as web developer, I've never actually even needed to reach for the PATCH verb. Also, when I look around at other Client APIs, the convenient methods I see are the ones already here in hyper. I don't recall seeing one for PATCH or others.\nI could just be being an unintentional jerk, and should just merge this.\n. I wasn't worried about maintenance, but rather \"when a user goes to the Client doc page, does extra convenience methods help, or provide noise.\" As in, do the convenience methods pull their weight. I'll merge this, but just wanted to bring it up since I imagine a similar PR adding a method for the CHECKOUT or other obscure method would be denied.\n. > If its of any value it was the lack of a doc for this method that forced me to read through the source code to figure out the method didn't actually exist. As a user, it just felt like it should exist.\nOh? Interesting. My initial reaction when using any method thats not one of the big 4 (get, post, put, delete) is to look for the method that lets me specify the exact method I want...\n. Indeed, the builder pattern kinda sucks both ways in Rust. When using &mut self, you get 2 annoying issues:\n- let builder = Builder::new().set_foo(1).set_bar(2) ends up with builder being &mut Builder, pointing at a value that has been dropped (the compiler complains the original value doesn't live long enough).\n- let foo = builder.set_foo(1).consume() You cannot chain into the consume method, since all those methods return &mut self, and to end, self is required.\nThis ends up requiring that you split into at minimum three lines:\nrust\nlet builder = Builder::new();\nbuilder.set_foo(1).set_bar(2);\nlet foo = builder.consume();\n. @reem yea, i was actually looking at that crate last night when answering this. Only thing I dislike is that it requires a bunch more imports to use the RequestBuilder.\nFrom:\nrust\nlet res = client.get(url).header(foo).header(bar).body(\"baz\").send();\nTo:\nrust\nlet res = client.get(url).set(Header(foo)).set(Header(bar)).set(Body(\"baz\")).send();\n. Maybe. Some of what happens in Client is redirect policy stuff, which I felt logically was separate from the Request class.\n. RequestBuilder has been removed in master.\n. @shaleh no, the pull request still contains the previous commit, as gitcop says, eea3c2b. Try git rebase -i master\n. Thanks for the effort in this PR! I'm going to close this, as we're not quite sure if this makes the example easier to read, or rather, that it shows the parts we want it to.\n. Yea, this requires rust 1.3+.\nIt's unfortunate that this happened in a \"patch\" version, but prior to 1.0, all versions are pretty much shifted over one. Come hyper 1.0, I'd expect any change requiring a newer rustc to bump the minor version.\n. Newer RFC: http://tools.ietf.org/html/rfc7234#section-5.3 . It says similar.\nI don't see a way (for now) to do this without set_raw, or implementing your own Expires header. (All implementations that exist in hyper don't prevent custom implementations).\nIf there is great need, maybe Expires could be an enum Expires { At(HttpDate), Past }. Which RFC requires this?\n. Yep, the solution is described in #298 \n. The Client does support connection pooling. To reuse an existing\nconnection, you must wait for the first connection to complete its request.\nAlso, there are some conditions that it won't reuse the connection:\n- the server sent back 'Connection: close'\n- there was an IO or http error while using the connection\n- the response was not fully read, which would prevent parsing of the\n  second response.\nOn Fri, Oct 16, 2015, 8:39 AM nnovikov notifications@github.com wrote:\n\nIt's possible?\nI try create one client and run post() many time. Hyper close connection\nand reopen it again. With client.clone() code works in the same way.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/668.\n. Interesting idea! What does the new crate improve on over mime?\n. Hm, I still prefer having specific Rust types for the common cases, as I find Strings to be too fragile...\n. I'm hoping to edit the mime crate to better support stars, suffixes, etc, and also reducing allocations to none (or 1 if mutable), similar to the Url crate rewrite.\n. Gr, I should probably make a release.sh that runs git tag and git push after cargo publish.\n\nHere is 0.6.15: https://github.com/hyperium/hyper/releases/tag/v0.6.15\n. Just published v0.6.16 that includes this.\n. holy carps yes!\n. You can try to get a reference to the ssl stream, if you know what it is (by default, openssl's SslStream), and from there, its up to the implementation.\nhttp://hyper.rs/hyper/hyper/server/request/struct.Request.html#method.ssl\n. This is likely a good idea. Though I'm intrigued that so much can happen after a panic...\n. Thanks!\n. I've fixed this in the 0.9.x branch, it will be part of the next bug fix release.\n. @mikedilger indeed, this is a lot of work! awesome!\nI've reviewed the code, though I must say, I'm not too familiar with this header, so I may have missed something.\n. Seems a new version is needed of the url crate?\n. @mikedilger I see it's passing now. Awesome!\nCould you rebase this into a single commit, feat(headers): add Content-Disposition ...? The current commits will make the changelog confusing (fixing bugs that were never released, etc).\n. Seems another PR updated the Cargo.toml to bump the url version already, making a conflict here.\n. \\o/\n. Thanks!\n. Indeed, it would seem the bug is in the parsing of the TransferEncoding header. It should handle more than 1 field occurrence. \n. This occurs in the parsing. TransferEncoding uses parsing::from_comma_delimited(), which currently only allows 1 line of a header.\nI cannot recall if there are any headers that are comma separated but should be rejected if there is more than one line. If not, then the fix would be in the from_comma_delimited method to check all the lines, not just the first.\n. Yes, the Client will keep (up to 5 by default) sockets open if keep-alive is possible. However, once the Client is dropped, that will drop the HashMap of open sockets as well.\nHave you actually hit this in an application?\n. @Ryman how so?\n. Ah, I see. That is irritating. I think the cookie type should probably be exported somewhere in hyper, so that it can be used without also having to depend explicitly on cookie. Such as in header::shared::Cookie.\n. Hm, I had read the opposite just recently, that a crate should probably\nreexport types that it depends on. I can't recall where I read that,\nthough.\nHyper has reexported Url since forever, and I haven't heard of issues about\nthat.\nOn Fri, Nov 20, 2015, 12:05 PM Ryman notifications@github.com wrote:\n\nYeah, it can be a pain. The re-exports should help in future, I think, but\n(at least at the time) there were suggestions that it might not be a good\npractice to follow in general though on an issue I logged about this: rust-lang/cargo#1636\n(comment)\nhttps://github.com/rust-lang/cargo/issues/1636#issuecomment-105704163\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/687#issuecomment-158511027.\n. Thanks for the pull request! Just so you know, you can edit commits with git rebase -i master, and then force push to this branch to update the PR.\n\n\nLooking into the spec, I found here a more in-depth ABNF, specifically allowing null or a space separated list of origins, being scheme://host[:port]. Does that match what is used in the wild?\n@Manishearth you've done a bunch of the CORS stuff in Servo, is there anything here that should be considered? Or anyone else that should be pinged?\n. @Manishearth Ah, so the fetch spec doesn't allow for a list of origins, just a single one.\nMy understanding of your suggestion would look something like this:\n``` rust\npub struct Origin(Url);\npub enum OriginError {\n    Url(url::ParseError),\n    PathNotAllowed\n}\nimpl Origin {\n    fn new(t: T) -> Result {\n        let url = try!(t.into_url());\n        if url.path().is_some() {\n            return Err(OriginError::PathNotAllowed)\n        }\n        Ok(Origin(url))\n    }\n}\n``\n. @untitaker I don't believe it does. At least, browsing through the docs, I couldn't find one.\n. @Manishearth looks like port is required, but the spec doesn't require it.\n. I realize there's a default port by scheme. I should have said more. The spec for theOrigin` header says the port is optional. By internally using a structure that doesn't record if the port was present, re-serializing will have different output from the input.\nrust\nlet s = \"https://rust-lang.org\"\nassert_eq!(s, Origin::from_str(s).unwrap().to_string())\n// \"https://rust-lang.org\" != \"https://rust-lang.org:80\"\nIf we chose to always remove the port if it is the default, we still could change the value, since the default port may have been part of the original header.\n\nI'm not sure how important this is in practice, since they should be equivalent to each other, but I can also imagine bugs happening because of this.\n. Unsure if this should be addressed in rust-url. For hyper, it could be enough to define our struct like this:\nrust\nstruct Origin {\n    origin: url::Origin,\n    show_port: bool,\n}\n. @untitaker I'd like to agree, but I worry humans don't actually implement what the spec says (all too common).\nExample: if using url::Origin, then in hyper a Origin::new(\"http://foo.example\") would return in Origin(url::Origin(\"http:\", \"foo.example\", 80)). Serializing this into a request would look like this:\nGET / HTTP/1.1\nOrigin: http://foo.example:80\nLooking in the CORS code of 2 popular nodejs libraries, I believe this would be rejected.\n- expressjs: https://github.com/expressjs/cors/blob/ddc7d03e12db8e74d44b73aa6136b90b2bd25640/lib/index.js#L26\n- hapijs: https://github.com/hapijs/hapi/blob/492e59496abcbc3d73642e5b1391bd3b8b6b1e1d/lib/cors.js#L183\nThey both do exact String matches, forgetting that default ports should matter as well.\n. Closing as inactive.\n. @untitaker this PR has struct Origin(pub String);. The discussion in the PR suggests having an Origin that knows the scheme, host, and port (perhaps from the url crate).\n. It may be sufficient to use url's Origin, and in the fmt_header method, leave off the port if it is the default port.\n. I think the Origin type in url looks a bit different in the proposed 1.0 branch.\n. This looks great to me. Thanks! \n. Fair point. A nice fix here would be to use the description for hyper errors, but delegate to fmt of errors from other crates.\nExample:\n``` rust\nimpl fmt::Display for Error {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        match *self {\n            Io(ref e) | Uri(ref e) | Ssl(ref e) | Http2(ref e) | Utf8(ref e) => fmt::Display::fmt(e, f),\n            e => f.write_str(e.description())\n        }\n    }\n}\n``\n. With https://github.com/rust-lang/rust/pull/30312 being merged, at least this should state something more thanos errorin Rust 1.7, which is an improvement...\n. @xaviershay it's because thedescriptionofio::Errorbefore Rust 1.7 simply says \"os error\". Instead of printing the description, we could print the fullfmt::Debugmessage ofio::Error` (or, in 1.7, the description will match the Debug output anyways).\n. @josephpd3 I'm sure that PR improved things. We could make it a little better in hyper by doing as I suggest in the 2nd comment.\n. The update to cooke@0.2 will be part of the 0.7 version of hyper, which will be published today.\n. @opensourcegeek No, this makes use of TcpStream::set_write_timeout. That sets a socket option to allow blocking on the write (and read for the other timeout) up to the amount of time specified. The time is not tracked between writes.. @opensourcegeek that looks correct to me!. I originally made that struct as a convenience when passing it around internally. I'm not so sure I'd want it part if a public API... Can you have a struct in Iron to do it? \n. I'm not yet sure how timeouts will be set in the mio branch. Could you dupe\nthe struct in Iron for now? If this struct is kept in hyper, it can be made\npublic eventually, and you could swap the def for a reexport and it should\ncontinue to work.\nOn Sat, Nov 28, 2015, 1:28 PM Jonathan Reem notifications@github.com\nwrote:\n\nI could just duplicate this in iron, but it seemed better to just expose\nit.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/697#issuecomment-160336903.\n. Closing this for now. Can revisit once hyper uses async io, and the timeout strategy is decided upon.\n. Indeed, it seems this is better behavior. Thanks for the patch!\n. This seems clever, but I worry it might be too clever. Let me see. The status codes will be duplicated into the scoped module? Such that StatusCode::BadRequest and scoped::ClientError::BadRequest will exist? I imagine people trying to *res.status_mut() = ClientError::BadRequest and wondering why they are getting errors...\n. I'm +0. If you two feel strongly that this is an overall win, then @reem can merge at his convenience.\n. Closing for now, but I'm not against proposals. Thanks for the idea!\n. You can call 'handle_threads(handler, num)' to do exactly that.\n\nOn Tue, Dec 8, 2015, 8:40 AM Philippe Delrieu notifications@github.com\nwrote:\n\nI work on HTML5 SSE connection that never answer and block the listening\nthread on Hyper. On machine that has only one CPU, the server number of\nlistening thread is 1 calculated from number of CPU:\nserver/mod.rs line 229 self.handle_threads(handler, num_cpus::get() * 5 /\n4)\nWith this configuration, I can't handle any more connection when the SSE\nconnection is started.\nIt will be interesting to add a way to force the min / max number of\nthread, or to add a new thread when all connection is busy or under\nspecific condition, ....\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/701.\n. Is this sort of thing common in many other headers? If so, perhaps it would make sense to define a struct in the shared module, instead of this returning a tuple?\n\nTest failure was unrelated. Also, as this adds a new method (and possibly struct), could reword the commit message to be a feat(headers)?\n. This looks really good, thanks!\n. @sfackler Thanks!\n. Something like this Ssl trait?\n. While hyper uses std::net, the blocking io is used. Without select, the\nonly way to know a Connection was closed is to try to write to it (or read,\nwhich will block until keep alive notices it's dead).\nSo you can only either read or write on it to determine if it's closed.\nOn Tue, Dec 22, 2015, 1:42 PM Alexandre Bury notifications@github.com\nwrote:\n\nSimilar to what golang provides with CloseNotifier\nhttps://golang.org/pkg/net/http/#CloseNotifier, when a request takes a\nwhile to process (or is just waiting/long-polling), it is often convenient\nto detect when the client closed the connection.\nI did not find a way to get this information with hyper (maybe I just\nmissed it?).\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/707.\n. If the request has no body, then a read will return EOF. \n. That presents a different problem though, since std::net uses blocking IO. If hyper let you try to read on the socket after having read all the declared request body, the read would block until 1) the client sent more data, or 2) the client disconnects. If it's a GET request, the client does not expect to send any more data, so you would block yourself until the client timed out. No further code would execute in that thread.\n\nYou might be able to get something if you duplicated the socket, put it in another thread, and let it readblock there...\nEither way, the move to async IO should help, since epoll gives notifications when the client hangs up.\n. The problem is you would need to be sure that no other data would be coming from the connection. Otherwise, the other thread would get it, instead of your main thread.\nYou could do this yourself, for now, anyways:\n``` rust\nlet mut tcp = req.downcast_ref::().unwrap().0.try_clone().unwrap();\nlet (tx, rx) = std::sync::mspc::channel();\nthread::spawn(move || {\n    tx.send(tcp.read(&[0u8]))\n});\n// else where\nmatch rx.try_recv() {\n    Ok(Ok(0)) => eof(),\n    Ok(Err(io_error)) => error(),\n    Err(TryRecvError::Disconnected) => thread_is_dead(),\n    Err(TryRecvError::Empty) => still_connected()\n}\n```\n. Nice! Thanks for the tedious work.\n. Yikes, forgot about this over the weekend.\nSeeng that you're on a Mac, I'd bet the problem is that your computer currently still has the archaic version of openssl that OSX ships with. Try updating openssl.\n. You can try using the 'security-framework' feature instead of the 'ssl'\nfeature in your Cargo.toml.\nOn Tue, Aug 9, 2016, 7:19 AM Kilian Koeltzsch notifications@github.com\nwrote:\n\nCurrent homebrew (v0.9.9) is refusing to link openssl \ud83d\ude15\n$ brew link --force openssl\nWarning: Refusing to link: openssl\nLinking keg-only openssl means you may end up linking against the insecure,\ndeprecated system OpenSSL while using the headers from Homebrew's openssl.\nInstead, pass the full include/library paths to your compiler e.g.:\n  -I/usr/local/opt/openssl/include -L/usr/local/opt/openssl/lib\nI'm failing to compile hyper 0.9.10. Should this be using something\ndifferent than openssl on macOS or is this still correct? I'd love to get\nthis working somehow.\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/709#issuecomment-238565495, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AADJF10kFocOQEZgRuUvW0RqiTDquhESks5qeIrDgaJpZM4G7PrN\n.\n. The async API already provides Response and &mut Decoder separately, so I think this will be solved with that.\n. It's crashing because of the call to unwrap. You'd be better off matching on the Err case. \n\nThis instance is because a socket in the client connection pool went stale. \n. Darn mobile, thumbs tapping close buttons... \nWith blocking IO, checking to see if a Connection was still alive could block the thread. So instead, the error happens the first time you try to write after the connection had been closed. \n. > Hyper client keeps pool of sockets for its requests?.. Didn't know that.\nYep! It's likely what most people would want, but it can be customized (or turned off): http://hyper.rs/hyper/hyper/client/struct.Client.html\n\nHm, so I should just retry in such case?.. Is that a legitimate solution?\n\nThis is exactly what Servo does: https://github.com/servo/servo/blob/master/components/net/http_loader.rs#L684-L685\n. What version of rustc? Are you using current stable, 1.5?\nOn Tue, Dec 29, 2015, 10:38 PM Yoshua Wuyts notifications@github.com\nwrote:\n\nNot sure what I'm doing differently, but when installing hyper I get an\nerror. I tried adding the #![feature(box_raw)] header to my main.rs file,\nbut that doesn't seem to help. Any ideas what's going wrong? Thanks!\nerror\n\u276f cargo build\n   Compiling openssl v0.7.4\n/Users/yw/.cargo/registry/src/github.com-0a35038f75765ae4/openssl-0.7.4/src/ssl/bio.rs:42:\n22: 42:35 error: use of unstable library feature 'box_raw': may be renamed\n/Users/yw/.cargo/registry/src/github.com-0a35038f75765ae4/openssl-0.7.4/src/ssl/bio.rs:42\n        (bio).ptr = Box::into_raw(state) as mut _;\n^~~~~~~~~~~~~\n/Users/yw/.cargo/registry/src/github.com-0a35038f75765ae4/openssl-0.7.4/src/ssl/bio.rs:145\n:5: 145:36 error: use of unstable library feature 'box_raw': may be renamed or moved out o\nf Box scope\n/Users/yw/.cargo/registry/src/github.com-0a35038f75765ae4/openssl-0.7.4/src/ssl/bio.rs:145\n     Box::>::from_raw((bio).ptr as mut _);\n^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nerror: aborting due to 2 previous errors\nCould not compile openssl.\nTo learn more, run the command again with --verbose.\nopenssl\nopenssl version -a returns:\n\u276f openssl version -a                                                                  <<<\nOpenSSL 0.9.8zg 14 July 2015\nbuilt on: Jul 16 2015\nplatform: darwin64-x86_64-llvm\noptions:  bn(64,64) md2(int) rc4(ptr,char) des(idx,cisc,16,int) blowfish(idx)\ncompiler: -arch x86_64 -fmessage-length=0 -pipe -Wno-trigraphs -fpascal-strings -fasm-bloc\nks -O3 -D_REENTRANT -DDSO_DLFCN -DHAVE_DLFCN_H -DL_ENDIAN -DMD32_REG_T=int -DOPENSSL_NO_ID\nEA -DOPENSSL_PIC -DOPENSSL_THREADS -DZLIB -mmacosx-version-min=10.6\nOPENSSLDIR: \"/System/Library/OpenSSL\"\nCargo.toml\nThis is my Cargo.toml\n[package]name = \"playground-rust-hyper\"version = \"1.0.0\"\n[lib]path = \"main.rs\"\n[dependencies]hyper=\"0.7.1\"\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/712.\n. Thanks!\n. With async hyper, this doesn't happen in Drop anymore, but the concept can still be done.\n\nIn the Http1 state machine, if the user has indicated Next::end() without writing any body, this header could be added.\n. This exists in master as follows: if no body was set on a request or response, then the Content-Length will be set to 0. There is some logic to not do this if it is a client request with GET or HEAD.. Hm, what version of hyper? I just tried that URL using https://github.com/hyperium/hyper/blob/master/examples/client.rs and it worked for me.\n. I believe this is a bug in the resizing of the buffer. It seems to zero the entire thing, not just the new part.\n. Oh yes of course, since it's returning a value, that'd mess with anyone who didn't have a semi-colon in place. Hrm...\n. @MichaelZapataScality I really appreciated the PR. This likely would be useful, but it seems this is indeed a breaking change, so if accepted, I'd wait to merge this for 0.8, with any other breaking changes.\n. I'm not so sure of adding this right now. Thanks for the idea, though!\n. #395 is on master now. You can receive a Control from hyper that allows you wake up the socket every time you have a new event to send, and then write the payload when the loop has woken up the socket.\n. @shepmaster yes, I would expect that to eventually trigger Handler.on_error(Error::Timeout).\n\n@mikeycgto hyper won't be exposing the rotor interior. I'd rather the internals of how hyper works not be part of its public contract.\nYou could do it the way @shepmaster did, by spawning a thread to wakeup the Control eventually. My first thought was instead to send the Control of the request to something that pools all of them, using something like a HashMap<StreamId, Vec<Control>>, when there is a /publish/some_id, you can send the contents to that thingy, it looks up all the subscriptions to that stream, and calls control.wakeup(Next::write()), on all of them.\nAnd then in the on_response_writable method, you can lookup all the new messages that need to be sent.\n. That error you received is because you tried to put HashMap<T, Control> into an Arc. Arc requires that anything put into it be Sync. The Control isn't Sync because it uses std::sync::mpsc::Sender internally, which itself is not Sync.\nOne possible option is to use a Arc<Mutex<HashMap>>, because a Mutex will guarantee synchronization of the value it's guarding.\n\nAlternatively, hyper could force unsafe impl Sync for Control {}, by making sure the Sender used internally is always cloned once. mpsc::Sender starts with internals that don't synchronize the sending with other threads. Once it has been cloned once, the internals upgrade to be safe. Unfortunately, mpsc::Sender remains !Sync, because that's how the type system works.\nSo, hyper could do something like this:\n``` rust\nstruct ClonedSender(Sender);\nunsafe impl Sync for ClonedSender {}\nimpl ClonedSender {\n    pub fn new(sender: Sender) -> ClonedSender {\n        sender.clone(); // upgrades internals\n        ClonedSender(sender)\n    }\n}\n```\nIt's safe, and allows Control to be Sync. But it also means that everyone pays the synchronization cost, even if someone only ever needs 1 copy of Control...\n. Do you have any more specific info, such as OS, if using child processes, or calling in to Rust from another language, or anything?\nRust specifically turns off SIGPIPE behavior here: https://github.com/rust-lang/rust/blob/master/src/libstd/sys/unix/mod.rs#L76\nSo I'd think that if something is occurring that skips that, it should probably be fixed in Rust itself.\n. Hm, some superficial Googling suggests that even with signal(SIGPIPE, SIG_IGN), gdb will still notice the signal and exit? Example http://ahlamnote.blogspot.com/2006/12/gdb-ignore-sigpipe.html\n. I'm going to say that and SIGPIPE happening in Rust program that uses libstd is perhaps a bug in libstd.\n. This is because there's actually 1 more timeout we would want, but we cannot currently set using std::net. This would be the connect timeout, for resolving the DNS. Current std::net uses a blocking request getaddrinfo, which doesn't have a way to specify a timeout.\nHopefully async resolve can be figured out and added in to the async version of hyper (when that comes out).\n. The is a connect timeout on master, so closing this.\n. Seems this isn't an issue anymore.\n. The spec does a poor job of defining exactly what it is, it's only ever mentioned briefly in paragraphs \"if there is a last event id, set this header\".\nIs it basically just struct LastEventId(pub String)?\n. The spec actually says that a payload is allowed:\n\nA payload within a GET request message has no defined semantics;\nsending a payload body on a GET request might cause some existing\nimplementations to reject the request.\n\nIt says the same thing for HEAD requests. How horrid.\n. @nnovikov I meant that you are right, the spec technically allows it. I just feel icky thinking about it.\n. Thanks, it took me a while to understand how this fixed it, but I finally realized that the server doesn't use the HttpsStream enum. I've merge this into the 0.9.x branch.\n. Trying to understand why those 2 windows builds are failing. 0.7.2 passed, but rustc nightly has a habit of breaking windows... \n. I agree with jdm, while this is certainly convenient, it's not part of the\nHTTP spec (if it is, I can't find it). I'd expect a higher level 'request'\nlike crate to do several of these things automatically.\nOn Sun, Feb 14, 2016, 9:38 AM Manish Goregaokar notifications@github.com\nwrote:\n\nAlright. Perhaps I should leave the from_url commit here?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/727#issuecomment-183935000.\n. I'm going to close this in favor or #894, as there is more discussion there.. :+1: \n. It feels weird to be on the Headers struct, but I think it'd be an excellent method for the ContentType struct. headers.get::<ContentType>().and_then(|ct| ct.charset()). What do you think of that? No additional imports required. \n. Interesting idea. I find the encoding property to be confusing, because\nthere is a Content Encoding header as well. Does it take that into account?\n\nOn Wed, Feb 17, 2016, 12:44 AM Simon Sapin notifications@github.com wrote:\n\nThis would be ~half as useful. Doesn\u2019t that code need to import\nContentType? In addition to imports, the point is to make this more\ndiscoverable.\nInitially I even wanted this on Response, but some_response.headers is\neasy enough to access.\nFor what it\u2019s worth, the Requests library has a Response.encoding\nhttp://docs.python-requests.org/en/master/api/#requests.Response.encoding\nand demonstrates it on their home page:\nhttp://docs.python-requests.org/en/master/\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/730#issuecomment-185098833.\n. I'd like to rewrite the mime crate soon, and I believe that would change how this works. As such, I'd rather not include something that will soon break, so closing until then.\n. Yikes, thanks for catching this!\n. Thanks for pointing this out. I've fixed it in https://github.com/hyperium/hyper/commit/63b2759e2fbf55dbf28289681d5fadc20f714138\n\nFor learning purposes, the warning is that Server::handle returns a Result<(), hyper::Error>, depending on if the spawning of the threads succeeded or failed. A common bug in applications is ignoring that an error occurred, so a default warning in Rust is that you should check what happened with a Result. In that commit, the solution is to unwrap the Result, which basically says \"if the threads didn't spawn, we should panic.\" That may not be the best solution in all applications, but it works for an example.\n. buf_redux looks interesting! All my current work is trying to get the async IO support done, in the mio branch, which no longer uses a big BufReader.\n. Yes, synchronous I/O is being removed from hyper. A \"hypersync\" or similar crate will likely exist. I'm close to merging that into master, so I'm going to close this issue for now. Thanks for the suggestion though!\n. Those have been failing for a couple weeks. I haven't taken the time to\ninvestigate why only those environments crash.\nOn Sat, Feb 27, 2016, 2:49 PM Jonathan Reem notifications@github.com\nwrote:\n\nHmm something appears to be very wrong on some of the windows builds, they\njust quit randomly in the middle of the tests with a random-looking exit\ncode.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/736#issuecomment-189742856.\n. Indeed, this seems like an error.\n. I agree, the mime crate needs some work. I've been working on a re-working of it, where a Mime just has several Name values. the Name struct is wrapper around str that provides some syntax guarantees, such that a Name only includes characters allowed by the spec. Otherwise, all the current variants I've converted into constants, so mime::Json still exists and can be used in match expressions.\n. The work-in-progress rewrite: https://github.com/hyperium/mime.rs/tree/ng\n- Needs something to determine when a parameter can be case-insensitive, such as Charset.\n- Operator overloads are cute, but may be the devil.\n- Some optimization could be added to reduce the amount of Strings allocated during parsing (such as comparing to a list of common constants).\n. So it's been a while, but I finally got around to having a redesign I think I like. See https://github.com/hyperium/mime.rs/pull/50. Thanks!\n. Test failure:\n\nsrc/client/request.rs:231:9: 231:55 error: this function takes 1 parameter but 2 parameters were supplied [E0061]\nsrc/client/request.rs:231         form_urlencoded::Serializer::new(&mut body, 0).append_pair(\"q\", \"value\");\n                                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n. Thanks for the pull request! \nI'm not sure I want to be running all of clippy against hyper. Some of the links are quite useful, but quite a few others I don't fully agree with. \n. Thanks! \n. This looks fantastic. If you could add the ContentLength test back in, this will be good to go!\n. Thanks!\n. Excellent, thanks!\n. Thanks! \n. The spec points out that order is not required to be preserved. Headers are\nstored in a hashmap, which does not preserve order. To do so requires more\nmemory/cpu.\nOn Sun, Mar 20, 2016, 2:49 PM Caleb Meredith notifications@github.com\nwrote:\n\nWhat is the output order for headers and is there anyway to enforce an\noutput order? Currently the order seems random.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/746\n. This is the first I've heard of this header. Is there a situation where its usage is common?\n. I recall finding that weird as well, but I was also left wondering if this fit better into the mime crate, or here in hyper.\n. @puhrez probably, though I think I'd like to the get ng branch finished and merged to master first.\n. For now, the new version of hyper won't be including the typed headers directly, so I'm closing this here as a won't fix.. That's disappointing. The blocker here is that mio needs to update to nix@0.5?\n. With mio@0.5.1, seems this can closed.\n. Oh wow, this is extensive. Thanks for being thorough!\n\nI was wondering in the issue #747 whether many people use this, because I was wondering if it should be part of hyper, or if the implementation can live in your own crate.\n. @calebmer seems the error was an intermittent. I restarted the build. I've also asked on IRC for some others to put feedback, as I have no experience with this header :)\n. @calebmer I'll merge this after comments are addressed. Thanks again for such a thorough job.\n. Excellent! Thank you!\n. Yes, your guess is correct. I assumed most people wanting an easy constructor with a cert and key were using it for a server, not a client.\n. Indeed, SSL was removed, see #985.. The error is a combination of 2 things:\n1. The Client is reusing the socket, since the server responded with keep-alive. This is not a bug.\n2. The server is sending an extra \\n after the end of the first response, and so when the hyper starts to parse the second response, it first sees the stray \\n. hyper's parser knows to skip empty lines when handling server requests, but it seems that it was not included in client responses.\nI'll fix it in the httparse crate, and since it's a bug fix, you'll be able to just cargo update to receive it.\n. Just tried with the latest update of httparse v1.1.2, and it now works properly!\n. Thanks for noticing!. Note that while the current traits require the Stream to be Clone, this is not necessary on the mio branch.\n. I was wondering, is it possible to conditionally set the default based on\nOS? Or would that require a separate crate to do it?\nOn Sun, Apr 17, 2016, 11:02 AM Corey Farwell notifications@github.com\nwrote:\n\nUpdate: this is now merged in #762\nhttps://github.com/hyperium/hyper/pull/762, but OpenSSL is still the\ndefault on OS X\nhttps://github.com/hyperium/hyper/blob/635622c37fa93e32fecb9378a8aab1e2117064d1/Cargo.toml#L52.\nIn a future breaking change release, the default should probably switch to\nsecurity-framework? Then #709\nhttps://github.com/hyperium/hyper/issues/709 could probably be closed\n(if not already).\nOn a side note, @sfackler https://github.com/sfackler started\nhttps://github.com/sfackler/rust-native-tls which is Yet Another Layer Of\nAbstraction that wraps around the system native TLS bindings. So Hyper\ncould potentially use this to offload system TLS logic.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/755#issuecomment-211073038\n. @frewsxcv yea, that's what I meant by using a separate crate. I'm not sure I can use those directives, and also have it be a feature that you can turn on or off. \n. This is has landed, so closing.\n. Closing per conversation that async hyper is removing RedirectPolicy.\n. \\o/\n. Unfortunately, yes this is the current expected behavior. There are 2 ways\nto determine if a socket has been closed, trying to use it, or using async\nio to detect hang ups. We can't use it before you make a new request\nbecause we have no data to send, and trying a read would block the thread\nforever (since the server likely wouldn't send anything if there was no\nrequest).\n\nCurrently, you can catch those errors and retry the request. The async\nbranch (mio) is nearly ready to merge, which will solve this in a different\nway, if you'd like to try porting your code over early.\nOn Sun, Apr 17, 2016, 1:36 AM Pascal Widdershoven notifications@github.com\nwrote:\n\nI couldn't find anything about this in the docs so asking here.\nI'm sharing a single Hyper client across multiple threads (using\nlazy_static) and noticed that by default Hyper seems to try keeping\nconnections alive. For my use case that's great since I only ever call a\nsingle host. However I ran into issues where Hyper would start throwing\nconnection closed errors on repeated calls a couple of minutes apart.\nIs that expected? Should I retry the request in those cases? I somehow\nexpected that Hyper would handle setting up a new connection if the old\ngets stuck/closed.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/763\n. Thanks for the pull request!\n\nAs GitCop pointed out, the commit message format didn't fit the guidelines. I've made the change myself in a commit that does follow the format.\n. You can use either. Hyper has no knowledge of databases. If using sync\nconnections, you may want to put that in a thread pool, so as to not block\nthe server. You could look at Next::wait() and the 'Control' type received\nby Handlers to signal when the db has returned data and you can now write a\nresponse.\nOn Thu, Apr 21, 2016, 5:03 AM Daogang Tang notifications@github.com wrote:\n\n\ndid hyper mio branch support async postgresql connection pool?\nwhat about using the sync pg driver?\n\nthx.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/766\n. Yes, a hyper server will create one event loop. If you'd like to use\nmultiple (which likely makes sense if you have many cores), you can spawn\nmultiple servers.\n\nOn Thu, Apr 21, 2016, 5:04 AM Daogang Tang notifications@github.com wrote:\n\nhi, I tested hyper mio branch, found that only one cpu occupied. Did hyper\nmio branch use only one thread now?\nthx.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/767\n. Yep, you can definitely listen on the same port, the OS buffers incoming\nsockets and hands them to the first listener that takes them.\n\nOn Thu, Apr 21, 2016, 7:19 PM Daogang Tang notifications@github.com wrote:\n\nspawn multiple servers? listening the same port?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/767#issuecomment-213211932\n. What is the error? From looking it over, it looks correct...\n\nOn Mon, May 2, 2016, 5:15 AM Leo Lahti notifications@github.com wrote:\n\nAnd how multiple servers should be spawned? This code doesn't work\npub fn listen(self) -> Vec>> {\n        let address = self.addr.to_string();\n        let mut vec: Vec>> = Vec::new();\n        for _ in 0..num_cpus::get() * 4 {\n            let handler: FabricHandler<'static, D> = self.handler.clone();\n            let addr = address.clone();\n            vec.push(thread::spawn(move||{\n                Server::http(&addr.parse().unwrap()).unwrap().handle(move |_| handler.clone())\n            }));\n        }\n        vec\n    }\naddress is 0.0.0.0:3000\n\u2014\nYou are receiving this because you commented.\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/767#issuecomment-216220586\n. Oh right, I forgot that in the example I had used mysql, I created the listener, and cloned it for each thread.\n\nrust\nfor _ in 0..threads {\n    let listener = listener.try_clone().unwrap();\n    thread::spawn(move || Server::new(listener) ... );\n}\n. @TileHalo I've added that to the Hello World example: https://github.com/hyperium/hyper/blob/mio/examples/hello.rs#L35-L47\n. hyper is more than a parser. The parsing part is handled by https://github.com/seanmonstar/httparse, which was modeled after picohttpparser. hyper also aims to handle a lot of the semantics of http1/2. It is not itself going to be a competitor to h2o or nginx. Rather, it will power any competitors, along with any other sorts of servers that aren't reverse proxies.\nI've been working on a reverse proxy project that uses the async hyper, and I've spent many a evening reading h2o or nginx source code to see what lessons I can learn. I don't have a working project that I can commit to a repo just yet, as I want to also release async hyper soon. I've been working on the proxy as a sort of \"drive the async work\" effort. Once I have released async hyper, I can work more on the specific parts of a proper reverse proxy: configuration, various directives like headers, files, directories, proxy, and so forth.\n. Closing as there isn't really anything actionable for hyper here.\n. @daogangtang some things you could do it to construct an SApp when you construct the server, and make the factory return a reference to it, such as move |_| { arc_sapp.clone() }. I don't know if you need mutable access to the SApp. You can alternatively create a struct and implement HandlerFactory for your struct, instead of passing a closure, if that ends up looking cleaner.\n. @ishbir sort of. The commit was on purpose, but the hyper Client won't be doing as much automatically. In 0.10, it's possible to handle proxying completely outside the hyper crate. You can connect to any host, and then the handler can use request.set_uri(RequestUri::AbsoluteUrl(target_url)) which will send a request to the host and proxy it (assuming the host knows how to proxy).\nLikewise, to provide proxying to https targets, a Connect type can tunnel to the target host before returning a ready TcpStream.\n. Not in v0.9. In async hyper, I believe it'd be possible with a handler like this:\n``` rust\nimpl Handler for Upgrader {\n    // ...\n    fn on_response(&mut self, res: &mut Response) -> Next {\n        res.set_status(StatusCode::SwitchingProtocols); // 101\n        res.headers_mut().set(Upgrade::WebSocket);\n        // other websocket upgrading headers\n        Next::write()\n    }\nfn on_response_writable(&mut self, _enc: &mut Encoder) -> Next {\n    // head has been written\n    // now ask that the transport is removed from this hyper Server\n    Next::remove()\n}\n\nfn on_remove(self, transport: TcpStream) {\n    go_do_websocket_things(transport);\n}\n\n}\n``\n. This is possible on master.\n. They are common enough headers (especiallyWWW-Authenticate) that I would welcome these additions tohyper::header`. I can also mentor the design.\n\nMost of what you propose makes sense to me.\nI'm hesitant to add a dependency on rust-crypto, not because I dislike the crate, but I believe it still needs an audit from cryptographers. MD5 is small and easily verifiable. And having a dependency on rust-crypto may encourage using other algorithms \"since it's there\". Alternatives include using the md5 hash that's in the openssl crate, which is already a dependency. There's also the https://crates.io/crates/md5, or even just embedding the algorithm directly in the header::shared module.\nOr maybe @jdm would hit me over the head for suggesting that...\n. Probably easiest to just branch from master, since this stuff shouldn't require any of the async changes. It'll be easier to merge into master, and I've been rebasing master into the mio branch frequently, so it'll end up there soon.\n. Having Digest be its own crate seems nice for now. If the community wishes it were part of hyper, then it can be added easily enough.\nIt sounds like you (@matt2xu and @malept) seem to have a decent grasp on the problem. I've never actually used the WWW-Authenticate header myself (even though I work on the authentication part of FIrefox Accounts!), so I'd rather defer to you. \n. For now, the new version of hyper won't be including the typed headers directly, so I'm closing this here as a won't fix.. I see, I misunderstood the spec. I understood that the Host header is the host of the proxy server, with the absolute-uri in the request line aimed at the target host. Re-reading the spec, it seems I am indeed incorrect, as HTTP/1.0 proxies may just forward the Host header directly.\nIt may be that the proxy you are using is indeed using version HTTP/1.0, or otherwise has a bug itself\nas I noticed this is also in the spec:\n\nWhen a proxy receives a request with an absolute-form of\n   request-target, the proxy MUST ignore the received Host header field\n   (if any) and instead replace it with the host information of the\n   request-target.  A proxy that forwards such a request MUST generate a\n   new Host field-value based on the received request-target rather than\n   forward the received Host field-value.\n. @shaleh do you mind testing that this works with your proxy?\n. To support https end points, I'll need to work in an initial CONNECT example.dom HTTP/1.1 dance before assuming the connection can be wrapped in SSL... Sigh, I was hoping this would just be a minor fix. Although, I think doing the CONNECT stuff may be doable outside of hyper...\n. Yea, the issue is that by the time the code in Http11Message is running to write the data, the connection has already been made. However, once CONNECT has been passed, then the ssl handshake should take place to access the site over HTTPS.\n\nI'm now thinking of composing NetworkConnectors to get this.\n``` rust\nstruct Tunnel {\n    connector: C,\n    proxy: (String, String, u16),\n}\ntype HttpToHttpsProxy = HttpsConnector>;\nlet http_to_https_proxy = HttpsConnector::new(\n    Openssl::default(),\n    Tunnel::new(\n        HttpConnector, \"http\", \"my-proxy\", 8080\n    )\n);\n```\nSteps that would occur:\n1. Client.get(\"https://www.google.com\")\n2. let tcp = tunnel.connector.connect(tunnel.proxy)\n3. tcp.write_all(\"CONNECT www.google.com:443 HTTP/1.1\\r\\nHost: www.google.com:443\\r\\n\\r\\n\")\n4. Check for HTTP/1.1 20x response on tcp\n5. https_connector.wrap_client(tcp, \"www.google.com\")\n6. Carry on like normal.\n. It does seem that this is entirely implementable with the tools hyper provides, but I suppose this can be provided to ease usage of proxies for the easy cases. Those cases seem to be:\n1. http to the proxy, and then https to the target\n2. http to the proxy, http to the target\n3. https to the proxy, and then http to the target\n4. https to the proxy, https to the target\nAs before, any attempt to connect to the proxy or the target over https without the ssl feature would just result in an unknown scheme error.\nNext, to set it up on the Client, it could look like this:\nrust\n// if target-uri is https, tunnels over http to proxy, otherwise does absolute-uri as in current PR\n// if ssl feature is disabled, requests to https would return `Err(unknown scheme)`\nlet client = Client::with_proxy(\"http\", \"my-proxy\", 8080);\n. And thanks to a mistake in designing the Ssl trait, I cannot easily compose these connectors because I cannot make an SslStream<SslStream<HttpStream>> using the Ssl trait, since HttpStream is hard coded in.\nThough just think of that sounds horrible. Double encryption yum.\n. Ah, seems that is a job for NPN...\n. Next Protocol Negotiation, a recent addition to TLS. It allows converting a TLS connection into some other connection (it was originally created for SPDY/HTTP2 so clients can upgrade TLS to h2).\nBut that's a lot of work, and from my googling, the majority of people use HTTP proxies, not HTTPS, so I'm going to settle by only providing to HTTP out of the box (I want to get back to the async work).\nrust\nClient::with_http_proxy(\"my-proxy\", 8080)\nIt will always try the http scheme, being an http proxy.\n. Yes, it will tunnel to the HTTP proxy, and negotiate TLS after the proxy has tunneled tcp.\n. I'm not super pleased with the code, but it seems to work. Tests pass, and I edited the examples/client.rs to look for HTTP_PROXY env var, allowing me to to easily compare it's results with curl -x http://my-proxy:8080. My tests against real proxies seemed to work (or at least, if it worked with curl, it worked in hyper. Failures in hyper were also failures in curl, so... \ud83c\udf4c ).\n. @shaleh does it work with your corporate proxy?\nWith this PR, you can do HTTP_PROXY=my-proxy:80 cargo run --example client -- https://www.google.com\n. @shaleh The value provided does not include the scheme, right? The code in the example doesn't do as much parsing as it could have the HTTP_PROXY env var.\n. Interesting issue. I've since decided in the async  branch to adjust the\nConnect trait to accept &Url instead of deciding beforehand what a\nConnector may or may not need.\nIf there is no port, will the server expect the Host header to include the\nport from the SRV record?\nOn Tue, May 3, 2016, 11:36 AM Erik Johnston notifications@github.com\nwrote:\n\nI work on a project where we use HTTPS to talk between servers, but\nresolve the host via SRV records rather than A records. The flow from going\nfrom a host name to an IP is as follows:\n1. Does the URL have a port? If so then resolve using normal A records\n   and use the given port\n2. If not, resolve via SRV and use the ports returned by the SRV lookup\nI was going to write a custom Protocol that matched against the scheme,\nbut the Client object has already resolved the port (using\nUrl::port_or_default), which means that I can no longer do the check in\nstep 1 above.\nIs there a reason why Protocol::new_message doesn't take an Option,\nand have Protocol::{Http11Protocol, Http2Protocol} check the scheme is\neither http or https and default the port as required there?\nThis seems helpful more generally as well, particularly for implementing\nschemes that have default ports but that aren't known by url::Url\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/776\n. The Connect trait in master receives a &Url instead of an explicit port argument.\n. I should really change the example of setting a different header. I chose\nConnection because I thought it was clear what that header does. But I see\nit being used everywhere just because the example uses it :_(\n\nOn Wed, May 4, 2016, 8:55 AM Tom Burdick notifications@github.com wrote:\n\nWell one thing seems pretty different almost right away, your explicitly\nenforcing a new connection on each request in the rust version, in the go\nversion your leaving the decision whether to keep-alive the connection and\nreuse it up to the implementation. Removing the\n.header(Connection::close()) changes the program running time on my machine\nfrom 10's of seconds to 2.7s\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/777#issuecomment-216910480\n. The penalty when sharing the Client is due to accidentally keeping a Mutex\nlocked while waiting on DNS. The Mutex locks the map of pooled connections.\nA patch exists that unlocks the Mutex while waiting on DNS, so that other\nthreads may access the pool quicker.\n\nOn Wed, May 4, 2016, 10:05 AM weberc2 notifications@github.com wrote:\n\nRemoving the Connection header and not sharing the client bring the\ntime back down to parity with Go. It does appear it was the connection\nheader, and yes, I copied it from the example. It seems the biggest penalty\nwas still sharing the client; is this penalty expected as well?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/777#issuecomment-216933562\n. Which should be released in 0.9.2 today https://github.com/hyperium/hyper/commit/5fcc04a6cd3dd2962eaefdf23133f88e9242e8b3\n. @Ogeon thanks for reminding me, I had forgotten. Just pushed up a deconstruct method on Request.\n\n@tailhook I've been watching your rotor-dns. The idea excites me, I just wanted to wait for it to mature more. Another possibility is binding to c-ares, which has some pretty decent bindings, including an example of tying it into mio. I expect to open an issue to track improving DNS in hyper (interesting to note that other projects seem fine with a threadpool of getaddrinfo, such as libuv, h2o, ...)\n. @siddontang yea, that is mitigated by increasing the amount of threads in the thread pool. That is a knob you can turn:\nrust\nClient::configure()\n    .connector(HttpConnector::default().threads(64))\n    .build()\n. @Stebalien Thanks for the feedback. I agree, use the Client api in this branch is harder, and some types of applications won't see much benefit for the work. (At least, they can now set connect timeouts.) \nI decided a few months ago that hyper needs to be low level, and not making decisions that affect performance. There other applications who really need the performance gains. Especially servers that make client requests of their own. Think proxy or reverse proxy servers. \nBy leaving the building blocks there, I expect client libraries to appear that are more opinionated, catering to applications like rustup or cargo. They could chose to use Futures, callbacks, or anything else. \nA synchronous API could even exist, exposing io::Read and Write. An example of that exists in the 'sync' example file. \nWhat examples are out of date?\n. @Ogeon by design. It doesn't actually make sense to require SSL implementations to make their context implement Clone. Instead, you could create a HttpListener, duplicate it a few times, and then construct SslContexts for them.\n. @bfrog server::Handler does not require Sync. It did have a Send bound, but more because I forgot to remove it. It wasn't needed. hyper still compiled as soon as I removed it.\n. Control is reexported at the top level, hyper::Control.\nOn Wed, May 11, 2016, 8:41 AM Tom Burdick notifications@github.com wrote:\n\nIt looks like HandlerFactory has a fn create which takes a http::Control,\nhowever... hyper::http is private, so its impossible currently to implement\nthe trait outside of hyper I believe?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/778#issuecomment-218499277\n. The latest push just now changes the server from spawning its own thread, to allowing it to be executable on the current thread. This means that if you're creating multiple servers with the behavior that it spawned its own thread, you now need to move the loop into a thread and run it. It looks like this now:\n\nrust\nlet (listening, server) = Server::new(listener).handle(factory).unwrap();\nthread::spawn(move || server.run());\nHowever, this has removed the Send + 'static bounds on Handler, so you can now try to create Handlers with references.\n. This feels fairly solid now, thanks to everyone having tested it. There is 1 failing issue on Windows, which seems to be that related to how mio implements IOCP. The specific issue is that the hyper Server drops the connection after the final write (and it's not marked keep-alive), but dropping it seems to abort the queued last write.\nI'm going to merge this now, and hope the IOCP issue is looked into (if you develop on Windows, more debugging would certainly be useful!).\n. Seems the change to the Box::new doesn't work.\nOn Wed, May 4, 2016, 11:36 PM GitCop notifications@github.com wrote:\n\nThanks for contributing! Unfortunately, I'm here to tell you there were\nthe following style issues with your Pull Request:\n- Commit: 581e01e\n  https://github.com/hyperium/hyper/commit/581e01e685d1464b4bcaef8c11a76cb63e1381b0\n  - Commits must be in the following format: %{type}(%{scope}):\n    %{description}\nGuidelines are available at\nhttps://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\nThis message was auto-generated by https://gitcop.com\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/779#issuecomment-217086775\n. Thanks!\n. Looks like that's a compiler bug. Your nightly is 20 days old. The commit\nbuilt correctly with the latest nightly.\n\nOn Thu, May 5, 2016, 8:43 PM siddontang notifications@github.com wrote:\n\nWhen I compile with 8b28288\nhttps://github.com/hyperium/hyper/commit/8b2828891f0ed547795e8322bed24ee26122f698,\nmeet:\nerror: internal compiler error: ../src/librustc_trans/debuginfo/type_names.rs:155: debuginfo: Trying to create type name for unexpected type: hyper::client::HttpsConnector::Output\nnote: the compiler unexpectedly panicked. this is a bug.\nnote: we would appreciate a bug report: https://github.com/rust-lang/rust/blob/master/CONTRIBUTING.md#bug-reports\nthread 'rustc' panicked at 'Box', ../src/libsyntax/errors/mod.rs:575\nnote: Run with RUST_BACKTRACE=1 for a backtrace.\nBut for 1d936fe\nhttps://github.com/hyperium/hyper/commit/1d936fee90e2647bf87af68fb21f7ff387e41953,\nit is ok.\nRust version:\n\u279c  hyper git:(mio) rustc -V\nrustc 1.10.0-nightly (576229fea 2016-04-15)\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/782\n. I'm not sure if I fixed what issue you were facing. I edited the client\nexample just as you did, and received 2 responses.\n\nOn Thu, May 5, 2016 at 11:04 PM siddontang notifications@github.com wrote:\n\nHi\nI try to reuse the client, so I change the example client.rs to:\nlet client = Client::new().expect(\"Failed to create a Client\");\n for _ in 0..2 {\n    let (tx, rx) = mpsc::channel();\nclient.request(url.parse().unwrap(), Dump(tx)).unwrap();\n// wait till done\nlet _  = rx.recv();\n}\nBut I find that only first request handled, the other hung up, the debug\nlog is:\nDEBUG:hyper::client::connect: Https::connect(\"https://http2bin.org/get\")\nDEBUG:hyper::client::dns: resolve \"http2bin.org\"\nDEBUG:hyper::client::connect: Http::resolved <- (\"http2bin.org\", Ok(V4(104.131.161.90)))\nDEBUG:hyper::client: default Handler.on_control()\nDEBUG:hyper::http::h1::parse: writing Headers { Host: http2bin.org, Connection: close, }\nDEBUG:hyper::client::response: version=Http11, status=Ok\nDEBUG:hyper::client::response: headers=Headers { access-control-allow-origin: , Content-Length: 196, x-clacks-overhead: GNU Terry Pratchett, Server: h2o/1.7.0, content-type: application/json, access-control-allow-credentials: true, Date: Fri, 06 May 2016 05:57:53 GMT, Connection: close, }\nResponse: 200 OK\nHeaders:\naccess-control-allow-origin: \nContent-Length: 196\nx-clacks-overhead: GNU Terry Pratchett\nServer: h2o/1.7.0\ncontent-type: application/json\naccess-control-allow-credentials: true\nDate: Fri, 06 May 2016 05:57:53 GMT\nConnection: close\n{\n  \"args\": {},\n  \"headers\": {\n    \"Connection\": \"keep-alive\",\n    \"Host\": \"http2bin.org\",\n    \"Via\": \"1.1 http2bin.org\"\n  },\n  \"origin\": \"45.35.21.30\",\n  \"url\": \"https://http2bin.org/get\"\n}\nDEBUG:hyper::http::conn: on_remove\nDEBUG:hyper::client::connect: Https::connect(\"https://http2bin.org/get\")\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/783\n. @siddontang thanks for investigating! I've merged your PR for spmc, and published 0.2.1. A cargo update should pull it in.\n. I recognize openssl has some annoyances on Windows. Work is happening, and soon hyper will use native-tls by default instead, which should only require openssl on Linux OSes.\n\nFor now, you can disable openssl by doing this in your Cargo.toml:\ntoml\n[dependencies.hyper]\nversion = \"0.9\"\ndefault-features = false\n. Yes, I would recommend something like that crate. I chose not to expose the\nmock module in hyper because I use it for tests, and I didn't want to\nfeel like I couldn't expand the tests because of backwards compatibility.\nOn Mon, May 9, 2016 at 7:26 AM Salim Afiune notifications@github.com\nwrote:\n\nI would like to ask if there is a way to use the MockStream trait in my\ntests.. I saw this other repository (\nhttps://github.com/Byron/yup-hyper-mock) but I wonder what you guys\nrecommend. Thanks!\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/786\n. The Client doesn't yet pool keep-alive connections.\n\nAs for pipelining, I don't think I'll be trying to add support for it, because it's complicated, servers don't all support it well (hence most browsers don't use it), and HTTP 2 does it far better. I'd wait for HTTP 2 support.\n. end signifies that the current response is done. After any flushing, it\nwill check if the connection is allowed to be kept alive, and if so, the\nstate is reset to the beginning to be used with a new request. Keep alive\nis working in the server implementation.\nremove will stop all action on the socket, and remove it from the event\nloop. It will then be passed to Handler::on_remove. The default\nimplementation of that method will just drop the socket, so that makes\nremove equivalent to an abort for the connection. However, you could also\nuse it for taking control of the socket, such as after receiving Upgrade\nheaders to websocket, you could remove the socket and give it to a\nwebsocket library.\nOn Thu, May 12, 2016, 7:06 PM siddontang notifications@github.com wrote:\n\nEm, I am waiting the pool mechanism and HTTP2, :-)\nBtw, what's the difference between Next::end() and Next::remove(), seem\nthat they all terminate the transport now. So in the server, if I want to\nre-use the connection for next request after on_response_writable finished,\nreturn Next::end()?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/789#issuecomment-218934425\n. The actual bug was that even though the chunked header was used, it wasn't writing the last zero chunk if encoder.write() was never called. I've fixed that.\n\nIt would be a nice enhancement to notice if on_response returns Next::end(), that it shouldn't set the Transfer-Encoding header.\n. I think I made the field private on purpose, because public fields mean I cannot refactor when I need to. It's likely instead missing a constructor that accepts a pre-made SslContext.\n. The windows builds are currently expected now that master is using async :(\nI'll merge this and cherry pick it into 0.9 as well, thanks!\n. What version of hyper is this with?\n. @looah-bmtmch on Windows?\n. @MrSpock SSL is no longer in this library. From that error, it looks like you're using openssl. You may wish to check there.. This is current expected behavior. The status of a socket cannot be\ndetermined without using it. While in blocking mode, that means hyper\ncannot try a check without possibly blocking the thread forever.\nIn non-blocking mode, hyper can poll for a hang up, and remove the\nconnection from the pool.\nCurrent master has moved to non blocking io.\nOn Thu, May 19, 2016, 5:54 AM Michael Tran notifications@github.com wrote:\n\nHello,\nUsing hyper 0.9.4, this code may fail depending on the duration of the\nsleep.\nfn main() {\n    let client = Client::new();\n{\n    let mut res = client.get(\"http://www.example.com\").send().unwrap();\n    assert_eq!(res.status, hyper::Ok);\n    let mut buffer = String::new();\n    res.read_to_string(&mut buffer);\n    // drain it to avoid drop message\n}\nthread::sleep(Duration::from_millis(360000));\n// exceed timeout of keep alive     ~~~~~^\nlet res = client.get(\"http://www.example.com\").send().unwrap();\nassert_eq!(res.status, hyper::Ok);\n}\nthread '' panicked at 'called Result::unwrap() on an Err value: Io(Error { repr: Custom(Custom { kind: ConnectionAborted, error: StringError(\"Connection closed\") }) })', ../src/libcore/result.rs:785\nbecause the connection is re-used from the pool of client and the timeout\nwas exceeded.\nIs it intended to not checking if the connector is still usable (i.e.\nshould the user verify it) ?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/796\n. @cristicbz yes, in v0.9.x, this still exists. The explanation for why is in the previous comment.\n. Thanks!\n. Looking at the implementation again, there's not much to these errors. Is there any reason you would need to name them? They pretty much only exist in hyper so that unwrap or debug printing them will give a more useful message.\n. I actually wonder if some of the topics are too small (the routing guide I just wrote feels so tiny). Maybe instead, a list of sufficiently more complicated topics that explore all of the required topics, such as:\n\n\nhello world\necho\nfile serving\n\nThey would definitely cover all the original topics, but it may not be obvious from their titles?. The docs that will exist for the v0.11 release are done. Clearly, there is always room for more, and better, docs.. I could imagine the guide going in steps:\n- Introduce the Handler trait. Such as show how to make a simple \"Hello World\" handler, like from the examples/hello.rs.\n- Explain WouldBlock, and/or try_read/try_write, and repeating with Next until the IO is done.\n- Introduce some routing, using req.uri().\n- Add an additional blocking service, like a worker pool. This would show off how to use Next::wait() and Control.ready().\nSomewhere in there, sometimes it makes sense to skip explaining all the pieces, and then eventually explain \"So remember Handler<HttpStream>? That's actually a Transport, go read about the Transport docs.\" or something.\n\nI'm currently fiddling with the docs script, to try to pull in any .md file in the doc directory, so that the guides will be part of the docs at http://hyper.rs/hyper, and can even be versioned.\n. Thanks for the thorough report! I'd love it if all reports were this detailed.\nI've removed the HTTP/2 client from master, as it wasn't complete, nor was the design compatible with the async IO rework. I plan to work on full HTTP/2 integration for v0.11. As this isn't an issue on master, the only thing I can see to do is close it, but again, thank you so much the report.\n. Ah, I see what is happening. Without the semi-colon, it's passing the ServerLoop back to the main thread, because of the call to join(), instead of the loop being dropped (and thus running forever).\nThanks!\n. @crumblingstatue because coveralls changes its mind frequently XD\nWhat is the comment clarifying? I'm not against more comments, just I wonder if this could be made clearer still.\n. Makes sense, thanks! \n. I agree it was a breaking change. It's unfortunate that it broke some instances. I'm very sorry about that.\nAt the same time, it felt like a security fix for a majority of users. It's likely that most people using hyper were just hoping that it does everything correct and securely. And it can take time for frameworks to upgrade to a new minor version of hyper, which would mean those users don't have the security fix quickly.\nIt was definitely a dilemma for me, and I opted for the decision that helped the majority case. Maybe I chose wrong, I'm certainly still open to hearing that I did.\nI'm going to close the issue, since it's not something that can be fixed in the code, but comments are still open.\n\n@aidanhs I agree about the nodejs version situation. I'm not afraid of tagging 1.0; I've done so on a few of my other crates. In hyper's case, I truly believe it's not 1.0 yet. Clearly, switching to async IO is a big change that I feel is required for a 1.0. I imagine that after releasing async IO, some feedback will come to make some other tweaks. It'd be nice for hyper 1.0 to also support the major use cases of HTTP2, but if that appeared in hyper 1.1, that'd be fine too.\nAlso, that quote on arewewebyet is definitely incorrect :)\nPerhaps it'd be best to add to the README some text \"hyper is still evolving towards 1.0, and may have breaking changes\", and add a link to a Milestone page. Perhaps also a Milestone page could be added to the wiki (or maybe the Issues milestones are sufficient?).\n. Yes, master merged the mio branch, and is on the path to 0.10. The 0.9.x branch exists to continue to accept bug fixes.\n. I do try to keep the releases page up-to-date with changes.\n. I haven't publicly documented them since I'm not actually sure about their use. I know servo needed them for ipc serialization (I think?).\n. Currently, there no longer exists any \"features\" in hyper, so closing for now.. This appears to be fixed in newer mio, will close this bug once hyper has incorporated it.\n. This is no longer happening in the tokio branch.. Thanks for the pull request! Sorry for the delay, I've been traveling and only have occasional computer access.\nThese all look really good. The only refactor that gives me pause is the derives for the StatusCode enum. If the compiler no longer takes a noticeably longer time generating them, then the fix looks fine. Last I checked, those derives took added several seconds each to the compilation.\n. Ah, glad to see that PR. Yes, I'd probably want to wait to introduce the\nchange when stable users have a safe way of keeping compile times better.\nOn Sun, Jun 12, 2016, 5:58 PM Leonardo Yvens notifications@github.com\nwrote:\n\nBenchmarked on nightly with precision of seconds, no change in compile\ntimes for debug or release. However I suspect the improvement is due to\nrust-lang/rust#31414 https://github.com/rust-lang/rust/pull/31414 which\nI believe is in beta. Should this wait for that change to land in stable?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/pull/817#issuecomment-225445094, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe/AADJF-CC4Aeg-o7pac15rgREEn8Uvhy2ks5qLCyugaJpZM4IuI8b\n.\n. Thank you!\n. I've publish v0.9.7 to crates.io that includes your fix. Thanks again!\n. Woo! Thanks for the pull request!\n\nPlease excuse my tardiness. I'm traveling, very little computer time.\n. Ah, this is a bug. The invariants I've been enforcing are: if you get an immutable view (raw or typed), and it doesn't exist, it will generate it and then give it to you (either serializing a typed, or parsing a raw). However, if you get a mutable reference, because you can cause them to be out of sync, it should obliterate the other stored value. So, get_mut should kill the raw part. I believe it does this correctly when you do headers.set(Foo), so it's a hole in get_mut.\n. I have not thought about it at all. Is there a particular RFC or spec I should read up on?\n. All TLS is now handled outside of hyper proper, so I'm going to close this. See #985 for reasons.. I've merged the accompanying PR.\n. Yes, there are. See #304 \n. This cannot be Next::end(), as that signals the entire message is complete. There is need to signal \"writing is done, but I still want to read from the server\".\nSome options I've thought of:\n- Make the Handler write with zero bytes if chunked, ie encoder.write(b\"\")\n- Add a method to Encoder<T>, such that the handler calls encoder.end()\n- Add a variant to Next, such as Next::response() or Next::read_only() or something else horrid :cry:\n. @daogangtang The answer from @matt2xu is what I would say as well. Some message formats require buffering before you can understand the full message. You can either do that yourself, or make the users of your library do it.\n. Thanks! Just a couple comments.\n- I think a typed could exist from parsing by getting typed(), and then later on a call to typed_mut() would not remove the raw representation.\n- Could you add a couple tests for the multiple combinations that might cause it to be out of sync?\n- Since the commit message becomes part of the changelog, could it be something tamer? :D Maybe just replacing \"kill\" with \"remove\"?\n. This probably would have been the better implementation, but it's a breaking change, and I don't plan to make any more of those for the 0.9.x era... :(\n. Perfect, thanks!\n. Going forward, hyper won't provide a proxy API built-in. All the pieces are now exposed to allow 3rd party proxy implementations, and multipart, albeit it's a fair amount of work.\nI expect both proxy and multipart support to exist in https://github.com/seanmonstar/request, though they don't currently.\n. > master - looks like this feature is forgotten.\nNot so much forgotten, I just wanted to come up with a better design. What you outline here seems like it should work on master: \nrust\nfn on_request(&mut self, req: Request) -> Next {\n    match request.headers().get() {\n        Some(&ContentLength(len)) if len > 10_000_000 => {\n            self.status = StatusCode::PayloadTooLarge;\n            Next::write()\n        },\n        None => {\n            self.status = StatusCode::LengthRequired;\n            Next::write()\n        },\n        Some(&ContentLength(len)) => {\n            self.length = len;\n            // hyper looks for Expect-100, and sends 100 status because of this read()\n            Next::read()\n        }\n    }\n}\n. Not offended at all! Thanks for helping think this issue through.\nOn Mon, Jun 20, 2016, 11:42 PM Artem V. Navrotskiy notifications@github.com\nwrote:\n\nYes, about this behavior and I had in mind.\nI'm sorry if offended. Loss (sometimes temporary) features on full code\nredesign is a normal and I did not mean anything bad. On the contrary, from\nmy point of view this is a very good time to remind about corner cases :)\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/838#issuecomment-227353726, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe/AADJF2kg53rTezjlZGbnHTCzmF2ekBXDks5qN4ffgaJpZM4I5p6B\n.\n. @martell You've only been using Rust a couple days? That makes this work even more impressive! I'd suggest opening a Pull Request with your work, it makes it easier to discuss changes.\n\nAs for your current diff, it definitely looks like the right direction. I imagine we would want to add some new states, of which I'm not entirely certain the best combination at the moment. I'll think more, but I can describe the expected behavior.\nWe would need to save somehow that the request would like a 100-continue response. We would also need a way to know whether we should respond with it, and also to know that we already have. A way we could decide to write 100-continue is if the user decides that they wish to keep reading from the body, we should flush that response. If the user decides they don't want to read from the body, they'll just return a Response, and we can just write that.\nrust\nif !req.headers().has::<ContentLength>()\n    return Response::new().with_status(StatusCode::LengthRequired);\n} else {\n    req.body().for_each(|chunk| something(chunk))\n}\nIn the above example, if the request didn't have a Content-Length header, the server wants to reject it immediately. In this case, hyper should not have responded with 100-continue. We can do this because Conn::poll() will be called again if the user tries to poll on the request body (the req.body().for_each).\nSo, we can record that an expectation exists, and then in Conn::poll(), if were in this expecting state, we can write (and it needs to be flushed immediately) the 100-continue response (record that we've since written that), and then try to keep reading the body. If Conn::start_send() is called to write a response, we can just remove the expectation state, since it no longer matters.\nDoes this all make sense?. I've gone back and forth whether it should be Reading::Expect or Writing::Expect. It kind of affects both. Whichever is chosen, we'd want to update read_body to check that we've written the 100-continue, and write_head would want to update the state that that there is no need to send a 100-continue, since some other response is already being sent.\nThe content is written via self.io.buffer(bytes) and then flushed with self.io.flush().\n. This should no longer be blocked on any dependencies, on master. We have our own dispatcher, and use a custom channel for the body.\nI think it wouldn't be too hard to tie want into the body channel, to know when and if the user has polled for data on the body.. @AlexDvorak no, that's adding the 100 Continue response to the write buffer immediately, right after parsing. This issue is describing that it shouldn't add it immediately, but instead only if the user polls the Body. That way, if the user rejects the request for some reason, the client doesn't see a weird HTTP/1.1 100 Continue\\r\\n\\r\\nHTTP/1.1 400 Bad Request.. That wouldn't work, since the Conn no longer has the Body side. When there's a request body, a channel is made (Body::channel). The channel implementation could be where this information is stored. The client::dispatcher already has a concept of knowing when the receiver side has been polled, by making use of want.. In the 0.9.x branch, the timeouts relate directly to TcpStream.set_read_timeout.\nSo every single read will block up to the timeout.\nOn master (with async IO), the timeout is for each specific event.\n. With async IO, the Handler returns a desired \"next\" event to listen for.\nrust\nfn on_request_readable(&mut self, decoder: &mut Decoder) -> Next {\n    // try to read\n    // and then return desired next event\n    if NO_TIMEOUT {\n        Next::read()\n    } else {\n        Next::read().timeout(Duration::from_secs(10))\n    }\n}\nThe timeout in this case is for this specific read event. If/when the socket is readable again, the timeout is cleared, and you could provide a different timeout (or none).\n. I've also simply felt that it'd be better to have access to the Transport in the on_request event. So to do this, I've been thinking of adding a &'a T field to the Request struct.\nrust\nfn on_request<'a>(&mut self, req: Request<'a>) -> Next {\n    let addr = req.transport().peer_addr().unwrap();\n}\nI wonder if lifetime elision can remove the need for those 'as...\n@Ogeon @Ryman would this hurt ergonomics for frameworks much that you could no longer hold on to the Request object? You could still get the underlying fields with req.deconstruct()...\n. I won't be adding any new features to the 0.9 RequestBuilder. I do however have a new crate that provides convenience over the Client API, where something like this might make sense. I haven't published the crate yet, though...\n. Thank you!\n. Thanks!\n. @lopuhin yea, I'd really appreciate an example. I've altered the client example locally to spawn several threads and make a bunch of requests to the same web page, and I don't get any panics... \n. @lopuhin oh! its not a race condition in this case, it's incorrect handling of a connect timeout.\nResolving the DNS took longer than the timeout allowed, which removed the handler, but the DNS did eventually resolve, and tried to continue where a handler no longer exists.\n. hyper, especially what now exists on master, will purposeful stay a lower-level HTTP implementation.\nI have begun work on request which will be a batteries-included HTTP Client crate. The benefit here is this new crate can be much more opinionated and include other crates to provide easy APIs, without bogging down the HTTP crate.\n. It does look like there are only 6 valid values. In those cases, I feel\nenums fit perfectly. Is it expected to be extendable? If not, no need to\nallow a String, right?\nOn Fri, Jul 1, 2016, 12:21 PM Aravind Gollakota notifications@github.com\nwrote:\n\n@jdm https://github.com/jdm Actually, why not just have an enum of the\nsix possible referrer policy types and regard anything else as an error?\nI'm on the fence about whether we'd want nonstandard as a variant here. In\none sense it's useful since it adds flexibility, but then again it muddles\nthe issue in a case where the spec really does specify exactly six variants\n(i.e. we don't really need the flexibility in this case). Maybe we should\njust defer to Hyper standard practice here -- cc @seanmonstar\nhttps://github.com/seanmonstar.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/pull/850#issuecomment-230028082, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe/AADJFzy04IV0rbw7pdQsug7p1YpUWP7sks5qRWivgaJpZM4JC2Dy\n.\n. @jdm if you send Content-Length: boogy\\r\\n, then headers.get::<ContentLength>() will return None.\n. Also, if you need in this in Servo before switching to async io, I recommend targeting the PR against the 0.9.x branch.\n. Hm, since the spec says those older keywords are semantically identical,\nwhat if they just parsed to the equivalent new value. Such that there were\nonly 6 variants to the enum, and 3 additional strings that would parse to\nit. @jdm I kinda prefer it, but are there issues I'm not thinking of?\n\nOn Fri, Jul 1, 2016, 10:30 PM Aravind Gollakota notifications@github.com\nwrote:\n\nUpdated to use an enum, and also to handle legacy keywords never, default,\nand always as per the spec\nhttps://www.w3.org/TR/referrer-policy/#determine-policy-for-token.\nOpened basically the same PR against 0.9.x as well: #851\nhttps://github.com/hyperium/hyper/pull/851. Feel free to close this one\nif you don't want to merge into master at this point.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/pull/850#issuecomment-230084855, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe/AADJF9xGoSAfHgW83mDwJH37MFRNoNuTks5qRfdjgaJpZM4JC2Dy\n.\n. Oh! I just assumed from reading the comment in my inbox, without looking at\ncode :o)\n\nOn Sat, Jul 2, 2016, 12:05 AM Aravind Gollakota notifications@github.com\nwrote:\n\nActually the current implementation does do exactly what you said -- there\nare only six variants, and the additional legacy strings just parse to\ntheir equivalent variants (e.g. both \"no-referrer\" and \"never\" parse to\nNoReferrer, etc.).\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/pull/850#issuecomment-230088036, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe/AADJF2e1-lkzCzMKa8xnA_egwl0bqJE6ks5qRg3HgaJpZM4JC2Dy\n.\n. Excellent, thanks!\n. Woops! Good news is that the wait means 0.9.10 also includes the Origin header. Published!\n. It was just a gut decision. It's being deprecated, so people can pick the\nnumber of threads themselves.\n\nOn Mon, Jul 4, 2016, 1:12 PM Cobrand notifications@github.com wrote:\n\nI noticed that the default number of threads used by hyper wasn't the\nnumber of cpus, but the number of cpus * 5 / 4 : see here\nhttp://hyper.rs/hyper/v0.9.9/src/hyper/src/server/mod.rs.html#229\nIt means that for 2 cpus, it will have 2 threads spawning, but for 4 cpus\n5 threads spawning, 8 cpus 10 threads spawning, etc ; but why it not have a\n1 thread <-> 1 cpu ratio ? What directed that decision ?\nIt is simply a mere question, not an issue what-so-ever, but maybe we can\nadd an explanation in the comments so people that are wondering this like\nme won't have to post another question here. Don't worry, if anyone\nproperly explain I will can the PR myself if needed.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/852, or mute the thread\nhttps://github.com/notifications/unsubscribe/AADJF1Opnc1Xv7hBNPfIgn4gFUiTuUwvks5qSWkYgaJpZM4JEobP\n.\n. Hyper is moving away from spawning threads for the server. This is already\ndone on master. This is because it's using non-blocking IO, so the event\nloop lives on one thread.\n\nOn Mon, Jul 4, 2016, 1:54 PM Cobrand notifications@github.com wrote:\n\nI understand that you might want to deprecate this and let the users pick\nthe number of threads they want themselves, but what if people don't want\nto pick themselves ?\nAt the very least make something that allows to pick the number of threads\ndepending on the number of cpus you have (with a closure I guess) directly\nin hyper. It would be quite cumbersome to extern the crate num_cpus on\neverything depending on hyper (since the number of threads depends heavily\non the number of cpus you have anyway).\nIf you agree with this, I could make a PR for this.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/852#issuecomment-230353154, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe/AADJF27gptqySGgG9Vy2Nf7XbYeYndRMks5qSXMggaJpZM4JEobP\n.\n. Could you rebase your commit against the 0.9.x branch? This is trying to merge all of master into 0.9.x.\n. Oh sorry, it doesn't send me a notification that you had rebased. Will look today. \n. @untitaker whatcha think? My only last hessitation is having people build the Origin struct literal, instead of some sort of Origin::new(\"https\", \"www.rust-lang.org\", None)...\n. This is looking really good! 2 comments left, and we can merge!\n. @puhrez sorry, 2 would be to remove the comment at impl FromStr for Origin about being unsure why there is no type error.\n. I'm still conflicted. RFC7230 pretty much just says \"Don't put userinfo in the URL\". It's not specced that it should read it and instead change it into an Authorization header.\n\nOn the other hand, other clients I looked at (nodejs, golang) do this automatic conversion.\nI still want to say that maybe it doesn't belong in the HTTP library, but I do expect things like https://github.com/seanmonstar/request to do this sort of thing automatically.\n. Interesting. Your proposed use case is to listen on port 80 and 443 in the same event loop?\n. While I have personal feelings on having an app run on both 80 and 443 together (I'd be that the http listener simply shoot out redirects to the 443 listener), I do believe this in general is a good thing to add.\n\nThis would require either modifying Server::new to accept 1 or more Accept, or add a second constructor, something like fn listeners(listeners: Vec<T>) (or generic over an Iterator? I dunno.)\nAnd then internally, this would just add each of the listeners to the event loop. The only tweak would be that scope.notifier() piece that is used to signal the server should shutdown should only exist for 1 of these listeners, and not on all of them.\nIt should be fine to keep it T: Accept, since the common case would be an array of TcpListeners listening on different ports. Anyone who wanted different types can compose using an enum.\n. Hm. So, you start a server with no listeners, and so you have an event loop running, essentially doing nothing? I get all the points of being able to kill the listener without killing the server, for shutdowns or restarts. I just don't know what you would do with creating a Server that has no listeners (until there is a definitive API to add in some listeners).\nSo, without that API, I'd lean towards providing zero listeners is a programmer error. That would mean a panic. I'm not for promoting panicking on everything, but this actually does seem like the right thing to do, since until there is a way to add listeners, a Server with no listener will only cause head scratches.\n. Failure is a bug in nightly rustc compiling regex crate.\n. This looks superb!\n. Thanks a bunch!\n. No, the type Into<Cow<'static, str>> means any type that create that Cow. This one sepcifically says \"any static string, or an owned String\". It is this, after the generic parameters are subbed in:\nrust\nenum Cow {\n    Borrowed(&'static str),\n    Owned(String)\n}\n. cc @mitsuhiko \n. Thanks!\n. @taheris wow, thanks for all the troubleshooting! If you file a PR to rust-openssl, can you update this issue?\n. Looks fixed, closing.. @koivunej the literal! stuff is for particularly common headers. Is Content-Location that common?\n. Great, thanks!\n. Great! I'll look it over more closely a bit later, as this method is tricky/dangerous.\n. This is excellent, thank you!\n. Oh woops, thanks for catching this!\n. Yep, eventually hope to replace the different TLS impls with the native-tls crate.\n. Starting with 0.10, hyper no longer bundles a TLS implementation, so this issue no longer applies.. I haven't been ignoring the idea of providing the request to the factory, I just don't see a nice, logical way to do so. How would you expect the API to look with that difference?\n. I've worried about receiving the Request in the factory, and then later in a Handler callback, not being able to get the Request from txn. I suppose the proper thing to do is just shove the Request into the Handler if you wish to look at it more than once? |req| Handler { request: req, .. }.\nThe request is already eagerly parsed, the idea would be that the result of the parse (hyper::Result<Request>) would be put into the txn, and then you would receive it via txn.request(). So, it is indeed already available when the factory is called.\n\nUntil now, hyper has just dumped sockets when a request has a parse error, but a goal of this proposal was to pass the parse error to the Handler. It seems receiving a Result<Request> in the factory is kinda gross. However, having the factory possibly return 2 different Handlers means I'd need to store that inside hyper as an enum with 2 variants, and then matching on it with every tick... That'd be unfortunate if you chose to deal with errors in the same Handler, since then the enum isn't needed. The match is likely negligible, though...\n. > I personally prefer the single factory method receiving the result, this keeps the implementation from having to do an extra match, especially when the user doesn't really care about errors. It also simplifies the success/error code path into an explicit branch in the handler, which might be easier to keep track of and build on.\nYou said \"result\", which means to me fn create(::Result<Request>) -> Self::Output. The rest of your statements could be applied to either option, so I cannot decide which you mean :)\n. To be clear, which seems better from a user perspective?\n1. Receive a `Result:\nrust\n   server.handle(|incoming| match incoming {\n       Ok(req) => Handle { request: Some(req), err: None, .. },\n       Err(e) => Handle { request: None, err: Some(e), .. }\n   })\n2. Two different methods, with a default ErrorHandler:\nrust\n   server.handle(|req| Handle { request: req, .. })\nA pro is that the DefaultErrorHandler can be defined in hyper to respond with certain status codes based on what the spec says to do depending on the various parse errors. A con is that it is more work if you want to handle errors yourself, instead of Option 1.\n. Indeed, I had meant to propose that the Factory would return Option, in\ncase there is an error try to prepare to construct a new Handler. It could\nbe a Result instead.\nReturning an Err would likely just mean drop the socket.\n. I'm feeling similar to @Ogeon \n. I imagine the Client would continue to not have a factory, instead you pass\na Handler to the request method. It would receive a Transaction object\nsimilar to the server, but request() doesn't need to return an Error, but\nresponse() does.\nOn Sat, Aug 13, 2016, 8:57 PM Austin Bonander notifications@github.com\nwrote:\n\nUltimately, I agree. It's the simplest to implement while giving the user\nthe choice between control and convenience.\nI realized that we've been discussing the server-side API all this time.\nHow would the client-side work?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/881#issuecomment-239649858, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AADJF91D45jFhO9Pct91xyE9zH_Ouh6fks5qfmgMgaJpZM4Jb6XQ\n.\n. You can actually see the server side of this proposed API in the tokio\nbranch: https://github.com/hyperium/hyper/tree/tokio\n\nAt RustConf, I had a good discussion with Alex, Aaron, and Carl about hyper\nand tokio, and was convinced to expose a fully futurized API, like tokio's\nService. I've been meaning to write up about that and post it here, but\nI've been cramming on work the past 3 weeks trying to ship my Q3 goal (Q3\nended yesterday).\nOn Sat, Oct 1, 2016, 1:14 AM Austin Bonander notifications@github.com\nwrote:\n\n@seanmonstar https://github.com/seanmonstar any movement on this? It\nseems like there's still a lot going on in master, which is still based\non rotor, though I guess a lot of the work is framework-agnostic. Do you\nneed someone working on it? If so, I have some free time here and there.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/881#issuecomment-250899833, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AADJF82A_mC_7F0pkw1qe1XnSRJpCSDgks5qvhZHgaJpZM4Jb6XQ\n.\n. I still haven't filed specific issues on what is needed, but the last comments in #934 describe what is missing at a higher level.\n\nI'm going to close this, since this API is not what is going to happen, but instead that Futures API in the above issue.\n. This should be fixed in mime@0.2.3. Just running cargo update -p mime should be enough. Sorry for taking so long on this.. I just ran some updated tests in hyper and confirmed that this is fixed. Since there is no needed code to change in hyper, I'm going to close without a PR.. Hrm, frustrating rustdoc bug. I imagine it's been fixed in nightly, since the docs are published using the stable release...\n. Noticed that the previous version of the docs did show the list: http://hyper.rs/hyper/v0.9.9/hyper/header/trait.Scheme.html\n. The latest docs seem to work: http://hyper.rs/hyper/v0.10.0/hyper/header/trait.Scheme.html. True. Does SslContext have a way of setting that? I imagine it didn't, and so the verify option was set on the Ssl instead. If it does, that line could be moved the Default implementation.\n. I just looked again, and clearly that isn't possible, because the hostname must be passed to the verify callback. Is there a different verification you'd hope to do, or just hoping to disable it?\n. To unblock your use-case, you can impl SslClient for PinnedCert to do exactly as you like, and then use Client::with_connector(HttpsConnector::new(PinnedCert))\nI feel the SSL/TLS design needs a bit of help in general.\n. Yes, you can implement SslClient however you'd like.\nOn Tue, Sep 20, 2016, 8:50 AM Tatref notifications@github.com wrote:\n\nI would like to connect to a fake certificate (the certificate does not\nmatch the domain), which is currently impossible.\nIt would be really great if we could connect to an invalid domain/ expired\ncertificate / unknown issuer...\nCan I just impl SslClient to make this work?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/887#issuecomment-248343756, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AADJF8HihVDqDgX3R16yyrEJejFEW5sfks5qsACrgaJpZM4Jhx0n\n.\n. With the release of 0.10, hyper no longer bundles a default SslClient, and instead proposes use of pluggable crates to provide it. So I'm going to close this.. For now, the new version of hyper won't be including the typed headers directly, so I'm closing this here as a won't fix.. Thanks!\n. This likely isn't the project you're looking for. This is an http library for the Rust language. Looks like you want the Python library. \n. Hm, I agree with this entirely, \ud83d\udc4d . This would be a breaking change, since remove currently returns a bool, but it seems like the right one to make. As such, I'd aim it for master and not for the 0.9.x branch. Basically:\n\nrust\nfn remove<H: Header>(&mut self) -> Option<H>;\n. Hm, interesting issue. I don't see an immediate way to accommodate it with the Header trait. Do you have an idea?\n. I think you could use a typed header in this case by combining get_raw with parse_header:\nrust\nheaders.get_raw(\"x-internalauth-nacl\").map(InternalAuthSalt::parse_header)\nHowever, it wouldn't store the parsed result internally, so the parsing would be needed each time you pulled the header out (which actually isn't usually that many times).\n. hyper has replaced its typed header system with http::HeaderMap, which allows any key.. Thanks for the PR! I agree this would perhaps be a more useful policy than just the Url. hyper on the master branch has moved away from providing a redirect policy, so I don't believe adding this here would be the solution. I'd imagine it would be a good fit for higher level client libraries, such as https://github.com/seanmonstar/request (wip).\n. With the introduction of cargo 'workspaces', this may be more feasible. My gut feeling is to make a hyper-types crate, that hyper depends on, which includes the header, method, status, uri, and version modules.\n. Something I've been thinking about recently was to instead make \"client\" and \"server\" features in the Cargo.toml. So, someone who only needs the client or the server can enable only that feature, and even both could be disabled if you just wanted the types.. @abonander I'm not sure what that means. Something more than httparse? Essentially hyper::header?. If hyper were to define \"client\" and \"server\" features, then disabling them would leave the following modules:\n\nerror\nheader\nmethod\nstatus\nuri\nversion\n\nWhile not all strictly needed by the header module, some of it is (error, method, I can't recall if others). That would mean that there wouldn't be much more gained removing the others, for more effort, no?. Oh right, I forgot about mime since it isn't in the file tree. It'd still be there, since header requires it.. So, while I don't have a specific announcement to make, I can say that a few of us in the HTTP space are working on a crate that would standardize many of these types, allowing frameworks to depend on those, without having to declare a relationship with a specific server or client implementation (such as hyper).. I'm sorry, I'm not quite sure what you mean. Which example are you referring to?\n. Sorry about the confusion!\n. You might want the query params, but not necessarily. A somewhat common usecase for a query string is as a cache buster, i.e. /foo/bar.js?abcdef, such as adding a timestamp or sha to the end. I'd also prefer leaving the choice of what to parse them into up to the user. Whether that is Vec<(Name, Value)>, a HashMap, or whatever.\n. Oh woops, I  didn't realize that the internal Item would need a new method, making this less easy than I suspected. Still, we should be able to figure it out.\n. Looks right to me. Seems travis-ci's OSX containers are lagging, all the linux tests pass, so I'll merge anyways.\n. travis logs say the code examples in the guide are now failing.\n. Excellent, thanks for sticking through to the end!\n. Yep, seems this was changed when proxy support was added, which received tweaks to allow the host/port to be found from the original URL, even though the proxy would use a new URL.\nA fix would perhaps be to check for the Host header before pushing it, or similar, such as using extend().\n. As 0.10.x is no longer actively developed, I'm going to close as wontfix. If anyone wants to send a PR to fix it, I'll merge!. @huachaohuang do you have a specific instance? This shouldn't be true, at least the exact steps you described.\nIt's true that the Handlers will be queued in a Vec, waiting for DNS to come back with a TcpStream to use. However, once it has been assigned, the request/response will be part of the same stream.\n. The Client no longer uses this code at all, so I'm going to close.. I'm guessing you're looking for the Python http2 library. This is a Rust\nHTTP library.\nOn Wed, Aug 24, 2016, 12:47 PM Pablo Liz notifications@github.com wrote:\n\nIs there a minimal example available to test server pushes like\nhttp2bin.org?\nIf not, what would be your recommendation?\nBefore testing against an external API i want to make sure there's no\nobvious errors in the python layer.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/902, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AADJF9l9jdXhK85EP4C-wM6iVrXjTpkbks5qjJ_fgaJpZM4JsYc6\n.\n. If you want to figure out how to get openssl building, look at https://github.com/sfackler/rust-openssl\n\nIf you like to disable SSL, you can try this in your Cargo.toml:\ntoml\n[dependencies]\nhyper = { version=\"0.9.10\", default-features=false }\n. Do you have a little more information? What is the exact code in on_response_readable that errors?\n. You can do similar. Keep reading in to a Vec<u8> buffer until end of file, and then use your UTF_8.decode utility.\n. Yes, master does not even use the num_cpus crate anymore. \n. Oh you're right, it's used in the examples/hello.rs file. I had completely forgotten. Updating it doesn't hurt, in this case. The failing tests have been known, thanks to the published version of mio, as seen in #816 .\n. Bumping to openssl 0.8 is a breaking change, so that'd require bumping hyper as well. openssl is also addinv support for opensslv1.1, which will likely bump it to 0.9. I've been hoping hyper 0.10 would be async hyper.\nMy plan has been this:\n- hyper v0.10: Be \"async\" hyper. Utilize tokio-tls.\n- reqwest: Be the convenient, higher level Client crate. This will release very soon, and depend on rust-native-tls. Everyone using hyper for a client should be able to easily switch the reqwest, getting better TLS support immediately, and a (as much as possible) not-breaking API, even as hyper v0.10 comes out with its async Client.\n. @zsck which do you need? I'm assuming that the majority of people who need HTTPS are using a Client (since so many terminate TLS with nginx for a Server). In that case, there are issues filed on the reqwest repo. It's also largely dependent on rust-native-tls being published to crates.io, instead of being a git dependency.\n. @zsck I understand. As i mentioned, openssl will be getting another breaking change (likely to 0.9) very very shortly (see https://github.com/sfackler/rust-openssl/issues/466). When it does, native-tls will be published, and I can publish reqwest.\n. @eddyb oh i know. I've tried to contact him several different ways for a couple months, and was also reminded about the crates.io policy of not taking a name away from someone, so I've settled on this weird name (requests with an 's' also exists). \n. Are there still situations that cannot be taken care with either:\n\nuse reqwest\nif on the server, set default-features = false for hyper, which removes the openssl dependency. @Arnavion mind adding exactly what you'd need to the issue? https://github.com/seanmonstar/reqwest/issues/24. The full issue was discussed in #985, and the solution there was just released as https://github.com/hyperium/hyper/releases/tag/v0.10.0, so closing.. I don't have a specific plan, I just recall that the current chunked decoding code started when hyper used blocking IO, and it likely doesn't handle blocks perfectly: https://github.com/hyperium/hyper/blob/master/src/http/h1/decode.rs#L152\n\nActually, looking it over, I'm surprised it works as much as it does! It could definitely do with some tests using mock::Async, which allows simulating blocking IO.\n. @shanegibbs wow the work here is impressive! I'll be able to sit down and give a proper review in the morning.\n. @shanegibbs Splendid work here. This is a great improvement, as the code should now be robust in a non-blocking world.\nI'd prefer to merge only after extensions are supported, or else we suddenly no longer work on those peculiar streams sending them.\n. Thanks for seeing this through!\n. Looks excellent! Thanks!\n. Hm, I no longer think this should be done (doing just before serialization), since as you pointed out, the information isn't available that far down the pipeline.. That the host is set first in the client implementation is for 2 reasons, I suppose:\n\nTo allow an explicitly set Host header to override the default.\nRFC7230 recommends making the Host header the first one after the start line.\n\nHowever, there are some downsides to how this is currently done. It is a little wasteful, as it copies the Headers struct unnecessarily. It also means that if someone did set a Host header, it is not necessarily put to the front, and so may not be printed first.\nPerhaps a better solution would be:\n\nDon't create a new Headers struct to copy in to, but instead check if there is no Host header, and if not, add it.\nIn hyper::http::h1::parse, adjust the ClientTransaction::encode function to wrap the Headers in a HostFirstHeaders<'a>(&'a Headers) adapter. This fmt::Display adapter could always write the Host header first, and then skip the Host in the iter part.. The spec says it's required. See the last sentence of the second paragraph in RFC7231#7.1.1.2:\n\n\nAn origin server MUST send a Date header field[...].\n. @smithsps it could be, so I wouldn't object to some sort of config, I suppose, but I'm left wondering if it realistically ever happens.\n. Just published 0.9.12 with this commit pulled in.\n. Thanks for digging into this!\n. Thanks!\n. /cc @jdm\n. @gsquire it would also help here to include a test in this module of this behavior\n. Thanks!\n. Thanks for the PR! Could you clarify you comment a bit?\n. Did you have specific concerns in hyper? You can see in master that we use\nvecio, which provides writev.\n\nOn Sat, Oct 8, 2016, 10:50 PM Demi Marie Obenour notifications@github.com\nwrote:\n\nThis is a feature request for the use of zero-copy techniques by Hyper.\nThese include:\n- scatter-gather IO\n- linked strings of smaller parts, as read from IO.\nSee this blog post\nhttp://www.rubyraptor.org/how-we-made-raptor-up-to-4x-faster-than-unicorn-and-up-to-2x-faster-than-puma-torquebox/\nfor details.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/926, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AADJFyKjCZNXP_ir9aHjwMUGdy9L7o7Pks5qyICNgaJpZM4KR6jr\n.\n. I'm going to close this, since hyper uses the bytes crate to reduce copies, and write_buf allows for using writev.. Did you have specific concerns for hyper?\n\nOn Sat, Oct 8, 2016, 10:51 PM Demi Marie Obenour notifications@github.com\nwrote:\n\nThis is a feature request for the use of memory pooling in Hyper, to\nreduce allocations despite the use of asynchronous IO.\nSee this blog post\nhttp://www.rubyraptor.org/how-we-made-raptor-up-to-4x-faster-than-unicorn-and-up-to-2x-faster-than-puma-torquebox/\nfor more details.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/927, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AADJFy91Kt-7waNThCyJWWDBVzIdapMBks5qyIDigaJpZM4KR6kx\n.\n. I do think it'd be interesting to be able to use  a pool for it all, and\nreduce the number of owned allocations. I also think it will be tedious\nwork to fully accomplish, and profiles don't show that allocation is a\nconcern at the moment.\n\nOn Sun, Oct 9, 2016, 12:36 PM Demi Marie Obenour notifications@github.com\nwrote:\n\n@seanmonstar https://github.com/seanmonstar I am thinking of the\nvarious String and Vec allocations for data structures such as HTTP\nheaders, as well as the parser objects themselves.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/927#issuecomment-252507373, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AADJF4v_0L7LsgAA2eUR8ZlCYyNT52GMks5qyUJRgaJpZM4KR6kx\n.\n. Rust doesn't have a GC that it needs to do dances around, like Java or Go, so there's less concern with creating objects on the stack. Strings make use of Bytes, which allow refcounted slices instead of copying and allocating. And there's also now a super basic \"cached HeaderMap\" for a connection, reusing a possible allocation.\n\nSo, I'm going to close this general issue down as fixed. If there are specific pieces that could still benefit, we can open specific issues for those things. :D. I would love to have a way to test for performance regressions! \n. It should be possible to put in a file in the 'benches' directory, that\nuses both the client and server in a benchmark. I believe that rustc bench\ntool includes a way to report the numbers to a file (ratchet?), and then\nmake a subsequent run fail if the numbers differ by too much. Would just\nneed a way to let Travis commit that file after a successful merge.\nOn Tue, Oct 11, 2016, 12:51 AM Demi Marie Obenour notifications@github.com\nwrote:\n\n@seanmonstar https://github.com/seanmonstar My thought would be to\ncreate a server and client on localhost and benchmark the rate at which\nthey can send messages to each other. In general this will not be accurate,\nsince machines are too different. However, if we do this on for machines\nthat should be fairly consistent (ex. Travis CI) we should be safe.\nAlternatively, we can come up with a way for compensating for differences\nbetween machines.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/928#issuecomment-252838379, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AADJF8FGg-aQOlU3Yl-NtLbH0mbzGWDTks5qyz_wgaJpZM4KR6lf\n.\n. There are several benchmarks in the benches directory, and benchmarks internally for smaller functions, so I'm going to close this as completed.. The rust ecosystem has settled on this pattern: libs use the system\nallocator, but rust binaries by default override that with jemalloc, which\nis considered to be quite excellent.\n\nOn Sun, Oct 9, 2016, 12:46 PM Demi Marie Obenour notifications@github.com\nwrote:\n\nFor an HTTP server, standard allocators leave much to be desired. It might\nbe possible to use custom allocators to improve performance.\nExamples of custom allocators are NGINX's palloc system.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/929, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AADJFzsiYMkAex0xvOk3NmL1TPp0DOUlks5qyUR-gaJpZM4KSFwz\n.\n. Then this sounds identical to #927 \n. Recent benchmarks show hyper to extremely competitive. I'm not against using an arena for things in hyper, but I'd rather specific issues be opened about certain parts, when its shown that using an arena would have a meaningful improvement.. This actually worries me a little. What happens if you take the buf and then try to keep on reading on the Request? It's internal counter of whether it can keep-alive will be all ruined, won't it?\n. Reading through the code, it looks like HttpReader wraps BufReaders, so the SizedReader (and Chunked) will not have counted how many bytes have been read off the socket, only how many have been read from the buffer.\n\nWhat depends on this?\n. I published 0.9.14 a few days ago that included this.\nOn Thu, Dec 15, 2016, 4:35 PM Sergio Benitez notifications@github.com\nwrote:\n\n@seanmonstar https://github.com/seanmonstar Can we get a new release\nwith this change?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/pull/931#issuecomment-267486202, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AADJF7P7aN4SQuMjEul2F-NSduhJbnI-ks5rIdzMgaJpZM4KUWJ2\n.\n. I work on the branch as time permits. The client example works today, though plenty other bits do not. \n. Oh right. That's a local crate I have that works just like env_logger, but adds colors and padding to module paths. Perhaps I should publish it, but it's not hard to just comment that out. It should just be a dev-dependency.\n. Just pushed to the branch again. It should handle request and response bodies now. Keep-alive partly works, as long as there was no response body. This is due to a bug in tokio-proto, should be fixed soon enough.\n. @daiheitan Indeed! It doesn't yet handle back pressure, which is what those asserts are there for at the moment. Still have work to do!\n\n@daogangtang The API won't change much, I don't think. The Response type could have some methods changed, the current \"builder\" style methods are just a test. There will likely still be bugs/panics, but if that doesn't scare you, you can try integrating :) It'd probably help actually, to determine if the Request/Response methods are adequate.\n. @daiheitan The Service and NewService thing are likely to see some refinement. I'd ask in the tokio gitter channel.\n. @daiheitan The tokio branch has been updated, with a change in API. You can pass a tokio Handle to server.handle(new_service, handle), and the Server will attach itself to that core. Running the core is up to you then.\nThere is also server.standalone(new_service), which manages the Core internally.\n. @dimbleby I don't have a timetable. As a baseline, since it depends on tokio-proto, it is blocked on that reaching a release (likely 0.1). Besides that, there are some things that need to be done. I really need to break them out into issues, describing what to do that would help someone get into it, but here's a quick list:\n- Writing of chunked bodies is missing the writing of the final zero chunk, 0\\r\\n\\r\\n, when the http::Conn receives the end of the body stream. (This doesn't affect reading chunked streams, just writing them).\n- Writing of bodies does not handle backpressure. If the body stream sends chunks faster than the tcp socket is writable, it will panic once the internal buffer is full. This should instead check if it can fit the current chunk, and if not, stash it and return Async::NotReady.\n- The client doesn't really handle keep-alive/connection pooling. The design of this is something that tokio-proto/tokio-service wants to help with.\n. @scottlamb Indeed, I would like to broaden what is an http::Chunk. It is currently super basic, just wrapping a Vec<u8>, but I would like to add optimizations to it. I opened https://github.com/hyperium/hyper/issues/953 for that discussion.\n. Ah, yes! The tokio branch has been merged (and squashed some) into master. So I'll close this, and any specific things can be individual issues.. If you're running this on a Mac, you may want to use the security-framework feature instead. In the long term, this is my plan: https://github.com/hyperium/hyper/issues/907#issuecomment-255509020\n. What version of hyper were you using? The asynchronous version is on the\nmaster branch, not 0.9.\nOn Mon, Oct 17, 2016, 8:55 PM Dawid Ci\u0119\u017carkiewicz notifications@github.com\nwrote:\n\nHi,\nHow should I benchmark hyper http server to get the best possible\nperformance?\nBasically I'm benchmarking example mioco http server vs example hyper\nserver:\n[I] dpc@futex ~/l/r/3/hyper (master) [I]> wrk -t8 -c100 -d10s http://localhost:1337\nRunning 10s test @ http://localhost:1337\n  8 threads and 100 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency     1.12ms  520.18us   6.59ms   94.00%\n    Req/Sec    11.99k     2.03k   14.67k    87.60%\n  904028 requests in 10.00s, 77.59MB read\nRequests/sec:  90404.81\nTransfer/sec:      7.76MB\n[I] dpc@futex ~/l/r/3/hyper (master) [I]> wrk -t8 -c100 -d10s http://localhost:5555\nRunning 10s test @ http://localhost:5555\n  8 threads and 100 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency     1.42ms    6.41ms  36.59ms   95.84%\n    Req/Sec    96.74k    54.04k  224.67k    60.08%\n  6911985 requests in 10.00s, 349.36MB read\nRequests/sec: 691238.73\nTransfer/sec:     34.94MB\nI thought that now that rotor is integrated, the performance should be\nvery good. Mioco http example is a bit different, but it does http parsing\nof some kind etc. so I was expecting hyper to win easily. What am I missing?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/937, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AADJF-d4Bcty0p9GiPefUS4G6Ri-qFdsks5q1EM_gaJpZM4KZWeO\n.\n. Try the hello.rs example. It uses all threads, the server.rs only uses 1,\nand has some states to handle as an http echo server.\n\nOn Mon, Oct 17, 2016, 9:42 PM Dawid Ci\u0119\u017carkiewicz notifications@github.com\nwrote:\n\n7de6f2b Merge pull request #933 from jwilm/misc-client-fixes\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/937#issuecomment-254405274, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AADJF-AmLdxZ8CyYPyGUyEsf4sabTl1cks5q1E4ugaJpZM4KZWeO\n.\n. I'm sure that is a noticeable part of it.\n\nI imagine another part is that mioco likely is doing a better job of saturating your CPUs automatically, whereas the hyper example could probably use some fine tuning per machine and use case to make sure TCP is the bottleneck.\n. Yes, there is url::percent_encoding that can decode any string.\n. Hey, thanks for submitting this PR!\nSeeing as it is aimed at the master branch, I would aim at using tokio-tls instead, since it's wrapped up native-tls in Futures. See https://github.com/hyperium/hyper/issues/907#issuecomment-255509020 as to my current plan, and feel free to refute my plan if something better occurs to you.\n. You can see in the source that they are purposefully hidden from the docs: https://github.com/hyperium/hyper/blob/master/src/status.rs#L232\nIt may just be wishful thinking, but I wanted to nudge people away from having StatusCode::from_u16(403) and whatnot everywhere. That defeats the purpose of having an enum with names, in my opinion.\nIf the community thinks my nudge just causes pain, I can reconsider.\n. That makes sense. They exist in the first place since the parser only returns a number, so its used as StatusCode::from_u16(parsed.status).\n. The ideal resolution here is to have these 2 impls:\nrust\nimpl From<StatusCode> for u16 {}\nimpl TryFrom<u16> for StatusCode {\n    type Err = InvalidStatusCode;\n}\nThe TryFrom is because not all u16s are valid status codes. Specifically, it must be within 100...599. The TryFrom trait still isn't stable, but the impl could be added behind the nightly cargo feature already in hyper.. @lilydjwg you mean on master? On master there is u16::from(status) (or into()).. The status code is Copy, so it should work just fine.. hyper is replacing its type with http::StatusCode, which does have documentation for its methods.. Thanks!\n. Whether or not to use Nagle's algorithm seems to be a popular topic without an obvious answer for all use cases. I very briefly checked what other popular libraries have for default:\n- nodejs: enabled by default\n- golang: disabled by default\nI don't have a strong feeling either way yet, but I imagine if I read a convincing paper or article, I could become convinced.\n. Hi there, and thanks!\nUnfortunately, using * means that every time openssl releases a new breaking change, hyper would try to use it immediately, even if the API has changed, and thus would no longer compile.\nAs for the eventual solution, this has been my plan: https://github.com/hyperium/hyper/issues/907#issuecomment-255509020\n. Thanks!\n. Thanks for the reminder, I've cherry picked this commit into master as well.\n. Sure, the thing is that the 0.9.x branch contains some commits that are based on synchronous hyper, and so I cannot merge those back in to master.\n. Here's the docs for the SslContext: https://docs.rs/openssl/0.7.14/openssl/ssl/struct.SslContext.html\nYou can set ssl_context.set_verify_mode(SSL_VERIFY_NONE, None) to disable verification.\n. The bug report is correct, it was technically a breaking change. It was made on the assumption that:\n- the only user of ReferrerPolicy is Servo\n- Servo submitted an update to header\n- I assumed they would want the update before async hyper came out, and assumed they expected the enum to change.\nSo I made an exception. If it is absolutely definitely the wrong call, I can revert the ReferrerPolicy commit and publish again.\n. Updating it would be a breaking change anyways, since you can only have 1 version of openssl-sys, so this could conflict with other dependencies.\n\nI'm curious, since I believe that the majority of people who need openssl are using the client. Is this correct?\n. Well, master is where asynchronous IO work is happening, and that will take advantage of tokio-tls, which wraps the new openssl and native-tls in Futures.\nIf people are in need of this for a Client, I have a higher level crate (https://github.com/seanmonstar/reqwest) that works with native-tls, and is just waiting on that crate to be published (which should be early this week).\n. > For us it will mean rewrite all code, related to hyper::client\nI really hope not! I've made the reqwest::Client API very very similar to hyper::Client, so the only changes required should be a replacement of your extern and use lines. I wanted reqwest to be a drop-in replacement, as much as possible.\n\nfor contributors of this crate it would mean just fix few lines to achieve compatibility with openssl 0.9.0. At least I hope so :)\n\nIt's true that the amount of code required in hyper to make the change is small. However, with hyper being core to web development, I've found that when a new breaking change version is published, it takes a while for the community to catch up. And in the meantime, people have conflicts of 1 framework using hyper 0.9, and another using hyper 0.10. It seems like a shame to make that ripple through the community and then not too long from now make a newer version to introduce async IO.\nMy thought has been that people can use the reqwest crate, and then there isn't that ripple. Maybe I'm wrong. Maybe it is better to just release hyper 0.10 with openssl updated (or using native-tls even), and then let asynchronous hyper be 0.11. \n. Sorry, the code for reqwest is not published on crates.io yet, because it\nuses the native-tls crate, which is also not published. The author of that\nsaid he'd be able to publish it this week, as he cleaned up the updates for\nthe new OpenSSL. Once it is, reqwest will be published after.\nYou can try the crate now by using a git dependency, and I'll update this\nissue when it is published.\nIt's using hyper 0.9 is not an issue, it disables the ssl feature of hyper.\nThat removes the dependency on openssl 0.7 and openssl-verify. Reqwest then\nuses the native-tls crate to implement a new https connector.\nOn Wed, Nov 9, 2016, 6:27 AM Evgeniy OZ notifications@github.com wrote:\n\nSorry, @seanmonstar https://github.com/seanmonstar , but reqwest is\nsome experimental code with 0.0.0 version and it has hyper 0.9 in\ndependencies so there is no point to replace.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/949#issuecomment-259426645, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AADJF6Y9amS-3VmYuMpPe5IZhAa_I0CVks5q8dhAgaJpZM4Kqf0O\n.\n. And, it's now published as 0.1.0! I'll have an article explaining it tomorrow, but if you wish to grab it now, it's there: https://crates.io/crates/reqwest\n. > To use openssl 0.9 I still need to vendor hyper, because hyper have dependency on older openssl and even if I write default-features=false, features=[], Cargo adds it to Cargo.lock anyway.\n\nThat shouldn't be the case. Try a cargo clean. I know it doesn't, because otherwise reqwest could not work, since it depends on the newer openssl 0.9, after disabling hyper's.\n. Does this problem occur without the use of openssl? \n. Very interesting. I wonder if the usage of SslStream in the 0.9.x branch is doing something wrong.\nI do hope that asynchronous IO helps in this way, and I know that the newer tokio-tls crate that hyper will be using has had much more work done. If this bug is because of hyper's usage of OpenSSL, one way to get around for now is to put nginx in front, and terminate TLS there, before sending requests to your hyper server.\n. Hm, does turning off keep-alive fix it? You can pass None to server.keep_alive(None): http://hyper.rs/hyper/v0.9.12/hyper/server/struct.Server.html#method.keep_alive\n. @e-oz looks like you can pass a Timeouts config struct to Iron::listen_with: http://ironframework.io/doc/iron/struct.Timeouts.html\n. Thanks for investigating this. I've had a hyper server running at meritbadge.herokuapp.com for more than a year, and it never hangs or segfaults. However, being on heroku means I don't use SSL.... @hannobraun I'm curious if setting read and write timeouts before passing the socket to wrap_server would help at all. Depends if the hang is waiting on socket io, or some sort of Mutex deadlock.. It was just something I never thought, and the code in Worker doesn't make it obvious that socket IO happened before handle_connection, when really, inside HttpsConnector::connect, after the socket has been accepted, there is indeed socket IO to handle the TLS handshake.\nThere isn't currently a way for the NetworkConnector to know about possible timeouts set in the Server, but perhaps it makes sense to have a healthy timeout set in there before wrap_server. We could say something like 10 seconds for read and write, or possibly it makes sense to update connector in some way to allow the server to hint at a timeout.. I'm publishing 0.10.0 right now (fixing docs deployment before publishing to crates.io, but asap!). So to allow it to be a non-breaking change, maybe a new method on the NetworkConnector trait that has a default implementation to ignore the timeouts.\nAgain, I'm not certain this will help, as it may be a deadlock somewhere else. Just thinking that TLS handshake has both read and write IO, and with a blocking socket, it will just block until the other side responds or hangs up.. @hannobraun Excellent! Thanks for sticking through it, and reporting back so much. I'm going to close this issue, since it does seem like it is fixed. If it occurs again, we can re-open.. The header macro is confusing. It might be more clear to implement Header yourself. But, in this case, it is defining a tuple struct, XRateLimitRemaining(pub usize), so you can access the usize by pattern matching, or accessing new_rate.0.\n. I'm confused. It should still be possible to send requests over HTTPS with v0.9.11. Just because a new version of openssl has released doesn't mean latest version of hyper stops working. \n. @e-oz interesting. I spoke to Alex, since upgrading the -sys crate dependency is mostly a breaking change, and he agreed. There is now ssh2 at 0.2.15 which uses openssl-sys 0.7, and he'll publish a 0.3 with the new openssl.\n. I have hit this exact same error when I was writing tests. I'll check in with the tokio team about the error.\nI also hope to write some guides explaining how to stream a body in hyper.. @pimeys great! I'm curious about what modifications you need to make, if you could open separate issues about them, so can we keep the focus here of the design of the Body stream (and Chunk).. So, the Chunk has had 2 variants added to it internally.\n\nInternally all reads use an internal MemBuf, which is a shared append-buf. When slices are needed, such as sending a Chunk on the Body, a MemSlice is made, which just increments a refcount, and updates the MemBuf to not touch that range of memory.\nIt can accept a Arc<Vec<u8>>, motivated by a usecase reported that a server had built up a cache of responses, and didn't want to copy the body response for every request, instead just sending an Arc copy. This one seems more arbitrary, and maybe could be adjusted.\n\nDoes it make sense to also integrate with tokio's EasyBuf? Maybe that would replace the Arc<Vec<u8>> variant of point 2? And it might make it easier to integrate with other tokio components?\nNote that tokio's EasyBuf currently isn't suitable for internal use in hyper, but maybe future updates will let it be so.. @scottlamb I tried looking through the owning_ref crate, and had a hard time understanding it's purpose.\nAs for memmaped slices, that sounds like the possibility of a bad time, if the memory is on disk and not in RAM when hyper tries to deref the slice to write into the socket. That blocking file IO could really hurt the performance of the event loop. I'm also not sure how to ask for an async deref, such that the loading could be done on another thread. It sounds like it would complicate a lot of things.. I think I understand now how owning_ref works. Essentially, having b\"Hello World\".to_vec(), but wanting to send a chunk that only references the bytes of b\"World\", right? \nI get the appeal of that, and actually find that pretty neat. At the same time, I'm wary of linking hyper's public API to owning_ref, if for no other reason than I feel like owning_ref is an obscure crate. Maybe that feeling is baseless, or maybe there's another way to get a similar affect without relying on that crate?\n\nRegarding sending multiple chunks, it assumes you don't have the multiple chunks ready yet to send (I would expect that normally someone has the bytes bundled into a single chunk). So, you must spawn some sort of other task that will try to send more chunks into the body as they become available, and the body has room. This could be a CPU task from futures-cpupool, or some other task in tokio (such as another network request).\nIf doing that feels bad, we should definitely try to find how to make that better. That'd partly be up to the design of tokio itself, and so possibly people would have input on the tokio-proto repo or the tokio gitter room, but it's also something that we can explore (and push the feedback in to tokio). We can ping Alex or Carl if we have specific feedback, too.. So, something that I think solves both @abonander and @scottlamb's cases, plus various others, is if the Chunk were basically Bytes. It has several benefits:\n\nIt can be used internally, completely replacing the MemBuf/MemSlice` thing. It has the same semantics, of being a shared appendable buffer.\nThe plan for tokio 0.2 is to replace EasyBuf with Bytes: https://github.com/tokio-rs/tokio-core/issues/68\nThe Arc<Vec> case is easily adapted to being just a Bytes that you clone.\nFor @scottlamb's case, a BytesMut can be used similar to a Vec, building up the bytes however you want. You can then slice that into a subset and send just those Bytes.\nFor @abonander's case, a Bytes can be sliced to a subset, and that can be yielded however you want.\n\nA few questions remain regarding using Bytes in hyper:\n\nIf bytes 0.4 will be released soon enough, or if this shouldn't block hyper 0.11.\nChunk currently has a variant for static slices, which feels nice. It's fun for the hello world example, but I also really appreciated it when I made a server that replied with contents from a include_bytes!(\"../some_file.txt\"), and knowing that it wasn't copying that full file multiple times (besides the necessary copy into socket buffer). Brief discussions with @carllerche suggested that it very well could be feasible to add static slice support into Bytes.\nShould hyper expose the type as Bytes directly, or continue to have it be Chunk(Bytes), with From<Bytes> and Into<Bytes> implementations? Keeping the internals opaque allow for small alterations that hyper might want.. @scottlamb you're right, I forgot about mmap. Asking in the tokio room, the suggested advice was basically \"don't do that\", because of the pauses in the event loop that can occur from loading the memory from disk. With those warnings, do you still find it compelling to try to do it anyways?. @scottlamb That is some really impressive homework, thank you so much!\n\nIt definitely looks like mmap has some things going for it. I'm sure at some point in the wild you may see adverse affects, especially as more variables occur, such as larger files, and many different ones, data not in disk cache, the disk has to seek, the disk just hangs for a long time. But, I'm certainly not wanting to prevent someone from trying to make that work.\nI realized that I had a misunderstanding on the user-supplied stream type that was required by tokio. I assumed it had to be tokio's Body type. But it can be generic over Stream. And if doing that, it may as well also be considered to allow the chunk portion of the stream to be generic as well.\nSo, this would mean changes like this to hyper:\n```rust\nstruct Response {\n    body: T,\n    // ...\n}\nimpl Response where T: Stream, T::Item: AsRef<[u8]> {\n    pub fn set_body(&mut self, body: T) {\n      // ...\n    }\n}\n```\nAnd then, for @scottlamb's case:\n```rust\nstruct YourService;\nimpl Service for YourService {\n    type Response = Response>;\n    // other types\n    fn call(&self, req: Self::Request) -> Self::Future {\n        ok(Response::new().with_body(Body::from(make_mmap_slice())))\n    }\n}\n```\nYou would just implement AsRef<[u8]> for your type, and then you wouldn't need to box and erase specifically, maybe you'd need an Arc or something, to send the pointer and some indices, really anything you wanted.\nWith the Body being a generic Stream, you also don't need to use the futures::sync::mpsc channel that backs Body, you could use something else, like futures::stream::Once (though, the Body hyper use's does have an optimization for only 1 item).\nThe only concern that I haven't toyed out all the way is that this may cause more work for people who don't need it. It should still be really easy to just send data, like a Vec<u8> or &'static [u8], or Bytes. Maybe this is done by defaulting to the generic, like Response<T = Body<Chunk>>. The trade off there, of course, is that people can accidentally not be generic very easily, by making libraries that accept Response instead of Response<T>.... @michael-zapata There is not an option to do that for now. The ability to borrow the socket would probably require some coordination with tokio, since there is tokio-proto types in-between the user and the socket. \nIt may be slightly easier to instead allow passing some struct Sendfile { path: PathBuf } on the Body stream, and having hyper figure out how to do that internally, but I'm also quite wary of that. sendfile can block the reactor thread when reading the file, and it is incompatible with HTTPS, and more of a pain if trying to work with HTTP2 streams. I'm not absolutely against it, but it'd require a bit more exploration and a prototype, and so something that feels out of scope for the next release.. I've worked on making the user-supplied body stream generic, and it exists for both the server and client in this branch: https://github.com/hyperium/hyper/compare/outgoing-generic\nA few things I either need to fiddle with, or would welcome feedback on, are:\n\nThis is using server::Response<B = Body>, so that it is generic over any stream, but for people who don't care to customize, they don't need to bother declaring it. Doing this made all the examples still work perfectly, while allowing me to alter an example to use something like futures::stream::Once<&'static [u8], hyper::Error>. However, with default type parameters, it can be easy to accidentally force non-generic in a library.\n\nFor example, if someone did fn decorate(res: &mut Response) { }, no one could pass Response<MyStream> to it. However, the same situation exists with HashMap, where if someone accepts HashMap<K, V>, they've locked their function to only hashmaps that use the default hasher.\nThe proper decision should favor the default case. I've figured the default is to just use hyper::Body, since it will be backed by Bytes, being perfomant and easy to use.\n- Unfortunately, though, I cannot yet decide on how to default the to hyper::Body in the Client. With the server, it was easier since a user can define their desire when implementing Service, when saying type Response = Response. They don't do that with a Client, instead passing client.request(req). So far, inference hasn't been able to detect the body that should be used, at least when making a GET request and so don't specify a body.\nIt might be that a decent way forward is to adjust Client::new to be bound to hyper::Body, and if you want to change that, you need to use Client::configure.\n- I haven't explored it yet, but it might be nice if the supplied body stream didn't need to actually emit hyper::Error, but just E: Into<hyper::Error>. That'd mean that io::Error would just work.... > Maybe a dumb question, but what is this error used for?\nHuh. I traced through the code in tokio and played with some examples, and found that a user will never receive the hyper::Error. If there is an error parsing the head, the error passed back to tokio will make tokio just kill the stream. An error can occur streaming the body, but realistically it'd only ever be an io::Error, until HTTP2 is added, in which case HTTP2 frame errors are also possible.\nThe purpose of requiring it on the Response side is currently a limited in tokio: you can only define 1 error type to be used through out.\nI know from conversations that the tokio team want to improve on error handling in newer versions, so maybe some of these points go away. For the time being, though, I wonder if it makes sense to just be an io::Error. Or really, some opaque error type that can From::from(io::Error), so someone can get the description of the error message. There isn't anything else you can do once the Request stream has sent an error; it will be shutdown regardless.\n\nThe points about the Service trait are very interesting! I'd recommend either opening an issue on the tokio-service repo, or discussing them out in the tokio gitter room.. Actually, thanks to another coversation in the tokio room, I realized that it is possible for users make use of the hyper::Error, such as knowing when there was a parse error before receiving a Request. \nIt is possible to wrap the Http protocol, with another ServerProto impl. It could probably even be a generic wrapper. It would instead find Frame::Error and translate them in a Frame::Message with a Result<Request, Error>. You could then use a new Service to handle that, like so:\n```rust\nstruct Example;\nimpl Service for Example {\n    type Request = Result;\n    // other types are the same\n    fn call(&self, incoming: Self::Request) -> Self::Future {\n        match incoming {\n            Ok(req) => {\n        },\n        Err(parse_error) => {\n            // you could check for some error types\n            // like Error::TooLarge, you could respond with a 414\n        },\n    }\n}\n\n}\n```\nIt's possibly worth wondering if hyper::server::Http should do this itself, and the wrapper could chose to ignore parse errors, or the other way around. Probably also worth being in a separate issue.. @mikeycgto The link to the example doesn't resolve, so I'm able to comment on most of your questions.... @mikeycgto:\n\nFirstly, is this the proper way to handle this sort of streaming?\n\nThat's certainly a way to do it. \n\nIs there a better way to send a stream of Chunks or, more generally, tie an arbitrary Stream to a response body?\n\nI don't know about a 'better' way, but the outgoing (user-supplied) body stream is generic, so you can certainly create your own Stream type. It looks like this example is already making use of that, since before you had to send a hyper::Body body, but this is sending a Box<Stream>.\n\nI see the CPU usage for the process spikes to 100%. I think this is likely because I am doing something wrong with the Interval type but I'm not really sure...\n\nI'm not familiar at all with how the tokio-timer crate works. To try to locate where the CPU usage is coming from, you could compare with different kind of infinite stream. A naive implementation could spawn a thread, use let (tx, body) = hyper::Body::pair(), and then in the thread loop { tx.send(chunk); sleep_thread_for_2_seconds(); }.\n. @scottlamb @mikeycgto the busy-looping may have been in part due to code in hyper, which was adjusted in #1074. Still seems to me that tokio shouldn't try to flush if it didn't write anything, but oh well.. hyper now uses the bytes crate, and so there is an impl From<Bytes> for Chunk, and related shortcuts for set_body. That might be the end of this issue...\nI do wonder if the Chunk type has any value anymore, or if the default body stream should just use Bytes directly.. I'm leaning towards closing this as fixed, unless there's an issue that hasn't been addressed yet.. @abonander If you keep hold of a BytesMut, you can try to reclaim it later by calling reserve on it. If there are no more existing references (Bytes) alive, it will just reset on the same buffer. It might be a nice feature for the bytes crate to allow some way of using a memory pool, or something.\nIn that case though, it's probably better for this stuff to make use of Drop and such (so implemented outside of hyper).. Thanks!\n. The master branch had been neglected, but it is now up-to-date and passing.. As explained in #985, hyper no longer picks a default TLS implementation, and any crate can provide one.. My mistake, I had forgotten when pulling in that commit that headers have a slightly different API in master than they did in 0.9. It should be fixed now.\n. Thanks!\n. That depends on the server. You can ask it however you'd like, but if the server hasn't decided to allow that, you cannot do it. I can use Amazon's S3 as an example: http://docs.aws.amazon.com/AmazonS3/latest/API/RESTObjectGET.html\nIt says to pass a Range header if you wish to download specific pieces of a resource.\n. Thanks!\n. Thanks! I incorporated most of these changes, with a few modifications. The tokio branch is now up-to-date.. That's an interesting panic, for sure. It seems to be this line right here: https://github.com/sfackler/rust-openssl/blob/v0.7.14/openssl/src/crypto/hmac.rs#L100\nIs it just certain keys that panic? Or it always does?. hyper no longer includes the cookie crate, so signing of cookies can be done with any method one prefers. Closing.. There currently is in the docs of the Openssl type: http://hyper.rs/hyper/v0.9.12/hyper/net/struct.Openssl.html. Indeed, look at the docs for Handler. You receive a Request.\nOn Mon, Dec 5, 2016, 6:49 AM H. Almohri notifications@github.com wrote:\n\nThanks for the response. I'm still a bit troubled here. I downloaded the\ncode and added hyper as a local extern in my code (I needed this for\ntesting). When I want to specify a handler for the server, the compiler\nexpects me to specify a type argument for Request and Handler. But this\ndoesn't happen if I include hyper as a dependency in Cargo.\nuse hyper::server::{Handler,Request,Response};\nstruct SenderHandler {\n    sender: Mutex>\n}\nimpl Handler for SenderHandler {\n    fn handle(&self, req: Request, res: Response) {\n        self.sender.lock().unwrap().send(\"start\").unwrap();\n    }\n}\nError: Expected 1 type arguments, found 0. I get this for both Request\nand Handler.\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/965#issuecomment-264872689, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AADJFzFZmc-qgC-2HJQNsL-73lnbX0APks5rFCRjgaJpZM4LC_o0\n.\n. Sorry, a Response.\n\nOn Mon, Dec 5, 2016, 10:11 AM Sean McArthur sean.monstar@gmail.com wrote:\n\nIndeed, look at the docs for Handler. You receive a Request.\nOn Mon, Dec 5, 2016, 6:49 AM H. Almohri notifications@github.com wrote:\nThanks for the response. I'm still a bit troubled here. I downloaded the\ncode and added hyper as a local extern in my code (I needed this for\ntesting). When I want to specify a handler for the server, the compiler\nexpects me to specify a type argument for Request and Handler. But this\ndoesn't happen if I include hyper as a dependency in Cargo.\nuse hyper::server::{Handler,Request,Response};\nstruct SenderHandler {\n    sender: Mutex>\n}\nimpl Handler for SenderHandler {\n    fn handle(&self, req: Request, res: Response) {\n        self.sender.lock().unwrap().send(\"start\").unwrap();\n    }\n}\nError: Expected 1 type arguments, found 0. I get this for both Request\nand Handler.\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/965#issuecomment-264872689, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AADJFzFZmc-qgC-2HJQNsL-73lnbX0APks5rFCRjgaJpZM4LC_o0\n.\n. I started working on it as soon as I saw that PR was merged. It's fairly close, but I stopped for the night. . I've pushed to the tokio branch with a working server. The client module is commented out, as I didn't have time to fix it, but many are probably more interested in the server, so I've got that working now.. Closing as duplicate of #309.. Ah, I didn't realize that this was talking about the tokio branch. Indeed, the issue is that the signal to close in the test suite is a message sent to the server thread. It's not going to happen synchronously, though I suppose for the tests it could be possible to do so.\n\nInstead, as suggested, waiting for the other thread to tick is required so that it can shutdown.. In general things are private because I'm being much more conservative with what is made public, so internal optimizations can be made without breaking people.\nIn this particular case, I didn't really like the idea of a IntoBody trait, but instead wanted Into<Body>. The IntoBody trait currently exists because I cannot impl Into<Body> for Vec<u8>, since neither Body nor Vec<u8> are defined in hyper. I think what is probably the best to do is to create hyper::Body, which may just wrap around tokio_proto::streaming::pipeline::Body, and so I can also kill the trait.\nA reason for hyper to have its own Body is because once hyper supports HTTP2, it would need to use tokio_proto::streaming::multiplex::Body, and I'd rather take care of those details internally.\nI hadn't done all this yet because, well, I've forgotten, and I also wasn't certain if it was the right thing to do, but it currently feels like it.. They should probably be the same type, and they should be made to work regardless of whether 1 side is HTTP1 and the other is HTTP2, and the type is really just meant to describe something that implements Future<Item=hyper::Chunk, Error=hyper::Error>.. My reasoning for using an Option<Body> internally is because 1) you cannot query a Body to see if it is empty, so therefore 2) you cannot know from just the Body whether you should pass a Message::WithBody(head, body) or Message::WithoutBody(head) to tokio. Maybe it makes sense to add a method to Body to check if it is empty. But I don't think that it being an Option<Body> needs to be made known to a user. Actually, considering that it is only needed for constructing the Message, and Request is constructed from a Message, not into one, the option can probably be removed from Request.... Wow, thanks!\nThe client implementation for IntoBody, that uses futures::lazy was needed because calling tx.start_send() when not inside a futures::task, it will panic. Wrapping it in a lazy future, and then spawning a task via future.wait() makes the call no longer panic. I've spoken to @carllerche about it before, it might be that tokio_proto::Body gets a constructor that accepts an immediate result at some point.. Thanks for all the work in doing this. I'll fix up that implementation myself, and update the tokio branch.. Thanks!. I haven't been ignoring this, but instead talking out the problem in detail with some folks, and I think I have a solution. I've filed a new issue with the long write up at https://github.com/hyperium/hyper/issues/985\ntl;dr: A proposal to release a new version of synchronous hyper that removes openssl from its dependency list.. The solution proposed in #985 was used, and 0.10 is now published: https://github.com/hyperium/hyper/releases/tag/v0.10.0\nThanks everyone for pushing on this idea, I really feel like this was the best solution and we can all move forward!. This was done in https://github.com/hyperium/hyper/commit/fc5003125201b0d6cc476cd470a2070061da724e, thanks though!. The http log line comes just before calling TcpStream::connect, which internally (in std::net) does a DNS lookup before trying to connect to the resolved socket address. This definitely looks like the internal call to getaddrinfo is blocking for 30 seconds. There is nothing that can be done in hyper 0.9, as it relies on std::net::TcpStream for DNS lookup, and there is no way of setting a timeout for it.\nWhile not perfectly fixed in the developing 0.10, it is mitigated by using a thread pool of DNS lookups. The best would be to make use of an actual asynchronous DNS library.. Closing as duplicate of #721. The memory is leaked after the program exits?. I copied the above into an example and ran it with valgrind, where valgrind --version gives valgrind-3.10.0.SVN. My uname includes Linux name 4.5.5-x86_64-linode69 GNU/Linux.\nI ran valgrind ./target/debug/example/client, and it reports \"All heap blocks were freed -- no leaks are possible\".. Seeing it possibly coming from OpenSSL made this article stick out when searching about valgrind memcheck: https://rachelbythebay.com/w/2012/12/14/quiet/\nIt seems to suggest that OpenSSL does things that makes valgrind unhappy, but I quote a random blog post as truth.. With 0.10 not depending on OpenSSL anymore, I wonder if this would still happen (admittedly you'd need to test on a non-HTTPS URL).. Thanks! I'll close, but if there's no info, I definitely want to know about leaks.. Thanks!. Most likely, it is the DNS resolution that is blocking for a long time. The\ncurrent usage of std::net does not allow for a timeout. This is solved in\nthe unreleased 0.10 version, but unfortunately there isn't anything you can\nreally do right now.\nOn Sun, Jan 1, 2017, 4:58 AM chenhouwu notifications@github.com wrote:\n\nI am a user of hyper 0.9.x, and suffers the blocking issue for a long\ntime without any solution after googling a lot. the code sample is here:\nfn create_hyper_client() -> Client {\n    let delay = Duration::from_secs(10);\n    let mut client = Client::new();\n    client.set_read_timeout(Some(delay));\n    client.set_write_timeout(Some(delay));\n    client\n}\nfn foo(){let mut res = {\n            let mut headers = Headers::new();\n            headers.set_raw(\"Content-Type\",\n                            vec![b\"application/x-www-form-urlencoded\"\n                                     .to_vec()]);\n            headers.set_raw(\"Accept\", vec![b\"application/json\".to_vec()]);\n        let client = low::create_hyper_client();\n        let url = format!(\"https://xxxx.com/api/v2/{}\", cmd);\n        Ok(try!(client.post(url.as_str())\n            .body(&signed_query)\n            .headers(headers)\n            .header(Connection::close())\n            .send()))\n}\nlet mut payload = String::new();\ntry!(res.read_to_string(&mut payload));\n\n}\nIf the server or the connection are unstable, the program will be blocked\nand never go through, so I have to kill & restart.\nAnything I should be careful for to avoid the situation?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/980, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AADJF5kwJtFBL8AMbuMf-BRm9zIg84UQks5rN6LegaJpZM4LYtO6\n.\n. It could possibly be the connect operation not timing out. That would be after DNS, where TcpStream::connect is trying to do the initial TCP handshake, and it also does not listen to a timeout.\n\nThe stages a request goes through:\n\nDNS (no timeout in std::net)\nConnect (no timeout in std::net)\nset_read_timeout, set_write_timeout (uses setsockopt)\nNormal IO (uses sockopt timeouts). In the medium term, a new version using async IO (and thus timeouts on everything) should be released.\n\nFor now, closing as duplicate of #721. A different solution was used, explained in #985, and a new version has been published: https://github.com/hyperium/hyper/releases/tag/v0.10.0\nThanks for pushing on this!. @sfackler good point, I've now removed the cookie and solicit crates from the 0.10.x branch, since they both had optional dependencies to openssl.\n@zsck The excellent hyper-openssl crate documentation shows how simple it is to add in openssl 0.9 support into your crate.. I plan on making this release later today. I've tested the 0.10.x branch myself, but if anyone else wants to try it or comment about what will be released, now's the time.. Below is the changelog currently expected for the release:\n\nFeatures\n\nclient:\nchange ProxyConfig to allow HTTPS proxies (14a4f1c2)\nremove experimental HTTP2 support (d301c6a1)\nlib:\nremove SSL dependencies (2f48612c)\nremove serde-serialization feature (7b9817ed)\nheader: remove cookie dependency (f22701f7)\n\nBreaking Changes\n\nThere is no more hyper::http::h2.\n\n(d301c6a1)\n* The Cookie and SetCookie headers no longer use the\n  cookie crate. New headers can be written for any header, or the ones\n  provided in hyper can be accessed as strings.\n(f22701f7)\n* There is no longer a serde-serialization feature.\n  Look at external crates, like hyper-serde, to fulfill this feature.\n(7b9817ed)\n* hyper will no longer provide OpenSSL support out of the\n  box. The hyper::net::Openssl and related types are gone. The Client\n  now uses an HttpConnector by default, which will error trying to\n  access HTTPS URLs.\nTLS support should be added in from other crates, such as\n  hyper-openssl, or similar using different TLS implementations.\n(2f48612c)\n* Usage of with_proxy_config will need to change to\n  provide a network connector. For the same functionality, a\n  hyper::net::HttpConnector can be easily created and passed.\n(14a4f1c2). Release is done, docs up, crate published, changelog at https://github.com/hyperium/hyper/releases/tag/v0.10.0. The comparison isn't entirely fair, which I'll explain why.\nIn the browser's case:\n\nIt's likely already cached the DNS lookup\nIt likely already has a waiting connection, so it can skip TCP and TLS handshake\nIt probably even has an HTTP2 connection waiting, which allows even slightly faster performance\n\nA more apt comparison is something like curl, or a browser with its cache wiped.\nWhen I compare time curl https://some.url versus hyper's example client (something like time client https://some.url), they are pretty even in time.. Thanks!. I forgot to update, but this was fixed in the tokio branch. Thanks for the report!. Thanks!. Thanks! The failing test is due to an error in MemBuf::reserve. I'll fix that up.. I initially set the type for ContentType to a vec because allowing it to be generic means each different type ends up with a different TypeId, which is how the typed headers are stored internally in the Headers type. This means that you could have this code:\nrust\nlet mime_with_static: Mime<&'static [mime::Param]> = ...;\nheaders.set(ContentType(mime_with_static));\nlet mime_with_vec = headers.get::<ContentType<Vec<mime::Param>>();\nAnd internally, it will have treat that as two different typed headers, so they will both be stored separately.\nI suppose that's not the end of the world, but at the time it seemed like a bad idea. At the same time, one can create any struct MyDifferentContentType(Whatever) and implement Header, and it will work as well.. Closing as this was merged.. I believe the last change would be to adjust the Connect trait, so that Connect::connect takes &self as well.. Wonderful! I'll click merge after travis finishes.\nCloses #992 \nCloses #993 . Well that's stupid.. they used to, when Service.call required mutable self, but that changed in #994, and we just forgot to update these. Thanks!. The failing test looks legitimate:\n``\nerror: no rules expected the token}`\n--> src/client/mod.rs:645:9\n|\n\n645 |         });\n|         ^\n\nBuild failed, waiting for other jobs to finish...\nerror: Could not compile hyper.\n``. Thanks!. You may find theheaders::shared::HttpDate` useful here, . Shoot, I didn't mean to close this. I was just cleaning up branches, since the tokio branch had been merged into master now, and then came to handle the PRs and issues. \nIf you could re-open, I can merge! (The git history is a little screwed. You may need to do git checkout -b retry master and then git cherry-pick 64d7d25.). A Client::easy() would be nice to remove the need for users to handle a core, but the other question is what to do with the futures of requests.\nrust\nlet client = Client::easy();\nlet work = client.get(url).and_then(dump_body_to_stdout);\n// what does a  user do with work\nI suppose if user wanted to build up a combination of requests, they could then wait on a join of all of them, such as work.wait(), and the Core in another thread should just keep making progress, right?\nPerhaps the easy client also has the idea of being eager: you build up a unit of work, and then give it to the easy client and let it run in an offthread.\nrust\nclient.eager(work); // or spawn(work) or similar. When using the default connector, it's needed to construct TcpStreams. But besides that, it's needed to use tokio-protos BindClient. Looks like this is a first step: https://github.com/tokio-rs/tokio-proto/pull/172. The new client API for 0.12 is simply Client::new(), which will integrate with the default tokio reactor/executor. . There is a health check before using (in Pool, the status is checked that it is still Idle, and not expired), and the hangup on the socket will trigger the status to be set to disabled. Unfortunately, the hangup may take some time to be received, and so it is possible for a client to try to start a new request on the socket before we know it has been closed.\nFor this test case, I've added a sleep to the core to wait for a few milliseconds, since the socket is local, the race was likely just scheduling between the server and client threads. The sleep should make it deterministic, allowing this test to check that disconnected sockets are tossed.\nSeparately, for the case when a client tries a socket before receiving HUP, hyper should do similar to what Go's http client does: check if the socket has been used before, and if it has, try to use a new socket. There is a field to track that on the Pooled type, but it will take a little more work to check it, and also make sure it's safe to retry the request (idempotent method, or body hasn't been written, etc).. There was actually a different underlying bug that this put a bandaid on, I've fixed it up in https://github.com/hyperium/hyper/commit/722661e6ea317a0b0cd8bc4d8864a26527f93da1. I merge manually, since I wanted to change the fix(server) into a refactor(server), but not bother you about it. Merged into the 0.10.x branch here: https://github.com/hyperium/hyper/commit/baef7abbdfe22ee4c008ce291cb96e88f5d5c8b0\nThanks a bunch for this. I hope it helps with #950.. Oh right, PS, if its at all possible to test that this does help #950 using a git dependency, that'd be great, so we can know if releasing 0.10.1 would be a notable bug fix.. This is absolutely the direction I had in mind. I would also remove the use\nof the Url type here, since it actually does more than is wanted on the\nserver side, and does several allocations. Since this type is created for\nevery request, we need to make it faster.\nI can do that as follow up if you prefer.\nOn Sat, Jan 14, 2017, 5:40 AM Guillaume Gomez notifications@github.com\nwrote:\n\nHere is the first draft of the new Uri struct. If this seems okay to you\n@seanmonstar https://github.com/seanmonstar, I'll remove the actual\nUriRequest and replace it with the new Uri.\n\nYou can view, comment on, or merge this pull request online at:\nhttps://github.com/hyperium/hyper/pull/1007\nCommit Summary\n\nCreate new Uri struct\n\nFile Changes\n\nM src/uri.rs\n   https://github.com/hyperium/hyper/pull/1007/files#diff-0 (139)\n\nPatch Links:\n\nhttps://github.com/hyperium/hyper/pull/1007.patch\nhttps://github.com/hyperium/hyper/pull/1007.diff\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/pull/1007, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AADJF25pKOqxkQBOnMp-tVEHD76ZPmDBks5rSNBKgaJpZM4LjoIg\n.\n. It's been removed in the 0.10.x branch, and in the tokio branch. The tokio branch will be merged into master in a day or 2.\n\nThanks for the effort though! I recommend trying the tokio branch.. I'll be cleaning up the issues this week, trying to tag things with the \"easy\" label that are good for starters. Especially as I merge the tokio branch, there is need to start writing guides/docs on how to get started using hyper.\nBesides that, if you would like other projects, watch in This Week in Rust, there is always a \"Call for Participation\" section with easy-ish issues from various projects.. hyper no longer includes a default TLS library, so you'll need to pick one. I'd recommend hyper-native-tls.\nSee #985 for reasoning.. I could certainly see value in adding a error!(\"HttpConnector used to connect to HTTPS URL, try using HttpsConnector with an SSL implementation\") or similar just before returning the Err. . Of course, this would only alert you if you had some sort of logger setup...\nSeparately, I wonder if it makes sense to change from suggesting Client::new() to Client::http() (or even Client::plaintext()?), so it is explicit that the client won't be able to connect to HTTPS.. The original code was taken from a PR on the standard library, and then broken by myself by not having tests. I've been rewriting it today with some tests and asserts, though I had somehow missed that Vec::resize was a thing.. Er, I didn't realize deleting that branch would close this. I had finished merging the tokio branch into master, and it was now out of date. Also, noticed there is a compile error in the benches/end_to_end.rs.. Well crazy me. I must have already done this in master. I was just tweaking some things in the 0.10.x branch, and saw this type and was like 'why does this exist'. Apparently I've already thought this before. No need to fix it in the 0.10.x branch, development is on master now.. I don't know how to have different licenses for different files. I have\nbeen wanting to relicense hyper with a dual license, but trying to get all\npast contributors to acknowledge and allow the change has so far felt like\na big hurdle.\nOn Wed, Jan 18, 2017, 12:18 AM Julius de Bruijn notifications@github.com\nwrote:\n\n@seanmonstar https://github.com/seanmonstar The only open question with\nthis PR is, that I used parts of the retry-after library. Even though this\nis quite modified already, the original was Apache+MIT and I don't know how\nto deal with the licensing; should we include the Apache license only for\nthis part or not.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/pull/1017#issuecomment-273411398, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AADJF5ltXFvMd6MC_NWLmSlKdSlrFuDjks5rTcrogaJpZM4LmlvE\n.\n. Thanks!. You should be able to use hyper::Method to access any of them: https://github.com/hyperium/hyper/blob/master/src/lib.rs#L41\n\nI'm personally uncertain how many additional \"helper\" methods should exist, when you can customize the method, headers and body on a Request and then call client.request(req). There are several of these in 0.10, but I tried to be more conservative this time, figuring get was definitely needed. Perhaps also post, but I dislike how you may or may not need a body for POST, but defining a function would require making you choose.... Since it seems the issue was just being able to use hyper::Method in Request::new, I'll close this for now. Proposals of convenience functions for Client are always welcome, ideally with examples supporting them.. You shouldn't need a mutable reference to Request...\n```rust\nlet mut req = Request::new(Get, url);\nreq.headers_mut().set(ContentLength(500));\nreq.headers_mut().set(ContentType::json());\n// also!\nreq.headers_mut().extend(other_headers.iter());\nclient.request(req)\n```\nI do think that the client request type is missing some builder methods, similar to the server response type. Adding those would allow this sometimes easier builder pattern:\nrust\nclient.request(\n    Request::new(Get, url)\n        .with_header(one)\n        .with_header(two)\n        .with_body(body)\n). Thanks!. Thanks!. @M3rs absolutely!. I meant to include this originally, but the parse function from Go is a good example: https://github.com/golang/go/blob/master/src/net/url/url.go#L469. @M3rs perhaps the best to do is include the port if it was in the original URI, and if it wasn't, do not include.\nSo:\nhttp://foo.bar:3333/baz => foo.bar:3333\nhttp://foo.bar:80/baz   => foo.bar:80\nhttp://foo.bar/baz      => foo.bar. It's a good question! It depends on the format of the request-target. If it is origin-form or absolute-form, (so, /foo or http://host/foo), then there MUST always be a path, even if not explicitly included. That means http://127.0.0.1:80 => \"/\" is correct.\nHowever, if it is authority-form or asterisk-form, the there is NOT a path.  Which again, means localhost:3000 => \"\" is correct. The details can found in this part of the spec.. That assumption is likely fine for now. It is true for HTTP/1. It will need to be updated slightly when supporting HTTP2, since scheme is always included at that point, but we don't need that just yet.. Would be fixed by #1089 . Url is no longer used in hyper.. This was done in #1038 . I've added some links to the release page: https://github.com/hyperium/hyper/releases/v0.10.0\nWould likely also be useful in the docs somewhere, and a guide dedicated to it.. @antoyo the easiest way right now is to make use of hyper-tls. However, the Client in hyper is generic over any kind of connector, so others can be created, with hyper-tls as a example.. Looks like the newest nightly updated to better detect unused macros, not your fault.. Thanks so much @M3rs, this is fantastic work! I'll file follow up issues to remove the Vec usage as well.. Correct.. @robinst sure, that'd be fine!. Excellent, thank you!. Excellent, thank you!. For history: the issue was that hyper noticed a partial write, and simply waited thinking that the socket was blocked. However, since the write returned Ok(n), tokio did not know to re-register the socket with epoll for the write event, and so we sat around waiting forever. The solution was to loop on the write until it returned EWOULDBLOCK, which means tokio would then re-register interest.. Thanks for reporting this. Seems there was an error in crates.io when trying to update its index, and so only the DB was updated, but it wasn't put into the crates.io-index.\nI cannot republish the version, but I have published 0.9.17 that is the exact same source, and it seems to have updated the index: https://github.com/rust-lang/crates.io-index/commit/d2b7dcc940d95ad59b2300cf84bbf7b2756898b7. For 0.9.16, found this was indeed a bug in crates.io. See https://github.com/rust-lang/crates.io/issues/448. The issue was that the commit message didn't match the format defined https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md#git-commit-guidelines\nI modified the commit message to match, thanks!. They are very uncommon, and you can always access them as hyper::Method::Patch etc.. That definitely sounds good. This is basically for this line: https://github.com/hyperium/hyper/blob/master/src/server/mod.rs#L258\nSo, impl From<Message<ProtoRequest, http::TokioBody> for Request? I could move the SocketAddr into the ProtoRequest type, but I don't know how someone would make use of this, since they cannot create those types.... This is something that Tokio needs to figure, since hyper is using Tokio internally. I've discussed the concept before with the Tokio devs, but apparently there wasn't a tracking issue, so I've filed https://github.com/tokio-rs/tokio-proto/issues/138.. Yep, this can be done now with the server::conn module, and in the next release, could also be done thanks to #1563.. Ah, how irritating that I used the wrong tag to mark it as no_run. Thanks for catching that! Seems this fix though doesn't fully fix it? I'm guessing that since this now has an extern crate, it needs a fn main() {} and extern crate hyper; and all the shebang.. Thanks!. This seems blocked on tokio-proto trying to buffer the first body frame, https://github.com/tokio-rs/tokio-proto/issues/153.\nI'm going to close this until that is figured out, so that I don't keep thinking that there is a Pull Request I haven't looked at.. There would also need to be a change in http/h1/parse, instead of using req.path.unwrap().parse(). Instead, we want to create a Uri using the related MemSlice. It could look like this:\nrust\nlet path = slice.slice(path_start..path_end);\n// path was found to be utf8 by httparse\nlet path = unsafe { MemStr::from_utf8_unchecked(path) };\nlet uri = try!(::uri::from_mem_str(path));. This is known, and a crappy part about hyper in 0.10.x and before. With blocking IO, there isn't a sufficient way for the hyper Client to reap stale connections, since detecting one requires doing IO, which could block indefinitely.\nThe problem doesn't exist in master.. Yea, I suppose state would need to be recorded, to know that inside \"some text\", a delimiter means nothing.. Oh interesting point. Yes, at the moment, uri::Uri was meant specifically for the request-target of HTTP requests. In RFC7230, it seems that relative URLs are not allowed.\n\n\nOne possibility is that we decide that Uri can be used for any URI case, in which case it could also be used in things like the Location header. Then the check that the Uri is absolute would need to be removed from the normal parsing, and only checked when parsing the request-target.\n\n\nThe other is to leave the Uri the way it is, and have Link represent the URI as a String, similar to how the Location header current does.\n\n\nI kind of like the idea of adding types to those headers, but only if supporting them in the Uri doesn't make parsing more complex and thus slow down parsing of the request-target. I also cannot remember currently if the URIs in these headers can contain additional formats that the request-target does not allow (besides a relative URL).. I think that sounds like a good plan, start with String, and we can open a new bug to see about using Uri in the each of these headers.. I believe the integration with coveralls is broken at the moment, it recently just went to 0% on master too. I don't yet know why, perhaps a change that's preventing kcov from collecting the data.. Do you feel this is done, feature wise? If so, I'll look it over once more later with the goal of merging, unless there was something else you wanted to add or adjust.. @davidcornu sounds good, open whenever ready. I've filed #1085 to track the bug.. Being generic over a stream of Ios was actually how the server used to work, and was changed to the current situation in https://github.com/hyperium/hyper/pull/1013!\nThe idea is that Http implements ServerProto, and there is also the exposed bind_connection method, so really, any stream of connections can already be used.\nMaking use of TLS for the Server just involves using tokio_tls::proto::Server::new(http, listener), from here: https://github.com/tokio-rs/tokio-tls/blob/master/src/proto.rs\n@alexcrichton may have more thoughts on the matter.. Oh right, what I had suggested doesn't actually work yet without #1036. With #1036 fixed, would that solve your use case @mattwoodyard?. Is this meant for the reqwest repo?. @mattwoodyard It looks like the generalization of tokio's TcpServer hasn't been released on crates.io yet. If I change the the version of tokio-proto to a git dependency, my example compiles using TcpServer.\n@alexcrichton hm, so I can create a RemoteAddr trait or similar, and then change the bounds to T: Io + RemoteAddr + 'static. I can implement this easily for TcpStream, but it breaks down quickly. I cannot implement the trait for TlsStream without depending on it, and then anyone who wants to make use tokio-tls also cannot implement the trait, since it is then a foreign type and foreign trait. The user then needs to create a wrapper, and then implement Read + Write + Io + RemoteAddr for it, and groan.\nIt might be possible to alleviate that if I include an impl<T: Io + AsRef<TcpStream>> RemoteAddr for T, which could work for TcpStream and TlsStream<TcpStream>, if rust-native-tls were to implement AsRef<T> (it doesn't currently, but does have get_ref() methods). However, that seems rather fragile. Also seems like besides hyper's desire for a RemoteAddr trait, various other protocols will also want to get that.. Thanks for the PR,\nI've actually purposefully not put these in for two reasons. I don't think there is value in seeing these badges on the release pages, since clearly the versions would not have been published if they didn't build. And also, this shows the status of the master branch, which is not the code people would be downloading.. Thanks!. Thanks! Besides the comments fixes, this also found a bug in the Preference header!. Great, thanks!. Hm, I worry about exporting hyper::Origin and hyper::header::Origin as different types.\nI've so far felt that if someone wanted to really use all the extras of the url crate, to depend on the url crate themselves. I also have been starting to wonder if there is value in requiring a Url over just using the Uri defined in hyper proper.. Thanks!. hyper in master no longer creates worker threads. You have complete control over what threads are used and what happens before using them, and then setting up the Http protocol on your thread(s) of choice.. Indeed, it is meant to be a libhttp. It is definitely possible for end-users to build things with it. But there are so many additional optional things many people want to when building a server or client, people usually use a framework anyways.. Thanks!. > the main purpose of hyper is to be \"stringly\" typed so this may be out of scope\nWhat gives you that impression? In fact, hyper actually uses a lot of types that aren't simply strings, to not be stringly-typed HTTP like so many other libraries.\nhyper actually re-exports the Url type from the url crate. If you have a specific issue with it, you'd probably want to file an issue there. \nIn this specific case, you could make use of percent_encode to convert your raw bytes into something acceptable in a URL.\n\nI can make an unchecked string out of my bytes\n\nIf it's not valid UTF-8, this is unsafe and can cause unexpected behavior in your app. Do not do that.\n. Oh, that sentence is meant to point out that HTTP/1 (and largely HTTP2) are protocols about sending and receiving strings. hyper tries to make use of Rust's type system to reduce the mistakes that can be made when everything is just a string.. So, it is possible currently without going through serializing and parsing a format string, but it is also more work than a single method. How to do so today:\n// with a Duration\nlet ts = time::Timespec {\n    sec: duration.as_secs() as i64,\n    nsec: 0\n};\nlet tm = time::at_utc(ts);\nlet date = HttpDate(tm);. Revisiting this, I'm considering removing the (public) usage of the time crate to create HttpDate. It would still be used internally, for strftime and strptime, but it could be made to work entirely with std::time::SystemTime now.\nrust\nheaders.set(LastModified(file_modified_date.into()));. HttpDate now has From<SystemTime> implemented for it, in v0.11.. I'm not quite certain what exactly you're looking for. There isn't a specific document about a release strategy, there is the Milestones that has a super rough look at what things would block a release.. Sorry, in what context? The url? The Origin header?. I see. So it can either be null, or the full origin. It seems like any way to make this work with hyper's Origin header would require a breaking change. Since that's the case, my thinking is something like this, for inclusion in v0.11:\n```rust\npub struct Origin(OriginOrNull);\nenum OriginOrNull {\n    Origin {\n        scheme: String,\n        host: Host,\n    },\n    Null,\n}\nimpl Origin {\n    pub fn new, H: Into>(scheme: S, hostname: H, port: Option) -> Origin{\n        Origin(OriginOrNull::Origin {\n            scheme: scheme.into(),\n            host: Host::new(hostname.into(), port),\n        })\n    }\npub fn null() -> Origin {\n    Origin(OriginOrNull::Null)\n}\n\npub fn is_null(&self) -> bool;\npub fn scheme(&self) -> Option<&str>;\npub fn hostname(&self) -> Option<&str>;\npub fn port(&self) -> Option<u16>;\n\n}\n```\n Whatcha think?\nFor servo, if you wish to make use of this right away while keeping to hyper 0.10, you could implement an Origin header in Servo.\n. Oh I remember this conversation again. We didn't use url::Origin because it requires the port. The header has the port optional.. Thanks to work in #1121, the breaking change required here is done. This would be pretty easy to implement using an internal private enum, as described in https://github.com/hyperium/hyper/issues/1065#issuecomment-280116120, keeping our use of Cow instead of String.. Those bounds are only the constructor ofServices, theNewService. TheServiceitself doesn't need to beSend + Sync. This is because theServerin hyper may soon be able to make use of multiple threads if asked, and so theNewService` constructor needs to be threadsafe.\nThis example in the tokio docs shows the ideas of how you can move the pool into the NewService constructor, and then just make clones of the pool for each Service. Note it uses the minihttp crate and TcpServer, which you can substitue as hyper's Http::bind. The missing piece might be the move part of the closure, but I cannot say without seeing.\n\nZooming out, if you're composing multiple things that all need a tokio reactor, you may not want Http::bind. bind is supposed to be an easy constructor for simple servers. You can hook up a TcpListener to a Core you already own, and pipe the incoming streams into Http::bind_server.. The field was actually just changed to an Option<SocketAddr>, because of a few reasons.\nAdditionally, the deconstruct method was more designed to allow taking the main expensive pieces without cloning. The address can be easily copied before, and so we can keep less noise in the deconstruct method.. The Method could potentially be a String and need cloning, if it's an odd method. The version is definitely just a cheap copy, and in the end probably not important to anyone. The current signature was just thinking \"what makes up the request?\"\n```\nPOST /foo HTTP/1.1\nContent-Length: 11\nHello World\n```\nOh, that's (Method, Uri, Version, Headers, Body)! I don't know if that's the best way to to do it, though :). I was incorrect in saying it should have been Body, since Http<B> is where B: AsRef<[u8]>, so it should have been Chunk. I've done so in master.. Oh, it's not that the various headers don't implement PartialEq, they do! It's that there isn't an impl for &ContentType, and all the others as references. How tedious.... Very true. I wonder, would it be too magical if headers also implemented PartialEq<Option<&Self>>?\n```rust\nif req.headers.get::() == ContentType::plaintext() {\n}\n``. Thanks! I think the issue in #1071 was instead that the user was comparing&ContentType == ContentType... Still, this code is correct, so merged!. I've been looking in to trying to park and unpark a little less, but one thing here strikes me as odd: if the Sender hasn't sent anything, why would tokio try to flush again, especially if the previous flush already said it was complete?. The expect evolution is that you could useTcpServerin tokio-proto, and hyper can remove some of it's TCP-specific handling. Half of the work forTcpServer` has been merged, the part adding graceful shutdown is still a PR: https://github.com/tokio-rs/tokio-proto/pull/135\nI'd probably want to defer those kinds of improvements to the TcpServer itself, since it's not an issue unique to hyper.\ncc @alexcrichton . > I had a pretty hard time figuring out how the \"easy mode\" was supposed to work and actually fail to see anything easy, there.\nThat's useful feedback, thank you. Were you specifically looking for an 'easy' method to give a Core to? Or you find even the usage of the easy method in the hello world example to hard to figure out?\n\nFrom what I understand, changing hyper to use the TcpServer from tokio_proto should solve this issue. I'd appreciate that.\n\nSo, it currently does, ish. The Http type in hyper implements all the right things to be usable with the TcpServer in tokio-proto, but only tokio-proto master. tokio-proto received some improvements to make integration easier, but those haven't yet been released in a new version to crates.io.. >  AFAICT the server part insists on creating its own Core. Or am I missing something?\nThe type hyper::server::Server is basically a specialized version of tokio-proto's TcpServer at the moment. It's created from Http::bind, and is meant for the 'easy' case, which is \"start using this thread to handle HTTP connections\".\n\nI'm missing the event loop from examples/server.rs. How would I run two HTTP Server instances on the same event loop?\n\nIt's true that we're currently light on docs. I expect one \"guide\" in #805 to discuss the advanced uses of the Http type, such as creating a Core outside of hyper, listening for connections from wherever you want, and just using the Http type to drive the HTTP state on the provided connection.\nTo run multiple servers, you would setup some listeners (probably TcpListener), pipe their incoming() connections into the Http instance, and then have the Core just run for as long as you want.\nExample-ish:\n```rust\nfn spawn_server(http: Http, listener: TcpListener, handle: Handle, factory: YourNewServiceType) {\n    handle.spawn(listener.incoming().for_each(move |(socket, addr)| {\n        http.bind_connection(&handle, socket, addr, factory.new_service()?);\n        Ok(())\n    }))\n}\nfn main() {\n    let core = make_core();\n    let listeners = make_listeners();\n    for listener in listeners {\n        spawn_server(Http::new(), listener, core.handle().clone(), || Ok(HelloWorld));\n    }\n    core.run(future::empty::<(), ()>()).unwrap();\n}\n``. The main pain point here is when you want to use hyper's server, but you need theCorebeforehand, or wish to control theCore` yourself.\nInstead of being given a reference to a Core, it seems a solution could be to allow an Http to \"spawn\" a server-like task into a Handle. This could end up looking like:\n```rust\nlet mut core = Core::new()?;\nHttp::new().spawn(addr, new_service, core.handle());\n// other Core/Handle things whatever\ncore.run(empty)?;\n```\nAn alternative API to do the same thing could be:\nrust\nlet mut core = Core::new()?;\nlet server_future = Http::new().spawn(addr, new_service);\ncore.handle().spawn(server_future);\nThis would ease having a server and a client on the same core:\n```rust\nlet mut core = Core::new()?;\nlet handle = core.handle();\nlet client = Client::new(&handle);\nhandle.spawn(Http::new().spawn(addr, move || {\n    Ok(Proxy { client: client.clone() })\n});\ncore.run(empty)?;\n```\n\nThis doesn't give the ability to run the Core using hyper's run_until logic, but the run_until seems generic enough that it should probably go in tokio-proto.. @alexcrichton Server doesn't support a custom Core, it creates its own. Http can be used with an Handle, though. \nPlaying with this, it does seem like it doesn't help a whole lot.\nBefore:\nrust\nlet mut core = Core::new()?;\nlet handle = core.handle();\nlet addr = \"127.0.0.1:3000\".parse().unwrap();\nlet http = Http::new();\nlet listener = TcpListener::bind(&addr, &handle)?;\nhandle.spawn(listening.incoming().for_each(move |(sock, addr)| {\n    http.bind_connection(&handle, sock, addr, Echo);\n    Ok(())\n}).map_err(|_| ()));\ncore.run(empty)?;\nAfter:\nrust\nlet mut core = Core::new()?;\nlet handle = core.handle();\nlet addr = \"127.0.0.1:3000\".parse().unwrap();\nlet http = Http::new().spawn(&handle, &addr, || Ok(Echo))?;\nhandle.spawn(http);\ncore.run(empty)?;\nThe benefit of it being a Future is that you can wrap it in another, allowing you to adjust how to shutdown the http future task.. @tomyan ah, with no compiler checking my code blocks in github comments, I forgot a piece. The listener.incoming().for_each() returns a Future<(), io::Error>, since accepting a socket can cause an IO error. You'd want to stick some sort of .map_err(|_| ()) on the end of it, since the thing passed to handle.spawn must be Future<(), ()>.. I've put this off for a while claiming that it will be solved in tokio-proto, but I'm now leaning towards may as well fix it in hyper, if a generic way appears in the future, no harm done. The proposal is in https://github.com/hyperium/hyper/issues/1322.. The API in master (soon to be 0.12) has been updated such that a Server is now just a future, needing to be run on some executor. Along with the change to tokio separating the reactor from the executor, this is effectively done.. Excellent, thank you!. The design of how these sorts of things is exactly why various web frameworks pop up. People have different opinions on how they should work. This feature shouldn't be in hyper, but in a server framework.. Oh, I'm sorry, I just assumed you meant for the server, since filters did sound like a server thing. For the client, in master, there is no more builder off the Client. You construct a Request, which has accessor and mutator methods, and then give it to the Client.. @limitee If you're using 0.10.4, then it's not the same issue here. This bug is in master.. I haven't built a test yet for master, but the chunked decoder got a pretty extensive rewrite to handle reads blocking mid chunk-size, so it may have been dealt with after all.\nEither way, thanks for this!. Published in 0.10.5.. The Client in hyper does not implement Send. It currently makes use of some types, like Rc and unsync channel, that prevents it. They could be replaced with Send versions, but it'd be at a performance cost. Is there a reason you're try to send it to another thread?. It is possible for hyper to change its implementation of Client, such that sync types are using internally, and this would allow sending those futures to other threads. It does mean paying a performance penalty even for those not using it on multiple threads, but maybe that's worth it?. After having looked into it, it'd be rather difficult to change. Tokio's ClientProxy uses a RefCell internally, which means it can't be Sync without a Mutex. And since the Client in hyper puts the proxy in an Rc, to become Send, it would require that the proxy is Sync.. Yes, the Client should be changed to be Send. Here's the pieces that would need to be adjusted in order to do so:\n\nThe Client cannot hold a tokio-core::reactor::Handle, as it is not Send. It either needs to be a Remote, or a new-tokio Handle.\nThe Connect and B: Stream bounds need to have Send added. It's needed to make FutureResponse send, since it boxes futures that contain them. For those that don't want to be required to use Send, the lower-level Connection API can exist without those requirements.\nThe Executor that is currently boxed would need to have Send added to its bounds as well. This probably will go away entirely with futures 0.2, since the executor can be gotten from the Context argument.. This has been done in master, and will be part of 0.12.0.. Fold gives the maximum control over all the details. There is a request (https://github.com/alexcrichton/futures-rs/issues/390) for a new method on Stream, and likely solution (https://github.com/alexcrichton/futures-rs/pull/394).. Nice, thanks!\n\n\nDo you want to include fuzzers in this repository?\n\nI don't know, what do they look like? I've been meaning to try out fuzzing, but so many plates spinning.... Well, regardless of the outstanding question about fuzzers, this definitely fixes bugs, so I'll merge now. Thanks!. For now, since the implementation was wrong, I removed the methods related to link extensions. Changing them would be a breaking change, so better to do this before releasing 0.11. The proper implementation can be added without breaking.. For now, the new version of hyper won't be including the typed headers directly, so I'm closing this here as a won't fix.. @pgerber that looks like correct usage to me (I don't know much about S3Client).\nMany have found that hyper does do connection pooling even with TLS, so there is perhaps something extra here that is going on. Let me list a few things that could be:\n\nAre all the requests being made at the same time, or at least before a previous request/response has finished? A connection is put back in the pool once the response has been read, and the pool will make use an idle connection if it's there, but if it isn't, it doesn't wait around. It starts a new connection immediately.\nIs the full response being read? If a response still has pending bytes to be read (hyper would know this either by counting after seeing the Content-Length header, or based on the chunk size during Transfer-Encoding: chunked), the response won't be put back in the pool. This is because hyper won't do extra reading that you don't ask for, and with bytes still pending, future responses would be behind the bytes that hyper won't read.\nDoes this occur with other TLS implementations? I don't know much about rustls, I've most often seen people using hyper_native_tls.. > It's actually PUT requests, but yes, requests are completed before the next request is started.\n\nTo clarify, the response body must read also. If S3 is returning some JSON response of details, and you don't read it, that connection cannot be reused.. Ah, that would do it! I can't believe I forgot to mention that condition as well.. @mgattozzi I'm not entirely certain about the details actually, the Url type is re-exported from the url crate. Sorry about the duplicate work, but I'd suggest opening this issue on that repo.. For all versions of hyper 0.10.x and before, this is true. Using std::net::TcpStream::connect(domain) makes use of blocking getaddrinfo, which does not have a timeout and cannot be interrupted. DNS on master does make use of a timeout, and can't really be fixed another way.\nThere's more in a previous duplicate issue, #721.. hyper no longer makes use the of the Url type internally anywhere. It's only usage at this point is in client::Request, for setting the target of the Request, and in the generic Connect type that Client uses.\nThe Connect trait is basically an alias for Server<Request=Url, Response=T> where T: Io.\n\nSo, hyper could remove the public re-export, and change Client and client::Request to make use of hyper::Uri. That looks like the right direction to go.\nMy last remaining question is whether there is value in implementing From<Url> for Uri, since it'd be a near-free conversion, and people who do have a Url could then do client.get(url.into()).. At least not for now. I expect something like reqwest will allow both types, to ease usage.\nFor now, you can reduce some of the cost by just using a reference to the Url: Uri::from_str(url.as_ref()).unwrap(). Thanks!. Sorry for not noticing a while ago!\nI'm trying to have any and all examples be in the form of guides, as opposed to in the source repo. So I'm going to close this, but the guides definitely could use an \"advanced\" server guide showing how to use your own Core.. Agh, 1#something really means 1 or more? Interestingly, when I look in other clients, they seem to do absolute matches, like if headers['accept-encoding'] === 'gzip', where as according to this, they should be checking in a possible comma-separated list?. Well, OK. I suppose I can take comfort in knowing we match the spec more closely. Thanks for verifying, and sorry for sending down the wrong path.. Great, thanks!. Yea, it looks like there may have been in a bug in that nightly, I've restarted the tests and they seem to be passing.. Thanks!. As of now, there isn't specific timeouts to set that are inside hyper. There are a few reasons why, but the main reason was because using futures makes it quite simple for anyone to deal with timeouts external to hyper. For example:\n```rust\nlet timeout = tokio_core::reactor::Timeout::new(Duration:from_secs(30), &handle))?;\n// a tokio timeout doesn't necessarily mean an error,\n//  but in our case, always make it an error\n// (it could also be used for things like \"send this message after this amount of time\")\nlet timeout = timeout.then(|_| Err(io::Error::new(io::ErrorKind::TimedOut, \"our timeout\")));\n// set up our client request\nlet future_body = client.get(some_url).and_then(|res| {\n    res.body().fold(Vec::new(), |mut vec, chunk| {\n        vec.extend_from_slice(&chunk);\n        Ok(vec)\n    })\n});\n// select on the request and the timeout\n// the first one to 'complete' will trigger our callback\n// since we converted the timeout to always be an error,\n// it will only ever be in the Err variant\nlet work = future_body.select(timeout).then(|result| {\n    match result { \n        Ok(body) => {\n            // do something with the body\n        },\n        Err(e) => {\n            // could be an http  or io error (including our time out error)\n            // inspect to find out which it was\n        }\n    }\n});\nhandle.spawn(work);\n``. As suggested, you just needed to use [String::from_utf8(vec)](https://doc.rust-lang.org/std/string/struct.String.html#method.from_utf8) to convert the folded vector into a String.. What sort of test? What were you hoping to do, or hoping would happen? . Understanding why doesn't work requires perhaps a bit more of an understanding of howFuture` in general works.\nIn this case, you've returned a Future that is basically AndThen<Timer, FutureResult>. So when tokio's internals receive this Future to drive the connection forward, it will be polling this AndThen. Inside the AndThen::poll, it will be calling Timer::poll until the timer is ready. Only then will then consider anything later in the chain. Therefore, when you want to add a timeout to any Future, you should usually select them together. A Select<Timer, Other> will poll both futures until one is ready or errors.\n\nAs for doing what you want, receiving notification that the socket has been closed, that may not actually be always easy to do. You'd need to somehow be polling on the Stream that holds the connection. You would definitely know if you were polling on the body, but there other situations that would be harder. \nFor example, if you've read in the whole body, and are now doing other work, like talking to a database, there isn't really any way to ask if the socket is still alive. When writing the body, you are also in a tricky situation. If using the default Body::pair(), the Sender should be able to tell you an error occurred when using start_send and poll_complete. If using some other Stream, you may not be able to know directly. The Stream would be dropped once there was a socket error, so I suppose you could know in the Drop of a custom Stream whether it was consumed or not.\n@alexcrichton or @carllerche, any thoughts on how to receive notification when one isn't polling the incoming body stream?. With the new dispatcher in hyper, (used by default except when using with TcpServer::new(Http::new())) when the socket closes, the response body stream will no longer be polled indefinitely. The internal connection state will be dropped, and a call to tx.send should return an error.. Yes, this is on purpose for now. Uri could possibly gain mutators in the future.\nhyper is going through what most libraries go through as they mature: removal of extras, providing a strong core, and allowing extras to be built on top with whatever opinions the builder has.. The reason was to start conservatively. I'm not against mutator methods on Uri, but I'd probably want to keep them pretty basic.\nFor now, it's possible to do this outside of hyper, such as making use of the url crate, so I feel that the urgency is lower, and we can focus on just getting it right.. That's correct. I meant that manipulating the string is possible with something like Url, and converting that into a Uri is just a parse after, which isn't actually that expensive, as it does much less then Url's parsing does.. As I said, I'm not against the idea, I just want to be conservative. Is there a minimal API that would help? Maybe a Uri::from_components(), with possible components being scheme, authority, path, query?. No, it's the other way around. All Urls are valid Uris, but not all Uris are Urls. Example URIs that aren't URLs: *, google.com:443, /foo/bar. So it is semantically correct to have From<Url> for Uri. However, I'd like to remove the url crate from hyper's dependencies (currently only needs it for some percent decoding, but working to get that into a separate much smaller crate).. >  setters has the problem that each would have to return Result<(), UriError>\nYes indeed, there is complexity to setters that made me omit them at first.\nA builder could be a good way to go. It seems like it could be explored out of crate, and if it's a monumental improvement over calling Uri::from_str(url.as_str()), we could consider its inclusion.. Since hyper is replacing its own type for http::Uri, this issue isn't directly actionable here. . Thanks, good idea!. Agreed. I starting with the most common, Host, but others should follow. Since changing the signature would be a breaking change anyways, it also makes sense to make the fields private and use constructors instead. That way we can start with Cow but we can switch to Bytes or something later in the future and not break. Some common headers that could benefit:\n\n[x] Location\n[x] Origin\n[x] Referer\n[x] Server\n[x] UserAgent. @mcarlin That'd be great! I turned the list into checkboxes, ideally we can keep them up to date.. The list of headers I made have all been converted. If there's changes want to a specific header, lets open specific issues. Thanks!. Thanks!. Looks great! Will merge once CI finishes, thanks!. Ok!. Published v0.10.6 with this change. Thanks!. Interesting! As conn.poll_complete() is called, we take that to mean to flush Conns write_buf into the io, but then we don't actually call io.flush(). I assume that's the missing piece?. Thanks for the steps to reproduce! It seems the issue was that during parsing, hyper didn't call read until the socket returned WouldBlock, which is required for tokio's socket implementation to know to register for more readable events.. Hi there! If you're not using Client::new, but Client::with_connector, you would need to configure a Pool also.\n\nAs this is a usage question and not really a bug, I'm going to close.. Sorry, it didn't notify me of the edit.\nA very common gotcha with hypers Pool is that you must read the full response for that socket to be reusable. \nBesides that, I assume the host is the same, that the version is HTTTP/1.1 (not 1.0), and there's no Connection close header?. Ah interesting. It seems a few things have gone wrong here.\nThe CpuPool is calling unwrap on the spawn of the thread, and when you've created a bunch of hyper Clients, and thus a bunch of thread pools, the spawning fails and the unwrap panics. futures-cpupool probably needs to not panic but return a Result here. @alexcrichton does that seem reasonable?\n\nThe second part is much harder to diagnose. The gist is that the Connection from hyper is receiving a Response, and when given back through tokio-proto's plumbing, tokio finds that there isn't a waiting future to receive it. This could mean that either the waiting future was dropped somehow before getting a response, but the connection was asked for a response anyways (it should have dropped when the FutureResponse dropped), or hyper's Connection is receiving, parsing, and notifying of a second Response after the first, and so there's no waiting future to receive it.\nIf you could, a pastebin of logs for hyper and tokio-proto at the trace level would be a great help!. Fantastic, thanks!. Thank you!. Thanks! Let me know if after fitting all the pieces together, this solves your use case, and I'll release a new version (so that hopefully, if it doesn't, we don't have new versions fixing nothing.). > Currently, there is no way to manually construct a client::Response\nThis is actually by design, for now. Keeping the construction private allows us to adjust the internal pieces without causing breaking changes.\n\nit would be nice if there was a way to write a Response to a file.\n\nI sympathize with the desire to have something like this, but I'm not sure doing it in hyper is the right place. Looking around in other languages HTTP libraries, they don't typically have this either. Probably because it's not something that everyone needs, and since it can be done in an external library, that's where it typically goes. It'd probably be a nice crate to exist, one that can provide a Connect and custom AsyncRead + AsyncWrite that can pipe the data off to a file!\n\nit would also work if client/server Response and Request types were the same.\n\nUnifying the the client::Request with server::Request and client::Response with server::Response is a definite possibility. There's a few kinks to work out for that, but probably better for a different issue.. Maybe we're thinking of different things. Why would you need to parse headers? I assumed you meant recording all the raw bytes, so parsing them isn't required. The Connect receives a Uri, which you can use to name some files, and then your returned io can copy bytes to the files while also sending and receiving on the socket.\nDo you mean only writing to file the message bodies?. In that case, yes, you would need to do some HTTP parsing to be able route the specific requests to specific files. If you're doing to record some data to use for testing, it'd be easier to do so with keep-alive enabled.. The constructors for a Request and Response are now publicly available, so I'm closing.. For now, the new version of hyper won't be including the typed headers directly, so I'm closing this here as a won't fix.. All that was needed for 0.12 has been done.  #1131 remains open since it discusses ways to inspect the Error, and so far hasn't been fully implemented. However, what exists now in master is an opaque struct with better messages, and inspection can be added without breaking backwards compatibility.. @sanmai-NL I don't quite understand which way you lean. You say each method can have its own type, but that it's not needed in hyper.. I made a comment in #1131 about having an internal Connect variant (and related ways to inspect for that).. As I've been working on HTTP/2 support in hyper, I realized that there is a similar situation in h2, which is that one could at anytime send a RST_STREAM frame. A user could definitely trigger a request, and spawn a long read of something, and if at some point that read fails, just want to tell the end point \"welp, things blew up, ignore this stream\". In h2, that could be done without killing the connection, but just sending a reset.\nIn HTTP/1, the only action would be to close the connection, but that's fine.\nThe point here is that this concept exists in HTTP/2, and could perhaps be used for both client and server errors. It could be a hyper::error::Reset, but that might be too specific to HTTP/2, or might mislead in thinking that it's only for HTTP/2, or that the connection will survive (even it's HTTP/1). So, we may want a different name, but I'm now thinking that for client request bodies, the error type would be this Reset type.\nOr perhaps even better, where B: Stream, Reset: From<B::Error>. Then the bigger hyper::Error type could be passed, for piping a stream from another request or response, but it'd also be clearer by looking at the documentation for Reset that you just use Reset::internal() (or whatever, naming), instead of looking at the variants of hyper::Error and wondering which to pick.\nAlso, this type would never be given to the user, only created by the user to signal a stream errored. I wrote up more of the design in #1431.. A backtrace is neat (but expensive?). I'm not sure I'd want to expose any enum at all with regards to the Error or ErrorKind, because of the inability to grow it. I'd reconsider when and if Rust ever grows some form of private variants (or however is used to prevent exhaustive matches).\nIt's worth thinking about the things some would do with an Error from hyper.\n\nJust log it. So it needs fmt::Debug and fmt::Display.\nTry to send a proper Response depending on the error that occurred? Like, return 431 when there was a Error::TooManyHeaders, perhaps a 414 if there were Error::TooLarge, and a 400 with other parse errors.\nMaybe check for certain io::Errors, to allow an application to adapt, such as if the error involves too many file descriptors open, or something.\n\nAnything else?\nI'm thinking of having methods on the type to allow inspecting the type of error it was, since it's always possible to add more methods. Like, error.is_uri_too_long() or whatever.. > I do not think it is a problem if programmers do exhaustive matching on the enum that implements Error.\nIt is a bit of a problem. With exhaustive matching, that means that adding a new error case is a breaking change. For instance, if at some point it was desirable to separate the Error::TooLarge into a UriTooLong and HeaderValueTooLong, that would break other people's code from compiling. If hyper were at 1.0, that would be mean needing to go to 2.0 just because we changed an internal detail of tracking errors.\n\nMaybe translate error messages into another language.\n\nA possibility is Error::code() -> u64 (maybe a smaller number type, probably not going to have trillions of error codes). As a number, you'd have to treat the case of future codes specifically, so adding new ones should be fine.\n\nBacktraces etc. are not very user friendly (may even instill fear), and leak information about the source code\n\nThis definitely true if someone were to print the a hyper::Error directly back on a webpage. A worthy thing to consider regarding the use of backtraces in hyper.\n\nWhat I am trying to point out is that having one Error type to cover lots of code seems less productive to me than having specific Error types.\n\nThat's actually part of the point of this issue. There are 2 rather distinct cases of failure in when using a Service (Server or Client), and using hyper::Error in both cases is odd.. Relevant to the design of type, from this comment:\n\nOne thing I'd like is to differentiate IO errors based on where they came from. I care about connect errors in particular [...]\n\nIn terms of internal variants, things I see that would be useful to group are:\n\nConnect\nParse\nIo. > If it was a struct that could be inspected somehow, it would still potentially break peoples code, just at runtime rather than at compile time, no?\n\n@nicoburns not necessarily. If it were a struct you could inspect, that'd probably be some method, like err.is_too_large(). That method can still return the correct value if internally the variant is split into more specific kinds, and new err.is_uri_too_large() and err.is_header_too_large() methods were added.\nThe current enum design makes it impossible to add any detail to a variant, since that requires changing the types of values that can matched publicly, so this extra detail could never be provided without a breaking change.. Something that I've wanted that is easily done in class-based languages is to be able to split up an error variant into sub-variants in the future, and not breaking existing code.\nWith Classes (not Rust)\nFor example, say there was a Connect variant, and later on, we want to split that into smaller pieces, Resolve and Handshake. With classes, this is easily done. Consider the following Python:\npython\ntry:\n    print(client.get(\"https://hyper.rs\"))\nexcept error.Connect:\n    # maybe retry\nSplitting the errors:\npython\nclass Resolve(error.Connect):\n    pass\nclass Handshake(error.Connect):\n    pass\nAnd the original exception code will continue to work, and anyone upgrading can update to handle the two cases individually, or continue to just treat them all as Connect errors.\nIn Rust\nIn Rust, we don't have classes that can extend like this, so we must use a different strategy to try to achieve this forward compatibility.\nWith Methods\nIf all this information is in private fields, and a user can only ask questions with methods, it is possible.\nrust\nif err.is_connect() {\n    // retry?\n}\nAdding is_resolve() and is_handshake() allows futures versions to identify sub-errors, and the is_connect() method still works too.\nThe downside here is that it doesn't work very nicely with pattern matching.\nWith Enums\nWe could do this and support pattern matching, but it could get verbose. With a Kind enum that you could ask the error about, every variant would need to include a sub-kind (and any sub-kind would additionally need to hold a potentially empty but opaque value to allow for future splitting too. For example:\nrust\nif let Err(err) = await client.get(url) {\n    match err.kind() {\n        ErrorKind::Connect(_) => {\n            // retry?\n        },\n        _ => {},\n    }\n}\nIf we split the Connect error into sub-errors:\n```rust\n[non_exhaustive]\nenum ErrorKind {\n    Connect(Connect),\n}\n[non_exhaustive]\nenum Connect {\n    Resolve(Resolve),\n    Handshake(Handshake),\n}\nstruct Resolve(());\nstruct Handshake(());\n```\nThen, the original code still works, because the top type is still ErrorKind::Connect, and new users can check the Connect if they like. It does mean the names can get long, though...\nrust\nif let Err(err) = await client.get(url) {\n    match err.kind() {\n        ErrorKind::Connect(Connect::Resolve(_)) => {\n            // don't retry?\n        },\n        ErrorKind::Connect(Connect::Handshake(_)) => {\n            // retry?\n        },\n        _ => {},\n    }\n}. @dekellum You mean if trying to import the variants as well? use Connect::*;?. client::FutureResponse implements Future, which means it automatically implements IntoFuture. You won't get the Response from it until after it resolves, like with future_resp.and_then(|res| now_i_have_a_response(res)).. Oh OK, so you have a closure where you want to return 2 different types, either a Response, or a FutureResponse. You could probably use the Either type from futures:\nrust\nand_then(move |r| {\n  if r.status() == StatusCode::ImATeapot {\n    Either::A(client2.request(req2))\n  } else {\n    Either::B(futures::future::ok(r))\n  }\n}).flatten()\n. I know what you mean, I was just saying that the types are distinct, and so therefore Rust complains. It's common in something like JavaScript where you can return either an immediate value or a promise, it just works. I wonder if that pattern can be made any nicer in Futures.... 1. No, your previous behavior is still valid. The Client takes a &Handle, so that it can attach to a tokio Core, but owns its own resources. If you keep constructing new Clients and throwing them away, you will be constructing new DNS worker threadpools and connection pools and throwing them away, so try not to do that.\nRegarding the type parameter, that's to allow a `Client` to have different connectors. Previously, the type parameter was removed by keeping a boxed trait object, but that's not what hyper should be doing. By having the generic, someone can now choose to box it or not. If you're building a library, it may make sense to be generic also. If you're using a client in your application, you probably know what connector you will be using.\n\n\nThe logging is just to be clear, since some people would start it up and assume it was using all their cores. That's not necessarily the best default. Each server should determine where it is spending its time. If the thread running the Core/hyper::Server is at 100% and others are idle, you may want to try spawning more cores in more threads.. Turns out a bug had snuck in, and test coverage wasn't making sure keep-alive turned off worked. New PR with a fix is currently going through CI, fix merged soon. Thanks for the report!. Thanks!. Definitely do not use wait() in most circumstances. If you have to ask if it's a good idea, then it isn't. It has very specific cases where it's useful.\n\nInstead, you should just return the future chain.\nrust\nreq.body().concat().and_then(|body| {\n    let payload = deserialize(&body);\n    // you should make `db.insert` async and return a future too\n    db.insert(table, payload).then(|result| {\n        match result {\n            // ...\n        }\n    })\n}). Collecting the chunks into 1 doesn't block the thread, only the use of .wait() on the end of it does. Otherwise, it just returns a Future, which you can then chain on. Absolutely remove the .wait(). The definition of .wait is: block this thread until the future is ready. That is certainly the wrong behavior, since that exact same thread is the one that would be reading the data from the socket in an event loop.\nThe database operations wouldn't necessarily deadlock the server, but it would hurt its performance, as you're doing likely synchronous (network and/or file) IO, which defeats the purpose of using asynchronous IO with your HTTP server.\nUsing a thread pool may resolve those issues, but you'd have better success using asynchronous database operations as well.. Documentation is almost ready to publish that includes examples on how to read the body.. Hm, so are you able to reliably reproduce this? Is there a server I can set up myself to see this?. I don't know what circumstances would cause it, but I can think of a part of the code that is likely the culprit. There is some code in hyper to track if it has read to the end of a request, but not necessarily until the stream returned EWOULDBLOCK (for instance, when there was a Content-Length header of 10, it will read exactly 10 bytes). Tokio normally knows to wake the task up again when the socket becomes readable, but it only registers when a read hits EWOULDBLOCK. In that case, hyper tries to record what happened, and \"wake up\" the task once the response has been written back. . I assume you mean that there isn't a way to store and access cookies by their name. That's correct, it is likely out of scope for hyper. There is a lot of good work in the cookie crate.. Hyper actually used to depend on the cookie crate, and so you would have Cookie structs that you could poke at. The dependency was removed because cookie had an optional dependency of openssl, which caused a lot of problems. I recall discussion of eventually removing that.\nI wouldn't say that parsing the cookie string into a struct with name and value and such is necessarily out of scope, but anything more than that likely is.. Thanks!. LGTM!. v0.10.9 has been published with this change.. Thanks for submitting this work! As suggested in a previous issue, I'm not certain whether this fits within the scope of hyper. It's possible and quite likely that anyone dealing with cookies much would want much more that a simple map.\nThe scarier part, is that once hyper commits to an API, it can't easily break it. So, it should probably at least be explored and published as a separate thing, and be considered in the future. Does that make sense?. Thinking about it, I've realized the error of my ways. The real problem here is not adding this method, it's that Cookie is just a Vec<String>! We only ever receive headers like this: Cookie: foo=bar; session=sean; hello=world, and having that be a vector of [\"foo=bar\", \"session=sean\", \"hello=world\"] doesn't really help anyone.\nWe should change the Cookie header to be a map-like object. I've opened an issue for discussion/design: https://github.com/hyperium/hyper/issues/1145. I'm going to close this, as a different solution is discussed in #1145.. @glennpierce If I understand correctly, you mean such that your service struct has other properties? Like struct Echo { foo: Something }? Or specifically that that something is a &Something? If you mean a literal reference, then the answer is that you can't, at least not with the convenient methods.\nIf you wish to share a thing, you'll need to make use of Arc.\nAlternatively, if you don't use Http::bind, and instead manage the Core yourself, then you make use of references, since you can guarantee the compiler the references won't live longer than the Core.\n(I'm going to close this as a usage question, instead of an issue/bug.). Thanks for the PR! I'm curious, what sort of code do you imagine using this?. Well, it mirrors the other setters and getters. Depending on the body type, it may be possible to inspect or not. Thanks!. For implementation, something like the VecMap inside Headers would probably be best, since it performs faster and with less memory than a HashMap when the number of items is small. I can't imagine the Cookie header, in the common case, having that many key-value pairs.\nSo, it could look like:\n```rust\npub struct Cookie(VecMap, Cow<'static, str>>);\nimpl Cookie {\n    pub fn new() -> Cookie;\n    pub fn get(&self, name: &str) -> Option<&str>;\n    pub fn set>, V: Into>>(&mut self, name: K, value: V);\n}\n```. Well, a breaking change would require a version bump (since we're before 1.0, that means the minor version). Good news is that we're about to do that anyways, with the async changes, to 0.11. So, if done quickly, it can ride that breakage together.\nRegarding duplicate cookie names, I just did some more searching. The situation is worse than I thought. The spec explicitly leaves it undefined when there are multiple cookies with the same name. \"[...] servers SHOULD NOT rely upon the order in which these cookies appear in the header.\" Thanks, RFC. It seems many libraries in many languages just grab the first one. That may not be the behavior determined in the spec, but it seems like it has become the de-facto behavior. The internet is fun.... That should be fine. And anyone really needing the duplicate headers can always check headers.get_raw. I'd suggest starting with an implementation following https://github.com/hyperium/hyper/issues/1145#issuecomment-295810782.. An invalid chunk size means the stream was encoded with the chunked transfer encoding, and then trying to decode, it found a chunk header to be invalid. Your log output shows that there was a panic in Rocket, which I've found to be this line: https://github.com/SergioBenitez/Rocket/blob/v0.2.6/lib/src/data/data_stream.rs#L44\nThat should not be a call to expect.. @SergioBenitez I was reading through the data.rs file in Rocket, and I may have found a possible cause. It looks like the buffer is taken from hyper, and a new HttpReader is constructed. Since its chunked encoding, and never been read before, it becomes a ChunkedReader(stream, None). There's 2 issues here, the second is where the error is coming from:\n\nhyper's original stream is a HttpReader<BufReader>, to allow 1 syscall to buffer the contents, and then ChunkedReader can make smaller reads looking for the chunk header. By taking the buffer, the Data now has a bunch of raw chunked data that hasn't been decoded, so now reads on the DataStream will include the chunked encoding bytes.\nOnce the buffer in the Data has been read through, it delegates to the ChunkedReader<NetworkStream> to read. At this point, it currently thinks chunk size is None, so it is going to try to find the chunk size in the next bytes. However, looking at the contents of the buffer from the pastebin, the end of the buffer is an 8192 length chunk, followed by 3765 bytes. On the network, there should still be 4427 bytes to read, but the ChunkedReader doesn't know. The next bytes of the PNG aren't a chunk header, and so it errors.. I'm going to close this, as it sounds like the issue is specific to Rocket, but if any other issues do occur that are specific to hyper, we can file more!. On the separate machine, are you still using chunked transfer encoding, or is a content length set? And is the file the same size? Or less than 4kb?. Thanks! Excellent work!. Excellent, thank you!. Hi @tinco! Thanks for starting this up!\n\nWhat is the goal here, for using a RefCell? Is this PR trying to address #1075?. You may be wanting a Handle, which lets you handle.spawn(future) on it. You can get a Handler from hyper's Server:\nrust\nlet server = Http::new().bind(addr, new_service)?;\nlet handle =server.handle();. Making use of a RefCell is probably not the way we want to go. I'm going to close this, but discussion should probably go on in #1075.. > Ah. That's unfortunate. I'm working on a different implementation\n@dorfsmay thats ok! I wasn't sure if you were, and I was hoping to get this in before tagging 0.11, so that's why I worked on this. But it's good also, because you bring up an interesting point. Clients (such as Servo) would want to push all cookies that relate to a certain resource, even if they have the same name.... To get the desired semantics, what if set is removed, and an append method added?\nrust\nlet mut cookie = Cookie::new();\ncookie.append(\"foo\", \"bar\");\ncookie.append(\"foo\", \"otherbar\");\nassert_eq!(cookie.to_string(), \"foo=bar; foo=otherbar\");. The reason was to be conservative, and allow hyper internals to change the way a Request is constructed without breaking backwards compatibility. However, as part of uniting the server and client types together in #1155, that would mean that the current client::Request::new(method, uri) would be usable with servers as well.\nFor now, I do recommend creating a server to run the tests, but a fix for #1155 is already in development, and I think it can be done without a breaking change, so 0.11 isn't blocked on it.. Thanks!. This is fantastic! I'd been perplexed as to why suddenly kcov was failing, but didn't have time to dig into it. Thank you so much!. Great, thank you!. Hm, I can look later, but I'm curious what other libraries do. I'd probably want to keep to whatever others do: either drop the whole thing on the floor, or accept all valid cookies.. I'm thinking that rejecting the request outright should be up to the user of hyper. They can optionally compare headers.get_raw and headers.get if they want to be sure it parses entirely.\nLooking at your linked document (which is awesome, by the way!), I'm kind of scared at how some libraries just accept broken cookies as if they were legit. In reality, though, any application that is used cookies for security purposes should be signing and encrypting them, or they're doomed anyways.\nIt looks like hyper should:\n\nBe lenient about a trailing ;\nEither drop the whole header on parse errors, or drop the current ; section. I'm not certain which is better, still.. It would seem the behavior from Go is just treating a cookie-string as a list of cookie-av; * (cookie-av) from the Set-Cookie behavior. That is what allows Set-Cookie: foo=bar; HttpOnly. Understanding that, I am warming up to that way, actually.\n\nAs for application behavior, I don't think hyper should try to be like Hapi. Hapi is a large server framework, trying to do a lot of things for you automatically. hyper should just give the user the information, and let them decide how to react. (Besides, since typed headers are parsed lazily, the time the typed Cookie would know of invalid strings is once the user tries to access it, and generation of the Response is entirely in their hands.). I think I've found in discussing this that the exact behavior isn't all that important to me. As long as it is documented, and not wrong, any of the options seem fine to me. Anyone who wants a different behavior can create their own type and implement Header.. No, by wrong I meant that if the parsing were too permissive to the point that a value were to contain other name-values. The behavior in this PR could work.. Thanks for this!. Thank you!. Hello! If you look at the error message, you'll see that you're trying to pass a Result<String, serde_json::Error> as the body. You need to handle that the serde_json::to_string could have had an error.\nHowever, I'd definitely recommend looking at the reqwest crate, it has code to do exactly this and more, already written for you.\nClosing as this is a usage question, not an issue with hyper.. Oh my, this is super exciting! I was slowly working on this, since I wanted to improve a reverse proxy example for the docs, but I also didn't want to slow down releasing 0.11, so I kept pausing. In my branch, I had united the inner parts into a Message with a generic Head, but the exposed result would be the same thing, and it doesn't really matter.\nI'll do a proper review in a moment.. Superb work, thank you!. Excellent, thank you!. What was the exact problem you're trying to solve here, so I can have some more context? . I've been thinking about adding 1 piece here, that would do what you want, a split method, and I think making with_body generic over a new body type would then allow you to do what you, right?\nrust\nimpl<B: Default> Response<B> {\n    pub fn split(self) -> (Response<B>, B);\n}\nrust\nimpl<B> Response<B> {\n    pub fn with_body<BB>(self, body: BB) -> Response<BB>;\n}\nWith just those changes, could you achieve what you want? I think I'd prefer having a Default bound and returning a default into of Option<B>, but maybe I'm wrong.. I'm not ignoring this, I've come back to re-read a few times now. I'm going to try out the PR locally and fiddle. I'm just afraid of being harder to use, but maybe it's required.. Ok, thinking about this, the general idea seems like the right way to go. I mostly didn't like res.set_body(Some(foo)), since it messed with Into<Body>, and it just looked weird using Some. But!\nhyper's default Body can easily encapsulate being an Option. It could easily have a Into<Option> implementation, and then we'd still have the nicer default API, and still be able to tell if the body was empty or not. Whatcha think?. After trying out a bunch of impls, I don't think what I said can actually be done properly.\nI'm now back to thinking that the body: Option<B> should stay. For the case where it's expensive to create the Default, that can be fixed by defining a cheap \"empty\" state. If the type is from another crate, a user can define a new type over it with a cheap default. For the case that you cannot tell if there is no body, again, being your own type you can add methods to ask if there is no body. We can add one to Body::is_empty, too.\nI could see Response having this adjusted method:\n```rust\nimpl Response {\n    pub fn split(self) -> (Response, B);\n}\npub struct Empty(());\n```\nOr possibly -> (Response<Empty>, Option<B>).... The issue I ran into is that libstd already defines a blanket Into<Option<T>> for T, so we can't implement custom ones for different body types. Maybe we could when specialization stabilizes, if that is indeed how we'd want to declare that a body exists or not.\nI'm sorry for the long silence. I actually am quite interested in this problem, and you're work in this PR has caused a few (even recently) discussions among some of us. Some of the tricky part is how to define that a message has no body. ! isn't stable, so we can't rely on it yet. Does that mean we define a NoBody type in hyper? There's some reluctance to do that, as well. So then, do we just say that Response<Foo> means there is definitely a Foo, and Response<Option<Foo>> means there might be? That might be the best solution, even though I find that it makes the default case to be worse. Specifically, when you receive a Response from a client request, it might have a body, it might not, but having to check an option feels bad, especially when in the Som(Body) case, that Body could still end up being empty... . > If Body already has the possibility of being empty, surely it should have an impl for Into<Option<T>> where T is some kind of non-empty type.\nThe problem is that the blanket impl From<Option<T>> for T in std means we cannot customize (yet, probably can with specialization).\nWe can't do this in hyper 0.11, but while trying to design an http crate that will have Request<T> and Response<T> that would replace hyper's types, we have killed the internal Option, so this should be the case eventually.\nI'm going to close the PR cause we can't merge, but I want to state again: thank you! This PR has been a huge help, even though it hasn't been merged.\n. As I mentioned, we're planning to extract these types into a plain http crate, and the design we currently have is essentially this:\n```rust\nstruct Request {\n    // head stuff\n    body: B,\n}\nimpl Request {\n    pub fn body(&self) -> &B { &self.body }\n    pub fn body_mut(&mut self) -> &mut B { &mut self.body }\n}\n```\nGranted, once hyper is using such a type, we probably need some bounds on B when using with a Service.\nDid you have other thoughts besides this? (Oh, Request and Response would be same with regards to their body).. Yes what you describe is exactly the correct approach. If you have things that would block a thread, you should run them in a  different thread. For example, if you look at nodejs, its file operations (fs.readFile and etc) are all executed on a thread pool, and the results sent back to the event loop thread.\nClosing as a usage question, and not a bug with hyper.. Thanks!. Hey @golem131, thanks for this! I had done the work of upgrading to unicase 2 last night, but hadn't merged. Nonetheless, I wanted to use your work over mine, cause I get excited about contributors. However, I wanted to make use of unicase::Ascii and unicase::eq_ascii instead of UniCase::new, since in every situation in hyper, only ascii case is interesting. Instead of asking you to go through and change it all to match what I already had, I just merged the branch I had.\nHowever, I'd still happily merge PR to upgrade base64!\n(PS, GitCop is asking that you format the commit message a certain way, not the title of the pull request. When you already have a commit, you can alter its message via git commit --amend.). Thanks!. Yes, those look correct. It's worth noting that the 'plaintext' section of those benchmarks is quite worthless, since it's testing for how fast a framework can process a bunch of pipelined requests. It's a situation that never happens in real life, since all browsers and clients don't use pipelined requests anymore.\nProbably more interesting is the JSON results, or the results using queries (seems hyper doesn't have tests for those yet).. With the recent improvements leading up to v0.11 (now released), hyper did much better: https://www.techempower.com/benchmarks/previews/round15/#section=data-r15&hw=ph&test=json. It shouldn't be required. In fact, since that can be distracting from just showing what is needed to get the example working, those could be removed.. That's because you've moved a box from outside the closure, and then your try to return (move again) it from the closure. A box can only be moved out of the closure once.. Looking at the error messages, it looks like you have hyper 0.10.x from crates.io, but the examples in master in this repo are using a largely redesigned hyper.. A release should happen next week, I don't think the confusion would happen for much longer.. @berkus hyper uses futures 0.1 at the moment. I'd recommend using that yourself, unless really wanting live on the bleeding (slash crying) edge, in which case you could try to use the futures-compat crate.. Unfortunately, there is no connect timeout to specify. The connect call ignores any socket option timeout. Additionally, before connect, there's a synchronous DNS lookup getaddrinfo, which also does not take a timeout.\nBoth of these are not a problem with non blocking IO, because you can stop waiting for a non blocking socket whenever you want.... As 0.10.x is no longer actively developed, I'm going to close this.. Could you provide some more information?. Thanks for starting the discussion!\nI realize a pool using getaddrinfo is not that great. I had originally thought that perhaps the Connect trait was sufficient. Someone can hook up any connecting they desire. Is there value in the http connector being generic over DNS? It'd seem like such a thin type at that point.... Sorry, I was on vacation, and now I've been trying to catch up on my flood of email.\nI know some others make use of the client of heavy loads already, and have heard of success plugging in a connector that used c-ares. I'm curious if they have thoughts as well (cc @jwilm).\nSince, as you said, adding this isn't a breaking change, I'd probably not want to block the imminent 0.11 release, and make sure we get an API that doesn't get removed or changed significantly shortly after.... I kind of feel like the correct place to do all this is with the tokio's ClientProto. The ServerProto onion seems to work well, but I think the ClientProto one is forgotten about or something. Such a client onion could look like:\n\nThe start of the onion, maybe some GaiDns thing, but it could also be skipped, if you already knew an IP address, or were using something like Unix sockets, that doesn't need DNS. This would give an T: AsyncRead + AsyncWrite.\nOptional next steps are ClientProto, building on that T. This could be something like tokios_tls::proto::Client.\nThe end, taking some T: AsyncRead + AsyncWrite, and creating a thing that is a Service over it. This could be something like hyper::client::Http (or is just hyper::client::Client?)\n\nThe Connect trait I feel is more of a bandaid to get hyper clients working nicely, while the tokio side is better determined.. Sorry I forgot about this! I think that discussing a change like this would be valuable! I'd actually prefer more discussion or exploration in this area before we were to merge something, and since this has grown stale, I'm going to close. Thank you again for starting the discussion!. It may take a few days to publish, I'm away from computer for the week (phone can poke merge button easily).. This looks great to me. Thanks! (And sorry again for taking so long.). Thanks!. Hey, I'm so sorry I didn't notice this a while ago. Thanks for the effort!\nI'm trying to have all examples and documentation like things be in the guides, and I do believe that an \"advanced\" server guide making a naive proxy would probably be an excellent guide to add!. My guess is that those docs were written/copied with tokio-proto's TcpServer in mind, since serve is a method on that type. It should have mentioned bind instead, you're correct.. By making use of an SslAcceptorBuilder, you can access the SslContext, and then wrap it all up into an SslAcceptor used by hyper-openssl.\nI highly recommend you do that instead of use hyper 0.9.18. The 0.9.x set of version will not receive any more updates or bug fixes.. Perfect, thanks!. Thanks!\nI technically had this in hyper's source so that I could add messages to the macro invocations, like unimplemented!(\"Conn::poll_complete\"). I found that immensely useful, and so I've filed a PR to add that functionality to rust proper: https://github.com/rust-lang/rust/pull/42155. It appears to be a bug in wrk. You can exercise it without hyper, just tcp streams, using this program here: https://gist.github.com/seanmonstar/a24424bc625f633c13dac5ab5eb20c64\nhyper is using the BufWriter from std, which has an 8192 byte buffer. First the headers are buffered, and then the body is written. However, BufWriter will check if it can fit the bytes in its buffer, and if it cannot, it will first flush the current buffer, and then write the next bytes. So in your example, that ends up meaning to 2 syscalls to write. On wrk's end, it doesn't seem to handle needing to read a second time in an efficient manner.\nThe pasted gist shows this same behavior, even with a tiny payload, as long as it was split over 2 writes.. I remembered that the 2nd write could be delayed due to Nagle's, and sure enough, call sock.set_nodelay(true) in the example program makes it fast, no matter how big the various writes are.\nDisabling Nagle's by default isn't typically done, as it is usually useful. Disabling it should only be done when measuring shows it has. You could call set_nodelay in a custom NetworkListener.. Thank you!. I have not followed rustls' development at all, so I couldn't give a recommendation. hyper's master branch hasn't been released yet, but I imagine when it is, all the hyper_* TLS crates will update to make use of it.. Yes, I'd love to release. I don't maintain all the various TLS implementations, though. I know the tokio-tls crate works with hyper master. I'm not sure I'd want to point at a specific library as THE TLS library to use, when many seem to have different pros and cons.. @mayah Thanks so much! Sorry for being slow.. Huh, so you're receiving a TCP stream, not processed by hyper or some other HTTP lib?\nI searched around in other HTTP libs, and didn't find an option in them to do this either. My initial feeling is that sounds like quite the footgun.. I'm going to close this as won't fix. Skipping hyper's chunked encoding can mess up the internal state.. I've never tried to view the log like that before... This may be beyond my git knowledge, is there a way to wipe the history of a branch? Hm.. perhaps by finding the first commit of master, checking it out on gh-pages, then copying the contents over, and force pushing?. There was an attempt in #1495, but some concern around if gh-pages would build with dates in the past. I don't personally ever git log --all (my personal alias, git l, is just git log --oneline -20 --no-merges). As such, I'm going to close the issue, not because I'm against it (if someone provides a fix, cool!), but to remove it from the list of things that I look at to determine what is broken in hyper. Thanks!. There aren't any plans. It's possible to implement any kind of proxy using the tools hyper has, such as how reqwest has done.. There is now a v0.10.11 published, docs are uploaded, and proper doc attribute set. Sorry about the inconvenience.. There may have been a misunderstanding of the usage of this trait. The Header (and HeaderFormat) trait is meant to be implemented by users outside of hyper. The HeaderClone trait is an implementation detail that is only used inside hyper, which guarantees that T: Header is also T: Clone, and since the headers are put into a boxed trait object, Box<Header>, that a clone_box() method exists so that hyper can clone them internally.\nThe HeaderClone trait has a blanket impl inside hyper for all T: Header + Clone.... This has been done, and and is viewable in https://docs.rs/hyper/0.10.12.. Blocked by https://github.com/rust-lang/rust/issues/29646. This was done in the http crate. The types there will replace the ones here in hyper in v0.12.. Yes, we would. We've been in contact with the owner, he specifically reserved it for just such an effort.\nHowever, it's probably a bit ambitious to stabilize an http crate super quickly, so for reqwest, it will likely just define its own types, and we'll hope that an eventual http crate mirrors what it has.. Yes, dupe, so I'm going to close. There's issues opened in reqwest crate about implementing those primitives there.. The version defined in the Cargo.toml is a minimum version (but less than 0.2). If you cargo update, it will use the newer patch versions.\nThe reason for the minimum futures is to force anyone who has hyper with an older version to upgrade futures to when it gained Stream::concat.. Um, wow! This is a lot of work!\nI haven't reviewed the code yet, but curious, being so much, does it make sense as possibly a separate crate?. I'm currently sitting somewhere in the middle. I don't feel like this doesn't belong, but I also feel apprehensive about the surface area being added. If through usage, it's found that changes are needed, it'd be a breaking version bump for everyone who uses hyper.\nWhat if this were released as a different crate, and after usage has found if any changes are required, then it can be considered for including in here? Does that sound reasonable?. Hm, I suppose it's just there to help you catch if you pass something that isn't a Connect, but with this change, you'll still see such an error when you go to build(), so this seems fine!\nLet me look into these build errors.... Fantastic, thanks for this and the deprecation fixes!. The benchmarks run probably aren't affected at all by this change, since this is adjusting the chunked encoder, and those benchmarks are all using the length encoder.\nI'm not sure I want to be adding a secondary buffer to enum Writing, when there is already a write buffer in Buffered. I find it's starting to get more complex to know which buffer still needs to be flushed.\nIf there's a change here, I'd much rather the change just be switching to using AsyncWrite::write_bufs. . In fact, I don't see it quite the same. I realize the change here is to try to hold onto the heap memory, so that it might able to be used again instead of asking jemalloc for another slot. But as the Writing enum is part of the connection's State, to me, it adds overhead to know whether there are bytes sitting in that buffer or not.. Thanks!. Done with v0.10.12, and will be done for v0.11 too.. There is #1322 opened which proposes a solution to the base problem encountered here. As such, I'm going to close this particular issue.. To clarify, the Request has the ability to store the remote_addr. If you use hyper's easy-mode server, Http::bind(), it will fill it in. The reason it isn't always there is Http is an implementation of ServerProto from tokio, and is generic over the IO stream used. Some streams might not have socket addrs, like UnixStream, and there's not generic way (not in any of the traits) to get the remote address, for that reason.. I'm not super familiar with Iron, but I can talk about the TCP part, and how to adjust it with hyper. This is likely because Nagle's algorithm is enabled by default. You can try disabling it to get the second packet to be sent faster. Nagle's algorithm tries to group more bytes in packets, so it's a balance of bandwidth vs latency. To do so with hyper, you'd need to provide a custom NetworkListener instead of using HttpListener (or Server::http).\n. As 0.10.x is no longer actively developed, I'm going to close this.. You are seeing an error reading a chunked response from a server, or there is an error occurring in the read function of a Body provided for a client request? . I see it, fixed committed. Will be in 0.10.12. Thanks!. Thanks!. I can think of 2 possible things here: \n\nhyper keeps a write buffer, and flushes periodically (specifically, when tokio-proto triggers hyper's poll_complete method). Tokio should trigger that after a round of asking the body stream for any pending chunks. So, if you body.start_send(chunk) several times in a row, those chunks should be accumulated into a buffer in hyper, and then Tokio will ask hyper to flush.\nTCP can also buffer things, because of Nagle's algorithm. This can be adjusted by setting tcp.set_nodelay(true) before giving the socket to hyper.\n\nSome logging, either by connecting into hyper's logs, or something like wireshark to watch TCP, would help show more about what is happening.. I'm going to close due to inactivity, but if you have more information, please share!. Thanks!. Thanks!. The code that's panicking is essentially this:\nrust\nlet expiration = Instant::now() - pool.timeout; // panic!\npool.find_conn_where_idle_instant_is_later_than(expiration)\nLooking in the docs, there doesn't seem to be a way to do a saturating (or even checked) subtraction. And without a constant signifying \"0\", I'm not even sure of some way to check that Instant::now() - ZERO > timeout.... This could be done differently, by saying for every socket, if Instant::now().elapsed(conn.idle) > timeout, but that requires doing subtraction operations for every socket. I had hoped to do the subtraction and clock check only once, and then only do a cmp check for each socket.... This is definitely something that we're interested in, see #1164 for some more comments and exploration.\nAs for your case, are you interested in whether some user has set a body, or whether there is body coming from the socket? The former could maybe be determined today, that depends on the specific Body type that is used. The latter can be hard to tell.. Ah, so would it be safe to say you have a much more localized desire, than the larger scope of that issue I linked?\nIt seems there is Request::body_ref(), and that a mirrored Response::body_ref() would allow you to see if it's been set, right?. I'm concerned that we want to move the Option out, and letting the Body type itself be an option or something. If so, then adding another method with the Option hardcoded feels wrong. But really, it feels like a breaking change to remove the Option anyways, and so maybe we may as well have the accessors for now, and just know they will have a type change in 0.12.... My mistake, I'm in the process of getting the guides compiling on CI.\nThe error is that and_then requires the closure to return a future-like thing. It's used for when you need to take a future result, and then do something else asynchronous that creates a new future. If you don't need to create a new future, map is slightly easier to work with. To fix your code:\nrust\nlet work = client.get(uri).and_then(|res| {\n    println!(\"Response: {}\", res.status());\n    Ok(()) // is Future-like (technically, implements IntoFuture)\n});\n Or:\nrust\nlet work = client.get(uri).map(|res| {\n    println!(\"Response: {}\", res.status());\n    // the implicit () return is fine\n});\n. As of today (note, this could change as time goes on, so Future User, check):\n\nhyper-tls provides an HttpsConnector that works with hyper v0.11, that uses native-tls internally.\nhyper-native-tls works with hyper v0.10, using native-tls.\nhyper-openssl works with hyper v0.10, using openssl.\n\nhyper-tls could go away in the future, if there is no longer a need. For now, the need is because hyper v0.11 is super new, and the ecosystem hasn't had time to catch up yet.\nAll this said: you probably should just use reqwest instead of hyper directly, if you have need of an HTTP client. It will take care of this for you.. The code example you pasted is probably the way to do this, for now. \nThe reason for having a separate type is simple: all valid URIs are not valid URLs. A client may only care about using a Url in 99% of cases, but a server needs to handle more cases.\nConsider these cases, which are all valid Uris, but not Urls:\n\n* (like OPTIONS * HTTP/1.1)\n/ (like GET / HTTP/1.1)\nwww.example.com (like CONNECT www.example.com HTTP/1.1)\n\nAdditionally, the layout of a URI is different in HTTP2, so having the Uri type in hyper allows adjusting for that.\nAs for a conversion, perhaps. I'm not 100% against it, but the reason so far is that url is a big dependency just to provide a single little From implementation. It so far seems like hyper shouldn't. The conversion you pasted should be fine. It shouldn't ever error (if it does, likely a bug in Uri or Url), and it's really not that expensive. Parsing a Uri is much cheaper than parsing Url.\nSee #1089 for more.. hyper is changing to just using http::Uri, so this isn't actionable in hyper proper. Closing.. Thanks!. Certainly! For instance, here's how you could setup a thread to run a core foever, and receive messages to start new requests:\n```rust\nlet (tx, rx) = futures::sync::mpsc::channel(0);\nstd::thread::spawn(move || {\n    let mut core = Core::new().unwrap();\n    let handle = core.handle();\n    let client = Client::new(&handle);\nlet messages = rx.for_each(|req| {\n    handle.spawn(client.request(req).and_then(do_something));\n    Ok(())\n});\ncore.run(messages).unwrap();\n\n});\n// give the tx to someone else\ntx.send(Request::new(Method::Get, uri))`\n```\nAs this is a usage question, and not a bug/issue, I'm going to close this.. The Mime type is not able to derive(PartialEq), and so constants of it cannot be used as patterns in match statements. You could use if headers.get() == Some(&ContentType(mime::TEXT_XML)) { ... }.\nBeing a usage question, and not a bug/issue, I'm going to close this.. 1. I imagine I'd keep from_wire private for now, but parsing some bytes and constructing a Request or Response manually is possible right now. You can use a parser, like httparse, and the constructors Request::new and Response::new are public.\n2. What dependent traits prevent creating custom headers? The doctests for the Header trait effectively run in a separate crate (the design of rustdoc), and they show creating new custom traits: https://docs.rs/hyper/0.11.0/hyper/header/index.html. If you have bytes, you can use headers.set_raw to add them.. I've actually been reluctant, since it I also maintain reqwest, it feels kind of unfair for hyper to single it out as the thing someone should reach for.... Thanks @yazaddaruvala!. Either is fine. I do prefer that a PR be focused, if possible, but size isn't an issue.. @yazaddaruvala actually, just last night as I was refactoring code in the client pool module, I wanted to replace the Rc<String> with a ByteStr... perhaps it should stay as a tiny module in http?. That's fine, as long as mod common isn't public.. Having read through plenty of HTTP frameworks, many tend to have a common or commons module of non-HTTP-specific stuff that is needed to implement the framework, so I like common.. Thanks!. Awesome, thanks!. Use hyper::Method.. I get what you mean by moving this 'state' field into the 'State' struct, but, I'm actually a little worried that it's easier to forget to set and unset the state, since other places might trigger a read. What I mean is, this PR is an example, there's more places that one needs to remember this field.. It does look \"clean\", but it took several minutes to verify that in fact every time NotReady is returned, it is was coming from the read operation, except when on KeepAlive. That worries me that it's almost too clever, and that if another case that returns NotReady is ever introduced, one could easily mess this state up.\nKeeping the state of the read being blocked in the IO seems clearer, and keeps the relevant state closest to where it can occur. And it also follows what Tokio does: the TcpStream in Tokio keeps track of its own blocked state internally, too.. I'm not sure what that error is, could you include it? All the code blocks in the documentation are compiled, so I do know it can work. Looking at your pasted TOML, I'd suggest this tweak:\ntoml\n[dependencies]\nhyper = \"0.11\"\nservice-fn = { git = \"https://github.com/tokio-rs/service-fn\" }. > Also I would suggest to change:\n\n# fn main() {}\nto\n\nWoops, that line isn't supposed to show at all! I can't actually run the server in the test, or it would never terminate :). There is no documentation specifically to that effect. Since you'd need to block the thread at a certain point in execution until it is ready, you'd need the work of the event loop to occur in another thread, and send the results over a channel that you block on.\nAlternatively, you can look at reqwest, which even with the hyper upgrade (not quite released to crate.io, but super soon), it still offers a synchronous API besides the new async API.. Thanks!. My thoughts are really short, probably flawed, and untested. Essentially, record some state Polled { NotPolled, TokioBufferedPolled, UserPolled }, updating in the Conn::poll method. Such that, on the 2nd poll, we now believe UserPolled, and would then respond with a 100-continue.\nThis might not work at all. It's possible that the buffer in Tokio will know better, and if the user polls after the buffer has, and the Conn hasn't notified that the task is ready for reading, it will short circuit and not poll the Conn again. I have no idea.. Thanks!. hyper 0.11 didn't ship with these for a couple reasons:\n\nIt's possible to have a rough overall timeout by using timeouts outside of hyper.\nI didn't want to pick a timer implementation that was different than the user, and then end up that multiple timer implementations were running.\n\nStill, I realize it would be useful to have these in hyper, so let's explore!\n\nFor anyone wanting it immediately, you can largely get most of it working externally. A \"connect\" timeout can be used by providing a custom Connect that wraps the HttpConnector and a Timeout. A \"write\" timeout (for a body) can be sort of hacked in by providing a custom Body stream. And a \"read\" timeout could be used by selecting on the FutureResponse, and/or the response body. I realize it's not super accurate, but it's there for the urgent.\nFor the implementation in hyper, unless there the coarser timeouts are bad (it shouldn't be seconds off, just perhaps a few milliseconds if the timer isn't quite reached, and another loop of the Core would take a few milliseconds to get back), I'm leaning towards using tokio-core timeouts. They're lighter weight, doesn't start a new thread, and doesn't require another dependency.. The current situation of timers in tokio are in flux, so I have been wanting to wait for the dust there to settle.. For now, the new version of hyper won't be including the typed headers directly, so I'm closing this here as a won't fix.. I'd recommend trying reqwest. The newest version  on master includes the upgrade to hyper 0.11, and has proxy support. It's not yet released on crates.io, trying to get that out this week.\n\nIt also includes an async API, marked unstable.. I'm going to close, since this is a usage question, instead of a bug. Cheers!. 1. I mentioned in #1174 that we're probably under-utilizing the ClientProto onion, which should probably allow getting a transport from anywhere, and into hyper's Client. If we can figure out how to improve on that without breaking changes to tokio or hyper, we could move towards that within hyper 0.11!\n2. I really want number 1 to happen, but for the moment, the string conversion and back is pretty small compared to the network IO.\n\nWould it make sense to repurpose this issue to track what I said about the ClientProto onion?. I've given this some more thought, and don't see a solution to this, really.\nAssuming the server identifies as the socket address, the string version needs to be sent as the Host header in HTTP/1, and as the :authority header in HTTP/2. If the server identifies as a domain instead, then you need to include the domain in the Uri so hyper can write it. Either way, a Uri is needed.\nConsidering that, and that resolving and connecting to a socket isn't actually something hyper is particularly interested in (it just wants to implement HTTP over some IO object, connectors can be implemented to do anything), I don't see a specific problem that this issue would be solving.. Thanks!. One could currently implement a ServerProto that is able to check the transport for anything before saying it is OK to be used with a Service.. A Service serves a connection. Would you need the certificate within the context of each request made on the same connection?. So, we're considering that Request and Response gain a typemap-like thing that can contain extensions. The original thought is that it would be able to contain HTTP2 extensions, but it could be used to store anything. Perhaps a wrapper can set req.extensions_mut().set(some_cert), and users' services can check for the req.extensions().get::<Cert>() (or whatever the type is).. The Request and Response have no concept of the underlying transport by design. So that previous method can't really work.. Another alternative is that since the Service is constructed at the start of the connection and used to serve all requests on it, the certificate could be grabbed in a NewService implementation and stored on the Service.\n```rust\nstruct ClientCertService {\n    cert: Option,\n}\nimpl Service for ClientCertService {\n    fn call(req: Request) -> Self::Future {\n        // check self.cert\n    }\n}\n```\nThis would require NewService to gain a way to inspect the transport.... Thanks for the report! There used to be code to properly handle 204s and 304s, but it was lost in the redesign to async. I'm adding it back in. The fix will be included when 0.11.2 is released.. Probably related: #1235 \nI'm fine with making whichever change is needed to keep up with the spec. It would probably mean a breaking change, so it couldn't be released super quickly. If the change is made, it's probably a good idea to close up the internals of the header, to allow future changes to not be breaking...\nAlso, if needed more quickly, the header can also be defined in Servo.. For now, the new version of hyper won't be including the typed headers directly, so I'm closing this here as a won't fix.. Hm, I was just about to merge and figure that we'd deal with body types in a 0.12 release, and did a final look over a noticed that, it seems Response at least doesn't actually expose really anywhere that there's an Option inside, right? So, while Request would need new methods, Response could perhaps be fixed...?. Crap, I think the Response::new and Response::default not having a bounds on B means the Option has to stay.... Yea, it can't really be changed in 0.11, so may as well add things like this to allow inspection. In 0.12, we'll have to make some breaking changes so that the the internal Option can be removed, and then an optional body would be up to the user, where Response<Option<Body>> vs Response<Body>.\nSorry for futzing around so long.. hyper is an HTTP implementation in Rust. When building an application with emscripten, you're target platform will be using HTTP from the browser engine (from XHR, Fetch, etc). To conditionally compile hyper for emscripten would probably mean not complining the majority of the crate.\nI kind of think that something like that should maybe be a layer above hyper. Maybe something like reqwest, which could change from using hyper to XHR for its HTTP needs.... What version of OpenSSL are you using? I've seen reports of older versions hanging on others, too. Unfortunately, there's not much hyper can do. You can set timeouts on your Client instance, to prevent hangs from lasting too long.. I'm not sure there's anything actionable here, at least not without additional data. Closing.. The thinking was that up until now, hyper has pretty much only used trace and debug, and those are incredibly noisy. To improve debugging for users, I wanted to make better use of the levels. An incoming request seems about an info level item.\nAs for being configurable, the log crate makes that possible, any logger can filter via module path and level.. Hm, you're right, I didn't remember to include a section on dependencies in the Client guide. I kind of took for granted the knowledge that an extern crate requires a corresponding dependency in your Cargo.toml.. I can get it soon, but if you want, the guide is at https://github.com/hyperium/hyperium.github.io/blob/master/_guides/client/basic.md. The docs were updated to include the Cargo.toml part, thanks @faraazahmad!. It using readv in this case should be nearly identical. The change hasn't been made I guess because read_buf didn't exist when this part of hyper was written. I also didn't want bad implementations of AsyncRead to zero the memory over and over. I guess we could just say \"that's a bad transport\", but I can still think people could blame hyper.... The reason for being generic is that HTTP can be over any transport. That could be TCP, TCP protected by TLS, Unix Domain Sockets, UDP, or anything else. It's a good thing!\nThe answer is probably to just do what in this PR.... I tried out bench this branch against master also, and saw a small (30,000 ns vs 31,000 ns, 5x on each branch) slow down in this branch. I've looked into the impls of AsyncRead and BufMut and things, and I don't have a good guess as why it seems slower.. Oh, good catch! I hadn't even noticed.. Well, that's surprising. It turns out using the std::io::Cursor does actually make things slower. The bench_server_tcp_thoughput_fixedsize_small_payload is what I ran, 5 times on master and 5 times with this branch.\n\nmaster: ~30,000 ns/iter\nbranch: ~32,000 ns/iter\n\nI didn't grab a profiler to try to determine why, but some possibilities: several of the methods on std::io::Cursor are not #[inline], such as position, set_position, read, get_ref, get_mut, so that requires a function call for many things that really are just accessing a field. The in-crate Cursor of hyper is able to have all those function calls optimized away.... Due to the performance regressions in the previous comment, I'm going to close this. I'm sorry! It seemed like a clear win, in terms of cleaner code. Maybe with some #[inline]s added in to std, this change could be landed in the future?. The compiler tells you what is wrong.\nBut to guide you to getting it working quickly, I can suggest these changes:\n\nDon't put the code in another module until you grasp how the module system works (many of the errors are from using extern crate inside a sub module, and then trying to use them from the crate root).\nChange the run fn signature to: fn run() -> Result<(), Box<::std::error::Error>> {.\nChange the main fn to fn main() { run().expect(\"http client errored\"); }. Thanks!. It looks like this can work entirely out-of-crate? I kind of lean towards keeping it that way. Is there something that having this in crate allows that wouldn't be possible otherwise?\n\nAs a side note, looking at the tokio-io-timeout crate, the implementations of AsyncRead and AsyncWrite don't pass forward the read_buf and write_buf methods, which would mean readv and writev are no longer used for TcpStream.. Can't the read and write timeouts be set in any connector by returning a TimeoutStream?. Oh, wow, woops :D\nFor the failing test, it is because the header! implementation for a single value doesn't allow for an empty header. It'd probably need a manual impl Header instead of using the macro (it's not common for a header to be allowed to have an empty value).\nIt seems the tests were never running, since the module was never used.... I looked in HTML spec, and its referred to as a 'last-event-id string', so a String seems fine. Thanks for fixing these!. It's a bug in hyper. I've been working on this week actually, to better handle when message shouldn't have bodies. Besides 304, also 204, and also when the request verb would not allow a response body, like HEAD or CONNECT.. The reason is probably because no one ever thought about it. \ud83d\ude04 \nThe remote_addr is kind of weakly supported, since not all transports even have the concept of a socket address (like Unix Domain Sockets). For that reason, the tokio-proto architecture doesn't provide it. The only way it would be set is if you used Http::bind, since that can use the knowledge of being bound over TcpStream to fetch the address.\nI wonder if the address should be moved out of the Request entirely, and be something you can set on a Service struct, perhaps required by a custom NewService.. The Request and Response from the http crate don't have fields for the socket addresses. These types will soon replace hyper's. Getting address is probably something that should be done by creating a listener and then storing the adress on a Service.. Are you sure it has this problem if you remove all waits from your code? I'm fairly confident it is the wait. \nThe reason is this: tokio currently eagerly caches the first body chunk. If the body is small, and could fit in 1 chunk, then after receiving it, the body stream will yield empty, and the wait will be able to finish without ever parking the thread.\nHowever, if the body needs more than 1 read, then after the wait polls for the first chunk, and sees it needs to wait for more, it will park the thread. That thread will completely pause, until the something tells it that the future is ready again. The problem is that the very same thread is needed to keep reading on the socket, and alert the wait when more data has been found.\n\nSeparately, you can use Stream::concat2 (so, body.concat2()) to accomplish the same thing your fold is doing.. I believe the issue is using wait on the same thread as the Core is running, so I'm going to close this. If you find otherwise, we can re-open!. @ivanovaleksey if you're trying to return a Future, and need the fully body before you can return that future, you likely need to return a different Future. The echo server example does a decent job of walking through how to return different futures.. This is fixed in https://github.com/hyperium/hyper/commit/a9413d7367e8b9f0245fc8a90a22ece7d55e7e04, will be release soon.. Sort of. It is a goal (vaguely, not exactly sure of which parts exactly).\nThere has been some progress towards making things generic over T: Executor in both the futures crate and tokio. Still, so far, the Handle is needed by tokio-proto's BindClient type. The default connector in hyper (HttpConnector) also needs one, as the TcpStreams are registered to the related core with it. So, that Core does need to run in order for the underlying IO transport to process events.\nIt could be possible, with a change to BindClient, for some connector that creates blocking sockets, which are managed by a different thread, to eventually work.... Yes, the reform will most likely affect this issue.. The Client actually can now take a generic Executor for spawning it's background connection tasks in!. I've put this off for a while claiming that it will be solved in tokio-proto, but I'm now leaning towards may as well fix it in hyper, if a generic way appears in the future, no harm done. The proposal is in #1322.. I'm actually not too worried about what is in the IANA registry. People register all sorts of super specific headers there, but that doesn't mean that everyone actually uses them. \nFor instance, the Access-Control headers are quite common for web apps, Whereas all the DAV related headers are likely used by very few (I had no idea there was so many).\nSo far, we've added the headers as people have needed them. If the header isn't that common, it's been recommended to make a separate crate.. I assume you updated the original comment to use Chunk instead of Vec<u8>. If so, that would definitely make a difference, because you'd need to copy the data from a chunk into a vec. However, as you found, there is no need to do so, because you can use &chunk with serde.\nI don't see a bug or really anything actionable here, so I'm going to close. But if you do run into something, we can open a new issue!. Ah yes, that does indeed seem like a problem. That it likely trigger when the Stream for the body includes a zero-length chunk. I've just pushed a fix to master, so hopefully this should be fixed in 0.11.2.. Would it be possible to include logs (from hyper) when the issue occurs?. I think that hyper can easily inspect if the body chunk is actually empty, and just ignore it. However, if the body has bytes, and HTTP specifies that the a message is not allowed to have bytes, I would prefer hyper to return an error. Unfortunately, the error handling in tokio isn't as fleshed out as we'd like, so the way for a user to know about this error isn't that easy.... I'll add a check for if the chunk itself is actually zero bytes, like this: https://github.com/hyperium/hyper/blob/85c6bec98bc189aac5c0dfbdc769e543782f9f8f/src/http/conn.rs#L440\nAn error will happen though if someone tries to send a real body.... And I've just pushed that to master.... To be clear, hyper won't cause a panic!. It currently returns an Err back to tokio with the message of illegal frame. Eventually, that means tokio will drop the socket and close everything about it. We definitely want to improve tokio's handling of errors there.. Thanks for this! As you've noticed it being a breaking change, I'd like to have this change occur with any other breaking changes. So I'd probably set this as a part of 0.12, and not merge until we know all the changes we want to make.. As noted in #189, headers are actually going to moved out of hyper proper. So as to not keep this dangling, I'm going to close this. Thanks for the submission, and of course, because the header system works for anything that implements Header, anyone can use these changes themselves by creating a new type.. What is done in src/route/app.rs:278?\nIt is the case that header values can be sent in encodings that are not UTF-8. In that case, the bytes would need to be decoded according to some other knowledge. Perhaps because of this, Headers should not itself implement Display, because it cannot always succeed.... Woops, closed the wrong issue with that commit.. Yea, providing value_string and fmt::Display for Headers is a mistake. Fixing it is a breaking change, so will be taken care of likely in the 0.12 release.. For now, the new version of hyper won't be including the typed headers directly, so I'm closing this here as a won't fix.. I actually feel like doing all this is out of scope for examples in the hyper repo. There is an HTTPS guide on the hyper.rs website, though.. There is a guide that shows making multiple requests at the same time in 1 thread. Is that useful?\nI'm going to close the issue, since this is a usage question and not a bug.. Thanks for reporting this. This should instead do a reverse search for a semi colon, and make sure that the section found between the semi colon and the end is a u16, so that something like :7334] isn't found in an IPv6 address with no port.. Fixed in https://github.com/hyperium/hyper/commit/7081c4498e707c1240c7e672d39ba4948fffb558, referred to wrong issue in commit message.\nThis will be in 0.11.2 shortly.. A Response has a Stream, which is quite different from a thing that can be read from. As seen in the guides, it's possible to easily concat the body.\nIt would also be fairly straight forward for some type to wrap a Response, and include a buffer, and then Read could be implemented by either polling the stream, or copy bytes from the yielded buffer.\n(Also, since a readable response would mean the client, have you seen reqwest?). The tokio-proto crate has not seen a new release yet.. Ah yes, it seems so. The client no longer uses BindClient what-so-ever.\nThere may be a desire to give hyper::Client some other executor that isn't a Handle, but if so, we can open a new issue about that.. Hey there, thanks for the PR!\nThe bounds there were actually on purpose, even though it may seem unnecessary at the moment. The goal has been that eventually the TcpServer in tokio-proto would be able to do all the hyper's Server can, and would use that. To do so, since the TcpServer can start listening on multiple threads, to prepare for the move, the Send + Sync bounds exist.\nYou can use a Service without those bounds if you manage a Core yourself, instead of using Http::bind.. Possibly. I'm not sure what sort of API that would look like though.. Sorry it took so long, I wasn't sure that this should be done, but I'm now in favor. Anyone wanting to use the multi-threaded server can do it themselves or use TcpServer. No need to have restrictions for people who don't want it.\nThanks!. We've been working on a new implementation of Request and Response, which includes a way to separate the head and body parts, and then construct a new one. That'd allow you to achieve the same result, right? We found that preferable to a map, since the naming sounds off.. The issue is legal, and two fold:\n\n\nDo we actually have permission to relicense the content? Most contributors also contribute to other Rust projects that are dual licensed, and would probably be OK with the change. The ones that wouldn't, we could probably rewrite their changes, or their change may not be copyrightable (typo fixes and things), or already gone due to refactors. And even then, do the contributors actually have the right to change their license, or could it have been owned by a company that doesn't want to give a patent license...\n\n\nIs it actually smart to dial license MIT and Apache? Apache gives a mutual patent license, so anyone suing the project automatically loses any license they received using it. However, the dual license allows someone to sue while simultaneously just using under the MIT license. I don't expect to be sued, but bleck.\n\n\nI filed this issue a while ago, when many projects were changing to a dual license. Since then, I'm not certain such a thing is good or not.... Indeed, it's a horrible world and we'd rather all just pretend it doesn't exist.\nI'll close this for now, and if compelling reasons appear that should make us reconsider, we can reopen.. Is there no log at the error level, either from hyper or from tokio_proto?. Is this actually true? I looked around in RFC 7617, and couldn't find text the stated this. In fact, I suspect it's common for clients to convert a request to http://user@example.org into the a basic auth header of base64(\"user\").. Ah, I see that the code in this type also does that. So then the point is that when decoding, it might not include a colon. Does it make sense to have an Option at all? Or should it actually fail parsing if there is no semi colon?\nProbably depends on real world usage, instead of exaclty what the spec does.. You can set a Connection::close() header. Even if the client ignores it, hyper will notice internally and close the connection.. As noted in #189, headers are actually going to moved out of hyper proper. So as to not keep this dangling, I'm going to close this. Thanks for the submission, and of course, because the header system works for anything that implements Header, anyone can use these changes themselves by creating a new type.. I suspect there is something else that is different in your example. client.get literally calls the exact same code you pasted as failing.. Ah OK. hyper currently doesn't support H2. It's being actively worked on,so not too far in the future.... Fixed in https://github.com/hyperium/hyper/commit/41c47241cd81e5140a04a970adfcb1bffae29473 (surprised GitHub doesn't seem to auto link it anymore, even though it auto closed it?).. There's 2ish ways to do it: \"manually\" or the \"proto onion\".\n\n\nManually: hyper::server::Http has a bind_connection method that is generic over the IO transport. So, someone can set up a Core, any sort of listener, and then use bind_connection on new transports.\nrust\nlet mut core = Core::new()?;\nlet handle = core.handle();\nlet listener = UnixListener::bind(path, &handle)?;\nlet server = listener.incoming().for_each(move |(sock, addr)| {\n    Http::new().bind_connection(&handle, sock, addr, HelloWorld);\n    Ok(())\n}).map_err(|_| ()); \ncore.run(server)?;\n\n\nProto onion: The 'tokio-proto way' is to compose ServerProto things, and have some sort of driver that can use them. Look at tokio-proto's TcpServer to see how it works with TCP. It works with hyper's Http, or someone can wrap that Http in a TlsServer<Http>, or any other protocol, and give that to TcpServer::new().\nrust\nTcpServer::new(Http::new(), addr)\n    .serve(|| Ok(HelloWorld));\n\n\nA caveat to the onion way: tokio-proto is in flux. There will likely be a newer/better way to do those things in a couple months.... \n. There's no active plans. hyper has been shedding less critical features, and while trying to be sure the tools are there for anyone else to build them on top. Maybe some day some of those features come back, I don't know.. This looks really impressive! I apologize I haven't had time to review it, I've been trying to wrap up changes to the http crate before RustConf. I'll take a look soon, I promise!. @spinda I'm so sorry, I don't have particularly good reasons other than forgetting. I'd like to look at this this week. I think upgrading protocols is necessary, and so hyper should definitely support it.\ncc @carllerche . I'd be especially interested in discussing the design before spending time writing code :D. I put more details of the proposal I suggested in #1323.. The internal change to not use tokio-proto is already merged, just not on by default while bugs are still found. It should probably be easier to make upgrades work, however, because of this work.\nI'd say the blocker for this feature is settling on an API to expose to a user.. I'm closing this due to inactivity. I recommend discussing the feature more in #1323.. Looks like the client guide was fixed, but server still needs this.. There isn't really a logo for hyper yet, so I'd settle for just a orange square of the same color as the website... :D. What errors do you get? The \"completely broken documentation\" is compiled and tests with every commit to the documentation, so it does work.\nBy the way, consider reqwest if you just want a super simple client to get out of the way.. Note that if you're using core.run within the Service::call, that will block the thread while that specific core runs. This could mean the core driving the server will not be able to run and see events (and thus read the request body from the socket).\nInstead, you should change the Service::Future to a different future type, instead of FutureResult, since sending a client request will not happen immediately.\n(PS, you pasted the Authorization header, if those values are real, you should reset them. :)). The main function cannot have a return value, but ? will try to return an error if it occurred. Consider putting your code in a function that can return a Result.. The minimum required rust version of hyper and some of it's dependencies is 1.15.. Woops, thanks for fixing this!. Yep, packaging now.. It is not possible to use ? inside the main function. You can place the code in another function can does have a Result return type.. This is #540, with the root being #309.. It's closed as fixed in >=0.11.. There isn't really a way to fix this without breaking compatibility.\nThe problem is that the Request can be deconstructed, and the HttpReader is a public enum, which is what keeps track of whether the body has been read or not. So there isn't anywhere to add a field, or add a Drop impl, or anything, that could signal that the socket shouldn't be read from for a new request.\nGiven the effort to try to find some way to fix this without breaking 0.10.x users, and that 0.10.x isn't receiving any more development, I'm going to close this as a wontfix.. Hey there, sorry for delay!\nThe Token scheme for the Authorization header seems quite uncommon. Anyone using just a simple token usually uses Bearer scheme instead. There's an abandoned draft for a Token scheme, defining a way to provide HMAC request signing. The author of that draft has since made the Hawk scheme instead.\nWould it make sense to keep a scheme (and implementation) like this outside of hyper, since it seems uncommon, and the formats seem to differ?. I'm going to suggest that this stay out of hyper for now, because it seems very uncommon, and implementations may differ on how servers are using this scheme anyways.\nThanks for the effort!. The Request type will be replaced with http::Request eventually, which has better ways of pulling out the body and putting together a new Request without the body.. The linked macro for literals is internal code. It's definitely unrelated.\nThe type you're looking for is a struct, and it is exported at hyper::header::ContentType. The macro used to define it just removes the need to write out some common pieces, only requiring to write the parts of the Header impl that are different from other headers. The macro expands to a pub struct ContentType(pub Mime);.\nWhat is the actual issue here? Intellisense cannot understand macros in Rust?. JSON by default is UTF-8. Additionally, the registered media type with the IANA is application/json, with no charset parameters.. Thanks!. Hey, thanks for filing this! It's true, hyper does ignore some things about how to deal with HTTP/1.0 peers. It would be nice to fix them.\n\nDo we still need HTTP/1.0 compatibility?\n\nI have wondered the same. I also haven't actually run into an HTTP/1.0 server or client myself.\nSome support already exists, and it seems like a good idea to add the rest.\n\nKeep-Alive: I had actually thought that this part at least was implemented correctly for 1.0 and 1.1. If a server sees a client talking 1.0, it won't assume keep-alive unless the client sent Connection: keep-alive. What part is incorrect?\nResponding with the correct version would be a good, not too complicated, fix.\nChecking the peer version and disabled chunked would be good too. I haven't read how 1.0 is supposed to handle messages without a length. Is it simply either Content-Length, or until EOF and thus keep-alive is disabled?. Thanks for submitting the PR!\n\nI'm curious, was it difficult to understand how the example worked without instructions like these? Or without seeing https://hyper.rs/guides?. Hm, sure. It probably makes most sense then to just have the README link to self-contained example in the guides.. The README has been updated by removing that line, and emphasizing looking at the guides instead. Ideally, there is only 1 place that needs to be kept up-to-date. Thanks for writing this up, though!. Hey there! There's a guide showing how to do this on the hyper website. Also, you may find the reqwest crate even easier to user, such as this Response.json example.. You're creating a future to concatenate the body together, and then dropping it. You'd need to chain off it. Such as:\nrust\nreq.body().concat2().and_then(move |body: Chunk| {\n    let v: Value = serde_json::from_slice(&body).unwrap();\n    println!(\"{:?}\", v);\n    Ok(())\n}).and_then(|_| {\n    Ok(Response::new().with_status(StatusCode::Ok))\n});. Yes, you need to return the chained future. The type Future = FutureResult<...> in your Service can change to any type that implements Future. As you're learning, I'm going to show you how to use a dynamic type, instead of a concrete type like you have currently:\n```rust\nimpl Service for TestSt {\n    type Request = Request;\n    type Response = Response;\n    type Error = hyper::Error;\n    type Future = Box>;\n    fn call(&self, req: Request) -> Self::Future {\n        match req.method() {\n            &Post => {\n                let fut = req.body()\n                   .concat2()\n                   .and_then(move |body: Chunk| {\n                        let v: Value = serde_json::from_slice(&body).unwrap();\n                        println!(\"{:?}\", v);\n                        Ok(())\n                    })\n                    .and_then(|_| {\n                        Ok(Response::new().with_status(StatusCode::Ok))\n                    });\n                Box::new(fut)\n            },\n            _ => {\n                let fut = futures::future::ok(Response::new().with_status(StatusCode::NotFound));\n                Box::new(fut)\n            }\n       })\n    }\n}\n```. This has been done!. Hi there! I believe so, yes. Servo uses hyper, and builds for Android.\nAs this is a question and not a bug, I'm going to close this.. Seems good, thanks!. In HTTP/1.1, most commonly requests are sent in origin-form, which means your request begins like this:\nPOST /tdfg/gdfgd?grg HTTP/1.1\nSo, that means the Uri has a path and query, but no other information. In HTTP/1.1, a Host header is also sent, contains the host. You can get that via req.headers().get::<Host>().. HTTP/1 does not define a way to pass on the scheme, unfortunately. The only way you have it so notice if the incoming socket is using TLS :(\nIn HTTP/2, there is a :scheme pseudo header that is sent.... I have no idea what could be happening, I haven't use proc macros. However, as that is an unstable nightly feature, it is likely a bug in the compiler. It'd be useful to them if you filed on the rust repo, with steps to reproduce and any error messages that occur.. Additionally, to read the write-up on why SSL was removed, see https://github.com/hyperium/hyper/issues/985. It really describes all the issues, and why the decision was made.. We do expect 0.12 to remove hyper's related types, and use http instead. As noted, that's a breaking change, so we'd like to group that with other breaking changes that will likely need to happen, like changes to allow h2 to work.\nThe idea mentioned here is neat, though: providing compatibility with http in hyper 0.11. That could perhaps allow downstream users and frameworks to start adopting http sooner, and then an when hyper 0.12 releases, that part is an easier change. I like it!. See https://github.com/hyperium/hyper/issues/1317 for the breaking change issue, but we can keep discussion in here for how to provide compatibility in 0.11!. > Where it makes sense, provide from and into_* methods on hyper types (such as Url, Headers, Request, etc. These methods convert between hyper and http types.\nThis seems like a good idea regardless, since none of the types can be replaced completely.\n\nPossibly difficult to establish backwards compatibility in some cases\n\nThis would be a requirement to release it on the 0.11 branch, so if there's something that requires breakage, it will have to wait.\n\nhttp types at the center, hyper types as the facade\n\nIf this can be made to work, this sounds like the best. As you pointed out, it gets more testing of the http crate sooner. This could mean that people using a Service with http types could pay zero cost. The original types in hyper can get a #[deprecated] attribute, but people's code will still build using them. Internally, a compat layer could just convert things, like when making a hyper::Request, the internal http::Method, http::Uri, etc would be converted into hyper::Method etc.. > So we have either the choice of raising the minimum supported version of Rust to something higher that supports associated constants (would this be considered a breaking change?)\nYes, I personally find that a breaking change, when I can control it. (grumble grumble about dependencies not feeling the same, and suddenly hyper's minimum version is forced to change...)\nSo, it probably couldn't have a dependency on the http crate in 0.11, at least by default. I think I'm fine with a cargo feature requiring a newer compiler version. So, that would mean that by default, hyper couldn't wrap the http types, which is unfortunate.\nWith a feature flag turned on, that seems fair. So then there's the issue of which side should have the performance cost: default, or when using the new shiny http types.\n\nIt would probably feel bad if you were using hyper and its own types, and added a dependency which enabled http compat, and suddenly your server were a little slower. It shouldn't be a huge loss, but it might be surprising, especially as the user didn't directly opt-in.\nAt the same time, we want to encourage using the new types. If it's known that turning on compat and using http types is slower, people may not want to do it. Again, it shouldn't be a whole lot slower, so maybe that's fine, as people could opt-in for the API compatibility with the growing ecosystem, and know that 0.12 will remove the slight performance cost.. When I start the hello world example, I can run wrk against it, and get way passed 16000 requests (I stopped at 200,000). Does it happen to you if you use wrk also?\n\nAlso, I don't have a Mac, so I'm running these tests on Ubuntu.. Ah, I didn't realize ab makes a new connection per request. In that case, it might be that you're hitting a max file descriptor limit on your Mac.. And what's the outcome?. A google search suggests doing this for macOS: https://stackoverflow.com/questions/7578594/how-to-increase-limits-on-sockets-on-osx-for-load-testing\nAs this seems to be Mac specific, and not a bug in hyper, I'm going to close the issue.. The Client contains a pool of connections internally. Are the requests to different hosts? The pool is lazy about ejecting expired connections, so that could be part of it.... Great work investigating this! Thanks!\nThe \"parked\" senders are Checkouts that are \"racing\" for either a newly connected socket, or an existing socket to become idle, whichever comes first. Your PR is definitely going in the right direction, it just needs to be a little more targeted to only remove the relevant sender, I'll look into it.. This is certainly something that should be done. As to where exactly, I don't know, but we can discuss that! And as part of the discussion, if anyone wants to try to implement this out-of-tree, it should be possible to test using hyper::Client with it, by just implementing hyper::client::Connect. With that, a client can be configured to use it.\nAfter discussing and experimenting, we should be able to merge the solution into the right place (either here in hyper, or up the stack if that makes sense.). On second thought, a fix here in hyper wouldn't be that much code, actually. It'd simply adjust the HttpConnector to filter the resolved addresses into IPv4 and IPv6, and then start resolving IPv6 addresses first, selecting on a tokio_core::reactor::Timeout, and then start racing the against IPv4 connects.. I'd merge a PR fixing this, certainly!\nAs for myself, my time is short, I'm spread thin over so many other things :(. This has been done in the 0.12.x branch.. @Aaronepower yes, the failing tests are that the the client is sending requests with blank URIs. Bytes like GET  HTTP/1.1\\r\\nHost: localhost:42805\\r\\n\\r\\n (note there is 2 spaces between the method and version, but no URI).\nI've pushed an update to master to make debugging those tests hopefully easier.. Woo, nearly there!. Yay! Great work, @srijs, thanks!. Thanks!. @algermissen Thanks for the comment!\n\nEg one aspect is listening on a port with multiple threads.\n\nSure. A recent PR, #1326, suggested allowing the Server to be able to use any Stream of IO objects, not just a TcpListener. I've wanted this too, but felt it was different enough to not be in this issue. With such a change, one could configure a TcpListener before giving to hyper, which would allow setting SO_REUSEPORT, and then you could have a server running on several threads with the same port.\n\nAnother one is related to handling failures in the incoming conns loop.\n\nAgain, by customizing a Stream of connections, one can completely decide what to do with errors coming in the stream. FWIW, errors from accept are usually errors from the pending connection, which means that connection should probably just be dropped, and one can accept again.\n. @lqf96 I would definitely like to also offer a way of handling CONNECT requests.\nHowever, it's not quite the same, as HTTP/2 defines CONNECT a little differently. The original socket does not get upgraded out of h2, it just sends and receives DATA frames on the same stream, and it should be forwarded to the target host. So, when hyper gains HTTP/2 support, it would be wrong to pull the socket out because some stream sent a CONNECT. It would need to continue to just stream bytes back and forth.\nAs for handling the response yourself, the thing is that you need to return a Response anyways, so it seems useful to be able to fill in the status code and headers, and let hyper write that to the socket.. > The former one can be used to upgrade from HTTP/2 to something else\nHTTP/2 does not define a way to upgrade to another protocol. You cannot upgrade from HTTP/2 to websockets.. Thanks for getting it this far, it helped me understand where the leak is. Completely removing the parked list could hurt any other pending requests, making the client use idle connections less often. I've opened #1325 that will cleanup when a Checkout is dropped, but only if the Sender is dead.. Hey there, thanks for starting this up! I do indeed want to add the ability to use any stream of connections, without having to use the tokio-proto stack, so this is definitely the right idea.\nI recently outlined in #1322 that shows a proposed API for using Http/Server with a Handle, instead of owning the Core. Importantly, #1322 defines a way to keep backwards compatibility, which would be needed to merge this into 0.11. Would you like to adjust this PR to match what is proposed there?\nAdditionally, while we would eventually want to get rid of the local_addr method, since it doesn't belong in hyper, we can't remove it in 0.11. So, a SocketAddr would need to be provided with the from_listener method, so it can be set in the Server. We could deprecate Server::local_addr also (maybe now, maybe later) to hint that it would go away in 0.12.. > so I guess we'll have to wait for 0.12. This is not a giant problem for me, as long as 0.12 comes in the next few weeks.\nNot likely, 0.12 will probably be a little while, there's still some upstream changes to figure out with futures and tokio.\nHowever! We don't need to wait for 0.12. As I said, we can morph this into the API in #1322, and be able to release it in a 0.11.x release. What do you think of trying to do that?. >  So since the API are necessarily different (some have their own Core, some don't), that would mean duplicating some code for a while? The core field of the struct could be an Option, right?\nI believe it can be done without duplicating too much code. For instance:\n\nServer.core could become Server.reactor, with an enum Reactor { Core(Core), Handle(Handle) }.\nServer.run/Server.run_until consume the Server, so the Core can be taken out, a Handle grabbed, and then the Server can be reconstructed the same, just with a Reactor::Handle(handle), and then because it implements Future, run can just call core.run(server).\n\n\nAnother question I had was, why did you require anything to be Send + Sync? This seem a little odd for stuff supposed to be run in an event loop.\n\nThis was because we hoped to soon move the internal Server::run thing to use tokio-proto's TcpServer, which can run on multiple threads. I'm not sure this is going to actually happen, but I'd worry about that in a different issue (in fact, there is #1275 that removes it, and I'll be looking at merging that PR soon too).. Master has seen some updates, adding a Serve type that may eventually be the replacement of Server (perhaps it takes its name in 0.12). We should add a method to Http that can create a Serve from any stream of incoming connections, which should accomplish the rest of the goal of this PR. Frankly, was just stuck on naming...\nThank you so much for exploring this! This helped figure out that Server both owning a Core and possibly being a Future was awkward.. This has been addressed in master, and the linked PRs have reasoning around it.. Sorry, didn't write here as the user also asked on Reddit, and got several answers.\nThe guide does try to touch on the stream being able to be changed, but it might not be that obvious. Probably the guide should be more properly designed, instead of the sort of mishmash I've put together so far.... Having Into there would probably be nice. This is actually a case of why #1129 exists. I would wish that users would not have to give a hyper::Error back to hyper to signify that the stream is busted.... Great, thanks!. @jonhoo probably not! In the linked example, the Core is dropped immediately, so it will never actually be running, and so won't execute the DNS queries!\nHowever, running them on the same Core is probably also not desirable in 99% of cases. It will completely block the thread while calling getaddrinfo, which could take a couple seconds to complete. While doing that, the thread cannot make any progress on any other requests, and it's a server, any responses are also blocked.\nIf you wanted to use the same thread pool executor for all Clients, you could create one like from futures-cpupool, and pass that handle as an argument when constructing a Client.. Oh woops, I misread, apologies! I see what you did now. I hadn't realized that Core implements Executor. It perhaps shouldn't... since passing it directly like that means the HttpConnector owns it, but doesn't know anything about other than it's an Executor. However, the Core must be running in order for any spawned future to be completed.\nYou could just pass the Handle of your main core as the Executor as well, if you really wanted to block the main thread :). Hey there! Thanks for submitting this!\nAs you noticed, there was also #1275, and some discussion happened in there around why these bounds existed. I've since finally merged that PR. This should be in 0.11.3 soon!. Master has grown to have a Serve type which will be used to explore replacing Server. Serve doesn't require a Core, but instead is a stream of binding connections with HTTP.\nThanks for taking a stab at this!. Yea sorry, I pushed a change to master that broke some tests. I've pushed a fix for them just now.\nWow, this change was more involved than I thought!. > Could you help me out by detailing what your concerns are with exporting it? Is it about the size of the API surface? Or something different?\nIt's just about promising backwards compatibility around naming and trait impls on that type.\n\nHowever, since HttpConnectorBlockingTask has not been exported from hyper, it's impossible to express an enum of these two tasks which could be used in the trait constraint for the Executor.\n\nTrue, you could not define an enum naming the HttpConnectorBlockingTask. However, it would work similar to if we just returned an impl Future using the conservative_impl_trait unstable feature. It would still implement the trait, so it can passed to anything that is generic over Future<Item=(), Error=()>, and it can also be boxed.\nSo, in your example of wanting to use a thread pool, if we use something like futures_cpupool, it would still be doable, since it is already generic over any F: Future<Item=(), Error=()>. You just wouldn't be able to name it specially, so you could have an enum Task { Something, Connect(HttpConnectorBlockingTask), }.\nIf this API were to return Box<Future> instead, it actually wouldn't change much. You still couldn't name the type. However, it would force boxing at a stage that might not need it. You could still end up creating an enum, like enum Task { Something, Connect(Box<Future<Item=(), Error=()>>), }, and just box the future as it's returned from hyper.\n\nI don't mean to be annoying, my main concern is around backwards compatibility. It can be a pain at times :). Great, thank you for the work!. Thanks to StrictTransportSecurity having all of its fields public, it's a breaking change to add a new one, so adding this would need to be part of 0.12. (While in there, the fields should be made private with getter and setter methods instead, so we can add more fields in the future...). I haven't seen a pull request, so fair game! Note that as pointed out earlier, this would be a breaking change and so couldn't be released soon.... For now, the new version of hyper won't be including the typed headers directly, so I'm closing this here as a won't fix.. An issue you may encounter is that a chunk can come over the socket that isn't a full JSON object, because it was bigger than could fit in the packet. Or you could have a packet arrive with a full object, and the start of another. So, you'd need to be able to buffer any partial chunks.. It's true that if one doesn't think about it, body.concat2() could buffer a ginormous body. I've so far been fine with that, since it's quite similar to showing examples with blocking IO to use io.read_to_string(&mut s). I think that a web framework should probably do more here, like checking the Content-Length header (and endpoints with size restrictions should probably reject requests without a Content-Length).\nAdditionally, this sort of functionality is likely useful outside of hyper, for any Stream over bytes. I don't know if it possibly makes sense as a thing on Stream, perhaps. It'd be interesting if it could be a property of the thing being extended, such that at MaxSizedChunk could reject being extended past a certain size, but unfortunately, the Extend trait doesn't really have any way of doing that other than panicking.\nAll this to say I'm unsure if it should be part of hyper directly, or somewhere else. It's possible @alexcrichton or @carllerche have thought of these things also.. Seems like a good goal. Perhaps CookieValue is CookieValue<'a>, which borrows from SetCookie?. Oh, I hadn't noticed the Drop behavior. Hm, on one hand, that seems clever, but on the other, it seems surprising...\nFor 0.12, hyper will have removed hyper::header, and all that was in it will be published as a separate crate (with an altered API to accommodate working with HeaderMaps).. > What's the timeline for this? Is it worth implementing this against 0.11?\nThere is the 0.12 milestone, but in short, it is waiting for any breaking changes for futures and the tokio crates, to be combined with the breaking change of using http. It will likely be a while, possible a couple months, so this feature could easily fit into 0.11.. For now, the new version of hyper won't be including the typed headers directly, so I'm closing this here as a won't fix.. That seems fine to me. I think I tried it out a few months ago, and ran into issues propagating the generics everywhere, but maybe I did it wrong!. Woops! Thanks for report, publishing again.... You may find that the reqwest crate has easier ways of doing some of these things.. The pasted example is blocking (thread is blocked at core.run() and the wait() call), so I assumed you didn't actually want it. So, what part then did you hope would be shorter?\nStill, if you do, reqwest does have an async client. Needs the \"unstable\" feature enabled on it.. The same reason older version of docs are still up on https://doc.rs: it's rude to break the internet by removing sites that people may have linked to.. @aturon I'd certainly welcome any thoughts around the API. Pulling out some questions:\n\nDoes it seem bonkers to have a Stream<Item=impl Future>? That is what is suggested by having impl Stream for Server { type Item = Connection }, and impl Future for Connection...\nDo the names make sense? Should the names be shuffled some, considering there would (eventually) no longer be a type exposed as a \"protocol\" (ServerProto)? Perhaps that makes Http more meaningful as a Builder type.\nWith Connection returning fatal connection errors, it's still possible for stream-specific errors to occur on a Connection that otherwise don't tear down the connection. Thoughts on Connection growing a on_h2_stream_error callback option?\n\nThe point here is that one could return a Response, and then part way through flushing it, the client resets the stream (perhaps a cancel notice, perhaps something worse without being a connection error), it would be nice to know if that response were successfully written or not.. #1362 is available, which starts to address this. Specifically, it adds a configuration option to disable the tokio-proto usage in the server and client. It is not enabled by default, until some more testing shows that at least it has fewer bugs than the tokio-proto dispatch does.\nOnce determined it should be the default, the no_proto methods will be deprecated, along with the ServerProto pieces that are exposed, and we'll try to move towards the naming discussed in here.\nThe work in #1362 already has some benefits:\n\nSeems to have fixed some bugs around keep-alive.\nCan have a small performance gain.\n\nBetter errors are returned on both the client and server.. An update: starting in v0.11.11, the new dispatcher was set to be enabled by default, and the tokio-proto specific parts were deprecated.\n\n\nIf you use the client, you don't have to do anything, it's just better.\n\nIf you use the server, it depends:\nUsing tokio_proto::TcpServer::new(Http::new()) is deprecated, but will still work for all of hyper 0.11.\nHttp::bind still works the same, just uses the new dispatcher internally.\nHttp::bind_connetion is deprecated in favor of Http::serve_connection.. There is a new Http::serve_incoming that can take any stream of IO objects. The returned Serve is a little harder to use, but it allows direct control to spawn connection tasks on any executor.. Woops, thanks for catching and fixing this!. You'd probably need to move the cookies vector into the closure, with the change to and_then(move |res| {.\n\nSeparately, you could do res.headers.get::<hyper::header::Cookie>() instead of looking in a loop.. I'm sorry, I don't have the full context on that you issue could actually be. It sounds like a more general Rust usage question. Could I suggest coming up with an example of code that has the error you're seeing, and ask either in something like Rust's IRC channel, or something like StackOverflow?\n(As this isn't a bug in hyper, I'm going to close the issue.). It wasn't a mistake, it was intentional. Perhaps a comment should have been left explaining the \"why\". Here's some why:\nThe server should never receive the fragment, and so it being on the type might make people think they should reach for it (and perhaps route on it). And clients should also never actually send a fragment to the server.\nI do realize there is legitimate reason for a client to interact with a fragment before or after issuing a request to a server, but there were concerns (at least my own) of misusing it\nIt should perhaps be noted that hyper::Uri will soon be replaced with http::Uri, and maybe that issue would be best for discussing how to expose it?. Great, thanks!. Thanks!. Awesome! I haven't had a moment to look this over, I hope to find time tomorrow.. Curious, when you paste the results from the multi-server example, is that running two instances of wrk at the same time, or 1 for the first port, and then 1 for the second port? I'm worried if only 1 at a time, that means the performance somehow dropped significantly.... >  the mechanism shutdown_signal like what run_until do may require external fields in struct Server to impl in Server's Future.\nYea, so either we'd need to:\n\nStore a boxed future on the struct that can be selected on. It'd probably be better to not need a box.\nPossibly Server itself shouldn't implement Future, but instead be a builder that can be combined with a shutdown signal to create yet another type, ServerFuture (maybe a better name), that is generic over the shutdown signal.\n\nOr perhaps Server still can implement future, which would internally just be a ServerFuture<Empty<(),()>>, and setting the shutdown signal returns a ServerFuture<F>.... @srijs that's a great suggestion, thanks! Indeed, the shutdown signal and timeout don't necessarily need to live in the base future. With a shutdown method, anyone can implement graceful shutdown with a timeout themselves.... So, a question that has come up in #1342 is if Server should instead be a Stream of Connections, where each Connection is a Future managing HTTP on that socket. If so, that'd conflict with Server being a Future itself.... I've been working with a start from this PR, and here's what I've got so far:\n\nHttp::serve_addr -> Serve which is a Stream<Item=Connection>\nServer::spawn_all(executor: E) -> Future which will spawn all incoming Connections onto the executor.\n\nThere's still the question of handling a shutdown signal on the SpawnAll. There could perhaps be SpawnAll::run_until<F>(f) -> RunUntil<F> or something.... I've been stumped the past couple days because tokio will very soon have the concept of a default handle, as well tokio_core::Handle no longer being the preferred executor, and so haven't particularly wanted to settle on a new API that would change in a couple weeks.\nI could just push what exists now, without the RunUntil or whatever...\n(PS, I've just been amending your commit, so it still has your name on it. Hope that's OK...). Thanks!. Not providing easy conversions is partly on purpose, because it can be easy to then disobey the rules given in Set-Cookie, such as respecting the path and domain. That said, I realize even if hyper doesn't provide an easy conversion, people will still just force a conversion and accidentally ignore the rules anyways...\nMany people may find that using the cookie crate may help parse all this stuff in the first place.\nThere is also an issue in reqwest to add proper cookie jar support, that would add these cookies for you, but also properly obey the rest of the Set-Cookie directives.... For now, the new version of hyper won't be including the typed headers directly, so I'm closing this here as a won't fix.. I believe this may be fixed in v0.11.7 if no_proto is set, but there isn't a test case in hyper directly.... In most cases, the internal hyper dispatch is now used, which will correctly stop reading if the stream is dropped. If still using TcpServer::new(Http::new()), you'll see this... so don't use that anymore :D. Woops, GitHub auto closed this because I had mentioned that enabling no_proto fixes this. I'll keep this open until no_proto is the default on, such that it is really fixed for everyone.. FWIW, v0.11.7 was released with this, if you configure the client with no_proto. Assuming no catastrophic bugs are found in the new dispatch, this will be enabled by default in a release soon.. no_proto is now the default, so closing this.. Thanks!. Cool! Since you're in there, doing all the breaks, how would you feel making the fields all private, and have setters/getters instead? That'd allow any new fields to be added without breaking changes in the future.... As noted in #189, headers are actually going to moved out of hyper proper. So as to not keep this dangling, I'm going to close this. Thanks for the submission, and of course, because the header system works for anything that implements Header, anyone can use these changes themselves by creating a new type.. This is shown because there is a CONTRIBUTING file in the repository. You can learn more here: https://help.github.com/articles/setting-guidelines-for-repository-contributors/. A fork shouldn't be required, you can accomplish the same thing quite easily implementing a new Future that works on listener.accept() instead of incoming().\nIt's probably a good idea to fix this in hyper as well. (Specifically, the accepting that happens in Server::run_until.)\nIt might be fair to consider if tokio_core::net::Incoming should be changed. While it does seem odd to have a stream yield Result<Option<Result<TcpStream, Error>>, Error>, it does more closely mirror std::net::Incoming, and docs of accept(2) mention that most errors are actually errors from the accepted socket, not from the listener, and do not mean the listener can't still be used.. @carllerche That's not the contract of Stream::poll, however. Stream::poll returning Err implies that the stream is dead and cannot be used again.. As is noticed by doing core.run(listener.incoming().for_each(do_stuff) terminating on the first error from accept.. I believe the helpers in hyper::server (so, Http::bind and an eventual Future version without a Core) that manages a TcpListener could do this internally.. rust\nfor socket in listener.incoming() {\n    let socket = match socket {\n        Ok(socket) => socket,\n        // Ignore socket errors like \"Too many open files\" on the OS\n        // level. Just continue with the next request.\n        Err(_) => continue,\n    };\n    // ...  \n}\nJust to clarify tailhook's comment: this code right here will spin the accept loop hard, since the EMFILE error doesn't remove the socket from the acceptor's queue. You might want to sleep the thread for a few milliseconds or something there.. Thank you!. I'm not certain, but this sounds similar to #1353. I can confirm what that issue reports, that if the Body from a client response is dropped before reading to the end, the connection just gets leaked into the reactor. There's work in #1362 that may fix this.. I've pushed a fix for when the Client has been dropped before the response finishes, along with a test for this case, to master.. This is in v0.11.7 (I believe requires no_proto still).. I cannot say without some more context. Other instances do not take 5 seconds to ready 500 bytes. It's possible it's the way the code is written, or it could be latency on the network, or something else.... For now, the new version of hyper won't be including the typed headers directly, so I'm closing this here as a won't fix.. The reason it doesn't is it can't be done in the type without some overhead, and it'd basically be an adapter of Stream<Item=impl AsRef<[u8]>> to AsyncRead, which isn't too hyper-specific.. If the other end is a Sink, there's stream.forward(sink) or sink.send_all(stream).... I'm going to close this for now, because it can't be done without overhead that would affect anyone who didn't need the AsyncRead implementation.. @ry \n\nI infer corresponds to chunks in transfer-encoding: chunked. [..]  Do I have this right?\n\nNo, the Chunk type is not actually related to transfer-encoding: chunked. (Maybe the name is confusing and should be something else?) A Chunk is simply a piece of the body as it arrives. hyper does hardly any buffering (the only buffering is that there needs to be some sort of buffer to read at all, and if the headers are smaller than the buffer, or a chunked-encoding body has chunks smaller, than some of the body will still be in the read buffer). Even when chunked encoded, the Chunks are yielded as soon as they are received from the transport.\n\nThe overhead I was talking about here is around the need for an impl AsyncRead to buffer a single Chunk at times. This is because you could call poll_read(buf_with_1kb_space), and a Chunk from the transport could have been 4kb. In that case, it needs to poll_data for a Chunk, copy over 1kb, and then save the Chunk so the other 3kb can be read.\nThe reqwest crate has a ReadableChunks type that adapts a Body into an AsyncRead.\n. Sure, seems good, thanks!. Looks nice to me, thanks!. Very true, this should likely both be configurable and probably also correctly try to write a 4xx response before closing.\n(Also, wow, a URL over 400,000 bytes?!). Very cool, thanks! (Nightly failure is because nightly recently gained ASCII methods on str, making AsciiExt imports trigger a warning.)\nI do admit, I had a hard-ish time understand what this problem was solving. But after looking at the tests, it seems to be \"give me a range up to the Nth byte\"?. I see, so its trying to turn the variants into a single a..b, as long as n >= b. Maybe an example or two in the docs might help, but I'm not really sure. I've never had to use it, so my context is very shallow.. Thanks! Curious, where did you see these warnings?. Very nice!. No, this is not expected behavior. In fact, in tests/client.rs, the very first test makes sure that no body doesn't send additional headers.\nIndeed, it's as you've described: the reason is because request::from_wire will create a Request with a Some(Body::empty()), which then does imply there is a body.. @aep this is using v0.12?\nHow is the body constructed?. Ah, ok. With wrap_stream, there's no way to know how big the body could actually be, so it will default to transfer-encoding then.. The body is read only if the Core is running. You run it to get the response, but the body is still in transit. Then, waiting on the body while the core is not running will indeed never finish.. Sorry, yes, this would be a breaking change, so it couldn't be part of 0.11. I'll put it in the 0.12 milestone, but if someone needs it immediately, one could just copy the code into a local module and use it instead of importing from hyper.. As noted in #189, headers are actually going to moved out of hyper proper. So as to not keep this dangling, I'm going to close this. Thanks for the submission, and of course, because the header system works for anything that implements Header, anyone can use these changes themselves by creating a new type.. Unfortunately, it can't just be merged, as it's a breaking change.. Do you have how you are configuring either hyper::server::Http or hyper::Server?. Would you be able to add server.no_proto() after http.bind()? Additionally, it'd need to use hyper master, as a bug was fixed with no_proto that is in 0.11.7.. Rather, that fix was released in 0.11.8, so simply an upgrade would be needed (and adding server.no_proto()).. The two things you are comparing are actually doing different things: the oneshot is buffering the full file contents into a single Vec, and then sending that as the body to hyper. The fs-pool approach is reading a chunk of the file and sending that on the Stream. I believe the fs-pool implementation has been shown by people with large files to work, so it could be a bug in hyper dealing with a streaming body.... It sounds like this is a bug, but I haven't been able to identify what causes it, nor set up a reliable way to investigate it.. I modified a hyper example to use cpu-pool to send a small file, and ran curl against it a whole bunch of times, and could never get it to error.\nSo, I read through your branch of nickel, seeing how you used the cpu-pool, and also the test code. The test code might be the cause, or it could be something even more hidden. Either way, there is a bug in the test code that could explain the issue you're seeing:\n\nThe response_for util function creates a Core and runs a request on it, returning a Response. The Core and Client are dropped as the function returns.\nThe test function, after getting the Response (and thus the Core is dropped) tries to stream from the body. With the Core dropped, any data that came on the socket will never be read, since the Core never polls the connection again.\n. @jolhoeft does the issue happen if with the test code adjusted?. Yes, tokio would eagerly try to buffer the first body chunk, which means depending on if the data was in the socket or not before core.run() returned would affect your test. (I believe the new dispatcher in hyper doesn't read as eagerly...)\n\nGlad to see that this just a test error!. Thanks! I merged another PR that included this change before I saw this one, sorry.. Specifically, it appears Body::from is used in the \"Body mapping\" section, but never mentioned in an import.. This has been fixed.. To clarify, is there a situation in the client where this doesn't happen? It look like in Dispatcher::poll, shutdown is called before returning Async::Ready(()) in all cases.. Thanks!. For a client connection, if a message has been read to the end of its framing, it shouldn't be expecting more data until a new request is sent, right? Should the behavior be adjust to try to read anyways, and if not expecting anything, return some protocol error?. I believe the error that commit was fixing was the case of a HEAD request where the response returns a body anyways, so by not continuing to read, a protocol error wasn't yelled after a HEAD.\nCome to think of it, that would just mean that the socket would return a protocol error the next time, and ruin a new request... I suppose it's best to point out early when a response had extra unexpected bytes.... This is fixed in 0.11.8.. Those logs by themselves seem fine: sometimes connections are bad.\nDo you mean the logs are incorrect?. I do want to make it easier to spawn all connections onto an executor. Though, I also think the tokio reform will change slightly how we should expose this.... I would recommend the futures-fs crate, as suggested before.. Thanks!. Thanks!. Just tried running this with master, and nothing panics (and sockets are correctly dropped!). As noted in #1388, running this with master shows all sockets being dropped after being closed.. Hm, I wonder if this will work while the connection is currently \"parked\". I guess if you have the Connection future, and call this function, then a later call to poll will notice that the state is disabled, and end, right?. Thanks for the report, I believe I see what is happening. I'll have a fix shipped in 0.11.8.. It looks like in the linked issue, the problem was found and fixed, so I'm going to close this.. Yep, this is #1304. Closing as duplicate.. Thanks!. Well, shoot. The reason I liked this was for the end user API, but I think it might be impossible to do in 0.11 because:\n\nBody is Send + Sync\nWe can't enforce the transport is Send + Sync, so we can't add Box<AsyncRead + AsyncWrite> to the internals of Body.\n\nWhat exact user API were you thinking with channels?. If there is an upgrade, what does res look like? Does a Response get generated and called? What goes in the Upgrade struct?\nWhat I preferred about the initial proposed API is that handling an upgrade was local to the Response, and so obvious. My concern with configuring the Client is that it can happen in different places, and thus it might not be obvious that upgrades are handled.... > Upgrade struct is right at the top of the example.\nAh OK, it wasn't in the original message I got in email, didn't notice the edit.\n\nSo, a user would receive the Response like normal, and would be able to inspect it, and if it wasn't an upgrade, try to read the body. Regardless, if it is an upgrade, the upgrades receiver would also receive an Upgrade...\nI suppose it allows working without a breaking change, but my personal opinion is that it kind of feels far away from the rest of the code. Hm, does that even matter? I suppose that the underlying connection is being used in an upgrade perhaps doesn't matter to the other place that received a Response.... Ok, sorry it's taken so long to get back here, I haven't had much time to focus on this feature, but it's now needed in Conduit, so it's got my attention again.\nI've started with the idea that the client could use a lower-level API of running HTTP over a single connection, and there is where upgrades can be handled at first (as well as custom pools and whatever else). I feel that designing an API to work directly with the higher level Client, which manages connections for you, is holding back this feature work, so that's why I've gone this direction. I think it could be possible to eventually design an API that works with the higher level Client, but here's a proposal to get things started: https://github.com/hyperium/hyper/issues/1449#issuecomment-368121931. A solution for #1449 was just merged to master, that introduces a lower-level connection API, where it is possible to make CONNECT and upgrade requests on it.\nThe Client uses it internally, but still specifically errors on CONNECT and upgrades since there is no exposed way to handle them correctly.. There's a proposed PR at #1563 to add this feature (and for servers).. Does the connection send bytes it shouldn't? Such as, is there a body to a head request, or some extra bytes after the end of a response body?. Would it be possible to turn on logs from hyper and (after sanitizing) paste the ones that appear around the error log? I'm setting up a super simple program to just hit some public API end points on Gitlab and not seeing this error log, so I could use a little more on how to investigate this.. You could send it to sean@seanmonstar.com.. The most likely cause for this was that the connection was being closed immediately after the end of a response body was read. The internal implementation would not have adjusted its state that an EOF was OK at that point (only doing so in flush), and the tokio-proto dispatcher was calling poll again (since the previous one succeeded).\nMerged to master is a fix to update its state that the message has completed and so an EOF is not unexpected. Would you be able to test using hyper master, to confirm?. Does the response that comes back include a response body?. PS, don't call Timer::default() in a loop. That is creating a worker thread every single time. Create it once outside the loop.. This has been fixed when the no_proto config is set on the Client. The new dispatcher will soon be the default, fixing this for everyone.. Ah yes, this is different! Not idle connections, but rather an active connection when the Response or the Body related to it has been dropped.. Ok, new patch fixes the test case you provided.. Yes, that commit did fix an issue that sounds just like this one.. Hey neat! Do you think this sort of thing would be well suited to be a guide?. Yea, that's a good point. You tell me, would you be interested in turning this into a guide at https://github.com/hyperium/hyperium.github.io/tree/master/_guides/server?. My personal (somewhat weakly held) opinion so far has been that \"examples\" can be hard to understand without context, and I've tried to not add too many, but instead any time I've wanted to make an example, tried to make it a guide instead.. Fair enough, convinced! Thanks!. Thanks!. I agree there are cases where this is desirable, but there are also reasons it doesn't exist yet. These are properties specific to TCP, whereas hyper (and HTTP even) don't require the underlying transport to be TCP (Unix domain sockets don't have a concept of addresses, for example).\nIt'd probably need some sort of middleware between when a transport is chosen ready to use and when a Response is given back to the user, but there isn't currently anything to really do that. For now, you'd probably need a custom Connect implementation that stores the relevant socket information in something that you can check outside of hyper.. When would one expect to be able to receive this information? You generally give a Request to the Client, and don't know what connection it will use at that point. If it's fine that this information is received on the Response, we could optionally put this information in the Response::extensions.\nIf we went that way, I'd think that instead of exposing exactly that the type is in extensions, some sort of ConnectionInfo type could exist that can be get and set on the Response (and similar info could be useful on the incoming server Request).\nA possible API:\n```rust\npub struct ConnectionInfo {\n    local_addr: Option,\n    remote_addr: Option,\n    // maybe new fields in the future\n}\nimpl ConnectionInfo {\n    pub fn get(res: &Response) -> ConnectionInfo {\n        // fetch an internal type from extensions(),\n        // fill in whatever info was possible\n    }\npub fn set(&self, res: &mut Response) {\n\n}\n\n}\n```. Yes, of course. I was asking at what point would it be expected to access the remote info? Is it fine as a property of the response?. Do it always happen, or only on certain URLs? Is there a request body, or a large response body? Is it possible to turn on logs for hyper?\nIf adventurous, you could try enabling no_proto on the client config, which has some fixes that may include this. It will become default soon, but might contain other bugs.... Does this still happen? With the release of v0.11.11, the internal dispatcher for the client has been redone, and many bugs were fixed, which I think includes this one.. I'm going to close this, since I don't know how to reproduce, and am hopeful that the bugs fixed with the new dispatcher fixed this as well. If not, we can re-open!. Awesome work!. The problem is creating a Core for the Client, and then dropping it. The Client still needs it running in order to make the request and return a body.\nTry creating a Client outside your Service, using the same Core as the Server.. It's because starting in Rust 1.23 (which is currently in beta), the methods that were on AsciiExt are now inherent methods, and so the imported trait is not \"used\" on >=1.23. You need to slap a #[allow(unused)] on the use std::ascii::AsciiExt line.. Thanks, these are really useful!. Does this answer the question? https://hyper.rs/guides/client/advanced/#multiple-requests. They do happen concurrently. One or the other may finish first. The order of the prints with the status code depends on the server. However, in this example, since they are joined, it does mean that it waits for both to finish to get the bodies. You could change the code to act on the bodies also, adding and_then after the concat2, for instance.. You take a reference to the Core via a Handle or a Remote. Handle is for same-thread. Remote can be sent to other threads. So core.remote().. Thanks!. You're right, I forgot about this method. I'll add it back to prevent breaking people, but remote_addr will also be deprecated.. The remote address likely won't be part of the Request any other way. However, each Service is created per connection, so the address can be stored in a Service. That should be trivial if managing a TcpListener yourself, but a way to access it when using Http::bind doesn't really exist, and could be explored.. If there's interest in getting this information even when hyper manages the listener, we could open a new issue about that. This related comment about an API in the client seems relevant.. Yikes, I'll take a look!. I believe the latest commit to master properly handles the incorrect state that this assertion is catching. Would you it be possible to test with master?. Well, it did seem like there was a problem with the connection being closed prematurely, but hyper shouldn't panic because of it.\nI think master fixed the panic, so I'm going to close for now.. Hm, there must be something more to this, because making a server with the above code and running curl against has it working for me.. Ok, I found the missing piece: using hyper with TcpServer. Looking into the cause.. > how in retrospect you feel about making a substantial change to Hyper in a patch release?\nI still feel pretty good about it, as it has 1) remove many less obvious bugs that existed because of the tokio dispatcher, and 2) has moved hyper forward significantly for when the tokio reform is complete.\nAs hyper is currently pre-1.0, semver is basically shifted over one place. So, going from 0.11.11 to 0.11.12 is fine with adding new features (in this case, new APIs), yet most of the work was more of a refactor to not depend on a internal dependency. If hyper were already 1.0, I'd probably consider the work something to go into a minor version, but it's not yet!\n\nthe coming about of this bug\n\nSoftware has bugs. It's unfortunate. I hate it. But it's a fact.\nThis one was reported over the weekend, but getting after getting back to work, it was fixed the same day I had time to look at it.\nThis particular bug was not introduced in the large refactor, which was release in 0.11.11, but rather in a later bug fix that was released in 0.11.13. The reason for this bug being released is how most bugs get released: there wasn't test coverage for this specific instance. As part of the bug fix, the commit also included test coverage that triggers the bug if the fix is not in place.\n\nwithout yanking the affected version? Are you planning to yank 0.11.13?\n\nI don't believe so, no. Yanking isn't meant to be used on every single version that happens to contain bugs. Yanking is to remove a version with a serious issue, perhaps legal or security related. Any user would get same behavior from cargo update whether I yanked 0.11.13 or not.\n\nIs there something about this chain of events that you take as a lesson?\n\nNot especially. I'm terribly sorry that a bug was introduced, I hate that I write bugs. I'm sorry if it caused issues in your deployment. But for this particular chain of events, I feel like it was handled promptly. The only thing I could think of myself is that it'd be great to have had the test before, but that's the problem with tests: we only ever have tests of the bugs we think of, not of those we don't.\n. Take a look at how you can easily do so with the reqwest library.. Thanks!. Yes, there is. Have a look at this example: https://github.com/hyperium/hyper/blob/master/examples/multi_server.rs. You can sort of do what you want, but not all of it is especially easy.\nFor logging request and response, that you can do by logging whatever you want just before calling client.request (or client.call), and you can log the response returned by the future, for example:\nrust\ndebug!(\"req = {:?}\", req);\nclient.request(req)\n    .map(|res| {\n        debug!(\"res = {:?}\", res);\n        res\n    })\nIn order to get a reference to the transport being used, you'd probably need to write a custom Connect so that you can return a transport that can log some instances about itself.\nProbably this is also related to #1402.\n(As this seems more like a question around how to do something in hyper, and not a bug that something doesn't work, I'm going to close for now.). I tried giving an answer in #1415. I suggested using the reqwest crate, as it does a lot of the boiler plate for you. If you don't want to use it, then you'd need to manually construct the bytes of the form data yourself, and then send them, similar to the example sending JSON in this client guide.\nThere's no need to open duplicate issues to ask the same question, though.. Look at the publish date of RFC 7168: it's an April Fool's joke.. What do you mean the hyper client becomes tainted? Are you sure the sockets had been closed before trying to open a new socket?\nYou mention that the second call to core.run() panics, but does it panic inside, or is the unwrap() you have right there? I believe the future from client.get should just return to you that IO error, and so you can handle that situation yourself.. What are you using for a server? I just tried this against the hello world server in hyper (and the server did actually fall over from too many files open, but I added a little of code to protect the server) and didn't see any error...\nI do notice that in the loop_fn, you use then, which will be give a hyper::Result<Response>, and then drop it. I wonder if that result includes the error as well.... Thanks to knowing it was DNS related, I've done a bunch of digging, and determined that the EMFILE seems to be remembered by subsequent calls to lookup the address on the same thread. I don't yet know if this is a some cached info in getaddrinfo, or related to the libc::res_init call when the resolution fails. Sharing the same CpuPool of 1 thread even in a new client triggers the error, but creating a new one for the second client doesn't see the error.. I'll see if I can reproduce this with just std (unless someone like to beat me to it), and if so, I'll file an issue on the Rust repo.. Filed at https://github.com/rust-lang/rust/issues/47955. According to some more info in the upstream bug, it looks to be a bug in some versions of libc. As such, I'm going to close as there's not much more we can do here.. On most operating systems, TCP keepalive is enabled by default. On Linux, you can adjust the keepalive options for the kernel. For those that want to customize all the details of a TCP stream in just hyper, that can be done for both the client and server before giving the stream to hyper (with client::Connect or server::Http::serve_*).. Hm, my mistake, some references I found suggested TCP keepalive was enabled by default on Linux.\nI guess it seems fine for the default of hyper to just enable these, and if anyone hates them, they can do the more involved config to remove them.. Yes, this is fixed and in 0.11.19.. Thanks!. For now, the new version of hyper won't be including the typed headers directly, so I'm closing this here as a won't fix.. Good idea, thanks!. @carllerche The problem with the trait in tokio-connect is that it doesn't give enough information. hyper tries to provide a higher level API for users, but some of the details of how HTTP works depends on the connection layer. The tokio-connect trait doesn't allow passing any argument, so it cannot be given a host name or even a socket address.\nThe Connect trait in hyper is meant to be a little higher level, allowing users to swap out the connect/transport layer, while still getting an easier-to-use HTTP client. This PR tries to encapsulate what information hyper needs to give to connect layer, and what that can give back to hyper, in order to determine how exactly it can speak HTTP over it.. After thinking that a connector might return some info, like being an HTTP proxy, and another might wrap that connector to provide TLS, the proposed design of returning Connected<T> means that details from the underlying return value will likely be lost when the wrapper takes the transport out.\nSo it may be better to change the return type to (T, Connected) instead of Connected<T>, and allow wrapping connectors to just append details to the returned Connected metadata type.. The ALPN stuff has been deferred for when HTTP2 upgrades are added, but the change still allows for that to be added in the future. A way for connectors to signal that the connection is to a proxy has stayed. This has been merged into 0.12.x here, without the deprecations and instead just changes to Connect directly.. As noticed, the panic is in client/mod.rs, the call to start_send().unwrap(). It's wrong to assume that the sender can always send. This should probably be changed to not unwrap, but to realize that the pooled connected has died, and to try a new one.. Should be published soon (today?). I'd like to get in some documentation fixes as well (separate from this issue).. @xrl yea, definitely. Bummer. The connection pooling code in hyper hasn't seen much love, and is complicated and apparently fragile :cry:.. I'd worry that changing the error from Error::Io would break anyone handling the errors in their own frameworks. Could this just be handled in rocket?. Instead of some hyper::error::User, this could just be Box<std::error::Error> instead. This punts allowing the error type to indicate an HTTP2 error code to reset with, but it's probably otherwise much clearer. Basically, all things in hyper that would allow a user to signal an error occurred could just be E: Into<Box<std::error::Error>, which is the same bounds like for std::io::Error::new(kind, my_error).\nSome benefits here:\n\nUsers can return their own error type, making it easier to plug their app in, and logs can show exactly the message that they wanted.\nThis still works with hyper::Error, so proxying one hyper::Body as the body of another message works fine. With specialization, we can remove the box internally, but not a big problem either way.\nWe still benefit from not having weird hyper::Error::from(io_err).. I think this is rather usable. There's some \"integration\" tests that use the full stack, client and server, and some basic cases are passing.\n\nI still don't feel the most confident about the client pool changes, but this could probably be merge this week.. @dbrgn that's because hyper-tls is depending on the crates.io version. You'll need to put [patch] in.. I've just updated this branch with a rebasing to master (and minor fixes otherwise). If you were depending on the previous code somehow, I've pushed that to the 0.11.x-h2 branch, though I wouldn't expect that branch to live long.. @xrl Would it be possible to try out your app with this branch?. Looks like an assertion in the mio dependency is causing the panic. I can't recall if mio works on NetBSD. cc @carllerche. I'm going to close this since there's nothing hyper can do here.. You can set the body type of a response to any custom Stream type (well, Stream<Error=hyper::Error, Item=impl AsRef<[u8]>>). The default is just easy to use in simple cases, but frameworks or users can change to a stream better suited to their needs. You'd do so like this:\nrust\nimpl Service for FileServe {\n    type Response = Response<FsReadStream>;\n    // ...\n}\nRelated guides:\n\nhttps://hyper.rs/guides/server/echo/#body-streams\nhttps://hyper.rs/guides/server/response_strategies/. Yea, there can't be a From<Stream>, since that's a trait, not a concrete type. Since hyper::Body is meant to be easy to use in common cases, maybe it's worth adding a Body::boxed_stream(s) -> Body?\n\nOh, I read the original comment about setting a response body, and assumed you were talking about the server.\nFor a client, you can also set a custom stream type, it's just a little different to configure, since you don't define a Service when using a client. This is the current way (I'm aware it's awkward, and should probably be done in a different way in 0.12):\nrust\nlet client = Client::configure()\n    .body::<FsReadStream>()\n    .build(&handle);\nhttps://docs.rs/hyper/0.11.*/hyper/client/struct.Config.html#method.body. I'm going to close this, as it doesn't seem to be an actual bug. :). I'll take a look. That commit specifically could be a measurable increase in atomic operations, causing a 10% slow down in scheduling (it'd be most noticeable if connections are kept alive, always reused, and bodies are small).\nFor the large regression... just curious, are you using TLS (HTTPS)?. Ok, for the large regression, this is my suspicion:\n0.11.16 added improvements to how it does buffering and writing, which greatly helps large bodies, even more so when streaming and chunked encoding are applied. This was done by making use of vectored IO. However, TLS can't really use vectored IO, and I believe most async TLS rust libs just use the default write_buf method, which packs up each individual chunk into its own TLS record. If so, that would mean that before 0.11.16, when the write buf was a single flat vector, writes of the headers and payload could fit in the same TLS record (and probably the same IP packet, if not too big). With 0.11.16 using vectored IO, it probably means the headers are in 1 record, and the body is in another.\nIdeally, TLS libraries would change to not use the default write_buf implementation, but would flatten the bufs themselves. But, we can't really control that, so, perhaps hyper can try to adjust itself.\nHere's what I'm thinking: hyper's buffer strategy grows the ability to notice if after a call to io.write_buf(bufs), if only 1 of the bufs was written, it will try to update itself to automatically flatten all bufs for that IO object from then on. It would mean that the very first write could still be split, but if the connection lives for many requests, it will perform better for all the subsequent writes.\nAnother option, and not necessarily mutually exclusive, is to expose a config option to enable vectored IO, or to always flatten into a single buffer.. Having knobs to twist does seem reasonable. I think it's probably best for hyper to try to automatically be faster when it can, though.\nSo, as of right now, hyper master contains:\n\nAn auto detector of its write buffer strategy, that will try to notice if no IoVecs are used. If it detects that aren't, it will convert itself into a flattening buffer. This means that for brand new connections that don't support vectored writes well, there may be a single write that is smaller, but after that, it will switch to using a single buffer to improve writes with those transports.\nclient::Config::http1_writev(bool) now exists to allow anyone to disable this auto-detection: simply set that value to false. By default, the auto strategy will be used.. After reports in IRC that this did fix the issue, this has been published in v0.11.18.\n\nAgain, thanks so much for the graph and being able to pin it down to some versions!. Good idea about content_length, I'll update the issue text.\nI really like being able to just call one method like poll_next and matching an enum, it's much simpler and elegant. But, my worry is that it's impossible to deprecate enum variants, where as methods can be deprecated but still supported.. You can add a deprecated attribute, but you can't ever stop passing the data in that variant and instead pass a new one, or you break code at runtime.. That's correct, and they probably wouldn't ever need to change But, the enum might need to grow new generic parameters, which could also be problematic. For instance, say we start with this:\n```rust\n[non_exhaustive]\nenum Frame {\n    Data(B),\n    Trailers(HeaderMap),\n}\n```\nBut then want to add a push promise variant. I don't yet now what the quite looks like. Should it be the Request plus a future of the response? Maybe something like:\n```rust\n[non_exhaustive]\nenum Frame {\n    Data(B),\n    Trailers(HeaderMap),\n    PushPromise(Request, PPF),\n}\n```\nAdding that generic would be a breaking change. So then, do we not allow passing a future? Or do we require boxing it? Or maybe we require a specific PushPromiseFuture that has an associated sender?\nI'm not sure. And, if we later decide that the current design sucks, we're completely stuck with it. If we deprecate the variant and try a PushPromise2 that is a million times better, then we can't actually use it or anyone who was using the previous variant is busted. Maybe I over think this stuff too much.. > But wouldn't adding a type parameter break back compat anyway by adding a new associated type?\nSo, I think it might be possible to add those without breaking, thanks to defaults allowed on associated types.\n\nShould content_length even be a method on Body? It can always just be set explicitly in the headers, right?\n\nThat's what I meant when asked if pulled its weight. The reason I added it was because I wanted to add the ability to hyper to be able to determine length vs chunked automatically. It's especially helpful for HTTP/1.1 clients, since many servers arbitrarily decided that don't love a client sending a chunked body, and so it'd be less surprising for users that did Request::new(DefaultBody::once(\"hello world\")).\nEven in cases where servers don't have client chunked encoding, some endpoints want to validate a content length before accepting a body that is too big.... I settled on the trait name being Entity, and keeping Body as the default implementation. I've merged an implementation in the 0.12.x branch in https://github.com/hyperium/hyper/commit/73a3fadc55ea021efa8cd1f19400141ceca96a5b. Hey @idubrov, thanks so much for the detailed report, and a test case!\n\nFor some reason, write to the socket on the client side succeeds (doesn't return EPIPE)\n\nThe first write can sometimes succeed, since it's just being put in the sndbuf, and then the kernel can try to send in on the wire. Networking is fun!\nLet's see what we can do to fix this:\n\nThey sort of are. If the proto::h1::Conn gets closed while idle, the handle in the pool should notice that it's been closed (seeing status() == Disabled). Are you suggesting that when taking the handle from the pool, the connection should have read() called on it again?\nIt does seem like regardless of better detection for 1, it's all around better to error than to hang forever, and so this should probably be done.. There should be a fix for this on master, including your test case passing!\n\n\nOn a related note, shouldn't the pool itself have a future associated with it to do the bookkeeping of the connections?\n\nMost likely. However, it not existing doesn't mean closed sockets will be kept around. Those will be dropped and closed. It's just a sender handle in the pool. Still, it'd be better to periodically clean those up.... You're right, it is poorly documented. The reason is because it's a newer feature, but I wasn't quite certain how well it would play with the newer tokio and futures. As that becomes more certain, the whooe server module will get some documentation about the 2ish APIs, low level and high level.\nFor your immediate case: Serve is a stream of Connections, bound to a service. However, each Connection is itself its own Future, needing to be executed. In your for_each call, you should spawn them onto the executor.. Also, you likely didn't show your whole program, so maybe it's not an issue, but that Core you created will need to be running for the IO in hyper to work.. The unfortunate thing is that you end up with 2 reactors (epoll event notifiers), one for HTTP and one for your TCP server. The TCP one is probably tokio's new default, in a separate thread.\nI don't know the best way to get them working together, I probably wouldn't recommend trying to do it just yet. hyper will upgrade to the new tokio soon, once the futures 0.2 release happens.\ncc @carllerche. Well, in neither example do I see how you create the TCP server, so I can't say for certain, but seeing the current_thread API suggests to me that you're using tokio, not tokio_core. If you're using both, then yes, they have currently have incompatible reactors, and so likely using 2.\nTokio uses mio, which abstracts over the various selection strategies in a cross platform way (so epoll on linux, kqueue on bsd, IOCP on windows).. The new design of Tokio is that by default, it spawns a global reactor, putting it in its own thread. This happens if you use Handle::default() (or functions on things like TcpListener that don't take a Handle argument). You can prevent the global by creating a reactor yourself, and passing references to it (its Handle).\nHowever! hyper does not yet use new Tokio, but instead the older tokio-core, So, it doesn't know about global reactors, and in fact, its Handle is technically a different type, so you cannot share them. This means that to drive your newer-Tokio TCP server, and the older-tokio-core hyper server, you need 2 reactors.\nThis might seem like poop, but don't worry, you just jumped in right during a transition period. Tokio is transitioning, and the new tokio 0.1 crate is a preview of the new design. The futures crate will see a list of breaking changes to version 0.2 in a couple weeks, and when that happens, tokio will upgrade to 0.2, and hyper will upgrade to both. After that, you no longer have the situation you're in at the moment.. (I'm going to close this issue, since it isn't about a bug in hyper.). Hey! I'm sorry RLS caused you problems when using hyper, and I hate to just point you somewhere else, but really, there's nothing I can do. It's a bug in RLS :D\nConsider filing a bug report over on the RLS repo.. Since Client is generic over a connector, which can return any type of AsyncRead + AsyncWrite, it is definitely possible to make tests using some mocked thing.\nhyper's tests/client.rs specifically use TCP as more of a promise that the client works correctly on TCP, instead of a bug existing in a mocked transport.. I'm going to close this as it's a question about patterns, rather than a bug in hyper.. Yes, I know of it, thanks! Switching to use it will be a breaking change, and since futures will release 0.2 soon, the change will be made together, in hyper 0.12.0. I'll tag this for that milestone.. Awesome! Yea, if you want to take a stab at it, that'd be fantastic!\n\n\nI think some things we'd want to do is have \"default\" constructors, that just assume the global reactor, and constructors that take a Handle. So, for instance, there is Http::serve_addr_handle, and I think something like that would stay, and we'd also have Http::serve_addr.\n\n\nFor places where the Handle is currently used as an executor, that will eventually be replaced by futures 0.2's Context::spawn.\n\n\nI wonder if it makes sense to change the HttpConnector to stop exposing the TcpStream directly, and instead expose an HttpStream, kind of like how in the server, there is AddrStream. I think this might allow for upgrade tokio-tcp versions without being a breaking change?\n\n\n. To your question about the API: I do think things should probably change up a bit!\n\nThe Http type was introduced to be a tokio_proto::ServerProto implementation. Now that it isn't, it might just be confusing. It's kind of a config builder, and also the starting point for both the lower-level connection API and higher-level server API.\nSome things started to appear, like Serve, which allowed a server-like interface that didn't require owning a Core. Now that Server doesn't need to own one, I wonder if Serve itself should go away...\nI also wonder if it'd be nice for Server to allow running entirely without importing tokio, if people just want the defaults.... This has been merged into the 0.12.x branch, here: https://github.com/hyperium/hyper/commit/603c3e4d2c6ebb3d495a85c4d9a8b36583eff3fc\n\nWe can open new issues around specific API changes.. Thanks!. To clarify, are you trying to add support to a client, or a server?\nFor a client, it is able to use any Connect type to receives IO transports to run HTTP over.\nrust\nlet client = Client::configure()\n    .connector(SocksConnector::new())\n    .build(&handle);\nFor the server, that Service layer has nothing to do with the underlying transport. You can accept a socket however you like, and then bind a server connection to a service using Http::serve_connection.. Yes, you can certainly combine connectors. Take a look at how hyper-tls does it. It by default just uses hyper::client::HttpConnector, but is actually generic over any, allowing someone to wrap any connector with TLS.\n(I'm going to close this since this seems to be a usage question and not a bug in hyper.). Oh, sorry, I assumed you could use HttpConnector internally to do the DNS resolution and get a TcpStream back, and then do the SOCKS negotiation on that stream.\nThe HttpConnector doesn't have much that you can plug into it.... Seems good!. Hmm, indeed, some docs on what do to do switch would be a good idea!. There's now some example code for serve_connection: https://docs.rs/hyper/0.11.19/hyper/server/struct.Http.html#method.serve_connection. There's a 0.12.x branch now on the repo where I've been trying to add new breaking changes to.. @srijs just as a heads up, I've merged 0.12.x into master, will be deleting the 0.12.x branch so there's no confusion of the difference between master and 0.12.x.. The API I've been prototyping has a similar look to the [h2 client](https://docs.rs/h2/0.1.*/h2/client/index.html), where you provide an already connectedio, and get back a sender (SendRequest?) andConnectionpair. You probably want to just spawn theConnectioninto an executor, and then use the sender to send requests, but there are methods onConnection` to allow finer control.\nAt this level, the internals can be configured to allow HTTP upgrades and CONNECTs (where as the higher level Client and Server treat them as errors, since there's no exposed API to handle them yet). After a user sends a request wanting an upgrade, and gets a 101 response back, they could coordinate to get the original io back out of the Connection. There's a few parts of this that may be tricky. Details next.\nSendRequest\n\nThis has a poll_ready method, allowing you to know if the related Connection is still usable.\nThere is a send_request(&mut self, req: Request<B>) method, similar to Client::request(req).\n\nQuestions:\n\nWhat should this be called? SendRequest? Sender?\nWhat should the send_request method be called? send_request? request? send?\nShould this type be Clone?\n\nConnection\n\nThe easiest thing is to just have Connection::into_inner(self) -> Io, however, servers can send the 101 upgrade response and the first part of the new protocol in the same packet. If they do that, the internal state will likely have those bytes in its read buffer. So, just calling conn.into_inner() would mean losing data. For that reason, I'm wondering if it is better to just remove this possible footgun.\nThe next thing that could be done is have Connection::into_parts(self) -> Parts<Io>. This is kind of like http's into_parts, which returns a struct with public fields, and a private one, allowing the possibility of adding new fields, while also allowing a user to take ownership of multiple things at once.\n\nrust\n  pub struct Parts<T> {\n      pub io: T,\n      pub read_buf: Bytes,\n      _non_exhaustive: (),\n  }\n- By default, the impl Future for Connection assumes it should manage the socket until completion, and then call AsyncWrite::shutdown(). However, if you're wanting to do an upgrade, you don't want shutdown to be called, but you do want to know when the Connection is otherwise \"done\" with HTTP. So, there probably needs to be another poll_* method to do that.\nQuestions:\n\nShould there be an into_inner() that could possibly lose data?\nIf you were to call into_inner or into_parts at some arbitrary time, even if there wasn't an upgrade, there could be unfinished state internally. Should it be an error to do that? Or should that extra state be available the Parts struct?\nWhat should Parts be called? Is Parts too vague (hyper::client::conn::Parts)? I didn't want to say specifically Upgrade, since you might use it without an upgrade...\nWhat buffer should be returned in Parts? It is internally a BytesMut, but we may not want to expose that directly. It's not hard to convert almost anything into a Bytes, so I started with that...\nShould Parts include both the read_buf and write_buf?\nWhat should the secondary poll_ method be called, that resolves when HTTP is finished but without calling shutdown? Connection::poll_upgrade()? What should it return? Should it return an Error if the connection is closed without a successful upgrade? Or should that be an Ok result, just with an additional enum?\n\nExample\nHere's an example that I'm currently using in tests (with await inserted for terseness):\n```rust\nuse hyper::client::conn;\n// connect a tcpstream somehow, and then...\nlet (mut tx, mut conn) = await conn::handshake(io)?;\nlet until_upgrade = future::poll_fn(|| conn.poll_upgrade());\n// using http crate\nlet req = Request::builder()\n    .uri(uri)\n    .header(\"upgrade\", \"foobar\")\n    .header(\"connection\", \"upgrade\")\n    .body(Body::empty())\n    .unwrap();\nlet upgrade = tx.send_request(req)\n    .map(|res| {\n        assert_eq!(res.status(), StatusCode::SWITCHING_PROTOCOLS);\n        assert_eq!(res.headers()[\"upgrade\"], \"foobar\");\n    });\nawait upgrade.join(until_upgrade)?;\nlet tcp = conn.into_parts().io;\n// use tcp over 'foobar' protocol\n```. > If we made Parts implement Read/Write\nThat's a definite possibility!. Great, I love it!\nI agree it should probably be enabled by default, and maybe someone may want to be able to configure the duration too, but this is a great first step.. Unfortunately, for HTTP/1, this requires information that hyper may not contain. For instance, since hyper is generic over the server connection streams, it doesn't know if it is supposed to http or https. Also, if the request is HTTP/1.0, a Host header may not be present.\nI'd suggest that this is something that frameworks can provide, as they are in a better position to know all of the required information.. Thanks for the PR!\nI'm not sure LINK and UNLINK are so common that they should be variants. Looking around at other HTTP libs, they don't seem to be included. The good news is that it's possible to use these with the Extension variant.. #1488 was just merged, and included some changes that touch this. Here's how it works now:\n\nsleep_on_errors is set to be default on\nWhen enabled, it will log at the error! level about the failures, so users can still see bad things are happening.\nThe timeout duration itself isn't configurable, it's just 1 second.\nIt can be turned off, and a completely custom strategy can be created by a user just by providing their own \"incoming\" stream of accepted connections.. Woops, thanks!. So, the changes look right! Thanks!\n\nHowever, as mentioned in a line comment, this is a breaking change, so couldn't be done in 0.11. I'd say this could be a PR against the 0.12.x branch, but with that switching to the new tokio, I'm unsure where timeouts will come from at the moment.... With #1488 merged, a variant of this is now in place. Thanks!. You could certainly use it instead of implementing for a struct. Here's some reasons you may opt for a struct instead:\n\nAs your service gets more complicated, it may be easier to reason about if you have a struct with fields, and methods you can call on it.\nIf you want to be able to name the service somewhere else, such as if you are composing multiple (like middleware).. If I were writing a small service (less than 10 lines) that I didn't expect to keep editing, I'd just use service_fn. Otherwise, I'd make a struct, since it would likely help as things got more complicated.\n\n(PS, I'm going to close this, since there's no bug here :D). Yea, they don't really need to be as different exports. I suppose I was thinking you'd do use hyper::client::{Client, Request, Service} and what-not... Could be cleaned up.. This should be handled with #1461, likely just export hyper::Service.. This wouldn't be too much work in hyper directly, but it does require tower to publish a version to crates.io. I'd probably expect it to do so only after futures 0.2, since it needs to update to the new futures.. Woo! Nice! (And sorry about 0.12.x, I had been rebasing master onto it for a while, assuming most people weren't actually depending on its history \ud83d\ude2d ).. > I'll try to rent an AWS instance later to try and reproduce on Linux.\nDon't bother! I can debug it myself.. For the hanging test, it's a combination of mutexes in the mock duplex code, and using the ThreadPool executor. The hang went away when I made sure that the task.notify() and the read or write happened without releasing the lock. But the test fails in an error since the tasks are on separate threads, but with only 1 core and mutexes, the code can't happen in the order that is being tested.\nThe test is specifically designed to be a series of events we can control, because its testing those series of events. I suspect that switching to the tokio's current_thread executor for that test will fix it.. I'll look into that test failure. Besides that, the benches don't compile XD.. So the failing keepalive client test is because of tasks being on separate threads, but with only 1 CPU, the order isn't preserved. Well, on one hand, it's good to find poorly written tests that break on multithreaded!\nThe test itself is ensuring that after we get a response back, a second request to same host should reuse the existing connection. However, knowing that the connection can be reused requires the Dispatch task to do some housekeeping after submitting the response back to the FutureResponse task. So, by the time the main thread has the response and starts a new request, the Dispatch task on the other thread hasn't had a chance to cleanup state and set itself ready for a new request, so it isn't back in the client's pool.\nAs a hack, we could just sleep the main thread for a few milliseconds, allowing the dispatch task to clean up...\nPerhaps in a separate issue, the design of that can be changed, since changing this test definitely means that users may see on occasion requests not reusing a connection it could have.. I've got the benches passing, and fixed up that test, in https://github.com/hyperium/hyper/tree/new-tokio. I've been pushing to that to trigger CI, and looking at some panics.\nSeems one was due to a race condition in the futures mpsc channel, so I've a work around there. Waiting for CI again.... Yay! CI is green! I'll see about merging this ... probably tomorrow, its getting late x_x. The issue on Windows was that we needed to call bind on the TcpBuilder before connect. All good now. I also loosened the requirement of Entity, such that the trait itself doesn't require Send, only when used in Client and Server and thus interacts with an Executor. That way, if people want to work with non-Send things, they still can, using hyper::{client, server}::conn.\nI merged those changes into your commit, and merged it into 0.12.x here: https://github.com/hyperium/hyper/commit/603c3e4d2c6ebb3d495a85c4d9a8b36583eff3fc\nThank you sooo much!. @enzious the executor argument for HttpConnector should not be current_thread, or tokios threadpool. It will spawn IO blocking task on it to do DNS, which would disrupt any async tasks on the executor. The constructor exists to allow sharing a futures-cpupool, instead of it creating a new one.\nThat should definitely be clarified in the docs!. @ChristophWurst I've been wanting to work on a new crate that updates the typed headers of hyper 0.11 to work with http::HeaderMap. However, I eventually decided that that work shouldn't block the 0.12 release, since it brings a lot of really good things, and releasing a new typed header crate later isn't a breaking change.\nI know a few people have tried exploring what that could look like, and I have a small unshared sketch myself that tries to reduce allocations and copies. I really should just open a repo and start collecting those thoughts in the issue tracker.... Alright, most things should actually have some proper documentation, as seen in https://hyper.rs/hyper/master. Additionally, the guides for the main site have been updated, and will be published once 0.12.0 is published. It's so close!. Yea, naming is super hard! :cry: I chose Entity as I noticed its usage in Akka HTTP... \ud83e\udd37\u200d\u2642\ufe0f \nThere is a trait, and a \"default\" implementation, by which this default is used as both a \"recvbody\", and is a fair option for users as a \"sendbody\". Here's a few options I've scrapped together:\n| Trait  | Default Impl |\n| ------------- | ------------- |\n| Entity  | Body  |\n| Payload | Body  |\n| Stream | Body  |\n| Body  | DefaultBody  |\nStream conflicts with futures::Stream, and so would be confusing...\nMaybe a trait name of Payload is best?\n\nIt occurs to me that maybe in the future, a custom base trait wouldn't be needed, and it really could be just a futures::Stream, with traits like PollTrailers existing, and if implemented, they'd be polled, thanks to specialization? I can't say it would all work just as well, as I haven't explored it since specialization isn't stable.. Additional trait name options:\n\nContent (like Content-Length describes the Content)\nTransfer. Thanks!. I've updated the example that will be shown when 0.12 is published!. There is this page in the guides: https://hyper.rs/guides/server/response_strategies/\n\nThat describes a few ways you could stream a body, depending on what constraints you need. Does that answer this question?. In 0.12.x, hyper will move to https Response type. It provides a few methods to do what you're saying, such as map.. > It's not immediately apparent to me why the 2/4 AppVeyor builds failed. Any pointers?\nHm, when it just exists like that with an error code, my assumption is that the process was aborted (either a double panic, or segfault). I'll restart and see poke around.. So, searching for the exit code, its a segfault basically. Derefencing a bad pointer. This might be fixed in https://github.com/tokio-rs/tokio/pull/243. @srijs Awesome work! I started a checklist in the original description to track what is blocking merging this. I realized I didn't know all of what that is, if you'd like to add to this list.... OK, so I'm thinking: screw it, we just merge this, and track that other stuff in new issues. Having it stagnate here doesn't help, and prevents working on newer things that need these changes. So, unless there's objections, I'll just merge as-is in a couple hours :D. @xrl see here for why: https://github.com/hyperium/hyper/issues/1481. Hm, I suppose on the server side, it should be possible to return the service with into_parts, yes.\nCare must be taken by the user since the service manages every request on the connection, and so bugs could exist if you set state on your service incorrectly, but I don't think this change makes this bug any easier to do. You'd have the same possibility with the channel example that you showed initially.\nThe good news is that the into_parts feature hasn't been release on crates.io yet, so changing to Parts<T, S> wouldn't be a breaking change.. I think it's probably best to not try to address that possible issue yet, and see if it is a problem in practice. If it is, we could do something to employ Response::extensions(), but again, I'd leave that for later.. This was done and is part of 0.11.24.. The master branch is now 0.12.x, a work-in-progress. It does not match the release 0.11.22 version.\nYou can view the examples in https://github.com/hyperium/hyper/tree/0.11.x, and https://hyper.rs/guides will always use the current release version.. There's no super easy way currently. You could make a connector that wraps the HttpConnector, accessing the TcpStream there.\nI'd be fine with this being an option on HttpConnector directly .... Woops! Is there a need to have a max buffer size of less than 8kb? There is a performance cost of having to do another cmp::min to determine the init buffer size...\nOr could we just enforce 8kb as the minimum, regardless of config?. @estk thanks for looking into this!\nI think this should probably do this:\n\nin Http::max_buf_size, compare the provided value with the minimum allowed, and use which is bigger.\nIf the value were smaller than allowed minimum, perhaps log a warning or error. It could even panic, using an assert!, I'm not sure which is best.\nAdd a line to the documentation of max_buf_size that the minimum is enforced.\n. This was done in #1489.. hyper doesn't currently support wasm, see #1245.. Yay! Thanks!. Sleeping the thread won't fix it: the connection task (future) that was spawned needs to be polled again, and that can't happen if the Core isn't running.. I don't know exactly where the issue is, but it's fixed in 0.11.25, so I personally wouldn't expend much effort myself to look further XD. Ah yes, I had noticed this as well a little while ago, and forgotten that the fix included that. Generally, implementations of Future should behave correctly if moved to different tasks. . That is a possibility, but otherwise 0.12 is pretty close to ready. There'd also be much less breaking changes... Well, somewhat.\n\nThe question would be how long do we wait? Continue to hold off 1) upgrade to http crate, 2) upgrade to tokio, 3) http2, 4) Send Client?\nThe existing APIs in 0.11 are a little confusing to use.. So, 0.12 will release with futures 0.1 implementations, since 0.2 is considered unstable. Any wishing to using hyper with the unstable futures 0.2 can fairly easily combine it with the futures-compat crate.\nThanks all!. @kamyuentse I kept trying variants, and couldn't seem to get it passing 100% of the time without disabling the exact thing it was testing. And so then I read through it, trying to remember what the heck it was even testing, and realized it was because before inside client/mod.rs there was a tx.start_send(req).unwrap(). That doesn't exist anymore, and the test is really contrived.\nActually, I'm fairly certain the problem is the race condition in futures mpsc queue: https://github.com/rust-lang-nursery/futures-rs/issues/909\nThat'd make sense, since the test was basically dropping the Receiver in a runtime thread, and trying to use the Sender in the test thread, and occasionally seeing deadlocks as the message was never dropped.. Thanks!. Oh, interesting! If tokio's current_thread executor could be updated to use a timer as well, we could probably change all waits to use that, but it doesn't currently do so.. I've also been thinking that hyper could have some common::Timer internal type, kind of like common::Exec. Doing this would probably even be easier than switching all waits over. Benefits:\n\nFiner control over a specific timer, if someone doesn't want to use the implicit default.\nWould support making the tokio Runtime optional, in case someone wanted to build hyper with their own runtime.\nWould allow it to work with wait.\n\nIf no timer were available, timeouts and intervals would effectively just be disabled. That shouldn't be a problem. Here's some code I was thinking of:\n```rust\nenum TimerImpl {\n    Default,\n    Empty,\n    Timer(Arc),\n}\ntrait Timer {\n    type Delay: Future;\n    fn delay(&self, until: Instant) -> Self::Delay;\n}\n```\nThe default would use tokio-timer implicitly, the empty would simply return future::empty(), and the trait would allow for custom timers. We'd implement Timer for tokio_timer::Handle.\nProbably the types wouldn't be exported publicly, but the client and server builders could have timer functions like their respective executor functions.. That's probably fine too. I mostly was thinking that there are cases where you could want to use hyper, but already have some other runtime. For that reason, I do expect to make the tokio dependency optional (enabled by default) likely by the 0.12 release.\nI also figured people might already be using a different timer implementation, such as using the older tokio-core.\nBut it's not required to provide that yet. I just would rather not actually expose a dependency on tokio-timer in a type signature, so I actually would rather box a trait object, like is done with Executor, instead of accepting tokio's TaskExecutor directly.. Talking through this a bit on IRC, here's some clarification. A user likely has various ways they want to declare when to use HTTP/1 vs HTTP/2. A major way to do is with TLS' ALPN mechanism, but that seems best handled in the Connect implementation, since hyper has delegated all transport negotiation and establishment to that trait.\nSome variants a user may need:\n\nHTTP/1 only\nHTTP/2 only\nHTTP/1 or HTTP/2 over ALPN\nHTTP/1 or HTTP/2, with HTTP/1 upgrades to 2\n\nA key part of ALPN is that if a client chooses to use it, it must advertise the protocols it can speak, such as http1,h2. If the server responds back with a protocol identifier, then once the TLS handshake is completed, the connection MUST use that negotiated protocol. So, it ALPN agreed on h2, hyper must use HTTP/2 once the connection is returned from Connect.\nThis means the connector needs some way of telling the hyper::Client if a certain protocol is required. We can make use of the Connected type to include that information.\n\nThere is also a question around how a user configures what variant they need. There is the Destination type, which could gain additional getters so that connectors can know whether to use ALPN. However, a potential downside there is that it seems likely that a user would need to configure their connector anyways, and so why should they need to repeat that configuration on the hyper::Client.\nIt might be sufficient to not have extra configuration on the Client. Of the scenarios above, the only one that seems to require the hyper::Client to know about is No. 4 (HTTP/1 upgrade to HTTP/2).. The caveats you mention sound about right.\nAn alternative to exposing a new type would be to just add negotiated_http1(self) and negotiated_http2(self) on Connected. It's not necessarily better, it just allows for the API to exist without a new Protocol type.\nDoes it make sense at all for the Client to tell a connector that a user configured http2_only or something (another option I've been thinking about is if to implicitly guess the preferred protocol by looking at Request::version())? I suppose if it does make sense eventually, it can always be added to Destination.. Yea, that'd be odd. There could conceptually be an http1_only option, and in that case, if ALPN passed both http1 and h2, and the server supported both, we'd likely have connections that could never work...\nPerhaps that concern can just be postponed, and people can configure their HTTPS connector how to do ALPN in the first place.. I have seen a few other HTTP2 client libraries which easily allow opening multiple h2 connections, but I'm wary about doing that (at least, about making it \"easy\" to accidentally do so). Note the spec pleads that clients shouldn't do that:\n\nClients SHOULD NOT open more than one HTTP/2 connection to a given host and port pair [...]\n\nOf course, since the connection pool is used by a Client, a user could by pass it in hyper by just making a new Client.... Looking over what Golang's client does, it opts for your option 1, which is to just open a bunch of connections if there isn't an existing HTTP2 connection. If after ALPN, it is HTTP2, then the extras are all closed up and only the first connection is kept.\nThat seems simpler to me, and less likely to cause problems for people who were successfully using the client for HTTP/1 already. For @pimeys concern, there's a couple things we could do to prevent that:\n\nIf the Client is configured for http2_only, then ALPN is never needed, and all connections are treated as HTTP2 (so no mass connect flood).\nIf a Client isn't configured that way, we could consider looking to see if Request::version() == Version::HTTP_2, and if so, specifically treat just that request as HTTP2-only.\n\nI also think the HTTP/1-and-HTTP/2-and-HTTP1Upgrade option can be removed from consideration. It turns out to be very seldom implemented, and browsers don't bother, since there exist some servers that naively hate upon seeing any Upgrade header, so it can't be sent proactively just to advertise.. @estk cool!\nI haven't personally thought out an exact implementation yet... One way could be for server::conn::Connection to be able to inspect a returned error, and if it's a parse error, try to take the IO and read buffer back out and use them to try the h2::server::handshake.... Awesome, thanks!. Awesome, thanks!. Is this http1 or 2 connections?. If at all possible, logs from hyper::client::pool,hyper::proto::h2 would probably also help.. The only thing I can think of is that something is holding on a reference to the h2 streams type, and perhaps being stuck in a future that doesn't poll as finished. And then eventually, Apple closes the connection and that triggers the internal h2 streams type to clean itself up.\nI've pushed some minor clean up to master, along with some clearer logs, if you want to take a look.. >  it happens when a dead connection gets a big spike of requests\nWhat determines it is dead? The remote has closed the connection, but the pool hadn't yet cleared out the handle? Or it's reached its expiration and was waiting for the idle interval to clean it up?. For reference, it was noticed that Weak::new() allocates space for the thing that the related Arc<T> would hold, even though Weak::new() can never upgrade to a strong reference by design. The fix in hyper was to create a single Weak::new() per pool, and clone that instead of creating Weak::new()s for every single waiter.\nI've open a PR to libstd to fix this easy to miss issue.. I expected this problem to appear eventually. Clearly, the best thing to happen is for that server software to be fixed. But, I realized that there is likely other janky server software out there that also relies on title case, just rotting with no fix to ever come...\nPossibly a solution could be for hyper to add an configuration option to force all header names to Title Case when writing to the socket. It could be some title_case(dst: &mut Vec<u8>, name: &str) {}, that intercepts and pushes upper-case bytes onto the destination.... It's probably preferable to not have to check a boolean in a loop, so probably a second function.. Since header names are required to be ASCII, you can just work with the bytes directly. That has better performance than char.. Your use case is the client, right? So it could start there...\n\nAdd some sort of http1_title_case_headers method to hyper::client::Builder.\nPass the value of that when constructing the hyper::proto::h1::Conn.\nPass that value to Http1Transaction::decode.. Would you be able to share what versions of hyper and tokio are being used? The exact versions can be found in the Cargo.lock file.. This is just a hunch, and may not be the issue, but I've seen an impact on benchmarks before: try pinning to v0.1.12 of tokio-core. So, in your Cargo.toml, have the line for tokio be tokio-core = \"=0.1.12\".\n\nAfter that version, tokio upgraded to a new reactor implementation. It's actually better in real world situations, since it more fairly distributes work on your system, but when benchmarking with wrk, where the work is always exactly the same, you only notice the cost of a fairer reactor/executor.. Hmmmm, I think for the TechEmpower benchmark, I also had to pin tokio-io directly, I remember some errors... As seen here: https://github.com/TechEmpower/FrameworkBenchmarks/blob/master/frameworks/Rust/hyper/Cargo.toml. Hm, how many threads is the Go version allowed to use? I assume if using tokio-core, you've stuck to 1 thread. That could be a difference.. I'd think that call would actually make the Go app use as many threads as you have CPUs. At least, that's what the docs of that method says.\nAs to hyper itself, I haven't really benchmarked with 1 request per connection, so it is possible there is some low hanging fruit. If I had to guess, it's probably not anything with accepting the connection, and probably something about setting up the HTTP state machine after accepted (and read and write buffers).. Oh interesting. If the version not using hyper performs the same, then yea, it must be at a lower level than hyper.. What would be most helpful would require a bit more time from you, which would be graph a profile or flame graph of the version not using hyper, looking where the app is spending time, and then filing an issue on the repo that owns that method...\nAnother option which might take more or less time, would be to see if a small example could be made just using mio. That'd help to determine if its in tokio, or mio.... The flamegraphs suggest that a lot of time is spent in __libc_close... I'm just guessing wildly at this point, but I wonder if something like setting TCP_NODELAY would have any impact.... Wow, fantastic find. With that, a case could be made on the tokio repo that the TcpListener should perhaps register on level triggered events, instead of edge... Or at least be an option. Care would be needed that someone is actually accepting the sockets as fast as possible, or else epoll would start to waste CPU alerting to an event that the user isn't ready to handle.... Iiiiiiiinteresing... and how well does this play with Github's rendering of the gh-pages branch? As long as there is a force-push and HEAD commit, it doesn't care?. Thanks for coming up with this interesting hack :)\nFor now, I'm going to close, since it's not clear if gh-pages will continue to work correctly.. Good catch, thanks!. The tests in CI failing are unrelated. I'm battling a race condition in the futures mpsc channel implementation, and still haven't gotten it working always, it seems.. It looks good to me, thanks!. Hey, thanks for the detailed write-up! It really helps me to understand what the end goal is. In this case, it seems like a fine feature for an advanced configuration to allow binding to a local address before connecting to a remote. Some jumbled thoughts:\n\nI'd probably suggest that it should be an option when configuring an HttpConnector, and not the Client directly, since it doesn't make sense in a generic fashion.\n\nIt seems we can use TcpStream::connect_std, which doesn't return a boxed future. So, there shouldn't be need to make changes to mio and tokio, right?. Yes, calling Handle::current() at that point is exactly what TcpStream::connect(addr) does internally, so that's fine. The point is just to call it directly before needing it, instead of calling Handle::current() when the HttpConnector is created, since at that point, the reactor may not be setup yet.. What's that message \"Error running reactor core!\" from? What else is this application doing?. Woops, test failures are because the Cargo.toml still references the example that you removed XD. Thanks so much!. The typed headers will also return None if there is a parse error turning it into the typed representation. You can peek at the raw bytes with headers.get_raw(\"Content-Disposition\").. So, that specific error is probably a red herring, but I can explain the problem:\n\n\nThere is a bounds that future being executed be Send. This is because the executor could be a thread pool, and so the future might move to a new thread.\n\nBy wrapping something in Arc, that makes it possible to send copies to different threads at the same time. Both copies would be able to access &T from the Arc<T>.\nIn order for that to be safe, T must be Sync, which states that all accesses of &T are thread-safe.\nSome examples of non-thread-safe &T access: Rc::clone, Cell, RefCell...\nSince those types can actually mutate T through a &T, but don't do so with synchronization, they don't implement Sync.\nBacking out again, that means that if you have an Arc<T>, in order for Arc<T>: Send, the type it is wrapping must be T: Send + Sync.\n\n\nI don't think you'll need an Arc here at all, but instead should be able to pop the service back out of the h1 dispatcher, just like the IO and read buffer.. You shouldn't need to to much with the Dispatch trait. You already know the exact implementation of dispatch, Dispatch<Server<...>>. So, it should be possible to add an impl block for that type directly.\nrust\nimpl<generics> Dispatch<io, etc, Server<S>> {\n    pub fn hello() {}\n}\nThough, it probably does mean the the server:: Connection needs to hold not a Dispatcher directly, but some sort of enum that can allow taking the dispatcher apart even in a &mut self context. An Option works, or occasionally a new enum can be better, depending on if there's more than 2 states, or the names would be ambigious.. Thanks for sticking with this! I maybe should have labelled this hard instead of medium, it seems it's more involved than I originally thought XD\nYes, we'd need some sort of wrapper for the generic AsyncRead + AsyncWrite to allow \"rewinding\" and using the read buffer as the start of the h2 handshake. It should itself be able to be generic, not actually requiring the AddrStream. And if it's built into the internals of the Conn type, it's existence probably doesn't even need to be known. As in, the user would still just see it as Conn<MyIoType, MyService>. Does that make sense? I sometimes don't notice if I glossed over something with not enough detail.. @estk looking at the logs right now, it seems to be complaining about illegal syntax. It looks like a merge conflict was saved, as there's a line like <<<<<<<<<<< HEAD ;). There seems to be some sort of race condition in h2 that sometimes prevents the client connection from completely closing up, resulting in the test server and client just staring at each other until Travis gives up. \ud83d\ude2d . Thanks! Indeed, many have reported this issue, I've so far in the past held out that fn main() -> Result<...> would be here soon, and the problem could start to go away... perhaps that was foolish of me, and this should be fixed to help newcomers, like you said!. I've updated the guides to work with 0.12.x, and I believe I addressed this while doing so.. The example in latest master? I know there can be a way to get it to hang, but example was adjusted to put the Client inside a lazy future run on the executor.. Right, that seems likely. There indeed was a way to hang. That example has since been updated. Try with latest master.. Oh wow, thanks for noticing this! It definitely was just forgotten, and it would have been unfortunate, cause bringing it back would have been a breaking change.. cc @carllerche. Also cc @sfackler, I believe I've noticed you have a custom body implementation.\nSome additional pros of requiring Buf is that a custom Buf is able to know when partial writes happen, and react, because of the advance function. Some examples of what things could do are: update some other flow control mechanism, free some resources, record more exact write stats, or recognize when an error occurs and know how much of a buffer had successfully been written in a drop check.. > confident that the pre-existing writev optimization you mentioned is working well in all the same situations\nSo, sort of. Say you have 2 large chunks available immediately. You can make them available in Payload::poll_data, and hyper will receive them and push them into basically a VecDeque of buffers to write, and then poll_data says NotReady (or Ready(None)), hyper will prepare a flush of its queue, using writev. So, for users that weren't really trying, hyper will already reduce the amount of copies done.\nBut, maybe you have a whole bunch of slices ready immediately. You could push them all individually onto poll_data, and just benefit from the internal VecDeque, but maybe you could gain a little bit of performance if it were just a single Buf (and thus, only a single poll_data call), and have some optimized way of accessing all the slices over hyper's generic VecDeque.\n\nwrapping blocking around the dereferences\n\nhyper doesn't actually dereference the slice, it passes it directly to AsyncWrite::write/AsyncWrite::write_buf. So, for a TcpStream, the dereference would happen in the kernel. If your application anticipates needing to block then, you could provide an AsyncRead + AsyncWrite that wraps its write calls in blocking, and hyper is none-the-wiser.\n\nperhaps using sendfile instead of accessing the bytes at all\n\nI think this would something about Payload, not the individual chunks, right? ... Or, perhaps not, if you needed to send multiple files, or only regions of certain files? I've been thinking about this on and off, and I think it could be done best with specialization. If it is for each Data chunk, then you could have a FileRegion trait implemented on your Data chunk, and AsyncWrite::write_buf can specialize on that trait, like how Vec::extend does.. Oh noes! What version of hyper are you using?\nAnd when you say it panics, where? At one of the unwraps you have, or inside hyper?. What OS is this happening on?. Do you what version of the Linux kernel it is? 0.11.26 tries to set SO_REUSEPORT and SO_REUSEADDR, so that the newer run_threads can work. Looks like SO_REUSEPORT is only in Linux >=3.9?. So, I think https://github.com/hyperium/hyper/commit/2c48101a6ee1269d7c94a0c3e606b2d635b20615 will fix this, if you want to try it out before I just publish a new version assuming it fixes it :). I've published v0.11.27 with the fix mentioned here!. Wrapping the client should mean that the new service provides a new impl Future over the wrapped service. This is a pretty common pattern, which we do a lot of in Conduit. For instance, see this simple timeout middleware: https://github.com/tower-rs/tower/blob/master/tower-timeout/src/lib.rs#L60\nThe reason for hyper's future to have private internals is so that we can change it around, adding new functionality or making optimizations, without being a breaking change.. I actually think all cases make sense, even though they may conflict with each other. Trying to set http1_only(true) and http2_only(true) would of course be invalid. It could be asserted, or it could simply take the latter call.\nThough, separating them could also work.. I think this area is rather subjective. Having written a lot of examples and tests, I think having a way to skip the boilerplate is very appealing. I also wonder if the low-level version is preferable to you because you're familiar with all the pieces, but someone wanting to focus on just handling requests may find it annoying or ugly.\nTurning the question around, is there a reason to not include it?. Thanks! I'll look at this more in the morning.\nAs for performance/stress, I know @pimeys pushes a lot of requests through the client. Though, might be skipping DNS, not sure.. One thought is that using blocking means it only works with the threadpool executor, while there is now also a current_thread runtime.. Can the From<Box<S>> impl that already exists be adjusted to support this case? I just noticed that it specifically for a boxed generic, but we probably don't want that.\nI wonder, can something be done like S: Into<Box<Stream<..>>>? Then boxes don't double box.. Thanks!. The ClientProto stuff is long gone, nothing to worry about there :)\nI've seen others ask to replace the resolve in HttpConnector also, and it would be nice to be do so. The only thing that has held me back is that it would be another trait to need to stabilize. I don't have a good design for one, and haven't spent time trying to solve this, since so far I've figured that just copying the TCP connecting bits from the HttpConnector is pretty simple.\nI'd be open to working this out, though!. > Maybe instead of String it could take an IpAddr?\nIf we already had an IpAddr, we wouldn't need to do resolution, right? :D In fact, hyper does skip resolution if the hostname parses as an IpAddr.\nI think it'd be reasonable to try to include a Resolve trait specifically for HttpConnector. What does it look like? Should it only be allowed to return io::Error, or should it allow any error, like Connect does?\nrust\ntrait Resolve {\n    type Future: Future<Item=Self::Addrs, Error=io::Error>;\n    type Addrs: Iterator<Item=SocketAddr>;\n    fn resolve(&self, host: &str, port: u16) -> Self::Future;\n}\nDoes it make sense to include a port as input? Or should the HttpConnect just override the any port when it receives the SocketAddr?. Great! How does the generic on HttpConnector play out in practice? Annoying? Ignorable?\nI've wanted to be able to change out the default resolver for trust-dns for a while, and besides wanting to wait for it to be as reliable as getaddrinfo, the other problem is some of the constructors for HttpConnector would break. This change could actually make the switch compatible.\nBasically, it could be similar to HashMap that has a default hasher that doesn't otherwise expose what it is, which allowed switching from SipHash-2-4 to 1-3. There could be a DefaultResolver newtype that hides its details, besides a GAI resolver type.\nI'll be of limited availability for the next week, but I'd welcome this change for the 0.12 release if someone would like to make a PR!. This may slip out of 0.12, as it isn't high on my priorities, and I'd like to release this week.. I got around to fleshing this out in #1674.. I think I may have seen this myself, but didn't realize the issue, or rather, assumed it would clean itself up pretty quickly. Seems not!. You should be able to keep keep_alive enabled, and simple disable retry_canceled_requests, right?. I found that this had been fixed on master, so I've backported the changes to the 0.11.x branch. A fix with this has just been published in v0.11.17.. In the usual case, the payload should be polled to completion. Here's the cases I can think of where it wouldn't be:\n\nThere was an error on the connection.\nAfter a poll, is_end_stream claimed it was done.\nThe body was not allowed, such as in response to a HEAD request, or as a 204 or 304 status code.\nThe headers (or the content_length method of the payload) declared a length, and the state machine detects the length has been reached. Any extra chunks would be wasted.. I believe the incoming body could be updated to know when it has ended.. Hm, what version of futures do you have?. Thanks!. Thanks for the PR! I wonder, does the added text clarify much? It might be that I'm biased, but I'm used to example code at a certain commit in a repo to always work with that version of the code, not necessarily what is published.\n\nMaybe there is some value in reminding people of that... What do you think of that message being in examples/README.md directly?. Hm, it would be nice if Request<CloneableBody> were Clone, that's true! But, I think Extensions are going to prevent that from being possible.\nOtherwise, I think your approach is very similar to what I would do myself!. Thanks for catching this!. This is known, and why I called it a very naive proxy. It can only work if the proxy received an absolute-form request target. That is what is described as well in RFC7230. A proper proxy would also handle relative URIs, assuming they were trying to talk directly to the proxy.. Thanks, I'm sure this would be useful! I actually think it might be better to just replace the existing send file example with this one, as it is better in most ways. What do you think?. Thanks so much, this looks great! \u2764\ufe0f . Hm, that code isn't doing anything unsafe... \n@carllerche possibly a threadpool bug?. I, uh... wat? If this happens with thread locals, shouldn't it also occur often with the futures crate accessing the current task, and in Tokio accessing the current reactor and timer and stuff?\nSorry for the false alarm about the Tokio threadpool.. So, can I just close this as a bug in macOS?. Thanks for the excellent PR, I appreciate the fine details, like the design of the enum and the doc comments! <3. What version of hyper are you using?. If trying to use 0.12, the reason the import doesn't work is because it is no longer there.. I definitely get what you mean! It's also difficult to enforce it through the type system... or did you mean that it should assert earlier, at construction time?. Thank you so much, this is great!. Yes, this is expected. The HeaderName from the http crate keeps things lowercase for performance and compatibility with HTTP2.\nHTTP/1 clients and servers should work just fine with any case, since RFC7230 declares them as case-insensitive. There are the occasional clients or servers that erroneously require title case headers. There was a config option added for the client to use title case, and if there's need, we can also add a server option. . Adding the option to the server is... kind of \"easy\", in that it can make use of the title case function used by the client encoding. The only tricky part I see is that the Server::encode function is highly optimized, so checking a boolean in a loop may be unfortunate. I wonder if there's something clever that can be done to avoid that.. The reason for the change is because those bounds are both what the futures crate and Tokio were both moving towards for the Executor trait. I realize it is a bit more inconvenient, and I don't especially love needing to require them. It didn't seem like there was a good solution otherwise, but I'm always open to hearing some.. The NewService gets called for every connection, so it cannot be FnOnce. You could either construct a new Service each time, or if you want to share some state, then you could clone it.. I saw mention of this in IRC, it seems you can't downcast the cause because Error::cause() doesn't return a Error + 'static, right?\nWhat if hyper::Error were to get a cause_static (sorry, naming is hard) method, kind of like std::io::Error::get_ref, to allow downcasting?. I'm not especially against some form of as_io_error, I was just thinking that people may wish to access the errors they created themselves, like from a Payload or Service, and suggested something that might solve all cases.. Yay, thanks!. Related #1542 . While I don't foresee any plans to add additional types to the chain, the issue you describe could also happen directly inside hyper. We'd need some way to make sure as_io_error handled any intermediate types that were added, and it'd be just as easy to miss.. Exactly as @lnicola said. This is about when a user receives a hyper::Body from hyper, the <Body as Payload>::content_length() call can try to give more information. This is especially useful if using that body to stream to a different message, such as in a proxy, having made a client request, and gotten a response back, and then returning that body as your own server's body.\nAs the documentation of content_length says, it's OK to not know the answer. It's just a hint to allow hyper to add a content-length header if not present. This in turn means that several common body cases will include a content-length header without forcing the user to remember it (like returning Body::from(\"hello world\").. Hey there! You have the exact same source as https://github.com/hyperium/hyper/blob/master/examples/client.rs ? We have CI run on every commit, and it's compiling. I suspect something may have snuck in. For instance, a semi colon on the end of the client request chain.\nZooming out, the error is that future::lazy requires the returned result of the closure to implement IntoFuture, but instead, () is being returned. () is implicitly returned if nothing is returned, as well.. So, I have discovered that CONNECT requests don't actually trigger the upgrade code like responding with a 101 does. Woops!\nI've got a new test for that, and a fix, which should at least get that part working. I haven't yet seen this assert triggered, though.. The newest commit to master includes a fix to treat CONNECTs as upgrades.. And the next commit after that, I believe I found what was triggering the debug assert. The connection had replied once with a response, and so cached the header map allocation to be used for a new request. Then, the connection, since it wasn't \"upgraded\", treated the next read bytes an HTTP parse error, trying to write a 400 response. When writing the response, the debug assert noticed I had \"forgotten\" to re-use the cached headers.. Thanks!. Great, thanks!. Excellent!. Sorry, it seems github doesn't send notifications about rebased/ammended commits. I'll look now.. Thanks!. Thanks!. Hey there! Do you have some details to your question? Without them, I'm not sure how to answer other than \"you just use it\" :D. Help me help you.. My first guess is if there could be a version conflict. What version of the futures crate do you have declared? hyper uses 0.1. A future returned by 0.2 does not implement the 0.1 trait.. @CasterKKK nope, see #1481 for context.. For what it's worth, I've been working on a branch to add HTTP upgrades to a higher-level API, such as Client and Server. It's relying on the transport being AsyncRead + AsyncWrite + Send + 'static to allow passing it as a boxed trait object in the Body. Removing these bounds here would make the current approach impossible.\nIs there need for the IO type to be !Send?. Hi there! A stable version (1.0) in some sense is getting closer.\n\nMost of the types (Method, StatusCode, HeaderMap, Request, Response, etc) have moved to the http crate, and are quite stable. I wouldn't expect much changes other than very minor paper cuts fixed when we mark that as http v1.0.\nThe Client and Server types have seen some re-design, but are in a much better place. I suspect they also won't change too much more, other than cleaning up some configuration options.\nThe big unstable part is around futures. There is a plan to move them to std::future, and have language support for async/await. However, this will mean a big change to the ecosystem from the current futures v0.1 crate. This is the main blocker affecting everything, really.\n\nAfter future is able to stabilize, I suspect a hyper v1.0 wouldn't be too far behind.. I definitely get the use case! I'd like to find a way to support it, but I'd also like to list why the constructor was so far private:\n\nThe Destination type may gain more fields, such as in #1485 to support ALPN.\nI worried that if a Destination gained more fields in new release, and a connector didn't know that and could create their own, then it could be possible for some intent on the connect action could be silently lost.\n\nWhat if, without adding a constructor, you could just mutate the internal URI of the Destination?. Thanks for the detailed PR, I really appreciated it!\nI'm not sure about (but could be convinced otherwise!) having the docs suggesting that you should reach for block_on. In general, you should most often be writing asynchronous code to be async, and to need to spawn into an executor, and so by showing that you can use block_on sometimes, I fear it promotes the wrong idea.\nEspecially since you can easily think that you could use block_on anywhere, but if you're inside another future already on the executor, you actually can't! It will panic, of course, but we've already taught a user the wrong pattern, and they may then have difficulty fixing it.. I appreciate several of the word clarifications you've made here. However, I actually think the docs should recommend that a user use run or spawn, and not block_on.\nAs I mentioned in #1568, if the concern is about forgetting to put it in a lazy future, then perhaps it'd be enough to just include a line comment about that above the lazy(|| { line.. Thanks for the efforts to improve the documentation, I greatly appreciate it! I'm going to close this for now, and allow discussion to happen in #1571. If we find ways in that issue to improve things, new PRs can always be submitted.. The panic is coming from calling tokio::spawn inside the client connection pool that is trying to spawn a timeout to remove the idle connection after a delay. tokio::spawn will panic if it called while there is no active executor.\nThe reason this is happening in your example is because after getting the Response, the Core is being dropped.\nNote that the body.concat2() likely isn't doing what you think, since that just returns a new future, Concat2<Body>. It still needs to polled to get the final concatenated body out of it.. So I've repurposed this issue to track some change that could be done in hyper to make these errors clear.\nIf a user doesn't configure to use a custom Executor, then the implicit default is used inside common::Exec. These changes could be made:\n\nChange Exec::execute to return Result<(), ::Error>, instead of panicking on error.\nIn most cases where spawning would have been critical, return the error back up to the user.\nIf the spawn wasn't critical (like the pool idle interval), log the error and ignore.\nAdd an Execute variant to hyper::Error.. What version of hyper are you using? The latest version, 0.12, doesn't use tokio_core anymore, and doesn't need to own a reactor, but instead is better at supporting an external reactor.. The last part isn't quite true. You can use tokio-core along with tokio. What you can't do, is try to call Core::run() from inside a future that is already executing on a tokio executor.. I think there is value in showing in the examples that you can just use run in many cases. Since the concern is around forgetting to put a Client in a lazy future and thus keeping the runtime from shutting down, what if there was just a comment added at that line about that?. Thanks for the efforts to improve the documentation, I greatly appreciate it! I'm going to close this for now, and allow discussion to happen in #1571. If we find ways in that issue to improve things, new PRs can always be submitted.. Thanks for starting this up!\n\nThis may be the simple way forward, I just want to discuss the pros and cons. In this case, a user can construct a Uri themselves, and then easily set it. What happens if they did so without a scheme or authority? dest.set_uri(Uri::default() would set it to /. Is that a problem? Should other connectors be able to handle empty string for scheme and host?\nA possible alternative is to take a string instead, fn set_uri(&mut self, s: &str) -> Result<(), hyper::Error>. This could require absolute URIs, and return an error otherwise. But maybe it's fine to make connectors have to deal with empty strings.\nThoughts?\ncc @sfackler . I like that. Is there a good use for having set_scheme as well?. You can convert the current URI into it's parts, and then you can parse the new one and insert it, and try to convert back into a URI. If it's illegal, that should return an error already.. I wrote the suggested changes up over in https://github.com/hyperium/hyper/pull/1572.. I have thought about it briefly, and as you mentioned, I worried about the generally much longer blocking of a DNS lookup vs reading a file that may be in cache.\nHowever, as mentioned, this would prevent the connector from working with any other executor.. I'm going to close for now, since making HttpConnector require tokio-threadpool is not really possible. It should be possible to explore a separate connector that does what this issue describes, though!. I agree with the sentiment of better explaining how to execute asynchronous client futures. As stated in the linked PRs, I'm not sure using block_on is the best thing to teach users, but it definitely is too tricky that the examples use futures::lazy without explaining why.\nWhen looking at the doc example, what would users likely be trying to do? Just getting a simple fetch in fn main working? Or perhaps trying to tie in some asynchronous requests with the rest of an app?\nPerhaps the docs the can be updated to suggest looking at the examples/client.rs for a \"here's a simple fn main example\", and that example could be updated with a comment about why rt::lazy is used. Then, the doc example could instead show that the futures should be spawned, removing rt::run and rt::lazy, and just using rt::spawn.. I'm sorry if my reluctance seems rude, I'm not trying to be! Throughout the lifetime of hyper 0.11, and future.wait() and core.run(fut), the issue tracker has received bug reports of when users inappropriately used those synchronous tools. I've gotten plenty of personal email asking about the same, and people would show in the IRC channel likewise having the same confusion.\nSo, I'm afraid of promoting these blocking tools, as they can easily lead to bugs, and then people blame hyper for being a piece of crap. ;)\nI do agree that block_on is very useful when writing tests, but I personally feel that the docs and examples should be guiding people towards using the Future combinators whenever they don't have the value right away. It seems to come up super often in server, when people want to return a Response, but only after getting the body, so they reach for a blocking utility, and harm the server (if it still works at all).. Thanks for starting on this!\nSo, I actually think this specific code can be de-duplicated (and it's need on later checks anyways) in the PipetoSendStream future. The idea is that if we would park the task (return Async::NotReady) because the Payload didn't have a chunk ready, we should also be sure to register the task to be notified of a RST_STREAM (by calling poll_reset). That way, whichever happens first will notify the task. Without the second part, we would keep waiting on the Payloads data even if the remote closed the h2 stream.\nI don't think much more is needed for the Client, since we're otherwise just always waiting on the remote to either give us data or reset.\nThe server does need a check: once the Service::call returns a Future<Item=Response>, and we've polled it and gotten that it's NotReady, that means we'll just wait for the user's service code to finish computing the details needed to reply. While waiting for that, it'd be best to always make sure (by poll_reset) that the remote doesn't stop caring early, and if they do, we can just drop the Service::Future, canceling it's work.\nDid I make sense?. @joshleeb yep, that's the right direction! The new spawned task H2Stream polls the user's service future until a Response is ready:\nhttps://github.com/hyperium/hyper/blob/ac1af8d15b768f5ba83345ff0af2f3a9a89d4ddf/src/proto/h2/server.rs#L177\nInstead of just try_ready, that should be update such that if it isn't ready, we also check self.reply.poll_reset. If the remote sent a RST_STREAM, the H2Stream future can just finish up immediately (which makes it drop, dropping the service future, canceling any work it was doing).. Thanks!. (Just tossing this in here, while it's annoying to have configure manually, there is #1485 to discuss an API to allow enabling it more automatically.). Since this seems like it's not a bug in hyper, I'm going to close. There is #1485 to track adding ALPN support to the Client.. TCP ports that are bound often have a property of not fully closing when asked to, so that OS can handle any late packets inbound to that port. There is a socket option to tell the OS \"Hey, it's really OK if I reuse the port right away\". You could try setting that option to see if that's the issue (it could also just be a bug in hyper or tokio).\nAnd... I just checked, and hyper's built-in listener builder doesn't have a way to set that option, but you could build a custom one (and if it works, we can add that method into hyper directly!):\n```rust\nextern crate net2;\nextern crate tokio;\n// hyper and stuff of course...\nuse tokio::net::TcpListener;\nfn listener() -> io::Result {\n     // whatever addr\n    let addr = SocketAddr::from(([127, 0, 0, 1], 3030));\n    net2::TcpBuilder::new_v4()?\n        .reuse_address(true)?\n        .bind(&addr)?\n        .listen(1024).and_then(|listener| {\n            TcpListener::from_std(listener, &Default::default())\n        })\n}\n// making a server with a custom listener\nlet incoming = listener()?.incoming();\nlet opts = hyper::server::conn::Http::new();\nlet server = hyper::server::Builder::new(incoming, opts)\n  .serve(new_service);\n```\n\nPS, calling Runtime::shutdown_now() is an abortive shutdown. It doesn't provide any of the resources in it a chance to tell peers it's going away. It forcibly closes all sockets at whatever state they are in. Maybe that's what you're looking for, but thought I'd point it out.. Since the Server is just a Future, you could create some other signal to notify shutdown, and then server.select2(shutdown_signal) before spawning it in the runtime.\nThere is a concept of graceful shutdown in hyper, specifically on individual Connection futures, but we haven't yet come up with an API on Server to signal all connections to gracefully shutdown. I'd like for that API to exist, though!. Likewise, since Conduit is currently using the Connections instead of Server, we make use of graceful_shutdown with this drain::Watch concept.\nI think something just like it could be ported to hyper's Server, bringing this to everyone (and Conduit would be one piece closer to not needing the lower-level APIs)!. With 0.12.2, it should be possible to mutate the Destination before passing it to the next one. There are setters.. hyper doesn't automatically decode or encode anything besides Transfer-Encoding: chunked. To handle zipped content, you'd need to pass chunks you receive in the Request to something that can decode, and likewise pass content to something that can encode before being used as a body in the Response.\nFor the Response, it's possible to implement hyper::body::Payload to encapsulate that encoding, instead of passing a hyper::Body directly in the Response.\n(As this isn't a bug in hyper, I'm going to close the issue.). It does seem like either we could add a second example in examples/, or add a better second guide at https://hyper.rs/guides/client/`.\nFor an immediate answer, you've got two-ish easy possibilities:\n\nStream::concat2: returns a Future<Item=Chunk>, so that at the end, all the data of the body has been conbined into a single buffer, allowing to easily then pass into serde_json.\nStream::collect: returns a Future<Item=Vec<Chunk>>, where you have a list of buffers of the full body, but not yet combined into a single buffer. This second option can be useful if you don't need to copy all the bytes into a single buffer, in which case this reduces a bunch of copies, but can be a little more difficult if you really need a single buffer.\n\nAn example using the first:\nrust\nclient\n    .get(uri)\n    .and_then(|res| {\n        res.into_body().concat2()\n    })\n    .and_then(|body| {\n        // try to parse as json, perhaps with serde_json\n        serde_json::from_slice(&body)\n            .map_err(|e| handle_json_error(e))\n    })\nFor anyone wanting this already implemented, you may wish to look at reqwest, which has this built-n as Response::json()\n. @brandonros fair. The example merged is nearly that. If you wanted, I'd be fine with the fetch_json to be changed to return impl Future<Item=Vec<User>, Error=Box<std::error::Error>>.. Now that looks odd. Box<Trait> should be fine and assume 'static... I wonder if the rules are different when returning impl Trait<Types>? Perhaps Box<std::error::Error + 'static>?\nEither way, the code would need to be updated slightly, since there's 2 different error types needing to be coerced into a Box<Error>. But would the change I mentioned be what you were looking for?. The \"message is incomplete\" error usually means the message read from the server wasn't complete... That's likely the problem we should look at!\nFor the second question, there's nothing wrong with specifying the content-length the way you did. However, it's not needed, since the body is Body::empty().. Thank you!. Thanks for the great description! I've thought about this before, and wondered about inserting the \"lost\" connect tasks into the pool anyways, to allow other checkouts to use it. Think that would also help this issue out?. That's true... A custom lazy future could be used for the connect call, that the select can then inspect to see if it had been started yet, to determine whether it should spawn into the executor to finish up the connect, I think.. FWIW, I have something locally now that does what I described, but coming up with a test case is tricky.... OK, finally got a test case working (bleck!), and filed PR https://github.com/hyperium/hyper/pull/1585.\nI believe making better use of \"lost\" connect futures will result in better performance and system health overall, over disabling the race feature directly. What do you think?. Yep! Just fixing up some other minor things I've noticed, but should be soon!. @DarrenTsung published v0.12.4 just now!. First step is that the h2 dependency would need Push support: https://github.com/carllerche/h2/issues/291. Yikes, definitely a bug! Thanks for pointing this out!\nI'm currently thinking that in the parse code, headers that have an empty value should just be dropped, as there's no real value in it.... Setup a test case for this, and it turns out to not be the problem. It's actually the missing reason code. It's thinking a header name is 302\\r\\nServer.... The parse bug has been fixed in httparse, released as 1.3.2. A cargo update will bring the fix in for anyone!. Thank you! Would you mind also updating the examples/README.md with a short description about what it is?. Awesome thank you!. It's worth remembering that Future::wait is convenient in some places, but it definitely SHOULD NOT be used if this is part of server code. Best case, you pause all concurrent requests on your server for some time, worse case, you deadlock the server if the future you're waiting for needs the current thread to be polling a different future in order to fullfill it.. Would you be able to capture the request and response headers? Bonus points if you could capture the logs from hyper (like using env_logger with RUST_LOG=hyper).\nAs for a benchmark tool, I have actually had problems with ab. I personally find wrk to be much better.. > for bigger file responses were split between several packets, also I've seen there several connection resets\nAh OK, so yes, with a ~90KB file, it will be sent over multiple packets (frequent packet size is much smaller, around 4-8KB).\nI re-read your original message, and noticed you're seeing timeouts. What's the timeout that ab is waiting? Is it shorter than it takes to read the full file from disk?. I can't see anything that suggests the issue is in hyper. It seems the tools are just closing connections. If I'm wrong, and an issue is identified, we can re-open!. The point of the error is to suggest that parsing of the response started, but then the connection was closed before the response completed. (I say point because it's possible there's a bug in hyper :)).\nIt'd be useful to see what the responses look like that cause the error message.. Some pieces of information would likely be very common. The two that come to mind are remote_addr and local_addr (is knowing the locally bound port sufficiently useful to be it's own thing)? However, a custom transport could have arbitrary information it could wish to advertise (like some details specific to a certain TLS implementation). I can think of a few ways that all this could be exposed:\n1. ConnectionInfo + optional \"extra\" info in extensions\nHave the \"common\" information be specific fields, and allow a user to get them from a Response by the API exposed here, ConnectionInfo::get(&res). The \"extra\" custom transport data would just be available through the normal res.extensions() API.\n\nPros:\nIt's very likely most transports can set the common data, like remote_addr, and so if that is all a user is interested in, then changing transports won't affect the existence of the values.\nCons:\nIf a transport can provide both the common info, and wants to provide extra info, it results in multiple allocations, storing both Box<ConnectionInfo as Any> and Box<SomeTransportExtra as Any> separately in the extensions.\n\nExample:\nrust\n// a transport:\nlet info = Connected::new()\n    .remote_addr(remote)\n    .local_addr(local)\n    .extra(RustlsExtraSomething::from(&conn));\nrust\n// getting from a Response\nlet common = hyper::ext::ConnectionInfo::get(&res);\nprintln!(\"remote={:?}, local={:?}\", common.remote_addr(), common.local_addr());\nlet extra = res.extensions().get::<RustlsExtraSomething>();\n2. A single custom \"extra\" info contains all the values a transport can provided.\nDo away with the ConnectionInfo type proposed here, and just have all info from the transport exist as a single value in res.extensions().\n\nPros:\nReduces the amount of allocations needed to provide transport info in extensions to just 1.\nCons:\nChanging transports means needing to remember to change what type is fetched from extensions.\n\nExample:\nrust\n// for a transport\nlet info = Connected::new()\n    .extra(RustlsExtraSomething::from(&conn));\nrust\n// getting from a Response\nif let Some(extra) = res.extensions().get::<RustlsExtraSomething>() {\n    println!(\n        \"remote = {:?}, local = {:?}, cert = {:?}\",\n        extra.remote,\n        extra.local,\n        extra.cert,\n    );\n}. Alternative 2 is explored in #1594.. Thank you!. @sfackler I'd been waiting on the work in Linkerd to test it out before merging, in case there were any changes needed. It also allows for people to tell me it's a good or stupid idea :D. This is a PR for the client, so I don't think it will help with that feature in warp.... Perhaps this could be added to the web_api example that already exists? That probably could use some cleanup, and some comments explaining what each part does... But it otherwise seems like a good fit for this.. Excellent, thanks!. Thank you! \\o/. Awesome work, thanks! With regards to testing, I peeked at what Golang does. They make use of some special reserved IP addresses to test their happy eyeballs implementation: https://github.com/golang/go/blob/master/src/net/dial_test.go#L136\nWould that help inspire some tests here?. > Instead, I can write a test directly for ConnectingTcp. It would remove need for this test-only custom resolver, but would mix this integration test with other unit tests.\nI think this way sounds much better! I have no problem with inner tests when testing very specific behavior that is difficult to simulate in the integration tests.. I haven't thought this through at all, so some questions: would this cause problems for people who weren't expecting this? Could people assume that they normally would have different ports? If so, perhaps this would just be an option on HttpConnector?. hyper-tls has a constructor that allows you configure a connector first, so it wouldn't need any changes.. Looks great, thanks!. Thanks!. Yea, as the example pasted shows, this is currently possible. It's this method here: https://docs.rs/hyper/0.12.*/hyper/server/struct.Server.html#method.builder\nPerhaps it could be clearer explained that this is how you do that? Maybe the server module documentation should mention building a server with a custom listener?. I think the last option seems the nicest, since it is sort of boilerplate to just convert a std::net::TcpListener into a tokio one. I don't know if it should such a prized method name as listen... Some possible name options:\n\nServer::tcp\nServer::from_std\nServer::from_std_tcp\n\nMaybe something else, I don't know!. Hey there! It seems you're looking for something different, a game called Hyperium, whereas this project is about https://hyper.rs, an HTTP library in the Rust programming language. I don't know where to point you, though, as a quick google search suggests there's various games with the name.. So far, I've figured people could depend on the http crate directly if they needed the less common types. What do you propose the exports would look like if re-exporting the whole crate?. Ah, sorry. You asked about re-exporting all of http. What do propose the export would be? Just hyper::http? Or something different?. I suppose a pub extern crate http; would be fine... Would you like to change this PR to do that?. Sorry for forgetting about this, I've made a tiny tweak and merged this manually to master. Thanks!. Hey there! You're right to be hesitant about simply concatenating the full body in memory. There isn't currently anything in hyper to do this sort of thing, but the building blocks are there.\nYou'd essentially want to poll for a chunk, and with each chunk, determine if you could parse a JSON object from it. If not, you'll want to just buffer that, and poll for a new one. Also may be worth looking at #1335 as well, that has some example code to do this.. Hm! Does it happen if you don't do the first request (wondering if it's a bug in a kept-alive connection)?\nWould you be able to dump hyper's logs? Adding a crate like env_logger, and then re-running with RUST_LOG=hyper would show them (you may wish to scrub them for any secrets they show before pasting back).. Aha! The logs suggest that it gets as far as trying to establish a connection, and then errors. So, it's failing at either the TCP or the TLS handshake. It seems likely its the TLS handshake, since the error for TCP would have been more descriptive.. If it is a bug in the TLS library, that'd be where to file about that. However, it might not necessarily be a bug, and instead just require you configure the TLS connector specifically for whatever the Custom Speech API might need.. I'm going to close as it doesn't seem like a bug in hyper, but if you have more questions, ask :). Doh! Thanks for the report!. Thanks so much! :heart:. The difference here is that in HTTP/1.1, a literal host header is sent by curl, and in HTTP2, it is not. Here's a pseudo translation of the two versions:\nGET /foo HTTP/1.1\nhost: localhost:3000\nGET http://localhost:3000/foo HTTP/2\nSo, in HTTP2 requests, the info that used to be sent in a host header is now in the URI authority. That's why you see it when printing req.uri().authority().. Yea, as mentioned, the original values should be left in place, since you might actually want to know them.\nSo far this hasn't been provided by hyper because knowing the scheme and host in HTTP/1.1 isn't always possible, unless the server has some more knowledge up front, like whether TLS is used, or the specific hostname that the server should be handling. Without that info, it seems like an API would have to return perhaps an Option<Uri>, or perhaps the function could ask for the extra information as arguments to use if the request doesn't include it.\nDoes such an API seem useful to be part of hyper directly? I'm neither for nor against, but if it is included here, those questions need to be handled.. Good point! Where is a good place for this to appear? In the module documentation of hyper::rt?. Yikes, you're right! Seems there's two parts to this bug:\n\nWhen the version is HTTP/1.0, and the response didn't send Connection: keep-alive, it should have closed the connection.\nWhen coercing an HTTP/1.1 response to HTTP/1.0 because that's what the client speaks, a Connection: keep-alive header should be added.\n\nProbably the best place to do this is in Conn::enforce_version. If enforcing 1.0, then check for the response version. If also 1.0, then check for Connection: keep-alive, and it not present, call self.state.disable_keep_alive(). If the response is 1.1, then translating to 1.1 should add Connection: keep-alive if self.state.wants_keep_alive() is true. . I tried out your code, and true enough, using current_thread::block_on_all(fut) does not work. It seems that contrary to what the tokio docs say, calling tokio::spawn from inside appears to be failing.. The problem turns out to have been using tokio_current_thread, just the executor, and not using a runtime. Using tokio::runtime::current_thread works correctly.. Strange. At least, the logs suggest that after writing the request bytes, trying to read showed Ok(0), implying the connection being closed, and thus not able to return a response. Do you know if these are new connections, or previously used and taken from the pool?. Is it easy to tell if this also happens without TLS (or with a different TLS implementation)?. Ok! I noticed that issue in std was fixed that should optimize clear better. I guess it won't be available until... Rust 1.30?. This sort of sounds like https://github.com/carllerche/h2/pull/295, which the fix was just published in h2 v0.1.11 this week. Do you know if using that version fixes this?. Yikes, well alright, I filed https://github.com/carllerche/h2/issues/300 to look into it.. This was fixed upstream, and released as h2 v0.1.12. A cargo update -p h2 should fix this up.. So, this isn't a case of hyper (or the http crate) not giving you the fragment. Instead, the browser will never send you the fragment during the redirect. The browser when it gets the redirect will do a GET /your-redirect-uri, but won't send the fragment. It will provide the fragment to the JavaScript application that is loaded.\nThe token flow is not meant for servers, but rather just to get API access in a front-end application. If the server needs access to the API, that's what the code flow is for.\nThis is quite common in OAuth2, and Microsoft's version is no different. They are all aware that fragments aren't sent to servers, as defined in RFC 7230:\n\n[...] a user agent would resolve to its absolute form in order to obtain the \"target URI\". The target URI excludes the reference's fragment component, if any, since fragment identifiers are reserved for client-side processing.. Thanks for starting this!\n\nI've been very conservative with requiring new compiler versions, so I hadn't done this yet. I'd been meaning to look into if it was possible maybe with a macro and and config set at in build.rs to use Box<Trait> until 1.26, when it can become impl Trait.. >  to be able to construct a Response, there, I have to use Response::builder()\nYou can also construct a Response directly, and mutate it without the builder. For your example:\nrust\nlet mut res = Response::new(Body::from(some_str));\n*res.status_mut() = StatusCode::BAD_REQUEST;\nThe purpose of the builder is to provide an alternative, \"easier\" way of building requests and responses, where the errors returned are usually always going to be programmer errors. For that reason, the examples that show unwrapping is because in those examples, any error is a mistake in the program, and should just panic quickly. For instance, doing something like Response::builder().status(1337). (The reason it returns an error instead of panicking internally is to allow the user to decide when to panic, or to try to use the builder with untrusted inputs without panicking.)\nSeeing as your example is likely for a server, you probably don't want to return an http::Error for a server. Returning any error in the Service will tell hyper to tear down the connection immediately, whereas most servers would rather send back some 500 response because an internal error.. Thanks for starting this!\n\nBox<dyn error::Error>\n\nThis is likely the reason CI is failing, it's not compatible with the minimum supported Rust version. I'd change to returning hyper::Error, using hyper::Error::new_listen().\n\nRuntime features\n\nThese enable tokio support, it can be disabled if people wish to use hyper with a different runtime.\n\nRustfmt\n\nLast time I tried out rustfmt (admittedly a while ago), it broke some things. I've just pushed a .rustfmt.toml file to master that should disable rustfmt for everyone in hyper for now. When it's released stable, I'll re-enable it. That should also make it easier for you to work in the repo without making unrelated style changes.\n\nBuilder<tokio_tcp::Incoming>\n\nThis is probably fine! Or... I mean, maybe it could be converted to the internal AddrIncoming automatically, which could make it easier to eventually configure the extra features AddrIncoming provides? I'm uncertain.. Thank you! \\o/. The issue here is using tokio-current-thread by itself, when a runtime is needed instead.. For an idle timeout in HTTP2, having the AsyncRead register a timeout for something longer than a request should ever take could work, right? Like, if the timeout is 5 minutes (or 10 or something), that should be long enough to not interrupt requests?. That does seem reasonable. So far, punting on timeout support has had the benefit of not being tied to a specific timer (or runtime). The core of hyper still works if you disable the runtime feature, but I think using tokio-timer for these timeouts internally would change that.. Thanks! Silly docs.rs..... Hm, I'm trying to reproduce, but setting http1_only(true) and then sending an HTTP2 request seems to be erroring, as expected.... Ah, hyper doesn't know anything about ALPN, you'd need to configure that in the TLS acceptor. The options in hyper are telling it what protocols to allow internally. The default is that if the transport sends HTTP/1 or HTTP/2 (after any decrypting or whatever the transport may do), it just works. The http{1,2}_only() methods are there in case for some reason you would rather that hyper tear down the connection if the protocol is different.. Those bytes look a lot like the initial SETTINGS frame an HTTP2 server would respond with.... > So, it comes down to what erroring means here?\nPerhaps! Do you have a suggestion on what should be changed here?. I agree with that. So, it seems the issue in this case is that if the client sends a HTTP/1 request, and hyper is told to only use HTTP/2, hyper will actually write the HTTP2 SETTINGS frame before realizing that incoming bytes weren't HTTP2. Does that sound right?. So the behavior seen here is happening in the h2 dependency. It's currently setup to first flush the server preface, and then read the client preface. This means the HTTP2 preface would be written to every connection here, without checking if it sent an HTTP2 preface itself.\nIf worth fixing, it'd just require swapping the order in h2. I'm going to close this here in hyper as there's nothing hyper itself can do, besides peeking for a preface before handing off to h2.. I see two TLS dependencies, does it happen with both? If so, that'd imply the bug is in hyper. If only one, that'd imply the bug is in that TLS lib.. In the linked actix issue, it appears they also noticed that switching to openssl fixed it, suggesting there might be a bug in rustls. I don't know if there is already a ticket open there.. Seems to be fixed in those versions, so I'm going to close this up. Thanks for looking into it!. The rt docs link to Tokio, which would allow anyone to read up on how to customize a Tokio runtime.. hyper's Server can be constructed with any sort of \"incoming\" stream of connections, such as what hyperlocal provides. Considering this flexibility, and that using unix domain sockets isn't actually the common case, it has seemed sufficient to leave this functionality outside of the hyper crate. I'm going to close this, as essentially a duplicate of #126.. Awesome PR, thanks so much!. > I (believe I) have to wait for the body to be ready before I can deserialise it\nCan you instead just change your Future that passes the response for the server back?  You shouldn't need to return a response immediately, that's the whole point of being able to return a Future. The server echo guide has examples of cases where you wouldn't be able to respond immediately, returning a new future.. To consume the body, you can use req.into_body(). The req.body_mut() only gives a mutable borrow, and so the future won't last longer than the end of the function (but you wish to return the future, so borrow checker is angry).. I don't have macOS, or any iDevice, to be able to investigate and help.... Yea, as you noticed, calling map_err will give you a new future type, MapErr<hyper::Server<..>, impl Fn>, which then can't call any methods on the hyper::Server.. Yep, looks like hyper is being too eager here.. Thanks!. Thanks!. If you want what existed in 0.11, you simply would \"select\" on your signal with the Server future, something like this:\nrust\nlet fut = server.select(rx.then(|_| Ok(())));\ntokio::spawn(fut); // or tokio::run, or whatever\nThe new with_graceful_shutdown that will be released soon will ease this, but will also gracefully close the connections instead of abruptly canceling them.. That's probably from Future::select, which yields (Item, NotFinishedFuture). You can just map that to ().. This is because rt::run (which is really tokio::run) will wait until all futures have finished. If you specifically want to only run until that specific future is finished, you can use Runtime::block_on.. Related, v0.12.9 is now published, making with_graceful_shutdown also available.\nI'm going to close this, as it doesn't seem like there's a bug in hyper.. Oh woops, I missed the initial opening, sorry!\nI think this can be largely accomplished by either a) implementing Payload for a custom type, or b) use a custom Stream and Body::wrap_stream.. Supporting conditional requests is certainly useful, but I think it may be out of scope for hyper. It should be possible to do this entirely outside of hyper (as shown by Servo's implementation).\nIt might be cool to see if Servo would be interested in extracting it's cache implementation into a library.. Sorry for taking so long to get to this, it slipped out of my notifications.\nI'd probably be more in favor of #1517, which allows for plugging in some custom DNS resolving logic, instead of adding more and more knobs to the HttpConnector (especially since I tried searching for other HTTP libraries to see if they handled this, and most seem to just allow plugging in a resolver).. This panic is when debug assertions are enabled (yay for catching bugs!), fix submitted to http crate: https://github.com/hyperium/http/pull/244. The idea of passing an argument to the NewService is being explored here: https://github.com/tower-rs/tower/issues/108\nIf that change is done, we could pass &Incoming::Item or something, and then the NewService could grab the remote address and anything else it wants (like TLS context info) to then be used in the constructed Services.. I did some exploration of converting NewService to MakeService<Ctx>, such that you can access the transport when creating a Service. The WIP is here: https://github.com/hyperium/hyper/commit/94cc8065490497dcaf6bbb9862c0b1f28bf10126\nHere's how the API worked out (mostly so as to not be a breaking change for NewService):\nrust\nlet server = Server::bind(&addr)\n    .serve(make_service_fn(|conn: &AddrStream| {\n        let remote_addr = conn.remote_addr();\n        service_fn_ok(move |_: Request<Body>| {\n            Response::new(Body::from(format!(\"Hello, {}\", remote_addr)))\n        })\n    })). The backtrace shows that just before starting the panic steps, it got to at src/tests/repository.rs:12 in your code. What's that line?\nNote that calls to unwrap() are a way of converting a fallible operation in a panic, saying \"if this errors, crash me here\". If it shouldn't crash, you should consider how to handle the Err case. If it should, you may want to replace them with expect(\"description of why this crash is appropriate\").. I'm going to close this since it doesn't look like the panic is happening inside hyper. If I'm wrong, we can re-open!. Hm, is_connect probably should be added, that's true! You can also inspect the underlying error using Error::cause2.\nI know matching on enum variants in these cases is much easier, the Error type used to be an enum. However, it made it difficult to add new variants, and impossible to refactor the representation of an error. For those reasons, it is now an opaque struct with some ways to inspect. See #1131 for more discussion around that.. > I would love a reconsideration to add enums back in the Error\nI expect the type itself to never make its representation public, since that was a hindrance before that prevented optimizations. Exposing a public Kind-like enum might happen, but it depends on #[non_exhaustive], and as the issue explains, building an enum that can gain new variants in a backwards-compatible way is difficult.. Client::new() is not available if the runtime feature is disabled, since it defaults to using an HttpConnector, which makes use of parts of the runtime.\nAre you using a different runtime than tokio? Or you simply wish to customize the tokio runtime specifically? If the latter, you don't need to disable it in hyper; hyper doesn't build its own runtime. The runtime feature simply provides built in support to make use of a provided tokio runtime.. Those 4 threads are part of the HttpConnector, which it uses exclusively to perform blocking DNS lookups (so they don't block the runtime thread).\nIf you wanted everything to always use a single thread, you could try using a different Connect that does non-blocking DNS lookups, perhaps using something like https://github.com/bluejekyll/trust-dns. Some concerns with simply using futures 0.3 directly in hyper:\n\nUnstable (which is expected, but we can't suddenly make hyper nightly-only.)\nNew unsafe code should not be required in hyper.\nFiguring out the Future vs TryFuture dance of bounds and impls.. I think this is a goal of the Futures (or wg-net?) team, as suggested by the 0.3 alpha announcement:\n\n\nTokio and Hyper support is not yet available for 0.3.0-alpha.1, but that\u2019s the next area of work.\nAs of this writing, futures 0.3.0-alpha.1 is not integrated in any way with other libraries like Tokio or Hyper. Achieving such integration is a crucial part of getting real experience with the design and ultimately heading toward stabilization.. ## Experience Report\n\nI started experimenting in a branch to see how it went, what follows is a report of my experience:\n\n\ud83d\udd34 Having async fn send_request(&self) -> Result<Response, Error> automatically make the future borrow &self is surprising. I wish the compiler could notice that I wasn't actually needing anything to be borrowed.\n\ud83d\udd34  Error messages are better than ever!\n\ud83d\udd34  Fixing the above issue by changing to fn send_request(&self) -> impl Future03<..> { async move { .. } } means lots of a functions that don't need to borrow any arguments have an extra level of indentation, just because.\n\ud83d\udd34 Many of those functions have several lines of copying config off self into local bindings at the top of the functions now. Feels gross, but it also clicked why if I think of async { similar to a closure.\n\ud83d\udc9a It was neat to replace the RetryableSendReqest future into just a loop { match await!(fut) .. }.\n\n\ud83d\udd34 Tried changing Service::Future to use Future03, which lead to wanting to inject task::Context literally everywhere, which made me pause for now.. ## Report 2\n\n\n\ud83d\udd34 \ud83d\udd34 Seeing all the places that would need to be passed a task::Context argument, simply to then pass it along, is a lot of noise. Seeing as very few places actually need to grab the current waker, the previous task::current() was much nicer. (Grumbled about here).\n\nHaving switched Service to have a type Future: Future03<..> + Unpin;, it still means there's a paper cut when trying to use async/await! for a service. Consider:\n\nrust\n  service_fn(|_| async {\n      Ok(Response::new(BODY))\n  })\nSince async is used, it uniformly has !Unpin on it, even though it isn't borrowing anything. So I'd need to use async { .. }.boxed() to get it to be Unpin. That requires importing Future03, and allocating on each request, which wasn't required with 0.1, and doesn't actually make it safer.. There has been a new RFC to stabilize std::future, just linking here to keep track of things over time: https://github.com/rust-lang/rfcs/pull/2592#issuecomment-437989421. As the compiler error suggests, there is no Authorization type in hyper::header anymore. You can set the header directly, via headers.insert(\"authorization\", some_str.parse().unwrap()).\nTyped headers are being worked on in https://github.com/hyperium/headers.. > and in the case of a hyper POST request handler this means create/return a hyper::Error - which seems impossible?\nA hyper::Error is returned to you when hyper itself sees an error, it's not something that you should need to create. For your Service, you don't need to set type Error = hyper::Error, that just happens to be the type that you'd get from a failing in the body. You can set type Error = MyOwnErrorType, and then just map any hyper::Errors into your own type.. Oh sorry, I didn't get a notification of the rebased commit. Thanks!. Is it possible to see the response headers and body? (Cleaned of any sensitive details.). Are you able to turn on logging (such as with pretty_env_logger, or your favorite), and set the equivalent to RUST_LOG=hyper=trace?. So it's peculiar how the logs seem to just stop after TRACE hyper::proto::h1::role       > Client::encode method=GET, body=None. That happens in the poll_write part of the dispatcher, and after that, it should enter poll_flush before possibly returning out of its loop, and that includes another log about having flushed.\nFor it to never even have gotten there suggests to me that something is blocking. I'm suspicious of the io.write_buf call, since just after it is another debug log line about how many bytes have been written.. I've set up a repro locally, and it's not that the call is blocking, write_buf is returning NotReady, and then apparently never becoming ready?. I found the issue in tokio-uds, filed a PR with a fix here: https://github.com/tokio-rs/tokio/pull/672. Looks like tokio-uds was released with the fix included. Closing up here!. Sorry, I don't quite understand, what problem are you running into?\n\nHowever, isn't the type supposed to resolve to Server<_, hyper::Body>.\n\nNo, the type reported is correct. It's supposed to a Server<IncomingConnectionsImpl, NewServiceImpl>.. NewService is a trait, you can't declare a type that holds a generic with the exact trait. Any type could implement it, and they could be different sizes in memory. If you wish to be able to hold any type as well, you need to make your type generic, similar to how hyper::Server is.. You cannot create a hyper::Error yourself, they happen inside hyper. If you have specific error conditions that can happen in your app, you should create your own error type that can describe them.. Thanks for starting on this! It definitely reads clearly.\nI downloaded the branch to compare benchmarks, since I've so far not implemented this because I didn't want to noticeably hurt performance. It does look like this made a couple slower, with the biggest impact being writing of content-length: x when not present around ~33% slower. I haven't yet built the TechEmpower server to see if turns out matter in a request life cycle (I expect it will on the pipeline benchmark).\nA possibly crazy idea I thought of was to make the function actually generic over some EncodeHeaders trait. That'd allow inlining and branching to be pulled up to the top, and could maybe allow the the lower-case version to not need to break up names from b\": \"... \ud83e\udd37\u200d\u2642\ufe0f . The benchmarks I ran are already in the code base, you can run them yourself (compare master to your branch) via cargo bench --features nightly --lib proto::h1::role::tests::bench_server_encode.\nAnd to clarify, I don't mean to say the server itself is 33% slower, just those specific benchmarks. It's possible the difference is not really noticeable in the context of a full request/response and IO cycle.. This is an interesting solution, and in fact it is how finagle does it (ServiceFactory receives a ClientConnection... well more like an Option<&ClientConnection>). However, it does make it harder to implement NewService for client abstractions.... This same question is tracked here in tower: https://github.com/tower-rs/tower/issues/108. This was a breaking change, but support has been added in a non-breaking fashion in #1692. Thanks!. I have seen multiple requests to relax the Send requirement in hyper, and in principle, I'm fine with it. \nThe tricky part has been around dealing with the Executor that is used to spawn the tasks. To support both tokio::spawn and alternative executors, while not needing an explosion of generics, it's simply required to be Executor<Box<Future + Send>>. As of now, the tasks that are spawned are: a) for hyper::Server, the hyper::server::conn::Connection which will include the Future from a user's Service, and b) if the protocol is detected as HTTP2, then internal H2Stream futures are spawned for each request/response future, also based on the user's Service.. I just tried this out, and while your example code does hang like you said, the issue isn't with the graceful shutdown in the server. It is indeed closing the connection to the client. The problem is that the client has spawned an interval to clear out idle connections in its pool, and tokio::run it blocking until that task is finished. Since tokio::run is blocked, the destructor for hyper::Client can't run (until the function scope exits).\nTo verify that was the issue, I wrapped the full future chain inside a future::lazy(|| { .. }), so that the Client is dropped at the end of the lazy closure.... Part of the requirement for 'static is because the future from the Service is going to be spawned on an executor which can potentially be a thread pool, so the future can't have any references since it might live on another thread.. Yea, I see what you mean. Maybe something could be done in tokio. The function hyper::rt::run just defers to tokio::run internally.. cc @carllerche. Unfortunately, two traits are needed, since some cases don't require a NewService to even be in scope (such as Http::serve_connection(io, svc)).. Yikes!\nSince this is only an issue for Android ARM, what if looping twice included some cfg? That way any other platform doesn't need to see slowdown.. Nice, the macro is pretty clever, thanks!. I'm noticing this more and more, since AppVeyor won't build any jobs in parallel, nor branches, so if a couple PRs appear, it can take a couple hours to get run (and even just a single PR will run 4 jobs at around ~6-7minutes each, for ~30mins total).. Previous attempt: https://github.com/hyperium/hyper/pull/1690. cc @sfackler . Would you mind expanding what you mean with your suggestion? hyper is an HTTP implementation, a reverse proxy is one tool someone may want that makes use of HTTP.... It does seem too high level, since there's so many design decisions to be made. For anyone wanting a starting point, there's a reverse proxy example in this repo.. Awesome, thanks!. The \"incomplete\" error means a request was written, but the server closed the connection before a response could be read.\nThis could also happen if the request was written on a kept alive socket that the server was just about to close.... What does the reqwest code look like? If it can't be reproduced with just hyper, it may be something wrong in reqwest.. The buffer change is super clear to me. The shutdown is less so. I'd expect that just dropping the streams would close the sockets. Is that sometimes not happening?. Dropping a TcpStream should close it automatically, thanks to this destructor. I wonder if since the sockets are duplicated, it works less well. Anyway, I don't see an issue with actually calling it, so I'm fine merging.. Ah, in the logs, it looks like there's also a hyper::Client somewhere? If so, depending on the exact invocation of run, it could be the server is shutting down, but the Client isn't able to close (see #1668).. Thanks for noticing! Seems the test was fragile, but I've gotten it back to the passing behavior. I'll also disable the warnings and minimum version in CI, since 0.10.x is no longer actively maintained.. There is HttpConnector::set_local_address already.\nOr do you mean setting it differently depending on the destination? If so, you could try implementing a custom Connect that is tailored for your workflow.. > Yes the API exists but requires creating a new client which destroys efficiency. Setting source address directly when making a request with hyper would be better (not in client builder).\nYour use case sounds possible to support, but also a bit detailed. That's OK! That's why the Client is generic over a connector. You can implement Connect on a new type, such that you can inspect the Destination::hostname(), and from that, configure a TcpStream with a certain local address, and then connect.\nIs there a reason this wouldn't work in your situation?. My feeling is that this functionality is fairly niche, so I'm going to close the issue for now. If there's lots of need that I don't know about, we can reconsider!. As mentioned in #1683, a custom Connect can be made to do this.. hyper's Client does not limit how many outstanding requests or connections is has, so depending on the work load and the resources of the machine, you may run into TCP issues. You can use Stream::buffered to control how many futures are pending at a time.. If you were to turn on logs for h2, we could see what exact frames are being received. It sounds like the server is sending RST_STREAMs back of PROTOCOL_ERROR reasons, but I don't know for sure.. Thanks for the report. This is known, and is a compiler bug. It's reported and tracked here: https://github.com/rust-lang/rust/issues/55376. Looks like latest nightly has this fixed.. You can get similar functionality by using Http::serve_connection.\nSee #1650 for the general issue of accessing the socket when constructing a Service.. Apparently the Travis support of Windows isn't stable enough. Restarted the build multiple times, and it hung every time. :sadtrombone:. @sfackler it's to match what's discussed here, that the name NewService may be less ideal than MakeService. . > want to track how long SSL handshake take and other statistics?\nThe Client can take any custom Connect, so you can instrument a connect to record statistics around DNS, TCP handshake, SSL handshake, etc.\n\nWhether an error occurred, whether there was some validation error, etc.\n\nhyper will give you an Error if the request fails in any way. I can't say whether it will fit your needs perfectly, but with the vague description, it sounds like it will!. It might actually be due to the DATA frame padding. I haven't actually seen that used before. The logs make me suspect that the underflow is because the padding of 192 bytes is being applied to the content-length counter.. It seems fair to add a line to the http2_only docs about this using HTTP2 Prior Knowledge, and if the server doesn't speak HTTP2, you may see something like a FRAME_SIZE_ERROR.. There is no bug, but as was mentioned in the Reddit thread, it could be synchronizing on the stdout lock helps with something else, like the task::current().notify() you have that may cause extra wakeups.. Thanks for the PR!\nI still feel similarly as I did when discussing this in the other issues (#126, #1633), which is that I'm not sure this belongs in hyper directly, since while UDS does have its uses, it's not common enough to be part of hyper directly.. > I do not believe it's possible right now to implement this feature outside in a separate library. I've tried.\nI've used the Server::builder to integrate different listeners and socket types myself, so I know it's possible, and not too difficult. What prevents you from doing that in this case?\nI don't think this should be merged because it's hard to do externally (it isn't!). However, I took a look at various other HTTP libraries, and found some built-in support for HTTP over UDS (I looked at nodejs and Go), and that was enough to convince me to make it easier.. @sfackler so do you think with how easy it is to put together externally, this should still remain outside of hyper?. This match isn't actually unused, it's matching an an uninhabitable type, making the entire branch unreachable. It helps with optimization.. Which bounds specifically? The exec traits? Are they not satisfied with Executor bounds?\nAre you trying to be generic over the executor also? Since there is E = Exec on the structs, you should be able to use it by just omitting the second generic, right?. Looking at those traits some more, I'm reminded why they aren't public: they expose a bunch of internal pieces, like the watcher stuff. A user shouldn't need to care about any of them, and I'd prefer they didn't have to be part of the trait, but without them, it was impossible to properly propagate the \"sendiness\" of the user's futures and the executor. If that could be done more easily, these weird traits wouldn't be needed at all..... Would you be able to expand on what you mean?. Ah, yes, that is expected behavior. If you look at the documentation for the IntoIterator for HeaderMap (you'll need to scroll to the bottom and expand it), it says:\n\nFor each yielded item that has None provided for the HeaderName, then the associated header name is the same as that of the previously yielded item. The first yielded item will have HeaderName set.\n\nThe reason for this is because you're using the consuming iterator, which moves the keys and values out of the map. Since the key is only stored once, it can only be yielded once. If you use a borrowed iterator, then the references to the keys can be yielded multiple times, since it doesn't need to move the key out of the map.\nrust\nlet (parts, body) = response.into_parts();\nfor header in &parts.headers {\n    println!(\"{:?}\", header);\n}. Is it actually the buffer size passed to the socket? I've understood that TCP packets usually won't be more than 8kb unless on a local network.... v0.12.16 has been released that includes a http1_read_buf_exact_size client option, allowing to set the read buffer to much higher.. I filed #1708 for the adaptive buffer stuff.. I've taken this branch and made the edits I mentioned, with the beginnings of a ReadStrategy enum, and merged into master in this commit: https://github.com/hyperium/hyper/commit/2e7250b6698407b97961b8fcae78696e94d6ea57\nThanks!. I think I get what this is trying to accomplish. Do you have a small example, like how this would be used for TLS?. Sleeping on TCP accept errors is actually common in other libraries, like nginx, nodejs, Netty... \nWas it masking an actual problem in your server?. - nginx: https://github.com/nginx/nginx/blob/1028d71/src/event/ngx_event_accept.c#L99-L127\n- Netty: https://github.com/netty/netty/commit/dcf78961724abf97fea9e768cca02ba65146b324. It seems like we could add a tcp_sleep_on_errors(bool) method to Builder<AddrIncoming, E>.. @starsheriff Have at it!. You could try a more \"functional\" style of getting it:\nrust\n// type is Option<u64>\nlet content_length = res\n    .headers()\n    .get(CONTENT_LENGTH)\n    .and_then(|val| val.to_str().ok())\n    .and_then(|s| s.parse::<u64>().ok());\nWork has been happening on a new \"typed headers\" repo, https://github.com/hyperium/headers. Once the final pieces have stabilized, it would have code like this:\nrust\n// type is Option<ContentLength(u64)>\nlet content_length = res.headers().typed_get::<ContentLength>();\n(As this is more a usage question and not a bug in hyper, I'm going to close :D). I haven't really investigated, could the fix for #1717 have fixed this too?. The connection isn't waiting on a read, due to this line: https://github.com/hyperium/hyper/blob/master/src/proto/h1/conn.rs#L231\nIt's basically to apply TCP backpressure, to not start reading a second message while waiting to respond to the first. If there were a way to register for HUP on AsyncRead, that could help achieve it without possibly reading a next message.. In h2, it's always reading, since it needs to in order to handle HTTP2 bookkeeping, since frames can come in related to any stream (or for the connection).\nWe could try adding a read check on the transport even if is_mid_message, and just not error if some bytes are found. It should work if a client isn't using HTTP/1.1 pipelining, but if it is, it'd be quite hard to detect an EOF read if a pipelined request is sitting in the buffer. Perhaps that's better than nothing (and the real world doesn't really use HTTP/1.1 pipelining anyways).. Ah sure, if it were to close the connection immediately, then connections that half-close after writing the request would never be able to read the response.... A possible solution is to offer some sort of \"support half-closed\" config option (default would need to be true to not break existing behavior), and if false, then that keep-alive read can forcibly close future down.. Thanks, I'll try out the repro locally.\nDo you have any more details that would help me while I look? Is it consistently leaking the connection immediately, or only occassionally?. Is the leak in broker, or in worker?. I see, it seems the dispatcher after having written the headers for some reason doesn't continue to do work, but stalls. I'll look more into it.. I've published v0.12.16 with a fix for this, thanks for reporting and for the reproducible instructions!. The transport type passed to the MakeService isn't matching. Due to Server::bind, it uses hyper::server::conn::AddrStream, not TcpStream.. hyper does not provide timeouts or redirects directly. The reqwest crate has support for both (and both sync and async Clients).. Fixed in #1722, thanks!. Awesome, thank you!. Yep, we can do that!. I believe things to be fairly stable. I feel the Client and Server have pretty nice APIs at this point. Things may get small tweaks, but 0.12 is used pretty extensively in large projects, and it feels good.\nSome things that are less stable:\n\nThe most unstable is the external dependeny on Future. The trait along with async/await syntax are being merged in libstd. When that is stable and working well, users implementing Future themselves will see some changes. Relevant: #1654 \nThe Service trait will likely be replaced with that from tower. The concept is similar, with some associated types differing.\nThe Payload trait may be replaced with a more general trait, such as tokio_buf::BufStream. Unless you have a custom body type that you implement Payload for (instead of using hyper::Body), this change should be invisible.\n\n(BTW, since this isn't a bug in hyper, I'm going to close. We can still keep discussing though.). Yea, I that is a monster!\nI had originally hoped that such a trait wouldn't be necessary, but without it, I had similarly gross bounds in hyper. The \"trait alias\" made it cleaner, and should still work for people implementing MakeService. I suppose the trait could be moved over to hyper::service, and exported.... There is graceful shutdown supported on the Server.. Do you really require the + Sync bounds on the return impl Future? If you just remove that, it would work.. spawn is to be used from inside running futures. Take a look at this Tokio guide.. Thanks for reporting this! I've pushed a fix for the link.. Thanks!. Done.. Indeed, you are correct, I wrongly made use of Handle::current(), it should be Handle::default(). I just pushed a fix of this to master: https://github.com/hyperium/hyper/commit/1d253b4d4759e045409fcf140adda7d327a05c8a. @carllerche any reason to not deprecate it?. Slap a #[deprecated] on Handle::current, and add Handle::current_or_background or something.. Wow! Thanks so much for looking into this! Some of the issues you ran into, I also noticed in my previous attempt (https://github.com/hyperium/hyper/pull/1690).\nThe secret was used to publish the master docs at hyper.rs/docs/master, but I believe I finally removed that, since it was mostly to show the large difference of 0.10 to 0.11. There isn't much need in having the docs for master built anymore.. You'll need to make use of futures::future::Either, since the and_then(|res| would either return an error immediately, or return the concat future.\nFor example:\n```rust\nuse futures::future;\nclient\n    // Fetch the url...\n    .get(url)\n    .from_err::()\n    // And then, if we get a response back...\n    .and_then(|res| {\n        // Can check ranges with is_* methods on StatusCode\n        // Or for a specific status, res.status() == StatusCode::OK\n        if !res.status().is_success() {\n            future::Either::A(future::err(FetchError::Status(res.status()))\n        } else {\n            // asynchronously concatenate chunks of the body\n            future::Either::B(res.into_body().concat2().from_err())\n        }\n    })\n// use the body after concatenation\n.and_then(|body| {\n    // try to parse as json with serde_json\n    let users = serde_json::from_slice(&body)?;\n    Ok(users)\n})\n.from_err()\n\n```\n\nAs this seems to be a usage question and not a bug in hyper, I'm going to close :). Looks like nightly Rust booped itself. Thanks!. I don't know if you've figured this out already, but it has to do with the way futures work. If you return NotReady, you need to have setup some way to notify the Task whenever a thing is Ready.. Sure, thanks!. If you're implementing Payload for a new type, you could also implement Drop and have the code then record your metrics. That's the approach we take in linkerd2.. We don't copy the values into the Payload either. We record request and response info immediately, and basically store a key to those metrics in the payload, and then insert bytes and latency at drop.. I think I originally made assumptions that the Uri would always be in absolute-form, and so some of the setter methods may panic if that weren't the case. Before exposing this, perhaps it'd be a good idea to make sure the setters wouldn't panic if originally created with a non-absolute URI?. I actually expect that code would panic, for sure. That's because setting the scheme and nothing else would be an error in http::Uri. Perhaps instead of Destination::new(uri), there could be try_from_uri(uri) -> Result<Self>, and to be conservative, if scheme or host isn't set, return an error?. Thanks!. A Connect implementation can do so by returning a Connected::new().proxy(true).\nBTW, if you're looking for an HTTP library that easily can use proxies, consider reqwest.. Yep, it has an async interface!. The possibility of needing to go to tower_service = \"0.3\" relatively soon worries me some.... @sfackler wait what? Got an example, or a link to something I can read more about?. It'd probably be useful if there were more knobs to configure here, but I can at least explain what limits currently exist:\n\nThere is a maximum number of headers set at 100. This doesn't affect how long each header can be.\nThere's a default max read buffer size set to ~400KB. If the headers haven't finished by that limit, the response will be canceled.\nThere's an option to change the max read buffer size on the Server side, but not the Client. Likely just an oversight.. > If need be I can close this PR and reopen only with my changes applied to a fresh fork.\n\nYou don't need to close the PR, you can simply run the command git rebase upstream/master (assuming upstream is https://github.com/hyperium/hyper).\n\nwe may want to think about making it impossible to set both of these options at the same time by using an enum or an assertion.\n\nWhat about just modifying the exact_read_buf... method to unset the max option if it is set, so that setting either effectively cancels the other?. You can make use of hyper::Server (the builder constructor) to ease using the upgrade API. You're not too far off! It'd be something like this:\n```rust\nlet incoming = srv.incoming().for_each(tls_accept);\nlet server = hyper::Server::builder(incoming)\n    .serve(new_service);\nlet mut rt = current_thread::Runtime::new().unwrap();\nrt.spawn(server.map_err(|err| eprintn!(\"server error: {}\")));\nrt.run().unwrap();\n``. Truthfully, that should really just returnimpl Future, instead of the namedGraceful.... It's not publicly exported so that the details aren't relied upon, such as the extra number of generics, or their exact bounds. For now, it can be converted into aBox, or if clever, you can do some shenanigans to get animpl Futureinto an associated type (kind of like how you can do so withservice_fn). Soon-ish, we can put existential types in traits.. @sfackler \\o/ It'd be useful to add such a test to hyper to know when this workaround can correctly be removed.. As you've noticed, you can largely just test yourServicewithout needing to start up a full server. However, depending on what that service is doing, you may need a runtime active. Like if you service spawns sub tasks/futures (like the hyper Client does), or usingtokio-fs`, which needs the threadpool available.\nBut in other examples, you can just call it. The Hello World example in hyper can just be called, as you described.. Hm, good point, it only applies to the HTTP1 buffer, so it should probably be prefixed with http1_.. Thanks!. I'm not opposed, but while we wait for CI, I'm curious to hear what use case you have that needed this :D. Makes sense, thanks!. Hm, sounds like it's looping here? https://github.com/hyperium/hyper/blob/877606d5c81195374259561aa98b973a00fa6056/src/proto/h1/io.rs#L215\nDoes the log message after it trigger over and over?. I meant the debug!(\"flushed {} bytes\", n); that happens just after write_buf line. It'd be useful to know if there is something mis-behaving, since the loop will exit in any of these 3 conditions:\n\nThe transport returned WouldBlock (or any other error).\nThe transport said it wrote Ok(0) bytes, meaning it is closed.\nThe buffer of chunks reports there is no more bytes to write.. Thanks for more details! By chance, do you happen to know if it it was logging the debug line \"flushed n bytes\" in the loop?. Ah yes, this is #1716. hyper by default allows for half-closed transports (calling shutdown(Write) sends a HUP). Often times, sockets will also error on write with EPIPE, I'm not sure why it wouldn't in your case.. Hm, maybe!\n\nSince the Connect trait is related and/or may be superseded by a similar trait in tower, cc @carllerche @davidbarsky @LucioFranco.. @LucioFranco I think we are close! Switching completely is breaking change, so maybe should be bundled with other breaking changes (like the http crate needs one...).. > Should we deprecate cause2 as well?\nI think so, yes.. The example mentions TcpStream, but using Server::bind will yield hyper::server::conn::AddrStreams.. Sure!. Thanks!. Ah bummer, the doctest is failing when default features are disabled (so no runtime).. Thanks!. hyper has tried when possible to link new compiler requirements with breaking changes. While we can sometimes use config flags to only enable things on newer version, I don't think there's a way to do that here, since this also requires putting edition = \"2018\" in the Cargo.toml.... > hyper to distribute requests to different threads on the same connection\nFor HTTP/1, hyper doesn't not spawn new tasks for each request of the same connection. Even if it did, it will not start processing a new request until the previous response is sent. So spawning a new task would just reduce performance.\nIn general, you cannot do blocking operations in an async task. You should have some other mechanism to run those operations, like a threadpool.. cc @carllerche @LucioFranco @davidbarsky . > Transition to BufStream instead of Payload\nOh that's right, thanks for reminding me. I think that change is a little trickier:\n\nBufStream is basically the poll_data part of Payload, but has no trailers.\ntower-http offers a Body trait that is based off Payload. It can poll data bufs, and trailers, which hyper needs. However, it's a separate trait from BufStream, doesn't have it as a super trait, and there is a blanket implementation of Body for all T: BufStream.\n\nThe issue this creates is that in order for something to be both a BufStream and Body, it could only manually implement BufStream, and assume the blanket Body implementation, which skips trailers.. I haven't tried, but I don't believe we can implement a blanket implementation of a foreign trait in hyper.... Thanks! Out of curiosity, do you know if the additional branches affect performance much? Likely the ones with least noise are in proto::h1::role at the bottom of the file.. Oh yea, so it does affect slightly bench_server_encode_headers_preset. Since this condition should be very rare, I think we can structure the change so that the normal case doesn't see any extra branches.. Why consume the handler here?\n. Left over *Response from a previous attempt?\n. I've never been a fan of assignment via derefing a pointer... What if it were fn set_status(StatusCode)?\n. This server can be stood up and torn down with each benchmark. See how I did in the client.rs benchmark.\n. what if in handle_request, a url /teardown or whatever would make the task fail!. Would that kick the serve_forever?\n. Ah, I set port to 0, so the OS would give an unused port.\n. Did you want this to be boxed also, removing the generic? Or purposefully left alone?\n. Woops, I wasn't supposed to commit that. I can remove it in a follow up commit.\n. So, this swallows IoErrors, right? Something simple like \"addr is in use\" could now be difficult to determine.\n. @reem The naming here hasn't made me happy, but I've struggled to think of anything better...\n. Yea that's illegal. \nDoes HttpStream with Http and Https as variants feel right? I could switch to that... \n. Is there any difference in the compiled code? \n. I tried doing this, and it seemed that boxing it up messed with the typeid. That's why I used a downcast with no check, because the AnyRefExt downcast returns None. \n. Also, can't you bind the item, like i@Typed(..) and return i? \n. I'm thinking about recording the length in here as well, and then once length reaches zero, returning a ShortWrite ioerror.\n. I love this. Excellent intro.\n. I'd rather there not be an example in the README, as it can bitrot as the library is still unstable.\nHow about a link to the example source file.\n. Nice catch.\n. At the moment it's only used for failures, Yea.\nOn Sep 27, 2014 3:39 PM, \"Jonathan Reem\" notifications@github.com wrote:\n\nIn src/server/mod.rs:\n\n@@ -71,7 +73,7 @@ impl, S: NetworkStream, A: NetworkAcceptor> Server<L\n             .map(|acceptor| acceptor.move_incoming())\n             .intertwine();\n-        spawn(proc() {\n-        TaskBuilder::new().named(\"hyper acceptor\").spawn(proc() {\n\nDoes this just add a name to failed tasks?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/65/files#r18126235.\n. This can use byte literal syntax. ex: b\"application/vnd...\".to_vec()\n. Byte literal syntax here also.\n. Underscore is used to mark something as unsused. Now that it's used, could you remove the underscore?\n. It made it really hard for me to know what the actual error was.\n. This allocates a String on the heap before passing back into format!.\n. This format! allocates a new String, which is then passing into the Formatter. You can use write!(fmt, \"Basic {}\", ...) which will write the bytes straight to the formatter without a heap allocation.\n. Heh, and of course, I feel the opposite. Perhaps once it can be &cookies_raw, I'll be convinced.\n. Only with a large number of cookies. With a few (1, 2, 3ish), it would remove the branch in the for loop, but add in 2 bounds checks, and make the code much more complicated to boot.\n\nHow many cookies is the common case? I'm thinking 0-2.\n. What do you mean \"for re-parsing\"?\n. Sure. Many of the nits you've noticed where because I was just trying to make it all work. I wanted to make sure it worked and was indeed faster before cleaning up.\n. Would you be able to uplift your changes into libstd?\n. Oh, woops. I missed a case: (Http10, _) => false. 1.0 defaults to close unless Keep-Alive is passed, whereas 1.1 is to default to keep-alive unless close is passed.\n. Probably can. I was fiddling around with several different schemes here trying to get the borrow checker happy.\n. Yea, I considered it being listen(handler, 100) or something. I tried a method on handler for 2 reasons:\n1. I was considering instead of just returning the number of threads, allowing this method to return a TaskPool (for some trait HyperTaskPool, to allow any implementation).\n2. I wanted to have a default that wasn't just 0u.\n. I'll try with an Arc.\n. I still need to figure out how to get the remote_addr back into Request, since you can't get a mutable ref to the internal reader from a BufferedReader. I'm thinking of passing it as an argument to new().\n.  Name the lifetimes? You mean describe the write status values?\n\nI was thinking of making Response<W = Fresh> so that users don't need to include the <Fresh> in their handlers. I don't think it will trip anyone up, since anyone needing a Writer will be forced to use Response.\n. Updated with a Sync bound and am using an Arc now...\n. Yea it does, don't know what I was thinking.\n. that's insane. but ok.\n. Previously, the for loop would just work on the bytes, and write them to the hasher. This new code allocates on the heap, which is a performance hit.\n. The header names should only be a few characters long, such as Date, Server, Last-Modified, etc. The loop should be short.\n. Hm. So, to get the string representation, since it could be raw or typed, I'm using to_string(), since both representations implement Show. So, this String should be the value that would have been written out to the socket...\nShould this convert the value from a String to a Vec? It seems user-code could do that if needed.\n. Oh, wow. I totally didn't notice I implemented on a trait object...\n. Would you mind updating the name of this method to match the new convention as well?\n. Actually it was only because Cow doesn't yet implement Clone. I've been meaning to pull this into a new crate, and when I do, I'll add the generics back in. \n. Nice. I imagine that was a case of writing the docs early, and then changing the name of struct later and forgetting about this doc comment.\n. I can try to remove it, but my guess is: yes, because we're dereffing Ref, and the compiler only thinks it lives till the the end of the scope.\n. I tried, and it complains that it can't infer H.\n. oh you're right. i forgot i did that.\n. Now that the headers implement Deref to access their wrapped types, you don't need to pattern match here. self.iter() should just work. \n. It was following suite to std::io::BufferedReader, which hasn't marked it as unsafe.\n. \\o/ this was fixed upstream\n. Very cool, thanks!\n. Rust conventions are to only uppercase the first letter in an acronym, such as Xml Json, Http. I'd name this WwwAuthenticate.\n. The log will already include DEBUG:hyper::header::common::www_authenticate: {msg}, so you can probably leave that out of the messages.\n. Also, in the None case, you're logging header, but you just matched that it was None. Did you mean to log raw here?\n. The RFC says this header can be a bit more complicated:\n\nFor instance:\nWWW-Authenticate: Newauth realm=\"apps\", type=1,\n                  title=\"Login to \\\"apps\\\"\", Basic realm=\"simple\"\nThis header field contains two challenges; one for the \"Newauth\"\n  scheme with a realm value of \"apps\", and two additional parameters\n  \"type\" and \"title\", and another one for the \"Basic\" scheme with a\n  realm value of \"simple\".\n\nI'd probably include a unit test testing the example from the RFC, and include a link to this section of the RFC at the top of the module.\n. I'd use a match statement here:\nrust\nmatch c {\n    b'\\x21' | b'\\x23' ... b'\\x7e' | b'\\x80' ... b'\\xff' => (),\n    _ => return false\n}\n. slice.is_empty() and slice.ends_with(\"\\\"')\n. Could you also add a pub use self::etag::Etag up top?\n. This can be just 'self[]' because of Deref. \n. I'm not ready to call hyper 1.0 yet.\n. Semver says that while we're in version 0.x, breaking changes are to be expected.\n. Yea, I agree.\n. That's fine too.\n. I'll bump the version when releasing, kill this.\n. Ouch, if defaulting to q=1, it'd be nice to remove the need to use a QualityValue. Either with an easy to use function, or possibly a trait IntoQualityItem, that could be implemented for both QualityItem and Mime...\n. Does this play well with Mime's attributes? Say, Content-Type: text/plain; charset=utf8?\n. - So, self[] is fine if passing a slice, like &[T] or &str. Examples: struct UserAgent(pub String).\n- **self does require Deref\n. woo!\n. Yes. It could be from an fstat. usize on 32bit system will limit you to files less than 4gb.\n. Likewise, if your server has files bigger than 4gb (which is becoming more common), then a 32bit server won't be able to serve them.\n. I don't see how it much cleaner, it looks the same to me except one is before the parens, one is after. But I moved it cause people seem to like it.\n. Trying to use a where clause here on the impl gave errors that down below L::Acceptor couldn't be resolved:\n/home/sean/code/hyper/src/server/mod.rs:64:101: 64:112 error: associated type `Acceptor` not found for type parameter `L`\n/home/sean/code/hyper/src/server/mod.rs:64     pub fn listen_threads<H: Handler>(mut self, handler: H, threads: usize) -> HttpResult<Listening<L::Acceptor>> {\n                                                                                                                                               ^~~~~~~~~~~\n/home/sean/code/hyper/src/server/mod.rs:138:73: 138:84 error: associated type `Acceptor` not found for type parameter `L`\n/home/sean/code/hyper/src/server/mod.rs:138     pub fn listen<H: Handler>(self, handler: H) -> HttpResult<Listening<L::Acceptor>> {\nThis should like be filed as an issue of Rust.\n. Is there need for more than just the Url?\nOn Sun, Jan 11, 2015, 12:29 PM Konstantin Stepanov notifications@github.com\nwrote:\n\nIn src/header/common/referer.rs\nhttps://github.com/hyperium/hyper/pull/235#discussion-diff-22769809:\n\n@@ -0,0 +1,35 @@\n+use header::{Header, HeaderFormat};\n+use std::fmt::{self, Show};\n+use header::shared::util::from_one_raw_str;\n+\n+/// The Referer header.\n+///\n+/// The Referer header is used by user agents to inform server about\n+/// the page URL user has came from.\n+///\n+/// See alse RFC 1945, section 10.13.\n+///\n+/// Currently just a string, but maybe better replace it with url::Url or something like it.\n\nBut then headers must have access not only to a request, but to a response\ntoo. We need to generalize them if we want to do it this way, for example\ncreate HttpContext trait with common methods and implement it for both\nHttpRequest and HttpResponse.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/235/files#r22769809.\n. The _tcp before was to remove the unused warnings. Since it's used, the _ can be removed.\n. So as to keep this in more of a straight line, how about each if let becoming try!(ssl_context.something(...).map_err(lift_ssl_error));?\n. Don't forget to remove. \n. This will only work for Headers that deref to something implements Index. Try &*self. \n. Now that Show and String are common, this could call the wrong one depending on which trait is in scope. Try explicitly using fmt::String::fmt(&value, fmt). \n. Why the clone here? \n. If you have a change, you can use git commit --amend to add code to one commit, or git rebase -i master to smash multiple commits into one.\n\nI imagine you can just remove the .clone(), and the rest should work, no?\n. This has been changed in master, the _ marker argument is no longer required.\n. Most recent rustup changed all Show to Debug, can you do the same here?\n. I noticed other parsers did indeed restrict the total size. I thought that would be complicated, but I just thought of a way.\n. Well, that is already checked in read_header.\n. With a newtype like this, could you also add deref!(Etag => EntityTag)?\n. I'd be fine with parsing::from_comma_delimited to accept &[u8] instead of &[Vec<u8>].\n. There isn't a promise that there is always a value. It may be empty, if it was just whitespace and then a newline, for instance. So, this could panic.\n. Nit: space before and after = signs\n. Nit: space after commas. \n. Nit: space before and after { braces. \n. Correct. \n. Since it's already got the StatusCode namespace, I'd leave this as just 'Unregistered'. \n. rewrite? either remove, or explain more.\n. Why remove all these convenience methods? The allow you figure out the class without requiring an additional import.\n. to prevent this allocation, you could do return write!(f, ...)\n. Also, this would mean a code of like 999 would be StatusCode999. Is that actually desirable, or should it be Unregistered(999)?\n. Since this is already tricky (it's possible to accidentally miss a variant in this match), it'd be best if there was only one of these lists. So here, I would defer to from_u64. Like: if n < 0 { None } else { FromPrimitive::from_u64(n as u64) }\n. Same reasoning as above regarding FromPrimitive applies here: ToPrimitive::to_i64(self).map(|n| n as u64)\n. Have sources? I'd be curious.\n@Manishearth do you agree? Or should it resolve to something else?\n. I'd rather keep these namespaced by enum for now. If there's much demand, this can be an immediate follow up, but it seems like a different decision than this PR.\n. There's no need for the wrapper struct here. Just name the enum above \"IfMatch\".\n. What's the Url? Mind including it in the comment? \n. Why Option? \n. And for that matter, why the value at all? It doesn't seem to be used... \n. Because of this, can you add the breaking change text to the commit? \n. Huh, seems odd to need this bound, but I see why. Not something I would immediately think of...\n. Since the name isn't going to be stored, we can relax the requirement, just like with get_raw. We can accept any &str, not just static ones. \n. Build fails cause addr doesn't exist. \n. Oh dangit. I had set that when I was fixing the bench marks, to compile faster. \n. My understanding is that Ok(0) is EOF. There no longer is an EOF error kind... \n. Yea, it's gross. The change from an EOF error kind to Ok(0) makes this harder. I tried a ReadByte extension trait, but could propagate the correct error upon EOF. So, the macros allow inserting the appropriate HttpError when EOF is found early. \nI also have been working on a branch to use httparse, which removes much of this module. \n. httparse is a push parser. My goal is to be like Pico, but using Iterator,\nto keep things safe.\nOn Sun, Mar 1, 2015, 6:51 PM Jonathan Reem notifications@github.com wrote:\n\nIn src/http.rs\nhttps://github.com/hyperium/hyper/pull/354#discussion_r25576303:\n\n@@ -507,14 +549,24 @@ pub type RawHeaderLine = (String, Vec);\n /// >                ; obsolete line folding\n /// >                ; see Section 3.2.4\n /// > ```\n-pub fn read_header(stream: &mut R) -> HttpResult> {\n+pub fn read_header(stream: &mut R) -> HttpResult> {\n-    macro_rules! byte (\n\nJust found httpparse, seems interesting but we'll need a push parser for\nasync integration later.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/354/files#r25576303.\n. Yes, but just like Pico, it's stateless. It will update the Request object with all the info it could find, but it won't keep track of it's state (as Pico's developer points out, keeping state makes it slower). So you can read some bytes, call parse(), and if it came back as Status::Impartial (or -2 in Pico), you can still inspect some properties. Perhaps you check the route and can determine it's a 404 early before having to parse any more. You should, however, read more bytes into the same buffer, and call parse() again. The parser will start from the beginning.\n\nIt's faster this way because: keeping state (and checking it every single byte) is slower, and in most cases, reading from a socket should read the entire head, so you shouldn't often get Partial parses.\n. Oh good catch. I was altering numbers when testing performance improvement for the server.\n. I did that on purpose, since it seemed better for a simple example to actually print errors.\n. It was actually because I couldn't use them in the tests in the client/mod.rs file.\nThere should already be a public API, using std::any::Any, right?\n. Oh right, I can just use the checked versions in the tests. FIxing.\n. Hmm, I started looking at other languages, and their built-in Clients don't offer a default user-agent either. The recommended way of setting one is just to set the header. A possible solution to this is client.get(url).header(UserAgent(someStr)).send()...\n. Perhaps. Still, that's a different approach than this PR. I'm going to close this.\n. This works now? I kept the box syntax cause there didn't used to be a way to coerce to a Boxed TraitObject without it...\n. It seems odd to me for a setter to ask for a reference. I'd expect either a String, or Into<String>.\n. That's OK. Switching to Into<String> should be a non-breaking change.\n. Ah, yes.\nSpecifically, the only way to pass a &str is to have a static str, or they need to create a String. Since they have already allocated a String in order pass a reference, it's wasteful to allocate a new String, especially since they likely just threw away the original they made.\n. The only reason I can see for using from_u16 is to handle parsing, which we already do. If you know the number yourself, just write the variant instead.\n. If that's what we want, it can be in a separate PR. Although, with the io::Error changes to holding a Box<Error>, the original SSL error is no longer really lost. It's boxed into a trait object.\n. This trait isn't used anywhere?\n. Since this trait isn't used, it's hard to envision how you expect it to be used. However, I think it'd likely be better to write the bytes directly to a Write than to allocate 2 Vecs and return them...\n. Not on crates.io yet?\n. So as to keep the Client without type parameters, what if we keep a Box<HttpRequestFactory> instead?\n. This change means the example on L165 allocates the \"content-length\" as a String, but there's no need.\n. This can be uri.into_bytes() I believe.\n. I think it might be better to toss an unimplemented!() here instead.\n. woops?\n. Hm, you're right, changing that is unfortunate.\n\nHere's an idea I haven't fully explored, but what I was thinking about before your pull request arrived in my inbox.\nInstead of Client using a RequestFactory, I was thinking that Client would continue to use client::Request and client::Response. However, those would internally be altered to contain a sort of HttpMessage. I imagined it being something like this:\nrust\ntrait HttpMessage: Read + Write {\n    fn get_incoming<T>(&mut self) -> HttpResult<http::MessageHead<T>>;\n    fn set_outgoing<T>(&mut self, outgoing: http::MessageHead<T>) -> HttpResult<()>;\n}\nRequest and Response would be altered:\n``` rust\nstruct Request {\n    message: Box,\n    // ...\n}\nimpl Request {\n    pub fn start(self) -> HttpResult> {\n        try!(self.message.set_outgoing(MessageHead {\n            subject: (self.method, self.uri),\n            headers: self.headers,\n            // version seems redundant?\n        }));\n    }\n}\n// and so forth...\n```\nThe HttpMessage implementation would know how to set up its internal Read and Write. For H1, the implementation would adjust itself upon receiving an Outgoing to determine which HttpWriter to use.\nThere's currently a http::Incoming, that could be adjusted to work for both incoming and outgoing. Possible name is MessageHead.\n. ah right\n. Could you add a usage example, per #468?\nOr, I wonder... would the header! macro be able to generate a usage example automatically? Then we'd suddenly have much better docs...\n. nit: space between the name and bracket\n. Mind cleaning this up also? Spaces don't cost use anything. Such as:\nrust\n(Some(p), Some(s)) => Ok(Language {\n    primary: p.to_string(),\n    sub: Some(s.to_string())\n}),\n. (I know it was just copied from the original AcceptLanguage header.)\n. Is this supposed to be part of this PR?\n. an empty string is not None?\n. Unless this was fixed in the time crate, to_utc is slow even if the time is already in UTC.\n. This does pattern matching, which will skip UniCase::eq. \n. These name are case-sensitive? \n. Technically could be f.write_str... But might not be consistent with elsewhere in hyper. \nMight be worth a separate issue to change those, as it is a little faster. \n. Nit: Add spaces surrounding brackets. \n. why the switch from f.write_str? No actual formatting is needed...\n. typo ivalid\n. Since most of the errors are about \"invalid\" values, I think this name should be specific to what kind of value was invalid. Perhaps Header.\n. Instead of this panic, can the cfg just be put on the ssl: Option property of the Server?\n. Whatcha think of adding a debug! (or info?) here explaining that enabling the feature will let you make https requests?\n. Any reason to keep the Option<()>? Without the verifier, it used to be a struct HttpConnector;.\n. ssl = [\"openssl\", \"cookie/default\"]\n. preferred style is a space after the colon, such as num: u16.\n. These can all be assert_eq!, and you'll get a decent error message automatically.\n. Could you add a from_and_cause! case to the tests below, to keep the coverage happy.\n. Was this commented out originally? Seems it can be killed.\n. This could just be self.get_mut().close(...), right?\n. Instead of having 3 options (and the possible panic! states below if all are None), how about some sort of MessageState enum, with the 3 variants. I think that would be clearer that these determine the state of the message, whereas reading the 3 options at first left me confused. Additionally, we could remove the panic!s where all 3 options are None, since the enum will enforce for us the state.\n. Probably similar here: if these options are for tracking state, a MessageState enum would probably be clearer.\n. The spec says that header names are valid tokens, which means they should be valid utf8. Is that not the case in http2? Either way, I'm not sure an unwrap should be used.\nAlso, in Http11, the Set-Cookie header is sent multiple times if there are multiple cookies. Is that different in Http2?\n. Headers::from_raw will do the right thing. However, headers.set_raw() will override whatever value was there before, like any setter.\nThe cookie formatting hack was indeed a nasty hack. We've been trying to think of a way to allow headers to indicate they output over multiple lines, but keeping that invisible from 99% of headers (since they don't need it) is difficult. I'd like to try to figure that out, such that a Header can return a Encoder that implements Iterator, and also be able to pass that to solicit, such that the bytes are written only once through hpack, instead of allocating a temporary vector beforehand.\n. Fair enough. It could probably be done inside a method on the state enum, but don't worry about it. I might look at if it's possible to keep state similar to the WriteStatus that Request uses.\n. I didn't even think about it, I just copied it from std::io::ErrorKind\n. I wonder, would it work out nicely to use std::ops::{Range, RangeFrom, RangeTo}? This could allow usage like let ranges = vec![ 0..1, 30..40];\n. What about if the name for bytes? Range::bytes(10..40)?\n. This will make several heap allocations, before being pushed into the fmt buffer and then being tossed. It'd be faster to skip those. For instance:\n``` rust\ntry!(write!(fmt, \"{}=\", self.unit));\nlet mut iter = self.ranges.iter();\nmatch iter.next() {\n    Some(range) => try!(write!(\"{}\", range)),\n    None => return Ok(())\n}\nfor range in iter {\n    try!(write!(\",{}\", range));\n}\nOk(())\n``\n. Hm, what does the spec say? Anything?\n. To prevent allocating for aVechere, the iterator froms.split` could just be used.\nrust\nlet parts = match (iter.next(), iter.next()) {\n    (Some(left), Some(right)) => (left, right),\n    _ => return Err(())\n};\n. Similar idea here regarding using the iterator.\n. This may want to use the header! macro, though I'm not quite sure how it would be used. @pyfisch has spent more time with it.\n. Yea, it may that's what the macro is for, in which case nevermind me. :)\n. You are right, I hadn't read the Range spec before suggesting that. I didn't realize that bytes=-500 means the last 500 bytes, I assumed it means 0-500.\n. mind adding the bench_header! macro usage down here?\n. I imagine he means the text. No reason to use #[doc] here.\n. hrm?\n. Nice\n. It seems slightly odd that the header outputs with the boolean at the end, but the struct has it first.\nAlso, booleans have a habit of being confusing without the explicit name right next to it. How about instead:\nrust\npub struct StrictTransportSecurity {\n    pub max_age: u64,\n    pub includes_subdomains: bool,\n}\nAdditionally, and I'm not sure if the value this might provide carries its own weight, but maybe StrictTransportSecurity::including_subdomain(1_000_000) and StrictTransportSecurity::excluding_subdomain(1_000_000) constructors might be useful?\n. I believe this line is the unstable feature failing on stable. And since it allocates a new String that gets tossed after the comparison, it'd be better to just compare ignoring case. You can do so using UniCase.\n``` rust\nlet name = UniCase(self.parse_directive_name());\nif name == UniCase(\"max-age\") {\n} else if name == UniCase(\"includeSubdomains\") {\n} else {\n}\n``\n. Could the parser do the parsing with just a slice, instead of cloning theVec?\n. Minor nitpick: could these functions be put into a#[cfg(test)] mod tests { ... }module?\n. I think this needs to usesplitnas well, since this will currently miss something like\"123/567/89\".\n. This can be re-written aswrite!(f, \"{}-{}\", first_byte, last_byte).\n.write!(f, \"{}\", v). Seems to be 1 extra space of indent with this match block...\n. Additional tests would be useful:\n-{ Content-Length: 10 }!={ Content-Length: 11 }-{ Content-Length: 10 }!={ Content-Length: 10, Server: foo }-{ Content-Length: 10 }!={ Server: foo }. This would panic ifotherdoes not have the header.\n. I'd put a length check before iterating, since it could save some time.\n. The double indirection is crappy, but using a generic wasn't really possible, since the type is erased into a trait object inside the keep alive loop. And sinceNetworkStreamrequires'static, I couldn't implement the trait for&mut T. Fun.\n. If showing users that we must deal with errors, this seems like a good place to. Running this script againsthttps://google.comwill trigger this error. For whatever reason, Google doesn't return utf-8 if it doesn't recognize the user-agent.\n. What's the difference between using a Connector with_proxy, and callingclient.add_proxy?\n. Is this header exported incommon/mod.rs?\n. This will be far too noisy, can this be removed?\n.Routeno longer exists, right?\n. This is due to a bug in rustc, because of the function pointer inProxyIf? Is there a issue number for rustc?\n. what if aProxyConnectorexisted insrc/proxy.rs, that could wrap anyC: NetworkConnector? This would allow all custom connectors to be wrapped, as well as let the logic stay in 1 module. It would also remove theif proxy.is_some()branch from code that never used a proxy.\n. This should besections.splitn(2, '='), in case any values arefoo=bar=baz.\n. Could theval.splitn(3, '\\'')iterator be used, instead of allocating a temporary vec?\n. To save on allocating a new string in lowercase, comparisons can be done usingUniCase. Such asif UniCase(s.trim()) == UniCase(\"inline\"). Same withUniCasehere.\n. I'm kinda surprised thatUtf8isn't part of theCharsetenum...\n.UniCase. These conditions could write directly to the Formatter, instead of temporary strings.\n. This could probably beval.trim_matches('\"'). This function and the one below can utilize [url::percent_encoding](http://servo.github.io/rust-url/url/percent_encoding/index.html).\n. This should also exportDispositionTypeandDispositionParam, or else no can do much with this header.\n. A doc test example here would 1) help people understand how to construct or use this header, and 2) properly test the header is usable from outside the crate.\n. We don't need to clone the language tag here (and its Strings and copy them), we can just pass a reference to the write macro.\n. Try with anif let`:\nrust\nif let Some(ref lang) = self.language_tag {\n    write!(f, \"{}'{}'{}\", self.charset, lang, encoded_valued)\n} else { ... }\n. I'll bump the version separately, no need to in a PR. \n. I'd like to believe that httparse will error if there is a header name with no value, such as Host:\\r\\nContent-Length: 10\\r\\n\\r\\n. Which, if that's the case, then raw could never be 0.\n. For the test_duplicates test, from RFC7230#3.3.2:\n\nIf a message is received that has multiple Content-Length header\n   fields with field-values consisting of the same decimal value, or a\n   single Content-Length header field with a field value containing a\n   list of identical decimal values (e.g., \"Content-Length: 42, 42\"),\n   indicating that duplicate Content-Length header fields have been\n   generated or combined by an upstream message processor, then the\n   recipient MUST either reject the message as invalid or replace the\n   duplicated field-values with a single valid Content-Length field\n   containing that decimal value prior to determining the message body\n   length or forwarding the message.\n\nFor the test_duplicates_vary test, step 4 of RFC7230#3.3.3:\n\nIf a message is received without Transfer-Encoding and with\n       either multiple Content-Length header fields having differing\n       field-values or a single Content-Length header field having an\n       invalid value, then the message framing is invalid and the\n       recipient MUST treat it as an unrecoverable error.\n\nThe request should error out with varying Content-Lengths, which hyper doesn't do, but at the very least, it shouldn't pick any of the stated values as valid.\n. It looks like the parsing of ContentLength has been left alone, so this test should still pass. I'd rather keep the functionality of ContentLength the same for now.\n. Just use the split iterator instead of allocating this temporary vector. It'd change the match to match (params.next(), params.next()).\n. Oh, and bump the indent for this closure please!\n. I believe this can use the fixed from_comma_delimited\n. I don't believe so. You don't need to have the trait imported for a type to implement it.\n. Openssl feature would still be enabled to provide the secure feature of cookies. So if you enable both, you'd be using the Openssl connector, right? \n. The manual implementations were deliberate actually, because it's faster to compile than rustc generating the huge match statements for this big enum...\n. Clever.\nA downside is that to set the Origin, you need to also have the Host type imported... Makes me think maybe the properties be private, with accessor methods?\n. unwrap doesn't propagate in that way. \nThis is unwrap:\nrust\nfn unwrap(self) -> T {\n    match self {\n        Ok(t) => t,\n        Err(e) => panic!(\"tried to unwrap, found err {:?}\", e)\n    }\n}\nYou probably want the try! macro, which will pull out T if it can, otherwise return Err(e).\n. Some discussion about parsing using Url has pointed out that we shouldn't accept an Origin that has a path part.\nHow about using this strategy instead:\n1. Find ://.\n2. Scheme is raw[..colon].\n3. Then Host::from_str(&raw[colon + 3..])\nI just took a peek, and saw there is no FromStr impl for Host, it'd probably be nice to move the parse_header code into a FromStr impl...\n. This should probably be port: None, since the raw header didn't actually include the port. Otherwise, once writing this header again, it will appear as if the header were really http://foo.com:80.\n. \ud83d\udc4d \n. using write!(f, \"{}://{}\", self.scheme, self.host) should do the same.\n. Nice! I had noticed that fixme and was going to file a separate issue, but you win!\n. I believe this step can be skipped (this step to a String). I'd expect this entire function could just be from_one_raw_str(raw), since inferrence should tell it to use <Host as FromStr>.\n. That doesn't sound right. I meant for this write! to be the only thing in the function. That way the Result is returned.\n. It might not be important yet. The idea I had was to have scheme(), hostname(), and port() accessors. By keeping the fields themselves private, it doesn't matter if we keep using Host internally, or some other field scheme.\nBut all the other headers are currently wide open. I'll consider a accessor pass before 1.0.\n. I'd try fn new<S: Into<String>, H: Into<String>(scheme: S, hostname: H, ...). The reason is that it's probably likely that a user had to construct a String anyways to create the hostname or scheme, it's a shame to essentially have format!(\"{}.com\", sld).as_slice().to_owned().\n. This is using Result from the crate root, which is hyper::error::Result<T>, which is an alias to ::std::result::Result<T, ::hyper::error::Error>.\n. I'd use next().expect(\"Server::new requires at least 1 listener\"), or something similar.\n. Hm, before this would allow a Listening to be printed nicely, by doing println!(\"listening on {}\", listening). This change will make the output look like listening on [V4(127.0.0.1:8080)].\nI suppose if there are muliple addrs, it likely should output a comma separated list. But either way, it'd probably be best to not have the Debug output of the SocketAddrs.\n. UnsafeCell::get is not unsafe, because it just returns a raw pointer. You can toss those around freely. However, dereferencing it is unsafe, which is needed to turn it into a safe pointer (the other way is to use mem::transmute, but that's also unsafe).\nThe extra caveats for into_inner are the same as using the pointer from UnsafeCell::get: accessing it is not synchronized over threads, but that is fine for us here, because of the mutable requirement of fn remove(&mut self).\n. Hm, I don't love that the return value could be more complicated, but how about this crazy idea: Option<Result<H, Raw>>...\nI'd personally just drop it, but is there a convincing case where the raw is still needed to justify complicating the return type?\n. Ah yes, of course, because the typed is storing them as Box<Header>. I think there is a way to add a downcast taking self by value, such as something like fn downcast(self: Box<Self>), but I'll toy on playground to find the right thing and report back.\n. Adding this to the impl Header + Send + Sync should do it:\n``` rust\n[inline]\nunsafe fn downcast_unchecked(self: Box) -> T {\n    (mem::transmute::<mut _, (mut (), mut ())>(Box::into_raw(self)).0 as *mut T)\n}\n```\nThen you can call val.downcast_unchecked() after having gotten the type from the TypeId.\n. Both feel yucky. I'd still prefer to just have Option<H>. The upgrade path could be to check headers.has() before calling remove().\n. Oh right. We can convert the *mut T into a Box<T> for free, with Box::from_raw, and then we can deref move out of the box:\nrust\n*Box::from_raw(mem::transmute::<*mut _, (*mut (), *mut ())>(Box::into_raw(self)).0 as *mut T)\n. I was imagine using something more primitive:\nrust\nlet end = s.find('?').unwrap_or(s.len());\n&s[..end]\nIs there a reason that this is incorrect?\n. Oh ok, good call. I'm wondering whether it's better to run the Url parser\nwhen constructing the RequestUri, and thus be able to return a reference,\nor do it on demand, as this patch does.\nOn Tue, Aug 23, 2016, 7:30 AM Ahmed Charles notifications@github.com\nwrote:\n\nIn src/server/request.rs\nhttps://github.com/hyperium/hyper/pull/899#discussion_r75877722:\n\n/// The target path of this Request.\n #[inline]\n-    pub fn path(&self) -> Option<&str> {\n-        match *self.uri {\n-            RequestUri::AbsolutePath(ref s) => Some(s),\n-            RequestUri::AbsoluteUri(ref url) => Some(&url[::url::Position::BeforePath..]),\n-            _ => None\n-    pub fn path(&self) -> Option> {\n-        match self.uri {\n-            RequestUri::AbsolutePath(ref s) => {\n-                let url = Url::parse(\"http://example.com\").ok().and_then(|u| u.join(s).ok());\n\nI was going for consistency and doing it in a way that I don't have to\nread the RFC and implement correct parsing and interpretation of urls.\nUrl::parse normalizes the urls, and therefore, it makes a copy. It would be\nweird if normalized paths and queries were returned for AbsoluteUri but not\nfor AbsolutePath.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/pull/899/files/e4ec7e0644b36b81407ec1899036c5c63b1dc2b9#r75877722,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AADJF2Xxk2msmuotBxxEluLzk2527Onvks5qiwQMgaJpZM4JqgGd\n.\n. This one is surprising. I would expect it to be a parse error.\n. Likewise, this one seems incorrect.\n. I'd be in favor of this test instead having 2 helpers, to prevent the proliferation of Some(...) in every test. Maybe something like:\n\nrust\nassert_eq!(parse(\"*\"), RequestUri::Star);\nassert!(parse_err(\"**\"));\n. The spec claims this variant has \"absolute-path [ \"?\" query ]\". Maybe its worth adjusting the variant to AbsolutePath { path: String, query: Option<String> }?\n. Excellent, I was thinking something like this would be needed. \n. This was done to keep the internals private. As a public enum, the internals are exposed and it'd be a breaking change later on to change them, since someone could have depended on the exposed internals. \n. A u64 was used before in case a chunk size claimed the incoming chunk was >4GB. On a 32-bit platform, usize cannot represent a number bigger than ~4 billion. Sounds absurd to send a chunk so big, but seemed prudent to be able to survive it.\n. Pretty clever, though it took me reading over it several times before I understood what you were trying to test specifically.\n. It didn't exist when this code was originally written (pre Rust 1.0), but there is now io::ErrorKind::UnexpectedEof, which seems more appropriate here.\n. Since this is saying that a read of size 1 is required, seems the error is more correctly thought of \"unexpected eof during chunk size line\". So it could now be represented as io::ErrorKind::UnexpectedEof.\n. A user may call read() again, and it should continue to just say EOF,  or Ok(0).\n. I was certain that the EPOLLERR would be set if there was also EPOLLHUP...\n. epoll docs suggest that EPOLLHUP is always listened for. May not be the case in kqueue/windows, I suppose...\n. Since these methods are called unconditionally later, anyone just upgrading hyper will find that suddenly, their custom NetworkConnector panics, which would be a breaking change. These should probably just do nothing, instead of calling unimplemented!.\nIf we want, we could put a warn! or even error! in here instead, so people looking at logs can see they should implement these. Or we could just do nothing.. This looks so much better!. I'd probably replace this with an AsRef<str> impl, since it sounds like stuttering when saying req.uri().uri().. I was actually thinking more that internally, we'd have Line change from Cow to another enum:\nrust\nenum Line {\n    Static(&'static [u8]),\n    Owned(Vec<u8>),\n    Shared(MemSlice),\n}. I planned on filing issues for a couple more passes through the file, removing the temporary Vecs and what-not. It can be fixed here if you want, or in another pass.. Again, instead of using only MemSlice, I'd think an enum of static, owned, or shared would be the best here. This is because it's not free to convert to a MemSlice if we don't already have one. And we want to keep the optimization for a super common route, / being just a static constant.. I've been thinking we'd need something like this, but a slightly different way may be better.\n```rust\npub struct MemStr(MemSlice);\nimpl MemStr {\n    pub unsafe fn from_utf8_unchecked(slice: MemSlice) -> MemStr {\n        MemStr(slice)\n    }\n}\n```\nThis forces us to use an unsafe {} block whenever we create a string, so we don't accidentally just create a MemStr that might not be utf8.. It's because we want to keep the unsafe near the proof. The proof that a certain MemSlice is valid utf8 is when we look at the req.path from httparse. Consider:\n```rust\nimpl Uri {\n    pub fn with_some_slice(slice: MemSlice) {\n        // save the slice internally\n    }\nfn something_else(&self) -> &str {\n    unsafe { from_utf8_unchecked(self.mem_slice.as_ref()) }\n}\n\n}\n```\nNow, what happens if future us (or some other future person), perhaps not remembering that this unsafety exists, creates a Uri::with_some_slice(my_maybe_not_utf8_slice) somewhere else in the code. It wasn't unsafe to create the Uri, so we don't realize that we did anything unsafe.\nCompare:\n```rust\nimpl Uri {\n    pub fn with_some_mem_str(str: MemStr) -> Uri {\n}\n\nfn something_else(&self) -> &str {\n    &self.mem_str.as_ref() // not unsafe!\n}\n\n}\n```\nA future persons then says \"I want to create a Uri over here, using my MemSlice, how do I do that? Oh, it takes a MemStr, how do I make that? Uh oh, only with unsafe from_utf8_unchecked(), I guess I need to check my MemSlice before trying that.. A MemSlice comes from receiving bytes from the socket. It has gone through httparse, which made sure there weren't radically invalid bytes here (just that it is a str without spaces), but we don't know if it is actually a well-formed Uri. So, we can't really provide the From<MemSlice> implementation, here.. Is there only allowed to be 1 Link header? If there a multiple, does the spec say anything about that? This function will parse if there is 1 link, and reject if there are more than 1, which is fine for some headers, just asking if that is the case with Link.. I've started to wonder if exposing all the fields publicly on headers was a good idea. I recently changed the Host header to no longer have public fields, but to have method accessors instead. That'd allow changing the exact types of Host.hostname, for instance, without breaking people.\nDoes that seem like a good idea here?. Probably should use .splitn(2, '='), for weird cases of rel=\"foo=bar\".. If we wanted to prevent this allocation+copy of the string, UniCase(link_param_name) could be used. Doesn't work with match, though.. It looks like verify_and_trim only ever is used with ASCII characters, so it can be done more efficiently with bytes. Changing start and end to u8, and calls to verify_and_trim(s, b'\"', b'\"').. A builder may be a good idea!\nI didn't mean to make those 2 fields generic, but rather, I was wondering if they are served well enough as String, and if someone wanted to, they can make a whole new struct MyLink { ... } header.. It looks like this is no longer used, or at least I cannot find it.. With the constructor on MemStr, this method is no longer needed.. This method should not exist on MemSlice.. Why this change?. This should hold a MemStr instead.. From implementations should be for conversions that cannot fail. As mentioned earlier, we receive a bunch of bytes from the socket, and after some httparse calls, we know the URI is a string, but we don't know if it is a valid Uri. It needs to go through Uri::new to parse it, and that could fail. It's better to not panic.\nI've updated master with a test case in the parse.rs module that will trigger this case, so if you rebase you should see the panic (that should be an Err instead).. This doesn't need to clone the slice just to compare the pointer. It can be this:\nrust\nlet path_start = path.as_ptr() as usize - slice.as_ref().as_ptr() as usize;. This goes through Uri::from_str -> InternalUri::from(&str) -> str.to_owned(), which means we're still copying the bytes here. We could instead introduce a new function in the uri module like so:\nrust\n// in uri.rs\npub fn from_mem_str(s: MemStr) -> Result<Uri, Error> {\n    Uri::new(InternalUri::from(s))\n}\nAnd then we can use ::uri::from_mem_str(path). Since the uri module isn't public, and only the Uri type is re-exported outside of the crate, we can keep the implementation details private.. I'd rename this variant to Cow, since it is misleading when you have InternalUri::Static(Cow::Owned(\"/foo\".to_string())), because it looks like a static string, but it is owned.. \nI found in the RFC https://tools.ietf.org/html/rfc5988#section-5.5 that the Link header can contain multiple links in a single header, by being comma-separated, and so the normal header rules apply which state that multiple headers of the same name can be joined together.\nAs an example, taken from a few pieces in the RFC:\nLink: </TheBook/chapter2>; rel=\"previous\", </TheBook/chapter4>; rel=\"next\"\n Link: </TheBook/chapter3>; rel=\"canoncical\"\nSo it seems this would need be able to accept several Links, both if a line has them comma-separated, and if there are multiple lines.. We should be able to remove this allow.. I wonder, would it be nicer to return Option<&[RelationType]>? Is there value in getting the &Vec? Probably not, but maybe. Same question for each of the getters returning &Vec.\nIf we wanted to do that, it'd be a change to opt.as_ref().map(AsRef::as_ref).. Like the comment above, maybe we want to return Option<&str> instead. A plus to doing that is that it doesn't leak the internal type, so if we later changed title to hold a Cow<'static, str> or something, the API wouldn't need to change.. No, Option just received a method to do this, but it's only in nightly, so this must do.. Perhaps T: Into<String> here, so people who allocated a String anyways can just give it to us, instead of us having to copy it again.. We should take the Mime by value, and allow the user to clone one or use the one they already have.. Awesome!. Visually parsing this line is difficult. I finally got what it's doing after several reads.. Fantastic, good work separating the logic out to make it easier to follow exactly how parsing works.. Should we keep the values field private?. I believe you are correct. Would you be willing to try to fix it?. This was part of trying to keep from busy looping, how broken is the \"this needs fixing\" part :D. Hrm, so as the comment below tries to describe, this situation would occur when hyper has read the end of a body, such as described by a Content-Length header, and then stops, as it's waiting on the response side to determine if it should read the next request.\nIf the socket were to already have some of the bytes in its buffer, then our not reading to end would mean TcpStream would not unpark the task again to read more. That's a scenario when hyper needs to park, and then unpark later when the response finishes and keeps the connection alive.\nSo, to get the same as poll_read from now on, does that mean we need to store our own read_has_blocked flag?. This case isn't really unreachable, HttpVersion::from_str(\"foo\") would hit it. It should return an error case instead.. The error should probably be Error::Version.\nAlso, this if could be removed, and empty string would match the _ arm in the match below.. Prefer a test against the Error::Version return value instead. This kind of test doesn't notice if the panic came from inside from_str, or from the unwrap.. Exactly what I was thinking!. Yay tests!. So that we don't leak that it is actually a Cow inside, let's just Deref to the $value type instead. This will let us change Cow to a Bytes or something later, and it should all still just work.. You can just elide all the fields you don't want, like so OriginOrNull::Origin { ref scheme, .. }. Aw, having to use Options is unfortunate, that I had forgotten about. Oh well, there's no other way!. My understanding of the suggestion for this method was to clear the values of only this key. This would seem confusing:\nrust\nlet mut cookie = Cookie::new();\ncookie.set(\"foo\", \"bar\");\ncookie.set(\"baz\", \"quux\");\n// where did my foo=bar go!\nassert_eq!(cookie.to_string(), \"baz=quux\");. This would allocate a brand new String, before then writing it to the formatter. It can be done without the temporary allocated, such as write!(f, \"{}={}\", key, val).. The VecMap is sufficient on it's own. There no need to double the strings here. The VecMap has insert and append, and iter gets all the key-value pairs, with duplicates.\nAlso, a Cow<'static, str> can be used, which allows someone who wants to set the same key and value on all cookies to do so without allocating and copying memory for it:\nrust\nlet mut cookie = Cookie::new();\n// no allocation or copy required\ncookie.set(\"foo\", \"bar\");\n// dynamic string, use a String\ncookie.set(nonce_key.to_string(), nonce_val.to_string());. We'd still want a Debug implementation. It can use formatter.debug_map().. So as to mirror Response, I was thinking that the methods should perhaps be body_ref() and body().\nMaybe exactly how the body stream is taken from a Request or Response should be different, but if so, sounds like a separate issue to discuss.. Returning a &HttpVersion instead of HttpVersion might have been inconsistent on one of the types. The intent was to just always return it by value, since it's smaller than a pointer and Copy. Could you update that here?. Yes, this looks like the best one:\nrust\npub fn body(self) -> Body { self.body.unwrap_or_default() }\nTechnically, with that it's possible for the impl to exist for B: Default, but I don't know if that helps anyone, really. For all incoming streams (incoming to this machine, built by hyper internall), it will always be Body.. As pointed out in https://github.com/hyperium/hyper/issues/1085, this is incorrect. A later commit simply removed the link_extension pieces, allowing for them to be added correctly later.. I'd go ahead a slap #[derive(Debug)] on this instead. It shouldn't actually leak anything about cows, and instead should allow someone to view a list of strings pairs.\nAlso, I'm surprised the deny(missing_docs) lint didn't catch no documentation on this struct.... I've toyed around with this a bit, actually. Using a Vec is actually faster here. BytesMut has some atomic checks inside each of its methods, and since we never share this buffer to other threads, we don't need it.\nI have toyed with passing self.io.write_buf_mut() directly, instead, since it is likely an already-allocated vector, and would remove the copy from the intermediate vector into the write buf. I couldn't tell with my machine if it made any noticeable change, and was also worried about the reserves inside encode making the buffer bigger than the max buf size, so, it hasn't changed. I'd welcome a change with measurements showing an improvements!. Same comments about extending a Vec being faster than a BytesMut here.. The idea here is actually to try to use the writev syscall, which could be done with AsyncWrite::write_bufs. Before tokio, that's what AtomicWrite tried to do. AtomicWrite is now just a legacy artifact I haven't refactored yet.\nThe point is, it's better to keep all these as individual slices, and allow the writev to write all of them at once, without needing to copy them in user space. . There is already a buffer to write into, in io.write_buf.. The compiler can inline itself. I've left the way it is as a reminder to investigate using AsyncWrite::write_bufs in the future, but I know that it's only a reminder to me, no one else would be able to determine that. Probably could use a comment to that effect. If you'd rather inline the implementation and have a comment there instead, that's fine.. I hear ya, and it's a worthy goal! The best way would be to make use of AsyncWrite::write_bufs, which will prevent a copy in the plain-tcp-on-unix case. Unfortunately, on Windows, and when using TLS, flattening (copying) into a single buffer is required.\nIn this case, since we're dealing with performance sensitive stuff, I'd love if any changes could include benchmarks showing that it was an improvement. I've spent a lot of time twiddling with things thinking it was an obvious improvement, and it turned out to make no difference.\nFor extending the write_buf, there's the additional constraint that it should ideally never grow beyond MAX_BUFFER_SIZE, which could happen with APIs taking a &mut Vec.. I tend to try a few things when checking performance: \n\nLook into a specific #[bench] in the file of the function I'm optimizing (or write one if the thing I'm optimizing isn't specifically benched). For instance, there is now a bench_server_transaction_encode in the h1.rs file, when I was writing the date.rs stuff.\nI run cargo bench --bench server (or --bench end_to_end if the stuff I touched would affect the Client also).\nI run cargo run --release --example hello, and then run wrk to see if requests per second changed.\n\nI compare the results of master vs my current work to determine if it was useful.. The code here is actually to be a fast path, since use extend is faster than going through the formatter, and HTTP/1.1 200 OK\\r\\n is the most common path, so it was made to be slightly faster.. I don't recall anymore. If someone is interested, it's possible run the benchmarks with and without this optimization.. It depends on resources of your computer. I tend to stick it to 1 thread, cause I use a shared server, and a duration of 10 seconds. So -t1 -d10. Then, I bump up the connections until it starts to reduce the req/s significantly, and then use the same configuration in the feature branch, and then compare req/s.. These 3 manual impls were because the auto derives noticeably affected compile times. Is that no longer the case?. This should include the total bytes part. This is what let's the benchmark show the MB/s.. While you're here, just noticed this, it'd be better to use 8kbs (8192) instead, since that's more typical of a full TCP buffer.. Oh my the chunked overhead for such tiny messages!. Oh wait, this is sending a single Vec<u8>, with b\"Hello, World\" in it a million times. I misread, and assumed it was sending b\"Hello, World\" as a million different chunks, and so was thinking that every single message would wrapped by the chunked header and trailer.. Oh right, good catch!. I find it adds value, because it encapsulates the safety into a separate type, so that Uri doesn't really need to think about safety.. Storing a &str isn't necessary. The API of ByteStr works just fine. The point is that we kind of want a String, but one that can be shared, since we receive Bytes when parsing new requests.. The Bytes type is sort of like an Arc<Vec<u8>>, which some improvements. The point is so that when a Request is parsed and constructed, the various pieces internally the are backed by a string of bytes, all point back to only a single shared buffer. So for a Uri, the string \"https://github.com/hyperium/hyper/pull/1226\" isn't copied into a new part of the heap (like it would if we used String), but its only one slot, and Uri's Bytes keeps the indices of what part it's interested in.. Returning an Err from Stream::poll signals the stream is doomed. Tokio will drop the stream.. Could we get a test case at the bottom, like there is for should_keep_alive?. This would likely be dynamic right? As in, at compile time, how often you know what the last event that was sent on a connection? Probably never?\nSo then String seems fine... Although, is the ID frequently a string? Would people usually just generate some random hex bytes for the ID? Or is often a number?. This is the exact same thing, isn't it?. That all of these boilerplate impls are needed is a bummer. Sorry to have to write that XD. \u2764\ufe0f . So, what exactly is the P? From what I can tell, is it just some arbitrary thing that might be created when inspected a Request, and useful once upgraded?. I'd eventually move the hyper::http module to be hyper::proto, most likely. That'd allow using the http namespace for the crate. I realize fixing all the renames is tedious, so I'm not saying it's required, I can get to it eventually :). These Method conversions can probably skip parse in most cases, and just match on the common variants, so the cost should be minuscule.. By using From on all the types, we can skip the builder, and use the http::Request directly. I say that just because for a conversion like this, performance would be crucial, and so skipping the error checking when we know there's no errors will be noticeable.. Thanks to hyper::StatusCode::Unregistered being able to have any stupid u16, this is likely the best approach!. The to_string is unfortunate, but it doesn't look like there's a good way around it, as hyper::Uri provides as_ref for &str, requiring the holding of 1 contiguous buffer.\n... Hm, though, http::Uri is backed by Bytes, just like hyper::Uri. I haven't looked to remind myself, but I wonder if there's a combination of methods that can be called to try to prevent a full alloc and copy?. The HttpVersion::__DontMatchMe variant can be used here, so we know it shouldn't ever exist, and then use unreachable! instead of panic!.. \ud83d\udc4d . That's a good point, I had forgotten about that variant. Woops.. Does changing the above to fn request<T>(&self, req: T) where T: Into<Request<B>> work for all previous examples, and also allow using http::Request? That might be nice into of having to call client.request_compat?. The Client implements Service, which actually makes it pretty simple to use for proxies in a server (just provide a client as the Service for a server!). So it'd probably need to implement it for http types also.\nAgain, I wonder if the current Service impl can be adjust to take Into types and then kind of automatically work for both. This one might be trickier, not sure.. If we wanted to try to make this even faster, the bytes could be split using the indices we already know, and a http::uri::Parts could be built from it. I wouldn't recommend spending time on it though, as the performance difference probably won't be noticeable versus the wait till 0.12.... Actually, now I wonder if the Http::bind bounds can use Into, like I mentioned for the Client stuff. Possibly not, not a huge deal if it can't.. Could this be impl<B> From<Response<B>> for http::Response<B>?. Could this be impl<B> From<Request<B>> for http::Request<B>?. Could this use the Headers::from(header_map) impl?. This should use header.raw() instead of value_string(). The value_string method can panic, even though the raw bytes were a valid header value.\nAdditionally, when using raw, that should mean a 2nd loop. The name can be constructed once, and used for each call to append for each item raw.. This should use append_raw, since set_raw will overwrite any previous value for a header name.. Ah dang, I see what you mean, it can't be done because of the generic + From + target is not a crate local.\n\nIt can stay as it is, using the default generic of hyper::Request, and just not have a conversion when one has hyper::Request<SomethingElse>. In this case, hyper::Request<B> can grow an into_compat method to compensate...\nWe can have an Into instead that does allow the generic, but then http::Request::from(hyper) doesn't work...\n\nI'm not certain which is preferable, actually. Probably depends on which case is more common (using From::from, or hyper::Request<NotDefaultBody>).. The docs say text/xml; charset=utf-8, but TEXT_XML is text/xml. Either the documentation is wrong, or the implementation :D\nI've typically stayed away from XML as much as possible (lifestyle choice), so I can't say from experience which is more common. I suspect including the charset is?\n. I'm personally fine with them panicking for now. It is an opt-in compat layer, and any panics should be horribly wrong, unexpected bugs. If TryFrom were stable, I'd be fine with using that, but it's not.\nIf you'd rather, try_into_http inherent methods can be added, to allow non-panicking methods.. The clone here isn't need, core.handle() already returns Handle.. This probably means bind_handle should return a Result, just like bind does, so that we don't panic.. Is it possible to not expose this type to outside the crate?. Could this inner enum go away, and just be a field of HttpConnectorBlockingTask?. I'm slightly worried about exposing the generic here. I suppose with a default set, it should still compile for everyone... The alternative is to keep a Box<Executor> (or perhaps Arc<Executor>).. Oh OK, it's used for the generic type on futures::future::Executor<T>... Could the constructor new_with_executor just be generic over F: Future<Item=(), Error=()>? After that, it's turned into a trait object and put in an Arc, so the generic isn't really important.... I checked out the branch and saw what you mean. Ideally we'd accept E: Executor<impl Future<Item=(), Error=()>, since there isn't really a reason to tell anyone the exact type that is being executed. If I delete from this export, it's essentially doing that. It's a type that implements the future we want, but users can't name it (as would be the case with impl Future), and seems best to me.. It's more usual for setters to just mutate the type itself, than to return a new type. We should probably stick with the usual :D. Typo: \"together\".. Hm, I see why this returns a Result. Google requires the max age minimum in order for a site to eligible to for its own preload list.\nThough, I'm not sure if we should be enforcing that specific requirement here.. I wouldn't enforce the limit when parsing the header either. It's a perfectly valid header, it just doesn't meet the requirements for Google's list at the time of writing (but could in the future).. It seems that this will drop the TcpStream right upon connect, and so there won't actually be that many concurrent connections. I think.. The original goal of the Extension variant was to allow for new arguments even if the version of hyper doesn't support them (hence being just Strings). Would it make sense for these new variants to just be on CacheDirective itself?. I suspect users to be able to configure a hyper Client, stating whether to allow both HTTP/1 and HTTP/2, or to require only HTTP/2. To allow both, ALPN needs to send both protocols. A connector would query the Destination to determine what protocols it should try for.\nI wasn't actually sure what to name the methods. They are meant to represent the desire of the user, but some desires may be wants or preferences, versus musts. Maybe some combination in this list is better?\n\nmust_h2\ncan_http1\ncan_http2\nprefer_h2. This was added when I was prototyping in hyper-tls, and noticed that to wrap another Connect2, I needed to take the transport out of the Connected. It's kind of verbose, however, and loses whatever settings the previous connector may have set. Would map<F, U>(self, f: F) where F: FnOnce(T) -> U perhaps be a better fit?. I would expect the Connected type have some methods to be able to set what protocol was actually negotiated. Should this be setters instead, set_h2() etc?. Actually, this also seems like a good way for connectors to report back if it's an HTTP/1.1 proxy, and so the absolute-form should be used for h1.\n\n@tafia This may interest you, as you developed hyper-proxy. Maybe something like connected.set_proxy() or set_http1_proxy().... That is a fine time to do so, or even if you're not using a pool, and just have a single connection, it lets you know if the connection could process it right now. I think I need to alter this PR slightly so that it returns NotReady for h1 connections that aren't pipelining. It would also return NotReady if this were an h2 connection and you'd reached SETTINGS_MAX_CONCURRENT_STREAMS.. It could, but that's probably a trap, since you may not choose to do anything special with a Connection, and just call exe.spawn(conn.map_err(|e| debug!(\"conn error: {}\", e)). If you did that, and poll did what poll_with_shutdown does in this PR, then the transport would never have shutdown called.\nIf Connection::Item were Parts, then that could probably be easier, since then you'd need to handle the Parts in some way (even if just dropping) when spawning the future. But, in order to do that, Connection needs to hold the internal state in an Option, so it can remove it, and thus every poll requires a self.inner.as_mut().unwrap(). I figured by providing poll_without_shutdown, Connection::poll isn't bothered, and anyone could wrap poll_with_shutdown and an Option if they wanted that kind of API.\nDoes that reasoning seem convincing?. Currently it tells the internal h1::Conn that after the first response, it cannot be used for a new request, and sets its state as Closed. This is the same as disabling keep_alive on the Client as well.\nI've sometimes thought that it should probably set Connection: close, to be nice, but then, even if the header isn't set, once a response has been read, it's up to the client to use it again, or close the connection.\nInterestingly, I think this option would do nothing if the connection were HTTP2. Or maybe it could send a GOAWAY after the request.... If the connection weren't ready, you'd get an error. We start using this poll_ready -> send pattern in the h2 crate, and it felt very natural, and it's what Sink is changing to in futures 0.2.. We couldn't make this change for 0.11.x, but could be in 0.12.. Could be done like this, right?\nrust\nmatch self.listener.accept() {\n    // Ok ...\n    Err(e) => {\n        if let Some(delay) = self.sleep_on_errors {\n            // continue or delay\n        }\n        return Err(e);\n    }\n}. All the lines printing about using 1 thread can probably be adjusted now :D. I'm curious what the lazy usage is for. Is that because calling all this code outside of tokio::run will panic?. I think this can be made slightly nicer in 0.2 with FutureExt::left and FutureExt::right, meaning we no longer need to import Either, ya?. Hadn't noticed before, this could just be try_ready!, huh? Don't need to fix, but if you wanted \ud83d\ude09 . I think there's no FutureExt::recover for this pattern, right?. This pattern is kind of confusing, could be fixed later though.. The check of poll_ready before spawning on the executor was to try to let the connection be available for reuse earlier, which was noticeable when using tokio's runtime, since the task might end up on another thread and thus insert back into the pool after the user got a finished response.\nIf the problem was calling poll_ inside a combinator, I've been meaning to add a pub(crate) fn is_ready to SendRequest, that would simply check wants atomic state without parking.. If taking a &mut, does this need to clone?. I'd rather not spawn Connection tasks onto a futures ThreadPool. It does not handle multiple futures at the same time (it processes them serially, only polling the first in the queue until it's done).\nIs there even a reason to still have the Exec type around? Can't we just use cx.spawn?. Is this meant to just be deleted?. I think I prefer cx being the last argument, as it's \"less important\"... I filed https://github.com/rust-lang-nursery/futures-rs/issues/883 as well.. Oh also, does this even need a Context argument? Seems it's not used?. Likewise here, I'd probably suggest the cx be the last argument, since we don't really need to notice it.. Yea, this is how I'd probably do this too. :+1:. I think this can still be done with WriteBufAuto, that allows only doing the strategy checking as long as it's still Auto.. I think this can be FutureExt::recover also.. Why does this return Either now? It's not immediately clear to me.. I think there's a recommendation that libraries shouldn't depend on futures directly, but rather on the individual crates (like futures-core, futures-channel, etc). The idea is that hyper could keep working if some extension needed a breaking change, and we only ever publicly claimed to depend on futures-core...\nIt'd be good to take inventory of what public dependencies we may be exposing here, either directly or indirectly:\n\nfutures-core since things like FutureResponse implement Future.\nfutures-io since we accept AsyncRead and AsyncWrite...\nI think all usage of futures-channel is no longer publicly exposed, so not a public dependency, right?\nWhile we use FutureExt internally, any types returned from it aren't viewable from outside the crate, I think.. Ah OK, right. That schedule_pool_timer was introduced as a bit of a hack, and it's still being all hacky. I guess I'd move it to being called from Checkout::poll, so that it's only created once the client starts to get used, and there's a Context to grab.. Ah, it does look like it has been updated there, cool!\n\n\nWe need a Send-able and Clone-able executor, but that's not guaranteed for the default executor.\n\nWhy do we need that?\n\nin cases where block_on has been used the executor will close once that future has been resolved\n\nThat's a really good point! Hm, I'd really hoped to be able to make use of cx.spawn, but this point seems to be a blocker. As if that executor should probably not exist, or at least it shouldn't provide an executor to the context that can actually spawn.. Yea, so I think that we should indeed just use cx.spawn, and not hold any executor inside the Client.\n(The tests might need to be changed to stop using block_on. At least, it definitely won't work with the published 0.2 beta.). I don't want to burden you with my stylistic whims. If you want to leave things the way they are, I may just shuffle argument orders as I'm touching various files in the future.. I mostly was thinking of these reasons:\n\nAllows the strategy swapping code to be separate from this, which is just wanting to write until blocked.\nThe checks to determine what strategy to switch to could probably only have to happen when strategy it still auto.. Oh, weird! (That spawn API feels a little odd, but not your fault :)). If you wanted to update the Cargo.toml to point at the git repo of futures, to get things working, that's fine!. You need to use the [replace] part, so that all dependencies use the same library also.. It looks like the receiver will return an error if the sender was dropped, so we should be able to just ignore this spawn error, right?. We should be able to completely remove the executor field of the client, and always use cx.\n\n(HttpConnector should still own its own executor, but that's because it needs to spawn blocking tasks. It should be enough to allow configuring the HttpConnector manually.). Oh, this is what made it pass always :D. I'm strongly considering making the default Server::bind either a) panic if binding errors, or b) lazily binding on the first poll of the Server. Forcing users to deal with an error that isn't likely to happen every single time feels like an annoying speed bump. Anyone wanting to handle a bind error can bind a TcpListener themselves, and use Builder::new.. I'm undecided on whether to keep this, or remove it. I did this since it allowed providing a hint in the message that things have changed, instead of simply hyper::server::Http is private. But it may be annoying to keep around for all of 0.12.x.... I'd put this in a # Panics section, and include the exact minimum, so that people can see what they need to guard against. Something like:\n/// # Panics\n///\n/// The minimum value allowed is 8192. This method panics if the passed `max` is less than the minimum.. True. I'd like to bring the implementation back for Client, which will need to define the ReqBody. I'm just unsure about how best to move forward to tower::Service, which has a poll_ready function (and may be changing soon).... I'm thinking that perhaps this field shouldn't be logged, since the State gets dumped somewhat frequently to help debug the current state, and seeing this longer field being the same constant forever will just be noisy.. Since there's no way to set this for the server yet (and I'm tempted to leave it out until someone asks for it), the bool check is kind of a waste. Whatcha think of removing it from the ServerTransaction version here?. I believe this will get a couple characters changed completely. Specifically, | and ~ will become \\\\ and ^, respectively. Probably not super common, but it'd be a semantic change...\nAlso, it'd be nice to include some tests of title_case, perhaps at the bottom of the file.. The z byte is 122, not 172 :D\nActually, to make it clearer, you can just write b'a' and b'z', which the compiler sees as the meaning the ASCII byte of the character.. Great, awesome!. Just some bikeshedding: what is something like this more commonly called? A \"local\" address? The \"bind\" address? And, would it be better to call this an \"address\", or just \"ip\"?\nI don't have much preference myself, as long as it's been considered.. I think my personal preference here would be to not include an entire example file, as it means another thing to adjust when changes are required. We don't have an example for every combination of configuration options.... I think we can probably build the rewinding in internal, and not require that ever transport type a user might want to use have to implement this function. Basically, a private struct Rewound<I>. Here's a way I'd do it:\n\nIn the h1 case, nothing should be needed there. If there is a parse error, we can just use deconstruct/into_inner to get the original transport and the read_buf back.\nIf we've done number 1, and want to start the h2 handshake, then a Rewound would be constructed with those 2 pieces, and then Rewound<I> would be the AsyncRead + AsyncWrite type passed to the h2 handshake/connection.\n\nThat'd make the server::Connection type look kind of like this internally:\nrust\npub struct Connection<I, S> {\n    inner: Option<\n        Either<\n            h1::Dispatcher<..., I>,\n            h2::Server<Rewound<I>, ...>,\n        >\n    >\n}. This could probably be inside T::on_error instead. Hm, it could perhaps be useful if the on_error method were adjusted to allow accessing the current &read_buf. Then, ServerTransaction::on_error could check to see if it at least starts with the HTTP/2 magic prefix before deciding to bubble the error back up (and let server::Connection try h2), or to just return the HTTP/1 bad response.. That could work... I'm not sure I've thought through all the ramifications of that. We couldn't actual require MSG_PEEK, since that specific to TCP, and the IO type could be anything. Hopefully, handling of errors is still similar, so that h1 parse errors still send an appropriate HTTP/1 response.\nThough, this would solve an issue I hadn't commented about yet, which is that the h2 fallover should only be applicable on the very first request. If the stream has already spoken h1, a later parse error shouldn't try to upgrade to h2.. There isn't an enforced preference, really... keeping things in less files came from two reasons: a) it can get annoying to have to import a bunch of the same stuff over and over, and b) sometimes some types make use of private fields of others (though this is less important now that there exists pub(scope)s.\nIf you think it's clearer in a separate file, that's perfectly fine :). It's fine! I've really wanted to take some time to clean up the tests, they've become a mess. They started with just a server helper, but eventually more specific details needed to be tested, and I never took the time to group up boilerplate.. I think this can just be Dispatcher::into_inner, right?. Is this new bounds required?. May want to demote this to a trace!, and remove the other two debug! logs in this function.. Ah, I see. If these bounds are removed, then they won't be needed in several other places as well. Usually, prefer bounds only on impls that need them (sometimes it's unavoidable in a struct definition, if you need to refer to an associated type).. Prefer self.pre = Some(bs) instead, since get_or_insert does some matching on the original field, but we aren't using it.\nYou could put a debug_assert!(self.pre.is_none()) before setting it, for correctness while tests are run.. Perhaps here and in read, the pre should be changed to None once all the bytes have been read. That will mean then skipping the rest of this if block on latter reads, and allow the Bytes to be freed since it's no longer needed.. I don't actually understand the question, or what this test is testing :D\nMind adding some comments about what each part of the test is triggering or why?. I think there may be a more idiomatic way to copy between a Buf and a BufMut. I think this may work:\n```rust\nlet cnt = buf.remaining_mut();\nlet mut bs = bs.into_buf().take(cnt);\nbuf.put(&mut bs);\n// bs.into_inner() stuff\n```\nIt's unfortunate the dance needed for BytesMut. It's already been decided that it was mistake that it doesn't implement Buf itself, but it can't without a breaking change. It will in bytes 0.5.. Oh, I see what you mean. Yea, this behavior is correct. You don't want to copy the buffered bytes, and try to a syscall in the same read. Because: what's the behavior if there is an error from the syscall? Return the error? But then the buffered bytes... what about those? It's messy.\nPlus, anyone relying on a read to completely fill a buffer is definitely using IO incorrectly. You never know exactly how much data might be in the kernels buffers, and you don't know if more arrived just as it partially filled your buffer, so you just have to keep reading until your buffer is full, or your get WouldBlock.. Oh great idea, so that Http1Transaction doesn't need to get more complicated, I like it!. I'd probably remove these traces, I'm sure they were useful developing the feature, but afterwards, debugging other things will likely mean these just feel more like noise.. I believe these bounds can be removed from here and the fmt::Debug impl :). This is just a thought, feel free to tell me it's crazy: it may be possible to actually just pass T here, and not need Rewind<T> only for h1. It seems like the only time rewind is called is when deconstructing h1 and building an h2 dispatcher, so in try_h2 is where it could be let io = Rewind::new(io); io.rewind(read_buf); .... I have a hunch this will mean that this new feature doesn't affect the performance of HTTP1 at all, since the read calls would never need to check the rewind buffer.. Should this instead show just using tokio-fs instead? I slightly worry people will miss this line and think they should just do blocking operations anywhere... Or do you think there is value in seeing the more general blocking tool?. Since this is only used in the examples, I think this can just go in the dev-dependencies, yea?. Since this could be a body for a client request or server response, the doc should probably just say it \"aborts the body\".. For now, I'd suggest making this just pub(crate).\nOh and then, these 2 functions can probably be reduced to calling a 3rd, private constructor, fn new_channel(content_length: Option<u64>), to remove duplicate code, yea?. If the constructor to set a length on the channel variant is private, we can rely on hyper's decoder to always limit the body size that is streamed (it enforces the length from the connection). Just for sanity, we could keep a debug assertion. Something like:\nrust\nif let Some(ref mut len) = *len {\n    debug_assert!(*len >= chunk.len());\n    *len = *len - chunk.len();\n}. I agree, this part should only be done for the CONNECTION header. If someone had some weird custom chunked: roflcopters header, then it could be removed because of removing Transfer-Encoding: chunked.. At least the header can be checked for, right? assert_eq!(res.headers()[\"content-length\"], \"13\").\nWith that, these #[ignore]s could be removed, and just the checking of res.body().content_length() could be commented out with a TODO.. Since it's not needed, this pattern could be replace with just .... This looks like it sets content_length of the Response's body by parsing the length from the Request. (Curious the tests didn't catch it...). Woops, I guess I didn't notice this the first time: this constructs a HeaderValue eagerly, even if there was already one set. This would need to be or_insert_with to make it not wasteful.. Thanks, added a comment for Future Someone.\nYes, this does depend on select's current logic... though the new test would be failed, and there is already another test to make sure the connect future is lazy, since we were otherwise seeing a lot of TCP streams started up and tossed immediately with a custom connector.... Unfortunately this would be a breaking change, since any place someone has before something like struct Foo(hyper::client::ResponseFuture) would no longer compile, since they'd need to add the generic in. And with impl Trait, they'd have no way of ever define the exact type there, so the generic would need to be propagated to every other type holding one. So in the mean time, this case will need to stay with a inner boxed trait object.\n(Supposedly it will be possible later to have struct ResponseFuture { inner: existential type Future<..> } or something like that, so there's hope!). Oh neat! I thought that even with cfgs, the older compiler would fail at the parsing step (which happens before cfgs are applied).. It's not a requirement, I'm just thinking out loud here: do you know if there's a way that the code inside these two functions could only be written once, so that edits to one doesn't mean the other accidentally drifts?. It seems CI noticed that this cfg should go on the impl instead.. I thought about it some more, and I do think it makes sense to convert into the internal AddrIncoming type instead. The changes will be easy, and then anyone using it will be able to take advantage of the default improvements like sleeping when max FDs is reached.\nThe changes are to add a pub(super) fn from_tcp() to AddrIncomong. The new function can be split, such that after getting the std_listener, it just calls AddrIncoming::from_tcp internally. And then this function also can just call AddrIncoming::from_tcp(listener).. Actually, since this should change to convert into an AddrIncoming, this whole impl can just be merge with the one below it.... Oh? I've been concerned about cfg being a single namespace, so I've gotten in the habit of prefixing custom configs... :shrug:. The Client is basically a Arc internally, so no need to double arc it.. Instead of the odd trait (HttpTryFrom will go away someday, whenever TryFrom actually stabilizes (so like 2038?)), this change just be uri_string.parse().. I'd change this to just UnixIncoming.. The name AddrStream probably makes less sense for UDS, it could be UnixStream or UdsStream or something.. What even is the SocketAddr of a UDS?. I think this can be removed?. What is a socket address of a UDS listener?. I wouldn't make a separate uds feature, just make this part of runtime.. But std doesn't define a UnixIncoming does it?. Fair enough!. This println snuck in ;). I'd leave this default at 8kb for now. Requests without a body will likely never need bigger.. I'd leave this as it was for now as well.. Since this size is uses for all reading, both chunks and headers, it maybe should be named read_buf_size.\nThough, as I think eventually allowing to adjust a read buffer strategy is a good idea, maybe this should state that it's using an exact size always. read_buf_exact_size?. Setting the max buffer size is currently only done on the server side (via Http::max_buf_size). I think for this new API, this should be about setting an exact (as in, always use exactly and only this size) read buffer size. Thus, (assuming read_buf_exact_size as the Builder function name), calling Conn::set_read_buf_exact_size should also just set max_buf_size to the same. WDYT?. I'd probably include as a last sentence \"Default is true.\".. Typo: 'whether'. Since it's specific to HTTP1, what if the name were prefixed with h1_, like the others?. Since it's HTTP1 only, perhaps the method should be prefixed with http1_, like the other builder methods in client/mod.rs.. We should probably document that setting this option conflicts with setting the http1_read_buf_exact_size option.. This should probably not be doc(hidden), but include similar wording to what it says in tower-service.. Hm, didn't think much about it, really!. This is more of a bit, but there isn't actually an HTTP2 setting for the initial connection window size. It always starts at 65,535, and this is set, we just immediately send  a WINDOW_UPDATE for the connection to make up the difference. So I'd just remove the setting reference, and just mention this changes the max connection flow control.. How about this, to reduce branches:\nrust\nif msg.head.subject == StatusCode::SWITCHING_PROTOCOLS {\n    (Ok(()), true)\n} else if msg.req_method == &Some(Method::CONNECT) && msg.head.subject.is_success() {\n    wrote_len = true; // will prevent content-length and transfer-encoding from being written\n    (Ok(()), true)\n}. ",
    "cactorium": "Is it alright if I take a stab at this?\n. @seanmonstar Awesome :D \nI think I did it? https://github.com/hyperium/hyper/pull/199 I'm still working on figuring out how to test it, but here's something to look at for now\n. https://github.com/hyperium/hyper/blob/master/src/net.rs#L257 It looks like they're verified, peek around there and the openssl docs if you want more details: https://www.openssl.org/docs/ssl/SSL_CTX_set_verify.html\n. Thanks!\nI was thinking using some structs like  SslListener<L>, SslAcceptor<A>, and SslServerStream<S>  to wrap around an arbitrary listener/acceptor/stream would be a more elegant design, would it be alright to write another pull request using these instead of the current approach, and see which one looks better?\n. @reem  That's good to hear :)\n. Note to self: try merging instead of rebasing next time to avoid O(n^2) commits... \n@seanmonstar Ah, crap, where should I put the TcpListener that's in HttpListener now if HttpListener is an enum? Maybe instead of directly instantiating them in http(...) and https(...), there's a pair of helper functions to make them, like HttpListener::new() and HttpListener::new_with_ssl(...), and the ssl details are stored in an Option<(Path, Path)> in HttpListener? And this also means the listeners are only kind of half-initialized until bind(...) is called, which seems kinda funky.. Sorry, I'm guessing I didn't entirely understand what you mean. Also, Happy New Year's, give or take a few day!\n. @reem It's weird. I think it's showing up in my repo correctly, but on PRs it looks like I'm recommitting everything. Is git rebase --continue the same as git rebase?\nThat still means that the inner: TcpListener field doesn't get a value until bind() is called, but it'll be instantiated earlier before binding, since it needs to be passed into the Server object. I guess just wrap it in an Option<TcpListener> and ignore the kind of weirdness of it?\n. What if the listeners were created using a factory:\n```\npub trait ListenerFactory {\n    pub fn bind(...) -> Box;\n    pub fn new() -> Self;\n}\npub enum HttpListenerFactory {\n    Http,\n    Https(Path, Path)\n}\npub impl ListenerFactory for HttpListenerFactory {\n    ...\n}\npub struct IdentityListenerFactory { }\npub impl ListenerFactory for ... {\n    ...\n}\npub struct Server {\n    // ...\n    listener: Box>,\n}\nimpl Server {\n    pub fn http(...) -> Server {\n        Server::with_listener_factory(..., box HttpListenerFactory::::Http)\n    }\npub fn https(..., key, cert) -> Server {\n    Server::with_listener_factory(..., box HttpListenerFactory::<L>::Https(key, cert))\n}\n\npub fn with_listener(...) -> Server {\n    Server::with_listener_factory(..., box IdentityListenerFactory::<L>::new())\n}\n\npub fn with_listener_factory(ip, port, listener: Box<NetworkListener>) -> Server {\n    Server::with_listener_factory(..., box HttpListenerFactory::Https(key, cert))\n}\n\n}\n```\nThat way the factory could be used to choose between a custom listener, or the standard Http/Https one, and NetworkListener would work basically like how it does now. Or would that be too complicated?\n. Wow, the code looks a lot cleaner! Gonna read through all of it and see if I can figure it out\n. Fixed! The ssl_context functions return a Options instead of a Results, so I made a macro called try_some! to act like try!\n. SslContext doesn't derive Clone, and using a reference causes a lot of lifetimes to be required, so this is the best solution I can come up for this. Any thoughts?\n. ",
    "veeti": "What's the story for certificate validation in the client?\n. Thanks: so (rust-)openssl does verification, but is something required on the hyper side? I see there's no default verifier included and the provided client example accepts everything for me. Is this expected? Should I file a bug for this?\n. Hyper doesn't seem to do any TLS verification right now with the default client settings. Any untrusted certificate goes.\n. ",
    "reem": "Compression specifically could be left up to downstream things to implement. Not sure this is the domain of an http library.\n. I think the best solution would be to expose a stream of Request/Response pairs as an Iterator, much like TcpStream, and then registered handlers would just receive this stream and can decide on whatever concurrency strategy they want.\nI think this is the most flexible approach we could take, especially considering that it's unlikely most users will interact with hyper directly so providing flexibility to frameworks is key.\n. This can't be done nicely without a much stronger abstraction - we'd need the ability to arbitrarily intertwine iterators, yielding whichever one returns first, which I think is actually quite tricky.\n. Scratch that. Implemented in #25, I created rust-intertwine to take care of delegating to many iterators in parallel.\n. I think this is fine, since you can choose your own representation for a Header if you want better support for a non-standard value for that Header.\n. However, I think we have to be very careful with Headers like TransferEncoding, Date, and Host, which are baked into hyper.\n. Uh oh, you're right. It just occurred to me that the existing scheme is entirely unsafe. If you try to access a header through two representations, you'll get an undefined transmute!\n. This is fixable by tracking TypeId, but I don't see a good way to allow access under two representations in the same app - if you use one representation you can make a change that might not be represented in the raw header. i.e. I can write the transfer encoding to gzip using one representation, but another representation still sees the original encoding.\n. I personally prefer the method chaining API offered by curl, considering that most requests are made and sent all at once and not modified by a large number of different functions like a server request.\nI have a rough sketch of this API in one of my branches, I'll probably make a PR later today.\n. Hmm. I sort of agree with this, that means we just leave room for a \"smoother\" library on top of this. Closing.\n. On further inspection, I'm actually surprised this works at all... Shouldn't the name defined here (https://github.com/seanmonstar/hyper/blob/master/src/header.rs#L93) be dropped at the end of the function, leaving you with a dangling pointer to it?\n. It has to store the actual string to resolve collisions, but it will only access the string if there is a collision. Given that most of the examples insert a limited number of headers, it's likely that there just aren't any collisions to resolve in them.Thanks,\n         Jonathan Reem\nOn Sat, Sep 6, 2014 at 11:15 PM, Sean McArthur notifications@github.com\nwrote:\n\nHrm, you're right, that should be a dangling pointer... does it manage to work because HashMap stores the hash u64, instead of the actual &str, and so when checking later, it looks up by u64?\nReply to this email directly or view it on GitHub:\nhttps://github.com/seanmonstar/hyper/issues/12#issuecomment-54728563\n. @seanmonstar You are right. I've updated the PR and commit.\n. I quite like this as a solution, but I'm also wary about how this makes impls for Handler more complex. I think it's a worthy tradeoff, but it's worth consideration. The second problem is that helpers which receive Request and Response will likely just use Request and Response, inadvertently making them unusable with alternative streams.\n. I think not. That dynamic dispatch is so much more ergonomic is, in my opinion, a slight problem in rust today. The only way to make this really work would be to remove the default type parameter in everything except Server.\n. Benchmarking dynamic vs. static dispatch here would probably be wise as it would let us know if this is even worth worrying about. If we could get static dispatch with dynamic-dispatch-like ergonomics, that would be even better.\n. Merged as part of #29\n. Is it possible for http? I though it was married to TcpStream directly?\n. I was thinking of the Server. I actually know close to nothing about the client (never used it) so I can't say, but I think you are right.\n. What numbers do you get for that?\n. That looks much more consistent. Does it look that way every time you run it, because if so, we did good!\n. Wow. That's pretty awesome. We should probably have this as a separate benchmark, just to be transparent about all the numbers.\n. We should investigate if making #17 use dynamic dispatch creates a material difference in performance, if so, then yes, that sounds a tiny bit annoying. However, I think it's useful enough to justify it.\n\nMost frameworks will probably not expose Request and Response directly, so I don't think it's too big of an issue. It's mostly useful for testing so one can mock Incoming, though it would probably be easier to just make http requests with a good client.\n. @seanmonstar Done. Will restart travis when #24 is merged.\n. For the record, we are consistently winning the benchmarks on my machine :)\n. You do not have to copy the Handler (bound it with Clone) or put it behind an Arc (bound it with Sync), both of which can be expensive, complex, and/or prohibitive when that Handler contains complex structures, connection or threadpools, or data which should be globally shared. This gives downstream users maximum flexibility to make those decisions for themselves.\nThis can be implemented downstream because we get Incoming by-value, if we still switch to using MoveAcceptor and Incoming fulfills Send, by doing much the same thing I do in listen now, but this standardizes it.\n. @seanmonstar Rebased and updated.\n. Ah... I'm more interested in just making sure the benchmarks compile than actually running them. I wonder if there is a way to do that using cargo.\nAre you sure cargo test builds docs?\n. NO_BENCH=1 cargo bench will compile but not run the benchmarks.\n. I do, I just didn't know that actually built the docs also. Will remove cargo doc then.\n. Hmm... Looks like NO_BENCH=1 doesn't work -.-\n. cargo bench --no-run does what we want.\n. ab works for me too. I'm not sure what's going on with wrk, because regular requests seem to work fine. ab tends to give me extremely low numbers for rust servers, both for this and rust-http.\n. I'm trying to fix this now, and getting some super weird results. It appears that the first request sent by wrk yields an empty TcpStream, which causes an error in Hyper. Additionally, I get extremely sporadic profiles for all remaining requests, with spouts of activity followed by huge swaths of no work at all.\n. cc #17\n. @seanmonstar Updated.\n. I made these changes, among others, in #32, but I duplicated Fresh and Streaming instead of moving them to net.\nWhat's RequestBuilder?\n. I've been waiting for us to stabilize a bit first. Once we are more stable with the API I will.\nhyper-org, hyper-rust and hyper-http are all free. I prefer the latter two, personally.\n. I think hyper-rust would be more intuitive and has more precedent.\n. hyperium is kind of cool.\nhyper-http is probably more official-sounding, but if you don't like it you don't like it :)\n. Actually hyperium is growing on me, it's pretty \"epic\" sounding.\n. Let's do it! :)\n. The only way around this is to either store the raw representation or store only a single representation and to keep track of what type was used to generate that representation.\n. Why do we keep the raw representation around? Since changes in the typed representation aren't reflected in the raw representation, I don't see why we should.\nEither we should disallow parsing under two different types or we should come up with a scheme to propagate changes between the two.\n. I can set the value of a header's typed representation, then parse it under a new representation and I won't get the updated value.\nI think that would be a non-trivial source of bugs, and also makes libraries much more dependent on one another.\n. I've got a branch somewhere with most of a representation that just converts to the raw representation if you ask it for a different type. I'll probably PR later tonight or tomorrow.\n. That is also possible. I think both representations have their pros and cons and I'm not sure which is best.\n. At minimum this can be refactored to not store the TypeId or the raw representation if we decide to not allow re-parsing.\n. Looks good. I'm glad we are gaining support for this. If we can get SSL on the server it would be a huge win for hyper.\n. I can't compile the tests locally, will check out why that one fails (hopefully) tomorrow when rustc gets fixed.\n. @seanmonstar Updated. I dislike that this ties users to a single representation, but I think that any other way is likely to the source of very hard to debug bugs. (For instance, if a downstream middleware were to modify a Header and then the application used a different version of the Header, it's likely to cause a very hard to find bug).\nThe only other alternative is to re-parse each new Header from the stringified version of the last typed header, which is most forwards-compatible with this approach if we decide to use go that way, though that approach has the downside that it's possible to lose information.\nI think the best solution to this problem is likely to be just to provide really robust representations of all common headers in hyper or the hyperium org.\n. I think there's no way for us to stop users from doing silly or malicious things like consuming Headers to private types that hold no data, but we can get around that with docs.\nIf a library uses a complex header that is not provided in hyper's core, then it's likely they should also be providing the canonical implementation of that header.\n. Also, we currently give Header a &[Vec<u8>] so they couldn't do something like set it to [] without being highly unsafe (and that's not our problem).\n. That's what we do in Iron. I guess that's really the best we can do.\n. We should probably use rust-url and hold a Url value instead of a String.\n. The tricky thing is that rust-url does not support parsing from only a relative url - you have to give it a full absolute path.\nWe have a huge hack in Iron where we construct a url for rust-url to parse, but I think that won't be necessary if we have all the info inside hyper.\n. It looks like it was closed with a fix, does the method he added not do what we want?\n. I think it's fair if Hyper provides a typed representation for request-line, with precedent being typed headers and other such things. We should just make sure to not lose any information.\n. Looks really good. I'm really glad we are getting this functionality down as it was one of the last really big warts.\nTravis failed because of the new iter methods (iter_mut and into_iter instead of mut_iter and move_iter respectively). \n. Relevant: https://github.com/rust-lang/rust/issues/690\n. I am under the impression there is a relatively easy way to do this nowadays vs. the ancient times, so tagging easy.\n. @seanmonstar I figured the README needed a refresher.\n. That seems fair. I'll amend this to move some stuff out of the readme.\nMainly, I'm just looking for a way to make the readme a little beefier.\nThanks,\n         Jonathan Reem\nOn Fri, Sep 19, 2014 at 11:40 AM, Sean McArthur notifications@github.com\nwrote:\n\nwhat do you think of this going in lib.rs instead? A brief description in the README to convince someone it's worth their time to check the doc pages, and then the rest can be part of the docs. This way, any code fences stay up-to-date, since cargo test runs doctests.\nReply to this email directly or view it on GitHub:\nhttps://github.com/hyperium/hyper/pull/46#issuecomment-56217523\n. @seanmonstar I agree that the README example can bitrot, however I think that having simple examples in the README is super valuable as it gets people interested.\n\nHow about a simpler server example in the README, and keeping the simple client example as is? I'd really like to have something there.\n. @seanmonstar Updated to have a simpler example. I think this should be fine, as it's simple enough that we can manage the bitrot with minimal effort.\n. Fixed, waiting for travis.\n. RefCell would not be a good solution here as it would be a leaky abstraction and lead to runtime failures when code tries to get two header references with overlapping lifetimes - this code would fail, for instance:\nrust\nlet length = req.headers.get_ref::<ContentLength>();\nlet encoding = req.headers.get_ref::<TransferEncoding>();\nRight now this is a compile-time failure, using RefCell would make it a runtime failure.\nWe would also have to return cell::Ref and cell::RefMut instead of & and &mut.\n. Basically scratch the above, I did crazy things with RWLock in #48 that fixes this and more.\n. Using & would be a lie about the validity of the pointer and would allows crashes in safe code by dereferencing that pointer. The alternative would be get_raw receiving &mut self just for exclusivity, but that is not great because get_raw users would then need to make clones of the returned data, which seems unfortunate.\nI'm planning a second wave of refactors to this that will hopefully make the interaction between raw and typed data much nicer, but in the meantime we have to make this *const.\nAlternatively, we could return a read-lock on the entire item, but that exposes too much of the implementation unnecessarily.\n. So after playing around with ideas about creating a better raw/typed story, it looks like the only ways to make it safe would be to demand &mut self for get, return a RWLockReadGuard (which is liable to cause deadlocks), or use RefCell and return Ref or RefMut, which is liable to cause runtime failures.\nI'm not sure which of these is the worst, but it's not a great situation generally.\n. I agree strongly about preventing runtime errors. I think this is the interface we want to expose for now. It prevents runtime errors for the typed interface, and this is better than what we have right now.\nI am thinking about possible strategies for exposing a totally safe interface, but I think this is the way to go until we have better support for reinterpretation, etc.\n. Can do, will probably push tomorrow.\n. That was quite a rebase, but it should be fixed now.\n. Some other issues are popping up. Will investigate.\n. Fixed the smaller issues in #63, should work now.\n. I actually got them to make this list by going to chat on #servo about using hyper and what they'd like :)\n. Metabug for the servo milestone.\n. Servo now uses hyper, and most of the relevant issues have been made into hyper issues and some have been closed.\n. The issue is that it is not possible to provide the granular guarantee to the type system/borrow checker that no two headers with the same name are accessed concurrently. The &mut self solution just bans all access to two headers at the same time, and the RWLock/RefCell solution pushes the problem to runtime, but allows it in the case where you access two different representations.\n. I was thinking about allowing access to raw headers through a type which just wraps a regular header and returns the input in parse_header - for instance headers.get::<Raw<ContentLength>>().\u00a0\nHowever, I didn't consider that this still doesn't allow for dynamic raw header access through strings.\nOn Wed, Sep 24, 2014 at 11:15 PM, Sean McArthur notifications@github.com\nwrote:\n\nAdditionally, while for most use-cases, the Typed API should be preferred, Servo has a legitimate reason for accessing all the Raw headers: providing the JS methods xhr.getResponseHeader() and family. In JavaScript, you can pass any string, and Servo cannot possibly know ahead of time (and so use compiled in types) which strings may be used. Also, the result passed to JS must a be a String. So, in those bindings, accessing raw headers (and many of them, thanks to xhr.getAllResponseHeaders()).\nThose restraints mean that we cannot do what is currently done: we must keep the raw bytes around even if accessed as a Typed value.\nThe steps I think we need are: \n1. We go back to struct Item { raw: Vec<Vec<u8>>, typed: Box<Header> }. We provided headers.get_raw(key: &str) -> Option<&[Vec<u8>]. mut isn't needed, since it doesn't require any transforming to get the raw bytes.\n2. The get(&mut self) still takes mut, and the compiler prevents a mutable borrow while there exists immutable borrows.\n3. Request<W>.headers() returns a &mut HeadersView that only provides get, get_ref, and has methods.\n4. Request<Fresh>.headers_mut() returns a &mut Headers, as it does normally.\nAlternatives: instead of a &mut HeadersView, we could use a phantom type like with Request, such as &mut Headers<Fresh> and &mut Headers<Frozen>.\nReply to this email directly or view it on GitHub:\nhttps://github.com/hyperium/hyper/issues/50#issuecomment-56768953\n. I think that we can provide both DynamicRaw and TypedRaw<H: Header>, where you can get TypedRaw using the regular methods and DynamicRaw using a special raw method which takes SendStr.\n. I just spent some time whiteboarding this issue, and I think that I've found a pretty good solution:\n\n``` rust\nstruct Headers { .. }\nimpl Headers {\n   // Typed\n   fn get<'a, M: Marker>(&'a self) -> Option>;\n   fn set>(&mut self, H);\n// Raw\n   fn get_raw<'a>(&'a self, &str) -> Option>;\n   fn set_raw(&self, &str, Vec>);\n}\nstruct HeaderView<'a, M: Marker> {\n    item: &'a HeaderItem \n}\nstruct HeaderItem(RWLock + Send + Sync>>);\nimpl HeaderView {\n  fn as<'a, H: Header>(&'a self) -> Option>\n  fn as_mut<'a, H: Header>(&'a self) -> Option>\n}\n// A bit of hypothetical Associated Statics syntax. Takes the form header_name in real code today.\nstruct Erased; impl Marker for Erased { name = \"\" };\ntrait Marker { name: &'static str; }\ntrait Header {} // current methods, minus name stuff\n// RawView works a lot like HeaderView except it parses to \n// ReadGuard]> and WriteGuard>>\n```\nThis allows multiple headers to be accessed at once with minimum likelihood of stepping on each-others toes. It has some of the same issues as just returning ReadGuard directly, but due to the ergonomics of doing something bad, I think it's not as big of an issue.\nIf you think this API might be valuable, I can take a shot at implementing it.\n. Here's a gist with the meat of the above implementation, corrected for reality: https://gist.github.com/27fb134d2554572b21f8\n(Untested, uncompiled code)\n. I've been thinking about the above interface and I'm having second thoughts. The interface is unfortunately not as safe as just taking &mut, because it can cause deadlocks, but it does allow immutable access to multiple headers at once, which is a benefit.\nBy introducing the marker and separating get and read_as/write_as we reduce the chance of deadlocks but they are still possible.\n. I think the performance implications of that are too bad. &mut self requires cloning, which I think is likely to be much cheaper than re-parsing.\n. I'm worried that it will be particularly nasty for certain complex headers, but stats are always better than speculation.\n. Mmm. This can actually be implemented in a library to avoid spawning a task on all requests.\nFor instance: Future::spawn(proc() req.send()) will work fine - the major thing we have to check for is to maintain the Send-ness of Request and Response.\n. I think they want the ability to prioritize new TCP connections over old ones by some form of throttling.\n. Probably all of those in addition to how long hyper itself takes for things like parsing.\nOn Wed, Sep 24, 2014 at 8:35 PM, Sean McArthur notifications@github.com\nwrote:\n\nWhich pieces are desired?\n- DNS time?\n- Connect time\n- Write time\n- Read time\nReply to this email directly or view it on GitHub:\nhttps://github.com/hyperium/hyper/issues/56#issuecomment-56759342\n. Looks good. This is definitely something we want.\n. Hmm. I'm not sure this will allow full handling yet. We need a way to get a raw socket from a NetworkStream to fully allow hijacking by downstream libraries.\n. Except... can't call a method which contains the Self type through a trait object. It would need to be downcasting and that's kind of icky.\n. Also, just for the record, if you put fixes #num inside the commit message (it can be after the first line) then github will automatically close the issue if that commit gets merged to master.\n. @seanmonstar We could just make this a regular, checked, downcast. I don't think there's a good reason to make this unchecked only.\n. Hmm.. I thought this was a pretty clever way to ensure that only Fresh and Streaming could be used.\n. Ugh, ok then.\n. Cool. You can also do trait IsSend: Send and then impl IsSend for Request {} etc. but this works too. I doubt the underscores are necessary since this isn't exported.\n. Ah. This solution works, so I don't think it's a problem.\n. I think that the long road for hyper is two or more layers - core hyper, which includes a fast http parser and low-level header and body access and a higher level or levels for both the server and client that provide more advanced features like typed headers and a builder interface.\n\nI'm not entirely sure how I think the lines should be drawn, but I see the need for a core implementation separate from a higher-level interface.\n. I've been thinking a lot about this, and I think that a better approach will be to simply separate the raw and typed interfaces entirely by creating a raw module inside Hyper that exposes a much lower-level interface and is meant to be used by projects like Servo or those wishing to build their own abstractions on top of Hyper.\nThis means we can take more liberties with the typed representation of Headers and other abstractions in the non-raw modules of Hyper, because the raw module will always be around and supported.\nI've done some preliminary work on a branch in my fork, and I hope to have something pushable in the near future.\n. We're gonna want to ensure that we design the Header trait to make this safely possible, so I think it's important that we don't merge something that can't work in the future.\n. How about abstrct?\n. How about dynamic?\n. I'm not a huge fan of upcast. \n. It's possible upcast makes sense in rust-error, since there is an associated downcast, but here I think dynamic is a better fit.\n. Thanks!\n. @s-panferov Thanks!\n. Curious, is there an overarching/forward-looking reason for these changes? Looks like a nice cleanup to me, but I'm curious what prompted this.\n. Awesome, merging.\n. I agree, but unfortunately there's no step in the regular usage process where you are warned about experimental.\n. Travis failure due to rustc issue, not a hyper one.\n. There are really two potential answers to this question, as I see them:\n1. You use the forthcoming raw Headers instead of the higher level API supplied by normal hyper. The RawHeaders API will be much more amenable to this sort of thing.\n2. You await a new, more ergonomic raw API in the new top-level Headers supplied by normal hyper, which will have facilities for the runtime insertion of headers from raw strings.\nAlternatively, you expose a typed interface instead of a (&str, &str) one. This would work by you just receiving an H: Header and using the typed interface of hyper headers instead of the raw one.\nI recognize that this doesn't solve your problem right now, and ergonomic header access is something we have been thinking about a lot and hope to solve in the near future.\n. @gtolle I don't see why not other than it should then be moved into a util module inside of header::common instead of being at the top level. I would also be happy to accept a PR with an implementation of the Authorization header as a relatively common header we should have support for in hyper.\n. Ideally this would do the base64 encoding and decoding for you, since it's pretty easy to get that logic wrong.\n. This needs a rebase after #83 \n. Alternatively, couldn't you just have it be:\n``` rust\ntrait AuthScheme {\n   fn decode(&str) -> Option;\n}\npub struct Authorization {\n   raw: String\n}\nimpl Authorization {\n    fn to(&self) -> Option {\n        AuthScheme::decode(self.raw.as_slice())\n    }\n}\n``\n. This test failure is actually because of a miscompilation on rustc's part, so this is good!\n. @seanmonstar Do you remember what the numbers for this used to be?\n. Excellent. Thanks for this change, it's also a lot cleaner/shorter.\n. Manually merged as 0fcbdc34f2ef122e91d5307704113314a58db024\n. Thank you for this fix!\n. I actually implemented something simple for conduit way back, https://github.com/conduit-rust/conduit-compress, it could probably be easily adapted to work with hyper, but probably fits more as an iron middleware than baked into the underlying HTTP implementation\n. @mhart Thanks!\n. MockStream belongs in a separate \"test\" module within hyper for now, and should likely be moved to another crate in the future.\n. It's on latest master but not nightly yet.\n. @seanmonstar since it's on nightly I've merged\n.box () (**self).clone()doesn't appear to work.\n. Looks good to me and is a nice proof-of-concept for future \"subtyped\" headers like this one. I'm glad we can support this use case. I'll wait on @gtolle and @s-panferov if they have any comments before merging.\n. Can you instead implement these methods as inherent onHeaders? We still want that functionality.\n. Thanks for this!\n. In profiles it looks like most of the time is spent inrust_timegm, which is a C foreign function.\n. Yes, I think.\n. I wonder if that will improve with runtime removal.\n. Yup, this is basically gone from the profiles.\n. It would requireArc>` but should work, so that is one workaround.\n. That requires allocating a new proc and task for each incoming Request, which basically defeats the purpose.\nMaybe we could work around the proc when unboxed closures are moved into libs, but we would still need a new task.\n. You are right, I was thinking of Future::spawn. We still have to allocate for a proc(), but that could be avoided if we defined our own Future type which stored F: FnOnce() -> T or a more specialized type that stored the NetworkStream and an fn(Box<NetworkStream>) -> (Request, Response<Fresh>) so that we get static dispatch and can avoid unnecessary allocation.\nBasically we should do the minimum possible work between \"get a connection\" and \"yield to incoming.next\", then allow all further processing to be done with the returned handle, so it can be done in another task.\nThe contention we'd get from locking/unlocking a mutex at 100s of concurrent connections will almost definitely hurt a lot.\nRelated data point: using a TaskPool in Iron instead of regular spawn sped up Iron by 80%.\n. Looks good.\n. Haven\u2019t tested yet. I will try it later tonight.\n. I will take a look tomorrow.\n. We need to decide on [] vs &* as a conventions thing.\n. We should try and get EmptyWriter upstreamed to std::io::util, it seems at least as useful as NullWriter.\n. Awesome! I think this makes a lot of sense, and I really like how you avoided doing any unnecessary allocation through proc() or Future.\n. I've actually just been working on this when it started showing up in profiles and was just about to make a PR, if you already have one ready feel free to make it or I'll just put up mine.\n. I'll make the PR then, since I've got all the work done.\n. just realized I didn't commit that change. updated.\n. Fixed.\n. Fixed through #115.\n. Awesome! Waiting on travis, but this looks like a strict improvement. I didn't know this was implemented yet.\n. Is it possible to include the IoErrors description in the description of HttpIoError?\n. Ugh, I wish there was a way to still signify that it was an HttpIoError, but it was caused by an IoError with X description, but you can't return a dangling &str.\n. Ya, I guess the intended usage is .cause().description(), so we should just go with that (i.e. the original PR), but that means we should also adjust our logging to keep .cause()ing until we get to a None.\n. Hmm... I guess the Show impl will do it for us, so maybe that's not necessary. I think (sorry) we actually just want the original PR.\n. Awesome! Thanks for making this change (and dealing with changing it and then unchanging it :P)\n. This is great news. I will take a look at this later today.\nOn Wed, Nov 12, 2014 at 3:21 PM Sean McArthur notifications@github.com\nwrote:\n\nInternals have been shuffled around such that Request and Reponse are\nnow given only a mutable reference to the stream, instead of being\nallowed to consume it. This allows the server to re-use the streams if\nkeep-alive is true.\nA task pool is used, and the number of the threads can currently be\nadjusted by a method on the Handler trait.\nBREAKING CHANGE\n@reem https://github.com/reem I see a big jump in reqs/sec with this.\nOn my machine, around 55k. I can't get Iron to compile today (cargo bug) to\ncompare, but it may be faster on your machine.\nYou can merge this Pull Request by running\ngit pull https://github.com/hyperium/hyper server-keep-alive\nOr view, comment on, or merge it at:\nhttps://github.com/hyperium/hyper/pull/116\nCommit Summary\n- feat(server): keep-alive! [WIP]\nFile Changes\n- M benches/client.rs\n  https://github.com/hyperium/hyper/pull/116/files#diff-0 (15)\n- M benches/server.rs\n  https://github.com/hyperium/hyper/pull/116/files#diff-1 (12)\n- D examples/concurrent-server.rs\n  https://github.com/hyperium/hyper/pull/116/files#diff-2 (77)\n- M examples/hello.rs\n  https://github.com/hyperium/hyper/pull/116/files#diff-3 (24)\n- M examples/server.rs\n  https://github.com/hyperium/hyper/pull/116/files#diff-4 (53)\n- M src/lib.rs\n  https://github.com/hyperium/hyper/pull/116/files#diff-5 (3)\n- M src/net.rs\n  https://github.com/hyperium/hyper/pull/116/files#diff-6 (13)\n- M src/server/mod.rs\n  https://github.com/hyperium/hyper/pull/116/files#diff-7 (126)\n- M src/server/request.rs\n  https://github.com/hyperium/hyper/pull/116/files#diff-8 (23)\n- M src/server/response.rs\n  https://github.com/hyperium/hyper/pull/116/files#diff-9 (29)\nPatch Links:\n- https://github.com/hyperium/hyper/pull/116.patch\n- https://github.com/hyperium/hyper/pull/116.diff\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/116.\n. Aside: we should standardize on [breaking-change] vs. BREAKING CHANGE. I like [breaking-change] because it is used in rust-lang/rust.\n. I'll try benchmarking it now.\n\nOn benches/server.rs, we should probably just have it make multiple concurrent requests.\n. 85-95k! which is basically on-par with rust-http and Iron. Great success!\n. Throughput is higher than rust-http/Iron, about 9 MB/s instead of around 6.\n. Travis can't build it until this is rebased. I'll take another look after a rebase, just to make sure I don't make any comments on something that has already been fixed.\n. Also I just made a PR that rewrites the std TaskPool to be like the one in my repo, so we should switch back after that gets merged. Sorry for going back and forth so much :P\n. Do you want me to do another pass now, or wait for you to finish?\n. Waiting to merge until things are building.\n. This has a bunch of merge conflicts now :/\n. More rebase necessary :/\n. Woo!\n. Just merged the rust-http PR. Retrying travis.\n. Manually merged in master.\n. Why do we want to enforce this? Can we even clone req/res anyway?\n. Couldn't we just move the headers out after writing them to the outgoing stream, instead of cloning them? For the most part I don't see this causing problems, but in certain cases  a Clone bound can be rather arduous.\n. Seems perfectly reasonable. Nothing builds right now so we should probably wait for the dust to settle before merging anyway.\n. Just to be clear, the support for this only needs to come in the parse_header implementation for CacheControl, right? We already support multiple raw header lines.\n. Also is this a servo issue?\n. Cool, thank you very much.\n. @seanmonstar Do we want to do this or would we like to refer to variants by their new namespace names throughout hyper?\n. Closed in favor of #127.\n. Thanks!\n. It should be pretty simple, as @seanmonstar said all you will need to do is implement the appropriate traits and use listen_network.\n. What's the deprecation warning coming from?\n. Oh god cargo is breaking now. retrying.\n. Ok, the only error here is from find_equiv, so I am merging with hopes to fix that in another PR.\n. This is an ugly hack, but I asked around on IRC and we couldn't figure out anything better.\n. SO MUCH is broken. I am fixing all the errors in benches right now and will push on this branch.\n. :dancers: \n. Merging now that keep alive is in.\n. cookie-rs is also not yet on crates, but will be soon - openssl is more complicated.\n. It should now, and crates in the registry are not allowed to point to git dependencies, since builds should be 100% reproducible.\n. This is actually unnecessary as openssl has gone up on crates.io.\n. Can it be a SendStr instead of a String to avoid allocation where it's not needed?\n. My biggest gripe here is that this means there are two sources of truth for the Response status. This could be mitigated by going from status_mut to set_status (or using modifiers, if we want to accept the conceptual overhead) and also setting raw_status whenever status is set.\n. Wow, a surprising increase. Could we get even better if we used a static buffer like with method matching?\n. Ah, figures. Do you want to push that version?\nOn Fri, Nov 21, 2014 at 3:54 PM Sean McArthur notifications@github.com\nwrote:\n\nThat is using a static buffer. [0u8, ..32]. The longest default phrase is\n31 characters.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/135#issuecomment-64056638.\n. I think it shouldn't be a major perf issue since we will match all canonical reason phrases with no allocation.\n. Great! Merging.\n. We are blocking on https://github.com/alexcrichton/cookie-rs\n. Done!\n. That's very weird - I'm using hyper right now in Iron and there are no problems.\n. Ah, I know, the version I uploaded to crates.io does not have the dev dependencies, so there's no double linking.\n. Remove the benches folder and remove the dev dependencies sections, that\nshould do it.\nOn Fri, Nov 21, 2014 at 8:37 PM Sean McArthur notifications@github.com\nwrote:\nDoes the version you have build and test locally? I'm having trouble doing\nso.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/137#issuecomment-64068968.\n. I guess not. It's alright to leave this since a working version is on crates right now.\n\nThanks,\n         Jonathan Reem\nOn Fri, Nov 21, 2014 at 8:41 PM, Sean McArthur notifications@github.com\nwrote:\n\nhrm, so then we can't really merge this until dev-dependencies are figured out?\nReply to this email directly or view it on GitHub:\nhttps://github.com/hyperium/hyper/pull/137#issuecomment-64069057\n. @shamansir you need to use:\n\ntoml\n[dependencies]\nhyper = \"*\"\nto get the version of hyper on crates.io.\n. Added some fixes that need to go on this branch because mixing git + crates.io dependencies breaks openssl. This should be merged and all further development of hyper should be done using crates.io reps.\nThis also removes all usage of rust-http since it's not really being actively maintained anymore.\n. Thanks for these changes - not really sure how that first one slipped through CI.\n. It does, and Hash can also be derived.\n. Overall major +1, this makes iterating over headers much more useful.\n. Looks great! Thanks for fixing this.\n. I believe that these are changes planned for master or already in master, but not yet on the nightly. I recognize the new parens needed because of the change of precedence for + in types.\n. I think a primary issue is that there is a lot of stuff in this crate. Re-exports help, but also clutter the namespace for higher-level modules.\n. This is actually really tricky right now since Request and Response have a lifetime now and HRTB are still semi-broken, I'm willing to give it a shot though.\n. Win all around, merging.\n. I am not 100% on the use of Deref here, but it's worth experimenting with.\n. I think it makes sense - we'll see if it causes any problems.\n. Why don't we instead just add another method to NetworkConnector called verify or something, and just have people who want to use this use Request::with_stream::<MyVerificationStream>? It's slightly more of a pain to use, but doesn't use huge type signatures and callbacks.\n. What if we changed our trait stack to separate NetworkConnector and NetworkStream so that NetworkConnector::connect is (&self, host, port) -> S where S: NetworkStream (right now that S would be a parameter to NetworkConnector but could be an associated type in the future), then have Request::with_stream actually take an instance of NetworkConnector.\nThen, a verification connector could take an SslVerifier as an argument in its constructor, and we could provide a simpler connector that stores the SslVerifier for use during connect.\n. connect would no longer be a static method, instead it would be a method on self and you'd pass a connector instance to with_stream (which would probably be renamed to with_connector).\n. This looks good with those nits addressed.\n. I prefer the enum, since it is incorrect to set both all: true and fields to a non-empty Vec and the enum enforces this.\nI've been thinking a bit about this Header, and I think it would be cool if we could somehow store a list of actual typed headers, rather than Strings. I'm not yet sure how to do to that, though.\n. @Manishearth ideally you don't actually have to have an instance of the header, since some headers are large or have complex representations.\nI agree that we want this functionality in the meantime anyway.\n. I'm going to try and land crates.io today or tomorrow.\n. We'll probably use version * until things start stabilizing.\n. You should just use hyper's crates.io version for now, which doesn't include the benchmarks. We are blocked from fully porting over by curl not yet being on crates.io.\n. This is rather unfortunate, since adding an Extension(u16) variant wouldn't allow the compiler to optimize Status down to two bytes, but instead it would have to have two bytes for the discriminant and two bytes for all values. If we want Extension(uint) it gets even worse, with Status being six bytes.\nI'm not sure how big a deal this is (it at all) but it's unfortunate.\n. @seanmonstar I wouldn't want Deref<u16> since that would get us a bunch of u16 methods that are undesirable or incorrect to use.\n. We could implement [From|To]Primitive\n. I actually quite like @pyfisch's linked modification to the teepee status. I think it makes a lot of sense to lump all non-registered status codes together, rather than having a specific enum variant for all the unregistered codes.\n. I think we've blown the additional byte that @pyfisch's implementation requires way out of proportion :P. It's not going to make any difference at all in reality.\n. I take responsibility as the first one to bring it up, but I've since realized I was being ridiculous.\n. Of note for the backwards compatibility problems is the extensible enums\nRFC, which might be relevant here.\nOn Wed, Jan 28, 2015 at 8:48 PM Manish Goregaokar notifications@github.com\nwrote:\n\nWhen it comes to the web, one must permit more behavior than the spec\nconstrains us to. The restrictions imposed on people designing webapps by\nthe spec (namely, don't use weird status codes) are not the same as the\nrestrictions for platforms implementing the spec. For example, while the\nHTML spec is rather specific as to how tags should be nested, the HTML\nparsing spec allows for all kinds of edge cases. It's in this spirit that\nthis test was written (at least, it seems like it) -- a browser or other\nHTTP client should not choke on strange status codes.\nIf you look at the WPT tests, many of them are doing just that -- using\nillegal code to invoke edge cases and whatnot. It is unfortunate that they\nhave to do that, but the web has evolved that way, and we have to live with\nit if we want to support random websites.\nThere is a macro-based option which should work if we want to support\nstatus codes >599 without losing efficiency, or the constants method\n(without the fake-enum).\nAlso, as platform implementors we must support behavior defined in the\nless stricter RFC anyway, so the 3 digit rule seems like a better one to\nimplement.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/177#issuecomment-71954643.\n. @mdbooth that would mean we clone the url inside of  Request::get which is not always necessary. In this case, taking the url by-value is actually more flexible, since it allows the user of this code to decide whether they wish to clone or not.\n\nDoes that seem reasonable to you? \n. Can we move the method and url arguments to client.request() so that you can just do client.request(Get, url) and then chain directly off of that, rather than requiring an explicit RequestBuilder::new, since that's a lot of characters.\n. Yup, looks great. Rebase?\n. I'm investigating this, but it seems pretty hard to work around.\n. Well done! I spent a bunch of time trying to figure out what the best split would be, but I couldn't come up with anything that didn't require a lot of mangling.\n. Thanks for reporting. I'll attempt to take a look at fixing this tomorrow.\n. Can you rebase this to get rid of the merge commit?\n. I think it might be best to move these lints into other repos/crates, since they are actually generally useful (I'd like to use them in other projects, especially str_to_string) and it keeps the codebase of hyper itself short. \nWe could have a hyper/lints or you could just stick them in your own repo.\n. Our dependencies aren't up to do date on crates.io yet (or that's what it looks like). Will update as soon as possible.\n. We could call the appropriate reading/writing functions in Drop, thereby ensuring we always read or write even if the Handler does nothing.\n. My primary concern, without even looking at the code, is that we won't be able to upload this to crates.io unless we upload each subcrate, which would be a large maintenance burden for me since I've been manually going through and updating crates.io after every change, and I would now have to do this for many crates and coordinate those changes.\n. @seanmonstar I talked to @sfackler and he confirmed my suspicion that the path dependency is only used for local builds and he has to change it to a crates.io dependency for uploads. \n. @sfackler is it possible to use version = \"^0.0.0\" or something like that?\n. Ok, so that clarifies the situation a bit - it is possible to use path for development, but it still does require uploading and maintaining crates.io versions for all the sub packages.\n. I think it's partially by design (builds should be fully isolated), but it may be possible for Cargo to support path dependencies by ensuring they are packaged within the distribution.\nThanks,\n         Jonathan Reem\nOn Thu, Dec 18, 2014 at 9:24 PM, Sean McArthur notifications@github.com\nwrote:\n\nUm, wow. I didn't realize that. I'd hoped it could still be one published\ncrate that provided many.\nIs there an issue in cargo for this to happen, or is it by design?\nOn Thu, Dec 18, 2014, 5:46 PM Jonathan Reem notifications@github.com\nwrote:\n\nOk, so that clarifies the situation a bit - it is possible to use path for\ndevelopment, but it still does require uploading and maintaining crates.io\nversions for all the sub packages.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/200#issuecomment-67587656.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hyperium/hyper/pull/200#issuecomment-67599872\n. I'm still not clear on what the exact benefit of this change is - what do we gain by having a bunch of small packages in one place over just one package?\n. I'm not sure I really empathize with the use case in #189, since hyper itself is not that big of a package yet and depending on the whole thing will add marginal additional compilation time etc. \n\n\nThat said I can still review this if @seanmonstar thinks we really want to do this, given the additional maintenance burden.\n. @DiamondLovesYou LTO should cut out unused stuff, and your users don't need to know you are using hyper (see Iron for an example of completely hiding the dependency).\n. It looks like progress and discussion on this PR has stalled, and it will require some serious rebasing to be relevant again. It seems that we don't need this change right now, but are open to it if done in a way that keeps maintenance and use simple. As a result, I'm closing this PR.\nFeel free to open another PR with the changes updated or if you think further discussion is warranted.\n. @cactorium let me be as clear as I can: this is the opposite of bothering us :)\n. @cactorium weird stuff with the rebase, usually rebasing gives you fewer commits. Did you by chance commit during the rebase process instead of using git rebase --continue?\nHttpListener could be changed to a struct with a field that contains HttpListenerKind or something, so that common data can just go in a normal field.\n. Oh man - that will be such an improvement.\n. Thanks!\n. @daogangtang that library actually uses hyper as a dependency, so it seems its possible to do this entirely outside of hyper.\nThat said I am interested in building some web socket stuff into hyper, but maybe the API can be very low level.\n. @pyfisch Most likely yes, all of the feature gates that hyper uses extensively are slated to be stabilized.\n. @jamwt I'm going to wait and let @seanmonstar merge this since he's worked on the client more and has a better idea of if this is appropriate.\n. regex and rustc-serialize are still broken despite open PRs, so this doesn't really fix anything yet.\n. Trying to fix... So many errors...\n. Trying to fix but getting bizarre errors when trying to implement Deref and DerefMut, looks like an associated types error.\n. @Gankro do you have push rights/crates.io rights for the other crates in rust-lang (regex, log, etc.)?\n. @seanmonstar r?\n. @pyfisch that seems reasonable. I will merge this when we get hyper building again.\n. It's green! It's green! Woo!\n. I am not a fan of that idea - AccessControlAllowOrigin is long enough already :/\n. @seanmonstar You said you had an in-progress PR with a lot of changes like this.\n. @seanmonstar would you be against just dropping curl from the benches to make our builds more reliable until 1.0?\n. @seanmonstar that's fine, I'll start reviewing.\n. Looks awesome except those nits. Associated types are a major improvement.\n. +1, I'll actually start following this now :P\n. I'm about to get on a flight in two hours, I'll also take a look later.\n. Ideally you would use git pull --rebase to get upstream changes, which uses rebase to make it so there are no merge commits.\n. The only thing I would change about this design is that the parsing helpers (from_comma_delimited, etc.) should be in their own module, since they feel like clutter here. Perhaps header::parsing?\n. Hmm. Right now macros are exported at the crate level. I think it's fine to export them, since you only get them if you #[macro_use] anyway.\n. Added a bunch of nits.\n. Waiting on deps to run this on travis.\n. Ya, the travis site is bugging out for me too.\n. @pyfisch it's fixed now, but I do see your concern.\n. Just a note, but it would have to be &[String], since &[&str] implies that you have a backing Vec<&str>, which we don't.\n. Closing because this is stale, feel free to bring it up again.\n. Closing as a dupe of #41\n. To enable logging with RUST_LOG, you need to initialize the logger implementation which reads that environment variable via the env_logger crate. Just add env_logger::init().unwrap() at the top of your main and run with RUST_LOG=hyper=trace to get all logs from hyper only.\n. @pyfisch Thanks for pushing this though, it's a very worthwhile change.\n. It looks like we accidentally dropped a few things from public exports - @pyfisch think you could do a pass to make sure we get everything and PR the fixes?\n. @adwhit can you update this PR to conform to gitcop? If you don't feel like it that's fine, I'll just merge #263 instead, but want to give you time since this PR does predate #263.\n. @ProtectedMode I've pulled but I'm on my phone so I can't update cargo yet. I'll update it as soon as I get home.\n. @ProtectedMode updated cargo\n. Superseded by #262 \n. Looks like an oversight. Thanks for the PR.\n. LGTM.\n. Rejoice!\n. Run cargo update and try again. Should be fixed.\n. Ugh multirust gave me a newer rustc than travis... \n. Seems like this was merged in #280 \n. Should be totally fine, especially since it seems you can elide these lifetimes on implementations with no problem.\n. I had the same thought - I'm pretty sure it is, but I'm not certain. I'm not really sure exactly what it is an example of, but its certainly related.\n. Anyway I think this is good to go, since the lifetimes are actually always the same.\n. No, you can't downcast from &Reader - we used to let you get an &NetworkStream, which you can downcast from, but that changed (which caused this regression).\n. Closed now that we re-exposed NetworkStream.\n. This should be possible in some form.\n. LGTM\n. I'd like to bump this issue again - I really think a more safety-first approach is appropriate here. The header logic is almost never going to be the bottleneck, and we can optimize later. Correctness is far more valuable right now.\n. Looks good to me other than that nit.\n. 24 entries is short enough to live in hyper imo, but I wouldn't mind another crate in hyperium to help split things up.\n. @pyfisch any news here? We'd like to land this to unblock servo/servo#117.\n. Wow I have no idea what I was looking at.\n. Thanks!\n. We could write a Drop impl for Request that tries to read out the remainder of the body.\n. If we are going to do this, it has to be configurable (the max amount we read before shutting down the connection).\n. Just came across this PR as an example of things that can go wrong from closing the socket if the body is not completely read - https://github.com/google/go-github/pull/317. Not necessarily saying we shouldn't go that way but it's something to keep in mind.\n. @durka definitely release that as its own crate :)\n. Looks great.\n. Actually, this is a horrible idea security-wise, I think. I may start reading a request body, see it's super long, and quit. I do not expect hyper to silently read the other 40 GB of that request.\n. I'm not sure, I think it's a combination of the two.\n. amended with BREAKING_CHANGE warning about await. It technically doesn't need to go away since we do still have a guard, but it's actually useless in most cases (doesn't do anything drop wouldn't, can't call close while it's blocked anyway).\n. There is now going to be a stable way to timeout on condition variables, so we could implement something.\n. https://github.com/rust-lang/rust/pull/23949\n. For clarification, you'd like to see a client post example?\n. LGTM, Thanks.\n. Ya, we'll see. There is a future where rust's aio support is amazing where this could be possible, but things are not in such a state yet.\n. Including in #395 \n. Hyper's thread pool size is tunable using http://hyperium.github.io/hyper/hyper/server/struct.Server.html#method.listen_threads.\n. We do have an issue for pervasive timeouts: #315 \n. @renato-zannon I may have been premature with that comment. Unless we want accept to block and for us to run it in another thread explicitly, we need to use Arc.\n. Looks like good work, but there is still another error.\n. After we're done reviewing and are ready to merge you'll squash.\n. This is such a good idea. We should have a convention for no floats or otherwise inexact types in headers.\n. LGTM.\n. This seems like a great idea. I've long wanted a supertest-like wrapper around hyper's client.\n. I think we should move to marker types and get rid of this distinction.\n. You're right, this issue might still be here. It would be pretty easy to add an IntoRawHeader for and implement it for String, &str, &[u8], &[Vec<u8>], Vec<u8>, Vec<Vec<u8>>, Vec<String>, etc.\n. Hmmm... It's likely that the guard returned by server.listen is incorrectly blocking for too long. I have to take another look at the code because this should work fine.\nIn order to facilitate fixing this, can you provide a standalone example that reproduces?\n. From the code in your example I think it's very likely that the problem was some deadlock in your code mixing channels and mutexes, since there is no reason hyper would treat that function differently than any other.\nClosing, unless you can reproduce (since I can't :/).\n. @timonv I looked at the example more closely and the issue is actually clear, I just didn't spot it before. The guard is created in get_message, so get_message is going to block until the entire server is done, have get_message also return the guard or create it in main to make things work.\n. You can close the server by calling .close() on the guard. You should just do this after you receive the message, if you want to close the server right then.\n. However, know that hyper runs servers with a thread pool by default, so you should take care to set the number of threads to 1.\n. I will investigate this further, reopening.\n. Does it? I think something is just wrong with a test but I haven't had time to fix it.\n. Hey @Byron, if you feel like there's more to discuss to have in this issue, I'm happy to reopen. I noticed that @seanmonstar closed this, but the issue also looked resolved to me as @pyfisch told you what to do in this case. On closer inspection, I can see how the solution is not entirely satisfactory.\nI agree that there's definitely more to do in terms of API surface to allow more complex modifications or extensions to Client and RequestBuilder, but that seems only tangentially related to this issue. I'd rather open another issue and link to this one from there though, since the major point of this issue has sort of been dealt with. Sound good?\n. Filed #378 :)\n. Compared to the cost of other operations, mainly io, the virtual calls seem to not matter at all.\n. I should've said something earlier, but I actually started working on a fix a while ago (hours ago). The io changes touch a lot of code, so the fix is very large. I'm haven't finished the entire thing yet, and am going to bed, but will finish up tomorrow.\n. @seanmonstar I'll defer to your patch then, instead of finishing mine.\n. @seanmonstar any progress? I can work on a patch if you're busy.\n. @Byron Thanks for the PR, but I don't think we'll be taking this approach right now, but will instead merge a fix to migrate to std::io tomorrow, rather than backtrack to old dependencies based on a deprecated library.\nYou can always depend on a git fork of hyper with those dependencies changed if you need something running right this second.\n. Ok, you've convinced me. I'll reopen and let @seanmonstar weigh in.\n. Needs a rebase already.\n. I'm going to close this and open a new issue about User-Agent handling.\n. In iron at least I can attempt to implement the AtomicUsize-tracked-by-connecton_{start, end} solution, which may eliminate a lot of these issues.\n. @octplane Could you try to profile the code?\n. @seanmonstar I'm not convinced that hyper should actually handle this vs. downstream users/libraries adding features like this.\n. I'm convinced.\n. Ah I didn't actually finish reviewing this... might need to make a followup PR with some more fixes.\n. @pyfisch I actually think it would be better if we just built our own custom url type that's specialized for HTTP use cases. The absolute rust-url Url type is significantly less useful in many cases then a relative URL with a virtual root.\n. @seanmonstar a crates.io build will use version and a local build will use path.\n. Closing because stale, feel free to try again.\n. We can place it in requests created by Clients then users can just remove or replace that header.\n. If we are going to continue to add options to Client and RequestBuilder, I think we should move to a modifiers-based API. Modifiers have worked out astoundingly well in Iron, and I think they could be useful here too.\n. Fixed in #375 \n. cc #346 \n. Good catch! This makes builds much faster.\n. @seanmonstar when you make the PR can you mention this issue in it so that github links to that PR here?\n. This increases our travis time to over 5 minutes, but other than that I guess it only helps, so +1.\n. To be truly agnostic, we'd need to move the request head parsing logic into the public API, and have those reads only execute when the user asks for them. Otherwise, the user won't be able to use whatever event notification mechanism they want.\n. Also, @seanmonstar I have some experience with mio, so if you have questions please ask.\n. The secondary issue is ensuring that we don't do things like:\nrust\nlet buf = get_buf();\ntry!(req.read(&mut buf));\n// process part of buf but don't save progress anywhere outside this call\ntry!(req.read(&mut buf)); // could yield wouldblock, and we would lose the info from the first read\n. Fixed in master!\n. Possibly, let me rebase.\n. Everything but that nit LGTM.\n. The Header downcasting stuff all needs Reflect bounds similar to Any and NetworkStream to be safe.\n. @Ryman you're right. The existing Any bound should be sufficient.\n. /me brings up modifiers again\n. wow that's a huge gain!\n. Can you bench this change? I'm curious how much of a difference this actually makes.\n. LGTM except nits\n. @seanmonstar fixed\n. The Unicase changes broke master\n. I was on my phone earlier - to be a little more clear:\nUnicase changed to use AsRef instead of Deref for its impls. The impl of AsRef for Cow is overly restrictive, so this causes breakage. The linked PR fixes this, but won't be in beta. It would be nice to build on beta.\n. LGTM. The Into<Box<NetworkStream + Send>> thing is a bit weird, but it works.\n. It's a pretty nice way to avoid double boxing in some cases.\n. @seanmonstar For some reason I thought beta was rebuilt every day, but apparently not...\n. Looks like we'll actually need to keep this to build on beta for a bit, so closing.\n. I would also be happier if we could at least use a common type with the cookies crate. Unfortunately, because of the nature of static typing, there's not really a great way for us to be compatible with the cookies crate without depending on the cookies crate (and the associated ssl stuff).\n. This is due to some new bubbling behavior with join guards.\n. @mlalic might be worth rewriting commits now just to get gitcop to shut up (I just deleted its comments since it's noise right now).\n. @nicholaswyoung just match on the method field of the Request and check for a Method::Extension which contains the expected string (SOURCE).\n. This is a breaking change of sorts, since nightly consumers will have to configure hyper to use the nightly feature.\n. The build needs to be run with --features nightly if a nightly rustc version is being used, but right now no feature is passed on travis.\n. LGTM except for that nit\n. Covered by #465 \n. @pyfisch httparse::Request and httparse::Response grew a second lifetime, which broke the impl.\n. @pyfisch should we try to move existing tests into this infrastructure, or is it meant to only be for certain types of tests? Agreed with @seanmonstart that this looks pretty awesome.\n. grumbles something about macros not being hygienic even though they are supposed to be\n. When a new version of thread::scoped lands, we will be able to remove the 'static bound, but for now we need 'static to be able to use Handler within hyper's internal thread pool.\nBy the looks of the Leak/thread::scoped discussion and the time to 1.0, it seems unlikely that the new API will look like the old one, so we will also have to provide a different Server API for non-'static handlers.\n. I wish we could pull the io::ErrorKind trick of having an unstable error variant to make this not a breaking change, but there's no good analogue for stability markers.\n. Can you re-run with RUST_BACKTRACE=1, so we can get a backtrace for that panic?\n. Nice!\n. Alternatively just add downcasting to NetworkStream proper, in addition to the impl for NetworkStream + Send.\n. @ssokolow I agree this would be nice. If you're up to PR the changes to the README, I'd be happy to review/merge.\n. I'd prefer build, crates, coverage, license. Since the colors might change, we shouldn't organize by color.\n. @ssokolow sorry for just dropping this, I just found it again and still want to do this. Feel free to PR build, coverage, license, crates.\n. LGTM - do we care about the coveralls regression as a blocker?\n. Why not into instead of to_owned?\n. Maybe we should pull in the void crate for this? I just updated it to work on stable.\n. I use a later version of openssl then what ships with OS X (from brew), so I didn't have this problem.\n. I like the new Server API, seems more easily extensible.\n. @seanmonstar give me a heads up before publishing a new version including these changes please.\n. You must send Connection: Close to signal to the client that they should not use keep alive on this connection. See the relevant section of the spec: https://tools.ietf.org/html/rfc7230#section-6.6\n. If we immediately closed the connection then the client may not be able to fully read the final response, as noted in the spec.\n. Awesome, LGTM.\n. Yes, you'll need to implement the Scheme trait (http://hyper.rs/hyper/hyper/header/trait.Scheme.html) with the scheme name (\"Token\") and format.\n. Then you can use that type with the Authorization header type, which is generic over Schemes.\n. @arnm there's a little bit of a bug in your FromStr impl, it will make the token include token=. \n. @arnm it will work when sending Authorization<Token>s but not when receiving them.\n. @pyfisch that has been happening, but I do not know how to fix it.\n. @pyfisch how urgent is this change would you say? It seems like a rather large update judging by the commits. Worth merging now and bumping to 0.7 you think? \n. I'm wary of doing several breaking releases back-to-back.\n. @shinchiro openssl requires some native dependencies to build on windows, see this section from the rust-openssl README: https://github.com/sfackler/rust-openssl#windows.\n. @arnm you could probably apply most of the things iron does on the server to a client, namely modifiers, an extensions map, etc. A Modifier that you apply to every request basically does what you want.\n. Oh, duh! Can't believe neither of us caught that earlier.\n. Done.\n. My 2c: I would not mind adding a convenience for patch, it seems mostly harmless to me; I am not very concerned about the maintenance burden of such a method.\n. It's definitely a legitimate concern generally speaking, but I think it is worth it in this case.\n. @anowell a possible solution to this problem is through something like modifiers (github.com/reem/rust-modifier, shameless plugs!) which allow you to define the modification once then apply it as both self -> Self and &mut self -> &mut Self. Iron uses this pattern extensively.\n. Very true, it's certainly a tradeoff. The type-driven nature can also be confusing in generic contexts.\n. The ergonomics are nice though because you can define new modifiers outside of the crate that defines the type being modified, so others could publish their own extensions to the RequestBuilder interface.\n. I think an enum might be reasonable, depending on how common this is.\n. Also rolled in some random formatting fixes I saw along the way, mostly unnecessary or missing newlines.\n. :bell: :fireworks: :100: \n. I am planning to use this in iron to expose keep alive and other timeout settings.\n. I could just duplicate this in iron, but it seemed better to just expose it. It's convenient to be able to pass it around externally too :P\n. Yeah, that's a good reason, I'll redefine it in iron.\nThanks,\n         Jonathan Reem\nOn Sat, Nov 28, 2015 at 7:17 PM, Sean McArthur notifications@github.com\nwrote:\n\nI'm not yet sure how timeouts will be set in the mio branch. Could you dupe\nthe struct in Iron for now? If this struct is kept in hyper, it can be made\npublic eventually, and you could swap the def for a reexport and it should\ncontinue to work.\nOn Sat, Nov 28, 2015, 1:28 PM Jonathan Reem notifications@github.com\nwrote:\n\nI could just duplicate this in iron, but it seemed better to just expose\nit.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/697#issuecomment-160336903.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hyperium/hyper/pull/697#issuecomment-160348355\n. Giving the spec another close read, it seems that both the existing and proposed behaviors are legal, since the spec doesn't tie any defined semantics to GET or HEAD requests with bodies. Since reading the body is more flexible and I've seen GET requests with bodies in the wild, I think we should do this.\n. I have the same concerns, this is very cool but might be too much. However, I am leaning towards it since I think the ability to talk about only a class of status codes is pretty interesting.\n\n\nThe problem @seanmonstar raised can be mitigated by providing a set_status function which takes an S: Into<StatusCode>, though it still is a bit of an ergonomic hurdle. Fortunately even without such an API the fix for that error is just one .into(), which is not so bad.\n. If we could somehow hint in that error to use Into then I think I would be for it but right now it's just not very newbie friendly.\n. Hmm something appears to be very wrong on some of the windows builds, they just quit randomly in the middle of the tests with a random-looking exit code.\n. Yup. Will rebase.\n. Hmm. I think people in Rust are used to assign-via-deref because this is a relatively common pattern, but I'm not opposed to set_status in principle. I wonder if there is a style guide convention for this case. \n. Hmm. I think so, the tricky thing is deciding when to do the teardown.\n. Weird. I tried to do it that way and kept getting address in use, I'll try it again.\n. Oh, cool. I'll give that a shot.\n. Oh, my bad. I completely forgot to change anything but the server response :/\n. I have to edit this PR anyway, so I'll just change it.\n. Gross but this seems necessary for now.\n. Is it illegal to name an enum and one of its variants the same thing? You could also call the variants Http and Https\n. match *self is nicer\n. I thought I defined this somewhere. Is this duplicated in hyper now?\n. Ah, I remember now, it was in rust-http.\n. I doubt it, but it's what we do elsewhere so we should stick to one form for consistency.\n. That could be good and I don't really see a reason why not.\n. Does this just add a name to failed tasks?\n. Ok, seems reasonable then.\n. Is there a reason this was changed? I left it here so people would know what was being done in each call.\n. excessive newlines, I think\n. Ah, that seems reasonable. Maybe a comment could replace the messages?\n. should be is_err\n. This is simple enough to be inlined.\n. reformat to:\n```\nNote:\nExtension methods are only parsed to 16 characters.\n``\n. delete\n. Can you document whattrueandfalsemean in this context? What does each indicate?\n. I appreciate the comments, but they have to stay in the codebase :). Drop this one.\n. We can just keep the first line here asWe already checked that the buffer is ASCII. Our style has beenunsafe { raw::from_utf8(ext) }.trim()`\n. The above could probably just be inlined here as:\nunsafe { raw::from_utf8(ext) }.trim().into_string()\n. This should go in src/lib.rs\n. Which will change to just plain serialize\n. This should use Vec::with_capacity to avoid resizing.\nEDIT: Wait, we don't actually know the exact number of cookies... It could at least start with raw.len() capacity though, which avoids resizing when there is one cookie per line.\n. We should standardize on a convention here, but I personally prefer &*cookies_raw instead of cookies_raw[].\n. Again just a style thing but elsewhere there is no newline here.\n. It would be much faster to slice until 1 before the end of the vec, iterate over that with no branches, then append the last one after the for loop.\n. typo in crate\n. create a corresponding\n. If this is quoted from somewhere, we should brace it off and cite it.\n. Same [] vs. &* question here.\n. Would be a lot faster to write the first one, the iterate over a slice of the rest of the values.\n. Same with_capacity comment as earlier.\n. I think this is a reasonable hack for a very unusual header. We will have to consider the ramifications of this for re-parsing, though.\n. It's not a huge deal, we can go with [] for now. \n. In the future, if we want to enable re-parsing headers into different representations, we will have to do extra work here as headers will be able to produce more than one value.\n. This macro should be renamed, since it no longer does continue.\n. this should probably be error!\n. and this macro should be renamed too\n. We should really be using https://github.com/reem/rust-resistant-taskpool. The std TaskPool crashes the whole process in the face of any subtask panics, allocates way too much, and does no load balancing.\n. Wait so there is no way to close a connection in HTTP 1.0?\n. why can't we just pass read_stream and write_stream directly here to avoid dynamic dispatch?\n. I'd much rather this be a parameter somewhere rather than a method on Handler, since that is much easier to change.\n. This is unfortunate. I'd much rather require Sync and place this behind an Arc ourselves. You can always lift Send to Sync using Mutex anyway (though that would be a horrible idea in practice).\n. If we do use a Clone bound, then there is no reason handle can't take &mut self, but from experience in Iron I can say that Send + Sync is a much clearer, more performant bound.\n. is this meant to be commented out?\n. same here\n. we should probably name the lifetimes here, so that they can be used when convenient.\n. Regardless, HUGE +1 that this no longer has the extremely noisy NetworkAcceptor/NetworkStream type parameters.\n. Makes perfect sense. Catching nits is like 50% of the utility of code review anyway.\n. I figured it was something like that, it just looked a bit weird to me.\n. Our default could be this, but keeping it as a trait method is inconvenient because it means you have to create a new type if you want to have a different number of threads, i.e. you can't use fn handlers.\n. On second thought, I'm actually not sure. It's harder to emulate the Clone behavior with a Sync bound than it is the Sync behavior with a Clone bound. If we keep the Clone bound though we should let handle take &mut self.\n. Actually it doesn't matter. I was thinking of some frustrations I had with rust-http way back in the day, but it occurs to me that I actually just had no idea what I was doing.\n. I would not mind Response<W = Fresh>.\n. Does trait Handler: Send not imply 'static'? \n. Should this really be String or should it be a more general type like Vec<u8>?\n. Wow go DST!\n. could this just take &mut Item and the &mut * be done at the call site?\n. same here as on downcast_mut\n. <3 tests\n. This is a good simplification. Using IntoCow here in the relevant places is much better.\n. In a separate crate it the generic makes a lot of sense.\n. Yup.\n. Is this transmute still needed?\n. I thought Mucell borrow_mut gives you a regular &mut, since it requires &mut self. \n. unneeded now \n. we should probably debug_assert or something that this actually succeeds, since it will cause an unsafe transmute or unwrap if it doesn't.\n. I think this is from the original code, but the chain of methods and operations here is long enough that the types in this transmute should be made explicit.\n. can you do just .and_then(get_or_parse_mut) here or do you need to be explicit with the ::<H>? \n. To give better error messages in the case where the second branch is actually reachable (due to an internal error in the use of this function) we should probably do item.typed.as_ref_mut().expect(\"some explanatory message\").downcast_mut_unchecked() or so instead of unreachable!().\nGenerally speaking, these functions should actually be unsafe themselves, since they do no checking. I'm not certain on the conventions here, but I think that internal unsafe functions should still be marked unsafe to help the library authors.\n. and_then(get_or_parse_mut::<H>) should work, you use it with parse later.\n. unsafe maybe?\n. Ok. I think the warning should probably be enough.\n. extra newline here\n. I don't think we are actually using this feature anymore.\n. Ya, huge improvement on our end.\n. You could just return a struct, and add fields when needed, so the type does not change.\n. Can we split this up into smaller tests?\n. Could be any number of things. We just always make sure to use a single run of benchmarks, as opposed to repeated runs.\n. Instead of building this RequestOptions struct, which will break if we add fields in the future, I think it would be best if client.request() returned a builder type, that way we can add more options without breaking existing code.\n. I think this is a good specialization to avoid dynamic dispatch, but it may be useful to set constant-size readers from non-BufReaders, like Files.\n. Maybe renaming this to BufBody and having a separate SizedBody.\n. you should be able to just use method::Method::..\n. This (and the header definitions) could all go in an encoding sub-folder inside of common.\n. nit: style is fn mark_dead(&mut self) {}\n. Shouldn't there be something here, or am I misunderstanding?\n. Ah, ok. You're saying this would be used if hyper had client-side keep-alive built-in.\n. We have tuple indexing, so you can do self.0 to get rid of this now!\n. @seanmonstar should these be deref also?\n. +1000\n. This should be changed to such as in\n. This is pretty awesome, but we will need to remember to update it.\n. Could this be replaced with url::Url? It doesn't seem like a lot of additional effort would be needed.\n. Should be deleted, not just commented.\n. Should this really be u64 and not usize?\n. Use a where clause instead, it's much cleaner. (for all these params)\n. this line and the one above could be combined\n. Here too, not usize for the size?\n. Shouldn't need this explicit lifetime.\n. Not ideal\n. where clause here too\n. Can we use a more descriptive name like verifier? It's a small change but it brings clarity.\n. missing space before the {\n. This feels a bit low. How about 256?\n. Agreed.\n. this unwrap should go on the send call above.\n. agreed\n. I would prefer Unregistered(999), especially for a Debug implementation.\n. this sentence doesn't make sense, probably some typos\n. .map is preferable to this match\n. Can just replace this with s.as_bytes().to_vec()\nAlso, just FYI no need for annotation here and the style is let mut v: Vec<u8> (no spaces around :).\n. Can you add some benches too like all the other headers? They are generated using a macro.\n. Look at the Drop impl. We need to use the key by value in the drop method, so we need to use the option dance.\n. It's a bit more general, and I think I might use it in the future for some other features, like a timeout or something.\n. Additional advantage of making this blocking: 'a here instead of 'static, so this can be used with non-'static data.\n. To make this blocking we'd just remove the thread::scoped call here and just run this loop.\n. ??\n. I think Ok(0) is still bad behavior, unless the recent RFC changed that.\n. can this be renamed, since it is specialized to methods?\n. This whole macro business is honestly horrible (lots and lots of code to do mostly the same thing), why is this necessary? Can't we add an extension method?\n. Just found httpparse, seems interesting but we'll need a push parser for async integration later (API similar to https://github.com/reem/rust-pico but ideally in rust without the ffi piece).\n. Asked about this and you're right. (deleted the other comment on this same thing)\n. Oh, so the idea is I call parse many times (until Status::Complete, I presume)?\n. Can you do this for the other examples too?\n. Either we should change defaults or go back to the original.\n. stray println!, probably should go back to error!\n. I'm fairly confident this will prevent uploading to crates.io. We will have to upload and depend on hypernet and hyperprotocol as normal dependencies.\n. I don't think these methods should be public. We should provide a safe, checked API.\nThis change should also probably be in another PR.\n. Yes, of course. Why do you need to use them in tests?\n. What if instead of a specific method for this header, we just have a set of headers we clone into every request, so users can set any default headers really easily and the API is really simple.\n. Yes, but then you have to add it for every request. If we provide a way to set default headers for every request, then you can cut all that boilerplate.\n. since the field is pub this is apparent, so no need to mention specifically in the docs\n. IIRC it's worked ever since Box::new existed, but the silent coercions with Box::new aren't as ambitious as with box.\n. Turning this down should be a nice perf win for short connections.\n. Reflect shouldn't be needed in this file as far as I can tell. What error comes up if you remove these bounds?\n. I see, since our Header traits should require Reflect.\n. typo in just\n. its should be it's here\n. 'static is implied by Any so we can get rid of it too.\n. This is totally a judgement call, but do you think we should add Any to the HeaderFormat supertraits?\n. Send is implied by HeaderFormat\n. 'static implied by Any here too\n. Why hidden for this and to_u16? That's something people are likely to want to do.\n. Eq, Ord, and Hash too while you're at it? It seems valid to want to put these in a hashmap for routing of some kind.\n. Maybe we want to change the signature of this function to return HttpResult so that we can use From instead of map_err(lift_ssl_error).\n. I think we should, so that we can keep the entire error around rather than losing information like we do now.\n. There is a hack to get around this where you define another trait that takes self: Box<Self> instead of self. See FnBox in std for an example.\n. Probably AsRef<str> would be the better thing, but sounds good.\n. We could get rid of this and just have HttpRequestFactory inherit from Default. \n. One possible renaming: the trait can be called HttpProtocol or just Protocol and the types can just be renamed to Http11 and Http2.\n. Since this is in the client module already, I'm not too concerned with it being overly broad, and I'd be really happy to get rid of HttpRequestBoxFactory :P\n. This function should probably take the guard for now, so that it at least lets you close a program running a server.\n. much shorter to just write self._guard.take().map(|g| let _ = g.join());\n. could be just use Error;\n. The convention is to use \"with\" for these sorts of constructors, so https_with_context may be appropriate.\n. better to use Option<SslConfig<'a>>\n. 'a appear unused here\n. LLVM almost certainly elides the bounds check here anyway. I'd personally rather have less unsafe. I doubt this has a noticeable impact on perf, but I'd be thrilled to be proven wrong.\n. This is inspired.\n. That said we can get better perf by just doing TypeId::of::<W>() == TypeId::of::<StatusFresh>(), which will get the branch optimized away because monomorphization.\n. should lose the _ now that it is used\nEDIT: nvm because the suggestion in the other comment makes it unused again\n. This function is starting to get really long, can you split this (or other) sections into another fn?\n. This should probably be __NonExhaustive.\n. typo in with as wit\n. Stray commented code related to this type. As far as I can see it can just be deleted.\n. Everything else looks great, but can we move this into the definition of the header macro, so that we automatically get serialization for most headers?\n. Unfortunately this doesn't work without exporting generate_header_serialization too, since the expansion is in another namespace. \nWe can just export it with a __ prefix like __hyper_deref. \n. I am not a fan of splitting this code out into a common function, in my opinion, the code is clearer and more idiomatic if we keep the use of client in a simple case like this down below, in main. I think clear variable names and comments will be enough to teach correct use.\n. what is the nitpick?\n. I think you should be able to write &mut mock as &mut NetworkStream here (which you could also just inline into the following line).\n. ",
    "untitaker": "Some servers send me a gzip-compressed response without me asking for it, so practically I must always be prepared for such responses.\nUnfortunately the RFC's language isn't very clear what the server is supposed to do if no Accept-Encoding header is sent. From RFC 2616:\n\nIf no Accept-Encoding field is present in a request, the server MAY assume that the client will accept any content coding.\n\nhttps://tools.ietf.org/html/rfc2616#section-14.3\nFrom the newer RFC 7231:\n\nA request without an Accept-Encoding header field implies that the user agent has no preferences regarding content-codings.  Although this allows the server to use any content-coding in a response, it does not imply that the user agent will be able to correctly process all encodings.\n\nhttps://tools.ietf.org/html/rfc7231#section-5.3.4\n. See also https://stackoverflow.com/questions/8364640/how-to-properly-handle-a-gzipped-page-when-using-curl\n. Probably, though I'd still prefer if Hyper handled this transparently for me (even if behind a featureflag).\nWould setting this as a default header (on Hyper's side) be acceptable?\n. This has bitten me again. This time a different library, @simonsapin's kuchiki provides a parse_html().from_http(url) interface, but doesn't explicitly set a header. The result is a garbage DOM.\n\nIf a user of hyper hasn't stated otherwise, I don't think we can assume a preference.\n\nIf a user of hyper hasn't stated otherwise, I don't think we can assume they'd thought about it.\n. Sorry, it seems to be an issue with the server in this case.\nEDIT: Yes, in the previous instance, setting Accept-Encoding: identity helped.\n. @seanmonstar Could you specify the version or commit in which this has been fixed?\n. The Origin header is set for CORS requests.\nOn 15 October 2015 01:36:27 CEST, Sean McArthur notifications@github.com wrote:\n\nIs this in common use? I've never used it myself, and when checking the\ndev consoles, I notice neither Firefox nor Chrome set that header while\nbrowsing.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hyperium/hyper/issues/651#issuecomment-148233353\n\n\nSent from my phone. Please excuse my brevity.\n. I don't think anybody is working on this.\nOn Thu, Nov 19, 2015 at 04:56:13AM -0800, Martin Feckie wrote:\n\n@seanmonstar Is anyone working on this?  If not I'd be interested in giving it a go\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hyperium/hyper/issues/651#issuecomment-158049297\n. I think the main discussion is under https://github.com/hyperium/hyper/pull/691, basically we waited until rust-url was 1.0 (where its Origin type was rewritten) and then forgot about it.\n\nOn 5 July 2016 01:21:00 EEST, Michael Perez notifications@github.com wrote:\n\nWould love to get newly-rusty hands wet; what's going on here? \nA variety of PRs have been closed, and one (to another project?) \n\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub:\nhttps://github.com/hyperium/hyper/issues/651#issuecomment-230359643\n\n\nSent from my Android device with K-9 Mail. Please excuse my brevity.\n. @seanmonstar To be fair, a draft requires it: https://datatracker.ietf.org/doc/draft-dejong-remotestorage/?include_text=1\nThe endpoints used are APIs, and caching is handled via ETag headers. I assume the requirement was primarily added to avoid leaking user data through cached responses.\n. FWIW, google.de replies with Expires: -1.\n. See also https://stackoverflow.com/questions/11357430/http-expires-header-values-0-and-1\n. I've concluded that this is an edgecase. I don't think it's a priority to support right now, so I'll close this for now.\n. Thanks for reviewing! Could you release a new version for this?\n. Thank you!\n. Lgtm. Fwiw iron has a default status code of 500 right now, for the same reason. I guess that can be removed again?\nOn 30 October 2015 03:11:02 CET, Ryman notifications@github.com wrote:\n\n@seanmonstar Not sure if that's a genuine appveyor failure? Looks like\na timeout on one of them, and the testrunner not completing on the\nother?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hyperium/hyper/pull/676#issuecomment-152388778\n\n\nSent from my phone. Please excuse my brevity.\n. Nvm I see you've already linked it.\nOn 30 October 2015 03:11:02 CET, Ryman notifications@github.com wrote:\n\n@seanmonstar Not sure if that's a genuine appveyor failure? Looks like\na timeout on one of them, and the testrunner not completing on the\nother?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hyperium/hyper/pull/676#issuecomment-152388778\n\n\nSent from my phone. Please excuse my brevity.\n. Build failure doesn't seem to be related. I'm not sure.\n. Perhaps wait for https://github.com/servo/rust-url/pull/138\n. This is now review-ready, turns out pinning only by version-range is a bad idea.\nAnyone?\n. @Ryman Just problems in principle: You might expose different behavior depending on which url version is installed. Some of that behavior differences are catched by the typesystem and the resulting combination just doesn't compile, but others may be more subtle.\n. BTW: You'd probably have to bump the minor version after this, since url is part of your public API\n. The url crate already has a Origin type. Perhaps use that one?\n. @seanmonstar No port implies default port, much like URLs.\nBetter reference: https://tools.ietf.org/html/rfc6454\nIn response to your question, in particular: https://tools.ietf.org/html/rfc6454#section-4\n. I don't think a change would be appropriate to Origin. This is about semantics. The representation could be nicer in that ports that equal to the default one are omitted, but it really doesn't matter. Also:\nrust\nlet x = Url::parse(\"http://example.com:80/\").unwrap();\nx.serialize()  // http://example.com/\n. I still don't see why we need to make a distinction between implicit and explicit default ports. The flag is not needed IMO\n. I would just omit default ports during serialization. The implementations you mentioned already wrongly detect inequalities, and I think making a distinction in hyper as well would make the situation worse.\nOn 17 December 2015 19:49:13 CET, Sean McArthur notifications@github.com wrote:\n\n@untitaker I'd like to agree, but I worry humans don't actually\nimplement what the spec says (all too common).\nExample: if using url::Origin, then in hyper a\nOrigin::new(\"http://foo.example\") would return in\nOrigin(url::Origin(\"http:\", \"foo.example\", 80)). Serializing this\ninto a request would look like this:\nGET / HTTP/1.1\nOrigin: http://foo.example:80\nLooking in the CORS code of 2 popular nodejs libraries, I believe\nthis would be rejected.\n- expressjs:\n  https://github.com/expressjs/cors/blob/ddc7d03e12db8e74d44b73aa6136b90b2bd25640/lib/index.js#L26\n- hapijs:\n  https://github.com/hapijs/hapi/blob/492e59496abcbc3d73642e5b1391bd3b8b6b1e1d/lib/cors.js#L183\nThey both do exact String matches, forgetting that default ports should\nmatter as well.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hyperium/hyper/pull/691#issuecomment-165545652\n\n\nSent from my phone. Please excuse my brevity.\n. That's surprising. Which concrete change would you like to see?\n. Right, but it wasn't clear at all if you wanted the author to actually use\nurl's struct (or if you think that their impl was flawed).\nOn Wed, Mar 09, 2016 at 01:00:48PM -0800, Sean McArthur wrote:\n\n@untitaker this PR has struct Origin(pub String);. The discussion in the PR suggests having an Origin that knows the scheme, host, and port (perhaps from the url crate).\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/hyperium/hyper/pull/691#issuecomment-194505076\n. Preparing new PR. I'll probably submit the special formatting in rust-url though.\n. Ah, thanks for the hint, I was about to change some things to master...\n\n@SimonSapin I want to to add a simple FromStr impl for Origin that just does url::Url::parse(...).map(|u| u.origin()), for the purposes of this PR. Should I wait post-1.0?\n. @SimonSapin I want to use rust-url's Origin type in Hyper's Origin header, so I need a way to parse it from a raw header value. You're right about extra components, this restriction could probably be applied after parsing the input as URL.\n. (I'm willing to write a PR for this)\n. Great, I will write a PR as soon as possible.\n. @seanmonstar Work in progress at #898, I underestimated the effort and need some guidance about further procedure.\n. @seanmonstar This should be ready to merge.\n. Thanks!\n. For reference see https://github.com/servo/rust-url/blob/master/src/host.rs#L85. Using the parser function from rust-url would be a bit wasteful in our case as we are storing the host as string.\n. Note that this has been merged into the maintenance branch and still needs to be merged into master \n. Fwiw I usually merge maintenance branches into master, because then git knows which commits are not yet merged into master and which are\n. formatting nitpick\n. Yikes, misread the diff. Sorry for the noise.\n. Because a H may be unsized, I probably can only return Option<Box<Header + Send + Sync>> here. However, then I'm unsure how I'd be casting the box to a concrete type.\n. I was trying to keep this analogous to get_mut and get, but UnsafeCell::into_inner has some extra caveats.\n. Also UnsafeCell::get is not marked as unsafe, I don't understand why it is wrapped in an unsafe block in get and get_mut.\n. This is actually incorrect. None may also be returned if the removed header was not parseable.\nI wonder if we should return Option<(Raw, Option<H>)> or something like that instead, to enable as many usecases as possible.\n. To be clear, I get a type conflict exactly at this spot: Expected H, got Box<Header + Send + Sync>. The first idea here is to add a new downcast_* method to impl Header + Send + Sync (again analogous to the get methods), but I don't know how to implement such a method.\n. I can't think of a reason why Raw is needed, but with the current return type there is no upgrade path for people who were checking the boolean value, as .is_some() is false even if the header was removed, but could not be parsed.\n. Therefore Option<Option<H>> or Option<Result<H, ()>> would be appropriate if we don't want to bother with Raw.\n. Fair enough, I will update the docstring then.\n. Unfortunately this doesn't work, apparently I can't deref *mut T.\n. Amazing.\n. ",
    "SimonSapin": "(@untitaker I\u2019ve extended kuchiki\u2019s from_http to also except an hyper::client::Response so that you can set headers and make the request yourself. In that case, the point of using it from_http instead of read_from with a Response as a generic std::io::Read is that it gets the charset from Content-Type, if any.)\n. I had a name conflict the last time I tried this, but maybe the language changed.\n. (\"This\" is @Manishearth's pretend-enum.)\n. Disabling security based on environment variables sounds dangerous.\n. I don\u2019t know how real the problem is, but it\u2019s not the same behavior. URL parsing does some normalization along the way, so comparing parsed URLs is not the same as comparing strings. And CORS is a security/privacy feature, so I\u2019d rather not take chances.\n. @Ms2ger, do you have an opinion on this?\n. I just published url 0.3.0 0.2.38 on crates.io which includes https://github.com/servo/rust-url/pull/134. Publishing is easy but I sometimes forget to do it. Feel free to ask for it in PRs!\n. Yes, the port number has a default based on the scheme:\nhttps://url.spec.whatwg.org/#origin\n\nReturn a tuple consisting of URL\u2019s scheme, its host, and its default port if its port is null, and its port otherwise.\n\nhttps://tools.ietf.org/html/rfc6454#section-4\n\nIf there is no port component of the URI:\n Let uri-port be the default port for the protocol given by uri-scheme.\n. I think the Origin type in rust-url was designed for equality testing, possibly without considering serialization or the Origin HTTP header. I\u2019d review a rust-url PR to make a change here if you think it\u2019s appropriate.\n. Re earlier comments, the rust-url 1.0 branch (which I hope to merge soon-ish, I still many tests and some bug fixes in setters) now implements the \"ASCII serialization of an origin\" and \"Unicode serialization of an origin\" algorithms as defined in the HTML\u00a0spec. https://github.com/servo/rust-url/blob/1.0/src/origin.rs\n\n@untitaker In what cases do you parse an origin from a string? Does a relevant specification define a parsing algorithm? Parsing as you describe would accept and ignore URL components that are not relevant to origins, e.g. http://me:secret@example.net:8080/foo?bar#baz -> https://example.net:8080. Maybe the presence of these components should be an error?\n. https://fetch.spec.whatwg.org/#http-origin and https://tools.ietf.org/html/rfc6454#section-7.1 both define the syntax for the Origin header. The former says it supplants the latter. They disagree in the header containing a single origin vs a space-separated list of them but they agree that one origin is scheme \"://\" host [ \":\" port ] with each component as in URLs and without extra components like a path.\nI\u2019d recommend not using the URL parser. Instead, use this regex ^([a-zA-Z][a-zA-Z0-9.+-]*)://(.+?)(:[0-9]+)?$ (where +? is non-greedy repetition) or an equivalent hand-written parser, plus rust-url\u2019s Host::parse for the host component.\n. This would be ~half as useful. Doesn\u2019t that code need to import ContentType? In addition to imports, the point is to make this more discoverable.\nInitially I even wanted this on Response, but some_response.headers is easy enough to access.\nFor what it\u2019s worth, the Requests library has a Response.encoding and demonstrates it on their home page: http://docs.python-requests.org/en/master/\n. No, only content type: https://github.com/kennethreitz/requests/blob/057722af23e/requests/utils.py#L334-L351\nI\u2019m guessing that\u2019s because charset is misnamed. What\u2019s relevant is not so much the set of supported characters but how to decode them (the encoding).\n. Still not ready to land, but what %{type} is appropriate here?\n. https://crates.io/crates/url/1.0.0 is (finally!) published and this does not actually depend on https://github.com/alexcrichton/cookie-rs/pull/42 since url is not in cookie\u2019s public API, so this is ready to land. Could you also publish it on crates.io? It\u2019s probably a breaking change.\n. Updated.\n. That\u2019s not what Cargo does. It considers 0.x.y+1 to be compatible with 0.x.y, and updates to it automatically (either when running cargo update or when there isn\u2019t a Cargo.lock file already).\n. I\u2019ve also reproduced the error with armv7-unknown-linux-gnueabihf but not: aarch64-linux-android, aarch64-unknown-linux-gnu, arm-unknown-linux-gnueabihf, or arm-linux-androideabi. So this looks specific to ARMv7 but not Android.\nI\u2019ve added corresponding cfgs, with a macro to avoid repeating stuff.\nThis PR works for me when building hyper by itself, let\u2019s try it in Servo before merging.. ",
    "Trolldemorted": "@seanmonstar is it possible to set the headers once per client, so that we don't have do add them with every request?. ",
    "cmr": "This is really important for SSL requests.\n. ISTM like the method module no longer needs to exist, since the variants can legitimately just be Method::Get.\nIt'd be nice to get any fix merged, though, my projects are broken right now.\n. ",
    "fhahn": "What do you think about using httpbin for testing the client implementation?\nIt's using Python & Flask, but seems very useful for testing the HTTP implementation.\n. ",
    "pyfisch": "I think it is useful. If @seanmonstar and @reem want to use it I will write some end-to-end tests using it.\n. I am working on this. (But I will wait with commiting until #216 is merged)\n. Referer header is already part of hyper: https://github.com/hyperium/hyper/blob/5d93a3bd9132f1cee405b553e5a0893693b3d78b/src/header/common/referer.rs\nSo close this issue and open eventually a new one for the relative URLs.\n. I would like to work on this.\nActually the spec can be found at https://tools.ietf.org/html/rfc7231#section-5.3.4 and not at 7.1.4\nSome notes:\nThe Accept header is quite similiar to the Accept-Encoding, both allow to specify quality values, but the existing implementation does not deal with it. It simply packs all media types into a vector without preference information. Is this an intentional simplification of http, and should also be used for Accept-Encoding, or should I write a proper solution for quality values?\n. Ok, I take everything back I said about quantity values, these are already handled by http://github.com/hyperium/mime.rs very well. I just did not see it.\n. But is will be better to move q= out of mime to make accept similiar to the other accept-* headers\n. This can be closed now.\n. Maybe we should just ask if they can fix their test? Just my 2 cents.\nAs I understand it a StatusCode higher thang 599 is just forbidden by all relevant specs.\n. Ok. Does anybody think that there are status codes out there greater 999 or smaller 100? In this case I would add the variants to the enum.\n. I asked on #whatwg and @Ms2ger answered:\n- XHR defines status codes as 16-bit attributes (unsigned :grinning: )\n- HTTP/1.1 RFC7231 defines status codes as \"three-digit integer code\"\n  - We were not sure if 042 is a \"valid\" status code\n- HTTP/2 simply refers to HTTP/1.1 for a definition.\n. I think it is hopeless :joy_cat:\n~~Two~~ 4 more interesting facts:\n- Both Chromium and Firefox understand 42 and 1024\n- Only Chromium understands 2147483647, firefox thinks it is 200\n- Firefox supports negative status codes with integer underflow :+1: :heart: \n- 0 makes problems (Not displayed or understood as 200)\nWho wants to test IE, Safari and Opera?\nSummary: Status codes are crazy.\nProposal: support u16 (This is what everyone supports. We could use an Option or the value 0 for anything we do not understand. Who uses such crazy codes will not care if they are understood.) Any ideas?\n. Would it be a serious performance bump, if we implemented StatusCodes like Methods? An enum for registered or well known status codes with an extension for unknown codes.\n. I modified teepee status code handling to support arbitary status code like header methods: https://gist.github.com/pyfisch/cceae250981243c33c5e (I understand that this should be avoided, I just tried to understand teepee and the problem better).\nAs @seanmonstar noted \"associated constants\" are needed to not change the interface much if we use an u16. I do not think that they are even planned for the near future (Is this RFC somewhat related? https://github.com/rust-lang/rfcs/blob/091e5fabbbbd0419b8d291a6d1cd8e6e59c56deb/text/0195-associated-items.md).\nSo the only option left is to use a newtype StatusCode(u16) and to define aliases for common status codes like static INFORMATIONAL: StatusCode = StatusCode(100);. It would change the API but once after there are associated constants we can update the code.\nOr is there another possibility?\n. @seanmonstar thanks for linking me the issue.\nSince you both @reem and @seanmonstar support my attempt to improve status codes, I published the code that is based on teepee at https://github.com/pyfisch/hyperprotocol. I created it as a separate repo since we wanted to split hyper anyway, and it looks for me like a good time to begin with it. Otherwise I can also integrate it into current hyper.\nAny suggestions for my header code?\n@seanmonstar You proposed Unregistered(u16) as an extension variant name. I admit UnregisteredStatusCode is quite long, but it is like the name for methods https://github.com/pyfisch/hyperprotocol/blob/master/src/method.rs#L56. I think we may should change them both to Unregistered.\n. Should I create a PR for this? I think it is better to add support for all status codes now and not to wait.\n. It looks to me like Cargo got support for sub-crates: http://doc.crates.io/guide.html#path-dependencies\nI propose to split Hyper into hyperprotocol, hyperclient, hyperserver and maybe hypernet.\n. Can be closed.\n. Can be closed.\nReplaced by #216 \n. Any comments? Anything that must be improved before merging?\n. Rebased.\nBy the way, will Hyper use Rust 1.0.0-alpha, after it is released? And after that use the stable versions? It really sucks that the build fails so often.\n. If this code is not perfect, please merge it anyway (after we are able to test it). All headers code needs a cleanup, I want to do. But I think it is better to this after the important headers are added.\n. @reem This is not finished yet probably Rust will complain about missing docs and other stuff.\n. Hyper ~~is~~ was  building again. The code compiled with rustc 0.13.0-nightly (ad9e75938 2015-01-05 00:26:28 +0000) for me.\nSo hopefully url is fixed soon so this can get merged.\n. I agree that it minimally less convenient to have to import things from two places. But I think it is worth it, because it makes hyper::header::common very clean. It only contains headers. Since header names must be unique, there can not be collisions between different headers. Currently the struct for the Cookie header is called Cookies, not very easy to know. This is because the name Cookie already used by https://github.com/alexcrichton/cookie-rs If we only have headers in common there are no such problems and we can rename Cookies to Cookie.\nThe rust guide recommends to import modules and no individual items (http://doc.rust-lang.org/guide.html#standard-input \"However, it's considered better practice to not import individual functions, but to import the module, and only use one level of qualification\"), I think you should anyway not do use hyper::header::{Connection, ConnectionOption} but use hyper::header. (I know hyper does not yet follow this practice at most places, but I think it would be a very good thing if it did)\nIt may be a good idea to reexport all contents of hyper::header::shared to hyper::header. If common would be renamed tocor something else very short you could douse hyper::header::{self, c}and then doheader::ConnectionOptionandc::Connection, which would be very easy to use, or don't you think so?\n. I am thinking about suffixing all headers withHeader` this would also make clear what structs and enums are headers and prevent collisions. This will break most existing programs and make the names longer. @seanmonstar What do you think?\n. Ok I will try to follow Thema :-D\n. +100\n. @kstep I am rewriting currently headers so do not hesitate to change it.\n. This is finished now. I think it can be merged and the other headers can be updated after this. GitCop complains, but how should a commit message for the merge look like?\n. @GitCop is finally happy :grin: \n. Squashing done. New PR is #250 \n. I will change it like you propose.\nBy the way. Should header:: export the macros? I think they are useful for custom headers.\n. Fixed all nits. Moved parsing to its own file. (Rustoc did not like it otherwise, and we also use separate files for everything else)\n. Can someone please rerun this on Travis, or do I need to change something in the code?\n. Can you please merge it? It has no new changes except a very few updates for master compared to #251.\n. I will look if there are things I have forgotten.\n. Ok, problems were already addressed in #264 and #265\n. Rebased and fixed everything.\n. Yes will change it.\n. Looks for me like you are using a to recent version of rust. Hyper will get fixed soon.\n. The scope is (as far as I know) not limited to specific values.\n. This should also take #80, #243 into account.\nProbably it would be a good idea to write out before what features the new header implementation should provide. You can extend this wiki page https://github.com/hyperium/hyper/wiki/Header-implementation\n. Seanmonstars branch looks good to me.\n. I think we should use HeaderMarker like teepee does: https://github.com/teepee/teepee/blob/6da58b4f2b92b41aee85f8b9490533b040b10954/src/httpcommon/headers/mod.rs#L112\nThis allows to strongly type the Connection header, and other things where you want to refer to a header without actually using a header. \nTo prepare for HTTP/2 we should provide 2 header name methods. One that returns the all lowercase name and one that returns the \"pretty\" name usually used in HTTP/1.x.\nrust\npub trait HeaderMarker {\n    type Output: ToHeader + Header + Clone + 'static;\n    // e.g. `accept-encoding`\n    fn header_name(&self) -> Cow<'static, str>;\n    // e.g. `Accept-Encoding`\n    fn nice_header_name(&self) -> Cow<'static str>;\n}\nBy using the lowercase name everywhere except for formatting we can drop the dependency on unicase.\n. I played a little bit with HeaderMarker and realised that there is no way to get the \"nice\" name from a header, if it is saved in Headers if using HeaderMarker.\nSo keeping the name part of the Header is better I think. Additionally Rust does not like the UPPERCASE_WITH_UNDERSCORE names the Teepee example uses for HeaderMarker\n. Would it not be better if the PathQueryFragment would be a url::Url? (I know that this not work well currently because you have to provide a host, but could not we provide a default host?\n. Merge this now. I will update language-tags at a later date.\n. Looks good to me, although I would prefer a stronger typed charset type.\n. Actually the list is not that long. It can be a separate crate like mime.rs\n. typo \"IfMtach\"\n. If anything is left to do tell me.\n. Is it possible with current blocking design to write a good HTTP/2 implementation?\n. I propose to keep them in hyper but to make them opt-in using cargo features.\nThere could be the following groups of opt-in header fields:\n- RFC7231: Semantics and Content#Content Negotiation; negotiation\n- RFC7232: Conditional Requests; conditional\n- RFC7233: Range Requests; range\n- RFC7234: Caching; caching\n- RFC7235: Authentication; authentication\n- RFC6265: State Management Mechanism; cookie\n- CORS; cors\nThe headers folder can be reorganised to represent the optional header fields. We can discuss if any of these groups should be included in the default compilation. There are still some non-essential header fields that remain in default like Server or Referer, maybe we can also make them optional.\n. Fixed tests.\n. +1 I did not think this far. Using integers  is much better here.\n. I am working on this.\n. Close this.\n. @filsmick:\nDo git commit --amend. Then change the commit message according to commit message format described in https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md. And then force push the updated commit with git push -f.\n. Added methods for float.\n@seanmonstar: I think we should provide a method for the user to create Quality directly with an u16 since converting to float costs a little time.\n. Updated the docs to give advice how to use Quality.\n. Actually hyper does not have a function to provide authorisation. But you can create a new client by wrapping client and passing all functions down to the original client.\nPseudocode:\n```\npub struct AuthClient{\n  client: hyper::Client,\n  credentials: Credentials,\n}\nimpl AuthClient {\n    // All the same methods as hyper::Client plus some for auth\n}\n```\n. @softprops @daogangtang You can use PR #354 for now.\n. Ok to me\n. @davidrhyswhite It kind of works now with the client example but Github returns a 403:\n$ cargo run --example client https://api.github.com/users/octocat\n     Running `target/debug/examples/client https://api.github.com/users/octocat`\nResponse: 403 Forbidden\nHeaders:\nContent-Type: text/html\nCache-Control: no-cache\nConnection: close\nLooks like Github does not like Hyper.\n. User-Agent header is required: https://developer.github.com/v3/#user-agent-required\n. I will move server and client later out of main hyper crate. They both depend on src/http.rs and src/uri.rs. I do not know where this code should be placed. I think it would be the best thing if we could get rid of RequestUri and use always rust-url absolute URLs.\nThis depends on https://github.com/rust-lang/rust/issues/23110 being fixed. Or is there a workaround for now?\n. Rust broke hyper again. The whole downcast stuff is broken.\n@reem Yes we should use relative URLs.\n. Everything works now.\nPath dependencies are rewritten to normal dependencies in cargo: http://users.rust-lang.org/t/multi-crate-cargo-repositories-best-practices/692/2?u=pyfisch So it stays simple to both distribute and develop hyper.\n. +1\nDoes a user may not want to set a User-Agent header? If so how should he disable the header?\n. looks good\n. Isn't this belonging to #373? I looked at modifiers and I like the idea to use them for the client. \n\nThat this features so prominently in the design of iron makes me think that this might be a bit much for hyper to do vs. a higher-level client abstraction; it's possible this kind of stuff just doesn't belong.\n\nWhat is the goal of hyper? I know hyper is currently more low level, but I think people will need an HTTP client like Pythons requests lib. Since we already provide a client we should be able to make this client powerful.\n. @Ryman I also think it should be SocketAddr. Since we always use both host and port, we can replace the ip, port pair with a socket address.\n. The benchmarks did fail before.\n. RFC2616 is obsolte.\nNew and better spec: https://tools.ietf.org/html/rfc7233#section-3.2\n. I will do this.\n. Travis CI calls it \"caching\". The documentation does not say anything about automatic deletion, but you can delete the cache manually.\n. Updated code.\n. @afck a valid commit message would be docs(mainpage): fix typo. See https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md for reference.\n. By the way, the documentation syntax will get better once rust-lang/rust#23812 gets fixed.\n. Thanks, fixed.\n. Rebased and build passes with openssl 0.5\n. Uses normal ssl again.\n. Also rebased.\n. I promised @alexcrichton to improve cookie-rs and make openssl an optional dependency, maybe I will make also CookieJar optional.\n. @jdm is right.\n. @Manishearth you contributed much code to CORS, are you okay with the changes?\n. No problem, here is the design in short form:\n- HeaderFormat gets removed, it is replaced with EncodeHeader, providing the encode_header() method returning a Vec<Vec<u8>>. Allowing multiple lines fixes #80. Using Vec<u8> allows us to encode non-ASCII headers, this is at least useful for Cookie, Set-Cookie, ETag, all other headers using entity tags and maybe some more.\n- Raw headers are also encoded as Vec<Vec<u8>>\n- An encode_headers() function is used to encode Headers for HTTP/1.x, for HTTP/2 a hpack should be used\n- All types representing headers stop implementing Display since they may contain non-ASCII data.\n. @seanmonstar would you prefer to merge the current code or should I implement the complete design first and land one huge PR?\n. Good summary.\nThere is a scenario two, where a website provides cookie values or entity tags containing non-ASCII data that should be send back to the website in another request.\nWe cannot simply pass &mut std::io::Write to an encode_headers function since we need to be able to serialize a header into multiple values at least for the Set-Cookie header and for better compression in HTTP/2. So we would need an iterator. The iterator would yield elements that have an encode() method taking &mut std::io::Write. I do not think that using iterators is any faster since you need also many allocations.\n. This is solved by #503 \n. Duplicate of #388\n. Forgot to update cargo. But how do old depencdencies change lifetime parameters inside hyper?\n:disappointed_relieved:\n. Yes we need to change Upgrade header field. (What means \"need\" we can also keep it but do not implement the RFC)\nThe RFC says:\nUpgrade          = 1#protocol\n     protocol         = protocol-name [\"/\" protocol-version]\n     protocol-name    = token\n     protocol-version = token\nWe do:\nUpgrade          = 1#protocol\n     protocol         = text\n. bug number 2 found.\n. Another bug found\n. This PR is complete now.\n. We can move (hopefully) all header tests into the new infrastructure. The macro just supports parsing and formatting, some headers have different tests, but we should be able to write them also inside the new test section. It should be also possible to add bench_header() to the section, but I am not sure if we need special bench testcases, I think we could just bench the normal test cases.\n. fixed nits\n. @seanmonstar Now you can merge. I wanted to update all headers.\n. +1\n(The test_header! macro is not required, you can also write your own tests inside the test section)\n. Sorry, I forgot to add BREAKING CHANGE warnings to the commits. The current behaviour is the intended behaviour.\nIt is impossible (I think so) to add optional parts to a macro without duplicating the definition, since every header should have tests this is no problem for the core of hyper. I think also external headers should have tests, they have been proven useful to discover bugs in header parsing and formatting inside hyper. Using the test_header! macro makes it really easy to test headers but it requires to be inside the header! macro. #489 will allow external code to use it in tests, but you can also write your own test functions inside the header! macro test section.\n. @seanmonstar yes this will probably work.\n. There is one problem: you can't have multiple headers with no tests in one module, because there will be multiple test_dummy modules.\n. Joining identifiers like function or module names does not work.\n. Updated pr, enum headers do not work as macro, so removed the code.\n. :+1: but you should not make deref! private.\n. I guess it will be complicated. We have to use apt-get to install some packages.\n. For what is the reason phrase needed in servo?\n. Updated.\n. @seanmonstar Yes I also doubt that kcov is working correctly. There are some files even missing in the report. But it reports what cases are not covered by the tests so I fix the reported cases.\n. Probably this should have a better name if it is exported.\n. Well, like all the specs are not as strongly typed as hyper is, so I think this difference is normal and hyper should provide the parsed URL. But is it a real problem, that the URL gets parsed and you compare two URLs and not two strings? Are there cases where this could be a real problem?\n. We could use Strings everywhere in hyper for URLs. At many places the spec uses relative URLs we can not parse with rust-url, so it is inconsistent but writing a custom URL parser is work and will make using hyper together with rust-url based projects harder.\n. @Velmont \\0 is not allowed in header values in general so I don't think it should be an allowed origin.\n. Ok, I will suse Error::Header but I think it is a bad thing to reuse a header code. Error::Header is already used by httpparse. The relativly precise Errors from the parser are merged into a few codes, I think this is bad because you loose useful information, but this is not the topic here.\n. Yes it could habve one. Any problems remaining?\n. openssl is optional for cookies: https://github.com/alexcrichton/cookie-rs/blob/595a9e095bef8d98691bd1eed135d9e540f279e0/Cargo.toml, so you should not kick out cookie support completly.\n. Sorry for the late comments, some are a bit nitpicky but they should help to archieve a higher conformance with the spec :wink: \n. +1\n. Looks good. I am in favor of Unregistered since ranges are registered, the name of the range unit is registered in a IANA registry and it must supply a description of the range. Ranges without public description are unregistered from my understanding.\n. Can we increase the \"Coverage Decrease Threshold for failure\" so that changes like this one do not fail?\n. Looks like AppVeyor failed to compile rustc-serialize.\n. I don't think many projects using hyper use language tags. So not that many people should be affected. I think it is ok to wait for some more breaking changes first.\n. Closed in favor of #669\n. @seanmonstar I actually broke it again (last time hopefully) so you could update in the mio branch also to the last version.\n. @lame-nickname is also working on this. Your implementation onlyb supports byte  values but it must support all types of ranges.\n. Maybe I should I extend my MediaType to also include the shortcut method present for Content-Type header to create simple media types?\n. It solves many problems mime has. While the mime crate only knows TopLevel and SubLevel, my crate splits the type into four parts: type, tree, subtype and suffix. This is closer to the relevant RFCs and allows things like \"check if this type is xml based\". The crate uses strings instead of incomplete enums because there are so many mime types and every selection of them is somewhat random and later extension is difficult. Both crates support parameters. The mime crate uses incomplete enums with very few variants for both keys and values. This means most parameters will use the extension variant and makes the enums no longer useful. The media-types crate uses a HashMap<String, String> for parameters. It provides methods to access some parameters like Charset as strong types. These methods can be extended in the future without harming compatibility.\nIt supports extended MIME types (https://github.com/hyperium/mime.rs/issues/22), wildcards work (https://github.com/hyperium/mime.rs/issues/28).\n. Some parts of the type could be enums, the rest has to many variants.\nCurrent:\n``` rust\n/// A Media Type commonly used to describe the contents of a resource.\n[derive(Clone, Debug, Default, Eq, PartialEq)]\npub struct MediaType {\n    /// The top-level type or None to match all types.\n    pub type_: Option,\n    /// A registration tree, None matches all trees.\n    pub tree: Option,\n    /// A subtype giving describing a concrete file format.\n    pub subtype: Option,\n    /// Some types use a suffix to refer to the base format like XML or JSON.\n    pub suffix: Option,\n    /// Media types can contain optional parameters for example for charsets or video codes.\n    pub parameters: HashMap\n}\n```\nProposal:\n``` rust\n/// A Media Type commonly used to describe the contents of a resource.\n[derive(Clone, Debug, Default, Eq, PartialEq)]\npub struct MediaType {\n    /// The top-level type or None to match all types.\n    pub type_: Option,\n    /// The subtype describes specific resource types.\n    pub subtype: Option,\n    /// Media types can contain optional parameters for example for charsets or video codes.\n    pub parameters: HashMap\n}\n/// A subtype, part of a media type.\npub struct Subtype {\n     /// A registration tree, the standards tree uses None.\n    pub tree: Tree,\n    /// A subtype giving describing a concrete file format.\n    pub subtype: String,\n    /// Some types use a suffix to refer to the base format like XML or JSON.\n    pub suffix: Option,\n}\n/// Provides the five discrete and the two composite top-level media types.\npub enum Type {\n    /// The \"text\" top-level type is intended for sending material that is\n    /// principally textual in form.\n    Text,\n    /// A top-level type of \"image\" indicates that the content specifies one\n    /// or more individual images.\n    Image,\n    /// A top-level type of \"audio\" indicates that the content contains audio data.\n    Audio,\n    /// A top-level type of \"video\" indicates that the content specifies a\n    /// time-varying-picture image, possibly with color and coordinated sound.\n    Video,\n    /// The \"application\" top-level type is to be used for discrete data that\n    /// do not fit under any of the other type names, and particularly for\n    /// data to be processed by some type of application program.\n    Application,\n    /// The \"multipart\" top-level type is to be used for data consisting of multiple\n    /// entities of independent data types.\n    Multipart,\n    /// A body of media type \"message\" is itself all or a portion of some\n    /// kind of message object.\n    Message,\n    // TODO: Maybe include model type and example type?\n    /// Less common top-level types.\n    Unregistered(String),\n}\n/// Provides the four registration trees.\npub enum Tree {\n    /// The standards tree is intended for types of general interest to the Internet community.\n    Standards,\n    /// The vendor tree is used for media types associated with publicly available products.\n    Vendor,\n    /// Registrations for media types created experimentally or as part of\n    /// products that are not distributed commercially may be registered in\n    /// the personal or vanity tree.\n    Personal,\n    /// Subtype names with \"x.\" as the first facet may be used for types intended exclusively for\n    /// use in private, local environments.\n    Private,\n    /// Other unofficial trees.\n    Unregistered(String),\n}\n```\nExamples:\n| string | typed |\n| --- | --- |\n| */* | MediaType { type_: None, subtype: None, parameters: HashMap::new() } |\n| image/png | MediaType { type_: Some(Image), subtype: Some(Subtype { tree: Standards, subtype: Some(\"png\".to_owned()), suffix: None }), parameters: HashMap::new() } |\nOf course I will add helper methods for easier creation of MediaTypes.\n. I have written a parser for comma-delimited headers that should catch all cases like multiline headers, too much whitespace and superfluos commas.\nhttps://github.com/pyfisch/kinglet/blob/master/src/headers.rs#L54-L100\n. You have forgotten to include the actual file containing the header.\n. Obviously this was considered to be a bugfix because nowhere hyper said that it didn't check the host. \n. I propose to create a subfolder called shared where all code can go that is used by more than one header.\nMoving the header definitions into a subfolder is imho a bad idea because it spreads the header files in the tree.\n. You used QualityItem instead of QualityValue in your comment, and I think it is a better name since the RFC uses \"quality-value\" only for the q= parameter. I will change it.\nI see your point, but introducing a new trait does not seems to fit for me. We will have to implement it for everything that may be used as a quality value if we want to provide a consistent API. Since this may be anything for custom headers like an integer, but creating traits for primitive types is poor style according to the Rust guide, and I agree.\nCurrently we would need to support IntoQualityItem trait for Mime and Encoding, in the future we will need it also for the Accept-Language header, the Accept-Charset and maybe other headers I do not yet know.\nAdding a function like qitem<T: ToString>(T) -> QualityItem<T>;, fits better I think. Maybe also adding QualityItem::new(item, quality) helps?\n. Yep. q= must be the last attribute, as stated by the spec. By the way Q can be removed from mime.rs, it is no MIME attribute.\nTwo tests I will add tomorrow:\n``` rust\n[test]\nfn test_parse_header_no_quality() {\n    let a: Accept = header::Header::parse_header([b\"text/plain; charset=utf-8\".to_vec()].as_slice()).unwrap();\n    let b = Accept(vec![\n        shared::QualityValue{value: mime::Mime(mime::TopLevel::Text, mime::SubLevel::Plain, vec![(mime::Attr::Charset, mime::Value::Utf8)]), quality: 1f32},\n    ]);\n    assert_eq!(a, b);\n}\n[test]\nfn test_parse_header_with_quality() {\n    let a: Accept = header::Header::parse_header([b\"text/plain; charset=utf-8; q=0.5\".to_vec()].as_slice()).unwrap();\n    let b = Accept(vec![\n        shared::QualityValue{value: mime::Mime(mime::TopLevel::Text, mime::SubLevel::Plain, vec![(mime::Attr::Charset, mime::Value::Utf8)]), quality: 0.5f32},\n    ]);\n    assert_eq!(a, b);\n}\n``\n. Hyper has many variants to do the common task of \"how to get the inner value of the header struct for formatting\"\n-self[](used byAccept-EncodingandAccept, requiresderef!)\n-let tm = **self;(used byDate, does not requirederef!)\n-self.0(used byAuthorization`)\nI personally prefer the first form self[] but also self.0 is good. We just should make sure we use the same everywhere in the code.\nTry it out: http://is.gd/ZkmjYV\n. Probably it should be there.\nBut I do not exactly know what the deref! is doing and for what we need it.\n. Actually it would be a good idea if header parsers could access the request to know the base URL. Like that the relative URL could be resolved immediately and we could use url::Url\n. Currently I do not think so. Maybe in the future?\n. Ok, bug in code. I want to preserve the upper/lowercase of the value, but the matching should be case insensitive. You will see it in the fixed code.\n. thx\n. You are right .clone() can be simply removed. It was needed for an older version that did not convert the string to lowercase.\n. Looks more like a problem with Hyper (only accepting Vec>) than your fault. I think it can stay like that until we rewrite hyper. :grin: \n. StatusCode253 was the old formatting, I think. But I will change it.\n. Remove.\n. I will readd them.\n. I just found this out when I entered really crazy StatusCodes to Chrome and Firefox. Sometimes they showed 200. If you want more information I can redo the tests.\n. Here: \n\nOnly Chromium understands 2147483647, firefox thinks it is 200\n0 makes problems (Not displayed or understood as 200)\n. This is probably true.\n\nIf we split hyper consequently there will be no \"hyper\" crate only \"hyperclient\" and \"hyperserver\". I have no idea what the current crate will be useful for.\n. Good point. ~~I will use Into<String>.~~ It looks like  Into<String> won't work yet, so I use String.\n. I guess the same here?\n. Looks like git tricked me here, I did not want to commit this :disappointed: \n. Generating it automatically is not possible with macros currently. But it should be basically a copy & paste job: copy the values from the tests to the docs. Or do you want a program example? (We could create samples for classes of headers)\n. No.\n. This was fixed in time crate: https://github.com/rust-lang/time/blob/fba17ed10a4774bb4666c79d58f7cec3ee858865/src/lib.rs#L770\n. Fixed in another commit. It should always be a None for single value headers, so I added it to from_one_raw_str(). List headers already check for empty values in a similiar way. This variant is now obsolete.\n. That's true, if let is not needed anyway here.\n. I think so. The RFC does not say that they are case-insensitive. WebSocket spec says, that websocket must be matched case-insensitive.\n. My mistake at merging.\n. Header is already taken and used when header blocks fail to parse. I rename it to Value.\n. * imports are evil, so do not change the normal import.\nEDIT: In this special case they can stay.\n. You cannot use the macro here.\n. You should probably use splitn(2) here. Imagine a malformed RangeSpec like 200-300-foobar. It would pass as valid.\n. You could check if start < end, so application code does not have to. \n. Really HTTP/1.0? RFC 1945 does not mention it.\n. And could you please adjust the doccomment format like in the Accept header.\n. This solves the same problem as https://github.com/hyperium/hyper/blob/b2eb4e5171d92d07f1ccc6b84396671f492c5445/src/header/parsing.rs#L48 (but without whitespace between the values). The algorithm should probably be the same. Most other code uses f for the formatter parameter. You can use Display::fmt(range, f) instead of write!(fmt, \"{}\", range).\n. There can be optional whitespace between the values and empty values like bytes=100-200, , , 300-400, -900.\nThe ABNF is:\nbyte-ranges-specifier = bytes-unit \"=\" byte-range-set\n     byte-range-set  = 1#( byte-range-spec / suffix-byte-range-spec )\n     byte-range-spec = first-byte-pos \"-\" [ last-byte-pos ]\n     first-byte-pos  = 1*DIGIT\n     last-byte-pos   = 1*DIGIT\nThe definition for 1# is given in https://tools.ietf.org/html/rfc7230#section-7 optional whitespce is allowed but not required. You can probably use from_one_comma_delimited() here.\n. Yes I mean the text, Accept just uses #[doc] to work around compiler bugs.\n.  Nice docs\n. f instead of fmt\n. This should use an Hyper Error as return type.\n. Also use an Error here\n. fixed.\n. ",
    "winding-lines": "@seanmonstar sounds good. I have been looking a bit at adding proxy to client but it would be useful to know more of the code first :+1: \n. Hello everybody, I have been working on the proxy implementation for a while (on and off) but I missed this conversation :-) I will evolve my PR based on this feedback.\n. Thanks Sean! Which other traits would work for Client? Do Copy/Send/Sync make sense?\n. Thanks, do you want to close this issue then?\n. @seanmonstar  I am done with adding tests in status.rs. I see that you use helper macros in other files, a simple function seems to do the trick here. Let me know if you want me to change/cleanup the code. \n. Yeah, I did a git pull from upstream master and something unexpected happened :-) I did a rebase, let me know if the code/history are in the desired state now.\n. @seanmonstar, I am done with mychanges once c1a8e3b gets built. We may have some overlap between tests and bench_header!(), but I think that's ok since they have different goals. Let me know if you have any feedback. \n. hm, this PR is not very successful in increasing coverage, I may just drop it.\n. Great :)\nMarius\n\nOn May 28, 2015, at 10:39 AM, Sean McArthur notifications@github.com wrote:\nI'll merge this, since it also tests the cause() part, which is a good idea. If there was a way to pass to kcov to ignore all fns inside a #[cfg(test)] mod, that would greatly help reduce inflated \"lines missed\" values.\n\u2014\nReply to this email directly or view it on GitHub.\n. @seanmonstar let me know if you have feedback here. This pushes the coverage above 90% :+1: \n. @seanmonstar good call, the tests are failing in rust-openssl.\n\n``\n cargo test\n    Updating registryhttps://github.com/rust-lang/crates.io-index`\n Downloading byteorder v0.3.10\n Downloading connected_socket v0.0.6\n Downloading bitflags v0.2.1\n   Compiling byteorder v0.3.10\n   Compiling rustc-serialize v0.3.15\n   Compiling gcc v0.3.8\n   Compiling libc v0.1.8\n   Compiling pkg-config v0.3.5\n   Compiling bitflags v0.2.1\n   Compiling lazy_static v0.1.11\n   Compiling time v0.1.26\n   Compiling openssl-sys v0.6.2 (file:///Users/user/oss/hyperium/rust-openssl/openssl)\n   Compiling openssl v0.6.2 (file:///Users/user/oss/hyperium/rust-openssl/openssl)\n   Compiling connected_socket v0.0.6\n     Running target/debug/openssl-b3a0b1bcbf1488a6\nrunning 61 tests\ntest bn::tests::test_to_from_slice ... ok\ntest bn::tests::test_negation ... ok\ntest crypto::hash::tests::test_clone ... ok\ntest crypto::hash::tests::test_finish_twice ... ok\ntest crypto::hash::tests::test_md5_recycle ... ok\ntest crypto::hash::tests::test_md5 ... ok\ntest crypto::hash::tests::test_sha1 ... ok\ntest crypto::hash::tests::test_ripemd160 ... ok\ntest crypto::hash::tests::test_sha256 ... ok\ntest crypto::hmac::tests::test_clone ... ok\ntest crypto::hmac::tests::test_finish_twice ... ok\ntest crypto::hmac::tests::test_hmac_md5 ... ok\ntest crypto::hmac::tests::test_hmac_md5_recycle ... ok\ntest crypto::hmac::tests::test_hmac_sha1 ... ok\ntest crypto::hmac::tests::test_hmac_sha1_recycle ... ok\ntest crypto::hmac::tests::test_hmac_sha224 ... ok\ntest crypto::hmac::tests::test_hmac_sha256 ... ok\ntest crypto::memcmp::tests::test_diff_lens ... ok\ntest crypto::memcmp::tests::test_eq ... ok\ntest crypto::hmac::tests::test_hmac_sha384 ... ok\ntest crypto::hmac::tests::test_hmac_sha512 ... ok\ntest crypto::pkey::tests::test_encrypt ... ok\ntest crypto::pkey::tests::test_encrypt_pkcs ... ok\ntest crypto::pkey::tests::test_gen_priv ... ok\ntest bn::tests::test_prime_numbers ... ok\ntest crypto::pkey::tests::test_private_key_from_pem ... ok\ntest crypto::pkey::tests::test_eq ... ok\ntest crypto::pkey::tests::test_gen_pub ... ok\ntest crypto::rand::tests::test_rand_bytes ... ok\ntest crypto::symm::tests::test_aes_256_cbc_decrypt ... ok\ntest crypto::symm::tests::test_aes_256_ecb ... ok\ntest crypto::symm::tests::test_rc4 ... ok\ntest ssl::error::test_uknown_error_should_have_correct_messages ... ok\ntest ssl::tests::clear_ctx_options::sslv23 ... FAILED\ntest ssl::tests::get_ctx_options::sslv23 ... FAILED\ntest ssl::tests::get_peer_certificate::sslv23 ... FAILED\ntest ssl::tests::new_ctx::sslv23 ... FAILED\ntest ssl::tests::new_sslstream::sslv23 ... FAILED\ntest ssl::tests::set_ctx_options::sslv23 ... FAILED\ntest ssl::tests::test_pending ... FAILED\ntest ssl::tests::test_read ... FAILED\ntest crypto::pkey::tests::test_sign_hashes ... ok\ntest ssl::tests::test_write ... FAILED\ntest ssl::tests::test_set_certificate_and_private_key ... ok\ntest ssl::tests::verify_callback_data::sslv23 ... FAILED\ntest ssl::tests::verify_callback_load_certs::sslv23 ... FAILED\ntest ssl::tests::verify_trusted::sslv23 ... FAILED\ntest ssl::tests::verify_trusted_callback_override_bad::sslv23 ... FAILED\ntest ssl::tests::verify_trusted_callback_override_ok::sslv23 ... FAILED\ntest ssl::tests::verify_trusted_get_error_err::sslv23 ... FAILED\ntest ssl::tests::verify_trusted_get_error_ok::sslv23 ... FAILED\ntest ssl::tests::verify_untrusted::sslv23 ... FAILED\ntest ssl::tests::verify_untrusted_callback_override_bad::sslv23 ... FAILED\ntest ssl::tests::verify_untrusted_callback_override_ok::sslv23 ... FAILED\ntest x509::test_negative_serial ... ok\ntest ssl::tests::test_write_hits_stream ... ok\ntest x509::tests::test_cert_loading ... ok\ntest x509::tests::test_subject_read_cn ... ok\ntest crypto::pkey::tests::test_sign ... ok\ntest x509::tests::test_cert_gen ... ok\ntest crypto::pkcs5::tests::test_pbkdf2_hmac_sha1 ... ok\nfailures:\n---- ssl::tests::clear_ctx_options::sslv23 stdout ----\n    thread 'ssl::tests::clear_ctx_options::sslv23' panicked at 'called Result::unwrap() on an Err value: Error { repr: Os(61) }', /Users/rustbuild/src/rust-buildbot/slave/stable-dist-rustc-mac/build/src/libcore/result.rs:729\n---- ssl::tests::get_ctx_options::sslv23 stdout ----\n    thread 'ssl::tests::get_ctx_options::sslv23' panicked at 'called Result::unwrap() on an Err value: Error { repr: Os(61) }', /Users/rustbuild/src/rust-buildbot/slave/stable-dist-rustc-mac/build/src/libcore/result.rs:729\n---- ssl::tests::get_peer_certificate::sslv23 stdout ----\n    thread 'ssl::tests::get_peer_certificate::sslv23' panicked at 'called Result::unwrap() on an Err value: Error { repr: Os(61) }', /Users/rustbuild/src/rust-buildbot/slave/stable-dist-rustc-mac/build/src/libcore/result.rs:729\n---- ssl::tests::new_ctx::sslv23 stdout ----\n    thread 'ssl::tests::new_ctx::sslv23' panicked at 'called Result::unwrap() on an Err value: Error { repr: Os(61) }', /Users/rustbuild/src/rust-buildbot/slave/stable-dist-rustc-mac/build/src/libcore/result.rs:729\n---- ssl::tests::new_sslstream::sslv23 stdout ----\n    thread 'ssl::tests::new_sslstream::sslv23' panicked at 'called Result::unwrap() on an Err value: Error { repr: Os(61) }', /Users/rustbuild/src/rust-buildbot/slave/stable-dist-rustc-mac/build/src/libcore/result.rs:729\n---- ssl::tests::set_ctx_options::sslv23 stdout ----\n    thread 'ssl::tests::set_ctx_options::sslv23' panicked at 'called Result::unwrap() on an Err value: Error { repr: Os(61) }', /Users/rustbuild/src/rust-buildbot/slave/stable-dist-rustc-mac/build/src/libcore/result.rs:729\n---- ssl::tests::test_pending stdout ----\n    thread 'ssl::tests::test_pending' panicked at 'called Result::unwrap() on an Err value: Error { repr: Os(61) }', /Users/rustbuild/src/rust-buildbot/slave/stable-dist-rustc-mac/build/src/libcore/result.rs:729\n---- ssl::tests::test_read stdout ----\n    thread 'ssl::tests::test_read' panicked at 'called Result::unwrap() on an Err value: Error { repr: Os(61) }', /Users/rustbuild/src/rust-buildbot/slave/stable-dist-rustc-mac/build/src/libcore/result.rs:729\n---- ssl::tests::test_write stdout ----\n    thread 'ssl::tests::test_write' panicked at 'called Result::unwrap() on an Err value: Error { repr: Os(61) }', /Users/rustbuild/src/rust-buildbot/slave/stable-dist-rustc-mac/build/src/libcore/result.rs:729\n---- ssl::tests::verify_callback_data::sslv23 stdout ----\n    thread 'ssl::tests::verify_callback_data::sslv23' panicked at 'called Result::unwrap() on an Err value: Error { repr: Os(61) }', /Users/rustbuild/src/rust-buildbot/slave/stable-dist-rustc-mac/build/src/libcore/result.rs:729\n---- ssl::tests::verify_callback_load_certs::sslv23 stdout ----\n    thread 'ssl::tests::verify_callback_load_certs::sslv23' panicked at 'called Result::unwrap() on an Err value: Error { repr: Os(61) }', /Users/rustbuild/src/rust-buildbot/slave/stable-dist-rustc-mac/build/src/libcore/result.rs:729\n---- ssl::tests::verify_trusted::sslv23 stdout ----\n    thread 'ssl::tests::verify_trusted::sslv23' panicked at 'called Result::unwrap() on an Err value: Error { repr: Os(61) }', /Users/rustbuild/src/rust-buildbot/slave/stable-dist-rustc-mac/build/src/libcore/result.rs:729\n---- ssl::tests::verify_trusted_callback_override_bad::sslv23 stdout ----\n    thread 'ssl::tests::verify_trusted_callback_override_bad::sslv23' panicked at 'called Result::unwrap() on an Err value: Error { repr: Os(61) }', /Users/rustbuild/src/rust-buildbot/slave/stable-dist-rustc-mac/build/src/libcore/result.rs:729\n---- ssl::tests::verify_trusted_callback_override_ok::sslv23 stdout ----\n    thread 'ssl::tests::verify_trusted_callback_override_ok::sslv23' panicked at 'called Result::unwrap() on an Err value: Error { repr: Os(61) }', /Users/rustbuild/src/rust-buildbot/slave/stable-dist-rustc-mac/build/src/libcore/result.rs:729\n---- ssl::tests::verify_trusted_get_error_err::sslv23 stdout ----\n    thread 'ssl::tests::verify_trusted_get_error_err::sslv23' panicked at 'called Result::unwrap() on an Err value: Error { repr: Os(61) }', /Users/rustbuild/src/rust-buildbot/slave/stable-dist-rustc-mac/build/src/libcore/result.rs:729\n---- ssl::tests::verify_trusted_get_error_ok::sslv23 stdout ----\n    thread 'ssl::tests::verify_trusted_get_error_ok::sslv23' panicked at 'called Result::unwrap() on an Err value: Error { repr: Os(61) }', /Users/rustbuild/src/rust-buildbot/slave/stable-dist-rustc-mac/build/src/libcore/result.rs:729\n---- ssl::tests::verify_untrusted::sslv23 stdout ----\n    thread 'ssl::tests::verify_untrusted::sslv23' panicked at 'called Result::unwrap() on an Err value: Error { repr: Os(61) }', /Users/rustbuild/src/rust-buildbot/slave/stable-dist-rustc-mac/build/src/libcore/result.rs:729\n---- ssl::tests::verify_untrusted_callback_override_bad::sslv23 stdout ----\n    thread 'ssl::tests::verify_untrusted_callback_override_bad::sslv23' panicked at 'called Result::unwrap() on an Err value: Error { repr: Os(61) }', /Users/rustbuild/src/rust-buildbot/slave/stable-dist-rustc-mac/build/src/libcore/result.rs:729\n---- ssl::tests::verify_untrusted_callback_override_ok::sslv23 stdout ----\n    thread 'ssl::tests::verify_untrusted_callback_override_ok::sslv23' panicked at 'called Result::unwrap() on an Err value: Error { repr: Os(61) }', /Users/rustbuild/src/rust-buildbot/slave/stable-dist-rustc-mac/build/src/libcore/result.rs:729\nfailures:\n    ssl::tests::clear_ctx_options::sslv23\n    ssl::tests::get_ctx_options::sslv23\n    ssl::tests::get_peer_certificate::sslv23\n    ssl::tests::new_ctx::sslv23\n    ssl::tests::new_sslstream::sslv23\n    ssl::tests::set_ctx_options::sslv23\n    ssl::tests::test_pending\n    ssl::tests::test_read\n    ssl::tests::test_write\n    ssl::tests::verify_callback_data::sslv23\n    ssl::tests::verify_callback_load_certs::sslv23\n    ssl::tests::verify_trusted::sslv23\n    ssl::tests::verify_trusted_callback_override_bad::sslv23\n    ssl::tests::verify_trusted_callback_override_ok::sslv23\n    ssl::tests::verify_trusted_get_error_err::sslv23\n    ssl::tests::verify_trusted_get_error_ok::sslv23\n    ssl::tests::verify_untrusted::sslv23\n    ssl::tests::verify_untrusted_callback_override_bad::sslv23\n    ssl::tests::verify_untrusted_callback_override_ok::sslv23\ntest result: FAILED. 42 passed; 19 failed; 0 ignored; 0 measured\nthread '' panicked at 'Some tests failed', /Users/rustbuild/src/rust-buildbot/slave/stable-dist-rustc-mac/build/src/libtest/lib.rs:259\n```\n. @sfackler thanks for the pointers! The hyper library is intended to be used by other people, so I don't feel that just installing a different openssl library on my computer is sufficient.\nIt's unclear to me how to use features, I tried the following but I get the same error.\n[dependencies.openssl]\nversion = \"0.6\"\nfeatures = [\"tlsv1_1\"]\nIt feels to me that the best approach would be to detect which library is available and then enable one feature or the other. \nDo you know of any client of your library doing something similar.\n. Sounds good, I can always brew a newer ssl library in the mean time.\nOn Thu, Jun 18, 2015 at 9:44 PM, Sean McArthur notifications@github.com\nwrote:\n\nI've actually been working a bunch on a patch that changes up the design\nof Ssl usage, to facilitate using different ssl libraries, and disabling\nssl altogether. I hope to have that finished tomorrow.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/575#issuecomment-113367067.\n. Good morning Hyper community,\n\nI've rebased my client proxy changes on master and made all the tests pass. I need to write some tests but I would like to get some advice first on the architecture. I tried a couple of alternatives like removing the concept of the Route or not have it closely tied to the HttpStream. The challenge is that the proxying is a pretty low level concept so any change tends to propagate through the codebase.\nWhere would you like me to take next? We have a stable commit right now and we can compare with other approaches.\n. @shaleh thanks for the feedback. I will add authentication and fix the https crash. I also need to add tests, I will do that after I refactor the internals based on other feedback.\nI do not know how frequent it is for people to have multiple proxies. If we assume that most people have one proxy for all requests then the current API is the simplest. For your use case you can create 3 Hyper clients in the three configurations that you describe:\n- without proxy\n- http proxy\n- https proxy\nThis keeps the library simple and allows flexibility in the consuming application, with the downside that there is more code in the application.\nLet me know what you think.\n. Got it, I have been working on multiple proxies but I have only 6-8\nhrs/week available myself. I will put out what ever code I have ready at\nthe end of this weekend.\nOn Fri, Oct 16, 2015 at 1:25 PM, Sean Perry notifications@github.com\nwrote:\n\nThe point of a library is to make the application author's life easier\nAND to have one place to put redundant code.\nAlmost every user of the hyper crate will need to implement proxy support\nat some point. The crate should make it easy for the application author to\nget it right. Ideally this means stuffing as much proxy knowledge into the\ncrate as possible.\nI'd like to see a baked in way to create a hyper based Client that read\nits settings from the environment. A similar bit of code that took a list\nof proxies instead of reading the environment would be another useful\ninterface for those that want the proxy to come from their own configs.\nSorry, I would have written code instead of asking but I have been busy on\nother projects.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/639#issuecomment-148824686.\n. Yeah, I have been trying to be less invasive. I think that some internal\nrefactoring is needed and it may be outside my current understanding of the\ncode. Let me try this weekend and see where I end up, you are certainly\nwelcome to take over as soon as you have the cycles :-)\n\nOn Sat, Oct 17, 2015 at 10:59 AM, Sean McArthur notifications@github.com\nwrote:\n\nI think the task of getting the proxy settings should be outside of\nhyper. The configuration could come from anywhere (environment variables,\ncommand line arguments, config files, hard coded, etc). Instead, hyper\nshould accept the parameters in the Proxy constructor.\nFor instance:\nclient.set_proxy(Proxy::Http {\n    host: env::var(\"HTTP_PROXY_HOST\").unwrap(),\n    port: env::var(\"HTTP_PROXY_PORT\").unwrap(),\n})\n\nAlso, it is possible to build a Proxy entirely outside of this crate,\nand use a hyper Client internally. That's why I've mentioned trying not to\nadjust too much of the internal http protocol modules. The Client (and\nRequest) just need to be able to use all the parts of RFC7230, such as the\nCONNECT method and alternate RequestUri formats. I'd rather if the logic to\nuse those was contained in the Proxy type.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/639#issuecomment-148938187.\n. @seanmonstar I got rid of the Route and instead added a request_uri in Request (and RequestHead) as you had suggested on the initial PR. I've added a list of proxies each with their own proxy policies. All of this is only in place for the Http 1.1 code.\n\nFor the SSL NetworkConnector there is still one architecture issue because all the SSL types are defined only in the h2.rs file. So the NetworkConnector's connect still defers back to the Proxy, and this code is not ported to use the new list of proxies as per the desired APIs.\nWhere do you want me to take this code next?\n. @seanmonstar, thanks for your feedback I've addressed some of it. \nI love your suggestion to have an implementation of NetworkConnector for Proxy, not yet implemented. What needs to happen is the following:\n1. the Proxy implementation will connect to the proxied port\n2. the socket must be passed down to the Http11 or SSL NetworkConnectors\nWith the current API this is not possible. This is the reason why the proxy is passed down.\nNote that the Pool NetworkConnector has a different use case, the lower level NetworkConnectors are allowed to open their own sockets.\nPlease feel free to take over this PR and play with some approaches :)\n. ",
    "jdm": "I think we want the ability to measure all of the applicable properties in https://dvcs.w3.org/hg/webperf/raw-file/tip/specs/NavigationTiming/Overview.html .\n. Yep!\n. Sounds like we're set here :)\n. Hooray, this will make rebasing https://github.com/servo/servo/pull/4117 easier :D\n. If-Match and If-None-Match.\n. removeRequestHeader is unspecc'd, so I don't expect Servo to make use of this.\n. I suppose we could print the address ourselves, but it seems like an easy papercut to avoid at the library level. Maybe libstd is the right place, however.\n. Servo would be super interested in hyper + mio to reduce the thread bloat :)\n. As far as I can tell all we use is the Cookie struct and Cookie::parse. Kind of sucks to duplicate that between hyper and cookie-rs, though. Maybe there could be a cookiejar crate that extracts the higher-level stuff and leaves cookie-rs with the parsing, test cases, and data definition.\n. Items without a quality value default to 1.0 in implementation terms, AFAIK.\n. It actually looks like hyper doesn't even yield the first chunk. I wonder if Firefox deals with the test output differently?\n. Oh, this sounds like it could be much more useful than https://github.com/servo/servo/blob/master/components/net/http_loader.rs#L140 !\n. It's also possible to do struct HashableStatusCode(StatusCode) and implement Hash on that.\n. 2616 has been superseded. See http://tools.ietf.org/html/rfc7231#section-4.3.2 for the relevant MUST NOT.\n. Would there be any loss of expressivity if the return value is ignored? If not, I'm in favour.\n. Does wireshark show this happening in Firefox?\n. Ah, see step 12.5 of https://fetch.spec.whatwg.org/#http-network-or-cache-fetch. Looks like this belongs in Servo.\n. \ud83d\udc83 \n. Servo will need these, so we're in favour of them being available in hyper proper. \n. I don't really have any opinion on whether to embed md5 or not.\n. Makes sense!\n. Using an enum that contains a Nonstandard(String) variant would make sense here.\n. I'm fine with pretending that unrecognized header values don't exist.\n. Servo ended up writing this by hand after https://github.com/hyperium/hyper/pull/727 was closed.\n. This isn't quite right - this still only looks at the very last comma-separated values and ignores the others. We want to return the rightmost value that is successfully recognized - this implies that we either need to iterate left to right and track the most recent successful parse, or iterate right to left and return the first value that is successful.\n. This looks good to me!\n. If valgrind reported it, presumably it means that the memory was not explicitly freed before the program exited.. The origin header.. Note - there are a ton of search results for \"multiple access-control-allow-origin\" that imply that servers that return multiple values are incorrect. The solution here may not be to change the header definition.. We should reference http://tools.ietf.org/html/rfc6454#section-7 instead and ensure that this header implements that specification.\n. Sorry, wrote this before seeing the existing conversation.\n. Another trick is to add _ to the names of otherwise-unused variables, which suppresses the warning.. ",
    "znewman01": "For reference, my simple benchmark of time::precise_time_ns gives an average of 24ns per invocation:\n```\nextern crate test;\nextern crate time;\nuse test::Bencher;\n[bench]\nfn bench_precise_time_ns(b: &mut Bencher) {\n    b.iter(|| time::precise_time_ns());\n}\n```\nOn my computer, the Hyper benchmark is 137,963ns, \u00b163387ns. So you'd have to check the clock 50 times to see a 1% increase. Is that acceptably low enough to do on each invocation (there are 21 timings listed in the W3C document, but several of them seem to be irrelevant (e.g. the DOM-related timings))?\nOf course, it makes sense to answer this question by taking real benchmarks of the timing code in Hyper, but that was slightly more work :smiley:\n. I'm interested because I'd like to implement HTTP archive output for Servo, which depends to an extent on being able to pull this information out of Hyper.\nIf nobody works on this issue before I finish up the other parts of that task, I'd be interested on taking it on. But in the meantime, anyone else should feel free to claim it.\n. Similar benchmarks show time::now_utc() at around 75ns.\nPerhaps it's the actual formatting step that's taking longer. That part would pretty easy to do only as-demanded.\n. I found one you missed: https://github.com/hyperium/hyper/blob/master/src/header/mod.rs#L576 :smiley: \n. ",
    "EliSnow": "I would love to use hyper for HTTP load testing and would want these metrics as part of the results\n. I believe the Tokio Trace proposal is relevant here.. I would be perfectly fine with just having the option of enabling it. Does that mean hyper_tls would have to add an option for reuse_address to apply to https connections?. ",
    "bfrog": "Closures or a Trait impl, a Trait impl might be nicer if your doing something like sending off the metrics gathered to another metrics recorder service\n. +1 for the async handler Trait\n. I would assume there would be some number of threads with event loops handling http requests rather than one thread with one event loop?\n. If hyper can add that feature I'd basically consider it usable for myself in production, otherwise it would probably cause a great deal of thread context switching for my use case (lots and lots and lots of short lived connections)\n. I see an error when compiling the latest mio branch with rustc 1.3\n``\n~/s/hyper git:mio \u276f\u276f\u276f git rev-parse HEAD\nc60cc831269d023b77f0013e6c919dbfefaf031d\n~/s/hyper git:mio \u276f\u276f\u276f cargo build\n   Compiling hyper v0.7.0-mio (file:///home/tburdick/src/hyper)\nsrc/http/conn.rs:6:21: 6:23 error: expected,, foundassrc/http/conn.rs:6 use http::h1::{self as http, Incoming, TryParse};\n                                       ^~\nCould not compilehyper`.\nTo learn more, run the command again with --verbose.\n~/s/hyper git:mio \u276f\u276f\u276f\n```\n. @seanmonstar the common usage of a state machine framework like rotor is a nice touch\nExcited for the day I can put this to work!\n:beers: \n. I've noticed that the latency, and variation of latency with the mio branch is much higher and seems to have a larger spread than whats currently on master. I ran cargo --release --example server in each branch then ran wrk against it.\nMio\nRunning 30s test @ http://127.0.0.1:1337/\n  10 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    22.23ms   34.30ms   1.03s    99.67%\n    Req/Sec     4.76k   693.41     8.08k    88.07%\n  1421686 requests in 30.06s, 122.02MB read\nRequests/sec:  47290.16\nTransfer/sec:      4.06MB\nwrk -c 1000 -t 10 -d 30s \"http://127.0.0.1:1337/\"  2.80s user 11.56s system 47% cpu 30.111 total\nMaster\nRunning 30s test @ http://127.0.0.1:1337/\n  10 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    54.80us   93.95us  22.16ms   98.91%\n    Req/Sec    84.24k    15.81k   97.11k    78.33%\n  2512893 requests in 30.07s, 215.68MB read\nRequests/sec:  83560.27\nTransfer/sec:      7.17MB\nwrk -c 1000 -t 10 -d 30s \"http://127.0.0.1:1337/\"  5.07s user 22.54s system 91% cpu 30.122 total\nCan anyone else confirm this? Is this a known issue?\n. Doable though hyper hides rotor at the moment.\nOn Jul 4, 2016 3:01 PM, \"Michael Coyne\" notifications@github.com wrote:\n\nWhat about using rotor's event loop directly and expanding a Handler type\nto support some sort of on_publish event? Perhaps one could compose two\nstate machines together via rotor_compose!?\nThe first would be a hyper handler and the second would be a custom state\nmachine for publishing events between different connections and clients.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/719#issuecomment-230348194, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe/AAISnxhTb9duDiwu09B736VTbj3p_mKzks5qSWaxgaJpZM4HB6EZ\n.\n. @daogangtang what I've done for this is create a worker pool and distribute requests randomly using std::sync::mpsc to communicate between hyper and my worker. The hyper http handler can then use Next::wait(). I get ~50K single query req/s this way which is pretty good I think\n. Here's some stuff from my project, a bit anonymized to give you some ideas perhaps\n\nrust\nfn serve_http(config : &Config) {\n    info!(\"http://127.0.0.1:3000\");\n    let addr = \"127.0.0.1:3000\".parse().unwrap();\n    let listener = HttpListener::bind(&addr).unwrap();\n    let worker_pool = WorkerPool::new(config).unwrap(); // creates a Vec<Sender<T>>\n    let guards: Vec<_> = (0..4).map(move |i: u32|  {\n        let routercfg = RouterConfig{\n            default_scheme: String::from(\"http\"),\n            default_host: String::from(\"127.0.0.1\"),\n            default_port: Some(3000) \n        };\n        let listener = listener.try_clone().unwrap();\n        let worker_pool = worker_pool.clone();\n        thread::spawn(move || {\n            let server = Server::new(listener);\n            server.handle(move |ctrl| Router::new(routercfg.clone(), ctrl, worker_pool.clone()));\n        })\n    }).collect();\n    for guard in guards {\n        guard.join();\n    }\n}\nThe WorkerPool::new function looks like...\n``` rust\nimpl WorkerPool {\n    pub fn new(cfg: &Config) -> Result {\n        let workers = (0..cfg.workers).map(|n| {\n            let redis = redis_client(&cfg.redis[..]).unwrap();\n            let pg = pg_client(&cfg.pg[..]).unwrap();\n            let mut worker = Worker::new(redis, pg);\n            let (tx, rx) = channel();\n            let _handle = thread::Builder::new()\n                .name(format!(\"my-worker {}\", n).to_owned())\n                .spawn(move || {\n                    worker_loop(rx, &mut worker);\n                });\n            WorkerHandle{\n                tx: tx,\n            }\n        }).collect();\n        Ok(WorkerPool {\n            workers: workers,\n        })\n    }\npub fn some_request(&self, somereq: SomeRequest) -> Receiver<SomeResponse> {\n    let worker = self.select_worker(req.id); // select a worker randomly or however\n    let (tx, rx) = channel();\n    worker.send(Request::SomeRequest(req, tx, ctrl)); //enum of all request types\n    rx \n}\n\n}\n```\nThe hyper server Handler looks like...\n``` rust\npub struct MyHandler {\n    url: Url,\n    ctrl: Control,\n    pool: Rc,\n    rx: Option>,\n    out_buffer: Vec,\n    out_pos: usize,\n}\nimpl MyHandler {\n    pub fn new(ctrl: Control, pool: Rc, url: Url) -> MyHandler {\n        MyHandler {\n            url: url,\n            ctrl: ctrl,\n            pool: pool,\n            rx: None,\n            out_buffer: Vec::with_capacity(4096),\n            out_pos: 0,\n        }\n    }\n}\nimpl Handler for MyHandler {\n    fn on_request(&mut self, req: Request) -> Next {\n        let req = MyRequest {\n            id: random_id(),\n        };\n        self.rx = Some(self.pool.some_request(req, self.ctrl.clone()));\n        Next::wait().timeout(Duration::from_secs(1))\n    }\nfn on_request_readable(&mut self, transport: &mut Decoder<HttpStream>) -> Next {\n    unreachable!()\n}\n\nfn on_response(&mut self, res: &mut Response) -> Next {\n    let resp = self.rx.as_ref().unwrap().recv().unwrap();\n    serde_json::to_writer(&mut self.out_buffer, &resp).unwrap();\n    res.headers_mut().set(ContentLength(self.out_buffer.len() as u64));\n    Next::write()\n}\n\nfn on_response_writable(&mut self, transport: &mut Encoder<HttpStream>) -> Next {\n    self.out_pos += transport.write(&self.out_buffer[self.out_pos..]).unwrap();\n    info!(\"out position of buffer {}, length {}\", self.out_pos, self.out_buffer.len());\n    if self.out_pos < self.out_buffer.len() {\n        Next::write()\n    } else {\n        Next::end()\n    }\n}\n\n}\n```\nHope that helps get you going\n. It always must be asked, you were comparing a release build right? cargo build --release\n. Well one thing seems pretty different almost right away, you are explicitly enforcing a new connection on each request in the rust version, in the go version your leaving the decision whether to keep-alive the connection and reuse it up to the implementation. Removing the .header(Connection::close()) changes the program running time on my machine from 10's of seconds to 2.7s.\n``` rust\n[macro_use] extern crate log;\nextern crate env_logger;\nextern crate hyper;\nextern crate rustc_serialize;\nuse std::thread;\nuse std::io::Read;\nuse std::ops::DerefMut;\nuse std::sync::Mutex;\nuse std::sync::MutexGuard;\nuse std::sync::LockResult;\nuse std::sync::Arc;\nuse hyper::Client;\nuse rustc_serialize::json;\n[derive(RustcDecodable, RustcEncodable)]\nstruct Story {\n    by: String,\n    id: i32,\n    score: i32,\n    time: i32,\n    title: String,\n}\nfn next(cursor: &mut Arc>) -> usize {\n    let result: LockResult> = cursor.lock();\n    let mut guard: MutexGuard = result.unwrap();\n    let mut temp = guard.deref_mut();\n    temp = temp+1;\n    return *temp;\n}\nfn main() {\n    env_logger::init().unwrap();\n    let client = Arc::new(Client::new());\n    let url = \"https://hacker-news.firebaseio.com/v0/topstories.json\";\n    let mut res = client.get(url).send().unwrap();\n    let mut body = String::new();\n    res.read_to_string(&mut body).unwrap();\n    let vec: Vec = json::decode(body.as_str()).unwrap();\n    let lock: Arc> = Arc::new(Mutex::new(0));\nlet mut handles: Vec<thread::JoinHandle<()>> = Vec::new();\nfor _ in 0..8 {\n    let client2 = client.clone();\n    let mut lock2 = lock.clone();\n    let vec2 = vec.clone();\n    handles.push(thread::spawn(move|| {\n        loop {\n            let cursor = next(&mut lock2);\n\n            if cursor >= vec2.len() {\n                break;\n            }\n\n            let url = format!(\n                \"https://hacker-news.firebaseio.com/v0/item/{}.json\",\n                vec2[cursor],\n                );\n\n            let mut res = client2.get(url.as_str())\n                .send()\n                .unwrap();\n\n            let mut body = String::new();\n            res.read_to_string(&mut body).unwrap();\n            let story: Story = json::decode(body.as_str()).unwrap();\n            println!(\"{}\", story.title);\n        };\n    }));\n}\n\nfor handle in handles.into_iter() {\n    handle.join().unwrap();\n}\n\n}\n```\n. Out of curiosity, why is Handler still required to be Sync and Send now? It should be neither correct?\n. It looks like HandlerFactory has a fn create which takes a http::Control, however... hyper::http is private, so its impossible currently to implement the trait outside of hyper I believe?\n. So it is, apologies\n. @seanmonstar Fantastic! No more std::sync::mpsc errors :beers: \n. When creating a enum'ed error wrapper around my method which may return\nseveral error kinds, its impossible to create a From for\nMyError which is annoying\nOn Tue, May 24, 2016 at 5:31 PM Sean McArthur notifications@github.com\nwrote:\n\nLooking at the implementation again, there's not much to these errors. Is\nthere any reason you would need to name them? They pretty much only exist\nin hyper so that unwrap or debug printing them will give a more useful\nmessage.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/802#issuecomment-221421739\n. Testing it on my core i7 desktop\n\nwrk --latency -c 500 -d 30s -t 12 http://localhost:3000/                                  \ue0b2 \u2713 \ue0b2 6952 \ue0b2 11:14:10 \nRunning 30s test @ http://localhost:3000/\n  12 threads and 500 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency     1.30ms    1.68ms  47.35ms   88.47%\n    Req/Sec    41.40k    20.85k  170.33k    69.83%\n  Latency Distribution\n     50%    0.88ms\n     75%    1.40ms\n     90%    3.20ms\n     99%    6.55ms\n  13930273 requests in 29.94s, 1.14GB read\nRequests/sec: 465263.03\nTransfer/sec:     39.05MB\n. This should be good now minus I guess styling/code likeability. It does what its meant to though.\nBefore these changes, for the hello example\nsh\nwrk --latency -c 500 -d 30s -t 12 http://localhost:3000/\nRunning 30s test @ http://localhost:3000/\n  12 threads and 500 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency     1.63ms    1.89ms  46.11ms   88.65%\n    Req/Sec    38.26k    25.27k  164.33k    70.47%\n  Latency Distribution\n     50%  804.00us\n     75%    2.93ms\n     90%    3.86ms\n     99%    6.60ms\n  12646358 requests in 29.98s, 1.04GB read\nRequests/sec: 421892.96\nTransfer/sec:     35.41MB\nAfter these changes for the hello example\nsh\nwrk --latency -c 500 -d 30s -t 12 http://localhost:3000/\nRunning 30s test @ http://localhost:3000/\n  12 threads and 500 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency     1.11ms    1.26ms  49.31ms   87.87%\n    Req/Sec    44.22k    16.81k  153.22k    67.20%\n  Latency Distribution\n     50%  700.00us\n     75%    1.38ms\n     90%    2.69ms\n     99%    5.77ms\n  14946137 requests in 29.95s, 1.22GB read\nRequests/sec: 499083.80\nTransfer/sec:     41.88MB\n. Ah right, I completely overlooked that, not really thinking about the difference there.\nUsing a reference works, but seems strange to me.\nrust\nif req.headers.get::<ContentType>() == Some(&ContentType(\"text/plain\".parse().unwrap())) {\n   println!(\"acceptable content type\");\n}\n. On the surface that seems nicer than my snippet, though I wonder if people would miss out on the use case without some good examples in the right places. Really the reason to even have that PartialEq impl for Option<&Self> is because headers.get returns it.\nHaving an example there would make a good deal of sense.. ",
    "ChrisMacNaughton": "I would love to be able to get access to more granular timing information as well for a project I'm working on.. ",
    "jgillich": "I've started writing a higher-level library called request (based on hyper's Request - yeah I suck at naming things). It has an builder interface, handles redirects and probably more things in the future. Usage looks like this:\nlet result = Request::with_url(\"http://example.com\").header(Accept(...)).get();\nThe code is a bit awkward (like using clone too often) so if anyone has any ideas on how to improve it, I would love to hear them. It is however more of a learning project, I might decide to abandon it one day if something better comes up (or I will just continue to improve it until it becomes something better).\nAbout hyper's Request, it feels too low level for \"regular\" applications. Handling redirects manually would mean you'd have to write a wrapper around Request, essentially what my request library is.\nHowever, when it comes to writing wrappers around it, it is actually too high-level. One example is setting the headers - it makes the most sense to store your headers in a Headers struct, but when you overwrite Request.headers, you wipe the Host header that it defined in its constructor.\nAs somebody who never wrote a HTTP library nor a browser engine from scratch, my naive proposal would be to take the low-level parts of Request, put them in a module where you can simply say \"here are my headers, url, method, send pls\", and then write a high-level module on top of it. And maybe one in between for browser engines and similar applications.\n. Sounds great! I might need a bit of guidance occasionally until I've fully grasped Rust, if that's fine I'd love to help.\n. @seanmonstar hyper builds just fine, the error comes from rust-http. I'll try to fix that one too.\n. Ok, PR for rust-http is done too: https://github.com/chris-morgan/rust-http/pull/174\nThe tests for hyper now pass with my fork:\n[dev-dependencies.http]\ngit = \"https://github.com/jgillich/rust-http.git\"\n. Can we get this merged? I also need this for a redirect loop. :+1: \n. @cmr (Nevermind, I guess you already knew that) You can checkout @kyledewey's branch and use it as an overwrite in the cargo config (paths): http://doc.crates.io/config.html\nBut I agree, I would also like to see my Travis tests to pass from time to time. :wink: \n@seanmonstar I think there is a single case of glob usage https://github.com/kyledewey/hyper/commit/b530eb54ee59ae229a6f41334d9a5be7d65af9d0#diff-c32e97574dbd96ceca6dcb3e8b7376bfR8\nDo you want me to change it? Unless @kyledewey wants to do it himself, of course.\n. ^ PR is up.\n. It would need a Path in addition to Url, but there's still a totally normal Url where the host part gets ignored.\nFYI, it would be useful for accessing the Docker remote API, where the Unix socket is the default and also the only standard way to limit access (they don't do authorization over HTTP as far as I know). I am not sure how many other programs do HTTP over Unix sockets. probably not a lot.\nAbout libraries that support it, Node's built-in http library does and some libraries that use it also mention it explicitly (for example request).\nI don't mind putting it in a separate crate, it surely is a uncommon feature. It will be a while before I start implementing this anyway, I think it can be decided when it is a bit more clear how the required changes would look like.\n. Very cool :) I guess this can be closed then.\n. HashMap::find_equiv: http://doc.rust-lang.org/std/collections/struct.HashMap.html#method.find_equiv\nsrc/header/mod.rs:148:19: 148:53 error: use of deprecated item: use get and BorrowFrom instead, #[deny(deprecated)] on by default\nsrc/header/mod.rs:148         self.data.find_equiv(&CaseInsensitive(name)).and_then(|item| {\n. Yepp, lets take yours then. Bug against rustc has been filed.\n. I think you can delete this comment, too: https://github.com/jgillich/hyper/commit/2b3b17c6a5a5ad39a70bf6d41ebb18c7e9a7e537#diff-c32e97574dbd96ceca6dcb3e8b7376bfL1588\n. ",
    "mytrile": "[~/tmp/demo]\u25b6 RUST_BACKTRACE=1 RUST_LOG=hyper=debug ./target/demo                                      \nDEBUG:hyper::server: Incoming stream\ntask '<unknown>' has overflowed its stack\n[1]    27509 illegal hardware instruction  RUST_BACKTRACE=1 RUST_LOG=hyper=debug ./target/demo\n```\n[~/tmp/hyper]\u25b6 RUST_BACKTRACE=1 RUST_LOG=hyper=debug cargo bench                                         [master]\n     Running target/release/client-f71daafad9cad1f7\nrunning 3 tests\ntask '' has overflowed its stack\nProcess didn't exit successfully: /Users/dimitar/tmp/hyper/target/release/client-f71daafad9cad1f7 --bench (status=4)\n```\n. ",
    "annevk": "If your comment is misplaced, you can remove it, no?\n. Could someone give an example of what the input is here and what the expected output is? I have a hard time following since the used terms have different meanings all over.\n. CORS needs to do string comparison. You can probably do something with utf-8 percent-encoding vs punycode to show the difference.\n. ",
    "s-panferov": "Fixed, anything else?\n. I don't see any places to use CookieJar in hyper for now. I imagine such flow:\n1. Hyper uses cookie::Cookie to parse Cookie header.\n2. Client code loads cookie::Cookie's from Cookie header to own cookie::CookieJar (maybe with signing).\n3. Client code uses the cookie::CookieJar to make some changes.\n4. Client code creates SetCookie header with help of cookie::CookieJar and passes it to hyper.\n. For convenience we can create some helpers for the last step: SetCookie::from_jar(&cookie_jar)\n. I sent two commits that add support of cookie-rs. Now i'm looking for some generic solution to make cookie-rs replaceable.\n. I added a default cookie_rs feature to Cargo.toml. One can completely disable cookie-rs and use default pub type Cookie = TypedCookie<String> or make it's own header type with another library. \n. The last thing we need here is a Set-Cookie's formatter. I don't know the entire hyper codebase enough, so i need advice.  I see #72, it is related?\n. Maybe we can merge this and implement formatter later?\n. Hi all! What do you think about accepting this MR with limitation to set one SetCookie header? I found out that it is quite enough for simple web-servers to store single cookie with _session_token and use it for authentication.\nFeel free to say no, I can just use the my own hyper fork to unblock myself while we are waiting.\n. I thought about it, everything looks ugly and hard to remember. Another variants are:\n- to_abstract()\n- abstracted()\n- as_abstracted()\n. dynamic is ok, maybe we can use it. Or maybe just upcast?\n. upcast quite nice shows what is going on and in rust-error you have corresponding downcast method. But my english is not native, so maybe there are some other meanings that i don't know. The my last try is upward(). If you don't agree i will fix abstr to dynamic.\n. +1 for PR, i like to see this header too\n. :+1: looks extendable\n. :+1: I have already checked this in a real project. Everything works excellent except the comments. \n. @seanmonstar I have no more comments, everything is ok for me.\n. @retep998 To be sure, you need:\n1. a conversion from CookieJar to Cookies header;\n2. a conversion from SetCookie header to CookieJar;\nIs it correct?\n. @retep998 I made a PR alexcrichton/cookie-rs#14. We need this for the first part.\n. @retep998 please take a look to #166.\n. Hmm. Build was broken by the new rustc nightly. \n. Rebased\n. @seanmonstar done.\n. The new version was published, thanks!\n. Can we upload it to crates.io with such structure? The last time I tried to publish my project with local dependencies cagro said No.\n. :+1: Can we make it configurable somehow in the future?\n. I think that Hyper must have something like KeepAliveTimeout in Apache.\n. @andor44 I think that you may try to use nginx as a reverse proxy in front of Rustless/Huper to work-around the issue. Nginx could handle a big amount of connections without any issues and it has usable keep-alive settings. I think nginx is required for blocking servers anyway.\n. @andor44 have you tried to use a reverse proxy already? Has it helped? \n. I see you has removed the ability to use String here. It is ok, but we need to remove all #[cfg(feature = \"cookie_rs\")] and make cookie-rs non-optional.\n. Do we need to remove this?\n. We forgot to pub use Cookies and SetCookie in this module.\n. Please change this definition to\nrust\npub fn to_cookie_jar(&self, key: &[u8]) -> CookieJar<'static> {\nWe need to specify a static lifetime because Rust will try to infer the lifetime and this is not what we want here. \u0415.g. code like this won't compile with lifetime errors:\n``` rust\nlet jar = req.headers().get::().map(|cookies| cookies.to_cookie_jar(&[]));\nif jar.is_some() {\n    req.ext_mut().insert(jar.unwrap());\n}\n// error: cannot infer an appropriate lifetime for autoref due to conflicting requirements\n``\n. +1 forcookies_raw[]:\n1. Slicing syntax does here what it designed for.\n2. It is much cleaner and homogeneously for eyes.\n3. It is a known syntax for people from Python, Ruby and so on.\n4. If later you will want to take another slice, (e.g.slice_from(1)), you will have to use slicing syntax anyway.\n. Please note that I useadd_originalhere. I do it because the header contains only raw data and: \n1. The data will be corrupted if we will useencryptedorsignedjar here.\n2. I can't imagine a situation when we need to usedelta` to get this changes.\n. Missed this, thanks! Fixed.\n. @seanmonstar Cool! I missed this. Fixed.\n. Maybe it's better to restrict the total size instead of the count?\n. We need to restrict the total size because actually it's possible to consume a lot of memory just by one header, e.g. Cookie.\n. Maybe it's better to rename it? How about MAX_HEADERS_LENGTH?\n. ",
    "alexcrichton": "I wouldn't be confident in saying that cookie-rs is super standards compliant (it hasn't seen much real-world usage yet, I'm just using it for the cargo registry), but I'd love to help out here!\nThe major questionable dependency is rust-openssl, which isn't quite what you'd want on windows. I certainly don't mind refactoring out signing into a separate sub-package. Just let me know!\nIf you guys end up creating your own cookie parser, I also wouldn't mind depending on that for the signing and such!\n. This seems like a great idea! As @sfackler said the same Cargo.toml will serve for publishing and developing, and I'd like to add something along the lines of cargo publish --all which will publish all packages in the current repository, automating the publish-each-package-separately step.\n. Yeah I'm up for any direction for cookie-rs to go in, it's gotten a lot more use than I originally though it would! I'd also be fine just making the openssl dep an optional dependency as it's only needed for signed/encrypted cookie jars, which not everyone needs.\nI'm also fine if you guys want to start your own cookie library, I'll be the first to say that cookie-rs would probably need some love! Regardless, lemme know any way I can help, and I surely don't mind!\n. @pimeys I think the error you're seeing there is just due to type inference in the compiler and the Stream trait. Right now fold is generic over the error returned, working with From to switch error types if necessary.\nThe error in your example I believe is that Ok(acc) doesn't have a known error type and the compiler is unable to infer what it should be. You can fix this with Ok::<_, hyper::Error>(acc) (eew) for now and we may want to consider making fold less generic in the future.. cc https://github.com/alexcrichton/futures-rs/issues/390, a possible extension that came up during integration in https://github.com/mozilla/sccache/pull/70. Another option is something like https://github.com/tailhook/tk-easyloop where it becomes easy to acquire a global handle.. Sure thing, I'll send the PR against master instead. Yeah that's the impl I was thinking of. I don't think users would use this explicitly, but that way Hyper \"as is\" would hook into tokio-proto's TcpServer so that could be used off the bat.. @mattwoodyard sounds like you went down the same rabbit hole I did! @seanmonstar is spot on in that the server Hyper bundles isn't currently intended to be used with TLS (or other protocols for that matter). The idea is that protocols are built externally and then there's generic support for taking a protocol and spinning up a server with it. \nNote, though, that support isn't quite here yet for all that. PRs like https://github.com/tokio-rs/tokio-proto/pull/135 and issues like https://github.com/hyperium/hyper/issues/1036 are key ingredients to getting that working. With https://github.com/hyperium/hyper/issues/1036 Hyper's request/response should work \"as-is\" with tokio-proto's TcpServer and with https://github.com/tokio-rs/tokio-proto/pull/135 then tokio-proto's TcpServer should reach feature parity with Hyper's current server in this repository.\n@seanmonstar I'll leave it up to you whether you'd like to merge this for now. The intention at least is that this shouldn't be necessary (and in fact, the entire server shouldn't be necessary!), so you can at least rest easy that in the future you won't have to maintain this :). Yeah I believe that's the general long term plan at least, to have Hyper work well with the tokio-proto server builders to leverage all of the logic in there (which will expand over time). Currently we don't have super concrete plans to expose SocketAddr itself specifically, but the thinking was that this would be a bound on the I/O objects that hyper operates with. Right now it's Io but the theory is that if Hyper wanted to extract a remote address it'd instead be Io + MyTrait.\nThis'd be a great trait for specialization to avoid imposing extra requirements, but unfortunately that's not there just yet :(.. @seanmonstar yeah it's true the situation isn't great no matter how you slice it right now. That's where I think that specialization will be best here because you really do want to work with all Io, it's just that optionally sometimes there's an extra piece of information to learn either through AsRef, a custom trait, or such.\nIn the meantime what do you think about with being conservative and removing the method from Request? It can always be added back later, and I was under the assumption that you typically don't want the TCP level peer because you've got some proxy like nginx in front of you anyway.. IIRC \"flush\" in this case basically just happens pretty commonly, but @carllerche would know for sure. Note that this is also why Hyper's server gives access to its handle and so does tokio-proto's proposed implementation. @radix keep in mind that these APIs are \"intro\" apis, they're \"easy mode\". You can always configure the server yourself more manually by calling the raw methods on tokio-proto that work with connected sockets instead of spinning up a TCP listener for you.\nIn that sense everything you've mentioned is supported, it just depends on how much logic you'll have to vendor locally one way or another.\nYou bring up some good points, though, and it may be useful for the server (in tokio-proto and perhaps in Hyper as well) to have a mode of operation where it's constructed from a handle rather than constructing the core itself.. @seanmonstar to be clear though, Server supports a custom Core today already, right? That was the intended purpose of the bind_connection method. So in that sense, just to confirm, you're thinking that this issue is targeted at \"make using a custom Core easier\", right?\nIf that's all true then what you proposed seems reasonable. The downside is that it may be difficult to shut down such a server. I'd probably recommend Http::spawn as a method which spawns directly into the reactor vs giving you a future that you then spawn. (although there may be downsides with that). Ah right yes sorry the distinction between Server and Http is important here. \nIt's true tha working with a future is a bit nicer for shutdown, but probably still not what you want? Unless you're tracking all instances of the service yourself it'd still be difficult to have a graceful shutdown semantics maybe?. You'll want to change || Ok(RequestHandler) to just RequestHandler I believe. I'm personally still too wary to bake a default event loop into tokio-core itself, but anything we can do to make that more amenable externally I'd be find thinking about!. At least for me in how I've worked with libs in the past it's pretty rare for me to have a parsed Url on hand. Typically I manage it via a string and then just pass it to a library (there's also typically very little manipulation of the URL as well).\nI could go either way, but in some sense reducing the suite of public dependencies is always a nice win! (if necessary though I'd definitely still use it for internal usage if the need arose). Ah and I should also mention that I dropped the relay crate while I was at it in favor of futures::unsync, but I can back out that change if you'd prefer.. Ok I believe that should handled the blocked read case?. @seanmonstar I'm not sure I quite understand, could you clarify? Naively it seems like that's a \"nothing goes to sleep\" situation, but I'm not sure.. I think so yeah, that'd make sense. This came up w/ a custom AsyncRead + AsyncWrite implementation so a call to io.flush() in poll_complete would do the trick.. Yeah it seems reasonable for there to be a constructor on CpuPool which returns a result. This does indeed seem like a plausible combinator to extract! My guess now though would likely be a separate crate rather thanan existing on as it's not clear where it may go. d'oh right, sorry I thought I had handled this elsewhere already.\nI was wondering if you know how the best way might be to handle this off-hand?. Yeah I believe so, I'll look into adding such a flag.. ",
    "gtolle": "Awesome! Thanks much.\n. Also, I thought I'd share the project I'm working on - would love to hear your feedback. \nIt's a high-level REST API client in Rust, inspired by Ruby's rest-client. I'm going for the smallest amount of code to make the most common types of REST API calls. It depends heavily on Hyper, of course.\nhttps://github.com/gtolle/rest_client\nIt does work, but it's my first piece of Rust code and there are probably tons of things I could be doing better.\n. Thanks for the quick reply and suggestions. \nI'll definitely look into the RawHeaders API when it arrives, and keep an eye on issue #50.\nThis is just a fun side project for me, so no worries about not solving my problem. :)\n. That makes sense. I'll definitely look into that.\nSide question: I'm implementing my own Authorization header now, and I'm finding myself wanting to reuse the from_one_raw_str function you've already written. Any objection to making that pub?\n. Makes sense. I'll take a stab at that tomorrow and then update the PR.\n. Alright, I took a stab at a typed Authorization header that supports two schemes: Basic and Raw (for uninterpreted strings). \nThe Basic scheme supports base64 encoding and decoding, with unit tests to make sure it works. I've also tested it against some real APIs using my rest_client.\nBut, I'm certain the parsing logic could be expressed more concisely, and there's probably a better way to capture the different schemes as well. My lack of deep Rust experience is rearing its ugly head here, so I'm open to suggestions.\n. ",
    "adwhit": "This issue has resurfaced, possibly due to the changes in rust-url 1.0.\nhttps://github.com/servo/rust-url/pull/176\n\nserialize_without_fragment is now &url[..Position::AfterQuery]\n. Thanks, done\n. The tokio branch is where the action is at the moment. AFAICT the examples in that branch are compiling, though whether they are 'working' is another matter. If you are just learning hyper I would recommend you work off  that or else wait until it is merged into master.\n\nAlternatively the 0.9.x branch also has working examples, but the API will change quite drastically when tokio is merged.. ",
    "matt2xu": "Yep, I just witnessed the same thing. I'm under the impression that the problem is there:\nhttps://github.com/hyperium/hyper/blob/master/src/client/mod.rs#L303\nThere is no mention of query anymore (or fragment for that matter). Maybe a simpler way would be to call url.set_host(None) to remove the host and port, and then url.into_string(), so everything else (path, query, fragment) is preserved.\n. \"again\" ah I know that feeling... Thanks for fixing this! \n. For what it's worth, I've been bitten by this bug too: https://github.com/matt2xu/edge-rs/blob/master/src/lib.rs#L175 :smile: \nI agree that your approach is sensible, and all that's missing is documenting this behavior. Frameworks on top of Hyper (or code using Hyper directly) can then decide whether closing the connection or reading the request's body. Ideally I would suggest that in the description of the Request a line be added \"It is the user's responsibility to handle the request's body by either reading it or discarding it and closing the connection. Note that by default, Hyper uses a pool of connections with keep-alive behavior, which means that if a request has a body that is not read, the socket is reused and the next request is parsed incorrectly.\". What do you think?\n. Ok, good. So we change the text a bit :smile: I still think that this deserves a few words in the documentation so people aren't surprised by this. I look forward to using the async branch by the way, when I have the time I'll update my code.\n. It seems to me that this is the same behavior with the current (blocking), at least that's what I observed empirically: if your server handles a POST request but does not read it's body, the method field of the subsequent POST request is \"body_of_previous_requestPOST\". Not sure if this should be considered a bug or not, so I implemented Drop for my Request so it reads the body in case it has not been read before.\n. +1 for sending Content-Length: 0 instead of an empty chunk when dropping. This should be not done all the time though.\nIndeed, in HTTP/1.1, there are cases where Content-Length is optional, and some in which it is explicitly forbidden: 1xx (Informational) responses and 204 (No Content) response. Also, when responding to a HEAD request, or when responding with a 304 (Not Modified) status, sending a Content-Length is optional and only valid if it is the same as the Content-Length that would have been sent if the request was a GET or the response was 200 (OK) respectively.\nSee 3.3.2 Content-Length\nhttp://httpwg.org/specs/rfc7230.html#header.content-length\nAlso note that \"A server MUST NOT send a Transfer-Encoding header field in any response with a status code of 1xx (Informational) or 204 (No Content).\", which Hyper currently does not respect.\n. +1 for moving the Charset to the mime crate. It would improve it, too, as\nwe could replace the lone Utf8 charset Value by a Charset value. Hyper\nwould have to reexport Charset from mime for compatibility, right ?\nLe 24 mars 2016 9:18 PM, \"Sean McArthur\" notifications@github.com a\n\u00e9crit :\n\nI recall finding that weird as well, but I was also left wondering if this\nfit better into the mime crate, or here in hyper.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/748#issuecomment-201002878\n. This is not hyper's fault, it's the openssl crate that does not compile under Windows out-of-the-box because it needs the header files of the OpenSSL library. You probably need to have those headers in one of the include directories in which Visual Studio looks, and then you'll have to do the same for the library (.lib file).\n\nAlternatively, you could 1) compile under Linux where libraries and include files are installed in system-wide locations, or 2) deactivate the \"ssl\" feature of Hyper to have it compile without further complications.\n. @shaobozi please note that the README of the openssl crate includes instructions on how to build for Windows: https://github.com/sfackler/rust-openssl\n. openssl is already a dependency, but it's optional, so I would go for the md5 crate instead. I'll start working on the headers this week-end. Question @seanmonstar from which branch do you prefer I start? I'm currently using mio for my framework.\n. @malept Wow this seems a pretty thorough implementation of the digest scheme! Yes it looks like it would be a great starting point. How do we proceed? Are you willing to shape this so it can be integrated in Hyper with a PR? Should I work on WWW-Authenticate then?\n. So I finally started to work on WWW-Authenticate, and I was thinking about our discussion. Looking at the guardhaus crate by @malept, Digest authentication seems (a lot) more complicated than Basic, and it is probably better to implement it in its own crate, as is already the case. This has the advantage of not having to integrate too much code nor add dependencies to Hyper.\nI like how Authorization is extensible using the Scheme trait, but the thing is that WWW-Authenticate can support many challenges in a single header (Basic and Digest being the two most well-known standard challenges).\nThe way I see it, I could implement the parsing of WWW-Authenticate as a list of challenges, each one with a scheme and the associated parameters (to be put in a hash map or something). Then the user of the library would implement conversion from a generic Challenge struct (rather than just a &str) to a specific one like Digest. Essentially the parsing step would probably rely on what from_comma_delimited does, just tailored for WWW-Authenticate to handle the special case of the scheme.\nThen all that's needed is for a crate like guardhaus is to implement From for Digest for instance, and I could get a Digest from a WWW-Authenticate header. What do you think?\n. I've started to implement the specification in a generic way here, and to be honest I find it quite complicated. The grammar allows extraneous spaces and commas almost everywhere, and is ambiguous when you have a sequence comma, space, comma. The token production rules are not stateless: the string \"x=\" can be interpreted as \"x\" followed by \"=\" or a single token \"x=\" (used for base64 values); choosing the right one depends on what comes after the \"=\" sign.\nTo parse a challenge, I've implemented a different Scheme trait that takes the list of parameters that were parsed. @malept @seanmonstar could you give me some feedback on this?\n1. Should I keep going and finish the implementation this way, or\n2. do something simpler, like find the first item in the header that matches the name of the desired scheme, and let the Scheme implementation do the parsing?\n3. Another suggestion?\nThe advantage of the first method is that corner cases, like escape characters in quoted strings, would only need to be handled once rather than in each separate libraries. The advantage of the second approach is that implementors know how to parse their contents, for example the from_str method of impl FromStr for Basic in authorization.rs knows that the &str it is given is base64. For this to work we need to know where a scheme begins, which is still not trivial.\n. I'm almost there! Latest version here. The one piece missing that I noticed just now is that it doesn't work for multiple parameters :sweat_smile: but that should be easy to fix. To make the code simpler, I have a pre-processing step that does split(',') + trimming + ignore empty strings (inspired from from_comma_delimited) without allocations. Then I map an entry to a sequence of tokens, and try to parse it as a challenge.\nI added a ChallengeInfo enum of either a single Base64 token, or a Params of a vector of tuples. The Scheme trait now has a from_info that takes an optional challenge info to build a Challenge.\nHowever, I think it should remain the responsibility of the Scheme implementation to format the header to a string. The reason is that schemes can have peculiar rules regarding what string to quote or not (looking at you Digest where realm, domain... \"MUST\" be quoted and stale, algorithm \"MUST NOT\" be quoted...).\nQuestion: how do we create a WWW-Authenticate with several schemes? I'm thinking of how a server-side framework would generate it. Maybe WwwAuthenticate<S> should be an enum Parsed(S) or Raw(String)? Other ideas?\n. > Are you just using the Basic scheme just as a testbed for the base64 token implementation?\nYes. The code is mostly just a copy/paste from authorization.rs, that's why the example uses a base64 token, and indeed it must seem a bit weird :confused: \nI was just reading RFC 7617 \"The 'Basic' HTTP Authentication Scheme\", I love the part where it says in Section 2 \"See also Section 4.1 of [RFC7235], which discusses the complexity of parsing challenges properly.\" Well all I can say is that I am now quite aware of that complexity :grinning:\n. Good news! After some additional work today on the parser, I think it is now complete! As of commit 3ca2530 it handles correctly multiple parameters, commas in quoted strings, and multiple extra commas; things like ,,,  ,   Digest a=b   , ,,  ,c  =  d,Basic zzzzz==   ,   Digest x=y,z=w, qop=\"auth, auth-int\"\n. @malept did you have time to think about my implementation?\nMaybe the easiest is that WwwAuthenticate just contain a String. It allows a server to easily add a challenge to a WWW-Authenticate header, for instance:\nrust\nfn add_challenge(&mut self, challenge: &str) {\n  if !self.inner.is_empty() {\n    self.inner.push_str(\", \");\n  }\n  self.inner.push_str(challenge);\n}\nTo get the first Digest challenge, you could call: www_auth.get_scheme::<Digest>().\nrust\nfn get_scheme<S: Scheme>(&self) -> ::Result<S> {\n  for challenge in parse_challenges(&self.inner) {\n    let challenge = try!(challenge);\n    let scheme = <S as Scheme>::scheme();\n    if challenge.scheme() == scheme {\n      // ... convert challenge to Scheme and return it.\n    }\n}\nNote: this is just sample code to illustrate what I mean, I haven't compiled any of it. Also, add_challenge could just always add a \", \" regardless of what's before since that's allowed by the spec, but it would look a bit weird.\nWe could either keep the Authorization header as it is today, or change it to use the updated Scheme trait and the parser from www_authenticate.rs.\n@jdm @seanmonstar thoughts?\n. > It looks like Authorization<S> supports both a Scheme and a String when you initialize it, without the use of an enum. It would be nice from an API consumer perspective to be able to add either via add_challenge().\nYes, that's because the Scheme trait is implemented for String, with a scheme that is None, so an Authorization can always be created even for unknown schemes. This cannot be done so easily for WWW-Authenticate, because we can have several different challenges. You would need a signature like WwwAuthenticate<S1: Scheme, S2: Scheme, ..., Sn: Scheme>(S1, S2, ...Sn), but that's obviously not possible; the closest thing would be something like WwwAuthenticate(Vec<Box<Any + Scheme>>). This would allow us to downcast each entry to a concrete implementation (or to String).\nIf we declare WwwAuthenticate(String) instead, we would have a method like this:\nrust\nfn iter_schemes<'a, S: Scheme>(header: &'a str) -> SchemeIter<'a, S>\nOr to iterate over all challenges:\nrust\nfn iter_challenges<'a>(header: &'a str) -> ChallengeIter<'a>\nI like having a WwwAuthenticate just holding a String that is parsed on demand, rather than a vector of boxes. What do you prefer? Once we resolve this question, I'll make a pull request.\n\nI'm not sure about your get_scheme() method. What if there are multiple Digest challenges and the first one uses an algorithm not yet supported by the implementation?\n\nGood catch. If the implementation does not support an algorithm, it would return Err; we could have parse_header skip errors until it finds an implementation that succeeds. That's still not ideal, because an implementation should select the best algorithm it supports, and that may not be the first. In fact, this would actually be an attack vector: have a malicious server return a Digest with algorithm=MD5 first knowing that the client implementation will just pick the first algorithm it can handle.\nSo that's a big no for get_scheme then!\n\nI wouldn't add a dangling comma, mostly because of the robustness principle.\n\nMe neither, I'm aware of the robustness principle, I was just being sarcastic and mocking the spec a bit (again) :smile: \n\nI would be fine with updating guardhaus to use the new trait. (Assuming an appropriate version bump from hyper.)\n\nGreat!\n. The parser implementation is complete. The remaining work is to decide 1) what to store in a WwwAuthenticate structure: a String, a Vec of Challenge, something else?\n2) how implementations can interpret a given scheme?\nNote I am starting to think that it would be worth it to have a crate dedicated to HTTP auth digest support. I'd rewrite the parser with nom and have the parser produce a Vec  (rather than an iterator of Challenge). Hyper could use that crate, as well as other HTTP client and server crates.. @mattnenterprise yes. Kind of like guardhaus or hyper_auth do, but without depending on Hyper itself, since it only depends on the challenge information present in the header (and the authorization header uses the same data structure IIRC). @malept ok, so it looks like this is doable! I'll get started as soon as I'm back from holidays (beginning of January) and update this issue after that.. I've created a separate repository to host an http-auth crate and ported my parser to nom: see https://github.com/matt2xu/http-auth\n@malept could you please take a look and tell me what you would like to see in the API ? Looking at guardhaus I notice that some parameters need to be quoted and some don't; I assume http-auth should make the difference between the two?. I no longer need this, but feel free to take the code. The parser passes the (limited) tests I had written, what would be needed would be to use this code (either as a separate crate or just copy/paste) and integrate it with Hyper.. In my framework, I've also chosen the simplest approach: read the whole body from the Decoder into a Buffer (essentially a Vec + position). See Handler::on_request_readable and Buffer::read_from methods.\nProbably in case of file upload you might want to store the request body in a file to avoid consuming too much memory. This could be a configuration option when initializing the server. Alternatively if you want to use a callback with a Read argument, you can use Cursor over a Vec read from the Decoder in on_request_readable.\n. I agree with @cybergeek94 on receiving the Request earlier.\nAlso, maybe wrap the &mut Response; in a hyper::Result or an option, to disallow modifying the response once you've started to write to the transport?\n. ",
    "abonander": "@reem I'm going to bed. Add any other notes you need to so I can fix them in one commit tomorrow.\n. Wow. That's not noise. I had just hoped to keep it on par, and crossed my fingers that I hadn't caused a regression.\nI'll finish the cleanup at lunch.\n. It's a little after lunch but I got the changes added.\n. I didn't check the closed issues before posting this.\n. Does this work on Windows and OS X? If so, it might be useful to include in the stdlib.\n. That will send a files contents over a socket, but I can't find the associated function to pipe the socket into the outfile. Edit: Socket handles can be file handles in Winsock2\n. Crates does support keywords in package metadata but I don't feel like the site itself promotes discovery. It feels less like a bookstore and more like a university library; you'll only find something if you know what you're looking for. Not as bad as http://search.maven.org/, but it's close.\n. I created this Wiki page, taking the liberty to add multipart as well as several other projects I found with a quick GitHub search.\n. @seanmonstar Works already. The 5 keyword limit is a bit of a drag, though. I thought the package name would function as a 6th keyword so keyword hyper would produce a result for Hyper but it doesn't. However, searching \"hyper\" lists both crates.\n. By my optimistic estimate, upwards of 75% of ICEs related to unboxed\nclosures have been fixed. They're already pretty solid and only getting\nbetter. I'm using them in multipart.\nI've encountered a couple here and there, but only when I'm trying something really weird.\n. I have a weirder, but I think related, error:\n``\n$ cargo test --features hyper\n   Compiling rand v0.3.8\n   Compiling num_cpus v0.2.6\n   Compiling winapi v0.1.23\n   Compiling log v0.3.1\n   Compiling memchr v0.1.3\n   Compiling url v0.2.36\n   Compiling openssl-sys v0.6.4\nBuild failed, waiting for other jobs to finish...\nfailed to run custom build command foropenssl-sys v0.6.4Process didn't exit successfully:C:\\users\\austin\\Rust\\multipart\\target\\debug\\build\\openssl-sys-765ddf9de3c5179c\\build-script-build` (exit code: 101)\n--- stdout\ncargo:rustc-link-lib=dylib=eay32\ncargo:rustc-link-lib=dylib=ssl32\nTARGET = Some(\"x86_64-pc-windows-gnu\")\nTARGET = Some(\"x86_64-pc-windows-gnu\")\nCARGO_MANIFEST_DIR = Some(\"C:\\msys64\\home\\Austin\\.cargo\\registry\\src\\github.com-0a35038f75765ae4\\openssl-sys-0.6.4\")\nOUT_DIR = Some(\"C:\\users\\austin\\Rust\\multipart\\target\\debug\\build\\openssl-sys-765ddf9de3c5179c\\out\")\nOPT_LEVEL = Some(\"0\")\nPROFILE = Some(\"debug\")\ndebug 0\nTARGET = Some(\"x86_64-pc-windows-gnu\")\nHOST = Some(\"x86_64-pc-windows-gnu\")\nCC_x86_64-pc-windows-gnu = None\nCC_x86_64_pc_windows_gnu = None\nHOST_CC = None\nCC = None\nTARGET = Some(\"x86_64-pc-windows-gnu\")\nHOST = Some(\"x86_64-pc-windows-gnu\")\nCFLAGS_x86_64-pc-windows-gnu = None\nCFLAGS_x86_64_pc_windows_gnu = None\nHOST_CFLAGS = None\nCFLAGS = None\nTARGET = Some(\"x86_64-pc-windows-gnu\")\nHOST = Some(\"x86_64-pc-windows-gnu\")\nCC_x86_64-pc-windows-gnu = None\nCC_x86_64_pc_windows_gnu = None\nHOST_CC = None\nCC = None\nrunning: \"gcc\" \"-O0\" \"-c\" \"-ffunction-sections\" \"-fdata-sections\" \"-mwin32\" \"-m64\" \"-fPIC\" \"C:\\msys64\\home\\Austin.cargo\\registry\\src\\github.com-0a35038f75765ae4\\openssl-sys-0.6.4\\src/openssl_shim.c\" \"-o\" \"C:\\users\\austin\\Rust\\multipart\\target\\debug\\build\\openssl-sys-765ddf9de3c5179c\\out\\src\\openssl_shim.o\"\ncommand did not execute successfully, got: exit code: 1\n--- stderr\nC:\\msys64\\home\\Austin.cargo\\registry\\src\\github.com-0a35038f75765ae4\\openssl-sys-0.6.4\\src/openssl_shim.c:1:0: warning: -fPIC ignored for target (all code is position independent)\n #include \n ^\nIn file included from /usr/include/openssl/x509.h:107:0,\n                 from /usr/include/openssl/ssl.h:156,\n                 from C:\\msys64\\home\\Austin.cargo\\registry\\src\\github.com-0a35038f75765ae4\\openssl-sys-0.6.4\\src/openssl_shim.c:2:\n/usr/include/openssl/sha.h:184:16: error: expected \u2018:\u2019, \u2018,\u2019, \u2018;\u2019, \u2018}\u2019 or \u2018attribute\u2019 before \u2018h\u2019\n     SHA_LONG64 h[8];\n                ^\nthread '' panicked at 'explicit panic', C:\\msys64\\home\\Austin.cargo\\registry\\src\\github.com-0a35038f75765ae4\\gcc-0.3.8\\src\\lib.rs:497\n```\nCompiling with MSYS2, I made sure OpenSSL was installed with pacman -S openssl. Maybe gcc is trying to link with the wrong dialect for the header file? I dunno.\n. Can RequestBuilder have a method that consumes it and creates a writable HTTP stream that multipart can write to? multipart's API was principally designed around the Request API, and expects a separate object representing the actual HTTP stream.\n. It'll be cool to see when that's done! I've been wanting to add support in multipart for rotor.\nAre you eliminating all synchronous I/O from Hyper or providing it just as an alternative?\n. Author of multipart here. You can use the Client struct with client::lazy::Multipart via the following method:  http://cybergeek94.github.io/multipart/doc/multipart/client/lazy/struct.Multipart.html#method.client_request\n. It would still be nice to receive the request in the HandlerFactory method, so anything in the Handler that needs to be constructed from the headers in the request doesn't need to do funky stuff with Option. Barring that, one callback method is much easier to implement than four, so I guess I can live with it. \n. I'm guessing Transaction::request() will attempt to read the request from the stream on-demand, given it's returned in a hyper::Result. Naturally, the request will have to be switched to being eagerly read, which I don't think should be an issue as almost any request handler will want information from it anyway.\nYou haven't shown how HandlerFactory will change. I'm guessing you'll be dropping the Control parameter, so it will just be an empty method call like:\n``` rust\ntrait HandlerFactory {\n    type Output: Handler;\nfn create(&mut self) -> Self::Output;\n\n}\n```\nThere's a couple possible approaches I would suggest, and both involve eagerly reading the request head before calling HandlerFactory::create() which would mean one or two more states in the internal state machine.\nFirst approach would be to pass hyper::Result<Request> to HandlerFactory::create(); if the request could not be read, the factory can modify some state in the created Handler instance to return a response with an error message or what-have-you:\n``` rust\ntrait HandlerFactory {\n    type Output: Handler;\nfn create(&mut self, req: hyper::Result<Request>) -> Self::Output;\n\n}\n```\nSecond approach would be to have Request passed to HandlerFactory::create(), and add a second method and associated type for dealing with the case where the request could not be read; the second associated type would be the Handler impl that will be sending the error response:\n``` rust\ntrait HandlerFactory {\n    type Output: Handler;\n    type Error: Handler = DefaultErrorHandler;\nfn create(&mut self, req: Request) -> Self::Output;\n\nfn error(&mut self, err: hyper::Error) -> Self::Error {\n    error!(\"Error reading hyper::Request: {}\", err);\n    DefaultErrorHandler\n}\n\n}\npub struct DefaultErrorHandler;\nimpl Handler { /. ./ }\n```\nA default error handler could be provided so that a single closure can still be used as a HandlerFactory. It could send an appropriate error code back to the client and print the error to stdout. It might also be possible to impl HandlerFactory for a 2-tuple of closures with signatures which match create() and error() respectively.\n. Yes, I assumed that the request could be just be moved into the Handler if there was reason to retain it. As an upside, this allows the allocations in the Request to be eagerly freed if it won't be used later, which might help keep peak memory usage down for lightweight, high-volume servers. Or, it can be stored in Arc/Rc and clones of that can be given out freely (but then you pay the cost for the box). \nYou're already matching on the state machine enum in each tick, right?  I assumed that the error state above would be just another item in that enum, so it's still only one match per tick. At least, that's how it seems like it would fit into the current implementation, your plan for implementing the proposed API is still a little bit fuzzy. I haven't looked into the Tokio API too deeply.\nI personally prefer the single factory method receiving the result, this keeps the implementation from having to do an extra match, especially when the user doesn't really care about errors. It also simplifies the success/error code path into an explicit branch in the handler, which might be easier to keep track of and build on.\n. Second paragraph is talking about the two-method factory. First is either, I guess, but mainly talking about single-method factory.\nHowever, I realized that the two HandlerFactory layouts I demonstrated can be unified, because the latter can be implemented for an instance of the former: https://is.gd/3GMd6N (Bikeshedding welcome on trait names.) The Hyper API would then just take implementations of DivergentHandlerFactory.\nUnfortunately, coherence prevents the impl for the 2-tuple I mentioned above, though this could be substituted with a macro, maybe.\n. Having a default error handler seems elegant, but the diverging code path with two separate factory methods and two separate handler implementations disgusts me for some reason. It seems like a greater maintenance burden on the user, even if they end up making the two converge later.\nWhat if the HandlerFactory returned hyper::Result<Self::Output>? You could unwrap the error with try! or the ? operator if you didn't care about the error state, in which case it gets passed back to Hyper, or you could handle it yourself. One factory method, one handler implementation, extra flexibility.\n. Returning Result means try!() works for unwrapping the request passed to the factory. The ? operator would work with Option and would probably be the more elegant solution, but there's still a lot of churn in that area so I don't think we should base an API design on that yet.\nHowever, if we don't expect most use cases to handle the error, we probably shouldn't concern the average user about it. But I'm sure there will still be some that want control over what's done when an error occurs, and we should give them that control somehow.\nPerhaps this could be done with a separate trait, and a builder method on Server to supply an implementation and replace the default. HandlerFactory::create() would simply be (Request) -> Self::Output.\n``` rust\npub trait ErrorHandlerFactory {\n    type Output: Handler;\n// If the returned value is `None`, drop the socket. Otherwise, continue the request with the supplied handler.\nfn create(&mut self, err: hyper::Error) -> Option<Self::Output>;\n\n}\npub struct Server {}\nimpl Server> {\n    pub fn new<...>(...) -> Self;\n}\nimpl Server::Output>> {\n    pub fn http(...) -> Result;\n}\n// same for https()\nimpl Server {\n    pub fn error_handler>(handler: E_) -> Server {\n        //...\n    }\n}\n```\n. Ultimately, I agree. It's the simplest to implement while giving the user the choice between control and convenience.\nI realized that we've been discussing the server-side API all this time. How would the client-side work?\n. @seanmonstar any movement on this? It seems like there's still a lot going on in master, which is still based on rotor, though I guess a lot of the work is framework-agnostic. Do you need someone working on this implementation? If so, I have some free time here and there.\n. For example, in multipart, I'm essentially hand-rolling header parsing for the fields because I don't want to unconditionally depend on  hyper and bloat the build.\n. It would be nice to have a more complete header parsing crate out there, though.. Yeah, hyper::header separated into its own crate would be neat, then it can be reexported like normal but pub extern crate hyper_header as header or something. \nI've gotten httparse to work for my use-case and the zero-copy parsing is nice, but having a whole crate of header definitions would be great too.. I'd still like to advocate for separate crates, if only because it allows them to be built in parallel even in release mode.. @seanmonstar Can we backport this to 0.9.x? That's primarily where I need it.\n. @seanmonstar \nI'm working out a plan on how to build a fork of multipart on top of the async API once the dust settles. For the server-side API, I'm thinking of having a Multipart master struct which then becomes a stream of MultipartField, then each MultipartField is a stream of Chunk.\nOf course, the main problem that multipart solves is deliminating on the multipart boundary. What I want to do is yield Chunks for each field until the boundary is hit, and then yield the data in that Chunk up to the boundary. If the byte subsequence turns out not to be the multipart boundary (such as if it was split between chunks), it needs to be yielded as well. I would prefer to do this without copying the data in the chunks and creating the new ones, if possible.\nI see two potential solutions:\n\n\nAdd an API for creating an owned Chunk which is a subslice into an existing one.  Memslice, which is used internally for server streams (I think), supports this already so is essentially zero-cost, same with the &'static [u8] variant. The other two variants would require copying the data but they appear to be used when the user is providing bodies and so would not be a major cost here.\n\n\nImplement Clone for Chunk so that I can clone chunks and yield a wrapper type which subslices them on deref. The costs are comparable, but the Arc<Vec<u8>> variant would have a trivial cost as well, making Vec<u8> the only costly one, though I don't believe it's relevant to my usage anyway.. What about posix_memadvise and PrefetchVirtualMemory to advise the OS to page-in the mmap'ed region? You could issue that call and then schedule an event for next idle to actually attempt the access, which will hopefully give the OS enough time to perform the operation, or cause the least disruption in case a page fault still happens. The latter call is restricted to Windows 8 or later, I don't know if you'd want to do the threading thing for previous versions or just dereference at idle (or immediately) and eat the cost. . I just realized we're talking about serving files. You can also use posix_fadvise() or set the FILE_FLAG_SEQUENTIAL_SCAN flag when opening the file on Windows, which will advise the OS to pre-cache the file. You could again try to read only on idle so as to limit disruption if the OS can't read ahead fast enough. Reading in chunks the size of a block in the filesystem would also help.\n\n\nAddendum: Linux also has readahead() which immediately initiates a read-ahead into cache (though probably equivalent to posix_fadvise(WILL_NEED) for the same arguments), however the docs say that it may block to read file metadata. If the file descriptor was recently opened, though, the metadata should still be in-cache anyway. . I don't think it's worth worrying about library writers shooting themselves in the foot by falling back on the default type param.\nIt's pretty clear to me that Client::get() should be stuck in its own impl block with the B param as a concrete type:\nrust\nimpl<C> Client<C, hyper::Body> where C: Connect {\n    /// Send a GET Request using this Client.\n    #[inline]\n    pub fn get(&self, url: Url) -> FutureResponse {\n        self.request(Request::new(Method::Get, url))\n    }\n}\n(Or alternately, futures::stream::Empty<[u8; 0], ::Error> as a true no-op stream).\nI doubt you'll get many users who are too lazy to write client.request(Request::new(Method::Get, url))\nbut still want to use their own body stream for the same Client.\nHowever, this leads into a separate concern I have, but one that I don't think will be easy to resolve because it also digs into Tokio a good bit: I don't think Client should be parametric over the body stream, because that prohibits using different stream types with the same Client. If possible, the B parameter should be lowered to the request() method. I do understand that the parts of Tokio that Client interacts with are dependent on the specific stream type, which does make for a bit of a conundrum. I can't help the feeling that this requirement could be lifted somewhat with some more tinkering in Tokio.. This kinda goes for Service as well, I think the trait shouldn't be tied to the specific type of the byte stream, but I don't really have a good idea on how to fix that. I just know that different endpoints are likely going to want to return responses in different ways and the current trait design is going to require some kind of dynamic workaround at the user level, either boxing and type erasure or the use of enum, both of which have their associated costs. . @seanmonstar I mean, I guess if there's no type erasure going on in a deeper abstraction layer that this could be rolled into somehow then the point is moot.. Kind of a naive idea, but I was wondering if there could be some way to have a return stream of Bytes that have been completely read from so the same handles could be reused. This could be done entirely in client code by cloning each Bytes handle yielded and trying to convert them to BytesMut later, but that seems more complex and less efficient. . cc #953 . Closing in favor of posting on #953.. @reem fixed.\n. ",
    "hannobraun": "After thinking about it for a moment, it seems clear to me that the port isn't part of the hostname and thus, serialize_host works correctly.\nI'm working on a pull request to fix this.\n. See #89.\n. > And if the port is 80 or 443, is it omitted? Probably should have a test also. \nNo, it isn't. I believe that always adding the port, even if it is the default one, is correct behavior: http://tools.ietf.org/html/rfc7230#section-5.4\nHowever, I've added more test cases to ensure that Host header is correct, if the port in the URL is omitted.\nOf course we could omit the port if it is the default one, but since it works as is and I wanted to get on with my other work, simplicity won out in this case :)\nDo you want me to omit default ports, or will you merge this as is?\n. You're welcome, and thanks for improving on it!\n. I'm possibly seeing the same issue. I haven't spoken up so far because I'm not sure it's Hyper-related or caused by my own code, and I haven't had the time to look into it yet. But since this issue is open now, I figured I'd chime in.\nIf my issue is Hyper-related at all, it definitely only occurs in connection with OpenSSL. HTTPS requests don't get a reply, while HTTP requests are handled promptly. The issue goes away after a restart.\nThis has been happening every 1-2 weeks since early August, now almost daily since late October. I didn't deploy a new version before the rate started picking up, so it must be related to external factors, too. I don't have traffic statistics at hand, but it can't be much. The page has near zero content and hasn't been announced anywhere, so I'd be surprised if anyone but me and the search engine bots were looking at it.\nWhether the issue is caused by Hyper+OpenSSL or my own code is hard to tell without further inspection, as the only real work is done in response to HTTPS requests. An HTTP request will only return a redirect to the equivalent https:// URL.\n@seanmonstar At the moment this has a very low priority for me, but if you wish, I can take the time to look into it and try to create a reduced test case. To be honest, I kinda hope this will just go away with async Hyper, so I wasn't planning on spending any effort on this, unless I need that website to go live before 0.10 lands.\n. For what it's worth, I've disabled keep-alive some months ago hoping that it would help, but it didn't seem to make any difference. But I'm guessing my issue is different from @e-oz's anyway, since I've never experienced that a restart didn't help.\n. Update from me: I'm going to need that website I'm working on pretty soon now, so my motivation to figure out this issue has increased quite a bit. Unfortunately the frequency of the freezes has gone down since I saw daily freezes in early November, and I'm only seeing the problem every 1-2 weeks now. That makes it harder to figure out what's going on.\nNone the less, I saw my first freeze today since I've pushed a version with more logging. As far as I can tell, all requests that enter my handler also leave it. That indicates the problem originates in Hyper (or below), which is what I suspected anyway.\nI'm going to keep investigating and will check back as I learn more.. At the time of my last post, I deployed a new version with the following changes:\n- Full logging enabled\n- Set read and write timeouts\nThat version froze yesterday. This rules out my suspicion/hope that setting the timeouts would solve the problem.\nAfter a careful examination of the logs I learned some more things:\n- The last successful HTTPS request left Worker::handle_connection (\"keep_alive loop ending for ...\" is logged)\n- All the following requests in the log are successful HTTP request. None of the frozen requests leave a trace in the log.\n- Since all requests in the log start with \"Incoming stream\", I believe the handling thread gets frozen outside of Worker.\nMy plan now is to add more logging to my Hyper fork and deploy that later today. I'll check back once I learn more.. I had another freeze. I think I can confirm that problem is related to, maybe even caused by, OpenSSL. After the last successful HTTPS request I have in the logs, there's a partial requests that stops right before calling wrap_server. \nUnfortunately I made a mistake placing the log messages within my wrap_server implementation, so I can't say anything definite right now, but I do believe that the freeze is happening somewhere within SslStream::accept, which is part of the OpenSSL crate, not Hyper.\nI've already fixed my broken log messages and am going to deploy that fix shortly. If that substantiates my suspicion, I'll try and upgrade the OpenSSL crate to the latest version.. @e-oz I know that Hyper's stuck on 0.7 currently. I plan to upgrade my Hyper fork to the latest version.. @e-oz Thanks for the info. Ideally, I'd like to fix the source of the problem. If that source happens to be rust-openssl, it makes sense to first check if it still occurs in the latest version. If I can't fix it, or the end result is not satisfactory for another reason, I can still fall back to using nginx for HTTPS.\nBy the way, I'm also seeing segfaults, about once per month. Haven't started tracking those down yet :). @seanmonstar No need to thank me. Just doing what I have to, to get that website online. Thank you, for building something that makes it all possible in the first place!. @mikedilger Thanks for the info, although I don't think it applies to my case. I'm not aware of anything in my dependencies that would register those callbacks. Certainly no Python in there. Very interesting bug though :-). Froze again. All evidence still points to SslStream::accept. Unfortunately I found another way how my logs could be misleading. Seems unlilely at this point, but I decided to cover my bases. I just deployed another version with improved logging and will check back once it freezes again.. And it froze again. My suspicions have been confirmed. The thread is definitely entering SslStream::accept and not coming out again.\nI've decided to wait for #985 to resolve before testing with the latest OpenSSL. In the meantime, I'm going to try Rustls [1][2]. Depending on how that goes, I might not even go back to OpenSSL afterwards. Let's see.. Now here's a surprise: 3 days into my Rustls evaluation, the process froze again. Everything looked exactly the same as it did with OpenSSL!\nI don't know what this means. Maybe the issue is with Hyper after all, maybe it's with the operating system, or maybe OpenSSL and Rustls just happen to have the same bug. No idea.\nUnfortunately, when I switched to Rustls, I also upgraded to the latest Hyper release, which means I lost all the extra logging from my special Hyper fork. I'll re-add the logging and will report back once I know more.. @seanmonstar Interesting, so the timeouts are set in Worker::handle_connection after the socket has been passed wrap_server. This seems wrong to me. We might be on to something :-)\nI will test whether setting the timeouts first will solve this problem, but I guess this should be fixed in any case. Do you agree, or am I missing something here?. I'll look into it. At the very least I'll hack something together to verify that this causes the problem, but I'll also try to come up with a good solution.\nWould you want me to create a pull request against 0.9.x pretty soon (I should be able to get it done by next week, at the latest)? Or do you think it would be better to defer this for a bit, until 0.10.x has landed?. @ojensen5115 Not me. I'm using Arch Linux with OpenSSL 1.0.2j. It does sound like the same bug, though.\nOn a related note: I've been running the 0.10.x branch (which includes #1006) for a week now. No freezes yet. Not conclusive at all, but a good sign perhaps (it froze four times in the week before).. As of today, my process has been running for 3 weeks without freezing. This is the longest confirmed uptime since I started tracking this issue in August.\nWhile this isn't firm proof, it's a strong sign that #1006 is indeed a fix for this problem. I welcome anyone who can reproduce this issue to update to the latest release and see if it helps. I'll keep my process running for as long as I can to further confirm this has been fixed, but I may have to deploy a new version soon.. @seanmonstar You're welcome, and thank you for your help. Glad to be rid of this problem (hopefully).. Pushed the fixes suggested by @seanmonstar. Also adjusted a misleading commit title (replaced \"fix(net)\" with \"fix(server)\").. Great, thanks!\n\nOh right, PS, if its at all possible to test that this does help #950 using a git dependency, that'd be great, so we can know if releasing 0.10.1 would be a notable bug fix.\n\nWill do. I'll keep you updated in #950 about what I find out.. You're right. I didn't think this through.\nI think a warn! would be appropriate. Doing nothing would just mean that timeouts would be silently ignored, which could be very surprising to both users and implementers of custom NetworkConnectors. An error! seems too strong to me, as nothing is actually going wrong (yet) at this point.. ",
    "kmcallister": "The idea is to use Hyper on platforms that don't already have a network stack.  I think porting std::io to such a platform, even with the help of picoTCP, would be a lot of work, but I don't know for sure.\nThis would probably involve decoupling the Stream trait from std::io::{Reader, Writer} as well.\n. ",
    "hexsel": "PicoTCP's rust bindings haven't been updated since way before the 1.0 release (2014/12/17), is this still pursuing for now?\n. @daogangtang I'm curious why not put the question on Rust at StackOverflow, or maybe post it on the Rust Reddit, this feels to me like the wrong vehicle for this type of question.\nIf I'm out of place, apologies.\n. ",
    "simonask": "As further info, I can add that a dtruss indicates that both bind, listen and accept get called, after which select is called from inside sys_common::net::await (the standard Rust TCP stack).\n. Sure thing:\n$ RUST_LOG=hyper=debug target/rust-web\nDEBUG:hyper::::server: binding to 127.0.0.1:3000\nAnd that's it\u2026 :frowning: \nEDIT: Trying to connect produces no additional output.\n. Hm, it does not! That would suggest a bug in Rust, right?\n. Wait a second, my mistake \u2014 the example from TcpListener does in fact work (as opposed to my telnet invocation skills). The following outputs \"Hello, World!\" to a connecting telnet instance:\n```\nfn main() {\n  let listener = TcpListener::bind(\"127.0.0.1:3000\");\n  // bind the listener to the specified address\n  let mut acceptor = listener.listen();\nfn handle_client(mut stream: TcpStream) {\n      stream.write(b\"Hello, World!\");\n  }\n// accept connections and process them, spawning a new tasks for each one\n  for stream in acceptor.incoming() {\n      match stream {\n          Err(e) => { / connection failed / }\n          Ok(stream) => spawn(proc() {\n              // connection succeeded\n              handle_client(stream)\n          })\n      }\n  }\n// close the socket server\n  drop(acceptor);\n}\n``\n. Exactly.\n. As you can probably tell, I'm new to Rust, but I'd be happy to help debugging in whatever ways I can. But I guess first of all: Are you or anyone else able to reproduce this behaviour?\n. Alright, I had the same issue with the example, but then I triedcurlwith a Rails app I had lying around, and it gave the same result. Apparently curl fails on all requests to localhost on my machine.wget` and browsers work without issue. I have no clue as to why I'm seeing this behaviour, but the problem seems to be with curl, and neither Rust nor Hyper.\nIt seems I had the following line in my /etc/hosts:\n::1        localhost\nwhich caused curl to attempt an IPv6 connection to localhost, which neither Rust nor Ruby were listening on.\n. Me too \u2014 really, really sorry to have wasted your time!\n. ",
    "tikue": ":) just implemented within the past few days! I didn't give very descriptive error messages for HttpError (lines 225-230 of src/lib.rs). Let me know if you'd like me to improve any of them.\n. Updated to do just that\n. It's possible if you encode the description in the HttpIoError variant; the latest commit does that. It's not particularly pretty, but it works. I'm not sure if this is \"idiomatic,\" since the IoError description is available via HttpIoError.cause().description().\n. Do you mean the trace macro?\n. Cool, should be good to go then!\n. no problen :)\n. These error messages could probably be improved.\n. ",
    "kyledewey": "I won't have the chance to change it anytime soon; I'm fine if someone else does.  I agree that using globs for enum members seems like it would lead to some surprise with respect to the Rust change.\n. ",
    "austinpray": "No problem! \n. ",
    "jimmycuadra": "I am also interested in this for use with the fleet API. At least some Ruby HTTP clients support requests to UNIX sockets, e.g. Excon.\n. That's awesome, softprops! Thank you.\n. Would there be any disadvantages to extracting the status and header modules into their own crates? What about giving them generic (non-\"hyper\") names? It'd be great to have generic types for these concepts in the Rust ecosystem (like we have the url crate) that could be used by downstream crates without having to tie their APIs to anything specific to Hyper.. Different apps may have different use cases, but I think the most common use cases would be the ability to return a canned response for all requests, or specific requests based on properties of the request. In most cases, this would probably just be the URL, but potentially people might have needs to return different responses based on headers, body, etc.\nDo you think a stubbing system would be appropriate to include in hyper? Or as a separate crate? Having test-specific hyper code end up compiled into a non-test binary of someone's app is not desirable, and I'm not sure how rustc treats code marked with #[cfg(test)] in dependent crates. If it's not possible to compile a dependent crate's test code only when the main crate is being compiled in test mode, perhaps the hyper stubbing system would need to be in another crate.\n. Fair enough. Thanks for the responses!\n. I believe I came across this when working on either rust-fleet or rust-etcd, and eventually figured out what was wrong with my connection settings using the logger.\n. I'm -1 on an option to disable verification. Rebuttal to AGWA's two points above: 1) An entire type that does nothing but circumvent verification has a bigger footprint than an environment variable. I don't think making it easy to grep for is a good thing to optimize for. 2) The kind of developer that would do what you're describing will still just copy/paste whatever they read on Stack Overflow, regardless of whether or not the the flag has \"insecure\" in the name.\n. Never mind... I'm an idiot. The commit I linked to was about the server and does not affect the client. What I needed to do was create a let binding to the Request before calling send on it:\n``` rust\nfn request(method: Method, url: String) -> HyperResult {\n    let mut client = Client::new();\nlet request = client.request(method, &url);\n\nrequest.send()\n\n}\n``\n. Could it be because I was attempting to return theResult` without unwrapping it?\n. Isn't hostname verification different than certificate verification?\n. I just posted this on #189, but this issue seems more active:\nWould there be any disadvantages to extracting the status and header modules into their own crates? What about giving them generic (non-\"hyper\") names? It'd be great to have generic types for these concepts in the Rust ecosystem (like we have the url crate) that could be used by downstream crates without having to tie their APIs to anything specific to Hyper.. Maintainers, would you please let us know what your inclination is on this? Is it something you're leaning towards doing? Or is more discussion required before you can answer that? If the plan is for this to happen, would it be possible to do as part of the 0.11 release, or would it be done after that, with 0.11 just focusing on async?\nI ask because we're kind of in limbo on some decisions in one of Ruma's libraries. We're looking for a generic implementation of HTTP methods, HTTP status codes, and HTTP headers. Hyper's types for these things fit the bill perfectly, but we don't want to tie our API to Hyper as-is, with all the other things it comes with. If we know for sure that there aren't plans to split these things out from Hyper, or that they're not even really on the roadmap right now, we can plan accordingly. Thank you!. This also confused me a lot. I'm not convinced hiding documentation is the right way to suggest that people avoid a particular API. If it's implemented at all, it should be documented, otherwise it just causes confusion.\nMy use case is for a trait that abstracts the concept of an HTTP API endpoint, without tying itself directly to Hyper. I was looking for a core/stdlib type so I could do, for example, type Status: Into<u16> in the trait, and then a status could be used to construct a Hyper Status, but could also be used with some other theoretical HTTP library.\nEdit: I meant status, not header.. I'm wondering about sort of the opposite of this. Right now hyper's Client requires a tokio_core::reactor::Handle. It's not clear from the current docs why this isn't generic over all implementations of futures::future::Executor.\nIn the example in the new guides, we see the client being constructed with a handle, but then the future still needs to be executed by calling core.run(work) at the bottom. It's not clear from the example why the client needed a reference to the core's handle if the future is going to be passed to the core to execute.\nMy use case is in designing an API client library that uses hyper underneath. It doesn't feel right to require that users of my library provide a tokio reactor in order to construct a client. Ideally the client would be agnostic to the executor, letting the user decide how the application should do it (synchronous via Future::wait, thread pool, tokio reactor, etc.). Which branch is this for? CowStr doesn't seem to exist in the master branch.. @antoyo See https://github.com/alexcrichton/futures-rs/issues/228. I should have specified: The reason I'm using hyper's Uri instead of the url crate is because hyper::client::Request::new takes a hyper Uri, and there are no conversion traits implemented to convert from a url::Url and a hyper::Uri (without going through an intermediate string form.). Right, but if I'm using strings for URL manipulation it kinda defeats the purpose of having a nice type for them. Would you be amenable to a PR adding simple setters for path/scheme/authority/host/port/query? Or some subset of those?. Or a PR for adding impl From<url::Url> for hyper::Uri?. Still happy to submit code for this if given the go-ahead for any particular approach.. Is impl From<url::Url> for hyper::Uri inappropriate because Url can represent more values than are valid Uris? I see the reference to the HTTP spec in the docs that talks about the URI needing to be one of four specific forms. I was hoping to have an infallible way to convert from Url to Uri, but this doesn't actually seem possible. If it's going to be necessary to check for errors during the conversion anyway, maybe just converting the Url to a &str and parsing it again is the best we can do.. Possible dupe of https://github.com/hyperium/hyper/issues/894?. Similar issue I raised before: https://github.com/hyperium/hyper/issues/1102\nAlthough I understand the motivation for removing Url, it seems users are feeling some pain in not having impl From<url::Url> for hyper::Uri.. Do the changes proposed in the Tokio reform RFC affect this at all?. This would make sense once we have a 1.0, audited, pure-rust implementation of TLS (presumably rustls, but could be something else by the time it happens.) My understanding is that the reason there's no default now is because there simply isn't a cross-platform option that makes sense right now. In other languages, they either assume/require OpenSSL (e.g. Ruby), or have a vetted native TLS implementation (e.g. Go).. Glad to be of help! I have no authority on hyper, BTW, so you might want to reopen your issue for more discussion. I was just adding my thoughts. :}. I was thinking about starting on this work too. My understanding was that the plan was to replace all the existing hyper types with ones from the http crate. Is there a more specific plan or is there any code underway already? Or can anyone from the community just pick this up?. Personally, I'd much rather see hyper's (now redundant) types disappear completely in 0.12. My impression is that people using Rust and hyper at this point understand that the HTTP stack is not stable yet, and that making breaking changes where it's clearly needed is expected in order to push us towards 1.0.. It is out of the question to just wait for futures 0.3 before releasing hyper 0.12?. Another way to look at it... Given:\n\nThe ecosystem is in major flux right now\nAnyone who's paying attention knows everything is pretty unstable until Rust 2018 in September\nfutures has just set precedent for releasing a new version at the same time as announcing that its replacement is imminent\n\nit's pretty reasonable to release an 0.12 as is. And maybe announce, similarly to futures, that an 0.13 will be coming sooner than it's been between previous versions of hyper.. ",
    "softprops": "This may be of interest to you folks. I just published a new crate called hyperlocal which provides hyper interfaces for unix domain sockets. I realized that while working on a docker client which also supports unix domain sockets that I could support both tcp and domain socket interfaces using hyper's client interface. I'll be rolling hyperlocal into that soon to replace the hand crafted http unix domain socket interface I'm currently using.\n. I really want to emphasize how well designed hyper's internals were made. It made it very straight forward to extend it in this way. +100 @seanmonstar \n. FYI, I'm planning on adapting to hypers interfaces for uds in https://github.com/softprops/hyperlocal as soon as there's a new release for hyper. Hi there. I'm open to prs for if anyone needs a change https://github.com/softprops/hyperlocal/blob/master/README.md. I have a crate that supports tokio uds in the meantime https://github.com/softprops/hyperlocal. Yes please :) \n. Wow. Super simple. Thanks!\n. Just a quick followup. I wanted to make sure request bodies were encoded correctly and I found a library for doing form encoding but I'm stumbling on what may be some basic rust basics\nBuilding your example above I'm still running into some rust newbie issues\n``` rust\nextern crate url;\nuse url::form_urlencoded;\nlet mut builder = client.post(\"https://example.domain/path\")\nlet params = vec![(\"foo\", \"bar\")];\n// this fails with the following compiler message\n// error: the trait hyper::client::IntoBody<'_> is not implemented for the type collections::string::String [E0277]\nlet body = form_urlencoded::serialize(params.into_iter());\nbuilder.body(body);\n```\nI found the IntoBody trait impl that seems to point to basic string slices\nso I tried to slice up the String form_urlencoded::serialize returns and I get a borrowing error\n``` rust\nextern crate url;\nuse url::form_urlencoded;\nlet mut builder = client.post(\"https://example.domain/path\")\nlet params = vec![(\"foo\", \"bar\")];\n// this now fails because\n// src/main.rs:48:15: 48:61 error: borrowed value does not live long enough\n//src/main.rs:48    let body = form_urlencoded::serialize(params.into_iter()).as_slice();\n//\nlet body = form_urlencoded::serialize(params.into_iter()).as_slice();\nbuilder.body(body);\n```\ndo you have any pointers for what I'm maybe doing wrong?\n. without the as_slice() and with  &. I still run into the missing IntoBody impl for String\nrust\n//src/main.rs:50:12: 50:23 error: the trait `hyper::client::IntoBody<'_>` is not implemented for the type `&collections::string::String` [E0277]\n//src/main.rs:50    builder.body(&body);\nlet body = form_urlencoded::serialize(params.into_iter());\nbuilder.body(&body);\nadding the as_slice()\nrust\n// src/main.rs:49:12: 49:34 error: the trait `hyper::client::IntoBody<'_>` is not implemented for the type `&&str` [E0277]\n//src/main.rs:49    builder.body(&body.as_slice());\nlet body = form_urlencoded::serialize(params.into_iter());\nbuilder.body(&body.as_slice());\nI feel like I'm probably missing something very fundamental.\n. it looks like *body does give me back a str but adding the & gets me back to \"error:  body does not live long enough\"\nHere's a more cut & paste example\n``` rust\nextern crate hyper;\nextern crate url;\nuse hyper::{ Client, Url };\nuse url::form_urlencoded;\nfn main() {\n  let mut client = Client::new();\n  let uri = Url::parse(\"https://api.service.com\").ok().expect(\"malformed url\");\n  let mut builder = client.post(uri);\n  let params = vec![(\"foo\", \"bar\")];\n  let body = form_urlencoded::serialize(params.into_iter());\n  builder.body(&*body);\n}\n```\n. @Ryman @seanmonstar thanks for rounding this out for me. I got up an running after following @Ryman's last suggestion. Thanks for your patience.\n. I updated my cargo config to point to\ntoml\n[dependencies.hyper]\ngit = \"https://github.com/renato-zannon/hyper.git\"\nrev = \"124a31fb9b7363960bebbdcf71df9e1e1cb0e075\"\nMy compiler errors/warnings went down to the following afterwards\nrust\nerror: the trait `core::marker::Send` is not implemented for the type `<str as collections::borrow::ToOwned>::Owned` [E0277]\n _assert_send::<client::Request<net::Fresh>>();\nnote: `<str as collections::borrow::ToOwned>::Owned` cannot be sent between threads safely\n _assert_send::<client::Request<net::Fresh>>();\n. Thanks for patching this up quickly. You guys are awesome\n. Oh well just saw the other pr which also addresses this\n. just ran into the same issue :/\n. Yep, I'm depending on git revs for now\ntoml\n[dependencies.hyper]\ngit = \"https://github.com/hyperium/hyper.git\"\nrev = \"2ce4385c163e1a9a393c89743cf04e047b776e83\"\n. Thanks again for you patience @seanmonstar\n. I guess the server communicating with rejected anything less than [https://github.com/sfackler/rust-openssl/blob/master/openssl/src/ssl/mod.rs#L99]. I say the other pull but it looked like it only addressed the server side of the issue. The client side connectors still have the ssl method used hard coded :/\n. Yea thinking about making this backwards compatible would probably involve some additional interfaces that allow you to specify which ssl method to use, this may help answer your question. I'm open to help take that on. I imaging it would be similar to the change to http listeners translated for network connectors\n. going to close this in favor of a more flexible solution for NetworkConnectors in the future.\n. for what is worth this is the http response I got on my older laptop https://gist.github.com/softprops/020f54f1a6461643288e\nNote the \n\"rating\":\"Bad\"\nat the tail end\n. So if any future osx'ers run into this issue, I hope this helps. It would have saved me an evening of chasing the answer down.\nIf you refer to openssl's readme it makes a reference about a few env variables you should take note of. Assuming you're using homebrew to upgrade osx's factory provided openssl to a sane version. You can do the following\n``` bash\nmake sure your cargo cache is clean to force a recompile of openssl\n$ cargo clean\ncompile your crate with OPENSSL env vars pointing to brews updated lib and incude dirs\n$ OPENSSL_LIB_DIR=$(brew --prefix openssl)/lib  OPENSSL_INCLUDE_DIR=$(brew --prefix openssl)/include cargo run\nonce openssl is build you no longer need to include them\n$ cargo run\n``\n. I'm trying to update a project to the latest versions of its dependencies includinghyper` but am running into an issue that I think was a breaking change in this pull. There used to exist a client.set_ssl_verifier which I used here. This method seems to have went away, but I can't find the current alternative. Does one exists in the latest release?\n. I think I figured it out\nrust\nlet client = Client::with_connector(\n  HttpsConnector::new(\n    Openssl {\n      context: Arc::new(\n        ssl_ctx // <- I create this now\n       )\n    }\n  )\n)\nthis factory method want's quite what I needed but enough to steer me in the right direction.\nGreat work on pushing this library forward.\n. I'm not sure I can run that down stream. I hit this build error\n``\nnative libraryopenssl` is being linked to by more than one package, and can only be linked to by one package\nopenssl-sys v0.6.4 (https://github.com/sfackler/rust-openssl#69cbd145)\n  openssl-sys v0.6.4\n```\nthis may be related to that?\n. scratch that. I just needed to turn off hypers default-features flag to force my local dep to take priority\nNow when I run the same code for an https url I get a different error\n``` rust\n![feature(duration)]\nextern crate hyper;\nuse hyper::Client;\nuse std::io;\nuse std::time::Duration;\nfn main() {\n  println!(\"test\");\n  let mut client = Client::new();\n  client.set_read_timeout(Some(Duration::from_millis(10)));\n  let mut res = client.get(\"https://google.com\").send().unwrap();\n  let _ = io::copy(&mut res, &mut io::stdout()).unwrap();\n}\n```\nthread '<main>' panicked at 'called `Result::unwrap()` on an `Err` value: Io(Error { repr: Custom(Custom { kind: InvalidInput, error: StringError(\"Invalid scheme for Http\") }) })', ../src/libcore/result.rs:732\nI suspect because I just opted out of hyper's default features in my build\n. I can't seem to the right combination of cargo config options make this happen. Can you provide an example?\n. okay. worked it out by cloning rust-openssl next to my project then creating a .cargo/config file with\npaths = [\"/abs/path/to/rust-openssl\"]\nnow the errors are without https\nthread '<main>' panicked at 'called `Result::unwrap()` on an `Err` value: Io(Error { repr: Os { code: 35, message: \"Resource temporarily unavailable\" } })', ../src/libcore/result.rs:732\nand with https\nthread '<main>' panicked at 'called `Result::unwrap()` on an `Err` value: Io(Error { repr: Custom(Custom { kind: TimedOut, error: StringError(\"socket read timed out\") }) })', ../src/libcore/result.rs:732\n:+1: @sfackler \n@seanmonstar thoughts aligning the non ssl timeout request err  with a similar err kind? Ideally something like io::ErrorKind::TimedOut would make it easier to handle these errors consistently\n. For what it's worth\n35 seems to be mapped to 2 errors in libc. In rusts io module these seem to map to a  ErrorKind::WouldBlock so I'm not sure if this mapping is actually a bug in rust itself. TimedOut errors are mapped here to the ETIMEDOUT const in libc. os code 60 ( shrugs ). \nsuggestions?\n. Cool thanks\n. @sfackler I tried my little test app with your latest commit and now get a consistent error for both https and http requests in hyper.\nthread '<main>' panicked at 'called `Result::unwrap()` on an `Err` value: Io(Error { repr: Os { code: 35, message: \"Resource temporarily unavailable\" } })', ../src/libcore/result.rs:732\nI would prefer a TimedOut error to an opaque Os error if possible\n. Is the something that could be stablized in the feature flagged socket timeouts in rusts std lib?\n. The error to expect when setting read write timeouts. I'm really excited to see this implemented but I'm finding little in the way of docs for how to handle timeout errors\n. Ok. I know its common in some rustdocs to have a panic or errors section to document how to handle errors. I'll see if I can't find someway to get these documented somewhere outside of gh issues comments and pull diffs :) \n. I totally get the thing about expanding surface area and documentation. \nFrom a library user's perspective though, I'd say it's not awkward because client.request(Method::Patch, ...) is hard to type. It's awkward because because it's inconsistent with the rest of the hyper's provided client api. \nIf the other HTTP method helpers were added as \"convenience\", at some point, I'd assume it was decided that client.request(Method::Get, ...) was an inconvenient interface. The lack of a the same convenience when trying to accomplish the same task led to a sense of inconsistency for me. That's what felt awkward. \nIn particular, I'm interface with Github's api which uses PATCH extensively, if not exclusively, for partial updates to resources.\n. I'm also not trying to be argumentative. I'm just trying to provide a consistent experience for future hyper users :)\n. > when a user goes to the Client doc page, does extra convenience methods help, or provide noise\nIf its of any value it was the lack of a doc for this method that forced me to read through the source code to figure out the method didn't actually exist. As a user, it just felt like it should exist.\n. It's that kind of inconsistency that makes it's absence feel awkward.\n. thanks @seanmonstar !\n. Hrm. It looks like this pr failed the build checks but the error looks unrelated to the error. Does this look familiar?\n. Woot! Thanks so much for such an awesome project @seanmonstar I can't wait for the async stuff\n. Would love to see setters for encoding query parameters. And also a getter for query params pairs. @seanmonstar thanks for responding. Awesome work as always. I like the extra effort  make to\nsure this interface is as ergonomic as it can be. I know there has been a ton of iteration on the async interface. It was worth it. Looking forward to the next release.\n@mgattozzi thanks for the link. I'm actually in the procress of refactoring my github client to use the master branch of hyper before it's release. I've got a lot of work to do! But I really like what I'm seeing so far.\nClosing this issue since I think my questions were answered.\nThanks guys!. I was just going to open an issue about server side read write timeouts. Would any of the potential solutions above also cover servers?. Nice. What are the chances of something like this landing in hyper itself?. Makes sense. Amazing. Thanks for the fast feedback and for such careful and thoughtful design choices. Hyper continues to be a source of inspiration for me. . If anyone happens upon this thread and is curious, https://github.com/softprops/hyperlocal/ is the result of that migration. thanks @seanmonstar!. Makes sense. Thanks for the response!. @jimmycuadra I just realized who you were! I just today took some inspiration from your etcd crate on how to use cargo feature to add a optional default tls impl https://github.com/jimmycuadra/rust-etcd/blob/master/Cargo.toml. I was mainly looking on for some direction for some ergonomic solutions but I think I found the perfect example in your crate :). Thanks. I think that gives me some ideas!. @srijs I just tried this and actually this works amazingly as-is for my usecase. Would it be okay with you if I I wrapped this up in a crate? I can't be the first person to hit this problem and I'm sure I wont be the last.. Thanks man. Thanks for contributing to the rust communities awesomeness score!. sweet! thanks for the update. ",
    "myfreeweb": "Would be nice if hyper itself could listen on unix sockets, without an additional crate.\nIt also should support listening on user-provided (already opened) sockets (for both tcp and unix), e.g. acquired via socket activation or file descriptor passing.\nActually I think socket activation should be handled in hyper itself as well\u2026 even though there's a brilliant pun opportunity for naming a crate that does it ;-). > hyper's goal is provide HTTP, and be generic over whatever the transport is underneath\nWell, it has a bind method that starts a TCP listener\u2026\nLooking at the master documentation, bind_connection seems like the right API though :). Yeah. And looks like there's still no easy way to provide a custom TcpListener/UnixListener (e.g. from listenfd).. ",
    "prepor": "It's an essential feature for http client library, most popular http client libraries support it. We also have already have support of unix sockets in tokio (https://github.com/tokio-rs/tokio-uds). Is there a chance that such feature will be accepted in case of PR?. @seanmonstar ok, hyperlocal of @softprops looks good, waiting for a release ;). ",
    "25519": "@seanmonstar, can you please reopen this? I wanted @softprops's hyperlocal server to support run_until so I implemented it. The file is almost entirely copy+pasted from a subset of this one in hyper but with UnixListener instead of TcpListener. I think it would make a lot more sense for hyper::server::Server to just have a type argument for listener instead of TcpListener.\nTo avoid breaking changes perhaps we could have a Server2<S, B, L> with listener: L and Server<S, B> = Server2<S, B, TcpListener> or something to that effect.. ",
    "portstrom": "I find it strange and surprising that Hyper doesn't support Unix domain sockets. It's a basic and very well-supported feature in any descent programming language (i.e. not Java). Node supports it. Python supports it. I use it a lot for running various services proxied behind Nginx. The crate hyperlocal depends on an old version of Hyper. If I were to change to TCP sockets I can't even set permissions. Please reopen.. ",
    "olix0r": "Now that Hyper uses a recent Tokio, it should definitely be possible to instrument Hyper around tokio-uds. Whether this belongs as a part of Hyper or just a recipe that can be shared, i have no opinion.. In the specific case I'm encountering, Conduit is proxying an HTTP/1 request with a Hyper server and client.\n\nThe client receives a response (and Body) and returns it to the server.\nWe wrap the client's body type with an implementation that does some extra accounting. \nWhen we poll_data the underlying body, we get data that matches content-length.\n\nAt this point I expect that body.is_end_stream() should return true, but it does not.\n\n\nAfter a poll, is_end_stream claimed it was done.\nThe headers (or the content_length method of the payload) declared a length, and the state machine detects the length has been reached. Any extra chunks would be wasted.\n\n\nIs it a bug that body.is_end_stream() returns false even though the complete body data has been returned from poll_data?. @sfackler thanks for the clarification!. ",
    "sfackler": "@myfreeweb \nrust\nunix_listener.for_each(|(socket, _)| {\n    let connection = Http::new().serve_connection(socket, MyService);\n    tokio::spawn(connection);\n    Ok(())\n});. I've started prototyping this: https://github.com/sfackler/typed-headers. You don't have to change anything, actually. If you have something like\ntoml\n[dependencies.foo]\npath = \"../thingy\"\nversion = \"0.1.0\"\nIt'll use the local version when building manually, but look for ^0.1.0 on crates.io when publishing. All you have to do is make sure the versions stay synced.\n. You can use any of the version string configurations you'd normally be able to do: http://doc.crates.io/crates-io.html#using-crates.io-based-crates\n. Seems like this can be closed.. Seems reasonable to me. I think it'd take manual intervention for people to be able to take advantage of HTTP/2 anyway, since you'd need to poke at ALPN in the handshake and then tell Hyper which protocol to use.. That should work, yeah, but it's unfortunate that there's that out of band signaling of what you're blocked on. Maybe there should be a tweaked Read trait that could return the proper information?\n. An easy approach would be to make your own implementation of SslClient that avoids the check.\n.  @maximih Hyper already allows all of the configuration you asked for by manually configuring the Openssl object: http://hyper.rs/hyper/v0.9.6/hyper/net/struct.Openssl.html\n. The version of openssl that ships with OSX is v0.9.8zd, which does not include TLSv1.2 support. As a result, TLSv1.2 bindings are opt-in in rust-openssl via the tlsv1_2 Cargo feature: https://github.com/sfackler/rust-openssl/blob/master/openssl/Cargo.toml#L13. If you want to use it, you'll need to install a newer copy of openssl and link to that instead.\n. It's a bug in SslStream's error handling. I will push a fix.\n. This should fix it: https://github.com/sfackler/rust-openssl/commit/69cbd145407288e3b22b7336fe6a679546b4b2fd\nCan you run the test against that and see if it resolves the issue?\n. I picked TimedOut basically arbitrarily. OpenSSL doesn't formally expose the underlying error so I had to just pick one. It might be the case that errno is preserved, in which case I can just return io::Error::last_os_error(), but that doesn't appear to be guaranteed anywhere in the docs.\n. Ok, try now.\n. The Os error isn't visible in the API, just the Debug output. io::Error has a kind() method which will return an io::ErrorKind variant that you can look at, though on Linux it'll be WouldBlock rather than TimedOut.\n. That would probably seem weird to linux users.\n. I tend to go with something like\nrust\nimpl fmt::Display for Error {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        try!(f.write_str(self.description())\n        match *self {\n            AllThingsWithInnerErrors(ref e) => write!(f, \": {}\", e),\n            ....\n        }\n    }\n}\n. Ah, great!\n. I am uncomfortable with option 2, particularly because I do not want to be the person on the hook to rush out an updated release with the download link changed to a new version when the next Heartbleed is inevitably found.\nCommon Crypto is part of security.framework so functionality for it would fall under the security-framework crate. Bindings for e.g. SecKey are already there, but the relevant encryption methods haven't yet been exposed.\nHyper's encryption support is already generic through the Ssl trait, though the implementation for the secure transport crate doesn't exist yet, and I think the trait definition should probably be tweaked a bit to make it work in more use cases.\nOnce rust-lang/rfcs#1361 lands, it'll be possible to switch SSL backends based on the target in a sane way.\n. Ah thanks\n. toml\nhyper = { version = \"0.9\", default-features = false, features = [\"security-framework\"] }\n. @kballard I'm close to publishing https://github.com/sfackler/rust-native-tls which should handle all of that and I believe we'll be able to make the default SSL backend for hyper.\n. The ssl feature has been removed, so I believe this issue can be closed.. Looks like this is blocked until the Clone requirement is dropped.\n. @novacrazy Hyper previously didn't validate a server's certificates at all. This is super bad. That was fixed, but openssl doesn't know how find a trusted certificate list on Windows by default, hence the errors, since there are no trusted roots.\n. This was not caused by the addition of hostname verification - if your company's self signed certs are set up in a reasonable way, the hostname check should pass just fine. It was caused by Hyper changing from completely ignoring the contents of the certificates the server sends to actually looking at those and seeing if they're trusted.\nI'm not sure I understand why you'd have to switch to curl to fix this - curl requires manual intervention in almost exactly the same way that Hyper does - you'll need to add those self signed certificates to OpenSSL's trusted set with something like http://sfackler.github.io/rust-openssl/doc/v0.7.13/openssl/ssl/struct.SslContext.html#method.set_CA_file for Hyper and --cafile for curl.\n. I have a PR open to implement this: #1232.. Awesome thanks!\nOn Wed, Mar 15, 2017 at 7:40 PM Sean McArthur notifications@github.com\nwrote:\n\nI just ran some updated tests in hyper and confirmed that this is fixed.\nSince there is no needed code to change in hyper, I'm going to close\nwithout a PR.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/885#issuecomment-286941361, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ABY2UWVhMlCPKpZ0fhTKiW_dd6vA1PrNks5rmKEEgaJpZM4JfUce\n.\n. I don't believe ring implements TLS.. The https://crates.io/crates/hyper-rustls crate provides RusTLS support for Hyper. I don't think it makes sense to default to RusTLS at the current time, though, since its supported feature set is pretty small. It doesn't support DHE key exchange, AES modes other than GCM, and protocols other than TLSv1.2. This means, for example, that it can't talk to Java 1.7 or lower.. The getaddr info leak is a valgrind bug. The subject_alt_names leak is from a rust-openssl bug that's fixed in openssl 0.8 and 0.9: https://github.com/sfackler/rust-openssl/commit/e5299fd7c9661579d6de30a5be5b032a90203c95. I think this is a reasonable approach.\n\nOne minor nit: the -sys crates used by schannel and security-framework don't have the same limitations as openssl-sys, since they're linking to system libraries and don't need to worry about the double-link issue.. This'd also require dropping the dependency on the cookie crate, right?. The ssl feature was intentionally removed: #985. I think this has been resolved by https://docs.rs/hyper/0.12.1/hyper/server/conn/struct.Connection.html#method.poll_without_shutdown, right?. Noticed that a project was pulling in two versions of traitobject.. I think this is also a problem on the tokio version.. Thanks! Could you cut an 0.10 release with this when you have a chance?. One thing I'd like is to differentiate IO errors based on where they came from. I care about connect errors in particular, since you can retry the request on a different host if you can't connect to one of them, even if the request isn't idempotent or you have a body you can't reset.. @dekellum Just because the Client's future returns a hyper::Error doesn't mean your future that works off of that has to return a hyper::Error. client.get(\"http://google.com\").map_err(|hyper_error| MyErrorType::from(hyper_error)).. Like this?\nrust\nresponse.body().map_err(|hyper_error| MyErrorType::from(hyper_error)).for_each(Fn). I don't understand. for_each passes the closure a Chunk, not a Result. It never sees the error that is transformed by the map_err.. You can use map_err to transform the error type of the stream. The Fn passed to response.body().map_err(|e| MyErrorType::from(e)).for_each(Fn) must return a Future<Item=(), Error=MyErrorType>, not a Future<Item=(), Error=hyper::Error>. This is specified by the futures crate's Stream trait, not hyper.. Unless something's changed since the RFC, #[non_exhaustive] generates a hard error, not a warning if you try to exhaustively match against of an enum outside of the crate it's defined in.. HttpConnector is defined as a unit-struct, so it unfortunately can't support a connect timeout without a breaking change, but everything's luckily pluggable so it should be straightforward to make a connector that wraps the connect/select dance: https://hyper.rs/hyper/v0.10.11/src/hyper/net.rs.html#393. I've implemented this: https://github.com/sfackler/hyper-timeout-connector\nWaiting on https://github.com/alexcrichton/socket2-rs/pull/1 to be merged before it can be published, though.. This is now published: https://crates.io/crates/hyper-timeout-connector. Cool, no worries. The 100 Continue is always sent immediately because tokio-proto tries to load the first bit of the body, but that's better than nothing!. I don't agree with that rationale. Even blindly returning 100 Continue is way better than not. Without this change, curl http://localhost:1337/echo -F foo=bar takes 1.01 seconds against the example echo server since it sits around for a second waiting for a 100 Continue that never comes.. Yeah, I was trying to figure out the right way to test this. Client support is something I'd love to have, but it's a bit more complex than the server side - you have to wait on the continue with a timeout in case the server doesn't know how to handle Expect: 100-continue, and resend the headers without the Expect if the server returns a 417. Manually driving the client side against a raw TcpStream seems like a decent option.. Updated with tests. Thanks!. I wrote up a little crate handling read and write timeouts via the standard tokio-core timer: https://crates.io/crates/tokio-io-timeout. I've added implementations of read_buf and write_buf.. @softprops the tokio-io-timeout crate can handle them if you manage the server accept loop manually. Example: https://github.com/sfackler/foo/blob/master/src/main.rs#L53. You can stick the IP address into the URI and no DNS resolution will be performed.. https://github.com/tokio-rs/tokio-proto/issues/176. Nope. @kamalmarhubi https://github.com/tokio-rs/tokio-rfcs/pull/3 has some background.. As an example, cat /dev/zeroes | curl http://some-server will run forever with zero ability to change that behavior.. @seanmonstar pointed out that a simple way of doing this is to add a method to disable keep-alive on Connections. Then, Service::drop-based tracking will be accurate.. Is there any particular reason you need to pull the header from the Hyper crate specifically?. @seanmonstar could you reopen? We still need to handle the client side.. Yep, looks like it is!. Yeah - we can either have idle connections constantly waiting on reads, or at the very least just perform a single nonblocking read on the connection when pulling it out of the pool. Anything other than a WouldBlock indicates that something has happened and we should throw the connection away.. Yeah, it seems like it'd be okay to either have the HEAD request report a protocol error, or just have the connection close out in the pool due to unexpected data.. Welp, this turns out to have been a PEBCAK. I was returning the serve_connection future into my for_each loop rather than spawning it, so exactly one connection was running on a selector thread at a time... >_>. Ah cool - I was working against 0.11.7, but I'm also seeing the right behavior with master!. It seems like racing pool checkout with opening a new socket would do this since a new connection can begin to connect, but the code doesn't complete that work if the pool checks something out: https://github.com/hyperium/hyper/blob/master/src/client/mod.rs#L202. Ah cool - I was working against 0.11.7, but I'm also seeing the right behavior with master!. This currently only allows you to disable keepalive rather than providing a toggle since the only use case I'm aware of involves turning it off and it seems a bit less risky to go in that direction only.. Nice catch - fixed and added a test for that case as well.. HTTP/1.1 connections are assumed to be kept alive unless otherwise stated with a Connection: close: https://tools.ietf.org/html/rfc7230#section-6.3.\nWhy do you think it's trying to read a Connection header? It's already read past the headers into the body, so more headers are definitely not going to be sent.. Ah, the issue is that ab is sending an HTTP/1.0 request but Hyper's responding with an HTTP/1.1 response. I think this is the same as https://github.com/hyperium/hyper/issues/1304.. no_proto isn't the default.. On second thought, I don't think this is a good idea.. The error seems to be nondeterministic and larger responses have a higher chance to get wedged so I think it's some specific IO state that causes the issues.. Ah, we were on 0.11.7 and I can't seem to repro on 0.11.9. Any idea what the fix was?. Seems like it's probably https://github.com/hyperium/hyper/commit/121b5eef19e65acfecb8261d865554e173f2fc78 right?. Cool, thanks!. Did you use futures::Stream?. ```rust\nextern crate env_logger;\nextern crate tokio_core;\nextern crate hyper;\nextern crate futures;\nuse hyper::{Client, Request, Method};\nuse hyper::header::Connection;\nuse tokio_core::reactor::Core;\nuse futures::{Stream, Future};\nfn main() {\n    env_logger::init();\nlet mut core = Core::new().unwrap();\nlet handle = core.handle();\n\nlet client = Client::new(&handle);\n\nlet mut request = Request::new(Method::Get, \"http://www.google.com\".parse().unwrap());\nrequest.headers_mut().set(Connection::close());\n\nlet f = client.request(request)\n    .and_then(|r| {\n        r.body().concat2()\n    });\n\nlet _ = core.run(f).unwrap();\n\n}\n```\nERROR 2018-01-09T23:04:57Z: hyper::client: client connection error: unexpected EOF waiting for response. It looks like it first appeared in 0.11.8 (with no_proto turned on there of course).. What is this protecting against?. Oh, nevermind. I see.\nIt seems really bad that this is reading 16 bytes at a time. That buffer should be like 1000 times larger than it is.. Do you know what these kinds of APIs look like in other HTTP client libraries?. Why do you say it's incorrectly reusing the stream? Does the response contain a Connection: close?. You can use the Stream.forward method to write a stream to the mpsc sender.\nOn Sun, Feb 4, 2018 at 10:10 PM Matt Hauck notifications@github.com wrote:\n\nIt is a bit unfortunate that as far as I can tell the only way to set a\nresponse body is by having the entire request body in memory. The one\nexception perhaps is setting a body with a futures::sync::mpsc::Receiver,\nwhich is a bit clunky. It would be very cool to just be able to assign\nsomething that implements Read or Stream or something.\nUse case: streaming a large file directly into a request or implementing\nan http proxy.\nMaybe there's something there that I'm missing?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/1436, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABY2UZTrbzqg7TWk4yk3Cx8TBttAelQYks5tRps8gaJpZM4R49mW\n.\n. I think content_length might be a better name than size_hint - its semantics and intended use case is pretty different than that of an iterator's size_hint. It'd probably also be good to note that it only needs to be correct if called before any data is streamed, but you don't need to keep it up to date with the amount of data remaining.\n\nI like the idea of merging the data poll method and trailers poll method into one that essentially acts like a Stream<Item = FrameItem>.. Why can't you deprecate the variants?. It seems like there will always need to be a variant for body data and one for trailers though, right?. But wouldn't adding a type parameter break back compat anyway by adding a new associated type?\nThinking more about it, should content_length even be a method on Body? It can always just be set explicitly in the headers, right?. Can't you just make a URI to the proxy and use HttpConnector to connect to it?. This would be great!. If we made Parts implement Read/Write that could be a decent way of handling upgrades in a non-footgunny way. You could manually grab the existing buffered data and stream out separately or just use the type itself as the stream for the upgraded protocol.. This doesn't have anything to do with hyper. Those errors are coming out of the first two lines of that function. The JSON string passed to it needs to be UTF-8 encoded, but it seems like the encoding it's using is something else.. I was initially thinking that the best route would be something like a Destination::negotiate_h2 method that would tell the connector to use ALPN, but I think it might actually be best to just have the connectors always use ALPN and just tell the Connected what protocol was selected. native-tls and openssl don't currently support configuration of ALPN on a per-handshake basis, and while we could add that it's kind of a weird thing to do.\nThis would require configuration of both the TLS connector and the client if you want to use only HTTP/1 but that seems fine since I think that'd be a pretty rare use case?. Here's what I think a reasonable route forward is:\nPublic API changes:\n```rust\npub struct Protocol(...);\nimpl Protocol {\n    const HTTP1_1: Protocol = Protocol(...);\n    const HTTP2: Protocol = Protocol(...);\n}\nimpl Connected {\n    pub fn negotiated_protocol(self, protocol: Protocol) -> Self { ... }\n}\n```\nIf a connector indicates that it has negotiated a protocol, Hyper has to respect that. If HTTP/1.1 is negotiated but the client was configured with http2_only, it'll have to return an error.\nThe pool implementation will need to change, since it currently depends on knowing up-front which protocol will be used. The constraint that only a single HTTP/2 connection attempt can exist at any time since we don't know if the connection will be using HTTP/2. It seems like a reasonable approach is that the pool's key type is just the authority, and the value is an enum of either a single HTTP/2 connection, or a set of idle HTTP/1.1 connections. The HTTP/2 mode is preferred, so if a new connection comes in that negotiated HTTP/2, it'll replace any existing HTTP/1.1 connections.\nDoes this all seem plausible? I can start working on the implementation if so.. Yeah, negotiated_http1 and negotiated_http2 seem reasonable to me as well.\nI'm not sure it'll be all that useful for the connector to know that http2_only was set. It seems pretty weird to have a server that supports h2 but prioritizes http/1.1 over it.. Yeah I think you'll need to explicitly configure ALPN for hyper-openssl at least for it to be used at all initially.. The changes required in the connection pool are pretty significant, so I want to write them out and make sure it seems reasonable before making them.\nThere are a couple of constraints we want to enforce:\n\nWe don't want to allow multiple live HTTP/2 connections to a single host.\nWe want to allow concurrent creation of new HTTP/1 connections to a single host.\n\nThe pool currently just tracks the set of pending HTTP/2 connections to guarantee constraint 1, and you ask the pool for permission before making a new connection. This becomes more complicated now since we don't know up-front what protocol we're going to be using until we get part way through the connection process.\nThere are a couple of options:\n\nDefer the pending connection check until ALPN tells us what protocol we're using.\nSerialize the first connection to a host of any protocol.\n\nImagine we're spawning off N requests at the same time to a new host. Option 1 is non-ideal in the HTTP/2 case since you'll perform N TCP and TLS handshakes, then throw away N-1 connections and perform a single HTTP/2 handshake. Option 2 is non-ideal in the HTTP/1 case since you'll have N-1 requests queue up behind a single request that performs the first TCP and TLS handshake, realizes the server speaks HTTP/1, and then the other N-1 requests can create their own connections.\nOn the whole, option 2 seems preferable.\nThis does mean we now need to track what protocol a host speaks. In particular, there's a distinction between a host we've never connected to and a host that has all of its HTTP/1 connections currently checked out. For simplicity, I'd like to just track that information \"forever\", even after idle connections have been cleared out.. Sure, there could be an option to open a second connection if the first has no remaining request slots.. That sounds reasonable to me.. I already use Bytes for my body implementation, so this'll be fine for me!. I've seen the \"protocol unavailable\" message once before myself but I can't remember what the context was unfortunately.. The associated future type for a service is going to either be a Box<Future> or be unique to every implementation. Consumers shouldn't generally care what the specific future type is.. > At the moment, I can't write a method that can consume either a hyper:client::Client or my new wrapper,\nWhy not?\nrust\nfn foo<T>(service: T)\nwhere\n    T: Service<Request = hyper::Request<hyper::Body>, Response = hyper::Response, Error = hyper::Error>\n{\n    // ...\n}\n. You can't assume they'll always be polled to completion because e.g. the client may have disconnected before the whole body could be sent.\nProcessing updates on drop is definitely the more reliable option.. is_end_stream is a hint:\nhttps://github.com/hyperium/hyper/blob/c3c35e866c06d8d0f7347cebff86b0442b33e2b3/src/body.rs#L57-L70. Are you using an old version of OSX? There's a bug in some versions of the linker which can cause crashes when interacting with thread locals: https://github.com/rust-lang/rust/issues/50586. I wrote a test, but something seems broken - Hyper's sending what looks like an HTTP/1.0-style EOF delimited request but with a version of HTTP/1.1:\n\n. Oh derp, i'm sending a get with a body... That's just cause2().and_then(|e| e.downcast_ref::<io::Error>()) - not sure that needs to be a whole separate method.. It seems pretty implausible to me that IO errors would suddenly start being wrapped in other things. IO errors aren't the only kinds of errors you'd want to introspect anyway, and the approach of adding a method for every error type doesn't scale to arbitrary user defined types.. This seems to flake, but only on x86_64 windows which is pretty weird..... ~I can't seem to repro locally on a Windows install :(~\nEDIT: nevermind!. Ah this seems to be busted on master as well.. Does that patch compile? The server runs in a thread pool in 0.12 so futures can be sent from one thread to another.. Ah right, server doesn't manage its own event loop anymore.. This would be nice for me as well. In hyper 0.11, I had a \"stack\" of composed connectors: HttpsConnector<ProxyConnector<HttpConnector>>. The ProxyConnector handled CONNECT tunneling for HTTPS proxies, and so needs to tell the underlying connector to point to the proxy address. In 0.12, that isn't currently possible so I ended up using a non-connector type under the ProxyConnector that just took a host/port.. The fact that there's a URI inside of the Destination is currently an implementation detail, so I'd expect just pub fn set_host(&mut self, host: &str) -> Result<(), Error> and pub fn set_port(&mut self, port: Option<u16>).. I can't think of one off the top of my head, but it seems like we might as well be uniform with the setters.. blocking will only work if you're running with the threadpool executor, (and not e.g. the current thread executor), so you'd need to be able to configure this. #1517 is related.. HTTP2 over TLS must be negotiated via ALPN according to the spec, so the server might be refusing to perform the handshake.. The client isn't using ALPN.. You'd have to switch to a TLS implementation that supports ALPN such as hyper-openssl, and configure it to be turned on:\n```rust\nextern crate openssl;\nextern crate hyper;\nextern crate hyper_openssl;\nuse hyper::client::connector::HttpConnector;\nuse hyper_openssl::HttpsConnector;\nuse openssl::ssl::{SslMethod, SslConnector};\nlet mut ssl = SslConnector::builder(SslMethod::tls()).unwrap();\nssl.set_alpn_protos(b\"\\x02h2\").unwrap();\nlet http = HttpConnector::new(4);\nlet connector = HttpsConnector::with_connector(connector, ssl);\n```. native-tls doesn't yet support ALPN, but I'm going to be working on adding it after cutting a new release.. https://github.com/sfackler/rust-native-tls/issues/49\nNot sure - the implementation needs to land in schannel-rs and then we need to figure out the semantics of how it works in native-tls. Shouldn't be more than a week or two though.. Here's some infrastructure I built out for a graceful server shutdown: https://gist.github.com/sfackler/77c02d840a9ba08b58a435cab2901809\nEach Connection is wrapped in via ShutdownState::wrap_connection in a future that will turn off keepalive when asked. The ShutdownState::shutdown method returns a future that pokes all of the connections and then waits for them to complete.. https://github.com/hyperium/hyper/issues/1481. Anything blocking this?. This seems pretty reasonable to me API wise. I actually have a FIXME in some code to attach the remote address to our Zipkin tracing info that this feature would support. :). ```rust\n    let request = hyper::Request::get(url)\n        .header(\"Accept\", \"application/json\")\n        .header(\"Content-Type\", \"application/json\")\n        .header(\"Authorization\", \"My_key\")\n        .body(Body::empty())\n        .unwrap();\nlet client = hyper::Client::new();\nclient.request(request);\n\n```. Yeah, that's what we're doing right now (30 second timeouts for HTTP/1 and 10 minute timeouts for HTTP/2), but ideally we'd be able to handle this more precisely.\nThinking about it a bit more, the minimum set of functionality that would need to be in hyper is just an idle timeout and a request header timeout. Read/write timeouts can be managed by the service implementation outside of hyper.. I think we can preserve those goals. Initially, timeouts could require the runtime feature, and we could add an abstraction over timers to support other runtimes.. Try turning off http1_writev: https://docs.rs/hyper/0.12.8/hyper/server/conn/struct.Http.html#method.http1_writev. The TLS-wrapped stream doesn't support vectorized writes while a normal TcpStream does, and there could be a bug in some of the fallback code.. The documentation for the tokio threadpool contains documentation on threadpooling: https://docs.rs/tokio-threadpool/0.1.5/tokio_threadpool/fn.blocking.html. I mildly prefer NewService2 to something like MakeService for this kind of thing - it more clearly identifies the new thing as just the replacement for the old and so reduces potential confusion as to which one to work with.. Ah cool, that makes sense \ud83d\udc4d . cc @carllerche. Here's a plaintext dump of the decrypted packets if you don't have a Wireshark install lying around: https://gist.github.com/sfackler/779b19c6432a3cbab19510c616422aff. Ah, here's a standalone reproduction! Weirdly enough, the Accept-Encoding: gzip is required to see the issue! The request succeeds if you omit the header entirely or set it to identity.\n```rust\nextern crate futures;\nextern crate hyper;\nextern crate hyper_openssl;\nextern crate openssl;\nextern crate tokio;\nuse futures::sync::oneshot;\nuse futures::{Future, Stream};\nuse hyper::client::HttpConnector;\nuse hyper::header::ACCEPT_ENCODING;\nuse hyper::{Body, Client, Request};\nuse hyper_openssl::HttpsConnector;\nuse openssl::ssl::{SslConnector, SslMethod};\nuse std::fs::File;\nuse std::io::Write;\nuse tokio::runtime::Runtime;\nfn main() {\n    let mut ctx = SslConnector::builder(SslMethod::tls()).unwrap();\n    ctx.set_alpn_protos(b\"\\x02h2\").unwrap();\n    let keylog = File::create(\"keylog\").unwrap();\n    ctx.set_keylog_callback(move |_, message| writeln!(&keylog, \"{}\", message).unwrap());\nlet mut connector = HttpConnector::new(1);\nconnector.enforce_http(false);\nlet connector = HttpsConnector::with_connector(connector, ctx).unwrap();\n\nlet runtime = Runtime::new().unwrap();\n\nlet client = Client::builder()\n    .http2_only(true)\n    .executor(runtime.executor())\n    .build::<_, Body>(connector);\n\nlet request = Request::builder()\n    .uri(\"https://www.google.com/\")\n    .header(ACCEPT_ENCODING, \"gzip\")\n    .body(Body::empty())\n    .unwrap();\n\nlet response = oneshot::spawn(client.request(request), &runtime.executor())\n    .wait()\n    .unwrap();\n\nresponse.into_body().concat2().wait().unwrap();\n\n}\n```. Ah yeah that could be it! It looks like the server uses no padding when sending an uncompressed body.. Fixed upstream!. docs.rs doesn't appear to support HTTP/2, and even if it did, you'd need to use ALPN to negotiate the protocol during the TLS handshake.. You'd need to use ALPN to negotiate the protocol during the TLS handshake.\n\n\nsites that support HTTP/2 (i tried google.com and api.telegram.org). > Also please consider how small this patch is compared to how complex hyperlocal is (while not even being correct or fully-featured!)\n\n\nThe existence of an overly complex and not correct library doesn't seem to be a particularly convincing argument that something needs to be inlined into a separate library IMO.. What is insufficient about passing a stream of UnixStream into https://docs.rs/hyper/0.12.14/hyper/server/conn/struct.Http.html#method.serve_incoming?. Why specifically do you need SpawnAll?\n```rust\nextern crate tokio; // 0.1.11\nextern crate hyper; // 0.12.13\nextern crate futures; // 0.1.25\nuse tokio::net::UnixListener;\nuse hyper::server::conn::Http;\nuse futures::{Future, Stream};\nuse hyper::{Response, Body};\nuse hyper::service;\nfn main() {\n    let incoming = UnixListener::bind(\"/tmp/my_socket\")\n        .unwrap()\n        .incoming();\nlet f = Http::new()\n    .serve_incoming(incoming, || service::service_fn_ok(|_| Response::new(Body::empty())))\n    .map_err(|e| println!(\"error: {}\", e))\n    .for_each(|conn| {\n        let f = conn.map(|_| ())\n            .map_err(|e| println!(\"error: {}\", e));\n        tokio::spawn(f);\n        Ok(())\n    });\n\ntokio::run(f);\n\n}\n``. An even simpler version that usesServer::builder` directly:\n```rust\nextern crate tokio; // 0.1.11\nextern crate hyper; // 0.12.13\nextern crate futures; // 0.1.25\nuse tokio::net::UnixListener;\nuse hyper::server::Server;\nuse futures::{Future, Stream};\nuse hyper::{Response, Body};\nuse hyper::service;\nfn main() {\n    let incoming = UnixListener::bind(\"/tmp/my_socket\")\n        .unwrap()\n        .incoming();\nlet f = Server::builder(incoming)\n    .serve(|| service::service_fn_ok(|_| Response::new(Body::empty())))\n    .map_err(|e| println!(\"error: {}\", e));\n\ntokio::run(f);\n\n}\n``. Yeah that's where I lean.. You can useresponse.into_body()rather thanresponse.body()to get the body by-value rather just a reference.. mio supports HUP registration via UnixReady, but that's not piped through Tokio. AddingTcpStream::poll_hup` would be great though, even if it would only work on Unix. The server I work on processes long-running requests, and we have request cancellation detection but it won't work via HTTP/1 without that.. New cargo can handle that by supporting multiple optional dependencies of tower at different versions. Might be worth doing this in a separate crate with a newtype wrapper until hyper can bump its minimum supported Rust version to 1.31.. Here's an example in rust-postgres: https://github.com/sfackler/rust-postgres/blob/master/tokio-postgres/Cargo.toml#L58\nWhile we don't do it yet, we could have an equivalent bit-vec-06 or whatever dependency that works side-by-side with the existing one.. This does fix the deadlock I'm seeing!\nI'll try to split out a minimal repo.. Is another process already using port 4567?\nEDIT: Oh, or is this on the client side?. The error is coming from the OS, so it's definitely a problem on its side.. \u2764\ufe0f . The rustc_version crate can handle the heavy lifting in the build script.. Should we deprecate cause2 as well?. > Is it really the case that async hyper (using futures) is really synchronous?\nI think you may be confused about what \"asynchronous\" means in the context of Tokio. It specifically refers to nonblocking IO - and tasks that cooperatively share a single OS thread by yielding to others when they're unable to make active progress because e.g. they're waiting on data from the network.\nThe tokio runtime is multi-threaded - there is a thread per CPU core by default. Blocking on a long running operation prevents other requests from running on that thread for the duration. If you have 8 CPU cores and 8 tasks are blocked, no progress can be made.. I don't remember exactly how tasks are pinned to threads, but it wouldn't be all that surprising if they ended up on the same one.. If you're using that feature, yeah, though that's a thing that we can fix on the cookie side. But it seems a bit unlikely that you'd be enabling that feature anyway if you're using the client side of hyper.\n. Is the intent for this that you'd call it when pulling a connection out of a pool?. Couldn't poll know that the connection's upgraded and not shut it down?. Does this inject a Connection: close or just cause poll to return ready after the first response comes in?. If you did try to send a request, would that just be queued up on the connection becoming ready, or would it be an error?. FWIW storing an Option and .as_mut().unwrap()'ing it is super common in futures/stream combinators so it wouldn't be that crazy. Seems fine to have two methods though.. Given that it wouldn't do anything for h2, would it make more sense to not have this method at all and have users set Connection: close to manage keep alive? Hyper does pay attention if that header is set on outbound requests I think, right?. Ah cool, makes sense. I was thinking it wouldn't be an error, so I was a bit confused :). Doesn't Hyper control what type the request body is?. Fixed. This should check for @ as well, right?. This is only set for your own crate so there's no need to try to avoid collisions fyi. ",
    "Manishearth": "Perhaps we can work around this on Servo's side if it's a perf issue?\n. If this is a perf issue, perhaps we could use an Option<RawStatus> instead? That way we can specifically request the fetch to set the raw status before fetching, else we can just discard and drop the string.\nSomething like Request::new(...).set_flag(StoreRawStatus). Not sure if that would be an improvement.\n. Ah, okay.\n. Uh, someone else already opened this PR ;P\n. Would there still be case sensitive access?\n\nI've been thinking a bit about this Header, and I think it would be cool if we could somehow store a list of actual typed headers, rather than Strings. I'm not yet sure how to do to that, though.\n\nTrait objects would work. I prefer having the raw-until-proven-parsed behavior that hyper has at the moment though :)\n. FWIW the crates.io experience will probably be broken like this until 1.0 since library authors will have to maintain two moving targets (rather than one, post-1.0)\n. (We're using RawStatus initialized to 0, and we're getting that it stays 0 instead of becoming 699)\n. Since Servo uses RawStatus, perhaps some way to pass it down to RawStatus would work?\nI agree that we should try to optimize Status as much as possible.\nAnother option is to add variants till 999 (with a macro?); which is still 2 bytes.\n. That's the fetch standard, not XHR. XHR references fetch, but that specific portion is for fetch(), not XHR::send()\nThis is the relevant bit of the fetch spec for handlign responses (XHR defines the actual handling of the task here )\n. That doubles the size of the struct though. Perhaps with a smaller int type it would get squashed by alignment.\n. Not exactly. The web platform specs don't forbid it explicitly; and this means that there will be apps out there using it. Well, it's the other way around probably -- webapps were using higher status codes and the specs have to be written such that the web isn't broken just because the specs are too strict.\nSo the test is correct; not something to be \"fixed\".\n. Not that I know of. Perhaps ask in #whatwg on freenode\n. Welcome to the world of web specs. We hope you stay, but you probably should get out while you can :joy_cat: \n. Not a serious one I guess, but something to be avoided.\n. We can actually \"pretend\" to be an enum, like so:\n```\nstruct StatusCode(pub u16);\nmod StatusCode {\n  use super::StatusCode;\n  pub static Ok: StatusCode = StatusCode(200);\n  ....\n}\n```\nDemo\n. @reem Yeah, but it still makes the enum larger than it needs to be -- with my solution above you can have enum-like behavior as well as having a u16 status code, though the matches won't be forced to be exhaustive on normal status codes anymore.\n. I was surprised too. But as you can see in the linked demo, it magically works! :)\n. I know, but I still don't like it\n(I have a tendency to overoptimize things that don't need it :stuck_out_tongue:)\n. When it comes to the web, one must permit more behavior than the spec constrains us to. The restrictions imposed on people designing webapps by the spec (namely, don't use weird status codes) are not the same as the restrictions for platforms implementing the spec. This is a crucial difference when approaching specs -- are you a platform designer, or a platform user?\nFor example, while the HTML spec is rather specific as to how tags should be nested, the HTML parsing spec allows for all kinds of edge cases. It's in this spirit that this test was written (at least, it seems like it) -- a browser or other HTTP client should not choke on strange status codes.\nIf you look at the WPT tests, many of them are doing just that -- using illegal code to invoke edge cases and whatnot. It is unfortunate that they have to do that, but the web has evolved that way, and we have to live with it if we want to support random websites.\nThere is a macro-based option which should work if we want to support status codes >599 without losing efficiency, or the constants method (without the fake-enum).\nAlso, as platform implementors we must support behavior defined in the less stricter RFC anyway, so the 3 digit rule seems like a better one to implement.\n. :heart: the design :)\nI'm not entirely certain if it does this already, but if not in the future we might want to be able to have Client persist cookies, similar to Python's requests.session.\n. \\o/\n. The tostring lint has been upstreamed into Clippy. I think the glob one would be nice to have as well, PRs welcome! :)\n. This doesn't use unboxed closures yet, because I don't like having to specify a dummy unboxed closure every time. I tried using default type params to get around it, but it didn't work too well and I got an ICE.\nAny ideas as to how this can be done?\n. @seanmonstar Oh, I thought \"boxed unboxed closures\" didn't work yet\nAdded a commit which fixes this\n. oops. wrong repo, this is what I get for having too many tabs open.\n. You mean https://github.com/servo/servo/issues/4246 :)\n. Looks okay to me.\n. (Without this, a lot of crates are having trouble cleanly updating past the libc issues, esp since openssl can only be linked to once)\n. Origin isn't really a string. It's a parsed URL, except that it doesn't have a path.\nhttps://fetch.spec.whatwg.org/#origin-header\nAn opaque newtype around Url with equality and a constructor implemented is what we want here, really.\n. Also, fetch and the original Origin RFC seem to differ on whether or not Origin should be an array.\nFetch says that it supplants the original RFC but I'm not sure what that means for hyper.\n. Well, I was going to suggest something along the lines of\n``` rust\npub struct Origin(Url); // field is private\nimpl Origin {\n    fn new(t: T) -> Result {\n        let url = try!(t.into_url());\n        Ok(Origin(url))\n    }\n}\nimpl PartialEq for Origin {\n /// only compare the scheme/host/port (Origin is supposed to be an opaque identifier with equality)\n}\n```\nWe can also add a stringifier which strips out the path.\n. https://github.com/servo/rust-url/blob/66545ce19dae6d1dd7fcbce56c471e15a43a0fc3/src/lib.rs#L203\nThis is the correct way of handling origins (doesn't have the null thing though)\n. cc @SimonSapin\n. When it's entered in the URL bar, it tells me that I'm sending authorization to a site that doesn't need it and complains (and doesn't send the authorization even if I tell it too). Stubborn.\nHowever, if accessing a URL that actually needs basic auth, it diligently converts and sends it.\nFor example, http://manish:foo@manishearth.anapnea.net/sand/basic.php . This is running the first example from http://php.net/manual/en/features.http-auth.php with no modifications.\nIt works with XHR too.\nI guess the more important question is -- is this the job of hyper or Servo? The URL spec explicitly mentions usernames in the scheme data, but the HTTP spec doesn't. OTOH, what should hyper do otherwise when fed a url with auth data in it? Ignoring it is confusing and unexpected.\n. Alright. Perhaps I should leave the from_url commit here?\n. My bad, forgot to undo it properly. fixed\n. I guess the mixture of raw and non-raw methods is breaking it, but I'm not sure. Does set_raw create two copies of the thing -- one typed, one untyped?\n. I guess the issue is that typed_mut doesn't remove the header from the raw headers when inserting a typed one.\n. Could we get a crate version published for this?\n. Should be \"running 2 tests\"?\n. What made cURL slower?\n. (fixed)\n. I haven't heard of this, but I've not really looked at the status code part of implementations\n. ",
    "mcpherrinm": "https://github.com/alexcrichton/cookie-rs/issues/10\n. ",
    "shamansir": "\nclearing ~/.cargo/git/\ndoing cargo update to get other repositories\nremoving [dev-dependencies.*] sections from Cargo.toml in ~/.cargo/git/checkouts/hyper-<commit-hash>/master/\nremoving benches directory from ~/.cargo/git/checkouts/hyper-<commit-hash>/master/\ndoing cargo build or cargo build -p hyper\n\n-- wasn't helpful to me\n. @reem ...Now it works! Thanks!\n. ",
    "barosl": "I've done the following changes:\n- Rename read_until_space() to read_token_until_space()\n- Check if the byte is part of the token in read_token_until_space()\n- Return HttpMethodError if the token is empty\n- Remove the unnecessary is_valid_method() function\nAlso added tests.\n. ",
    "mikedilger": "@annevk  I'm sorry I was wrong.\n@reem I'm sorry I think my comment wasn't relevant to what you meant by this issue.\n. Case in point: my email/mime creation crate depends on hyper, and it has nothing to do with HTTP.\nI don't think splitting it up into lots of tiny crates makes sense, but headers/mime should really be separate.. Could do that.  But a Url struct would add 6 fields that wouldn't be used:  scheme, username, password, host, port, and default port.  And I'm not sure if hyper would always know its hostname in every circumstance.  Also, the Url::parse_path() output seems to be geared for this usage, only there is no struct, it just returns a 3-tuple.  Could take that approach too (i.e. drop the struct).\n. Sounds good.\n. FYI, for those who need a workaround for this issue while we wait for async:\n1. Keep a count of how many worker threads are busy or waiting in the keep-alive loop.  The handler trait now has hooks (on_connection_start and on_connection_end) allowing you to increment/decrement your count of busy threads.  You'll need to use a Mutex or AtomicUsize or other sync primitive where you update the count.\n2. Have your handler function check the count, and if the count is high enough (e.g. maybe all but 4 threads are occupied), set the Connection::close header (which hyper will notice and respect, closing the connection after the response).\n3. I still recommend using the 'timeouts' feature and setting read and write timeouts on your server; but now those timeouts don't need to be super-short anymore.\nThis way you can still support keep-alive most of the time, but when things get really busy, your server won't \"hang\".  I've tested this and it works well.\n. I concur.  I think the number of people who find hyper \"locks up\" is sufficiently high to justify disabling keep-alive by default for 0.6.  It could be considered a DoS security vulnerability as it currently stands.   The performance benefit of keep-alive can't really be achieved under blocking I/O anyhow without an enormous number of threads, or being under very low load.\n. A co-worker of mine wrote a tool to benchmark hyper-based servers, and which is annoying in just the right ways to inspect keep-alive related behaviour: http://github.com/alanstockwell/hyperspank  (shout out to @alanstockwell)\n. This commit is the culprit:  cb59f609c61a097d5d9fa728b9df33d79922573b\nfix(http): read more before triggering TooLargeError\nI wont try to fix, I'll leave it for you Sean as you're more familiar with what you just did.\nTo test, the client that makes the server loop is a GET request via this firefox extension: http://www.restclient.net/\n. Another option I thought of:  HttpListener could get a separate listen method (where http and https would do everything except the bind step),  and then a new method could be created that gets a mutable reference to the SslContext, to be called prior to listen.\nAlso I forgot to cc @seanmonstar \n. self.with_listener(listener, threads) requires both self (Server) and listener.  If the context is moved, then 'self' is no longer available.  See https://github.com/mikedilger/hyper/tree/ssl_context\n. I'm glad I asked, because I hadn't thought of that.\nI did this in 3 commits.  See PR #479\n. I've amended the commits and force-pushed the amended branch.  I think I've addressed your concerns.\n. If anyone takes this on, you might want to start with the one at https://github.com/mikedilger/formdata/blob/master/src/headers.rs and then extend it to comply with the standards listed above.\n. Go-go async support! That's gonna be awesome.  Thanks\n. I just realized I completely neglected to handle the \"filename*\" parameter with ext-value (including character set, blah blah). I'll be adding more commits.\n. I'll rework this and do another pull request later.\n. I think I have addressed everything above except using url::percent_encoding, which depends on PR servo/rust-url#134\n. Precisely.   I'm in no hurry to get this PR merged as I can use raw headers in the meantime.  But if you like things tidy, @SimonSapin would have to make a release.\n. Ok, rebased onto master and collapsed into a single commit\n. Ok, rebased again.\n. https://tools.ietf.org/html/rfc7616 adds sha-256 and sha-512, and while MD5 is still supported it is not recommended (see paragraph 3.2).  So pulling in md5 might not be sufficient.  I notice @matt2xu code uses the crypto from openssl, IMHO is probably the most reasonable choice here.\n. I've got multiple websites running on 0.9.11 with no issue, but I'm front-ending them with nginx, and nginx is handling all of the TLS and then proxying the content  (hyper serves only to 127.0.0.1 so people can't bypass the nginx frontend).  Also my handler sets connection-close if it is busy (and hyper enforces it), and that fixed the problem of clients tying up all the threads with keep-alives.\nWith this setup, I've had no problems.  Just another data-point . Also, I'm not using Iron, so there's that.\n. @hannobraun This is quite a long shot, but I've recently seen surprising behaviour where OpenSSL uses locking callbacks provided externally, and if you link to something that provides such (e.g. python) then you could accidentally block OpenSSL calls with something like a python GIL not being unlocked: https://github.com/sfackler/rust-openssl/issues/532.  Like I say, a long shot, but if you are linking to python, something to consider.. FYI I'm looking forward to the solution for this as well.  My use case is a server with plugins.  Consider a flate plugin that takes the Response prepared by a handler and modifies the body stream by compressing it.\nAs far as I can tell, I can't do this direclty in hyper 0.11.  I have to instead define my handlers to return a different internal-to-my-crate type that looks like Response, and then after all the plugins, turn it into a hyper Response.\n. It is in http://www.iana.org/assignments/character-sets/character-sets.xhtml, maybe we should change the charset enum...\n. I'll have to push a PR to add another EncodeSet because it's a slightly different set from the 6 or so defined in that crate already.\n. https://github.com/servo/rust-url/pull/134\n. ",
    "emk": "That is entirely possible. Let me whip up some test cases.\nLe Mon Nov 24 2014 at 13:15:19, Sean McArthur notifications@github.com a\n\u00e9crit :\n\nDoesn't this also require Hash?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/pull/144#issuecomment-64237621.\n. Thank you for your feedback!\n\nTwo new patches:\n1. The first patch derives Eq and Hash for Method, which should help port iron/router.\n2. The second patch provides a test case for (1), plus some short test cases for the other functions in this file.\nFeel free to grab just (1), or both if you'd like the tests. I'm also happy to revise the patches. Thank you for considering this change!\n. ",
    "andor44": "This fails because I haven't submitted a PR to rust-openssl (that is failing because sync has been moved into std) yet because it has some broken tests and I'm unsure if I managed to break them myself or they were expected to fail to begin with.\n. Now it's failing due to IntoMaybeOwned being renamed to IntoCow (har har), I'll submit a seperate PR for that tomorrow.\n. @s-panferov I'll give that a shot.\nHere's the relevant part of the code. I'm not sure how deep down the rabbit hole this should be handled though. Probably as deep as this though I'm not sure how easily you can specify a timeout in the current Hyper architecture.\n. Yes. I am using nginx, and it uses HTTP 1.0 for reverse proxying requests, which doesn't have keep-alive as part of the spec, and it works perfectly.\n. ",
    "retep998": "Yes, a way to turn a CookieJar into Cookies and a way to apply the changes from SetCookie to the CookieJar. Those two things would make working with cookies significantly easier.\n. Updated with test.\n. It should actually be\nhyper = { version = \"0.6\", default-features = false }\n. Why does this take the jar by value when CookieJar.iter() takes &self?\n. ",
    "dpc": "Hmmm. My github-fu is weak. I guess there's no reason to open an issue for PR. Please excuse me this time.\n. Since I've create an unnecessary issue let me leave small info about a tool I've hacked together that exercises Hyper: https://github.com/dpc/hyper-get\n. Why is StatusCode an enum? When I see around 400 lines of:\n/// 132 (unregistered)\n  Code132 = 132,\nIt seems to me it should be struct StatusCode ( u16 ) with some helpers / static constants for common codes.\n. I'm just playing so don't bash me too much if you don't like it, but would that work?\nhttps://github.com/dpc/hyper/commit/9c2b06b52f742aa97541b2a4cc764a14af617597\nThe only way to create a custom StatusCode is StatusCode::from_code and checks can be added there, and for common codes there are constants.\nI don't like the fact that consts are defined in hyper::status namespace instead of hyper::status::StatusCode though. Is there a way to move this consts in right namespace somehow?\nAlso, I've removed all the the unregistered codes. Their constants could be restored though, and if the problem with the namespace is solved, this could been a drop-in replacement.\n. @seanmonstar : What's the purpose of Deref? To get the raw code? Wouldn't explicit fn to_raw(&self) -> u16 be OK?\n. 7de6f2b Merge pull request #933 from jwilm/misc-client-fixes\n. hello.rs example:\n[I] dpc@futex ~/l/r/3/hyper (master) [I]> wrk -t8 -c100 -d10s http://localhost:3000\nRunning 10s test @ http://localhost:3000\n  8 threads and 100 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   349.14us    1.12ms  29.04ms   98.12%\n    Req/Sec    44.40k    19.14k  168.10k    74.20%\n  3290810 requests in 10.00s, 276.18MB read\nRequests/sec: 329100.55\nTransfer/sec:     27.62MB\nStill a bit slower (2x) - why could it be? Is it because mioco example is really not formatting any real response and just writes the whole response in one go?\n. ",
    "ajnirp": "I'm unsure of how to proceed. Which is better?\npub struct Vary(pub VaryOption)\npub enum VaryOption { AnyField, HeaderFields(Vec<String>), }\nor\npub struct Vary { all: bool, fields: Vec<String>, }\n. Build is failing, but apparently due to files not touched by this commit :/\n. Squashed. Also, how do I test for tags containing chars in the x80-xff range? Apparently rust doesn't allow byte literals to exceed x7f.\n. Welcome, and thanks for the mentoring :)\n. I couldn't figure out how to get the empty Vec subtest to work. I was getting an assertion fail panic:\n(left: `Some(Allow([]))`, right: `Some(Allow([]))`)`\n. Rebased, also added a bench\n. @seanmonstar I tried to test for an empty vec.\nlet empty_vec: Vec<Method> = vec![];\nlet allow = Header::parse_header([b\"\".to_vec()].as_slice());\nassert_eq!(allow, Some(allow(empty_vec)));\nwhich was giving the above-mentioned error. I couldn't figure out what was wrong with this, so I removed the test before pushing.\n. Just checked, that was indeed the problem. Should we include this test, then? (asserting against Extension(\"\".to_string()))\n. Patched that, and also addressed the fmt_comma_delimited nit.\n. The latest rustc updates seem to have introduced some breaking changes. These same build errors are also holding up a PR I have.\n. done\n. ",
    "jamougha": "Hi. I'll take a look at this.\n. This turns out to be quite difficult due to the lack of a Rust URI library. I've used URLs to make a simple and non-conforming implementation - I don't know if you'd rather have that than nothing at all. I might work on a URI library over Christmas since it seems to be needed...\n. @seanmonstar Based on my fairly crude understanding no. The spec allows partial URIs, e.g. 'foo/bar', which are not valid URLs and can't be parsed by rust-url without a base. The Referer spec doesn't appear to specify a base to use. \nPerhaps the obvious choice is to parse it relative to the requested URL and this seems to have been the intent of earlier versions of the spec but obviously that isn't available to a header in the Hyper API.\n. ",
    "ArtemGr": "That doesn't work. When I change Cargo.lock and hit the build my changes in the Cargo.lock are overwritten!\nFor example, original: http://pastebin.com/ejcBPnru; change: http://pastebin.com/2F82hpvc; after \"cargo test\" the Cargo.lock becomes identical to the original one.\n. @seanmonstar could hyper change its openssl dependency to use the crates version in order for Cargo to recognize that it's the same version? Steven says the semver should kick in then (https://github.com/sfackler/rust-postgres/issues/87) and everything should work.\n. Great, I'll test then!\nBTW, you'd need to only update the openssl dependency for it to be compatible with mysql and postgresql drivers, the rest of them dependencies should be fine as is. Just thought I'd better mention this.\nI might have made a pull request myself but I'm not that familiar with hyper's multi-crate structure.\n. It works, thanks! Hyper is now useable alongside Mysql and Postgresql drivers.\n. ",
    "kud1ing": "Maybe another option: adding an enum value Unhandled(uint) that contain values beyond the spec.\nThis statically isolates specified and non-specified status codes.\n. Yes, on the client. I've improved the description.. I wonder, since i query approx. 30.000 URLs and this seems to be timing related (it's more likely with --release): is it possible that i hit an OS limitation? E.g. connections are not closed fast enough?. If hyper is not holding on to anything for longer than necessary, i tend to close this.. ",
    "chris-morgan": "I just noticed this and would like to comment on it: I disagree with the premise and will fight for the status quo.\nI am operating on RFC 7231\u2019s definition of status-code which is more restrictive than the simple 3DIGIT that the grammar definition in RFC 7230 gives:\n\nThe first digit of the status-code defines the class of response.\n   The last two digits do not have any categorization role.  There are\n   five values for the first digit:\no  1xx (Informational): \u2026\n\nFrankly, I\u2019m not sure why it wasn\u2019t defined in the grammar as %x31-35 2DIGIT, but the text provides further normative restrictions which make 0xx and 6xx\u20139xx illegal. This state, the grammar permitting something that the text then restricts as illegal, is not at all uncommon.\nSimilarly, when considering the registry at http://www.iana.org/assignments/http-status-codes/http-status-codes.xhtml, it is worth while bearing in mind that this is an exhaustive registry, unlike the HTTP method, where extension methods are explicitly supported. (This is, incidentally, a change from RFC 2616 which hardcoded the list of known status codes and added an extension-code rule, but that list of its has been obsolete for ages.)\nI say it clearly and in direct disagreement with @Manishearth: a test using status code 699 is illegal and is invoking undefined behaviour. Those tests should be removed. There is clear evidence that while many (probably most, historically) things support values outside the range 100\u2013599, some do not (I get the impression this is happening more and more for new things as security is considered more and more important, e.g. in Fetch), so it\u2019s not as though we\u2019re introducing an extra restriction that no one has done before by actually disallowing values outside the range permitted by the specifications.\nIf the alternative were as elegant or efficient as the current implementation, I would not mind too much about extending it to support illegal states, though I would still fight quietly against it. But as it is, with the language as it is there is no solution even half as good as the current one. I submit as a refresher the article about status-line design that I wrote initially; there are a couple of notable changes in the world since then (RFC 723X superseding RFC 2616, and 1xx being made legal again in HTTP/2), and the Rust syntax has changed in places, but the contents of the article are still sound. Most notably for this discussion, using an enum with an extension code variant has severe backwards-compatibility problems.\n. Can it actually? The only way in which it will is if in the closure passed to a.try_mutate() you do something with a, which I don\u2019t see happening. It\u2019s only called twice, both times in src/header/mod.rs, and neither has this documented bad behaviour.\n. Of, you're doing things like that, are you? That is bad and needs to be\nfixed. In Teepee I went to great lengths to ensure total memory safety,\nwith such things as the TypedRef type.\n. (I believe a certain bluntness is needed to be effective in this case. Pray take no offence, any one who should read this.)\nSpeaking of the status quo with no reference to the changes enacted in this PR:\nI\u2019ve never looked closely at what hyper did with its header representation and mucell and so forth. I took a little closer look just now and I am not at all pleased at what I see.\nHeader reparsing (accessing it as multiple types) is not permitted, which while being more restrictive in corner cases does simplify various things. Most notably, it does indeed mean that mutation can be constrained to only occur through a mutable reference, and so indeed mucell\u2019s niftiness is wasted. I deemed the misbehaviour in corner cases as unacceptable in Teepee, which is why I wrote mucell\u2014but it does have additional costs, most notably that you cannot use plain references any more but must propagate new reference types that implement Deref. If you consider the corner-case misbehaviour acceptable, then you might as well bypass the small costs of mucell.\nTo the author or authors of all this code: your license to use the unsafe keyword and more importantly the transmute function has been revoked for 30 days and you will be on probation for 180 days thereafter. Injudicious usage of transmutation has left the header representation subsystem with notable memory safety bugs. This is in no manner the fault of mucell but rather the cruel and unusual treatment it has received (e.g. mem::transmute::<&H, &H>(downcast(&*item.borrow())), ruining the reference counting, about which I may furthermore add that the downcast(&*item.borrow()) part should not compile due to a lifetime conflict). As mentioned above, if you\u2019re going to use mucell returning plain references is not an option; new reference types to handle the dropping of the reference count must be used, as is demonstrated in Teepee, the header representation scheme of which I believe to be devoid of memory-safety bugs.\nI have not extensively assessed the impact of this PR, but I do know that my judgement on the issue is that the entire header module needs careful auditing and probably rewriting and I believe all unsafe code should be removed from the module with prejudice for the moment.\nI will leave you with just one comment about the PR itself:\nBear in mind also that this OptCell is not a safe type; a reference may exist through Deref when set is called. set should therefore be marked an unsafe function.\n. I mostly retract my last paragraph; because set can only be called when the wrapped value is None (in debug mode, anyway) the worst that can happen is that a supposedly immutable &None changes underneath the variable binding to &Some(\u2026). This is bad, but does not affect memory safety as there can be no references to inside a None.\n. ",
    "mdbooth": "Travis failure is due to the time crate being broken. Its build process seems to require the HOST environment variable, and breaks if it's not set.\n. Hadn't noticed the url object ends up wholesale in the request object.\nOk, I guess that makes sense.\n. Will do.\n. Well spotted :) Yes, I did. I'll omit it entirely as you suggest.\n. I had given this cursory thought, but thinking about it this would inevitably be a breaking change due to having to return multiple results. I'll do this.\n. ",
    "DiamondLovesYou": "\nHm, Yea. I could make 3 sub crates, hyperc, hyperd, and hyperp, or\nwhatever, and bundle them all as hyper.\n\nThat would be excellent!\nThough I'd bikeshead and say should be named hyper-client, hyper-header, and hyper-server.\n\nI don't think I want them in separate repos and such, though.\nThat's not needed. Checkout rust-openssl's (Cargo.toml)[https://github.com/sfackler/rust-openssl/blob/master/Cargo.toml]. It explicitly sets the path of the dep.\n. I suppose I can live with that.\n. > Why split into 5 packages? client and server are obvious. why not just 1 other crate, protocol or something?\n\nhyper-net (contains net.rs from before this PR) is used by both the client && server, but nowhere else: it exists to provide net.rs Stuff to both. I created hyper-core to hold all the Things that everyone depends on. Depending on what features are requested, all of these crates are accessible from the main hyper crate.\nThese are intended to be as small as possible individually.\n\nOk, so that clarifies the situation a bit - it is possible to use path for development, but it still does require uploading and maintaining crates.io versions for all the sub packages.\n\nI've added a script that'll publish all the packages. Once https://github.com/rust-lang/cargo/issues/948 is fixed, it can be made even better. Obviously, I haven't tested it.\n. > This seems like a great idea! As @sfackler said the same Cargo.toml will serve for publishing and developing, and I'd like to add something along the lines of cargo publish --all which will publish all packages in the current repository, automating the publish-each-package-separately step.\n:+1: \n. @reem See https://github.com/hyperium/hyper/issues/189.\n. @reem Compile time doesn't matter, size does. Also, the pepper API already provides it's own client API, so I'd like users to that and not use hyper's.\n. @reem Well, unforunetly in my case, LTO is broken. Nevertheless, what exactly are the server && client doing in this package? Shouldn't developers be using Iron for such features? I know I will. Moreover, small crates are a Good Thing: changes to server or client will be isolated, limiting those affected (remember extra?).\nI realize this PR will require a few changes of hyper's users, however seeing as hyper hasn't reached 1.0 yet, this is the best time for such.\n. Alright, fair enough.\n. ",
    "brendanzab": "Yeah, looking at the IANA list of headers, it seems that headers span more than just http. I can also see that we are missing many of them! It would be nice to see if we could split them out and do some more rgourous testing of our implementation coverage, perhaps even testing to see how many we implement based on their supplied CSV file.. I also found this when trying to create a reverse proxy. I posted my problem in #1263. I'm guessing this issue is the more general one though, so perhaps we should close that one.. I get the following test error locally:\nthread 'header::common::last_event_id::test_last_event_id::test1' panicked at 'called `Result::unwrap()` on an `Err` value: Header', src/libcore/result.rs:860:4\nThe offending test:\n```rust\nheader! {\n    // ...\n(LastEventId, \"Last-Event-ID\") => [String]\n\ntest_last_event_id {\n    // Initial state\n    test_header!(test1, vec![b\"\"]);\n    // Own testcase\n    test_header!(test2, vec![b\"1\"], Some(LastEventId(\"1\".to_owned())));\n}\n\n```\nAny ideas?. Thanks! Hopefully it's fixed now!. So for now I just decided to get my users to pass in the remote_addr manually.. Sounds reasonable. Perhaps it would be good to document the position somewhere of what headers make it into the library?. I wasn't quite sure if you wanted this to be a Cow, but what I decided on based on the other things here.... No idea. Looked on MDN, Wikipedia, and IANA for the syntax but couldn't find a reference to this header. What list did you use to figure out what headers to include?. ",
    "mehcode": "My vote would be http_headers and then http/headers if/when Cargo supports sub-crates. \nRationale is: The base http package provides base HTTP types. The http_headers package provides additional types for HTTP headers.. If we could solve this it would remove a lot of code inside Shio that's currently present to work around this.\n\nAs a short-term fix for those interested, Shio can be used as a lightweight wrapper around Hyper to run an HTTP server where the service has direct access to the underlying handle.\nrust\nfn main() {\n  Shio::new(|context| {\n    // reference to the actual reactor Handle so you can easily \n    // use postgres-tokio, hyper client, etc.\n    context.handle() \n  }).run(\"127.0.0.1:7878\");\n}. @XX You probably want Request::deconstruct.\n```rust\npub fn foo(request: Request) -> Response {\n    let (method, uri, version, headers, body) = request.deconstruct();\n    let total = body.concat2().wait().unwrap();\n    println!(\"{:?}\", total);\n// method, uri, version, and headers are still usable\n\n}\n``. @SeunLanLege TheContentType` header is actually defined here:\nhttps://github.com/hyperium/hyper/blob/9bb71b9bbfedc4b47c96dd83efd75f852abced6b/src/header/common/content_type.rs#L48\nThere is a documented header! macro it uses to define itself with here: https://docs.rs/hyper/0.11.2/hyper/header/index.html#defining-custom-headers\n\nFor future reference, to save yourself the searching (through code), you can search in the documentation (search bar up top) and then click the [src] link in the top right.\n\nThat bit of code you linked is internal-only (not exported) and used in the Extend impl which is when you take one set of headers and extend it with another one. I'm not completely sure why its doing what it's doing but @seanmonstar can probably answer that.. @seanmonstar Any hope of including this in the upcoming v0.12 release? If what you said still holds true, it's not much code in hyper for a short-term fix.\nMost of my \"real world\" (in production) issues come from my stuff trying to use dodgy ipv6 connections. . @cetra3 Could  you open an issue on Shio? We should generalize and support this.. @seanmonstar @hban RFC 8305 (which obsoletes RFC 6555) seems to recommend 250ms for the timeout (section 5).\nI'm not super clear on what big changes are between 6555 and 8305 but it might be worth looking into.\nhttps://tools.ietf.org/html/rfc8305\n\nSee https://github.com/golang/go/issues/23841 for some more concrete details \n\nReally awesome work by the way \ud83d\udcaf I can remove a bunch of hacks I currently have.. ",
    "tshepang": "sad when people do this https://docs.rs/http_headers/0.0.2/src/http_headers/lib.rs.html. @seanmonstar is it a private project at the moment, or is there somewhere where one can join in, even if just to watch progress?. there is, only it doesn't render locally\n. fixed. ",
    "mbilker": "The header API is now available through http::header. hyper::header has been removed.. That would perfectly fit my use case and not affect the functionality of the headers API for general use of the client library part of Hyper. Currently investigating how headers are written for HTTP/1.0 and HTTP/1.1 connections.. I found the write_headers function[1] and see that the client calls it when it is encoding the response. Is it more preferable to include a boolean parameter to tell write_headers to use title case or duplicate the write_headers function into one named, for example, write_headers_title_case and replace the extend call for the header name with one to title_case(dst, name)?\n[1] https://github.com/hyperium/hyper/blob/dfdca25c004aeb583b931f57e19510b3096362e3/src/proto/h1/role.rs#L638-L645. Alright, that's what I did for my naive example code (that's still WIP and unpublished). Is it preferable to search for the hyphen and capitalize the next character? Or go character by character in a for loop keeping state in a boolean to capitalize the next character? Or using a while let Some loop so I could use chars.next() to avoid using a boolean to store state?\nMy naive example:\n```rust\nfn title_case(dst: &mut Vec, name: &str) {\n    dst.reserve(name.len());\nlet mut should_capitalize = true;\n\nfor c in name.chars() {\n    if should_capitalize {\n        should_capitalize = false;\n\n        for c in c.to_uppercase() {\n            dst.push(c as u8);\n        }\n    } else {\n        if c == '-' {\n            should_capitalize = true;\n        }\n\n        dst.push(c as u8);\n    }\n}\n\n}\n. A `while let Some` version:rust\nfn title_case(dst: &mut Vec, name: &str) {\n    dst.reserve(name.len());\nlet mut iter = name.chars();\n\nlet push_uppercase = |dst: &mut Vec<u8>, iter: &mut ::std::str::Chars| {\n    if let Some(c) = iter.next() {\n        for c in c.to_uppercase() {\n            dst.push(c as u8);\n        }\n    }\n};\n\npush_uppercase(dst, &mut iter);\nwhile let Some(c) = iter.next() {\n    dst.push(c as u8);\n\n    if c == '-' {\n        push_uppercase(dst, &mut iter);\n    }\n}\n\n}\n``. Revised this to use a byte slice (&[u8]) instead of a&str. I see that lowercase to uppercase conversion of ASCII characters can be done by XORing the lowercase byte withb' '` to get the uppercase character byte.\nI probably should open up a PR for this now, but I am still trying to work out how to add a configuration option to toggle between title case and straight lowercase output.. Made a PR. Thank you so very much for the guidance!. I noticed that the encode methods are not tested at the bottom of the file, but they are heavily tested in the integration tests of Client. I will add some tests for the title_case method and some integration tests to check for title cased headers through the client request.. I modified the client integration test macros to accept a title_case_headers parameter and I added a test using said change to ensure the client is encoding the headers as title case.\nIf you feel that this change is unnecessary because of the unit test, then I can revert that file back to its original state.. Hmm. The tests passed on my computer, but on Travis they flat out fail or crash.\nLet me know if they crash on your computer.. Thank you very much!. I agree with that reasoning. Should it be commented like the method field to indicate it isn't logged or just get rid of the line entirely?. Oh, I forgot to think of those. A check to see if the byte falls between 97 (a) and 172 (z) should suffice.. Since ServerTransaction implements Http1Transaction, I cannot just remove it from the method signature as that would deviate from the trait definition, but I can prefix it with an underscore to signify that the boolean is unused.. I read the octal field by accident from the man page. I fixed it to a >= b'a' and <= b'z'.. ",
    "asonix": "It seems that there is an API available through http::header, but it isn't as extensive as the one that used to be in hyper. Are there plans to change this, or is parsing header values (such as content-disposition) left to downstreams?. Yeah, this could probably be handled in Rocket. I'll look into that when I have some time. mint should definitely be at least 3.9, unless that's a really old install.\nI was on 3.12 in 2013 on elementary OS (another ubuntu derivative). ",
    "dekellum": "I've been successfully using hyper 0.11.x with the compat feature, CompatFutureResponse and the http crate types. In most cases the byte-oriented HeaderMap best fits my uses. However, in certain cases I'm also passing http::header::HeaderValue to hyper::header module types to use its typed parsing facilities, as in the following.\nParaphrased from body-image/src/client.rs:\n``` rust\nuse self::hyper::header::{ContentEncoding, ContentLength,\n                          Encoding as HyEncoding,\n                          Header, TransferEncoding, Raw};\nlet encodings = headers.get_all(http::header::CONTENT_ENCODING);\nfor v in encodings {\n    if let Ok(v) = ContentEncoding::parse_header(&Raw::from(v.as_bytes())) {\n        for av in v.iter() {\n            //...\n        }\n    }\n}\n```\nTo prepare for hyper 0.12.x and take advantage of some other niceties with tokio reform, I've started attempting the port to the master branch of hyper. The typed hyper::header module is of course gone. Is there any plans or interest in (re-)offering this typed header facility as a standalone crate that can be used in a similar way as above? Possibly with some more direct support for the http crate types? Or would you suggest I independently implement the subset of the parsing I need?\nThis issue dates from 2014 and I suspect the release and migration to the http crate satisfies the original request, but I didn't want to create a duplicate before asking. Please advise.\n. I forked a hyperx crate, with the header module from 0.11.x branch (76fdbcf2) and have been using this to ease my migration and testing with tokio (reform) and hyper master branch (0.12-pre).\nhttps://docs.rs/hyperx\nhttps://crates.io/crates/hyperx/0.12.0\n@seanmonstar please consider this as a prototype and contribution to some future official extraction of the module.  So far I haven't done anything to make this play nicer with the http::header types. \nEdit: Add repo link: dekellum/hyperx. For anyone arriving here by searching for hyper and mmap, the body_image master branch (candidate for body_image 0.4.0 release) now has zero-copy/async. support for memory mapped http bodies using (glibc) madvise(SEQUENTIAL) (for aggressive OS read-ahead), and tokio-threadpool blocking annotation.\nThanks for publishing your bench results, @scottlamb. I have some non-hyper specific tokio benchmarks included in body_image as well (see CHANGELOG.md for those results.) An mlock strategy could also  be added there in the future. Another item that is currently lacking is  MAP_HUGE(TLB|_2MB|_1GB) , for lack of support in the memmap-rs crate, which is ripe for forking since its passively (or is it passive-aggressively?) maintained.\n. Edit: What follows was ill-informed on my part, but gives an example of how a new and foolish user might make the mistake of trying to instantiate a hyper::Error. See comment below. \nHi, I'm not sure this is still open for feedback or where its progressing, but given my evolving use case, I'm surprised by this opening comment:\n\nThe hyper::Error is the correct error type for the Client to return from its Future, as well as from the response's body stream.\n\nAs of hyper 0.11 this is of course a requirement, but I'm finding that awkward.  I'm implementing a client that needs to be resilient to retrieving large responses up to ~1GiB in size and processing these with more than one pass.  After retrieving a threshold size the client will switch from in-memory to buffering the response on disk.   In addition the client may wish to terminate response streaming early if the initial Content-Length header, or the actually received chunked response, is too large (for example, given available disk space.)  I don't want to panic in these cases, but I do want the body stream to terminate and hyper to close the connection (which won't be completely read).  These kinds of errors are entirely in the domain of my application, but as it stands, my best route is along the lines of:\n~~~ rust\nif length_to_read > self.max_payload() {\n    Err(IoError::new(\n        ErrorKind::Other,\n        format!(\"[APP] response body too large: {}+\", length_to_read)\n    ).into()) // -> hyper::Error\n} //...\n~~~\nAlso my disk based implementation can io::Error, but as it stands its going to be difficult without hacks like the above to reliably distinguish between I/O errors originating from the HTTP sockets and my disk impl. I/O errors. But distinguishing these is important to determine which should be retried vs. resulting in a fatal application error.\nMy personal ideal would be the ability to use the failure crate's Error type inside of FutureResponse::and_then and Body::for_each, or some kind of trait object.   If that is too high level or costly, then how about an AppError(u32) variant in the hyper::Error enum or a reserved application error range in a numeric hyper error?. Yes, thanks, but like with my above code example originating in hyper::Body::for_each(Fn) I would end up hoping(!) I'm the only one using ErrorKind::Other or prefix matching on \"[APP]\" in order to convert the sub-set of all possible errors that are my own applications errors. Its a hack at best.\n. No, unfortunately the logic that decides upon and produces the error needs to be in the Fn itself,  which is defined by hyper to return a Future with type Error=hyper::Error.. I'll try and get to where I can show more of my code, and my apologies if I'm explaining myself badly,  but the for_each passed Fn argument must (per Hyper) return a Future::<Item=(), Error=hyper::Error>. So I have my own application errors in here that I need to shoehorn through a hyper::Error and transform into something better outside, when the future is resolved.. @sfackler: thanks for your patient suggestions. I now finally get it, and its much better! I was missing the wrapping nature of Future/Stream map_err, and then the rustdoc for the [hyper::Body] stream with associated Error type set as hyper::Error gives the impression there is no further option:\n\ntype Error = [hyper::]Error\nThe type of error this stream may generate.\n[...]\nfn for_each(self, f: F) -> ForEach \nwhere\n   F: FnMut(Self::Item) -> U,\n   U: IntoFuture,\n\nSo now the issues opening comment makes perfect sense and I'll edit down my prior ill-informed input.  Since the issue title includes experience I would just suggest that somewhere between futures' or hyper's rustdoc and/or a hyper client demo with error handling including map_err and futures::future::err could save the next foolish user about 1.5 days! \nThanks again and sorry for the noise.\n[hyper::Body]: https://docs.rs/hyper/0.11.15/hyper/struct.Body.html#impl-Stream. Regarding just a naming aspect in this design. Chrono has a similar use of the same names for both a variant and nested sub-type.  There at least, it can be challenging to get the  use imports right without naming ambiguity. If there are natural names that avoid same-names, that can be friendlier, e.g:\n~~~ rust\nenum Connect {\n    OnResolve(Resolve),\n    OnHandshake(Handshake),\n}\n~~~. yes, to make it more compact.\n. That would definitely make the feature more pragmatic, less dogmatic, and better for users. . I've started doing this e.g. a public, documented, unused _FutureProof variant because I think the alternative approaches are dysfunctional at best.  I guess only time will tell if I can avoid criticism for breaking changes (e.g. adding error variants) with this approach.. Assuming that by users you mean developers/code using the Hyper crate, perhaps a better name for this is (error::)Application?  \"User\" might otherwise get confused, for example, with some authorization mechanism. . Thank you for giving feedback. \nFirstly, the use of run as used in the current doctest, will also panic if used in an executor. block_on is just more appropriate for a (doc)test than run, given the potential for a halt or live-lock if the client is not dropped, lazy not used, etc.  I think many users will start using hyper 0.12, as a client in particular, from the context of either a simple main() or unit tests, where block_on remains appropriate.   But I think your point of warning is still valid. Could a block_on example usage be acceptable if it included some more explanation or warning like the following?\nrust\n//! *Note*: Using `block_on` (or `run`) will panic if used in an executor,\n//! since these methods block.  For fully asynchronous client usage, use \n//! `spawn` instead.  This `block_on` pattern can be applicable as a starting\n//! point, in test code, CLI's, or batch processors.\n//! See the guide (link) for a fully asynchronous example using `spawn`.\nI have also made PR #1568 which uses spawn (as you suggest) in examples/client. Part of the rationale of using block_on in the doctest, is that its usefully different from the examples/client.  Another useful note in the doctest is to reference the example and/or the associated guide-level walk-through.. I've attempting a better problem statement in #1571. If replacing run in unacceptable, these proposals could be reformulated to just provide the alternatives along side. \n. > \"What would [new] users [of the Client] likely be trying to do?\"\nI think we've covered all of these potential starting points/use cases:\n\nUnit tests of client usage (ala TDD, even if its for testing a hyper Server application)\nInitially simple main for experimentation (scaling to a real CLI)\nclient requests in an existing asynchronous server or other tokio/futures application\n\nFor (1) I'm surprised and would like to better understand your reluctance to include a  block_on example. For my body-image testing, I've found that pattern quite useful, even for non-trivial tests:\nhttps://github.com/dekellum/body-image/commit/2c77175edcff382441aef90d7c0c2c86d3e43cbd#diff-31bbf71c54bca98a0ae3d40a327af940R642\nAs I'm sure you are aware, you can't just replace printing in the current example or doctest with asserts for unit tests. Asserts need to be performed in the test thread to properly panic the test runner.  I would also imagine you've built up a much more elaborate testing harness in hyper itself, but as far a I know, you haven't packaged that for end user reuse? Thus end users need to start from scratch.\nIn all of these use cases I think its important that the first bullet of this problem statement is addressed so that these aren't dead ends to achieve a real application.  My proposals do just that for use cases (1) and (2), as I've learned ways of doing it, the hard way, without a particularly helpful guide. It would also be nice to see an example of that in the full setting of use case (3).\n. ",
    "ayax79": "fixed semicolon compilation errors too.\n. ",
    "cyderize": "Oops, someone already else has a pull including this here\n. ",
    "aatxe": "You're correct. I misspoke. The final two examples join before printing anything.\n. ",
    "freiguy1": "Same issue here. I've simply made a hello world application which depends on hyper.  My Cargo's dependencies looks like this:\nhyper = \"0.0.16\"\n. ",
    "steveklabnik": "Ah!\n. http://hermanradtke.com/2015/07/12/my-basic-understanding-of-mio-and-async-io.html awesome introduction to mio\n. bah! of course. :cry: \nThank you so much, @zr40. I knew I had to be doing something stupid....\n. update: 0.9 was published six days ago.\n. This branch was just merged, it seems?. Landing this and cutting a new version would be great \ud83d\udc4d . I second @drusellers , and I think this is a great idea.. ",
    "daogangtang": "like: \nhttps://github.com/cyderize/rust-websocket\n. @reem yes, I realize it. Hyper can be the lower layer of it.\n. the same :(\n. nice, thank you.\n. @bfrog good. is there some code to show?\n. spawn multiple servers? listening the same port?\n. wow\n. nice, perfect work.\n. and I must said sapper on hyper mio branch is now very clear and comfortable to write, next we will explore how to work with diesel, db conn pool, background tasks, im chatroom and so on. \nThanks for async hyper, a perfect design. \n. @hexsel I notice.\n. ok\n. Come on baby, I want to ask when will  the initial workable version of hyper on tokio be ready more or less?  Could we participate in? Thx.\n. I can run it now.   Hope to reach the initial workable version quickly. :)   Including request body processing.\n. Thank you. Is it suitable to integrate tokio branch to upper web framework level now? Such as https://github.com/sappworks/sapper \n. nice\n. but, if I remove this, an error will occur later\n``\n   Compiling sapper v0.1.0 (file:///home/mike/works2/sapper)\nerror[E0525]: expected a closure that implements theFntrait, but this closure only implementsFnOnce--> src/app.rs:184:13\n    |\n184 |             || Ok(self_box)\n    |             ^^^^^^^^^^^^^^^\n    |\nnote: the requirement to implementFn` derives from here\n   --> src/app.rs:182:34\n    |\n182 |         let server = Http::new().bind(\n    |                                  ^^^^\nerror[E0308]: mismatched types\n```\nhttps://github.com/sappworks/sapper/blob/hyper11/src/app.rs#L184\n. hi, I can run it now.\nhttps://github.com/sappworks/sapper \nThx.\nSapper now follows up hyper's latest updates, and I bench them just now, it seems nice.\nhttps://github.com/sappworks/sapper/wiki/Dev-version-benchmark\n. ",
    "Detegr": "It seems that the nightly version Travis currently uses rustc 0.13.0-nightly (636663172 2014-12-28 16:21:58 +0000) is not able to build this. However, with the rustc I'm using this change was necessary.\n. ",
    "jamwt": "So, you guys facilitate providing a connector which retrieves an stream.  Those streams are coming out of a pool.\nThis stream is a wrapper as part of the pool implementation that attaches to drop so the stream can be re-added to the pool when it is done--if the stream is still \"healthy\".  This has different definitions for mysql connections vs. http ones, etc, but the general gist is \"can this stream be reused for the next request?\"\nSo the connection trait has a method called \"is_healthy(&mut self) -> bool\".\nHere's some application code using these abstractions:\n{\n    // client is hyper::client::Client, grabbed one from the pool which may or may not be reused.\n    // Easy to do this using `with_connector`.\n    let mut client = pool.client();\n    let response = client.get(/* something */).send().unwrap();\n    /* do something with response, which is regular ol' hyper::client::Response */\n}\n// drop()\nWhen the response drops, the stream wrapper drops, and it checks to see if it is \"healthy\" according to the definition of HTTP (keep-alive), and if it should be re-added to the pool for reuse.  This information is derived from the response headers.\nUnfortunately, it's not clear to me how else to get access to those response headers without some support from the HTTP framework, or without having to force the user (i.e., the application author) to remember to always explicitly pass the response into something...\nOr to completely replace the hyper client/request builder/response layer with wrappers all the way down, so that we were using a custom response object that we could implement Drop and have it check the inner response (the hyper one) for headers, and use into_inner to extract the stream, and then unsafe transmute the stream into the concrete type that we know it is... etc.  That seems like overkill, when this is the one piece of information missing (given with_connector) that's necessary to integrate with connection pools.\n. Okay, can do.\n. (I can't wait for rustfmt; good way to learn idioms is to have them thrust upon you.)\n. No, the \"built-in\" HttpStream is created and then dropped when used by the client currently, so it doesn't particularly care about the state of the response header; it's going to close anyhow.\nThis is for custom NetworkStreams that are part of a pool and have additional fields that track health.\n. (At least, so far; it's possible at some future date when client keep-alives are built into hyper in some fashion, that this method will be interesting again... but I'm treating that as out of scope of this change.)\n. ",
    "sunng87": "Same here. Still getting a few deprecated item error on the master branch. \n. ",
    "jakevn": "Duplicate of #219 \n. ",
    "martinsp": "regex and rustc-serialize are updated now and compiles on rustc 0.13.0-nightly (c89417130 2015-01-02 21:56:13 +0000)\n. ",
    "Gankro": "@reem Anything I can do to help with this fix?\n. Sadly not. :(\n. ",
    "globin": "Btw builds with mucell master, and carllerche/curl-rust#53.\n. Updated\n. ",
    "kstep": "Seems like curl is out of date and makes the travis build to fail =(\n. Thanks!\n. If you approve this way of action, I can try to implement it.\n. @reem, what do you think?\n. @seanmonstar actually I thought about similar design, although i wanted to expose get_headers() method on HttpContext as well. It looks like it takes much more effort to implement it, not due to feature complexity, but because of number of changes in existing code needed to pass this additional argument around.\n. Actually I used Location header definition as a model. And yes, I think it would be nice to make it Url, but I'm not sure it will work for every possible value, provided by, e.g., HTTP clients. It can be something like relative URL or something after all, just like Location, and at the parser method I don't have base URL.\n. But then headers must have access not only to a request, but to a response too. We need to generalize them if we want to do it this way, for example create HttpContext trait with common methods and implement it for both HttpRequest and HttpResponse.\n. This is the case, which makes me want for Rust to support implicits, like Scala.\nAnyway, I wouldn't like to make special exception for base URL in respect to passing to around to header parsers, as it looks not generic enough for me.\n. And I think, if Referer should wrap around Url, so should do Location. And it's a place for another issue, which I just created (#243).\n. ",
    "shaleh": "I am getting this when enabling a https proxy using the new code.\n$ cargo run --example client https://google.com/\n     Running `/home/perryse/repos/rust/hyper-upstream/target/debug/examples/client https://google.com/`\nthread '<main>' panicked at 'called `Result::unwrap()` on an `Err` value:  Ssl(OpenSslErrors([UnknownError { library: \"SSL routines\", function:  \"SSL23_GET_SERVER_HELLO\", reason: \"unknown protocol\" }]))', ../src/libcore/result.rs:746\nnote: Run with RUST_BACKTRACE=1 for a backtrace.\n    Process didn't exit successfully: /home/perryse/repos/rust/hyper-upstream/target/debug/examples/client https://google.com/ (exit code: 101)\nHere is the diff I applied to the sample client.\n```\ndiff --git a/examples/client.rs b/examples/client.rs                                                 \nindex 6d6a938..9c1edc8 100644                                                                        \n--- a/examples/client.rs                                                                             \n+++ b/examples/client.rs                                                                             \n@@ -20,7 +20,8 @@ fn main() {                                                                        \n         }                                                                                           \n     };                                                                                                \n\nlet client = Client::new();                                                                       \nlet mut client = Client::new();                                                                   \n\nclient.set_proxy(\"https\", \"my-proxy-server\", 8080);                                               \nlet mut res = client.get(&*url)                                                                 \n     .header(Connection::close())\n```\n. I will test it out tomorrow.\n. No dice.\n\n\n```\n$ git log -n 2\ncommit 46bef474f815da055816b6e76700575b350382bf\nMerge: eb2f90a 273e411\nAuthor: Sean Perry <>\nDate:   Wed Apr 27 08:12:02 2016 -0700\nMerge remote-tracking branch 'origin/openssl-opts' into shaleh/debug-proxy\n\ncommit 273e411a106dd8fd31efa8de7a969d0ffad64f47\nAuthor: Sean McArthur sean.monstar@gmail.com\nDate:   Tue Apr 26 18:37:49 2016 -0700\nfeat(ssl): improve default options for Openssl server and client\n\n```\nHere is the trace\n$ RUST_BACKTRACE=1 cargo run --example client https://google.com/\nRunning `target/debug/examples/client https://google.com/`\nthread '<main>' panicked at 'called `Result::unwrap()` on an `Err` value:   Ssl(OpenSslErrors([UnknownError { library: \"SSL routines\", function:  \"SSL23_GET_SERVER_HELLO\", reason: \"unknown protocol\" }]))', ../src/libcore/result.rs:746\nstack backtrace:\n   1:     0x7f746224c040 - sys::backtrace::tracing::imp::write::h3675b4f0ca767761Xcv\n   2:     0x7f746224e7cb -  panicking::default_handler::_$u7b$$u7b$closure$u7d$$u7d$::closure.44519\n   3:     0x7f746224e438 - panicking::default_handler::h18faf4fbd296d909lSz\n   4:     0x7f74622423fc - sys_common::unwind::begin_unwind_inner::hfb5d07d6e405c6bbg1t\n   5:     0x7f7462242888 - sys_common::unwind::begin_unwind_fmt::h8b491a76ae84af35m0t\n   6:     0x7f746224b5f1 - rust_begin_unwind\n   7:     0x7f746227decf - panicking::panic_fmt::h98b8cbb286f5298alcM\n   8:     0x7f746209808d - result::unwrap_failed::h7894835727094893990\n                    at ../src/libcore/macros.rs:29\n   9:     0x7f7462095a32 - result::Result<T, E>::unwrap::h2608118172930375710\n                    at ../src/libcore/result.rs:687\n  10:     0x7f7462093ad9 - main::h699de4ed11b187dfkaa\n                    at examples/client.rs:27\n  11:     0x7f746224e094 - sys_common::unwind::try::try_fn::h14622312129452522850\n  12:     0x7f746224b57b - __rust_try\n  13:     0x7f746224db2b - rt::lang_start::h0ba42f7a8c46a626rKz\n  14:     0x7f74620aa739 - main\n  15:     0x7f7460df7ec4 - __libc_start_main\n  16:     0x7f7462093628 - <unknown>\n  17:                0x0 - <unknown>\nProcess didn't exit successfully: `target/debug/examples/client https://google.com/` (exit code: 101)\n. Ok, this one is my fault. But may be helpful to others.\nWhile trying to debug proxy support I had setup a proxy using scheme = HTTPS. But HTTPS is not actually supported. All traffic needs to go through HTTP, then HTTPS if needed. This was the cause of the odd ssl error. A quick way to debug this:\n```\n$ openssl s_client -connect my-proxy:8080\nCONNECTED(00000004)\n140284460365472:error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol:s23_clnt.c:795:\n\nno peer certificate available\nNo client certificate CA names sent\nSSL handshake has read 7 bytes and written 295 bytes\nNew, (NONE), Cipher is (NONE)\nSecure Renegotiation IS NOT supported\nCompression: NONE\nExpansion: NONE\n```\n@seanmonstar I opened #774 to track the issue using a proxy.\n. correct\n. Yes please. Some of us need this to use Rust at work.\n. Something like:\nlet mut client = Client::new();\n// after checking config, env for HTTP_PROXY, whatever\nlet proxy = Proxy::new(server, port, scheme);  // AuthProxy::new for the more complicated cases\nclient.add_proxy(proxy);  // set_proxy, which ever. Bike shed as needed\n// now a request using 'scheme' will be proxied\nclient.get(....)\n. Note the requirement for a list of proxies. When the final HTTP call is made it should check the request's scheme against defined proxies for a matching scheme.\n. Since Rust does not support optional arguments I used AuthProxy in my example for the case where the proxy needs authentication. If this is too cumbersome using Option for the credentials is probably OK.\n. I think using a container for the proxies avoids the need for Option<Proxy>. Just walk it and compare schemes. Since the list will only every be a few items long it is sane to walk it. No need for a hash or other lookup table.\n. No worries, I do not need either lists or Proxy-Authorization.\n. At the moment there is an assumption that both HTTP and HTTPS will be handled by the same proxy. This could cause problems. While I do not need it I know others do require authentication support.\nAs for design concerns, is there a reason you made a new constructor instead of allowing the user to call something like add_proxy? Common use code will look something like:\nlet client = match read_proxy_env() {\n    Some(proxy_url) => {\n         Client::with_proxy_config(proxy::Config {\n             proxy_host: proxy_url.some_struct_value,\n             proxy_port: proxy_url.some_other_struct_value,\n             proxy_version: \"1.1\".to_string()\n         })\n    }\n    None => Client::new(),\n}\nExcept as I noted above this only works when one proxy config works for both settings. If there is a separate HTTP and HTTPS proxy things get more complex. This complexity needs to be duplicated in each and every client project using hyper.\nNot directly this patch's problem but reading env::var(\"http_proxy\") is not trivial. I need to use something like into_url on the string, then find the bits in the Url struct. Similarly how should one handle no_proxy? It would be nice if there was convenience help provided for this set of common env variables.\n. The code works as expected for HTTP requests with the caveat that all requests go to the proxy because there is no support for no_proxy or the equivalent.\nAny attempt to access a SSL url generates a SIGPIPE for me. \n. The point of a library is to make the application author's life easier AND to have one place to put redundant code.\nAlmost every user of the hyper crate will need to implement proxy support at some point. The crate should make it easy for the application author to get it right. Ideally this means stuffing as much proxy knowledge into the crate as possible.\nI'd like to see a baked in way to create a hyper based Client that read its settings from the environment. A similar bit of code that took a list of proxies instead of reading the environment would be another useful interface for those that want the proxy to come from their own configs.\nSorry, I would have written code instead of asking but I have been busy on other projects.\n. What is wrong with my commit message? Is it an unknown scope?\n. That would not surprise me. yay corp IT.\n. This works for HTTP like www.example.com but fails for HTTPS like https://google.com. I get a response back from the proxy server telling me the request is invalid.\nResponse: 400 Bad Request\nHeaders:\nPragma: no-cache\nContent-Length: 691\nCache-Control: no-cache\nContent-Type: text/html; charset=utf-8\nProxy-Connection: close\nConnection: close\n. This is the sequence that works via telnet/nc\nCONNECT www.google.com:80 HTTP/1.0\nUser-Agent: simple/1.1\nHost: www.google.com\\n\\n\nGET / HTTP/1.0\\n\\n\nNote the use of a port number instead of \"http://\". When I tried to use http://www.example.com I would get back an invalid request response.\nSince you have the is_proxied boolean now, calling the CONNECT as a preamble should be easy enough. This is what other C based http libraries are doing. curl is here https://github.com/curl/curl/blob/master/lib/http_proxy.c\n. Exchanging the 80 for 443 and starting the SSL/TLS stack should be enough to get HTTPS working.\n. Are you thinking for making a Client using something like Client.new_with_proxy(host, port)?\n. Or, HttpsConnector (and HttpConnector) could have a set_proxy() method that the Client could invoke when its own set_proxy is called. \n. NPN?\n. But it still proxies for connections to HTTPS sites, right? Lots and lots of websites are HTTPS these days.\n. Cool. Let me know when you need me to play QA again :-)\n. I will check it tomorrow. I had planned today but was busy.\n. I get a failure:\nthread '<main>' panicked at 'called `Result::unwrap()` on an `Err` value: Io(Error { repr: Custom(Custom { kind: Other, error: StringError(\"failed to lookup address information: Name or service not known\") }) })', ../src/libcore/result.rs:746\nwget, curl, etc. all work. I have not had the time to debug this. Sorry.\n. Bingo. I have had problems with other software failing if the variable left off the http://.\n. ",
    "GitCop": "There were the following issues with your Pull Request\n- Commit: 26850d14024b42e5b7f07444dfc5fe105d40888c\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. There were the following issues with your Pull Request\n- Commit: 26850d14024b42e5b7f07444dfc5fe105d40888c\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. There were the following issues with your Pull Request\n- Commit: ae326f2c166b5826a7b74df6251297aa11eaa5b3\n  - Invalid type. Valid types are feat, fix, docs, style, refactor, perf, test, chore, revert\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. There were the following issues with your Pull Request\n- Commit: 8e44720395755f57d44049e2ea2bf6806bf679d3\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n  - Invalid type. Valid types are feat, fix, docs, style, refactor, perf, test, chore, revert\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. There were the following issues with your Pull Request\n- Commit: 69d3aeba1f1793aed3a1b42b3180f6fe293e9135\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. There were the following issues with your Pull Request\n- Commit: 8d165c1f2f129ae1ea0ee38aee9951f6c2a4ccb8\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. There were the following issues with your Pull Request\n- Commit: 48186f4883222297f4840961edb82049e0b84d1b\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. There were the following issues with your Pull Request\n- Commit: f2750301ba56ef21539618281dee0e30b6abccdd\n  - Invalid type. Valid types are feat, fix, docs, style, refactor, perf, test, chore, revert\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. There were the following issues with your Pull Request\n- Commit: 893e8a97a2b3e556b54d60700ab37a87aa8389bf\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. There were the following issues with your Pull Request\n- Commit: 2c798348edba2e262bbedeb4d7b0d434cdfcaed1\n  - Your commit message body contains a line that is longer than 100 characters\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. There were the following issues with your Pull Request\n- Commit: afa8a1b314640b1e5d98d0d343aaa187153dc34c\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. There were the following issues with your Pull Request\n- Commit: f1523324c8dc45b859353c6b9d1498aa1771f68f\n  - Your commit message body contains a line that is longer than 100 characters\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. There were the following issues with your Pull Request\n- Commit: 5ecf54323d2dde70efe0c977bcd7bf6f7389a5cb\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. There were the following issues with your Pull Request\n- Commit: 12746b6076b62dd8167af2670ac345dc2497c36f\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. There were the following issues with your Pull Request\n- Commit: 7fef4c4ef72acc4bed2fb9948eaecea016afa395\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 97a9f5d207280c950797e1d8d92437234d1a2151\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n- Commit: e62cdfd7af7c3cd47247ef69b93f6da03357c058\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. There were the following issues with your Pull Request\n- Commit: fc776e815e1e5de7ae550014d254b23fdf957fc9\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n- Commit: e9a791f5d59e31fccc72c25a9ab674d51f69a9ed\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n- Commit: 689a842a3d0e0ac10de66eb2f0a53489875d9abf\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. There were the following issues with your Pull Request\n- Commit: c14bffb64ba9f27b5a09e001c22b3aca4465777d\n  - Your commit message body contains a line that is longer than 100 characters\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. There were the following issues with your Pull Request\n- Commit: fac65ff094f097a4c3cbbc7b226857dd1717ee0b\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. There were the following issues with your Pull Request\n- Commit: 37a71e8634988cc316cbcd8e86a60d2429d9050d\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. There were the following issues with your Pull Request\n- Commit: 841c1b421c2cc20b528f6813c61e05af3674926e\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 79cfffe43e005492bee83d8bd0f090cd8ecd7320\n  - Your commit message body contains a line that is longer than 100 characters\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 8182eb7776b24a4c3189dcd079870a5307d16558\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 3bb03749797747067c83f3f7175e7f82b76125f2\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: c1f80e0d7e4568dd382e580a129aff9426581c71\n  - Invalid type. Valid types are feat, fix, docs, style, refactor, perf, test, chore, revert\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 244994b7aa3151953768f7c025576365d7cfcaf0\n  - Invalid type. Valid types are feat, fix, docs, style, refactor, perf, test, chore, revert\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 03cb86ced0950d69175442ee6e904057ac9ac985\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 50442b197389eb638cc2cf5502fd231c894194d2\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 08e3b8d07b8ca2ad49c634288ee8228bca8343bb\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n- Commit: f48731c11ef41590cb92d05b0b28502c91df12c8\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n- Commit: 5cf7e1c2c4c2eb0b7da575aa13b5655039355130\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n- Commit: 321d6533e90d2dcc86f12f0f5ac19269c309501b\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: d134be98fe292fac5f78f8d5e285f50c5f19998a\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: de050aa3c7ba00865c0332833730325523e21518\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n  - Invalid type. Valid types are feat, fix, docs, style, refactor, perf, test, chore, revert\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: de050aa3c7ba00865c0332833730325523e21518\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n  - Invalid type. Valid types are feat, fix, docs, style, refactor, perf, test, chore, revert\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 1b69c8404dc884dad5d37bb81e7fbcec7855602c\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n  - Invalid type. Valid types are feat, fix, docs, style, refactor, perf, test, chore, revert\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 72313b28090f8148c31b0f43c308f26ca4dd3079\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 9b4b9e234068116abb442d5aac390e5cba197b0e\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n  - Invalid type. Valid types are feat, fix, docs, style, refactor, perf, test, chore, revert\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: fb8aea7f25818a0d7ac99cc673eac10864aa86fc\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 6a803990afe1c58f22d0e3ed326d051ad07e8bbc\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 85dac24238df2ea92155a7e99f8edcc4184a92be\n  - Your commit message body contains a line that is longer than 100 characters\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 00f3616a4c414cba4265d8073093d598b11185f9\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 861e7b71750aa53e90e83b4a91a440498b8da374\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: a701bab61c0acb42522fcb2859708545e48078b7\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 002727ede4f578e8f3ca18a12eb58316fc90043d\n  - Invalid type. Valid types are feat, fix, docs, style, refactor, perf, test, chore, revert\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 80176c61db23e34864dce7d42b426808278c149c\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n- Commit: 20178be4c89c2278203d3e37f13f72709e5bb6b1\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 73241252db142cc93830a71849101715a810cd4c\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 9bba39ea0ee5b1db08bfd7f4856a8e5ea7c04282\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 80dd268088a27ad3ffe23f40e9b13649a42f4720\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 3ce492a13535b223636212eb59c7f08995b0a791\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 3ce492a13535b223636212eb59c7f08995b0a791\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 6716c2c3f9d67bf9e2c844694abee4f87a0ad8c0\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 21699928e4f73ccf46ddffe39ba501ce738bb031\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n- Commit: ccee453f65f20f70d28f3da160e5a0b85d4d23e0\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 704f78a470b03783cf9eadf289d76201959d8ed9\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 387f2820c02079ff6df20e1e532eaaa639a640ae\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: db9fdbbcdb04e4ebd0b31fec5627a6942b71e886\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 0ee3a4609e250e3e116a495923b5022e8f5edb1c\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: d94e347141d4a5d9808b8720b3b429739f6d7b0a\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: d2f0cea53f0dac3cd4776ee0f79e8f767215355c\n  - Invalid type. Valid types are feat, fix, docs, style, refactor, perf, test, chore, revert\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 03262d343841ccac2c1a0f9b33fbec1e0b2df389\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n- Commit: 38d44fc6b36d93661127c160e7109f04b1d65750\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: b4f8ec489f6ecdba68e189ffc8bfdf95d78745dc\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: af831f47f299c910ee2ed0f5ea599f3d41bb9a7b\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n- Commit: 4ba3033a49119a6744c932cabf7c104db938f81b\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 81e4965f69e24c44939dbf4f2698d5143b54e03b\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 287dc391638a99ee8604f14926d4d81344fa8a4d\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n- Commit: 808ccdda443c6e6963124226185fea69b5a8a485\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 287dc391638a99ee8604f14926d4d81344fa8a4d\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n- Commit: 808ccdda443c6e6963124226185fea69b5a8a485\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 287dc391638a99ee8604f14926d4d81344fa8a4d\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n- Commit: 808ccdda443c6e6963124226185fea69b5a8a485\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 9fce21a3326fe46dcceaf28c359a252d1fbddf5b\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 9fce21a3326fe46dcceaf28c359a252d1fbddf5b\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n- Commit: ad27736ba355c3609b59ac51de0c1fd3d02c981d\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n- Commit: 2a242befce1895a3a4dd4d6d17309849836a83b3\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 28cfdeac55234c0088840be0b08d9132129a9635\n  - Your commit message body contains a line that is longer than 100 characters\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 50068d161da4b4b3e4395e5680f77d93f82718d8\n  - Your commit message body contains a line that is longer than 100 characters\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 7f922ba36a69bcf97f76f12e11ef7d6d4c125ba7\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 65ba136f02de49289966a7fb183b8890f3691de3\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 7b4554f551a7bc537f9be58a92cfefacddd7404b\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 16f53588040e1dc134ab49cbff7d2b4306d61268\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 2adcf41a02c553e771b0bdd796296a6fd4acc240\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 2adcf41a02c553e771b0bdd796296a6fd4acc240\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n- Commit: d4fcebc74bcb6e880636e8a4abdbef3b256f525e\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: c2690c1b6f48238fe112bca2ec651e7c3f3f5d84\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 5109c29956e3f8cb22618fde014fc0090223c831\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n  - Invalid type. Valid types are feat, fix, docs, style, refactor, perf, test, chore, revert\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 5109c29956e3f8cb22618fde014fc0090223c831\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n  - Invalid type. Valid types are feat, fix, docs, style, refactor, perf, test, chore, revert\n- Commit: 3ba3bcc2c7f3a1e91db2acab7b3629ee3fdb1ab2\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: ca133ad4f3a986533b5960dbc6d933b7f3cb7266\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: d0d3f29dd0b4cee8f2ef4bdf5d695adcf3a4c4fc\n  - Invalid type. Valid types are feat, fix, docs, style, refactor, perf, test, chore, revert\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 65777aed06e69e2ce48d436bdb915b5d0fffe496\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 65777aed06e69e2ce48d436bdb915b5d0fffe496\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: c30780b56de9f05bcc70c8b8a1e5a87b23064f3d\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 29af56969230ecf1db7e5dacf63ddae9bade346c\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 55101837b3f26357fbe6332c07075e839b20a44e\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 1d7655fd8f285e2a830e32c06516d1846e34940a\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 8f33a393b8fb36f85c976228a8c4006d34fcec75\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: eea3c2b4a366a7a5f3bda3ceadeeafec44d7a3de\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: eea3c2b4a366a7a5f3bda3ceadeeafec44d7a3de\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 3e1f2de5383fc1e4a1852412b423d0f0285fe345\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: eb7149de90c1850e155128a0544210783eb8451a\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n  - Invalid type. Valid types are feat, fix, docs, style, refactor, perf, test, chore, revert\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 84e6458b72b4e43bf0098162d2ec929e1b8532f3\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 308bf9b64c3b270d09b51ccbfa992b90c3faf491\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: d48b9ce83ff6b7e1c000ee9933a43df917cd995c\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n- Commit: 1e2928b789e5fc3bd7e3f3fe4a21f52a93567d96\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: f18ae05f2f1de7ad8069490958988e95f52288c1\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: d6f1980b1328cf7fe6247f8a2368c53bef2e60da\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n- Commit: 650c466da95982595576c7b9615a82cf625275fc\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 8a0f65bb92b0ef579e3f7a7d2b56dbdfe20ce014\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: eb03ce060abe76cd0a897c1263ea7338c47c5b67\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: e66bbb5a5f7749a98b6c53ac2cb6c349d2357924\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 3d5f555af6d376c1e42da0f9060cfe7b63b3dc5f\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 419aeee05e33e1a46b554cca0ef4139e18f885c7\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n- Commit: 0e80f7445cffd790583349ac6ab98195057f579b\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 268c4ea94410d16dd65f9c6f671d65982d634f55\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 3df236cc3116a9e8fb39437522e2f74cea8d557a\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 6a8c5c966e4db29f6353972b316d12bbf1c2d5fa\n  - Invalid type. Valid types are feat, fix, docs, style, refactor, perf, test, chore, revert\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: c720295e99d0f85e5f5311eb55de335136a45bb7\n  - Invalid type. Valid types are feat, fix, docs, style, refactor, perf, test, chore, revert\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 2ba4227d09656a5b7f2f0815d69e3c62869fdc9e\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 23b62cc90b01a645a14f4182e1de40327505999f\n  - Invalid type. Valid types are feat, fix, docs, style, refactor, perf, test, chore, revert\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: c82260d8c8a5287d8963ab1095ad231efe2ed338\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: eebbfe07f34fdef533705abdf1a8becf92b0b3a0\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 4bf4accc5a4b31724f2858858962bf741dde025a\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n- Commit: 6cf43c1bd0b72349de23530dddef0aadca37557c\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: e647e548631634c47a8eefacb139c100d2418424\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 581e01e685d1464b4bcaef8c11a76cb63e1381b0\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 884cf850cb48bde34dfa49a6ab8cec5891722330\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 7f975b0f3c232c044b8f57a4d0572dde159829f7\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: e100e6093ec5bdf2394dc1b28cb636deba4a2972\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: c65e0c9f4bdd8bbdfc2890fc26abbd47ae68954e\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 2bc5d0ff656427cbe1727456a57ba92d7918f2a2\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 496db4a54081d48f1adfc8403b29a24ac64067f5\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: c88a1f01e559189e9de22a0fad6cc9eb97c4c468\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: c471ce67da0a2b144374049479db2665277b2054\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: c5a8d8645f56633fae596001f541d7dafb75fa96\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 74f1cc0328d5d7ca94c703510ff09412cbd16ac4\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 52d772f218f294deb8701b226b62068819c5be24\n  - Invalid type. Valid types are feat, fix, docs, style, refactor, perf, test, chore, revert\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 2ad42d5ce53dbedde6065ab08d08776f6fd3b853\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 8d71fc03314a95655ba607bd1030b886eef20fe0\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: d7f675eee3fd32df7ed27b5ba9a9e615423c2d31\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: fe8d11d254d728d051ebf1accb562f887556255b\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 4e0253f3296f7cb246d552966288761020f85776\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n- Commit: 28746fcbe416fc6e5e91e10145bf026307406b6b\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\n- Commit: a9eec2d59c6112dd5577d870a025a4d5adfbdaed\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 13781287cca611a2c4f8787523ff28b2a8c34461\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n- Commit: 4b64374afb83276140fbc99a9e5ec1b7a6247c11\n  - Commits must be in the following format: %{type}(%{scope}): %{description}\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: 4a806eeb9c515974dab34326d973331b08d63f6d\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\n\nCommit: 99079e8193f9dad6d493811d1f446be701f00a7f\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: 03f3b42a771af41ade59ca0cb91274d1c8ac12e5\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\n\nCommit: f84a5369055702570b2ae3b2d34621d4db0f8ca3\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: 03f3b42a771af41ade59ca0cb91274d1c8ac12e5\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\n\nCommit: f84a5369055702570b2ae3b2d34621d4db0f8ca3\n\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\n\nCommit: 31b8cba4094550dbcde39c044a8ce1b08f1b2463\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: 03f3b42a771af41ade59ca0cb91274d1c8ac12e5\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\n\nCommit: f84a5369055702570b2ae3b2d34621d4db0f8ca3\n\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\n\nCommit: ecef9b67e99e0e5d1e8cd346ab4187209296f232\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: 03f3b42a771af41ade59ca0cb91274d1c8ac12e5\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\n\nCommit: f84a5369055702570b2ae3b2d34621d4db0f8ca3\n\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\n\nCommit: b977be3243b6f6d9f506ee1c4eb9d1b1d11246d6\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: 03f3b42a771af41ade59ca0cb91274d1c8ac12e5\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\n\nCommit: f84a5369055702570b2ae3b2d34621d4db0f8ca3\n\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\n\nCommit: 22d75f7cc6295f9c83f5d3c2577ef2a32dc0c9ec\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: 4d4857d84ac006c057c11c1ff9c3ec4891a44358\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: ff6a3d22a427a92c20363000a3370b84bf1eca9f\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: 6cdf656077073b437db4bd1c9754d40f30a2d85c\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\n\nCommit: 80ae945fcdf36e50c520a0cfee727ebd6c75aa0b\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: d27b6de84bdfe3d0b15f33d8bed653a4c380bcbe\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: 1d908f62b343fb92fade944d5e9b824ab602b7d1\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: b5b5a5cd585036f9b20186563013ec33d322416f\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: 6ad249df456f050c9f981beda8ae8e6e62eb7741\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: ecf678d2d39a72f744f7446ea3feda06355b8058\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: 0dcfd18e51b432f2b20a6345638577fc4256922c\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: 41fc8dff3360a955693247eee416ba0c5186f5ee\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: a0c5c8cb973e794cd31c9e9b53677f20de0c7236\nYour commit message body contains a line that is longer than 100 characters\nInvalid type. Valid types are feat, fix, docs, style, refactor, perf, test, chore, revert\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: 0ef8760ca393b19622fd3b8a80bdadcb21d8efe9\nInvalid type. Valid types are feat, fix, docs, style, refactor, perf, test, chore, revert\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: 54baa369bf31f7c9c95fda825579a12d77821aac\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: 54baa369bf31f7c9c95fda825579a12d77821aac\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\n\nCommit: a683af7f004fa8a6f6dd4399a9a959da1d638d9f\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: 6c74b5ff9d7699339efc102dd8fe40728816ca21\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: e6e478fa4d29b97a40fd366783bad4b88a40f435\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: f489de4d61162442b972ee7e4012e2b1e3c5de0c\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: ff4369835b002764d62525ad46bec3702ce6bf25\nYour commit message body contains a line that is longer than 100 characters\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: fc8280e5b3fe8a964b38db8d56cfaf4bcecccf49\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: e7a598e0086fa8aafa2836747d49c1d895fcf699\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: 7652b19f698aeeeac06ed21672f18348679ded8b\nYour commit message body contains a line that is longer than 100 characters\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: 89a69528642f335a7a845ce8767b61a13e410369\nYour commit message body contains a line that is longer than 100 characters\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: 222ef07b8e8e4ae655cbc57aae05766229d32637\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: 71fb78da4ac72f3e3e2e7a7ffaec3b3b1cda3c85\nYour commit message body contains a line that is longer than 100 characters\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: afff049dd2de9dc1387788b890c237ded4cc7265\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: 00e6b3479572423524a30c7cfaed11e4727749fb\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: bb6bebf371cdd2060202e69858954b3dca171172\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\n\nCommit: 387cc8749744854fdd30f1bd068ae56a00b7e5cb\n\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\n\nCommit: bb7056a3732c58610ce27be72fe1183b1989233b\n\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\n\nCommit: 3393155a47cc61c33b5ff351716f90bbc1e39c93\n\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\n\nCommit: c8fea8800f6e125e2d68bc3ff95ef8ad130391e7\n\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\n\nCommit: 3bac597b025b587fb6b7f4692d67dcd4f8c87672\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: bb6bebf371cdd2060202e69858954b3dca171172\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\n\nCommit: 387cc8749744854fdd30f1bd068ae56a00b7e5cb\n\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\n\nCommit: bb7056a3732c58610ce27be72fe1183b1989233b\n\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\n\nCommit: 3393155a47cc61c33b5ff351716f90bbc1e39c93\n\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\n\nCommit: c8fea8800f6e125e2d68bc3ff95ef8ad130391e7\n\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: cdf28ed4a416376506bd3678a3a20c0421a15be6\nCommits must be in the following format: %{type}(%{scope}): %{description}\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. Thanks for contributing! Unfortunately, I'm here to tell you there were the following style issues with your Pull Request:\n\nCommit: b3799a4a747409fd3568eedcc3930d5927fda08b\nInvalid type. Valid types are feat, fix, docs, style, refactor, perf, test, chore, revert\n\nGuidelines are available at https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md\n\nThis message was auto-generated by https://gitcop.com\n. ",
    "iwinux": "So sending data to channel in hyper handler will block for acquiring lock even we use an async sender?\n. ",
    "DeerOfBlades": "Hi !\nI was looking at the issues and this one turned up a question for me: how headers are dealt with?   \nI kinda had a clue looking at hyper/src/http/h1.rs, but I can't find references to how a a too long header field is dealt with (i.e: a Content-Type with an massive amount of chars as value) and how a massive amount of header fields is dealt with (I kinda crossed my eyes at MAX_HEADERS, but my Rust is not so advanced :c)\nTy for reading !\n. ",
    "xaviershay": "I tried and failed. Field notes:\nTried to write a test in src/http/h1.rs (after temporarily making MAX_BUFFER_SIZE public).\nrust\n    #[test]\n    fn test_parse_too_large() {\n        let mut request : Vec<u8> = b\"GET / HTTP/1.1\\r\\nHost:  \".iter().cloned().collect();\n        let mut long_header = vec!(b'X', MAX_BUFFER_SIZE as u8 + 1);\n        let mut footer : Vec<u8> = b\"\\r\\n\\r\\n\".iter().cloned().collect();\n        request.append(&mut long_header);\n        request.append(&mut footer);\n        let mut raw = MockStream::with_input(&request[..]);\n        let mut buf = BufReader::new(&mut raw);\n        println!(\"{:?}\", parse_request(&mut buf));\n    }\nWas able to get a Err(Header) result, but then wasn't sure whether a) that was correct, or b) what might then map that to a status. I was trying to elicit an Error::TooLarge response from parse method (line 867):\nrust\n        match try!(rdr.read_into_buf()) {\n            0 if rdr.get_buf().is_empty() => {\n                return Err(Error::Io(io::Error::new(\n                    io::ErrorKind::ConnectionAborted,\n                    \"Connection closed\"\n                )))\n            },\n            0 => return Err(Error::TooLarge),\n            _ => ()\n        }\nBufReader itself won't return an error condition, it does call try!(read) on the internal buffer though. Couldn't figure a way to wire up MockStream to it in a way that would fail properly.\nThen I tried a different approach: try to elicit failure with an end-to-end test.\n``` rust\nextern crate hyper;\nuse std::io::Read;\nuse hyper::Client;\nuse hyper::header::Connection;\nuse hyper::header::UserAgent;\nfn main() {\n    let client = Client::new();\nlet res = client.get(\"http://localhost:3000/\")\n    .header(Connection::close())\n    .header(UserAgent(std::iter::repeat(\"X\").take(1000000).collect::<String>()))\n    .send().unwrap();\n\nprintln!(\"{:?}\", res.status);\n\n}\n```\nThis panics on the unwrap:\nthread '<main>' panicked at 'called `Result::unwrap()` on an `Err` value: Io(Error { repr: Custom(Custom { kind: ConnectionAborted, error: StringError(\"Connection closed\") }) })',\nRunning against http://google.com (sorry google) I found a sweet spot at 100000 chars, where I get a PayloadToLarge response, which I can't get from hyper. Bigger than that I get a broken pipe error.\nI also tested against a naive Ruby webrick server and wasn't able to get a failure, it just takes longer and longer to parse the request (seems bad).\nBack to hyper, maybe the server is explicitly terminating the connection if some buffer size is exceeded? I tried using the server from the README and enabling logging with export RUST_LOG=trace (I see there are trace! calls already), but that only enabled tracing withing cargo and rustc, not my test binary or hyper. I placed a println! and a trace! next to each other right at the hyper entry point and only the println! worked.\nThen I gave up :(\nPotential next steps for anyone who wants to pick this up:\n- Figure out how to enable tracing (this should be straightforward...)\n- Find where (if?) hyper is explicitly closing the connection on large headers, using the test client code above.\n- Work backwards from there.\n. I'm getting conflicting messages from this thread. If the problem is that os error isn't useful, that's coming from fmt of a non-hyper IO error. So handing off error formatting of non-hyper errors (such as IO) to fmt wouldn't actually address the initial example. Right?\n. I hit this problem, found this issue, brew link openssl --force worked for me.\n. Fixed the gitcops\n. Ignore me, I got confused. This still compiles fine.\n. ",
    "ctjhoa": "Hi @reem @seanmonstar,\nI've made some work on this but I'm stuck with a test.\nhttps://github.com/ctjhoa/hyper/commit/d1b4563ada8821df308cbd3ab88696fe854b5a50\nIn test_check_error_431 the mock return 2 responses and I don't know why.\nCan you tell me what am I doing wrong and if the structure meet your expectations?\nThanks.\n. ",
    "rsolomo": "@pyfisch and @reem, I think the Basic scheme for Authorization headers is no longer publicly available after this change, unless I'm missing something?\n. Sending a server-sent events through Hyper should be possible, by setting the header Content-Type : text/event-stream on a response and calling write with a serversent event payload.\nHowever, it may be worth noting that this will keep one of your threads busy.\n. I don't know how or if it would be possible spawn a new thread per EventSource connection in Hyper.\n395 should make use cases like this nicer since we won't be using a thread for each connection.\n. ",
    "ProtectedMode": "@adwhit, GitCop is talking about your commit message, just amend the message and force push it.\n. @reem, could you please pull this? I want to see if I can get Iron's static working.\n. @reem, okay, thank you.\n. ",
    "knevcher": "Now it works. Thanks.\n. ",
    "ashleysommer": "Oh wow, thank you so much for adding this.\nI was maintaining a local modified version of Hyper with exactly this change in Handler, specifically so I could pass the request/response into my system entry point.\n. Thanks for jumping on it so quickly. I'm excited about this work.. I believe this can be closed now.\n. Oh, yes, creating a hyper::Body that is just a wrapper around the tokio_proto Body is a good idea, so that you can implement Into<Body> on that.\nThen if that hyper::Body was exposed publicly, I could do impl Into<hyper::Body> for MyResponseBody and be able to pass MyResponseBody directly into set_body(). That way I don't need to add a dependency on tokio_proto into my application, and can simply use hyper::Body.. Another point to make. Currently hyper::server::response::Body and hyper::client::response::Body are both separately defined to tokio_proto::streaming::pipeline::Body. Would a hyper::Body replace both of those? Will server::response::Body always be the same as server::client::Body, regardless of what tokio_proto Body it is using?. closed by https://github.com/hyperium/hyper/commit/f1785dc5700129db26889f55969e9f9b2e22ac7a. Added another commit.\nRemoved the two different IntoBody traits from client::response and server::request.\nReplaced them both with a Into<Body> using the new body::Body (in the from of From<> impls).\nThere was one difference between the two existing implementations of IntoBody for Vec<u8>,\nclient::request used this implementation:\nfn into(self) -> Body {\n    let (mut tx, rx) = Body::pair();\n    ::futures::lazy(move || tx.start_send(Ok(Chunk::from(self)))).wait().unwrap();\n    rx\n}\nand server::response this this implementation:\nfn into(self) -> Body {\n    let (mut tx, rx) = Body::pair();\n    tx.start_send(Ok(http::Chunk::from(self)));\n    tx.poll_complete();\n    rx\n}\nI understand the difference between the two, but unfortunately we cannot have two different impls with this blanket implementation of hyper::Body. I've gone with the latter implementation for the Into<Body> impl in this commit.\nPart 2/2 Closes #969\n. Thanks for the clarification about the different implementations.\nI see now that using that implementation does cause some client tests to crash (specifically the tests like client_post which include a body with the request) because it is calling tx.start_send() when not inside a futures::task;\nI assumed that when creating a Body, we would always be inside a futures::task, but I will need to rethink that.. ",
    "rphmeier": "Update: It looks like Hyper has moved to an internal thread pool rather than the deprecated (?) TaskPool since the this issue was posted. \nI'd suggest probably to close this, since I'm not sure anyone wants this feature or whether it's even useful.\n. ",
    "u2": "How to spawn any threads for one server?. ",
    "bestouff": "And now: \nCompiling hyper v0.1.7\n     Running `rustc /home/xav/.cargo/registry/src/github.com-1ecc6299db9ec823/hyper-0.1.7/src/lib.rs --crate-name hyper --crate-type lib -g -C metadata=24a8dc85bc5bf743 -C extra-filename=-24a8dc85bc5bf743 --out-dir /home/xav/toysarust/target/deps --emit=dep-info,link -L dependency=/home/xav/toysarust/target/deps -L dependency=/home/xav/toysarust/target/deps --extern openssl=/home/xav/toysarust/target/deps/libopenssl-9e47789a605aabbf.rlib --extern rustc-serialize=/home/xav/toysarust/target/deps/librustc-serialize-8214bc2e838e96ca.rlib --extern mime=/home/xav/toysarust/target/deps/libmime-115ca8125c42dc12.rlib --extern unicase=/home/xav/toysarust/target/deps/libunicase-88de2458e97b894d.rlib --extern cookie=/home/xav/toysarust/target/deps/libcookie-4a08a2c06bb5c4fc.rlib --extern time=/home/xav/toysarust/target/deps/libtime-24f9c2dbbbc6f19b.rlib --extern unsafe-any=/home/xav/toysarust/target/deps/libunsafe-any-3f018797a3613438.rlib --extern url=/home/xav/toysarust/target/deps/liburl-4c384fb33b0bde93.rlib --extern log=/home/xav/toysarust/target/deps/liblog-4e79c2d7625e8c6f.rlib --extern mucell=/home/xav/toysarust/target/deps/libmucell-ac2514f1ba9841c5.rlib -Awarnings -L native=/usr/lib/x86_64-linux-gnu -L native=/home/xav/toysarust/target/build/time-24f9c2dbbbc6f19b/out`\n<log macros>:5:31: 5:59 error: mismatched types:\n expected `_`,\n    found `log::LogLevelFilter`\n(expected integral variable,\n    found enum `log::LogLevelFilter`) [E0308]\n<log macros>:5 ; let lvl = $ lvl ; if lvl <= $ crate:: max_log_level (  ) {\n                                             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~\n<log macros>:1:1: 6:70 note: in expansion of log!\n/home/xav/.cargo/registry/src/github.com-1ecc6299db9ec823/hyper-0.1.7/src/lib.rs:156:9: 157:6 note: expansion site\n/home/xav/.cargo/registry/src/github.com-1ecc6299db9ec823/hyper-0.1.7/src/lib.rs:154:1: 158:3 note: in expansion of todo!\n/home/xav/.cargo/registry/src/github.com-1ecc6299db9ec823/hyper-0.1.7/src/http.rs:176:17: 176:55 note: expansion site\n. ",
    "stchris": "Yes, I only fixed the build. Not sure how to fix the tests, though :(\n. Cheers! :+1: \n. ",
    "xymostech": "@reem Done!\n. ",
    "hugoduncan": "Would you like these squashed to a single commit?\n. The equality issue is in QualityItem for quality values that can't be exactly represented by f32.\nI added a bench, squashed, and rebased.\n. I am happy to add an enum for the charset type, but I think we would need to agree which list of charsets to include (and have the capability of specifying a string).  Would the list in the \"Preferred MIME Name\" column of the IANA rgistry (as suggested by rfc2616) be suitable?\n. The suggested list has 24 entries, which seems reasonable to me.  @pyfisch Would you be interested in owning such a crate (seems it would go well alongside rust-language-tags)? @seanmonstar would you be OK adding such a dependency?\n. Just noticed https://github.com/lifthrasiir/rust-encoding.\n. I addressed @reem's comments and squashed.\n. I see IfNoneMatch was added.  For consistency, I would have no objection to @fmendez adding an IfMatch that paralleled his IfNoneMatch implementation.\n. I'm not happy with this, but haven't found an alternative yet.\n. @seanmonstar Uncommenting this line fails, and I'm not sure why.\n. Just to be sure, it should be like this?\nQualityItem { item \u2026 quality: 0.9f32 },\n. I added the wrapper with the thought that it could be shared between IfNoneMatch and IfMatch, and to have something to implement a function on for checking if an entity matched.  Since IfNoneMatch and IfMatch need to use different versions of entity tag matching anyway (weak vs strong), maybe that is less important.\n. ",
    "lifthrasiir": "@seanmonstar lifthrasiir/rust-encoding#64 is probably relevant. I'm not sure whether this is truly desirable or not though.\n. ",
    "sbstp": "I'm pretty sure the Shift-JIS bug is still there.\nI added a test, assert_eq!(Shift_Jis,\"Shift-JIS\".parse().unwrap()); and it doesn't work.\nThe line \"Shift-JIS\" => Shift_Jis, never matches and it goes straight to Ext(\"SHIFT-JIS\").\n. Do you want me to PR a fix?\n. I was only going to fix the parsing part, since uppercase should handle mixed case.\n. People are probably going to use it anyway, it would be nice for it to have a clean API. People should know the risks taken when using this method. \nFor instance, I'm currently working on a tiny library that gets your external ip address using UPNP. There is a mandatory header called \"SOAPAction\" whose value never changes. I have to take a &'static str and convert it into a vector, and then put that inside another vector. I could also create a custom header, but that would generate a lot boilerplate which is for the most part, unnecessary.\n. I can create a pull request for this if you want it. There's still the issue of this bypassing the safety mechanisms though.\n. Shouldn't that be \"SHIFT-JIS\" since you're using uppercase?\n. ",
    "fmendez": "My pleasure!! :smile: \n. ",
    "andydude": "I am interested in being assigned to this, but I might look around the hyper source first.\n. I would like to help with this.\n. ",
    "DemiMarie": "Hyper now uses asynchronous I/O, so HTTP/2 is no longer blocked in async I/O.\n. May I ask what the advantage of the h2 crate is over the rust-http2 crate?. The correct solution for your company is to install the certificates in a place where OpenSSL will find them.\n. @seanmonstar Basically performance.  I would like to see Hyper be as fast at HTTP as any server/client written in C or C++.\n. @seanmonstar I am thinking of the various String and Vec allocations for data structures such as HTTP headers, as well as the parser objects themselves.  The String and Vec allocations can probably be handled better by arena allocation, however.\n. @seanmonstar What is the bottleneck currently?\n. @seanmonstar My thought would be to create a server and client on localhost and benchmark the rate at which they can send messages to each other.  In general this will not be accurate, since machines are too different.  However, if we do this on for machines that should be fairly consistent (ex. Travis CI) we should be safe.  \nAlternatively, we can come up with a way for compensating for differences between machines.\n. @seanmonstar By \"custom allocator\" I mean something like arena allocation for strings, not a better malloc.\n. Not quite; this is more about using techniques like arena allocation, while\n927 is more about pooling.  But if you want to handle both as one issue\nthat's fine.\nOn Oct 10, 2016 1:44 AM, \"Sean McArthur\" notifications@github.com wrote:\n\nThen this sounds identical to #927\nhttps://github.com/hyperium/hyper/issues/927\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/929#issuecomment-252541013, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AGGWB1sYxnuEqxCvNMqI64tfArILU0oiks5qydDEgaJpZM4KSFwz\n.\n. Is there any activity on the tokio branch?\n\nOn Oct 19, 2016 03:38, \"Zimon Dai\" notifications@github.com wrote:\n\nalert: I am keeping an eye on tokio branch and as far as I can say, the\nbranch is broken and could not even compile. So if you want to try\ntokio-hyper (like me) try a fork\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/934#issuecomment-254736081, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AGGWB9jBytkncIpi4hek-Sp5bsMJ5YPRks5q1ckDgaJpZM4KW-a6\n.\n. That makes sense.\n\nIt seems that hyper is becoming a base on which other, higher-level HTTP libraries are written, rather than one that is used directly by the end-user.. My suggestions:\n\nrunning under gdb and placing a break on _exit.\nchecking your logs to ensure that there is no panic message.. \n",
    "stepancheg": "I have kind of working HTTP/2 implementation: httpbis. (\"httpbis\" is a name of working group developing HTTP/2, \"bis\" traslates as \"twice\".)\nhttps is used in my implementation of gRPC (which works over HTTP/2).\nIt is a fork of @mlalic's solicit library, which was largely rewritten. Now it contains missing HTTP/2 parts, and it is rewritten using tokio instead of being synchronous.\nIt implements most of HTTP/2 spec, including multiplexing and proper windowing.\nProper windowing means that client or server won't send WINDOW_UPDATE request untill Stream passed to user callback is polled. So for example, connection won't stall, and memory won't be exhaused if user provided callback is slow.\nCurrent status is that it works, however, it needs lots of polishing, including:\n documenting\n testing\n finding and fixing bugs\n adding configuration options\n designinig better API\n improving performance\n(And I could use help for these issues).\nIf someone's interested I'd like to merge it into Hyper somehow.. @DemiMarie author of rust-http2 here. rust-http2 is buggy, poorly documented and barely maintained. I'd like to build a proper library from rust-http2, but I don't have time. rust-http2 was created as a base for grpc-rust. And I'm probably going to replace rust-http2 with h2 eventually in grpc-rust.. ",
    "lilith": "HTTP/2 support is huge for performance. Globally 82% of clients support it - 93% in the USA.\nIs HTTP/2 support planned for hyper 1.0?. I have the same use case as @thibaultdelor, and am seeing the same problem. Using hyper 0.9.12 and rustc 1.14.0-nightly (5665bdf3e 2016-11-02). ",
    "avkonst": "Could you please advise when hyper 0.12 is coming?. That is unfortunate dependency :( Is it feasible to have 2 releases with the first one releasing this feature?. Thanks. It seems it would require to go one level lower, than the level of abstraction provided by hyper + iron for me.  I would expect that the web framework like Iron will benefit automatically from Hyper being http2 capable. Plus, it seems h2 does not handle http 1.1 and alpn, it says it is only http2 \"parser\".. @carllerche I understand this is on volunteer basis \ud83d\udc4d  I see big potential in Rust and trying to setup development with Rust, where I work. It turned out that the main objection I receive is not the learning curve, but availability of solid http stack. I understand that bits and pieces are there, which can be glued together into complete solution.\n\"solid\" I (and people around me) mean, like Vert.x or Jetty are solid in Java: setup of a client or a server in few lines with reasonable defaults and completes (such as HTTP 2, streaming, pipes, async). In case of Scala layers over, all the APIs are async Future based too.\nI understand that Rust will get the same API completeness one day, I see it happening now. However, making any business case today is hard without knowing the release date of essentials like this ticket. In my case, it would be easier to influence other people saying something like: \"you know, I understand lack of http 2 support is a concern for us, but while we are developing new product with what is available today and trying it out with few customers, it would be perfectly fine. And in X months it will get upgraded to http 2 with minimal impact anyway\". \nIf I knew this number X, it would be extremely helpful.\nPS: one of the reasons of rapid Go adoption (although I do not like Go at all), was \"solid\" HTTP and networking stack.. @seanmonstar Thank you! It is great to know this :). Completely agree with the above comment.\nWhat is the behavior, when timeout is 0 ms?\nI consider it totally appropriate to reject new connections and free related resources immediately if they can not be accepted due to lack of handlers allowed. It is unlikely that there will be anyone allowed in 10ms (or whatever small interval), but context for timeouts and inbound connections will be held in RAM. \nUpper layer should be notified about such rejections.. \"We don't want to allow multiple live HTTP/2 connections to a single host.\"\nIf single HTTP2 connection is congested, it might be reasonable to open the second connection. Not always, but sometimes it could be a required policy. I think it should be client's decision, not done by hyper.. \"Of course, since the connection pool is used by a Client, a user could by pass it in hyper by just making a new Client...\"\nThere is no a reason for a client to be naughty without a good reason :) And the only good reason to have the second connection is congestion, high latency or other factor indicating low performance. This information should be exposed to a client to make a decision, and a client should be able to instruct hyper whether to allow the second, third and so on connection... PS: I also assume that the second connection might easily target alternative IP address, in case DNS is resolved to multiple addresses.. The server does alpn negotiation according to the description. The other\nserver (based on jetty in java) also does alpn negotiation. I had many\nclients in various languages successfully communicating with my server but\nrust client does not.\nOn Fri, 22 Jun 2018, 05:36 Steven Fackler, notifications@github.com wrote:\n\nHTTP2 over TLS must be negotiated via ALPN according to the spec, so the\nserver might be refusing to perform the handshake.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/1574#issuecomment-399184772,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ADyZVW3yipUYVgaVKNer5o87yJZG1q2vks5t-9mZgaJpZM4UxZrF\n.\n. @sfackler what should I change in the posted reproducer code in order to make it using ALPN?. Thanks, I will try this.. Could you please clarify one moment? I see hyper-tls uses native-tls, which uses openssl on Linux. Is it expected that the proposed change is already supported by native-tls by default?. @sfackler, thank you! is there a ticket for native-tls to subscribe to? how long do you think it will take?. \n",
    "szagi3891": "What changes are planned in the \"Tokyo\"?. ",
    "rpjohnst": "@szagi3891 tokio-rs/tokio-rfcs#3. This looks like a duplicate of #309. The workaround for 0.9.x is to make sure that either 1) the entire request body is read, or 2) that the connection is closed after handling the request.. ",
    "carllerche": "@avkonst you can use the h2 crate as is today.. @avkonst I would say that calling h2 a \"parser\" is a bit unfair. We are using already with great success. As you can see here setting up ALPN is not hard. Also, you don't need http 1.1 to do prior knowledge.\nThat said, all the work is happening on a volunteer basis, so if the release doesn't match your timeline, I would suggest trying to pitch in ;). The issue is essentially about being able to reuse the same reactor core that hyper is using. The best way to do this IMO is for hyper to have a way to initialize w/ a provided Handle. This would allow a third party to manage the reactor loop and libs are then able to run on any loop instead of every lib owning their own lib.\n. There are potentially some extra calls to flush that were added before the park / unpack semantics were figured out. They can probably be removed at some point though I am a bit worried about breaking existing code that happens to rely on it (hyper might be relying on them). If the request future is dropped, then that can trigger a cancellation. The\nexample with select above will drop the request future if the timeout\ncompetes first. That is how the request is cancelled.\nOn Sun, Mar 19, 2017 at 10:55 AM \u0141ukasz Kurowski notifications@github.com\nwrote:\n\nThanks, that explains a lot.\nI can't see any correlation between timeouts and request, how can I ensure\nthat request is cancelled after timeout?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/1097#issuecomment-287634290,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAAYJALkjAv9KTabGbGlLPWdx8nj6mgxks5rnWwTgaJpZM4MhxZh\n.\n. The answer is 2. It is pointless to dual license under MIT and Apache2 as you gain none of the Apache2 protection.\n\nNot only that, but the process of re-licencing by getting all individuals who submitted contributions to click a checkbox is untested in court and highly dubious in my view. I am going to avoid explaining why I think it is dubious given that I am not a lawyer.. @sanmai-NL the main issue, I believe, with Apache 2.0 is that it isn't GPL compatible.\nHyper is already MIT, so there is no issue there.. I believe that is the plan, but doing so would require a breaking change (thus a 0.x bump).. I'd like to help work on this, but I would feel like I have a better sense of how everything should fit together once some of our work on h2 and other surrounding libs start to stabilize.\nThat said, it is good to start writing this down.. I'm still not seeing the problem with Incoming. If it yields an error, that is the error. Then you try to poll incoming again. and it should yield the next socket.. @seanmonstar that contract isn't actually accurate. Stream returning Err is implementation specific. See: https://github.com/alexcrichton/futures-rs/issues/206.\nThe Incoming stream is intended to allow polling after an error is returned. None represents the final state.. @seanmonstar Re: the for_each example, the current expectation is that you would add an or_else before the for_each to handle the error.. I don't have much context here. I'm not sure what exactly Connect instances are supposed to do for hyper. I don't know why passing a Uri is required.\nAs I'm sure you are aware, I have my stab at a connect trait here. It seems to pan out well as it is.. Unfortunately, netbsd only compiles in CI as we don't have any resources to actually run the tests.\nIt is possible that there is a NetBSD only bug.. The Buf trait is kind of like a more specialized Iterator<Item = u8>. IntoBuf is like IntoIterator. You can approximate the answer to \"when should I use Buf or IntoBuf\" by thinking about Iterator and IntoIterator.\nRoughly speaking, structs should usually be generic over Buf. This is assuming that the struct impl only needs to iterate the Buf one time (since Buf has no seek).\n\"Leaf\" APIs should take IntoBuf for convenience. This allows passing in &my_vec and what not. The leaf apis would immediately convert from IntoBuf -> Buf.\nIf one needs to iterate a buffer multiple types, then taking IntoBuf is necessary. However, IntoBuf takes self by ownership, so the strategy is to bound with where for<'a> &'a T: IntoBuf. This allows calling my_t.into_buf() multiple times (and iterate the type multiple times).\nI hope this helps.. Well, I would still like to figure out if it is a bug in Tokio or not.\nIt sounds like it is not a Tokio bug, but I'm not sure what the best way to confirm this would be.. A very clever approach. I wonder if it can be simplified a bit, while maintaining the same strategy.\nThe goal is to keep the tasks that are spawned private while being able to pass in either a Send executor or a !Send executor.\nPerhaps one strategy might be to define:\nrust\npub trait HyperExecutor<S, B, I, N, E, W>: Executor<H2Stream<S::Future, B>> + Executor<NewSvcTask<I, N, S, E, W>>\nwhere S: Service,\n           B: Payload\n           W: Watcher<I, S, E>,\n{\n}\nIf H2Stream and NewSvcTask are private, it should be impossible to implement HyperExecutor, but making HyperExecutor public would allow the trait to be clicked in the docs and the trait could be documented to explain how it works and what the user should pass in.. If there is a strong reason to have two traits, so be it.. Unfortunately, that API is a hazard that exists due to backwards compat... it should be improved in 0.2.. @seanmonstar It is still useful to get a handle to the current reactor and not a lazy handle... but it is by far the minority case.\nSo, the question is how to reduce the hazard while still being able to access the functionality.. Well, and Handle::current can start the global reactor... which was deprecated a while ago.... I don't want anymore background ever :) I wonder if getting a handle to the current reactor should be a fn not on Handle.\nreactor::current() or something.. But yeah, I'd take a PR for deprecating Handle::current() at the very least... even w/o a replacement should be OK.. +1 on MakeConnection.. AFAIK, tower-hyper is an experiment. At some point, hyper proper will support tower types & traits.. Roughly, I think the proposed step of introducing Tower support without introducing any breaking changes is good. This would add initial support while we figure out the best \"breaking change\" API.\nLooking at hyper::Client, it does look like it should implement Service itself. You are correct that it does a lot internally, but in 0.12, the simplest strategy will be to just implement Service for it. Once a breaking change happens, I think the best option will be to have struct Client<T: HttpService = DefaultStack> { ... } or something.\nI think there may be an alternate way to add support for tower_http_service::Body... Starting with Client:\nYou don't have a bound on B in the struct definition, so you can impl tower::Service for Client<B> where B: tower_http_service::Body. The same strategy may work with the server half. Basically, you ignore the Payload trait when implementing the tower traits.\nI do think that we should explore what an 0.13 API may look like more in tower-hyper before committing on breaking changes.\n. ",
    "mgattozzi": "This seems like a good plan. Allows opt in breakage and can let people experiment before the 0.12 release and can let them use http2 while those who are okay with waiting can continue with http1.1. This is what I need as using OpenSSL 0.7 for Hyper is blocking using other libraries I want to use.. @seanmonstar Thanks for the heads up. I'll open it up on there end or find a solution there. If I get one I'll close this!. I've found a work around for now that involves direct String manipulation. Not ideal but it works. I'll close this issue here since it's not Hypers fault.. I don't know if it's wasteful still but I look at it like I'm constructing a future to be executed on an event loop (in this case Tokio Core). In my Github library I pass around a reference to the core construct the Future based off the Request and then send it off. You can see the bit of code that does that here No need to pass Client around or anything. You could just pass the Core around in the Struct instead. That being said I don't know if this is the best way to do it but I've not found any issues with it personally.\nI'm not as sure about number 2.. I learned something new and moved the client internally as well so it all works out!. ",
    "cyndis": "The client can also get an EndOfFile but there it should be handled correctly, here the issue is that the server code thinks the EndOfFile is coming from the acceptor, not the stream. So really, we probably should be turning all IoErrors from the stream in accept() into something else so that they are not confused with IoErrors from the acceptor. I guess ConnectionAborted would be a good choice. That would hide the underlying reason, but I can't think why it would be ever needed.\n. Here's v2 according to what I described in the previous message. I will squash these once the patch is ready.\n. Great, I'll squash.\n. Whoops, something went wrong there..\n. Fixed.\n. Thanks for a great library :)\n. ",
    "durka": "We should fix this, or advertise the behavior in blinking red marquee in the documentation. I had no idea where to start when I ended up with order-dependent 404 errors in my application (because one POST form submission had content, and the next one had an invalid HTTP method due to this bug).\nWhat scenarios motivate not wanting to read the entire request out of the network buffer?\n. I'm thinking maybe I should publish my Drain adapter as a mini-crate! It's an Iron middleware that reads out an unread request so that the socket can be reused, up to some limit, and if the limit is reached and there's still more data then it closes the socket.\n. @reem done\n. ",
    "SergioBenitez": "I just ran into this issue. This is a rather major issue as it completely breaks Hyper's abstraction over HTTP. That is, it breaks Hyper. If it's not going to be fixed, at least place a warning in the documentation as @durka notes.\n. Does simply not marking a socket keep-alive solve the issue? My main grievance is not based on whether Hyper should or should not read any remaining data, it's that Hyper fails to parse the next HTTP request correctly, resulting in bogus structures. I don't believe not marking the socket keep-alive prevents this from happening. If that's the case, then this isn't any better than the status-quo. If it does prevent this from happening, then it seems like this issue can be closed.\nCan you explain why this can happen at all? Why not fast-forward the stream until after the previous request's content? That is, if a request has been dropped and a new request is reusing that old request's socket, advance the stream by old_Content-Length - (current_read_position - old_headers_size) bytes.\n. @seanmonstar \n\nWhile that's true in the current blocking IO code, but it is not that way in the async branch. If a request body is not completely read (in async branch), hyper will drop the socket, not try to parse a new one on it.\n\nExcellent. That solves the issue for me.\n. I've submitted https://github.com/hyperium/hyper/pull/975 to fix this for 0.9.x. Note that this is a breaking, albeit minor, change. It's up to @seanmonstar to accept it now.. Note that the Travis-CI failure is unrelated to my PR.\n. @seanmonstar ping.\n. @seanmonstar Everything works as expected: the buffer will be refilled, and reading will continue. I explicitly tested that keep-alive continues working as expected.\n. That's right, but the original Reader shouldn't be used after calling take_buf. Even then, in the worst case, the SizedReader will simply say that there was an eof.\nIn a soon-to-be released project, I keep the TCP stream around for later reading. The current API forces me to keep around two lifetimes if I want to keep the TCP stream around, neither of which are necessary. With this API, I don't need to keep any lifetimes around, and I can rewrap the stream in more friendly APIs.\n. Hi @seanmonstar, still waiting on this. With very high probability, I'll be publishing my crate next week, and I'd really like to not have a fork of Hyper on crates.io. Let me know. If it helps with getting this out, I'd be happy to add a #[doc(hidden)] tag so that others don't use this unnecessarily.. @seanmonstar Can we get a new release with this change?. @seanmonstar ping. Thanks so much! :). It's certainly not very graceful to call expect there. I've mended this in https://github.com/SergioBenitez/Rocket/commit/1e5a1b89409feb827b0d1ee20525191d17ad5c13. Unfortunately, I don't think this will solve @TheFreakLord's issue.\n@TheFreakLord Can you post the full HTTP Request that's causing the problem? This will help determine if the request is valid and we can move forward from there.. I don't believe dropping the stream closes the socket unless the peer closes the socket as well. This results in socket leaks when you use something like NGINX on top of Hyper because the sockets are never closed. Empirically, this resolved a leak (> 250MiB of memory used after a few days, which resulted in killing the server) when paired with NGINX.\nWhat's more, if the client simply ignores the Connection: close header (which is what NGINX does), then you also get a socket leak. Among other things, this makes it pretty easy to DoS the server by sending it data that it never reads and just sits in a socket buffer.. ",
    "golddranks": "Has this fix included in any release yet? I'm encountering the bug with 0.9.10.\n. Allright, thanks for the info :)\n. No, it's the upstream changes that broke the thing. OpenSSL and Cookie now use new paths. (Sorry, I kinda participated in making that happen, but then again... THEY broke because their upstream dependencies moved to use the new paths. So something's gotta be done.)\n. Btw. I'm currently tinkering with Hyper, trying to fix things. No promises (I'm a rust noob), but I'll send a PR right away if I manage to get it to build.\n. Oops, gonna rephrase the commit line. (Edit: or just do nothing, since there was another PR :D)\n. There was several same kind of PR:s yesterday. The bottom line: an actual fix will be commited soon, before that, just edit your Cargo.lock privately.\n. ",
    "sapsan4eg": "Guys, issue was open in Feb 2015, almost two years. In hyper 0.10  the problem does not repeat itself, but when the scheduled release? As I understand 0.9x is not compatible with 0.10. And this does not solve the current problem with 0.9x. . That issue was closed but not solved. As I understand it the only way out is to move to 0.10. But the release has not yet been. And 0.9x is not compatible with 0.10. And this does not solve the current problem with 0.9x.. ",
    "matthauck": "ping. Has this change been released yet?. Interesting. I was looking at the docs for hyper::Body and didn't see any From<Stream>.\nI will take a closer look at those links, but I'm a bit skeptical as both of those docs are in the server guide section. \nAt the very least, it may be interesting at least to add to the client guide a example of how to stream a large file upload.. Aha, and my rust beginner status shines through. :) \nGreat, I will give that a look.. I see. I didn't think i could mutate the status/headers after setting the body. I will give that a try.. Thanks. That worked! It does feel a bit backwards to set the body before setting the status/headers, but that did the trick with no .unwrap()! :tada: . ",
    "Wilfred": "If you're not happy using select! in hyper itself, how about adding an example to the README? It took me a little fiddling to get it working, so having an example would have helped me.\n. ",
    "wezm": "Once set_read_timeout is stabilised it can be used to add timeout support, yes?\n- http://doc.rust-lang.org/nightly/std/net/struct.TcpStream.html#method.set_read_timeout\n- http://doc.rust-lang.org/nightly/std/net/struct.UdpSocket.html#method.set_read_timeout\n. Sure, doesn't look all that helpful though. I can tell you that it's the unwrap on send .send().unwrap(); that is panicking though:\nstack backtrace:\n   1:        0x1050720df - sys::backtrace::write::h0f2fc53eb11eb814gWr\n   2:        0x105075464 - panicking::on_panic::hd617a4042e8486fciUv\n   3:        0x10506b245 - rt::unwind::begin_unwind_inner::hd84dfec22ac3667d1Bv\n   4:        0x10506bad6 - rt::unwind::begin_unwind_fmt::h5bb6fa95bd57b24bFAv\n   5:        0x105074d3c - rust_begin_unwind\n   6:        0x1050949d5 - panicking::panic_fmt::hea516303ab7688d0lwy\n   7:        0x104fad606 - result::Result<T, E>::unwrap::h5683422046223242116\n   8:        0x104fad22c - main::ha0a39c096ced901bjaa\n   9:        0x105076f88 - rust_try_inner\n  10:        0x105076f75 - rust_try\n  11:        0x105075c68 - rt::lang_start::h04063553a12d35edNOv\n  12:        0x104fd7b1e - main\n. Sure, happy to help any way I can:\n``\n     Runningtarget/debug/requestTRACE:hyper::client: send Get Url { scheme: \"http\", scheme_data: Relative(RelativeSchemeData { username: \"\", password: None, host: Domain(\"files.wezm.net\"), port: None, default_port: Some(80), path: [\"testpodcast.xml\"] }), query: None, fragment: None }\nTRACE:hyper::client: host=\"files.wezm.net\"\nTRACE:hyper::client: port=80\nDEBUG:hyper::net: http scheme\nDEBUG:hyper::client::request: request line: Get \"/testpodcast.xml\" Http11\nDEBUG:hyper::client::request: headers=Headers { Connection: close, Host: files.wezm.net, }\nTRACE:hyper::buffer: slicing (0, 1408, 4096)\nTRACE:hyper::header: raw header: \"Server\"=[110, 103, 105, 110, 120, 47, 49, 46, 54, 46, 51]\nTRACE:hyper::header: raw header: \"Date\"=[87, 101, 100, 44, 32, 48, 54, 32, 77, 97, 121, 32, 50, 48, 49, 53, 32, 48, 53, 58, 53, 48, 58, 51, 52, 32, 71, 77, 84]\nTRACE:hyper::header: raw header: \"Content-Type\"=[116, 101, 120, 116, 47, 120, 109, 108]\nTRACE:hyper::header: raw header: \"Last-Modified\"=[77, 111, 110, 44, 32, 49, 54, 32, 70, 101, 98, 32, 50, 48, 49, 53, 32, 48, 52, 58, 52, 51, 58, 48, 57, 32, 71, 77, 84]\nTRACE:hyper::header: raw header: \"X-Varnish\"=[50, 57, 56, 52, 57, 51, 32, 50, 57, 56, 52, 57, 49]\nTRACE:hyper::header: raw header: \"Age\"=[52, 51]\nTRACE:hyper::header: raw header: \"Via\"=[49, 46, 49, 32, 118, 97, 114, 110, 105, 115, 104, 45, 118, 52]\nTRACE:hyper::header: raw header: \"Transfer-Encoding\"=[99, 104, 117, 110, 107, 101, 100]\nTRACE:hyper::header: raw header: \"Connection\"=[99, 108, 111, 115, 101]\nTRACE:hyper::header: raw header: \"Accept-Ranges\"=[98, 121, 116, 101, 115]\nDEBUG:hyper::client::response: version=Http11, status=Ok\nDEBUG:hyper::client::response: headers=Headers { Transfer-Encoding: chunked, Via: 1.1 varnish-v4, Accept-Ranges: bytes, Date: Wed, 06 May 2015 05:50:34 GMT, Server: nginx/1.6.3, X-Varnish: 298493 298491, Age: 43, Content-Type: text/xml, Connection: close, Last-Modified: Mon, 16 Feb 2015 04:43:09 GMT, }\nTRACE:hyper::client::pool: PooledStream.drop, is_closed=true, is_drained=false\nthread '<main>' panicked at 'calledResult::unwrap()on anErr` value: HttpIoError(Error { repr: Os(57) })', /Users/rustbuild/src/rust-buildbot/slave/beta-dist-rustc-mac/build/src/libcore/result.rs:729\nAn unknown error occurred\nTo learn more, run the command again with --verbose.\n``\n. The test case above works fine (does not panic) as posted. I tried adding aConnection: close` header and it still works fine. :confused: \n. Just read the man page for shutdown on Linux and OS X. From that point of view they should operate identically (of course the actual implementation may differ).\n. The hyper test case works when Connection close is removed. The TCP example when edited as follows also works, with and without the Connection close header.\nrust\n    let mut stream = net::TcpStream::connect(\"files.wezm.net:80\").unwrap();\n    stream.write_all(b\"GET /testpodcast.xml HTTP/1.1\\r\\nHost: files.wezm.net\\r\\n\\r\\n\").unwrap();\n. Yup, panics with the same error as the original test case.\n\nOn 7 May 2015, at 10:34 am, Sean McArthur notifications@github.com wrote:\nHm, what if you change the tcp example to call shutdown twice?\n// ...\nstream.shutdown(net::Shutdown::Write).unwrap();\nstream.shutdown(net::Shutdown::Write).unwrap();\n// ...\n\u2014\nReply to this email directly or view it on GitHub https://github.com/hyperium/hyper/issues/508#issuecomment-99659400.\n. Cheers, thanks for your help and responsiveness.\n. I tracked down the problem and have come up with this as a fix but I'm new to Rust and this project so you may have a better approach: https://github.com/wezm/hyper/commit/4a42f43cefca076fc3dd3bdf871e19292b23e3b1\n. \n",
    "Ryman": "@softprops It's due to the new scoping rules, you need to bring params and body to be declared above builder.\n``` rust\nfn main() {\n  let mut client = Client::new();\n  let uri = Url::parse(\"https://api.service.com\").ok().expect(\"malformed url\");\n  let params = vec![(\"foo\", \"bar\")];\n  let body = form_urlencoded::serialize(params.into_iter());\n  let mut builder = client.post(uri);\nbuilder.body(&*body);\n}\n``\n. Shouldn't this be using http://doc.rust-lang.org/std/net/enum.SocketAddr.html?\n. Updated to notallowthe lint, mainly due to travis having multiple rustc versions active and that it should be easy to fix these when type ascription lands due to fixme annotations.\n. According to [this](http://doc.rust-lang.org/std/marker/trait.Reflect.html) the bound should beAnyrather thanReflect + 'staticasAnyimplies that?\n. Could be related to #368 \n. @e-oz See the second example here, under **\"To recover from a poisoned mutex\"**: http://doc.rust-lang.org/std/sync/struct.Mutex.html#examples \n. See [here](https://github.com/hyperium/hyper/blob/master/.travis.yml#L9-L11), you need to enable the feature flag, see [here for more info](http://doc.crates.io/manifest.html#the-[features]-section).\n. Thedrop` tests don't seem to actually test the body itself is flushed?\nThe branching on PhantomData looks like a neat technique!\n. @seanmonstar I mean that the tests seem to only check with a zero byte body in the response, I wonder if it's a benefit to include a test that actually ensures a body is dealt with appropriately?\n. ``` rust\n[macro_use] extern crate mime;\nextern crate hyper;\nuse hyper::header::ContentType;\nfn main() {\n    // With macro\n    println!(\"{}\", ContentType(mime!(Application/(\"x-www-form-encoded\"))))\n// With unwrap\nprintln!(\"{}\", ContentType(\"application/x-www-form-encoded\".parse().unwrap()))\n\n}\n```\n. @AAG81 In your above example you can do \nrust\n.header(ContentType(\"application/x-www-form-encoded\".parse().unwrap()))\n. @seanmonstar They build a modified String on the stack so they can't use &str in this case?\n@arnm I think something similar to the below may work for you (assuming you import the IntoUrl trait):\nrust\nfn get<'a>(&'a self, path: &'a str) -> RequestBuilder<'a, Url> {\n    let url = self.url(path); // builds fully qualified url as String\n    let url = url.into_url(); // convert it to an actual Url instance\n    ... // use url, same as before\n}\n. To get you unstuck, this example should help: https://github.com/hyperium/hyper/blob/master/examples/client.rs\n. @GildedHonour http://hyper.rs/hyper/hyper/client/struct.RequestBuilder.html#method.headers\nrust\nlet res = client.post(\"..\")\n                .headers(headers)\n                .send()\n                .unwrap()\nFor the second, you might want to look at http://doc.rust-lang.org/rustc-serialize/rustc_serialize/json/fn.encode.html\n. @brycefisher You should be able to replicate something like this https://github.com/hyperium/hyper/blob/388ddf6f3b1ea734bc28f6b161bb9d52643d49a6/src/header/common/expect.rs#L47 \nGood luck!\n. cc @reem @untitaker for prior art downstream @ https://github.com/iron/iron/pull/397, may have opinions on this.\n. @seanmonstar Not sure if that's a genuine appveyor failure? Looks like a timeout on one of them, and the testrunner not completing on the other?\n. @miolini you may want tcp_tw_reuse instead if you're worried about the server specifically: http://stackoverflow.com/questions/6426253/tcp-tw-reuse-vs-tcp-tw-recycle-which-to-use-or-both/6427337#6427337\n. @untitaker for my own reference, what went wrong with a version range?\n. Does this not warrant a version bump since it will break downstream crates which depend on cookies = \"0.1\" which interop with hyper?\n. If lib foo depends on cookie 0.1 to build a CookieJar and passes it to hyper::Cookie::from_cookie_jar then it'll be a version mismatch I think, as cargo will not use the same version between foo and hyper as they are semver incompatible? \ni.e. error: expected CookieJar, found CookieJar (with different crate versions)\n. I've confirmed that when I pull this branch and use it as a local override, then nickel-cookies fails to build:\nbash\nsrc/cookies.rs:55:52: 55:55 error: mismatched types:\n expected `&cookie::jar::CookieJar<'_>`,\n    found `&cookie::jar::CookieJar<'_>`\n(expected struct `cookie::jar::CookieJar`,\n    found a different struct `cookie::jar::CookieJar`) [E0308]\nsrc/cookies.rs:55                 header::SetCookie::from_cookie_jar(jar)\n                                                                     ^~~\nsrc/cookies.rs:55:52: 55:55 help: run `rustc --explain E0308` to see a detailed explanation\nsrc/cookies.rs:55:52: 55:55 note: Perhaps two different versions of crate `cookie` are being used?\nsrc/cookies.rs:55                 header::SetCookie::from_cookie_jar(jar)\nI don't mind fixing it in this case, but this kind of thing is a breaking change which in some cases may be non-trivial to fix :(\n. Yeah, it can be a pain. The re-exports should help in future, I think, but (at least at the time) there were suggestions that it might not be a good practice to follow in general though on an issue I logged about this: https://github.com/rust-lang/cargo/issues/1636#issuecomment-105704163\n. I think it's only an issue when there's a diamond of dependencies, where two crates re-export something from another, and a downstream crate has to use both of these together. I think that's pretty rare though and warrants a more stern look at deciding what upstream versions to support in that case.\nSo my opinion is that re-exporting cookie (or whatever else) is worth doing. :+1: \n. > providing a set_status function which takes an S: Into, though it still is a bit of an ergonomic hurdle\nThis is what I would suggest too, seems more flexible and people don't have to remember to deref the mut reference. (Personally, I see foo.set_status(..) as more ergonomic than *foo.status_mut() = ..)\nfwiw, the error when you make the mistake is:\nexpected `hyper::status::StatusCode`,\n    found `hyper::status::scoped::ClientError`\n(expected enum `hyper::status::StatusCode`,\n    found enum `hyper::status::scoped::ClientError`) [E0308]\nWhich doesn't seem that bad to me, perhaps adding some suggestion of using .into() in the docstring could help? The From implementation gets listed under the docs for StatusCode while the blanket impl of Into doesn't appear on the docpages for the specialisations :( \n. Okay, should I rebase to the first commit or just close the PR?\n. There's a lot of self.0.foo action, would it make sense to implement Deref / DerefMut on Conn?\n. I haven't spent enough time with the new api to know if it'll be a problem, but I imagine if deconstruct is available it'll probably be fine :)\n. If this is the allocation you are referring, I think you can convince the compiler by changing a number of the signatures to fn foo(&mut self) -> &'a str to unlink the return value's lifetime from the mutable borrow of self (lifetime elision) and instead link it to the structs buffer.\n. ",
    "soc": "I just experienced this. For simple use-cases like \"download this file\" the dependencies of cookies are really unfortunate.\nCookies depends on various unicode libraries, and unicode stuff is quite large due to the need of a lot of code and/or data to handle all the rules.\n. ",
    "mneumann": "@reem: How about rather closing the connection on drop unless the read was fully exhausted? That should be safe. \n. ",
    "renato-zannon": "@Ap0ph1s I don't know if this is a satisfactory answer for you, but on the web app world it's common to use a reverse proxy (commonly nginx) to serve static files and deal with slow clients. Since nginx is event-driven, it doesn't need a big thread pool to handle a big number of clients, and you can remove that concern from your backend server.\n. Seems that travis' rust is outdated. I tested on rustc 1.0.0-nightly (dfc5c0f1e 2015-02-18) (built 2015-02-19)\n. @reem I tried to address your comments on the last commit. I refrained from changing the non-blocking behavior of Server::listen - even though that would be necessary to make it possible to close over non-`static data - because that would be a breaking change. It should be relatively straightforward to do though, and I would be happy to do it.\n. Those are from a recent breaking change. I'll download the new nightly and fix that!\n. @reem I've updated the PR again even though it is still WIP, because there's an an error I haven't been able to figure out by myself - from lines 252 to 256 on src/lib.rs:\n```\n[allow(unconditional_recursion)]\nfn _assert_send() {\n    _assert_send::>();\n    _assert_send::();\n}\n```\nError:\nsrc/lib.rs:254:5: 254:48 error: the trait `core::marker::Send` is not implemented for the type `<str as collections::borrow::ToOwned>::Owned` [E0277]\nsrc/lib.rs:254     _assert_send::<client::Request<net::Fresh>>();\n                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/lib.rs:254:5: 254:48 note: `<str as collections::borrow::ToOwned>::Owned` cannot be sent between threads safely\nsrc/lib.rs:254     _assert_send::<client::Request<net::Fresh>>();\n                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nIf I comment these lines out, hyper compiles, and all tests pass.\nBTW: turns out there were lots of breaking changes on the nightly. Let me know if I should squash all these fix(rustup) commits.\n. Boiled this down to Cow<'static, str>. This doesn't compile:\n``` rust\n[allow(unconditional_recursion)]\nfn _assert_send() {\n    use std::borrow::Cow;\n    _assert_send::>();\n}\n```\nFails with:\nsrc/lib.rs:256:5: 256:38 error: the trait `core::marker::Send` is not implemented for the type `<str as collections::borrow::ToOwned>::Owned` [E0277]\nsrc/lib.rs:256     _assert_send::<Cow<'static, str>>();\n                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nsrc/lib.rs:256:5: 256:38 note: `<str as collections::borrow::ToOwned>::Owned` cannot be sent between threads safely\nsrc/lib.rs:256     _assert_send::<Cow<'static, str>>();\n                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nerror: aborting due to previous error\nCould not compile `hyper`.\nEven though this compiles fine:\n``` rust\n[allow(unconditional_recursion)]\nfn _assert_send() {\n    use std::borrow::ToOwned;\n    _assert_send::<::Owned>();\n}\n```\nWhich seems contradictory to me.\n. @seanmonstar Cool :) Even though they can be a bit tedious, these changes are a great way to get early exposure to the codebase. Maybe in the future I'll be able to submit more interesting PRs :)\n. Yes, I found this odd too. Took me a while to figure out where to put the bound\n. ",
    "Vikaton": "@renato-zannon Thanks! Ill keep that in mind.\n. ",
    "mhristache": "Seems parts of it was fixed on master but there is one issue left (check use header::HeaderFormat; below) causing the whole macro to fail:\n```\n    impl ::std::fmt::Display for $from {\n        fn fmt(&self, f: &mut ::std::fmt::Formatter) -> ::std::fmt::Result {\n            use header::HeaderFormat;\n            self.fmt_header(f)\n        }\n    }\n:11:14: 11:20 error: unresolved import header::HeaderFormat. Maybe a missing extern crate header?\n:11 Result { use header:: HeaderFormat ; self . fmt_header ( f ) } } }\n``\n. I guess thenote: write[..]instead` are due to https://github.com/rust-lang/rust/pull/22502. The error seem to be caused by https://github.com/rust-lang/rust/commit/a99e698628cbd396c8100ef776d10ac61d911847.\n. @akoskaaa read_to_string() was changed in the new io module. Looks like the example needs to be updated. Here is how I modified my code to make it compile:\nuse std::io::Read;\n    ...\n    let mut body: String = \"\".to_string();\n    try!(res.read_to_string(&mut body));\n. I have a bunch of use cases where disabling certificate validation is needed, mainly related to use on machines not connected to internet (the case at my company):\n-  self signed certificates are used on most of the machines\n-  the CA files are not up to date (e.g.  machines are using older OSs)\nMore than that, it should also be possible to enable old, insecure ciphers in a relatively easy way mainly to be able to talk to clients/servers not supporting TLS1.2 (everything using Java 1.7 or older).\nHyper should be flexible enough to support these use cases. Defaults can be to enable most secure options but give the user the possibility to configure hyper according to his/her needs.\nI have opened https://github.com/hyperium/hyper/issues/811 for this.\nEdit: fix a typo\n. cc @pyfisch as he is the one which added the commits mentioned above\n. I guess you can append the identto the name of the test function as the ident has to be unique anyhow.\n. Any updates on this?\n. Well, it didn't check the host before so I don't really get your point. \nAlso, there doesn't seem to be an easy way to disable hostname verification, is there? Any suggestion on how to achieve that?\nOtherwise I will have to use 0.8 or switch to curl.\nThanks\n. Just found out that I can force the previous hyper version by setting \"=0.9.3\" in the Cargo.toml for the crate where the binary is created, which propagates to all libs using hyper, so I will use that for now.\n. @tarcieri you are correct but so far hyper released a new minor version every time a breaking change was added.\n@sfackler As @MoSal mentioned, libcurl provides ways to disable the host verification and I want something similar for hyper. I will try to play with the Openssl context as you suggested in the other thread.\nSetting the CA file does not help my use case as I would have to ask the user to provide the path to the CA file which is basically killing the ease of use of my tool for no good reason (it's an internal tool, running in an environment without internet access, all servers are trustable etc).\nThanks for your comments\n. @tarcieri thanks for the clarifications, I already said in my previous comment that you are correct in regards to semver. Also, I would appreciate if you keep the irony out of your comments. I don't find it friendly and I expect only friendliness and love from the rust community :). Thanks\n@paragonie-scott I was expecting a minor version bump as was (almost) always the case with hyper breaking changes so far.\n. ",
    "naps62": "I'm getting the exact same issue. Also tried against master, resulting in the same partial fix\n. ",
    "Byron": "When using the compiler version mentioned by @renato-zannon, the build, tests and benchmarks work for me too.\n. Oh, actually, the benchmarks seem to hang, like a deadlock of some sort. I am on OSX 10.10.2, in case it matters. Also it's the first time I am running hyper benchmarks, and thus can't tell if this hang is new.\nI will keep going, in the hopes that this is just a bug in the benchmarks.\n. I have quickly put together my own version of it - it's by now means representative in terms of quality, but it is something I can use for now.\nhttps://github.com/Byron/yup/tree/master/lib/hyper-mock\n. Good - I will keep working on my own little fork for my own use, and in time, it will be published on crates as yup-hyper-mock, with all the due credits intact. Unless you have a better idea, or concerns, of course.\n. :D ! I didn't scroll down in the diff and missed the important part.\nFunny - maybe next time, I'll be first.\n. Besides, would it be possible for you to publish a new release ? I am suffering from this bug :(.\nThank you\n. Thank you.\nBut how would aggregation work within generics ? The APIs I write use generics a lot, and these need traits.\nUnfortunately, there is no Client trait yet.\nEven better than that would be if there was a RequestBuilder trait, and a generic parameter for it in the Client. That way, I could sneak in my own which could insert the respective headers.\nMaybe something along the lines of this:\n``` Rust\npub struct Client {\n    connector: C,\n    redirect_policy: RedirectPolicy,\n_m: PhantomData,\n}\n```\n. ### Just for the record\nThe original issue was not solved. A hyper Client is missing a trait, which makes it more difficult to implement new kinds of Clients, some of which may automatically deal with authentication under the hood.\nAs the RequestBuilder is finally issuing the send() call, it would also be sufficient to be able to replace the RequestBuilder with an own implementation, possibly by adding a generic parameter for it in the Client type. After all, most people would want to inject an Authorization header field.\nClosing the issue without actually dealing with the described problem is behaviour I do not approve of. In case the point made here is not clear or faulty, then this was not made clear in the previous communication either.\n. Considering I didn't (even) get the subject's grammar right, I'd be happy if you would open an issue that is more to the point, the way you see it by now.\nAfter all, I still believe that hyper can improve in the realm of extensibility, and should pursue this path further.\nThank you\n. @seanmonstar It's alright :) - I might have been reacting a bit strongly to this too, had a bad day.\nThe reason I seem to be so much into having a Client trait  primarily because I see the Go code for youtube APIs which is happy just with an OAuth-enabled client. I thought it might be a wrong move to enforce my own Trait to make that usable with generics, and would have preferred such a 'tool' to be delivered by hyper.\nGo\nfunc New(client *http.Client) (*Service, error) {\n    if client == nil {\n        return nil, errors.New(\"client is nil\")\n    }\n    s := &Service{client: client, BasePath: basePath}\n    s.Userinfo = NewUserinfoService(s)\n    return s, nil\n}\nBy now I feel differently about it. Currently I just take a hyper-client and an authenticator, which takes care about providing tokens for authentication. That looks very much like this and feels OK to me, at least on the client side.\nOn the side of the implementor, you see that not having a Client trait forces me to carry around the NC type parameter. Maybe there are other ways to get rid of it though ... after all, I am only interested in the hyper client and don't care what connection mechanism it might use.\nMaybe some day there will be a clear idea on how these cases can and should be tackled, and we do the right thing\u2122 to our APIs to make them as nice and easy to use as possible.\n. Oh, and it would be great if you could make a release right away, as I am still suffering from this bug.\nThank you :) - using alphas is fun !\n. That's what I am doing, and thanks to buggy cargo it recompiles hyper whenever I run cargo test, and I run it a lot.\nWould it hurt to have a working version in the meanwhile ? Travis likes it too, so will everyone just pulling hyper from crates.io today.\nA working version is a merge and a publish away, which helps everyone today. Tomorrow is another day, which should upgrade to std::io to track latest.\nHope I make sense ... .\n. Thank you :) ! My change shouldn't even conflict with anything you cooked up in the meanwhile. If you merge, you'd just have to remember to undo my changes to track the latest openssl. Seems doable, let's see what @seanmonstar thinks about that.\n. Thanks for that idea, this actually works ! It's important to put these in the right order though:\n``` toml\nopenssl = \"= 0.4.3\"\ncookie = \"= 0.1.13\"\nIf hyper would be listed before openssl, there would be a version conflict. Makes sense.\nhyper = \"*\"\n```\nCompiling feels so much better now. Besides, I learned something new about cargo today, which shall help me to remain independent and workaround all of the current issues.\n. That I tried in the very beginning - cargo would keep overwriting the file, it seems it's not really supposed to be edited.\nCargo.toml works fine though.\n. Thanks - from what I found so far is that APIs get more usable the more Traits they support. Especially if generic APIs want to use your types, more traits are better.\nHaving a Trait for the hyper::Client for example would make my code more readable. Currently it looks like this ...\n``` Rust\npub struct DeviceFlow {\n    client: C,\n   [...]\n    _m: PhantomData,\n}\nimpl DeviceFlow \n    where   C: BorrowMut>,\n            NC: hyper::net::NetworkConnector {\n    [...]\n}\n```\n... and the problem is that I need to keep NC around to denominate the correct hyper client. Maybe there is another way, but I didn't find it :(.\n. General note: I just noticed that having a trait for a type makes it harder to use actually, as the trait needs to be imported as well to allow using any trait method. This is a general annoyance in Rust to me, as this should only be necessary if there is ambiguity. The more generic code is involved, uses get more convoluted too.\n. To my mind, if hyper is supposed to be low-level, it shouldn't try to be particularly smart and try to 'help' the user with default values. Those usually cause confusion if they are not totally obvious. If someone writes a client or uses a default one to communicate to a particular server, he or she will notice soon enough that the server isn't happy without a user agent field.\nFrom my own experience, and I am a total beginner when it comes to anything related to the web, it's quite hard to miss something like the user-agent. In my case, it was set in the reference implementation I looked at, and I had no doubt I want to set it as well.\n. This PR includes #382 .\n. Dito ! \nSomething similar I do with BorrowMut, in case I want people to either allow me to own something, or to just borrow it mutably, without them having to care. More complexity on my side translates to more flexibility and ease of use on the client side, which is a hit I am willing to take as many benefit from it.\n. Indeed, I just did a 'I need this real quick' PR and ignored the fact that I have no clue what it does. tm seems like too short for a rather global namespace without any hygiene.\nI will leave the PR up anyway though, until the topic has received the attention it (probably) deserves.\n. Thanks. The fix works for me.\n. ",
    "yberreby": "Oh, I'm sorry I didn't read the guidelines. How can I undo this commit to fix the style?\n. I updated the message and relaxed the 'static lifetime requirement.\n. ",
    "AaronM04": "Okay, thank you! I will submit a pull request to fix the example.\n. Yay, GitCop approves :)\n. Ah, of course. That makes more sense.\n. ",
    "talevy": "++ I would also love to see this! thank you @Byron for extracting this and republishing it as a crate!\n. This is very much premature, but figured any activity to this thread is a positive!\nI have been playing around with what it would look like to write an asynchronous hyper client.\nhere it goes: https://github.com/talevy/tengas.\nthis has many things hardcoded, and is not \"usable\" by any means. Currently it does just enough \nto get an event loop going and allows to do basic GET requests and handle the response within a callback function.\nI tried to re-use as many components of hyper as possible. Seems to work!\nI had to re-implement HttpStream to use mio's TcpStream instead of the standard one.\nI plan on making this more generic and slowly match the original hyper client capabilities.\nAny feedback is welcome! Code is a slight mess because it is the first pass at this to make it work.\n. @seanmonstar is this branch public somewhere?\n. ",
    "MarkSwanson": "Ok, I'm sure it's not your fault.\nIt's probably my fault, or I may have found an issue (not with hyper). \nI'll close this and circle back for a deeper look shortly.\n. This may help:\nhttps://github.com/hyperium/hyper/issues/725\n. Thanks, but hyper-openssl will not work either because I can't pass it an SslContext.\n. Ok, I see that if I back down to Hyper 0.9.18 that things seem to be working the same way as the old version I was using, and yet it's new enough that I can resolve my cargo dependency issues.\nI've switched to 0.9.18 and I think I'll be happy with that (I say think because I now have so many compile errors to resolve :-)\nIt looks like the 10.x branch is a major rewrite in this area - so feel free to close this if you feel that this ticket would only distract you from your current plans.\nThanks again for Hyper!\n. ",
    "timonv": "I also tried unparking the thread, to no avail. If I try to manually drop the guard after closing it, it hangs. I added some statements to check if multiple requests happen, nothing. \n. Sure! Let's see if I can do that in under ten minutes :-)\n. Ohh, close https://github.com/timonv/hyper_blocking_example\n. You can't? The example I gave doesn't work and reproduces the problem. :(\n. @reem Not sure if I need to mention for closed issues, but doing it anyway. Why would it deadlock? The mutex guard should be dropped right after the handler finishes it's shizzle. Is there anything else I can do to make this work? Maybe if Handler supported Copy I could just use an Arc.\nI'd like to have this out of the way as its just the auth part of the project anyway :')\nEdit: If its faster, I'm also on IRC.\n. @reem So I can't just create a server, get the token and ditch the server again? I can have the guard in the main loop sure, but that seems like an ugly and unneeded solution, as it would essentially keep the entire server open for the duration of the app. If it blocks untill the entire server is done, then you'd kinda expect it to stop over time.\n. @reem I was already closing the guard. I tried moving to a single thread for gigs yesterday but it didn't work. https://github.com/timonv/hyper_blocking_example/blob/master/src/main.rs\nThe weird thing is, if you print some giberish at the end of the handler, it gets printed. What could Thread::scoped's join guard be waiting for? No trouble dropping the mutex guard either. \n. ",
    "ryansname": "@reem I seem to be facing the same issue in a similar use case: very simplified version. I've narrowed it down to a problem when the Listening struct is dropped. \nOf note also is that the handler is still active after the call to close(). \nIs there anything I can help with to track down this problem?\n. ",
    "LukasKalbertodt": "I just want to remark that I'd like to use close. A solution would be appreciated! :) \n. ",
    "JohanLorenzo": "I encountered this issue too. For reference, here's a simpler piece of code that shows Listening.close() doesn't work:\n``` rust\nextern crate hyper;\nuse hyper::server::{ Server, Request, Response };\nuse std::thread;\nfn hello(_: Request, res: Response) {\n    res.send(b\"Hello World!\").unwrap();\n}\nfn main() {\n    let mut listening = Server::http(\"127.0.0.1:8000\").unwrap().handle(hello).unwrap();\n    println!(\"SERVER STARTED\");\n    // Check with your OS that the port is open. For instance:\n    // watch -n 0.1 \"lsof -Pan -i tcp  | grep 8000\"\n    thread::sleep_ms(5000);\n    listening.close();\n    println!(\"SERVER STOPPED\");\n    // See the port is still open\n    thread::sleep_ms(5000);\n}\n```\nI wonder if we shouldn't update the documentation, until a fix gets merged. \n. Hello @seanmonstar \nI'd like to update the documentation, while #338 gets fixed. What do you think?\n. ",
    "thibaultdelor": "I'm sorry but I don't understand why this bug has been closed. The problem still exists right?\nI am doing intergration test and spin up a new hyper server for each test. I use a pool of port number but the thing is that Hyper never release the port after being closed meaning that I can't run all my tests.... ",
    "jmatraszek": "I am still having this issue (using iron 0.5.1, hyper 0.10.4, rustc 1.15.0). @seanmonstar should this issue be really closed?\nBTW. Tried sleeping, as suggested here: https://github.com/hyperium/hyper/issues/968#issuecomment-272646517\nMy code: https://github.com/jmatraszek/haxonite/blob/6_serve_watch/src/main.rs#L132. To some point -- I agree with you. In a typical app I would never use StatusCode::from_u16(200) instead of StatusCode::Ok.\nBut on the other hand it may be useful in some not-so-typical applications: for example right now I am developing a simple server that will be used to mock APIs, so the status code has nothing to do with the application logic itself, it's just configured in a config file. It is easier to do StatusCode::from_u16(status_from_config) than to match by myself.\n. ",
    "jgh-": "Yeah I'm seeing this on iron 0.5.1, hyper 0.10.7, and rustc 1.16.0 still.  Calling close at least seems to let the drop happen without a deadlock, but the server is obviously not shut down.\nfrom server/mod.rs (on 0.10.x branch):\nimpl Listening {\n    /// Warning: This function doesn't work. The server remains listening after you called\n    /// it. See https://github.com/hyperium/hyper/issues/338 for more details.\n    ///\n    /// Stop the server from listening to its socket address.\n    pub fn close(&mut self) -> ::Result<()> {\n        let _ = self._guard.take();\n        debug!(\"closing server\");\n        Ok(())\n    }\n}\n_guard is Option<JoinHandle<()>>, from the documentation on JoinHandle:\n```\nAn owned permission to join on a thread (block on its termination).\nA JoinHandle detaches the child thread when it is dropped.\n```\nSo not only is this not closing the connection, it's also detaching the thread that was started.. ",
    "n3phtys": "Definitely still happening with rustc 1.23.0-nightly and hyper 0.10.13. This issue should be reopened.. ",
    "ghost": "``\n\u256d\u2500mindcat@mindcat-linux-pc ~/workspace/nekoneko  \u2039master*\u203a \n\u2570\u2500\u27a4  cargo build -j 4\n    Updating registryhttps://github.com/rust-lang/crates.io-indexCompiling hyper v0.2.0\n/home/mindcat/.cargo/registry/src/github.com-1ecc6299db9ec823/hyper-0.2.0/src/net.rs:36:10: 36:18 error: missing documentation for an associated type\n/home/mindcat/.cargo/registry/src/github.com-1ecc6299db9ec823/hyper-0.2.0/src/net.rs:36     type Acceptor: NetworkAcceptor;\n                                                                                                 ^~~~~~~~\n/home/mindcat/.cargo/registry/src/github.com-1ecc6299db9ec823/hyper-0.2.0/src/lib.rs:3:9: 3:21 note: lint level defined here\n/home/mindcat/.cargo/registry/src/github.com-1ecc6299db9ec823/hyper-0.2.0/src/lib.rs:3 #![deny(missing_docs)]\n                                                                                               ^~~~~~~~~~~~\n/home/mindcat/.cargo/registry/src/github.com-1ecc6299db9ec823/hyper-0.2.0/src/net.rs:43:10: 43:16 error: missing documentation for an associated type\n/home/mindcat/.cargo/registry/src/github.com-1ecc6299db9ec823/hyper-0.2.0/src/net.rs:43     type Stream: NetworkStream + Send + Clone;\n                                                                                                 ^~~~~~\n/home/mindcat/.cargo/registry/src/github.com-1ecc6299db9ec823/hyper-0.2.0/src/lib.rs:3:9: 3:21 note: lint level defined here\n/home/mindcat/.cargo/registry/src/github.com-1ecc6299db9ec823/hyper-0.2.0/src/lib.rs:3 #![deny(missing_docs)]\n                                                                                               ^~~~~~~~~~~~\n/home/mindcat/.cargo/registry/src/github.com-1ecc6299db9ec823/hyper-0.2.0/src/net.rs:92:10: 92:16 error: missing documentation for an associated type\n/home/mindcat/.cargo/registry/src/github.com-1ecc6299db9ec823/hyper-0.2.0/src/net.rs:92     type Stream: NetworkStream + Send;\n                                                                                                 ^~~~~~\n/home/mindcat/.cargo/registry/src/github.com-1ecc6299db9ec823/hyper-0.2.0/src/lib.rs:3:9: 3:21 note: lint level defined here\n/home/mindcat/.cargo/registry/src/github.com-1ecc6299db9ec823/hyper-0.2.0/src/lib.rs:3 #![deny(missing_docs)]\n                                                                                               ^~~~~~~~~~~~\nerror: aborting due to 3 previous errors\nCould not compilehyper`.\nTo learn more, run the command again with --verbose.\n\u256d\u2500mindcat@mindcat-linux-pc ~/workspace/nekoneko  \u2039master*\u203a \n\u2570\u2500\u27a4  rustc -V                                                                                                                                 101 \u21b5\nrustc 1.0.0-nightly (4db0b3246 2015-02-25) (built 2015-02-26)\n```\n. ok, I see =D\n. What is your rustc version? are you updated?\n. Err... How can I combine commits that all?\n. Ouch.\n. Give up, I don't have any idea where can store the CookieJar now.\nI can't put CookieJar in Client struct, because CookieJar has lifetime, it confused me.\n. I'm experiencing this problem as well. Currently benching using cargo run and cargo run --release https://github.com/SergioBenitez/rocket and it will hang for thirty seconds or more using:\n$ ab -n 10000 -c 100 http://localhost:8000/\nCurrently on Rust nightly. Always happens after 16000 requests.\nBenchmarking localhost (be patient)\nCompleted 2000 requests\nCompleted 4000 requests\nCompleted 6000 requests\nCompleted 8000 requests\nCompleted 10000 requests\nCompleted 12000 requests\nCompleted 14000 requests\nCompleted 16000 requests. I can improve the example to return the vector from get_json and then increment the id's of all users and then println! it in another function.. Also I can add another example that is a server doing this.. I'll open a pr for this. ",
    "John-Nagle": "rustc 1.0.0-nightly (4db0b3246 2015-02-25) (built 2015-02-26)\nThat's two hours old; it may be obsolete by now. \n. It looks like old_io just went away. Although I'm not entirely sure.  Here's the reddit discussion:\nhttp://www.reddit.com/r/rust/comments/2wrc3c/read_from_stdin_in_alpha_2_without_using_old_io/\n. Thanks for all the quick effort.\n\"My dear, here we must run as fast as we can, just to stay in place.\" - Alice in Wonderland\n. Is \"Read\" live in the rev mentioned above?  I'm getting\nsrc/rssread.rs:258:28: 258:34 error: type `hyper::client::response::Response` does not implement any method in scope named `Read`\nsrc/rssread.rs:258     let string = match res.Read() {\nShould I wait a few more days for things to settle down?\n. OK, got that. My RSS reader is working again with the latest Hyper, thanks to all of you. \n. ",
    "sifton": "Ah, cool, my mistake. Didn't think to check.\n. ",
    "akoskaaa": "Hey, I am not sure if this is a blocker, but with the current build the example client does not build for me. Here's the exception:\nsrc/main.rs:19:20: 19:36 error: type `hyper::client::response::Response` does not implement any method in scope named `read_to_string`\nsrc/main.rs:19     let body = res.read_to_string().unwrap();\n                                  ^~~~~~~~~~~~~~~~\nsrc/main.rs:19:36: 19:36 help: methods from traits can only be called if the trait is in scope; the following trait is implemented but not in scope, perhaps add a `use` for it:\nsrc/main.rs:19:36: 19:36 help: candidate #1: use `std::io::Read`\nerror: aborting due to previous error\n. ",
    "davidrhyswhite": "Ah, shame on Github. Guess I'll need to find a different API to play around with Rust and Hyper.\n. ",
    "ghmlee": "``` rust\nuse hyper::Client;\nuse hyper::Url;\nuse hyper::header::ContentType;\nuse hyper::mime::Mime;\nfn main() {\n    let mime: Mime = \"application/x-www-form-urlencoded\".parse().unwrap();\n    let mut client = Client::new();\n    let res = client.post(\"http://localhost:8888/\")\n                          .header(ContentType(mime))\n                          .body(\"foo=bar\")\n                          .send();\n}\n```\n. It should be merged soon.\n. ",
    "dovahcrow": "When will this bug be fixed? timeout should be an urgent feature.\n. All right, thanks. But what about the client? Are there any good ways to\nadd timeout to a HttpClient\uff1f\nOn 2015\u5e744\u670819\u65e5\u5468\u65e5 \u4e0a\u53482:15 Sean McArthur notifications@github.com wrote:\n\nTimeouts won't be supported by TcpStreams until Rust 1.1, which would be\nmid June. To support timeouts in hyper earlier, we'd need to explore using\nan additional thread, but it's performance may suffer too much.\nIn the mean time, I suggest putting nginx in front of your server, which\nhandles this well.\nOn Sat, Apr 18, 2015, 10:24 AM Young Woo notifications@github.com wrote:\n\nWhen will this bug be fixed? timeout should be an urgent feature.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/368#issuecomment-94184696.\n\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/368#issuecomment-94188584.\n. Now hyper becomes the main stumbling stone of projects because of openssl issue actually.... \n",
    "miguelmartin75": "This error is still apparent in v0.6. My server hangs sometimes and it is quite frequent, I know it's not my code because not even the Handler's handle is called for when I send a HTTP request; it can take up to an order of minutes or not at all for the handle function to be called. It seems to not be an issue when hosting & requesting locally. \nI've switched to rust-http and my code works fine. This really needs to get fixed IMHO as this library does have a nice API.\n. ",
    "juanibiapina": "Is this issue the place to follow for updates on this bug?\n. No solution for the problem itself?\n. You could make a new release without the keep-alive, like you suggested, since this is still 0.x. Then you could implement the timeout when 1.4 comes out.\nAs a user of the lib, I don't mind because I would be actively upgrading a not 1.0 dependency.\n. @mikedilger you beat me to it xD\n. ",
    "Ogeon": "It feels a bit like sweeping it under the rug, but it's about as good as any other workaround. It may become a gotcha in its own way, though. Probably less obvious, but still...\n. Doing the connection counting trick will at least let users choose a balance, but tune it the wrong way and your thread pool may be filled up with idle favicon connections and your server basically reverts to single thread mode. I implemented it in Rusful and it prevents lock-ups, but not much more. Disabling keep-alive may even be a better alternative, after all, since it will treat every connection equally. It's at least better than lock-ups.\n. Cool stuff! I may feel adventurous enough to try this in a branch of Rustful. :smile: I have really been looking forwards to this, so I would be happy to give it a spin.\nBy the way, I see that mio still doesn't seem to support Windows. Can Hyper still support Windows, without mio doing it?\n. That's great! I'll probably not be able to stop myself from trying this within the coming days... I'll be in touch if I bump into any problems.\n. Cool! Looks like it's time to give this another try. Just one question:\nIs there a reason for making the Request components private, besides preventing accidental changes? Are there any side effects from them being changed? I ask because this prevents me from repackaging them in the Rustful Context type without making references (which may prevent even more things), and it makes it makes it impossible to write pre-routing that actually modifies the request.\nI'm somewhat prepared to lessen the power of the pre-routing filters, since I'm not even sure how useful the are, but I'm still not much of a fan of doing it. The filters would then only be able to observe and abort.\nThe request problem could be worked around by including it as it is, instead of splitting it, and maybe add accessors as shortcuts. The host name+port injection would also have to change. I may have missed it by I don't think Hyper does this, and it's sometimes a useful header. It could, of course, live outside the Request, but that would be a bit awkward.\nAll I would need is a way to destructure the Request, and it doesn't matter if it's a method. That worked fine for the previous version of Response. Second best would be mutable accessors, but that would somewhat defeat the purpose of keeping everything immutable.\nAnyway, nice to see that this is almost complete. :+1: \n. @seanmonstar Yeah, I think the decision to make them immutable was a good idea from that perspective. A deconstruct method is all I need and it would be great if it was added. The critical part is the Headers struct, which may become expensive to clone. The URI is parsed, and is cloned at the same time, and the method should be cheap enough to clone in the most common situation. The best would be if I didn't have to clone anything. :smile:\nI have, by the way, started to port everything to the new system and it's working quite well, so far. I have just managed to make the main functionality work, and the simplest examples are compiling. The only thing I really haven't figured out a good solution for, at the moment, is file uploading. I'm not yet sure how to coordinate the file reading and sending in a good way that doesn't clog everything up. I'll probably figure something out after some sleep.\n\nI'm surprised you need to inject the Host header into requests. HTTP/1.1 is pretty clear that clients must include the Host header.\n\nI should look into that again. I don't remember why I added that part (I rediscovered it when I wrote that comment), so it may actually be unnecessary. Does Hyper check that the Host header exist?\nOh, and another quick question: What happens with the request body if the handler decides to return Next::end() before reading it? Will Hyper take care of it automatically?\n. @seanmonstar Alright, so I take it that I have to read the body to make sure the socket is reused for keep-alive. That's good to know :+1: Thanks!\n. I got the impression that it was done automatically in 0.8.x and earlier, but I may be wrong. It would be nice if the responsibilities of the handler were documented, to make it more clear what's automatic and what's not. I asked because some of the examples skips the body.\n. @seanmonstar Looks like I misunderstood it, then :smile: Probably a leftover assumption from rust-http, which used to include the body in the request.\n. @seanmonstar I have bumped into a problem with zero sized response bodies. I don't know if it's intentional, but it seems like I have to call encoder.write(...) at least once for the response to be properly sent. It will otherwise result in \"empty response\" errors.\nDo you want me to file separate issues for things like this?\n. I hadn't and did now. Part of problem is still there. The general state flow is as follows:\n1. In on_request -> Next::wait,\n2. immediately wake up and go into write,\n3. in on_response -> Next::write,\n4. do nothing in on_response_writable, since body length is 0, and -> Next::end\nSkipping step 4 and calling Next::end in 3 seems to work after the update. Calling encoder.write with an empty slice in 4 causes the headers to be sent and the returned value from write is WouldBlock.\n. Yeah, it's still there. Another thing I've noticed is that wrk reports read errors. I haven't done any deeper investigations into those, though, but I guess you have seen them as well.\n. > @Ogeon As I should have done, I've added a test in the server tests for that exact instance, and I can now say it is fixed.\nAh, nice! I can confirm that it works now.\n\nAs for read errors, you mean errors printed by env_logger from hyper (that the socket closed?), or the read errors reported directly from wrk? The former, I've fixed (it was a useful error log when first working on the branch). The latter, I haven't seen in a long time.\n\nIt's directly reported from wrk. It can look like this for my hello_world example, after a run with 456888 requests:\ntext\nSocket errors: connect 0, read 456873, write 0, timeout 0\nIt looks like it's not one for each request, so I'm not really sure what would trigger them. Could it be something I have missed, when implementing it?\n. It's the hello_world example from Rustful, and it's the same for other examples there, as well. It should just write \"Hello, stranger!\" and the headers should just be date, content length, content type, and server name. It looks fine in the browser, so that's why I'm a bit confused. I tried some of the Hyper examples and they didn't generate the errors, so there must be something with how I'm doing it. I'll investigate more later, and see what I can find.\n. Ok, I found something. The \"simplified\" handler goes into wait mode if no body should be read, and waits for a signal that tells it that it's time to start the writing the response. Changing this to make it immediately go into write mode (which will mess with the flow, but should work for hello_world) makes the errors disappear.\nI tried to replicate the hello example from Hyper, using the more advanced handler method. It did not call Next::wait and it did not cause any errors. I changed it to call Next::wait, and made it call control.ready(Next::write()) from a thread, and that made the errors appear again.\nWhat do you think?\n. Hard to say. The error conditions seems to be either a network error (return -1), a 0 read before finishing the response, or some failure in http_parser_execute. There shouldn't be anything to read (unless the errors appears when data is finally received), so the only logical failures would be the network error or the 0 read, given that http_parser_execute returns the number of parsed bytes. It's quite complex, though, so it's hard to say exactly what happens. Either way, 0 reads will still cause problems.\nIf it does read something, then the problem should be caused by something in http_parser_execute. It's huge and has many jumps to error, but it looks like it would report those errors to the user.\nI tried to pass the --timeout 10s option, but that didn't make a difference. That should show up in the timeout counter, instead, so I didn't really expect anything.\n. Hmm, yeah, looks like that's the case. It's also static, so I guess it won't be replaced by an other function.\n. I just noticed that the way Control::ready behaves has changed. It's no longer possible to call it from on_request and then make on_request return Next::wait() (small example). It won't wake up after on_request. Is this a bug?\n. Alright, nice! :smile: It works just as before, now.\n. I've been trying to re-enable OpenSSL support in Rustful today, and it went alright, except when it came to dealing with the different Transport types. The fact that many parts of the API depends on it gives me three alternatives:\n1. Make almost everything in Rustful generic over Transport. This would work if it didn't cause a bunch of coherence problems in some important parts.\n2. Make Http/Https enums for Encoder and Decoder. This would work if the Transport type for HTTPS was public. I tried with <Openssl as Ssl>::Stream, as well, but it looks like it counts as a type parameter and caused conflicting implementations of From.\n3. Mask Encoder<T> and Decoder<T> as Read and Write. My current solution is a variant of this, but it's not so nice, and won't work well if more than simple read/write functionality is ever expected.\nIt would be nice if the Transport type could be made public for the OpenSSL case, allowing solution 2, or if both HTTP and HTTPS used the same type (I saw HttpsStream in there, but I guess that's something else), allowing simple type aliases for Encoder and Decoder. A completely different solution is, of course, also welcome.\n. That should do it, as far as I could tell. It did look like it was just OpensslStream<HttpStream>, though, but it could also have been some misleading error messages.\n. @seanmonstar I could implement the nicer solution nr. 2 now, when OpensslStream is public, so all is well. :smile: It's an ok solution. Also, I had to use Encoder<OpensslStream<HttpStream>> and  Encoder<OpensslStream<HttpStream>>, as I vaguely mentioned before. I'm not sure if that was what you actually meant.\n. It's very nice to see this move on to being a PR :tada: I would just like to make another request for a way to destructure the Request in a server.\n. @seanmonstar Thank you :smile: I think that was the last piece that was missing for me, in Hyper itself, apart from threading. That's another story, though.\n. @seanmonstar I noticed that there's no try_clone for HttpsListener. Is this an oversight or by design?\n. Alright, I think I got it working now, like this:\n``` rust\nlet listener = HttpListener::bind(host);\n//... listener.try_clone(), etc.\nlet ssl = try!(Openssl::with_cert_and_key(cert, key));\nlet server = hyper::Server::new(HttpsListener::with_listener(listener.0, ssl));\n``\n. Then I suppose it should be possible to use scoped threads. Interesting...\n. I don't think it will be a problem. I'm consuming the request inon_request, so it won't leave the scope. I'm quite sure the'as will be elided, as well. It's the same for theHandler` trait in Rustful.\n. This looks really nice! I think having just one handler method and getting rid of the explicit intent should make it a lot easier to implement frameworks and wrappers. I do agree that having access to the request in the factory, as well, would make it even nicer. That would probably allow me to simplify some parts of my current implementation.\n. I somehow like this variant the most:\n``` rust\ntrait HandlerFactory {\n    type Output: Handler;\nfn create(&mut self, req: hyper::Result<Request>) -> hyper::Result<Self::Output>;\n\n}\n```\nSure, it requires you to be aware of the error case, but handling it is trivial. The only risk is that its purpose may be unclear. What I like with it is that it's high control with low effort. There's only one trait (apart from Handler) to care about and only one method to implement, but you can still have access to the error case or just dismiss it with very little effort. For example:\n``` rust\n//Using try!, as mentioned above, to just dismiss it and get the default error response\nimpl HandlerFactory for MyFactory {\n    type Output = MyHandler;\nfn create(&mut self, req: hyper::Result<Request>) -> hyper::Result<MyHandler> {\n    let request = try!(req);\n    //do stuff\n    Ok(handler)\n}\n\n}\n//Using req.map to just dismiss it and get the default error response\nimpl HandlerFactory for MyFactory {\n    type Output = MyHandler;\nfn create(&mut self, req: hyper::Result<Request>) -> hyper::Result<MyHandler> {\n    req.map(|req| self.make_request(req)) //something like this\n}\n\n}\n//The error can be ignored with req.ok\nimpl HandlerFactory for MyFactory {\n    type Output = MyHandler;\nfn create(&mut self, req: hyper::Result<Request>) -> hyper::Result<MyHandler> {\n    let request = req.ok();\n    //do stuff\n    Ok(handler)\n}\n\n}\n//And the return type can, of course, be a combination of handler and error handler\nenum OkOrErrHandler {\n    Ok(MyHandler),\n    Err(MyErrorHandler),\n}\nimpl HandlerFactory for MyFactory {\n    type Output = OkOrErrHandler;\nfn create(&mut self, req: hyper::Result<Request>) -> hyper::Result<OkOrErrHandler> {\n    Ok(match req {\n        Ok(req) => OkOrErrHandler::Ok(MyHandler::new(req)),\n        Err(e) => OkOrErrHandler::Err(MyErrorHandler::new(e)),\n    })\n}\n\n}\n```\nI have a feeling that the underlying implementation may become very complicated if we want to make the error invisible until someone asks for it, though I would be happy to be proven wrong. I'm also afraid that some people may not realize that there is an error case. They may end up wondering why their requests doesn't reach their handlers and the connection just closes or sends a canned error response. Simplification is good, but too much of it may make the alternative scenarios more complex.\n. ",
    "octplane": "It is much smaller: 1024 bytes (as indicated by the title of the Issue :wink:  ). And the issue starts getting visible at precisely this value.\n. It makes strictly no difference.\n. @reem , @seanmonstar I have no idea on how to profile rust code... I'm on OSX, FWIW... \n. Ok, after some investigation (read the wget logs), I found out that hyper does not conform to some expected parf of the HTTP specification:\n```\ntime curl -vvv -X POST -d @broken.json http://127.0.0.1:5000/hook/                                                            \n Hostname was NOT found in DNS cache\n   Trying 127.0.0.1...\n* Connected to 127.0.0.1 (127.0.0.1) port 5000 (#0)\n\nPOST /hook/ HTTP/1.1\nUser-Agent: curl/7.37.1\nHost: 127.0.0.1:5000\nAccept: /\nContent-Length: 1025\nContent-Type: application/x-www-form-urlencoded\nExpect: 100-continue\n\nDone waiting for 100-continue\n< HTTP/1.1 200 OK\n< Transfer-Encoding: chunked\n< Date: Wed, 11 Mar 2015 20:41:28 GMT\n<\nConnection #0 to host 127.0.0.1 left intact\nOK.curl -vvv -X POST -d @broken.json http://127.0.0.1:5000/hook/  0,00s user 0,00s system 0% cpu 1,011 total\n```\n\n\nBecause the payload is bigger than 1024 bytes, curl attempts a two step posts using the Expect: 100-continue instruction. After 1s, curl gives up and send the payload:\nset->expect_100_timeout = 1000L; /* Wait for a second by default. */\nhttps://github.com/bagder/curl/blob/df5578a7a304a23f9aa3670daff8573ec3ef416f/lib/transfer.c#L1103\nHyper happily receives the payload and call the handler.  \n. ",
    "adrianheine": "Travis is on 2015-03-14 and thus fails.\n. Using SocketAddr seems reasonable to me.\n. ",
    "r-darwish": "The head is a few bytes long. By looking at Wireshark I could see that the different lines of the head are spread among multiple TCP packets, which causes BufReader to yield the first received packet, which contains only the first head line. \n. ",
    "mattnenterprise": "I will just go ahead and do this.\n. I would like to give this a try.\n. @seanmonstar  Could you give more information on how you think this should be implemented?\n. Any recent progress on this ?. @matt2xu Is the idea to have the crate parse the WWW-Authenticate response header, and then have it create the correct Authorization request header ?. ",
    "hoxnox": "Do you already have a vision how to embed mio into hyper? I'm very interested in async client and have  enough time to contribute some code.\n. I maked a pull request: https://github.com/hyperium/hyper/pull/454\n. ",
    "jnicholls": "mio will be adding Windows support in the near future, so depending upon it should be a safe bet.\nThe API surface of hyper's server will not have to change much if at all, but the client will need an async interface, either in the form of closure callbacks, a trait handler, something like a Future or Promise return value, etc.\n. Yeah honestly a trait handler with monomorphization/static dispatch is the only way to go.\n. A feature flag makes great sense in this case then.  There are plenty of\npeople who would be able to take advantage of hyper + mio on *nix systems;\nprobably the vast majority of hyper users in fact.\nOn Sun, Jul 26, 2015 at 5:22 PM, Sean McArthur notifications@github.com\nwrote:\n\nI've been investigating mio support, and fitting it in was actually pretty\nsimple (in a branch). I may continue the branch and include the support\nwith a cargo feature flag, but I can't switch over completely until Windows\nsupport exists.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/395#issuecomment-125041688.\n. It is interesting how stable express, vanilla, and spray are in terms of\nresponse times over time.  I'm surprised nickel and iron are not equally as\nstable; interestingly enough they both have the same shape, so my guess is\nit's identical behavior on their primary dependency: hyper :)\n\nOn Thu, Aug 6, 2015 at 5:33 AM, Sergey Kamardin notifications@github.com\nwrote:\n\nBy my own benchmarks with lots of http connections, rust will be fastest\nway, if it will have async io:\nhttps://camo.githubusercontent.com/698a9884f2e7734d4fd27b8af45a4b79ef06c3bd/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f662e636c2e6c792f6974656d732f30543230316f3053336c324633653149336631782f254430254131254430254244254430254238254430254243254430254245254430254241253230254431253844254430254241254431253830254430254230254430254244254430254230253230323031352d30382d303625323025443025423225323031322e33322e35362e706e67\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/395#issuecomment-128308700.\n. I agree that hyper should decouple the logic of composing and parsing HTTP\nrequests/responses from the actual I/O.  This is what I alluded to in my\noriginal request.  Such a change would make it possible to run any kind of\nI/O model (in-memory, blocking I/O, non-blocking I/O, etc.) and any\nsub-variants thereof (unix readiness model, windows callback/IOCP model)\nwith any stack that a user would prefer to use (mio, curl multi-interface +\nlibuv, etc.)\n\nThat's a lot of freedom offered by simply splitting up the composition and\nparsing logic from the I/O logic.  I agree with Paul.\nOn Fri, Aug 7, 2015 at 8:14 PM, Paul Colomiets notifications@github.com\nwrote:\n\n@seanmonstar https://github.com/seanmonstar\nI don't have a vision; I haven't looked that hard into how mio works. I'd\nlove to hear suggestions.\nI have a vision. In short it boils down to splitting hyper into three\nlogical parts:\n1. Types (Headers, Status, Version..., may be some generic version of\nRequest)\n2. Logic. For example the function determining what HTTPReader is used,\nshould be decoupled from real streams. I.e. there should be enum like\nHTTPReaderKind which then is turned into current HTTPReader with a simple\nmethod like kind.with_stream(stream)\n3. And code handling real streams, with convenience Request objects\nimplementing Read, buffering an so on.\nThe first item is basically ok, except maybe put types into separate\ncrates. But logic is too coupled with streams. Decoupling it should also\nsimplify testing AFAIU.\nThen we can do competing experimental asychronous I/O implementations\nwithout rewriting too much of hyper. (I will publish my implementation\nsoon). The biggest question on mio right now is how to make things\ncomposable. I.e. you can't mix multiple applications in same async loop,\nuntil some better abstractions are implemented, so I'm currently\nexperimenting with it.\nHow does this sound? What I need to start contributing these changes into\nhyper?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/395#issuecomment-128866149.\n. If you do separate crates instead of modules, I would group #1 and #2 into\na crate, and #3 in a separate crate (http_proto & hyper, for example, where\nhyper is the actual client/server I/O logic).\n\nnode.js put their http_parse into a separate project from the node.js\nproject in a similar fashion.\nOn Saturday, August 8, 2015, Sean McArthur notifications@github.com wrote:\n\nThat actually sounds quite feasible. I'll think more on the relationship\nbetween the 2nd and 3rd crates. But the first crate sounds simple enough:\nmethod, uri, status, and headers. Need a proper name, and to figure out the\nleast annoying way to publish multiple crates at a time.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/395#issuecomment-129058122.\n\n\nSent from Gmail Mobile\n. Looking forward to hearing more about your integration @seanmonstar.\n. ",
    "dcsommer": "+1 for prioritizing a trait handler. Futures have some amount of overhead, and closure callbacks have even more overhead and can lead to callback hell. If the goal is maximum performance, an async handler interface would be a natural starting point.\n. I'd like to just note that having a way for direct, 2-way communication\nalong the callback chain is very important for efficiency reasons. The\nadditional overhead of enqueueing events in the event loop rather than\nexecuting them directly on a parent has been a performance bottleneck in\nthe past for async webserver code I've written in C++. Unfortunately, I\nhaven't yet seen a way to do this safely in Rust.\nOn Wed, Sep 23, 2015 at 11:09 AM, Paul Colomiets notifications@github.com\nwrote:\n\nAs far as I can tell, the best way to do this would be to be able to\ndispatch a protocol-specific message onto the event loop, which when\nreceived and processed by the loop ends up notifying the Protocol (and\npassing the message onto it).\nYes. All the same issues with websockets. This is a thing that I'm going\nto support in rotor because the library is basically useless without the\nfunctionality (I. e. you can't implement a proxy). As I've said, it's my\nnext priority.\nHowever, flow control may be done another way. You could just have a\nVec and/or Vec in connection state. So readiness\nhandler can supply data chunk to any handler and can choose the stream to\nsend data from for writing. It's easy to group state machines in rotor as\nlong as they all share the same connection (and same thread of execution).\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hyperium/hyper/issues/395#issuecomment-142683795.\n. @tailhook yeah, I read the article. It was really good, and I'm excited to see people take async IO seriously in Rust. My issue with point 2 is for the case where you aren't yet ready to perform a state transition. How can the child inform the parent of state transitions that don't originate with a call from the parent? For instance, what if your request handler has to perform some async operation to calculate the response?\n. \n",
    "gobwas": "hyper + mio looks very promising =) :+1: \n. By my own benchmarks with lots of http connections, rust will be fastest way, if it will have async io:\n\n. @jnicholls fair enough :beers: \n. Also, FYI, the \"Thread group\" of JMeter is configured as:\n\n. How and when could it be solved? I see that #368 is closed..\n. Oops, sorry :+1: \nThank you! \n. ",
    "tailhook": "@seanmonstar \n\nI don't have a vision; I haven't looked that hard into how mio works. I'd love to hear suggestions.\n\nI have a vision. In short it boils down to splitting hyper into three logical parts:\n1. Types (Headers, Status, Version..., may be some generic version of Request)\n2. Logic. For example the function determining what HTTPReader is used, should be decoupled from real streams. I.e. there should be enum like HTTPReaderKind which then is turned into current HTTPReader with a simple method like kind.with_stream(stream)\n3. And code handling real streams, with convenience Request objects implementing Read, buffering an so on.\nThe first item is basically ok, except maybe put types into separate crates. But logic is too coupled with streams. Decoupling it should also simplify testing AFAIU.\nThen we can do competing experimental asychronous I/O implementations without rewriting too much of hyper. (I will publish my implementation soon). The biggest question on mio right now is how to make things composable. I.e. you can't mix multiple applications in same async loop, until some better abstractions are implemented, so I'm currently experimenting with it.\nHow does this sound? What I need to start contributing these changes into hyper? \n. Okay, I've just put some code of async HTTP handling online:\nhttps://github.com/tailhook/rotor-http\nIt's not generally usable, just put here to encourage you to split the hyper. It uses Headers from hyper. And I would probably better help to refactor hyper rather than rewriting whole logic myself.\nThe \"http_proto\" name is probably good for crate that contains types and abstract HTTP protocol logic (like determining length of request body).\n. I second @reem opinion. You can't just implement Evented, it will not work. Also it's expected that there will be IOCP-based library for windows that has very different interface than mio.\n. @seanmonstar, few questions:\n1. From quick skimming, it looks like you made the mio-only version, rather than making mio support optional, right? Is it generally accepted strategy?\n2. Quick benchmarking of hello.rs shows that it's much slower (<1k against 40K sync version), whereas my version and coroutine-based version does same order of magnitude requests per second. Any ideas?\n. > Update: current mio branch no longer using futures, and seeing a significant performance improvement. My linux box has horrible specs, so I won't post benchmarks from it.\nI can confirm that benchmarks are fine now.\nI'm curious why the difference is so drastic without futures? Is it because of inlining, or because of the different structure of the code? Is it just overhead of lambdas? \nBy the way code looks super-similar to what I've written about and working on. And it would be nice to join the effort. So have you seen that? Does you see any inherent flaws in what I'm doing? Or does the absence of documentation is the main cause that stopped you from using my library?\n. > I wanted the ability to pause transports, which I see is a TODO in greedy_stream :)\nYes. It was done to keep the scope of the protocol smaller for quick experiments. Easy to fix. I need to get messaging between unrelated connections right; then I will make a non-greedy stream that is pausable and has an idle timeout.\n\nThe amount of generics I saw trying to read rotor's source left me often confused.\n\nWell, yes, I'm trying to build a library that allows you to combine multiple independent things to create an app (One of the things will be an HTTP library). So the problem is not an easy one, and require some amount of generics. But it's not that much in user code. I'm also looking forward to moving some of the generics to associated types, to make code simpler.\n\nI'm sure our efforts could be combined in this area. My main reason here was to be able to prototype while understanding what's going on internally, instead of needing to ask on IRC.\n\nYes, that sounds reasonable. Let me know if I could be of any help.\n. > As far as I can tell, the best way to do this would be to be able to dispatch a protocol-specific message onto the event loop, which when received and processed by the loop ends up notifying the Protocol (and passing the message onto it).\nYes. All the same issues with websockets. This is a thing that I'm going to support in rotor because the library is basically useless without the functionality (I. e. you can't implement a proxy). As I've said, it's my next priority.\nHowever, flow control may be done another way. You could just have a Vec<Handler> and/or Vec<OutputStream> in connection state. So readiness handler can supply data chunk to any handler and can choose the stream to send data from for writing. It's easy to group state machines in rotor as long as they all share the same connection (and same thread of execution).\n. @dcsommer \n\nI'd like to just note that having a way for direct, 2-way communication\nalong the callback chain is very important for efficiency reasons.\n[ .. snip .. ]\nUnfortunately, I haven't yet seen a way to do this safely in Rust.\n\nIf I understand you right, then there is a way in rotor. In the article there are are two cases of communication:\n1. From parent to child, you just pass value as an argument to callback\n2. From child to parent either you return a value (like in body_finished callback), or a Option<State> like in almost every other example there (the latter is a form of communication too).\nBut in fact you may return a tuple if you need two things:\nstruct StreamSettings { pause_stream: bool }\ntrait RequestHandler {\n    fn process_request(self) -> (StreamSettings, Option<Self>);\n}\nOr you might pass a mutable object:\ntrait RequestHandler {\n    fn process_request(self, s: &mut StreamSettings) -> Option<Self>;\n}\n(the latter is used for Transport object in rotor)\n. @dcsommer, basically the parent need to be prepared for the situation. And it's communicated either by return value (i.e. turn Some/None into NewState/Wait/Stop) or by transport.pause(). Which way to choose depends on which layer this is (or, in other words, is the transport passed down here or is it hidden in the layers below). I'll put an example in rotor soon.\nOverall, I feel it's a little bit offtopic here. Feel free to open an issue in rotor itself.\n. > @tailhook actually, I think there could be some performance gains if some reading and writing directly to the stream could be overridden\nI have few thoughts about that. It's not my top priority, but let me share some brain-dump:\n1.  I think that it's possible to have InfiniBand or userspace TCP stack buffers in Transport  (by changing transport and event loop, but keeping Protocol same). But in your example it's not. (However, this thesis should be confirmed).\n2. It's might be interesting to just move chunked encoding to lower layer, i.e. to transport itself. Just like we usually do that for encryption (which interacts with chunked encoding in some subtle ways too). \n3. The write optimization is probably useless without writev (i.e. sending multiple buffers at once to the kernel space)\nI'm also only getting basics in rotor. So I'm trying to make protocol writer's life easier for now. For protocols that need last bits of performance, it's possible to \"squash\" two layers of abstraction. This is inherent to how rotor is designed.\n. @yazaddaruvala, I've just published a follow-up article and fundamental update to the rotor. I'm going to build few small applications with it and HTTP. Overall, it's not very solved problem in rust so it will take some time.\nOn the other hand we haven't agreed on any kind of collaboration with hyper. So I'm not sure if we will duplicate the work.\n. @arthurprs, no not yet, according to Medium stats.\n. Hi, I have a quick status update:\n1. Current master rotor-http has most features of the HTTP implemented (server-side). Of course, they are largely untested, but it hope to make tests shortly.\n2. It uses only hyper::{version,status,method,header} from hyper. It would be great if those tools be a separate library.\n3. The rotor-library itself is now super-small. It would be nice if we agree on the interface and start building apps that can co-exist in the same main loop.\n4. Another article and more docs will be done soon. I just put it here in case anyone want's to take an early look.\nP.S.: I've noticed that wrk may behave very slow in case you're closing connection which should not be closed (e.g. has no Connection: close header). I've not rechecked but it may be the reason of slowness of the test in the branch of hyper that was based on eventual io.\n. @KodrAus there is an example in rotor-stream. The full implementation of HTTP client will eventually be in rotor-http too. But DNS resolver is a prerequisite.\n. Okay here is the third article, including some benchmark vs golang, nginx and hyper.\nHopefully, it will answer some questions here.\n\n@seanmonstar \n\nOne difference I have is giving direct read and write access to the underlying socket, since that's a requirement another use case has for eeking out as much control as possible.\n\nCurrent rotor core library gives direct access to the socket. You can build on top of that. I'm not sure what is the reason because the performance of rotor-http that is build on top of rotor-stream (the latter does buffering and higher level abstractions, including hiding away the sockets) is decent. The benchmarks are in the article.\nCould you give some insight on a use case you are talking about? I'm looking forward to integrating  sendfile() and memory mapped files with rotor-stream. But I think this use case is quite niche (although, it is probably required to compete with nginx)\n\nHowever, on my machine, it was still performing at around 60% of my ideal target (a super simple state machine that ignores https semantics). \n\nWell, that script linked gives 600k requests per second on my laptop, comparing to 65k for nginx. I don't think it's much useful to compete with something that pushes lots of responses as fast as a connection is opened. Or do you say that you can get 60% of that performance on normal http request parsing?\n\nAt a recent Mozilla work week, others expressed interest in building a reverse proxy that could actually compete with nginx.\n\nSure, writing a HTTP implementation that has competitive performance comparing with nginx is my goal too.\n\nEven blocking IO was quite simple to emulate, using threads and channels.\n\nWell, I think it's possible to write blocking client implementation that wraps mio loop without threads and channels. And I doubt that blocking IO for servers is something useful. Although, offloading work to the thread pool is simple indeed.\n. > Yep. The WebPush team at Mozilla has to run servers where every single instance of Firefox must keep an open socket to the Push server. They want to reduce cost, and are thinking Rust can help do that. They want as little memory usage as possible for every connection, so that means controlling every allocation, including buffers used to read and write.\nSure, keeping keep-alive connections with minimum overhead is my goal too. This is how netbuf (the buffer object that rotor-stream uses) is designed: it deallocates the buffer when there are no bytes. This was doubtful trade-off. But it looks like okay in the bencharks. AFAICS in rotor-http there are no heap-allocated stuff per state machine, except buffers.\nThe size of state machine in hello-world is 288 bytes which is probably not the smallest possible (you may probably get as small as 8 or 16 bytes), but is perhaps less than most current servers have. You also have an overhead of Slab and timer slab, and probably larger message queue, all of that are currently fixed-size in mio.\nAnyway according to quick test a hello world example configured for 1M connections takes about 350M RSS (379M of virtual memory, in case you doubt that something is non-initialized yet). I haven't done real connections, though. I believe there is much more overhead in the kernel space.\n. > my current branch are at a point that I could switch out the internal use of 'tick' to 'rotor', with basically no change to the exposed API. This would just reduce duplicate effort in state machine development.\nGreat. Should I cut a new release of rotor? I mean do you have any outstanding questions/issues with API, so I can release all API changes in one bulk.\n\nOne of the things I noticed was that server cannot utilize more than one cpu core now. I assume this is because of mio. Are there any plans to build a master/cluster process on top to run multiple, isolated event queues for the new hyper?\n\nYou can easily run multiple event loops, each in it's own thread. Here is an example in rotor:\nhttps://github.com/tailhook/rotor-http/blob/7a24c516e30cdb6773584f465d4a8cccd8435fdc/examples/threaded.rs#L132\nThat's not hyper, but I believe you can do the same with @seanmonstar's branch.\n. > That's pretty cool. So you would leave the implementation of how to distribute the load (e.g. round-robin) to the library consumer?\nI'm not sure I understand question well. But you have several options for load distribution:\n1. In the example OS distributes sockets somehow by letting each thread accept on it's own. It works well for tiny asynchronous tasks\n2. Another option is to use SO_REUSEPORT in linux. AFAIU linux distributes connections equally (by a hash ring) between sockets (which are equal to threads in the example)\n3. For more complex processing you probably want to read the request in one of the IO threads which are distributed by option (1) or (2) and send job to worker threads which are running some MPMC queue (just an example)\n. Okay, I've done some quick tests https://gist.github.com/tailhook/f1174e1a3e8b340d1e1f\nShortly:\n- hyper-mio: 63450.68/63454.14/65230.27\n- hyper-rotor: 66627.13/65829.25/67861.90\n- rotor-http: 65600.74/66425.12/64309.17/69134.65\nIt's on i5-3230M CPU @ 2.60GHz / Linux 4.3.3, versions of the libraries are in gist\nThe tests were run for each of the version once, then next round. Also I've discarded some outliers with much lower RPS (all examples generated 61-62k sometimes).At the end of the day, I would say that variablility of the value is more than the difference, and I'm not sure I've captured fastest samples. Anyway. it doesn't look like slower. May be I'll try to find some time to make non-laptop test (test on laptops are always wrong because of powersaving). \nIn the meantime I've published rotor 0.5.0 on crates.io.\n\nbesides the time I've spent reading the source of rotor to understand it's concepts\n\nAny hints to start with? I know I need a lot more for documentation, but maybe some quick pointers. Like should I better make a tutorial or fill in more comprehensive coverage of API. Are standalone examples good enough? \n@lilianmoraru I've seen your request to test proxygen, but I can't find time to get it. It may help, if you create a vagga.yaml so it would be easy for me to test.\n. Thanks @lilianmoraru . So here is a test having a response with similar number of bytes (more details https://git.io/vgIpo):\n- rotor-http: 57k (requests per second)\n- proxygen: 28k\nFrom quick skimming it looks like proxygen accepts a connection by one thread and hands it off to another thread for processing (is it even async?), this explains why performance is 2x slower on this microbenchmark (i.e. 2 thread wake-ups instead of one). \nThe proxygen compiled with default options, which includes -O3 as far as I can see.\n. Sorry if it's a wrong thread, but do you have any plans on async DNS in the long term?\nI've started rotor-dns. It's very limited for now, but the major showstopper for it is not the DNS implementation, but all the plugins of gnu libc (i.e. you can configure /etc/nsswitch.conf and use ldap for getaddrinfo).\nOn the other hand, musl libc completely ignores all this stuff. And its a pretty uncommon to use anything other than DNS and /etc/hosts for resolving the names nowadays.\nAny thoughts?\n. What do you think about KCM in linux 4.6? My thoughts are here: https://github.com/tailhook/rotor-stream/issues/3 . In short: it's something which should be in \"must have\" category in a year.\n. At the closer look, it looks like KCM is of very limited use for HTTP. So it's probably off-topic here.\n. @srijs, while we use the crates in production, basically we need more users with more use cases before we declare them stable. And at least Address structure needs more accessor metrics.\nThe plan of abstract-ns is to make more than just plain DNS, first thing is to have notifications when address change (even if it's just polling DNS system) and to be able to plug not just DNS but also other name discovery mechanisms like consul or zookeeper. While this might be not useful in a browser, it's useful for a server-side usage of hyper.\nAlso, we have tk-pool which has connection pooling and reacts on a name changes.\nLet me know if I can be of any help.. > Personally, there's a few changes I would suggest to the current Resolver trait\nSure, open an issue. It's not carved in stone yet. I'm not satisfied with Resolver trait but I have to admit all my attempts to enhance it are just a little bit better. So your ideas might be helpful.\nOn the other hand, I tend to accept Stream<Address> (or just Address) in most APIs (as opposed to Resolver) so the trait might not be too critical and also easy to upgrade. Not sure if Stream API is enough for hyper though.. @klausi As far as I can see:\nfor socket in listener.incoming() {\n    let socket = socket.expect(\"failed to accept\");\n... that example server will crash on error. And you need to replicate all the same error handling and sleeping to handle the load.. > This server never crashes because it just ignores errors and keeps on running.\nYes, but it hangs the whole CPU when in error condition. Which matters when you're being DoS attacked.\nBut other than that, yes. Tk-listen is just a few lines of code wrapped into futures/combinators boilerplate, obviously, you can reimplement it.. > When ab benchmarking the 2 versions with and without sleep() I did not see a significant difference in CPU usage. In both cases the CPU usage is high because a lot of requests need to be processed.\nThis is because you're running a microbenchmark. Check the following things:\n\nDo you have keep-alive enabled?\nDo some work in request handler. Because requests in test finish in microseconds new descriptors are freed shortly.\nAdd some sleep into a request handler. In case accepting thread sleeps you will have basically zero CPU used. And without sleep, you'll have a full one core running at 100%.\n\nNote that (2) and (3) emulate real work-a-load of one or other type.. ",
    "mlalic": "@seanmonstar \nI've also been following how the mio branch has been unfolding and thinking about how it interacts with supporting HTTP/2, as well.\nFrom the aspect of HTTP/2 support, the new approach in tick is definitely better than the previous future-based one. It boils down to the fact that now it is more or less explicit that a single event loop owns the connection and that all events on a single connection (be it writes or reads) will, therefore, be necessarily serialized (as opposed to concurrent).\n\nI would like to throw in just a remark on something that would need to be supported in some way by any async IO implementation that we end up going with here if it is to also back HTTP/2 connections efficiently.\nSomething that seems to be missing in both tick, as well as rotor, is the option to send messages to the protocol/event machine.\nFor example, in HTTP/2 we would like to be able to issue new requests on existing connections. This is, after all, one of the main selling points of HTTP/2! In order for a new request to be issued, we require unique access to the state of the connection. This is because issuing a new request always needs to update the state (as well as read it). Examples are deciding on the new stream's ID (and updating the next available ID), possibly modifying the flow control windows... Therefore, issuing the request must execute on the same event loop and by the Protocol/EventMachine, as that is what effectively owns the connection state.\nAnother example would be sending request body/data. This cannot be simply written out directly onto the socket like in the case of HTTP/1.1 for multiple reasons (flow control, framing, priority, etc.), all of which come down to the fact that writing a data chunk requires unique/mutable access to the state. Thus, each request should notify the protocol (which owns the HTTP/2 connection) that it has data to be written and then the protocol itself should decide when exactly to perform the write onto the underlying async socket...\nThis actually goes for writing out responses on the server side, as well, since from HTTP/2's point of view, the difference is quite negligible (both are considered outbound streams). Basically, the AsyncWriter that is there currently is insufficient to support HTTP/2.\nAs far as I can tell, the best way to do this would be to be able to dispatch a protocol-specific message onto the event loop, which when received and processed by the loop ends up notifying the Protocol (and passing the message onto it). The type of the message would ideally be an associated type of the Protocol to allow for different protocols having different custom-defined messages.\nOf course, there might be a different way to achieve this, but for now I can't see what would be more efficient, given that there are operations in HTTP/2 which necessarily need unique/mutable access to the connection state, which would be owned by the event loop...\nI made a minimal prototype of this, just to verify that it would work, as well as to see what kind of changes would be required in solicit [1]. I don't want to get too involved in the exact specifics of the async IO implementation that we end up going with here (avoid the whole \"too many cooks...\" situation), but it'd be good if these requirements could be considered already to minimize any churn or duplication required to also support HTTP/2.\n[1] It out turns that by only adding a couple of helper methods it all works out quite nicely already, given that solicit was not coupled to any concrete IO implementation. I'll put in the work to adapt the part in hyper once the async IO approach is closer to being decided on and finalized...\n. So I've updated the PR based on the discussion so far: rebased the fixes that were made along the way to the corresponding commits and adapted the commit messages to the style guidelines (except the one that needs to be rebased out of the tree anyway!).\nThe status is that with this, the public API of the client seems to be very nearly unaffected.\nThe return type is now HttpResult<HttpResponse>, where HttpResponse is a new struct that has the same public API as the previous Response struct, apart from not being generic. Therefore, all the examples and tests can work without any changes, but if anyone relied on the fact that this public type is generic, that code would break. Obviously, the name of the type is also different, but we could easily call this one Response and rename the old one, although in that case a different type of \"breakage\" occurs, since Response was a publicly exposed type, someone might have used it directly, instead of going through the Client (though very unlikely).\nFor now I also removed the with_connector method, but we could keep that in and instantiate an HTTP/1.1 request factory in the implementation so as to keep that change also completely transparent.\n. So, what do you guys (@seanmonstar, @reem) think: should we go down this route? If so, I can bang this into shape with proper test coverage, documentation, error handling, etc.\n. @seanmonstar \n\nI know Servo uses Request::with_connector, cause the XHR spec defines some fun rules slightly different than standard HTTP\n\nIndeed, currently the establishment of the underlying TCP connection that the HTTP/2 connection would use is somewhat hidden away, but letting it use the NetworkConnector abstraction for that should be quite simple. The NetworkConnector produces an object that is both Read and Write, which is all that solicit's HTTP/2 connection requires. The custom connectors that Servo may already have should then work regardless of whether the tcp connection is used for h1 or h2.\n\nI have a Pool implementation in #486. That would allow keeping the requests around, and having h1 -> h2 upgrade functionality.\n\nThe way the pool is implemented right now doesn't lend itself at all to reusing connections for HTTP/2. What is currently pooled are the tcp connections, not HTTP connections. This is virtually the same for h1, but it is not so for h2. This is because in h1, you can simply send the raw request bytes on one of the established tcp streams and you're good; no previously sent requests on that particular stream matter for the raw payload that you transmit over the wire, nor for the parsing of the response payload. In h2, however, the payload you send for a request does depend on previously sent requests - you need to assign a new stream id, hpack encoding/decoding the headers is stateful, flow control windows depend on previously sent data, etc. Therefore, simply pooling the TCP connections does nothing to allow \"keep alive\"-like usage of an HTTP/2 connection.\nOf course, it's doable to pool the actual HTTP 2 connections, by doing what you've done on the connector level within (what is currently named in this pr) the HttpRequestFactory. In fact, if acquiring a lock before creating a new request is already deemed acceptable, I could even squeeze my async client into the same api, allowing multiple concurrently issued requests to the same host to use the same HTTP 2 connection, as long as the original factory instance is kept alive and its clones given to new hyper clients (provided that spawning an io thread is also acceptable).\n\nWhat did you think of my previous suggestion of keeping Client, Request, and Response as opaque structs, and having the trait be a HttpMessage, implemented by http1 and http2? I'd like to think this would ease implementing on the server as well...\n\nI don\u2019t think I fully understood what you were aiming at with the HttpMessage trait. From what I can gather, it should be a type that exposes an interface for queuing HTTP \"messages\" (set_outgoing), as well as for grabbing them off a connection (get_incoming). The Read/Write trait bounds were for reading/writing the body?\nThe way it looks like it would be used would to implement the request's Fresh -> Streaming -> Response transformation would be to first queue the MessageHead (i.e. Fresh -> Streaming), then stream out the response (calls to the underlying Write?) and grab the response head (i.e. Streaming -> Response), and finally read out the response (calls to the Read). All this has already become encapsulated by the FreshHttpRequest and StreamingHttpRequest traits. The implementations of these two traits, along with a corresponding factory for HTTP/1.1 and HTTP/2 fully encapsulate all relevant protocol logic.\nSo, I don\u2019t see the benefit of this alternate approach. It seems it would only shift the actual protocol logic a level lower... Is it that you hope to reuse this HttpMessage component to support server-side HTTP/2, as well?\nOriginally, when you wrote that comment, I thought the suggestion was so that we avoid having type parameters on the Client, which I\u2019ve achieved by making the Response struct fully independent from the protocol that produces it. (The original post is what nudged me into realizing it was easily doable.)\nPerhaps you could flesh out your proposal more because I just might not be fully getting the idea from the previous short description.\n. @seanmonstar I have an experiment over on this branch (forked off the current master HEAD, not this PR) refactoring the HTTP/1.1-specific parts of Request/Response into an implementation of an HttpMessage trait, such as what you described.\nIs this sort of what you had in mind for the HttpMessage API?\n. @seanmonstar \nThe trait does work out quite nicely for HTTP/2 too.\nSo, here's an attempt at landing the PR, this time with everything polished up with proper docs and tests for the new features. Feedback of course appreciated.\n(Side note: the HttpMessage API would allow for some nicer tests for the Client itself. Right now, it seems very difficult -- or at least extremely kludgy -- to test what the client itself sends, regardless of the protocol. For example, I wanted to write a test which checks whether the client properly handles redirects, as by looking at the code it seems like it always sticks to the original request method, regardless of the redirect status code it sees, but I gave up once I saw that writing a test that checks exactly what requests got sent wasn't as easy as I'd hoped. With the HttpMessage API we can just test which messages got dispatched, making it all much smoother.)\n. Happy to do it! Glad we've worked out the initial integration; we can take it from here and tweak/improve things incrementally, of course... Should be less of a big-bang than this :)\n. > Just curious, from the example: \"Host\": \"http2bin.org,http2bin.org\",, is it supposed to have the host doubled like that?\nhyper probably includes the Host header and the HTTP/2 client includes the :authority pseudo-header so that's probably where it ends up looking doubled.\n:authority \"should\" be used in HTTP/2 requests, but host is still fine, so we can tweak it that the Http2Message doesn't set any of those unless they're given to it in the message head? (Like HTTP/1.1 at least one of those headers is still required for every request, so it means that the Request always needs to set it...)\n. Since the HTTP/2 stuff got merged, openssl found its way back in :) I've published a new version of solicit (0.3) to crates.io, that relegates it to an optional dependency too, behind the \"tls\" feature. Hyper doesn't use anything from there yet anyway, so it should be fine to just go with the default set in all cases. \n. Looks good to me. \n. This doesn't break anything, for two reasons:\n- solicit has no \"openssl\" feature :) All this has been doing here was pulling in its version of the (optional) openssl library, apparently...\n- Even the \"tls\" feature, which is what was meant here, I'm sure, isn't used anywhere\nI mentioned before that we don't need it here for anything... :)\n. This seems to be a resurgence of #361...\nBasically, Github does not delimit their response header lines with CRLF (only \\n) and hyper can't handle only the linefeed.\nInterestingly enough, they do properly use the CRLF for success responses; it is only when they're returning the 403 that the response uses only the LF.\nIn this case, you're getting a 403 because Github expects a User-Agent header to be included with every request, otherwise it's \"Forbidden\". This means you can easily fix your problem by adding a .header(UserAgent(\"my-agent\")), but hyper should still perhaps be able to handle that response too.\n\nBasically the following test fails:\n``` rust\n    #[test]\n    fn test_no_crlf_only_lf() {\n        let mut raw = MockStream::with_input(b\"HTTP/1.0 403 Forbidden\\nCache-Control: no-cache\\nConnection: close\\nContent-Type: text/html\\n\\nRequest forbidden by administrative rules. Please make sure your request has a User-Agent header (http://developer.github.com/v3/#user-agent-required). Check https://developer.github.com for other possible causes.\\n\");\n        let mut buf = BufReader::new(&mut raw);\n        let res = parse_response(&mut buf);\n    assert!(res.is_ok());\n    assert_eq!(res.unwrap().subject.1, \"Forbidden\");\n}\n\n```\nand this one passes:\n``` rust\n    #[test]\n    fn test_crlf() {\n        let mut raw = MockStream::with_input(b\"HTTP/1.0 403 Forbidden\\r\\nCache-Control: no-cache\\r\\nConnection: close\\r\\nContent-Type: text/html\\r\\n\\r\\nRequest forbidden by administrative rules. Please make sure your request has a User-Agent header (http://developer.github.com/v3/#user-agent-required). Check https://developer.github.com for other possible causes.\\n\");\n        let mut buf = BufReader::new(&mut raw);\n        let res = parse_response(&mut buf);\n    assert!(res.is_ok());\n    assert_eq!(res.unwrap().subject.1, \"Forbidden\");\n}\n\n```\nThe raw bytes given to the stream in the former correspond exactly to the raw response that gh returns when no UA is included in the request.\n. Actually, I think this can happen, but not because the response is empty, but because the Content-Length header is invalid.\nFor example, try accessing a server that gives Content-Length: asdf or even Content-Length: (i.e. empty) and you'll reproduce this.\nIt's because the get_incoming method definitely drops the stream here and returns an Err, but then Response tries closing it in the error match arm here.\nAdding a line to save the stream before returning the Err in get_incoming fixes it, though...\n. TIL :)\nThough I'm not really surprised as it's just git diff -w\n. You're absolutely right, I disregarded what would happen during stack unwinding if an exception is thrown... As soon as you step foot into unsafe land, it's back to C++ :)\nHere's a different approach, with no unsafe, but the same idea, though.\nHere, the Wrapper type keeps the stream in an Option so that it can internally move out of it even in a &mut self method (by temporarily zeroing out the option). The only way to change the value is by going through the map_in_place method, which takes the current value from the Option, gives it to a closure, but expects the new one to be returned from it. Then, it puts that result back into the option. If the closure panics in this case, the object will have been owned only by the closure and dropped just once during unwinding. (It's all safe Rust, so there couldn't have been any aliasing introduced.) On the other hand, when the closure correctly returns, we're guaranteed that the Wrapper always has an object in the Option.\nThe last possibility is that someone catches the unwinding before the Wrapper instance itself is dropped. That would mean that the Wrapper would be left in a sort of poisoned state where the internal Option is unexpectedly None. This would cause another panic when any of its methods are subsequently called.\nI think this is an improvement over the current version where we can get a panic by dropping the stream early, due to not being careful enough how the stream is juggled around... The only way to lose a stream here is by panicking within one of the methods of Http11Message, catching the panic before the message is dropped, and then trying something else with the message.\nWhat do you say? :) (As you can tell, I'd really like to find a way to clean this up :))\n. You probably need to update your rustc to the latest stable version (1.3.0), as that's when the Duration API got stabilized.\n. Yeah, not yet... I wanted to maintain some flexibility, without pushing multiple versions out to crates.io, if it turned out that I needed to do some changes there to make things work better in hyper (so far it turned out that I didn't).\nOf course it's something to do before finally landing this to make sure hyper is pinned to a proper version.\n. That was my initial idea as well, but after some thought I found it wouldn't work.\nYou see, the FreshHttpRequest, StreamingHttpRequest, and HttpResponse traits define methods that move (i.e. consume) the object they're called on (start, send). What that means is that you can't call them on trait objects (such as Box<FreshHttpRequest>). Therefore, you have to know the exact types of the request and response objects, so even if the factory were boxed up, the Client would end up having to be generic over the FreshHttpRequest trait (which is what the factory produces). Perhaps there's a different workaround for this, but since the type of the fresh request needs to be known at the point of calling the start method, I don't see how we could fully avoid any type parameter to the Client.\nA different option is to make the request and response methods not consume the object, but that would be a much more invasive change to the codebase and would require a lot more thought about the implications of such a change. I, myself, am not sure whether that'd be a good approach, since at least currently, the requests' \"natural\" lifecycle is a transformation Fresh -> Streaming -> Response and so it is natural that the methods consume/move the object.\n. Fair enough... I'll revert this. Come to think of it, this change isn't even required for the http2 code anymore (as I found a different way to do what this had been intended to).\n. Sure, might make more sense for now...\n. Hehe :)\nAs I mentioned in the opening comment, the PR is definitely not ready to be merged just yet.\nI removed this since I wanted to be able to experiment with changes without being slowed down by having to put docs everywhere and get rid of warnings.\nIf we want to go forward with polishing this up, then of course all those issues will be solved and the commit that removed these two lines rebased out of the tree.\n. Nice one!\n. How about we do something similar to what you suggested with using into_bytes for the path.\nNamely, implement Borrow<str> for Method and then just pass that (as_bytes) to the solicit API that expects a &[u8]. It would avoid an extra allocation here...\n. Yeah, you're right AsRef would probably be better.\n. Right, that's a nice hack and could be used to circumvent the problem I mentioned.\nThat said, I'm still not convinced of the benefit of doing it like that, instead of having a generic Client. Consider the send method on the RequestBuilder. In this scenario, its signature needs to change to return HttpResult<Box<HttpResponse>> -- since we can't know the actual type of the response. This is also a change to the public API of the client -- and in my opinion a more significant one than introducing a generic type parameter (with a default).\nIf the send method returns a trait object, all clients that previously did stuff like:\nrust\n    // get res the usual way\n    println!(\"Response: {}\", res.status);\nWould need to be changed to use the appropriate trait method, instead of directly accessing the field. This also implies having to import the trait itself.\nIsn't this more invasive than adding a type annotation when declaring a client instance?\nI have a branch client-box-api on my fork where you can see how it looks with this alternative approach. (It also includes the HTTP/2 commits)\nLet me know what you guys like better...\n. It sounds good. My feeling is that it might imply a bit more than what the trait currently does (only deals with the client side aspect), but bikeshedding over the name too much doesn't gain us anything... \n. Nice one. \n. I see. \nEssentially, we'd end up removing the (currently) private bits of the request and response structs (which are the ones that make them tightly coupled to an HTTP/1.x implementation) and replace them with this new trait object and have the structs delegate the protocol-specific operations to it. So the client keeps its api unchanged, as it still only exposes the same response struct (at least from the perspective of the public fields). \nHow about we combine the two approaches... The HTTP response trait that I introduced could be replaced by a struct with the same public fields as the current one. Then, the streaming response trait mandates that the response is exactly that struct and not a generic implementation of the trait. Coupled with the boxed up factory (on the other branch that I mentioned), we'd end up removing the generic parameter and the change in the signature of the send method (at least from the api, if not binary perspective). \nI'm currently on mobile so I can't write any code snippets to get the point across better, but I hope it's understandable what I'm proposing.\nWhat do you think about it? I might be missing something? \n(if you want to take some time to think through alternative designs yourselves, I'm fine with that and we can put this on hold for a while, I just opened the pr since I wanted to get some code out there as a basis for such a discussion as it's always easier when there's something to base it off) \n. Done.\n. Indeed, this is still done in the Response so as not to duplicate it in all HttpMessage impls. Removed.\n. If you mean without the try!, then no. The error types are mismatched: close_connection requires hyper::error::Error and the close returns an std::io::Error. Since the types aren't automatically converted (i.e. without a From::from call), to me it looked nicest to go with a try!.\n. All right, say there's an enum:\nrust\nenum MessageState {\n    Idle(Box<NetworkStream + Send>),\n    Writing(HttpWriter<BufWriter<Box<NetworkStream + Send>>>),\n    Reading(HttpReader<BufReader<Box<NetworkStream + Send>>>),\n}\nNow in set_outgoing(&mut self, ...), the internal state of the message needs to transition to MessageState::Writing and the writer needs to be based on the stream originally wrapped in the Idle variant. I'm not sure how the Box<NetworkStream> should be moved into a different variant here.\nset_outgoing takes &mut self, so neither the full state enum nor the Box within the Idle variant can be moved. The only thing I can think of around that would be to use mem::replace, but it'd still require something (akin to None) to be put in place of the original state while the stream is juggled into the correct Writer.\nThis None-like state, though, would still imply that it's technically possible to lose the stream along the way, so it's only a slight improvement...\nIs there some better approach to implementing the transition which would avoid this None state altogether?\n. Here, on the other hand, the state enum works out just fine. I suppose because there's no state that needs to be transferred between the variants when a transition happens...\n. The names should still be valid utf8 (8.1.2 HTTP Header Fields) on the HTTP layer, that's true. (HPACK is what treats both the name and value as an opaque octet sequence.) So, indeed, if the name cannot be decoded as utf8, the response is malformed. This is now fixed (along with a test).\nAs for multiple SetCookie headers -- the situation is unchanged: multiple cookies correspond to multiple set-cookies headers. That said, I was hoping that hyper would correctly handle this itself...\nWhat I see now, though, is that it effectively fakes it by having the value of the Set-Cookie entry in the header::Headers struct contain a CRLF delimiter and continue on to the next Set-Cookie header.\nrust\n    let cookies = header::SetCookie(vec![\n        cookie::Cookie::new(\"foo\".to_owned(), \"bar\".to_owned()),\n        cookie::Cookie::new(\"baz\".to_owned(), \"quux\".to_owned())\n    ]);\n    // Now the following is true:\n    cookies.name() == \"Set-Cookie\"\n    cookies.value_string() == \"foo=bar; Path=/\\r\\nSet-Cookie: baz=quux; Path=/\"\nThat hack works when sending the header over HTTP/1.1, but not HTTP/2, as the CRLF is meaningless. I've worked around it in the prepare_headers function to special case the Set-Cookie and extract the cookies that it contains into separate HTTP/2 headers (although since for now there's only client support, it shouldn't actually get triggered, as clients aren't supposed to send that header).\nOn the other hand, when parsing a response with multiple set-cookie headers returned by an HTTP/2 server, it seems that hyper's Headers::from_raw method ends up returning a headers collection with a SetCookie header that correctly contains all the cookies, as verified by a new unit test... Should from_raw not be relied on to do the right thing?\n. That would be a nice improvement to aim for, for sure.\n. As I mentioned in the comments over at #542, you should bump up this version to \"0.3\" to make sure that hyper doesn't end up requiring openssl transitively through solicit.\n. ",
    "yazaddaruvala": "Any updates? I'm really looking forward to this!\n. Hey @seanmonstar, good read: http://seanmonstar.com/post/141495445652/async-hyper. Thanks for the update, and all the hard work!\nNext::end() covers the situation where the server wants to end the connection. However, one thing that isn't explicitly obvious is how the server handles a connection that gets closed prematurely from the client's side?\nWould this be handleable in on_request_readable during match transport.read(...)? or would(should) Handler need an on_request_closed?\n. @seanmonstar nit: I think you missed the handling of State::Done in the match.\nWhy not fn ready(self, txn: &mut Transaction<T>) -> State and deal with state transitions inside Hyper code? Seems like a better utilization of the type system.\n. 1. In theory it should cut down on allocations.\n2. Move Encoder closer to use a pre-defined Tokio trait. Just need to remove the io from Encoder.\n3. It also sets hyper up for more reuse. For example, as you previously pointed out Buffered has its own internal buffers.\n4. A better init capacity (i.e. not 0) would probably improve performance. Any thoughts on the init-capacity? Note: This buffer can never exceed: (ChunkSize::len - ChunkSize::pos) + 2 + msg.len() + 2. It might be a good size to initialize it to max(msg.len()) + 4 or something.\nFWIW: I did try swapping out BytesMut for Vec<u8> (to improve performance more) but the tests weren't passing, which was strange so I didn't want to modify tests and went back to BytesMut. I also didn't wanna play around a bunch with init-capacity, sharing more buffers or removing the io from Encoder unless you thought this was a decent first step and thats the direction you wanted to go.\nRegarding benches: There seems to be a tiny improvement for bench_server_tcp_throughput (i.e. ~4.5%), but nothing substantial, and no change I could discern in any of the others (including wrk). I think the wrk benchmark is not a good example, as the response is just a hello world (i.e. the buffer isn't really getting any re-use).\nLet me know if I did this right/wrong (I did 3 iterations of each command):\ncargo bench\ncargo bench --all-features http\ncargo run --release --example hello + wrk http://127.0.0.1:3000\nOrigin Master:\n```\ntest get_one_at_a_time  ... bench:     160,683 ns/iter (+/- 53,933) = 338 MB/s\ntest post_one_at_a_time ... bench:     139,204 ns/iter (+/- 14,831) = 391 MB/s\ntest bench_raw_tcp_throughput    ... bench:      29,455 ns/iter (+/- 1,715) = 5 MB/s\ntest bench_server_tcp_throughput ... bench:      64,910 ns/iter (+/- 4,129) = 2 MB/s\ntest get_one_at_a_time  ... bench:     133,196 ns/iter (+/- 23,932) = 408 MB/s\ntest post_one_at_a_time ... bench:     134,964 ns/iter (+/- 27,127) = 403 MB/s\ntest bench_raw_tcp_throughput    ... bench:      30,639 ns/iter (+/- 9,273) = 5 MB/s\ntest bench_server_tcp_throughput ... bench:      63,335 ns/iter (+/- 3,177) = 2 MB/s\ntest get_one_at_a_time  ... bench:     134,292 ns/iter (+/- 22,861) = 404 MB/s\ntest post_one_at_a_time ... bench:     138,777 ns/iter (+/- 28,843) = 392 MB/s\ntest bench_raw_tcp_throughput    ... bench:      29,926 ns/iter (+/- 3,009) = 5 MB/s\ntest bench_server_tcp_throughput ... bench:      62,860 ns/iter (+/- 7,198) = 2 MB/s\ntest http::h1::parse::tests::bench_parse_incoming                   ... bench:       4,359 ns/iter (+/- 990) = 201 MB/s\ntest http::h1::parse::tests::bench_server_transaction_encode        ... bench:         364 ns/iter (+/- 112) = 206 MB/s\ntest http::h1::parse::tests::bench_parse_incoming                   ... bench:       4,490 ns/iter (+/- 1,672) = 195 MB/s\ntest http::h1::parse::tests::bench_server_transaction_encode        ... bench:         437 ns/iter (+/- 89) = 171 MB/s\ntest http::h1::parse::tests::bench_parse_incoming                   ... bench:       4,768 ns/iter (+/- 813) = 184 MB/s\ntest http::h1::parse::tests::bench_server_transaction_encode        ... bench:         351 ns/iter (+/- 109) = 213 MB/s\nYazads-MacBook-Pro% wrk http://127.0.0.1:3000\nRunning 10s test @ http://127.0.0.1:3000\n  2 threads and 10 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   305.84us   88.61us   5.21ms   89.37%\n    Req/Sec    16.19k     1.37k   21.02k    84.65%\n  325384 requests in 10.10s, 40.03MB read\nRequests/sec:  32216.24\nTransfer/sec:      3.96MB\nYazads-MacBook-Pro% wrk http://127.0.0.1:3000\nRunning 10s test @ http://127.0.0.1:3000\n  2 threads and 10 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   305.93us   62.02us   2.84ms   71.35%\n    Req/Sec    16.13k     1.29k   20.49k    87.00%\n  320848 requests in 10.00s, 39.47MB read\nRequests/sec:  32085.10\nTransfer/sec:      3.95MB\nYazads-MacBook-Pro% wrk http://127.0.0.1:3000\nRunning 10s test @ http://127.0.0.1:3000\n  2 threads and 10 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   316.02us  179.23us   9.93ms   99.08%\n    Req/Sec    15.86k     1.14k   19.51k    86.00%\n  315543 requests in 10.00s, 38.82MB read\nRequests/sec:  31551.20\nTransfer/sec:      3.88MB\n[Local Changes](https://pastebin.com/xiJsErg6):\ntest get_one_at_a_time  ... bench:     131,957 ns/iter (+/- 13,539) = 412 MB/s\ntest post_one_at_a_time ... bench:     160,557 ns/iter (+/- 211,404) = 339 MB/s\ntest bench_raw_tcp_throughput    ... bench:      29,558 ns/iter (+/- 8,365) = 5 MB/s\ntest bench_server_tcp_throughput ... bench:      61,322 ns/iter (+/- 3,232) = 2 MB/s\ntest get_one_at_a_time  ... bench:     135,429 ns/iter (+/- 29,762) = 401 MB/s\ntest post_one_at_a_time ... bench:     141,821 ns/iter (+/- 22,682) = 383 MB/s\ntest bench_raw_tcp_throughput    ... bench:      29,960 ns/iter (+/- 14,258) = 5 MB/s\ntest bench_server_tcp_throughput ... bench:      62,109 ns/iter (+/- 3,325) = 2 MB/s\ntest get_one_at_a_time  ... bench:     129,452 ns/iter (+/- 34,420) = 420 MB/s\ntest post_one_at_a_time ... bench:     134,567 ns/iter (+/- 12,938) = 404 MB/s\ntest bench_raw_tcp_throughput    ... bench:      30,774 ns/iter (+/- 18,852) = 5 MB/s\ntest bench_server_tcp_throughput ... bench:      58,977 ns/iter (+/- 2,983) = 2 MB/s\ntest http::h1::parse::tests::bench_parse_incoming                   ... bench:       4,743 ns/iter (+/- 833) = 185 MB/s\ntest http::h1::parse::tests::bench_server_transaction_encode        ... bench:         379 ns/iter (+/- 151) = 197 MB/s\ntest http::h1::parse::tests::bench_parse_incoming                   ... bench:       4,321 ns/iter (+/- 1,697) = 203 MB/s\ntest http::h1::parse::tests::bench_server_transaction_encode        ... bench:         395 ns/iter (+/- 159) = 189 MB/s\ntest http::h1::parse::tests::bench_parse_incoming                   ... bench:       4,651 ns/iter (+/- 1,507) = 188 MB/s\ntest http::h1::parse::tests::bench_server_transaction_encode        ... bench:         357 ns/iter (+/- 118) = 210 MB/s\nYazads-MacBook-Pro% wrk http://127.0.0.1:3000\nRunning 10s test @ http://127.0.0.1:3000\n  2 threads and 10 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   313.23us   62.16us   2.79ms   78.37%\n    Req/Sec    15.75k     1.32k   32.25k    95.52%\n  314983 requests in 10.10s, 38.75MB read\nRequests/sec:  31188.50\nTransfer/sec:      3.84MB\nYazads-MacBook-Pro% wrk http://127.0.0.1:3000\nRunning 10s test @ http://127.0.0.1:3000\n  2 threads and 10 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   307.08us  107.77us   7.70ms   96.92%\n    Req/Sec    16.15k     0.92k   19.47k    84.65%\n  324517 requests in 10.10s, 39.92MB read\nRequests/sec:  32127.92\nTransfer/sec:      3.95MB\nYazads-MacBook-Pro% wrk http://127.0.0.1:3000\nRunning 10s test @ http://127.0.0.1:3000\n  2 threads and 10 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   322.04us  210.94us  10.11ms   99.46%\n    Req/Sec    15.66k   684.91    19.80k    81.19%\n  314725 requests in 10.10s, 38.72MB read\nRequests/sec:  31162.78\nTransfer/sec:      3.83MB\n```. > The benchmarks run probably aren't affected at all by this change, since this is adjusting the chunked encoder, and those benchmarks are all using the length encoder.\nlol I'm good at life. I'll try and make an actual benchmark for this.\n\nI'm not sure I want to be adding a secondary buffer to enum Writing, when there is already a write buffer in Buffered. I find it's starting to get more complex to know which buffer still needs to be flushed.\n\nThe new buffer always has .take called on it, and as such is fully flushed every time. I guess, I'm curious: Do you not consider the call to .concat() using a secondary buffer?\n. Ok closing this. All of these ideas suck when I bench them.. Actually, I guess this is kinda useful:\n```\n     Running target/release/deps/end_to_end-014a7943b1aabad9\nrunning 2 tests\ntest get_one_at_a_time  ... bench:     176,725 ns/iter (+/- 266,501) = 395 MB/s\ntest post_one_at_a_time ... bench:     157,687 ns/iter (+/- 9,219) = 443 MB/s\ntest result: ok. 0 passed; 0 failed; 0 ignored; 2 measured; 0 filtered out\n Running target/release/deps/server-45555c2f466b2f1c\n\nrunning 4 tests\ntest bench_raw_tcp_throughput                            ... bench:      29,996 ns/iter (+/- 3,678) = 5 MB/s\ntest bench_server_tcp_throughput_chunked_large_payload   ... bench: 103,856,036 ns/iter (+/- 7,276,174)\ntest bench_server_tcp_throughput_chunked_small_payload   ... bench:      58,820 ns/iter (+/- 4,112) = 2 MB/s\ntest bench_server_tcp_throughput_fixedsize_small_payload ... bench:      59,082 ns/iter (+/- 2,911) = 2 MB/s\ntest result: ok. 0 passed; 0 failed; 0 ignored; 4 measured; 0 filtered out\n.\n     Running target/release/deps/end_to_end-014a7943b1aabad9\nrunning 2 tests\ntest get_one_at_a_time  ... bench:     149,290 ns/iter (+/- 43,187) = 467 MB/s\ntest post_one_at_a_time ... bench:     152,446 ns/iter (+/- 18,027) = 458 MB/s\ntest result: ok. 0 passed; 0 failed; 0 ignored; 2 measured; 0 filtered out\n Running target/release/deps/server-45555c2f466b2f1c\n\nrunning 4 tests\ntest bench_raw_tcp_throughput_small_payload              ... bench:      30,170 ns/iter (+/- 45,908) = 5 MB/s\ntest bench_server_tcp_throughput_chunked_large_payload   ... bench: 101,208,206 ns/iter (+/- 8,786,614) = 128 MB/s\ntest bench_server_tcp_throughput_chunked_small_payload   ... bench:      60,735 ns/iter (+/- 5,039) = 3 MB/s\ntest bench_server_tcp_throughput_fixedsize_small_payload ... bench:      58,281 ns/iter (+/- 2,980) = 2 MB/s\ntest result: ok. 0 passed; 0 failed; 0 ignored; 4 measured; 0 filtered out\n``. Ideally,bench_raw_tcp_throughput_small_payload` would have a large counterpart, but I'm not sure what the best way to do the concatenation would be. I don't want to end up benching the concatenation technique rather than the socket.\n. Lol I was just typing up a comment asking if you wanted me to make smaller CRs.\nBut actually, do you prefer more bite sized CRs so you can do them at a glance or larger ones like this?. Got it.\nFor now, I do like that it is in uri.rs, having it colocated is really helpful to find out if it is useful or how we can improve the interface. Basically, it allows people to play with it without worrying about it being used elsewhere.\nI can put it in its own sub-module within Uri. Especially, if you want to eventually use it in other places then that definitely makes sense, and it would be good to ensure only the pub interface is used.. @seanmonstar re you happy the way it is (i.e. an internal module)?\nOr would you prefer if ByteStr was in its own file: src/uri/mod.rs + src/uri/str.rs?. I'd prefer something like use ::common::ByteStr;, would that work for you?. Yup agreed, I wouldn't want to expose this to anyone.\nI would also be inclined to name it use ::private_utils::ByteStr. No real preference on the name. Let me know.. Updated to common. That was going to be my next PR, but I can make it this one. As much as possible, I want to only deal with State in Stream and Sink :)\nLets see what it looks like. If you don't like it, I'm happy to abandon it.. Thoughts on it now, i.e. only being set in Stream?. Interesting, I was actually curious if the \"except when on KeepAlive\" was an accidental inconsistency.\nNo worries, I just sorta imagined that read_blocked was a legacy name, and it should have been stream_blocked. But since that is not the case, and if future code paths could return NotReady but are not supposed to set read_blocked then I agree, this is not the correct approach.. For more context I understand that .read_bufs corresponds to a readv syscall, but I have no idea what the performance characteristics of using that syscall vs .read would be.. I have a love hate relationship with generics. At lease as far as I can tell everywhere in Hyper. I.e. Server and HttpConnector we use TcpStream.\nThere is a possibility that Config currently allows people to add a connector which is not HttpConnector. There is also a possibility someone doesn't use hyper::Server but then they are using the __Proto proxies. \nCouple options: 1. \"Plug those holes\" by making Conn explicitly use a TcpStream. 2. Make the creation of a Connector unsafe. 3. don't use slow transports - add documentation.\nI prefer option 1. but this does slightly increase the commitment that hyper will only use tokio transports.\nOption 1 does also deprecate what I imagine was a use case for having custom Connectors. . Cool, let me know if there is anything you'd like me to tweak.\n. Yeah I mean.. the benches are weird sometimes. I've found they run faster or slower if I switch tabs in the same terminal. But its all good, if its slower its slower.\n. Lol nothing to be sorry about, the impl in std clearly needs some love. Might be a good first commit.\n. The only reason I was using BytesMut is because of the Tokio docs and types. I'll change them back to Vec.. Ok, I wont lie your statements are a bit above my pay grade. Mostly I was just trying to get rid of the allocations that come from .concat(), but can deffer that for now.\nDo you mind if I just inline AtomicWrite since its just a simple passthrough, or would you rather keep it to be able to extend later?. Hey yeah, the only reason I wasn't using io.write_buf is because I'm not sure when the io.flush method gets called.\nIf you're cool with .encode extending io.write_buf and then io.flush inside conn, that I can do.\nI'm happy with it any way, just trying to remove the extra allocations inside .encode if possible.. Yeah fair enough. I was hoping that if we could move all this to the Tokio types then the Tokio foundation would magically handle all the performance stuff.\nWhats a good way to run performance tests? I only really have access to a 4 year old mackbook pro. Lol, I never want to me in charge of performance sensitive code.\nI'll add a comment instead. Similar to the comment for date, do you remember what that speedup was?\n. Any specific parameters for wrk?. Well, in its defense, the message size is 6 magnitudes greater, and the number of iterations is only 4 magnitudes higher :). To make sure I know what you mean:\n$b.bytes = 130 + 35 + $total_bytes;?. I got it, $b.bytes = 35 + $total_bytes;. tldr: Im very happy to leave it alone and remove the comment for now.\nI was playing with it last night, what I found was that more or less we do not interact with ByteStr or Bytes mostly we interact with &str. But at the same time we don't know the lifetime.\nWhat would be ideal is if we could store ByteStr {Bytes, &str /* pointing to Bytes */}. Then if Uri was only using a &str, ByteStr would not have much use.\nThoughts?\n. Not a rebuttal, I'm just curious what you mean by shared. Doesn't ByteStr owns Bytes?. @seanmonstar my next CR will probably move read_blocked into http::Conn::State. I've verified that its semantically equivalent in all other locations, help me with errors.\nFor example:\npub fn parse<S: Http1Transaction>(&mut self) -> Poll<MessageHead<S::Incoming>, ::Error> {\n          loop {\n              // Initially, read_buf will be empty; read_blocked=false\n              match try!(S::parse(&mut self.read_buf)) {\n                  Some(head) => {\n                      // Can only get here if `parse` has all of the data it needed to construct a MessageHead\n                      // Which means, read_buf was just written to.\n                      // Which in turn means read_blocked = false; because read_from_io would have had to return Async::Ready\n                      //trace!(\"parsed {} bytes out of {}\", len, self.read_buf.len());\n                     return Ok(Async::Ready(head.0))\n                  },\n                  None => {\n                      if self.read_buf.capacity() >= MAX_BUFFER_SIZE {\n                         // This error case can in theory happen when read_blocked = true or false;\n                         // However, does the state still matter if we are returning an error?\n                         debug!(\"MAX_BUFFER_SIZE reached, closing\");\n                         return Err(::Error::TooLarge);\n                      }\n                  },\n              }\n              // Semantically equivalent to expand the macro:\n              // read_blocked = false\n              // do read_from_io\n              // If read_from_io == NotReady: read_blocked = true; return NotReady\n              match try_ready!(self.read_from_io()) {\n                 0 => {\n                      trace!(\"parse eof\");\n                      //TODO: With Rust 1.14, this can be Error::from(ErrorKind)\n                      return Err(io::Error::new(io::ErrorKind::UnexpectedEof, ParseEof).into());\n                  }\n                 _ => {},\n              }\n          }\n      }\nIn that example, when we return an error, the connection will be closed correct? As such the state no longer matters, and I can set read_blocked to whatever without worry?. Perfect. ",
    "arthurprs": "@tailhook great post, did it show up in HN and /r/rust already?\n. @tailhook I'll help with the second one them.\nAlso, I'm curious, what kind of performance do you get w/ Golang in the same machine?\n. The mio branch cpu usage is like half of the threaded. That might be related \n. It's probably reasonable to disable naggle by setting NO_DELAY by default with an option to enable.. json results look good, but there's probably room for improvement overall. Right now most of the effort is aimed towards releasing the new version on top of tokio.. It is, that diff line is meant to unify the styles.. ",
    "alubbe": "Quick update that mio 0.5 is out and supports windows.\n. Awesome news! Speaking of benchmarks, what kind of numbers are you seeing\ncompared to the current hyper master?\n. Thanks for the rough benchmark numbers. If I understand correctly, the\nrequests carry out synchronous workloads, i.e. they don't yield back to the\nevent queue. I would love to see a benchmark where each request 'sleeps'\nfor some amount of time (1 or 10ms, mocking a network request) and only\nthen sends its response. No hurry though, just curious :)\n. Thanks for the update, I was able to get the examples to work.\nOne of the things I noticed was that server cannot utilize more than one cpu core now. I assume this is because of mio. Are there any plans to build a master/cluster process on top to run multiple, isolated event queues for the new hyper?\n. That's pretty cool. So you would leave the implementation of how to distribute the load (e.g. round-robin) to the library consumer?\n. That's a great answer - thank you for elaborating. If you'd like some early testing for your proxy based on the mio branch, let me know, I'll give it a spin.\n. Btw, I just came across this on hacker news yesterday, you might find it interesting: http://natsys-lab.blogspot.de/2014/11/the-fast-finite-state-machine-for-http.html\n. ",
    "sorenhoyer": "Can't wait!\n. ",
    "KodrAus": "Sounds good! Are there plans for client side? I'd be interested to see what an evented model for outgoing requests will look like.\n. Awesome stuff. It looks like what you'd expect working with mio at a lower level to me. Do you have plans for an evented client sample?\n. Specifically, I'd like a crate for status codes. Right now in some response APIs of mine I expose the status as a u16 because I don't have a dependency on hyper.\nhypers license is permissive, so there's nothing stopping someone from doing a copy+pasta of the status mod, slap the license in there and call it a day. It's not really the same as a crate blessed by @seanmonstar though that we know will always be in line with hyper (and any other http bits a user may want to use).. Can you declare the ErrorKind enum in error-chain to be private? error-chain does have the nice benefit of collecting a backtrace from the error's source.. @sanmai-NL That's interesting, are you able to share a bit about what you do with specific hyper::Error variants? In the code I've written using hyper I don't think I've had a case where I could do something useful with any specific  variant of Error, just shrug and pass it along. But that could definitely just be me so I'm interested to know how other people hold it.. > Maybe translate error messages into another language.\n@dtolnay Oh that's interesting... I've never thought of translating errors before. I guess you could do that on an arbitrary text stream though, rather than individual error variants?\n\nWhat I am trying to point out is that having one Error type to cover lots of code ... seems less productive to me than having specific Error types.\n\n@sanmai-NL I have the opposite opinion on this with respect to libraries like hyper that are consumed by other libraries. I think having multiple error types that span a single use-case adds boilerplate when trying to chain errors, and cognitive load when consuming them. Now instead of one error type to deal with you've got potentially many. Since the server and client use-cases are distinct splitting them seems reasonable to me.\nFor application code though I agree having an individual error type per operation is nicer to manage.\n\nBacktraces etc. are not very user friendly (may even instill fear), and leak information about the source code ...\n\nI think that's a good point. Returning backtraces in responses isn't very good. But having backtraces in logging is very good, and makes issues much easier to diagnose. This is especially true in Rust where you could be handling an error downstream from where it was produced, so the backtrace you get out-of-the-box might be really unhelpful. Maybe for hyper having a backtrace somewhere in its internals isn't any more useful than a backtrace where you receive it? But that could be made a concern for application logging rather than on error types directly.\nAs far as mapping a hyper response to a http response in a server goes I thought that would be done by hyper directly, rather than by callers? If that's the case then the ergonomics of inspecting the error don't matter so much. If not then maybe we should look at how that code would change with this new design and see if it becomes clunky.. Does this still block forever if you use tokio_core::reactor::Core.run() and pass your total future in instead of calling total.wait()?. Specifically I think that because hypers body is effectively a channel with a sender and a receiver if you block on the receiver end (in your call to concat2) on the same thread that's driving the sender then you'll deadlock, because the receiver will prevent the sender from making any progress.\nAt least that's how I think the Body works here.. ",
    "Keats": "@tailhook are you planning another article to sum up the whole thing now that you are happy with it?\nInterested in benchmark comparisons for hyper and rotor master branches as well \n. 400-500k req/s? How are you testing it?\nI get ~105k req/s on a good 2 years laptop that way:\ncargo run --example hello --release\nwrk --latency -t12 -c100 -d20s http://localhost:3000\n. Any reason all methods are not exported? (PATCH etc). ",
    "dashed": "@alubbe You can sorta do this by making flamegraphs: \n- http://carol-nichols.com/2015/12/09/rust-profiling-on-osx-cpu-time/\n- http://www.brendangregg.com/flamegraphs.html\n. @tailhook A state diagram to visualize the rotor API might be a good start. On earlier iterations of rotor, I had to draw out state diagrams to grok the API. \n. I'm running into this issue for v0.9.8. For now, I disable keep-alive: i.e. server.keep_alive(None);.\n. ",
    "jwilm": "@seanmonstar any ideas about schedule for this feature? Would love to know which pieces are still missing and if there are any opportunities to contribute.\nThanks!\n. This has been resolved through a separate commit\n. I'm interested in having the header, method, and status crates split out at least. These are theoretically very reusable components aside from requiring all of hyper at the moment.\n. @seanmonstar thanks for the discussion on IRC about this and for filing the issue. For anyone else following, this makes setting client::Request headers from a Headers work (with 0 overhead) without worrying about any state that hyper had in the original headers map (because there won't be any!).\n. Maybe just a problem of not checking for it then? Seems fine to explicitly register for it. \n\nOn Oct 10, 2016, at 16:21, Sean McArthur notifications@github.com wrote:\n@seanmonstar commented on this pull request.\nIn src/http/conn.rs:\n\n@@ -610,6 +617,8 @@ impl> Conn {\n             return ReadyResult::Continue(self);\n         }\n-        events = events | EventSet::hup();\n  epoll docs suggest that EPOLLHUP is always listened for. May not be the case in kqueue/windows, I suppose...\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. One thing to watch out for: the openssl environment variables need an absolute path since the openssl build runs in a different  directory than where cargo is invoked. The same error is reported for relative paths as for openssl just being missing.\n. As another data point, it sounds as if nginx uses TCP_NODELAY when a connection enters the keep-alive state but is otherwise off.\n. The HUP check should probably go after the readable / writable checks in conn.rs. That is, move the is_hup() block below the is_writable() block. Do you fancy giving that a try?\n. Seems like the latest commit on master caused the breakage\n. Thanks! Sorry for the confusion. \n. Come to think of it, it probably doesn't make sense to try and write if the connection has terminated. Maybe the hup check should be between read and write?\n. http://hyper.rs/hyper/v0.9.12/hyper/server/struct.Server.html#method.handle. This should probably include the license from the retry-after crate. Glad to see it making it into hyper!. @pimeys I think you can just paste retry-after's license into the top of the file you're adding to hyper. They're both available under the MIT license.. Adding both would cover the case where hyper actually manages to re-release under a dual license. That probably makes sense. Make sure you just take the \"header\" portion of the Apache license, though.\n\nThanks for doing this work @pimeys :). re: tokio\nI contributed a similar fix for this on master (rotor) at some point before tokio was released. Not sure if it was before or after the decoder rewrite or how many of those fixes actually made it into the tokio tree.. ",
    "lilianmoraru": "@tailhook Could you please also benchmark against Facebook's Proxygen?\n. @tailhook Here is a \"basic\" configuration: gist. It compiles proxygen and rotor but the examples of course need to be modified because they do not do the same thing logic-wise.\n. ",
    "ivanShagarov": "\nThis just gives the performance to those who need it.\n\nMost of people and organisations who want to move to Rust-lang have only one goal - improve the performance :)\n. ",
    "erikjohnston": "Ignore me if you've already done this, but if you're using non-blocking sockets with OpenSSL you can't just use the io::{Read, Write} traits, you need to port the code to use ssl_read and ssl_write [1] instead. This is because OpenSSL can return special error codes that indicate that the code must call read if they're currently writing or write if they're currently reading. (Or at least that's my understanding).\nIf you don't, it will work most of the time and then occasionally fail.\n[1] http://sfackler.github.io/rust-openssl/doc/v0.7.9/openssl/ssl/struct.SslStream.html#method.ssl_read\n. > Interesting issue. I've since decided in the async  branch to adjust the Connect trait to accept &Url instead of deciding beforehand what a Connector may or may not need.\nThat sounds like it would solve this then.\n\nIf there is no port, will the server expect the Host header to include the\nport from the SRV record?\n\nNo, the Host header would be without the port.\n. ",
    "fhartwig": "Sorry, I apparently forgot to run the tests. On it.\n. Ok, tests now build and pass on my machine. Do you want me to squash the second commit?\n. Done.\n. Amended commit message to make gitcop happy.\n. https://github.com/rust-lang/rust/issues/23121 says that they hope to have it ready for the beta release, but I'm not sure if that still applies. I can re-write the function to avoid slice patterns if you like.\n. Ok, slice patterns are gone. Tests pass for me, travis seems to have trouble with github today.\n. This fixes the build on nightly, but is obviously going to break it on beta :disappointed: \n. Ok, sorry, I'm an idiot.\n. error: the trait `core::marker::Reflect` is not implemented for the type `S` [E0277]\n(in lines 26 and 47)\n. ",
    "codahale": "Even with that attribute added, there\u2019s a followup complication error:\nsrc/header/common/authorization.rs:25:1: 44:2 error: the trait `core::marker::Reflect` is not implemented for the type `S` [E0277]\nsrc/header/common/authorization.rs:25 impl<S: Scheme + 'static> Header for Authorization<S> where <S as FromStr>::Err: 'static {\nsrc/header/common/authorization.rs:26     fn header_name() -> &'static str {\nsrc/header/common/authorization.rs:27         \"Authorization\"\nsrc/header/common/authorization.rs:28     }\nsrc/header/common/authorization.rs:29 \nsrc/header/common/authorization.rs:30     fn parse_header(raw: &[Vec<u8>]) -> Option<Authorization<S>> {\n                                      ...\nsrc/header/common/authorization.rs:46:1: 54:2 error: the trait `core::marker::Reflect` is not implemented for the type `S` [E0277]\nsrc/header/common/authorization.rs:46 impl<S: Scheme + 'static> HeaderFormat for Authorization<S> where <S as FromStr>::Err: 'static {\nsrc/header/common/authorization.rs:47     fn fmt_header(&self, fmt: &mut fmt::Formatter) -> fmt::Result {\nsrc/header/common/authorization.rs:48         match Scheme::scheme(None::<S>) {\nsrc/header/common/authorization.rs:49             Some(scheme) => try!(write!(fmt, \"{} \", scheme)),\nsrc/header/common/authorization.rs:50             None => ()\nsrc/header/common/authorization.rs:51         };\n                                      \u2026\n. I can\u2019t repro on 0.3.7, so whatever the problem was it\u2019s solved now.\n. ",
    "xuefengwang": "Upgrade to 0.3.6 fixed it for me.\n. ",
    "GGist": "@seanmonstar That could work, of course you would be allowing anyone to also call set_uri() with other variants of RequestUri which is easier, albeit more error prone, than modifying the Url directly. I am also not sure about spanning the construction process (as far as this request is concerned) across two different methods.\nI am not too versed on the Http standard, but it looks like the asterisk represents a request that applies server wide instead of pointing to one specific resource. As such, we could probably represent it with a simple flag within the Request object that we check before converting the request to text. In an attempt to reuse the Url structure for location information (and nothing more, ex: path) I think a step in the right direction would be:\nlet req = Request::server_wide(Method::Extension(\"M-SEARCH\".to_string()), \"http://239.255.255.250:1900\");\nNow ideally we would throw an error if the user entered in any path to the Url so that they arent confused when what they think is being sent, isn't actually sent. This is assuming we actually want to reuse the Url object in this scenario and throw that error if it occurs. \nHowever, we could make it so that we are explicit to the user that we are interested in a location and nothing more by doing:\n```\nimpl Request {\nfn server_wide(method: Method, addr: T) -> Request where T: ToSocketAddrs;\n}\nlet req = Request::server_wide(Method::Extension(\"M-SEARCH\".to_string()), \"239.255.255.250:1900\");\n```\nwhich would help the user understand that we are using just the location. I believe ToSocketAddrs accepts host names that can be resolved through DNS (not sure if it accepts protocol info like http).\nThe only problem here is if the user tries going into the Url object that is still being exposed by the request and manually adds some path elements thinking they will be used when they wont.\n@reem Unfortunately I am not too versed on modifiers to comment on them, but hey, whatever provides a good interface works for me.\n. On second thought, I just realized that my proposed solution may not work because we would have to have another, duplicate method, to support the Request::with_connector() for server wide requests.\nI will keep thinking this over, in the meantime, if we want to proceed with the solution proposed by @seanmonstar or anyone else, then that sounds fine to me.\n. ",
    "jonalmeida": "I'm curious to know how others are building hyper or if I've done something wrong in my build process.\n. ",
    "adimarco": "@jimmycuadra Did you ever figure this out?  And/or was this related to integration testing with Rusoto?  I'm seeing the same behavior there.\n. ",
    "afck": "Ah, sorry! I changed it.\n. ",
    "paulosuzart": "@markuskobler will you try again? Just hit the same error. \n. @markuskobler your fix are pertinent and useful. I tried to fix myself and ended up fixing exactly the way you did. Before submit my PR I found yours. So if you just fix your commit messages they might be accepted.\n. ",
    "markuskobler": "@paulosuzart Are you hitting the error below, because apparently its working by design.\nnative library openssl is being linked to by more than one package, and can only be linked to by one package\nTheir might be a better way but I got round it by using a submodule to checkout rust-openssl and then had a .cargo/config like this.\npaths = [\n      \"vendor/hyper\",\n      \"vendor/openssl\"\n]\n. @paulosuzart Sorry now I understand. So I thought my rebase https://github.com/markuskobler/hyper/commit/660a362b68ef5671a951f2c4d66093621d0e3fd3 fixed the gitcop warning.\nI think it just needs someone to kick off the travis build again now that it looks like cookie-rs has been upgraded to the latest rust openssl.\n. Great thank you!. Might be worth looking at #992 . Rather than adding the chrono dependency is it easy enough to use the time crate?. Ok makes sense. For anyone else that stubbles across this you can simply write something like \nlet mut builder = env_logger::LogBuilder::new();    \n    builder.filter(Some(\"hyper\"), log::LogLevelFilter::Warn);\n    builder.init(). Happy to change that as well but that would be the first use of HttpResult net.rs\n. So had you envisaged adding  adding a new HttpSslError(SslError) to the HttpError enum?\n. I think you also need to change the NetworkConnector::connect and NetworkListener::accept signatures?\n. ",
    "brandonson": "That should do it.\n. ",
    "e-oz": "I'm not sure if it's a hyper's issue, but maybe somebody will be kind enough to show code how to catch that Poisoning Error? Would be awesome to kill just one thread and let others work. Or terminate, at least, to let monitoring know server needs to be restarted.\n. I'm sure issue is fixed and I just don't understand something. My experience with Rust is very small - about month.\nCurrently my issue is: when some thread panic, all other threads (in Iron) became useless - I can't lock Arc> anymore. I can catch it but I can't do anything useful except send 503 response to user. Good solution would automatically \"restart\" thread - kill poisoned thread, instantiate new mutex for resource object. Or, if it's not possible - just ask main thread to die, to let monitoring daemon restart server.\n. > I'm curious, since I believe that the majority of people who need openssl are using the client. Is this correct?\nYes, it's correct, but it's very desired change - without it it's impossible to use openssl 0.9.0 and it, therefore, makes impossible to use ssh2 0.3.14 and other things.\n\nIf people are in need of this for a Client, I have a higher level crate \n\nFor us it will mean rewrite all code, related to hyper::client, for contributors of this crate it would mean just fix few lines to achieve compatibility with openssl 0.9.0. At least I hope so :)\nAs I can see, master and tokio are far from stable, so it's not a replacement.\n. I agree that this approach is more flexible. Thank you, will try reqwest.\n. Sorry, @seanmonstar , but reqwest is some experimental code with 0.0.0 version and it has hyper 0.9 in dependencies so there is no point to replace.\n. @seanmonstar \nworks fine, thank you very much! Just few lines were changed, now all tests are green.\nTo use openssl 0.9 I still need to vendor hyper, because hyper have dependency on older openssl and even if I write default-features=false, features=[], Cargo adds it to Cargo.lock anyway.\nBut at least it compiles :)\n. That's exactly what happens and that's why I need to vendor hyper. \"cargo\nclean\" was the most often used line these days, but now everything is fine.\nThank you for help.\nOn Fri, 11 Nov 2016 at 03:08, Sean McArthur notifications@github.com\nwrote:\n\nClosed #949 https://github.com/hyperium/hyper/issues/949.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/949#event-855310431, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAgIEE1uPo8flw6Usa0f8WoIrNkTKasSks5q87H5gaJpZM4Kqf0O\n.\n. @Philipp91 if you don't use tls connections in your app, you can try to declare dependency as \nhyper = { version = \"0.9\", default-features=false, features=[] }\nIf it will not help, try to fork repo and in your version of Hyper remove dependency of openssl (as I did here: https://github.com/e-oz/hyper/blob/0.9.13/Cargo.toml - don't rely on my repository, it can be removed).\n\nIf you do use tls connections, you can use reqwest crate for them and again remove openssl dependency from Hyper (see above).. I confirm this issue. Without using openssl. Appeared after upgrading from 0.9.10 to 0.9.11, still exist in 0.9.12, even when hyper is without openssl.\n. More about my environment: nginx is behind, most of queries to the server are simple http, not https.\n. Downgrade to 0.9.10 didn't help.\n. Error message in nginx log:\n[error] 23607#0: *9 connect() failed (111: Connection refused) while connecting to upstream, client: 8.my.9.ip, server: server.domain.com, request: \"GET / HTTP/1.1\", upstream: \"http://127.0.0.1:3000/\", host: \"server.domain.com\"\n0 errors from the server itself.\nConnection is refused immediately, without any waiting.\n. I can say it's not based on amount of requests. With 0.9.10 reboot doesn't help, with 0.9.12 reboot helps (although it's not a solution, so I'm on 0.9.9 right now).\n. Switching to 0.9.9 helped - no failures 5 hours already. Will try keep_alive on weekend.\n. Nice, now 0.9.9 just failed and don't want to work after restart... Our main site is just offline and I can't do nothing.\n. Looks like Iron doesn't give access to underlying Hyper Server, so keep-alive is not an option.\n. @seanmonstar at least it started this time, thanks. Will report how long it will work.\n. @seanmonstar looks like for me switching keep-alive off solved the issue.\n@mikedilger I use nginx as a proxy too.\n. And after 8 days it failed again, in night time, without any requests.. My sincerest apology - I found reason of failures, it was segfault in another library. I'm sorry for false assumptions without any proofs, excuse me please.. @hannobraun you can't use openssl crate of the latest version with hyper.. @hannobraun latest version of openssl is still not perfect, I'm experiencing segfaults with it. I'm not trying to stop you, though :). rust-openssl-verify has been declared deprecated just now. It's the reason to update dependencies :)\n. I spent around 13 hours on it (vendoring everything I can, trying to hack Cargo.lock) and in result reverted to previous version.\n. I've tried master and it has incompatibilities.\n. How it's happened in my case: after some update (maybe OpenSSL update on the ec2 instance, maybe new build of my project), openssl 0.7.14 started crashing on attempts to create ssl connection.\nAfter that I tried a lot of combinations to create Cargo.lock with only one version of openssl, but Hyper isn't compatible with openssl 0.9.\nTo make things even better, ssh2 published new version with minor (last number) change, and despite I had strict \"0.2.13\" in Cargo.toml, Cargo decided it's not critical update and it would be nice to have new shiny version. With dependency on openssl 0.9 :) So now each time I increase version of app in Cargo.toml, cargo build fails, then I manually change version of ssh2 to 0.2.13 in Cargo.lock and only after that cargo build works.\nSo there is a choice: or you stick with current version of Hyper, openssl 0.7 and old versions of other libraries, dependent on openssl, or you upgrade other libraries but... Hyper will not be able to send HTTPS. \n. Thanks to @seanmonstar there is a way now: https://github.com/hyperium/hyper/issues/949#issuecomment-259576662\nAnd I think it's the better way.\n. Sorry, 2 tabs were near.. ",
    "boghison": "+1, been waiting for this ever since HTTP2 came out :)\n. Oh OK, thanks!\n. ",
    "coveralls": "\nCoverage decreased (-2.11%) to 87.44% when pulling 984f39e7a530c16a0950117e0d0c5266aefd3d6a on mlalic:http2-initial into 1e5d7d403b6fc756bc81c92429b98b881951e2e7 on hyperium:master.\n. \nCoverage decreased (-1.54%) to 88.78% when pulling 65049360239fd16908644b520175ec15cd7aa19a on mlalic:http2-initial into 0cd7e9d91f08fad0d62601dd66b3f9feea5f12b4 on hyperium:master.\n. \nCoverage remained the same at 84.3% when pulling 76ee86a441c2c9a61c36376ab48316616ed56719 on pyfisch:patch-1 into 37dbf5ab4402ba79dbedd659a23d11337b4ed91c on hyperium:master.\n. \nCoverage increased (+0.88%) to 85.18% when pulling 0091556a24ecfec25f15857bb4eccb69e838c44e on pyfisch:increasecov into 7f5e0382d958da2f0bf4636cdab9a6e9827cd8bb on hyperium:master.\n. \nCoverage increased (+0.88%) to 85.18% when pulling 0091556a24ecfec25f15857bb4eccb69e838c44e on pyfisch:increasecov into 7f5e0382d958da2f0bf4636cdab9a6e9827cd8bb on hyperium:master.\n. \nCoverage increased (+0.97%) to 85.27% when pulling d014dff4289fce930db01604d73144f6fd5051e2 on pyfisch:increasecov into 7f5e0382d958da2f0bf4636cdab9a6e9827cd8bb on hyperium:master.\n. \nCoverage increased (+0.96%) to 85.26% when pulling ff346f147f010d55aa7198ccf2f59f299ee3a983 on pyfisch:increasecov into 7f5e0382d958da2f0bf4636cdab9a6e9827cd8bb on hyperium:master.\n. \nCoverage increased (+1.15%) to 85.45% when pulling 5176922a7d4fd59c69bcf9426695935aecc6aa7e on drop-res into 7f5e0382d958da2f0bf4636cdab9a6e9827cd8bb on master.\n. \nCoverage remained the same at 85.45% when pulling d5558b687d32d0affb9aaa7185227a4e294f5454 on res-send into d294ea501d76ca5372460575e5b47556a0f0de01 on master.\n. \nCoverage remained the same at 85.45% when pulling 9cda05497049c829866fe582846c5221670e7ca6 on Byron:master into 38f40c7f6a17bd33951bbab1adddf542cbb96de6 on hyperium:master.\n. \nCoverage remained the same at 85.45% when pulling 5f40dab8e0c12d1da1798760dad62ff9c79eb096 on demut-connector into 38f40c7f6a17bd33951bbab1adddf542cbb96de6 on master.\n. \nCoverage remained the same at 85.45% when pulling 5f40dab8e0c12d1da1798760dad62ff9c79eb096 on demut-connector into 38f40c7f6a17bd33951bbab1adddf542cbb96de6 on master.\n. \nCoverage increased (+0.02%) to 85.47% when pulling 4988060a54ffbbefb3c21a102ca6dc33d887e231 on mlalic:fix-client-ssl-verifier into 38f40c7f6a17bd33951bbab1adddf542cbb96de6 on hyperium:master.\n. \nCoverage increased (+0.02%) to 85.47% when pulling f4556d554faa2a1170fec0af5b4076c31e7c3600 on mlalic:fix-client-ssl-verifier into 38f40c7f6a17bd33951bbab1adddf542cbb96de6 on hyperium:master.\n. \nCoverage increased (+0.03%) to 85.47% when pulling 3334fca278e662b2755e41045ce641238514bea9 on conn-close into a3637d5f73be47ab5e90fb1581103332612fe8cf on master.\n. \nCoverage increased (+0.03%) to 85.47% when pulling 3334fca278e662b2755e41045ce641238514bea9 on conn-close into a3637d5f73be47ab5e90fb1581103332612fe8cf on master.\n. \nCoverage remained the same at 85.5% when pulling e0ccdc0c653484fc2596d8b13db112af78d4991b on header-convenient-constructors into 085d7b0752d7fc0134e99e9eec2a67cc66b319b3 on master.\n. \nCoverage remained the same at 85.5% when pulling b6114ecd2e65bd59e79a67a45913adaf0f1552f0 on header-convenient-constructors into 085d7b0752d7fc0134e99e9eec2a67cc66b319b3 on master.\n. \nCoverage remained the same at 85.5% when pulling 62d96adc6b852b3836b47fc2e154bbdbab9ad7f6 on header-tm! into 085d7b0752d7fc0134e99e9eec2a67cc66b319b3 on master.\n. \nCoverage remained the same at 85.5% when pulling af2daac33b2aa79fe2c89df68ace90cd38953c04 on deps into 085d7b0752d7fc0134e99e9eec2a67cc66b319b3 on master.\n. \nCoverage decreased (-0.08%) to 85.42% when pulling 49b5b8fdfe256ead8f3aa3d489bc4b299c190a9a on server-keep-alive into 871f37a5605d433e5699ed2f16631001d86d7805 on master.\n. \nCoverage remained the same at 85.42% when pulling 7d508d684f529d2f4d3f96fcc45fbd14722413e2 on clippy into 5e91ba19e4abc910def567e2c75921688355d671 on master.\n. \nCoverage remained the same at 85.42% when pulling 38d44fc6b36d93661127c160e7109f04b1d65750 on apetrelli:master into 7179651d816a9408f6b4d798889436ca63831491 on hyperium:master.\n. \nCoverage remained the same at 85.42% when pulling b4f8ec489f6ecdba68e189ffc8bfdf95d78745dc on winding-lines:master into e9dcf45df3128c4e81fc6854a064864914a6dd8d on hyperium:master.\n. \nCoverage remained the same at 85.42% when pulling be041d915a55fa1b5088e112b81727b864949976 on winding-lines:master into e9dcf45df3128c4e81fc6854a064864914a6dd8d on hyperium:master.\n. \nCoverage increased (+0.03%) to 85.45% when pulling 3acc8523480567f9ca890a5492740eaa331445f6 on pyfisch:errors into c8086db2665b5750a9606284d3b4f31db4a18600 on hyperium:master.\n. \nCoverage increased (+0.03%) to 85.64% when pulling 5d669399b6ca5ec7d0f01b9d30513cd1cc4cc47b on pyfisch:errors into ca6cf2b2941e7223b23a22eedef1f748107ea689 on hyperium:master.\n. \nCoverage increased (+0.03%) to 85.64% when pulling 5d669399b6ca5ec7d0f01b9d30513cd1cc4cc47b on pyfisch:errors into ca6cf2b2941e7223b23a22eedef1f748107ea689 on hyperium:master.\n. \nCoverage increased (+0.03%) to 85.64% when pulling 5d669399b6ca5ec7d0f01b9d30513cd1cc4cc47b on pyfisch:errors into ca6cf2b2941e7223b23a22eedef1f748107ea689 on hyperium:master.\n. \nCoverage remained the same at 85.42% when pulling 2c99d4e9068b30ecb6d4eac4d364924fb253fdcd on form-url-encoded into 9912e385e152780cf5ab671e3b07d1ac62ddd892 on master.\n. \nCoverage increased (+0.19%) to 85.6% when pulling d7167e88c347d1496796e302a4a8b226cf1be99d on error-cov into c8086db2665b5750a9606284d3b4f31db4a18600 on master.\n. \nCoverage remained the same at 85.64% when pulling fcda4039b47d16916272721a1cdf3cb650f28724 on nstoddard:master into 5747792cf46b9ff7a0d58a51a0827885c5765345 on hyperium:master.\n. \nCoverage increased (+0.46%) to 86.09% when pulling f705bb63e51ee1428b804b9f5b40b24b7424ea1a on winding-lines:more-tests into 5747792cf46b9ff7a0d58a51a0827885c5765345 on hyperium:master.\n. \nCoverage increased (+1.17%) to 86.8% when pulling 7a3875117effc1a661b216b64cf2511f86453501 on winding-lines:more-tests into 5747792cf46b9ff7a0d58a51a0827885c5765345 on hyperium:master.\n. \nCoverage increased (+2.57%) to 88.21% when pulling 284ee088e768cc6b0d2e43598066da8d5370e8a7 on winding-lines:more-tests into 5747792cf46b9ff7a0d58a51a0827885c5765345 on hyperium:master.\n. \nChanges Unknown when pulling 4ba3033a49119a6744c932cabf7c104db938f81b on winding-lines:more-tests into * on hyperium:master*.\n. \nCoverage increased (+2.71%) to 88.07% when pulling 795ee9f5e0fd754415217a56867aa3d47d2a294b on winding-lines:more-tests into 69aa25fd0c043949b9d103f571179365aeec50f5 on hyperium:master.\n. \nCoverage decreased (-0.28%) to 85.36% when pulling a5e6174efd57afb1df7113c64f4e7718a3a94187 on issue-543 into 5747792cf46b9ff7a0d58a51a0827885c5765345 on master.\n. \nCoverage increased (+0.14%) to 88.21% when pulling 2ce7ebc888bae97bb509c84069a312b50cbe39cf on winding-lines:result-cov into 221f2c9b3c232f40a8a1575f2f952530897e1840 on hyperium:master.\n. \nCoverage increased (+0.96%) to 89.02% when pulling 06c594063059689c5990e30c1311152701f8cb37 on winding-lines:result-cov into 221f2c9b3c232f40a8a1575f2f952530897e1840 on hyperium:master.\n. \nCoverage increased (+1.11%) to 89.18% when pulling 43e274cfce9442191e6cc04e569c785b2aeccbf9 on winding-lines:result-cov into 221f2c9b3c232f40a8a1575f2f952530897e1840 on hyperium:master.\n. \nCoverage increased (+0.23%) to 88.3% when pulling 0717389bc2600ec18fc7f2685db7574c1cda2623 on winding-lines:connection-cov into 221f2c9b3c232f40a8a1575f2f952530897e1840 on hyperium:master.\n. \nCoverage increased (+1.4%) to 89.47% when pulling 8852b4dce0770debf353101c3b029224017a93f4 on winding-lines:connection-cov into 221f2c9b3c232f40a8a1575f2f952530897e1840 on hyperium:master.\n. \nCoverage increased (+0.29%) to 89.47% when pulling c1a8e3bd0204ed9dde5ef1f84f69b6731de9cf5b on winding-lines:connection-cov into 9dc85279ac07302400ec42ceb7d9ff405c5d4f91 on hyperium:master.\n. \nCoverage increased (+0.08%) to 89.27% when pulling 59d8e80e6c61bfbfb4c1289d8315acb0fdf9ff4e on winding-lines:coverage into 9dc85279ac07302400ec42ceb7d9ff405c5d4f91 on hyperium:master.\n. \nCoverage increased (+0.09%) to 89.27% when pulling b24e1a5e6c479aedf719bd491366079331ccaec2 on winding-lines:coverage into 9dc85279ac07302400ec42ceb7d9ff405c5d4f91 on hyperium:master.\n. \nCoverage remained the same at 89.18% when pulling b1686d1b22aa95a17088f99054d577bbb2aef9dc on infinityb:fix-buffer-underflow into 9dc85279ac07302400ec42ceb7d9ff405c5d4f91 on hyperium:master.\n. \nCoverage remained the same at 89.56% when pulling 020db5769dd5c2a791bcbe28d8f3c02a660965c0 on clatour:expose-range-unit into 1e5d7d403b6fc756bc81c92429b98b881951e2e7 on hyperium:master.\n. \nCoverage increased (+0.69%) to 90.25% when pulling f7154c0fec0bdce2bb1e95f130e2ea65d7b1559e on winding-lines:coverage into 1e5d7d403b6fc756bc81c92429b98b881951e2e7 on hyperium:master.\n. \nCoverage increased (+0.76%) to 90.32% when pulling abbc4d6f7e46fa77f7a7007895c4f0947049d393 on winding-lines:coverage into 1e5d7d403b6fc756bc81c92429b98b881951e2e7 on hyperium:master.\n. \nCoverage decreased (-0.03%) to 88.75% when pulling 7c0421e3fc1d5a8b4868b57acca87abd685f3430 on nonexhaustive-error into 486a219bc88c5cc532a7d7a23d89f9999721f1bf on master.\n. \nCoverage remained the same at 88.78% when pulling 81e4965f69e24c44939dbf4f2698d5143b54e03b on ssokolow:patch-1 into 486a219bc88c5cc532a7d7a23d89f9999721f1bf on hyperium:master.\n. \nCoverage remained the same at 88.78% when pulling 19d2530c3c411ee930ecd08dff7a19eaa95aa5ff on ssokolow:patch-1 into 486a219bc88c5cc532a7d7a23d89f9999721f1bf on hyperium:master.\n. \nCoverage remained the same at 88.78% when pulling 19d2530c3c411ee930ecd08dff7a19eaa95aa5ff on ssokolow:patch-1 into 486a219bc88c5cc532a7d7a23d89f9999721f1bf on hyperium:master.\n. \nCoverage decreased (-0.0%) to 88.75% when pulling 71ac65da5beb1c7dd7238f6be14d9262580ac5ed on http-versions into e2611b44174fbb30f03dda06ae735ccb28757437 on master.\n. \nCoverage increased (+0.03%) to 90.608% when pulling 9d3957678c5487b06eb73df955cfaef5d2f5bbc6 on Stebalien:repeated-header into 028f5864324f95d4d9007c304358b6e7b91743fc on hyperium:master.\n. \nCoverage increased (+0.04%) to 90.62% when pulling 70c6914217a9b48880e61b7fb59acd15c6e1421e on Stebalien:repeated-header into 028f5864324f95d4d9007c304358b6e7b91743fc on hyperium:master.\n. \nCoverage decreased (-0.09%) to 90.487% when pulling 5fbc252a32dfdf759cadc1abf2889332a69c6863 on calebmer:feat/prefer into 028f5864324f95d4d9007c304358b6e7b91743fc on hyperium:master.\n. \nCoverage decreased (-0.1%) to 90.521% when pulling 6f6493010a9c190b29aceb3c10c65785923a85f5 on calebmer:feat/prefer into c85b056cabd1bbe62340af03696810c7e155fe17 on hyperium:master.\n. \nCoverage increased (+0.005%) to 90.625% when pulling 905e0d2ff4ea4714fc41fd852a3c721f844cd3a4 on per-tag-docs into 2cb83b4271fc2f815dd4e0e451237d9d0892b746 on master.\n. \nCoverage remained the same at 90.521% when pulling 2c86e8078ec01db2283e1fee1461db4c7bf76d3f on sfackler:ssl-split into bc3878de36544aa6e99fb117cb0d11a47a582934 on hyperium:master.\n. \nCoverage remained the same at 91.713% when pulling 4bdc5c61233e3fa08f6920f35e23233cdc967df8 on jwilm:mio-handle-client-request-error into d55a70dc56dac1f0f03bc4c3a83db0314d48e69a on hyperium:mio.\n. ",
    "secretfader": "@seanmonstar Awesome. Thanks for the link to documentation. Do you have opinions or links on how to handle binary data transfer?\n. You answered the question. So long as I have access to the raw stream of bytes, I'm good to go. Thanks!\n. A month later, and I'm still trying to wrap my head around Hyper. I'm implementing an HTTP server that needs to respond to SOURCE requests, for Icecast emulation. Do you have an example of how I might reason about this?\n. ",
    "whispermemory": "13.3.0 Darwin Kernel Version 13.3.0: Tue Jun  3 21:27:35 PDT 2014; root:xnu-2422.110.17~1/RELEASE_X86_64 x86_64\n. ",
    "jamperry": "Looking at the code it looks like the cfg predicate:\n``` rust\n[cfg(not(feature = \"nightly\"))]\n```\nis not working correctly as I'm using nightly:\nshell\nJamess-MacBook-Air:hyper james$ rustc --version\nrustc 1.0.0-nightly (16e1fcead 2015-04-15) (built 2015-04-14)\n. Thanks to @reem, this is now resolved. If anyone else encounters this, just edit your Cargo.toml to add  hyper as a depedency with a feature flag like this:\ntoml\n[dependencies]\nhyper = { version = \"*\", features = [\"nightly\"] }\n. ",
    "Hoverbear": "Thanks! That was a confusing error to hit.\n. Proposing this issue can be closed, in such a case.. The tokio branch is now using native_tls.. Hm, should it return Option<Body> or just Body? I'm actually a bit curious why both Some<Body::Empty> and None are options when constructing a request. \nFrom the code it seems like it just treats None as Body::Empty anyways:\nrust\n    #[inline]\n    pub fn body(self) -> Body {\n        self.body.unwrap_or_else(|| {\n            trace!(\"Request::body empty\");\n            Body::empty()\n        })\n    }. Please feel free to submit a PR with such example code! If you need help doing this let me know.. Proposing this issue can be closed.. @sanmai-NL I encourage you to make a PR! :). ",
    "fuchsnj": "@seanmonstar thanks\n. That seems to be correct. I am sending \"{}\" in the POST body\n. Was able to fix this by making sure the request stream was read completely, closing as a duplicate of #309 \n. ",
    "dileepbapat": "yep, my bad. worked with beta2\n. ",
    "tarcieri": "For what it's worth, I just implemented RFC 6125-compliant hostname verification for Ruby's OpenSSL extension (a.k.a. CVE-2015-1855):\nhttps://github.com/ruby/openssl/pull/12/files\nI'd be happy to do a Rust implementation.\n. I just started an RFC6125 hostname verification library for Rust:\nhttps://github.com/tarcieri/pkixnames\n. One thing I'm curious about... what type is used for representing presented identifiers? I think I'd like the internal implementation of this library to be done completely as Vec<u8>s\n. @seanmonstar the subjectAlternativeNames (SANs) or Common Names (CNs) in X.509 certificates\n. It's beginning to seem like rust-openssl is probably where I should be asking about this :wink:\n. @frewsxcv +1 for that\n. Note that running an X.509 PKI that broken only offers the illusion of security.\nRe: TLS 1.2 and Java 1.7, it's supported out-of-the-box by the Sun JSSE provider.\n. @MoSal I buy @AGWA's argument that having a standard notation that's easy to grep for is desirable.\nThat said, while I'm glad you think curl makes it super easy to shut off the security, I'm not sure that's actually a desirable property. I think the world would be a better place if there were no -k option to curl, and people needed to explicitly type --insecure, for example.\n. >  the point is that semver was not followed by hyper.\nPlease look here:\nhttp://semver.org/\n\nMajor version zero (0.y.z) is for initial development. Anything may change at any time. The public API should not be considered stable.\n\nHyper is following semantic versioning just fine. Your expectations aren't, however.\n. @maximih by default hyper's previous configuration was insecure. That's bad, but it's still in 0.x versions, and now they have shipped a fix so it's now secure-by-default.\nSemVer says you should reasonably expect changes at any time, because hyper is still in an initial development stage.\nI'm sorry that a change in a 0.x minor version broke your insecure configuration because hyper added security, but at the same time you cited SemVer, and SemVer says they're allowed to do that.\n. @aidanhs this was a CVE-worthy security bugfix. Previously Hyper was trivially vulnerable to a MitM attack.\nRegardless of version numbers, if fixing CVE-worthy security issues involves breaking changes, IMO those changes should be made. If programs were relying on the old behavior, they are broken and should be fixed.\nThis is par for the course with security fixes: if new attacks are found, often breaking changes have to be made to fix them. The Internet community has recently \"retired\" several old, broken algorithms and protocols like RC4, DHE (at least for HTTPS), and SSLv3. Making those changes involved breakages.\nWe shouldn't continue to support insecure systems for backwards compatibility's sake. Supporting broken crypto for backwards compatibility's sake makes everyone else less secure.\n. ",
    "frewsxcv": "Worth noting this is also an issue in Servo: https://github.com/servo/servo/issues/4954\n. Since it hasn't been explicitly stated in here, here's a relevant project: https://github.com/briansmith/webpki\n. > What is a good API for disabling TLS verification when the user desires it?\nHopefully, this will not be possible.\n. > kcov can be used without sudo, but travis-cargo doesn't yet do that.\nPosted today: https://huonw.github.io/blog/2015/06/travis-cargo-0.1.3/\n. Thanks!\n. Related to https://github.com/hyperium/hyper/issues/472\n. > If so, I think there should be two separate methods depending on whether it's intended for client or server use.\nEver since https://github.com/hyperium/hyper/pull/757, there are now separate traits for server and client TLS use. That said, there still needs to exist a crate that actually verifies the certificates for this to be completed.\nIn my opinion, this issue can be closed as a duplicate of  https://github.com/hyperium/hyper/issues/472.\n. Note to selves: if this ever happens, we should enable OSX on Travis CI.\n. Update: this is now merged in https://github.com/hyperium/hyper/pull/762, but OpenSSL is still the default on OS X. In a future breaking change release, the default should probably switch to security-framework? Then https://github.com/hyperium/hyper/issues/709 could probably be closed (if not already).\nOn a side note, @sfackler started https://github.com/sfackler/rust-native-tls which is Yet Another Layer Of Abstraction that wraps around the system native TLS bindings. So Hyper could potentially use this to offload system TLS logic.\n. > I was wondering, is it possible to conditionally set the default based on\n\nOS? \n\nYou can probably accomplish that with something like this\n. Enabling hostname verification is neither a breaking change nor a new feature; it is a bugfix.\nSpeaking generically, if one's software is relying on a broken feature, any bugfix can be breaking change.\n. I'm now seeing there is a 0.9.x branch that's separate from master. Is there a reason for this separation?\n. Ah, right the mio stuff, makes sense. Thanks!\n. > (I think?)\nYes\n. Next step here is to incorporate native-tls now that it's published, right? Need any help with that?\n. Awesome, thanks for your work on this @seanmonstar! :1st_place_medal: . It seems like for most people, they'll want to migrate their crates to use reqwest instead of Hyper's HTTP client. Maybe this should be mentioned in the CHANGELOG and possibly temporarily the README.. Looks like it's published now https://crates.io/crates/hyper-tls. I'm not particularly fond of the wording here, just sharing the idea. Maybe it should be bold, maybe it should mention 'built-in TLS support', not sure. It's not clear to me why that's unfair, but no worries. Here's (seemingly) relevant code in reqwest: https://github.com/seanmonstar/reqwest/blob/855e6615eb553feab5d382c2017ad76e82560768/src/async_impl/response.rs#L109-L122\nThe difficult part here seems to be coming up with a minimal example for this. Not sure if this answers your question, but the 'examples' directory is a special directory that cargo recognizes for storing examples. To run an example, from the root of the repo, run:\ncargo run --example hello. Will this break constructing HttpsListener for users who don't have the SslServer imported?\n. Yeah, that sounds right on second thought\n. No idea, don't have enough time to look into it so I ditched that change. ",
    "zmanian": "What is a good API for disabling TLS verification when the user desires it?\nEnvironment variable? Argument to the connection object?\n. ",
    "MoSal": "@zmanian @frewsxcv \nThere are use-cases where skipping TLS verification is necessary.\nIn libcurl, the options CURLOPT_SSL_VERIFYPEER and CURLOPT_SSL_VERIFYHOST are available and you can set them to 0.\nThe curl tool has the option -k,--insecure which relies on the library options mentioned above.\n. > Just noticed this, it seems like in this case it may be a waste to use TLS at all.\nNot necessarily. There are other local use cases that benefit from skipping verification. For example: \n- Testing server performance with and without TLS.\n- (Easily) isolating potential server TLS issues.\nUsing curl/libcurl for those use-cases is trivial and just works.\n. @sfackler \nLet me quote my comment from #472 \n\nThere are use-cases where skipping TLS verification is necessary.\nIn libcurl, the options CURLOPT_SSL_VERIFYPEER and CURLOPT_SSL_VERIFYHOST are > available and you can set them to 0.\nThe curl tool has the option -k,--insecure which relies on the library options mentioned above.\n. \n",
    "AGWA": "Although it should go without saying that disabling certificate verification is a terrible thing to do, there will be developers who will want to disable it and will find a way to do so whether or not Hyper provides an API for it.  Rather than leaving developers to their own devices, I think Hyper should provide an API to disable verification for two reasons:\n1. It will be easier to spot in code audits.  Searching for the API call that disables verification is easier than spotting and analyzing a custom SslClient implementation.  It would even be possible to search GitHub and file bug reports against projects that are disabling verification.\n2. Developers are likely to search the Web for the invalid certificate error message and find a blog post or Stack Overflow answer that contains an example SslClient to disable verification.  This example might come without a sufficient disclaimer that it's doing something very bad.  In contrast, if there's an \"official\" way to disable verification, it can come with a big warning and be named in such a way that may cause at least some developers to think twice before using it.  For example, in Go's TLS library, the property to disable verification is named InsecureSkipVerify.\n. ",
    "daniellandau": "My bad, I didn't have the latest nightly after all.\n. ",
    "ucarion": "data is what would have been written to a NetworkConnector -- in hyper's mock.rs, it corresponds to the contents of this variable:\nhttps://github.com/hyperium/hyper/blob/master/src/mock.rs#L9\nI have this already, and what I want to get is the response of the remote HTTP server.\nSorry for the imprecise wording; I don't really know what things are called here.\n. You're absolutely right. Here's the function I'm trying to write, as well as an example of how I'd like to call it. It doesn't work right now.\n``` rust\nuse std::io::{self, Read, Write};\nuse hyper::net::{HttpConnector, NetworkConnector, HttpStream};\nfn fetch_http(host: &str, port: u16, scheme: &str, data: &[u8]) -> io::Result> {\n    let mut connector = HttpConnector(None);\n    let mut stream = connector.connect(host, port, scheme).unwrap();\nstream.write(data).unwrap();\n\nlet mut buf = Vec::new();\nstream.read_to_end(&mut buf).unwrap();\nOk(buf)\n\n}\nfn main() {\n    let msg = b\"GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\";\n// I would like this to output the response from the server, including HTTP headers and whatnot.\nprintln!(\"{:?}\", fetch_http(\"example.com\", 80, \"http\", msg));\n\n}\n``\n. I tried using TcpStream, but the problem is that I don't know in advance how long the server's response is. Reading fromResponse::new(stream)(wherestreamis the result ofHttpConnector(None).connect`) almost works, but it doesn't give me back the headers.\nPerhaps I'm approaching my goal in the wrong way: do you know of a way to implement an HTTP recorder/replayer (\u00e0 la vcr) with hyper? I tried making a MockConnector so that in my tests I could simply write Client::with_connector(MockConnector) in order to replace actual HTTP responses with replayed ones, but as you can see I'm having trouble with this approach.\n(I was trying to make the fetch_http above because the only things NetworkConnector and NetworkStream know about are the URL of the server and the data being sent to the server.)\n. > Reading your proposed fetch_http function, it looks like it should all work. What wasn't, specifically?\nActually, I went back and it turns out I misspoke. fetch_http does return the correct result, but it takes multiple seconds for the call to read_to_end to terminate. I'm guessing some sort of timeout is forcing termination. I'm guessing read_to_end would only work if the server sends EOF, which example.com doesn't do (it sends a content-length instead)?\n. > Though, that will copy the decoded body (in case you need to replay the body encoded in chunks, you'd need to do figure something else out).\nI understand that I wouldn't be able to replay the chunks individually with this approach, but I'd still be able to read the complete response, right? I'd just lose the information about what the individual chunks were?\n. I think I've got something that works now, thanks! For future internet people, this is what I've come up with:\n``` rust\npub fn fetch_http(host: &str, port: u16, scheme: &str, data: &[u8]) -> io::Result> {\n    let mut connector = HttpConnector(None);\n    let mut stream = try!(connector.connect(host, port, scheme));\ntry!(stream.write(data));\n\nlet mut buf = Vec::new();\nlet mut res = Response::new(Box::new(stream)).unwrap();\ntry!(write!(&mut buf, \"{} {}\\r\\n\", res.version, res.status));\ntry!(write!(&mut buf, \"{}\\r\\n\", res.headers));\ntry!(io::copy(&mut res, &mut buf));\n\nOk(buf)\n\n}\n```\n. ",
    "Ms2ger": "https://xhr.spec.whatwg.org/#the-statustext-attribute\n. CC @Velmont; I assume he's written tests that would fail with parsed URLs, if there's a difference.\n. Regardless of whether it's allowed, what should browsers do if they encounter it anyway?\n. This might be useful for Servo; otoh, we'll probably channel all calls into hyper through a single point anyway.\n. Note that the \"Closes #NNNN\" syntax only works in commit messages and PR summaries, not comments.. ",
    "norcalli": "This seems like it could be solved with the crossbeam crate.\n. ",
    "gyscos": "Though, as reem said, it'll still likely need a new server API.\n. I see. That's actually the way golang implement it, by spawning a thread (well, a goroutine) to try to read from the body, and notify when the call completes.\nI guess channels in rust are not as widespread as in golang, making an idiomatic API for this trickier (though perhaps using std::sync::CondVar?...), and it'd also probably add the need for an Arc in there... :-/ \n. Also, I tried this simple program:\n``` rust\nextern crate hyper;\nuse std::io::Read;\nuse hyper::Server;\nuse hyper::server::Request;\nuse hyper::server::Response;\nfn main() {\n    Server::http(\"127.0.0.1:3000\").unwrap().handle(|mut req: Request, _: Response| {\n        let mut b = [0];\n        // Attempt to block until the client disconnects\n        println!(\"{}\", req.read(&mut b).unwrap_or(42));\n        println!(\"{:?}\", b);\n    });\n}\n```\nAnd them I simply run curl http://localhost:3000\nUnfortunately, the read comand returns immediately here (it returns 0 and writes nothing to b), and does not wait for the client to cancel the connection.\nTrying to write is not always an option, it would be really nice to have this working (and golang also uses a read attempt, so it should be possible?). Maybe hyper does something on the connection?\nEdit: indeed, a Request.body is a SizedReader or an EmptyReader: request.rs. And those don't forward the request to the underlying connection most of the time: h1.rs.\n. Yes, so in the current condition it doesn't look possible to detect cancellation of a simple GET request?\nThe fact that it works in golang makes me believe it would work if reading on the underlying socket, but hyper does not expose that.\n. Exactly, the blocking read in another thread is what golang's standard library does to detect client disconnection. It also uses blocking IO, just like here.\nAsync IO is another solution to this problem, but I'm not sure it's ready just yet.\n. Golang implements it by actually copying from the original socket to the one visible by the user (they use a io.Pipe for that) - it also means they keep reading until EOF is found. That way, the user still has access to the data in the body , and the library can detect when the socket is closed.\nIt should be doable using downcast_ref indeed, thanks. Now onto exposing this from iron...\n. ",
    "dschneider": "@seanmonstar I have set up an Ubuntu virtual machine to verify. It works indeed. So it's most likely a configuration issue on our AMI. Thank you for looking into this!\n. ",
    "jakejscott": "I don't mind having a go at getting this setup if nobody else has already volunteered :)\n. Looks like a few other projects are doing this:\nhttps://github.com/rust-lang/log/blob/master/appveyor.yml\nhttps://github.com/tomaka/glutin/blob/master/appveyor.yml\nhttps://github.com/tomaka/cpal/blob/master/appveyor.yml#L4\n. It would be nice if OpenSSL also used appveyor https://github.com/sfackler/rust-openssl/issues/212\n. ",
    "oldtree2008": "but cargo build is ok\nD:\\hyper>cargo clean\nD:\\hyper>cargo build\n   Compiling typeable v0.1.1\n   Compiling bitflags v0.1.1\n   Compiling httparse v0.1.1\n   Compiling gcc v0.3.5\n   Compiling unicase v0.1.0\n   Compiling pkg-config v0.3.4\n   Compiling traitobject v0.0.1\n   Compiling rustc-serialize v0.3.14\n   Compiling libc v0.1.7\n   Compiling matches v0.1.2\n   Compiling lazy_static v0.1.10\n   Compiling time v0.1.25\n   Compiling openssl-sys v0.6.2\n   Compiling log v0.3.1\n   Compiling num_cpus v0.2.5\n   Compiling mime v0.0.11\n   Compiling openssl v0.6.2\n   Compiling url v0.2.33\n   Compiling cookie v0.1.20\n   Compiling hyper v0.4.0 (file:///D:/hyper)\nD:\\hyper>\n. I found the reason. openssl lib \n. ",
    "kempchee": "I'm going to attempt to make the changes myself using the first proposed solution.  If I get stuck I'll post on this thread.  When I'm ready I'll make a PR\n. Wouldn't that be useful?  For instance, I initialize a websocket connection.  Later on, my client makes an http request and that request wants to be able to send data through the websocket while the new request is still processing.  I'm just not sure if this scenario would require passing NetworkStream+Send to more than one thread(my intuition tells me it would).  In any case I will attempt both\n. ",
    "ssokolow": "Sure. My main concern is that I'm not sure what ordering to use. \nIn my projects, I tend to block things out as \"[CI] [Coverage] [Static Analysis] [Release Metadata] [License]\"\n   \n...but, here, the colours make me want to organize it like this instead...\n   \n. I normally wouldn't organize by colour either, but that crates.io badge really throws off my usual rules.\nNormally, my rationale is:\n1. The left 2/3rds change colour to indicate problems and should be a mass of green.\n2. The right 1/3rd doesn't indicate status and should be a neutral blue.\n3. Source badges to the left of release badges (coverage before crates)\n4. License can be counted as either source or release\nThat way, I can use the row of badges as a simple status dashboard.\nSticking the crates badge so close to the status-indicating badges knocks my brain off the fast-path evaluation because I actually have to read to determine whether the orange indicates a problem rather than scanning my eyes over a row of colours.\nPerhaps this so that it's clear that the \"blue stuff\" section has already started?\n   \nIdeally, there'd be an option to use a crates.io badge in a colour that either means \"all good\" (green) or lies outside the \"green through red\" spectrum that intuitively indicates status. (blue, black, white, grey, etc.)\n(Just a suggestion. If it's not up for discussion, I'll make the PR now.)\n. Whoops. One sec while I force-push a commit fix.\n. There. Sorry about that. My sleep cycle is somewhat disrupted and I forgot to consider how it subtly affects my memory and judgement.\nEDIT: ...and I just realized that my writing instincts overrode the \"don't capitalize first letter\" that I'd just read. One sec.\n. ",
    "odinho": "@Ms2ger: Good to see you assume the best of people :P  There's some I'm quite sure would fail if you throw them through URL normalization.  But there is for sure lots of cases that's not tested as I'm not awesome enough to think of'em.\nHere's the ones that exist: http://w3c-test.org/cors/origin.htm\n(Aside: Blink does everything correct except the \\0's which possibly it strips in the \"strip whitespace\" step.  Maybe I did wrong there as I see Gecko agrees.)\n. ",
    "apetrelli": "Resolves #529 \n. I'm trying to extend HttpConnector to support proxies, so I created an attempt of my version of HttpConnector, named HttpProxyConnector, copying code locally. The offending line is this:\nOk(HttpStream::Http(CloneTcpStream(try!(TcpStream::connect(addr)))))\nNotice that I am a novice in Rust, so please pardon my lack of precision.\n. Probably I missed proxy support in client :-D I did not find it in docs, is it there somewhere? If not then probably I should open an issue in the docs :-D\n. Ok fine for me.\n. ",
    "messense": "It would be awesome to have this feature!\n. I wonder if this can be rewritten as:\nrust\nErr(ref e) if let Some(delay) = self.sleep_on_errors => {\nso you don't need to use .unwrap() later.. ",
    "kikokikok": "Hi All,\nI've just been tracking down the reason why multirust-rs is not able to work behind a proxy, It seems like the Http Client used in multirust is the Hyper one which leads me to this discussion and the associated PR.\nDo you have an ETA on this one ? it seems like it hasn't evolved since October. Any chance to see this merged or is it still not mature enough. \nI see a lot of value in having this functionality built-in Hyper as it serves a lot of tools/libs in the ecosystem and could clearly help to drive Enterprise adoption.\nThanks !\n. ",
    "mitsuhiko": "I'm in the same boat. I really need proxy support. Is there any chance I can help out with this?\n. @seanmonstar unfortunately HttpListener's field is private so you cannot do that from outside the library.\n. As mentioned in the ticket I would love to help drive this PR forward. Proxy support is very important to me.\n. @MichaelZapataScality I fail to see how that ensures no cases are forgotten. Can you clarify what you mean by that?\n. I fail to see how match is helping though. First of all if something is Ext or not is pretty random at the moment.  For instance you ned to use ext for all common vendor mimetypes. Secondly because of ext you can already not handle all. But ultimately you can make up completely bogus mimetypes with the current system anyways (for instance nobody stops you from making an image/json).\nA tuple mime type would still be a separate type.\n. @crawford the type system does not guarnatee that at all. As mentioned the type system allows me to construct image/json which is not a registered mimetype.. I'm trying to use hyper with tokio 0.1 now and it's basically impossible despite the shim in the new tokio-core. With this pull request in tokio-core it's now generally possible to tokio::spawn when a core is running (https://github.com/tokio-rs/tokio-core/pull/314). However since all hyper types are not Send you still cannot use tokio::spawn which requires Send.\nThe only way to spawn without the Send bound is tokio::executor::current_thread which is not shimmed. I'm not sure what the plans are to make hyper work with new tokio, but my guess is that types will have to implement Send. (Also for my API to make any sense I also convert all my errors to Send which now means that I cannot set an hyper error as failure cause without it being Send as well).. ",
    "JeffBelgum": "@seanmonstar I am in need of Proxy-Authorization for a project at work. In a comment above, you suggest that it could be handled outside of hyper. Would you be able to provide some guidance as to how to do this? Would it involve creating a new type implementing NetworkConnector or some other approach?. It's send as part of the CONNECT tunnel request.. Great, thanks for the help! Would you be open to a PR against the 10.x branch that implements proxy authorization in the current Proxy struct?. ",
    "brycefisher": "My vote here is to provide two client examples:\n- The existing, overly-simplistic client.rs (for quickly wrapping your around a simple example)\n- A new example that DOES something more interesting, like:\n  - try to print your GPS coordinates from your IP address (using freegeoip.net etc)\n  - print the an issue number, title, and url from this repo using the github api (would require parsing json)\n  - scrape craigslist for a used guitar\n  - find an interesting piece of trivia from an opengov API\n. I'd like to tackle this one.\nI started looking at the spec, and I realized there is only ever one valid value for this header. For example, this value could never be false.\nGiven that invariant, I would probably want users to set this header without needing to pass in a bool. Ex:\n```\nextern crate hyper;\nuse hyper::header::{Headers, AccessControlAllowCredentials};\nfn main() {\n    let mut headers = Headers::new();\n    headers.set(AccessControlAllowCredentials);\n}\n```\nHowever, we probably would want to parse raw AccessControlAllowCredentials headers values of any case. For example an HTTP client should probably still parse this sort of response:\nHTTP/1.1 200 OK\nAccessControlAllowCredentials:TrUE\n...\n. Can't get tests to pass tonight...trying tomorrow:\nhttps://github.com/brycefisher/hyper/commit/29c33f59586976ac87b8de1c38bcc48e89d4dcc8\n. Gave up on any casing\n. @Ryman oh nice, that's exactly what I was looking for!\n. :sob: I forgot the colon.... sinc Ryman just suggested an improvement over my impl, I'm going to close and fix up this commit with his suggestions once the tests pass.\n. Hooray!! Thanks @seanmonstar and @Ryman \n. ",
    "pyros2097": "Yeah More docs please. I Couldn't  even get google.com it gave me this error.\nthread 'send_request' panicked at 'called `Result::unwrap()` on an `Err` value: Error { repr: Custom(Custom { kind: InvalidData, error: StringError(\"stream did not contain valid UTF-8\") }) }', src/libcore/result.rs:741\n. Well this https://github.com/valyala/fasthttp for go surpassed the go's standard http library almost 10x by using pools and buffers a lot. Maybe this would improve hyper's response times under heavy loads only. Pooling requests, requests, responses, buffers, streams ...etc. ",
    "mfarrugi": "~~The front page readme / examples of this project are still broken, and also requires the Response to be mutable.~~\n. I've got no idea what I thought was broken. Forgive me :)\n. ",
    "AAG81": "I don't know how to add that For example How to replace that with json\n``` rust\nextern crate hyper;\nuse std::io::Read;\nuse hyper::header::ContentType;\nuse hyper::Client;\nfn main() {\n    let mut client = Client::new();\n    let res = client.post(\"http://127.0.0.1\")\n        .header(ContentType::json())\n        .body(\"caller=09121571&callee=502&uid=234567\")\n        .send()\n        .unwrap();\n    assert_eq!(res.status, hyper::Ok);\n}\n```\n. I changed content_type.rs in hyper src compiled it again add new method \nnow I have it and works fine;\nis there a better way without changing the hyper src?\n. Thanks a lot\n. I don't mean TCP acknowledge, I mean don't wait for HTTP response\nin hyper client.\n. ",
    "nstoddard": "Oh, I totally forgot about this PR. Sorry about that!\n. ",
    "gsingh93": "I don't need the client, I really just want a standalone RequestBuilder. It could possibly return a struct that contained the status line and headers as a String and a Vec<u8> for the body.\nI'm currently using hyper to convert the headers into a String in a type safe way (Headers implements Display), and then manually prepending the status line, appending \\r\\n, and appending the body. It would be nice to be able to build the complete request.\nAnd in any case, adding a Debug impl to RequestBuilder could be a general improvement (although not my main motivation).\n. ",
    "zr40": "Instead of -I, try either -i or -X GET -I. With -I, curl will send a HEAD request unless you tell it otherwise with -X.\n. ",
    "lame-nickname": "Ok, so in the new commit, I've included all your suggestions regarding iterators and unnecessary allocations. \nI've also made some decisions regarding the TODOs:\n1). I think it makes sense to allow Range without any ranges (empty vector). In that case it will be transmitted as \"bytes=\"  and it will be up to a server do decide what to do with it.\n2) Now instead of skipping bad ranges during parsing, we'll return an Err, which basically means that the whole Range header is invalid.\n. No worries. I'm glad you've reviewed the commits, as there were several things I've clearly missed reading the HTTP spec. Will do better next time! ;) \n. Ok guys, I've made the requested changes. I wouldn't be surprised if they were unidiomatic, so let me know if that's the case.\nThere are 2 open issues:\n- i.e.  bytes=-1,-1,-1 or bytes=1-,1-. According to the spec, there should be only one range spec of {RangeSpec::AllFrom, RangeSpec::Last} and it should always be at the end of the range set. Currently, it's not enforced and it's up to the application code to check that.\n- i.e. bytes=1-100,abc,200-. Should we just drop the invalid range specs and mark the whole range as valid (as long as there is at least one valid range spec) or mark the range as invalid, if there is at least one invalid range spec? Currently, we do the former.\n. Cool. Do you have an opinion on Other vs Unregistered? Let's also cc @pyfisch, as he's the one who created Accept-Ranges header.\n. I've given it some more thought and I'm no longer sure that Range and RangeUnit names have to be consistent. In case of Range, Unregistered makes little sense, as range as a whole isn't registered nor unregistered. So I'd leave it as it is.\nI know this isn't a very important problem, but I just like to name stuff the way it makes the most sense ;)\n. I'd argue that RangeUnits have to be registered, not Ranges.\nBut I'm ok with Unregistered too, so no more bikeshedding ;)\n. Yeah, I wasn't convinced with simple neither, but that was the best I could come up with at the time. I'll change it to bytes()\n. I'm not sure how I would use the header! macro here. From what I've seen it autogenerates a single field struct and for Range I need to have both unit and list or ranges/rangeSpecs.\n. I'm not sure if that makes sense. The thing is that Range and RangeFrom have their equivalent in the RangeSpec struct, but RangeTo doesn't. So we could implement Into<RangeSpec> for RangeTo and for Range, but that would leave out RangeFrom (and RangeSpec::Last), which IMO isn't very clean. \n. I've made the same assumption when I've started implementing it ;)\n. Done.\n. Yeah, the HTTP/1.0 was a mistake on my side. \nI've used Pragma header as a template and it uses /// for the comments. \nCan you tell me why #doc is preferred? IMO, it's a lot noisier and harder to read.\n. I'm not sure if hyper::Error makes sense here. At least not hyper::Error::Header. The RangeSpec struct isn't really a header, so ::Error::Header doesn't make much sense for parsing failure. Plus I don't see any other ::Error enum value, that would make sense in this context.\n. ",
    "derekdreery": ":D\n. ",
    "stiv-yakovenko": "The problem is still there: hello.rc doesn't compile or work in both sitiuations: hyper =\"0.9.9\" and hyper={...githup url here...}\n. UPS, port was busy. Excuse me please.\n. ",
    "yjv": "Thanks!\n. ",
    "steffengy": "Now also available through https://crates.io/crates/schannel\n. @p-jackson \nBe aware that it very likely won't work that way anymore for any future version.\nrust-native-tls as a wrapper in the future will be nice though.\n. ",
    "luser": "In https://github.com/hyperium/hyper/issues/755, someone linked to https://github.com/sfackler/rust-native-tls, which is a crate wrapping openssl/security-framework/schannel, which might be a good way to go in the future.\n. I get the same error if I checkout the 0.9.x branch from this repo and run cargo build --no-default-features --features=security-framework.\n. Sorry for the zillion commits, took me a while to figure out what gitcop wanted. :)\n. ",
    "p-jackson": "Created a gist that shows how to get schannel working with hyper, just incase someone encounters this thread while looking for that info.\nhttps://gist.github.com/p-jackson/198dd5de05b53d14b533d272f2eaefce\nschannel needs an update before it'll work with hyper 0.9\n. ",
    "nshtg": "Are there any plans to integrate rust-native-tls using a special feature flag? Easy usage of hyper without openssl would be really exciting!\n. ",
    "sinhpham": "What is blocking this issue? I may find some time to work on this, however I'm not familiar with the code base. Can someone give me an overview of what needs to be done and what potential obstacles there are?\n. ",
    "Diggsey": "rustup has been using native-tls as the default on windows for a while now. Are there any outstanding bugs that are blocking this?\n. ",
    "Arnavion": "I think this can be closed now?. I personally am waiting for (TODO: Customizable redirect policy) to be fixed in reqwest before I can switch my crates to it :) . ",
    "DoumanAsh": "Windows 8.1. x64\nWhat sort of logging do you need?\nIt's easy to add prints at each step :)\nAfter a few tries it seems problem appears only when i attempt to execute get().send()\nFrom time to time it happens at different point(not strictly at the one point in the code)\n. I can try that later on and will put log here\nWhich log level is needed? I suppose debug?\n. made quick look:\nhttp://pastebin.com/Ay03qLms\nA lot of directs...\nAnd for some reason the second request loses Host in its headers:\nheaders=Headers { Host: , }\nNormal case:\nhttp://pastebin.com/8rakpbHT\n. @seanmonstar \nActually the normal case is the lucky run with opt-level 3 :)\nI will try with current master and with opt-level 1\n0.5.2 opt-level 1 http://pastebin.com/9KwjwDLU\nMASTER opt-level 1 http://pastebin.com/TLGxh56y\nP.s. it is good that client does not need to be declared as mutable :)\n. Hm... maybe it is powershell's doing...\nI tried two full rebuilds with opt-level 3.\n5/5 no issue at all\nTried two more times... seems like master makes difference\n. Just in case i will try more tomorrow. Just to be sure it is not related to moon phase or random...\n. Re-checked again. Master has no issue.\nSo this problem will be fixed in next update of crate.\nWill keep in mind to check master next time :)\n. It is not actually doc issue, but function signature issue i suppose?\n. JFYI I actually struggled to reproduce the issue on my windows machine(though I didn't check release mode as I doubt there is platform dependent code)\nUPD: it does happen to me only in release mode. Thank you guys, we'll need to set minimum versions on these. ",
    "jamii": "I filed this on solicit too. I'm not sure where the breaking change occurred.\n. ",
    "Aintaer": "As far as I can tell, hyper only has the http2 client wrapper around solicit. There's no server implementation.\nI took a whack at it, but ran into some conceptual difficulties.\nRight now, server::Server only deals with net::HttpListeners, which in turn wraps around TcpListener. This makes the assumption that an HttpListener is a one-to-one correlation with a tcp connection, which is true of http1, but not in the multiplexed world of http2.\nAdditionally, server::Handler has a singular tuple of (Request, Response), but http2 allows for, essentially, multiple Responses.\nWould love to see/hack on a Rust implementation of http2! (Or at least a wrapper around solicit)\n. ",
    "coder543": "alright, thanks!\n. ",
    "samfoo": "@seanmonstar, I would have preferred a simple split, but the spec allows for quoted strings (which could contain ; and, in the future, more than just the two directives. It specifically says that directives not supported by a UA should be ignored, which is why I implemented the way I did. Perhaps that's too much YAGNI? To be honest, a split is probably fine for 100% of cases at present. Thoughts?\nI'm happy to alter the parsing if that's the concern. My rust is a bit ahem neolithic, so it's probably just my lack of understanding idioms. I'll go through and clean up pointlessly allocated Strings\nI used a tuple struct reluctantly, since it seemed to be the way most of the other headers were implemented. I'd prefer a field struct too, so I'll update that as well as the constructors.\n. I'm hoping this addresses the performance/allocation concerns. There's now only one allocation per-directive-name -- try as I might to please the borrow-checker gods, I cannot seem to convince that compiler that I'm not really borrowing *self twice.\n. Thanks @Ryman! Changed so now there's no allocation.\n(sidenote: I was confused because the error message was talking about borrowing *self, not the &str...)\n. @seanmonstar No worries, mate. No offence taken. Like I said before, I didn't think it was necessarily the best code to start with. Glad to have it merged.\n. ",
    "Arrem": "Same issue on Windows 8.1 using Rust 1.1 and hyper 0.6.1\n. ",
    "Ivo-Balbaert": "Thanks Sean that was the solution!\nIvo\nFrom: Sean McArthur [mailto:notifications@github.com] \nSent: maandag 29 juni 2015 19:10\nTo: hyperium/hyper\nCc: ibalbaert\nSubject: Re: [hyper] Compile error due to openssl on Linux (#591)\nLooking more, it seems likely the header files aren't installed. See the README https://github.com/sfackler/rust-openssl#building  regarding building openssl.\n\u2014\nReply to this email directly or view it on GitHub https://github.com/hyperium/hyper/issues/591#issuecomment-116763733 .  https://github.com/notifications/beacon/AA6zfFGk4yBDbLuzHdlq2IYo6x6mCS9_ks5oYXNvgaJpZM4FOC98.gif \n\nDit e-mailbericht is gecontroleerd op virussen met Avast antivirussoftware.\nhttps://www.avast.com/antivirus\n. ",
    "airportyh": "Cool! Thanks for the detailed workaround. I will give it try.\n. The workaround worked. Thank you!\n. ",
    "pcwalton": "@reem Done.\n. @reem Exported and added the namespace.\n. ",
    "arnm": "Thanks. That worked.\nFor those who need to do something similar:\n``` rust\n[derive(Clone, PartialEq, Debug)]\n///Token holder for Token Authentication, most often seen with oauth\npub struct Token {\n        ///Actual bearer token as a string\n        pub token: String\n}\nimpl Scheme for Token {\n        fn scheme() -> Option<&'static str> {\n                Some(\"Token\")\n        }\n    fn fmt_scheme(&self, f: &mut fmt::Formatter) -> fmt::Result {\n            write!(f, \"token={}\", self.token)\n    }\n\n}\nimpl FromStr for Token {\n        type Err = error::Error;\n        fn from_str(s: &str) -> error::Result {\n                Ok(Token { token: s.to_owned()})\n        }\n}\n```\nThen I could pass this Token into Authorization:\nrust\n    let mut headers = Headers::new();\n    headers.set(\n        Authorization(\n            Token {\n                token: \"blah\".to_owned()\n            }\n        )\n    );\n. @reem That was the only way I got it to work.\nThis is the curl command I need to replicate in Rust: curl -H \"Authorization: Token token=token\" -X GET -G \"http://domain.com\"\n. @reem ya the FromStr implementation is wrong but I'm actually only making requests with that header and don't receive any responses with it so I don't think even need it. \n. So, I guess there is no way to do this currently? At least that is what I gathered from The Client implementation where you have to specify the request type and destination to get a RequestBuilder where you can specify all of the other things.\nI would like for there to be no predetermined order of operations when defining a request. Meaning, I could specify the request data before specifying request type or vice versa. I think this allows for the most flexible interface and could bring performance improvement.\n. @seanmonstar It's not only the header fields but I have noticed that most libraries do not offer this sort of API. I'm no sure why though. Anyways, If there is no interest in introduction something like this I guess this issue can be closed.\n. @seanmonstar Thanks for the help but none of that worked :(\nDoes the function signature look O.K? I think my problem is that I'm trying to return a RequestBuilder but the type I'm returning and the parameterized types are mismatching\n. @Ryman Thanks, that worked.\n. ",
    "semmaz": "@cybergeek94 Im pretty sure you're using wrong gcc, MSYS2 one, instead of gcc that comes with mingw-w64-x86_64-toolchain. Maybe you missed step 3 from here?\nTo make sure see what $ which gcc gives you (should be /mingw64/bin/gcc). Also, with pacman -S openssl you, most likely, just reinstalled openssl that used by msys2, while openssl that youl need comes with mingw-w64-x86_64-toolchain and have name mingw-w64-x86_64-openssl, thus instead of pacman -S something use pacman -S mingw-w64-x86_64-something to get missing package\n. @shinchiro I think something \"wrong\" with your gcc setup (see this issue from gcc-rs). If you want to build hyper with openssl just follow build instructions from rust repo (this also mentioned in rust-openssl here).\n. @shinchiro Just bring gcc from mingw-w64-x86_64-toolchain into PATH environment variable (e.g. set PATH=C:\\msys64\\mingw64\\bin;%PATH%), preferably temporarily, as this might cause issue with cmd elsewhere, and you should be golden.\nAs for atom specific build package, this is achievable with custom build command, but, it seems that setting PATH with this is broken right now on windows, you might overcome this by good old bat file:\nset PATH=C:\\msys64\\mingw64\\bin;%PATH%\ncargo build\nand launching it from custom build command.\n. ",
    "shinchiro": "@semmaz Thanks..finally I managed to compile hyper via mingw64_shell.bat. \nBut is it possible to compile it inside IDE like atom (build package) with mingw64_shell or something like that\n. Got it..thanks :)\nTo make the bat more flexible, I changed to this so it can accept any parameter aside 'build'\nset PATH=C:\\msys64\\mingw64\\bin;%PATH%\ncargo %*\n. ",
    "ealasu": "I must have been looking at RFC 2616 instead of 7233 (the former only allows the bytes unit). Will fix.\n. @pyfisch fixed.\n. @seanmonstar fixed.\n. ",
    "k0pernicus": "Ok, my bad - I not used headers(...) but header(...)... (newbie here)\nBut, with that custom header, i don't receive again any UTF-8 response... :-/\n. I've got the solution for ElementaryOS systems.\nDon't forget to install libc6-dev:i386 and libssl-dev:i386 to link 32 bits lib in your 64 bits Linux distribution! :-)\n. Oh ok, I don't understand that the header macro was actually a tuple struct...\nThanks a lot :-)\n. ",
    "batisteo": "Changed from:\n``` rust\nuse hyper::header::{Headers, ContentType};\nuse hyper::mime::{Mime, TopLevel, SubLevel, Attr, Value};\nlet mut headers = Headers::new();\nheaders.set(\n    ContentType(Mime(TopLevel::Application, SubLevel::Json,\n                     vec![(Attr::Charset, Value::Utf8)]))\n);\n```\nto:\n``` rust\nuse hyper::header::{Headers, ContentType};\nuse hyper::mime::{Mime, TopLevel, SubLevel, Attr, Value};\nlet mut headers = Headers::new();\nheaders.set(\n    ContentType(Mime(TopLevel::Application, SubLevel::Json,\n                     vec![(Attr::Charset, Value::Utf8)]))\n);\n```\nfor consistency with previous block.\n. ",
    "paomian": "I get the same error when i call the method get\nrust\nlet url = [\"https://api.leancloud.cn/1.1/classes/\",class.as_ref(),\n               \"/\",id.as_ref()].concat();\n    let mut ress = client.get(url).headers(headers).send().unwrap();\nclass and id is String type.\nbut I get the IntoUrl code \n``` rust\npub trait IntoUrl {\n    /// Consumes the object, trying to return a Url.\n    fn into_url(self) -> Result;\n}\nimpl IntoUrl for Url {\n    fn into_url(self) -> Result {\n        Ok(self)\n    }\n}\nimpl<'a> IntoUrl for &'a str {\n    fn into_url(self) -> Result {\n        Url::parse(self)\n    }\n}\n//may be it is impl for String?\nimpl<'a> IntoUrl for &'a String {\n    fn into_url(self) -> Result {\n        Url::parse(self)\n    }\n}\n```\nSo i don't know why about this i get the error\nmy rust and cargo:\nrustc 1.3.0 (9a92aaf19 2015-09-15)\ncargo 0.4.0-nightly (553b363 2015-08-03) (built 2015-08-02)\n. ",
    "bsansouci": "I noticed the typo in the url \"http://www.gooogle.com/\" but correcting it didn't change anything. It worked for \"http://www.reddit.com/\" for some reasons :p\n. Awesome :)\n. ",
    "Programming4life": "For anyone running into this problem: I ran into this same problem with \"http://www.google.com/\" and some other sites I did some digging and realized the response is gziped you have to decompress it first thats why you get \"stream did not contain valid UTF-8\".\n. @seanmonstar Adding hyper = { version = \"0.6\", no-default-features = true } doesn't fix it.\n. Switched languages. Solved :)\n. ",
    "jonfk": "@Programming4life  I got the same issue and I see why that is happening. I am wondering why hyper doesn't decompress the response transparently, I am guessing it's to be more explicit about what is happening. Does hyper offer a way to decompress the gzipped response or do I have to get another library to do the decompression? \nThanks if you can help.\nHere is the code I am using:\n``` rust\nextern crate hyper;\nuse hyper::client;\nuse std::io::Read;\nfn main() {\n    let client = client::Client::new();\nlet mut res = client.get(\"https://www.google.com\").send().unwrap();\nassert_eq!(res.status, hyper::Ok);\nlet mut response_string = String::new();\nres.read_to_string(&mut response_string).unwrap();\nprintln!(\"{}\", response_string);\n\n}\n```\n. ",
    "havarnov": "Yes, but you'd also had to implement Deref for HashableStatusCode. Not a big deal, but a little smoother IMO.\nI've submitted a pull request, so it's up to you if you think it's useful.\n. Of course, that's much better.\n. ",
    "muja": "https://github.com/hyperium/hyper/pull/622 with this pull request it's possible now, filsmick: Add the net2 crate as a dependency, and follow the example that I've provided.\n. ",
    "gnunicorn": "@seanmonstar, Unless you have any other idea, how I could figure out from the handler, what the SSLCert send by the client is... Yes.\n. ",
    "GildedHonour": "you're right but in the examples throughout the code  we have header(s) created separately, whereas in that example one header created through fluid interface. So if we create  let mut headers = Headers::new(); how to add them to the  client?\n. @Ryman\nIn curl I can do this:\ncurl -d '{\"key\":\"api key\"} my url\nand the same thing in Rust:\nlet res = client.post(\"my url\")\n      .body(\"key=api key\")\n      .send()\n      .unwrap();\nAnd how can I do this in Rust (nested keys and arrays)?\n```\ncurl -d '{\"key\":\"api key\",\"key1\":{\"key2\":\"fdsfdsfdsfdsfd<\\/p>\",\"key3\":[{\"key4\":\"fdsfdsfd\",\"key5\":\"fdsfdsfd\"}],\"key5\":{ and so on....\n```\n. thx. is there up to date example of sending a post request in hyper with some form data which compiles?\n. Where is form data in that example?. >There's no need to open duplicate issues to ask the same question, though.\nThere is a need, and even a neccessity. I've asked a concrete question: how to do that in HYPER!. ",
    "manuel-woelker": "I was trying to implement this today, but I hit a snag on the AbsoluteUri(Url) part. url::Url does not implement AsRef, and there does not seem to be a way to get a cheap &str ref out of it.\nApparently I wasn't the first taking a stab at this, googling turned up this discussion, which looked very familiar:\nhttp://stackoverflow.com/questions/32062866/how-to-use-the-lifetime-on-asref\nBut with the implementation of std::fmt::Display, UriRequest now also supports to_string(), which is probably sufficient.\n. ",
    "zoumi": "I think it a bug of rust-openssl ,you can put the libssl32.dll, and libeay32.dll to your:\ntarget\\debug\\deps\nor \ntarget\\release\\deps\nto solve this problem temporarily.\n. ",
    "Maplicant": "Same issue happened to me on Windows 10, Rust 1.14.0 (nightly) (GNU). Does anyone know which version of libssl32 and libeay32 I have to use? I'm getting errors about the dll's being uncompatible with every dll I've tried,\n. ",
    "matthewkmayer": "Conservative behavior would be to not follow redirects for unsafe methods.  Since Hyper is following redirects for unsafe behavior, that should be fixed.  Perhaps this issue can be for that.\nUpdating documentation about redirect behavior would be nice.  I think http://hyper.rs/hyper/hyper/client/enum.RedirectPolicy.html would be a good place to put the info about client redirect behavior.\nWould you like a new ticket for updating those docs?\n. A good first step would be to allow following all redirects.  \nIf I'm understanding right, you describe something more fine-grained where a user can specify to only follow certain verbs and destinations.  EG \"only follow redirects for PUTs to this URL.\"  Is that right?\nIf so, that's more work and I'm not sure of what use cases it would be useful for.\n. FYI in my project I switched to FollowNone and handled the redirect in my code.  I think that was the only option available to me due to signed header authorization that includes the destination host name.  Works like a charm!\n. Is there a rust ticket for that?  I gave the existing issues, open and closed, a look and didn't see a relevant one.  I'd like to keep my eyes on that.\nThe ... happy path for our need for this timeout appears to work with the latest hyper release, thanks for your hard work!\nThis issue is for a very much not happy path but was the most expedient way to test things and could also be a bit of a papercut for our users, so I want to fix it when the language feature is available on stable.\n. \ud83d\udc4d upgraded the Hyper dep and ran docs locally, the link now works. Thanks!. Thank you for the exceptionally quick turnaround time on these fixes, @seanmonstar . \ud83d\ude04 . ",
    "Antti": "It seems like this header is more complicated than others, just by judging it's ABNF:\nABNF\nLink           = \"Link\" \":\" #link-value\nlink-value     = \"<\" URI-Reference \">\" *( \";\" link-param )\nlink-param     = ( ( \"rel\" \"=\" relation-types )\n               | ( \"anchor\" \"=\" <\"> URI-Reference <\"> )\n               | ( \"rev\" \"=\" relation-types )\n               | ( \"hreflang\" \"=\" Language-Tag )\n               | ( \"media\" \"=\" ( MediaDesc | ( <\"> MediaDesc <\"> ) ) )\n               | ( \"title\" \"=\" quoted-string )\n               | ( \"title*\" \"=\" ext-value )\n               | ( \"type\" \"=\" ( media-type | quoted-mt ) )\n               | ( link-extension ) )\nlink-extension = ( parmname [ \"=\" ( ptoken | quoted-string ) ] )\n               | ( ext-name-star \"=\" ext-value )\next-name-star  = parmname \"*\" ; reserved for RFC2231-profiled\n                              ; extensions.  Whitespace NOT\n                              ; allowed in between.\nptoken         = 1*ptokenchar\nptokenchar     = \"!\" | \"#\" | \"$\" | \"%\" | \"&\" | \"'\" | \"(\"\n               | \")\" | \"*\" | \"+\" | \"-\" | \".\" | \"/\" | DIGIT\n               | \":\" | \"<\" | \"=\" | \">\" | \"?\" | \"@\" | ALPHA\n               | \"[\" | \"]\" | \"^\" | \"_\" | \"`\" | \"{\" | \"|\"\n               | \"}\" | \"~\"\nmedia-type     = type-name \"/\" subtype-name\nquoted-mt      = <\"> media-type <\">\nrelation-types = relation-type\n               | <\"> relation-type *( 1*SP relation-type ) <\">\nrelation-type  = reg-rel-type | ext-rel-type\nreg-rel-type   = LOALPHA *( LOALPHA | DIGIT | \".\" | \"-\" )\next-rel-type   = URI\n. ",
    "tabac": "@seanmonstar Hi, I'd like to give this a try if you're OK, we still want this right?. I took a quick look at this. So what you're saying is move the Host specific code from here to somewhere in here, right? If so, how are we  going to have access to the Request.url() from the second function?\nAlso, in the Client code we're creating a new Headers instance place the Host first and extend with the remaining headers. I assume that we do that so that the Host header appears first. Do we care about the order of the remaining headers? If not maybe a combination of swap_remove and push could work without iterating.. How about this part?\n\nAlso, in the Client code we're creating a new Headers instance place the Host first and extend with the remaining headers. I assume that we do that so that the Host header appears first. Do we care about the order of the remaining headers? If not maybe a combination of swap_remove and push could work without iterating.\n\nIt would take a few additions in Headers's and VecMap's implementations to expose those Vec methods. I know we're not gaining much but just asking.. @seanmonstar I have to work on the way we .split(). The Link header's delimiters are ; and , but these characters can appear inside quoted text. So we have to ignore them in that case.\nDo you have anything in mind that does something similar? I did a bit of search and unfortunately haven't found something. I was thinking of an iterator over ASCII characters yielding string slices.. @seanmonstar Please take a look and let me know what you think. I intend to do some more testing and add some tests. I also left some comments/questions.\nEDIT: Tests are passing locally. I will look into it a bit later.. @seanmonstar The tests fail because of the change introduced in this commit.\nThe change doesn't allow relative URIs containing something like ../ or ./ which I think that are allowed based on: RFC3986, RFC1808.\nDoes uri::Uri refere to absolute URIs only? If so I could just change the unit test.. I went with uri::Uri because for the headers Content-Location, Location, Referer we are using String but you have a comment to use URL. All three as well as Link should support relative URIs.\nFrom what I understand from here a relative URI can be something like: //something, /something, ./something, ../something, somethine_else, even ./some:thing.\nMaking uri::Uri more generic touches parts of the library which I am not fully aware of and I feel it's more like a different task. I will go with String if you're OK with that. We could open another issue for supporting relative URIs in uri::Uri.\n. @seanmonstar I want to add more tests and try it out a bit. Other than that I think you could review if you want. (Not sure what's going on with coveralls). . I am kind of lost with coveralls. It's reporting 0 coverage for link.rs and for almost everything else. Am I doing something wrong?. @seanmonstar feature wise, I think it's OK, I don't have something to add at the moment.\nI am currently working on an example HTTPS client in order to test it further but any possible fixes could go to a different PR.. @seanmonstar I could do this. I guess nobody else is working on it right?. If we make fields private we would have to provide setters and getters. I am planning to implement a builder pattern like constructor so we could skip the setters. I think it's fine to make things private.\nAbout making some of the fields generic, it makes sense but which ones? We can do it for title* and link-extension and that way leave the parsing of those two fields to the user. Not sure if it makes sense for other fields maybe link, anchor but I like Uri as it is.. Oh, I haven't realized that for from_one_raw_str, I will look into it.. I have tried UniCase before doing the above. Maybe there's a better way I will check.. OK, I will leave those two as Strings then.. Is there a more idiomatic way to do this?. When we want case-insensitive comparison I am using this function since we're dealing only with ASCII.. This function as well as from_str_delimited kind of overlap with the ones you have in header/parsing.rs. We could move them but I think it's fine like this.. I don't know what to do here. I think we should support more than one Link headers per request but I have the impression that parse_header() should return a Result with one header object not a Result<Vec<Link>>.. Returning a Result from the constructor doesn't look very good. I did it like that because uri::Uri is not public. We could change that if you want to.. I agree, it doesn't look very good. I changed it to receive a tuple, I think it's a bit better. I thought about creating a tuple struct and passing it but it won't be so efficient I believe. . I can't think of a use case needing a &Vec, I changed everything to return Option<&[T]>.. ",
    "mfeckie": "@seanmonstar Is anyone working on this?  If not I'd be interested in giving it a go\n. @pyfisch Whoops, was fixing up GitCop issue and missed it.  will resbumit\n. @seanmonstar Thanks!  I work on so many different things with different policies on rebasing, squashing, merging and particularly force pushing!  Good to know what works for you folks.\nHappy to adjust to include the additional possibilities. Will await the feedback from the folks you've pinged.\n. cool! Will .take a look!\n. ",
    "puhrez": "Would love to get newly-rusty hands wet; what's going on here? \nA variety of PRs have been closed, and one (to another project?) \n. @seanmonstar that seems good for a single \"serialized-origin\". I'm not very familiar with things (in general) but according to the spec the value of an Origin header may actually be a vec of this implementation of Origin.\nAside from that in order to parse/generate, after having read the docs the Origin struct also needs to implement Header and HeaderFormat right?\nalso aside: y use u16 when there are no negative ports?\n. Ah yes, I knew it meant unsigned but for some reason (not being very used to u/i distinctions), I mixed the concepts.\nre header! macro trait merging:\n~~the idea then becomes to do something like (from the docs)~~\nheader! { (Origin, \"Origin\") => [String, String, Option[u16]] }\n<insert yr impl block and default_port fn here>\nUPDATE:\nactually... reading thru more of the doc, \n\n\"This works well for simple \"string\" headers. But the header system actually involves 2 parts: parsing, and formatting. If you need to customize either part, you can do so.\" \n\nsince the optional port is not a string, do we have to implement the Header/HeaderFormat trait anyway? regardless, I think would this be an appropriate place to use url::Host for the host like rust-url in its definition so we get all that typed goodness.\non second though, perhaps it can use header::Host since that already has a sense of hostname and port. Moreover, when that gets moved over to use url::Host, this one naturally benefits.\n~~on third thought, isn't Origin (according to the newest spec) just an optional  header::Header::Host with a scheme?~~\n. started a pull request incorporating my comments above as well as trying to conform to contribution style, haven't tested it well (read: at all) yet tho :). \nused header::Host for inspiration\n. I think this should be easy with the header! macro from what I read here: https://www.w3.org/TR/2011/WD-eventsource-20110310/, ctrl-f \"Last-Event-ID header\"\n. that what it seems like\n. \ud83d\udc40 \n. This would be a PR against the ng branch yea?\n. fair fair\n. So what sort of spec would you hold for this guide? like what points should it cover?\n. @seanmonstar can u take a look  at this and let me know how I can make it better?\n. @seanmonstar could you rerun both builds? One didn't start, the other failed downloading a dependency.\n. @seanmonstar btw I still plan to obfuscate the setting if host/port via your earlier suggestion.\n. so 1, the comment about  new and 2? the accessor funcs?\n. oh haha\n. @seanmonstar so i think we're good here,\naside: could you label other issues that I may tackle with easy?\n. I originally did that, but then I get an unused result warning\n. !\n. So I see the reason for a constructor, by why obstruct access? \n. ",
    "psdh": "Use case: servo/servo#7497\n. ",
    "brianloveswords": "This is a dupe of #368\n. ",
    "anowell": "Thanks. That helps me understand the tradeoff that was made for RequestBuilder.\n. ",
    "myabdelis": "Thanks a lot guys !\n. ",
    "huonw": "I suppose another approach would be to break send into two parts: a small generic part that calls self.url.into_url() which then calls a non-generic function that does all the work, but I personally feel like this version is a little nicer.\n. (Based on top of #665 so tests pass on nightly.)\n. ",
    "mjc-gh": "This looks like a duplicate (or is superseded by) #298\n. I'm making an attempt to build a standalone Server Sent Event broker using async hyper. Will update this thread with my progress...\nStill trying to figure out how to manage \"subscribed\" connections for a given channel. The goal is to then \"publish\" an event payload to all connections \"subscribed\" to a given channel. \n. @frederikbosch will keep you posted :smile: \n. Any advice on how to achieve this @seanmonstar? I've tried a few techniques using channels and other async approaches but haven't been able to come up with something that works well with hyper's new event based design.\nIt feels like I need to leverage an event loop to implement this sort of thing. Ultimately, I'm trying to have two main HTTP endpoints:\n1. /subscription/:channel route which will be the event stream endpoint and will leave the socket waiting. \n2. /publish/:channel route which lets you publish an arbitrary message to all subscribed clients\nI have the skeleton setup already but the guts of it all still elude me \ud83d\ude35! Any guidance would be much appreciated.\n. What about using rotor's event loop directly and expanding a Handler type to support some sort of on_publish event? Perhaps one could compose two state machines together via rotor_compose!?\nThe first would be a hyper handler and the second would be a custom state machine for publishing events between different connections and clients.\n. @seanmonstar definitely understand hiding rotor complete and keeping it internal to hyper.\nI had a similar idea with using a HashMap to track Control instances across handlers and have something that works for a single threaded server. I then moved to creating multiple Server instances within different threads using something like the following:\n``` rust\nBroker {\n    // other stuff\n    control: Control,\n    subscribers: Arc>>\n}\nimpl Broker {\n    fn new(ctrl: Control, subs: Arc>>) -> Broker {\n        Broker {\n            // other stuff\n            control: ctrl,\n            subscriber: subs\n        }\n    }\n}\nfn main(){\n    let listener = HttpListener::bind(&\"127.0.0.1:3002\".parse().unwrap()).unwrap();\n    let mut handles = Vec::new();\nlet subs: HashMap<String, Vec<Control>> = HashMap::new();\nlet subs_ref = Arc::new(subs);\n\nfor _ in 0..2 {\n    let listener = listener.try_clone().unwrap();\n\n    handles.push(thread::spawn(move || {\n        Server::new(listener).handle(|ctrl| Broker::new(ctrl, subs_ref.clone())).unwrap();\n    }));\n}\n\nfor handle in handles {\n    handle.join().unwrap();\n}\n\n}\n```\nWhich then started producing the following error:\nerror: the trait bound `std::sync::mpsc::Sender<hyper::Next>: std::marker::Sync` is not satisfied\nI also tried to do something with callbacks so that you could call a subscribe function and supply a closure that would call wakeup on a closed Control instance as well as receive the actual message data somehow. Was having issues sorting out the sync aspects with Fn's though.\n. Thanks @seanmonstar!\nI had tried an RwLock but I now realize that you need a full Mutex to provide the proper guarantees for this sort of thing. Thanks again for the help and the explanations!\n. Got a pretty complete POC working. If anyone is interested in viewing it, it's available on here: https://github.com/mikeycgto/esper\nI'm planning on developing it further, check out the issues section for more thoughts on that!\n. Definitely think this greatly simplifies the API. I'm interested in migrating my Event Source server to any new async API when it's ready. Would be happy to even start implementing changes against a development branch!\nI do need the ability to wake up arbitrary connections from another connection. To achieve this, I'm using a HashMap that maps to Control instances (or more specifically: HashMap<Topic, Vec<(Client, Control)>>. Once an outgoing message is queued, I call ready() on the Control instances.\n. I'm in the process of blogging about futures and the changes to hyper for my company's blog. I have some questions about streaming responses with hyper. I put together a small example that just creates an infinite stream and sends out a Chunk periodically via an Interval from tokio-timer. The source for this is available here: https://github.com/Sigient/hyper_examples/blob/future-streaming/src/main.rs\nFirstly, is this the proper way to handle this sort of streaming? I want to eventually rewrite esper and will be keeping open a connection for an Event Source stream so I can send data as events are received from other clients. Is there a better way to send a stream of Chunks or, more generally, tie an arbitrary Stream to a response body? I'm thinking of implementing the Stream trait for some message queue type in esper and defining a poll function which knows when there are new messages available. I'm still trying to wrap my head around futures before I attempt implementing something this complex though.\nSecondly, when I run this example and connect a client to the stream, I see the CPU usage for the process spikes to 100%. I think this is likely because I am doing something wrong with the Interval type but I'm not really sure.... Sorry about that @seanmonstar! The repo was private and I have now made it public. Thanks!. No longer seeing the busy looping. Thanks Sean!. ",
    "nnovikov": "Big tnx!\nAfter res.read_to_string() I have what I want!\nHyper superb!\n. ",
    "dignifiedquire": "@seanmonstar I'm running into this issue myself, but I'm not sure how/where to best fix it. Any pointers where I should start looking?\n. ",
    "miolini": "@seanmonstar yes, source of app in the ticket. I expect around 5000 sockets (1000 threads x 5 sockets).    But it use all my sockets. 30k for client, 30k for server.\n\n. Issue solved by setting up sysctl:\nnet.ipv4.tcp_tw_recycle = 1\n. Unfortunately tcp_tw_reuse is not working in this case. Tested on ubuntu:14.04 amd64.\n. ",
    "apoelstra": "Yeah, I'd be happy with that.\n. @xaviershay the problem is that a Display impl is calling description on the std error instead of Display::fmt, so no useful information is propagated, even though it's accessible from the std error.\n. FYI this changes the behaviour when sending on stale connections from returning a ConnectionAborted error to returning a BrokenPipe error. Code which detected this when deciding whether to just retry sending or treat it like a real error will break.. ",
    "josephpd3": "Hey all, I am a little confused on this issue. @seanmonstar, did your PR rust-lang/rust#30312 resolve the matter or am I not quite understanding? Apologies, I'm still getting used to Rust and would like to help if I can.\n. ",
    "NecroTechno": "Alright, awesome. Thanks!\n. ",
    "opensourcegeek": "@seanmonstar I'm trying to use set_write_timeout on client, but the client doesn't disconnect after the timeout. I'd like to run bunch of POST requests with big payloads to check the throughput of the connection. When the connectivity is really poor I don't want it to run all the tests. I was wondering if I can set the timeout using this method to close/drop connection after it pushed for X number of seconds? . @seanmonstar Thanks - I got around by using custom type implementing Read trait and passing it to ChunkedBody. Now I track the time in my custom type which seems to work Ok so far.  . @seanmonstar I'd written a small post on how I'm doing chunked body POSTs using hyper, if you could look into it when you get a chance and give me any feedbacks it would be really useful for me. Thanks. . @seanmonstar great - thanks.. ",
    "kaedroho": "@jdm Thanks!\nThat excerpt you referenced refers to the body on HEAD responses. Here, I'm refering to the body on GET/HEAD requests. This is actually mentioned in that spec in a separate paragraph:\n\nA payload within a GET request message has no defined semantics;\n   sending a payload body on a GET request might cause some existing\n   implementations to reject the request.\n\n\"no defined semantics\" does sound a little worrying, but I can't see anything here that disallows it.\n. Fixed + squashed into original commit. Thanks!\n. ",
    "bombless": "I like this PR as we should do things right.\n. So this last '::{self}' part can be removed now.\nHmm in this diff it seems that this use statement can be removed.\n. ",
    "musitdev": "Sorry I didn't see it. I look the code to understand my problem and didn't think to look at the doc after.\n. ",
    "malept": "\nIs this sort of thing common in many other headers?\n\nI'm using it for implementing RFC 7616 (HTTP digest authentication) - the username parameter can alternatively be username*.\nIn searching the RFCs, I found references to RFC 5987 in:\n- RFC 5988 (Link header)\n- RFC 6266 (Content-Disposition header)\n- RFC 7616 (Authorization: Digest header)\n\nIf so, perhaps it would make sense to define a struct in the shared module, instead of this returning a tuple?\n\nThat sounds reasonable.\n\nAlso, as this adds a new method (and possibly struct), could reword the commit message to be a feat(headers)?\n\nWill do. I wasn't sure whether this was a refactor or a feature.\n. I've added some tests for the error cases, reworded the commit message per feedback, and added a struct. I wasn't sure whether to call the last member in the struct value or data (or something else).\n. FYI, I've been working on HTTP Digest authentication here, partially as a way to learn Rust & its ecosystem. I have Authorization support fully implemented and part of Authentication-Info. I would be happy to contribute the implementation to hyper as a starting point, I just wasn't confident enough in doing so until I got enough time to figure out a good way to implement WWW-Authenticate in a similar manner to Authorization (I was aware of #178 when I started).\n. > Are you willing to shape this so it can be integrated in Hyper with a PR?\nYeah, that was always the (eventual) goal.\n\nShould I work on WWW-Authenticate then?\n\nSounds good. I probably need to be involved in the Digest authentication part, since there's some shared code between the two headers and I want to make sure the (internal) API works for both.\n. Quick update: I've converted my digest authentication implementation to use crypto libraries that are bundled with the OS (namely, CryptoAPI on Windows and CommonCrypto on OS X) and threw that into its own crate - so OpenSSL is now only a requirement for some operating systems. Hopefully this alleviates the dependency concerns.\n. I don't mind if people want Digest authentication support inside Hyper or not. I think that's up to @seanmonstar.\n\nDigest authentication seems (a lot) more complicated than Basic\n\nRFC 7616 is indeed complex :smile: \nMy thoughts were to have a similar Scheme-like trait for WWW-Authenticate.\nThat is an interesting note about challenges. I think whatever wants to use WWW-Authenticate a layer up from Hyper needs to take into account both multiple challenges in a single WWW-Authenticate header, and multiple WWW-Authenticate headers.\n. My half-serious suggestion is that I wish there was a Rust-based ABNF parser that we could use here :smile:\nMy real answer is: because of the way that the Authorization header is currently implemented, it's probably better if the WWW-Authenticate Scheme implementation handles parsing the ( token68 / #auth-param ) blob of text. I would personally rather have hyper parse all of it for me (I have an entire module in guardhaus dedicated to parsing/generating these parameters, and it's probably not complete), but I think it's much more important that both Scheme traits are similar in terms of how to implement them.\n. Are you just using the Basic scheme just as a testbed for the base64 token implementation? I ask because I got a little  confused reading that code - Basic authentication has a base64 token in the Authorization header, auth-params in the WWW-Authenticate header. Of the schemes in http://www.iana.org/assignments/http-authschemes/http-authschemes.xhtml, the only one I saw that uses a base64 token is https://tools.ietf.org/html/rfc4559#section-4.1.\nHaving read all three Digest RFCs, the quoting weirdness is due to backwards compatibility.\nI'll post my thoughts on your recent changes later, I need some time to think about it.\n. > However, I think it should remain the responsibility of the Scheme implementation to format the header to a string.\nAgreed.\n\nMaybe WwwAuthenticate<S> should be an enum Parsed(S) or Raw(String)?\n\nIt looks like Authorization<S> supports both a Scheme and a String when you initialize it, without the use of an enum. It would be nice from an API consumer perspective to be able to add either via add_challenge().\nI'm not sure about your get_scheme() method. What if there are multiple Digest challenges and the first one uses an algorithm not yet supported by the implementation? (Example: if the WWW-Authenticate headers in the RFC example were merged into one header.)\n\nAlso, add_challenge could just always add a \", \" regardless of what's before since that's allowed by the spec, but it would look a bit weird.\n\nI wouldn't add a dangling comma, mostly because of the robustness principle.\n\nWe could either keep the Authorization header as it is today, or change it to use the updated Scheme trait and the parser from www_authenticate.rs.\n\nI would be fine with updating guardhaus to use the new trait. (Assuming an appropriate version bump from hyper.)\n. @matt2xu Guardhaus's HTTP digest implementation only relies on hyper for two things:\n\nheader parsing\nthe HTTP method enum\n\nIf those features were split out of hyper proper, I could use that, and then hyper would only be a build-time dependency (for the example apps).. Thanks, fixed/rebased in da0abe8.\n. ",
    "mcasper": "I ran into this problem recently and turns out my openssl had gotten linked to an older version. What does openssl version -a return?\n. ",
    "lilyball": "The problem is OS X doesn't ship with openssl/ssl.h anymore. Period. Apple has deprecated the use of OpenSSL on their platforms in favor of alternative libraries. The library is still present, but it's still the same 0.9.7 and 0.9.8 that Apple has provided for ages.\n. Incidentally, the README of sfackler/rust-openssl states\n\nOSX releases starting at 10.11, \"El Capitan\", no longer include OpenSSL headers which will prevent the openssl crate from compiling.\n. Sure, but that's just a stopgap. We can't expect everyone to install a new version of OpenSSL into /usr/local.\n\nThree possible solutions that come to mind:\n1. Change openssl-sys to actually include a copy of the OpenSSL 0.9.8 headers, which it falls back to on Apple platforms if there are no headers provided by the system.\n2. Change openssl-sys to actually download and statically build a copy of OpenSSL if the headers can't be found on the system. Incidentally, Apple's own documentation states that if you want to use OpenSSL you should statically link your own version into your app (though it encourages you to not use it at all).\n3. The ideal solution, though possibly the most work, is to change Hyper to use Apple's own APIs on Apple platforms instead of OpenSSL. It appears there's already a security-framework crate (by @sfackler) that provides SecureTransport. For symmetric encryption you'd want to use Common Crypto (though I don't see a crate offhand for it, but I admittedly didn't search very hard). Note that you'll also have to update any dependencies that use openssl as well.\n. @sfackler CommonCrypto is provided in libSystem, under the import path <CommonCrypto/CommonCrypto.h>. Security.framework is built on top of CommonCrypto rather than including it. That said, it is perfectly reasonable to expose CommonCrypto as part of the security-framework crate.\nIncidentally, while iOS provides basic encryption/decryption using SecKey as part of Security.framework (specifically the functions SecKeyEncrypt, SecKeyDecrypt, SecKeyRawSign, and SecKeyRawVerify), these functions don't appear to exist on OS X.\n. Seems to me that hyper should use the target.*.dependencies feature to automatically select between openssl and security-framework.\n. ",
    "simlay": "If you're using homebrew, I found that http://stackoverflow.com/a/17231736 fixed this issue for me.\n. ",
    "BProg": "On Debian you should just install libssl-dev package and it will work, or just update libssl.\n. ",
    "mr4x": "Use:\nsudo chown -R $(whoami) /usr/local\nbrew install openssl\nbrew link openssl --force\n. @SimonSapin use refactor(hyper): update to rust-url 1.0\n. ",
    "pandeiro": "Thank you @BProg, that command worked for me on Xubuntu as well.\nAs the referenced https://github.com/rust-lang/rfcs/pull/1361 has already landed and this issue persists at least for now, could I recommend adding these fixes (at least for OSX/Debian-based Linux) directly in a note in the README? It would help beginners like me, who may not know to search through the Issues list.\n. Much appreciated, with the additional explanation. Very helpful.\n. ",
    "kiliankoe": "Current homebrew (v0.9.9) is refusing to link openssl \ud83d\ude15 \n$ brew link --force openssl\nWarning: Refusing to link: openssl\nLinking keg-only openssl means you may end up linking against the insecure,\ndeprecated system OpenSSL while using the headers from Homebrew's openssl.\nInstead, pass the full include/library paths to your compiler e.g.:\n  -I/usr/local/opt/openssl/include -L/usr/local/opt/openssl/lib\nI'm failing to compile hyper 0.9.10. Should this be using something different than openssl on macOS or is this still correct? I'd love to get this working somehow.\n. Sorry to ask, but I'm rather new to using rust... I've added features = [\"security-framework\"] to my Cargo.toml, but am running into the same issue as before. How do I go about disabling the default ssl? Thanks \ud83d\ude0a \n. Ah, I see. Thanks for the link and reasoning!\nWould it be possible to make the error messages a little more clear though than they currently are? I tried quite a bit to debug this and was unable to find out anything by looking around with the error message. It probably would've helped if I've looked in the issues here more closely, but a quick search didn't show anything \ud83d\ude15. That would be great!. ",
    "masche842": "A workaround to link against openssl (installed with homebrew) is to use a custom .cargo/config:\n[target.x86_64-apple-darwin.openssl]\nlibdir = \"/usr/local/opt/openssl/lib\"\ninclude = \"/usr/local/opt/openssl/include\"\nAnyway, using security-framework seems the way to go.\n. ",
    "fungos": "Same thing for windows:\n```\n[target.i686-pc-windows-msvc.openssl]\nlibdir = \"C:\\OpenSSL-Win32\\lib\"\ninclude = \"C:\\OpenSSL-Win32\\include\"\n[target.x86_64-pc-windows-msvc.openssl]\nlibdir = \"C:\\OpenSSL-Win64\\lib\"\ninclude = \"C:\\OpenSSL-Win64\\include\"\n```\n. ",
    "brianirish": "I just ran into this issue for the first time today (new Hyper user), and @sfackler has provided the best answer. I changed it slightly to use the latest version of hyper from GitHub.\nCargo.toml:\n[dependencies]\nhyper = { git = \"https://github.com/hyperium/hyper\", default-features = false, features = [\"security-framework\"]}. ",
    "mkpankov": "\nIt's crashing because of the call to unwrap. You'd be better off matching on the Err case. \n\nThis I understand :) I wonder why the error happens, though\n\nIt's crashing because of the call to unwrap. You'd be better off matching on the Err case.\n\nHyper client keeps pool of sockets for its requests?.. Didn't know that.\n\nWith blocking IO, checking to see if a Connection was still alive could block the thread. So instead, the error happens the first time you try to write after the connection had been closed. \n\nHm, so I should just retry in such case?.. Is that a legitimate solution?\n. Thank you, will try it out after holidays. Closing :)\n. ",
    "yoshuawuyts": "ahhh, think I've tracked it down: homebrew was returning I was using rustc@1.5, but my local env returns rustc@1.2. I must've made a duplicate install somewhere; I reckon this will pass using 1.5 so closing for now. Thanks!\n. @bluetech awesome, thanks so much for your reply! That looks exactly like what I needed.\n@seanmonstar I think an example in the docs would definitely be helpful!. I took this back to the CLI WG a few days ago, and I don't think we've quite nailed the solution yet. Getting boundaries right for crates is tricky!\nI think the core of the issue for us right now is that in clap-port-flags we have to choose between exposing a new, specific method just for Hyper support or telling people to copy-paste some boilerplate.\nExamples\nI think showing the problem might work best:\nCurrent Usage\nThis is the current recommended usage. It's 3 lines using APIs from 3 different sources. For people that are getting started with HTTP, it requires that they understand the difference between sync / async sockets, and that they touch the hyper::Builder constructor.\n```rust\nuse clap_port_flag::Port;\nuse futures::prelude::*;\nuse hyper::service::service_fn_ok;\nuse hyper::{Body, Response, Server};\nuse structopt::StructOpt;\n[derive(Debug, StructOpt)]\nstruct Cli {\n  #[structopt(flatten)]\n  port: Port,\n}\nfn main() -> Result<(), Box> {\n  // Parse CLI args\n  let args = Cli::from_args();\n// Create TCP socket\n  let listener = args.port.bind()?;\n  let handle = tokio::reactor::Handle::current();\n  let listener = tokio::net::TcpListener::from_std(listener, &handle)?;\n// Run service\n  let server = Server::builder(listener.incoming())\n    .serve(|| service_fn_ok(|_| Response::new(Body::from(\"Hello World\"))))\n    .map_err(|e| eprintln!(\"server error: {}\", e));\n  tokio::run(server);\nOk(())\n}\n```\nTokio in clap-port-flag\nIn this version we would integrate all tokio code into clap-port-flag. It's now only 1 line, and touches 1 crate. It still requires people to know the difference between sync and async sockets, and also relies on the hyper::Builder constructor.\n```rust\nuse clap_port_flag::Port;\nuse futures::prelude::*;\nuse hyper::service::service_fn_ok;\nuse hyper::{Body, Response, Server};\nuse structopt::StructOpt;\n[derive(Debug, StructOpt)]\nstruct Cli {\n  #[structopt(flatten)]\n  port: Port,\n}\nfn main() -> Result<(), Box> {\n  // Parse CLI args\n  let args = Cli::from_args();\n// Create TCP socket\n  let listener = args.port.bind_tokio()?;\n// Run service\n  let server = Server::builder(listener.incoming())\n    .serve(|| service_fn_ok(|_| Response::new(Body::from(\"Hello World\"))))\n    .map_err(|e| eprintln!(\"server error: {}\", e));\n  tokio::run(server);\nOk(())\n}\n```\nstd::net::TcpListener support in hyper\nThis version would expose a new method on Hyper that accepts a std::net::TcpListener. This would be the same as the last example, except the Server::builder code is no longer required, and users no longer need to be aware of the differences between sync and async sockets.\n```rust\nuse clap_port_flag::Port;\nuse futures::prelude::*;\nuse hyper::service::service_fn_ok;\nuse hyper::{Body, Response, Server};\nuse structopt::StructOpt;\n[derive(Debug, StructOpt)]\nstruct Cli {\n  #[structopt(flatten)]\n  port: Port,\n}\nfn main() -> Result<(), Box> {\n  // Parse CLI args\n  let args = Cli::from_args();\n// Create TCP socket, and run service\n  let server = Server::listen(args.port.bind()?)\n    .serve(|| service_fn_ok(|_| Response::new(Body::from(\"Hello World\"))))\n    .map_err(|e| eprintln!(\"server error: {}\", e));\n  tokio::run(server);\nOk(())\n}\n```\nWrapping Up\nI hope this somewhat explains what we're running into. I can't claim to know what the right solution is, given I don't know all the constraints Hyper itself is facing. But I do think it'd be great if we could figure out a way to make all this setup easier! I def hope it makes sense where I'm coming from.\nThanks again for your time!. Perhaps another option might be:\n- Server::from_tcp\n\nI feel like Server::from_std_tcp is a bit long, but otherwise I think any name would work!. Okay, updated the errors & rustfmt!\n\nThis is probably fine! Or... I mean, maybe it could be converted to the internal AddrIncoming automatically, which could make it easier to eventually configure the extra features AddrIncoming provides? I'm uncertain.\n\nHmm, I don't have enought background knowledge to comment on this. The only thing I know is that it'd be slightly harder to implement - but happy to do that if you think that's the right thing to do! - would probably need a bit of guidance on it though, haha.\nBar tests passing, I think this PR should be mostly done now! Are there any other things that need adding?. @seanmonstar updated the patch again with your feedback; hope this is good! :sparkles:. Yayay, so happy this landed! Thanks for all the help! :tada:. Hmm, I guess the following does work:\nrust\n  let server = Server::from_tcp(args.port.bind()?)?.serve(service);\n  info!(\"listening on {}\", server.local_addr());\n  tokio::run(server.map_err(|err| error!(\"server error {}\", err)));\n  Ok(())\nHmmm; I wonder if that's as good as it can get. I'm guessing there's no way to smooth this any further right?. Ah yeah, I'm guessing this is probably the limit then haha. Thanks for bearing with me. Closing! \u2728. ",
    "tg339": "Was on 0.6 when I posted the issue. Updated to 0.7 and still getting the same thing. \nHere's the log incase it helps\nTRACE:hyper::header: Headers.set( \"Connection\", Connection([Close]) )\nTRACE:hyper::client: send Get Url { scheme: \"https\", scheme_data: Relative(RelativeSchemeData { username: \"\", password: None, host: Domain(\"data.medicare.gov\"), port: None, default_port: Some(443), path: [\"resource\", \"pqp8-xrjv.json\"] }), query: Some(\"$limit=1\"), fragment: None }\nTRACE:hyper::client: host=\"data.medicare.gov\"\nTRACE:hyper::client: port=443\nDEBUG:hyper::net: https scheme\nTRACE:hyper::client: host=\"data.medicare.gov\"\nTRACE:hyper::client: port=443\nTRACE:hyper::header: Headers.set( \"Host\", Host { hostname: \"data.medicare.gov\", port: Some(443) } )\nDEBUG:hyper::http::h1: request line: Get \"/resource/pqp8-xrjv.json?$limit=1\" Http11\nDEBUG:hyper::http::h1: headers=Headers { Host: data.medicare.gov, Connection: close, }\nTRACE:hyper::client::response: Response::with_message\nTRACE:hyper::client::pool: previous_response_expected_no_content false\nTRACE:hyper::http::h1: previous_response_expected_no_content = false\nTRACE:hyper::buffer: get_buf []\nTRACE:hyper::buffer: read_into_buf buf[0..4096]\nTRACE:hyper::buffer: get_buf [u8; 4096][0..4096]\nTRACE:hyper::http::h1: try_parse([72, 84, 84, 80, 47, 49, 46, 49, 32, 50, 48, 48, 32, 79, 75, 13, 10, 83, 101, 114, 118, 101, 114, 58, 32, 110, 103, 105, 110, 120, 13, 10, 68, 97, 116, 101, 58, 32, 77, 111, 110, 44, 32, 48, 52, 32, 74, 97, 110, 32, 50, 48, 49, 54, 32, 50, 50, 58, 50, 54, 58, 52, 50, 32, 71, 77, 84, 13, 10, 67, 111, 110, 116, 101, 110, 116, 45, 84, 121, 112, 101, 58, 32, 97, 112, 112, 108, 105, 99, 97, 116, 105, 111, 110, 47, 106, 115, 111, 110, 59, 32, 99, 104, 97, 114, 115, 101, 116, 61, 117, 116, 102, 45, 56, 13, 10, 84, 114, 97, 110, 115, 102, 101, 114, 45, 69, 110, 99, 111, 100, 105, 110, 103, 58, 32, 99, 104, 117, 110, 107, 101, 100, 13, 10, 67, 111, 110, 110, 101, 99, 116, 105, 111, 110, 58, 32, 99, 108, 111, 115, 101, 13, 10, 65, 99, 99, 101, 115, 115, 45, 67, 111, 110, 116, 114, 111, 108, 45, 65, 108, 108, 111, 119, 45, 79, 114, 105, 103, 105, 110, 58, 32, 42, 13, 10, 69, 84, 97, 103, 58, 32, 34, 50, 52, 49, 48, 51, 56, 99, 97, 49, 57, 102, 55, 52, 50, 48, 52, 55, 97, 101, 98, 100, 48, 48, 55, 57, 54, 98, 57, 55, 98, 57, 48, 34, 13, 10, 76, 97, 115, 116, 45, 77, 111, 100, 105, 102, 105, 101, 100, 58, 32, 84, 104, 117, 44, 32, 51, 49, 32, 68, 101, 99, 32, 50, 48, 49, 53, 32, 49, 49, 58, 49, 50, 58, 51, 54, 32, 80, 83, 84, 13, 10, 88, 45, 83, 79, 68, 65, 50, 45, 87, 97, 114, 110, 105, 110, 103, 58, 32, 88, 45, 83, 79, 68, 65, 50, 45, 70, 105, 101, 108, 100, 115, 44, 32, 88, 45, 83, 79, 68, 65, 50, 45, 84, 121, 112, 101, 115, 44, 32, 97, 110, 100, 32, 88, 45, 83, 79, 68, 65, 50, 45, 76, 101, 103, 97, 99, 121, 45, 84, 121, 112, 101, 115, 32, 97, 114, 101, 32, 100, 101, 112, 114, 101, 99, 97, 116, 101, 100, 13, 10, 88, 45, 83, 79, 68, 65, 50, 45, 70, 105, 101, 108, 100, 115, 58, 32, 91, 34, 105, 115, 95, 115, 117, 112, 112, 108, 105, 101, 114, 95, 112, 97, 114, 116, 105, 99, 105, 112, 97, 116, 105, 110, 103, 34, 44, 34, 117, 108, 116, 114, 97, 118, 105, 111, 108, 101, 116, 95, 108, 105, 103, 104, 116, 95, 100, 101, 118, 105, 99, 101, 115, 34, 44, 34, 118, 111, 105, 99, 101, 95, 112, 114, 111, 115, 116, 104, 101, 116, 105, 99, 115, 34, 44, 34, 99, 105, 116, 121, 34, 44, 34, 101, 120, 116, 101, 114, 110, 97, 108, 95, 105, 110, 102, 117, 115, 105, 111, 110, 95, 112, 117, 109, 112, 115, 95, 97, 110, 100, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 44, 34, 99, 111, 109, 109, 111, 100, 101, 115, 95, 117, 114, 105, 110, 97, 108, 115, 95, 98, 101, 100, 112, 97, 110, 115, 34, 44, 34, 115, 116, 97, 110, 100, 97, 114, 100, 95, 109, 111, 98, 105, 108, 105, 116, 121, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 95, 97, 110, 100, 95, 114, 101, 108, 97, 116, 101, 100, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 34, 44, 34, 104, 111, 115, 112, 105, 116, 97, 108, 95, 98, 101, 100, 115, 95, 97, 110, 100, 95, 114, 101, 108, 97, 116, 101, 100, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 34, 44, 34, 99, 97, 110, 101, 115, 95, 99, 114, 117, 116, 99, 104, 101, 115, 34, 44, 34, 111, 114, 116, 104, 111, 115, 101, 115, 95, 111, 102, 102, 95, 116, 104, 101, 95, 115, 104, 101, 108, 102, 34, 44, 34, 100, 121, 110, 97, 109, 105, 99, 95, 115, 112, 108, 105, 110, 116, 115, 34, 44, 34, 112, 114, 111, 115, 116, 104, 101, 116, 105, 99, 95, 108, 101, 110, 115, 101, 115, 95, 99, 111, 110, 118, 101, 110, 116, 105, 111, 110, 97, 108, 95, 99, 111, 110, 116, 97, 99, 116, 95, 108, 101, 110, 115, 101, 115, 34, 44, 34, 105, 110, 102, 114, 97, 114, 101, 100, 95, 104, 101, 97, 116, 105, 110, 103, 95, 112, 97, 100, 95, 115, 121, 115, 116, 101, 109, 115, 34, 44, 34, 104, 111, 115, 112, 105, 116, 97, 108, 95, 98, 101, 100, 115, 95, 109, 97, 110, 117, 97, 108, 34, 44, 34, 99, 112, 97, 112, 95, 100, 101, 118, 105, 99, 101, 115, 95, 114, 101, 115, 112, 105, 114, 97, 116, 111, 114, 121, 95, 97, 115, 115, 105, 115, 116, 95, 100, 101, 118, 105, 99, 101, 115, 95, 97, 110, 100, 95, 114, 101, 108, 97, 116, 101, 100, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 97, 110, 100, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 34, 44, 34, 111, 115, 116, 101, 111, 103, 101, 110, 101, 115, 105, 115, 95, 115, 116, 105, 109, 117, 108, 97, 116, 111, 114, 115, 34, 44, 34, 112, 97, 114, 101, 110, 116, 101, 114, 97, 108, 95, 110, 117, 116, 114, 105, 101, 110, 116, 115, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 44, 34, 98, 108, 111, 111, 100, 95, 103, 108, 117, 99, 111, 115, 101, 95, 109, 111, 110, 105, 116, 111, 114, 115, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 110, 111, 110, 95, 109, 97, 105, 108, 95, 111, 114, 100, 101, 114, 34, 44, 34, 115, 117, 112, 112, 111, 114, 116, 95, 115, 117, 114, 102, 97, 99, 101, 115, 95, 103, 114, 111, 117, 112, 95, 50, 95, 109, 97, 116, 116, 114, 101, 115, 115, 101, 115, 95, 97, 110, 100, 95, 111, 118, 101, 114, 108, 97, 121, 115, 34, 44, 34, 97, 100, 100, 114, 101, 115, 115, 95, 50, 34, 44, 34, 112, 97, 116, 105, 101, 110, 116, 95, 108, 105, 102, 116, 115, 34, 44, 34, 100, 98, 97, 95, 110, 97, 109, 101, 34, 44, 34, 111, 114, 116, 104, 111, 115, 101, 115, 95, 112, 114, 101, 102, 97, 98, 114, 105, 99, 97, 116, 101, 100, 34, 44, 34, 100, 105, 97, 98, 101, 116, 105, 99, 95, 115, 104, 111, 101, 115, 95, 105, 110, 115, 101, 114, 116, 115, 95, 99, 117, 115, 116, 111, 109, 95, 102, 97, 98, 114, 105, 99, 97, 116, 101, 100, 34, 44, 34, 115, 101, 97, 116, 95, 108, 105, 102, 116, 95, 109, 101, 99, 104, 97, 110, 105, 115, 109, 115, 34, 44, 34, 99, 111, 109, 112, 101, 116, 105, 116, 105, 118, 101, 95, 98, 105, 100, 95, 115, 101, 114, 118, 105, 99, 101, 95, 97, 114, 101, 97, 34, 44, 34, 112, 111, 119, 101, 114, 95, 111, 112, 101, 114, 97, 116, 101, 100, 95, 118, 101, 104, 105, 99, 108, 101, 115, 95, 115, 99, 111, 111, 116, 101, 114, 115, 34, 44, 34, 119, 104, 101, 101, 108, 99, 104, 97, 105, 114, 115, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 95, 115, 116, 97, 110, 100, 97, 114, 100, 95, 109, 97, 110, 117, 97, 108, 95, 112, 101, 100, 105, 97, 116, 114, 105, 99, 115, 34, 44, 34, 115, 117, 112, 112, 111, 114, 116, 95, 115, 117, 114, 102, 97, 99, 101, 115, 95, 112, 114, 101, 115, 115, 117, 114, 101, 95, 114, 101, 100, 117, 99, 105, 110, 103, 95, 98, 101, 100, 115, 95, 109, 97, 116, 116, 114, 101, 115, 115, 101, 115, 95, 111, 118, 101, 114, 108, 97, 121, 115, 95, 112, 97, 100, 115, 34, 44, 34, 122, 105, 112, 95, 112, 108, 117, 115, 95, 52, 34, 44, 34, 103, 97, 115, 116, 114, 105, 99, 95, 115, 117, 99, 116, 105, 111, 110, 95, 112, 117, 109, 112, 115, 34, 44, 34, 105, 110, 102, 117, 115, 105, 111, 110, 95, 112, 117, 109, 112, 115, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 105, 110, 115, 117, 108, 105, 110, 95, 105, 110, 102, 117, 115, 105, 111, 110, 34, 44, 34, 58, 99, 114, 101, 97, 116, 101, 100, 95, 97, 116, 34, 44, 34, 105, 110, 102, 117, 115, 105, 111, 110, 95, 112, 117, 109, 112, 115, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 105, 109, 112, 108, 97, 110, 116, 101, 100, 95, 105, 110, 102, 117, 115, 105, 111, 110, 34, 44, 34, 110, 101, 117, 114, 111, 115, 116, 105, 109, 117, 108, 97, 116, 111, 114, 115, 34, 44, 34, 105, 110, 102, 117, 115, 105, 111, 110, 95, 112, 117, 109, 112, 115, 95, 105, 109, 112, 108, 97, 110, 116, 97, 98, 108, 101, 95, 97, 110, 100, 95, 117, 110, 105, 110, 116, 101, 114, 114, 117, 112, 116, 101, 100, 34, 44, 34, 104, 101, 109, 111, 100, 105, 97, 108, 121, 115, 105, 115, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 44, 34, 116, 114, 97, 110, 115, 99, 117, 116, 97, 110, 101, 111, 117, 115, 95, 101, 108, 101, 99, 116, 114, 105, 99, 97, 108, 95, 110, 101, 114, 118, 101, 95, 115, 116, 105, 109, 117, 108, 97, 116, 111, 114, 115, 95, 116, 101, 110, 115, 95, 117, 110, 105, 116, 115, 34, 44, 34, 108, 105, 109, 98, 95, 112, 114, 111, 115, 116, 104, 101, 115, 101, 115, 34, 44, 34, 109, 101, 99, 104, 97, 110, 105, 99, 97, 108, 95, 105, 110, 95, 101, 120, 115, 117, 102, 102, 108, 97, 116, 105, 111, 110, 95, 100, 101, 118, 105, 99, 101, 115, 34, 44, 34, 105, 110, 116, 114, 97, 112, 117, 108, 109, 111, 110, 97, 114, 121, 95, 112, 101, 114, 99, 117, 115, 115, 105, 118, 101, 95, 118, 101, 110, 116, 105, 108, 97, 116, 105, 111, 110, 95, 100, 101, 118, 105, 99, 101, 115, 34, 44, 34, 104, 105, 103, 104, 95, 102, 114, 101, 113, 117, 101, 110, 99, 121, 95, 99, 104, 101, 115, 116, 95, 119, 97, 108, 108, 95, 111, 115, 99, 105, 108, 108, 97, 116, 105, 111, 110, 95, 104, 102, 99, 119, 111, 95, 100, 101, 118, 105, 99, 101, 115, 34, 44, 34, 105, 110, 102, 117, 115, 105, 111, 110, 95, 112, 117, 109, 112, 115, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 101, 120, 116, 101, 114, 110, 97, 108, 95, 105, 110, 102, 117, 115, 105, 111, 110, 34, 44, 34, 101, 110, 116, 101, 114, 97, 108, 95, 110, 117, 116, 114, 105, 101, 110, 116, 115, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 95, 97, 110, 100, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 44, 34, 112, 110, 101, 117, 109, 97, 116, 105, 99, 95, 99, 111, 109, 112, 114, 101, 115, 115, 105, 111, 110, 95, 100, 101, 118, 105, 99, 101, 115, 34, 44, 34, 104, 111, 109, 101, 95, 100, 105, 97, 108, 121, 115, 105, 115, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 44, 34, 119, 104, 101, 101, 108, 99, 104, 97, 105, 114, 115, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 95, 115, 116, 97, 110, 100, 97, 114, 100, 95, 109, 97, 110, 117, 97, 108, 34, 44, 34, 102, 97, 99, 105, 97, 108, 95, 112, 114, 111, 115, 116, 104, 101, 115, 101, 115, 34, 44, 34, 101, 121, 101, 95, 112, 114, 111, 115, 116, 104, 101, 115, 101, 115, 34, 44, 34, 58, 105, 100, 34, 44, 34, 97, 117, 116, 111, 109, 97, 116, 105, 99, 95, 101, 120, 116, 101, 114, 110, 97, 108, 95, 100, 101, 102, 105, 98, 114, 105, 108, 108, 97, 116, 111, 114, 115, 95, 97, 101, 100, 115, 34, 44, 34, 98, 108, 111, 111, 100, 95, 103, 108, 117, 99, 111, 115, 101, 95, 109, 111, 110, 105, 116, 111, 114, 115, 95, 109, 97, 105, 108, 95, 111, 114, 100, 101, 114, 34, 44, 34, 112, 104, 111, 110, 101, 34, 44, 34, 119, 97, 108, 107, 101, 114, 115, 95, 97, 110, 100, 95, 114, 101, 108, 97, 116, 101, 100, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 34, 44, 34, 111, 120, 121, 103, 101, 110, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 97, 110, 100, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 34, 44, 34, 101, 110, 116, 101, 114, 97, 108, 95, 110, 117, 116, 114, 105, 101, 110, 116, 115, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 44, 34, 110, 101, 98, 117, 108, 105, 122, 101, 114, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 95, 117, 108, 116, 114, 97, 115, 111, 110, 105, 99, 95, 97, 110, 100, 95, 99, 111, 110, 116, 114, 111, 108, 108, 101, 100, 95, 100, 111, 115, 101, 34, 44, 34, 99, 111, 109, 112, 97, 110, 121, 95, 110, 97, 109, 101, 34, 44, 34, 119, 104, 101, 101, 108, 99, 104, 97, 105, 114, 115, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 95, 99, 111, 109, 112, 108, 101, 120, 95, 114, 101, 104, 97, 98, 105, 108, 105, 116, 97, 116, 105, 118, 101, 95, 109, 97, 110, 117, 97, 108, 34, 44, 34, 112, 114, 111, 115, 116, 104, 101, 116, 105, 99, 95, 108, 101, 110, 115, 101, 115, 95, 112, 114, 111, 115, 116, 104, 101, 116, 105, 99, 95, 99, 97, 116, 97, 114, 97, 99, 116, 95, 108, 101, 110, 115, 101, 115, 34, 44, 34, 114, 101, 115, 112, 105, 114, 97, 116, 111, 114, 121, 95, 115, 117, 99, 116, 105, 111, 110, 95, 112, 117, 109, 112, 115, 34, 44, 34, 110, 101, 117, 114, 111, 109, 117, 115, 99, 117, 108, 97, 114, 95, 101, 108, 101, 99, 116, 114, 105, 99, 97, 108, 95, 115, 116, 105, 109, 117, 108, 97, 116, 111, 114, 115, 95, 110, 109, 101, 115, 34, 44, 34, 119, 97, 108, 107, 101, 114, 115, 34, 44, 34, 119, 104, 101, 101, 108, 99, 104, 97, 105, 114, 115, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 95, 115, 116, 97, 110, 100, 97, 114, 100, 95, 112, 111, 119, 101, 114, 95, 112, 101, 100, 105, 97, 116, 114, 105, 99, 115, 34, 44, 34, 114, 101, 115, 112, 105, 114, 97, 116, 111, 114, 121, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 95, 114, 101, 108, 97, 116, 101, 100, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 97, 110, 100, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 34, 44, 34, 110, 101, 98, 117, 108, 105, 122, 101, 114, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 44, 34, 110, 101, 103, 97, 116, 105, 118, 101, 95, 112, 114, 101, 115, 115, 117, 114, 101, 95, 119, 111, 117, 110, 100, 95, 116, 104, 101, 114, 97, 112, 121, 95, 112, 117, 109, 112, 115, 95, 97, 110, 100, 95, 114, 101, 108, 97, 116, 101, 100, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 97, 110, 100, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 34, 44, 34, 119, 104, 101, 101, 108, 99, 104, 97, 105, 114, 95, 115, 101, 97, 116, 105, 110, 103, 95, 99, 117, 115, 104, 105, 111, 110, 115, 95, 115, 107, 105, 110, 95, 112, 114, 111, 116, 101, 99, 116, 105, 110, 103, 34, 44, 34, 118, 101, 110, 116, 105, 108, 97, 116, 111, 114, 115, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 44, 34, 119, 104, 101, 101, 108, 99, 104, 97, 105, 114, 95, 115, 101, 97, 116, 105, 110, 103, 95, 99, 117, 115, 104, 105, 111, 110, 115, 34, 44, 34, 99, 112, 97, 112, 95, 97, 110, 100, 95, 114, 97, 100, 115, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 101, 95, 103, 95, 99, 111, 109, 98, 105, 110, 97, 116, 105, 111, 110, 95, 109, 97, 115, 107, 115, 34, 44, 34, 99, 112, 97, 112, 95, 114, 97, 100, 115, 95, 114, 101, 108, 97, 116, 101, 100, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 34, 44, 34, 117, 114, 111, 108, 111, 103, 105, 99, 97, 108, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 44, 34, 98, 108, 111, 111, 100, 95, 103, 108, 117, 99, 111, 115, 101, 95, 109, 111, 110, 105, 116, 111, 114, 115, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 109, 97, 105, 108, 95, 111, 114, 100, 101, 114, 34, 44, 34, 116, 114, 97, 99, 116, 105, 111, 110, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 34, 44, 34, 105, 110, 116, 101, 114, 109, 105, 116, 116, 101, 110, 116, 95, 112, 111, 115, 105, 116, 105, 118, 101, 95, 112, 114, 101, 115, 115, 117, 114, 101, 95, 98, 114, 101, 97, 116, 104, 105, 110, 103, 95, 105, 112, 112, 98, 95, 100, 101, 118, 105, 99, 101, 115, 34, 44, 34, 110, 101, 103, 97, 116, 105, 118, 101, 95, 112, 114, 101, 115, 115, 117, 114, 101, 95, 119, 111, 117, 110, 100, 95, 116, 104, 101, 114, 97, 112, 121, 95, 112, 117, 109, 112, 115, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 44, 34, 115, 116, 97, 116, 101, 34, 44, 34, 103, 101, 110, 101, 114, 97, 108, 95, 104, 111, 109, 101, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 95, 97, 110, 100, 95, 114, 101, 108, 97, 116, 101, 100, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 97, 110, 100, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 34, 44, 34, 111, 114, 116, 104, 111, 115, 101, 115, 95, 99, 117, 115, 116, 111, 109, 95, 102, 97, 98, 114, 105, 99, 97, 116, 101, 100, 34, 44, 34, 119, 104, 101, 101, 108, 99, 104, 97, 105, 114, 115, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 95, 99, 111, 109, 112, 108, 101, 120, 95, 114, 101, 104, 97, 98, 105, 108, 105, 116, 97, 116, 105, 118, 101, 95, 112, 111, 119, 101, 114, 34, 44, 34, 111, 115, 116, 111, 109, 121, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 44, 34, 104, 111, 115, 112, 105, 116, 97, 108, 95, 98, 101, 100, 115, 95, 109, 97, 110, 117, 97, 108, 95, 112, 101, 100, 105, 97, 116, 114, 105, 99, 34, 44, 34, 104, 111, 115, 112, 105, 116, 97, 108, 95, 98, 101, 100, 115, 95, 101, 108, 101, 99, 116, 114, 105, 99, 34, 44, 34, 99, 111, 110, 116, 105, 110, 117, 111, 117, 115, 95, 112, 97, 115, 115, 105, 118, 101, 95, 109, 111, 116, 105, 111, 110, 95, 99, 112, 109, 95, 100, 101, 118, 105, 99, 101, 115, 34, 44, 34, 119, 104, 101, 101, 108, 99, 104, 97, 105, 114, 115, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 95, 115, 116, 97, 110, 100, 97, 114, 100, 95, 112, 111, 119, 101, 114, 34, 44, 34, 98, 114, 101, 97, 115, 116, 95, 112, 114, 111, 115, 116, 104, 101, 115, 101, 115, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 34, 44, 34, 122, 105, 112, 34, 44, 34, 115, 116, 97, 110, 100, 97, 114, 100, 95, 112, 111, 119, 101, 114, 95, 109, 97, 110, 117, 97, 108, 95, 119, 104, 101, 101, 108, 99, 104, 97, 105, 114, 115, 95, 115, 99, 111, 111, 116, 101, 114, 115, 95, 97, 110, 100, 95, 114, 101, 108, 97, 116, 101, 100, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 34, 44, 34, 115, 117, 112, 112, 111, 114, 116, 95, 115, 117, 114, 102, 97, 99, 101, 115, 34, 44, 34, 58, 117, 112, 100, 97, 116, 101, 100, 95, 97, 116, 34, 44, 34, 116, 114, 97, 99, 104, 101, 111, 115, 116, 111, 109, 121, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 44, 34, 111, 120, 121, 103, 101, 110, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 44, 34, 111, 99, 117, 108, 97, 114, 95, 112, 114, 111, 115, 116, 104, 101, 115, 101, 115, 34, 44, 34, 109, 97, 105, 108, 95, 111, 114, 100, 101, 114, 95, 100, 105, 97, 98, 101, 116, 105, 99, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 44, 34, 115, 117, 114, 103, 105, 99, 97, 108, 95, 100, 114, 101, 115, 115, 105, 110, 103, 115, 34, 44, 34, 119, 104, 101, 101, 108, 99, 104, 97, 105, 114, 115, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 95, 99, 111, 109, 112, 108, 101, 120, 95, 114, 101, 104, 97, 98, 105, 108, 105, 116, 97, 116, 105, 118, 101, 95, 112, 111, 119, 101, 114, 95, 101, 95, 103, 95, 103, 114, 111, 117, 112, 95, 51, 95, 103, 114, 111, 117, 112, 95, 52, 95, 103, 114, 111, 117, 112, 95, 53, 34, 44, 34, 115, 111, 109, 97, 116, 105, 99, 95, 112, 114, 111, 115, 116, 104, 101, 115, 101, 115, 34, 44, 34, 104, 111, 115, 112, 105, 116, 97, 108, 95, 98, 101, 100, 115, 95, 116, 111, 116, 97, 108, 95, 101, 108, 101, 99, 116, 114, 105, 99, 95, 112, 101, 100, 105, 97, 116, 114, 105, 99, 34, 44, 34, 104, 101, 97, 116, 95, 99, 111, 108, 100, 95, 97, 112, 112, 108, 105, 99, 97, 116, 105, 111, 110, 115, 34, 44, 34, 97, 100, 100, 114, 101, 115, 115, 34, 44, 34, 101, 110, 116, 101, 114, 97, 108, 95, 110, 117, 116, 114, 105, 101, 110, 116, 115, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 102, 111, 114, 95, 115, 112, 101, 99, 105, 97, 108, 95, 109, 101, 116, 97, 98, 111, 108, 105, 99, 95, 110, 101, 101, 100, 115, 95, 97, 110, 100, 95, 112, 101, 100, 105, 97, 116, 114, 105, 99, 115, 34, 44, 34, 105, 110, 118, 97, 115, 105, 118, 101, 95, 109, 101, 99, 104, 97, 110, 105, 99, 97, 108, 95, 118, 101, 110, 116, 105, 108, 97, 116, 105, 111, 110, 34, 44, 34, 112, 114, 111, 115, 116, 104, 101, 116, 105, 99, 95, 108, 101, 110, 115, 101, 115, 95, 99, 111, 110, 118, 101, 110, 116, 105, 111, 110, 97, 108, 95, 101, 121, 101, 103, 108, 97, 115, 115, 101, 115, 34, 44, 34, 99, 111, 99, 104, 108, 101, 97, 114, 95, 105, 109, 112, 108, 97, 110, 116, 115, 34, 44, 34, 100, 105, 97, 98, 101, 116, 105, 99, 95, 115, 104, 111, 101, 115, 95, 105, 110, 115, 101, 114, 116, 115, 95, 112, 114, 101, 102, 97, 98, 114, 105, 99, 97, 116, 101, 100, 34, 44, 34, 115, 112, 101, 101, 99, 104, 95, 103, 101, 110, 101, 114, 97, 116, 105, 110, 103, 95, 100, 101, 118, 105, 99, 101, 115, 34, 93, 13, 10])\nTRACE:hyper::http::h1: Response.try_parse([Header; 100], [u8; 4096])\nTRACE:hyper::buffer: reserved 28672\nTRACE:hyper::buffer: read_into_buf buf[4096..32768]\nTRACE:hyper::buffer: get_buf [u8; 32768][0..10335]\nTRACE:hyper::http::h1: try_parse([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 88, 45, 83, 79, 68, 65, 50, 45, 84, 121, 112, 101, 115, 58, 32, 91, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 116, 101, 120, 116, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 116, 101, 120, 116, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 116, 101, 120, 116, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 116, 101, 120, 116, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 110, 117, 109, 98, 101, 114, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 109, 101, 116, 97, 95, 100, 97, 116, 97, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 109, 101, 116, 97, 95, 100, 97, 116, 97, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 116, 101, 120, 116, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 116, 101, 120, 116, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 116, 101, 120, 116, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 116, 101, 120, 116, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 109, 101, 116, 97, 95, 100, 97, 116, 97, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 116, 101, 120, 116, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 44, 34, 99, 104, 101, 99, 107, 98, 111, 120, 34, 93, 13, 10, 88, 45, 83, 79, 68, 65, 50, 45, 76, 101, 103, 97, 99, 121, 45, 84, 121, 112, 101, 115, 58, 32, 116, 114, 117, 101, 13, 10, 88, 45, 83, 111, 99, 114, 97, 116, 97, 45, 82, 101, 103, 105, 111, 110, 58, 32, 112, 114, 111, 100, 117, 99, 116, 105, 111, 110, 13, 10, 65, 103, 101, 58, 32, 48, 13, 10, 13, 10, 49, 51, 56, 54, 13, 10, 91, 32, 123, 10, 32, 32, 34, 105, 115, 95, 115, 117, 112, 112, 108, 105, 101, 114, 95, 112, 97, 114, 116, 105, 99, 105, 112, 97, 116, 105, 110, 103, 34, 32, 58, 32, 116, 114, 117, 101, 44, 10, 32, 32, 34, 117, 108, 116, 114, 97, 118, 105, 111, 108, 101, 116, 95, 108, 105, 103, 104, 116, 95, 100, 101, 118, 105, 99, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 118, 111, 105, 99, 101, 95, 112, 114, 111, 115, 116, 104, 101, 116, 105, 99, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 99, 105, 116, 121, 34, 32, 58, 32, 34, 65, 78, 67, 72, 79, 82, 65, 71, 69, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 34, 44, 10, 32, 32, 34, 101, 120, 116, 101, 114, 110, 97, 108, 95, 105, 110, 102, 117, 115, 105, 111, 110, 95, 112, 117, 109, 112, 115, 95, 97, 110, 100, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 99, 111, 109, 109, 111, 100, 101, 115, 95, 117, 114, 105, 110, 97, 108, 115, 95, 98, 101, 100, 112, 97, 110, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 104, 111, 115, 112, 105, 116, 97, 108, 95, 98, 101, 100, 115, 95, 97, 110, 100, 95, 114, 101, 108, 97, 116, 101, 100, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 115, 116, 97, 110, 100, 97, 114, 100, 95, 109, 111, 98, 105, 108, 105, 116, 121, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 95, 97, 110, 100, 95, 114, 101, 108, 97, 116, 101, 100, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 99, 97, 110, 101, 115, 95, 99, 114, 117, 116, 99, 104, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 111, 114, 116, 104, 111, 115, 101, 115, 95, 111, 102, 102, 95, 116, 104, 101, 95, 115, 104, 101, 108, 102, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 100, 121, 110, 97, 109, 105, 99, 95, 115, 112, 108, 105, 110, 116, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 112, 114, 111, 115, 116, 104, 101, 116, 105, 99, 95, 108, 101, 110, 115, 101, 115, 95, 99, 111, 110, 118, 101, 110, 116, 105, 111, 110, 97, 108, 95, 99, 111, 110, 116, 97, 99, 116, 95, 108, 101, 110, 115, 101, 115, 34, 32, 58, 32, 116, 114, 117, 101, 44, 10, 32, 32, 34, 105, 110, 102, 114, 97, 114, 101, 100, 95, 104, 101, 97, 116, 105, 110, 103, 95, 112, 97, 100, 95, 115, 121, 115, 116, 101, 109, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 104, 111, 115, 112, 105, 116, 97, 108, 95, 98, 101, 100, 115, 95, 109, 97, 110, 117, 97, 108, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 99, 112, 97, 112, 95, 100, 101, 118, 105, 99, 101, 115, 95, 114, 101, 115, 112, 105, 114, 97, 116, 111, 114, 121, 95, 97, 115, 115, 105, 115, 116, 95, 100, 101, 118, 105, 99, 101, 115, 95, 97, 110, 100, 95, 114, 101, 108, 97, 116, 101, 100, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 97, 110, 100, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 111, 115, 116, 101, 111, 103, 101, 110, 101, 115, 105, 115, 95, 115, 116, 105, 109, 117, 108, 97, 116, 111, 114, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 112, 97, 114, 101, 110, 116, 101, 114, 97, 108, 95, 110, 117, 116, 114, 105, 101, 110, 116, 115, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 98, 108, 111, 111, 100, 95, 103, 108, 117, 99, 111, 115, 101, 95, 109, 111, 110, 105, 116, 111, 114, 115, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 110, 111, 110, 95, 109, 97, 105, 108, 95, 111, 114, 100, 101, 114, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 115, 117, 112, 112, 111, 114, 116, 95, 115, 117, 114, 102, 97, 99, 101, 115, 95, 103, 114, 111, 117, 112, 95, 50, 95, 109, 97, 116, 116, 114, 101, 115, 115, 101, 115, 95, 97, 110, 100, 95, 111, 118, 101, 114, 108, 97, 121, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 97, 100, 100, 114, 101, 115, 115, 95, 50, 34, 32, 58, 32, 34, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 34, 44, 10, 32, 32, 34, 112, 97, 116, 105, 101, 110, 116, 95, 108, 105, 102, 116, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 100, 98, 97, 95, 110, 97, 109, 101, 34, 32, 58, 32, 34, 65, 76, 65, 83, 75, 65, 32, 69, 89, 69, 32, 67, 65, 82, 69, 32, 67, 69, 78, 84, 69, 82, 83, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 34, 44, 10, 32, 32, 34, 111, 114, 116, 104, 111, 115, 101, 115, 95, 112, 114, 101, 102, 97, 98, 114, 105, 99, 97, 116, 101, 100, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 100, 105, 97, 98, 101, 116, 105, 99, 95, 115, 104, 111, 101, 115, 95, 105, 110, 115, 101, 114, 116, 115, 95, 99, 117, 115, 116, 111, 109, 95, 102, 97, 98, 114, 105, 99, 97, 116, 101, 100, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 115, 101, 97, 116, 95, 108, 105, 102, 116, 95, 109, 101, 99, 104, 97, 110, 105, 115, 109, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 112, 111, 119, 101, 114, 95, 111, 112, 101, 114, 97, 116, 101, 100, 95, 118, 101, 104, 105, 99, 108, 101, 115, 95, 115, 99, 111, 111, 116, 101, 114, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 119, 104, 101, 101, 108, 99, 104, 97, 105, 114, 115, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 95, 115, 116, 97, 110, 100, 97, 114, 100, 95, 109, 97, 110, 117, 97, 108, 95, 112, 101, 100, 105, 97, 116, 114, 105, 99, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 115, 117, 112, 112, 111, 114, 116, 95, 115, 117, 114, 102, 97, 99, 101, 115, 95, 112, 114, 101, 115, 115, 117, 114, 101, 95, 114, 101, 100, 117, 99, 105, 110, 103, 95, 98, 101, 100, 115, 95, 109, 97, 116, 116, 114, 101, 115, 115, 101, 115, 95, 111, 118, 101, 114, 108, 97, 121, 115, 95, 112, 97, 100, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 103, 97, 115, 116, 114, 105, 99, 95, 115, 117, 99, 116, 105, 111, 110, 95, 112, 117, 109, 112, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 105, 110, 102, 117, 115, 105, 111, 110, 95, 112, 117, 109, 112, 115, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 105, 110, 115, 117, 108, 105, 110, 95, 105, 110, 102, 117, 115, 105, 111, 110, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 105, 110, 102, 117, 115, 105, 111, 110, 95, 112, 117, 109, 112, 115, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 105, 109, 112, 108, 97, 110, 116, 101, 100, 95, 105, 110, 102, 117, 115, 105, 111, 110, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 110, 101, 117, 114, 111, 115, 116, 105, 109, 117, 108, 97, 116, 111, 114, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 105, 110, 102, 117, 115, 105, 111, 110, 95, 112, 117, 109, 112, 115, 95, 105, 109, 112, 108, 97, 110, 116, 97, 98, 108, 101, 95, 97, 110, 100, 95, 117, 110, 105, 110, 116, 101, 114, 114, 117, 112, 116, 101, 100, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 104, 101, 109, 111, 100, 105, 97, 108, 121, 115, 105, 115, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 116, 114, 97, 110, 115, 99, 117, 116, 97, 110, 101, 111, 117, 115, 95, 101, 108, 101, 99, 116, 114, 105, 99, 97, 108, 95, 110, 101, 114, 118, 101, 95, 115, 116, 105, 109, 117, 108, 97, 116, 111, 114, 115, 95, 116, 101, 110, 115, 95, 117, 110, 105, 116, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 108, 105, 109, 98, 95, 112, 114, 111, 115, 116, 104, 101, 115, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 109, 101, 99, 104, 97, 110, 105, 99, 97, 108, 95, 105, 110, 95, 101, 120, 115, 117, 102, 102, 108, 97, 116, 105, 111, 110, 95, 100, 101, 118, 105, 99, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 105, 110, 116, 114, 97, 112, 117, 108, 109, 111, 110, 97, 114, 121, 95, 112, 101, 114, 99, 117, 115, 115, 105, 118, 101, 95, 118, 101, 110, 116, 105, 108, 97, 116, 105, 111, 110, 95, 100, 101, 118, 105, 99, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 104, 105, 103, 104, 95, 102, 114, 101, 113, 117, 101, 110, 99, 121, 95, 99, 104, 101, 115, 116, 95, 119, 97, 108, 108, 95, 111, 115, 99, 105, 108, 108, 97, 116, 105, 111, 110, 95, 104, 102, 99, 119, 111, 95, 100, 101, 118, 105, 99, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 105, 110, 102, 117, 115, 105, 111, 110, 95, 112, 117, 109, 112, 115, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 101, 120, 116, 101, 114, 110, 97, 108, 95, 105, 110, 102, 117, 115, 105, 111, 110, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 101, 110, 116, 101, 114, 97, 108, 95, 110, 117, 116, 114, 105, 101, 110, 116, 115, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 95, 97, 110, 100, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 112, 110, 101, 117, 109, 97, 116, 105, 99, 95, 99, 111, 109, 112, 114, 101, 115, 115, 105, 111, 110, 95, 100, 101, 118, 105, 99, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 104, 111, 109, 101, 95, 100, 105, 97, 108, 121, 115, 105, 115, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 119, 104, 101, 101, 108, 99, 104, 97, 105, 114, 115, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 95, 115, 116, 97, 110, 100, 97, 114, 100, 95, 109, 97, 110, 117, 97, 108, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 102, 97, 99, 105, 97, 108, 95, 112, 114, 111, 115, 116, 104, 101, 115, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 101, 121, 101, 95, 112, 114, 111, 115, 116, 104, 101, 115, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 97, 117, 116, 111, 109, 97, 116, 105, 99, 95, 101, 120, 116, 101, 114, 110, 97, 108, 95, 100, 101, 102, 105, 98, 114, 105, 108, 108, 97, 116, 111, 114, 115, 95, 97, 101, 100, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 98, 108, 111, 111, 100, 95, 103, 108, 117, 99, 111, 115, 101, 95, 109, 111, 110, 105, 116, 111, 114, 115, 95, 109, 97, 105, 108, 95, 111, 114, 100, 101, 114, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 112, 104, 111, 110, 101, 34, 32, 58, 32, 34, 40, 57, 48, 55, 41, 50, 55, 50, 45, 50, 53, 53, 55, 34, 44, 10, 32, 32, 34, 119, 97, 108, 107, 101, 114, 115, 95, 97, 110, 100, 95, 114, 101, 108, 97, 116, 101, 100, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 111, 120, 121, 103, 101, 110, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 97, 110, 100, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 101, 110, 116, 101, 114, 97, 108, 95, 110, 117, 116, 114, 105, 101, 110, 116, 115, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 110, 101, 98, 117, 108, 105, 122, 101, 114, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 95, 117, 108, 116, 114, 97, 115, 111, 110, 105, 99, 95, 97, 110, 100, 95, 99, 111, 110, 116, 114, 111, 108, 108, 101, 100, 95, 100, 111, 115, 101, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 99, 111, 109, 112, 97, 110, 121, 95, 110, 97, 109, 101, 34, 32, 58, 32, 34, 65, 76, 65, 83, 75, 65, 32, 69, 89, 69, 32, 67, 65, 82, 69, 32, 67, 69, 78, 84, 69, 82, 83, 32, 65, 32, 80, 82, 79, 70, 69, 83, 83, 73, 79, 78, 65, 76, 32, 67, 79, 82, 80, 79, 82, 65, 84, 73, 79, 78, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 34, 44, 10, 32, 32, 34, 119, 104, 101, 101, 108, 99, 104, 97, 105, 114, 115, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 95, 99, 111, 109, 112, 108, 101, 120, 95, 114, 101, 104, 97, 98, 105, 108, 105, 116, 97, 116, 105, 118, 101, 95, 109, 97, 110, 117, 97, 108, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 112, 114, 111, 115, 116, 104, 101, 116, 105, 99, 95, 108, 101, 110, 115, 101, 115, 95, 112, 114, 111, 115, 116, 104, 101, 116, 105, 99, 95, 99, 97, 116, 97, 114, 97, 99, 116, 95, 108, 101, 110, 115, 101, 115, 34, 32, 58, 32, 116, 114, 117, 101, 44, 10, 32, 32, 34, 114, 101, 115, 112, 105, 114, 97, 116, 111, 114, 121, 95, 115, 117, 99, 116, 105, 111, 110, 95, 112, 117, 109, 112, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 110, 101, 117, 114, 111, 109, 117, 115, 99, 117, 108, 97, 114, 95, 101, 108, 101, 99, 116, 114, 105, 99, 97, 108, 95, 115, 116, 105, 109, 117, 108, 97, 116, 111, 114, 115, 95, 110, 109, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 119, 97, 108, 107, 101, 114, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 119, 104, 101, 101, 108, 99, 104, 97, 105, 114, 115, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 95, 115, 116, 97, 110, 100, 97, 114, 100, 95, 112, 111, 119, 101, 114, 95, 112, 101, 100, 105, 97, 116, 114, 105, 99, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 114, 101, 115, 112, 105, 114, 97, 116, 111, 114, 121, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 95, 114, 101, 108, 97, 116, 101, 100, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 97, 110, 100, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 110, 101, 98, 117, 108, 105, 122, 101, 114, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 110, 101, 103, 97, 116, 105, 118, 101, 95, 112, 114, 101, 115, 115, 117, 114, 101, 95, 119, 111, 117, 110, 100, 95, 116, 104, 101, 114, 97, 112, 121, 95, 112, 117, 109, 112, 115, 95, 97, 110, 100, 95, 114, 101, 108, 97, 116, 101, 100, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 97, 110, 100, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 119, 104, 101, 101, 108, 99, 104, 97, 105, 114, 95, 115, 101, 97, 116, 105, 110, 103, 95, 99, 117, 115, 104, 105, 111, 110, 115, 95, 115, 107, 105, 110, 95, 112, 114, 111, 116, 101, 99, 116, 105, 110, 103, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 118, 101, 110, 116, 105, 108, 97, 116, 111, 114, 115, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 119, 104, 101, 101, 108, 99, 104, 97, 105, 114, 95, 115, 101, 97, 116, 105, 110, 103, 95, 99, 117, 115, 104, 105, 111, 110, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 99, 112, 97, 112, 95, 97, 110, 100, 95, 114, 97, 100, 115, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 101, 95, 103, 95, 99, 111, 109, 98, 105, 110, 97, 116, 105, 111, 110, 95, 109, 97, 115, 107, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 99, 112, 97, 112, 95, 114, 97, 100, 115, 95, 114, 101, 108, 97, 116, 101, 100, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 117, 114, 111, 108, 111, 103, 105, 99, 97, 108, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 98, 108, 111, 111, 100, 95, 103, 108, 117, 99, 111, 115, 101, 95, 109, 111, 110, 105, 116, 111, 114, 115, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 109, 97, 105, 108, 95, 111, 114, 100, 101, 114, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 116, 114, 97, 99, 116, 105, 111, 110, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 105, 110, 116, 101, 114, 109, 105, 116, 116, 101, 110, 116, 95, 112, 111, 115, 105, 116, 105, 118, 101, 95, 112, 114, 101, 115, 115, 117, 114, 101, 95, 98, 114, 101, 97, 116, 104, 105, 110, 103, 95, 105, 112, 112, 98, 95, 100, 101, 118, 105, 99, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 110, 101, 103, 97, 116, 105, 118, 101, 95, 112, 114, 101, 115, 115, 117, 114, 101, 95, 119, 111, 117, 110, 100, 95, 116, 104, 101, 114, 97, 112, 121, 95, 112, 117, 109, 112, 115, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 115, 116, 97, 116, 101, 34, 32, 58, 32, 34, 65, 75, 34, 44, 10, 32, 32, 34, 103, 101, 110, 101, 114, 97, 108, 95, 104, 111, 109, 101, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 95, 97, 110, 100, 95, 114, 101, 108, 97, 116, 101, 100, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 97, 110, 100, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 111, 114, 116, 104, 111, 115, 101, 115, 95, 99, 117, 115, 116, 111, 109, 95, 102, 97, 98, 114, 105, 99, 97, 116, 101, 100, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 119, 104, 101, 101, 108, 99, 104, 97, 105, 114, 115, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 95, 99, 111, 109, 112, 108, 101, 120, 95, 114, 101, 104, 97, 98, 105, 108, 105, 116, 97, 116, 105, 118, 101, 95, 112, 111, 119, 101, 114, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 111, 115, 116, 111, 109, 121, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 104, 111, 115, 112, 105, 116, 97, 108, 95, 98, 101, 100, 115, 95, 109, 97, 110, 117, 97, 108, 95, 112, 101, 100, 105, 97, 116, 114, 105, 99, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 104, 111, 115, 112, 105, 116, 97, 108, 95, 98, 101, 100, 115, 95, 101, 108, 101, 99, 116, 114, 105, 99, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 99, 111, 110, 116, 105, 110, 117, 111, 117, 115, 95, 112, 97, 115, 115, 105, 118, 101, 95, 109, 111, 116, 105, 111, 110, 95, 99, 112, 109, 95, 100, 101, 118, 105, 99, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 119, 104, 101, 101, 108, 99, 104, 97, 105, 114, 115, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 95, 115, 116, 97, 110, 100, 97, 114, 100, 95, 112, 111, 119, 101, 114, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 98, 114, 101, 97, 115, 116, 95, 112, 114, 111, 115, 116, 104, 101, 115, 101, 115, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 122, 105, 112, 34, 32, 58, 32, 34, 57, 57, 53, 48, 49, 34, 44, 10, 32, 32, 34, 115, 116, 97, 110, 100, 97, 114, 100, 95, 112, 111, 119, 101, 114, 95, 109, 97, 110, 117, 97, 108, 95, 119, 104, 101, 101, 108, 99, 104, 97, 105, 114, 115, 95, 115, 99, 111, 111, 116, 101, 114, 115, 95, 97, 110, 100, 95, 114, 101, 108, 97, 116, 101, 100, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 115, 117, 112, 112, 111, 114, 116, 95, 115, 117, 114, 102, 97, 99, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 116, 114, 97, 99, 104, 101, 111, 115, 116, 111, 109, 121, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 111, 120, 121, 103, 101, 110, 95, 101, 113, 117, 105, 112, 109, 101, 110, 116, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 111, 99, 117, 108, 97, 114, 95, 112, 114, 111, 115, 116, 104, 101, 115, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 109, 97, 105, 108, 95, 111, 114, 100, 101, 114, 95, 100, 105, 97, 98, 101, 116, 105, 99, 95, 115, 117, 112, 112, 108, 105, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 115, 117, 114, 103, 105, 99, 97, 108, 95, 100, 114, 101, 115, 115, 105, 110, 103, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 119, 104, 101, 101, 108, 99, 104, 97, 105, 114, 115, 95, 97, 99, 99, 101, 115, 115, 111, 114, 105, 101, 115, 95, 99, 111, 109, 112, 108, 101, 120, 95, 114, 101, 104, 97, 98, 105, 108, 105, 116, 97, 116, 105, 118, 101, 95, 112, 111, 119, 101, 114, 95, 101, 95, 103, 95, 103, 114, 111, 117, 112, 95, 51, 95, 103, 114, 111, 117, 112, 95, 52, 95, 103, 114, 111, 117, 112, 95, 53, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 115, 111, 109, 97, 116, 105, 99, 95, 112, 114, 111, 115, 116, 104, 101, 115, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 104, 111, 115, 112, 105, 116, 97, 108, 95, 98, 101, 100, 115, 95, 116, 111, 116, 97, 108, 95, 101, 108, 101, 99, 116, 114, 105, 99, 95, 112, 101, 100, 105, 97, 116, 114, 105, 99, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 104, 101, 97, 116, 95, 99, 111, 108, 100, 95, 97, 112, 112, 108, 105, 99, 97, 116, 105, 111, 110, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 97, 100, 100, 114, 101, 115, 115, 34, 32, 58, 32, 34, 49, 51, 52, 53, 32, 87, 32, 57, 84, 72, 32, 65, 86, 69, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 34, 44, 10, 32, 32, 34, 101, 110, 116, 101, 114, 97, 108, 95, 110, 117, 116, 114, 105, 101, 110, 116, 115, 95, 115, 117, 112, 112, 108, 105, 101, 115, 95, 102, 111, 114, 95, 115, 112, 101, 99, 105, 97, 108, 95, 109, 101, 116, 97, 98, 111, 108, 105, 99, 95, 110, 101, 101, 100, 115, 95, 97, 110, 100, 95, 112, 101, 100, 105, 97, 116, 114, 105, 99, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 105, 110, 118, 97, 115, 105, 118, 101, 95, 109, 101, 99, 104, 97, 110, 105, 99, 97, 108, 95, 118, 101, 110, 116, 105, 108, 97, 116, 105, 111, 110, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 112, 114, 111, 115, 116, 104, 101, 116, 105, 99, 95, 108, 101, 110, 115, 101, 115, 95, 99, 111, 110, 118, 101, 110, 116, 105, 111, 110, 97, 108, 95, 101, 121, 101, 103, 108, 97, 115, 115, 101, 115, 34, 32, 58, 32, 116, 114, 117, 101, 44, 10, 32, 32, 34, 99, 111, 99, 104, 108, 101, 97, 114, 95, 105, 109, 112, 108, 97, 110, 116, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 100, 105, 97, 98, 101, 116, 105, 99, 95, 115, 104, 111, 101, 115, 95, 105, 110, 115, 101, 114, 116, 115, 95, 112, 114, 101, 102, 97, 98, 114, 105, 99, 97, 116, 101, 100, 34, 32, 58, 32, 102, 97, 108, 115, 101, 44, 10, 32, 32, 34, 115, 112, 101, 101, 99, 104, 95, 103, 101, 110, 101, 114, 97, 116, 105, 110, 103, 95, 100, 101, 118, 105, 99, 101, 115, 34, 32, 58, 32, 102, 97, 108, 115, 101, 10, 125, 10, 32, 93, 13, 10, 48, 13, 10, 13, 10])\nTRACE:hyper::http::h1: Response.try_parse([Header; 100], [u8; 10335])\nTRACE:hyper::client::pool: PooledStream.drop, is_closed=true\nthread '<main>' panicked at 'called `Result::unwrap()` on an `Err` value: Version', ../src/libcore/result.rs:738\n. To add to the weirdness of the error if I copy paste the client code and use the command line argument URL the response works but if the URL is a string in the code then I get the error.\nThis works\n```\nfn main() {\n    env_logger::init().unwrap();\nlet url = match env::args().nth(1) {\n    Some(url) => url,\n    None => {\n        println!(\"Usage: client <url>\");\n        return;\n    }\n};\n\nlet client = Client::new();\n\nlet mut res = client.get(&*url)\n    .header(Connection::close())\n    .send().unwrap();\n\nprintln!(\"Response: {}\", res.status);\nprintln!(\"Headers:\\n{}\", res.headers);\nio::copy(&mut res, &mut io::stdout()).unwrap();\n\n}\n```\nThis doesn't\n```\nfn main() {\n    env_logger::init().unwrap();\nlet url = \"https://data.medicare.gov/resource/pqp8-xrjv.json?$limit=1\";\n\nlet client = Client::new();\n\nlet mut res = client.get(url)\n    .header(Connection::close())\n    .send().unwrap();\n\nprintln!(\"Response: {}\", res.status);\nprintln!(\"Headers:\\n{}\", res.headers);\nio::copy(&mut res, &mut io::stdout()).unwrap();\n\n}\n```\n. @seanmonstar  Thanks for speedy fix.\n. ",
    "kelseasy": "No loss per se, but it enforces the use of ; after a set(), meaning that a match only setting headers has to be surrounded in brackets. (And that probably makes it a breaking change, sadly)\n. I went ahead and made a PR, the needed changes illustrate how this would end up looking like for anyone using it.\n. That also affects simple closures that did not need any brackets beforehand.\nBut this also avoids having to declare a temporary variable when doing multiple set() operations while still being explicit. I'm not familiar enough with hyper to know if that change is useful enough to warrant this breakage though.\n. This enforces the typing system on it, the same goes for many parts of Hyper. It's actually a great feature, that ensures no cases are forgotten, and will make the compiler yell at you for any typo.\n. On a match? (It may be a bad example though, what I really meant was that you could only get in parts of code dealing with a signature like fn foo(bar: Mime) when you are sure that this is a mimetype, making the signature totally explicit/reliable)\n. I'd love an option to get the raw socket behind it, as there's times where you want to avoid userland completely, and just use a splice() or a sendfile().\nRight now, this doesn't seem doable, or did I miss something during my experiments? (Granted, this is not really asynchronous, but this is still a very real use-case). That explains a lot. While skimming through the documentation (namely this one), there are a few non-exported types that are still exposed somehow.\nKeeping the logic contained internally can only help. There's the option of keeping everything internal, or perhaps exposing it through a feature (though that seems a bit convoluted).. Closing, this was meant as a quick-fix, but doesn't solve the underlying issue (exposing Url).. That straight unwrap() seems a bit extreme.. Well, since this is meant to be an Option<T>, it may be a good idea to use a match there to return the None value instead of panic-ing. (I realise that this was in the previous code, but it's an easy fix). ",
    "frederikbosch": "@rsolomo Thanks for your reply! So, should I spawn a new thread per new EventSource connection? In my project, the webserver is just for monitoring purposes. I do not expect lots of traffic. Will that change after #395 is implemented?\n. @rsolomo Thanks again. Maybe I should implement websockets after all then.\n. Nonetheless, I will leave this issue open since EventSource API is not really usable at this moment. When #395 is implemented, I will see if I can provide an example with your suggestions.\n. @seanmonstar Fantastic! Thanks for the great library!\n. @mikeycgto It be very nice to follow your progression. I did spend time on this since the issue was resolved, but still have some very relevant use-cases.\n. ",
    "shepmaster": "I made a basic example that responds to every HTTP request with an event stream. You can see it on Stack Overflow. \n. @seanmonstar Would you expect something like this to work:\nrust\nfn on_response_writable(&mut self, response: &mut Encoder<HttpStream>) -> Next {\n    // ...\n    return Next::wait().timeout(remaining);\n}\nIt would have been very convenient, but there's no way to say what the next state should be, so the handler just... exits Instead, I ended up spawning a thread to provide my timeout and trigger the Control.\n. OP has also cross-posted to Stack Overflow.. ",
    "PeterSP": "$ uname -a\nLinux [hostname] 4.0.4-301.fc22.x86_64 #1 SMP Thu May 21 13:10:33 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\nUsing glibc 2.21\nrustc version 1.3.0\nSingle process, run in gdb.\nNo other languages in the program (communicates over network with programs in other languages, but no other languages embedded in the program itself).\n. Bizarre. Hopefully that'll \"fix\" the \"problem.\"\n. ",
    "KiChjang": "Fixed by #862.\n. ",
    "ozten": "I think keeping GET and HEAD's no body constraint is a good idea, to follow HTTP's standards.\nAccording to elastic search's Request Body Search, I think you can use POST.\n\nBoth HTTP GET and HTTP POST can be used to execute search with body. Since not all clients support GET with body, POST is allowed as well.\n. \n",
    "Victor-Savu": "I would go even further and suggest a 3-way split: http , server and client. The hyper-http crate would jut implement the protocol in a network-agnostic way.. ",
    "crawford": "\nBut ultimately you can make up completely bogus mimetypes with the current system anyways (for instance nobody stops you from making an image/json).\n\n@mitsuhiko IANA regulates the MIME types, so they would be the ones stopping you. You could make something follow the same string format that MIME types use, but it would not be a MIME type. That's what the type system guarantees.. ",
    "calebmer": "Ok, that's cool \ud83d\udc4d\n. If you look at the PostgREST project you'll see it's being used to suppress counts and in a few other cases. The spec also gives some interesting examples. For my usage I'd like to explore the header for styling a response. For example: Prefer: case=camel or Prefer: envelope.\nTo me, the Prefer header represents the configuration of some niche behaviors.\n. Basically it's an optional Expect.\n. After a quick Google search, I found Microsoft Azure uses it (here is there specific extensions). Of course, as I mentioned in #747 the popular (~6,500 stars) PostgREST REST API uses it.\nAnd a few other links of people using it that my Google search turned up:\n- https://github.com/Reading-eScience-Centre/coverage-restapi/blob/master/spec.md#61-prefer-header-method-for-embedding-data\n- https://github.com/davidyack/Xrm.Tools.CRMWebAPI/commit/fd54a5a2fec221956f4b5a238751cba4794e2ba3\n. On another note, I'm not sure why the test is failing, could you shed some light on that?\n. Sorry about the indentation, my editor is set to two spaces and looks for an .editorconfig for other levels of indentation.\nComments addressed :blush::+1: \n. ",
    "nokaa": "That is correct. It looks as though there is an open pull request to fix this, so hopefully it will be remedied soon.\n. ",
    "mjkillough": "This seems to be working on master. A similar program now outputs:\nhv.to_string() -> Set-Cookie: foo\nSet-Cookie: bar\n(Full output is here)\n. I think the failing tests are only those running against Nightly and they look to be failing on master too.. ",
    "pascalw": "Ok thanks that makes sense. Looking forward to the mio branch getting stable :)\n. ",
    "TileHalo": "And how multiple servers should be spawned? This code doesn't work\nrust\n   pub fn listen(self) -> Vec<thread::JoinHandle<Result<Listening, Error>>> {\n        let address = self.addr.to_string();\n        let mut vec: Vec<thread::JoinHandle<Result<Listening, Error>>> = Vec::new();\n        for _ in 0..num_cpus::get() * 4 {\n            let handler: FabricHandler<'static, D> = self.handler.clone();\n            let addr = address.clone();\n            vec.push(thread::spawn(move||{\n                Server::http(&addr.parse().unwrap()).unwrap().handle(move |_| handler.clone())\n            }));\n        }\n        vec\n    }\naddress is 0.0.0.0:3000 \n. Code 98, \"Address already in use\"\n. Little digging into mio documentation told  that mio's TcpListener::bind() sets SO_REUSEADDR. Hypers HttpsListener uses this but HttpListener doesn't.\n. Actually Both HttpListener and HttpsListener uses TcpListener::bind()\nEDIT: \"Problem\" is in mio, since it doesn't set SO_REUSEPORT.\n. Ok, that explains alot. Thank you. Could it be possible to make example how to spawn multiple processes or should hyper::server::Server have some way of doing it? I assume that one must create mio::tcp::TcpListener by hand.\n. ",
    "bonifaido": "I think the option you are looking for is SO_REUSEPORT (which does load balancing between listeners only on Linux, on OSX the last opened listener receives all the traffic, on Windows I don't know, but not what on Linux). If this option is not set down the line somewhere (hyper, rotor, mio, net2) it won't work. I guess it isn't.\n. ",
    "ishbir": "Seems like this merge was undone by https://github.com/hyperium/hyper/commit/d35992d0198d733c251e133ecc35f2bca8540d96. Was it on purpose?\n. ",
    "KeenS": "What is the status of this issue? Is anyone active on this issue? I need WWW-Authenticate header to use with Authorization: Bearer.. Thank you for your reply. I'll try to implement this.. rebased to fix commit messages. Yes it does. Though it depends on some internal types like CowStr, if only I ported with them, it can be separated.. @seanmonstar Are you going to merge this patch, or want it to be a separated crate?\nThis is NOT a authorization framework but just a header parser/printer. I implemented this because 401 unauthorized requires for the response to contain WWW-Authenticate header. . Yes, that's very reasonable. Then I close this PR and prepare for publishing it as a new crate. Thank you.. this https://crates.io/crates/www-authenticate. :). ",
    "weberc2": "@bfrog Yes, sorry for omitting that detail.\n. Removing the Connection header and not sharing the client bring the time back down to parity with Go. It does appear it was the connection header, and yes, I copied it from the example. It seems the biggest penalty was still sharing the client; is this penalty expected as well?\n. Cool. Thanks for the input. I'll close this issue since the shared client penalty is a known issue.\n. ",
    "lambda": "@tailhook Using mDNS is not uncommon, especially for home and small office networks using a lot of Mac clients. Apparently Windows may be getting better support for it soon, so it may become more widespread. So there's at least one other host resolution mechanism that's reasonably common. And apparently some people do use LDAP for name resolution as well, though I've never personally encountered it.\nI think that if you're writing a server-side application that you fully control, just being able to use DNS plus /etc/hosts will usually be fine, but for deploying applications that other people might run in various different environments, you want to use your platform's name resolution, which generally means running getaddrinfo in a thread if you want it to be asynchronous. Having a async DNS resolver like rotor-dns is great, however, for situations in which it is sufficient.\n. ",
    "siddontang": "Hi @seanmonstar \nWe met an problem when using async DNS in another thread before. \nIf one host is down, getaddrinfo will take a long time (>1s in our test) to return failure, this may block following normal host resolving and then affect whole system. \nWe use rust-c-ares + mio now but it only works well in *inx, not windows. \nI think maybe we can use c-ares + rotor later, but for windows, may still thread.  \nBtw, thanks your awesome async hyper, we are refactoring our network framework with it now. :-)\n. Thanks. \n. I update the newest code and find still not fixed. \ud83d\ude22 \nRust version: rustc 1.10.0-nightly (8da2bcac5 2016-04-28)\nOS: Mac OSX.\n. I try to use one DNS worker and find it works now, very strange. \nfn register(&mut self, reg: Registration) {\n        self.dns = Some(Dns::new(reg.notify, 1));\n}\n. Hi @seanmonstar \nI find this may be caused by spmc crate. I use its example adding a sleep after send like: \n```\nlet (tx, rx) = spmc::channel();\nlet mut handles = Vec::new();\nfor n in 0..5 {\n    let rx = rx.clone();\n    handles.push(thread::spawn(move || {\n        let msg = rx.recv().unwrap();\n        println!(\"worker {} recvd: {}\", n, msg);\n    }));\n}\nfor i in 0..5 {\n    tx.send(i * 2).unwrap();\n    // If sleep here, the consumer can't receive following data.\n    // thread::sleep(Duration::from_millis(100));\n}\nfor handle in handles {\n    handle.join().unwrap();\n}\n```\nIf not sleep, it works well.\n. \ud83d\udc4d \nIt works now. \n. Btw, I find that client now doesn't support connection pool now, although there is a pool implementation in pool.rs, is it? \n. Em, I am waiting the pool mechanism and HTTP2, :-) \nBtw, what's the difference between Next::end() and Next::remove(), seem that they all terminate the transport now. So in the server, if I want to re-use the connection for next request after on_response_writable finished, return Next::end()? \n. Thank for your detailed explanation :-)\n. ",
    "Stebalien": "This is a great feature and really exciting. However... I really hope you're planning on adding some convenience handlers/methods/blocking APIs to the client. While client API is very flexible and great for applications where performance is paramount, it's completely unusable for simple (usually single-threaded) applications (not hyperbole). I apologize for being so blunt but I feel that this needs to be said very clearly. These applications can always switch to the curl library but personally, I like avoiding C dependencies when unnecessary.\nAs for more actionable feedback, the client examples appear to be out of date.\n. > What examples are out of date?\nThe client example was, or, at least, I could have sworn it was (Client::new accepted a Handler).\n\nBy leaving the building blocks there, I expect client libraries to appear that are more opinionated, catering to applications like rustup or cargo. They could chose to use Futures, callbacks, or anything else.\nA synchronous API could even exist, exposing io::Read and Write. An example of that exists in the 'sync' example file. \n\nThis is good and will allow hyper to integrate well with other libraries. However, releasing this as-is without some \"hyper-sync\" or \"hyper-easy\" library in place will either force users to abandon hyper, never upgrade, or do this work over-and-over. Basically, I'm objecting to the fact that this is a breaking change without a clear upgrade path.\n. Why did you test this case?\n. Technically, this now allows raw to have length 0. Is that OK?\n. So can I debug_assert this?\n. Ok, this change never picks any of the stated values even if they are all identical.\n. Good point, my diagnosis was wrong (guessing is bad). This change doesn't change the behavior of ContentLength as you say. However, it changes the behavior of the test_header macro to correctly verify that parsing and then formatting a header returns the original header. However, in this case, hyper will \"clean\" the header removing the second content length so this test will fail.\n. ",
    "afiune": "Awesome thank you @seanmonstar !! \n. ",
    "looah-bmtmch": "I'm getting the same problem whenever trying to use https, I tried the same code as shown by novacrazy while using version 0.9.4, and I'm getting the same error.\n. @seanmonstar windows 10\n. ",
    "novacrazy": "@seanmonstar This was with hyper version 0.9.4\nAny thoughts on why it would fail like this?\n. ",
    "dwillie": "I'm experiencing this on Raspbian armhf\u00a0cross compiled from Debian 64bit with Hyper 0.9.6\n. ",
    "MrSpock": "I have exact the same error on MacOS for signed certificate:\nHyper(Ssl(OpenSslErrors([UnknownError { library: \"SSL routines\", function: \"ssl3_get_server_certificate\", reason: \"certificate verify failed\" }])))\n. ",
    "cristicbz": "I think I'm still seeing this in current release, reading your last comments it sounds like maybe, whilst the move to non-blocking IO happened, the fix for dead connections has not?\n. Apologies, saw 'current master' in may and I thought it'd have been merged by now. Didn't realise it was a big year long refactor. Thanks! \n. ",
    "cetra3": "@seanmonstar what version is this fixed in?. @srijs I'm using the shio-rs framework that requires a hyper::Body to be sent in the response so the proposed methods here don't work.\nI've implemented a workaround using the hyper::Body::pair() function, but it's very complex to do so, and has its own issues with futures.\nSo it is possible to still use hyper::Body with a file stream which is good, but the ergonomics around it is pretty bad.\n. It does look very similar. I'll give that PR a shot to see if it's resolved. I've tested the latest master (commit af8d11b2bf4ebe1f69fc1ad1251ae58afd14d6ca), and this breaks stuff on normal connections, causing sockets to stay in TIME_WAIT.\nIn other words, the opposite is now happening: It's leaking connections on a successful attempt.\nMy code to test this is as follows:\nCargo.toml:\n```\n[package]\nname = \"leak_test\"\nversion = \"0.1.0\"\n[dependencies]\nhyper = {git = \"https://github.com/hyperium/hyper\"}\nshio = \"*\"\n[patch.crates-io]\nhyper = {git = \"https://github.com/hyperium/hyper\"}\n```\nsrc/main.rs:\n```\nextern crate hyper;\nextern crate shio;\nuse shio::prelude::*;\nuse hyper::Client;\nfn proxy(ctx: Context) -> BoxFuture {\n    Client::configure().no_proto().build(ctx.handle())\n        .get(\"http://www.google.com\".parse().unwrap())\n        .map(|res| Response::build().body(res.body()))\n        .into_box()\n}\nfn main() {\n    Shio::new(proxy).run(\":7878\").unwrap();\n}\n```\nThen run the following in a terminal:\n```\nConnect 100 times\nab -n 100 http://localhost:7878\nWait a bit for sockets to close\nsleep 20\nCheck how many active sockets there are\nlsof -i -n -P | grep leak_test\n```\nYou will see 100 open sockets that don't go away:\nleak_test 18478 cetra   53u  IPv4 0xa5f869b873e90b7      0t0  TCP 192.168.1.143:50030->216.58.220.100:80 (ESTABLISHED)\nleak_test 18478 cetra   54u  IPv4 0xa5f869b873e50b7      0t0  TCP 192.168.1.143:50032->216.58.220.100:80 (ESTABLISHED)\nleak_test 18478 cetra   55u  IPv4 0xa5f869b871779bf      0t0  TCP 192.168.1.143:50034->216.58.220.100:80 (ESTABLISHED)\nleak_test 18478 cetra   56u  IPv4 0xa5f869b872809bf      0t0  TCP 192.168.1.143:50036->216.58.220.100:80 (ESTABLISHED)\nleak_test 18478 cetra   57u  IPv4 0xa5f869b872aaddf      0t0  TCP 192.168.1.143:50038->216.58.220.100:80 (ESTABLISHED)\nleak_test 18478 cetra   58u  IPv4 0xa5f869b744e37af      0t0  TCP 192.168.1.143:50040->216.58.220.100:80 (ESTABLISHED)\n.... Thanks!. ",
    "drusellers": "OMG YES\n. Yes please. I appreciate the forward looking nature of this issue.. ",
    "pimeys": "I'd add \"Stopping a server cleanly\".. I'm having the same problem and just figuring out how much work it would be for me to branch this and update the dependencies. Was not that complex with solicit, but here I already struggle a bit...\n. Have you tried the master or tokio branches? I could refactor my code to use the async version, but how stable are those?\n. Could you open a bit how this is supposed to work currently? I'm trying switch to the hyper HEAD and having a problem reading the body with this code:\nrust\nlet body_f = response.body().fold(body_vec, |mut acc, chunk| {\n    acc.extend_from_slice(chunk.as_ref());\n    Ok(acc)\n}).map_err(|_| { response::FcmError::ServerError(None) });\nWhere compiler gives me:\nerror[E0283]: type annotations required: cannot resolve `hyper::Error: std::convert::From<_>`\n   |\n82 |             let body_f = response.body().fold(body_vec, |mut acc, chunk| {\n   |                                          ^^^^\nNow, is there some good practice how to read the body to a vector without blocking?. Pretty much got it working and got my first proper use case with hyper-tokio client to compile:\nhttps://github.com/pimeys/fcm-rust/blob/tokio/src/client/mod.rs#L82\nI'm trying to write an asynchronious google push notification client with Tokio. I needed to modify Hyper a bit to to be able to modify headers and have access to some internal things which I think I should be able to refactor at some point.\nBut god damn, it works. Now I need to get this working with HEAD, get it fast and get rid of that Handle passing in the constructor, as noted here https://github.com/hyperium/hyper/issues/1002.\nBut first, I want to have this working on our use case, and we will have a handle to use :). I've tested the folding and it works. Although it was not very obvious, good documentation would help here.. <3. You are absolutely right. Removed the dependency and relying only on what time crate has to offer.. Cool. I'll take a look tomorrow. This is my first real dip into this project's internals, so thanks for pointing nice things. Also if there's somewhere a TODO what is left to get this tokio branch to be 0.1 ready, you can point me some tasks. Our company will be one of the first ones using this in production, so I better know every single detail how hyper-tokio works.... @jwilm Will add it today. Thanks for a great library. We need this and having it as a separate library makes life much harder than just having it in here.. @jwilm @seanmonstar @markuskobler et.al. What is the preferred way of adding the license from retry-after to hyper? Retry-after is MIT and Apache, Hyper is MIT.\nThe latest amend utilized the HttpDate module allowing me to delete more code from the retry_after module.. Sigh, pushing a wrong branch closed the old pull request... https://github.com/hyperium/hyper/pull/998. https://github.com/hyperium/hyper/pull/1017\n. @seanmonstar The only open question with this PR is, that I used parts of the retry-after library. Even though this is quite modified already, the original was Apache+MIT and I don't know how to deal with the licensing; should we include the Apache license only for this part or not.. @jwilm It is your call. How would you like the licensing to work here. Do want to merge it to HEAD here or should we change eetry-after library to support the modern 0.10 hyper?. @jwilm The MIT or the Apache? I see you have a double license there. I can add both :). @jwilm Added the licenses. Hopefully all is good now :). And at least in some point, when using request the method module needs to be public to set the request method:\nhttps://github.com/pimeys/hyper/commit/27a7454f265896bb5ff778242445ef852f9c1890. Ok, didn't notice the methods are available in hyper module. Works now.. I get this tendency of not calling the headers_mut() repeatedly as in your example. I know that with Rust it's not slowing it down and the first example works nicely in my case.\nI don't know how much of a simple high level interface Hyper needs, or should it be basis for another library to provide it.. Been running this on production for a couple of weeks with pretty big loads. Fast and works nicely, but some bugs might be worth to acknowledge if anybody else is testing... There is something fishy how hyper manages dead connections. It the remote end drops the connection, hyper gives a connection error and after that just silently sucks every request into the limbo. In other cases the connection just doesn't answer at all, but at least we can trigger a timeout and restart the connection.\nP.S. if anybody wants to debug the h2/hyper with Apple pushes, all help is appreciated! https://github.com/pimeys/apns2. Yes. We're using https. This is the client code:\nhttps://github.com/panicbit/fcm-rust/blob/master/src/client/mod.rs#L42. I'd say a config option would sound better for Hyper and then again the automatic split for Reqwest. Being able to have more control how the client works in Hyper is one of the things why we'd use it over Reqwest, but for systems triggering requests with more random payloads and endpoints I'd say an automatic solution would work better.. Let me just write this down here to remind me to read the issue if there's going to be any changes:\nI'd really appreciate if the new Connect refactoring wouldn't open more than one connection. I'm using hyper in my Apple push notification client a2, and if I'd open too many connections to Apple's service, they'd consider it a denial-of-service attack and just ban our servers completely. That would be quite unfortunate.. Http2. I checked what was updated after the deployment:\nhyper from h2 branch to  0.12.0-pre.0 (HEAD), tokio-core 0.1.16 replaced with tokio 0.1.5. So there's quite minimal changes in the deployment, that's why the main culprit I can think of is hyper's new Pool implementation.\nWe'll monitor how it looks like after couple of days, will it settle into some memory usage or keep growing.. Ok, so I'm having this running and logging with tee some hours with production traffic on a test machine.. First logs, if you need more trace points, please let me know. I could run this longer, but right now the production instances freed some memory, about 10% drop, so at least they're not going to OOM. Just something seems to use more RAM than before...\nWith long keep-alive timeout, reusing connections:\nTRACE 2018-04-18T18:59:05Z: hyper::client::pool: checkout waiting for idle connection: (\"https://api.push.apple.com\", Http2)\nTRACE 2018-04-18T18:59:05Z: hyper::client::connect: Http::connect(https://api.push.apple.com/3/device/###########)\nDEBUG 2018-04-18T18:59:05Z: hyper::client::dns: resolving host=\"api.push.apple.com\", port=443\nDEBUG 2018-04-18T18:59:05Z: hyper::client::connect: connecting to 17.188.130.151:443\nTRACE 2018-04-18T18:59:06Z: hyper::client::pool: Pool::put (\"https://api.push.apple.com\", Http2)\nDEBUG 2018-04-18T18:59:06Z: hyper::client::pool: pooling idle connection for (\"https://api.push.apple.com\", Http2)\nTRACE 2018-04-18T18:59:06Z: hyper::proto::h2: send body chunk: 404B\nTRACE 2018-04-18T18:59:06Z: hyper::proto::h2: send body eos\nTRACE 2018-04-18T18:59:06Z: hyper::client::pool: Pool::put; existing idle HTTP/2 connection for (\"https://api.push.apple.com\", Http2)\nTRACE 2018-04-18T18:59:42Z: hyper::client::pool: take? (\"https://api.push.apple.com\", Http2): expiration = Some(Duration { secs: 600, nanos: 0 })\nDEBUG 2018-04-18T18:59:42Z: hyper::client::pool: reuse idle connection for (\"https://api.push.apple.com\", Http2)\nTRACE 2018-04-18T18:59:42Z: hyper::proto::h2: send body chunk: 660B\nTRACE 2018-04-18T18:59:42Z: hyper::proto::h2: send body eos\nTRACE 2018-04-18T18:59:42Z: hyper::client::pool: Pool::put; existing idle HTTP/2 connection for (\"https://api.push.apple.com\", Http2)\nTRACE 2018-04-18T19:00:13Z: hyper::client::pool: take? (\"https://api.push.apple.com\", Http2): expiration = Some(Duration { secs: 600, nanos: 0 })\nDEBUG 2018-04-18T19:00:13Z: hyper::client::pool: reuse idle connection for (\"https://api.push.apple.com\", Http2)\nTRACE 2018-04-18T19:00:13Z: hyper::proto::h2: send body chunk: 480B\nTRACE 2018-04-18T19:00:13Z: hyper::proto::h2: send body eos\nTRACE 2018-04-18T19:00:13Z: hyper::client::pool: Pool::put; existing idle HTTP/2 connection for (\"https://api.push.apple.com\", Http2)\nWith short keep-alive timeout, creating new connections:\nTRACE 2018-04-18T19:06:44Z: hyper::client::pool: checkout waiting for idle connection: (\"https://api.push.apple.com\", Http2)\nTRACE 2018-04-18T19:06:44Z: hyper::client::connect: Http::connect(https://api.push.apple.com/3/device/############)\nDEBUG 2018-04-18T19:06:44Z: hyper::client::dns: resolving host=\"api.push.apple.com\", port=443\nDEBUG 2018-04-18T19:06:44Z: hyper::client::connect: connecting to 17.188.138.24:443\nTRACE 2018-04-18T19:06:45Z: hyper::client::pool: Pool::put (\"https://api.push.apple.com\", Http2)\nDEBUG 2018-04-18T19:06:45Z: hyper::client::pool: pooling idle connection for (\"https://api.push.apple.com\", Http2)\nTRACE 2018-04-18T19:06:45Z: hyper::proto::h2: send body chunk: 440B\nTRACE 2018-04-18T19:06:45Z: hyper::proto::h2: send body eos\nTRACE 2018-04-18T19:06:45Z: hyper::client::pool: Pool::put; existing idle HTTP/2 connection for (\"https://api.push.apple.com\", Http2)\nTRACE 2018-04-18T19:07:04Z: hyper::proto::h2::client: client tx dropped\nTRACE 2018-04-18T19:07:24Z: hyper::client::pool: checkout waiting for idle connection: (\"https://api.push.apple.com\", Http2)\nTRACE 2018-04-18T19:07:24Z: hyper::client::connect: Http::connect(https://api.push.apple.com/3/device/##############)\nDEBUG 2018-04-18T19:07:24Z: hyper::client::dns: resolving host=\"api.push.apple.com\", port=443\nDEBUG 2018-04-18T19:07:24Z: hyper::client::connect: connecting to 17.188.138.24:443\nTRACE 2018-04-18T19:07:25Z: hyper::client::pool: Pool::put (\"https://api.push.apple.com\", Http2)\nDEBUG 2018-04-18T19:07:25Z: hyper::client::pool: pooling idle connection for (\"https://api.push.apple.com\", Http2)\nTRACE 2018-04-18T19:07:25Z: hyper::proto::h2: send body chunk: 404B\nTRACE 2018-04-18T19:07:25Z: hyper::proto::h2: send body eos\nTRACE 2018-04-18T19:07:25Z: hyper::client::pool: Pool::put; existing idle HTTP/2 connection for (\"https://api.push.apple.com\", Http2)\nTRACE 2018-04-18T19:07:42Z: hyper::client::pool: take? (\"https://api.push.apple.com\", Http2): expiration = Some(Duration { secs: 10, nanos: 0 })\nTRACE 2018-04-18T19:07:42Z: hyper::client::pool: remove unacceptable pooled connection for (\"https://api.push.apple.com\", Http2)\nTRACE 2018-04-18T19:07:42Z: hyper::client::pool: checkout waiting for idle connection: (\"https://api.push.apple.com\", Http2)\nTRACE 2018-04-18T19:07:42Z: hyper::proto::h2::client: client tx dropped\nTRACE 2018-04-18T19:07:42Z: hyper::client::connect: Http::connect(https://api.push.apple.com/3/device/#######################)\nDEBUG 2018-04-18T19:07:42Z: hyper::client::dns: resolving host=\"api.push.apple.com\", port=443\nDEBUG 2018-04-18T19:07:42Z: hyper::client::connect: connecting to 17.188.138.24:443\nTRACE 2018-04-18T19:07:42Z: hyper::client::pool: Pool::put (\"https://api.push.apple.com\", Http2)\nDEBUG 2018-04-18T19:07:42Z: hyper::client::pool: pooling idle connection for (\"https://api.push.apple.com\", Http2)\nTRACE 2018-04-18T19:07:42Z: hyper::proto::h2: send body chunk: 440B\nTRACE 2018-04-18T19:07:42Z: hyper::proto::h2: send body eos\nTRACE 2018-04-18T19:07:43Z: hyper::client::pool: Pool::put; existing idle HTTP/2 connection for (\"https://api.push.apple.com\", Http2)\nTRACE 2018-04-18T19:07:54Z: hyper::proto::h2::client: client tx dropped\nTRACE 2018-04-18T19:07:56Z: hyper::client::pool: pool closed, canceling idle interval\n. So some notes on the systems we're running with Hyper:\n\nThe one with h2 connections, one per customer. We use long keep-alive timeouts, and basically the system grabs more memory without freeing when we reuse an idle connection that needs to be reopened.\nWe also run a system with Hyper 0.11, using only h1 connections. This time we're just holding one pool and all customers reuse the same connections. We keep them alive, but don't see same memory issues as with h2. My guess though is, that the smaller amount of connections and the constant traffic through them being generic actually keeps them up all the time, unlike the h2 ones that can be idle the whole night and in the morning get more traffic, reopening them and causing the issue.\n\nI can try Hyper 0.12 in our h1 system, but I really doubt I see bigger memory usage.. Oh, one more observation:\nWhen we get a jump in RAM usage, it happens when a dead connection gets a big spike of requests. The memory leak is about 60-100M, meaning it's much more than a couple of dead connections (should be about 6 per customer). I'd say something is not cleaned when we race the new connection in the pool, but I'm not sure.. > What determines it is dead? The remote has closed the connection, but the pool hadn't yet cleared out the handle? Or it's reached its expiration and was waiting for the idle interval to clean it up?\nNo, I mean I have a keep-alive timeout of 10 minutes, and we have some customers that don't use their connection for the night and then just blast a massive amount of requests, so the pools open new connections and we have like hundreds of thousands of concurrent requests polling for new connections.\nBut like I said in IRC, I don't think this is an issue now really to block 0.12. We don't OOM, the memory is freed eventually and the difference to h2 0.11 branch is just doubled RAM usage, which is maybe not nice but we're talking about some hundreds of megabytes in our case.. Monitoring the latest 0.12 for the weekend, the memory usage is bigger but doesn't really grow above certain limit. Also we notice drops every now and then, evening it out. The graph starts from a deployment and ends to the current timestamp.\n\n. The RAM usage was reduced by several commits before, but this being the best deal and now the usage actually even gets lower when running the system longer. I consider this fixed now.. We skip the DNS after forming the connection so I doubt this has any effect on our use case.... I'd follow this issue and maybe even help:\nhttps://github.com/tokio-rs/tokio/issues/363\nWould be pretty nice to just use Tokio's DNS resolver in Hyper when it's ready. There are some unofficial crates to use in your custom connector that should not be that hard to add to your stack, e.g:\nhttps://github.com/sbstp/tokio-dns. I think this is a duplicate and there's an issue tracking this and a possible fix here:\nhttps://github.com/hyperium/hyper/issues/1509. Check the Uri from the http crate:\nhttps://docs.rs/http/0.1.5/http/uri/index.html. All http types were moved to another library called http, so yes.. For batteries included crate, that uses hyper under the surface, you should check reqwest:\nhttps://github.com/seanmonstar/reqwest/. At least the RFC notes that the headers are case-insensitive:\nhttps://tools.ietf.org/html/rfc2616#page-31\nJa huumeet.info, tori jne :D. ",
    "hjr3": "I think showing the examples is a good place to start. One of the more challenging things about understanding futures, tokio and hyper is context. Examples, such a hello world, show more of that context and give people a better chance of solving their problem.\nI do think there is value in doing a deep-dives on a particular topic, but I think examples and spelunking through source is good enough until things really stabilize.. Looking for something like this?\nrust\nreq.body().fold(Vec::new(), |mut v, chunk| {\n    v.extend(&chunk[..]);\n    future::ok::<_, hyper::Error>(v)\n}).and_then(move |chunks| {\n    let body = String::from_utf8(chunks).unwrap();\n    future::ok(body)\n})\nThat will return a Future<Item=String, Error=hyper::Error>. You can wait() on that future if you want to block until the body is completely read into the String.. I am going to try get a PR up for this. There are two options for timers, but I am unsure of which is best for hyper. The tokio_timer crate is more accurate but uses a dedicated thread. The Timeout in tokio-core is less accurate but does not require the extra thread.\nIf I was making the decision, I would create a single tokio-timer Timer (1 dedicated thread), configure it properly and then use that for any timeout needs. Does anyone else have any opinions?. Based on the discussion, I wrote a TimeoutConnector that wraps an existing Connect implementation here https://github.com/hyperium/hyper/compare/master...hjr3:issue-1234?expand=1. I left the code in the connect.rs file for now, so as not to deal with module shenanigans. The TimeoutConnector can be used with the HttpsConnector in hyper_tls too. This may also get use closer to the suggestion from @nielsle about using Middleware. I say may because I did not like very closely that how the PR works. ~~I still owe some tests.~~\nThe alternative is to embed the timeout in HttpConnector too, but the wrapper seemed better/cleaner.\nI will start playing around with the crate from @sfackler and see if I can get read/write timeouts setup.. @skinowski Definitely. Where is the advanced example? I only see the simple example. . I have read/write timeouts in place. After putting those in, it seems natural to want to configure the client with a connect_timeout instead of wrapping the Connect implementation. I am trying to figure out how to do that.. @skinowski I also added a PR to add the general timeout to the guide https://github.com/hyperium/hyperium.github.io/pull/13. I created https://crates.io/crates/hyper-timeout to get connect, read and write timeout functionality. So far, it has been working for my use case. There may be some changes required to tokio-io-timeout, including this comment from @seanmonstar:\n\nAs a side note, looking at the tokio-io-timeout crate, the implementations of AsyncRead and AsyncWrite don't pass forward the read_buf and write_buf methods, which would mean readv and writev are no longer used for TcpStream.\n\nI will see about getting some PRs up for tokio-io-timeout.. @sfackler \ud83d\udc4d ~i will update my crate.~ edit: nevermind, this is a library. though i did notice i committed the Cargo.lock, which i fixed.. A similar issue was discussed in https://github.com/hyperium/hyper/issues/1137, but it has changed a bit. Here is what I do:\nrust\nresponse.body().concat2().and_then(move |body: Chunk| {\n    let foo = serde_json::from_slice::<Foo>(&body).unwrap();\n}\nA hyper::Body is a stream of hyper::Chunk, so we need a non-blocking way to get all the chunks before we parse the json. The concat2() function takes the separate body chunks and makes one hyper::Chunk value. Once we have a chunk that contains the entire body contents, we can leverage the fact that hyper::Chunk can be converted via AsRef into a slice of bytes ([u8]). We can then use the serde_json::from_slice() function to deserialize the bytes into an example Foo struct.\nI am willing to improve/expand on this and make a PR to https://github.com/hyperium/hyperium.github.io/blob/master/_guides/client/basic.md if it will be accepted.. I put my first draft up here: https://github.com/hyperium/hyperium.github.io/pull/8. Feedback is appreciated!. @RCasatta I believe Rust is making this closure of type FnOnce because you are closing over the my_data value. In order to make it a closure of type Fn we need to move my_data into the closure and then clone it.\nrust\n    let server = Http::new().bind(&addr, move || Ok(HelloWorld{\n        shared_data : my_data.clone()\n    })).unwrap();. @seanmonstar TimeoutConnector can be out of crate. I don't see how the read and write timeouts would be out of crate. That being said, I was looking at other issues where you were talking about the ClientProto onion. Maybe that is a better way to introduce some of this functionality.. Of course! Not sure why I did not think of that earlier. Ok, I will make a separate crate and add all of the logic there.. That issue is out of date now. Have you read https://hyper.rs/guides/client/json/ yet?. ",
    "ktsujister": "I modified the commit message to follow the style.\n. ",
    "crumblingstatue": "What the hell. How did the coverage decrease by adding a doc comment?\n. > What is the comment clarifying? I'm not against more comments, just I wonder if this could be made clearer still.\nI explained it in the commit message.\nIf one just reads the doc page for Response, they can only see that Response implements Read.\nBut it might not be immediately apparent what the Read implementation actually reads. This comment clarifies that the Read implementation is for reading the response body.\n. ",
    "paragonie-scott": "More directly: Why are you expecting non-stable software's API to be... stable?\n. ",
    "aidanhs": "I agree that this was a bugfix. However\n\nMore directly: Why are you expecting non-stable software's API to be... stable?\n\nand the other comments saying \"well it's pre-1.0 so you should be ready for breaking changes every day\" aren't really fair in general (this issue aside). Arewewebyet says \"Rust has a mature HTTP stack\", with a footnote of \"getting there, stable but maturing\" [1]. Neither the github readme nor hyper.rs mention anything about instability, and so the only hint is the orange badge with the version. If hyper is actively changing and breaking (it is), I don't think it's unreasonable to want it to do a better job of advertising that fact.\nThe reality is that the nodejs ecosystem (arguably one which contributed significantly to the popularity of semver) has damaged the meaning of pre-1.0 version numbers with a culture of refusing to touch 1.0. It's got better, but for a project with such a key role in the ecosystem like hyper, an explicit note saying \"Hyper is pre 1.0 and is still undergoing breaking changes\" helps clarify both for people used to old nodejs-semver and who aren't really aware of semver at all.\n[1] as an aside, there's a comment on hyper on arewewebyet from feb which says \"I don\u2019t see hyper having major breaking changes in the forseeable future and is pretty usable/ready.\", which is clearly wrong\n. @seanmonstar I did consider doing that, but didn't want to be too presumptuous. Since you suggested it, I've made a PR! I think the issues milestone is probably best, since it's most likely to get updated.\n@tarcieri in my comment I do say \"this issue aside\" - I maybe could have emphasised that more.\nI was already in agreement with everything you've said in your comment and personally I think \"this was a security bugfix\" is a fine reason for fixing this in the patch version of a hypothetical post-1.0 project. My comment was more aimed at the general \"well you should know what you're getting in for with pre-1.0\" feeling I was getting - hyper would be changing even if there weren't critical security issues (I'm a big fan of the direction fwiw) and I think we can do a better job of calling this out, especially given the wider context of nodejs history and hyper being a pretty key project in an important corner of the rust ecosystem. To do something about it I've created https://github.com/bashyHQ/arewewebyet/pull/48 and https://github.com/hyperium/hyper/issues/889.\n. By the way, I'm very much open to alternative wording.\n. ",
    "arkpar": "I've been investigating this issue but still not sure what causes it. First I patched hyper to drop the socket after everything have been written and the final write have been confirmed with write_done in mio/tcp. Introduced an additional Writing::Flushing state in which connection waited for the socket to be writable again before closing it. That did not help much. \nThis commit resolved it but I have no idea why and I'm quite sure that's not the best way to fix it:\nhttps://github.com/ethcore/mio/commit/3842d3b250ffd7bd9b16f9586b875ddcbac2b0dd \nSetting SO_LINGER socket option might also help, but I haven't tried this.\nhttps://msdn.microsoft.com/en-us/library/windows/desktop/ms738547(v=vs.85).aspx\nhttps://msdn.microsoft.com/en-us/library/windows/desktop/ms740476(v=vs.85).aspx\n. ",
    "leodasvacas": "Benchmarked on nightly with precision of seconds, no change in compile times for debug or release. I suspect the improvement is due to rust-lang/rust#31414 which is in beta however. Should this wait for that change to land in stable?\n. Very well, reverted changes to status.rs.\n. ",
    "bluetech": "Just a data point, here's perf report of the above wrk command before this PR (only >= 2%, rust 1.9.0):\n17.14%  hello    libc-2.23.so        [.] __memcpy_avx_unaligned\n     9.93%  hello    libc-2.23.so        [.] __memset_avx2\n     5.64%  hello    hello               [.] hyper::http::h1::parse::_$LT$impl$u20$http..Http1Message$u20$for$u20$http..ServerMessage$GT$::parse::h95f4390be86b6454\n     5.26%  hello    hello               [.] _$LT$hyper..http..conn..State$LT$H$C$$u20$T$GT$$GT$::update::hda2a28a5f3d7f4ac\n     4.34%  hello    hello               [.] core::fmt::write::h4eb847ed3e152952\n     4.00%  hello    hello               [.] _$LT$std..io..Write..write_fmt..Adaptor$LT$$u27$a$C$$u20$T$GT$$u20$as$u20$std..fmt..Write$GT$::write_str::h428ca1799ea8eabb\n     3.95%  hello    hello               [.] core::fmt::Formatter::write_fmt::ha8631b2bdb82a0b7\n     3.76%  hello    hello               [.] _$LT$hyper..http..conn..Conn$LT$K$C$$u20$T$C$$u20$H$GT$$GT$::on_writable::h150e5d121479d65f\n     2.88%  hello    hello               [.] _$LT$mio..event_loop..EventLoop$LT$H$GT$$GT$::run_once::h42b5013245ea60d3\n     2.16%  hello    hello               [.] mallocx\n     2.07%  hello    hello               [.] sdallocx\n     2.07%  hello    hello               [.] time::display::parse_type::h4267bac127e2a6cf\nand after:\n6.57%  hello    hello               [.] _$LT$hyper..http..conn..State$LT$H$C$$u20$T$GT$$GT$::update::hda2a28a5f3d7f4ac\n     6.15%  hello    hello               [.] hyper::http::h1::parse::_$LT$impl$u20$http..Http1Message$u20$for$u20$http..ServerMessage$GT$::parse::h95f4390be86b6454\n     6.04%  hello    hello               [.] _$LT$mio..event_loop..EventLoop$LT$H$GT$$GT$::run_once::h42b5013245ea60d3\n     5.61%  hello    hello               [.] _$LT$std..io..Write..write_fmt..Adaptor$LT$$u27$a$C$$u20$T$GT$$u20$as$u20$std..fmt..Write$GT$::write_str::h428ca1799ea8eabb\n     4.92%  hello    hello               [.] core::fmt::write::h4eb847ed3e152952\n     4.88%  hello    libc-2.23.so        [.] __memcpy_avx_unaligned\n     4.85%  hello    hello               [.] _$LT$hyper..http..conn..Conn$LT$K$C$$u20$T$C$$u20$H$GT$$GT$::on_writable::h150e5d121479d65f\n     3.28%  hello    hello               [.] rotor::handler::replacer::ha0a65d97791110f7\n     3.28%  hello    hello               [.] core::fmt::Formatter::write_fmt::ha8631b2bdb82a0b7\n     3.14%  hello    hello               [.] mallocx\n     2.85%  hello    hello               [.] _$LT$hyper..http..conn..Conn$LT$K$C$$u20$T$C$$u20$H$GT$$GT$::ready::h4913e9752920612a\n     2.76%  hello    libc-2.23.so        [.] __memset_avx2\n     2.64%  hello    hello               [.] time::display::parse_type::h4267bac127e2a6cf\n     2.31%  hello    hello               [.] sdallocx\nSo this PR does do what it says on the tin. I guess when the string formatter shows near the top, the situation is not bad :)\n. I wrote some paragraphs about why I don't think things like binding TCP or spawning tasks are boilerplate, and how the things that Server does currently (tcp keepalive, tcp nodelay, sleep on error, graceful shutdown in the future?) would be better handled at a generic TCP level IMO\u00b9. But I decided to spare you all of that - shorter examples/appearing less scary is a good enough reason, even if I don't agree :)\n\u00b9 There is also an AddrStream type which is a wrapper around TcpStream but additionally keeps track of a remote_addr for each connection. But remote_addr isn't used so I'm not sure what functionality this type serves. (Also not sure why it keeps track of the remote addr itself when TcpStream::peer_addr() is available.). @lnicola I prefer the \"Simple vs. Easy\" idea that nice composable \"simple\" primitives are preferable to \"easy\" abstractions. Personally, I don't think Rust should aim for \"easy\", that fight is quite hopeless compared to other languages. But this is a discussion that is more appropriate for another venue.. This is something I've noticed. I don't know if it's desirable but it was easy enough to make the changes.\nI have only performed basic tests. If someone has e.g. a web crawler program which uses hyper, that could be a good stress-test, and comparison before/after.\nI should also note that tokio-threadpool's README says \"Note: This library isn't quite ready for use.\". That said, the dependency is private so updating it will not be a breaking change.. Travis fails on nightly due to this rustc bug: https://github.com/rust-lang/rust/issues/50707. @seanmonstar Hmm indeed, I did not think of that. This seems to make blocking unusable from libraries, since libraries cannot assume which runtime they are running under. I'll open an issue about that in the tokio repo, I think it is worth mentioning in the docs.\nI suppose that the \"remove a dependency\" advantage can be salvaged by creating a tokio_threadpool::ThreadPool, if someone's up to it.. You can do this:\n```rust\nextern crate futures;\nextern crate tokio;\nextern crate hyper;\nuse futures::prelude::*;\nuse hyper::service::service_fn_ok;\nuse hyper::{Body, Response, Server};\nfn main() {\n    let addr = std::net::SocketAddr::from(([127, 0, 0, 1], 3000));\n    let listener = std::net::TcpListener::bind(&addr).unwrap();\n    let handle = tokio::reactor::Handle::current();\n    let listener = tokio::net::TcpListener::from_std(listener, &handle).unwrap();\nlet new_service = || service_fn_ok(|_req| Response::new(Body::from(\"Hello World\")));\n\nlet server = Server::builder(listener.incoming()).serve(new_service);\n\ntokio::run(server.map_err(|e| {\n    eprintln!(\"server error: {}\", e);\n}));\n\n}\n```. I forgot to mention: hyper optionally sets some TCP options on the accepted sockets when it creates the listener. If you create the listener and you want to set them, you can do it as follows:\n```diff\ndiff --git a/src/main.rs b/src/main.rs\nindex a74a15c..5d2f29c 100644\n--- a/src/main.rs\n+++ b/src/main.rs\n@@ -11,10 +11,15 @@ fn main() {\n     let listener = std::net::TcpListener::bind(&addr).unwrap();\n     let handle = tokio::reactor::Handle::current();\n     let listener = tokio::net::TcpListener::from_std(listener, &handle).unwrap();\n+    let incoming = listener.incoming().map(|socket| {\n+        socket.set_nodelay(true).unwrap();\n+        socket.set_keepalive(Some(std::time::Duration::from_secs(7200))).unwrap();\n+        socket\n+    });\n let new_service = || service_fn_ok(|_req| Response::new(Body::from(\"Hello World\")));\n\n\nlet server = Server::builder(listener.incoming()).serve(new_service);\n\nlet server = Server::builder(incoming).serve(new_service);\ntokio::run(server.map_err(|e| {\n     eprintln!(\"server error: {}\", e);\n``. I think you are asking to be able to get what the HTTP specification calls the [Effective Request URI](https://tools.ietf.org/html/rfc7230#section-5.5). It is calculated from configuration, the request target, and theHost` header. This sounds useful to me; it looks easy to get it wrong (or incomplete), and every multihomed HTTP server needs to handle it.\n\n\nI don't think overriding req.uri() is a good idea though, the actual URI that was used should still be accessible. It sounds like it should be a standalone function which takes the necessary inputs and provides the Effective Request URI as output.. actix-web has a similar-sounding issue, it might be related: https://github.com/actix/actix-web/issues/454. ",
    "ryansroberts": "https://tools.ietf.org/html/rfc6101#section-5.6.2\nRust openssl bindings provide all the needed calls by the look of it. The client x509 cert will need to be made available to middleware as its often used to identify the client.\nhttps://github.com/sfackler/rust-openssl/blob/master/openssl/src/ssl/mod.rs#L224\nhttps://github.com/sfackler/rust-openssl/blob/master/openssl/src/ssl/mod.rs#L1052\n. ",
    "bozaro": "I think about check_continue method and came to the conclusion: this method is not good solution and I prefer to remove it.\nMuch better to send \"100 Continue\" status on first Body::read() call.\nIn this case no additional logic/callback needed for make desigion about \"100 Continue\":\n- If you call Body::read() method, then you needs to request body and hyper send to client \"100 Continue\";\n- If you have anought information to send final status without body, then hyper send status without \"100 Continue\".\nI try to implement this logic on 0.9.8 branch and create a new PR.\n. I tried to implement the logic of sending \"100 Continue\" status at the beginning of reading, but I could not find a way to do this without losing compatibility :(\n. Move to issue #838\n. Yes, about this behavior and I had in mind.\nI'm sorry if offended. Loss (sometimes temporary) features on full code redesign is a normal and I did not mean anything bad. On the contrary, from my point of view this is a very good time to remind about corner cases :)\n. Thanks a lot.\nI can solve a problem by code like:\n```rust\nextern crate iron;\nextern crate hyper;\nuse iron::prelude::*;\nuse iron::middleware::Handler;\nuse iron::Protocol;\nuse hyper::net::{NetworkListener, HttpStream};\nuse std::net::TcpListener;\nuse std::io;\nuse std::net::SocketAddr;\nuse std::sync::Arc;\nstruct ResponseHandler(Vec);\nimpl Handler for ResponseHandler {\n    fn handle(&self, _: &mut Request) -> IronResult {\n        Ok(Response::with((iron::status::Ok, &self.0[..])))\n    }\n}\n[derive(Clone)]\nstruct TcpListenerNoDelay {\n    listener: Arc\n}\nimpl NetworkListener for TcpListenerNoDelay {\n    type Stream = HttpStream;\nfn accept(&mut self) -> Result<Self::Stream, hyper::Error> {\n    let tcp = try!(self.listener.accept());\n    try!(tcp.0.set_nodelay(true));\n    let stream = HttpStream(tcp.0);\n    Ok(stream)\n}\n\nfn local_addr(&mut self) -> io::Result<SocketAddr> {\n    self.listener.local_addr()\n}\n\n}\nfn main() {\n    // Generate fixed response with\n    let mut data = Vec::::new();\n    while data.len() < 1024 * 8 {\n        data.push(b'0');\n    }\n    // Start server\n    let addr = \"localhost:5000\";\n    println!(\"http://{}/\", addr);\nlet listener = TcpListener::bind(addr).unwrap();\n\nIron::new(ResponseHandler(data))\n    .listen(TcpListenerNoDelay { listener: Arc::new(listener) }, Protocol::http()).unwrap();\n\n}\n``\nI think it's good idea to addset_nodelaymethod forHttpListener. I make PR for this change some later.. I think I was happy early. We must dig deeper.. So, as result,TcpListenerNoDelay` really helps to me.. ",
    "martell": "Hey all,\nI'm looking at implementing this on master with the tokio integration.\nI've literally only been using rust a few days so it is hard for me to follow through the code with inferred type assignments and generics mixed together.\nAnyway, Here is what I have so far.\n```git.patch\ndiff --git a/src/http/conn.rs b/src/http/conn.rs\nindex 7954fadb..3e90c8ba 100644\n--- a/src/http/conn.rs\n+++ b/src/http/conn.rs\n@@ -116,6 +116,7 @@ impl Conn {\n                     }\n                 };\n                 self.state.busy();\n+                let wants_continue = head.expecting_continue();\n                 let wants_keep_alive = head.should_keep_alive();\n                 self.state.keep_alive &= wants_keep_alive;\n                 let (body, reading) = if decoder.is_eof() {\n@@ -124,6 +125,10 @@ impl Conn {\n                     (true, Reading::Body(decoder))\n                 };\n                 self.state.reading = reading;\n+                if wants_continue {\n+                    self.state.reading = Reading::Init;\n+                }\n+\n                 return Ok(Async::Ready(Some(Frame::Message { message: head, body: body })));\n             },\n             _ => {\n@@ -674,6 +679,8 @@ mod tests {\n             Ok(())\n         }).wait();\n     }\n+\n+\n     #[test]\n     fn test_conn_closed_write() {\n         let io = AsyncIo::new_buf(vec![], 0);\ndiff --git a/src/http/mod.rs b/src/http/mod.rs\nindex 13c50119..a0ea5a27 100644\n--- a/src/http/mod.rs\n+++ b/src/http/mod.rs\n@@ -2,7 +2,7 @@\n use std::borrow::Cow;\n use std::fmt;\n-use header::{Connection, ConnectionOption};\n+use header::{Connection, ConnectionOption, Expect};\n use header::Headers;\n use method::Method;\n use status::StatusCode;\n@@ -68,6 +68,10 @@ impl MessageHead {\n     pub fn should_keep_alive(&self) -> bool {\n         should_keep_alive(self.version, &self.headers)\n     }\n+\n+    pub fn expecting_continue(&self) -> bool {\n+        expecting_continue(self.version, &self.headers)\n+    }\n }\n/// The raw status code and reason-phrase.\n@@ -115,6 +119,16 @@ pub fn should_keep_alive(version: HttpVersion, headers: &Headers) -> bool {\n     ret\n }\n+#[inline]\n+pub fn expecting_continue(version: HttpVersion, headers: &Headers) -> bool {\n+    let ret = match (version, headers.get::()) {\n+        (Http11, Some(expect)) if expect == &Expect::Continue => true,\n+        _ => false\n+    };\n+    trace!(\"expecting_continue(version={:?}, header={:?}) = {:?}\", version, headers.get::(), ret);\n+    ret\n+}\n+\n #[derive(Debug)]\n pub enum ServerTransaction {}\n```\nThe function I added to http/mod.rs seems correct and with RUST_LOG=trace I get\nTRACE:hyper::http: expecting_continue(version=Http11, header=Some(Continue)) = true\nIgnoring the changes I made to conn.rs just for testing.\n@seanmonstar can you give me some direction here?\nI can gather that we would be using Sink and not a Stream for this but I am not sure about what would be the best way to go about integrating this into the code base.\nWhere should I be piping the data back etc.\nI'm am assuming this is a good time for api breakages.\n. Thanks for taking the time to look.\nMost of that makes sense to me.\nI have setup a WIP PR for this\nWe have to be compliant with the rfc spec to only send the 100-continue when we get the Content-Length makes sense to me.\nWhere does the above code go in the code base however?\nThe use case for this is typically for a REST API server and we only really want to send the body after Auth has happened based on the header data, probably an oauth2 bearer token etc.\nSo when the user requests the body is an ideal time to send the 100-continue\nI see the Conn::poll() in conn.rs\nI'm just not sure what states yet either but can play around with that to achieve the goal and refactor, from initial reading I see\nReading::Init\nReading::Body(..) in the function `can_read_body`\nReading::KeepAlive\nReading::Close\nI think we want a state like Reading::Head because we are beyond the init stage but are not onto reading the body yet.\nMy biggest problem is I can't find where I can write to the SINK, this is probably a combination of my lack of rust knowledge and the fact that this is not my own code base :). @sfackler Added support for immediately replying with 100-continue\nThis is a good short term fix for getting support in tree.\nIdeally we would only send this on the attempted read of the body.\nDiscussions on IRC lead to some work being done in tokio which needed a new future Sink to support this. https://github.com/alexcrichton/futures-rs/pull/414\nThis was then dropped afterwards.\nIt is still up in the air about how we are going to best solve this.\nI wanted to get some context into this thread so we can proceed.\n@seanmonstar did mention he might have an idea about how to help this in hyper?\nThis thread might give the best context on what is needed.\nhttps://github.com/alexcrichton/futures-rs/issues/409\n. > The 100 Continue is always sent immediately because tokio-proto tries to load the first bit of the body, but that's better than nothing!\n@sfackler that is the reason we closed #1040 . Awesome now we have some support in tree. :)\n@seanmonstar last week you said on irc that there might be something hyper can do about the buffering. Can we get an outline of your thoughts on that maybe in the discussion on #838 ?\nI will also link the relevant different implementation attempts carl tried for the futures crate. \n. ",
    "AlexDvorak": "@seanmonstar was this not fixed by 26417fc24?\nrust\nif msg.expect_continue {\n   let cont = b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\";\n   self.io.headers_buf().extend_from_slice(cont);\n}. So, would modification to the `Body` struct like so be fine?rust\npub struct Body {\n    kind: Kind,\n    /// Keep the extra bits in an Option<Box<Extra>>, so that\n    /// Body stays small in the common case (no extras needed).\n    extra: Option>,\n    UserHasPolled: bool,\n}\n``\nOr should the modification be happenning elsewhere?\nIf that's ok then how would one access theBodyfrom theproto/h1/conn.rs?. what are you reffering to by channel implementation? I assume your're not reffering tompsc::channel`. @sanmai-NL could you post the full test script? . ",
    "stapelberg": "Thanks. What do you mean by \u201cevent\u201d? Could you give a code example maybe, similar to what I provided?\n. ",
    "andresilva": "Sorry for the radio silence (and forgetting to add that test). Cheers!\n. ",
    "mattforni": "@seanmonstar Would be happy to contribute to that crate when you publish. Keep me posted?\n. ",
    "lopuhin": "I'm still getting this error on 220d09f:\nthread 'hyper-client' panicked at 'handler not in queue for key', ../src/libcore/option.rs:699\nstack backtrace:\n   1:        0x101062fab - std::sys::backtrace::tracing::imp::write::h3800f45f421043b8\n   2:        0x101065135 - std::panicking::default_hook::_$u7b$$u7b$closure$u7d$$u7d$::h0ef6c8db532f55dc\n   3:        0x101064d6e - std::panicking::default_hook::hf3839060ccbb8764\n   4:        0x101058d57 - std::panicking::rust_panic_with_hook::h5dd7da6bb3d06020\n   5:        0x1010656f6 - std::panicking::begin_panic::h9bf160aee246b9f6\n   6:        0x101059ba8 - std::panicking::begin_panic_fmt::haf08a9a70a097ee1\n   7:        0x10106534f - rust_begin_unwind\n   8:        0x10108b260 - core::panicking::panic_fmt::h93df64e7370b5253\n   9:        0x10108cb95 - core::option::expect_failed::h03c4c03f58c1633f\n  10:        0x100e6be37 - _<std..option..Option<T>>::expect::h904cc49f34fb7126\n  11:        0x100e6bc28 - _<hyper..client..Context<K, H>>::pop_queue::ha385db4d7e271633\n  12:        0x100e94848 - _<hyper..client..Context<K, H> as hyper..http..conn..MessageHandlerFactory<K, T>>::create::hdab9d8df17821a8b\n  13:        0x100e99731 - _<hyper..http..conn..ConnInner<K, T, H>>::write::h8bf0793167db4de5\n  14:        0x100e991e7 - _<hyper..http..conn..ConnInner<K, T, H>>::on_writable::h23c7a4038164366b\n  15:        0x100e838a3 - _<hyper..http..conn..Conn<K, T, H>>::ready::ha7943110f672e530\n  16:        0x100e826bb - _<hyper..client..ClientFsm<C, H> as rotor..machine..Machine>::ready::h12d8e10694517c93\n  17:        0x100e64172 - _<rotor..handler..Handler<M> as mio..handler..Handler>::ready::_$u7b$$u7b$closure$u7d$$u7d$::h23e72b149b40a114\n  18:        0x100e61f39 - rotor::handler::machine_loop::_$u7b$$u7b$closure$u7d$$u7d$::h236e9fcf74f8593f\n  19:        0x100e612d3 - _<slab..Slab<T, I>>::replace_with::h360746f6793e2f7f\n  20:        0x100e60ab7 - rotor::handler::machine_loop::h95bcdc235462b1b1\n  21:        0x100e6098f - _<rotor..handler..Handler<M> as mio..handler..Handler>::ready::h63fa883c90431441\n  22:        0x100e6092f - _<mio..event_loop..EventLoop<H>>::io_event::h134e5ea52ae4ecee\n  23:        0x100e60838 - _<mio..event_loop..EventLoop<H>>::io_process::h0b3c112a870fd570\n  24:        0x100e5fc50 - _<mio..event_loop..EventLoop<H>>::run_once::h2c2a794cc3a3077f\n  25:        0x100e5f49b - _<mio..event_loop..EventLoop<H>>::run::h28c2d6d411bbd2f1\n  26:        0x100e5f3ba - _<rotor..creator..LoopInstance<M>>::run::h10df6fe28ea10bfb\n  27:        0x100e5f2e0 - _<rotor..creator..LoopCreator<M>>::run::hd70222702ee8783e\n  28:        0x100e5e550 - _<hyper..Client<H>>::configured::_$u7b$$u7b$closure$u7d$$u7d$::hf7f94e2f06fe4a88\n  29:        0x100e5e407 - _<std..panic..AssertUnwindSafe<F> as std..ops..FnOnce<()>>::call_once::h02b88cb629f75f13\n  30:        0x100e5e35e - std::panicking::try::_$u7b$$u7b$closure$u7d$$u7d$::_$u7b$$u7b$closure$u7d$$u7d$::hd5b87ecaef035883\n  31:        0x100e5eb24 - std::panicking::try::call::h7ab4dd542e8f0d6d\n  32:        0x101067ceb - __rust_try\n  33:        0x101067c85 - __rust_maybe_catch_panic\n  34:        0x100e5dfed - std::panicking::try::_$u7b$$u7b$closure$u7d$$u7d$::h8e4abf05d797c710\n  35:        0x100e5debf - _<std..thread..LocalKey<T>>::with::h2d2e8e9c5ad81465\n  36:        0x100e5dcef - std::panicking::try::h174a46106ff9d681\n  37:        0x100e5dbce - std::panic::catch_unwind::h1e31bf21058af93e\n  38:        0x100e5da41 - std::thread::Builder::spawn::_$u7b$$u7b$closure$u7d$$u7d$::hc9a714b59d9b1d07\n  39:        0x100e5ed77 - _<F as std..boxed..FnBox<A>>::call_box::hede04a1363ea441c\n  40:        0x101064398 - std::sys::thread::Thread::new::thread_start::h9e5bde00f3b3e2e2\n  41:     0x7fff91d5999c - _pthread_body\n  42:     0x7fff91d59919 - _pthread_start\nI can provide a simple script to reproduce the error (based on client example).\n. Thanks for looking into it! Here is an example that reliably reproduces the crash for me:\ngit clone https://github.com/lopuhin/rust-broad-crawl.git\ncd rust-broad-crawl\ngit checkout 069c7e0aaa8efeb92bd9c81585614d21b4cba4e6\ncargo run top-1k.txt\nNote that this will make about 1000 requests to top 1000 sites from Alexa 1m (I hope there is nothing scary there). It will be making requests for about 10 seconds printing headers, then timeouts will arrive, and then the crash, so the end of the output looks like this:\nERROR: Timeout\nERROR: Timeout\nERROR: Timeout\nReceived ()\nthread 'hyper-client' panicked at 'handler not in queue for key', ../src/libcore/option.rs:699\nnote: Run with `RUST_BACKTRACE=1` for a backtrace.\nRust version rustc 1.10.0 (cfcb716cf 2016-07-03) on OS X (I can try to reproduce on ubuntu too).\n. Thanks a lot, @seanmonstar !\n. ",
    "aravind-pg": "@jdm Actually, why not just have an enum of the six possible referrer policy types and regard anything else as an error? I'm on the fence about whether we'd want nonstandard as a variant here. In one sense it's useful since it adds flexibility, but then again it muddles the issue in a case where the spec really does specify exactly six variants (i.e. we don't really need the flexibility in this case). Maybe we should just defer to Hyper standard practice here -- cc @seanmonstar.\n. Sounds good, will update to use an enum. Also, sounds like I will indeed need to target this against 0.9.x.  This header will probably be generally useful in master as well, so I can open a separate PR against master if you like (or maybe you can cherry-pick?).\n. Updated to use an enum, and also to handle legacy keywords never, default, and always as per the spec.\nOpened basically the same PR against 0.9.x as well: #851. Feel free to close this one if you don't want to merge into master at this point.\n. Actually the current implementation does do exactly what you said -- there are only six variants, and the additional legacy strings just parse to their equivalent variants (e.g. both \"no-referrer\" and \"never\" parse to NoReferrer, etc.).\n. @seanmonstar Could you please bump the version?\n. @seanmonstar Ping, Servo needs the version bump.\n. Great, thanks!\n. ",
    "Cobrand": "I understand that you might want to deprecate this and let the users pick the number of threads they want themselves, but what if people don't want to pick themselves ?\nAt the very least make something that allows to pick the number of threads depending on the number of cpus you have (with a closure I guess) directly in hyper. It would be quite cumbersome to extern the crate num_cpus on everything depending on hyper (since the number of threads depends heavily on the number of cpus you have anyway).\nIf you agree with this, I could make a PR for this.\n. I did not see that master's src what different, thank you for the explanation.\n. ",
    "lcowell": "Thanks for the response. This behaviour is a little confusing and unexpected. I'd think if I pass hyper a url with parts that it isn't going to pass to the server, that it would make some noise.\nI'll have a look at rolling it in myself too. \nedit: I don't mean to be griping. I think what I'm wondering is: is there some way to improve the user(programmer) experience?\n. ",
    "LaylConway": "Nevermind, it seems this was a crossbeam problem, not a hyper one\n. ",
    "ebarnard": "At the moment I just want to listen for http on multiple IPV4 and 6 addresses. That just seemed like a natural extension.\n. Everything's working. Just one last difficulty.\nWhat should the behaviour be if the constructor is passed no listeners?\nIt could return an error.\ne.g. fn listeners<I: IntoIterator<...>>(listeners: I) -> Result<Server, NoListenersError> (I'm reluctant to add another variant to Error just for this case.)\nIt could panic.\nI don't like panics.\nServerLoop::run dies immediately.\nServerLoop::run runs normally (with no listeners)!\n\nI'm a fan of option 4.\nWe wouldn't need a second constructor - Server::new would do :thumbsup:.\nIt makes sense if we add (at some point) the ability to add and remove listeners while the server is running. This is useful from a service apache2 reload point of view and if you want to do a graceful shutdown (i.e. kill the listener then wait a bit before killing all the open sockets).\nIt's pretty easy to check if you've got no listeners and just before starting your server maybe isn't the best place to do it.\n. Thanks. Nits addressed.\n. I'm going to split listeners in to lead_listener and other_listeners to avoid having to unwrap here.\n. Damn. Didn't realise that included the V4.\n. ",
    "natemara": "Thanks! I thought that seemed like an overly restrictive API and I was just misunderstanding it.\n. ",
    "koivunej": "I'd like to take a shot at this. ABNF from RFC here is:\nContent-Location = absolute-URI / partial-URI\nABNF is exactly same as with Referer which is implemented as\n```\nheader! {\n    // TODO Use URL\n    (Referer, \"Referer\") => [String]\n// testcase\n\n}\n```\n/TODO:? Use URL/ is mentioned for Location and Referer headers, so I guess it'd be best to implement Content-Location as simple (ContentLocation, \"Content-Location\") => [String] for consistency?\n. looking at some previous header adding PRs I might've gone too far by adding this into literal!{ ... } in src/header/mod.rs.\nshould I remove it?\n. @seanmonstar I do not think it is, I'll remove it from literals!.\n. ",
    "taheris": "@seanmonstar: no problem, PR created\n. ",
    "farodin91": "Any progress? Could I help?\n. ",
    "jethrogb": "That's frustating indeed...\n. SslContext has the same functions for verification as Ssl.\n. I want to pin to a specific certificate and don't care about hostname verification.\n. Yup, did that. :) \nYou could do\npub struct OpensslClient {\n    ctx: SslContext,\n    default_verify: bool,\n}\n. The RFC doesn't leave room for not including the password:\n```\n   To receive authorization, the client\n\n\nobtains the user-id and password from the user,\n\n\nconstructs the user-pass by concatenating the user-id, a single\n       colon (\":\") character, and the password,\n\n\nencodes the user-pass into an octet sequence (see below for a\n       discussion of character encoding schemes),\n\n\nand obtains the basic-credentials by encoding this octet sequence\n       using Base64 ([RFC4648], Section 4) into a sequence of US-ASCII\n       characters ([RFC0020]).\n```. > Does it make sense to have an Option at all? Or should it actually fail parsing if there is no semi colon?\n\n\nWhat is the behavior for other headers? I thought it'd be ok to be lenient in parsing and just document proper behavior.. Could you do a release?. #309 is closed but the bug still exists?. ",
    "tatref": "I would like to connect to a fake certificate (the certificate does not match the domain), which is currently impossible.\nIt would be really great if we could connect to an invalid domain/ expired certificate / unknown issuer...\nCan I just impl SslClient to make this work?\n. ",
    "smithsps": "``` rust\n[macro_use] extern crate hyper;\nuse hyper::header::{Headers, From};\nfn main() {\n    header! { (MyFoo, \"Foo\") => [String]  }\n    header! { (YourFoo, \"Foo\") => [String] }\nlet mut headers = Headers::new();\nheaders.set(MyFoo(\"bar\".to_owned()));\nheaders.get::<YourFoo>(); //panic\n\n}\n```\nWhen headers.set() is called and a new Item is created with Item::new_typed(), Item raw is only initialized to None. \nThen when Item::typed() is called in headers.get() and there isn't a matching tid, there is a expect  on the type's item's raw, but as its None it panics.\nAnd if you intialize it with Item::raw(), everything seems to work fine.\nBut I'm not confident in my solution, so would it be better to have it in Item::new_typed()?\nrust\npub fn new_typed(ty: Box<Header + Send + Sync>) -> Item {\n        ...\n        let item = Item {\n            raw: OptCell::new(None),\n            typed: map,\n        };\n        item.raw();\n        item\n    }\nOr is it better to use raw() in this fashion, in Item::typed()?\nrust\n    pub fn typed<H: Header + Any>(&self) -> Option<&H> {\n        ...\n                match parse::<H>(self.raw()) {\n                // replacing: self.raw.as_ref().expect(\"item.raw must exist\")\n                    Ok(typed) => {\n                        unsafe { self.typed.insert(tid, typed); }\n                        self.typed.get(tid)\n                    },\n         ...\n    }\n. RFC7231#7.1.1.2 - An origin server MUST NOT send a Date header field if it does not\n   have a clock capable of providing a reasonable approximation of the\n   current instance in Coordinated Universal Time.\nIt'd be uncommon, but it's technically possible that hyper could be used on such a system. \n. @seanmonstar agreed, the only thing I could think of could be clockless embedded device that for some reason didn't have a NTP sync. \n. Looks like there is an existing pull request for this over at https://github.com/hyperium/hyperium.github.io/pull/27 via @lePereT\n. ",
    "bbatha": "I couldn't think of anything that didn't substantially change the design of the header parsing api. I think you'd have to find the salted header first, then make a Header that has name() return a &'a str but this runs into lifetime issues. Most of the hacks I can think of basically boil down to leaking the salted header \"name\" field, but given that it changes every request that is a non-starter.\n. Hmm, that seems like it will work ok. I can make the InsternalAuthSalt struct contain a ref to the raw header name too if I need it. I'll just have to bypass the most of the fmt_header machinery when passing the header through to a a request.\n. ",
    "Darksonn": "I have reached a situation where I need to send headers with dynamic key names. The solution mentioned here allows extracting the header from the headers object, but how can I send a header with a dynamic header name?. As far as I can see when looking at the source code, Client appears to be fully internally reference counted, thus meaning that a Client could be cheaply cloned when needed several places.\nIf this is a suggested pattern for using the client, it should probably be mentioned in the documentation.\n\nRegardin block_on, I'd like to mention an issue I've run into while testing my library which uses hyper under the hood:\nI created a rather complicated future using a bunch of joins and and_thens, which resulted in the type length in the compiler exponentially exploding and requiring annotations like #![type_length_limit=\"4194304\"] to compile.\nI imagine this is related to this issue on the rust compiler.\nNow, large parts of it could be rewritten to a bunch of block_on and avoid the issue.. I realize this might not be the best way to handle it, and maybe one should be doing something else, but I'm not sure what that way is.\n1: https://github.com/rust-lang/rust/issues/54540. @frenchtoastbeer I wrote an example for you here. I believe you missed the into_parts method.\nAs for what futures are.. Well a future is just \"some task that could be performed, and which has this result if we performed it\". As for map, it's a method that \"given some task we could choose to perform, return a new task that could be performed, that first does what the first task did, and then some more\".\nAs for how to actually perform the future, you do it by using either the run method from tokio or by using the spawn method on a [Runtime][5]. You use run if you have one future you want to run, and spawn if you have several. (In fact run just uses a single spawn internally)\n[5]: https://docs.rs/tokio/0.1/tokio/runtime/struct.Runtime.html. @frenchtoastbeer Well I'm just glad I could help. It took me around an hour, although I've already done a bunch of stuff with futures and hyper in the past, as I've been writing a library using hyper (which has been temporarily put on hold until async fn is stable).\nAs for including it as an example, notice that it makes use of spawn, which was mentioned in the top post of this issue, although there should probably also be an example using the other spawn intended for usage inside a future.",
    "NeoLegends": "Please split it up into more crates. People could start depending on only the things they truly need instead of importing hyper as one super big crate.\n. ",
    "habnabit": "I do like that as a possible solution.\n. @seanmonstar not mime? The rest of that looks good, though.. So, I'm not sure if it's something necessarily relevant to this issue, but\nit would be nice to be able to provide my own hyper client provider to a\nlibrary that needs a client without having to modify the library. Neither\nsplitting hyper nor using features would inherently solve this, I think.\nBut, this is at least part of my motivation.\n. ",
    "Stargateur": "I try it, i don't know if i do it well\n``` rust\n![deny(warnings)]\nextern crate hyper;\nextern crate env_logger;\nextern crate num_cpus;\nuse hyper::server::{Server, Handler, Request, Response};\nuse hyper::net::{HttpListener};\nstatic PHRASE: &'static [u8] = b\"Hello World!\";\nstruct Hello;\nimpl Handler for Hello {\n    fn handle(&self, _: Request, res: Response) {\n        res.send(PHRASE).unwrap();\n    }\n}\nfn main() {\n    env_logger::init().unwrap();\nlet listener = HttpListener::new(\"127.0.0.1:3000\").unwrap();\nlet mut handles = Vec::new();\n\nfor _ in 0..num_cpus::get() {\n    let listener = listener.clone();\n    handles.push(::std::thread::spawn(move || {\n        Server::new(listener)\n            .handle(Hello).unwrap();\n    }));\n}\nprintln!(\"Listening on http://127.0.0.1:3000\");\n\nfor handle in handles {\n    handle.join().unwrap();\n}\n\n}\n```\n. ",
    "KokaKiwi": "Aah my bad.\nThe confusion came from the fact that the examples on the master branch doesn't work for the published version (aka the branch 0.9.x) (which is comprehensible since there's a rework in progress)\nThis issue should be closed as not-a-bug :stuck_out_tongue: \n. ",
    "hagsteel": "What about using a hashmap for the query string?\nI imagine that any time you want to work with the querystring you want to work with the values.\ne.g pagination\nlet page = request.query[\"page\"].unwrap();\n. ",
    "ahmedcharles": "Are there tests for Request that I should update? I didn't find any obvious ones. Alternatively, I can write unit tests for Request.\n. Did you notice the test changes and do you know if they are actually correct or is the implementation buggy? It seems like some things that are accepted should be rejected.\n. I implemented all of the suggested changes, though it doesn't fix one of the test cases, since I'm not entirely sure how to go about changing the request uri parser.\n. I guess I didn't run the doc tests. I'll do that. :)\n. No problem. I really like that Rust has a tool for testing documentation, since that's something that's always out of date.\n. I did add it to the readme. I think?. Anything else required?. I was going for consistency and doing it in a way that I don't have to read the RFC and implement correct parsing and interpretation of urls. Url::parse normalizes the urls, and therefore, it makes a copy. It would be weird if normalized paths and queries were returned for AbsoluteUri but not for AbsolutePath.\n. I also found that appealing as an option. Though I didn't want to change the RequestUri enum. Also, I'm not sure what the appropriate design would be. It'd be nice if Url supported parsing partial urls, then it could ignore the domain.\nPerhaps it would be best to implement a custom Url to return as part of AbsolutePath instead of just a String. That way we can return references to owned data while only parsing once, up front.\nI'll take a look and see what I come up with.\n. Ok, I was wondering about that.. I'll give that a try.. ",
    "fanyer": "or should I compile hyper locally ,and Then  introduct it into my project, rather than get hyper with cargo on site of crate.io?  It seems work, but how to add ssl certification\n. ",
    "alexmironof": "I copied whole example/client.rs from master. That server doesn't return utf-8 even if i set AcceptCharset header.\nI've got a workaround using 0.9 version of hyper and encoding crate:\n```\n    let client = Client::new();\nlet mut res = client.get(&*url)\n    .header(AcceptCharset(vec![qitem(Charset::Ext(\"UTF-8\".to_owned()))]))\n    .header(Connection::close())\n    .send().unwrap();\n\nlet mut buffer: Vec<u8> = Vec::new();\nres.read_to_end(&mut buffer);\n\nlet decoded = UTF_8.decode(&buffer, DecoderTrap::Ignore).unwrap();\n\n```\nbut can't figure out how to use it with on_response_readable\n. Thanks for the response!:+1: I've got it working now :smile:\n. ",
    "YetAnotherMinion": "Is there any way to see GitCop without signing up?\n. failures:\n    server_empty_response_chunked\n    server_empty_response_chunked_without_calling_write\n    server_get_chunked_response\n    server_get_fixed_response\ntest result: FAILED. 5 passed; 4 failed; 0 ignored; 0 measured\n. It looks like failing tests on windows were present on master already. Should I be targeting 0.9.x branch instead?\n. @seanmonstar  It's a dev-dependency on master right? That is why I thought it would be a really low impact change because it would not even touch the release code.\nedit: @seanmonstar I did not even realize you were the one who wrote num_cpus in the first place. That has to be strange getting some rando being overly pedantic and telling you what you already did. \n. Is there even any point in updating the num_cpus version? @seanmonstar  You do know best after all...\n. ",
    "kwaegel": "Upgrading may also fix a build issue on Widows, as I mentioned in the linked bug for rust-rosetta: https://github.com/Hoverbear/rust-rosetta/issues/566 .\nUnfortunately, cookie v0.3.0 also depends on rust-openssl v0.7, so fixing the build issue would require an upgrade in that crate as well. Such a change is already in master, but isn't part of a release yet.\n. ",
    "Thomasdezeeuw": "cookie v0.3.1 now depends on v0.8. Is their anything else that is blocking an update to v0.8?\n. @seanmonstar that sounds great, looking forward to it. I would offer help, but I started learning Rust last week and I'm not sure I would be any help.\n. I ran into the same issue, installing a new version of OpenSSL worked for me, by for example running brew install openssl. And then adding the code below to your ~/.profile.\nbash\nexport OPENSSL_INCLUDE_DIR=`brew --prefix openssl`/include\nexport OPENSSL_LIB_DIR=`brew --prefix openssl`/lib\nBasically the rust-openssl package needs headers > v1.0 (?) and the default ones in Mac OS are from version 0.9.8, see https://github.com/sfackler/rust-openssl#osx.\n. ",
    "arcrose": "Is there anything I could do to help speed this process along? My project at work has actually had to drop a couple of features because of the OpenSSL version mismatch between a few of our dependencies, and I'd like to be able to help resolve that if possible.\n. In my case, I need the library to just be using OpenSSL 0.8. The problem is that Hyper's requirement for 0.7 conflicts with some of my other dependencies which now use 0.8. Cargo picks up on the fact that I'm using the Hyper Client and resolves the dependencies to using 0.7 everywhere, which breaks another one of my dependencies which needs 0.8.\n. >Are there still situations that cannot be taken care with either:\n\n\nuse reqwest\nif on the server, set default-features = false for hyper, which removes the openssl dependency\n\n\nWith regards to switching to reqwest, there's the cost of time to actually become familiar with reqwest and then change all of the code in users of Hyper's codebases. As someone running Rust in production, it's not always easy to come up with time to make all the appropriate changes and sufficiently test that no regressions occurred when there are features and other pressing things to look after.\n@seanmonstar Look, hyper is a really popular library. I understand that you may feel there are better alternatives to using the Hyper client today, but asking all of Hyper's users to update their code to an entirely new library is really unfair as one of Hyper's core developers- the amount of time it would take for you to update Hyper and for users to simply switch to the new version totals to far less than what you're suggesting would impose on developers.. I really like this idea. I think that switching to a design that allows users to supply an SslServer or SslClient of their choosing should alleviate the problems I've had.\nI think @seanmonstar has stumbled on something that seems somewhat fundamental to crate design.  If you could, it would be a huge help for other crates also using openssl directly to have a detailed reference of the changes that would be made to resolve this issue so that they can emulate the approach.. I didn't mean so much \"could you explain how to add openssl support\" rather \"could you document the design considerations that others could follow to implement a similarly 'generic over SslClient' approach\".. ",
    "eddyb": "As a side note, it's a shame that https://crates.io/crates/request takes the name even though it looks like development stopped before Rust 1.0, and @ghmlee seemed to have dropped off GitHub :disappointed:.\n. ",
    "dereckson": "This should be prioritized: Hyper crates won't compile out of the box on Debian Sid or Fedora Rawhide, they shipped OpenSSL 1.1 this week, a version only supported in the openssl crate at 0.9.x.\nI've given more context on https://users.rust-lang.org/t/openssl-1-1-and-openssl-0-9-api-breaking-changes/8112. ",
    "ajdlinux": "This is blocking me from upgrading other libraries (git2, to be precise). I'm happy to port over to using reqwest, as our requirements are very much appropriate for a higher-level library like that, but as soon as I started looking into it, I hit https://github.com/seanmonstar/reqwest/issues/30.\nUntil reqwest stabilises and implements at least a few of the more important feature requests that have already been reported, migrating to reqwest isn't going to be feasible just yet. In the meantime an updated hyper would be really helpful!. ",
    "ahwatts": "After hunting through the build scripts for the openssl* crates, I found a combination of environment variables which at least got hyper to build on my Mac:\nexport OPENSSL_INCLUDE_DIR=/usr/local/opt/openssl/include OPENSSL_LIB_DIR=/usr/local/opt/openssl/lib DEP_OPENSSL_INCLUDE=/usr/local/opt/openssl/include\nI hope that helps someone.. ",
    "compressed": "From what I can see, using reqwest does not resolve this issue because reqwest still depends on cookie version 0.2 via its hyper dependency, which brings along openssl 0.7.4.. ",
    "shssoichiro": "@compressed reqwest compiles because it sets default-features = false for hyper. However, this is a conflict if you depend on reqwest and any other crate that depends on hyper with its default feature set (which includes cookie ^0.2). See reem/iron-test#37 as an example.\nInterestingly, OS X will successfully compile a crate despite the above version conflict, but Linux will fail the build.. ",
    "shanegibbs": "@seanmonstar you mentioned that the decoder needed some work. Should I take a pass at a fix for this? Or are you planning on a re-write?\n. As an initial step, I took a quick look at an async test. How does this look: https://github.com/hyperium/hyper/pull/909\n. Fix merged \ud83d\udc4d \n. @seanmonstar I've completed a basic implementation, excluding extensions. See what you think. If okay, I'll continue this pattern to implement extensions.\n. > I'd prefer to merge only after extensions are supported, or else we suddenly no longer work on those peculiar streams sending them.\nAgreed. I'll continue working on this branch.\n. Sure, I can give it a crack \ud83d\ude09 \n. Hmm, looks like tests are broken...\n. Perfect, that did the trick thx @seanmonstar!\nOkay I have literally moved the hup check (see https://github.com/hyperium/hyper/pull/958). This does appear to fix the issue.\nShould I look into tests for this? It wasn't obvious to me how I would go about do this \ud83d\ude09 \n. @jwilm https://github.com/hyperium/hyper/pull/962\n. All gd \ud83d\udc4d \n. @jwilm this makes sense to me. I created another PR https://github.com/hyperium/hyper/pull/962\n. I modified the Echo example to test it -> main.rs\nrust\nlet timer = Timer::default();\nprintln!(\"Press Ctrl-C on client now...\");\nBox::new(timer.sleep(Duration::from_millis(2000))\n    and_then(|_| {\n        println!(\"Sleep done (should not happen if client Ctrl-C'd)\");\n        futures::future::ok(Response::new().with_body(req.body()))\n    })\n    .or_else(|e|\n        let body = format!(\"Sleep failed: {}\", e);\n        println!(\"{}\", body);\n        futures::future::ok(Response::new().with_body(body))\n    }))\nI was hoping the sleep future wouldn't complete. And/or the Echo service is Droped.\nUltimately, rather than waiting for the request to complete, I was interested in doing resource cleanup when the client disconnected. For example, cancel any running database queries.. Can probably have decode as a argument here, and make this just a read_async function to test the other decoders as well perhaps.\n. Oh interesting. I see. Will undo.\n. Ahhh. Makes sense.\n. Fair enough. I'll add some doc \ud83d\ude04 \n. I have observed this panic. I need to investigate how Decoder is called and formulate a test for it.\n. Pretty crude extension parsing for now. If we receive a ; in the size line, we just keep reading until the next \\r.\n. ",
    "fengcen": "Ok. Thank you for the information.\n. ",
    "sinistersnare": "Fixed on master... sorry! Looks like a new release is needed :D\n. ",
    "d13s2": "Looks like this was due to the same problem from #768. Running the following command was enough to fix it!\nsudo apt-get install libssl-dev\n. ",
    "tilpner": "This issue is back again in 0.11.2. The current DNS lookup uses futures_cpupool with CpuPool::new(threads) instead of Builder::new().name-prefix(\"hyper-dns\").pool_size(threads).create(). Well... sure, I just hope the whole stuff is inlined properly. :)\n. ",
    "gsquire": "Ah I see.\nI think the ideal way to do that would be to scan right to left checking the value each time and returning the first valid one. I will make that change. Thanks for your input.\n. I don't think my solution is elegant so I am open to suggestions on improving it.\nI also rebased onto master.\n. I refactored the ugly flow I had before. It should be good to go now.\n. There is work being done to integrate tokio into hyper on this branch already it looks like: https://github.com/hyperium/hyper/tree/tokio\n. Ok, I'll give that shot. I think I misunderstood the idea of a Service before but this makes more sense now.. I'm not reopening this but if you have a second, this is what I came up with. I'm not convinced it's entirely ideal at the moment but it at least works.. ",
    "mabels": "yes I lost early control of this pull request. And did not found the github\nfunction to remove the pull request.\nI will start over again soon\ncheers\nmeno\nOn Sat, Oct 8, 2016, 00:19 Sean McArthur notifications@github.com wrote:\n\nThanks for the PR! Could you clarify you comment a bit?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/pull/924#issuecomment-252374531, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AABLJr2axoO8Kcep7CoLSJeJIIWGgdOxks5qxsVVgaJpZM4KRdN4\n.\n. close it to have a fresh start!\nThere is no way to change the subject later on!\n. \n",
    "sanmai-NL": "@seanmonstar: Or compare benchmarks against the previous revision by rebenching, not committing anything.\n. Every function/method can have its own error type. More general abstractions may seem reasonable now, but have such a large API surface that revising error handling will break code all over the place. The abstraction of Errors as being server or client-related, or problematic vs. not really problematic (your request body streaming comment) is not needed in my view.. @seanmonstar, regarding https://github.com/hyperium/hyper/issues/1130#issuecomment-304724449: \nI\u2019m saying the current abstract distinction between Server and Client in the API is not \u2018needed\u2019 w.r.t. to error handling. With \u2018needed\u2019, I meant to say that it works better to have an error type for every fallible function. That\u2019s simple and always works.\n```rust\n[derive(Copy, Clone, Debug)]\npub enum MyFnError {\n    FailurePathOne { cause: OtherFnError },\n}\nimpl Display for MyFnError {\n    fn fmt(&self, f: &mut Formatter) -> fmt::Result {\n        fmt::Display::fmt(match *self {\n            FailurePathOne::OtherFnError { .. } => \"Failed, ... . \",\n        }, f)\n    }\n}\nimpl Error for MyFnError {\n    fn description(&self) -> &'static str { \"\" }\nfn cause(&self) -> Option<&Error> {\n    match *self {\n        MyFnError::FailurePathOne { ref cause, .. } => Some(cause),\n    }\n}\n\n}\npub type MyFnResult = Result<(), MyFnError>;\n``. @seanmonstar: I do not think it is a problem if programmers do exhaustive matching on theenumthat implementsError. Yes, their code will need some small fixes, but only if they upgrade theirhyperdep. If a newError` variant can be returned and exhaustive matching is done, they probably have to alter the logic in their own code anyway, no?\nI use Error enums extensively (in closed source code),  I did not encounter ergonomic or API stability issues. \nUpdate:\nAlso, note that I do not use error-chain. Producing non-technical but complete \u2018backtraces\u2019 required very little boilerplate code and could be abstracted away easily. Hopefully, you can consider my comment as a data point that keeping things simple and primitive (keeping the status quo wrt. the issue reported) may be a wiser, be it conservative choice.\nUpdate:\nI was unclear in my last sentence. I mean keeping the status quo or better yet, improving error handling in a completely different direction, not splitting hyper::Error into a client and server-related Error.\n. No sorry, I do nothing with hyper::Error variants, did you understand my comment as if I do? I do retain such Error values as the cause field (of some struct variants from some custom Error enum) for my own backtraces. What I am trying to point out is that having one Error type to cover lots of code (e.g. the current hyper::Error, as well as the proposed split into server and client errors) seems less productive to me than having specific Error types. The latter can easily remain enums, since they are specific to some function scope and only break exhaustive matches on values of that specific Error type (i.e., return values of that particular function).. Another general comment: in error handling the viewpoint of regular people needs to be taken into account. I have found this requires tight developer control over error reporting. Backtraces etc. are not very user friendly (may even instill fear), and leak information about the source code, which from a business perspective is intellectual property. For hyper, the user faces the web content and I think hyper has an adequate API to return HTTP status codes and nice error pages. . I hope we all avoid glob imports, but every importable item should have a unique name irrespective of that.. @Hoverbear: Before closing, can you please add a conspicuous warning message to the examples to warn about the version incompatibility? Thanks!\nI was about to ask why https://github.com/hyperium/hyper/blob/12d01e402363a1d7432e878ad43e6345a29e7a21/examples/hello.rs mismatches the current API docs at https://hyper.rs/hyper/v0.10.9/hyper/server/index.html . . @vovagp: So what you mean is you want to control the buffer size? @seanmonstar: Maybe I'm missing something but is this possible? That seems to provide the reporter what he needs to attain the performance he expects.. Alright, I thought you were about to release the redesigned hyper very soon, and so the TLS story we may want to document in advance.. Ah, then we had a miscommunication. I was merely suggesting rustls as an example implementation (that I happen to be interested in most). Currently, AFAICT, there is no documentation on how to set up an HTTP server with TLS given current hyper master at all. Could you point me to such docs, and if absent/incomplete/misplaced, tell me what you'd like the docs to look like? Maybe others like me can do the documentation work then.. I think this can be closed now, since @lucab wrote the example. . @seanmonstar: Hyper doesn\u2019t use tokio-proto anymore since some recent commits of yours, right?. @seanmonstar: Is this a matter of just updating the metadata and other tidbits, or is something else holding this up? Would be nice if casual contributors could take care of this. Maybe what would suffice is an EASY/DIFFICULT tag on the issue.. I fully agree with both of you. I, for one, am only interested in releasing my company's OSS code under Apache 2.0 (or an equivalent more geared towards European IP law). Apache 2.0 appears superior to MIT for general OSS project purposes. So, can this issue be closed until a concrete need arises to revisit the IP matter?. @carllerche: That is strange. Thanks, I didn't recall that fact. That is the position of the Free Software Foundation, based on their interpretation. I do wish to clarify something in relation to your comment. Suppose Hyper grants Apache 2.0 licenses instead of MIT licenses, then this would have no liability consequences for licensees, e.g. they would remain safe if they were granted GPL licenses for other (third-party) components, in the sense that they would not infringe their GPL license per FSF's reading of it. Granting Apache 2.0 licenses would only limit Hyper in that Hyper itself may then not be granted GPL licenses for its own dependencies. \nSo MIT vs. Apache 2.0 is trade-off, Hyper can choose to be bitten by a dog (patent infringement claims) or a cat (GPL license infringement claims) so to say. And all of this is contingent on the basis that the authors of Hyper have indeed granted a license to licensees at all. That is questionable given the lack of signed Contributor License Agreement between all authors and some guardian entity. \ud83d\ude16 I would be more concerned about patent infringement claims than about GPL copyright infringement claims, since parties that hold patents naturally have legal resources while GPL licensors do not.\nUs programmers often relegate these thorny legal issues to lawyers, but it is a fact all of this OSS legalism has hardly been tested in courts and remain speculative. Even lawyers can't give a definite answer.. @kamalmarhubi: interesting, yet I personally have no idea how user clients could browse a website via Unix domain sockets. What would the purpose of such a feature be?. @seanmonstar: Do you have any idea how hard it will be to migrate Hyper + rustls to the new API? \nSee ctz/hyper-rustls#36. How could we adapt hyper-rustls to not use tokio_proto::TcpServer::new?. @seanmonstar: could you let me know when you plan to review this?. @LegNeato, @seanmonstar: done. @seanmonstar: okay great, but when is a review planned, if any?. @seanmonstar: would it be okay to merge this PR, for the time being? Nobody is going to look up a stale PR branch to reuse any of this work, so it\u2019d be a waste. Even if you plan to release the redesigned hyper version soon, then at least I could pin hyper to an older version that still has the header module, along with this enhancement.. No there isn\u2019t. I was under the impression that the new headers crate will not be API-compatible with the old module. Apart from that, I assumed that the starting point in terms of headers to reimplement would be the original Hyper headers module, and so that it would matter for everyone whether this PR gets merged or is left depending on further initiative.. @seanmonstar: not meaning to press you on this at all, but very curious how in retrospect you feel about making a substantial change to Hyper in a patch release, the coming about of this bug, your decision to fix it with a new patch release without yanking the affected version? Is there something about this chain of events that you take as a lesson? \nAre you planning to yank 0.11.13?. @seanmonstar: thanks for sharing your thoughts. Again, not trying to press you. You do great work and I haven\u2019t paid for it. Also, be clear there\u2019s no question in my mind you addressed the bug well!\nI personally felt the bug is serious, because it hangs the server and doesn\u2019t even trigger a crash. So it would be possible that someone deploys some service with an updated (patch release) Hyper dep and then suddenly suffer from unavailability of all POST endpoints. Basically it\u2019s also a DoS vuln.\nThose are my 2 cents.. One test failed locally:\n```\nfailures:\n---- client::connect::http::tests::client_happy_eyeballs stdout ----\nthread 'client::connect::http::tests::client_happy_eyeballs' panicked at 'assertion failed: (left == right)\n  left: 4,\n right: 6', src/client/connect.rs:1022:17\nnote: Run with RUST_BACKTRACE=1 for a backtrace.\nfailures:\n    client::connect::http::tests::client_happy_eyeballs\n``\nShould be unrelated.. I found that I also needhttp::request::Parts. How about reexporting all ofhttprather than selectively?. I\u2019m not sure I understand your last sentence.. Yes, justhyper::http; as that would be the effect ofpub extern crate ...;, which I still see as the main way to reexport. It could indeed be something else withpub use.. @seanmonstar, done. See also rust-lang-nursery/api-guidelines#176. I think the action that could be taken to address this is to document the API changes v0.11 -> v0.12 a bit better.. Imagine someone new tohyper. First thing he or she will do is adding it as dependency. Then they\u2019ll ask themselves what features to enable inCargo.toml. So, the best place would be the README being the first encounter with docs. This short overview of features can contain a pointer perhaps to some elaboration in the API docs. . Allright, one thing I see consistently, with or without anyhttp*_only()` call, is this:\n```\n Uses proxy env variable no_proxy == '127.0.0.1,10.0.0.0/8,192.168.0.0/16,172.16.0.0/12,::1,fd00::/8, localhost,.localdomain'\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0   Trying ::1...\n TCP_NODELAY set\n Connected to localhost.localdomain (::1) port 8082 (#0)\n ALPN, offering h2\n ALPN, offering http/1.1\n successfully set certificate verify locations:\n   CAfile: /etc/ssl/certs/ca-certificates.crt\n  CApath: none\n} [5 bytes data]\n TLSv1.2 (OUT), TLS handshake, Client hello (1):\n} [219 bytes data]\n TLSv1.2 (IN), TLS handshake, Server hello (2):\n{ [89 bytes data]\n TLSv1.2 (IN), TLS handshake, Certificate (11):\n{ [5058 bytes data]\n TLSv1.2 (IN), TLS handshake, Server key exchange (12):\n{ [300 bytes data]\n TLSv1.2 (IN), TLS handshake, Server finished (14):\n{ [4 bytes data]\n TLSv1.2 (OUT), TLS handshake, Client key exchange (16):\n} [37 bytes data]\n TLSv1.2 (OUT), TLS change cipher, Client hello (1):\n} [1 bytes data]\n TLSv1.2 (OUT), TLS handshake, Finished (20):\n} [16 bytes data]\n TLSv1.2 (IN), TLS handshake, Finished (20):\n{ [16 bytes data]\n SSL connection using TLSv1.2 / ECDHE-RSA-AES256-GCM-SHA384\n ALPN, server did not agree to a protocol\n Server certificate:\n  subject: CN=testserver.com\n  start date: Aug 13 16:07:04 2016 GMT\n  expire date: Feb  3 16:07:04 2022 GMT\n  issuer: CN=ponytown RSA level 2 intermediate\n*  SSL certificate verify result: self signed certificate in certificate chain (19), continuing anyway.\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0} [5 bytes data]\n\nGET / HTTP/1.1\nHost: localhost.localdomain:8082\nUser-Agent: curl/7.61.0\nAccept: /\n{ [5 bytes data]\n< HTTP/1.1 307 Temporary Redirect\n...\n< \n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n...\n* Connection #0 to host localhost.localdomain left intact\n```\n\nNote:\n* ALPN, server did not agree to a protocol\nThis means curl could not agree with hyper to use HTTP 2 or any protocol, so defaults to HTTP 1.1. (curl/curl#2749).\ncURL\ncurl 7.61.0 (x86_64-pc-linux-gnu) libcurl/7.61.0 OpenSSL/1.1.0h zlib/1.2.11 libidn2/2.0.5 libpsl/0.20.2 (+libidn2/2.0.4) nghttp2/1.32.0\nRelease-Date: 2018-07-11\nProtocols: dict file ftp ftps gopher http https imap imaps pop3 pop3s rtsp smb smbs smtp smtps telnet tftp \nFeatures: AsynchDNS IDN IPv6 Largefile GSS-API Kerberos SPNEGO NTLM NTLM_WB SSL libz TLS-SRP HTTP2 UnixSockets HTTPS-proxy PS\nAfter resolving this issue, I will try to make a better reproducible example of the defect in hyper I suspected for my \u2018HTTP 2 only\u2019 requirement. Any ideas?. Thanks, I fixed the ALPN issue.\nWith rustls ALPN configured to accept h2 and http1.1, http2_only(true), some kind of corrupt response data are sent:\n```\n  curl --http1.1 --location -k -v https://localhost.localdomain:8082/ | hexdump\n Uses proxy env variable no_proxy == '127.0.0.1,10.0.0.0/8,192.168.0.0/16,172.16.0.0/12,::1,fd00::/8, localhost,.localdomain'\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0   Trying ::1...\n TCP_NODELAY set\n Connected to localhost.localdomain (::1) port 8082 (#0)\n ALPN, offering http/1.1\n successfully set certificate verify locations:\n   CAfile: /etc/ssl/certs/ca-certificates.crt\n  CApath: none\n} [5 bytes data]\n TLSv1.2 (OUT), TLS handshake, Client hello (1):\n} [216 bytes data]\n TLSv1.2 (IN), TLS handshake, Server hello (2):\n{ [89 bytes data]\n TLSv1.2 (IN), TLS handshake, Certificate (11):\n{ [5058 bytes data]\n TLSv1.2 (IN), TLS handshake, Server key exchange (12):\n{ [300 bytes data]\n TLSv1.2 (IN), TLS handshake, Server finished (14):\n{ [4 bytes data]\n TLSv1.2 (OUT), TLS handshake, Client key exchange (16):\n} [37 bytes data]\n TLSv1.2 (OUT), TLS change cipher, Client hello (1):\n} [1 bytes data]\n TLSv1.2 (OUT), TLS handshake, Finished (20):\n} [16 bytes data]\n TLSv1.2 (IN), TLS handshake, Finished (20):\n{ [16 bytes data]\n SSL connection using TLSv1.2 / ECDHE-RSA-AES256-GCM-SHA384\n ALPN, server did not agree to a protocol\n Server certificate:\n  subject: CN=testserver.com\n  start date: Aug 13 16:07:04 2016 GMT\n  expire date: Feb  3 16:07:04 2022 GMT\n  issuer: CN=ponytown RSA level 2 intermediate\n  SSL certificate verify result: self signed certificate in certificate chain (19), continuing anyway.\n} [5 bytes data]\n\nGET / HTTP/1.1\nHost: localhost.localdomain:8082\nUser-Agent: curl/7.61.0\nAccept: /\n{ [5 bytes data]\n100     9    0     9    0     0    529      0 --:--:-- --:--:-- --:--:--   529\n* Connection #0 to host localhost.localdomain left intact\n0000000 0000 0400 0000 0000 0000             \n0000009\n```. > and then sending an HTTP2 request seems to be erroring, as expected...\n\nSo, it comes down to what erroring means here?. If a request comes in with an incompatible HTTP version specified, hyper should close the connection?. To me it does. (But I haven\u2019t spent the time to dig into this issue to give you any more confirmation/knowledge than you already have.). @AlexDvorak: I didn\u2019t have one really, it\u2019s just a curl invocation.. Does TCP_NODELAY mediate the issue?. Although the implementer notes an error log entry would be emitted, he/she does not indicate how to control and view this error log. E.g., what env. var. should be set and for which path?. I invite @klausi (issue reporter and main implementer) and @aep (discussion contributor) to this discussion.  . @seanmonstar Perhaps yes.\nCould you please point me to the code and the rationale for this behavior in nginx or Netty? nginx isn\u2019t a library AFAIK so the error handling strategy would be different.. See also #1712.. ",
    "zimond": "alert: I am keeping an eye on tokio branch and as far as I can say, the branch is broken and could not even compile. So if you want to try tokio-hyper (like me) try a fork\n. @seanmonstar what is pretty_env_logger in tokio branch?\n. @seanmonstar The latest commit is still breaking. If I set server response.body to something larger than a slice(4096), hyper will panic on assertion of self.available() > data.len() in src/http/buffer.rs\n. Another question: If I want to curl download something using tokio-curl, a handle to tokio-core event loop is needed. Any ideas how to get a handle in a NewService implementation?\n. Fine, I asked in tokio gitter channel. Would it be possible that hyper provide a new trait which inherit NewService with an API like new_service_with_handle or something? Just a rough thought.\n. @seanmonstar thanks!\n. closed by  cfcbd8c. seems updated\nhttps://www.techempower.com/benchmarks/#section=data-r14&hw=ph&test=json. ",
    "dimbleby": "This sounds great.  \nDo you have any view on a likely timetable for getting this to a point where it can be released?  Is there anything that the rest of us can do to help?\n. ",
    "scottlamb": "Do you have plans to broaden the definition of Chunk? Or would you be open to discussing doing so, here or in a new issue? It's currently this:\nrust\n/// A piece of a message body.\npub struct Chunk(Vec<u8>);\nI'd love for it to be something that lets me avoid copying into a temporary vector in favor of using a &[u8] I already have. (My project has a few cases where this would be useful; I'd be happy to describe them if desired.)\nOne practical approach might be to use an enum based on the owning_ref crate:\nrust\n/// A piece of a message body.\npub enum Chunk {\n    Static(&'static [u8]),\n    Vec(owning_ref::VecRef<[u8]>),\n    Box(owning_ref::BoxRef<[u8]>),\n    Rc(owning_ref::RcRef<[u8]>),\n    Arc(owning_ref::ArcRef<[u8]>),\n}\nwhich I think would let you do anything without copying, although some things would need a reference count or indirection (extra memory allocation / pointer to chase) per chunk.\nA couple other approaches that I considered but don't think are actually possible: (1) some way of exposing a 'lifetime parameter associated with a particular request, (2) some way of associating a parameterized Context (or owner) with each Response or Body + having each chunk take a Fn(&Context) -> [u8].\n. Also relevant in the tokio-based master branch. I confused myself with poor benchmark results (again!) until @carllerche mentioned Nagle's algorithm. When I applied this hacky patch:\n```\ndiff --git a/src/server/mod.rs b/src/server/mod.rs\nindex eb87a62..d6d54d7 100644\n--- a/src/server/mod.rs\n+++ b/src/server/mod.rs\n@@ -378,6 +378,7 @@ impl Server\n     // Future for our server's execution\n     let srv = listener.incoming().for_each(|(socket, addr)| {\n\n\nsocket.set_nodelay(true).unwrap();\n             let s = NotifyService {\n                 inner: try!(new_service.new_service()),\n                 info: Rc::downgrade(&info),\n```\n\nit got better.\n. This API already will make it possible to avoid copying in several cases, but I'd prefer it use the owning_ref crate. That would let callers can supply anything that can give them a &[u8] owned in any of the usual ways. That is, replace this:\nrust\nenum Inner {\n    Owned(Vec<u8>),\n    Referenced(Arc<Vec<u8>>),\n    Mem(MemSlice),\n    Static(&'static [u8]),\n    // ...possibly EasyBuf as mentioned in the previous comment...\n}\nwith this:\nrust\nenum Inner {\n    Static(&'static [u8]),\n    Vec(owning_ref::VecRef<[u8]>),\n    Box(owning_ref::BoxRef<[u8]>),\n    Arc(owning_ref::ArcRef<[u8]>),\n    // ...I also mentioned owning_ref::RcRef in #934 but now think it wouldn't actually work...\n}\nand add From implementations that accept the respective owning_refs. All of the existing Froms could be matched with the new Inner.\nHere are a couple examples of how I'd use the extra flexibility in a real program (which does HTTP range serving of .mp4 files with the actual frames of video taken from files on disk and everything else from a SQLite database by dividing up into a bunch of \"slices\" of the file's byte positions generated in various ways):\n\nrunning arbitrary code on Drop. I have a little struct that wraps memmap::Mmap; it does a munmap and close when dropped. I'd like to create a Chunk that references that rather than copying. (Although there's a caveat that when doing mmap, it'd also be good to control which thread reads the memory in question; if pages have to be faulted in from disk, that thread can get stuck for a long time. I don't haven't looked into how that control would work with tokio and don't know if you'll ever be interested in supporting it.)\nsubslices of a vector. I actually have a few cases where this happens: a shared per-request buffer which the boring parts of the .mp4 file are generated from (becomes a bunch of slices/Chunks interspersed with ones generated in other ways), slices that are most efficiently generated all or nothing then trimmed to become Chunks of the HTTP byte range request doesn't want all of them, and a few slices that are always generated together and can be placed in a single allocation.\n\n\n\n(I think my use case stresses this API more than most; I'd be happy to tell you more about it if you're interested.)\nThe only other improvement I can think of would be if the stuff that needs to reference a per-request object could avoid reference counting by the chunks having some per-request lifetime bound. But I haven't done any benchmarking to see if an atomic reference count on each chunk is a noticeable performance impact in my program (or any realistic scenario, for that matter), and I'm not even sure what I'm vaguely describing is possible in safe Rust code.. > As for memmaped slices, that sounds like the possibility of a bad time, if the memory is on disk and not in RAM when hyper tries to deref the slice to write into the socket. That blocking file IO could really hurt the performance of the event loop. I'm also not sure how to ask for an async deref, such that the loading could be done on another thread. It sounds like it would complicate a lot of things.\nOkay. I'm not too surprised to hear you say that. I was thinking about it; instead of controlling which thread accesses the chunk, maybe I can get the same effect by calling mlock from a thread I choose before giving you the chunk. I probably want to use smaller chunks then (so I can send the first byte of the file before the last byte is read), and I have to be more careful about how much I have in flight to avoid running out of memory, so it's more complexity at the application layer, but I think it's possible and maybe even simpler overall.\nAnyway, if the mlock approach doesn't work out and I end up wanting help from hyper with controlling the thread that accesses the memory, I'll open a separate issue as it's clearly a whole other thing to consider.\n\nI tried looking through the owning_ref crate, and had a hard time understanding it's purpose.\n\nI just worked through an example which I think will make this clearer to both of us. (It showed me that I had the wrong Inner definition above which probably wasn't helping.)\nHere I'm using it for the mmap case. I'm starting with a Box<memmap::Mmap>, turning that into a BoxRef<memmap::Mmap, memmap::Mmap>, using the map member function to turn that into a BoxRef<memmap::Mmap, [u8]>, and then using the erase_owner member function to turn that into an ErasedBoxRef<[u8]>. The Chunk can keep around an ErasedBoxRef<[u8]> and know that it has a [u8] it can keep as long as its wants. When it drops that reference, the Box is dropped, and the munmap call happens along the way. (I verified with the strace utility that the munmap call actually happens as hoped.)\n```rust\nextern crate owning_ref;\nextern crate libc;\nextern crate memmap;\nuse std::io;\nuse std::fs::File;\npub struct Chunk(Inner);\nenum Inner {\n    Static(&'static [u8]),\n    Vec(owning_ref::VecRef),\n    Box(owning_ref::ErasedBoxRef<[u8]>),\n    Arc(owning_ref::ErasedArcRef<[u8]>),\n}\nimpl From> for Chunk {\n    #[inline]\n    fn from(r: owning_ref::BoxRef) -> Chunk {\n        Chunk(Inner::Box(r.erase_owner()))\n    }\n}\nfn main() {\n    let f = File::open(\"f\").unwrap();\n    let mmap = Box::new(\n    memmap::Mmap::open(&f, memmap::Protection::Read).unwrap());\n    if unsafe { libc::mlock(mmap.ptr() as *const libc::c_void, mmap.len()) } < 0 {\n        panic!(\"{}\", io::Error::last_os_error());\n    }\n    let mmap = owning_ref::BoxRef::new(mmap);\n    let mmap = mmap.map(|m| unsafe { m.as_slice() });\n    let chunk: Chunk = mmap.into();\n}\n```\nLikewise, when I want to trim a vector before sending it out on the wire, I can stuff it into a VecRef<u8, [u8]> and then use map to get a subslice to put into the chunk. The chunk owns the whole vector but only sees part of its contents.. I have a dumb question orthogonal to our owning_ref discussion: how do I send more than one Chunk? Is there an example somewhere?\nIn particular, a Service returns a Future<Item=hyper::server::Response, Error=hyper::Error>. If I have just one Chunk, I can call set_body(chunk) on the Response before returning it. But if I have more than one Chunk, that deadlocks. (The TokioBody has a mpsc::channel(0), which only allows the one Sender to have one value in flight.) So I need to send the chunks after the future is resolved. So I need to call ::tokio_core::Handle::spawn myself with the future, I think? But how do I get access to the Handle from my Service? My best guess so far is to stash away server.handle().remote() into a lazy_static from main, then use Remote::spawn from my Service to get a handle to launch futures. That doesn't seem ideal.... > I think I understand now how owning_ref works. Essentially, having b\"Hello World\".to_vec(), but wanting to send a chunk that only references the bytes of b\"World\", right?\nYeah, that's among the things you can do with it, via something like this:\nrust\nlet v = owning_ref::VecRef(b\"Hello World\".to_vec()).map(|v| &v[6..]);\nlet chunk: Chunk = v.into();\n\nAt the same time, I'm wary of linking hyper's public API to owning_ref, if for no other reason than I feel like owning_ref is an obscure crate. Maybe that feeling is baseless, or maybe there's another way to get a similar affect without relying on that crate?\n\nI dunno what to say about that feeling\u2014on the one hand, it has an order of magnitude fewer downloads than hyper, on the other it's a relatively small amount of code and has been maintained for the past 18 months.\nFor the b\"Hello World\" -> b\"World\" case, it looks like there's a ::tokio_core::io::Window that does something similar. But I don't think it does the type erasure thing, so I don't know how I'd use it for the mmap stuff. And I think you'd need basically a non-window + window version of each of the current enum variants.\n\nSo, you must spawn some sort of other task that will try to send more chunks into the body as they become available, and the body has room.\n\nHow do I do that? I think I need a ::tokio_core::Handle and don't know where to get one easily. Maybe I'm just asking for it to be given as a parameter to NewService::new_service. Or maybe what I want is already easy and I'm missing it; I'm totally new to tokio.... fwiw, I think that's a one-liner already (untested): body.fold(Vec::new(), |a, b| { a.extend_from_slice(&b[..]); futures::ok(a) }). Hmm, I think that would give me the ability to subset a Chunk, but not to have it backed by something more complex than a Vec<u8> as in the mmap example I gave above.. mlock from a worker thread seems like it would address the pause concern. It requires a thread handoff for each chunk, but given that no one actually uses aio_read, so does any approach to filesystem I/O other than doing writes from non-reactor threads or having enough reactor threads (with a shared event loop and/or work stealing) to not care if one blocks on disk, and I gather you and the tokio folks are looking to avoid those.\nI should answer your question about if this is worthwhile with a benchmark. I'll try to work one up, but I apologize in advance for slowness: I have a tiny amount of time for my Rust projects every week and have been spreading that kinda thin, so nothing I do goes fast. I did look at it for a moment tonight and realized a problem with using owning_ref::ErasedBoxRef<[u8]>: that type isn't Send. D'oh.\nIntuitively, it seems a little silly IMHO to go to the effort of the switch from sync to async (with all the pain of a non-intuitive programming model, the danger of accidentally doing slow/blocking stuff on the wrong thread, etc), in the name of performance (I think that was the main goal?) and then have to do context switches between every read and write and do extra copies. But maybe it comes down to a choice about what's important to optimize: small requests or large requests, serving from the filesystem or from elsewhere, etc. When I mention using mmap and avoiding copies, I'm thinking about filesystem-based responses much larger than the CPU cache.. I brought up mlock because it makes a guarantee: on successful return, the memory is paged in and will stay that way until munlock or munmap is called. So if you call it from a worker thread and then pass the reference to the reactor thread, you can be absolutely confident accessing that memory won't cause the reactor to pause.\nposix_fadvise, posix_madvise, and readahead don't do that. They might do nothing. Even if they read the file into RAM, they don't tell you when it's done, and they don't guarantee it won't be immediately undone. Calls to read (for traditional IO) or memory accesses (for mmap) can still pause.. I've done my homework now, so I can answer @seanmonstar's question:\n\n@scottlamb you're right, I forgot about mmap. Asking in the tokio room, the suggested advice was basically \"don't do that\", because of the pauses in the event loop that can occur from loading the memory from disk. With those warnings, do you still find it compelling to try to do it anyways?\n\nYes. It's compelling.\nI hacked together a benchmark on this branch which serves a file in eight modes:\n\ninline-direct-read will read a file and serve it directly from the reactor thread. It's the simplest thing but the blocking read can pause the reactor thread.\ninline-copy-read will read a file and throw in a totally unnecessary copy just for comparison's sake.\ninline-direct-mmap will mmap a file and serve it directly using owning-ref. Also can pause the reactor thread.\ninline-copy-mmap will mmap a file and copy it before serving, as is necessary with the current API.\nthreaded-direct-read is like inline-direct-read but does the blocking stuff in a CpuPool.\nthreaded-copy-read, also uses a CpuPool.\nthreaded-direct-memmap, likewise. It uses mlock to avoid stalling the reactor when the memory is accessed.\nthreaded-copy-memmap does the copy from the thread pool; it doesn't need mlock.\n\nI created a 1 MiB file (dd if=/dev/zero of=f bs=1M count=1) and added the line * - memlock unlimited to /etc/security/limits.conf so mlock would work.\nThen I ran it, restricting to a single core:\n$ taskset --cpu-list 0 cargo run --release --example server\nand used wrk to benchmark, giving it the other cores:\n$ for i in {inline,threaded}-{direct,copy}-{read,memmap}; do taskset --cpu-list 1-3 wrk http://localhost:1337/$i; done\n(I also ran each in a longer mode, used top to verify it was CPU-bound, and glanced at a few CPU profiles gathered with perf record -e cycles -p $(pidof server) --callgraph=dwarf, viewed via perf report -g --children, and didn't see any huge surprises.)\nHere are the results on my laptop:\n\ninline-direct-read: 1.15GB/sec\ninline-direct-memmap: 3.37GB/sec\ninline-copy-read: 868.08MB/sec\ninline-copy-memmap: 1.24GB/sec\nthreaded-direct-read: 0.98GB/sec\nthreaded-direct-memmap: 2.05GB/sec\nthreaded-copy-read: 566.26MB/sec\nthreaded-copy-mmap: 0.89GB/sec\n\nIf I were being rigorous, I would run it several times and calculate error bounds, and I would do it directly on hardware (I'm using Ubuntu 15.04.1 LTS on VMware Fusion on a new Macbook Pro now), but it's not even close. Direct mmap is much faster than with a copy or using read.\n(Also, avoiding thread handoffs seems to be a noticeable difference. I'm a little surprised; I thought they'd be insignificant with such large responses.)\nOn this machine, one core can easily saturate 1000Mbit/sec Ethernet in the slowest mode so there's no problem anyway, but the software I'm writing is intended to run on cheap ARM hardware where it matters more.. Thanks. Glad you liked the benchmark.\nYour newest proposal sounds great to me\u2014I'd have all the flexibility I was looking for with owning_ref, without hyper needing to depend on that crate, and potentially without some overhead of boxing and match or trait dispatch.\nI agree some libraries probably will accidentally take away that flexibility, but I don't know if any of the other ways we discussed would prevent that anyway. Rocket decided with the hyper 0.10.x to design its API to require a Read instead of matching hyper's Write, so it requires an extra io::copy between. I don't know what hyper could have done to anticipate or avoid that. I think there's no answer but to be careful at every added layer...\nI also agree there are caveats to mmap, btw. A big one is that if the file gets truncated while you're reading it, your program will crash with SIGBUS. It's not a concern for my application (which runs as its own user and is the only thing that can read or write the files it's serving) but it means read is a better default.. @seanmonstar wrote:\n\nI haven't explored it yet, but it might be nice if the supplied body stream didn't need to actually emit hyper::Error, but just E: Into. That'd mean that io::Error would just work...\n\nMaybe a dumb question, but what is this error used for? I think it's basically just for hyper to know that it should drop the connection to indicate error to the HTTP peer? I think even Error = () would suffice for that. Given that applications/libraries are the ones producing the error, they can do logging and such themselves in whatever way they desire.\nhyper::Error is kind of weird for this in that its documentation states that it's \"A set of errors that can occur parsing HTTP streams.\", which is way more specific than \"any sort of error an application could encounter that prevents it from fully generating a HTTP stream\".\n(By the way, there probably should be some way for hyper::server to tell the application if the whole response including the last chunk was fully written or not, but I think that's a separate concern from the body stream.)\n@abonander wrote:\n\nI don't think Client should be parametric over the body stream, because that prohibits using different stream types with the same Client.\n\nI think the server side is actually similar: there's only one Service, and so only one definition of B. If frameworks (such as Iron, Rocket, etc) want to define any higher-level stuff (such as having an option to build simple synchronous handlers that use io::Write as in hyper 0.10.x), they'll end up having to state an opinion about what B should be. (Hopefully they'll leave an escape hatch such as an enum variant for custom stuff like what I want to do with mmap.) It'd be nice if it were possible to avoid forcing them to make this choice, but I think it's still significantly better than hyper being too rigid. It seems like the Rust web ecosystem has almost everything based on hyper, and then various frameworks on top of that. This hyper interface gives them the flexibility to experiment, and low-level performance-oriented code can avoid using a framework entirely and still not have to reinvent hyper.. @mikeycgto, I wonder if your busy-looping is a bug in tokio or mio. I'm also seeing terrible performance with somewhat different code (a CpuPool sending chunks over a futures::sync::mpsc::channel), and just filed a bug about it in tokio:\nhttps://github.com/tokio-rs/tokio-core/issues/177\nI don't understand the problem well enough to know if it's related to what you're seeing or not.. I like Payload! Thanks!. I think any of Payload, Content, or Transfer would work well. I searched through RFC 7233 and didn't see any usage of any of those terms that's inconsistent with what this trait does. Mild preference for Payload still; no particular reason.. I think you're in luck. (And me; I've been wanting this too.) Looks like 0.12.x is going to add it. See Body::wrap_stream on master and #1438.. btw, even now on 0.11.x, you don't have to use Body at all; you can instead use something like hyper::Response<Box<Stream<Item = Vec<u8>, Error = Error> + Send>>. The downside is that you may be giving up compatibility with libraries/frameworks that expect Body.. fwiw, I'm looking forward to the hyper 0.12.x API changes and would be sad if it were delayed for months because of this. futures 0.3 is apparently coming \"relatively soon\", but it will be nightly-only at first, so unsure when it's actually coming for stable.. Thanks for ccing me, and sorry I'm a little late to the party.\nI'm a little confused about the desired benefits. From the first comment, it sounds to me like you're confident that the pre-existing writev optimization you mentioned is working well in all the same situations, but you're afraid application writers might not know this. Is that accurate?\n\nIf so, it seems like a shame to complicate the interface. Could documentation changes accomplish the same result? (I'd also think anyone who really cares about that will probably end up looking more closely anyway with a profiling tool / strace / etc. to see if whatever they're doing is actually working.)\nIf not, what's the gap you're concerned about? I suppose maybe that there's a race between the application adding a bunch of chunks from another thread and hyper consuming them; if hyper is too fast, less gets combined?\n\nfwiw, I mentioned on reddit the idea of a different chunk bound than AsRef<[u8]>, but I had a different set of benefits in mind. Maybe bytes::Buf is a step toward those as well, but if so the next step isn't obvious to me:\n\nselectively wrapping blocking around the dereferences (which is something I'd love to do). Does Buf help with this? It's not obvious to me how, but maybe there's some other work here I'm unaware of in tokio/bytes/etc. I guess it might be possible to do this with Buf (or even the existing AsRef<[u8]>) if blocking were split into start_blocking and end_blocking (the former could be called in bytes/bytes_vec, and the latter on drop), but maybe there's too error-prone an interface because it adds the potential of the calls being unbalanced.\nperhaps using sendfile instead of accessing the bytes at all, when writing directly to a socket (http or some fancy Linux thing that tells the kernel to do the outbound encryption.) (This isn't something I personally have any plans now to use, but iirc someone else was asking about it a while back.) Would bytes::Buf get some hook for this? (I'm not actually sure how it'd work anyway with the support for writev merging across chunks; I guess if you already have a non-empty IoVec might merge this chunk into, you'd need some way of deciding not do to that so you can later call sendfile instead. So a couple new methods, one to say if it wants sendfile, another to actually use sendfile.). > maybe you could gain a little bit of performance if it were just a single Buf (and thus, only a single poll_data call), and have some optimized way of accessing all the slices over hyper's generic VecDeque.\n\nInteresting, thanks. It's not clear to me at first glance that a poll_data call or the VecDeque operations would be expensive, but I'm sure you've thought about this more than I have.\n\n\nwrapping blocking around the dereferences\n\n\nSorry, I was oversimplifying by partitioning the world into \"my application\" vs \"hyper\" without thinking about the details of how hyper interacts with tokio and such. But hyper is the thing my application is sending the chunks to. If I want to provide an AsyncWrite implementation on the other side that selectively uses blocking, how can I pass to it (through hyper) whether this chunk is one that needs blocking or not?\n\n\nI think this would something about Payload, not the individual chunks, right? ... Or, perhaps not, if you needed to send multiple files, or only regions of certain files?\n\n\nThere definitely exist applications that do both those things. For example, my moonfire-nvr composes arbitrary-length .mp4 entities from metadata it assembles on-the-fly and from parts of one or more on-disk files.\n\nI've been thinking about this on and off, and I think it could be done best with specialization.\n\nInteresting. I'll have to study how that works. Maybe it's also the answer for my question above about blocking. Too bad specialization's still unstable, though.. Oh, I hadn't noticed #1505. It's double-boxing, though. Yeah, something like S: Into<Box<Stream<...>>> sounds promising.. ",
    "clemensw": "tokio branch wouldn't build for me.  Updating to the available crate-based dependencies seems to fix the issue. (#963). ",
    "shimauoh": "I'm facing the same, although i download OPENSSL for windows (openssl-win64) nothing changed , still  the same message \"openssl/bn.h\" no such file or directory .. any one can help , note: i am trying to run a cryptographic proof of data integrity written in C on windows8 machine ... ",
    "efskap": "Needed apt install libssl-dev to fix this on Ubuntu, in addition to apt install openssl. ",
    "3Hren": "This is useful for example when writing a proxy server for HTTP <-> binary <-> HTTP prototol chain.. Here is more verbose dump to be sure that the entire HTTP frame was received: http://paste.org.ru/?5l7p0z. > Hm, so are you able to reliably reproduce this? \nI am. I'm very interested in fixing this, you can ping me 24/7 :)\n\nIs there a server I can set up myself to see this?\n\nUnfortunately it's private right now. I'll try to extract a minimal reproducable example, but it takes time...\nDo you have any ideas what it can be?. Just tested on linux (above) and OS X, hangs on both.. JFYI I've tried minihttp, the problem exists... Seems like the bug is somewhere either in my code or in mio/tokio. Will investigate it more precisely, but I think we can close this issue.. > Huh, so you're receiving a TCP stream, not processed by hyper or some other HTTP lib?\nYep, exactly. \n\nI searched around in other HTTP libs, and didn't find an option in them to do this either. My initial feeling is that sounds like quite the footgun.\n\nI had that feeling too :) Okay, is there a way in hyper to eat a body (no matter encoded or not) and then to obtain decoded body?. Seems like (not sure 100%, but gdb prints that msg has 0 length) that there is an attempt to write a zero-sized slice here: https://github.com/hyperium/hyper/blob/master/src/http/h1/encode.rs#L51, which results in EWOULDBLOCK. Then flushing (here: https://github.com/hyperium/hyper/blob/7ce31211320d76c1bc60493b62d1e9ecfbff8048/src/http/conn.rs#L365) succeeds, because tokio_core::net::tcp::TcpStream::flush is a no-op (https://github.com/tokio-rs/tokio-core/blob/master/src/net/tcp.rs#L507). And because queue_finished is false, we got infinite userland looping without syscalls.\nAny ideas how it can be?. Thanks for the answer!\nWell, hanging was fixed, but now nginx replies with upstream prematurely closed connection while reading response header from upstream.\nNot sure if these two issues are connected.. Sure, will do tomorrow.. The following things happened:\nbash\nJul 18 12:03:28.262 TRCE parse(b\"GET\\x20/brconfigs__prestable__v012/get-brconfigs/known_antivirus?brandID=yandex&partnerID=common-yandex\\x20HTTP/1.1\\r\\nHost:\\x20api.browser.yandex.net\\r\\nX-Real-IP:\\x20185.58.188.40\\r\\nX-Request-Id:\\x2082effe37adf42c9a\\r\\nX-Forwarded-For-Y:\\x20185.58.188.40\\r\\nIf-None-Match:\\x20\\\"94aa7472983570cc5f2ac69ad00a2a5039c8ae988857c6f4758f98227013af75\\\"\\r\\nUser-Agent:\\x20Mozilla/5.0\\x20(Windows\\x20NT\\x206.1)\\x20AppleWebKit/537.36\\x20(KHTML,\\x20like\\x20Gecko)\\x20Chrome/58.0.3029.110\\x20YaBrowser/17.6.1.749\\x20Yowser/2.5\\x20Safari/537.36\\r\\nAccept-Encoding:\\x20gzip,\\x20deflate,\\x20br\\r\\n\\r\\n\")\nJul 18 12:03:28.262 TRCE Request.parse([Header; 100], [u8; 502])\nJul 18 12:03:28.262 TRCE httparse Complete(502)\nJul 18 12:03:28.262 TRCE maybe_literal not found, copying \"X-Real-IP\"\nJul 18 12:03:28.262 TRCE maybe_literal not found, copying \"X-Request-Id\"\nJul 18 12:03:28.262 TRCE maybe_literal not found, copying \"X-Forwarded-For-Y\"\nJul 18 12:03:28.262 TRCE expecting_continue(version=Http11, header=None) = false\nJul 18 12:03:28.262 TRCE should_keep_alive(version=Http11, header=None) = true\nJul 18 12:03:28.262 TRCE is_eof? Decoder { kind: Length(0) }\nJul 18 12:03:28.262 INFO Request::new: addr=[::1]:49786, \"GET /brconfigs__prestable__v012/get-brconfigs/known_antivirus?brandID=yandex&partnerID=common-yandex HTTP/1.1\"\nJul 18 12:03:28.263 DEBG Request::new: headers={\"Host\": \"api.browser.yandex.net\", \"X-Real-IP\": \"185.58.188.40\", \"X-Request-Id\": \"82effe37adf42c9a\", \"X-Forwarded-For-Y\": \"185.58.188.40\", \"If-None-Match\": \"\"94aa7472983570cc5f2ac69ad00a2a5039c8ae988857c6f4758f98227013af75\"\", \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 YaBrowser/17.6.1.749 Yowser/2.5 Safari/537.36\", \"Accept-Encoding\": \"gzip, deflate, br\"}\n...\n...\n...\nJul 18 12:03:28.373 TRCE Headers.set( \"X-Request-Id\", \"82effe37adf42c9a\" )\nJul 18 12:03:28.373 TRCE Headers.set_raw( \"Content-Disposition\", Raw([b\"attachment;\\x20filename=known_antivirus\"]) )\nJul 18 12:03:28.373 TRCE Headers.set_raw( \"Etag\", Raw([b\"\\\"94aa7472983570cc5f2ac69ad00a2a5039c8ae988857c6f4758f98227013af75\\\"\"]) )\nJul 18 12:03:28.373 TRCE Conn::poll()\nJul 18 12:03:28.373 TRCE poll when on keep-alive\nJul 18 12:03:28.373 TRCE Headers.set( \"X-Powered-By\", \"cocaine-http-proxy/0.3.7\" )\nJul 18 12:03:28.373 TRCE Conn::start_send( frame=Message { message: MessageHead { version: Http11, subject: NotModified, headers: {\"X-Request-Id\": \"82effe37adf42c9a\", \"Content-Disposition\": \"attachment; filename=known_antivirus\", \"Etag\": \"\"94aa7472983570cc5f2ac69ad00a2a5039c8ae988857c6f4758f98227013af75\"\", \"X-Powered-By\": \"cocaine-http-proxy/0.3.7\"} }, body: true } )\nJul 18 12:03:28.373 TRCE should_keep_alive(version=Http11, header=None) = true\nJul 18 12:03:28.373 TRCE WriteBuf reserving initial 8192\nJul 18 12:03:28.373 TRCE ServerTransaction::encode head=MessageHead { version: Http11, subject: NotModified, headers: {\"X-Request-Id\": \"82effe37adf42c9a\", \"Content-Disposition\": \"attachment; filename=known_antivirus\", \"Etag\": \"\"94aa7472983570cc5f2ac69ad00a2a5039c8ae988857c6f4758f98227013af75\"\", \"X-Powered-By\": \"cocaine-http-proxy/0.3.7\"} }, has_body=true, method=Some(Get)\nJul 18 12:03:28.373 TRCE Headers.remove( \"Transfer-Encoding\" )\nJul 18 12:03:28.373 DEBG encode headers = {\"X-Request-Id\": \"82effe37adf42c9a\", \"Content-Disposition\": \"attachment; filename=known_antivirus\", \"Etag\": \"\"94aa7472983570cc5f2ac69ad00a2a5039c8ae988857c6f4758f98227013af75\"\", \"X-Powered-By\": \"cocaine-http-proxy/0.3.7\"}\nJul 18 12:03:28.373 TRCE Conn::start_send( frame=Body { chunk: [] } )\nJul 18 12:03:28.374 ERRO writing illegal frame; state=KeepAlive, frame=Body { chunk: [] }\nAnd another one, only for that problem request:\nbash\nJul 18 13:30:34.447 TRCE Conn::poll()\nJul 18 13:30:34.447 TRCE Conn::read_head\nJul 18 13:30:34.447 TRCE parse(b\"GET\\x20/brconfigs__prestable__v012/get-brconfigs/known_antivirus?brandID=yandex&partnerID=common-yandex\\x20HTTP/1.1\\r\\nUser-Agent:\\x20curl/7.35.0\\r\\nHost:\\x20localhost:10100\\r\\nAccept:\\x20*/*\\r\\nIf-None-Match:\\x20\\\"94aa7472983570cc5f2ac69ad00a2a5039c8ae988857c6f4758f98227013af75\\\"\\r\\n\\r\\n\")\nJul 18 13:30:34.447 TRCE Request.parse([Header; 100], [u8; 257])\nJul 18 13:30:34.447 TRCE httparse Complete(257)\nJul 18 13:30:34.447 TRCE expecting_continue(version=Http11, header=None) = false\nJul 18 13:30:34.447 TRCE should_keep_alive(version=Http11, header=None) = true\nJul 18 13:30:34.447 TRCE is_eof? Decoder { kind: Length(0) }\nJul 18 13:30:34.447 INFO Request::new: addr=[::1]:57814, \"GET /brconfigs__prestable__v012/get-brconfigs/known_antivirus?brandID=yandex&partnerID=common-yandex HTTP/1.1\"\nJul 18 13:30:34.447 DEBG Request::new: headers={\"User-Agent\": \"curl/7.35.0\", \"Host\": \"localhost:10100\", \"Accept\": \"*/*\", \"If-None-Match\": \"\"94aa7472983570cc5f2ac69ad00a2a5039c8ae988857c6f4758f98227013af75\"\"}\nJul 18 13:30:34.447 TRCE Conn::poll()\nJul 18 13:30:34.447 TRCE poll when on keep-alive\nJul 18 13:30:34.447 TRCE parking current task\nJul 18 13:30:34.447 TRCE Conn::poll_complete()\nJul 18 13:30:34.447 TRCE Conn::write_queued()\nJul 18 13:30:34.447 TRCE flushed State { reading: KeepAlive, writing: Init, keep_alive: Busy, method: Some(Get), read_task: Some(Task) }\nJul 18 13:30:34.447 TRCE Conn::flush = Ok(Ready(()))\nJul 18 13:30:34.470 TRCE Headers.set( \"X-Request-Id\", \"44e93a9bee0a37b0\" )\nJul 18 13:30:34.470 TRCE Headers.set_raw( \"Content-Disposition\", Raw([b\"attachment;\\x20filename=known_antivirus\"]) )\nJul 18 13:30:34.470 TRCE Headers.set_raw( \"Etag\", Raw([b\"\\\"94aa7472983570cc5f2ac69ad00a2a5039c8ae988857c6f4758f98227013af75\\\"\"]) )\nJul 18 13:30:34.470 TRCE Conn::poll()\nJul 18 13:30:34.470 TRCE poll when on keep-alive\nJul 18 13:30:34.470 TRCE Headers.set( \"X-Powered-By\", \"cocaine-http-proxy/0.3.7\" )\nJul 18 13:30:34.470 TRCE Conn::start_send( frame=Message { message: MessageHead { version: Http11, subject: NotModified, headers: {\"X-Request-Id\": \"44e93a9bee0a37b0\", \"Content-Disposition\": \"attachment; filename=known_antivirus\", \"Etag\": \"\"94aa7472983570cc5f2ac69ad00a2a5039c8ae988857c6f4758f98227013af75\"\", \"X-Powered-By\": \"cocaine-http-proxy/0.3.7\"} }, body: true } )\nJul 18 13:30:34.470 TRCE should_keep_alive(version=Http11, header=None) = true\nJul 18 13:30:34.470 TRCE WriteBuf reserving initial 8192\nJul 18 13:30:34.470 TRCE ServerTransaction::encode head=MessageHead { version: Http11, subject: NotModified, headers: {\"X-Request-Id\": \"44e93a9bee0a37b0\", \"Content-Disposition\": \"attachment; filename=known_antivirus\", \"Etag\": \"\"94aa7472983570cc5f2ac69ad00a2a5039c8ae988857c6f4758f98227013af75\"\", \"X-Powered-By\": \"cocaine-http-proxy/0.3.7\"} }, has_body=true, method=Some(Get)\nJul 18 13:30:34.470 TRCE Headers.remove( \"Transfer-Encoding\" )\nJul 18 13:30:34.470 DEBG encode headers = {\"X-Request-Id\": \"44e93a9bee0a37b0\", \"Content-Disposition\": \"attachment; filename=known_antivirus\", \"Etag\": \"\"94aa7472983570cc5f2ac69ad00a2a5039c8ae988857c6f4758f98227013af75\"\", \"X-Powered-By\": \"cocaine-http-proxy/0.3.7\"}\nJul 18 13:30:34.470 TRCE Conn::start_send( frame=Body { chunk: [] } )\nJul 18 13:30:34.470 ERRO writing illegal frame; state=KeepAlive, frame=Body { chunk: [] }\nFor some reasons we're in KeepAlive state, while should be in Body. Then this (https://github.com/hyperium/hyper/blob/master/src/http/conn.rs#L458) emits an error, which probably RST the connection, which results in nginx error.. Finally!\nCan be reproduced if set NotModified status with empty body while building response.\nbash\nJul 18 13:43:01.841 TRCE Conn::poll()\nJul 18 13:43:01.842 TRCE Conn::read_head\nJul 18 13:43:01.842 TRCE parse(b\"GET\\x20/\\x20HTTP/1.1\\r\\nHost:\\x20localhost:8080\\r\\nUser-Agent:\\x20curl/7.51.0\\r\\nAccept:\\x20*/*\\r\\n\\r\\n\")\nJul 18 13:43:01.842 TRCE Request.parse([Header; 100], [u8; 78])\nJul 18 13:43:01.842 TRCE httparse Complete(78)\nJul 18 13:43:01.843 TRCE expecting_continue(version=Http11, header=None) = false\nJul 18 13:43:01.843 TRCE should_keep_alive(version=Http11, header=None) = true\nJul 18 13:43:01.843 TRCE is_eof? Decoder { kind: Length(0) }\nJul 18 13:43:01.843 INFO Request::new: addr=[::1]:60373, \"GET / HTTP/1.1\"\nJul 18 13:43:01.843 DEBG Request::new: headers={\"Host\": \"localhost:8080\", \"User-Agent\": \"curl/7.51.0\", \"Accept\": \"*/*\"}\nJul 18 13:43:01.844 TRCE Conn::poll()\nJul 18 13:43:01.844 TRCE poll when on keep-alive\nJul 18 13:43:01.844 TRCE parking current task\nJul 18 13:43:01.845 TRCE Conn::poll_complete()\nJul 18 13:43:01.845 TRCE Conn::write_queued()\nJul 18 13:43:01.845 TRCE flushed State { reading: KeepAlive, writing: Init, keep_alive: Busy, method: Some(Get), read_task: Some(Task) }\nJul 18 13:43:01.845 TRCE Conn::flush = Ok(Ready(()))\nJul 18 13:43:01.852 TRCE Conn::poll()\nJul 18 13:43:01.852 TRCE poll when on keep-alive\nJul 18 13:43:01.853 TRCE Headers.set_raw( \"X-Powered-By\", Raw([b\"Cocaine\"]) )\nJul 18 13:43:01.853 TRCE Conn::start_send( frame=Message { message: MessageHead { version: Http11, subject: NotModified, headers: {\"X-Powered-By\": \"Cocaine\"} }, body: true } )\nJul 18 13:43:01.853 TRCE should_keep_alive(version=Http11, header=None) = true\nJul 18 13:43:01.853 TRCE WriteBuf reserving initial 8192\nJul 18 13:43:01.853 TRCE ServerTransaction::encode head=MessageHead { version: Http11, subject: NotModified, headers: {\"X-Powered-By\": \"Cocaine\"} }, has_body=true, method=Some(Get)\nJul 18 13:43:01.853 TRCE Headers.remove( \"Transfer-Encoding\" )\nJul 18 13:43:01.854 DEBG encode headers = {\"X-Powered-By\": \"Cocaine\"}\nJul 18 13:43:01.854 TRCE Conn::start_send( frame=Body { chunk: [] } )\nJul 18 13:43:01.854 ERRO writing illegal frame; state=KeepAlive, frame=Body { chunk: [] }. Well, I think according to RFC this is my fault: The 304 response MUST NOT contain a message-body.\nWhat do you think: should handling such cases be done by hyper or left for user's responsibility?. I'd easily can check it by myself (already did), but it almost fully copies this part of code: https://github.com/hyperium/hyper/blob/85c6bec98bc189aac5c0dfbdc769e543782f9f8f/src/http/h1/parse.rs#L147. The same error I've got on attempt to reply with body (empty too) on HEAD request.. Thanks! I think this issue can be closed, because hyper no more hangs.. > I think that hyper can easily inspect if the body chunk is actually empty, and just ignore it. However, if the body has bytes, and HTTP specifies that the a message is not allowed to have bytes, I would prefer hyper to return an error. Unfortunately, the error handling in tokio isn't as fleshed out as we'd like, so the way for a user to know about this error isn't that easy...\nI'm OK if hyper would panic on such RFC violations, but it should be mentioned in docs.. Yeah, I know)\nBut it can panic for some cases and that's ok. The other solution may be introducing some kind of strongly-typed Response, for example to statically forbid replying with body for HEAD requests. This won't saves from NotModified statuses with body, thus.\nAt last, yes, tokio error handling can be improved, but I can't imagine how.. rust\nlet headers = req.headers()\n    .iter()\n    .map(|header| (header.name().to_string(), header.value_string()))\n    .collect();\nAs an alternative I could pack them as Vec<u8>, but didn't find such method.... Oh, found (https://hyper.rs/hyper/master/hyper/header/struct.Raw.html), sorry.. I think we can we assume value_string() method as dangerous, because it may crash your application depending on user input.. > As an alternative I could pack them as Vec, but didn't find such method...\nWell, technically it is possible (https://github.com/3Hren/cocaine-http-proxy/blob/master/src/route/app.rs#L285), but looks weird.\nI can implement value_vec() -> Vec<u8> method if you like.. ",
    "lilydjwg": "I find from_u16 is pub now, but to_u16 is not. I need it to do some logging.. @seanmonstar Into will consume the StatusCode so I have to clone. I'm inspecting the status code of responses.. No, u16::from(status) doesn't work, because there is impl<T, U> Into<U> for T where U: From<T> but not the opposite.\nThis does work:\nlet st: u16 = (*res.status()).into();\nBut it looks awkward. If StatusCode is Copy, I guess it's better for Response.status() to return a copy.. ",
    "kichristensen": "Should this be closed as this is handled in #97? . ",
    "little-dude": "It seems that I can create a client with something like\nrust\nClient::with_connector(\n    HttpsConnector::new(\n        OpensslClient::new( // here I need a custom SslContext, that ignore insecure connections but not sure how to do\n                          )\n        )\n    )\nBut I don't know what the ssl context should be.\n. ",
    "richardwhiuk": "Prior to 1.0, any change in the version number can be breaking, right? At least that's how I've always interpreted semver ...\n. ",
    "nox": "I wonder if it could be removed from Hyper entirely and defined in a separate crate, but for that we would have to be sure that we are the only users. Maybe though given no one reported any failure with 0.9.11 it means there is indeed no other user but Servo.\n. ",
    "sdroege": "It will also allow people to actually compile rust-openssl (and thus hyper) if they have openssl 1.1 installed\n. Unfortunately porting to the new API either means not making use of all the new improvements (SslConnector / SslAcceptor), or breaking public API. If breaking the public API (the OpenSslClient and Openssl structs, and not implementing the Ssl trait anymore) is acceptable, I can take a look at that.\n. Question is also which branch to work on, master and 0.9.x are somewhat different in that regard (and I have a simple port for master here that compiles but is otherwise untested)\n. ",
    "Philipp91": "I'm using hyper through iron. The rust-openssl version 0.7.x fails to build on my Windows machine, even if I use it in a standalone project:\nerror: failed to run custom build command for `openssl-sys-extras v0.7.14`\nprocess didn't exit successfully: `C:\\...\\iron-test\\target\\debug\\build\\openssl-sys-extras-4d40c2369b784529\\build-script-build` (exit code: 101)\nrust-openssl version 0.9.x works fine. What should I do?. ",
    "jswrenn": "I'm not sure. I have not yet managed to reproduce the problem in a short amount of time, and running the application without openssl is not possible. \nEDIT: To give an idea of the timeline between starting the application and it failing: The last time this happened was a week after the server application was started, during which about 90k requests were handled. The incident before that one occurred several days after the application was started.\n. ",
    "ojensen5115": "This may be unrelated, but I'm curious if the people experiencing this issue are using Debian / OpenSSL?\nI experienced almost identical symptoms in a Python application I was working on some time ago, where after an inconsistent amount of time (sometimes days, sometimes weeks) the application would simply hang doing nothing, and the problem was essentially impossible to reproduce intentionally -- the time after which the issue occurred did not seem to correlate to the number of requests, so simply bombarding the server with requests would not trigger the bug.\nThe underlying problem was that the Debian repo's version of OpenSSL would sometimes hang indefinitely when being called in Python's do_handshake() method. I wonder if perhaps the same underlying issue is at play here as well. For what it's worth, I ended up \"fixing\" it in my application by setting a timeout around the call to OpenSSL (see here).. ",
    "theduke": "Body should really have a convenience method, maybe fold_to_vec or collect_to_vec that yields a Future<Item=Vec<u8>, Error=hyper::Error>.. @chenhouwu I have the same issue.\nVery annoying. Since you can't kill a thread externally (in rust), the only workaround I see right now is to run the client in a thread. In the main thread I check for a timeout, mark the thread as stale, and try again in a new thread. \nHorrible solution of course. Sufficient for my current problem, but nothing I could recommend for any long running program that needs to be stable.. @chenhouwu  yeah I'll have to do the same in the medium term.... Ok, seems like I was imagining the workaround...\nGuess it's the same issue as #980.\nClosing this.\n. I would suggest to try and use the http crate name for this. \nIt already exists,  https://crates.io/crates/http , but the owner could hopefully persuaded to give it up.. ",
    "lygstate": "How about rusttls?. https://github.com/ctz/rustls,\nit's using ring. ",
    "stearnsc": "I tried with two randomly generated keys of different sizes and it panicked for both. That was enough to convince me it wasn't a magic-number kinda scenario, but I don't know more than that.. Some more digging; it also fails using \"signed\" instead of \"encrypted\" (which maybe isn't surprising?). However, I tried using the newest version of cookie directly (https://github.com/alexcrichton/cookie-rs), and it succeeds. That uses cookie 0.3.1 (hyper uses 0.2.5), which pulls in openssl 0.8.3, so my working hypothesis is that this is somehow a bug in openssl that got fixed. What's confusing me is why nobody else seems to be having this issue; iron brings in hyper, which brings in the old version of cookie, which brings in the old version of openssl; I can't imagine nobody using these tools does anything with signed or encrypted cookies.. Maybe whatever's triggering this bug is also tied with the homebrew openssl issue?\nDoes hyper have plans to upgrade to openssl 0.8 at some point? If so, (and if that's not in the too distant future), I might just punt on this issue and hope the upgrade fixes it... ",
    "rvolgers": "That return value is 0xbf2c0c95, which looks like a random stack address instead of a status code. \nSeems plausible that it has to do with this: https://marc.info/?l=openssl-cvs&m=122564502632730\nOn my Ubuntu system I have libcrypto libraries with both the 0.9.8 and the 1.0.0 API. At the 0.9.8 API level HMAC_Init_ex does not return anything (void), at the 1.0.0 API version it returns an int status code. \nNot sure how that should be fixed. Does the openssl crate have any support for different OpenSSL API levels?. ",
    "halmohri": "Thanks for the response. I'm still a bit troubled here. I downloaded the code and added hyper as a local extern in my code (I needed this for testing). When I want to specify a handler for the server, the compiler expects me to specify a type argument for Request and Handler. But this doesn't happen if I include hyper as a dependency in Cargo. \n```\nuse hyper::server::{Handler,Request,Response};\nstruct SenderHandler {\n    sender: Mutex>\n}\nimpl Handler for SenderHandler {\n    fn handle(&self, req: Request, res: Response) {\n        self.sender.lock().unwrap().send(\"start\").unwrap();\n    }\n}\n```\nError: Expected 1 type arguments, found 0. I get this for both Request and Handler. \nUpdate: I worked it out with specifying Request<OpensslStream<HttpStream>>. . Can you point me to where this handle function is defined? (server.handle(|_| Echo::new()).unwrap()). ",
    "awalcutt": "I'm new to rust and hyper so I'm not super familiar with the internals here. I found that, if you sleep even a single nanosecond before the second assert\ni.e. std::thread::sleep(Duration::new(0,1));\nthe test passes. I don't know if that's expected behavior or not.. > Ah, I didn't realize that this was talking about the tokio branch.\nFor the record, I'm using hyper 0.10.0-a.0 after having cloned the master branch this morning. Anyway, glad I could help clarify the situation :). ",
    "upsuper": "I guess the owner may want a patch based on master rather than 0.9.x branch.. ",
    "dirk": "@seanmonstar, @reem: Anything we can do as a community to help this PR along?. ",
    "vityafx": "@seanmonstar Are not you gonna say that the problem is that my server's dns lookup process takes too long? If so, what could be the reason of it? How can I fix this? Also, I still don't see how this answers the question \"why does it print https scheme in the log if I don't use https at all?\".\nI've just checked: nslookup host works perfectly fine and fast. Do you mean the problem is exactly in getaddrinfo? If so, the question is the same, how do I fix it and why does this problem happen?. ",
    "danielrs": "@seanmonstar I'm not in my machine right now, but I remember the stacktrace going all the way up to libc, maybe the issue is present in my system and not yours? I'll post more version information in a little while.. All right here's a more detailed use case. First the cargo.toml file:\n```toml\n[package]\nname = \"hyper_leak\"\nversion = \"0.1.0\"\nauthors = []\n[dependencies]\nhyper = \"0.9.14\"\n```\nAnd src/main.rs:\n```rust\nextern crate hyper;\nuse hyper::client::Client;\nuse hyper::method::Method;\nfn main() {\n    let client = Client::new();\n    client.request(Method::Get, \"https://github.com/\").send();\n}\n```\nThe program was built using cargo build and then run using valgrind --leak-check=full --undef-value-errors=no ./target/debug/hyper_leak, the output was:\n==7925== Memcheck, a memory error detector\n==7925== Copyright (C) 2002-2015, and GNU GPL'd, by Julian Seward et al.\n==7925== Using Valgrind-3.12.0 and LibVEX; rerun with -h for copyright info\n==7925== Command: ./target/debug/hyper_leak\n==7925== \n==7925== \n==7925== HEAP SUMMARY:\n==7925==     in use at exit: 106,107 bytes in 3,301 blocks\n==7925==   total heap usage: 36,539 allocs, 33,238 frees, 2,701,400 bytes allocated\n==7925== \n==7925== 170 (32 direct, 138 indirect) bytes in 1 blocks are definitely lost in loss record 625 of 684\n==7925==    at 0x4C2AB8D: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==7925==    by 0x5110817: CRYPTO_malloc (in /usr/lib/libcrypto.so.1.0.0)\n==7925==    by 0x51E3B5E: sk_new (in /usr/lib/libcrypto.so.1.0.0)\n==7925==    by 0x52159FA: asn1_template_noexp_d2i (in /usr/lib/libcrypto.so.1.0.0)\n==7925==    by 0x5215B30: asn1_template_ex_d2i (in /usr/lib/libcrypto.so.1.0.0)\n==7925==    by 0x5214CEE: ASN1_item_ex_d2i (in /usr/lib/libcrypto.so.1.0.0)\n==7925==    by 0x521564A: ASN1_item_d2i (in /usr/lib/libcrypto.so.1.0.0)\n==7925==    by 0x52392B3: X509V3_EXT_d2i (in /usr/lib/libcrypto.so.1.0.0)\n==7925==    by 0x1E0DD1: openssl::x509::X509::subject_alt_names::hd09c32c1bbfe2620 (mod.rs:477)\n==7925==    by 0x1D5A5B: openssl_verify::verify_hostname::h7374f5e702ed75b6 (lib.rs:65)\n==7925==    by 0x1D5900: openssl_verify::verify_callback::h5536858276483a97 (lib.rs:57)\n==7925==    by 0x1CCED1: _$LT$hyper..net..openssl..OpensslClient$u20$as$u20$hyper..net..SslClient$LT$T$GT$$GT$::wrap_client::_$u7b$$u7b$closure$u7d$$u7d$::ha13bd732a99f9af3 (net.rs:682)\n==7925== \n==7925== 4,096 bytes in 1 blocks are definitely lost in loss record 681 of 684\n==7925==    at 0x4C2AB8D: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==7925==    by 0x40A8741: ???\n==7925==    by 0x40A668B: ???\n==7925==    by 0x40CACF0: ???\n==7925==    by 0x40A7B8C: ???\n==7925==    by 0x5E33E50: gaih_inet.constprop.5 (in /usr/lib/libc-2.24.so)\n==7925==    by 0x5E35177: getaddrinfo (in /usr/lib/libc-2.24.so)\n==7925==    by 0x22EC79: lookup_host (net.rs:180)\n==7925==    by 0x22EC79: std::net::lookup_host::h59083babc1981eb4 (mod.rs:135)\n==7925==    by 0x22DAF6: std::net::addr::resolve_socket_addr::h65fb9eb6a87c8437 (addr.rs:678)\n==7925==    by 0x22E048: _$LT$$LP$$RF$$u27$a$u20$str$C$$u20$u16$RP$$u20$as$u20$std..net..addr..ToSocketAddrs$GT$::to_socket_addrs::h14535bad554ddb0b (addr.rs:699)\n==7925==    by 0x19052E: _$LT$$RF$$u27$a$u20$T$u20$as$u20$std..net..addr..ToSocketAddrs$GT$::to_socket_addrs::hac73e3b592c1df4d (addr.rs:745)\n==7925==    by 0x172BB2: std::net::each_addr::hc1a2112c4405d0ba (mod.rs:80)\n==7925== \n==7925== LEAK SUMMARY:\n==7925==    definitely lost: 4,128 bytes in 2 blocks\n==7925==    indirectly lost: 138 bytes in 7 blocks\n==7925==      possibly lost: 0 bytes in 0 blocks\n==7925==    still reachable: 101,841 bytes in 3,292 blocks\n==7925==         suppressed: 0 bytes in 0 blocks\n==7925== Reachable blocks (those to which a pointer was found) are not shown.\n==7925== To see them, rerun with: --leak-check=full --show-leak-kinds=all\n==7925== \n==7925== For counts of detected and suppressed errors, rerun with: -v\n==7925== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0)\nNow that I take a look, the last entry of each error points to /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so, maybe this is actually a valgrind bug?\nMy system information is:\nLinux: Linux adaline 4.8.13-1-ARCH #1 SMP PREEMPT Fri Dec 9 07:24:34 CET 2016 x86_64 GNU/Linux\nValgrind: valgrind-3.12.0\nglibc (with ldd --version): ldd (GNU libc) 2.24. ",
    "laishulu": "Seems not caused by DNS, because the stability of my program varies quite much for different api vendors. When the api server have stability issue (can be seen from web pages), my program blocks more often than normal. The api server from another vendor rarely blocks, yes, but still has little chance to block.. resonable. So.....since the std lib don't provide timeout, I have no means to overcome it only if to use thread control or async io?. I will shift to rust-curl, @theduke . ",
    "MTRNord": "Nice to know :) thanks for info I will take a look at that. ",
    "GuillaumeGomez": "Is the travis failure.... normal?. I think I can do it in a second step. I'll just \"borrow\" the url methods and use them directly instead of creating a type. For now I'll replace RequestUri everywhere and then I'll remove the url type usage.. I think I'll stop here for this PR. I cleaned up a bit and remove the old RequestUri.\n@seanmonstar: Do you see anything I might have forgotten?. cc me. Ok, new version! Now I just need to find where I could use the MemSlice instead of a Vec<u8>.. It's now working so are the benchmarks. New benchmarks:\n```\ncargo bench --features=nightly\nwarning: unused manifest key: package.categories\nwarning: unused manifest key: package.categories\n   Compiling hyper v0.11.0-a.0 (file:///Users/imperio/rust/hyper)\n    Finished release [optimized] target(s) in 53.65 secs\n     Running target/release/deps/end_to_end-308d9266fbe8eafc\nrunning 2 tests\ntest get_one_at_a_time  ... bench:     144,366 ns/iter (+/- 27,775) = 357 MB/s\ntest post_one_at_a_time ... bench:     162,861 ns/iter (+/- 137,436) = 317 MB/s\ntest result: ok. 0 passed; 0 failed; 0 ignored; 2 measured\n Running target/release/deps/hyper-8ed5eff9a7a63d2c\n\nrunning 358 tests\ntest header::common::accept::bench::bench_format                    ... bench:         614 ns/iter (+/- 511)\ntest header::common::accept::bench::bench_parse                     ... bench:         619 ns/iter (+/- 42)\ntest header::common::accept_language::bench::bench_format           ... bench:         709 ns/iter (+/- 72)\ntest header::common::accept_language::bench::bench_parse            ... bench:       1,269 ns/iter (+/- 210)\ntest header::common::allow::bench::bench_format                     ... bench:         351 ns/iter (+/- 33)\ntest header::common::allow::bench::bench_parse                      ... bench:         526 ns/iter (+/- 251)\ntest header::common::authorization::basic::bench_format             ... bench:         319 ns/iter (+/- 115)\ntest header::common::authorization::basic::bench_parse              ... bench:         197 ns/iter (+/- 23)\ntest header::common::authorization::bearer::bench_format            ... bench:         173 ns/iter (+/- 20)\ntest header::common::authorization::bearer::bench_parse             ... bench:          44 ns/iter (+/- 4)\ntest header::common::authorization::raw::bench_format               ... bench:          52 ns/iter (+/- 4)\ntest header::common::authorization::raw::bench_parse                ... bench:          39 ns/iter (+/- 4)\ntest header::common::cache_control::normal::bench_format            ... bench:         187 ns/iter (+/- 17)\ntest header::common::cache_control::normal::bench_parse             ... bench:         256 ns/iter (+/- 17)\ntest header::common::connection::close::bench_format                ... bench:          54 ns/iter (+/- 13)\ntest header::common::connection::close::bench_parse                 ... bench:          66 ns/iter (+/- 8)\ntest header::common::connection::header::bench_format               ... bench:          59 ns/iter (+/- 14)\ntest header::common::connection::header::bench_parse                ... bench:         103 ns/iter (+/- 20)\ntest header::common::connection::keep_alive::bench_format           ... bench:          52 ns/iter (+/- 2)\ntest header::common::connection::keep_alive::bench_parse            ... bench:          81 ns/iter (+/- 30)\ntest header::common::content_encoding::multiple::bench_format       ... bench:         126 ns/iter (+/- 14)\ntest header::common::content_encoding::multiple::bench_parse        ... bench:         143 ns/iter (+/- 16)\ntest header::common::content_encoding::single::bench_format         ... bench:          60 ns/iter (+/- 11)\ntest header::common::content_encoding::single::bench_parse          ... bench:          59 ns/iter (+/- 17)\ntest header::common::content_length::bench::bench_format            ... bench:          62 ns/iter (+/- 13)\ntest header::common::content_length::bench::bench_parse             ... bench:          30 ns/iter (+/- 15)\ntest header::common::content_type::bench::bench_format              ... bench:         210 ns/iter (+/- 40)\ntest header::common::content_type::bench::bench_parse               ... bench:         252 ns/iter (+/- 34)\ntest header::common::cookie::bench::bench_format                    ... bench:         143 ns/iter (+/- 41)\ntest header::common::cookie::bench::bench_parse                     ... bench:         173 ns/iter (+/- 42)\ntest header::common::date::asctime::bench_format                    ... bench:         780 ns/iter (+/- 92)\ntest header::common::date::asctime::bench_parse                     ... bench:         311 ns/iter (+/- 28)\ntest header::common::date::imf_fixdate::bench_format                ... bench:         779 ns/iter (+/- 184)\ntest header::common::date::imf_fixdate::bench_parse                 ... bench:         232 ns/iter (+/- 23)\ntest header::common::date::rfc_850::bench_format                    ... bench:         795 ns/iter (+/- 348)\ntest header::common::date::rfc_850::bench_parse                     ... bench:         251 ns/iter (+/- 35)\ntest header::common::etag::bench::bench_format                      ... bench:         141 ns/iter (+/- 22)\ntest header::common::etag::bench::bench_parse                       ... bench:          62 ns/iter (+/- 7)\ntest header::common::expires::asctime::bench_format                 ... bench:         776 ns/iter (+/- 73)\ntest header::common::expires::asctime::bench_parse                  ... bench:         313 ns/iter (+/- 118)\ntest header::common::expires::imf_fixdate::bench_format             ... bench:         763 ns/iter (+/- 83)\ntest header::common::expires::imf_fixdate::bench_parse              ... bench:         228 ns/iter (+/- 28)\ntest header::common::expires::rfc_850::bench_format                 ... bench:         778 ns/iter (+/- 254)\ntest header::common::expires::rfc_850::bench_parse                  ... bench:         247 ns/iter (+/- 72)\ntest header::common::host::bench::bench_format                      ... bench:         135 ns/iter (+/- 23)\ntest header::common::host::bench::bench_parse                       ... bench:          59 ns/iter (+/- 7)\ntest header::common::if_match::multi::bench_format                  ... bench:         286 ns/iter (+/- 45)\ntest header::common::if_match::multi::bench_parse                   ... bench:         327 ns/iter (+/- 44)\ntest header::common::if_match::single::bench_format                 ... bench:         138 ns/iter (+/- 19)\ntest header::common::if_match::single::bench_parse                  ... bench:          99 ns/iter (+/- 8)\ntest header::common::if_match::star::bench_format                   ... bench:          50 ns/iter (+/- 5)\ntest header::common::if_match::star::bench_parse                    ... bench:           1 ns/iter (+/- 0)\ntest header::common::if_modified_since::asctime::bench_format       ... bench:         778 ns/iter (+/- 80)\ntest header::common::if_modified_since::asctime::bench_parse        ... bench:         313 ns/iter (+/- 72)\ntest header::common::if_modified_since::imf_fixdate::bench_format   ... bench:         775 ns/iter (+/- 63)\ntest header::common::if_modified_since::imf_fixdate::bench_parse    ... bench:         231 ns/iter (+/- 33)\ntest header::common::if_modified_since::rfc_850::bench_format       ... bench:         773 ns/iter (+/- 71)\ntest header::common::if_modified_since::rfc_850::bench_parse        ... bench:         256 ns/iter (+/- 111)\ntest header::common::if_none_match::bench::bench_format             ... bench:         143 ns/iter (+/- 12)\ntest header::common::if_none_match::bench::bench_parse              ... bench:         129 ns/iter (+/- 23)\ntest header::common::if_unmodified_since::asctime::bench_format     ... bench:         773 ns/iter (+/- 314)\ntest header::common::if_unmodified_since::asctime::bench_parse      ... bench:         312 ns/iter (+/- 142)\ntest header::common::if_unmodified_since::imf_fixdate::bench_format ... bench:         779 ns/iter (+/- 124)\ntest header::common::if_unmodified_since::imf_fixdate::bench_parse  ... bench:         228 ns/iter (+/- 28)\ntest header::common::if_unmodified_since::rfc_850::bench_format     ... bench:         772 ns/iter (+/- 83)\ntest header::common::if_unmodified_since::rfc_850::bench_parse      ... bench:         251 ns/iter (+/- 170)\ntest header::common::last_modified::asctime::bench_format           ... bench:         777 ns/iter (+/- 134)\ntest header::common::last_modified::asctime::bench_parse            ... bench:         359 ns/iter (+/- 61)\ntest header::common::last_modified::imf_fixdate::bench_format       ... bench:         781 ns/iter (+/- 97)\ntest header::common::last_modified::imf_fixdate::bench_parse        ... bench:         231 ns/iter (+/- 26)\ntest header::common::last_modified::rfc_850::bench_format           ... bench:         786 ns/iter (+/- 227)\ntest header::common::last_modified::rfc_850::bench_parse            ... bench:         248 ns/iter (+/- 28)\ntest header::common::location::bench::bench_format                  ... bench:          53 ns/iter (+/- 20)\ntest header::common::location::bench::bench_parse                   ... bench:          39 ns/iter (+/- 4)\ntest header::common::origin::bench::bench_format                    ... bench:         156 ns/iter (+/- 20)\ntest header::common::origin::bench::bench_parse                     ... bench:         123 ns/iter (+/- 14)\ntest header::common::prefer::normal::bench_format                   ... bench:         190 ns/iter (+/- 67)\ntest header::common::prefer::normal::bench_parse                    ... bench:         590 ns/iter (+/- 72)\ntest header::common::preference_applied::normal::bench_format       ... bench:         255 ns/iter (+/- 77)\ntest header::common::preference_applied::normal::bench_parse        ... bench:         604 ns/iter (+/- 77)\ntest header::common::range::bytes_multi::bench_format               ... bench:         342 ns/iter (+/- 53)\ntest header::common::range::bytes_multi::bench_parse                ... bench:         342 ns/iter (+/- 33)\ntest header::common::range::custom_unit::bench_format               ... bench:         155 ns/iter (+/- 14)\ntest header::common::range::custom_unit::bench_parse                ... bench:          83 ns/iter (+/- 8)\ntest header::common::referer::bench::bench_format                   ... bench:          52 ns/iter (+/- 6)\ntest header::common::referer::bench::bench_parse                    ... bench:          39 ns/iter (+/- 7)\ntest header::common::server::bench::bench_format                    ... bench:          52 ns/iter (+/- 7)\ntest header::common::server::bench::bench_parse                     ... bench:          40 ns/iter (+/- 3)\ntest header::common::strict_transport_security::bench::bench_format ... bench:         150 ns/iter (+/- 26)\ntest header::common::strict_transport_security::bench::bench_parse  ... bench:         160 ns/iter (+/- 26)\ntest header::common::transfer_encoding::ext::bench_format           ... bench:          52 ns/iter (+/- 7)\ntest header::common::transfer_encoding::ext::bench_parse            ... bench:          79 ns/iter (+/- 7)\ntest header::common::transfer_encoding::normal::bench_format        ... bench:         102 ns/iter (+/- 12)\ntest header::common::transfer_encoding::normal::bench_parse         ... bench:         140 ns/iter (+/- 14)\ntest header::common::upgrade::bench::bench_format                   ... bench:         237 ns/iter (+/- 94)\ntest header::common::upgrade::bench::bench_parse                    ... bench:         358 ns/iter (+/- 47)\ntest header::tests::bench_headers_fmt                               ... bench:         169 ns/iter (+/- 54)\ntest header::tests::bench_headers_from_raw                          ... bench:          77 ns/iter (+/- 9)\ntest header::tests::bench_headers_get                               ... bench:           8 ns/iter (+/- 1)\ntest header::tests::bench_headers_get_miss                          ... bench:           0 ns/iter (+/- 0)\ntest header::tests::bench_headers_has                               ... bench:           1 ns/iter (+/- 0)\ntest header::tests::bench_headers_new                               ... bench:          82 ns/iter (+/- 7)\ntest header::tests::bench_headers_set                               ... bench:          56 ns/iter (+/- 21)\ntest header::tests::bench_headers_view_is                           ... bench:           1 ns/iter (+/- 0)\ntest http::h1::parse::tests::bench_parse_incoming                   ... bench:       3,368 ns/iter (+/- 292)\n```\nOld benchmarks:\n```\ncargo bench --features=nightly\nwarning: unused manifest key: package.categories\nwarning: unused manifest key: package.categories\n    Finished release [optimized] target(s) in 0.0 secs\n     Running target/release/deps/end_to_end-ec7a2aa5f4e7a213\nrunning 2 tests\ntest get_one_at_a_time  ... bench:     148,265 ns/iter (+/- 69,582) = 348 MB/s\ntest post_one_at_a_time ... bench:     161,180 ns/iter (+/- 33,001) = 320 MB/s\ntest result: ok. 0 passed; 0 failed; 0 ignored; 2 measured\n Running target/release/deps/hyper-4da063bedd471883\n\nrunning 357 tests\ntest header::common::accept::bench::bench_format                    ... bench:         527 ns/iter (+/- 125)\ntest header::common::accept::bench::bench_parse                     ... bench:         578 ns/iter (+/- 51)\ntest header::common::accept_language::bench::bench_format           ... bench:         716 ns/iter (+/- 226)\ntest header::common::accept_language::bench::bench_parse            ... bench:       1,304 ns/iter (+/- 185)\ntest header::common::allow::bench::bench_format                     ... bench:         339 ns/iter (+/- 44)\ntest header::common::allow::bench::bench_parse                      ... bench:         586 ns/iter (+/- 116)\ntest header::common::authorization::basic::bench_format             ... bench:         355 ns/iter (+/- 95)\ntest header::common::authorization::basic::bench_parse              ... bench:         201 ns/iter (+/- 120)\ntest header::common::authorization::bearer::bench_format            ... bench:         173 ns/iter (+/- 42)\ntest header::common::authorization::bearer::bench_parse             ... bench:          50 ns/iter (+/- 11)\ntest header::common::authorization::raw::bench_format               ... bench:          52 ns/iter (+/- 6)\ntest header::common::authorization::raw::bench_parse                ... bench:          32 ns/iter (+/- 3)\ntest header::common::cache_control::normal::bench_format            ... bench:         189 ns/iter (+/- 29)\ntest header::common::cache_control::normal::bench_parse             ... bench:         268 ns/iter (+/- 195)\ntest header::common::connection::close::bench_format                ... bench:          54 ns/iter (+/- 6)\ntest header::common::connection::close::bench_parse                 ... bench:          63 ns/iter (+/- 9)\ntest header::common::connection::header::bench_format               ... bench:          55 ns/iter (+/- 7)\ntest header::common::connection::header::bench_parse                ... bench:         106 ns/iter (+/- 25)\ntest header::common::connection::keep_alive::bench_format           ... bench:          61 ns/iter (+/- 15)\ntest header::common::connection::keep_alive::bench_parse            ... bench:          91 ns/iter (+/- 82)\ntest header::common::content_encoding::multiple::bench_format       ... bench:         136 ns/iter (+/- 36)\ntest header::common::content_encoding::multiple::bench_parse        ... bench:         142 ns/iter (+/- 19)\ntest header::common::content_encoding::single::bench_format         ... bench:          52 ns/iter (+/- 17)\ntest header::common::content_encoding::single::bench_parse          ... bench:          54 ns/iter (+/- 4)\ntest header::common::content_length::bench::bench_format            ... bench:          60 ns/iter (+/- 7)\ntest header::common::content_length::bench::bench_parse             ... bench:          29 ns/iter (+/- 3)\ntest header::common::content_type::bench::bench_format              ... bench:         207 ns/iter (+/- 24)\ntest header::common::content_type::bench::bench_parse               ... bench:         248 ns/iter (+/- 28)\ntest header::common::cookie::bench::bench_format                    ... bench:         142 ns/iter (+/- 14)\ntest header::common::cookie::bench::bench_parse                     ... bench:         179 ns/iter (+/- 56)\ntest header::common::date::asctime::bench_format                    ... bench:         772 ns/iter (+/- 77)\ntest header::common::date::asctime::bench_parse                     ... bench:         322 ns/iter (+/- 78)\ntest header::common::date::imf_fixdate::bench_format                ... bench:         768 ns/iter (+/- 134)\ntest header::common::date::imf_fixdate::bench_parse                 ... bench:         229 ns/iter (+/- 47)\ntest header::common::date::rfc_850::bench_format                    ... bench:         780 ns/iter (+/- 109)\ntest header::common::date::rfc_850::bench_parse                     ... bench:         243 ns/iter (+/- 18)\ntest header::common::etag::bench::bench_format                      ... bench:         142 ns/iter (+/- 12)\ntest header::common::etag::bench::bench_parse                       ... bench:          61 ns/iter (+/- 7)\ntest header::common::expires::asctime::bench_format                 ... bench:         770 ns/iter (+/- 162)\ntest header::common::expires::asctime::bench_parse                  ... bench:         309 ns/iter (+/- 72)\ntest header::common::expires::imf_fixdate::bench_format             ... bench:         766 ns/iter (+/- 100)\ntest header::common::expires::imf_fixdate::bench_parse              ... bench:         228 ns/iter (+/- 69)\ntest header::common::expires::rfc_850::bench_format                 ... bench:         770 ns/iter (+/- 92)\ntest header::common::expires::rfc_850::bench_parse                  ... bench:         246 ns/iter (+/- 23)\ntest header::common::host::bench::bench_format                      ... bench:         132 ns/iter (+/- 18)\ntest header::common::host::bench::bench_parse                       ... bench:          58 ns/iter (+/- 6)\ntest header::common::if_match::multi::bench_format                  ... bench:         282 ns/iter (+/- 34)\ntest header::common::if_match::multi::bench_parse                   ... bench:         343 ns/iter (+/- 202)\ntest header::common::if_match::single::bench_format                 ... bench:         139 ns/iter (+/- 56)\ntest header::common::if_match::single::bench_parse                  ... bench:         105 ns/iter (+/- 56)\ntest header::common::if_match::star::bench_format                   ... bench:          51 ns/iter (+/- 23)\ntest header::common::if_match::star::bench_parse                    ... bench:           1 ns/iter (+/- 1)\ntest header::common::if_modified_since::asctime::bench_format       ... bench:         771 ns/iter (+/- 229)\ntest header::common::if_modified_since::asctime::bench_parse        ... bench:         312 ns/iter (+/- 30)\ntest header::common::if_modified_since::imf_fixdate::bench_format   ... bench:         779 ns/iter (+/- 128)\ntest header::common::if_modified_since::imf_fixdate::bench_parse    ... bench:         227 ns/iter (+/- 52)\ntest header::common::if_modified_since::rfc_850::bench_format       ... bench:         760 ns/iter (+/- 81)\ntest header::common::if_modified_since::rfc_850::bench_parse        ... bench:         247 ns/iter (+/- 30)\ntest header::common::if_none_match::bench::bench_format             ... bench:         144 ns/iter (+/- 42)\ntest header::common::if_none_match::bench::bench_parse              ... bench:         120 ns/iter (+/- 56)\ntest header::common::if_unmodified_since::asctime::bench_format     ... bench:         793 ns/iter (+/- 310)\ntest header::common::if_unmodified_since::asctime::bench_parse      ... bench:         312 ns/iter (+/- 81)\ntest header::common::if_unmodified_since::imf_fixdate::bench_format ... bench:         775 ns/iter (+/- 147)\ntest header::common::if_unmodified_since::imf_fixdate::bench_parse  ... bench:         227 ns/iter (+/- 23)\ntest header::common::if_unmodified_since::rfc_850::bench_format     ... bench:         767 ns/iter (+/- 148)\ntest header::common::if_unmodified_since::rfc_850::bench_parse      ... bench:         245 ns/iter (+/- 102)\ntest header::common::last_modified::asctime::bench_format           ... bench:         779 ns/iter (+/- 113)\ntest header::common::last_modified::asctime::bench_parse            ... bench:         313 ns/iter (+/- 64)\ntest header::common::last_modified::imf_fixdate::bench_format       ... bench:         770 ns/iter (+/- 229)\ntest header::common::last_modified::imf_fixdate::bench_parse        ... bench:         229 ns/iter (+/- 42)\ntest header::common::last_modified::rfc_850::bench_format           ... bench:         770 ns/iter (+/- 114)\ntest header::common::last_modified::rfc_850::bench_parse            ... bench:         245 ns/iter (+/- 29)\ntest header::common::location::bench::bench_format                  ... bench:          51 ns/iter (+/- 5)\ntest header::common::location::bench::bench_parse                   ... bench:          32 ns/iter (+/- 4)\ntest header::common::origin::bench::bench_format                    ... bench:         154 ns/iter (+/- 45)\ntest header::common::origin::bench::bench_parse                     ... bench:         116 ns/iter (+/- 15)\ntest header::common::prefer::normal::bench_format                   ... bench:         190 ns/iter (+/- 105)\ntest header::common::prefer::normal::bench_parse                    ... bench:         607 ns/iter (+/- 68)\ntest header::common::preference_applied::normal::bench_format       ... bench:         252 ns/iter (+/- 32)\ntest header::common::preference_applied::normal::bench_parse        ... bench:         612 ns/iter (+/- 221)\ntest header::common::range::bytes_multi::bench_format               ... bench:         334 ns/iter (+/- 102)\ntest header::common::range::bytes_multi::bench_parse                ... bench:         334 ns/iter (+/- 71)\ntest header::common::range::custom_unit::bench_format               ... bench:         157 ns/iter (+/- 22)\ntest header::common::range::custom_unit::bench_parse                ... bench:          85 ns/iter (+/- 10)\ntest header::common::referer::bench::bench_format                   ... bench:          52 ns/iter (+/- 7)\ntest header::common::referer::bench::bench_parse                    ... bench:          32 ns/iter (+/- 9)\ntest header::common::server::bench::bench_format                    ... bench:          51 ns/iter (+/- 19)\ntest header::common::server::bench::bench_parse                     ... bench:          32 ns/iter (+/- 4)\ntest header::common::strict_transport_security::bench::bench_format ... bench:         147 ns/iter (+/- 14)\ntest header::common::strict_transport_security::bench::bench_parse  ... bench:         162 ns/iter (+/- 44)\ntest header::common::transfer_encoding::ext::bench_format           ... bench:          54 ns/iter (+/- 4)\ntest header::common::transfer_encoding::ext::bench_parse            ... bench:          76 ns/iter (+/- 8)\ntest header::common::transfer_encoding::normal::bench_format        ... bench:         105 ns/iter (+/- 9)\ntest header::common::transfer_encoding::normal::bench_parse         ... bench:         140 ns/iter (+/- 23)\ntest header::common::upgrade::bench::bench_format                   ... bench:         237 ns/iter (+/- 24)\ntest header::common::upgrade::bench::bench_parse                    ... bench:         367 ns/iter (+/- 186)\ntest header::tests::bench_headers_fmt                               ... bench:         173 ns/iter (+/- 25)\ntest header::tests::bench_headers_from_raw                          ... bench:          94 ns/iter (+/- 12)\ntest header::tests::bench_headers_get                               ... bench:           7 ns/iter (+/- 1)\ntest header::tests::bench_headers_get_miss                          ... bench:           0 ns/iter (+/- 0)\ntest header::tests::bench_headers_has                               ... bench:           1 ns/iter (+/- 0)\ntest header::tests::bench_headers_new                               ... bench:          84 ns/iter (+/- 10)\ntest header::tests::bench_headers_set                               ... bench:          56 ns/iter (+/- 6)\ntest header::tests::bench_headers_view_is                           ... bench:           1 ns/iter (+/- 0)\ntest http::h1::parse::tests::bench_parse_incoming                   ... bench:       3,840 ns/iter (+/- 510)\n```. I even rewrote commits message.. Oh nice catch!. New version with internal enum.. Updated.. @seanmonstar: Updated: anything else to change?. New benches:\n```\nrunning 2 tests\ntest get_one_at_a_time  ... bench:     128,290 ns/iter (+/- 11,401) = 402 MB/s\ntest post_one_at_a_time ... bench:     127,876 ns/iter (+/- 12,776) = 403 MB/s\ntest result: ok. 0 passed; 0 failed; 0 ignored; 2 measured\n Running target/release/deps/hyper-d8f89bd3a96bdf05\n\nrunning 361 tests\ntest header::common::accept::bench::bench_format                    ... bench:         583 ns/iter (+/- 191)\ntest header::common::accept::bench::bench_parse                     ... bench:         586 ns/iter (+/- 29)\ntest header::common::accept_language::bench::bench_format           ... bench:         794 ns/iter (+/- 385)\ntest header::common::accept_language::bench::bench_parse            ... bench:       1,154 ns/iter (+/- 53)\ntest header::common::allow::bench::bench_format                     ... bench:         371 ns/iter (+/- 189)\ntest header::common::allow::bench::bench_parse                      ... bench:         633 ns/iter (+/- 53)\ntest header::common::authorization::basic::bench_format             ... bench:         339 ns/iter (+/- 143)\ntest header::common::authorization::basic::bench_parse              ... bench:         193 ns/iter (+/- 52)\ntest header::common::authorization::bearer::bench_format            ... bench:         183 ns/iter (+/- 42)\ntest header::common::authorization::bearer::bench_parse             ... bench:          45 ns/iter (+/- 6)\ntest header::common::authorization::raw::bench_format               ... bench:          52 ns/iter (+/- 14)\ntest header::common::authorization::raw::bench_parse                ... bench:          38 ns/iter (+/- 12)\ntest header::common::cache_control::normal::bench_format            ... bench:         198 ns/iter (+/- 18)\ntest header::common::cache_control::normal::bench_parse             ... bench:         275 ns/iter (+/- 47)\ntest header::common::connection::close::bench_format                ... bench:          60 ns/iter (+/- 9)\ntest header::common::connection::close::bench_parse                 ... bench:          66 ns/iter (+/- 18)\ntest header::common::connection::header::bench_format               ... bench:          54 ns/iter (+/- 8)\ntest header::common::connection::header::bench_parse                ... bench:         104 ns/iter (+/- 40)\ntest header::common::connection::keep_alive::bench_format           ... bench:          54 ns/iter (+/- 21)\ntest header::common::connection::keep_alive::bench_parse            ... bench:          80 ns/iter (+/- 30)\ntest header::common::content_encoding::multiple::bench_format       ... bench:         138 ns/iter (+/- 17)\ntest header::common::content_encoding::multiple::bench_parse        ... bench:         159 ns/iter (+/- 40)\ntest header::common::content_encoding::single::bench_format         ... bench:          56 ns/iter (+/- 25)\ntest header::common::content_encoding::single::bench_parse          ... bench:          59 ns/iter (+/- 12)\ntest header::common::content_length::bench::bench_format            ... bench:          60 ns/iter (+/- 21)\ntest header::common::content_length::bench::bench_parse             ... bench:          37 ns/iter (+/- 6)\ntest header::common::content_type::bench::bench_format              ... bench:         219 ns/iter (+/- 29)\ntest header::common::content_type::bench::bench_parse               ... bench:         269 ns/iter (+/- 35)\ntest header::common::cookie::bench::bench_format                    ... bench:         150 ns/iter (+/- 24)\ntest header::common::cookie::bench::bench_parse                     ... bench:         168 ns/iter (+/- 4)\ntest header::common::date::asctime::bench_format                    ... bench:         897 ns/iter (+/- 137)\ntest header::common::date::asctime::bench_parse                     ... bench:         288 ns/iter (+/- 197)\ntest header::common::date::imf_fixdate::bench_format                ... bench:         812 ns/iter (+/- 484)\ntest header::common::date::imf_fixdate::bench_parse                 ... bench:         214 ns/iter (+/- 67)\ntest header::common::date::rfc_850::bench_format                    ... bench:         815 ns/iter (+/- 144)\ntest header::common::date::rfc_850::bench_parse                     ... bench:         234 ns/iter (+/- 149)\ntest header::common::etag::bench::bench_format                      ... bench:         154 ns/iter (+/- 20)\ntest header::common::etag::bench::bench_parse                       ... bench:          71 ns/iter (+/- 32)\ntest header::common::expires::asctime::bench_format                 ... bench:         809 ns/iter (+/- 445)\ntest header::common::expires::asctime::bench_parse                  ... bench:         284 ns/iter (+/- 141)\ntest header::common::expires::imf_fixdate::bench_format             ... bench:         793 ns/iter (+/- 120)\ntest header::common::expires::imf_fixdate::bench_parse              ... bench:         213 ns/iter (+/- 28)\ntest header::common::expires::rfc_850::bench_format                 ... bench:         789 ns/iter (+/- 80)\ntest header::common::expires::rfc_850::bench_parse                  ... bench:         230 ns/iter (+/- 99)\ntest header::common::host::bench::bench_format                      ... bench:         140 ns/iter (+/- 36)\ntest header::common::host::bench::bench_parse                       ... bench:          64 ns/iter (+/- 13)\ntest header::common::if_match::multi::bench_format                  ... bench:         303 ns/iter (+/- 37)\ntest header::common::if_match::multi::bench_parse                   ... bench:         347 ns/iter (+/- 44)\ntest header::common::if_match::single::bench_format                 ... bench:         148 ns/iter (+/- 42)\ntest header::common::if_match::single::bench_parse                  ... bench:         108 ns/iter (+/- 34)\ntest header::common::if_match::star::bench_format                   ... bench:          52 ns/iter (+/- 5)\ntest header::common::if_match::star::bench_parse                    ... bench:           2 ns/iter (+/- 0)\ntest header::common::if_modified_since::asctime::bench_format       ... bench:         784 ns/iter (+/- 54)\ntest header::common::if_modified_since::asctime::bench_parse        ... bench:         290 ns/iter (+/- 39)\ntest header::common::if_modified_since::imf_fixdate::bench_format   ... bench:         790 ns/iter (+/- 127)\ntest header::common::if_modified_since::imf_fixdate::bench_parse    ... bench:         211 ns/iter (+/- 16)\ntest header::common::if_modified_since::rfc_850::bench_format       ... bench:         789 ns/iter (+/- 291)\ntest header::common::if_modified_since::rfc_850::bench_parse        ... bench:         227 ns/iter (+/- 43)\ntest header::common::if_none_match::bench::bench_format             ... bench:         154 ns/iter (+/- 20)\ntest header::common::if_none_match::bench::bench_parse              ... bench:         129 ns/iter (+/- 50)\ntest header::common::if_unmodified_since::asctime::bench_format     ... bench:         801 ns/iter (+/- 238)\ntest header::common::if_unmodified_since::asctime::bench_parse      ... bench:         279 ns/iter (+/- 44)\ntest header::common::if_unmodified_since::imf_fixdate::bench_format ... bench:         794 ns/iter (+/- 346)\ntest header::common::if_unmodified_since::imf_fixdate::bench_parse  ... bench:         213 ns/iter (+/- 40)\ntest header::common::if_unmodified_since::rfc_850::bench_format     ... bench:         791 ns/iter (+/- 287)\ntest header::common::if_unmodified_since::rfc_850::bench_parse      ... bench:         231 ns/iter (+/- 56)\ntest header::common::last_modified::asctime::bench_format           ... bench:         796 ns/iter (+/- 100)\ntest header::common::last_modified::asctime::bench_parse            ... bench:         280 ns/iter (+/- 35)\ntest header::common::last_modified::imf_fixdate::bench_format       ... bench:         800 ns/iter (+/- 273)\ntest header::common::last_modified::imf_fixdate::bench_parse        ... bench:         230 ns/iter (+/- 119)\ntest header::common::last_modified::rfc_850::bench_format           ... bench:         792 ns/iter (+/- 157)\ntest header::common::last_modified::rfc_850::bench_parse            ... bench:         229 ns/iter (+/- 26)\ntest header::common::location::bench::bench_format                  ... bench:          52 ns/iter (+/- 11)\ntest header::common::location::bench::bench_parse                   ... bench:          46 ns/iter (+/- 18)\ntest header::common::origin::bench::bench_format                    ... bench:         166 ns/iter (+/- 36)\ntest header::common::origin::bench::bench_parse                     ... bench:         128 ns/iter (+/- 15)\ntest header::common::prefer::normal::bench_format                   ... bench:         201 ns/iter (+/- 50)\ntest header::common::prefer::normal::bench_parse                    ... bench:         609 ns/iter (+/- 146)\ntest header::common::preference_applied::normal::bench_format       ... bench:         252 ns/iter (+/- 37)\ntest header::common::preference_applied::normal::bench_parse        ... bench:         600 ns/iter (+/- 42)\ntest header::common::range::bytes_multi::bench_format               ... bench:         351 ns/iter (+/- 10)\ntest header::common::range::bytes_multi::bench_parse                ... bench:         334 ns/iter (+/- 36)\ntest header::common::range::custom_unit::bench_format               ... bench:         167 ns/iter (+/- 23)\ntest header::common::range::custom_unit::bench_parse                ... bench:          90 ns/iter (+/- 29)\ntest header::common::referer::bench::bench_format                   ... bench:          52 ns/iter (+/- 10)\ntest header::common::referer::bench::bench_parse                    ... bench:          46 ns/iter (+/- 11)\ntest header::common::server::bench::bench_format                    ... bench:          52 ns/iter (+/- 2)\ntest header::common::server::bench::bench_parse                     ... bench:          45 ns/iter (+/- 1)\ntest header::common::strict_transport_security::bench::bench_format ... bench:         159 ns/iter (+/- 25)\ntest header::common::strict_transport_security::bench::bench_parse  ... bench:         162 ns/iter (+/- 3)\ntest header::common::transfer_encoding::ext::bench_format           ... bench:          53 ns/iter (+/- 3)\ntest header::common::transfer_encoding::ext::bench_parse            ... bench:          79 ns/iter (+/- 3)\ntest header::common::transfer_encoding::normal::bench_format        ... bench:         111 ns/iter (+/- 25)\ntest header::common::transfer_encoding::normal::bench_parse         ... bench:         150 ns/iter (+/- 32)\ntest header::common::upgrade::bench::bench_format                   ... bench:         242 ns/iter (+/- 59)\ntest header::common::upgrade::bench::bench_parse                    ... bench:         429 ns/iter (+/- 66)\ntest header::tests::bench_headers_fmt                               ... bench:         171 ns/iter (+/- 108)\ntest header::tests::bench_headers_get                               ... bench:          12 ns/iter (+/- 5)\ntest header::tests::bench_headers_get_miss                          ... bench:           3 ns/iter (+/- 1)\ntest header::tests::bench_headers_has                               ... bench:           5 ns/iter (+/- 2)\ntest header::tests::bench_headers_new                               ... bench:          91 ns/iter (+/- 13)\ntest header::tests::bench_headers_set                               ... bench:          58 ns/iter (+/- 23)\ntest header::tests::bench_headers_view_is                           ... bench:           1 ns/iter (+/- 0)\ntest http::h1::parse::tests::bench_parse_incoming                   ... bench:       3,194 ns/iter (+/- 516)\ntest result: ok. 0 passed; 0 failed; 257 ignored; 104 measured\n```\nSeems like global performances improved quite a bit! :D. Updated.. Go on nightly and just run cargo doc. I can't figure out what's wrong with the remaining warnings so good luck. ;). Hum, good point!. It makes more sense.. Ok, let's update it this way then!. I'm not so sure to understand the usefulness of having a new struct for this. Just making the method unsafe should be enough, no?. Seems fair, I remove it.. It is quite useful actually for some internal operation when you want to translate directly from MemSlice to &str.. To be able to perform this comparison in an easier way.. So what am I supposed to do in here?. I just removed it.. Outch... Good catch!. ",
    "ashleygwilliams": "current status:\n``\n  Compiling hyper v0.10.0-a.0 (file:///Users/ag_dubs/rust/hyper)\nerror: cannot borrow immutable fieldself.pool` as mutable\n   --> src/client/mod.rs:140:24\n    |\n140 |         let checkout = self.pool.checkout(&url[..::url::Position::BeforePath]);\n    |                        ^^^^^^^^^\nerror: cannot borrow immutable field self.connector as mutable\n   --> src/client/mod.rs:145:13\n    |\n145 |             self.connector.connect(url)\n    |             ^^^^^^^^^^^^^^\nerror: aborting due to 2 previous errors\nBuild failed, waiting for other jobs to finish...\nerror: cannot borrow immutable field self.pool as mutable\n   --> src/client/mod.rs:140:24\n    |\n140 |         let checkout = self.pool.checkout(&url[..::url::Position::BeforePath]);\n    |                        ^^^^^^^^^\nerror: cannot borrow immutable field self.connector as mutable\n   --> src/client/mod.rs:145:13\n    |\n145 |             self.connector.connect(url)\n    |             ^^^^^^^^^^^^^^\nerror: aborting due to 2 previous errors\nerror: Could not compile hyper.\n```. ",
    "cmbrandenburg": "I'm in the same position as @jimmycuadra in that I'm working with an API client library that wraps Hyper. Maybe I'm missing something here, but it seems that being reactor-agnostic is not possible for client libraries using Hyper's 0.11.x series, but if the hyper::Client were to accept a Remote parameter instead of a Handle parameter, then it would be possible for the API client library to hide Core because then the library could manage its own background thread in which it runs a private Core reactor. As it is, I don't see how it's possible for the reactor to run in a different thread from the thread that constructs the Client.\nSomeone please correct me if I'm wrong.. ",
    "leoschwarz": "If Client::new takes a &Executor<...> instead of Handle a first issue is that either it has to take a Arc<Executor<...>> actually (which might not be the best ergonmics wise either), or a lifetime has to be added to Client, which might not be a very popular choice.\nI'm slightly leading towards Arc<Executor<...>> but maybe there is some opinion? Because the life time feels like the right way to do it, but again it can be annoying for the API user.. ",
    "CorruptComputer": "No clue why these are failing, everything is fine here \ud83e\udd14 \nPS C:\\Users\\ngupton\\Desktop\\hyper> cargo build --release\n    Updating registry `https://github.com/rust-lang/crates.io-index`\n   Compiling typeable v0.1.2\n   Compiling libc v0.2.19\n   Compiling semver v0.1.20\n   Compiling rustc-serialize v0.3.22\n   Compiling antidote v1.0.0\n   Compiling quick-error v0.2.2\n   Compiling cfg-if v0.1.0\n   Compiling log v0.3.6\n   Compiling error-chain v0.7.2\n   Compiling lazy_static v0.2.2\n   Compiling bitflags v0.7.0\n   Compiling bitflags v0.4.0\n   Compiling bytes v0.3.0\n   Compiling toml v0.2.1\n   Compiling traitobject v0.0.1\n   Compiling nix v0.5.1\n   Compiling winapi-build v0.1.1\n   Compiling winapi v0.2.8\n   Compiling mime v0.2.2\n   Compiling void v1.0.2\n   Compiling slab v0.1.3\n   Compiling user32-sys v0.2.0\n   Compiling gdi32-sys v0.2.0\n   Compiling kernel32-sys v0.2.2\n   Compiling spmc v0.2.1\n   Compiling pkg-config v0.3.8\n   Compiling num_cpus v1.2.1\n   Compiling rustc_version v0.1.7\n   Compiling httparse v1.2.1\n   Compiling openssl v0.9.6\n   Compiling matches v0.1.4\n   Compiling unicode-bidi v0.2.4\n   Compiling ws2_32-sys v0.2.1\n   Compiling unicase v1.4.0\n   Compiling language-tags v0.2.2\n   Compiling unicode-normalization v0.1.3\n   Compiling idna v0.1.0\n   Compiling metadeps v1.1.1\n   Compiling url v1.2.4\n   Compiling openssl-sys v0.9.6\n   Compiling vecio v0.1.0\n   Compiling time v0.1.36\n   Compiling net2 v0.2.26\n   Compiling miow v0.1.5\n   Compiling cookie v0.3.1\n   Compiling hyper v0.10.0\n   Compiling mio v0.5.1\n   Compiling rotor v0.6.3\n   Compiling hyper-openssl v0.2.1\n   Compiling hyper v0.10.0-a.0 (file:///C:/Users/ngupton/Desktop/hyper)\n    Finished release [optimized] target(s) in 64.53 secs. SSL is still there though? :thinking:. Ah well, I'm fairly new to rust and love the language! Any recommended starter projects for me to work on? . ",
    "PReinie": "I guess the good news is that when I searched for http-1009 this was the 2nd entry in Google's results, and the first one I clicked on, so you accomplished making information available for others who need help. . ",
    "NoraCodes": "Does this work with 0.11.0? It seems that hyper::net no longer exists.. ",
    "william20111": "\nDoes this work with 0.11.0? It seems that hyper::net no longer exists.\n\nThis ^ im currently using 0.10 as hyper::net is gone. Any update on this..?. ",
    "tesaguri": "You can use hyper-tls. The guide explains how to use it with v0.11.. rust\nlet body = res.body().map_err(|_| ()).fold(vec![], |mut acc, chunk| {\n    acc.extend_from_slice(&chunk);\n    Ok(acc)\n}).and_then(|v| String::from_utf8(v).map_err(|_| ()));\nprintln!(\"Body: \\n{}\", body.wait().unwrap());\nWell, with the above being said, you could ask stuff like that on Stack Overflow or some such.. Or you can write like this (since 78512bdb184903061ea02f1101c99a097483cb69):\n```rust\nuse hyper::client::Response;\nuse std::str;\nlet future_body = future_res.map(Response::body).flatten_stream().concat();\nlet body = future_body.wait().unwrap(); // : hyper::Chunk\nlet as_str = str::from_utf8(&body).unwrap();\n``. How about [hyper-openssl](https://github.com/sfackler/hyper-openssl)?\nItsOpensslServerimplementshyper::net::SslServerandFrom.. I think you want to usemapinstead ofand_then`.. You can use hyper-tls crate for the time being.\nBut unfortunately, it is not released to crates.io yet. So you need to use the git repository as the dependency.. ",
    "wez": "Just ran into this.  A couple of suggestions:\n\nThe client guide buries this issue under \"Client Configuration\" which is several steps too late into the flow.  Please make a point of calling out that an additional crate is required to do TLS.\nPlease consider breaking the TLS portion of \"Client Configuration\" into a separate \"Enabling HTTPS\" section to make this clearer to folks skimming docs.\nPlease make the error message more directive.  This is bubbling up in my first client integration as Error { repr: Custom(Custom { kind: InvalidInput, error: NotHttp }) } which doesn't tell me very much about what is going on\n\n. ",
    "kornholi": "Should be fixed in https://github.com/hyperium/hyper/commit/f04b1b0c295533b2eeef1d2ffa72ef80cc9d8ffa.. ",
    "radix": "Confirmed that it fixes my Program. Thank you very much!. Funny thing that I came to the Hyper issue tracker to search for issues about sharing the Core, to see it at the very top of the list :)\nI'm struggling even with using Server::handle, as @alexcrichton suggested -- I think for similar reasons that @scottlamb was talking about, with wanting to set things up before starting the HTTP server. For example, my HTTP server needs to have access to some other reactor-using data, but I can't get the reactor until I start my HTTP server.\nI'm still new to both Tokio and Rust, so I don't understand the discussion about TcpServer. It seems that TcpServerInstance also wants to own the Core, which seems similarly problematic. In other asynchronous frameworks I've used, the loop is always something you instantiate separately and pass to things that need it, to facilitate running several different things on the same event loop, so it's surprising to find this inverted structure in the Tokio ecosystem. Am I just misunderstanding this design?\nFWIW, the design I'm struggling with is setting up HTTP handlers that will communicate with an \"Actor\" (I'm trying the unreleased Kabuki library) in order to serialize a certain subset of my operations. The Actor needs to run on the reactor, and so does the Hyper server, but I need to be able to give the actor to my HTTP-handler closure, so I can't set things up in the right order.. The Twisted project developers have long regretted having a default event loop. It makes many things difficult. I recommend against it.. It would be nice to be able to easily append path segments, too.. ",
    "antrik": "Hint: such issues can be significantly reduced by using a defensive programming approach based on slicing:\nlet len = buf.len();\nbuf.set_len(len + additional);\nlet to_fill = &buf[len..];\nptr::write_bytes(to_fill.as_mut_ptr(), 0, to_fill.len());\n(In this specific case though I'm not sure why this unsafe code exists at all -- rather than just doing something like let len = buf.len(); buf.resize(len + additional, 0)?...). ",
    "M3rs": "I'm interested in giving this a try. Is it just alright to put in a pull request when I have something that passes tests?. Question: How do you want the authority with a default port handled? \nShould I refactor the method pub fn authority(&self) -> Option<&str> so if the port is a default (80, 443), it just returns the \"authority\" and not the port portion?\n``\nrelated test failures:\n---- uri::test_uri_parse_absolute_with_default_port_http stdout ----\n    thread 'uri::test_uri_parse_absolute_with_default_port_http' panicked at 'assertion failed:(left == right)(left:Some(\"127.0.0.1:80\"), right:Some(\"127.0.0.1\")`)', uri.rs:324\n---- uri::test_uri_parse_absolute_with_default_port_https stdout ----\n    thread 'uri::test_uri_parse_absolute_with_default_port_https' panicked at 'assertion failed: (left == right) (left: Some(\"127.0.0.1:443\"), right: Some(\"127.0.0.1\"))', uri.rs:335\n```\nMy forked/branched version: uri.rs\n. Ok - I have pushed an update to my uri.rs which causes the port to be included.\nWhat are the rules on path? The test_parse! methods give a mixed idea of what it should be expected if no path is given.\nExamples:\n```\naddress => path\n\nhttp://127.0.0.1:80 => \"/\"\nhttp://127.0.0.1:61761/chunks => \"/chunks\"\nlocalhost:3000 => \"\" (no path)\n```\nIs that just a mistake in the test, and in the third case (localhost), the path should be expecting \"/\" instead of \"\"?\nThe pub fn path(&self) -> &str method looks like it is defaulting \"\" when it cannot get a path.. Ok - I have updated the pub fn path(&self) -> &str method logic to try to check for absolute-form1 and include a path if one is not specified.\nHowever, the test_uri_parse_error() no longer appropriately errors. I am considering borrow logic from rust-url's (origin.rs)[https://github.com/servo/rust-url/blob/master/src/origin.rs] to throw an Error::Method if it is an opaque scheme.\n1 I am making the assumption that if self.scheme().is_some() is true that indicates the url is in absolute-form and missing a path.\n. Build fail (nightly) note:\nerror: unused #[macro_use] import\n  --> src/lib.rs:20:1\nIs that something I can address, or not my fault?. This just in authorization.rs, right? I can try to swap these. . I'd be happy to work on this.. It is only used in the block else if s.contains(\"://\") (albeit, now in a method call).\nWould you prefer the fn parse_authority(s: &str) -> Option<usize> method removed (definition) and inlined in place of let auth = parse_authority(s); (relevant line) so the unwrap() call is safer?. Good point! Admittedly, that was a copy-paste from the previous code and I didn't think about it. Pushed an update.. ",
    "antoyo": "What is the state of HTTPs clients based on tokio?\nI looked into reqwest and it does not seem to be based on tokio.\nWhat do I need to do to create an HTTPS request based on tokio?\nThanks.. I do not send it to another thread.\nI think this issue is caused by boxing the future since BoxFuture requires Send.\nEdit: It is indeed caused by boxed() since this example fails to compile with the same error:\nrust\n        let client = Client::new(&handle);\n        let future = client.get(url).map_err(|_| ()).and_then(|res| {\n            res.body().map_err(|_| ()).fold(vec![], |mut acc, chunk| {\n                acc.extend_from_slice(&chunk);\n                Ok(acc)\n            })\n        })\n            .map_err(|_| ())\n            .boxed();\nIt is normal behaviour?\nI'll try to switch to Box<Future> instead of BoxFuture.\nEdit 2: I've fixed my library to use Box<Future> and now it works.\nI still wonder if futures was designed this way on purpose.\nIt seems to me that BoxFuture is a way to return different types of future from one function.\nBut it is not usable with some tokio-based crates like hyper and twist.. Since this is an issue with futures, I close this issue.\nThanks.. ",
    "nayato": "I think the easiest right now is to use tokio-proto to layer tokio-tls under hyper, here's working sample:\nhttps://github.com/nayato/hyper-test/blob/90add9d2db27503a204294177f4552e0bb11dca2/src/main.rs#L43. is this now blocked on moving away from tokio-proto?. @seanmonstar it all sounds reasonable. I'm not sure I get the part about returning Chunk of buffered bytes at the end though. I'd expect any buffered bytes be \"put back\" and made available through reading from returned IO object. I.e. return implementation that first depletes buffered bytes, then proxies calls to actual underlying IO object.. ",
    "Darkspirit": "tokio-tls uses native-tls which isn't \"as much in Rust as possible\".\ntokio-rusttls (started as a fork of tokio-tls) sounds promising to me.\nrustls is built on top of ring and webpki.\nring is a fork of Google's Boringssl, which aims to rewrite as much as possible (and meaningful) in Rust. Both projects (ring and boringssl) are working together!\nFor earlier hyper versions, there was hyper-rustls. rustls is probably going to get included in Mozilla Servo, a webbrowser written in Rust. With using the system's native TLS implemenation we would not profit from Rust's advantages to have a secure TLS implementation.. I would like to apologize, tokio-rustls causes this behavior.. ",
    "daboross": "@TerraX-net at the moment, native TLS is a more secure solution than Rust ring/rustls due to rustls not having any security audits performed on it. When it reaches more maturity, it will definitely be a better default, but for now it's better to use native-tls.. Thanks!\nThe build errors just seem to be mostly some renames that futures did, would you mind if I just submitted another PR changing those in hyper?. No problem, thank you!. ",
    "robinst": "Looks like this was done on master and is a relatively small change. Would you mind if I opened a PR to backport it to 0.10.x?. Thanks! For anyone wondering, the above is now also released in 0.10.10.. ",
    "saneyuki": "@seanmonstar \nThank you! I confirmed I can use v0.9.17.. ",
    "itsmontoya": "I don't  understand why the commit-message-check failed, my message is less than 72 chars :/. ",
    "fmonjalet": "Thank you! I'll think of a workaround in the meantime. . ",
    "marcb": "I'm also interested in CONNECT support. Looking to correlate TLS SNI with the domain name passed to CONNECT, to (dynamically) whitelist and also map the name to another for the resolution of the next hop.\nContext an in-bound forward proxy for one platform to reach other platforms within an enterprise network across DMZs and fronted by reverse proxies.\nAnother protocol switch example is to support the proxy protocol (aka ELBs) stripping and insertion.. ",
    "rsdy": "After doing some more debugging, it looks like a server-side configuration issue.\nHowever, the connections are still being rotated on a regular basis, with seemingly no way to specify a timeout to keep them around. Looking at the output of netstat, I don't understand how max_idle parameter would work, because the number of active connections seems independent of that value. This behaviour may be best documented?. Thanks for clarification. That makes sense perfect sense.. This is the code I have used to initialise the Client, ie. explicitly pass in a Pool. Sorry I missed this detail:\nlet client = Client::with_connector(Pool::with_connector(PoolConfig { max_idle: 16 },\n                                                         HttpsConnector::new(TlsClient::new()))); \nedit: I set up a watch for netstat, and I can see that the connection pool doesn't work at all. The number of connections at any point in time equals the number of threads that I'm calling Client from (+ the ones being torn down), even if it's Arc'd between them. Connections are rotated after every single transaction.. @seanmonstar do you have any other tips why this might not be working? As far as I can tell, I'm using the library correctly, and connection pooling still doesn't work.. Thanks a lot! Reading the result fully seems to have done the trick. Awesome.. ",
    "davidcornu": "@seanmonstar started https://github.com/hyperium/hyper/compare/master...davidcornu:link-extensions. Will open a PR when I've updated the tests to get some feedback if that's OK.. This doesn't seem right. If I'm reading the ABNF from https://tools.ietf.org/html/rfc5988#section-5 correctly\n\nLink           = \"Link\" \":\" #link-value\n  link-value     = \"<\" URI-Reference \">\" *( \";\" link-param )\n  link-param     = ( ( \"rel\" \"=\" relation-types )\n                 | ( \"anchor\" \"=\" <\"> URI-Reference <\"> )\n                 | ( \"rev\" \"=\" relation-types )\n                 | ( \"hreflang\" \"=\" Language-Tag )\n                 | ( \"media\" \"=\" ( MediaDesc | ( <\"> MediaDesc <\"> ) ) )\n                 | ( \"title\" \"=\" quoted-string )\n                 | ( \"title*\" \"=\" ext-value )\n                 | ( \"type\" \"=\" ( media-type | quoted-mt ) )\n                 | ( link-extension ) )\n  link-extension = ( parmname [ \"=\" ( ptoken | quoted-string ) ] )\n                 | ( ext-name-star \"=\" ext-value )\n\nlink-extension isn't a literal but either a single attribute as a parmname (defined in https://tools.ietf.org/html/rfc5987#section-3.2.1) or a key value pair separated by = where the key is a parmname and the value is either a ptoken or a quoted-string (defined in https://tools.ietf.org/html/rfc2616#section-2.2).\nWith that in mind, my understanding is that headers like\nLink: <https://example.com>; rel=\"previous\"; foo=\"bar\"; baz=\"qux\"\nare valid. foo and bar are both link-extensions.. If that is indeed correct, LinkValue's link_extension field should probably be named link_extensions and return a Option<Vec<LinkExtension>> (or just a Vec<LinkExtension>) where LinkExtension is something like\nrust\nstruct LinkExtension {\n  name: String,\n  value: Option<String>\n} . ",
    "mattwoodyard": "I tried getting that working first (https://play.rust-lang.org/?gist=d8d0d1ed14574f4085b1d663c6354ef8&version=stable&backtrace=0), but it seemed to be missing some implementation (I think: https://github.com/hyperium/hyper/issues/1036). I was going to add that, but then I noticed that tokio-proto didn't have graceful shutdown, which is something I wanted, so I did this.  \nIs there something I've missed?. For my immediate task, I'm just trying to get TLS to work. I'm not particularly attached to the approach in this PR. If #1036 can make the tokio_tls stuff work, thats fine. Longterm I'd like graceful shutdown with my TLS. If the plan is to generalize the hyper approach into tokio-proto, I can take a swing at that.. Closing in favor of #1047 . Compile with this PR, still produces an error. It looks to me like the BindServer should pick work via  ServerProto. Clearly, the compiler disagrees with me. Should hyper need a BindServer impl? If so why does the ServerProto impl no fulfill the bounds? Is there a way to make the compiler spit out more type inference detail?\n  |\n213 |     let tcp = TcpServer::new(Http::new(), addr);\n    |               ^^^^^^^^^^^^^^ the trait tokio_proto::BindServer<_, tokio_core::net::TcpStream> is not implemented for hyper::server::Http\n    |\n. I have no idea what I had done, but a couple rounds of git pull; and cargo update got it building. Works now, with ssl too. Thanks.. ",
    "spk": "No problems thanks for the explanations. Hehe; for me its more without charset; made a fix in https://github.com/spk/hyper/commit/4d893a7fc9cf2b187598298dc467b4db9b44d516. ",
    "kkartaltepe": "\nWhat gives you that impression?\nhyper is a fast, modern HTTP implementation written in and for Rust. It is a low-level typesafe abstraction over raw HTTP, providing an elegant layer over \"stringly-typed\" HTTP.\n\nThis might just be my misinterpretation.\nI did not know that the Url was a rexport that would explain why I was having issues finding documentation on it. It looks like my question is better answered over on the Url repo, and in fact from their docs I see that non UTF-8 query parameters are an off by default feature.\nThanks for the information! Hopefully using hyper with this option turned on in Url wont be an issue.\n(I hope its ok that I close this myself as my issue is actually about the Url crate). ",
    "alexbowers": "that would be great. Great, thanks.. Feel free to take the patch, idea and reimplement as you see fit if necessary.. After thinking on it, this is pretty conclusively incorrect. I'll close, but the issue at #1062 still stands. ",
    "steckel": "That's probably what I was looking for.\nMy question stemmed from some confusion when I attempted to replicate the code in examples/hello.rs using 0.10.* not realizing that it represented a different design implementation (async io with Service and Future) that was available in 0.10.0.\nThank you for pointing me to the Milestones.. ",
    "samgiles": "@seanmonstar That looks real similar to the url crate's Origin implementation, since it's a dependency, could we rely on the serialization algorithms implemented there?\nAh, I might implement Header for url::Origin, would be a nice intermediate solution.. ",
    "alexeyzab": "Hi there! I'd like to try implementing this.. I went ahead and squashed the extra commit as well as force pushed it. \nNot sure if that's the right approach here, but I wanted to keep this change as a single commit. Let me know if there are other things I can add/improve here.\nThank you!. Oh, this is really neat, thanks for pointing it out! I am a bit new to Rust and didn't know about this until now.. ",
    "MJDSys": "I saw the PR for the Option<_> change after I'd already submitted this PR :)\nIf you prefer deconstruct doesn't have SocketAddr, should the method and version be removed too?  Those seem like other easily clonable fields.  I can adjust the PR to remove those as well.  Otherwise, I can update this PR to return the Option.. That seems like the most sensible way to do it.  I was only adding back remote_addr, as there didn't seem to be a specific reason why it was removed at the time.\nFor now I'll just close this PR.  It's easy to adjust Iron to this new reality, and this can always be revisited if it turns into a problem :)\nThanks for your work in all this!. ",
    "mwanner": "Coming from a Python Twisted background, I'm also pretty surprised about the protocol implementations creating or owning their event loops. I had a pretty hard time figuring out how the \"easy mode\" was supposed to work and actually fail to see anything easy, there.\nI hacked together something that does work for me, here:\nhttps://github.com/mwanner/hyper/commit/ef7c13def227034af0a2c9674eb3f1ddc7f5d865\nSeeing this discussion, I don't quite this a PR is appropriate, though.\nFrom what I understand, changing hyper to use the TcpServer from tokio_proto should solve this issue. I'd appreciate that.. Thanks for your quick response.\n\nWere you specifically looking for an 'easy' method to give a Core to?\n\n..any method at all. AFAICT the server part insists on creating its own Core. Or am I missing something? That's what I tried to fix with my patch (talking about and patching against master).\n\nOr you find even the usage of the easy method in the hello world example to hard to figure out?\n\nI'm missing the event loop from examples/server.rs. How would I run two HTTP Server instances on the same event loop?. I see, I definitely missed this comment here:\n/// This server is intended as a convenience for ...\nI guess the name Server fooled me, but I see how it can be useful for \"easy\" cases.\nTogether with your example, I managed to put together something pretty minimal that compiles. I even filed a PR, but please feel free to reject, though.. ",
    "nielsle": "The alternative API looks nice. My ideal solution would require changes to tokio-proto as well. I wonder if the following could be massaged to pass the  borrow checker.\n~~~\ncore.handle()\n     .spawn2(|handle| Http::spawn_new(addr, new_service(handle))\n~~~. Withoutboats has a pull request that adds middleware wrappers to tokio_service::Service. Perhaps that could be used to add logging and timing and retries to the hyper::Client\ntokio-rs/tokio-service#21\nThis solution would be fairly generic and extendable, but it might also be slightly complicated.. The following link describes a workaround \nhttps://doc.rust-lang.org/std/process/fn.exit.html\nThe following link describes a proposal for a language change that would allow users to use ? in main\nhttps://github.com/rust-lang/rfcs/pull/1937. ",
    "tomyan": "Just adding my voice to those who found it surprising that protocol handlers would either create the core themselves, or initiate the event loop and block - seems like creating and running the event loop should be separate concerns (as in twisted, node, etc) from the protocol handlers, so that they can be composed together freely within the same event loop.\nIMO it would still be easy if there were three steps: create the core, set up the protocol handler (without blocking) & run the event loop (where the first and third steps are not specific to hyper or any other protocol handler), but would not lead to a jarring experience when you want to deal with multiple different types of events within the same event loop - in my case before I found this issue I started trying to create a wrapper around Server's run method that would return a future and not block (using a thread to run the server in) - not the sort of thing I would expect to need to do with a event/futures based library.. @seanmonstar, @alexcrichton: I've been trying to take the example from @seanmonstar's comment above (titled \"Before\") and make it work in my code, but haven't had much luck. I have the following function for running a server with a handle to an existing core:\npub fn run(handle: &Handle) {\n    let addr = \"127.0.0.1:1337\".parse().unwrap();\n    let http = Http::new();\n    let listener = TcpListener::bind(&addr, &handle).unwrap();\n    handle.spawn(listener.incoming().for_each(move |(socket, peer)| {\n        println!(\"got connection from {}\", peer);\n        http.bind_connection(&handle, socket, peer, || Ok(RequestHandler));\n        Ok(())\n    }));\n}\n\n(RequestHandler is a struct that implements hyper::server::Service, and works when I use hyper's run method)\nWhen I run this I get the following errors:\nerror[E0277]: the trait bound `[closure@src/http_server.rs:53:53: 53:74]: hyper::client::Service` is not satisfied\n  --> src/http_server.rs:53:14\n   |\n53 |         http.bind_connection(&handle, socket, peer, || Ok(RequestHandler));\n   |              ^^^^^^^^^^^^^^^ the trait `hyper::client::Service` is not implemented for `[closure@src/http_server.rs:53:53: 53:74]`\n\nerror[E0271]: type mismatch resolving `<futures::stream::ForEach<tokio_core::net::Incoming, [closure@src/http_server.rs:51:47: 55:6 http:_, handle:_], std::result::Result<(), std::io::Error>> as futures::Future>::Error == ()`\n  --> src/http_server.rs:51:12\n   |\n51 |     handle.spawn(listener.incoming().for_each(move |(socket, peer)| {\n   |            ^^^^^ expected struct `std::io::Error`, found ()\n   |\n   = note: expected type `std::io::Error`\n              found type `()`\n\nerror: aborting due to 2 previous errors\n\nI have been trying various things without much luck and was wondering if you'd be able to advise where I'm going wrong?\nThanks\nTom. Thanks @seanmonstar, that makes perfect sense (I probably should have been able to work it out). Do you have any idea about the other error, which I'm still getting:\nerror[E0277]: the trait bound `[closure@src/http_server.rs:55:53: 55:74]: hyper::client::Service` is not satisfied\n  --> src/http_server.rs:55:14\n   |\n55 |         http.bind_connection(&handle, socket, peer, || Ok(RequestHandler));\n   |              ^^^^^^^^^^^^^^^ the trait `hyper::client::Service` is not implemented for `[closure@src/http_server.rs:55:53: 55:74]`\n\nI don't think RequestHandler has changed from what I was successfully running with the server.run(...) method. It seems strange that it would be expecting the hyper::client::Service trait, rather than hyper::server::Service? Anyway, here's the definition of RequestHandler:\n#[derive(Clone, Copy)]\nstruct RequestHandler;\n\nimpl Service for RequestHandler {\n    type Request = Request;\n    type Response = Response;\n    type Error = hyper::Error;\n    type Future = FutureResult<Response, hyper::Error>;\n\n    fn call(&self, request: Request) -> Self::Future {\n        match (request.method(), request.path()) {\n            (&Get, \"/\") => self.slash(),\n            _           => self.not_found()\n        }\n    }\n}\n\nimpl RequestHandler {\n    fn slash(&self) -> <RequestHandler as Service>::Future {\n        ok(Response::new().with_body(\"Hello, World!\\n\"))\n    }\n\n    fn not_found(&self) -> <RequestHandler as Service>::Future {\n        ok(\n            Response::new()\n                .with_status(StatusCode::NotFound)\n                .with_body(\"404 Not Found\\n\")\n        )\n    }\n}\n\nThanks\nTom. Of course, this is handling one connection! Thanks for the pointer :-). @bwo well put. I'm hoping this gets revisited once https://github.com/tokio-rs/tokio-core/pull/212 (or similar) gets incorporated - I would expect libraries to use the default (per thread) loop, with an option to override. @seanmonstar, @alexcrichton what are your thoughts on this?. ",
    "bwo": "FWIW I also found this far from an \"easy mode\", because the first thing I wanted to do with Hyper was create a server which, in handling connections, would itself make http requests (surely not a particularly advanced requirement). The examples using Client all require creating a Core yourself and getting the handle from it; the examples using Server just implement call for the Service trait \u2026 which, as far as I can tell, doesn't give you a way to get your hands on a handle.. ",
    "olegmedoed": "totally agree with @bwo, because \"easy mode\" which is promoted in examples creates impression that it's \"right/standard way\" to create a web server, but web  server created in this way is useless in most cases, since as @bwo mentioned it has no ability to talk to other web-services or DBs.. ",
    "izolyomi": "I've also just encountered this issue or at least something very similar. Being new to Rust and Hyper, I'm trying to create a few liner where some costful operation is served with async Http.\nMy approach was to implement my Service::call() to spawn a task to the reactor and use and_then() on its resulted future to build the HTTP response serializing the result. But I've found no way to access the message loop handle anywhere in call().\nDo we have a final conclusion about the best way how the message loop handle should be retrieved in such cases?\nEDIT: I've found this issue and example. I recommend to include something like this in the official examples.. Being new to Rust and Hyper, this example just have saved me from a lot more of investigation. It was just what I needed, so it's absolutely useful, something like this should be between the official examples.. ",
    "alu": "Hi.\nI create http Proxy Like http server with hyper server and client.\nThe server need keep-alive connection to origin server so it need shared hyper client.\nI found this example and tried implementing it with reference.\nMy codes is here.\nI think I can more simplfy if #1322 be implimanted, but my codes are better (maybe not best) for now?. ",
    "fzakaria": "I'm talking about from the client side.\nI just tried to use Hyper (release not master) and it was impossible to even make any changes to the request object -- especially if I wanted to lets say: calculate an Authorization header based on already set headers.\n\nRequestBuilder doesn't allow access to headers\nEven if I hand form the Request (not using RequestBuilder) there is no method in Client that accepts it. It seems like it must take RequestBuilder and transforms it to Request in send.\n\nA simple trait for ClientRequestFilter (Request -> Request) and ClientResponseFilter or however you imagine it might be usefu.\nPS: Unclear how much of this is resolved in master. I just took the current release which is available on crates.io. I'll investigate more. \nThanks for the follow-up. ",
    "limitee": "My problem is the same, hyper hangs, telnet is ok, but hyper do nothing. I use the release versoin 0.10.4.. Tokio only handles events. Don't has a thread pool to do the ture work.Use the cpupool can resolve this. . ",
    "algermissen": "Personally, I'd rather have the user of Client in charge to make that decision. Does it make sense to isolate the relevant structures and let the user pick whether to make them Send or not?. All fine from my POV - as long as you do not make it Send by default :-). +1 for the code based solution - then there can be a static lookup mechanism (array) to go from code to message. And that would be compatible.. A URI can have an empty path segment per spec. In general care must be taken not to confuse URIs and URI-References and the issues involved with resolving a URI reference against a context URI. In addition are the rules for HTTP request URIs. Then also, URIs and proxy requests can be unintuitive but exceptional cases be very useful (eg. doing a proxy requests to a non HTTP URI)\nLooking at the current implementation briefly it looks not quite right but seems to focus on HTTP Requests instead of full URI spectrum.\nIn general, I think the best advice is to stick to the RFCs very strictly and let them guide the architecture of the various pieces (structs). Scala's Akka-HTTP did a good job, AFAIK and it certainly will be helpful to run the design by an expert briefly. I'll try to get one of them interested.\nSorry, I have never myself implemented an HTTP lib, just know that non-strict implementations cause a lot of pain down the line if you want to do real HTTP.\nAkka-HTTP has always struck me as one of the truly better implementations around URI and HTTP specs. Eg:\nhttp://doc.akka.io/docs/akka-http/current/scala/http/common/uri-model.html\nHere is the explicit support for path-emptyness: http://doc.akka.io/japi/akka/2.4.4/akka/http/scaladsl/model/Uri.Path.html#isEmpty--\nJan\n. Caveat: I am very(!) new to this, and merely trying to add value here, not complaining.\nFWIW it feels that the current convenience impl and also the proposals hide too much of the internals (or do not allow for working with them through accessors). Eg one aspect is listening on a port with multiple threads (eg [1]). Another one is related to handling failures in the incoming conns loop (sorry, need to dig the reference up). So I think a more fine grained API will be beneficial.\n[1] https://github.com/algermissen/web-rust/blob/master/src/bin/ts1.rs#L50. I had a similar observation today, when POSTing a body and accidentally setting Content-Length to 0. The effect was that I never saw a response on the client side - so something seems to not proceed on the server side.\nI did not investigate this further, but the issue description reminded me a lot about it.. Maybe this is not quite to the point, but the thread reminded me of https://crates.io/crates/tk-listen . ",
    "pgerber": "\nAre all the requests being made at the same time, \u2026\n\nNo, the pool is currently dedicated to a single thread doing one request after another. The code that does the request (the S3Client you can see in the code sample) is in another crate and I'd have to check if it does anything weird. I can't see why it would work with HTTP and not HTTPS though but I'll check to be sure.\n\nIs the full response being read\n\nIt's actually PUT requests, but yes, requests are completed before the next request is started.\n\nDoes this occur with other TLS implementations?\n\nI had already tested with hyper-openssl and just now tested hyper_native_tls. None of them work.\n. It turned out that the S3 storage provider accidentally set the Connection: close header. They are still in early beta, so I'll forgive them.\n@seanmonstar Thank you so much for your help!. ",
    "timokau": "Will you implement From<Url> for Uri? Or how would you recommend converting between the two types?\nAs a  quick hack Uri::from_str(&url.to_string()).unwrap()) works, but thats unnecessarily costly and requires an unwrap.. Okay, thank you.. ",
    "Kerollmops": "Can I ask why you choose to remove the Url crate (kind of Rust-official) and not the Uri one ? What are the advantages of Uri hover Url ?\nI don't understand why being less generic is a good thing in this case ?\nUsers working with multiple web-libraries (or just libraries that works with Urls) will need to depends on multiple structs representing the same type of data, useless and not efficient, don't you think ?. ",
    "mmirate": "I was writing a pull-request for this issue, but I've discovered that this interpretation of the RFC is incorrect.\n1#encoding actually means \"a comma-separated list of encoding containing at least 1 element`.\nThe relevant material is in Section 1.2 of the RFC which defines this header:\n\n1.2.  Syntax Notation\nThis specification uses the Augmented Backus-Naur Form (ABNF)\nnotation of RFC5234 with a list extension, defined in Section 7 of\nRFC7230, that allows for compact definition of comma-separated\nlists using a '#' operator (similar to how the '*' operator indicates\nrepetition).  Appendix C describes rules imported from other\ndocuments.  Appendix D shows the collected grammar with all list\noperators expanded to standard ABNF notation.\n\nFrom Section 7 of RFC7230:\n\n7.  ABNF List Extension: #rule\nA #rule extension to the ABNF rules of [RFC5234] is used to improve\nreadability in the definitions of some header field values.\nA construct \"#\" is defined, similar to \"*\", for defining\ncomma-delimited lists of elements.  The full form is \"\\<n>#\\<m>element\"\nindicating at least \\<n> and at most \\<m> elements, each separated by a\nsingle comma (\",\") and optional whitespace (OWS).\nIn any production that uses the list construct, a sender MUST NOT\ngenerate empty list elements.  In other words, a sender MUST generate\nlists that satisfy the following syntax:\n1#element => element *( OWS \",\" OWS element )\n\n. Correct.. \n",
    "vandenoever": "This version compiles with master but does not return any data.\nThe closure in and_then() is never called.\nThe error that is printed is\noops, an error Io(Error { repr: Custom(Custom { kind: Other, error: StringError(\"event loop gone\") }) })\n```rust\nextern crate futures;\nextern crate hyper;\nextern crate tokio_core;\nuse futures::Future;\nuse hyper::{client, server, Client, Url};\nstruct Proxy;\nfn server_request_to_client_request(req: &server::Request) -> client::Request {\n    // todo: handle parse error\n    let url = Url::parse(&format!(\"{}\", req.uri())).unwrap();\n    let mut client_req = client::Request::new(req.method().clone(), url);\n    client_req.set_version(req.version().clone());\n    *client_req.headers_mut() = req.headers().clone();\n    client_req\n}\nimpl server::Service for Proxy {\n    type Request = server::Request;\n    type Response = server::Response;\n    type Error = hyper::Error;\n    type Future = Box>;\nfn call(&self, req: server::Request) -> Self::Future {\n    let core = tokio_core::reactor::Core::new().unwrap();\n    let handle = core.handle().clone();\n    let client = Client::new(&handle);\n    let mut client_req = server_request_to_client_request(&req);\n    println!(\"got request {}\", req.uri());\n    client_req.set_body(req.body());\n\n    Box::new(client.request(client_req)\n        .map_err(|e| {\n            println!(\"oops, an error {:?}\", e);\n            e\n        })\n        .and_then(|res| {\n            println!(\"got response {}\", res.headers());\n            let mut resp: server::Response = server::Response::new();\n            resp = resp.with_headers(res.headers().clone());\n            resp.set_status(res.status().clone());\n            resp.set_body(res.body());\n            futures::future::ok(resp)\n        }))\n}\n\n}\nfn main() {\n    let addr = \"127.0.0.1:1337\".parse().unwrap();\n    let server = server::Http::new().bind(&addr, || Ok(Proxy {})).unwrap();\n    println!(\"Listening on http://{} with 1 thread.\",\n             server.local_addr().unwrap());\n    server.run().unwrap();\n}\n. Here is a version that uses a tokio Core per Service. This does not print error but hangs. The reason is probably that it mixes multiple event loops. The code hangs on one loop while another has data.rust\n//#![deny(warnings)]\nextern crate futures;\nextern crate hyper;\nextern crate tokio_core;\nuse futures::Future;\nuse hyper::{client, server, Client, Url};\nstruct Proxy {\n    core: tokio_core::reactor::Core,\n}\nfn server_request_to_client_request(req: &server::Request) -> client::Request {\n    // todo: handle parse error\n    let url = Url::parse(&format!(\"{}\", req.uri())).unwrap();\n    let mut client_req = client::Request::new(req.method().clone(), url);\n    client_req.set_version(req.version().clone());\n    *client_req.headers_mut() = req.headers().clone();\n    client_req\n}\nimpl server::Service for Proxy {\n    type Request = server::Request;\n    type Response = server::Response;\n    type Error = hyper::Error;\n    type Future = Box>;\nfn call(&self, req: server::Request) -> Self::Future {\n    let client = Client::new(&self.core.handle());\n    let mut client_req = server_request_to_client_request(&req);\n    println!(\"got request {}\", req.uri());\n    client_req.set_body(req.body());\n\n    Box::new(client.request(client_req)\n        .map_err(|e| {\n            println!(\"oops, an error {:?}\", e);\n            e\n        })\n        .and_then(|res| {\n            println!(\"got response {}\", res.headers());\n            let mut resp: server::Response = server::Response::new();\n            resp = resp.with_headers(res.headers().clone());\n            resp.set_status(res.status().clone());\n            resp.set_body(res.body());\n            futures::future::ok(resp)\n        }))\n}\n\n}\nfn main() {\n    let addr = \"127.0.0.1:1337\".parse().unwrap();\n    let server = server::Http::new()\n        .bind(&addr, || {\n            let core = tokio_core::reactor::Core::new().unwrap();\n            Ok(Proxy { core: core })\n        })\n        .unwrap();\nprintln!(\"Listening on http://{} with 1 thread.\",\n         server.local_addr().unwrap());\nserver.run().unwrap();\n\n}\n```. ",
    "chrmod": "I would be very much interested in such example code. Found another, apparently also not working approach https://gist.github.com/infinityb/600c22ae549cecf43244 (maybe I'm using wrong version of the libraries). ",
    "meganehouser": "I wrote a simple proxy server with single event loop.\nhttps://gist.github.com/meganehouser/d5e1b47eb2873797ebdc440b0ed482df\nI referred to weldr.. ",
    "jbg": "https://github.com/jbg/prox/blob/master/src/main.rs. Thanks for the explanation. I had not run cargo update and was having problems with multiple versions of futures being installed, which lead to me making the fork. This can be closed!. what would that URI look like? (the question is about SOCKS proxies, not HTTP proxies). ",
    "terry90": "I'm currently writing a simple proxy with possibility of custom middlewares.\nSince I'm a new rustacean, do not expect the code to be the most opti.\nhttps://github.com/terry90/rs-simple-proxy. ",
    "crackcomm": "Thanks, that explains a lot.\nI can't see any correlation between timeouts and request, how can I ensure that request is cancelled after timeout?. @carllerche this is a great mechanism, thank you for this explanation and @seanmonstar thank you for this example.. Maybe response could be shared between client and server so easily proxied, sharing a single builder.. ",
    "bryaan": "Got it, thanks. ",
    "lhecker": "@seanmonstar I believe I'm currently facing this problem as well...\n\nIf using the default Body::pair(), the Sender should be able to tell you an error occurred when using start_send and poll_complete.\n\n...because that doesn't work for me.\nI basically have a handler similar to this:\n```rust\nlet (tx, rx) = hyper::Body::pair();\nthread::spawn(move || {\n    loop {\n        tx = match tx.send(Ok(some_data_chunk)).wait() {\n            Ok(tx) => tx,\n            Err(err) => break,\n        };\n    }\n});\nreturn Response::new().with_body(rx);\n```\nEven if the client disconnects the above thread will never quit, because the Sender always returns Ok(_). \ud83d\ude15. ",
    "lucab": "Just a usecase/question: I used to have a base url stored as a hyper::Url and then adding components to it via .join() and query_pairs_mut(). This PR seems to have removed this kind of usage, as there are no more methods to mutate an Uri in place once built. Am I right that this is on purpose and the recommended usage is as described by @alexcrichton in https://github.com/hyperium/hyper/issues/1089#issuecomment-286252505?. I'm fine with FutureResponse, the hard times are coming from trying to do an async conversion on an already resolved Response (and perhaps doing it the wrong way).\nIn a simplified snippet similar to my combinator:\n``\nclient1.request(req1).and_then(move |r| {\n  if r.status() == StatusCode::ImATeapot {\n    client2.request(req2) // This is a FutureResponse\n  } else {\n     // ... I would have expected a r.into_future() here\n }).flatten().from_err();. First, thanks for the quick feedback (and sorry, I should have provided a snippet earlier)!future::Either` does indeed fit this scenario and solve my issue (I just missed its existence before).\n\nso you have a closure where you want to return 2 different types\n\nOTOH, this is not exactly what I was planning to do. I naively wanted to reconcile the already-resolved Response back to its async counterpart as I know that all the other branches of that closure will return FutureResponse. Wrapping everything in a Either looks like a perfect generic solution, but here I instinctively looked for a simpler async conversion, which looks like is not really possible by design/constraints?. Related https://github.com/ctz/hyper-rustls/pull/22.\nEDIT: added tokio-rustls example.. ",
    "bittrance": "I have a very similar use case to OP:s description, but setters has the problem that each would have to return Result<(), UriError> which would be rather cumbersome. I think I would prefer a builder:\nrust\nlet builder = UriBuilder::new(\"https\", \"example.com\").path(\"/foo\");\nbuilder.add_query_param(\"key\", \"value\");\nlet uri = builder.build().expect(\"Bad uri input\");\n.build() would of course be -> Result<Uri, UriError>.\nHow does that sound?. ",
    "avranju": "The problem with using the url crate for building URLs from string fragments is that there doesn't seem to be an easy way to map the ParseError type from the url crate to the UriError type from hyper.\nrust\nlet base_path = \"http://localhost\";\nlet path = \"/boo\";\nlet uri: Result<Uri, UriError> = Url::parse(base_path)\n    .and_then(|base| base.join(path))\n    .map_err(|_| /* How to construct UriError here? */)\n    .and_then(|url| url.as_str().parse());\nPlayground link.\nThe problem is that the ErrorKind enum that UriError uses is not public. Right now I unwrap as a workaround - but that feels wrong.. ",
    "mcarlin": "@seanmonstar, I'm looking to start contributing here. Mind if I take a stab at it and convert over those headers you mentioned if you're not already working on it?. ",
    "liamchristopher": "Commit message amended.. @seanmonstar Thanks. For a simple function that was somehow too complicated. I'm still getting used to rust's syntax and seeing that I can return an alternate value in constructing a success response really cleared things up.\nI added a few tests, too. Checks the default, from_str and error on from_str.. @seanmonstar I think github ate my last comment. I updated the test to do what I think is the right thing. Let me know what you think.. @seanmonstar Actually hold up. That test should be against Error::Version specifically. I have one more change committed.\n. D'oh!. Thanks, I reworked this a few times, but wasn't sure what to return. \nLet me straighten this one out, and I'll update it.\n. @seanmonstar Ok. That took me way too long to figure out the right(?) way to do that. \nThe test now asserts true if an error condition is raised, and fails otherwise.\nlet me know what you think.. ",
    "illegalprime": "@seanmonstar I'm ready to publish the shiny new websockets crate but I can't until this change gets published in a hyper version, I was wondering what the timeline is for that? Thanks!. 1. I wanted to parse some bytes into hyper headers, what would be the best way to do that?\n2. I was talking about HeaderClone and GetType, but I see your example, thanks!. ",
    "almielczarek": "I'm interested in helping with this!\nJust to make sure I am on the right track, I think what I should do is implement the TE struct using the header! macro, passing the QualityItem<Encoding> struct as this also has a notion of quality values, adding the Trailer variant to the Encoding enum and adding it to the related impls, and then writing the documentation based off of RFC7230. Does this make sense or am I missing something?. This is to address issue #1109. I can create a new pull request if you would like that in the commit message.. I need to fix an error. I will also put the issue this PR is referencing in the commit message.. This commit references issue #1109.. I'd like to work on this.. Sorry. I think I merged things into my PR incorrectly.\nIf need be I can close this PR and reopen only with my changes applied to a fresh fork.\nAnyway, your requested changes all make a lot of sense and I have applied them.\nThere's one thing you brought to light that we may need to think a little bit more about. With this set of changes if a user sets both of the options regarding buffer sizes, the max buffer size will override the exact buffer size regardless of the order in which they are set.\nI added notes to the documentation for both options, but we may want to think about making it impossible to set both of these options at the same time by using an enum or an assertion.. Didn't think of that!\nThat seems to be the best option.. ",
    "alsuren": "Oh wait a second: bind() creates the Core itself rather than getting it passed in, so there's no way for the caller to close over it anyway :( .. oh... github actually handles time-travelling really poorly doesn't it? (I have trouble when I re-order my commits when rebasing on other projects, and my test commit (HEAD^ on https://github.com/alsuren/hyper/commits/gh-pages) doesn't render at all).\nI can write a git filter-branch script to rewrite the history if you want, or you can do a single force-push to flatten out all of the history into a single commit with an appropriate timestamp.. ",
    "dobrite": "I was unable to reproduce the second panic. Everything is working great on my end \ud83d\udc4c . I'll re-open if it happens again and will be sure to get those logs too.\nThanks for all the work everyone does! It has been an amazing experience developing in Rust. \ud83c\udf89 . ",
    "hannesg": "@seanmonstar sure! I've updated that.. ",
    "bennofs": "Yeah it would also work if client/server Response and Request types were the same.. How could saving to files be  implemented in another crate? Wouldn't this basically require this other crate to have it's own http parser, to parse the requests and headers out of the stream?. @seanmonstar Yeah connect receives an URI, but the connection may be re-used if you don't disable connection pooling. And I would like it to work with connection pooling, as it would still make the request after logging it.. ",
    "mp4096": "Have you considered using error-chain? TBH I didn't use it before, but it sounds a lot like what you want to do.\nAnyway, maybe @brson himself could say if error-chain might be helpful in your case?. ",
    "dtolnay": "\nThat's interesting, are you able to share a bit about what you do with specific hyper::Error variants?\n\nMaybe translate error messages into another language.. Ah you're months ahead of me in #1028. Sorry!. It is beyond my git knowledge too! A long time ago I found this awesome alias that I stuck in .gitconfig and have been using ever since.\n[alias]\n    lg = log --graph --all --color --pretty=format:\\\"%x1b[31m%h%x1b[32m%d%x1b[0m%x20%s\\\" -16\n\n\nThis may be helpful.. It is doing mdbook build instead of cargo doc but the force push part should work the same.. There are two problems.\n\nDocs for 0.10.10 have not been published to hyper.rs.\nThe html_root_url here should not have the last /hyper on the end.\n\nThese are breaking the documentation of reqwest as well.\nLet's release 0.10.11 with a fixed html_root_url and upload documentation for both 0.10.10 and 0.10.11.. You are right. I misunderstood these traits.\nTo tease this apart:\n\nThere is a trait Header that users are meant to implement. They are also free to call the Header trait methods if they want.\nThere is a trait HeaderClone that users are not meant to implement, nor call its trait methods.\n\nHow would you feel about these changes?\n\nAdd an empty private supertrait Sealed to HeaderClone.\nPut doc(hidden) on the clone_box method.\nPublicly expose HeaderClone.\n\nI like this because now Header has all public supertraits so it is clear that you can implement it. Previously Header had a private supertrait which suggests that you will not be able to implement it.\nAlso now rustdoc can show the HeaderClone for T: Header + Clone impl, so users can tell from rustdoc what types they are allowed to implement Header for. Previously they would have to dive through some hidden types to find this out.. ",
    "nicoburns": "\nIt is a bit of a problem. With exhaustive matching, that means that adding a new error case is a breaking change. For instance, if at some point it was desirable to separate the Error::TooLarge into a UriTooLong and HeaderValueTooLong, that would break other people's code from compiling. If hyper were at 1.0, that would be mean needing to go to 2.0 just because we changed an internal detail of tracking errors.\n\nWouldn't this be a breaking change regardless of whether hyper's error type is an enum or not? If it was a struct that could be inspected somehow, it would still potentially break peoples code, just at runtime rather than at compile time, no?. ",
    "tobz1000": "Has the (unstable) #[non_exhaustive] attribute been considered to address the problem of breaking changes?\nIMO this is a preferable solution, since as a user I would like to be confident that I'm handling every possible error type. This attribute allows for a lint which would let you know when a new error type has been added, and should be handled, without causing a compiler error.\nIt doesn't address the issue of users creating their own errors, but that seems like a lesser concern to me.. I was referring to the possibility of a Clippy lint, or compiler warning in future, which would appear after a minor update in which new variants had been added (see the \"Unresolved questions\" section).. ",
    "rolftimmermans": "I came here via #1652. I think that methods is_* on an Error struct are very unergonomic and a mistake in general.\n\nCode that needs to handle many scenarios will be a long if/else if chain.\nFor contributors, it is very easy to forget to add is_* methods when the internal enum is extended, leading to holes in the API.\nThere is no help for an API user to implement error handling, because the is_* methods convey no information about which classes of errors there are (also see previous point). The is_* methods might be implemented for a small subset, they might overlap, there is no way to know! Contrast this with enums where you know everything is mutually exclusive, and you know (at least for the current version in use) that the set is exhaustive.\nIt is difficult to estimate what level of granularity a user of the library might need to recover from certain errors. The is_* methods might be too granular or not granular enough for their use cases.\n\nIf the number of internal errors is large and there is a concern for frequent breaking changes, I am greatly in favour of a two-stage classification. Use one enum for the general error category, and other enums for more granular, specific errors. At the very least the general category should be made public so an API consumer can match on it.. I also would like this feature. I looked at the code but it seems header encoding for the server is not quite the same as for the client.\nCan someone point me in the right direction of how this could be tackled? Then I can try to submit a PR.. Well TIL that HTTP2 does not use the Host header. It seems instead that curl is lying to me ;-)\n```\ncurl -v --http2-prior-knowledge localhost:3000/foo\n...\nGET /foo HTTP/2\n\nHost: localhost:3000\nUser-Agent: curl/7.54.0\nAccept: /\n```\n\nAnyway, would it then make sense to also include the value of the HTTP1 Host header in req.uri().authority() for consistency? That we it is always possible to get the host via req.uri().. That would be perfect. Any suggestions what the API would be? I wouldn't mind implementing it with a PR.\nTo avoid others falling in the same pitfall that I fell in it would make sense to me to make this API as obvious as possible, potentially as simple as just doing req.uri(). Can we have a req.effective_uri() or something?. Adding onto this, from the description you linked it seems this should ideally also take into account any X-Forwarded-Proto headers, is that right? But trusting X-Forwarded-* headers does require explicit opt-in to avoid security issues.... I imagine something like this: https://github.com/Byron/yup-hyper-mock\nIt's nice that this project exists, but it would be even nicer if it were included with hyper so that there will never be any incompatibilities.. The above is the output as tested with h2 0.1.11:\n[[package]]\nname = \"hyper\"\nversion = \"0.12.7\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\ndependencies = [\n \"bytes 0.4.9 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"futures 0.1.23 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"futures-cpupool 0.1.8 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"h2 0.1.11 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"http 0.1.8 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"httparse 1.3.2 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"iovec 0.1.2 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"itoa 0.4.2 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"log 0.4.3 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"net2 0.2.33 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"time 0.1.40 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"tokio 0.1.7 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"tokio-executor 0.1.2 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"tokio-io 0.1.7 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"tokio-reactor 0.1.2 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"tokio-tcp 0.1.0 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"tokio-timer 0.2.4 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"want 0.0.6 (registry+https://github.com/rust-lang/crates.io-index)\",\n]. Thanks for the clarification. I have added a comment in #1131 with my thoughts on the matter. I would love a reconsideration to add enums back in the Error, it really is so much easier and clearer for API users.\nI will attempt to use cause2() for now to solve my problem, thanks for the suggestion.. OK, this is what I have now in my match arm.\nThe err is a hyper::Error wrapped with tokio::timer::timeout::Timeout.\nrust\nErr(err) => {\n    (|| {\n        if let Some(inner) = err.into_inner() {\n            if let Some(cause) = inner.cause2() {\n                if let Some(io) = cause.downcast_ref::<io::Error>() {\n                    if let Some(inner) = io.get_ref() {\n                        if inner.is::<hyper_tls::Error>() {\n                            return Response::invalid_certificate()\n                        }\n                    }\n                }\n            }\n        }\n        Response::origin_failure()\n    })()\n}\nThere is a lot to improve with Rust error handling. \ud83d\ude1e \nI hope that someday I can match like this:\nrust\nErr(timer::Timeout::Inner(hyper::Error::Connect(_))) => {\n    Response::invalid_certificate()\n},\nErr(_) => {\n    Response::origin_failure()\n},. We are very much looking for this feature and do not mind to bear the performance costs, but I get that this might not be the same for everyone. \nIs it possible to merge this, but put the code behind a feature flag, so that it doesn't influence baseline performance in the default case?\nJust wondering if there is an alternative to get this included without hurting the majority use case.. ",
    "bkchr": "Thx for the fast support :). ",
    "serayuzgur": "Hi, thanks for quick response. wait() blocks the operation for eternity. It can never complete reading req.body. I lived something like that before when I was working with tokio-proto. If a Decoder returns Ok(Some(...)It feels like it never finishes. I passed that with checking Content-length and returning Ok(None) if the size matches. So what I tried is something like that. It again stuck with wait(). What do you think?\nrust\nlet chunks = req.body().fold(Vec::new(), |mut v, chunk| {\n    v.extend(&chunk[..]);\n    futures::future::ok::<_, hyper::Error>(v)\n}).wait().unwrap();\nlet mut payload_mut = deserialize(chunks.as_slice());\nmatch db.insert(table,payload_mut) {\n    Some(record) => {db.flush(); return self.success(response, &record)}\n    None => return self.error(response, StatusCode::Conflict),\n }. Hi @seanmonstar , \nYou closed the issue so I believe, you are sure what you are saying but forgive me I have to ask.\nCollecting all chunks may block the current thread. I am sure it is not about db because I commented it out and tried. When I take a look at tokio's samples I realized threat_pool usage and implemented it (self.thread_pool.spawn_fn). This resolved all my problems. Can you please take a look at  this code. Is this could be the solution? It seems waiting for the stream blocks the polling (or reading?) and system never executes one more line. . Thank for the detailed explanation. Since I promised a documentation about it, I will fix my usage and create an example about it. Thanks.. ",
    "shesek": "\nDocumentation is almost ready to publish that includes examples on how to read the body.\n\nDid that happen?. ",
    "lf94": "I second this. Hyper has actually been really nice to use on its own. I'm currently stuck with this error:\ncannot move out of data in a '&' reference: cannot move\n...with nearly anything, such as request.body().collect(), request.body().concat2() and so on.\nI know why but I'm not sure how to fix it.\n\nFor anyone reaching here by Google:\nrequest.into_body().collect().and_then(|chunks| {\n        let file_name = Path::new(original_path).file_name().unwrap();\n        let mut file_handle = File::create(file_name).unwrap();\n        let bytes: Vec<u8> = chunks.into_iter().flat_map(|chunk| chunk.into_bytes()).collect();\n        file_handle.write_all(&bytes).unwrap();\n        Ok::<_, _>(())\n      });\ninto_body() is the key here. It consumes the body, returning Body. body() returns just a reference, &Body, which causes all sorts of problems.. ",
    "david415": "What's the conclusion of this github issue? Where can I find the code solution to \"i want my http server to read the entire request body\" ?. ",
    "dorfsmay": "Cookies are key to web server/client communication.\nI agree that session management, keeping track of cookies etc... is out of scope for hyper, and as noted the cookie crate does a great job for this. But I think that any apps running on top of a web server will eventually need to look at cookies from requests, for all kind of reasons, and  for things simpler than session management. If splitting on the equal sign and provide a map to the cookies is out of scope, why wasn't splitting on the semi-colon and provide individual cookie \"strings\" not out of scope.\nThe effort to add this seems minimal, it's basically one struct and a couple of methods,. I'm happy to add a PR for this. Let me know your thoughts.. This is being revisted in #1145.. I understand your concern about long term support, it totally makes sense... I started writing a quick answer, but turned into a novel - sorry about that. I don't want to be argumentative, I am not trying to push for this PR just for its own sake, but hope the need for a better parsing of the Cookie header isn't missed.\nThis PR is not trying to deal with cookie life cycle, it is very specific to the http \"Cookie\" header. Parsing cookies from the \"Cookie\" header will never need to be more complicated, as it is exactly this, a succession of keys and values (separated by ; and =) - not to be confused with the Set-Cookie header and the issues of storing cookies, determining their scope, etc... In my view, the current implementation is not a good representation of the \"Cookie\" header, and this PR is basically trying to bring it at par with what has been done for hyper::header::SetCookie.\nAs you mentioned in #1139, dealing with cookie life cycle is a much bigger job and the cookie crate can be used for this. But in my experience, the need to be bale to just check specific cookies on incoming requests (so pure k/v) arise quite often.\nIs there any way to get feedback form people using hyper? I wonder how many make use of the \"Cookie\" header without wanting to use a heavy gun such as cookie-rs, and end up having to write their own version of this.... 1. We need to drop duplicate cookies, but in a very specific order. I believe the RFC does not specify the order, but most servers (all?) accept the first instance of each key only due to the way clients send them (higher scope first).\n\nI was originally going to replace the vec of string by a HashMaps, but decided against it as this would break backwards compatibility, but totally agree that this is the way to go. As explained in #1142, I feel that the current implementation of the Cookie header is not a good implementation of what a Cookie header is.\n\nWhat is the process to inject a breaking change?. My understanding is that servers should not rely on it, but because all clients send cookies the same way (narrower, more pertinent scope first), accepting the first key of a series of duplicate is what all servers do, and not doing so could create security issues.\nShould I take a first stab at implement a new struct for the \"Cookie\" header, something along the method in #1142, but as the struct instead?. Ah. That's unfortunate. I'm working on a different implementation, but had problems fighting the borrow checker...\nNow I actually believe a map is not the right structure for the cookie header.\nThe data should be a Vec of tuples, because that really what it is, but it should have a push method to add more cookies to it, including duplicate keys, because that is legal from a client perspective, and a get method that will only show the first key when duplicate exists.\nThis is what I was working on... Take a look, maybe what I am saying here will make more sense. Keep in mind that some of the complication in there is due to trying to work around the borrow checker: https://is.gd/MxBTqt. When do you plan to release 0.11?\nAre you going to implement something, or should I push harder on this one?\nMaybe I can just use memory for now to get it in, and work on making reference from the Hash (VecMap) to the Vec later as an improvement.... I'm happy with happy append (or push in my solution above) vs set, but get has to return the first value, that was set/appended for that key, because that is the way everybody expect servers to work.\nClient are supposed to be appending in order, even duplicate keys.\nSever should only care about the first key when there are duplicates.\nThe raw value, or an iterator for that matter, should make everything available in the order it was set.. @seanmonstar @LegNeato\nAs part of the larger discussion in #1145\nThis is a first stab to make sure that's going in the right direction.\n\nIt doesn't matter how you dice it, at the end of the day, a \"Cookie header\" is really a string representation of a Vec<(String, String)>, so let's use that, and use methods and/or additional elements in the structure to provide the functionalities we need, such as a get() returning the first value for a given key.\n~I know HashMap, I'll re-submit a different PR with VecMap, right now, this compiles and demonstrates the concepts.~\nI use a Vec<(String, String)> + a HashMap (VecMap later), in order to be able to both not lose duplicate keys, and only give the value for the first key on a et\nAnother way to do the above would be to just use a Vec<(String, String)>, and make the get() method walk it. It would be cheaper in memory, but more expensive if an implementer looks up more than one key.\nUsing owned value in the HasMap is a waste of memory, but I am very green to Rust (weeks), I wasted hours trying to make it use reference to the owned values inside the Vec and make it work in hyper... Again this is more to show what I think would be the right implementation for the Cookie header. Also, we could roll with this as it gets the signatures right, and implement internal references later if it is worth it (and maybe somebody more experience add that!).\nI added a set, diff from a push (append) as per @LegNeato sugestion\nStill missing: a proper iterator. I wasted another few hours on this, will work more on that later.\n. Thanks for taking the time to go through my code and the comments, this is really helpful.. Three different results out of three direfferent libraries so far!\n\nhttps://github.com/dorfsmay/Invalid_cookies_in_Cookie_header\nThinking more about this, if ignoring bad cookies while accepting good ones from a given header is not acceptable by virtue of being rigorous with our inputs, shouldn't we return an http 400 or 422 then? If we're being rigorous to the extreme, isn't discarding the entire header as bad as just ignore what we assume are bad cookies?\nAgain, genuinely interested, not trying to push my opinions/PR here.. Yes, very interesting how different libraries behaves fundamentally differently. Sadly, RFC6265, leaves a lot of space for interpretation...\nOne thing I found out since I have started this document is that it seems that in the early days of the web sites used singular cookie without name, so a simple string without equal sign was interpreted as a value, which Django still supports. I'm surprised by golang behaviour given Google inc involvement in that language and their prominent presence on the web, they use strings with missing equal sign as a name. I'm wondering if this is due to a naive parsing with no consideration for this case, or the result of a conscious choice.\nAs far as current support for hyper, my thoughts are:\n I agree with being lenient with the trailing semi-colon. I am yet to see a server which does not.\n discarding all cookies because some of them are invalid seems like an optimization gone bad, especially given how cookies can be injected by third parties. Let say your session starts failing, silently, because of this, how do you debug this\u203d\n I understand how discarding bad cookies only and keeping the good ones could be considered an optimization, or an interpretation, which, although I think is the right thing to do, could lead to unforeseen  consequences, but, should I system rely on invalid cookies (or anything) to start with? Again considering how cookies are regularly inject by third parties, which can sometime be difficult, or even impossible to fix, I think this not doing this would be unfair to  a client and a server with are using the right format. This is how \"express\" and \"ring\", two widely used libraries are doing it.\n Please note how \"hapi\" (a javascript framework used by some large companies) behaves: It has a very strict interpretation of the RFC, and returns http 400 on anything not following the RFC, including a space between the value and the semi-colon! Although I think this is too strict, I think if good cookies are going to be discarded because of bad ones present, this is how it should be done, a clear failure that forces the issue to be dealt with.\nA compromise?\nWhat about having one behaviour by default and an option for the other one. For example, discard bad cookies and keep the good one by default, but have a \"strict_rfc_6265 option returning http 400 on malformed Cookie header. If anything, having that option in the docs will highlight the fact that this can be an issue.. I don't understand the concern about being able to parse a Set-Cookie header when receiving a Cookie header... Regardless, this would be a much better option than the current behaviour (accepting the request but discard the entire Cookie header).. Do you consider the behaviour from this PR, discarding all the invalid invalid cookies and keep all the valid cookies, wrong?\nIs it worth that I add/change the documentation to reflect this behaviour?\n. Agreed, but with my implementation, I would have had to add a Debug trait to VecMap. I wanted to get the code out fast for sake of discussion, rather than spend too many hours on an implementation that wasn't going to be used.. I understood the suggestion as push()/append() to add an extra cookie name/value to the header, and set() to for the entire header to this one value.. Great point. Thanks.. ",
    "Twey": "I'm using it to, amongst other things, write a function on Request that computes and injects a Content-Length header if one doesn't already exist.  I anticipate it being useful for other such code that wants to derive some information from the body.. Essentially, I have some code where I transform the response body but want to leave the rest of the response info intact for upstream consumption.  Specifically, I'm a) asserting that a particular API call always returns a body, and don't want my callers to always have to unwrap(); b) deserializing the body of the API response from JSON.  So combined I have a transformation from Request<Option<Body>> into Request<DeserializedType>.  I had, essentially, my own local copy of Response, to which I transformed Response as soon as possible, but this seemed a bit silly, and I noticed that Response had been generalized over the body type: it just lacked tools to actually work with the generalized type (e.g. with_body requiring that the new body be of the same type as the old body) that I needed.  Since that seemed to be the direction the codebase was going anyway, I thought I'd contribute them.  Separating sums and products is good API hygiene anyway, and happens to help solve my problem; I'm not sure this is precisely the right API to do that (I modified the existing API as little as possible, but it might be nice to avoid propagating Options everywhere), but seems like a reasonable step.. Yes, this is similar to the method I've called take_body, but with less type information.  That method could be renamed split.\nHowever, that approach alone, keeping the Option internal to the Response, has two issues: 1) it's now impossible to know whether the response had no body or whether it had a body that was equal to B::Default (and generating B::Default and comparing the body to it may not be cheap [or ergonomic \u2014 e.g. deciding whether a Body is Body::default() requires creating another Future layer and then flattening it out]), and 2) it's impossible to talk in the type system about responses that definitely have (or do not have \u2014 although this can be written Response<!> in new Rust) a body.  1) is an instance of the general principle that results in Rust functions returning Result or Option a lot: the idea is that the user should be able to decide what to do with the information, rather than the library making a guess at how they want to handle the special case.  2) is directly part of my use case.\nIt's a simple translation from .body() to .into_body().unwrap_or_default() (the name body() in the current codebase seems to be inconsistent: similarly-named functions, like headers() or version(), do not consume the Response) to get the same effect for the runtime API, but gives the user much more control.  The part I mostly dislike about this patch is that there are a lot of instances of <B: Stream> Response<B> in the codebase, which become <B: Stream> Response<Option<B>>.  It seems like instead we should push the type information further down into the code, so the Option becomes less necessary (obviously we have it when the Response has just come off the wire, but we can quickly project out of it, e.g. fn check_body<B>(Response<Option<B>>) -> Either<Response<B>, Response<()>>, and then track the presence or absence of the body through the codebase).  But that's a slightly larger project that I don't have time for right now \u2014 I'm using hyper in anger at work :)  Maybe I'll have some time to play with it on the weekend.. Yes, absolutely! That sounds great. In fact we already have the notion of an \u2018empty\u2019 body.\nThere's a similar argument to be made for Request, of course!. Is Into<Option<\u2026>> worth it?  Perhaps we just want to expose an alias pub type Body = Option<TokioBody>;?\nEDIT: Scratch that \u2014 I guess you explicitly want to be able to say things like Body::empty() instead of None, right?. What's wrong with the impls?\nUnfortunately, that approach doesn't fix the primary issue, which is that there's no information in the type system about whether or not the response has a body, so the user has to check or unwrap() every time they want to use it.\nRe split(): the proper return type here is (Response<!>, B) (or (Response<!>, Option<B>) without the Default constraint that throws away information).  Since ! has no values, the only value the body could have is None, which is accurately reflected in the type system.  But there's still no way to say that the body definitely has a body so long as the optionality of the body is hidden inside the implementation.. Would we want custom ones?\nAs for ! \u2014 there is the void crate for just such a case.\nIf Body already has the possibility of being empty, surely it should have an impl for Into<Option<T>> where T is some kind of non-empty type. But this should be largely immaterial \u2014 the only case where it matters whether the body could be empty or not (because we need to be able to wrap up non-body responses) is when it comes off the wire, in which case we already fix the body type.. I'm still thinking about this!  I've actually put it on my work schedule for this/next week, since we currently have an internal hyper fork with this feature and we'd like to get rid of it.\nFeel free to close, but would you be happy with a similar PR with alternative API suggestions?. ",
    "MagnificentPako": "I'm still confused why this only happens when doing local tests. It doesn't happen when the server is running on a separate machine.. ",
    "tinco": "Hi @seanmonstar :) Yes looks like #1075 is the sort of thing I'm trying to address. I'm trying to avoid any form of multithreading in my application, so would much prefer to have only a single Tokio core running. The idea of the Rc is that different pieces of code (with their own responsibilities) hold a reference to the core, and then the RefCell enables them to at any point borrow the core, get a handle and spawn some future on it.\nI'm very much bending this API to my own selfish goal though, so I totally understand if this is not the right way for the project. Also, maybe some re-architecting could yield a more elegant solution. If there were some copyable interface to the event loop I could pass around that would be much better, but I don't know how that would work, maybe that's even something Tokio itself should think about?. ",
    "LegNeato": "I actually like the solution form-data in npm uses, as they have the same problem. They have set that replaces all values with the key and append which tacks it on (possibly duplicating the key).\nrust\nlet mut cookie = Cookie::new();\ncookie.append(\"foo\", \"bar\");\ncookie.append(\"foo\", \"otherbar\");\nassert_eq!(cookie.to_string(), \"foo=bar; foo=otherbar\");\ncookie.set(\"foo\", \"baz\");\nassert_eq!(cookie.to_string(), \"foo=baz\");. Sounds good, no rush...I basically just did this to play around with Rust a little more and get familiar with the codebase.. This would be a breaking change, right? If so can you add BREAKING_CHANGE: <description> to the commit message?. ",
    "tynor": "Oh, awesome, I didn't see #1155 when I was looking through the issue queue. Thank you (both for the answer and your work on Hyper in general.). (And I actually just realized it was made after this one, no wonder. :P). ",
    "marti1125": "@seanmonstar thanks! I fixed it =D. ",
    "suyanlong": "i want know ,how send  result to the event loop thread???. Hi ,I want to know with theadpool\uff0chow do work for  making multiple requests ? @seanmonstar . ",
    "golem131": "@seanmonstar - updated. ",
    "berkus": "Confusion still happens with hyper 0.11.25:\nerror[E0599]: no method named `and_then` found for type `hyper::client::FutureResponse` in the current scope\n  --> src/service_client.rs:69:14\n   |\n69 |             .and_then(|res| {\n   |              ^^^^^^^^\n   |\n   = help: items from traits can only be used if the trait is in scope\n   = note: the following trait is implemented but not in scope, perhaps add a `use` for it:\n           candidate #1: `use futures::future::Future;`\nEven though I have use futures::future::Future; in the file, this happens with futures 0.2.0.\nWith futures 0.1.21 it does similarly bad things:\nerror[E0277]: the trait bound `(): futures::Future` is not satisfied\n  --> src/service_client.rs:69:14\n   |\n69 |             .and_then(|res| {\n   |              ^^^^^^^^ the trait `futures::Future` is not implemented for `()`\n   |\n   = note: required because of the requirements on the impl of `futures::IntoFuture` for `()`\n. @seanmonstar yeah, i've been trying to live on the crying edge today, and it seems painful. Thanks for the update. I learned many new things today.. ",
    "alex": "Right, so the way to implement this would be to create the socket, set it non-blocking, initiate the connect, and the select on it with the timeout value. That should be implementable without changing the blocking API.\nFor my particular case, I'm not particularly worried about the blocking DNS lookup, so just doing the fcntl(fd, F_SETFL, O_NONBLOCK) + connect() + select() dance would be a huge win.\nEdit: And then after the connect you can just stick it back in ~O_NONBLOCK and pretend like nothing ever happened :-). @seanmonstar \ud83d\udc4d  tokio made this way easier in that I can just do a client.get(...).select(timeout) and it covers everything.. That snippet is basically what I landed on, but it definitely took a lot of docs reading to get there! Just having that exact snippet in the guides would have been a huge help, so \ud83d\udc4d  from me.. I'm still learning my way around the tokio ecosystem, but for my application just being able to filter before my application isn't enough, I need the actual contents of the client certificates in the app itself.. Yup. (https://github.com/alex/ct-tools is the application, it's an app specifically geared to help people interact with their client certs + certificate transparency). I'm not very familiar with the internals of hyper -- is the hyper 0.10 approach of exposing the ssl<T>() method no longer technically possible, or just not consistent with the API you're trying to offer?. I suppose the extensions dealio makes as much sense as anything, given that constraint.. Hmmm, that makes a fair bit of sense to me.. Thanks for the quick fix @seanmonstar !. Thanks!. ",
    "srijs": "Fixed up the line length in the commit message.. Thanks for the swift response!\nPersonally I think there is value in having a robust and reusable piece of code that handles connecting to a tcp server, and the fact that hyper-tls reuses HttpConnector seems like an affirmation of this.\nAn alternative I could think of is to split the concerns and handle dns lookup outside of the Connect trait, but that would be a breaking API change, something that I've been trying to avoid when making these changes.\nFundamentally what I would like to achieve is to be able to customize the way that hostnames are resolved when using hyper, without having to write and maintain my own connector.\nI'm happy to explore/implement another solution if you can give me a hint towards how you would like this feature to be implemented.. @seanmonstar Have you had time to give this some thought? Would love to get your guidance as to where this PR should go. Apologies for bothering you if you are busy.. Just a quick note here: I've stumbled upon the abstract-ns crate by @tailhook, which already provides the trait we need here (link to doco).\nOn top of that, there are two crates ns-std-threaded and ns-dns-tokio that provide a futures-cpupool and a truly async (via the domain crate) implementation of this trait, respectively.\nUnfortunately all three crates are labelled as \"Proof of Concept\" at this point, so there would probably need to be some effort to stabilise them in order to introduce a dependency.. Thanks for taking the time to pitch in, @tailhook!\nWhat you describe sounds like an awesome idea, and from experience I can confirm that a connection pool which is able to react to changes in dns records (or subscribe to other discovery feeds, such as Kubernetes endpoints) is an extremely valuable thing to have in a production environment.\nWe might want to pull on a slightly different thread here, which is: Is there a way we can integrate some of this into hyper, so that it would become easy to hook up an implementation of abstract_ns::Resolver to the hyper thread pool?\nI mentioned in an earlier comment that we could also decouple the dns resolving mechanism from the Connect trait, which starts to make sense if service discovery needs to interact directly with the pooling mechanism in order to invalidate \"stale\" connections.\nOf course this would be a bigger change than what I originally proposed, which is why we should consider it carefully, and I'm especially interested in your opinion, @seanmonstar, whether you see this as an option or feel it would complicate hyper too much.\nPersonally, there's a few changes I would suggest to the current Resolver trait, but I think if we managed to agree on a trait that could be shared between hyper and abstract_ns that would be a great thing.\nLooking forward to hearing from the both of you!. @seanmonstar penny for your thoughts?. You might want to consider wrapping the return type of iter in a tuple struct to prevent implementation details from leaking, like so:\n```rust\nstruct CookieIter(::std::slice::Iter<(Cow<'static, str>, Cow<'static, str>)>);\nimpl Iterator for CookieIter {\n    type Item = (&str, &str);\n    fn next(&mut self) -> Self::Item {\n        self.0.next().map(|kv| (AsRef::as_ref(kv.0), AsRef::as_ref(kv.1))\n    }\n}\n```\nand then...\nrust\n    /// Iterate cookies.\n    pub fn iter(&self) -> CookieIter {\n        CookieIter(self.0.iter())\n    }. I think one question might be if there is a way to introduce parts of the http crate w/o breaking the API just yet? Two possible approaches I could think of:\n\n\nIntroduce conversion/compatibility methods, e.g. to be able to pass a Service using http types to Http::bind (or an equivalent compat. method).\n\n\nReplace some of the internal logic with pieces from http (url parsing comes to mind as an example), making existing hyper types a lightweight facade on top of http types so that the next step of replacing them for the 0.12 release would be easier (all the while reaping the benefits of less code in hyper, and getting validation on the http logic).. I think we both are in agreement that that's what should happen for 0.12. (Assuming @seanmonstar making that call of course).\n\n\nDepending on what the time table around this is though, I think it might be beneficial to offer some level of compatibility before introducing 0.12.. @seanmonstar Thanks for your input! If you don't mind I'd like your feedback on the following:\nSo far I can see two different approaches, each with their pros and cons on how we can achieve this. It might also make sense to mix the two approaches, depending on how well they work for the different types.\nEDIT: Although I initially favoured Option 2, after playing around with the code base it seems to be a lot harder to implement than I originally thought due to various reasons (the biggest one being a feature mismatch between the types in hyper and http). So my suggestion would be to go with Option 1 in the beginning, and then optionally work on porting the missing features over to http.\nOption 1: Conversion functions\nWhere it makes sense, provide from and into_* methods on hyper types (such as Url, Headers, Request, etc. These methods convert between hyper and http types.\nPros\n\nLeast intrusive set of changes\nCan be hidden behind feature flag if out-of-the-box dependency on http is not desired\n\nCons\n\nPerformance overhead when converting, which might be a deterrent for downstream users to adopt the new feature\n\nOption 2: http types at the center, hyper types as the facade\nInstead of providing conversion functions, change the hyper types to wrap the http version of the type, and change the method implementations to proxy through and apply the necessary changes for backwards compatibility.\nProvide wrap/unwrap methods to change between the types.\nPros\n\nVirtually no performance overhead\nStart using the implementations from http (parsers, etc), so they can be hardened before hyper 0.12.\nPossibly a reduction in code size for hyper (since parsing/validation logic etc can be removed in quite a few places)\n\nCons\n\nPossibly difficult to establish backwards compatibility in some cases (the test failures in #1318 seem to indicate this)\nCan't be feature-flagged. @seanmonstar okay, so after an evening of experimentation, this is where I'm at:\n\nI've explored the \"http types at the core, hyper types as facade\" approach. However, there is a major issue: The http crate as it stands uses associated constants, a feature that Rust 1.15 (which is configured as a test in travis) does not yet support.\nSo we have either the choice of raising the minimum supported version of Rust to something higher that supports associated constants (would this be considered a breaking change?), or we accept that this approach is not feasible. The conversion-methods only approach on the other hand is feasible in any case since we can hide the methods behind a feature flag, therefore making depending on http opt-in.\nI have a working implementation of hyper::Uri wrapping http::Uri in my PR (#1319) in case you want to have a look, and I was able to delete a good portion of the URI parsing and extracting logic by doing that (~350 lines, see commit 9d44b6294f9b2827056f43b8904cf031afe7c704).\nPlease let me know how you'd like to proceed.. Closing this since #1319 got merged.. @seanmonstar I've pushed a couple of commits that should address your feedback so far. Would appreciate a second review, to identify further gaps that you'd like to see addressed.. Hi @cetra3! When building a response, you are not forced to use hyper::Body. In fact, you can use any other type that implements futures::Stream.\nTo get from a std::io::File to a Stream you can use the futures-fs crate, for instance.\nAs an example:\n```rust\n// initialise fs pool somewhere in your server\nlet pool = futures_fs::FsPool::default();\n// later, in a request handler\nlet file_read_stream = pool.read(\"example.txt\");\nlet response = hyper::Response::new().with_body(file_read_stream);\n``. @seanmonstar should we add this to the guide?. @xinghun92 Try explicitly creating aRequest`:\nrust\nlet mut request: ::hyper::Request<FsReadStream> = ::hyper::Request::new(::hyper::Method::Post, ::hyper::Uri::from_str(\"http://www.google.com\").unwrap());\nlet pool = FsPool::default();\nlet file_read_stream = pool.read(\"test.txt\");\nrequest.set_body(file_read_stream);. Hmm, seems like this is starting to become more tricky. Your current problem would be solved by using Client::configure().body::<FsReadStream>().build(), but then the next problem will be that FsReadStream has error type std::io::Error, where Config::build() expects the body to have error type hyper::Error\n@seanmonstar Can you think of anything that might make this easier? For instance, could we change Config::build and Client::request so that they can automatically cast errors?\nI'm thinking something like\n```rust\nimpl Config\nwhere B: Stream,\n      B::Item: AsRef<[u8]>,\n      B::Error: Into,\n{\n    ...\n}\nimpl Client \nwhere\n    C: Connect,\n    B: Stream + 'static,\n    B::Item: AsRef<[u8]>,\n    B::Error: Into,\n{\n    ...\n}\n```. FYI current tip of master (1a9f26482680968c78ef64913e7eedeb51660777) fails CI for me, so I re-based this off of a slightly stale version of master.\nEDIT: Hmm, CI fails for me regardless, but with the same errors. Could it be a pipeline/test problem?\n\nEDIT 2: Ah, looks like Travis is testing the result of merging by branch into current master (+refs/pull/1333/merge), which is why it keeps failing. TIL. Yeah, I'm open for suggestions how to simplify it!\nIt's just that every attempt to slim it down on my part has resulted in exposing implementation details on the public API, which I was assuming is not what you want.\nI feel like part of the reason for that is the Executor trait having the type of the future to be executed as a type parameter, which means requiring a type to impl Executor means exposing the type of future that will be executed on it.\nI can see reasons for designing it that way (presumably the executor containing a channel of futures of this type or some such) but it just means consumers of the trait needs to do a bit more ceremony.\nAssociated type constructors could potentially fix it, but then we're not there yet :). @seanmonstar resolved conflicts.\nI'd like to try and resolve the last outstanding issue, whether to export HttpConnectorBlockingTask or not.\nCould you help me out by detailing what your concerns are with exporting it? Is it about the size of the API surface? Or something different?\nAt the moment, I feel rather strongly against not exporting it. In my opinion, this will complicate the situation for frameworks being built on top of hyper.\n\nFor instance, assume for a moment that we are building a framework based on hyper, and there is some cpu-intensive task that we'd like to offload to a thread pool, and this thread-pool needs to be customisable, similar to what we want for the DNS pool here.\nSo now there are two types of tasks that we'd like to schedule on the executor: Hyper's http connector task, and our custom framework task. However, since HttpConnectorBlockingTask has not been exported from hyper, it's impossible to express an enum of these two tasks which could be used in the trait constraint for the Executor.\n\nAs an alternative, I would suggest that we require an Executor<Box<Future>> instead of an Executor<HttpConnectorBlockingTask>. This does not constrain consumers of hyper in the way that I've described above, and has the additional upside of not expanding the API surface. The downside is the future will be moved to the heap, which might result in slightly worse performance.\nIn summary, the three options we have:\n\nDon't export any new symbols, require Executor<Box<Future>>\nMore flexibility for consumers \ud83d\udc4d \nNo increase in API surface \ud83d\udc4d \nSlightly worse performance \ud83d\udc4e \n\n\nDon't export any new symbols, require Executor<HttpConnectorBlockingTask>\nLess flexibility for consumers \ud83d\udc4e \nNo increase in API surface \ud83d\udc4d \nNo performance impact \ud83d\udc4d \n\n\nExport HttpConnectorBlockingTask, require Executor<HttpConnectorBlockingTask>\nMore flexibility for consumers \ud83d\udc4d \nSlight increase in API surface \ud83d\udc4e \nNo performance impact \ud83d\udc4d \n\n\n\n\nWould be great to get your thoughts on this and work towards getting this merged!. @seanmonstar Thanks for taking the time and explaining it in the way you did! You managed to convince me that not exporting the symbol is an acceptable solution in this case, so I made the necessary changes.\nLet me know if you'd like to see any other changes before merging this!. Hi @softprops!\nUnfortunately I don't think there is a straight-forward way to achieve this :( But that doesn't mean it's not possible!\nYou are right that the chunks very likely don't contain a parseable json object, so the challenge would be to change this so that each item coming down the stream is a \\n separated line of text from the body.\nI've written a bit of code here, to illustrate what that could look like.\nAfter you've obtained such a stream, you can then use Stream::map_err and Stream::and_then to parse it using serde_json:\n```rust\nenum Error {\n    Hyper(hyper::Error),\n    FromUtf8(FromUtf8Error),\n    Serde(serde_json::Error)\n}\nimpl From for Error {\n    fn from(err: FromUtf8Error) -> Error {\n        Error::FromUtf8(err)\n    }\n}\n// somewhere down the line...\nlet stream = Lines::new(response.body().map_err(Error::Hyper))\n    .and_then(|line| serde_json::from_str(&line).map_err(Error::Serde))\n```\nHope that helps! Feel free to ask if this is unclear or you have any further questions :). No worries, go for it!\nOdds are there's a couple of edge-casey bugs in there though, so you\nmight want to write a couple of tests around it just to make sure ;)\nOn Sun, Sep 24, 2017, at 01:20 PM, doug tangren wrote:\n\n@srijs I just tried this and actually this works amazingly as-\nis for my> usecase. Would it be okay with you if I I wrapped this up in a\ncrate? I> can't be the first person to hit this problem and am sure this\nwould be> useful to others?\n--\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub:\nhttps://github.com/hyperium/hyper/issues/1335#issuecomment-331684152\n\n. If this is nothing that should live in hyper then I agree that a separate crate would be appropriate. I feel it's probably not generic enough to live in futures itself...\nIt seems you feel rather strongly about not including it in hyper, @seanmonstar? If so, I'm happy to close this.. I'm keen to understand why we need a shutdown signal in the first place, thus requiring the Server to hold on to the signal future. Could this not just be method like Server::shutdown(&mut self) instead? This seems like it would be more generally useful.\nFor convenience, you could always construct some sort of Shutdown future around Server which when polled polls the shutdown signal first, and if successful calls Server::shutdown.\nWhat am I missing?. FYI nightly seems to fail for reasons apparently not linked to this change set. Thanks for merging!\nYeah, so the problem it's solving is given the full length of the requested representation of a resource, just return the inclusive range that should be used to slice the data internally before returning.\nSo for instance, you implement an endpoint serving a file from disk, and you want to support range requests. It's a lot easier to just get a (start, end) offset that you can use to seek and read than having to deal with all the different ways a client can request a range. So you would stat() the file, plug in the length into this function, and get the relevant offsets.\nAny suggestions for how to improve the docs to make this clearer?. Adding a bit more color here, the second and third panic (failed to retrieve response from reactor: Canceled as well as failed to send request to reactor: send failed because receiver is gone) are caused by code in rusoto.\nHowever these panics seem to be caused by hyper itself panicking (due to the assertion failure) and taking down a thread (which holds the channels that the two other panics refer to).\nThe panic in hyper seems to be due to some issue with the connection pooling, but I'll let @seanmonstar sort that one out :crossed_fingers: . I'm keen to attempt doing this! @seanmonstar, would you be open to accepting a PR against the 0.12.x branch?. FYI, I started spiking this out of curiosity, and opened https://github.com/tokio-rs/tokio/issues/217  to follow up on a few unclarities.. Okay, so far I have:\n\nreplaced use of tokio-core by tokio (this will use the sub-crates as soon as https://github.com/tokio-rs/tokio/pull/224 lands)\nintroduced Http::serve_addr (using Handle::current)\nchanged Server::run and Server::run_until to return a Run future rather than a Result\nuse tokio_executor::spawn in places where Handle::spawn was used (this will move to task::Context::spawn with futures 0.2 as you mentioned)\n\nIf you think that's enough, I can open a PR against 0.12.x and we can hash out the details there, or otherwise I'm happy to make more changes.. Looking through my changes again, I'm wondering if we should change the API for Server to work better with tokio::run.\nCurrently w/o any major changes to the API, integrating hyper::Server with tokio::run looks something like this:\n```rust\nlet http = Http::new();\ntokio::run(lazy(move || {\n    let mut server = http.bind(addr, || { ... }).unwrap();\n    server.shutdown_timeout(Duration::from_secs(60));\n    server.run().map_err(|err| println!(\"error: {}\", err)\n}))\n```\nI think it'd be neat if it looked something like this instead:\n```rust\nlet http = Http::new();\nlet server = http.server()\n    .with_shutdown_timeout(Duration::from_secs(60))\n    .with_error_handler(|err| println!(\"error {}\", err))\n    .build(addr, || { ... });\ntokio::run(server)\n```\nThis would require a bunch of changes, effectively delaying all I/O until the server future gets polled (so that we're accessing the right task-local handle and executor), and invoking an error handler for all errors we encounter (since tokio::run expects the future to be infallible).\nHowever maybe it makes sense to postpone this refactor until we have the basic changes on the 0.12.x branch, and then we can bikeshed on the API.. Understood! Just polishing up a few things, then this should be ready for PR!. Quick update here, I'm stuck on fixing up the integration tests, which has proven more difficult than I thought. Will try to push further tomorrow!. Now that tokio 0.1 has landed in the 0.12.x branch, we should be able to attempt this.\nIs anyone working on this yet? Otherwise I'd have some time tomorrow to take a stab!. Good news: So far I've got everything but the tests to compile. I'm using the unstable-futures feature that recently landed in tokio, together with two PRs I've opened to use futures 0.2.0-alpha in dependency crates:\n\nwant: https://github.com/seanmonstar/want/pull/1\nfutures-timer: https://github.com/alexcrichton/futures-timer/pull/5\n\nI'll try to find some time tonight to fix up the tests, and then this should be ready for review (fingers crossed).. Tests compile now, however running into issues with iovec. Will investigate and (hopefully) fix tomorrow!. Okay, I think I figured out the issue with iovec, and could use some help finding the right way to go.\nPreviously (iirc) WriteBufAuto was used to detect whether the underlying AsyncWrite object supported/used vectored i/o, and was adjusting the buffering strategy accordingly. This worked because the method on AsyncWrite was write_buf, which actually accepted a Buf object. So the detection is more or less straight-forward: If the underlying object calls Buf::bytes, it likely does not use vectored io, but it's likely that it does when it called Buf::bytes_vec instead.\nWith the new interface in futures, the equivalent to write_buf is now poll_vectored_write which accepts a mutable slice of IoVec. The issue with that is that the control is inverted: Instead of the write object making the choice of whether to use vectored i/o, the caller decides whether to use it, with the write object using the default impl of poll_vectored_write instead if it doesn't support vectored io (the default impl will fallback to using poll_write on the first iovec that was passed to it). This makes detection a lot harder in my understanding.\nFrom what I can see, we have multiple options now:\n\nDrop the detection logic, always attempt to use vectored I/O (the AsyncWrite impl will fall back if not supported)\nDrop the detection logic, never use vectored I/O (sounds like a bad idea?)\nPetition for the AsyncWrite trait in futures 0.2 to use Buf instead of requiring a slice of IoVec (or possibly add a second method poll_write_buf?)\nAnother magic way how we could detect this?\n\nConceivably we could  also combine the approaches, e.g. go with Option 1 first and pursue Option 3 longer term.. I've got a sketch for a possible (imo slightly hacky) detection algorithm based on poll_vectored_write.\nFor context, my logic to write a Buf into an underlying AsyncWrite object looks something like this:\nrust\nif !buf.has_remaining() {\n    return Ok(Async::Ready(0));\n}\nlet n = {\n    static PLACEHOLDER: &[u8] = &[0];\n    let mut bufs = [From::from(PLACEHOLDER); 64];\n    let i = Buf::bytes_vec(&buf, &mut bufs[..]);\n    try_ready!(io.poll_vectored_write(cx, &bufs[..i]))\n};\nbuf.advance(n);\nreturn Ok(Async::Ready(n));\nWe could exploit our knowledge of what the default impl for poll_vectored_write does in the following way:\nIf i > 1 (more than one io vec available) and n == bufs[0].len(), then we know with some certainty that the default impl was used, since only the first of many buffers was written. Switch our strategy to Strategy::Flatten. A false positive could be produced in a situation where the number of bytes that the underlying I/O can accept coincides with the length of the first buffer.\nIf i > 1 (more than one io vec available) and n > bufs[0].len(), then we know that a non-default impl was used, since more than just the first buffer was written, meaning there is a good chance that vectored I/O is supported. Switch our strategy to Strategy::Queue.\nIf neither of these conditions apply, we can't be certain either way, and should keep using the current strategy (which is Strategy::Auto by default).\nThe big risk here is that we depend on the behaviour of default impl for poll_vectored_write in futures, which I assume might change at any point.. @seanmonstar thanks for the heads-up, I'm rebasing now...\n@aturon thanks, let's make futures 0.2 a success! :). The PR can now be found here: https://github.com/hyperium/hyper/pull/1470. No worries, I was just surprised by how quickly it had moved since I started a couple of days ago :)\nOne thing to note here is that I've tried to keep the API mostly the same (biggest exception being Server::run). It sounded like it would be a good idea to postpone improving the API until later, after the \"raw\" tokio integration landed. Let me know if you feel different!. The hanging test is a weird one, it works on my machine (OS X), so I can't reproduce at the moment. I'll grab an AWS instance later to try and reproduce on Linux.. Thanks, much appreciated!\nIn other news, my PR to split off tokio-tcp (https://github.com/tokio-rs/tokio/pull/224) was merged, so we can hopefully drop the direct dependency on tokio soon-ish. Hmm, so the issue with current_thread is that it's not Send nor Sync, making it unsuitable for a custom executor.\nThe only way I can think of solving that problem is to make it optional for Client to be Send, which would probably require tracking that as type state, e.g. Client<IsSend> vs Client<IsNotSend> or making the executor a type parameter itself, e.g. Client<TaskExecutor>.\nMaybe there is another way to fix the tests so they could run on a multi-threaded executor?. Okay, so I think I fixed the initial problem by using a thread pool of size 1 as an executor. There are some other failures now on Travis that I still can't reproduce locally :/\nAny chance you could have another look?. Thanks for providing more info on that test! I thought I fixed that particular test earlier by introducing exactly the sort of thread::sleep that you suggested.\nThe latest Travis run showed two other tests failing instead: one with a \u201aresource temporarily not available\u2018 error, and the other one (a dispatch test) timing out.\nI\u2018ll try to fix the benches later!. @seanmonstar Nice! I pulled your changes into this branch, just in case you had any other feedback you wanted to see addressed before merging.\nAppVeyor builds seem to be failing both on this as well as your new-tokio branch, could that be related to our changes?. I'll take a look at futures-compat, thanks! One thing is that we'll also need is compat between tokio::io::Async{Read, Write} and futures::io::Async{Read, Write}. Would you consider that in-scope for futures-compat, or would that live somewhere else?\nOn the other hand, I would expect tokio to drop this feature and go all-in on 0.2 when it's released? Or is your worry about breaking hyper master in the meantime?\nI'll look into the build errors tomorrow if you don't beat me to it!. Addressed a bunch of stuff, as well as fixed everything to work with the futures 0.2 beta release!\n@seanmonstar I was fighting the conn_drop_prevents_pool_checkout test this afternoon because it was flakey. The reason (iiuc) was a race condition between the tokio runtime shutting down and the client sending the second request (and by extension the server thread reading from the connection). I've made some changes that I think are okay, to make the test run deterministically, but I'd appreciate you taking a look and telling me if the changes are not okay. . It's not immediately apparent to me why the 2/4 AppVeyor builds failed. Any pointers?. Still seeing issues while using Carl's races branch. Commented on the PR in tokio.. @seanmonstar Nice work finding that use-after-free bug in tokio! \ud83d\udc4f\nI've targeted your branch with the fix, and at least locally the tests are running reliably now. Pushed the changes to also check with Travis and AppVeyor.. @seanmonstar Addressed your feedback so far, I think this should be ready for a second round of review!\nTests run smooth on OS X and Linux, however the AppVeyor builds seem to hang occasionally.\nThe last thread of discussion that's still open was around whether to split the futures and tokio dependencies into dependencies on their subcrates. I'm happy to do it in this PR if you want me to, otherwise I can follow up with another PR once tokio and futures stabilise a bit.. All done! I'm using my branch of futures momentarily until https://github.com/rust-lang-nursery/futures-rs/pull/902 is merged in some form.. @seanmonstar Good stuff! I added 2 PRs that we should get merged, one of them is https://github.com/seanmonstar/want/pull/1.\nAs for other merge blockers, would you consider anything that needs a release (and is sourced from git right now) a blocker, or is that okay to fix up later as the new versions get published?. From the CI errors, it looks like we might need to back-port some of the fixes I included for the new tokio behaviour. I'll see if I can figure out which ones they are!. Yeah, it\u2018s a race condition I fixed as part of the futures 0.2 changes\nthat are being reverted here, should be a matter of backporting it!\nOn Tue, Apr 10, 2018, at 5:43 PM, Kam Y. Tse wrote:\n\nOn my local machine, the test conn_drop_prevents_pool_checkout can\npass some time.\nSeems there is a race somewhere, I am trying locate the problem.\n--\nYou are receiving this because you commented.\nReply to this email directly or view it on GitHub:\nhttps://github.com/hyperium/hyper/pull/1482#issuecomment-380005818\n\n. I'll happily take this one!. I like the idea of making the timer optional, that seems like it would work well with keeping the current calls to wait() as they are, and just not use a timer in those cases (unless the test explicitly tests timeouts/intervals).\nHowever I'm not sure if it's worth abstracting away tokio-timer? The Timer logic in tokio-timer can be used independently of the tokio runtime, so it should be flexible enough for most use-cases.\nSo what about a slightly simpler solution?\nrust\nenum Timer {\n    Empty,\n    Default,\n    Custom(tokio_timer::Handle)\n}\nThat avoids having to box futures to abstract across Timer impls, and still allows for some degree of flexibility.. If I were to take an educated guess, I would say the lint didn't trigger because CookieIter is not exported all the way to the crate API.\n@mayah, you might want to add a pub use self::cookie::CookieIter to src/header/common/mod.rs to make sure CookieIter is exported from the crate.. I'm happy todo that as a smaller PR before continuing here, if you don't mind! Having to alias the crate has been cramping my style a little bit :). I'll see if I can come up with something. Maybe there's a feature we can land in http to enable a more performant conversion here?. The problem is that hyper has made H2 and H2c two distinct values of HttpVersion, rather than conveying non-cleartext/cleartext via some other channel. http on the other hand does not make the distinction, which is why this match is not exhaustive and the function therefore partial.. Done in a9a56626d1c822e61d3bdd60030c79627c5d94a6. I've explored this a bit:\n\n\nConverting from hyper::Uri to http::Uri can be done without copying the underlying data. In fact, I've included this in my changes to the branch.\n\n\nConverting  from http::Uri to hyper::Uri is not easily possible, however, since http \"chops\" the Bytes into different parts. If allocations here really become a problem, I guess we could consider changing http::Uri to keep a reference to the \"top-level\" Bytes so that we could implement http::Uri::as_bytes or something similar.. I like that idea a lot! One concern I'd have is the impact on type inference. I'll go and explore it for a bit and get back to you. . - [x] Implement compatibility for Client Service API.. Unfortunately not, since the only reason Rust lets me impl this is due to the fact that part of the impl receiver type (Body) is from this crate (since both the trait as well as the receiver of the impl are from other crates).\n\n\nEDIT:\nSo one idea I had that would solve this at least temporarily (which should be enough given that the mid-term goal is to get rid of the old types in a breaking release), is to go down a similar path as http and introduce a custom TryFrom trait.\nThis would solve two issues that I currently see as drawbacks:\n\n\nSome of the conversion methods are technically fallible, but the From trait does not allow to express fallibility, therefore the only choice is to panic. This might not be a great experience for the user, especially if it's about cases that could be influenced by user input (e.g. web server crashes due to being passed a uri or header that hyper accepts, so the request is accepted, but later http doesn't like and we panic).\n\n\nSince the custom trait would live in this crate, we could implement impl<B> HyperTryFrom<Request<B>> for http::Request<B> like you suggested.\n\n\nLet me know what you think!. See explanation for From<Request> below.. I suppose it could, if I used mem::replace on the mutable reference returned here.\nWill give it a shot!\n\n\n[x] Use Headers::from in Request::from. You got it!\n\n\n[x] Use append_raw in Headers::from.\n\n\n[x] Write tests for header conversion covering multiple values for a single header name.. Makes sense.\n\n\n[x] Use header.raw() in Headers::from.. Okay, so I did a brief exploration on this one, and the main challenge that I've encountered is that while I can make request work for both hyper::Request and http::Request, the Item of FutureResponse is still hyper::Response, which IMO is not an optimal user experience. So I'd probably need to make FutureResponse generic over the response type, which would be a breaking API change...\n\n\nLet me know if you have any other ideas on how to solve this! I'll work on the other items in the meantime.. @seanmonstar to get an idea where you stand on this, do you see the panic-ing of the conversion functions as a concern at all, or do you think it's a non-issue?\nIntroducing from methods that panic has been bothering me more and more when thinking about it over the last couple of days, and at least personally I would feel a lot more confident about the quality of my contribution if the conversion methods could safely signal an error w/o resorting to panic!.\nWould be great to know your thoughts on this!. In that case, I'd be fine with leaving it like it is. Or did you want me to add the generic into_compat method before we merge? Anything else you'd like to see changed?. Since HttpConnectExecutor is wrapping E in an Arc in any case, there shouldn't be an issue with hiding the generic in there as a trait object. I'll give that a shot!\n\n\n[x] Hide Executor generic. Absolutely! I was setting this up so that we can potentially add different kinds of blocking tasks, but I suppose as long as the API supports it without forcing a breaking change, we can always expand this into an enum later.\n\n\n[x] de-enumify HttpConnectorBlockingTasks. I'm not 100% sure what you are asking here.\n\n\nNot exposing it as in not exporting it, but with the type still being part of the signature of HttpConnector::new_with_executor? Or instead boxing so that HttpConnector::new_with_executor requires an Executor<Box<Future<Item=(), Error=()>>>?\nFrankly, both don't seem ideal to me, but of course neither is my current solution. Personally it feels a little cleaner to use an opaque but descriptively named type here as I did, but I'm happy to change it if you prefer one over the other!. Hmm, maybe I'm misunderstanding, but as far as I can see when implementing a function that is generic over F, it's impossible for us to produce a future of type F without being passed one from the outside. But since our goal is to be able to execute arbitrary futures, I'm unsure how that would help us?. Yeah, most constructors including Client::default now need a thread-local handle. When we change the API I think we should probably defer most or all I/O (like port binding) until the future is polled, but for now that's the compromise I made.. Heh, will do!. Looks like it, yeah!\n\n\n[x] Use .left() and .right() combinators. No worries, I'll fix it up!\n\n\n[x] use try_ready! instead of explicit match. Oh, neat!\n\n\n[x] use recover. Yeah, Either used to have this useful split, that's gone away in futures 0.2 unfortunately.\n\n\nMaybe just replace it with a match?. I'll look into that!\n\n[x] look into adding SendRequest::is_ready method. It's needed because the method itself takes &self, so self.executor is &Exec. Cloning makes it owned and therefore mutable.\n\nThe method needs to take &self because it is called from Client::request, which takes &self. Maybe we could fix this up if we moved schedule_pool_timer into the constructor for Client?. I'm not sure about that, actually. I know that this is how CpuPool used to work, but I've recently worked with ThreadPool and I'm relatively sure that it will multiplex multiple futures onto a single thread.\nEffectively each thread is a while loop that reads tasks off a channel and polls them once, then repeats. The waker for each task will cause it to be re-submitted to the channel so it'll get polled again.\nCan you take a look at https://github.com/rust-lang-nursery/futures-rs/blob/master/futures-executor/src/thread_pool.rs#L124 and let me know if your understanding matches mine?\nThe reason we can't use cx.spawn is two fold:\n\nWe need a Send-able and Clone-able executor, but that's not guaranteed for the default executor.\n\nI'm hesitant to trust the lifetime of the default executor here (as in, the time until it is closed), since the context in most cases will come from the ResponseFuture, and in cases where block_on has been used the executor will close once that future has been resolved. However I think we want an executor than has a longer lifetime, ideally bound to the lifetime of Client.. Good catch!\n\n\n[x] delete futures_cpupool import. Oh yeah, in theory we could remove that one! I guess my thinking here was that since Conn is a public API, we might want to reserve the possibility of needing Context for future changes? Maybe that's a YAGNI though, so you tell me!. No problem!\n\n\n[ ] move cx to be the last argument. Can you go into more detail about that? Why would we need WriteBufAuto?. It returns Either because further down we return the Spawn future from the same function. The Spawn future is lazy and needs to be polled to spawn the future (since it's using the executor from the context to spawn).. Good points! We have the same situation with tokio, where I was gonna fix that up in another PR.\n\n\nYour call whether to do it as part of this PR, or whether I should follow up with a combined futures and tokio PR for it!. Will do!\n\n[x] use recover. Luckily my PR to add a Context arg to future::lazy just landed in time for futures 0.2 beta, so I fixed it using that instead!. On second thought, I guess I'll keep this open until https://github.com/rust-lang-nursery/futures-rs/issues/883 is settled?. Yeah, it is pretty unfortunate. I guess the way to think about it is cx.spawn should be used for short-lived futures (or futures that'll either likely complete within the lifetime of the task, or that are not essential to complete).\n\nFor long lives futures (such as pool timers and connection management), I believe we need to have the Client accept an executor that the user guarantees will be long-lived (such as the tokio runtime), or maintain a thread ourselves for this purpose.\nFor Server this won't be a problem I suppose because the Run or Serve tasks will generally be long lived anyway.. Ah, cool! I can definitely factor out the strategy swapping code, I guess WriteBufAuto would now implement some sort of write_to method that takes a AsyncWrite?\n\n[x] factor out strategy swapping code. - [x] change to use .left() and .right(). Ah, that looks like a great way to solve the problem!\n\nI'm a bit hesitant to go about changing all the tests, especially since once Aaron's PR is merged, block_on will be the simplest way to write that test code.\nI guess I could try to shim the new block_on using ThreadPool?. I tried this, but then the types will mismatch with futures 0.2.0-beta, which tokio depends on. I'll try shimming it instead!. Yay, that works!. Moved it into Checkout::poll now.. - [x] remove custom executor. Good point!\n\n[x] ignore dns spawn error. We can change this to use Either::factor_first once https://github.com/bluss/either/pull/19 is merged!. \n",
    "tomprince": "I've cherry-picked 011f28cb18d285401bc8bea2b0f0dbdf80089d97 into this.. ",
    "vovagp": "Well, that's your opinion. But I still think that this is a problem on the server side. In this case, in the Hyper logic.\nOFFTOPIC:\nExample for Netty:\n$ curl -I http://127.0.0.1:8080/\nHTTP/1.1 200 OK\nContent-Type: text/html\nX-Netty: 4.1.10.Final\nContent-Length: 60000\nConnection: keep-alive\n$ wrk -t8 -c300 -d30s --latency --timeout 2s http://127.0.0.1:8080/\nRunning 30s test @ http://127.0.0.1:8080/\n  8 threads and 300 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    27.67ms   17.31ms 251.93ms   84.73%\n    Req/Sec     1.40k   348.24     5.00k    69.85%\n  Latency Distribution\n     50%   22.78ms\n     75%   34.00ms\n     90%   48.13ms\n     99%   91.91ms\n  332801 requests in 30.09s, 18.63GB read\nRequests/sec:  11061.49\nTransfer/sec:    634.15MB\nSame version of wrk work correctly.. @sanmai-NL If possible. With biggest or dynamic buffer size we will get more than 226 RPS in highload system when content size more than 8192 bytes.. ",
    "mayah": "Thanks for the comment. You're right.\nI've updated the patch, and has written a test to use that.\nPTAL?. Thanks for the review.\nI've exported CookieIter, and moved test to document test.\nPTAL?. Thank you!. ",
    "mockersf": "Ok I found my answer, instead of sharing the Client I can share a Remote which is made to be shared, and using this Remote to create a thread local Client in the service, so that it's happening only once in the right event loop: the gist. ",
    "timgluz": "Hi, i'm using this snippet, but it works only with versions < 0.11\n```\nuse hyper;\nuse hyper::{client, Client, Url };\nuse hyper::net::HttpsConnector;\nuse hyper_native_tls::NativeTlsClient;\n...\nlet host = Cow::from(\"127.0.0.1\");\n let port = 3128;\n let scheme = \"http\";\n// configuration of PRoxy client\n let ssl = NativeTlsClient::new().unwrap();\n let connector = HttpsConnector::new(ssl);\n let ssl_proxy = NativeTlsClient::new().unwrap();\n let proxy = client::ProxyConfig::new (\n    scheme.as_str(), host, port, connector, ssl_proxy\n );\n// usage\n let mut client = Client::with_proxy_config(proxy)\n let mut res = client.get(uri.as_str()).send().expect(\"Failed to fetch results from the url\");\n```. Ok, thanks;. ",
    "kennethuil": "What are the plans for putting proxy support back into the new version?. ",
    "fdubois1": "Where did you publish that finally ?  You talked about a new crate, I red somewhere hyper-auth but can't find it.\nThanks. Thank you @KeenS . ",
    "killercup": "(Damn, forgot to comment here when I saw this yesterday.)\nI wrote a macro a while ago that does basically this in a way where you don't have to repeat the variant names and strings multiple times: https://play.rust-lang.org/?gist=02ff6d695cde7de8cc7dd52a98f95218. I'm not sure what your stance on internal macros is, I just wanted to leave this here :). ",
    "Thomspoon": "Is there away to provide the unannounced guides in a way that makes sense? . You haven't included it:\nrust\nuse hyper::mime::*;. Should be fixed now that the PR was merged.. @XX You could just create a new Hyper::Request using the Request::new method, and construct the remaining information with Request::set_version and Request::set_body. Finally, to add your headers, just utilize Request::header_mut, which returns a mutable header struct for your newly constructed request.. I can't replicate that problem. Could you tell what browser you're using, and what code you're using? \nHere's my test gist, and I was using FireFox 55.0.3. \nAlso, this issue doesn't seem to be directly related to Hyper itself noted here, but to the mime crate. However, I don't think Hyper should explicitly specify utf-8, since I believe the default already is: RFC 4627 Section 3.. ",
    "duxet": "Sorry, i was sure i tried that too. Seems to be working fine, thanks! \ud83d\udc4d . ",
    "polachok": "You can do something like this w/o modifying hyper:\n```rust\n    let mut core = Core::new().unwrap();\n    let handle2 = core.handle(); \n    let listener = TcpListener::bind(&http_listen_addr, &handle2).unwrap();\nlet server = listener.incoming().for_each(|(sock, addr)| {\n    let s = MySuperService;\n    Http::new().bind_connection(&handle2, sock, addr, s);\n\n    Ok(())\n});\ncore.run(server).unwrap();\n\n```\nBtw, I don't think tokio-file-unix does what you think it does.. >What's your concern about tokio-file-unix? \nIt doesn't work for regular files.. ",
    "kw217": "Ah, fair enough. I was worried that I would lose the goodness of Http::Server (which bind() creates), in particular, the shutdown handling, but I guess in reality that's not too important to me.\nWhat's your concern about tokio-file-unix? The docs say \"Asynchronous support for file-like objects via Tokio\", and a superficial look through its lib.rs seems to suggest it does the right things.. I'm not sure what you mean by that. We have used it succesfully to read files from disk in our tests (using the code I pasted above), and it appeared to be behaving in a correctly asynchronous manner (judging by the response behaviour etc). This is on CentOS. By \"doesn't work\" do you mean it panics, or it appears to work but isn't fully asynchronous?. OK, the answer to my original question seems to be that Hyper is fine, but the docs don't make it clear that if you want access to the handle, you must use Http::bind_connection rather than Http::bind. \nPlease could the docs be improved? As a newbie, I clicked through to hyper::server which lists four structs, one of which is \"Server: an instance of a server created through \"Http::bind\". So I went toHttp::bindand it seemed to do what I wanted. Immediately below isHttp::bind_connectionbut it says \"This is the low-level method ... This method is typically not invoked directly but is rather transitively used throughbind`.\"\nI think those statements are a bit too strong.\n\nFirstly, despite the name, Server is just another server - it's not special in any way. Http is the key struct for HTTP servers. Can the first sentence of the Server comment say \"Convenience type used by Http:bind\", so it's more obvious this isn't the primary type?\nSecondly, can Http::bind say \"if you need more flexibility, use bind_connection\" and Http::bind_connection remove the comments about \"low-level\" and \"not typically invoked directly\"? Instead it could say \"For simple cases consider using bind instead\".. Your service is a struct which implements the Service trait, and hence the call method. In your new method, just pass in the handle as an argument and store it in the struct. Then it's there for you to use in the call method.\n\nThe key point is that you should construct the server the way https://github.com/hyperium/hyper/issues/1207#issuecomment-306496191 does with Http::bind_connection, rather than using Http::bind as the docs imply.. OK, I'm happy to follow #1322 instead, as long as the docs are improved to make the new usage clear.. This would definitely be an improvement - thanks. \nIn terms of documentation, please can you consider my concerns from https://github.com/hyperium/hyper/issues/1207#issuecomment-308144548, specifically making it clear that Server is just a helper and you can build a more flexible server by using Http directly? That's still the case, even if this current change makes Server more powerful.\nAs a newbie, I clicked through to hyper::server which lists four structs, one of which is \"Server: an instance of a server created through Http::bind\". So I went to Http::bind and it seemed to do what I wanted. Immediately below is Http::bind_connection but it says \"This is the low-level method ... This method is typically not invoked directly but is rather transitively used through bind.\"\nI think those statements are a bit too strong.\n\nFirstly, despite the name, Server is just another server - it's not special in any way. Http is the key struct for HTTP servers. Can the first sentence of the Server comment say \"Convenience type used by Http:bind\", so it's more obvious this isn't the primary type?\nSecondly, can Http::bind say \"if you need more flexibility, use bind_connection\" and Http::bind_connection remove the comments about \"low-level\" and \"not typically invoked directly\"? Instead it could say \"For simple cases consider using bind instead\".. Thanks @seanmonstar. Yes, making it an option on the connector makes lots of sense, so it looks like this:\nrust\nlet bind_addr: Option<IpAddr> = Some(\"127.0.0.1\".parse().unwrap());\nlet mut connector = HttpConnector::new(4);\nconnector.set_local_address(bind_addr);\nlet client = Client::builder().build(connector);\n\nAha, I see now that you've upgraded away from tokio-core (I was looking at the latest 0.11 release, not master). It looks a bit simpler now, and I see the Windows knowledge is already in Hyper so the need for it is no longer a concern. Thanks!\nHowever there is one remaining problem - where previously I had to allocate, now I think there's a case that isn't expressible at all. hyper::client::http::connect() takes an Option<Handle>, and I can extend it to also take a local_address: Option<IpAddr>. If the handle is present, I can bind to the local address before calling TcpStream::connect_std. But if the handle is absent, the only method I can call is TcpStream::connect - and that doesn't provide any way to bind first. Am I safe to call just Handle::current() here and call TcpStream::connect_std anyway, or is something missing from tokio?. I'm not sure what caused the build timeout; I don't think it's related to my code.. Right, sorry about that. Fixed now - back to the same timeout error you said not to worry about.. Thank you!. It's normally called the local address; see bind(2) at https://linux.die.net/man/2/bind and http://pubs.opengroup.org/onlinepubs/009695399/functions/bind.html . Normally bind takes a SockAddr, but for this specific case of binding-before-connecting, it's vanishingly rare that you want to specify the port as well as the IP, which is why I have specified IpAddr. But it's still an address.. No problem - it was just there to show what it would look like. I've removed it now.. ",
    "b4stien": "@kw217 would you mind providing a small gist of what your final solution (with https://github.com/hyperium/hyper/issues/1207#issuecomment-306496191) looks like?\nI'm having troubles finding how to get back a reference to the handle in the call function of my service (spoiler alert: I'm a complete Rust beginner).. ",
    "d33d33": "The error occur inside the read function of a Body provided to a client.\nStill a wip but it may help you to understand the issue: https://github.com/runabove/beamium/blob/threads/src/sink.rs#L305. So fast :D\nYou rocks!. ",
    "ekicyou": "I confirmed a good operation. Thank you!. Thank you! Try the built-in close.. ",
    "bradleybeddoes": "Thanks for the link to #1164 @seanmonstar that was interesting background reading.\nCurrently I am most interested in determining if another part of the application has set a Body or not on the Response object which is about to be sent back over the wire (or alternatively that same part of the application has indicated that the Response is considered to be done and nothing else should touch it).\nThe concept is that when a Body has been set (or the Response is marked done) this will flow through unimpeded. When this is not the case however, custom code, which is invoked based on the Status of the Response, will be executed to (potentially) set a Body.\nFor example adding JSON to the Body with error details which have resulted from processing an invalid Request within a RESTful API so you don't need to replicate error handling/population code in multiple locations.\nHopefully that makes sense, little bit of weird one to explain, happy to provide a code example if that would help.\n. #1164 is certainly more advanced than what I need right now.\nResponse::body_ref() would work out nicely - shall I create a PR?. Hey @seanmonstar, apologies, this fell off my radar for a short period. Are you happy for me to create a PR for the functionality discussed above or would you prefer to handle within some other work you have on the go?. Thanks, have submitted https://github.com/hyperium/hyper/pull/1244 noting potential change of api in the future.. Sure. What did you have in mind, re: fixing Response here?. ",
    "laplaceon": "Ahhh, that explains it. It works as expected now.. ",
    "ThetaSinner": "Great, that'll work thanks.\nI'm happy enough using the git repo for now.. It's taken me a while to get around to implementing this in my project. I hadn't looked closely enough at hyper-tls to notice that it works with client configuration.\nI should have said in my original question that it's https on the server that I need. \n. ",
    "danger89": "So now I got a question related to this story...\nWhat are the differences between:\n hyper-tls\n hyper-native-tls\n* hyper-openssl\nI'm very confused as an user.\nAnd which is the best SSL/TLS implementation to use now and in the (near) future??\nI don't get it anymore.\n. Ow thanks, I didn't know about reqwest. The better the abstraction the easier for everyone. From httparse to hyper, from hyper to reqwest. From reqwest to AI that will destroy earth. . ",
    "bxqgit": "@seanmonstar Now it works. Thank you!. Also I would suggest to change:\n# fn main() {}\nto\nfn main() {\n    run();\n}\nAnd mention, that one can see the result at:\nhttp://127.0.0.1:3000/. @seanmonstar I'm talking about not some examples in the source. It's about the code on the front page of https://hyper.rs/ Users come and see this page. Then they try to run the code from the page. And it won't work!\nBecause:\n1. There's no word about service-fn dependency in Cargo.toml\n2. The main() function doesn't call the run() function, so the server won't start at all.\nThat's a bad first impression about hyper.rs framework. That's bad for user acquisition. I would change the code and instructions on the front page so that it would JUST RUN.. ",
    "skinowski": "Could you please update the 'advanced' client example with an overall timeout? This is the general case and if it's in the example, it'll be super helpful.. @hjr3 Here: https://hyper.rs/guides/client/advanced/\nI've also figured how to do this myself:\nlet dur = Duration::from_millis(1000);\nlet work = client.get(...).and_then(...)....;\nlet tm = timer.timeout(work, dur);\nBut it's really easy to get caught in wrapped types of these futures: map, and_then, map_err, select2, join, etc. are not easy to follow for a beginner.\n. ",
    "Ralith": "Sure, but this is Rust; we shouldn't have to round-trip that information through a string.. > I really want number 1 to happen, but for the moment, the string conversion and back is pretty small compared to the network IO.\nIt's not about performance so much as robustness. There are far fewer moving parts if you keep data in its native format.\n\nWould it make sense to repurpose this issue to track what I said about the ClientProto onion?\n\nIf you think that's the way to go and it subsumes this specific concern, I have no objection to that.. ",
    "RCasatta": "It works, thanks and sorry for the more rust than hyper question, I am a rust newbie. ",
    "asajeffrey": "Hmm, the CORS spec here is, er, unenlightening: https://www.w3.org/TR/cors/#access-control-allow-origin-response-header. The grammar allows more than one origin, but there is a note \"In practice the origin-list-or-null production is more constrained. Rather than allowing a space-separated list of origins, it is either a single origin or the string \"null\".\"\nThe web platform tests are quite explicit about adding more than one such header (https://github.com/w3c/web-platform-tests/blob/b37004f3d52b3b53a5db51cfc488ed415bd6b610/fetch/api/resources/preflight.py#L10-L11):\npython\n    for origin in request.GET['origin'].split(\", \"):\n        headers.append((\"Access-Control-Allow-Origin\", origin))\nI think the note in the CORS spec isn't normative, so the implementation should allow more than one header?. Yes, this is a breaking change, sigh.. ",
    "gabisurita": "Maybe not being able to perform a request is totally OK, but compiling would be really useful to use some hyper features such as typed headers and request builders, having those as separate crates would be great as well.\nBy the way, I've solved my problem using only the emscripten API, in case someone is looking for a quick way to have HTTP requests (limited to GET and POST) on a Rust asm.js compiled App.. ",
    "joshtriplett": "@gabisurita \n\ntyped headers and request builders\nSounds like the ideal solution might be a crate supporting emscripten and wasm that uses the new http crate for its API, instead.. \n",
    "najamelan": "I would like to get an upgraded connection, so I have an impl AsyncRead/AsyncWrite on both the server an in a wasm frontend... On the server that would work fine right now, but on wasm?\nAny tips on what the most realistic strategy is for now? Can I avoid handrolling this in javascript?. ",
    "markstory": "Would you be open to having the docs updated to be more noob friendly? I am happy to make the changes of you can tell me where to find to guide sources.. Thanks for pointing me in the right direction. I will try to have a pull request up this weekend.. ",
    "faraazahmad": "I made a PR but the tests are failing due to square brackets in markdown. How do I solve it? I tried backticks too.. ",
    "slyrz": "Great to hear it's being resolved and thank you for fixing this!\n. ",
    "valeriansaliou": "Thanks \ud83d\udc4d , looking into it. Will get back with a solution to share.. Hi! Still on it. Didn't have much time over the last days to work on it.. I could replicate the exact same bug by modifying the (working) Echo example in ./examples/server.rs to a Request <> Request proxy pattern:\nNote that I used my local API server for this test.\n```rust\n![deny(warnings)]\nextern crate futures;\nextern crate hyper;\nextern crate tokio_core;\nextern crate pretty_env_logger;\nuse futures::future::FutureResult;\nuse hyper::Client;\nuse hyper::StatusCode;\nuse hyper::Method::Patch;\nuse hyper::header::ContentLength;\nuse hyper::server::{Http, Service, Request, Response};\nstruct Echo;\nimpl Service for Echo {\n    type Request = Request;\n    type Response = Response;\n    type Error = hyper::Error;\n    type Future = FutureResult;\nfn call(&self, req: Request) -> Self::Future {\n    futures::future::ok(match (req.method(), req.path()) {\n        (&Patch, \"/echo\") => {\n            let mut core = tokio_core::reactor::Core::new().unwrap();\n            let handle = core.handle();\n            let client = Client::new(&handle);\n\n            let mut tunnel_req = Request::new(Patch, \"http://api.crisp.chat.dev/v1/user/availability\".parse().unwrap());\n\n            if let Some(len) = req.headers().get::<ContentLength>() {\n                tunnel_req.headers_mut().set(len.clone());\n            }\n\n            tunnel_req.set_body(req.body());\n\n            match core.run(client.request(tunnel_req)) {\n                Ok(response) => response,\n                Err(err) => panic!(\"could not stream: {}\", err),\n            }\n        },\n        _ => {\n            Response::new().with_status(StatusCode::NotFound)\n        }\n    })\n}\n\n}\nfn main() {\n    pretty_env_logger::init().unwrap();\n    let addr = \"127.0.0.1:1337\".parse().unwrap();\nlet server = Http::new().bind(&addr, || Ok(Echo)).unwrap();\nprintln!(\"Listening on http://{} with 1 thread.\", server.local_addr().unwrap());\nserver.run().unwrap();\n\n}\n```\nUsing cURL command:\nbash\ncurl -X \"PATCH\" \"http://127.0.0.1:1337/echo\" \\\n     -H \"Content-Type: application/json; charset=utf-8\" \\\n     -u 55cef0f3-546b-45ae-b781-6adc780d4839:23c34f5cd0919c686aa402440b229242568b76eb512d1e03de41c549979e4d56 \\\n     -d $'{\n  \"type\": \"online\",\n  \"time\": {\n    \"for\": 60\n  }\n}'\n...waits forever and times out.. Wouldn't that come from futures::sync::mpsc::Receiver <> futures::sync::mpsc::Sender where I'm trying to bridge futures::sync::mpsc::Receiver <> futures::sync::mpsc::Receiver?. Thanks @seanmonstar, will try this.\nPS: on the Authorization header thing, woops but no worries, it's a local-only one \ud83d\ude05 . Got it to work w/ this Gist as an example: https://gist.github.com/mockersf/6ae921598913c3b59799bf2a33546922 (referenced from #1189).\nShould also fix a previous issue of mine #1260. Was all due to a misunderstanding on my end.\nMore examples on this would be nice, I guess it's a common problem for newcomers, as it's hard to learn coding proper Hyper + Tokio + Futures when you encounter all those at once \u2014 especially the Futures part.\nThanks for the help anyway! I consider this closed.. ",
    "ampotos": "Hi,\nI have a similar issue, did you find any solution ?\n. Ok.\nIf it can help the same behavior happen when 2 thread are doing the same request almost at the same time. The second start when the first didn't finish to wait, in this case the first thread never wake up.\nI'm new to rust so I can try to help but I'm not sure to be really useful.. ",
    "ivanovaleksey": "Hello @seanmonstar, it seems I faced with the similar issue while trying to build a client.\nI make everything as in the example though my application is just hanging up and waiting for something.\nI guess it is very stupid question but what it is a common way to organize the things to avoid \"using wait on the same thread as the Core is running\".\nI wonder should I use tokio::executor::current_thread or something else.. @seanmonstar thank you for the reply.\nI don't know why but the problem was when I wasn't return a future from a separate function but built it within main() like\nrust\nfn main() {\n    let f = built my future with different combinators\n    rt::run(f);\n}. ",
    "P-E-Meunier": "Same here, exposing a handle is not enough: I'm running two HTTP servers on the same event loop (one http handling let's encrypt, and redirecting other requests to https), plus a pleingres database connection, and an SSH server.\nI would be able to spawn the pleingres and SSH server using just the current handle, but not to run the two HTTP servers, because each wants its own event loop.\nI'd be willing to write the two extra lines in my program to start the event loop myself, though.. Hi! As I figured out with my second commit, the tests currently in master do not pass with my proposed change, so I guess we'll have to wait for 0.12.\nThis is not a giant problem for me, as long as 0.12 comes in the next few weeks (at least before the next big change in rustls/*ring*).\nBy the way, I like how the server code is structured. It's really short and clean.. Sure. So since the API are necessarily different (some have their own Core, some don't), that would mean duplicating some code for a while, marking it as deprecated (as you said before, but not just for local_addr).\nThe core field of the struct could be an Option, right?\nAnother question I had was, why did you require anything to be Send + Sync? This seem a little odd for stuff supposed to be run in an event loop.. Here's a really direct application of allowing arbitrary streams: tests! Maybe you don't can't open ports on you machine, and you want to run the protocol inside buffers (or on unix domain sockets if you want to benchmark what gets sent to the kernel).\n. ",
    "nghenglim": "The README is suggesting\n\nSee the Hello World example for a toy server using hyper\n\nBut IMHO for people who want to have a quick try will be expecting something like  https://github.com/nghenglim/hello-async-hyper , which can give a better idea of setting up a project with Hyper as a dependencies. ",
    "anderejd": "I agree with @nghenglim, examples should be self contained and copy-paste:able.. ",
    "pftbest": "Just hit this issue as well. Wanted to try hyper, copied the code from the front page. Missing fn main was a trivial fix, but then finding this service_fn crate was kinda hard since it's not on crates.io.. ",
    "vishalcjha": "changing from for_each to res.body().concat2() makes it very comparable if not better than rust. \nBut in go i read one streamed result at a time. I think question is still open. . Ok When i changed from Vec to Vec as now in code results are very comparable with for_each. But still bit slower. May be there is bit some where i can squeeze. . ",
    "king6cong": "Yeah. Better leave for libraries like reqwest. . Great, got it. Thanks . ",
    "parasyte": "FWIW, I was able to get futures-cpupool working. Spoiler: in a baseline benchmark, the naive single-threaded design with HTTP/1.1 pipelining is an order of magnitude faster.\nWith futures-cpupool:\n```rust\nextern crate futures;\nextern crate futures_cpupool;\nextern crate hyper;\nuse futures::{Async, Future, Poll};\nuse futures_cpupool::{CpuFuture, CpuPool};\nuse hyper::{Method, StatusCode};\nuse hyper::server::{Http, Request, Response, Service};\nstruct Ping {\n    pool: CpuPool,\n}\nimpl Ping {\n    fn new() -> Self {\n        Self {\n            pool: CpuPool::new_num_cpus(),\n        }\n    }\n}\nimpl Service for Ping {\n    type Request = Request;\n    type Response = Response;\n    type Error = hyper::Error;\n    type Future = Box>;\nfn call(&self, req: Request) -> Self::Future {\n    Box::new(self.pool.spawn(PingResponse::new(req)))\n}\n\n}\nstruct PingResponse {\n    req: Request,\n}\nimpl PingResponse {\n    fn new(req: Request) -> Self {\n        Self { req }\n    }\nfn worker(&self) -> Poll<Response, hyper::Error> {\n    let mut response = Response::new();\n\n    match (self.req.method(), self.req.path()) {\n        (&Method::Get, \"/ping\") => {\n            response.set_body(\"pong\");\n        },\n        _ => {\n            response.set_status(StatusCode::NotFound);\n        },\n    };\n\n    Ok(Async::Ready(response))\n}\n\n}\nimpl Future for PingResponse {\n    type Item = Response;\n    type Error = hyper::Error;\nfn poll(&mut self) -> Poll<Self::Item, Self::Error> {\n    self.worker()\n}\n\n}\nfn main() {\n    let hostport = \"127.0.0.1:3000\";\n    let addr = hostport.parse().unwrap();\n    let server = Http::new()\n        .pipeline(true)\n        .bind(&addr, || Ok(Ping::new())).unwrap();\nprintln!(\"Listening on {}\", hostport);\n\nserver.run().unwrap();\n\n}\n```\nNaive single-threaded design:\n```rust\nextern crate futures;\nextern crate hyper;\nuse futures::Future;\nuse hyper::{Method, StatusCode};\nuse hyper::server::{Http, Request, Response, Service};\nstruct Ping;\nimpl Service for Ping {\n    type Request = Request;\n    type Response = Response;\n    type Error = hyper::Error;\n    type Future = Box>;\nfn call(&self, req: Request) -> Self::Future {\n    let mut response = Response::new();\n\n    match (req.method(), req.path()) {\n        (&Method::Get, \"/ping\") => {\n            response.set_body(\"pong\");\n        },\n        _ => {\n            response.set_status(StatusCode::NotFound);\n        },\n    };\n\n    Box::new(futures::future::ok(response))\n}\n\n}\nfn main() {\n    let hostport = \"127.0.0.1:3000\";\n    let addr = hostport.parse().unwrap();\n    let server = Http::new()\n        .pipeline(true)\n        .bind(&addr, || Ok(Ping)).unwrap();\nprintln!(\"Listening on http://{}/\", hostport);\n\nserver.run().unwrap();\n\n}\n```\nBenchmark with h2load:\nbash\nh2load --h1 -c 100 -n 1000000 -m 50 http://localhost:3000/ping\n\n~95,000 requests per second with futures-cpupool.\n~400,000 requests per second with naive single thread.\n\nBenchmark numbers are from a Mid-2014 MBP with 2.2 GHz Intel Core i7.\nI haven't done a full analysis, but the primary issue appears to be thread synchronization. The pool is created with the same size as the number of CPU cores available, but the CPUs do not get saturated under load... Only about half of them stay busy. On my system that's 4x more work for 5x less performance. Abysmal. Cranking the pool size to n*2+1 makes the benchmark tank, and CPU saturation is even worse.\nIMHO, run one server for each available core and load balance across them. \ud83d\ude15. ",
    "jD91mZM2": "A stream might be easy enough to use on it's own, but when it comes to updating Hyper 0.9 to 0.11 it's really difficult to change every single read_to_string. Currently I made a io::Read wrapper instead.\nEDIT: reqwest looks cool though!. ",
    "spinda": "Motivating scenario: I have a Service whose call method makes use of a RefCell, since the self parameter of call is forced to be an immutable reference and I need to mutate some shared state according to requests processed. RefCell does not have Send + Sync, however, so without this change I'd have to use something more costly like Arc, when internally hyper only executes call on the same thread as run anyway.. Ah, I see. Would it make sense to have an explicitly single-threaded version of bind without these bounds, to implement the boilerplate of managing a Core directly? (which could for the moment call into the current path for bind under the hood, since it's not yet multithreaded). Perhaps keep Server single-threaded, drop the bounds from it, and introduce a ParallelServer with Send + Sync equivalent to the current Server type? Then a bind_parallel method on Http which produces a ParallelServer.. That sounds great, and I also wrestled with the naming of this function. Feel free to close this then.. No problem, and thanks!. Hi again, have you had a chance to look at this since RustConf?. Thanks for taking a look! Not sure how much time I'm going to have over the next few days (ending an internship and moving back home). I'll address these comments as soon as I can.. ",
    "kpcyrd": "Since extending an enum is a breaking change, I've added a couple more things that are related to preloading. Most of it is taken from here: https://www.w3.org/TR/preload/\nThe as target might need some more work, it's currently a string that could be replaced with an enum as well. Valid values are :\n\u00a0\naudio, video, track, script, style, font, image, fetch, worker, embed, object, document.\nFeedback welcome. :). that would work for me as well. It seems removing the call to body.concat2() doesn't change anything.. There are no setters on Uri, if the api allows modifying parts of the Destination, should I try to build a new Uri with the value provided? Is there a way to ensure a Uri meets all requirements of a a valid destination?. @seanmonstar awesome, thanks! closing in favour of #1572 . ",
    "rytone": "Mistake on my part - the issue only occurs when calling request.set_version(HttpVersion::H2). I thought I had tested that, but I guess not. The server I am making requests to is HTTP/2 capable.. ",
    "porglezomp": "(Fair enough.). ",
    "blueridanus": "How's progress on this? Can I help?. ",
    "PENGUINLIONG": "It sometimes happens although I have placed a favicon in the root directory, but it's not detected by a browser until some time after. I'm surprised MS Edge can do it right all the time.. ",
    "Crandel": "Sorry, my mistake, go deeper into documentation and find all answers. Can you update documentation and show how to extract body from response?\nI need to parse response and I don`t have any idea how to do it. Never was a problem to using Python or Go for this simple action. \nI need to use https (thanks to Google its a default method for all popular websites) and authorization **headers**, extract body and parse string, using some regex. And I need to do it for several websites and save result into the file  . @hwchen Yes, I saw this example, but it doesnt help if you need to call HTTPS website(most of them use HTTPS) with authentication and other custom headers. The example should be close to real life and real use cases.. +1\nI miss example, how to create a client for https url with custom header (Token Authorization) and save result from future to string. The examples are very limited. . ",
    "CGavrila": "Thank you!\nMakes sense, I assumed that might be the problem. With that said, there is no such mention in the README file or anywhere else I've looked.\nI will retry and re-open if this is still an issue. Thanks again!. ",
    "stianeklund": "Moving to https://github.com/hyperium/hyperium.github.io/issues/18. ",
    "FGRibreau": "I changed the client guide example to:\n```\nextern crate futures;\nextern crate hyper;\nextern crate tokio_core;\nuse std::io::{self, Write};\nuse futures::{Future, Stream};\nuse hyper::Client;\nuse tokio_core::reactor::Core;\nfn main(){\n    run();\n}\nfn run() -> Result<(), hyper::Error> {\n    let mut core = Core::new().unwrap();\n    let client = Client::new(&core.handle());\nlet uri = \"http://httpbin.org/ip\".parse().unwrap();\nlet work = client.get(uri).and_then(|res| {\n    println!(\"Response: {}\", res.status());\n\n    println!(\"Response: {}\", res.headers());\n\n\n    res.body().for_each(|chunk| {\n        io::stdout()\n            .write_all(&chunk)\n            .map_err(From::from)\n    })\n});\ncore.run(work).unwrap();\nOk(())\n\n}\n```\nTo make it compile but was not able to find the OK result type, any help?\n(Once I got this I will submit a PR to fix the guide since I'm sure I was not the only one with this issue :)). ",
    "Aarowaim": "A simple fix is to unwrap() in each of these places. Failure to run an example is a valid reason for a panic; something has gone terribly wrong! (It is also for this reason examples should be self-contained, by having main()).\nThe working example should be:\n```rust\nextern crate futures;\nextern crate hyper;\nextern crate tokio_core;\nuse std::io::{self, Write};\nuse futures::{Future, Stream};\nuse hyper::Client;\nuse tokio_core::reactor::Core;\nfn main() {\n  let mut core = Core::new().unwrap();\n  let client = Client::new(&core.handle());\nlet uri = \"http://httpbin.org/ip\".parse().unwrap();\n  let work = client.get(uri).and_then(|res| {\n    println!(\"Response: {}\", res.status());\nres.body().for_each(|chunk| {\n  io::stdout()\n    .write_all(&chunk)\n    .map_err(From::from)\n  })\n});\ncore.run(work).unwrap();\n\n}\n```\nThe Rust Programming Language book has a section on the subject of panics\n\nWhen you\u2019re writing an example to illustrate some concept, having robust error handling code in the example as well can make the example less clear. In examples, it\u2019s understood that a call to a method like unwrap that could panic! is meant as a placeholder for the way that you\u2019d actually like your application to handle errors, which can differ based on what the rest of your code is doing.\n\n? is a way of simply ignoring the exceptions rather than addressing them with a handler or a panic. In my experience it is best to handle exceptions as soon in the call stack as there is information sufficient to respond. Propagating exceptions makes the code messy unless there's a good reason not to handle them immediately. \nHttp exceptions can usually be responded to by retrying a few times and then informing the user to check if that particular website is down and troubleshoot their internet connection. In many cases, an http client will not have access to network troubleshooting/control, or can simply be run a second time by the user.. ",
    "yaa110": "the code was changed to the following code and it is working now:\nrust\nBox:new(req.body().concat2().and_then(|body| {\n    let v: Value = serde_json::from_slice(&body).unwrap();\n    // ...\n})). ",
    "flokli": "Travis complains about an unused extern crate pretty_env_logger in rust nighly.\nShouldn't be related to this PR.. @seanmonstar No problem :-)\nSure, its kind of uncommon, nevertheless I stumbled over a (private) HTTP API using this Token scheme for authentication, added support for this outside of hyper, and thought it might be useful for others, too (as it doesn't add that much to the codebase).\nMaybe @ernestas-poskus, who  +1'd here knows a real-world example, which could justify this more, even though it might not be an official spec?. Sure, I can understand that. No worries :-). ",
    "andir": "@seanmonstar while you are right that there is no standard for Token there are a few applications using it. For example django-rest-framework is using that scheme (per default, http://www.django-rest-framework.org/api-guide/authentication/#tokenauthentication). You can change the keyword that is being used to Bearer or whatever. \nI fully support NOT merging this right now, just wanted to state that there are indeed people using Token (as a default).\nEfforts should go towards changing the default in django-rest-framework and other frameworks so they just stick to the standard.. ",
    "XX": "@mehcode Thanks for the help. How can I again construct this request after deconstruction to transfer it to another function?. @Thomspoon Thanks. Why does not the Request implement a Clone? Is there any reason for this?. @KodrAus Thanks for the answer. If I pass total future in instead of calling total.wait(), there is no blocking. . ",
    "philippludwig": "@Thomspoon that does not work; adding the headers fails since: \n``\nfor header in headers.iter() {\n    req_copy.headers_mut().set(header);^^^ the trait hyper::header::Header is not implemented for hyper::header::HeaderView<'_>``\n}\n. ",
    "seunlanlege": "@seanmonstar . Oh i see, but problem with that approach is that we lose intellisense. :disappointed: . what would it take to write them all as structs?. > What is the actual issue here? Intellisense cannot understand macros in Rust?\nthat would appear to be the case.. ",
    "0610919566": "https://github.com/hyperium/hyper/blob/master/CONTRIBUTING.md#git-commit-guidelines. https://github.com/hyperium/hyper/commit/7ba058a5352c8b59f0d2ee18ab698b22837de1a2. ",
    "maghoff": "Thanks for getting back to me :) I'll try to clarify the rest:\n\nConnection defaults to close in 1.0 and keep-alive in 1.1, so when the client requests keep-alive, the server has to include Connection: keep-alive in the response to verify support for this. (This is in contrast to 1.1, where both sides can assume keep-alive if nothing else is said) Hyper server is lacking this in the response. I haven't looked at the client, but I assume the converse error here? In any case, the correct behavior for the client is to ask for keep-alive and treat the connection mode as whatever the server responds, dependent on version:\nThe server responds with HTTP/1.0 and no Connection header: Treat the connection as non-pipelined, as if the server had said Connection: close.\nThe server responds with HTTP/1.1 (or 1.x, where x >= 1) and no Connection header: Treat the connection as pipelined, as if the server had said Connection: keep-alive.\n\nIf the server response includes a Connection header, regardless of HTTP version, respect this header.\n\n\nI think you have understood correctly how to treat messages without a declared Content-Length in 1.0. Either you have Content-Length, or the body is sent and terminated by closing the connection. This means that if the server is planning on replying without a set Content-Length, it must avoid enabling Connection: keep-alive. This probably interacts with how a client would send the body in a POST or PUT request. Perhaps it is impossible to send a body without Content-Length to a 1.0 server? I'm not sure. . > The server should never receive the fragment\n\n\nYou are right. I was confused on this point, but have now re-read the spec regarding it :)\nI no longer feel that I should be able to access the fragment where I have tried to do so, so I will close the issue. A code comment explaining the \"why\" might be appropriate :)\nThanks for your quick response :+1: . ",
    "mrenoon": "I had no problems with the example. However, there are some people who read our README, see the line \"See the Hello World example for a toy server using hyper.\", clicked to see the file and do not immediately know how to get it running, as evidenced by issue #1265. Ok cool!. ",
    "srgsuchkov": "I use something like this :\n```\nstruct TestSt;\nimpl Service for TestSt {\n    type Request = Request;\n    type Response = Response;\n    type Error = hyper::Error;\n    type Future = FutureResult;\n    fn call(&self, req: Request) -> Self::Future {\n        futures::future::ok(match req.method() {\n            &Post => {\n                req.body().concat2().and_then(move |body: Chunk| {\n                                                let v: Value = serde_json::from_slice(&body).unwrap();\n                                                println!(\"{:?}\", v);\n                                                Ok(())\n                });\n                Response::new().with_status(StatusCode::Ok)\n            },\n            _ => {\n                Response::new().with_status(StatusCode::NotFound)\n            }\n       })\n    }\n}\nfn main() {\n    let addr = \"0.0.0.0:3000\".parse().unwrap();\n    let server = Http::new().keep_alive(true).bind(&addr, || Ok(TestSt)).unwrap();\n    server.run().unwrap();\n}\n```\nwhen I run the server and make some requests\ncurl -X POST -H \"Content-Type: application/json\" \"127.0.0.1:3000/u\" -d '{\"name\": \"Name1\", \"age\": 20}'\nI expect to see println with this data but got nothing.\nCould you pls explain what I'm doing wrong ?\n( hyper v0.11.2 ). Sorry, I'm newbie in rust, mb I can't understand some thing, but if I rewrite me code to:\n```\n&Post => {\n    req.body()\n       .concat2()\n       .and_then(move |body: Chunk| {\n            let v: Value = serde_json::from_slice(&body).unwrap();\n            println!(\"{:?}\", v);\n            Ok(())\n        })\n        .and_then(|_| {\n            Ok(Response::new().with_status(StatusCode::Ok))\n        });\n\n},\n```\nI got error : \nnote: expected type `hyper::Response`\n found type `()`\nHow can I unwrap hyper::Response from futures::AndThen ?. Thank you so much, explains everything for me.. ",
    "kingofoz": "Thanks, @seanmonstar . ",
    "chrxr": "Cargo.toml dependencies\nfutures = \"0.1.14\"\nhyper = \"0.11.2\"\ntokio-core = \"0.1.9\"\n. Ah! Got it, thanks. Is it also possible to get the uri scheme in a similar way? This method also currently returns None for me but Scheme isn't included in the Host header. . Thanks! HTTP/2 FTW. ",
    "13h3r": "I tried to run this on ubuntu vpc and it works fine with ab.\nI tried wrk on mac and it also works fine. The only difference between ab and wrk is connection management. ab open new connection every time and wrk reuse existing once. Do you have any ideas to check to verify connection management problem here?. I did ulimit -n 32000 and set kernel params to corresponding values.. Sorry for not mentioning this. Same problem. App hangs after 16k connections. ",
    "klausi": "The requests are always to the same host, http://localhost/ in this example. I will try to find out what happens on a cloned client and what exactly is growing in memory.. After spending half an hour of adding where T: Debug, to all the things in pool.rs I was able to debug log the pool after 20 requests:\nPool { inner: RefCell { value: PoolInner { enabled: true, idle: {}, parked: {\"http://localhost:80\": [Sender {\n inner: (Weak) }, Sender { inner: (Weak) }, Sender { inner: (Weak) }, Sender { inner: (Weak) }, Sender { \ninner: (Weak) }, Sender { inner: (Weak) }, Sender { inner: (Weak) }, Sender { inner: (Weak) }, Sender { \ninner: (Weak) }, Sender { inner: (Weak) }, Sender { inner: (Weak) }, Sender { inner: (Weak) }, Sender { \ninner: (Weak) }, Sender { inner: (Weak) }, Sender { inner: (Weak) }, Sender { inner: (Weak) }, Sender { \ninner: (Weak) }, Sender { inner: (Weak) }, Sender { inner: (Weak) }, Sender { inner: (Weak) }]}, timeout: \nSome(Duration { secs: 90, nanos: 0 }) } } }\nThe hashmap of parked things is growing linearly with the requests performed. The only call to remove() entries form the parked HashMap is in the put() function of Pool, but it is never called. So maybe we need to clean up the parked HashMap in other places as well?. Very good, glad I could help at least some way :-). After digging around a bit in Hyper and Tokio I think that  tokio_core::net::Incoming is flawed. It has an Error type but each TCP connection attempt it produces is not a Result but a TcpStream already. So there is no way to catch the IO error on individual incoming accept() attempts and then continue to receive new connections. Contrast that with std::net::Incoming which produces a Result for each connection attempt.\nSo I think the path forward here is to try out a forked version of tokio_core and Hyper to see if it is possible to produce TCP connections in the same Result way as the standard library.. I'm trying the or_else() future as @carllerche recommended.\nStarting from:\nrust\nlet server = listener.incoming().for_each(move |(sock, addr)| {\n    http.bind_connection(\n        &handle,\n        sock,\n        addr,\n        Proxy {\n            port: port,\n            upstream_port: upstream_port,\n            client: client.clone(),\n        },\n    );\n    Ok(())\n});\nAttempt 1: just insert the or_else() and see what the compiler tells us:\nrust\nlet server = listener.incoming().or_else(|e| {\n                println!(\"{:?}\", e);\n            }).for_each(move |(sock, addr)| { ... });\nerror[E0277]: the trait bound `(): futures::Future` is not satisfied\n   --> src/lib.rs:169:46\n    |\n169 |             let server = listener.incoming().or_else(|e| {\n    |                                              ^^^^^^^ the trait `futures::Future` is not implemented for `()`\n    |\n    = note: required because of the requirements on the impl of `futures::IntoFuture` for `()`\nI was hoping the compiler would give me a hint about the return type I have to produce in my closure, but that is not helpful. I'm not using () anywhere, so what is she talking about? Looking at the docs at https://docs.rs/futures/0.1.16/futures/stream/trait.Stream.html#method.or_else there is no example and the type only says I need to return an U which is IntoFuture<Item = Self::Item>.\nAttempt 2: Return an empty Ok tuple as the for_each() does\nrust\nlet server = listener.incoming().or_else(|e| {\n                println!(\"{:?}\", e);\n                Ok(())\n            }).for_each(move |(sock, addr)| { ... });\nerror[E0271]: type mismatch resolving `<std::result::Result<(), _> as futures::IntoFuture>::Item == (tokio_core::net::TcpStream, std::net::SocketAddr)`\n   --> src/lib.rs:169:46\n    |\n169 |             let server = listener.incoming().or_else(|e| {\n    |                                              ^^^^^^^ expected (), found tuple\n    |\n    = note: expected type `()`\n               found type `(tokio_core::net::TcpStream, std::net::SocketAddr)`\nAttempt 3: Return an Err:\nrust\nlet server = listener.incoming().or_else(|e| {\n                println!(\"{:?}\", e);\n                Err(e)\n            }).for_each(move |(sock, addr)| { ... });\nAt least it compiles!!!\nBut it does not solve the problem: returning an error here bubbles up and crashes my server as before. With the only difference of the additional print statement.\nAttempt 4: Return an empty future, assuming it does nothing and Incoming continues with the next connection attempt:\nrust\nlet server = listener.incoming().or_else(|e| -> futures::future::Empty<_, std::io::Error> {\n    println!(\"{:?}\", e);\n    futures::future::empty()\n}).for_each(move |(sock, addr)| { ... });\nThat compiles, but as soon as the first IO error happens the server does not respond anymore. Looking at the docs: https://docs.rs/futures/0.1.16/futures/future/struct.Empty.html it says \"A future which is never resolved.\". Aha, so that is probably blocking my server. So this is not really an Empty future and should be renamed to \"AlwaysBlockingDoingNothing\".\nAttempt 5: Let's try the or_else() after the for_each():\nrust\nlet server = listener.incoming().for_each(...).or_else(|e| -> Result<_> {\n    println!(\"{:?}\", e);\n    Ok(())\n});\nThis compiles, but does not swallow the error. The server still crashes except for the additional print statement.\nAt this point I'm running out of ideas. How can I swallow the IO error and make the incoming future continue?. @sinkuu nice idea for a workarund! Unfortunately that results in an even worse behavior with the attack from above. By ignoring the errors one CPU core jumps to 100% (even if no requests are performed anymore after the attack) and the server is not responding anymore. When trying to establish connections they run into timeouts.\nI assume that happens because some cleanup after accept() errors is missing, which sounds very similar to what is described at https://crates.io/crates/tk-listen : \"Some connection accept errors (like \"connection reset\") must be ignored, some (like \"too many files open\") may consume 100% CPU when ignored. You need to know what to do with them every time\". So it sounds like @tailhook might have figured stuff out in https://github.com/tailhook/tk-listen which I will look into next.. Using tk-listen I can now mitigate the problem and the server does not crash anymore when it has only a few file descriptors with ulimit -n 50. Yay!\nHere is the full source for a resilient Hyper echo server:\n```rust\nextern crate futures;\nextern crate hyper;\nextern crate service_fn;\nextern crate tk_listen;\nextern crate tokio_core;\nuse futures::Stream;\nuse hyper::header::{ContentLength, ContentType};\nuse hyper::server::{Http, Response};\nuse service_fn::service_fn;\nuse std::time::Duration;\nuse tk_listen::ListenExt;\nuse tokio_core::net::TcpListener;\nuse tokio_core::reactor::Core;\nconst TEXT: &'static str = \"Hello, World!\";\nfn main() {\n    let addr = ([127, 0, 0, 1], 3000).into();\nlet mut core = Core::new().unwrap();\nlet handle = core.handle();\nlet handle2 = core.handle();\nlet http = Http::new();\nlet listener = TcpListener::bind(&addr, &handle).unwrap();\n\nlet server = listener\n    .incoming()\n    .sleep_on_error(Duration::from_millis(10), &handle2)\n    .map(move |(sock, addr)| {\n        let hello = service_fn(|_req| {\n            Ok(\n                Response::<hyper::Body>::new()\n                    .with_header(ContentLength(TEXT.len() as u64))\n                    .with_header(ContentType::plaintext())\n                    .with_body(TEXT),\n            )\n        });\n        http.bind_connection(\n            &handle,\n            sock,\n            addr,\n            hello,\n        );\n        Ok(())\n    })\n    // Maximum of 10,000 connections simultaneously.\n    .listen(10_000);\n\ncore.run(server).unwrap();\n\n}\n```\nNow calling ab -c 1000 -n 100000 http://localhost:3000/ in a new shell works, but it does not finish. The last ~200 of 100k requests never finish and at some point ab exists with\nCompleted 10000 requests\nCompleted 20000 requests\nCompleted 30000 requests\nCompleted 40000 requests\nCompleted 50000 requests\nCompleted 60000 requests\nCompleted 70000 requests\nCompleted 80000 requests\nCompleted 90000 requests\napr_socket_recv: Connection reset by peer (104)\nTotal of 99798 requests completed\nWhile ab is in progress I can successfully reach the server manually in my browser, so this might not be a big problem. And it is certainly an improvement by not crashing the server :)\n@seanmonstar: what do you think of using tk-listen as a dependency in Hyper and patching server/mod.rs to do something similar?. The tinyhttp example in tokio-core has the same vulnerability, also filed an issue there.. An alternative solution to this is using std::net::TcpListener to accept connections, as in the Tokio multi threaded server example: https://github.com/tokio-rs/tokio-core/blob/master/examples/echo-threads.rs\nAdvantages:\n no need for tk-listen\n server is resilient and does not crash\n* slight performance increase because request handling is distributed on worker threads with their own Tokio core event loop\nThe downside is that you have more code in your server that you need to reason about and maintain.. Sorry, should have posted a working example: Here is a more resilient HTTP server without tk-listen:\n```rust\nextern crate futures;\nextern crate hyper;\nextern crate num_cpus;\nextern crate service_fn;\nextern crate tokio_core;\nuse std::net::{self, SocketAddr};\nuse std::thread;\nuse futures::Future;\nuse futures::stream::Stream;\nuse futures::sync::mpsc;\nuse hyper::header::{ContentLength, ContentType};\nuse hyper::server::{Http, Response};\nuse service_fn::service_fn;\nuse tokio_core::net::TcpStream;\nuse tokio_core::reactor::Core;\nconst TEXT: &'static str = \"Hello, World!\";\nfn main() {\n    let addr: SocketAddr = ([127, 0, 0, 1], 3000).into();\nlet num_threads = num_cpus::get();\n\nlet listener = net::TcpListener::bind(&addr).expect(\"failed to bind\");\nprintln!(\"Listening on: {}\", addr);\n\nlet mut channels = Vec::new();\nfor _ in 0..num_threads {\n    let (tx, rx) = mpsc::unbounded();\n    channels.push(tx);\n    thread::spawn(|| worker(rx));\n}\n\nlet mut next = 0;\nfor socket in listener.incoming() {\n    let socket = match socket {\n        Ok(socket) => socket,\n        // Ignore socket errors like \"Too many open files\" on the OS\n        // level. Just continue with the next request.\n        Err(_) => continue,\n    };\n    channels[next]\n        .unbounded_send(socket)\n        .expect(\"worker thread died\");\n    next = (next + 1) % channels.len();\n}\n\n}\n// Represents one worker thread of the server that receives TCP connections from\n// the main server thread.\nfn worker(rx: mpsc::UnboundedReceiver) {\n    let mut core = Core::new().unwrap();\n    let handle = core.handle();\n    let http = Http::::new();\nlet done = rx.for_each(move |socket| {\n    let socket = match TcpStream::from_stream(socket, &handle) {\n        Ok(socket) => socket,\n        Err(error) => {\n            println!(\n                \"Failed to read TCP stream, ignoring connection. Error: {}\",\n                error\n            );\n            return Ok(());\n        }\n    };\n    let addr = match socket.peer_addr() {\n        Ok(addr) => addr,\n        Err(error) => {\n            println!(\n                \"Failed to get remote address, ignoring connection. Error: {}\",\n                error\n            );\n            return Ok(());\n        }\n    };\n\n    let hello = service_fn(|_req| {\n        Ok(Response::<hyper::Body>::new()\n            .with_header(ContentLength(TEXT.len() as u64))\n            .with_header(ContentType::plaintext())\n            .with_body(TEXT))\n    });\n\n    let connection = http.serve_connection(socket, hello)\n        .map(|_| ())\n        .map_err(move |err| println!(\"server connection error: ({}) {}\", addr, err));\n\n    handle.spawn(connection);\n    Ok(())\n});\nmatch core.run(done) {\n    Ok(_) => println!(\"Worker tokio core run ended unexpectedly\"),\n    Err(_) => println!(\"Worker tokio core run error.\"),\n};\n\n}\n```\nThis server never crashes because it just ignores errors and keeps on running.\nThis is more primitive than tk-listen because it does not use any timeout at all. The echo server withstands the ab attack, although ab -c 1000 -n 100000 http://localhost:3000/ still hangs at the very end. Same as with tk-listen the server is at least reachable from another browser.. Thanks for the tip on high CPU load. I implemented an error check + thread.sleep() in the example above: https://gist.github.com/klausi/f94b9aff7d36a1cb4ebbca746f0a099f\nWhen ab benchmarking the 2 versions with and without sleep() I did not see a significant difference in CPU usage. In both cases the CPU usage is high because a lot of requests need to be processed. On a typical server today there will be multiple CPU cores so I think it is fine if the socket accepting process spins one core harder in the case file descriptors run out. It does not seem worth the effort to add random sleep() code just because EMFILE errors do not clean up the accept queue behind them.. Good points! Per default Apache Bench does not have keep-alive enabled. The -k option can be used for that, here is the command I used now for testing:\ntime ab -k -r -c 100 -n 10000 http://localhost:3000/\nThe thread sleeping in the request handler is a good idea to see how hard the CPU is used. When I compared the 2 versions with and without EMFILE timeouts the runtime was equal, but the CPU usage was a lot higher in the no timeout version as expected. I then also tried to play a little bit around with the timeout number (10ms vs. 100ms) but could not see a significant difference when running the server with a limited amount of file descriptors.\nThat got me thinking that I might focus a bit too much on this limited file descriptor edge case that I don't really care about. What I want to keep from this exercise is a multi-threaded hyper server (I think we don't have an example for that yet) and a non crashing hyper server when there is heavy load. So now I'm back at using tk-listen with worker threads: https://gist.github.com/klausi/93b57d3abe2c5bc4975b0b9921f2a3c2. I started with a PR to have the sleep_on_error functionality directly in the Hyper server: #1450 \nReviews and feedback welcome!. This test is trying to exhaust available ports on the system to trigger an IO error which makes the server panic. This was failing for me locally, maybe the Travis VM is too slow so that the problem does not occur? I raised the number of requests to 10 million, let's see if that makes a difference.. Yay, Travis is failing now as expected. This test is not super ideal because it has to make that many requests, but on the other hand it is a nice integration test to check if Hyper can keep up when a flood of requests arrives.\nThe next step now is to figure out how to actually fix this and make the test pass.. I think I have to close this because a test case like this has random fails and is not reliable. I had a similar test running in Rustnish, but removed it after failing randomly on Travis CI: https://github.com/klausi/rustnish/commit/e7fcd752dc620dedd4c589efd0f3d1f05eecaf6a\nSorry! Let me know if you have better ideas how to test such an attack.. My current approach to pass down the IP address to my service (a proxy server use case):\n```rust\nlet address: SocketAddr = ([127, 0, 0, 1], port).into();\nlet mut core = Core::new().unwrap();\nlet handle = core.handle();\n// We can't use Http::new().bind() because we need to pass down the\n// remote source IP address to our proxy service. So we need to\n// create a TCP listener ourselves and handle each connection to\n// have access to the source IP address.\n// @todo Simplify this once Hyper has a better API to handle IP\n// addresses.\nlet listener = TcpListener::bind(&address, &handle)\n    .chain_err(|| format!(\"Failed to bind server to address {}\", address))?;\nlet client = Client::new(&handle);\nlet mut http = Http::::new();\n// Let Hyper swallow IO errors internally to keep the server always\n// running.\nhttp.sleep_on_errors(true);\nlet server = listener.incoming().for_each(move |(socket, source_address)| {\n    handle.spawn(\n        http.serve_connection(socket, Proxy {\n                port,\n                upstream_port,\n                client: client.clone(),\n                source_address,\n            })\n            .map(|| ())\n            .map_err(|| ())\n    );\n    Ok(())\n});\nprintln!(\"Listening on http://{}\", address);\ncore.run(server).chain_err(|| \"Tokio core run error\")?;\nbail!(\"The Tokio core run ended unexpectedly\");\n```\nFull source: https://github.com/klausi/rustnish/blob/goal-09/src/lib.rs. @stevedonovan my TCPListener workaround still works with Hyper 0.12:\n```rust\nlet address: SocketAddr = ([127, 0, 0, 1], port).into();\nlet mut runtime = Runtime::new().unwrap();\nlet listener = TcpListener::bind(&address)\n    .chain_err(|| format!(\"Failed to bind server to address {}\", address))?;\nlet client = Client::new();\nlet http = Http::new();\nlet server = listener\n    .incoming()\n    .for_each(move |socket| {\n        let source_address = socket.peer_addr().unwrap();\n        tokio::spawn(\n            http.serve_connection(\n                socket,\n                Proxy {\n                    port,\n                    upstream_port,\n                    client: client.clone(),\n                    source_address,\n                },\n            ).map(|| ())\n            .map_err(|| ()),\n        );\n        Ok(())\n    }).map_err(|e| panic!(\"accept error: {}\", e));\nprintln!(\"Listening on http://{}\", address);\nruntime.spawn(server);\n```. Ah, just found the usual DoS security weakness again with my code from above. If your server needs to handle many requests and runs out of file descriptors then the code from above will panic and your server will exit and stop.\nI wrote about this before and Hyper even has a protection against this built in now - but if you are constructing your TCP listener manually then you are on your own again :-(. By tainted I mean that the client is not usable any more. Performing requests on the tainted client will always yield IO errors although there should not be IO errors.\nYes, I think the sockets are closed because if I run the same example with a second fresh client then the IO error does not occur:\n```rust\nextern crate futures;\nextern crate hyper;\nextern crate tokio_core;\nuse hyper::{Client, Uri};\nuse futures::future::{join_all, loop_fn, Future, Loop};\nuse tokio_core::reactor::Core;\nfn main() {\n    let mut core = Core::new().unwrap();\n    let client = Client::new(&core.handle());\nlet url: Uri = (\"http://localhost/\").parse().unwrap();\n\nlet nr_requests = 30_000;\nlet concurrency = 1000;\n\nlet mut parallel = Vec::new();\nfor _i in 0..concurrency {\n    let requests_til_done = loop_fn(0, |counter| {\n        client\n            .get(url.clone())\n            .then(move |_| -> Result<_, hyper::Error> {\n                if counter < (nr_requests / concurrency) {\n                    Ok(Loop::Continue(counter + 1))\n                } else {\n                    Ok(Loop::Break(counter))\n                }\n            })\n    });\n    parallel.push(requests_til_done);\n}\n\nlet work = join_all(parallel);\ncore.run(work).unwrap();\n\nlet mut core2 = Core::new().unwrap();\nlet client2 = Client::new(&core2.handle());\n\nlet work = client2.get(url.clone()).map(|res| {\n    println!(\"Response: {}\", res.status());\n});\ncore2.run(work).unwrap();\n\n}\n```\nInstantiating a new core2 and client2 works, there are no IO errors when performing the request.\nPanics: Sorry, the first program from above panics because of the unwrap() of course. Because I get an IO error that should not be there.\nSo a primitive solution to this problem is to catch IO errors on Hyper clients, then throw the Tokio core and the hyper client away, create new instances of them and then perform requests.. I'm using the default Apache installation on Ubuntu 16.04, which listens on localhost port 80 and just delivers a static HTML file from /var/www/html/index.html.\nI tried to reproduce this with the hello.rs example from Hyper as well, but the client works as expected in that case. Which could mean that the Apache server does something differently - maybe keeping TCP connections open to the client or similar?\nIn the loop_fn: Yes, during the request flood the same IO error \"Too many open files\" starts to appear, I just ignore it there. I know that during the flood this error can happen. The interesting part is that once the flood is over and I send a single request with the same client to Apache it still errors.. I can now reproduce the problem with the hello.rs Hyper server. The client works fine if you run the program from the op with the URL http://127.0.0.1:3000/ but it fails as described when the URL is http://localhost:3000/. So it seems to me the DNS lookup code in the Hyper client might do something wrong.\nAt least I'm relieved that this is not an Apache specific problem, sorry for the confusion.. Thanks a lot Sean! My workaround for my proxy use case is to hard-code 127.0.0.1 instead of host names for now. That way I can avoid dead Hyper clients because of outdated DNS errors.. Oh, cool, this was merged fast! Sorry about the additional merge commit. I though you would use the squash merge method on Github and did not clean up the commits here. Will do that next time!\nAnd a big thank you to @tailhook, I copied quite a bit of your code and docs!. The test fail on AppVeyor does not seem related to this change. client_keep_alive_connreset() has failed randomly before on other commits on AppVeyor, so I think we can ignore that in this issue.. @seanmonstar good idea with the if let in the match body, implemented that. Ready for review again!. I think we can put this on hold until the new Tokio is integrated and then rewrite this wherever it fits in. . Good point! Not sure what we can do to keep the connection open for a bit before dropping it? Add a future that just sleeps 1 second?. Tried that, but the compiler does not allow let in a match arm, as far as I can see.. ",
    "pkazmier": "It would seem to be simple to implement in Hyper as a short-term fix, but I wonder if there is an opportunity for Tokio to provide Happy Eyeballs capability, so every Hyper (or other network client) that comes along does not have to do so. This would mean that the DNS resolution and TCP connection establishment would need to be moved down into Tokio. Happy Eyeballs is something that most developers aren't going to be aware of, and it probably should be provided lower down in the networking stack. But in the meantime, I'm all for a short-term Hyper-only solution as the client is not reliable for me in its current state.. It is great to see this addressed in Hyper. It is, however, unfortunate that it had to be addressed in Hyper instead of in a lower-layer of the networking stack for Rust. Others not using Hyper or HTTP are going to encounter the exact same issue. Most languages solve this lower in the stack to avoid this very situation. Unfortunately, I'm not familiar with Rust enough to suggest the ideal location.. ",
    "estk": "I'm interested in taking this on as my next issue, but it wont be until im able to wrap up by current pr. That one turned out to be a Doozy!. Hi!\nI'd like to try to take this issue on. After pulling the code and looking around I have a few questions. It seems that the max_buf_size is set in a chain through server/conn.rs -> h1/conn.rs -> h1/io.rs. The actual use case seems to be something like this:\nlet http = Http::new().max_buf_size(...);\nlet conn = http.serve_connection(some_io, some_service);\nSo, where should the error be exposed to the user?\nIt would seem that from an api perspective it would be awkward to have max_buf_size() have any return value besides Self. So should serve_connection return a result that could potentially create a max_buf too small error? Both options dont seem great for me. Hoping the maintainers will have some insight. :)\n. I'd like to take this one on.. Excellent thanks for the head start.. @seanmonstar Is this what you were hoping for?. So, I'm a bit stuck at the moment, my current strategy is to wrap the ServiceFn passed to Http::serve_connection in an Arc so that the h1 Connection can hold a reference to the service in case we want to try an upgrade. The problem is by doing this, somehow NewService is no longer Sync. See the error below for details.\nSo, that seems fine, but the thing that really has me scratching my head is that the ServiceFn though not in Connection directly before was by proxy since it was owned by the h1::Dispatcher. Why is NewService all of a sudden not Sync now?\nI'm fairly new to rust so I feel like I'm a bit out of my depth here, and would really appreciate any help.\n``\n$ RUST_LOG=hyper=trace cargo test --test h2\n   Compiling hyper v0.12.0-pre.0 (file:///Users/evan.simmons/rust/hyper)\nerror[E0277]:::Servicecannot be shared between threads safely\n   --> src/server/conn.rs:536:42\n    |\n536 |                 self.serve.protocol.exec.execute(fut);\n    |                                          ^^^^^^^::Servicecannot be shared between threads safely\n    |\n    = help: the traitstd::marker::Syncis not implemented for::Service= help: consider adding awhere ::Service: std::marker::Syncbound\n    = note: required because of the requirements on the impl ofstd::marker::Sendforstd::sync::Arc<::Service>= note: required because it appears within the typeserver::conn::Connection<::Item, ::Service>= note: required because it appears within the typefutures::future::chain::Chain::Item, ::Future>, fn(::InitError) -> error::Error {error::Error::new_user_new_service::<::InitError>}>, server::conn::Connection<::Item, ::Service>, [closure@src/server/conn.rs:534:31: 534:42]>= note: required because it appears within the typefutures::AndThen::Item, ::Future>, fn(::InitError) -> error::Error {error::Error::new_user_new_service::<::InitError>}>, server::conn::Connection<::Item, ::Service>, [closure@src/server/conn.rs:534:31: 534:42]>= note: required because it appears within the typefutures::MapErr::Item, ::Future>, fn(::InitError) -> error::Error {error::Error::new_user_new_service::<::InitError>}>, server::conn::Connection<::Item, ::Service>, [closure@src/server/conn.rs:534:31: 534:42]>, [closure@src/server/conn.rs:535:30: 535:65]>`\nerror: aborting due to previous error\nFor more information about this error, try rustc --explain E0277.\nerror: Could not compile hyper.\nTo learn more, run the command again with --verbose.\n```. Hey Sean,\nThanks for the excellent and speedy explanation. Those were the two solutions that I had considered and am glad to have you weigh in. This issue feels a bit like playing chess with the compiler.. :). @seanmonstar So, I've now gone down the deconstruction path, and I saw two options:\n\nImplement and into_inner() on the trait.\nWrap the dispatch with an enum such that we can match on if it is a server and return an Option in the Dispatcher::into_inner()\n\nBy the looks of it, by wrapping in the enum I'd have to implement the Dispatch trait on it which seems like a lot of boilerplate and hence probably not the right way to go.\nAfter giving the first option a try I find myself again a bit stuck and would love a tip if you have a sec, I'm getting the following compiler message which is a bit ironic since I dont really care what the type is on client since it never returns Some. Is there a way to tell the compiler that this only returns None? If not, is there any way to reconcile with the compiler, or should I just try the enum option?\n``\n$ RUST_LOG=hyper=trace cargo test --test h2\n   Compiling hyper v0.12.0-pre.0 (file:///Users/evan.simmons/rust/hyper)\nerror[E0207]: the type parameterS` is not constrained by the impl trait, self type, or predicates\n   --> src/proto/h1/dispatch.rs:396:9\n    |\n396 | impl Dispatch for Client\n    |         ^ unconstrained type parameter\nerror: aborting due to previous error\nFor more information about this error, try rustc --explain E0207.\nerror: Could not compile hyper.\nTo learn more, run the command again with --verbose.\n``. Hokay, stuck again. Current issue is below, my guess is that since we are parameterizing for a specificI, we'll need to actually wrap that with a sum type that contains eitherIorRewindedAddrStream`. (There's definitely a better name for that but I'll leave it for cleanup.)\nPS I wrote the RewindedAddrStream because I didn't see a way to rewind io given the type bounds AsyncRead + AsyncWrite.  Is that true?\n``\n$ RUST_LOG=hyper=trace cargo test --test h2\n   Compiling hyper v0.12.0-pre.0 (file:///Users/evan.simmons/rust/hyper)\nerror[E0308]: mismatched types\n   --> src/server/conn.rs:394:43\n    |\n394 |         self.conn.get_or_insert(Either::B(h2));\n    |                                           ^^ expected type parameter, found structserver::tcp::rewinded_add_stream::RewindedAddrStream|\n    = note: expected typeproto::h2::server::Serverfound typeproto::h2::server::Server>, , >`\nerror: aborting due to previous error\nFor more information about this error, try rustc --explain E0308.\nerror: Could not compile hyper.\nTo learn more, run the command again with --verbose.\n. Haha, thanks Sean, yeah part of this is that I've got about 1 month of rust experience. \nI've successfully specialized the type of the `AsyncRead + AsyncWrite` type param to something that can be rewound. Compile issues seem to be behind me at least at the moment, now I'm just scratching my head about the following issue:\n$ RUST_LOG=hyper=trace,h2=trace cargo test --test h2\n   Compiling hyper v0.12.0-pre.0 (file:///Users/evan.simmons/rust/hyper)\n    Finished dev [unoptimized + debuginfo] target(s) in 5.31 secs\n     Running target/debug/deps/h2-ed3b5b7c313e5877\nrunning 1 test\n DEBUG hyper::proto::h1::dispatch > starting poll_catch\n TRACE hyper::proto::h1::conn     > Conn::read_head\n TRACE hyper::proto::h1::conn     > flushed State { reading: Init, writing: Init, keep_alive: Busy, error: None, read_task: None }\n DEBUG hyper::proto::h1::dispatch > done reading flushing\n DEBUG hyper::proto::h1::dispatch > starting poll_catch\n TRACE hyper::proto::h1::conn     > Conn::read_head\n DEBUG hyper::proto::h1::io       > read 103 bytes\n TRACE hyper::proto::h1::role     > Request.parse([Header; 100], [u8; 103])\n TRACE hyper::proto::h1::conn     > State::close_read()\n DEBUG hyper::proto::h1::conn     > parse error (invalid HTTP version specified) with 103 bytes\n DEBUG hyper::proto::h1::dispatch > read_head error: invalid HTTP version specified\n DEBUG hyper::proto::h1::dispatch > or_else of poll_catch\n DEBUG hyper::server::conn        > error polling connection protocol: invalid HTTP version specified\n DEBUG h2::codec::framed_write    > send; frame=Frame::Settings(Settings { flags: SettingsFlags(0), header_table_size: None, enable_push: None, max_concurrent_streams: None, initial_window_size: None, max_frame_size: None, max_header_list_size: None })\n TRACE h2::frame::settings        > encoding SETTINGS; len=0\n TRACE h2::codec::framed_write    > encoded settings; rem=9\n DEBUG hyper::proto::h2::server   > handshaking\n TRACE h2::server                 > Handshake::poll(); state=Handshaking::Flushing(_);\n TRACE h2::codec::framed_write    > flush\n TRACE h2::codec::framed_write    >   -> not a queued data frame\n TRACE h2::codec::framed_write    > flushing buffer\n TRACE h2::server                 > Handshake::poll(); flush.poll()=Ready\n TRACE h2::proto::streams::flow_control > inc_window; sz=65535; old=0; new=65535\n TRACE h2::proto::streams::flow_control > inc_window; sz=65535; old=0; new=65535\n TRACE h2::proto::streams::prioritize   > Prioritize::new; flow=FlowControl { window_size: Window(65535), available: Window(65535) }\n TRACE h2::server                       > Handshake::poll(); connection established!\n TRACE h2::proto::settings              > send_pending_ack; pending=None\n TRACE h2::codec::framed_read           > poll\n DEBUG h2::proto::connection            > Connection::poll; err=FRAME_SIZE_ERROR\n DEBUG h2::codec::framed_write          > send; frame=Frame::GoAway(GoAway { last_stream_id: StreamId(0), error_code: FRAME_SIZE_ERROR })\n TRACE h2::frame::go_away               > encoding GO_AWAY; code=FRAME_SIZE_ERROR\n TRACE h2::codec::framed_write          > encoded go_away; rem=17\n DEBUG h2::proto::connection            > Connection::poll; err=FRAME_SIZE_ERROR\n TRACE h2::proto::connection            >     -> already going away\n TRACE h2::proto::connection            > connection closing after flush, reason=FRAME_SIZE_ERROR\n TRACE h2::codec::framed_write          > flush\n TRACE h2::codec::framed_write          >   -> not a queued data frame\n TRACE h2::codec::framed_write          > flushing buffer\n DEBUG hyper::server::conn              > conn error: http2 general error: protocol error: frame with invalid size\n```\nMeanwhile in a separate term:\n```\n$ curl -vvv --http2-prior-knowledge localhost:3000\n Rebuilt URL to: localhost:3000/\n   Trying ::1...\n TCP_NODELAY set\n Connection failed\n connect to ::1 port 3000 failed: Connection refused\n   Trying 127.0.0.1...\n TCP_NODELAY set\n Connected to localhost (127.0.0.1) port 3000 (#0)\n Using HTTP2, server supports multi-use\n Connection state changed (HTTP/2 confirmed)\n Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0\n Using Stream ID: 1 (easy handle 0x7fa5b0805800)\n\nGET / HTTP/2\nHost: localhost:3000\nUser-Agent: curl/7.54.0\nAccept: /\n\nConnection state changed (MAX_CONCURRENT_STREAMS updated)!\nClosing connection 0\ncurl: (16) Error in the HTTP2 framing layer\n```\n\n\nI'm thinking ive still dropped some bytes somewhere, so that will be my next investigation, I'm thinking I'll tcpdump the traffic and compare with what is available in the rewound io object that I pass to h2.. Working, see pr description.. You were totally right, it looks like it might be a bit of a nightmare to add the checking to the Connection.. @seanmonstar I'm a bit stuck again, it looks to me like things should be working, any idea why the ci seems to only pass on nightly?. Lol, that\u2019s embarrassing, i guess ill blame that on not having coffee yet. The build that i was referring to was the one before. Im mobile now but ill fix it up this evening. @seanmonstar one thing that i cant seem to figure out is why the ci tests fail (but not for every build option) while locally they seem to be fine. Any ideas?. @seanmonstar whew, it looks like we're approaching the finish line on this one. Any further comments or tests you'd like me to add?. Haha thanks @seanmonstar, this has been an excellent learning experience so I'm not quite ready to give up yet. I've addressed the comments you made today, aside from the .http1only() suggestion, which I'm more happy to implement, but I probably wont have time today.\nUnfortunately it seems like I haven't quite fixed the flakey-ness of the CI tests. It really has me baffled since I cannot reproduce it locally and it seems to happen on different rustc's every time. I've even gone to the trouble of running it in a debian docker container to see if I could replicate it there (no luck.) My suspicion is that it is a real issue, in h2 as you said, but without being able to reproduce it locally its very difficult to debug. If you could point me in the right direction there it would be super helpful. Also, if youre ready to just wrap this up yourself feel free, I'm sure I'll learn a ton from the code you add.. Nice, didn't know about this. Thanks for the guidance!. I really like this idea, part of the PR cleanup I was planning was to try to internalize (to the api) all of my changes and I think this is a perfect way to do it! The only other thing I was thinking about was peeking at the first few bytes in Connection and checking against h2::PREFACE before even going down the path of either h1 or h2. The reason for taking this approach would be that you would have a clean separation between h1 and h2. The other benefit is that we dont even have to back stuff out of h1 if we check for the preface.\nThoughts?\nPS I really appreciate all the mentoring on this one, I feel like I've learned so much about rust ecosystem just on this one pr. \ud83d\ude04 . @seanmonstar, it looks like hyper as a project prefers to keep new files to a minimum, is this an appropriate place to put this?. @seanmonstar this is a significant deviation from how other tests are performed, but I'm not really sure how else I would go about it. Any guidance here?. Absolutely!. It seems not, ive removed it. \nSo I know for the future, Is it a rust thing to not include bounds that will be satisfied but are not required? I would think that since this is an intermediate data structure we would want to be as specific as possible about what it contains for the end user.. This is a great rust nugget of knowledge, thanks.. Done. Done. Absolutely, actually I'm not super confident on what is in here, but getting close to something that seems right.. @seanmonstar do you know if there are any guarantees around how many bytes should be written onto buf? If there are none we could drastically simplify this code.. @seanmonstar This the crux of what im concerned about, is it okay that we're not reading out all bytes from a perf/correctness point of view?. Haha sorry, was a bit of a non-question. I think ive answered it myself, I was wondering if there is an undocumented dependency of the read_buf method to read all the bytes possible into the buf in a single call.\nHow I'm doing it here is one of the following per call:\n- Is there a prefix? Read as many bytes in the prefix as possible out, If there are some left, put those back in the prefix field.\n- If there is not a prefix, read direct from the inner\nIn practice this means the buf passed in will not always be filled even though there may be bytes ready to read. I can imagine a situation where there is code relying on a small buffer being completely filled which could break.\n. Excellent info as always.. Yeah, this is something I thought about, I cant remember why I didn't do this, let me try to look through the code and jog my memory.. ",
    "Aaronepower": "I can't seem to divine what is causing these tests to fail. The only difference I've found is that hyper's Uri doesn't have a trailing / with empty path and http::Uri does when converting to string.. Closing since the compat feature was implemented.. ",
    "lqf96": "This is a great idea, but what about handling CONNECT method at the server side (like in a HTTP proxy server)? I think the upgrade function should only provide the underlying I/O object, and it is the user's responsibility to return a proper HTTP response.. Yes, that is indeed a problem. Maybe for HTTP/2 we need two kinds of upgrade, one for the TCP connection and another one for the H2 stream containing the HTTP request. The former one can be used to upgrade from HTTP/2 to something else, and the latter one can be used for CONNECT or (possibly) running WebSocket over H2 stream.. ",
    "idanarye": "Just want to note that the websocket crate already supported upgrading with old sync Hyper. It could do it because the old Request exposed the underlying IO stream. The new async version doesn't.. ",
    "kamalmarhubi": "An added benefit of this approach is making it possible to implement HTTP over unix domain sockets. Having TCP baked in as it is currently would make that rather annoying!. Yeah, was thinking something like that. So long as you think it's a good direction, I'll take a crack at it.\nAnd if the Drop ergonomics thing makes sense, then CookieBuilder<'a> with &'a mut SetCookie inside. Not so sure about that one; thoughts?. Oh and one thing I'm unclear on: how much of the \"typed header\" stuff will remain in Hyper after switching to the http crate's types?. > Hm, on one hand, that seems clever, but on the other, it seems surprising...\nYeah, that was my thought too. Thinking a bit more, it should be possible to avoid a \"commit\" step.\n\nFor 0.12, hyper will have removed hyper::header, and all that was in it will be published as a separate crate (with an altered API to accommodate working with HeaderMaps).\n\nWhat's the timeline for this? Is it worth implementing this against 0.11?. (aside)\n\nThe tokio-proto crate is being de-emphasized.\n\n@seanmonstar is there any discussion to read on this?. (TIL https://github.com/tokio-rs/tokio-rfcs). @seanmonstar how long do you think it'll be for this to steep? I want to take a crack at https://github.com/seanmonstar/warp/issues/9 which I believe is ultimately blocked on this.. Serves me right for the very quick search and glance.... ",
    "xinghun92": "I use a Stream to construct a Request like this.\nlet mut request = ::hyper::Request::new(::hyper::Method::Post, ::hyper::Uri::from_str(\"http://www.google.com\").unwrap());\nlet pool = FsPool::default();\nlet file_read_stream = pool.read(\"test.txt\");\nrequest.set_body(file_read_stream);\nAnd I can not compile it, the error is \nthe trait `std::convert::From<futures_fs::FsReadStream>` is not implemented for `hyper::Body`\nHow to fix it? thank you!. It fails when send this request using client.\n```\nlet mut core = tokio_core::reactor::Core::new().unwrap();\nlet handle = core.handle();\nlet client = Client::new(&handle);\nlet work = client.request(request).and_then(|res| {\n    println!(\"Response: {}\", res.status());\n    println!(\"Headers: \\n{}\", res.headers());\nres.body().for_each(|chunk| {\n    io::stdout().write_all(&chunk).map_err(From::from)\n})\n\n}).map(|_| {\n    println!(\"\\n\\nDone.\");\n});\n```\nThe error is \nlet work = client.request(request).and_then(|res| {\n    |                               ^^^^^^^ expected struct `hyper::Body`, found struct `futures_fs::FsReadStream`. ",
    "jonhoo": "If I want to not use a thread pool for DNS resolution, but instead do it synchronously on the current thread, is creating two Cores like this the only way to do so?. > In the linked example, the Core is dropped immediately\nWhere? core goes into the returned ControllerHandle struct, whereas core_dns goes into the Client, so I don't think either is dropped?\n\nHowever, running them on the same Core is probably also not desirable in 99% of cases. It will completely block the thread while calling getaddrinfo, which could take a couple seconds to complete.\n\nIn this particular case there are no other outstanding requests. I actually want fully blocking, synchronous operation :). Ohh, I didn't realize that Handle implemented Executor! That's much nicer, thanks!. That'd be nice, but is there a particular reason you don't want to expose the io::Error through an explicit as_io_error method? As someone pointed out on IRC when I asked about it, cause() isn't really intended to be used as a way to figure out if a particular error occurred. Part of this is because causes form a chain, and you don't technically know how deep you have to go. And more importantly, the error nesting could change between versions.. Oh, yeah, I think having both is probably a good idea! I think my concern about cause nesting would make it pretty difficult to extract user errors from behind a hyper::Error nonetheless, but at least it would be possible!. @sfackler cause_static?. Also, could we include as_io_error -> Option<&std::io::Error> in this patch?. @sfackler no, that's not true. While it may be true currently, unless hyper explicitly guarantees that any io::Error will only be nested exactly one deep in the cause hierarchy, that could suddenly start failing as more error nesting is introduced.. I'm not sure I agree? It's not inconceivable that hyper at some point got, say, a tokio::Error internally, which then in turn contains an io::Error. Or that it uses something like failure's .context() which adds a layer of indirection to the io::Error. To your second point, I think io::Errors are sufficiently special to warrant them being exposed. For example, an error like AddrInUse the caller can often recover from by falling back to a non-fixed port.. Absolutely true! But as a consumer of the library, I'm unlikely to know if the internals change. Forcing users to go through cause for io::Error means that changing the internals of hyper::Error may be cause for a breaking semver change if it adds or removes nesting.. I chatted briefly to @davidbarsky about this yesterday, and the difference between\nrust\ntokio::run(task);\nand\nrust\nlet mut rt = Runtime::new().unwrap();\nrt.block_on(task);\nis that tokio::run won't return until the Runtime becomes idle (as in, shutdown_on_idle). This is probably because hyper spawns some futures (like the connection pool) which doesn't shut down (and make the Runtime idle) until the Client has been dropped. So, if you change the code to read:\nrust\ndrop(client);\ntokio::run(task);\nI'd guess that it'll work just fine. And that's also slightly cleaner than to just drop the Runtime as you're doing with rt.block_on.. ",
    "mersinvald": "Since this change relaxes the thait requirements should it be concidered as breaking?. Didn't notice the existing PR on the same reason: https://github.com/hyperium/hyper/pull/1275. @seanmonstar that's awesome news! Thank you!. ",
    "raphaelcohn": "see https://hstspreload.org/. ",
    "gabibbo97": "Hello, if no one is working on this I would like to start an implementation. I have made a significant breaking change to the header:\n\nall members are now private\nyou can create the header using a builder-like pattern\n\nI have updated also the documentation\nThis is my first pull-request of all time in Rust \ud83d\ude04 \nwhoops I did upload the wrong version, fixed now. Everything should be ok now. Hi Sean, thanks for your review, from the last time I have edited all of the setters from builder-pattern like to proper setter methods.\nI also agree with you on the preload issue, the RFC tells us that a StrictTransportSecurity header that does not comply with Google's guidelines is still valid so I have removed the check and added a method that checks if your current struct matches the guidelines, in this way I believe that we can manage to parse valid but not Google compliant headers and also check if our new header meets the requisites.\nThe docs have been updated according to this change. ",
    "MoritzFago": "Yes it would be simpler, but i hoped, that i could use the async functions of hyper. ",
    "aturon": "cc @alexcrichton @withoutboats\nGlad to see things heading this way -- please let me know if we can be of any help.. Note that futures 0.2 integration is now landing in tokio, so we'll want to coordinate work here with work in https://github.com/hyperium/hyper/issues/1448.\nTo that end, getting a PR up and merged soon would be helpful, so that we can parallelize some of these API questions with the work on futures 0.2 integration.. @srijs awesome work!. @srijs @seanmonstar \nThe unstable bit is just waiting until futures 0.2.0 is published. We're putting out a beta this afternoon and otherwise are pretty much ready to go. So I would advise not investing time working around that flag.. Thanks for checking this out @seanmonstar! Do you think you could push your branch somewhere? Some of this feedback is hard to understand without context.\nWhen we chatted on Discord, we summarized these issues as:\n\nThe current async fn syntax makes some borrowing situations unergonomic to deal with\nBecause async fn/impl Trait cannot yet be used in traits, it's not possible for Hyper to completely move to the syntax yet (though existential types on nightly might be enough -- that still needs to be tried).\nBecause of the previous item, this conversion attempt still required a lot of manual futures, which means passing context arguments around.\n\n\nMore in-depth responses:\n\nHaving async fn send_request(&self) -> Result<Response, Error> automatically make the future borrow &self is surprising. I wish the compiler could notice that I wasn't actually needing anything to be borrowed.\n\nYep -- we talked about this some on Discord, but it's worth elaborating here. I think this is one of the core questions for the design of the async/await syntax, and I agree that the current setup has some pretty annoying downsides. Finalizing this syntax is one of the main blockers to stabilizing async/await. \nI do want to note, however, that it's not an option to determine the borrowing structure by the body of the function -- it needs to be driven purely by the signature (with whatever elision rules we decide on).\nI'll get a general issue started for discussing alternatives and ping here once that's ready.\n\nError messages are better than ever!\n\nIs this related to futures 0.3? In general impl Future and async/await address this problem by making the involved types opaque. So presumably you're hitting this with some combinator-heavy code and would see similar things in 0.1?\n\nFixing the above issue by changing to fn send_request(&self) -> impl Future03<..> { async move { .. } } means lots of a functions that don't need to borrow any arguments have an extra level of indentation, just because.\n\nYep, the ergonomic \"cliff\" around different borrow modes here is suboptimal. This is directly connected to the first item, and is part of the design space there.\n\nMany of those functions have several lines of copying config off self into local bindings at the top of the functions now. Feels gross, but it also clicked why if I think of async { similar to a closure.\n\nThis is one place where pointers to code would help -- it's hard to say much about this without context. In particular, it's worth trying to see whether borrowing in this context is possible.\nBut in general, yes async blocks are essentially unit-taking async closures.\n\nHaving switched Service to have a type Future: Future03<..> + Unpin;\n\nThis is another place where seeing the diff would be helpful.. Oops, sorry, @seanmonstar and I talked about this last night but I neglected to follow up with a comment.\nTL;DR: I think this was a design mistake with block_on, and I'm correcting it by having it spawn tasks onto a global thread pool. Eventually that pool will be configurable as well.\nBut bottom line: we want you to be able to assume that you can use cx.spawn freely, even for long-running tasks.. ",
    "soqe": "Had tried to use move. Got a message \"value used after move\". Don't understand how to copy a value and use it after. . ",
    "nieksand": "On line 65 we already do s.contains(\"://\"). \nSo this check on line 93 can never be true.. ",
    "kamyuentse": "\nis that running two instances of wrk at the same time, or 1 for the first port, and then 1 for the second port? I'm worried if only 1 at a time, that means the performance somehow dropped significantly...\n\nprevious multi_server test ran at the same time, 1 test per port. \nusing\n```\n!/bin/bash\nwrk -t4 -c100 -d30s http://localhost:1337 > result1.txt &\nwrk -t4 -c100 -d30s http://localhost:1338 > result2.txt &\n```\nIf just run 1 test on 1 port, the result could be\nwrk -t4 -c100 -d30s http://localhost:1337\nRunning 30s test @ http://localhost:1337\n  4 threads and 100 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    12.38ms    8.25ms 149.64ms   94.21%\n    Req/Sec     2.21k   516.48     2.57k    89.17%\n  264028 requests in 30.02s, 23.17MB read\nRequests/sec:   8795.68\nTransfer/sec:    790.24KB\nsimilar with the server example result. Because in previous test, two Server share the Handle, so the result shown that the ability to deal with the request is a half of the server example.\n\n\nStore a boxed future on the struct that can be selected on. It'd probably be better to not need a box.\nPossibly Server itself shouldn't implement Future, but instead be a builder that can be combined with a shutdown signal to create yet another type, ServerFuture (maybe a better name), that is generic over the shutdown signal.\n\n\nI will try to implement this proposal later.\n. @seanmonstar Should we decouple the reactor from Server, then merge Http and Server, and introduce a type named ServerBuilder?. Can you provide more detail about you use case, and the 'trace' level log.\nI will take a look over it.\nJeff Olhoeft notifications@github.com\u65bc 2017\u5e7412\u670830\u65e5 \u9031\u516d\uff0c\u4e0a\u53487:54\u5beb\u9053\uff1a\n\nWhat would you like to do with this issue? We haven't resolved the issue\nwith futures-fs or futures-cpupool, but using channels from futures works\nfine (as in the send_file.rs example). That is my plan going forward, so\nthis is solved for me.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hyperium/hyper/issues/1377#issuecomment-354514059,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AO0Xad9dorA4LNZm_rWL3KUm6eR_Bgiyks5tFXvCgaJpZM4QitvG\n.\n. You can try to use:\n```\nlet (tx, rx) = mpsc::channel::>(buffer);\nresp = resp.with_header(ContentLength(...))\n                   .with_header(ContentType(...))\n                   .with_status(...)\n                   .with_body(rx);\n\n// Send data using tx\n```\nOr use something like bytes: from-to to split the file transferred in multi-request/response.. Sorry for my laziness. The second way is using the range request. bytes: from-to is one of the header formats.\nRefer RFC-7233: Range Requests for more information.. Check reqwest for ergonomic HTTP Client in Rust.. Hi, I want to have a try, any mentoring instructions for this change?. @enzious I think this is a part of 0.12.x? But update to futures 0.2 is still work in progress.. On my local machine, the test conn_drop_prevents_pool_checkout can pass some time.\nSeems there is a race somewhere, I am trying locate the problem.. I want to know why removing that test case.. @seanmonstar Thanks for your explanation! I don't know whether futures issue cause tokio worker panic, but I think I should cc @carllerche .. @srijs I try to port it last night, but tokio-timer require work with Runtime, so in many test cases, res.join(...).wait() not work well. Good luck!. Maybe the \"require\" not correct, use wait() directly  will get a Shutdown error, but it work fine with Runtime::spawn(..). I can't find a doc clarify this behavior. Maybe it can work with the current_thread.. ",
    "sinkuu": "What about filtering out Errs?\nrust\nlet server = listener\n    .incoming()\n    .then(|x| future::ok::<_, ()>(x.ok()))\n    .filter_map(|x| x)\n    .for_each(|(sock, addr)| {\n        println!(\"{:?} {:?}\", sock, addr);\n        Ok(())\n    });. Type-position macro?\n```rust\n[cfg(impl_trait_available)]\nmacro_rules! impl_trait_or_box {\n    (ty: $($t:tt)+) => {\n        impl $($t)+\n    };\n    (expr: $e:expr) => {\n        $e\n    };\n}\n[cfg(not(impl_trait_available))]\nmacro_rules! impl_trait_or_box {\n    (ty: $($t:tt)+) => {\n        Box<$($t)+>\n    };\n    (expr: $e:expr) => {\n        Box::new($e)\n    };\n}\nfn method(...) -> impl_trait_or_box!(ty: Future + Send) {\n    ...\nimpl_trait_or_box!(expr: res)\n\n}\n```. ",
    "aep": "am i missing something here? How does sleeping prevent anyone from just exhausting FDs by leaving connections half open? SYN is essentially free.. running into this too. blocks https://github.com/rusoto/rusoto/pull/1074. @seanmonstar wrap_stream which immediately  returns Ok(Async::Ready(None))\nusing Body::empty() works fine for now. yep, no idea how to do this correctly. \nI would prefer if it didn't chunk at all, since there are cases where you might want to take the stream and just send whatever you want yourself (websocket for example)\nbut for rusoto, this hack works fine: https://github.com/rusoto/rusoto/pull/1074/commits/ed67c8364044668d2af7fdd5ab2b04d0e464b156#diff-77037ac1da2b41727b3e95f3c007f331R370. ",
    "MarcAntoine-Arnaud": "Yes it look like a network issue (I have test on other provider and it works as attending). ",
    "cramertj": "In particular, this is nice when using tokio_io::io::copy to copy the body into an AsyncWrite. Currently, this looks like:\nrust\nres.body().fold(sock, |sock, chunk| {\n    tokio_io::io::write_all(sock, chunk).map(|(s, _)| s)\n})\nWith Body: AsyncRead, you can do:\nrust\ntokio_io::io::copy(res.body(), sock). > an adapter of  Stream<Item=impl AsRef<[u8]>> to AsyncRead\nYeah, I guess I'd expect such a thing to exist in some form or another. Do you have any thoughts about how to make these types line up better? The fold works, but it's definitely not very intuitive.. So, what I want then is probably something like res.body().forward(my_async_rw.framed(bytes())) where bytes() is something like https://github.com/tokio-rs/tokio-io/pull/78 ? Interestingly, even this only works because my AsyncWrite also happens to be an AsyncRead-- if it wasn't, framed wouldn't be available.\nEdit: if that were the case, I could still used FramedWrite::new.. @seanmonstar In order for the stream.forward trick to work, the type has to implement Sink with SinkItem = hyper::Chunk. Maybe this could work in the future when https://github.com/alexcrichton/futures-rs/issues/623 is resolved so that AsyncWrites could automatically implement Sink and accept items of all T: AsRef[u8].. @seanmonstar SGTM-- I'll keep this in mind to come back to once alexcrichton/futures-rs#623 is resolved.. I'm super excited for this and would be interested in helping out! futures-0.2 is nearly code-complete, so we could probably get started soon. Do you have a branch you'd like PRs submitted to?. > Are they not satisfied with Executor bounds?\nExecutor in 0.1 is generic on the type of future it can execute, so there's no way to request and Executor that can execute the required (private) future type (H2Stream<F, B>).\n\nAre you trying to be generic over the executor also? Since there is E = Exec on the structs, you should be able to use it by just omitting the second generic, right?\n\nYes, the purpose of my question was to allow callers to specify their own executor.. Yeah, ideally you'd have something like E: for<T: Future<Output = ()> + Send> Executor<T>, but alas the trait system isn't there yet.. ",
    "ry": "@seanmonstar Can you suggest a way to turn a Body into an AsyncRead ?\nI guess the reason why there's overhead in presenting Body as an AsyncRead is that Body promises to delivery a \"Chunk\" - which I infer corresponds to chunks in transfer-encoding: chunked. These chunks are not bounded in length, and so cannot be guaranteed to be written completely into the buffer supplied by poll_read() - and therefore it would require internal buffering to present an AsyncRead?  Do I have this right?\nIf the above is correct, it seems the problem is that Body is too high-level of a concept. It would be desirable to have lower-level body which didn't promise to deliver complete chunks, but just parts of the body as they arrived.. ",
    "davechallis": "@seanmonstar Yeah, that is a silly URL length :) It came up as we're investigating migrating a Java HTTP service to a Rust one, so have some extensive tests we're running against both to ensure it's suitable for our purposes (as well as usual benchmarks, we're also seeing how it handles broken data, huge data, etc.).. ",
    "haselhorst": "Thanks a lot for this fast fix!. ",
    "walfie": "Was this bug reintroduced at some point? I'm upgrading an app from hyper 0.11.1 and I'm having a similar issue on hyper 0.11.18. The Transfer-Encoding header is being added to requests that have an empty body.\nCode\nCargo.toml\n```toml\n[package]\nauthors = [\"Example\"]\nname = \"hyper-chunked-get-error\"\nversion = \"0.1.0\"\n[dependencies]\nfutures = \"0.1.18\"\nhyper = \"=0.11.18\"\ntokio-core = \"0.1.12\"\n```\nsrc/main.rs\n```rust\nextern crate futures;\nextern crate hyper;\nextern crate tokio_core;\nuse hyper::{Client, Method, Request};\nuse tokio_core::reactor::Core;\nuse futures::{Future, Stream};\nfn main() {\n    let mut core = Core::new().unwrap();\nlet client = Client::new(&core.handle());\n\nlet uri = \"http://localhost:9000\".parse().unwrap();\nlet mut request = Request::new(Method::Get, uri);\nlet body: &[u8] = &[]; // Set empty body\nrequest.set_body(body);\n\nlet response = core.run({\n    client\n        .request(request)\n        .and_then(|resp| resp.body().concat2())\n}).unwrap();\nprintln!(\"{:?}\", std::str::from_utf8(&response).unwrap());\n\n}\n```\nRunning\nWhen I run it, e.g.,\n```\nListen to port 9000\nwhile true; do nc -l 9000; done\nIn a different shell\ncargo run\n```\nI get as output (from nc), for any version of hyper >=0.11.2:\n```\nGET / HTTP/1.1\nHost: localhost:9000\nTransfer-Encoding: chunked\n0\n```\nIf I downgrade to hyper 0.11.1, I get:\nGET / HTTP/1.1\nHost: localhost:9000\n(no Transfer-Encoding header, as I would expect)\nor maybe I'm doing something wrong? I could open a separate issue if it's actually a different problem.. adpaters -> adapters. tryig -> trying. ",
    "jolhoeft": "The only configuration we are doing is keep alives. For testing we are using our default, which is to enable them.\nThe configuration is all done in https://github.com/jolhoeft/nickel.rs/blob/0aa741ea2977821aee9079fe29a57ba1eaeb3c2c/src/server.rs, specifically the serve method:\n```rust\n    pub fn serve(mut self,\n                 addr: &SocketAddr,\n                 keep_alive_timeout: Option,\n                 thread_count: Option,\n                 verbose: bool)\n                 -> HttpResult<()> {\n        let arc = ArcServer(Arc::new(self));\n        let mut http = Http::new();\n    if let Some(threads) = thread_count {\n        // override the default set in Server::new\n        self.fspool = FsPool::new(threads);\n    }\n    http.keep_alive(keep_alive_timeout.is_some());\n    let server = http.bind(addr, move || Ok(arc.clone()))?;\n\n    if verbose {\n        match server.local_addr() {\n            Ok(a) => { println!(\"Listening on http://{}\", server.local_addr().unwrap()); },\n            Err(e) => { println!(\"Error getting socket: {:?}\", e); }\n        };\n        println!(\"Ctrl-C to shutdown server\");\n    }\n\n    server.run()\n}\n\n``. I will try 0.11.8 shortly. In the meantime, I tried a different approach. I used a scoped thread pool (thescoped-pool` crate, I have a use case that needs scoped threads) and oneshot::channel. This is working all the time so far. The code:\nrust\n        let (tx, rx) = oneshot::channel();\n        self.pool.scoped(|scope| {\n            scope.execute(move || {\n                let mut file = match File::open(path_buf) {\n                    Ok(f) => f,\n                    Err(e) => { tx.send(Err(e)); return; },\n                };\n                let mut buf: Vec<u8> = Vec::new();\n                match copy(&mut file, &mut buf) {\n                    Ok(_) => { tx.send(Ok(buf)); },\n                    Err(e) => { tx.send(Err(e)); },\n                };\n            })\n        });\n        let body: ResponseStream = Box::new(rx.\n                                            into_stream().\n                                            map_err(|e| HyperError::from(io::Error::new(io::ErrorKind::Other, e))).\n                                            and_then(|r| match r {\n                                                Ok(r) => Ok(Chunk::from(r)),\n                                                Err(e) => Err(HyperError::from(e)),\n                                            })\n        );\n        self.origin.set_body(body);\n        Ok(Halt(self))\nI thought this was what futures-cpupool was doing, so I'm puzzled why this works and that sometimes fails.. My tests with 0.11.8/server.np_proto() and the futures-cpupool approach continue to fail intermittently.\nI'm seeing the same  behavior on both Linux and Windows (gcc toolchain). I.e. futures-cpupool fails intermittently, and my oneshot::channel approach works reliably.. I suspect this is an issue in futures-cpupool, but I don't understand the workings there enough to be sure.. Yes, the futures-fs approach is streaming, but the futures-cpupool approach I tested against is also buffering into a Vec:\n```rust\n        using futures-cpupool\n        let stream = self.cpupool.spawn_fn(|| {\n            let mut file = match File::open(path_buf) {\n                Ok(f) => f,\n                Err(e) => { return future::err(e) },\n            };\n            let mut buf = Vec::new();\n            match copy(&mut file, &mut buf) {\n                Ok(_) => {\n                    eprintln!(\"Got buf: {:?}\", &buf[0..16]);\n                    future::ok(buf)\n                },\n                Err(e) => future::err(e),\n            }\n        }).into_stream().\n            map(|b| Chunk::from(b)).\n            map_err(|e| HyperError::from(e));\n    let body: ResponseStream = Box::new(stream);\n    self.origin.set_body(body);\n    Ok(Halt(self))\n\n```\nMy next thought is to migrate the oneshot::channel approach to mpsc::channel so that streaming large files is feasible. . What would you like to do with this issue? We haven't resolved the issue with futures-fs or futures-cpupool, but using channels from futures works fine (as in the send_file.rs example). That is my plan going forward, so this is solved for me.. It is tricky to reproduce. It only occurs with the nickel.rs test harness. Loading pages through a browser always works. I suspect there is some timing issue that the test harness is triggering more regularly than a browser would.\nI think the approach would be to modify the send_files.rs example to use futures-cpupool, then rig up a test harness similar to nickel's and see if that can trigger it. That is probably the best way to get trace level logging too. I expect trace on the nickel test harness would be a vast amount of data.\nI'll see if I can get to this in the next week or so.. @kamyuentse , I go in more detail in the futures-fs issue https://github.com/seanmonstar/futures-fs/issues/4. The code I am using is present there.. Just getting a chance to look at this. That does sound like a possible cause, and should be fixed in any case.. I reworked the clients in the test harness as you suggested, and that seems to have resolved the problem with files streaming in futures-cpupool. I understand why it was failing now, although it is unclear why it was sometimes succeeding. Is there some buffering going on in tokio, so sometimes the read would complete before the core and client were dropped?. The AppVeyor failures don't appear to be related to this PR. Possibly. I wrote it because I realized I was misunderstanding how to get the response body out of the request body. I was thinking of it as a series of transforms on the request body until I had the response body, but couldn't figure out how to bail early with an error status if I needed to. I eventually realized you transform the request body into a response future. You create a new future/stream for the response body.\nHaving written that, it does sound like a very useful thing for the guide.. I will give it a try. I expect it will take me a couple days. Clear prose is harder to write than code.\nDo you want to merge this in separate from that? I see the example and the guide as two different but related things.. Oddly my experience is the reverse. I look for examples before a detailed guide. I find a good example can give me a better high level view of how everything goes together. People have a wide range of learning styles, though, and I think we need both.\nMy approach on the guide is to explain this example in more detail, and add comments on how to approach Json processing, and possibly spawning threads for generating response bodies.. Two threads are not needed. I had a mental block, thinking I could only have one channel per thread, which isn't true. I've updated this example. There are still two versions, because the non-streaming version is simpler for small amounts of data/processing.. Thank you, that was just the clue I needed. I'll have another PR for you shortly.. Fixed, and PR merged, closing.. I don't understand the Travis errors. They are failing claiming I am not using use std::ascii::AsciiExt;, but only in nightly and beta. I am using that import though, and when I build with nightly/beta locally, everything is fine.. Odd that I can't reproduce it locally, but it should be fixed now.. The small buffer is deliberate since the test file is so small. There is a comment about that, but further up the file.. Yes, the buffer is too small for speed, this is just to illustrate how to do it. Real world applications will need to use a larger buffer, which is mentioned in a comment, although perhaps that should be next to the buffer allocation so it doesn't get missed.\nThe bounds are confusing me. It is specifying a range that is simply all the data that was just read into the buffer. From my reading of the Read trait's docs, implementers are just supposed to overwrite whatever is there, so specifying a full range should be unnecessary. I tested various buffer sizes, and never saw a problem with partial buffers.. Ok, I tested, and you are right, we are getting trailing data, but the browser is ignoring them. I was confusing it with a Vec.. I've tended to think of it as the body stream, being a futures::Stream containing the body of the request or response. Would BodyStream work as a trait name?. Thank you, I missed this when it first came through. It seems reasonable to start a Nickel migration on a branch, but maintain the current version for a while.. ",
    "ernestas-poskus": "Still getting:\n```\nERROR:tokio_proto::streaming::pipeline::client: pipeline error: unexpected end of file\nERROR:tokio_proto::streaming::pipeline::client: pipeline error: end of file reached before parsing could complete\n```\nwith \n[[package]]\nname = \"hyper\"\nversion = \"0.11.8\". > Do you mean the logs are incorrect?\nI am not sure if they are correct or not, need to add more verbosity.. ",
    "biluohc": "To avoid large file wasted memory.\nRead  a(some) u8 from File and write it to socket , then repeat the process? \n. Oh, Thanks you very much.\nBut I do not understand the second method?\nWhat's is the bytes, this crate?\nCould you give a example?. Oh, but HTTP Range Requests is another thing.. ",
    "lnicola": "See also https://docs.rs/futures-fs/0.0.3/futures_fs/.. Can you try with https://github.com/hyperium/hyper/commit/7fe9710a98650efc37f35bb21b19926c015f0631? I ran into what looks like the same issue and that commit fixed it for me.. @unixpickle FYI, hyper 0.11.25 is now out.. @bluetech there's a saying that goes like \"make the easy things easy and the hard things possible\". I think it works well in this case.. This is what I had in mind with https://github.com/hyperium/hyper/pull/1505, but it's quite possible it's not general enough.. I'm not sure how to do that without running into conflicting implementations :confused:.. @scottlamb #1516. I also tried the following approach, but it seems to overlap with the other From implementations.\nrust\nimpl<S> From<S> for Body\nwhere\n    S: Into<\n        Box<Stream<Item = Chunk, Error = Box<::std::error::Error + Send + Sync>> + Send + 'static>,\n    >,\n{\n    #[inline]\n    fn from(stream: S) -> Body {\n        Body::new(Kind::Wrapped(stream.into()))\n    }\n}. I think this is about returning the value of the Content-Length header. hyper doesn't buffer the message, so if the other side doesn't send the header, Body::content_length() has no way of knowing what to return.. @joshleeb Do you want to take this?. Done, I think.. The server tests are ignored because they depend on #1546. We can either leave this open or fix them later.. @joshleeb if you get a chance, can you include a commit to enable the corresponding checks in the tests from #1556? . See https://github.com/hyperium/hyper/issues/189.. This should be implemented in http, not hyper, right?. I don't really expect that additional check to matter too much in the grand scheme of things.\nIndeed, it missed 1.29 by a day.. Make this an array, maybe?. Actually it might be worth treating Connection separately, to avoid this.. https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Connection has a more complete set of headers.. Done. Nit-pick: maybe swap these and make it a struct-like variant (H2 { ... }). Ah, right, fixed.. ",
    "july2993": "thanks for you reply, it's the same as #1304  i even did'n notice that ab send HTTP/1.0 \ud83d\ude22  .. ",
    "letmutx": "This looks great!\nThe channel based approach we discussed also seems to be equally ergonomic and a looks much simpler to implement without adding another type parameter to virtually all types in proto. Is there any reason you prefer this over that?. ```rust\nstruct Upgrade {\n    io: T,\n    response: MessageHead\n    handle: Handle\n}\nfn main() {\n    let client = Client::configure().enable_upgrades().build();\n    let upgrade_rx = client.upgrades();\n    let upgrade_task = upgrade_rx.then(|upgrade: Upgrade| {\n        do_something(upgrade);\n        Ok(())\n    });\n    let handle = client.handle();\n    handle.spawn(upgrade_task);\n    let req = Request::new(Method::Get, \"https://example.domain/\".parse()?)\n    .with_header(Connection::upgrade())\n    .with_header(Upgrade::websocket());\n    let req = client.request(req).and_then(|res| {\n        handle_req(res);\n        Ok(())\n    });\n    core.run(req).unwrap();\n}\n```\nBut come to think of it, that is a lot of boilerplate for a single request. My use case is kind of like a proxy I would make a stream of requests, so I am biased.. > Does a Response get generated and called?\nYes.\n\nWhat goes in the Upgrade struct?\n\nUpgrade struct is right at the top of the example. . I too tried to take a stab at it a while ago. The problem seems to be with the pool. At the dispatcher level, I could extract the io object out of the Conn to the dispatcher(this was ~2 months ago). But the fact that the pool knows it is only as a KeepAlive was a big hurdle. I had to remove the pool or rewrite it. Eventually I gave up.. ",
    "mathstuf": "I doubt it; we're talking to Gitlab which is using Grape for its REST API and I'd expect it to be well-behaved in that respect. I'll check the logs though to see if that's happening.. I'm only seeing 200 OK responses with full JSON data objects.. We see it when running the queries through Rayon, so it could be something to do with saturating reqwest's connection pool. Currently dumping logs out (there's lots of activity and it's taking a while to get a week's worth of logs).. Is there an email address that would be good to send it to? I anonymized it by removing all of the received data bits (they now just say Object() or Array()), but it is 220K which I'd rather not upload directly to github.. ",
    "bradking": "\nWould you be able to test using hyper master, to confirm?\n\nYes, it works as of v0.11.9, thanks!. ",
    "mthebridge": "Ah - apologies, so it isn't (double negatives confused me!).  Just tried enabling no_proto() and makes no difference.  . @seanmonstar No, no body at all - it's a polling GET that returns when a change is detected (see under \"Waiting for a change\" at https://coreos.com/etcd/docs/latest/v2/api.html), and it's expected in our real use case that most of the time it would time out with no body. \nThanks for the performance tip on Timer::default(), though that isn't the cause.\nI've tried doing some code reading and debugging but I'm finding the hyper code quite tricky to get my head around!. Sorry to dispute - but pulling from the latest master (8f6931b3), and switching to use no_proto(), I still see the same problem with the above script.  So there must be another bug..\nWould you prefer this reopened or a new issue?. In fact, I can repro on master by patching your new test as follows.  The key is to return a chunked-encoding with no content-length and no body.  With this code, the drop_client_closes_idle_connections test hangs forever (because the connection never drops).\ndiff\n--- a/tests/client.rs\n+++ b/tests/client.rs\n@@ -673,8 +673,9 @@ mod dispatch_impl {\n             sock.set_write_timeout(Some(Duration::from_secs(5))).unwrap();\n             let mut buf = [0; 4096];\n             sock.read(&mut buf).expect(\"read 1\");\n-            let body =[b'x'; 64];\n-            write!(sock, \"HTTP/1.1 200 OK\\r\\nContent-Length: {}\\r\\n\\r\\n\", body.len()).expect(\"write head\");\n+            // let body =[b'x'; 64];\n+            let body = vec![];\n+            write!(sock, \"HTTP/1.1 200 OK\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n\").expect(\"write head\");\n             let _ = sock.write_all(&body);\n             let _ = tx1.send(());. Yes, that works!  Thanks so much for the speedy fixes.. Sure, I get that.  But it feels to me like having hyper::client::Clients implementation of Service return a Box<Future> would be nicer.  At the moment, I can't write a method that can consume either a hyper:client::Client or my new wrapper, because FutureResponse can't be implicitly converted into Box<Future> or vice versa.\nIn short: I'm not sure what the FutureResponse type gains you.  Why is it a wrapper and not just a type alias for Box<Future<Item=Response, Error=Error>>?. This is what happens when you try and simplify your code down to a minimal example...\nIt's a bit more complicated than that because I need this to be a trait object. :) I have some existing code that uses a Box<Service<...>>, with the same associated types as the Service implementation for hyper:;client:;Client.  And it is that trait object which I want to be able to be either a standard client crated from hyper::Client::new(), or my wrapper type.\nI guess I could always define a new trait and implement that for the existing client and my new type, and then require a boxed version of that trait.  It still feels like a slightly weird asymmetry - I can chain Services together easily on the server side, but it feels much harder to do so on the client side.. Sorry for delay.  I've been back at this and realized that it was our existing other code that was wrong - I've fixed that up and it all works.  Happy to close this down.. ",
    "njaard": "Sometimes you want to write logs and include the remote host in the log.. I guess you could also want it even earlier than that: you establish a TCP connection, log the remote host and then SSL auth fails.. I would normally agree, but fashioning a function that accepts a service and returns an appropriate (Boxed?) server based on what the address looks like is really difficult for someone who doesn't have an exceptionally good understanding of tokio and hyper's types.\nAt least there should be an example (or pre-baked) function for this in hyperlocal (for which this isn't the right place).\nAlso, people might be more inclined to use this feature if they knew how :). > hyper's Server can be constructed with any sort of \"incoming\" stream of connections, such as what hyperlocal provides\n~~Maybe this statement is technically true, but it~~ It is impossible to properly implement something like \"hyperlocal\", as \"hyperlocal\" demonstates, by not actually functioning correctly. Server cannot be constructed with any kind of stream type because to do so, you would need to have access (for example) to common::Exec and friends, and you'd need to impl Server<SomeOtherAddrIncomingType>, which you can't. and SpawnAll only understands tcp::AddrIncoming, and SpawnAll is a private type.\nOne cause seems to be that to replicate the functionality Hyper already has with Tcp sockets but instead with Unix Domain Sockets, one would need to have a copy of pretty much all of hyper/src/server and hyper/src/common (at least), since most of those are used by hyper's TCP support, and most of those are private symbols.\nTherefor I urge you to reconsider this problem. It's much more severe than simply \"Hyper doesn't directly support Unix Domain Sockets\", it's more of a \"Hyper doesn't sanely allow you to extend it with other stream types\".. First, I assert that it's not common enough because it's not easily available.\nAlso please consider how small this patch is compared to how complex hyperlocal is (while not even being correct or fully-featured!). > The existence of an overly complex and not correct library doesn't seem to be a particularly convincing argument that something needs to be inlined into a separate library IMO.\nWell, you're not wrong, but I was intending the statement as a shorthand for the following points:\n\nI do not believe it's possible right now to implement this feature outside in a separate library. I've tried.\nIf it were possible, I believe it would require a lot of duplication of code inside of hyper. As one example, the code that does protocol promotion from Http\u00a01 to Http\u00a02.\nIt's easy to implement this feature correctly inside the current library without any overhead.\n\nAlso:\n* I believe it's correct to do so, for the same reason that std supports the feature directly. > What is insufficient about passing a stream of UnixStream into https://docs.rs/hyper/0.12.14/hyper/server/conn/struct.Http.html#method.serve_incoming?\nTo make one of those, I need to have a copy of SpawnAll which requires a duplication of most of hyper/server/conn/ and hyper/common/.. > Why specifically do you need SpawnAll?\nI truly don't know! Why does hyper need SpawnAll?. I have renamed the classes. I ended up not taking my own advice and I didn't use \"Path\" for any function, instead using UnixIncoming and friends externally and uds internally (so as to not contradict how tcp works, but also mapping sensibly from an unavoidable imbalance in the naming). I'm really confused as to why @sfackler 's code above is so simple, yet my implementation that simply mirrors the tcp implementation is so complex.. Not a lot, but I think it should be there for completeness/correctness.. std calls it a UnixStream (for TcpStream), so I wouldn't feel right about using the same name for something else. Maybe PathIncoming? That is, for consistency, where hyper's tcp implementation calls it \"AddrSomething\", we call this \"PathSomething\".. Well, in that case, it should be actually platform-dependent, since Windows doesn't have Unix Domain Sockets. How does one make a feature depend on another feature (runtime) and also a platform (unix)?. std doesn't define TcpIncoming either :) - std has std::os::unix::net::SocketAddr and std::net::SocketAddr which is what the hyper's tcp AddrIncoming is supposed to wrap.. ",
    "fulara": "But it seems that these are executed sequentially? Is there any way to do it concurrently? Or do I have to spawn mujltiple workers myself?. Great, excellent, apologies for wasting your time.\nYou can close the ticket then.\nJust one more question - I think its more question towards tokio not hyper, so apologies about that.\nIf I wanted to push tasks into core from other thread than the one that is invoking work() how would I go about that? . ",
    "moderation": "@seanmonstar with remote_addr being removed is there an alternative method or is the capability being removed all together?. ",
    "oa-metaswitch": "+1 for getting some way to access the TcpListener. I'm currently relying on getting access to the remote address, and it would be a shame to have to manage the transport layer manually. Particularly now that support for tokio_proto is going away.. Hi Sean.\nThanks for the quick reply, and sorry: I should have been more specific. I've already attempted something like what you describe above, however: hyper tacks on a few headers (transfer encoding, Date header, etc) before sending, and I'd like to log the request as it actually goes out over the wire, including those headers. \nI currently have a tracer that works by implementing a custom connect and wrapping the TcpStream, but to sensibly log the request I then find I have to re-parse it to get the method, headers, body, etc.\nIt would be nice to have a logging callback, maybe somewhere around https://docs.rs/hyper/0.11.12/src/hyper/client/mod.rs.html#193, that could pass a reference to the transport and the request after the extra headers have been added. Is that sensible? Otherwise, is there a way of doing this already?\nThanks.. @sfackler sorry for taking a while to respond. \nI don't really have any examples of this in other client libraries, but I don't think there are many other libraries that would have a need for it. Put differently, I think hyper is a bit more opaque than other HTTP client libraries I've worked with. In particular\n\nIt's agnostic to the transport layer, which makes it hard to access information about the TCP connection.\nIt's also opaque in its request processing, in that it does not give you easy access to the request just before it's sent on the wire. \n\nDon't get me wrong, I think it's great that it works like this, I would just really like some way to special-case for TCP connections when I have a need to access the transport layer.. Thanks! I've got a prototype version up and running and it seems to be working fine. . ",
    "jedisct1": "+1. ",
    "ensc": "@klausi  I do not know how, but Http::bind() seems to workaround the 'static lifetime requirements of the inner function while they still exist when calling handel.spawn() manually.  E.g. I tried to write this code but failed to implement bar().. > On most operating systems, TCP keepalive is enabled by default\nreally?  RFC1122 \"4.2.3.6  TCP Keep-Alives says\" that it MUST be off by default and that's the case with Linux too.  Keepalive parameters can be configured (with Linux) only globally but not per-process.\n\nhyper (with client::Connect or server::Http::serve_*)\n\nmmh... (at least) server::Http::serve_... seem to be very difficulty to use and probably a lot of hyper internal code must be replicated to make it usable like bind().  E.g. (I do not know why, but) bind() allows a lambda expression with non-'static elements, while every try with serve_* fails due to 'static related lifetime issues (which are imo a severe design problem of tokio). \nSee https://gist.github.com/ensc/155b28cbc07af11c3309348f7b19d9df for an example; foo() which uses bind() is ok, while bar() which tries to reimplement parts of hyper's run_until(), fails.\nEnabling TCP keepalive in hyper are a few lines of code (one in Listener::poll() and perhaps some functions to change the default keep alive time).  I can not imagine a case were a (long running) http server does not want to drop dead connections.. ",
    "stevedonovan": "With 0.12, @klausi workaround no longer compiles. Anything further on this issue? It becomes important when providing a webhook for little devices that don't bother to fill in referer.. Thanks, man! This was obvious in hindsight. Shall we keep this open as a marker until 0.12 lands on crates.io?. ",
    "xrl": "@srijs thanks for chiming in! That is correct, the first one is a panic from the reactor, the rest are from calls to a dead reactor.\nI have extract my code and made a single-shot stress tester. It spawns kinesis writer threads and try to send data as quicker as possible.\nYou will need to set up your AWS credentials, either through ENV variables or through the ~/.aws/credentials file. Then you will need a Kinesis topic with writeable shards (I have 80 at time of writing).\nThe code is here: https://github.com/tureus/kinesis-hyper-bug\nroot@doit-1800981089-sz6zt:~/kinesis-hyper-bug# cargo build --release && RUST_LOG=info ./target/release/kinesis-hyper-bug 100 1000 500\n    Finished release [optimized] target(s) in 0.0 secs\nINFO:<unknown>: testing kinesis put_records num_threads=100 num_puts=1000 puts_size=500 stream_name=itsecmon-logs\nERROR:<unknown>: failed to send to kinesis: \"end of file reached before parsing could complete\"\nERROR:<unknown>: failed to send to kinesis: \"end of file reached before parsing could complete\"\nthread '<unnamed>' panicked at 'assertion failed: !self.can_read_head() && !self.can_read_body()', /root/.cargo/registry/src/github.com-1ecc6299db9ec823/hyper-0.11.12/src/proto/conn.rs:262:9\nnote: Run with `RUST_BACKTRACE=1` for a backtrace.\nERROR:<unknown>: failed to send to kinesis: \"connection reset\"\nthread '<unnamed>' panicked at 'failed to retrieve response from reactor: Canceled', libcore/result.rs:916:5\nthread '<unnamed>' panicked at 'called `Result::unwrap()` on an `Err` value: ErrorImpl { code: EofWhileParsingValue, line: 1, column: 0 }', libcore/result.rs:916:5\nthread 'thread '<unnamed><unnamed>' panicked at '' panicked at 'failed to retrieve response from reactor: Canceledfailed to retrieve response from reactor: Canceled', ', libcore/result.rslibcore/result.rs::916916::55. @seanmonstar unfortunately for this bug report, I have fixed my environment. I did more debugging and ruled out hyper/rusoto as the source of my slowness/errors by using other tools (I should have done that earlier... oops!).\nMy AWS account was using a VPN connection to a corporate network. This VPN, or something along the path to AWS services, was messing up my connections. I have moved to a direct connect setup and things are stable and I can no longer reproduce this bug.. I think this bug is now safe to close because I cannot reproduce it.. This issue was first brought up the rusoto project: https://github.com/rusoto/rusoto/issues/914. Thanks! This fixed the issue for me. Things are rock solid from my initial testing.. @seanmonstar when can this be put out in a release?. @seanmonstar my tool appears more resilient now. I can run it at full speed without the reactor dying from a panic. I do see regular outputs of the new IO error you added:\nroot@doit-1800981089-sz6zt:~/kinesis-hyper-bug# cargo build --release && RUST_LOG=error RUST_BACKTRACE=full ./target/release/kinesis-hyper-bug\n    Finished release [optimized + debuginfo] target(s) in 0.0 secs\nERROR 2018-01-31T17:10:32Z: hyper::client: pooled connection was not ready, this is a hyper bug\nERROR 2018-01-31T17:11:49Z: hyper::client: pooled connection was not ready, this is a hyper bug\nERROR 2018-01-31T17:15:16Z: hyper::client: pooled connection was not ready, this is a hyper bug\nERROR 2018-01-31T17:15:58Z: hyper::client: pooled connection was not ready, this is a hyper bug\nERROR 2018-01-31T17:16:00Z: hyper::client: pooled connection was not ready, this is a hyper bug\nShould I create a new ticket for this error?. I updated to 0.11.17 and it has been quiet with ~30 minutes of stress testing. Thanks!. @seanmonstar @srijs why was this work reverted?. ",
    "FalacerSelene": "I'm also being affected by this - for now I've pinned to version 0.11.12.. ",
    "passchaos": "Yeah, the buffer is too small to get a fast download speed, but more importly, the bound is necessary to get the consistent file.. In most cases, the size of the file is not a multiple of that of the 16, so, the last time to read a file to the buffer will not fill the buffer, without boundary, send files will be compared to the original file more than a few bytes.. ",
    "kevinji": "I believe this is fixed by 6ef22da8ea28f630e474a577ac7e39a6d932ab89 and 39e03a91e28ef3d42b8a4d1a70fbca3367779155.. ",
    "PlasmaPower": "Oh, I forgot that was a thing. You're right, the server isn't sending Connection: close. It looks like this is a problem with the server after all. I think it should be sending Connection: close, as it only breaks when multiple requests are grouped into one TCP stream.. ",
    "ChristophWurst": "\nhttps://github.com/hyperium/hyper/blob/master/src/header/common/mod.rs#L226-L253\n\nThis file is gone, hyper::header was removed in https://github.com/hyperium/hyper/commit/f0cdf82fd46d2a166bf36ca83cb81a297ed9a17e.. There should also be documentation about an replacement for hyper::header, which was removed in https://github.com/hyperium/hyper/commit/f0cdf82fd46d2a166bf36ca83cb81a297ed9a17e and it's not a public module anymore. The commit message says The hyper::header module is gone for now -- will it come back? Should http crate types be used instead?. > Should http crate types be used instead?\nI've found the ticket regarding moving hyer::header: https://github.com/hyperium/hyper/issues/189, but the issue was removed from the 0.12 milestone recently. @seanmonstar what's the plan here? Will there be a replacement for hyper::header for the release of 0.12?\nUpdate: found some more info on the topic at https://github.com/hyperium/http/issues/136. ",
    "dbrgn": "Is this supposed to work together with the latest version of hyper_tls? When I simply replace the latest released version of hyper with this git branch, I'm getting this error message:\nerror[E0599]: no method named `build` found for type `hyper::client::Config<hyper_tls::HttpsConnector<hyper::client::connect::HttpConnector>, hyper::Body>` in the current scope\n   --> src/push/gcm.rs:109:10\n    |\n109 |         .build(&handle);\n    |          ^^^^^\n    |\n    = note: the method `build` exists but the following trait bounds were not satisfied:\n            `hyper_tls::HttpsConnector<hyper::client::connect::HttpConnector> : hyper::client::Connect`\nThis is the (HTTP 1 only) code:\n// Create async HTTP client instance    \n    let https_connector = match HttpsConnector::new(4, &handle) {    \n        Ok(conn) => conn,    \n        Err(e) => return boxed!(future::err(    \n            PushError::Other(format!(\"Could not create HttpsConnector: {}\", e))    \n        ))    \n    };    \n    let client = Client::configure()    \n        .connector(https_connector)                                                 \n        .build(&handle);\nOr is this simply a version mismatch that could be resolved with a [patch] section in Cargo.toml?. > @dbrgn that's because hyper-tls is depending on the crates.io version. You'll need to put [patch] in.\nThanks! I had to do this:\n```\nCargo.toml\n[patch.crates-io]\nhyper = { version = \"0.11.18\", git = \"https://github.com/hyperium/hyper\", branch = \"h2\", features = [\"http2\"] }\n```\nAnd then:\ncargo update -p \"hyper:0.11.21\" --precise 0.11.18. **Edit: Disregard the comment below, it doesn't have anything to do with Hyper. Sorry!**\n\n\nI believe this is a problem with hyper and not with apns2: https://github.com/pimeys/apns2/issues/6\nThe application in question is a HTTP1 server with async Hyper, that uses a HTTP2 client to connect to APNS.\nSimplified code:\n```rust\nimpl Service for PushHandler {\n    // Boilerplate for hooking up hyper's server types\n    type Request = Request;\n    type Response = Response;\n    type Error = HyperError;\n// The future representing the eventual response\ntype Future = BoxedFuture<Self::Response, Self::Error>;\n\nfn call(&self, req: Request) -> Self::Future {\n    // ...\n    let apns_future = apns::send_push(...);\n    boxed!(apns_future)\n}\n\n}\n```\nFor some reason the h2 connection to the server is immediately closed. In the log I can find this line:\n\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h2::client: client tx dropped\n\nThis is the full log:\nDEBUG 2018-04-03T10:12:27Z: rustls::client::hs: Server DNS name is DNSName(\"api.development.push.apple.com\")\nTRACE 2018-04-03T10:12:27Z: rustls::client::hs: Not sending CertificateVerify, no key\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h1::conn: flushed State { reading: KeepAlive, writing: Init, keep_alive: Busy, error: None, read_task: Some(Task) }\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h1::dispatch: Dispatcher::poll\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h1::conn: Conn::read_keep_alive\nDEBUG 2018-04-03T10:12:27Z: rustls::client::hs: Session not saved\nTRACE 2018-04-03T10:12:27Z: hyper::client::pool: Pool::put (\"https://api.development.push.apple.com\", Http2)\nTRACE 2018-04-03T10:12:27Z: hyper::client::pool: Pool::put removing canceled parked (\"https://api.development.push.apple.com\", Http2)\nDEBUG 2018-04-03T10:12:27Z: hyper::client::pool: pooling idle connection for (\"https://api.development.push.apple.com\", Http2)\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h1::conn: flushed State { reading: KeepAlive, writing: Init, keep_alive: Busy, error: None, read_task: Some(Task) }\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h1::dispatch: Dispatcher::poll\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h1::conn: Conn::read_keep_alive\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h1::conn: flushed State { reading: KeepAlive, writing: Init, keep_alive: Busy, error: None, read_task: Some(Task) }\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h2::client: client tx dropped\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h1::dispatch: Dispatcher::poll\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h1::conn: Conn::read_keep_alive\nTRACE 2018-04-03T10:12:27Z: apns2::client: Request error: an operation was canceled internally before starting\n WARN 2018-04-03T10:12:27Z: push_relay::server: Error: Push message could not be processed: Push was unsuccessful: Error connecting to APNs\nTRACE 2018-04-03T10:12:27Z: hyper::proto: should_keep_alive(version=Http11, header=None) = true\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h1::role: ServerTransaction::encode has_body=true, method=Some(Post)\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h1::encode: sized write, len = 19\nDEBUG 2018-04-03T10:12:27Z: hyper::proto::h1::io: flushed 155 bytes\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h1::conn: maybe_notify; read_from_io blocked\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h1::conn: flushed State { reading: Init, writing: Init, keep_alive: Idle, error: None, read_task: Some(Task) }\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h1::dispatch: Dispatcher::poll\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h1::conn: Conn::read_head\nDEBUG 2018-04-03T10:12:27Z: hyper::proto::h1::io: read 0 bytes\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h1::io: parse eof\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h1::conn: State::close_read()\nDEBUG 2018-04-03T10:12:27Z: hyper::proto::h1::conn: read eof\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h1::conn: Conn::read_keep_alive\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h1::conn: parking current task\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h1::conn: maybe_notify; notifying task\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h1::conn: flushed State { reading: Closed, writing: Init, keep_alive: Disabled, error: None, read_task: Some(Task) }\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h1::conn: shut down IO\nTRACE 2018-04-03T10:12:27Z: hyper::proto::h1::dispatch: Dispatch::poll done\nCould this be a bad interaction between h1 server and h2 client?. ",
    "MikHulk": "If you want I can test on Free BSD. I could try on VM with this OS.. I have tested on Free BSD 11.1, and hyper run on this OS. I will try to see with kqueue mainteners on NetBSD for help.. ",
    "idubrov": "Ok, this seems to be the test case to reproduce this behavior:\n```rust\n[test]\nfn client_keep_alive_connreset() {\n    use std::sync::mpsc;\n    extern crate pretty_env_logger;\n    let _ = pretty_env_logger::try_init();\nlet server = TcpListener::bind(\"127.0.0.1:0\").unwrap();\nlet addr = server.local_addr().unwrap();\nlet mut core = Core::new().unwrap();\n\n// This one seems to hang forever\nlet client = client(&core.handle());\n// This one works as expected (fails, because second connection is not handled by the server)\n//let client = Client::configure()\n//  .keep_alive(false)\n//  .build(&core.handle());\n\nlet (tx1, rx1) = oneshot::channel();\nlet (tx2, rx2) = mpsc::channel();\nthread::spawn(move || {\n    let mut sock = server.accept().unwrap().0;\n    //sock.set_read_timeout(Some(Duration::from_secs(5))).unwrap();\n    //sock.set_write_timeout(Some(Duration::from_secs(5))).unwrap();\n    let mut buf = [0; 4096];\n    sock.read(&mut buf).expect(\"read 1\");\n    sock.write_all(b\"HTTP/1.1 200 OK\\r\\nContent-Length: 0\\r\\n\\r\\n\").expect(\"write 1\");\n\n    // Wait for client to indicate it is done processing the first request\n    // This is what seem to trigger the race condition -- without it client notices\n    // connection is closed while processing the first request.\n    rx2.recv();\n    let _r = sock.shutdown(std::net::Shutdown::Both);\n\n    // Let client know it can try to reuse the connection\n    let _ = tx1.send(());\n\n    println!(\"we are ready to receive the second connection\");\n    let mut _sock = server.accept().unwrap().0;\n    println!(\"accepted second connection\");\n});\n\n\nlet res = client.get(format!(\"http://{}/a\", addr).parse().unwrap());\ncore.run(res).unwrap();\n\ntx2.send(());\n\nlet rx = rx1.map_err(|_| hyper::Error::Io(io::Error::new(io::ErrorKind::Other, \"thread panicked\")));\ncore.run(rx).unwrap();\n\nprintln!(\"connecting for the second time -- hangs\");\nlet res = client.get(format!(\"http://{}/b\", addr).parse().unwrap());   \ncore.run(res).unwrap();\n\n}\n```\nP.S. Seems like Hyper tries to re-use pooled connection that was closed on the remote. For some reason, write to the socket on the client side succeeds (doesn't return EPIPE), so Hyper hangs forever (if it was reported, though, I would expect getting \"pooled connection was not ready, this is a hyper bug\"). I don't quite understand why \"event Readable | Hup\" event received earlier does not trigger connection to be evicted from the pool.\nP.P.S. I think, there are two issues here:\n\nConnections are not checked when taken from the pool, so closed connections are reused.\nWhen connection is reused, it is not in the same exact state as the new one. It looks to me that important difference is the \"read_blocked\" flag set to \"true\" on reused connection, since it blocks connection from doing \"empty\" read when it is idle. Hacking the code to reset this flags does make the client to fail when it tries to reuse \"bad\" connection (which is not good, but better than simply waiting forever).. >Are you suggesting that when taking the handle from the pool, the connection should have read() called on it again?\n\nYes, that's what I think. It looks to me that new connection does read as the first thing (\"try_empty_read\") whereas reused one does not.\nOn a related note, shouldn't the pool itself have a future associated with it to do the bookkeeping of the connections? Otherwise, closed connections will sit in the pool until they are reused?. ",
    "George3d6": "Sorry, the code is actually wrong, I modified it a lot to figure out how to make it run and this version is plain wrong since it doesn't use the core I created for IO but rather the current thread :/\nThe version of the code I ended up using is:\n```\n    let server_addr = \"127.0.0.1:1834\".parse().unwrap();\n    let server = Http::new().bind(&server_addr,|| Ok(DataServer)).unwrap();\nlet movable_handle = server.handle();\nlet receptor = listener.incoming().for_each(move |stream| {\n    //movable_handle used here to spawn futures\n});\n\nserver.handle().spawn(receptor);\nserver.run();\n\n```\nWhich basically means I'm taking the handle from the server and running everything on whatever  context/core the server is using (which I assume is on the current thread of execution).\nThe alternative would be to create the core and use a handle from it to spawn all processes and I assume that would work, though I'm happier with this (less code and as far as I can tell exact same result).\nWhat I'm unsure of is if there is a way to accomplish this (running two servers on the same event loop) w/o this  \"hack\" and without going into tokio-core, as in, only using things like current_thread and in some way binding the execution of the server to that ?. Wait, so the above snippet of code would create tow reactors ? I assumed that in that case the TCP server would just use the hyper's server thread+notification-loop.\nAlso, a bit ot, but does tokio use epoll instead of poll ? And if so, would this stop hyper from working on non-linux systems ? Or would it just fall back to poll ?. I'm not using current_thread anymore, but yes, the TCP server is created using Tokio not tokio_core and ps shows the program apparently spawns to threads... -_-.\nI'm quite unsure why the TCP servers would use it's own thread though, I spwan it using the server's handler and I spwan the futures inside it's callback using the same handler (not current thread).\nCan a process two separate futures be spawned on the same handler but use different threads to run ? Or does the server just start a new thread by default when I call server.run(); and the main thread stays inactive ?. ",
    "colindean": "My intended outcome for this was the inclusion of recommendations in the\ndocumentation. That there aren't good examples means there may be work\nfor someone to do, even if that someone is me-a-few-months-from-now.\n. ",
    "teythoon": "We need SOCKS support in the client.  I realize how to use a custom connector, my question rather is if I (or someone else) implements a SocksConnector, does she have to duplicate the functionality of client::HttpConnector or can one somehow compose the Services to avoid duplication.. So I started implementing this, and as anticipated I'm at the point of more or less completely copying hyper/client/connect.rs.  So either I'm still confused (very well possible), or you pointed me in the wrong direction.\nhyper-tls uses hyper::client::HttpConnector, or any other connector, like the proposed SocksConnector.  That is nice, but that is in fact the other direction (layering Services on top of say hyper::client::HttpConnector).\nMy question was whether and how it is possible to make hyper::client::HttpConnector use the SocksConnector to establish a TCP connection.. ",
    "ParisLiakos": "Yeah, i already did that, hyper::Method::Extension(\"UNLINK\".to_string()) works fine, thanks :+1: \nIf other HTTP libs dont include them they i was probably wrong :) I came across them frequently though.\nI guess we should draw the line somewhere, otherwise we would probably have to include all of https://www.iana.org/assignments/http-methods/http-methods.xhtml . ",
    "BatmanAoD": "Disclaimer: I am not a web developer, either frontend or backend.\nSwallowing errors by default seems like a terrible idea to me. This is the best way to make unreliable and difficult to debug software. In fact, JavaScript's \"swallow errors by default\" design philosophy is perhaps the primary reason why I'm not a web developer; I was hoping that a full-stack Rust framework (with WebAssembly on the frontend) would make the idea more appealing to me, because Rust seems to have precisely the opposite design philosophy.\nHowever, it does seem that for a DoS attack or heavy load, the server needs to be able to ignore requests for some short period of time. But the user should still be able to do something with the specific errors that are generated.\nSo my suggestion would be to permit users to specify callbacks to invoke when specific errors occur, or possibly a generic callback invoked when any ignored error occurs.\nA reasonable default behavior might be to automatically set up these callbacks to simply log the error. That would accomplish the goal of making robust server setup easier, while also ensuring that there's still an easy way to discover and investigate possible bugs--or, in a production environment, actual attempted DoS attacks.. ",
    "jnferner": "Thanks for quick reply! You're right, they both have their strengths. Personally, which one would you default to when writing a new service?. Thanks again :). ",
    "earthengine": "Technically, Service should be linked to a FnMut not Fn, as the Service::call method is like\nrust\nfn call(&mut self, req: Request<Self::ReqBody>) -> Self::Future\nand accepts a &mut self.\nIf it could accept FnMut it can accept more closures. Restricting to Fn makes the closure cannot modify internal states and so limits the functionality.\nAnother option is FnOnce + Clone. This will enable capturing immutable states but does not have lifetime issues.. ",
    "DustinByfuglien": "Ops.. I'm accidentally close a issue.\nI agree. Two exports of one thing brings some discourage.. Thanx.\nhyper::Service sounds reasonably.. ",
    "enzious": "With the new tokio, can http::client::HttpConnector::new_with_executor(...) be used with a current_thread TaskExecutor? It is requiring Sync. ",
    "dataf3l": "I'll check it out. @seanmonstar Thank you, that solved my problem, I'm now using these Cargo.toml file:\n[dependencies]\nfutures = \"0.1.17\"\nhyper = \"0.11.22\"\npretty_env_logger = \"0.2.2\"\ntokio-core = \"0.1.15\"\nand that seems to have solved the problem, Thank you for your help!. ",
    "danneu": "@dataf3l If you make your Response body a Box<Stream<Item = hyper::Chunk, Error = hyper::Error>> instead of the default hyper::Body, then all you need to do is return a response from your service that has a stream body. Response::new().with_body(stream)\nHere's a server that will make a bunch of http requests and stream the responses to the client: https://play.rust-lang.org/?gist=c0f2e737c1acda435d20376330bffb55&version=nightly\nIf you boot it locally, curl http://localhost:3000 will show the replies streaming in as the server receives them.\nThey key is type Response = hyper::Response<Box<Stream<Item = Chunk, Error = hyper::Error>>> in the Service instead of type Response = hyper::Response<hyper::Body>.\nYou can create a streaming body with hyper::Body. It's just not as straight forward.\nThe other issue you might run into is how to actually create a stream from your data. For example, maybe you want to read 32kb chunks of a file at a time and send those chunks. A quick solution would be to use https://docs.rs/futures/*/futures/stream/fn.unfold.html and https://doc.rust-lang.org/std/os/unix/fs/trait.FileExt.html#tymethod.read_at for random access.. Sweet, thanks for illuminating. I look forward to trying 0.12.x.\n. @seanmonstar Great stuff. I made my two issues at a bad time. Didn't realize hyper was in the middle of a transition.\nLooks good, thanks.. ",
    "russmack": "The https://hyper.rs/guides use tokio-core which is marked for deprecation.. ",
    "ubnt-intrepid": "It is right that  the attention to implementation is required.\nI've also noticed that this method cannot deal with the context generated after calling Service::call (i.e. generated as a resolved value of Service::Future).  As in the above example, it could be solve the problem by passing the value of Future held in in_flight, but I think this is not a smart solution.\nA better way is that Response<T> (the resolved value from Future) has an additional field.  It may occur some breaking changes involving http crate.. I've understood. Continually use the current API and identify the problems.. When the http1_only mode is added, the behavior when the argument of http2_only(enabled) is false becomes undefined (there are two possible modes whether the fallback is required or not).\nIt seems to be better to separate the configuration for the protocol (using HTTP/1 or HTTP/2) and upgrading (to enable/disable the fallback to h2 when using h1).. I've just created an PR for resolving this issue, just adding http1_only to Connection and Builder.\nThe flag field http2 in the struct Http has replaced with an enum which has three modes (http1_only, http2_only and fallback).\nWhen http2_only(false) or http1_only(false) are called, the inner mode is set to \"fallback\".. Here is an example of using TLS with tokio_tls::TlsAcceptor:\n```rust\nextern crate hyper;\nextern crate native_tls;\nextern crate tokio_tls;\nuse hyper::rt::Future;\nuse native_tls::{Identity, TlsAcceptor as NativeTlsAcceptor};\nuse tokio_tls::TlsAcceptor;\nfn main() {\n    let der = std::fs::read(\"./identity.p12\").unwrap();\n    let cert = Identity::from_pkcs12(&der, \"mypass\").unwrap();\n    let acceptor = NativeTlsAcceptor::builder(cert)\n        .build()\n        .map(TlsAcceptor::from)\n        .unwrap();\nhyper::rt::run(\n    hyper::Server::bind(&\"127.0.0.1:3000\".parse().unwrap())\n        .acceptor(move |io| {\n            acceptor.accept(io)\n        })\n        .serve(|| {\n            hyper::service::service_fn_ok(|_| {\n                hyper::Response::new(hyper::Body::from(\"Hello World!\"))\n            })\n        })\n        .map_err(|e| eprintln!(\"server error: {}\", e));\n);\n\n}\n```\ntokio-rustls and tokio-openssl also provide the similar signature of method, so they could be used the same procedure.. I'm closing this PR because the proposed method cannot have a way to access the TLS transports after the handshake process is completed.. You could obtain remote address directly from the transport by using make_service_fn, as follows:\n```rust\nuse hyper::{\n    Body, Request, Response,\n    service::{make_service_fn, service_fn_ok},\n    server::conn::AddrStream,\n};\nlet make_svc = make_service_fn(|s: &AddrStream| {\n    // acquire the remote address from the transport.\n    let remote_addr = s.remote_addr();\n// build a `Service` with the acquired remote address.\nservice_fn_ok(move |_: Request<Body>| {\n    Response::new(Body::from(format!(\"Hello, {}\", remote_addr)))\n})\n\n});\nServer::bind(&\"127.0.0.1:4000\".parse()?).serve(make_service)\n```\n. The benchmark result on my environment:\nmaster:\ntest proto::h1::role::tests::bench_parse_incoming               ... bench:       3,199 ns/iter (+/- 1,142) = 274 MB/s\ntest proto::h1::role::tests::bench_parse_short                  ... bench:         282 ns/iter (+/- 10) = 141 MB/s\ntest proto::h1::role::tests::bench_server_encode_headers_preset ... bench:         246 ns/iter (+/- 13) = 439 MB/s\ntest proto::h1::role::tests::bench_server_encode_no_headers     ... bench:          34 ns/iter (+/- 0) = 2235 MB/s\nthis PR:\ntest proto::h1::role::tests::bench_parse_incoming               ... bench:       3,229 ns/iter (+/- 1,014) = 271 MB/s\ntest proto::h1::role::tests::bench_parse_short                  ... bench:         286 ns/iter (+/- 6) = 139 MB/s\ntest proto::h1::role::tests::bench_server_encode_headers_preset ... bench:         256 ns/iter (+/- 20) = 421 MB/s\ntest proto::h1::role::tests::bench_server_encode_no_headers     ... bench:          34 ns/iter (+/- 0) = 2235 MB/s\n. Fixed the patch to make the number of branch to be the same as the original.\n\nbenchmark result\nmaster:\n\n```\ntest proto::h1::role::tests::bench_parse_incoming               ... bench:       3,176 ns/iter (+/- 74) = 276 MB/s\ntest proto::h1::role::tests::bench_parse_short                  ... bench:         280 ns/iter (+/- 4) = 142 MB/s\ntest proto::h1::role::tests::bench_server_encode_headers_preset ... bench:         259 ns/iter (+/- 30) = 416 MB/s\ntest proto::h1::role::tests::bench_server_encode_no_headers     ... bench:          34 ns/iter (+/- 0) = 2235 MB/s\n```\n\nthis PR:\n\n```\ntest proto::h1::role::tests::bench_parse_incoming               ... bench:       3,193 ns/iter (+/- 107) = 274 MB/s\ntest proto::h1::role::tests::bench_parse_short                  ... bench:         280 ns/iter (+/- 8) = 142 MB/s\ntest proto::h1::role::tests::bench_server_encode_headers_preset ... bench:         245 ns/iter (+/- 20) = 440 MB/s\ntest proto::h1::role::tests::bench_server_encode_no_headers     ... bench:          34 ns/iter (+/- 0) = 2235 MB/s\n```\n\n. I've added doc comment to them.. Seems better.. ",
    "1tgr": "Thanks, I came up with this wrapper for now:\n```rust\npub struct HttpNoDelayConnector(HttpConnector);\nimpl Service for HttpNoDelayConnector {\n    type Request = Uri;\n    type Response = TcpStream;\n    type Error = io::Error;\n    type Future = Box>;\nfn call(&self, uri: Uri) -> Self::Future {\n    Box::new(self.0.call(uri).and_then(|s| {\n        s.set_nodelay(true)?;\n        Ok(s)\n    }))\n}\n\n}\n```\nWill see if I can put together a pull request to set this directly on HttpConnector. With HTTP, I'm not sure there's a reason not to make TCP_NODELAY the default.. ",
    "yjh0502": "@seanmonstar No. I just tried to test with small buffer size. I choose arbitrary small buffer size which is coincidentally smaller than INIT_BUFFER_SIZE, and found hyper is failing. I think it's better for now to enforce minimum buffer size limit (in this case 8k) rather than breaking with tiny buffer size.. Yes it compiles.\n```\n$ git branch\n* loose_types\n  master\n$ git log HEAD~1..HEAD\ncommit 859115ec18799aab51f18abe0824a4d9a5aa24fd (HEAD -> loose_types, yjh0502/loose_types)\nAuthor: Jihyun Yu yjh0502@gmail.com\nDate:   Mon Jun 11 12:16:10 2018 +0900\nloose type constraint on `serv`\n\n$ cargo clean && cargo check\n   Compiling nodrop v0.1.12\n   Compiling libc v0.2.42\n   Compiling cfg-if v0.1.3\n   Compiling lazy_static v1.0.1\n   Compiling memoffset v0.2.1\n   Compiling byteorder v1.2.3\n   Compiling scopeguard v0.3.3\n   Compiling futures v0.1.21\n   Compiling slab v0.4.0\n   Compiling lazycell v0.6.0\n   Compiling fnv v1.0.6\n   Compiling indexmap v1.0.1\n   Compiling string v0.1.0\n   Compiling try-lock v0.1.0\n   Compiling httparse v1.2.4\n   Compiling crossbeam-utils v0.3.2\n   Compiling log v0.4.2\n   Compiling arrayvec v0.4.7\n   Compiling crossbeam-epoch v0.4.1\n   Compiling iovec v0.1.2\n   Compiling net2 v0.2.32\n   Compiling num_cpus v1.8.0\n   Compiling rand v0.4.2\n   Compiling time v0.1.40\n   Compiling bytes v0.4.8\n   Compiling crossbeam-deque v0.3.1\n   Compiling mio v0.6.14\n   Compiling http v0.1.5\n   Compiling tokio-io v0.1.6\n   Compiling tokio-executor v0.1.2\n   Compiling want v0.0.4\n   Compiling futures-cpupool v0.1.8\n   Compiling tokio-threadpool v0.1.4\n   Compiling tokio-timer v0.2.4\n   Compiling tokio-reactor v0.1.1\n   Compiling tokio-fs v0.1.0\n   Compiling tokio-udp v0.1.0\n   Compiling tokio-tcp v0.1.0\n   Compiling tokio v0.1.7\n   Compiling h2 v0.1.9\n   Compiling hyper v0.12.1 (file:///home/jihyun/repo/git/hyper)\n    Finished dev [unoptimized + debuginfo] target(s) in 7.93 secs\n``. Sorry for late reply. I'm trying to migrate from0.11to0.12. The hardest part is aboutSend, which is not required on0.11because it runs on single tokio core. My code has quite amount ofstd::rc::Rcandstd::ref::RefCellto represent shared internal state across multiple http requests. Those should be changed tostd::arc::Arcandstd::sync::Mutexto beSend. The amount of code for those changes for quite large so I'm trying to find a way to run hyper on single thread, as0.11` does.\nIt seems that even if those constraints are relaxed hyper cannot run on single thread because of an executor, which forces the future to be Send.\nhttps://github.com/hyperium/hyper/blob/d127201ef22b10ab1d84b3f2215863eb2d03bfcb/src/common/exec.rs#L20-L38\nThe problem could be solved by using tokio::executor::current_thread::spawn instead of tokio_executor::spawn [1]. The patch is reasonably small so I think I can maintain patched hyper while migrating to std::arc::Arc.\n[1] https://github.com/yjh0502/hyper/commit/1353f849cb7d693257d37a9d487e87e397a2c574. ",
    "unixpickle": "Tested with 7fe9710 and it worked!. Very speedy fix!. I'm still not entirely sure what the problem was, though.\n7fe9710 supposedly works because it delays EOF until the connection has been added back to the pool. This seems to imply that I could work around the problem on 0.11.24 by sleeping after reading the body. However, this is not the case. Here's an updated client that still does not work on 0.11.24:\n```rust\nextern crate futures;\nextern crate hyper;\nextern crate simple_logger;\nextern crate tokio_core;\nuse std::thread::sleep;\nuse std::time::Duration;\nuse futures::{Future, IntoFuture, Stream};\nuse hyper::{Chunk, Client, Error};\nuse tokio_core::reactor::Core;\nfn main() {\n    let mut core = Core::new().unwrap();\n    let handle = core.handle();\n    let client = Client::configure().keep_alive(true).build(&handle);\n    loop {\n        let res = client.get(\"http://127.0.0.1:8080/\".parse().unwrap())\n            .and_then(|resp| resp.body().fold((0usize, Vec::::new()), join_chunks));\n        let (num_chunks, data) = core.run(res).unwrap();\n        println!(\"got {} bytes ({} chunks)\", data.len(), num_chunks);\n        sleep(Duration::from_millis(100));\n    }\n}\nfn join_chunks(\n    mut state: (usize, Vec),\n    next: Chunk\n) -> Box), Error = Error>> {\n    state.1.extend(next.to_vec());\n    Box::new(Ok((state.0 + 1, state.1)).into_future())\n}\n```\nThere must be something else I'm missing. For example, I don't see why this drop is necessary. Maybe @seanmonstar can shine some light on this.. Ah, that's very helpful. However, I'm still not sure I see the full picture.\nHere's a modified version where the core runs forever, and the sleep is done using a future. The problem still happens on 0.11.24. In this case, the core is running forever, so @seanmonstar's previous explanation doesn't apply.\n```rust\nextern crate futures;\nextern crate hyper;\nextern crate simple_logger;\nextern crate tokio_core;\nuse std::time::Duration;\nuse futures::{Future, IntoFuture, Stream};\nuse futures::stream::repeat;\nuse hyper::{Chunk, Client, Error};\nuse tokio_core::reactor::{Core, Timeout};\nfn main() {\n    let mut core = Core::new().unwrap();\n    let handle = core.handle();\n    let client = Client::configure().keep_alive(true).build(&handle);\n    core.run(repeat::<(), Error>(()).for_each(move || {\n        let local_handle = handle.clone();\n        client.get(\"http://127.0.0.1:8080/\".parse().unwrap())\n            .and_then(|resp| resp.body().fold((0usize, Vec::::new()), join_chunks))\n            .and_then(move |(num_chunks, data)| {\n                println!(\"got {} bytes ({} chunks)\", data.len(), num_chunks);\n                Timeout::new(Duration::from_millis(100), &local_handle).unwrap()\n                    .map_err(From::from).map(|| ())\n            })\n    })).unwrap();\n}\nfn join_chunks(\n    mut state: (usize, Vec),\n    next: Chunk\n) -> Box), Error = Error>> {\n    state.1.extend(next.to_vec());\n    Box::new(Ok((state.0 + 1, state.1)).into_future())\n}\n```\nBy the way, I have been testing for the problem by running netstat -an | grep 127 | wc -l.. I did some investigating, since I didn't think this should be left a mystery. I found that commit 7fe9710 fixed another bug in addition to the delayed EOF bug. The bug was in this block of code from 0.11.24 (see in src/client/mod.rs):\nrust\nif let Ok(Async::NotReady) = pooled.tx.poll_ready() {\n    // If the executor doesn't have room, oh well. Things will likely\n    // be blowing up soon, but this specific task isn't required.\n    let _ = executor.execute(future::poll_fn(move || {\n        pooled.tx.poll_ready().map_err(|_| ())\n    }));\n}\nThe problem here is that pooled.tx.poll_ready() is called once from one task, and then repeatedly from a new task. In general, I'm guessing futures do not support being rescheduled on a different task. In particular, the Giver does not handle being moved to a new task; it continues to wake up the original task (which can end before the connection is put back into the pool).\nAnd, it hardly needs to be said: the bug doesn't happen for 1 chunk because the first time the executed poll_fn is called, the connection is ready to be given back to the pool.\nThe EOF bug is one issue that needed to be fixed. My original reproduction fell victim to both bugs, but the later one with Timeouts only fell victim to the task rescheduling bug.\nIf anybody is interested, here is a minimal patch on top of 0.11.24 that fixes the task rescheduling bug but not the EOF bug:\n```diff\ndiff --git a/src/client/conn.rs b/src/client/conn.rs\nindex f6a139b5..ed5d7147 100644\n--- a/src/client/conn.rs\n+++ b/src/client/conn.rs\n@@ -126,6 +126,10 @@ impl SendRequest\n         self.dispatch.poll_ready()\n     }\n\npub(super) fn is_wanting(&self) -> bool {\nself.dispatch.is_wanting()\n\n}\n+\n     pub(super) fn is_closed(&self) -> bool {\n         self.dispatch.is_closed()\n     }\ndiff --git a/src/client/dispatch.rs b/src/client/dispatch.rs\nindex efc720d8..d7943d9b 100644\n--- a/src/client/dispatch.rs\n+++ b/src/client/dispatch.rs\n@@ -45,6 +45,10 @@ impl Sender {\n         }\n     }\n\n\npub fn is_wanting(&self) -> bool {\n\nself.giver.is_wanting()\n}\n+\n     pub fn is_closed(&self) -> bool {\n         self.giver.is_canceled()\n     }\ndiff --git a/src/client/mod.rs b/src/client/mod.rs\nindex eb8c10ea..e81ef5dc 100644\n--- a/src/client/mod.rs\n+++ b/src/client/mod.rs\n@@ -253,7 +253,7 @@ where C: Connect,\n                     // for a new request to start.\n                     //\n                     // It won't be ready if there is a body to stream.\nif let Ok(Async::NotReady) = pooled.tx.poll_ready() {\n\nif !pooled.tx.is_wanting() {\n                         // If the executor doesn't have room, oh well. Things will likely\n                         // be blowing up soon, but this specific task isn't required.\n                         let _ = executor.execute(future::poll_fn(move || {\n@@ -661,4 +661,3 @@ mod background {\n         }\n     }\n }\n-\ndiff --git a/src/client/signal.rs b/src/client/signal.rs\nindex 2ddf67f7..7fd6bb44 100644\n--- a/src/client/signal.rs\n+++ b/src/client/signal.rs\n@@ -88,6 +88,10 @@ impl Giver {\n         }\n     }\n\n\npub fn is_wanting(&self) -> bool {\n\nself.inner.state.load(Ordering::SeqCst) == STATE_WANT\n}\n+\n     pub fn is_canceled(&self) -> bool {\n         self.inner.state.load(Ordering::SeqCst) == STATE_CLOSED\n     }\n```. \n",
    "orangesoup": "@seanmonstar Absolutely!\n```\n[[package]]\nname = \"hyper\"\nversion = \"0.11.25\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\ndependencies = [\n \"base64 0.9.0 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"bytes 0.4.6 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"futures 0.1.21 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"futures-cpupool 0.1.8 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"httparse 1.2.4 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"iovec 0.1.2 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"language-tags 0.2.2 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"log 0.4.1 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"mime 0.3.5 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"percent-encoding 1.0.1 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"relay 0.1.1 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"time 0.1.39 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"tokio-core 0.1.17 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"tokio-io 0.1.6 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"tokio-proto 0.1.1 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"tokio-service 0.1.0 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"unicase 2.1.0 (registry+https://github.com/rust-lang/crates.io-index)\",\n]\n[[package]]\nname = \"tokio\"\nversion = \"0.1.5\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\ndependencies = [\n \"futures 0.1.21 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"mio 0.6.14 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"tokio-executor 0.1.2 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"tokio-io 0.1.6 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"tokio-reactor 0.1.1 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"tokio-tcp 0.1.0 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"tokio-threadpool 0.1.2 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"tokio-timer 0.2.1 (registry+https://github.com/rust-lang/crates.io-index)\",\n \"tokio-udp 0.1.0 (registry+https://github.com/rust-lang/crates.io-index)\",\n]\n``. Sadly it doesn't seem to compile with0.1.12`, throws a whole bunch of errors.. Yeah, that worked, made a huge difference as well. Still a ~15% off though.\nwrk -t2 -c4 -d20s -H \"Connection: close\" http://127.0.0.1:8080\nRunning 20s test @ http://127.0.0.1:8080\n  2 threads and 4 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   100.47us   63.45us   4.02ms   92.08%\n    Req/Sec    13.60k     1.11k   16.16k    64.68%\n  543793 requests in 20.10s, 77.27MB read\nRequests/sec:  27055.20\nTransfer/sec:      3.84MB\nCPU usage went down from 360% to 100%.. The Go version is single-threaded. Technically it uses runtime.GOMAXPROCS(runtime.NumCPU()), but it's using a single-threaded event loop and just barfing out hello world on the same thread. So even if I increase threads and connections in wrk, the CPU usage stays around 100% (increases when GC running, but that's on another thread afaik) and the throughput is around the same with less connections and threads:\nwrk -t8 -c16 -d20s -H \"Connection: close\" http://127.0.0.1:13370\nRunning 20s test @ http://127.0.0.1:13370\n  8 threads and 16 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency     3.49ms   25.75ms 344.71ms   98.09%\n    Req/Sec     4.80k   711.35     5.89k    86.02%\n  758862 requests in 20.10s, 68.75MB read\nRequests/sec:  37754.70\nTransfer/sec:      3.42MB. Just to be sure I set GOMAXPROCS to 1, got the same result. Under the hood that app uses https://github.com/tidwall/evio, which - as states - is a single-threaded event loop.\nTo be fair, the pure tokio implementation (without hyper) does the same as hyper. I really don't have any deep knowledge about this, but wouldn't it suggest that the bottleneck is either in tokio or in mio?. Do you reckon I should open an issue about this somewhere else? And if so, where?. @seanmonstar Tbh I don't feel comfortable enough in Rust yet to be sure that my tokio/mio implementation would be perfect, so I've ran multiple benchmarks for all test cases again except tokio - so hyper old/latest, and go. Done flamegraph for all options, and also used strace if there's anything interesting happening there.\nAll these things were running separately, so while benchmarking throughput I didn't use strace or perf and vica versa.\nGo\nwrk -t2 -c4 -d20s -H \"Connection: close\" http://127.0.0.1:13370\nRunning 20s test @ http://127.0.0.1:13370\n  2 threads and 4 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    55.62us   51.12us   3.09ms   87.85%\n    Req/Sec    18.71k     2.47k   23.86k    60.60%\n  746448 requests in 20.10s, 67.63MB read\nRequests/sec:  37137.91\nTransfer/sec:      3.36MB\nAvg. CPU load: 100% (single thread).\nstrace\n```\n% time     seconds  usecs/call     calls    errors syscall\n\n98.72    0.656000        7718        85         6 futex\n  0.62    0.004110           0     23435           epoll_wait\n  0.27    0.001764           0     23405           close\n  0.19    0.001245           0     23403           write\n  0.09    0.000565           0     46824           fcntl\n  0.04    0.000292           0     70222           epoll_ctl\n  0.04    0.000235           0     23412           accept\n  0.02    0.000160           0     23407           read\n  0.02    0.000127           0     23407           getsockname\n  0.00    0.000006           2         4           sched_yield\n  0.00    0.000000           0         2           pselect6\n  0.00    0.000000           0         5           epoll_pwait\n\n100.00    0.664504                257611         6 total\n```\ngraph\nhttps://cdn.rawgit.com/orangesoup/09c33197de50615d0527a5088543affd/raw/351666be5c759a7c39780063208a9bc6a48f1a40/flamegraph_go.svg\n\nhyper (tokio-core = \"=0.1.12\"; tokio-io = \"=0.1.4\")\nwrk -t2 -c4 -d20s -H \"Connection: close\" http://127.0.0.1:8080\nRunning 20s test @ http://127.0.0.1:8080\n  2 threads and 4 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    98.89us   65.99us   4.25ms   92.33%\n    Req/Sec    13.47k     1.21k   15.62k    69.15%\n  538551 requests in 20.10s, 76.53MB read\nRequests/sec:  26793.80\nTransfer/sec:      3.81MB\nAvg. CPU load: 100% (as you said, this version is single-threaded).\nstrace\n```\n% time     seconds  usecs/call     calls    errors syscall\n\n43.89    0.008857           0    124116           close\n 33.18    0.006696           0    124112           writev\n  5.62    0.001135           0    155298     31183 accept4\n  4.65    0.000939           0    248230           setsockopt\n  4.64    0.000937           0    124115           readv\n  3.21    0.000648           0     93556           epoll_wait\n  2.83    0.000572           0    124115           epoll_ctl\n  1.96    0.000396           0    124115           ioctl\n  0.00    0.000000           0         8         3 read\n  0.00    0.000000           0         3           write\n  0.00    0.000000           0         1           open\n  0.00    0.000000           0         2           fstat\n  0.00    0.000000           0         1           lseek\n  0.00    0.000000           0         1           mmap\n  0.00    0.000000           0         1           munmap\n\n100.00    0.020180               1117674     31186 total\n```\ngraph\nhttps://cdn.rawgit.com/orangesoup/c68ef2fe9cbe0fb43bf01f7b883d8096/raw/0de030d2f0e3465d7466ca9350b8982317b1a322/flamegraph_hyper_old.svg\n\nhyper (latest, tokio 0.1.5)\nwrk -t2 -c4 -d20s -H \"Connection: close\" http://127.0.0.1:8080\nRunning 20s test @ http://127.0.0.1:8080\n  2 threads and 4 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   121.06us  105.47us   7.58ms   97.88%\n    Req/Sec    12.00k     1.16k   13.51k    73.38%\n  480046 requests in 20.10s, 68.21MB read\nRequests/sec:  23883.08\nTransfer/sec:      3.39MB\nAvg. CPU load: 115%.\nstrace\n```\n% time     seconds  usecs/call     calls    errors syscall\n\n40.55    0.009221           0    112527           close\n 29.99    0.006820           0    112523           writev\n  9.18    0.002087           0    225052           epoll_ctl\n  5.94    0.001350           0    141657     29131 accept4\n  4.49    0.001021           0    113994      1378 futex\n  4.08    0.000928           0    225052           setsockopt\n  3.94    0.000895           0    112526           readv\n  1.83    0.000417           0    112526           ioctl\n  0.00    0.000000           0         2           read\n  0.00    0.000000           0         1           open\n  0.00    0.000000           0         2           fstat\n  0.00    0.000000           0         1           lseek\n  0.00    0.000000           0         1           mmap\n  0.00    0.000000           0         1           munmap\n\n100.00    0.022739               1155865     30509 total\n```\ngraph\nhttps://cdn.rawgit.com/orangesoup/dedaab5cd10a26ececb80b86e7b3e3aa/raw/9bcd8d92b8669f38cc75d7b7017776845b0d35f4/flamegraph_hyper_latest.svg. I think I've tried using that option with the pure tokio implementation to see if there's any difference, but didn't change much really. But then again, it might be that I just messed that up totally. Is there like a pure tokio \"hello world\" example that's not an echo server?. So I've gone a little deeper now, wrote this little app with mio:\n```rust\nextern crate mio;\nuse std::io::{Write};\nuse std::net::Shutdown;\nuse mio::net::{TcpListener};\nuse mio::*;\nconst SERVER: Token = Token(0);\nfn main() {\n    let addr = \"127.0.0.1:8080\".parse().unwrap();\n    let server = TcpListener::bind(&addr).unwrap();\nlet poll = Poll::new().unwrap();\n\npoll.register(\n    &server,\n    SERVER,\n    Ready::readable(),\n    PollOpt::edge(),\n).unwrap();\n\nlet mut events = Events::with_capacity(1024);\n\nloop {\n    poll.poll(&mut events, None).unwrap();\n\n    for event in events.iter() {\n        match event.token() {\n            SERVER => {\n                let (mut stream, _) = server.accept().unwrap();\n                let _ = stream.set_keepalive(None);\n                let _ = stream.write_all(b\"HTTP/1.1 200 OK\\r\\nContent-Length: 11\\r\\nContent-Type: text/plain\\r\\nConnection: close\\r\\n\\r\\nhello world\");\n                let _ = stream.shutdown(Shutdown::Read);\n            }\n            _ => unreachable!(),\n        }\n    }\n}\n\n}\n```\nAnd this got me to even lower: 22k req/s (although only ~50% cpu usage).\nBut... this example uses edge-triggered epoll. So I've swapped out PollOpt::edge() for PollOpt::empty(), and got... 53k req/s with only 90% avg cpu usage. This is just superb now.\nI'm guessing under the hood tokio is using edge-triggered epoll, but I honestly really think this should be an available option to set at least in tokio. Probably wouldn't make much sense for hyper since most of its users will serve HTTP 1.1/2 clients with keep-alive.\n. ",
    "vasily-kirichenko": "@seanmonstar thanks, it works! But is it possible to see the actual Utf-8 parsing error?. ",
    "alexsasharegan": "By the way, the docs are quite nice! Just wanted to help you guys reach newcomers like me!. ",
    "0xc0": "Running the following Dockerfile hangs:\nFROM rust\nRUN [\"git\", \"clone\", \"https://github.com/hyperium/hyper.git\"]\nWORKDIR hyper\nRUN [\"git\", \"checkout\", \"603c3e4d2c6ebb3d495a85c4d9a8b36583eff3fc\"]\nENTRYPOINT [\"cargo\", \"run\", \"--example\", \"client\", \"http://httpbin.org/ip\"]\nHowever, checking out 485767403188a9a367d674099e9fc03a11264e2b (the parent commit), it does not hang.. ",
    "Kixunil": "The last one - 0.11.26\nIt panics on my unwrap - the one at the end of line: let server = hyper::server::Http::new().bind(&addr, move || Ok(service.clone())).unwrap();. FYI, I just rewrote the code to use tokio_core::net::TcpListener::bind(&addr, &handle).unwrap(); and hyper::server::Http::new().serve_incoming(listener.incoming().map(|(socket, _addr)| socket), move || Ok(service.clone())); and it works.. Linux Mint. 3.2.0-48-generic\n(Yes, it is old install.). I plan to try it. Thank you for quick response!. ",
    "meven": "I am on it !. By the way the send_file example seems not to function.. ",
    "ddosoff": "That's strange for me too that low level api prohibited.. Thanks!. If you googled this issue, I added boilerplate code: https://github.com/ddosoff/hyper-boilerplate. ",
    "DarrenTsung": "Ah okay great, forget about the ClientProto stuff then.\nI think thinking about a stable trait design is a fair point and might be more involved than I expected given the wide range of use-cases hyper needs to support.\nHowever, if a trait-bound on HttpConnector is the goal, then the only logic we can replace is here, right?\nrust\n                        let work = dns::Work::new(host, port);\n                        state = State::Resolving(oneshot::spawn(work, executor));\nThe input on some hypothetical resolve function would be: fn resolve(host: String, port: u16) as per dns::Work::new() and it would return a Future<Item=Iterator<Item=SocketAddr>, Error=io::Error> (This is the same trait structure as #1174). \nOkay, but maybe that's not the end goal, what other possible use cases might be brought up?\n Return results synchronously instead of a Future\n    * This would be a strange use-case for hyper as \"async I/O\" is a point in the main page, is it fair to call this one a \"write a custom HttpConnector\"?\n Take in more context than host: String and port: u16\n    * Looking at several different DNS crates (trust-dns, abstract-ns) as well as the standard ToSocketAddrs trait, this set of arguments seems reasonable and standard. Maybe instead of String it could take an IpAddr?\n* Using a trait provided by another crate (like abstract-ns as discussed in #1174)\n    * This would be a good point, I could see some sort of ToSocketAddrsFuture trait that's implemented and shared amongst crates so there's no need for new types to bridge implementations. \nLet me know if I'm missing anything, or if you're worried about any other use-cases! The only thing I can see is possibly supporting a generic ToSocketAddrsFuture (or something) trait with other crates, which would include research into what crates are used, what should be on a generic trait, etc. It expands the scope from a trait for HttpConnector to a trait of any DNS resolver to plug into, which is quite a leap.\nAnyways I think an initial step is for me to duplicate the HttpConnector and add in DNS substitution. That way I can continue without being blocked and if supporting a larger scope is required it can be prototyped outside of Hyper without requiring releases for the crate as a whole. If no larger scope is required though, it would be good to get the trait bound merged in!\n. Didn't see your reply @pimeys, thanks for the links! I'll definitely keep an eye on tokio-dns, and would be happy to wait for it if that's the right solution.\n@seanmonstar: Ah, yeah oops, that would not be necessary :P.\nDoes Connect allow users to define any error? From the code it looks to have some sort of bound on io:Error like the proposed trait, although you could just create io::Error from your Error.\nAh, okay, I'm looking at the 0.11 branch, on master branch it does allow any error. Given that HttpConnector is an implementation of Connect and defines its error type as io::Error it would make sense to me to have the Resolve trait (bounded on HttpConnector) as io::Error as well.\nGood point with the port:\n Looking at trust-dns, the implementation for lookup_ip does not take in a port and returns IpAddrs\n tokio-dns::Resolveronly operates on the host and returns IpAddrs as well. \n* abstract_ns::Resolve operates on only a string as well, it returns SocketAddrs though.\nGiven the API for these crates, I would lean towards avoiding passing in the port and have the future return Iterator<Item=IpAddr> and constructing the SocketAddrs from the IpAddrs and port.\nrust\ntrait Resolve {\n    type Future: Future<Item=Self::Addrs, Error=io::Error>;\n    type Addrs: Iterator<Item=IpAddr>;\n    fn resolve(&self, host: &str) -> Self::Future;\n}\nLet me know what you think!\n. As an update on this, I've created a duplicate of hyper 0.11's HttpConnector and have swapped out the DNS resolver on a branch to use trust-dns and c-ares (after running into some internal trust-dns issues (https://github.com/bluejekyll/trust-dns/issues/470)).\nBoth implementations would match the latest proposed trait without any problems :+1:.. Oh, sorry for ignoring this thread!\nHappy to contribute a PR once we're satisfied with the code, we're still on 0.11 so it would require some changes to work with 0.12. . Yeah, I thought that would work as well although I wasn't sure how to continue running the connect future without blocking the request from completing. \nThe other thing is you wouldn't want to \"continue\" the connect future if it hasn't started the binding a socket, which is some middle point in the future returned by the Connector type (completely unknown from Hyper's perspective).\nI guess an alternative would be to check if an idle connection exists, if not race the connect and checkout, finishing the connect future always?. Awesome! Thanks for making a test case, I can't imagine that was easy. \nI think #1585 is the better solution and should be the best of both worlds (requests fast as possible without socket thrash). Thanks a ton @seanmonstar! I'll test it out and leave a comment here.. Seems good to me - not seeing any socket thrash. :shipit: . Is there a release planned soon / can we get a release for this feature?. Thanks! \ud83d\ude04 . I would leave a comment here that .started() being false depends on the order of the futures in the Select2 struct, given that future A is polled before future B. So we shouldn't change it to be\nconnect.select2(checkout) as it would break things.\nAlso if Select2's logic ever changes it would break things, but \u00af\\(\u30c4)/\u00af.. ",
    "izderadicka": "Yes it's duplicate of #1509,  thanks.. headers:\n```\nGET / HTTP/1.0\nConnection: Keep-Alive\nHost: localhost:1337\nUser-Agent: ApacheBench/2.3\nAccept: /\n```\n```\nHTTP/1.0 200 OK\nconnection: keep-alive\ncontent-length: 88652\ndate: Mon, 02 Jul 2018 08:52:48 GMT\n. Log:\n TRACE hyper::proto::h1::conn > Conn::read_head\n TRACE hyper::proto::h1::conn > flushed({role=server}): State { reading: Init, writing: Init, keep_alive: Busy, error: None }\n TRACE hyper::proto::h1::conn > Conn::read_head\n DEBUG hyper::proto::h1::io   > read 106 bytes\n TRACE hyper::proto::h1::role > Request.parse([Header; 100], [u8; 106])\n TRACE hyper::proto::h1::role > Request.parse Complete(106)\n DEBUG hyper::proto::h1::io   > parsed 4 headers\n DEBUG hyper::proto::h1::conn > incoming body is empty\n TRACE hyper::proto::h1::conn > read_keep_alive; is_mid_message=true\n TRACE hyper::proto::h1::role > Server::encode status=200, body=Some(Known(88652)), req_method=Some(GET)\n DEBUG hyper::proto::h1::io   > flushed 88755 bytes\n DEBUG hyper::proto::h1::io   > read 106 bytes\n TRACE hyper::proto::h1::conn > flushed({role=server}): State { reading: Init, writing: Init, keep_alive: Idle, error: None }\n TRACE hyper::proto::h1::conn > Conn::read_head\n TRACE hyper::proto::h1::role > Request.parse([Header; 100], [u8; 106])\n TRACE hyper::proto::h1::role > Request.parse Complete(106)\n DEBUG hyper::proto::h1::io   > parsed 4 headers\n DEBUG hyper::proto::h1::conn > incoming body is empty\n TRACE hyper::proto::h1::conn > read_keep_alive; is_mid_message=true\n TRACE hyper::proto::h1::role > Server::encode status=200, body=Some(Known(88652)), req_method=Some(GET)\n DEBUG hyper::proto::h1::dispatch > error writing: Connection reset by peer (os error 104)\n DEBUG hyper::server::conn::upgrades > error polling connection protocol: error writing a body to connection: Connection reset by peer (os error 104)\n DEBUG hyper::server::conn           > conn error: error writing a body to connection: Connection reset by peer (os error 104)\n TRACE hyper::proto::h1::conn        > Conn::read_head\n TRACE hyper::proto::h1::conn        > flushed({role=server}): State { reading: Init, writing: Init, keep_alive: Busy, error: None }\n TRACE hyper::proto::h1::conn        > Conn::read_head\n DEBUG hyper::proto::h1::io          > read 106 bytes\n TRACE hyper::proto::h1::role        > Request.parse([Header; 100], [u8; 106])\n TRACE hyper::proto::h1::role        > Request.parse Complete(106)\n DEBUG hyper::proto::h1::io          > parsed 4 headers\n DEBUG hyper::proto::h1::conn        > incoming body is empty\n TRACE hyper::proto::h1::conn        > read_keep_alive; is_mid_message=true\n TRACE hyper::proto::h1::role        > Server::encode status=200, body=Some(Known(88652)), req_method=Some(GET)\n DEBUG hyper::proto::h1::io          > flushed 88755 bytes\n DEBUG hyper::proto::h1::io          > read 106 bytes\n TRACE hyper::proto::h1::conn        > flushed({role=server}): State { reading: Init, writing: Init, keep_alive: Idle, error: None }\n TRACE hyper::proto::h1::conn        > Conn::read_head\n TRACE hyper::proto::h1::role        > Request.parse([Header; 100], [u8; 106])\n TRACE hyper::proto::h1::role        > Request.parse Complete(106)\n DEBUG hyper::proto::h1::io          > parsed 4 headers\n DEBUG hyper::proto::h1::conn        > incoming body is empty\n TRACE hyper::proto::h1::conn        > read_keep_alive; is_mid_message=true\n TRACE hyper::proto::h1::role        > Server::encode status=200, body=Some(Known(88652)), req_method=Some(GET)\n DEBUG hyper::proto::h1::dispatch    > error writing: Connection reset by peer (os error 104)\n DEBUG hyper::server::conn::upgrades > error polling connection protocol: error writing a body to connection: Connection reset by peer (os error 104)\n DEBUG hyper::server::conn           > conn error: error writing a body to connection: Connection reset by peer (os error 104)\n TRACE hyper::proto::h1::conn        > Conn::read_head\n TRACE hyper::proto::h1::conn        > flushed({role=server}): State { reading: Init, writing: Init, keep_alive: Busy, error: None }\n TRACE hyper::proto::h1::conn        > Conn::read_head\n DEBUG hyper::proto::h1::io          > read 106 bytes\n TRACE hyper::proto::h1::role        > Request.parse([Header; 100], [u8; 106])\n TRACE hyper::proto::h1::role        > Request.parse Complete(106)\n DEBUG hyper::proto::h1::io          > parsed 4 headers\n DEBUG hyper::proto::h1::conn        > incoming body is empty\n TRACE hyper::proto::h1::conn        > read_keep_alive; is_mid_message=true\n TRACE hyper::proto::h1::role        > Server::encode status=200, body=Some(Known(88652)), req_method=Some(GET)\n DEBUG hyper::proto::h1::io          > flushed 88755 bytes\n DEBUG hyper::proto::h1::io          > read 106 bytes\n TRACE hyper::proto::h1::conn        > flushed({role=server}): State { reading: Init, writing: Init, keep_alive: Idle, error: None }\n TRACE hyper::proto::h1::conn        > Conn::read_head\n TRACE hyper::proto::h1::role        > Request.parse([Header; 100], [u8; 106])\n TRACE hyper::proto::h1::role        > Request.parse Complete(106)\n DEBUG hyper::proto::h1::io          > parsed 4 headers\n DEBUG hyper::proto::h1::conn        > incoming body is empty\n TRACE hyper::proto::h1::conn        > read_keep_alive; is_mid_message=true\n TRACE hyper::proto::h1::role        > Server::encode status=200, body=Some(Known(88652)), req_method=Some(GET)\n TRACE hyper::proto::h1::conn        > Conn::read_head\n TRACE hyper::proto::h1::conn        > flushed({role=server}): State { reading: Init, writing: Init, keep_alive: Busy, error: None }\n TRACE hyper::proto::h1::conn        > Conn::read_head\n DEBUG hyper::proto::h1::io          > read 106 bytes\n TRACE hyper::proto::h1::role        > Request.parse([Header; 100], [u8; 106])\n TRACE hyper::proto::h1::role        > Request.parse Complete(106)\n DEBUG hyper::proto::h1::io          > parsed 4 headers\n DEBUG hyper::proto::h1::conn        > incoming body is empty\n TRACE hyper::proto::h1::conn        > read_keep_alive; is_mid_message=true\n TRACE hyper::proto::h1::role        > Server::encode status=200, body=Some(Known(88652)), req_method=Some(GET)\n DEBUG hyper::proto::h1::io          > flushed 88755 bytes\n DEBUG hyper::proto::h1::io          > read 106 bytes\n TRACE hyper::proto::h1::conn        > flushed({role=server}): State { reading: Init, writing: Init, keep_alive: Idle, error: None }\n TRACE hyper::proto::h1::conn        > Conn::read_head\n TRACE hyper::proto::h1::role        > Request.parse([Header; 100], [u8; 106])\n TRACE hyper::proto::h1::role        > Request.parse Complete(106)\n DEBUG hyper::proto::h1::io          > parsed 4 headers\n DEBUG hyper::proto::h1::conn        > incoming body is empty\n TRACE hyper::proto::h1::conn        > read_keep_alive; is_mid_message=true\n TRACE hyper::proto::h1::role        > Server::encode status=200, body=Some(Known(88652)), req_method=Some(GET)\n DEBUG hyper::proto::h1::dispatch    > error writing: Connection reset by peer (os error 104)\n DEBUG hyper::server::conn::upgrades > error polling connection protocol: error writing a body to connection: Connection reset by peer (os error 104)\n DEBUG hyper::server::conn           > conn error: error writing a body to connection: Connection reset by peer (os error 104)\n DEBUG hyper::proto::h1::dispatch    > error writing: Connection reset by peer (os error 104)\n DEBUG hyper::server::conn::upgrades > error polling connection protocol: error writing a body to connection: Connection reset by peer (os error 104)\n DEBUG hyper::server::conn           > conn error: error writing a body to connection: Connection reset by peer (os error 104)\n TRACE hyper::proto::h1::conn        > Conn::read_head\n TRACE hyper::proto::h1::conn        > flushed({role=server}): State { reading: Init, writing: Init, keep_alive: Busy, error: None }\n TRACE hyper::proto::h1::conn        > Conn::read_head\n DEBUG hyper::proto::h1::io          > read 106 bytes\n TRACE hyper::proto::h1::role        > Request.parse([Header; 100], [u8; 106])\n TRACE hyper::proto::h1::role        > Request.parse Complete(106)\n DEBUG hyper::proto::h1::io          > parsed 4 headers\n DEBUG hyper::proto::h1::conn        > incoming body is empty\n TRACE hyper::proto::h1::conn        > read_keep_alive; is_mid_message=true\n TRACE hyper::proto::h1::role        > Server::encode status=200, body=Some(Known(88652)), req_method=Some(GET)\n DEBUG hyper::proto::h1::io          > flushed 88755 bytes\n DEBUG hyper::proto::h1::io          > read 106 bytes\n TRACE hyper::proto::h1::conn        > flushed({role=server}): State { reading: Init, writing: Init, keep_alive: Idle, error: None }\n TRACE hyper::proto::h1::conn        > Conn::read_head\n TRACE hyper::proto::h1::role        > Request.parse([Header; 100], [u8; 106])\n TRACE hyper::proto::h1::role        > Request.parse Complete(106)\n DEBUG hyper::proto::h1::io          > parsed 4 headers\n DEBUG hyper::proto::h1::conn        > incoming body is empty\n TRACE hyper::proto::h1::conn        > read_keep_alive; is_mid_message=true\n TRACE hyper::proto::h1::role        > Server::encode status=200, body=Some(Known(88652)), req_method=Some(GET)\n DEBUG hyper::proto::h1::dispatch    > error writing: Connection reset by peer (os error 104)\n DEBUG hyper::server::conn::upgrades > error polling connection protocol: error writing a body to connection: Connection reset by peer (os error 104)\n DEBUG hyper::server::conn           > conn error: error writing a body to connection: Connection reset by peer (os error 104)\n```\nI'll try wrk tomorrow. @seanmonstar  - if you mean timeout reported by ab, then it's takes likes 20-30 secs and then tests ends. Definitely more then to read the file. . Hi, \nI tried wrk - it seems to work better (it uses HTTP 1.1 where keep alive is by default) , but it does not report failed requests, but throughput looks reasonable.\nSometimes I see these errors in log, when wrk is ending. But I guess it might be wrk problem as it can close connections on test end and not wait for response.\nTRACE hyper::proto::h1::conn        > flushed({role=server}): State { reading: Closed, writing: Init, keep_alive: Disabled, error: None }\n DEBUG hyper::server::conn           > conn error: error writing a body to connection: Broken pipe (os error 32)\n TRACE hyper::proto::h1::conn        > flushed({role=server}): State { reading: Closed, writing: Init, keep_alive: Disabled, error: None }\n DEBUG hyper::proto::h1::dispatch    > error writing: Broken pipe (os error 32)\n DEBUG hyper::server::conn::upgrades > error polling connection protocol: error writing a body to connection: Broken pipe (os error 32)\n DEBUG hyper::server::conn           > conn error: error writing a body to connection: Broken pipe (os error 32)\n DEBUG hyper::proto::h1::dispatch    > error writing: Broken pipe (os error 32)\n DEBUG hyper::server::conn::upgrades > error polling connection protocol: error writing a body to connection: Broken pipe (os error 32)\n DEBUG hyper::server::conn           > conn error: error writing a body to connection: Broken pipe (os error 32)\n DEBUG hyper::proto::h1::dispatch    > error writing: Broken pipe (os error 32)\n DEBUG hyper::server::conn::upgrades > error polling connection protocol: error writing a body to connection: Broken pipe (os error 32)\n DEBUG hyper::server::conn           > conn error: error writing a body to connection: Broken pipe (os error 32)\n DEBUG hyper::proto::h1::dispatch    > error writing: Broken pipe (os error 32)\n DEBUG hyper::server::conn::upgrades > error polling connection protocol: error writing a body to connection: Broken pipe (os error 32)\n DEBUG hyper::server::conn           > conn error: error writing a body to connection: Broken pipe (os error 32)\n DEBUG hyper::server::conn           > conn error: error writing a body to connection: Broken pipe (os error 32)\n DEBUG hyper::server::conn::upgrades > error polling connection protocol: error writing a body to connection: Broken pipe (os error 32)\n DEBUG hyper::server::conn           > conn error: error writing a body to connection: Broken pipe (os error 32). ",
    "zrzka": "Disabled both, as a start to test again & confirm what I have found, but I think it's enough to disable retry canceled requests. Will test this (keep alive enabled) under some load as well, but can't say when I confirm it, because of the reproducibility.\nBTW app is still running (~5h). We decided that it will pass internally if it will run for at least a week, because it will be under heavier load later.. Thanks! For future readers, it was published as v0.11.27.. ",
    "da2018": "@pimeys  Both of them(http and hyper) are http library, so do we need to install two same library to do this?. @pimeys  Thanks.. Got it, thanks for your answer.. ",
    "davidbarsky": "The examples directory is using the master branch of Hyper, which will be 0.12. The current release of Hyper on crates.io is 0.11.27, which lacks the hyper::service module. Since you're seeing this build error, I'm assuming that you're pulling Hyper from crates.io and not the mainline branch of hyperium/hyper.\nIf you replace hyper = \"0.11\" in your Cargo.toml with hyper = { git = \"https://github.com/hyperium/hyper\" }, your project should build correctly.. Maybe! That said, I've opened an PR to alleviate this issue.. > Thanks for the PR! I wonder, does the added text clarify much? It might be that I'm biased, but I'm used to example code at a certain commit in a repo to always work with that version of the code, not necessarily what is published.\nThat's a fair point.\n\nMaybe there is some value in reminding people of that... What do you think of that message being in examples/README.md directly?\n\nCould be! But if Hyper 0.12 will be released soon\u2014the milestone for 0.12 suggests that the case\u2014then maybe adding the README to examples might be unnecessary. Either way, I'll update the PR (or open a new one...) to add the README to the examples directory.. Ah, didn't see https://github.com/hyperium/hyper/commit/2415ce96e198bafc107c38e53a7bbacc2d361dbf. Closing this PR as it's handled.. A good option would be to use futures' mpsc module. Unless you have good reason, I'd suggest skipping the \u201cevery n seconds\u201d bit of your plan because handling backpressure gets trickier. However, if you do have good reason, I'd suggest taking a look at Tokio's Timer module. . @salman-ca: I'm going to guess that you've gotten this work by now, so I'll close this issue for now.. I want to ask a clarifying question\u2014why do you want to skip the body parsing? In most of the APIs I've interacted with, non-200 status codes often contain useful errors, and I'd opt for not throwing away potentially useful errors.. Oh, I also have no idea how to tackle replacing Service's Service impl. That's a bit... beyond me.. I'll close this ticket until https://github.com/tower-rs/tower/issues/136 is resolved. I think it's best that any experimentation along these lines occur in tower-rs/tower-hyper.. I'd suggest importing use tokio::runtime::Runtime and running your task like:\nrust\nlet mut rt = Runtime::new()?;\nrt.block_on(task);\nTherefore, the full code example, assuming the 2018 edition of Rust, would be:\n```rust\nuse tokio::runtime::Runtime;\nuse hyper::Client;\nfn main() {\n    let client = Client::new();\n    let uri = \"http://httpbin.org/ip\".parse().unwrap();\n    let task = client.get(uri)\n            .and_then(|res| {\n                println!(\"Response: {}\", res.status());\n                Ok(())\n            })\n            .map_err(|err| {\n                println!(\"Error: {}\", err);\n            });\nlet mut rt = Runtime::new().unwrap();\nrt.block_on(task);\n\n}\n``. Short answer: I'd suggest using Tokio's [block_on`](https://tokio-rs.github.io/tokio/tokio/runtime/struct.Runtime.html#method.block_on) method. I haven't tested this code, but it should look something like this:\n```rust\n[test]\nfn post_endpoint() {\n  use tokio::runtime::Runtime;\n  // Create the runtime\n  let mut rt = Runtime::new().unwrap();\n  // resp assumed to be defined elsewhere.\n  let resp = rt.block_on(resp);\n}\n```\nLong answer\u2014every future created by Hyper must be run in the context of Tokio's event loop. Unlike, say, Node, there isn't a default/global event loop in Rust, so you have to create instances/handles to Tokio yourself.\n(If you can send a PR that uses this to test endpoints, that'd be greatly appreciated!). I think these changes are good! I think it'll require @seanmonstar's sign-off, but I'm not opposed to this.. Yep! Send over the pull request. I'll close this issue in the meantime, as this isn't strictly a bug.. std::thread::sleep is a thread-blocking operation, which means the entire reactor + any futures spawned to that reactor would block the reactor thread. I'd suggest using Tokio's timer to place a future\u2014not the runtime!\u2014to sleep. This will allow other futures/requests to make progress in the the meantime.. These thoughts aren't complete, nor are they particularly well-edited, but here goes:\n\nI think a breaking change to support Tower everywhere in Hyper is probably okay, given the last breaking release to Hyper was June 1st, 2018, almost ten months ago.\nI kinda view hyper::Client as a particularly chunky Service that manages connection pooling, re-connection, and whatnot. From the perspective of Tower, I think it can be viewed as a newtype produced by a bunch of Layers + a ServiceBuilder.\nSpeaking of naming services, I'm somewhat split:\nIt might make sense to encourage people to create new clients on the fly, especially if the underlying connection pool can be shared and reused, side-stepping the naming issue, and a bunch of unpleasant Arc<Mutex<T>> to get around borrow checking errors.\nHyper could vend some common client configurations under a newtype'd struct with the uncomfortably large type signatures tucked away behind a field + concrete types, with various policies (timeouts, retries, the like) would be accessible through some sort of builder.\n\n\n\nI can't comment on the BufStream/Body stuff as I don't have enough context or expertise on the matter.. Copy editing nit: \u201dConsumes the AddrStream and returns the underlying IO object\u201c. ",
    "aaronriekenberg": "Sounds good.  Updated to replace existing send_file.rs with this blocking example.  Thanks.. Fair point.  I updated the example to use tokio_fs and tokio_io to have the same behavior, which is probably a better example.. Fixed.  tokio-threadpool is no longer needed.  Added tokio-fs to dev-dependencies.. ",
    "logaritmisk": "@sfackler I'm running 10.12.6\nI tried it on another computer running 10.13.4 and that worked. Then I tested with lto = true on my older computer and that worked as well! So it seems it's the same issue as rust-lang/rust#50586\nThanks, now I have a workaround and can continue with my project \ud83d\udc4d \nEdit: Hmm, but now I get another issue. With lto = true and compiled with release on macOS 10.12.6, the code from my first post is using 200% of my CPU, and I can't call my endpoint.. Okey, so I found a way to get this to work on 10.12.6.\nAdd #[inline] for the check method and compile with lto = false.. I'm dealing with a \"hard to please\" client, and title case headers is one of the things I have to use. So this is a feature I would love to see.. ",
    "mhseiden": "Sorry for the belated response! I must have just missed an email somewhere...\nI think it would be nice to assert at construction time. Ie either the default runtime is used and there's no swapping individual components, or the builder requires/asserts that all of the components have been set. \n. ",
    "ps1dr3x": "I'm having this problem too. I'm writing a proxy and this is causing the proxied request be different from the original request. Maybe i can make some tests and try to work on a pull request?. I'll try to explain better. If a server responds to a request, and that response's headers contains duplicated keys, eg:\n\nHTTP/1.1 200 OK\nExample-Header: example-value\nExample-Header: another-example-value\n\nThis code:\nrust\nlet (parts, body) = response.into_parts();\nfor header in parts.headers {\n    println!(\"{:?}\", header);\n}\nwill print:\n\n(\"Example-Header\", \"example-value\")\n(None, \"another-example-value\"). Ah, oops! I wasn't aware of that. I was wondering how a Map could not have some keys \ud83e\udd37\u200d\u2642\ufe0f\n\nThanks for the clarification!. ",
    "Globidev": "I see, that actually makes sense since executors will most likely involve a thread pool of sorts.\nI won't pretend that I am competent enough to suggest an alternative, I was mainly just curious :)\nAnyway, thanks a lot for taking the time to answer!\nClosing.. Your last and_then is called on a impl Future<Error = hyper::Error> so its closure is expected to return an impl IntoFuture<Error = hyper::Error>. Since you return an Ok(item), it is inferred to return a Result<_, hyper::Error>.\nto be able to use the ? syntax on a Result<_, serde_json::Error> inside that closure, you would need a way to convert from serde_json::Error to hyper::Error, and that's pretty much what the compiler is telling you.\nSince hyper::Error and serde_json::Error come from external crate, you cannot write an impl From<serde_json::Error> for hyper::Error\nI see that you are using failure::Error though, it provides an impl of From for both hyper::Error and serde_json::Error. So what you could do is map the future's error to a failure::Error using map_err before doing your deserializing:\n```rust\nfn work() -> Result {\n    let client = hyper::Client::new();\n    let uri = \"...\".parse()?; // here ? works too cause there is an impl From for failure::Error\nlet future = client.get(uri)\n    .and_then(|result| result.into_body().concat2())\n    .map_err(failure::Error::from) // Now we have a Future<Error = failure::Error>\n    .and_then(|body| { // Infered to return a Result<MyItem, failure::Error>\n        let item: MyItem = ::serde_json::from_slice(&body)?; // now works cause there is an impl From<serde_json::Error> for failure::Error\n        // ...\n        Ok(item)\n    });\n\nfuture.wait()\n\n}\n```. ",
    "joshleeb": "Is it worth Body::content_length() returning the content length of the received response even if the header isn't present?\nI assuming that a request without a content-length header is still valid, and that we can simply figure out the content length by taking the length of the body.. That makes sense. Thanks @lnicola. Yea sure, thanks :smile:. I'd like to take this one on \ud83d\ude04. @seanmonstar apologies for taking so long to get to this.\nI've used the tower-h2 code as a guide but I'm not sure if I'm on the right track.. I'll start taking a look at this one \ud83d\ude04. Ahh damn sorry about that. Should be all fixed now \ud83d\udc4d . @seanmonstar thanks for writing that up.\nI think the first part makes sense and I've updated the PR to move the poll_reset() and return code to be apart of PipetoSendStream rather than the individual Client, and Server.\nThe second part I'm a little confused about. Are you referring to referring to h2::Server::poll_server? And then in this method, after we've created an H2Stream,\nrust\nlet fut = H2Stream::new(service.call(req), respond);\nWe then want to call poll_reset so we can cancel the future if we get back Ok(Async::Ready(reason))?. :+1: That thought completely skipped my mind. Updated to remove the comma separated headers listed only in the CONNECTION header.. Updated this list to remove CONNECTION, and include the other headers mentioned in the mozilla docs you linked.. It looks like it does pick it up but I suspect that because the panic is not in the main test thread it doesn't cause the test to fail. \nhttps://travis-ci.org/hyperium/hyper/jobs/390534326#L825\nhttps://travis-ci.org/hyperium/hyper/jobs/390534326#L825. ",
    "cSchubes": "Hi Sean,\nThanks for getting back to me so quickly. Something was off on my system - cloning the entire repo fixed everything. Good to know that about future::lazy.. ",
    "bubaflub": "Just tried doing the stupid thing and commenting out those debug_assert!(...) calls and I now get:\nthread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: Error { kind: Parse(Header), cause: None }', libcore/result.rs:945:5\nBut I do get a 400 Bad Request sent back before the crash.  So I might be doing something wrong and maybe I haven't actually hijacked the underlying connection or maybe my service is triggering on every request and not just on every new connection.. ",
    "CasterKKK": "So cannot you update futures to 2.0+?. ",
    "alexgreencode": "@seanmonstar Thanks for explanation. I faced with the same issue as da2018. I think it would be awesome to publish  this plan to the main page.\nP.S. async/await - cool stuff.. ",
    "hashmap": "I found this PR very helpful, I experienced all pain described in #1571. ",
    "nappa85": "I'm using 0.12.1. After a little inspection, the problem is given by tokio-threadpool, dependency of tokio.\nThe backtrace is:\n   1: tokio_executor::enter::enter\n             at tokio-executor-0.1.2/src/enter.rs:40\n   2: tokio_threadpool::worker::Worker::do_run::{{closure}}\n             at tokio-threadpool-0.1.4/src/worker/mod.rs:113\n   3: >::try_with\n             at /checkout/src/libstd/thread/local.rs:290\n   4: >::with\n             at /checkout/src/libstd/thread/local.rs:244\n  5: tokio_threadpool::worker::Worker::do_run\n             at tokio-threadpool-0.1.4/src/worker/mod.rs:106\n  6: tokio_threadpool::pool::Pool::spawn_thread::{{closure}}\n             at tokio-threadpool-0.1.4/src/pool/mod.rs:411\ntokio_executor::enter is callable only once, I can't use tokio::core in an hyper-based application thread, I must spawn a separated thread.. ",
    "hwchen": "Just want to note that this modified example in #1568 was important for helping me figure out 3) from above, sending requests from a client with an existing hyper server. I had thought about going down that path, and that example pushed me towards a solution.. @Crandel sorry, I was responding to the thread in general, and not specifically to your concerns. I think that if you want to have a user-friendly client, have you looked at https://github.com/seanmonstar/reqwest, which is an ergonomic layer over hyper? The experience is a lot closer to Python's request or Go.\nHyper might be a little lower level than you need.. ",
    "frenchtoastbeer": "I'm writing an asynchronous client application based on hyper, and wow - has this been painful.  I'm writing an app that takes a stack of queries to a single server, and issues them up to x num of concurrent requests at a time.\nI've achieved getting x num of concurrent requests to be sent at a server, but I don't yet have all the request results.  Based on what I've learned from the examples, its like I either can use the request status & headers, or I can use the request body, but not both.\nIt's been... tough.  I want the results all wrapped in a  response type struct (which includes the body) and then sent to another thread via mpsc channel.\nWhat I'd really like to see is some asynchronous client example that gives me some kind of environment (I'm guessing via a .map call?  ) which has the full request available.\nSo far, all the examples just immediately print return status, headers and then enter a completely different 'task' to chunk the response body and handle that separately.  \nI just want access to the full response, at one point in time.  By \"full response\" I mean return status, the headers, and the body... the full response.  Instead, I've spent over ten hours just reading up on tokio trying to figure out what futures are, or what the hell concat2 is even returning, all while pondering if this is lazily evaluated. Or even map, for that matter - is it lazy?  How can I ensure a web request is finished?  I feel like \"let body = res.into_body().concat2();\" should allow me to at least do a \"tx.try_send( body.to_vec() )\" but that doesn't work.\nI'm a novice in rust, and way out of my league apparently, but even from where I'm standing I'm pretty sure an example of an asynchronous app that creates a \"full\" response could wipe away a 1000 tears.\n. @Darksonn You're incredible! I love you.  A lot.  Your code is so clean!?!  How long did that take you?  I think.... I think I can accomplish my goal now.  Please include Darksonn's example in the hyper client source files.. OK thanks.  I was avoiding reqwest as it didn't have async when I first looked, but now that I'm looking again - it appears it might?. ",
    "dylanede": "Thank you for the quick and in depth reply. I was aware of the existence of SO_REUSEADDR, but I wasn't sure whether it was relevant in this case. I would have expected identical behaviour from restarting the server within the process to just restarting the process, which as noted above is not what I see.\nI am using shutdown_now after doing all of the graceful shutdown I can for other tasks, because I cannot find another way of getting the Server future to complete gracefully. That is what I was hoping I might have missed in the docs, since they do mention that for Server, \"the future completes when the server has been shutdown\". The trouble is that I cannot find how to achieve that.\nAnyway, I tried using reuse_address, similarly to how you have described. The main differences are that I have handling for IPv6 addresses as well as IPv4, and I enable nodelay on the TcpStreams that the incoming stream puts out.\nWith this configuration the setup succeeds, however I find that I cannot connect to a server on a recreated socket. In other words, after running the server and then restarting it within the same process, it does not accept TCP connections. It also no longer accepts connections when bound on IPv6 addresses at all, even for the first creation of the socket.\nIn conclusion I'm not convinced that the problem that is normally solved by using SO_REUSEADDR is fully responsible here.\nThanks again for this great library, by the way.. I see now that shutting down the server is a case of making the incoming stream end. I will see if that helps things.. ",
    "ChriFo": "I have the same behavior with Windows (and Appveyor) and a server implementation based on https://github.com/actix/actix-web which uses tokio. Everything is fine on macOS and Linux (and Travis)!\nI tried to setup a socket with the socket2 crate (set_reuse_address) but without success.. The server seems to be ok. I think it is the client (reqwest): carllerche/mio#776. ",
    "abarth": "Thanks!. ",
    "amerzaki545": "Please help. ",
    "brandonros": "Super grateful for this!\nMy one qualm is... how often does an application do nothing but make an HTTP request and then exit? It is a good example of the library and what it offers no doubt, but I think a better example would be showing a function that returns a future that resolves with the deserialized body, which I think is a more common real world use case.\nIn the example I posted above, you're able to use the return value of the HTTP JSON GETting function for however you want, then logged from the calling function.. 21 | fn fetch_json(url: hyper::Uri) -> impl Future<Item=Vec<User>, Error=Box<std::error::Error>> {\n   |                                                                         ^^^^^^^^^^^^^^^^^ expected lifetime parameter\n   |\n   = help: this function's return type contains a borrowed value with an elided lifetime, but the lifetime cannot be derived from the arguments\n   = help: consider giving it an explicit bounded or 'static lifetime\n```\n![deny(warnings)]\nextern crate hyper;\n[macro_use]\nextern crate serde_derive;\nextern crate serde;\nextern crate serde_json;\nuse hyper::Client;\nuse hyper::rt::{self, Future, Stream};\nfn main() {\n    let url = \"http://jsonplaceholder.typicode.com/users\".parse().unwrap();\n// Run the runtime with the future trying to fetch, parse and print json.\n//\n// Note that in more complicated use cases, the runtime should probably\n// run on its own, and futures should just be spawned into it.\nrt::run(fetch_json(url));\n\n}\nfn fetch_json(url: hyper::Uri) -> impl Future, Error=Box> {\n    let client = Client::new();\nclient\n    // Fetch the url...\n    .get(url)\n    // And then, if we get a response back...\n    .and_then(|res| {\n        // asynchronously concatenate chunks of the body\n        res.into_body().concat2()\n    })\n    // use the body after concatenation\n    .and_then(|body| {\n        serde_json::from_slice(&body).expect(\"parse json\");\n    })\n\n}\n[derive(Deserialize, Debug)]\nstruct User {\n    id: i32,\n    name: String,\n}\n``. Yes. I think people looking for the simplicity ofrequest-promise` will be happy to find this has been covered with your very fine Rust package. Without this, I know I'm personally left scratching my head saying \"why would anybody who just wants to make an HTTP request and get some JSON sign up for this much pain\"?. ",
    "saarw": "Ok! Updated the title to reflect problem in the issue.. This seems fixed when upgrading from 0.12.2 -> 0.12.3. Thanks!. Nevermind, turned out it was a problem with full nginx disk that caused it to fail some requests but not other. Sorry about the bother.. It at least seems to happen with new connections. The issues is that we have 2 tasks in the single-threaded reactor that do connections to different hosts at the same time, so the logs look like below. We seem to get this more on Macs than Linux, but can't confirm it's Mac-exclusive.\n2018-08-01T22:03:41.269534+02:00 TRACE hyper::client::pool - checkout waiting for idle connection: (\"https://address1\", Http1) \n2018-08-01T22:03:41.269631+02:00 TRACE hyper::client::connect::http - Http::connect; scheme=https, host=address1, port=None \n2018-08-01T22:03:41.269764+02:00 DEBUG hyper::client::dns - resolving host=\"address1\", port=443 \n2018-08-01T22:03:41.275190+02:00 TRACE hyper::client::pool - checkout waiting for idle connection: (\"https://address2\", Http1) \n2018-08-01T22:03:41.275263+02:00 TRACE hyper::client::connect::http - Http::connect; scheme=https, host=address2, port=None \n... \n2018-08-01T22:04:09.108421+02:00 DEBUG hyper::client::connect::http - connecting to ...an ip\n2018-08-01T22:04:09.188078+02:00 DEBUG hyper::client::connect::http - connecting to ...another ip\n...\nThen rustls negotiation etc. happen for both requests, and sometimes one of the requests will fail (consistently the same one, the other one always seems to succeed).. The problem goes away when upgrading to the july release of hyper-rustls and rustls crates, closing.. ",
    "withkittens": "For now I resolved it with\n::serde_json::from_slice(&body).expect(\"valid json\")\nBut what if I don't want panic?. @khuey \n\nThis isn't really something you can do. It's better to convert your serde error to a useful Response (at a minimum, an HTTP 500 error code) rather than attempting to return an error to hyper.\n\nGood point, although this will hide the exact error (which I may be not interested in, but still).\n\nEDIT: I missed that this is client side, not server side. Ignore me.\n\nYeah, for server side what you said is what I would do.\n@Globidev This is what I was looking for, thank you for the generous explanation! I've seen .map_errs in various examples, but they were usually written after all and_thens. Also, I didn't know there is future.wait().\nThis resolves my question.. @seanmonstar Thanks for your note, I agree. For now, while I'm trying to get a grasp on Rust futures and how tokio works in general, I'm more interested in client side and simple console apps. I have a strong background with C# with its Tasks and async/await, and now I want to learn how the same things look like and work in Rust.\nIn the above func, I did want to convert an async operation to a sync result in a blocking way, so I think Future::wait fits perfectly here. Toy servers, non-blocking event loops and similar concepts are my next step. :). ",
    "khuey": "EDIT: I missed that this is client side, not server side. Ignore me.. ",
    "Paxa": "Awesome \ud83d\udc4f . ",
    "scrogson": "It appears that RFC 6555 has been obsoleted by https://tools.ietf.org/html/rfc8305. ",
    "hban": "I've added a test, but I'm not really happy how it turned out. I needed to provide custom name resolver, which Hyper doesn't support, so I hacked one in, hidden behind non-default feature flag. It's crude and ugly solution.\nInstead, I can write a test directly for ConnectingTcp. It would remove need for this test-only custom resolver, but would mix this integration test with other unit tests.\nAnyway, I'm not really sure which options is better, or if there is a third one I missed.\nRegarding RFC 8305 @scrogson mentioned, I see it as a extension of work done here (correct me if I'm wrong). DNS part would require support for querying A records separately from AAAA records. ToSocketAddrs doesn't support specifying address family AFAIK, so we would need some other resolver. This would also impact implementing custom resolvers since they would either need to receive address family as parameter or return pair-of-futures/stream. Staggering connections could be done now, but I'd prefer for them to be a separate PR (if they are desired feature).. Apparently Travis doesn't enable IPv6 by default (travis-ci/travis-ci#8361), so I copied workaround from one of the comments to make it work. I hope that's OK.. Done (and commits squashed).. ",
    "hntd187": "Thanks, this is exactly what I was looking for!. ",
    "veeableful": "Hi @seanmonstar, It happens when I remove the first request. I've added env_logger and here's the output:\nTRACE 2018-07-19T01:53:32Z: hyper::client::pool: park; waiting for idle connection: \"https://westus.stt.speech.microsoft.com\"\nTRACE 2018-07-19T01:53:32Z: hyper::client::connect: Http::connect(\"https://westus.stt.speech.microsoft.com/speech/recognition/interactive/cognitiveservices/v1?language=en-US&cid=ENDPOINT_ID&format=detailed\")\nDEBUG 2018-07-19T01:53:32Z: hyper::client::dns: resolving host=\"westus.stt.speech.microsoft.com\", port=443\nDEBUG 2018-07-19T01:53:32Z: hyper::client::connect: connecting to 104.42.72.155:443\nthread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: Io(Custom { kind: Other, error: Custom { kind: Other, error: Kind(UnexpectedEof) } })', libcore/result.rs:945:5\nnote: Run with `RUST_BACKTRACE=1` for a backtrace.\nI've also run it with both requests where I set the subscription key and got the access token. Here's the output:\nTRACE 2018-07-19T01:56:03Z: hyper::client::pool: park; waiting for idle connection: \"https://westus.api.cognitive.microsoft.com\"\nTRACE 2018-07-19T01:56:03Z: hyper::client::connect: Http::connect(\"https://westus.api.cognitive.microsoft.com/sts/v1.0/issueToken\")\nDEBUG 2018-07-19T01:56:03Z: hyper::client::dns: resolving host=\"westus.api.cognitive.microsoft.com\", port=443\nDEBUG 2018-07-19T01:56:03Z: hyper::client::connect: connecting to 40.112.254.71:443\nTRACE 2018-07-19T01:56:04Z: hyper::proto::h1::conn: read_keep_alive; is_mid_message=false\nTRACE 2018-07-19T01:56:04Z: hyper::proto: should_keep_alive(version=Http11, header=None) = true\nTRACE 2018-07-19T01:56:04Z: hyper::proto::h1::role: Client::encode has_body=true, method=None\nTRACE 2018-07-19T01:56:04Z: hyper::proto::h1::io: reclaiming write buf Vec\nTRACE 2018-07-19T01:56:04Z: hyper::proto::h1::io: detected no usage of vectored write, flattening\nDEBUG 2018-07-19T01:56:04Z: hyper::proto::h1::io: flushed 169 bytes\nTRACE 2018-07-19T01:56:04Z: hyper::proto::h1::io: reclaiming write buf Vec\nDEBUG 2018-07-19T01:56:04Z: hyper::proto::h1::io: flushed 5 bytes\nTRACE 2018-07-19T01:56:04Z: hyper::proto::h1::conn: flushed State { reading: Init, writing: KeepAlive, keep_alive: Busy, error: None }\nTRACE 2018-07-19T01:56:04Z: hyper::proto::h1::conn: wants_read_again? false\nTRACE 2018-07-19T01:56:05Z: hyper::proto::h1::conn: Conn::read_head\nDEBUG 2018-07-19T01:56:05Z: hyper::proto::h1::io: read 1184 bytes\nTRACE 2018-07-19T01:56:05Z: hyper::proto::h1::role: Response.parse([Header; 100], [u8; 1184])\nTRACE 2018-07-19T01:56:05Z: hyper::proto::h1::role: Response.parse Complete(395)\nTRACE 2018-07-19T01:56:05Z: hyper::header: maybe_literal not found, copying \"Pragma\"\nTRACE 2018-07-19T01:56:05Z: hyper::header: maybe_literal not found, copying \"X-AspNet-Version\"\nTRACE 2018-07-19T01:56:05Z: hyper::header: maybe_literal not found, copying \"X-Powered-By\"\nTRACE 2018-07-19T01:56:05Z: hyper::header: maybe_literal not found, copying \"apim-request-id\"\nTRACE 2018-07-19T01:56:05Z: hyper::header: maybe_literal not found, copying \"x-content-type-options\"\nDEBUG 2018-07-19T01:56:05Z: hyper::proto::h1::io: parsed 11 headers (395 bytes)\nDEBUG 2018-07-19T01:56:05Z: hyper::proto::h1::conn: incoming body is content-length (789 bytes)\nTRACE 2018-07-19T01:56:05Z: hyper::proto: expecting_continue(version=Http11, header=None) = false\nTRACE 2018-07-19T01:56:05Z: hyper::proto: should_keep_alive(version=Http11, header=None) = true\nTRACE 2018-07-19T01:56:05Z: hyper::proto::h1::conn: Conn::read_body\nTRACE 2018-07-19T01:56:05Z: hyper::proto::h1::decode: decode; state=Length(789)\nTRACE 2018-07-19T01:56:05Z: hyper::proto::h1::conn: flushed State { reading: Body(Length(0)), writing: KeepAlive, keep_alive: Busy, error: None }\nTRACE 2018-07-19T01:56:05Z: hyper::proto::h1::conn: wants_read_again? false\nTRACE 2018-07-19T01:56:05Z: hyper::proto::h1::conn: Conn::read_body\nTRACE 2018-07-19T01:56:05Z: hyper::proto::h1::decode: decode; state=Length(0)\nDEBUG 2018-07-19T01:56:05Z: hyper::proto::h1::conn: incoming body completed\nTRACE 2018-07-19T01:56:05Z: hyper::proto::h1::conn: maybe_notify; read_from_io blocked\nTRACE 2018-07-19T01:56:05Z: hyper::proto::h1::conn: read_keep_alive; is_mid_message=false\nTRACE 2018-07-19T01:56:05Z: hyper::proto::h1::conn: flushed State { reading: Init, writing: Init, keep_alive: Idle, error: None }\nTRACE 2018-07-19T01:56:05Z: hyper::proto::h1::conn: wants_read_again? false\nTRACE 2018-07-19T01:56:05Z: hyper::client::pool: Pool::put \"https://westus.api.cognitive.microsoft.com\"\nDEBUG 2018-07-19T01:56:05Z: hyper::client::pool: pooling idle connection for \"https://westus.api.cognitive.microsoft.com\"\nGot token: eyJhbGciOiJodHRwOi8vd3d3LnczLm9yZy8yMDAxLzA0L3htbGRzaWctbW9yZSNobWFjLXNoYTI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ1cm46bXMuY29nbml0aXZlc2VydmljZXMiLCJleHAiOiIxNTMxOTY1OTY1IiwicmVnaW9uIjoid2VzdHVzIiwic3Vic2NyaXB0aW9uLWlkIjoiOGE5ODE4NDU5ODNhNGM5M2JlMWU0MjNhMWNkY2E5N2QiLCJwcm9kdWN0LWlkIjoiQ1JJUy5TMiIsImNvZ25pdGl2ZS1zZXJ2aWNlcy1lbmRwb2ludCI6Imh0dHBzOi8vYXBpLmNvZ25pdGl2ZS5taWNyb3NvZnQuY29tL2ludGVybmFsL3YxLjAvIiwiYXp1cmUtcmVzb3VyY2UtaWQiOiIvc3Vic2NyaXB0aW9ucy9iZDAxMDU0YS01MzFiLTQ1OWMtOGY2Zi0zODg3ZDRlOGFmOWQvcmVzb3VyY2VHcm91cHMvQ3VzdG9tU3BlZWNoL3Byb3ZpZGVycy9NaWNyb3NvZnQuQ29nbml0aXZlU2VydmljZXMvYWNjb3VudHMvQ3VzdG9tU3BlZWNoIiwic2NvcGUiOiJodHRwczovL3dlc3R1cy5hcGkuY29nbml0aXZlLm1pY3Jvc29mdC5jb20vY3VzdG9tc3BlZWNoIiwiYXVkIjoidXJuOm1zLmN1c3RvbXNwZWVjaCJ9.21TNU0nIbm5uJjhTaRU3WRADZXNdbUU9UcgMDgzRISg\nTRACE 2018-07-19T01:56:05Z: hyper::client::pool: park; waiting for idle connection: \"https://westus.stt.speech.microsoft.com\"\nTRACE 2018-07-19T01:56:05Z: hyper::client::connect: Http::connect(\"https://westus.stt.speech.microsoft.com/speech/recognition/interactive/cognitiveservices/v1?language=en-US&cid=this-is-some-endpoint-id&format=detailed\")\nDEBUG 2018-07-19T01:56:05Z: hyper::client::dns: resolving host=\"westus.stt.speech.microsoft.com\", port=443\nDEBUG 2018-07-19T01:56:05Z: hyper::client::connect: connecting to 104.42.72.155:443\nthread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: Io(Custom { kind: Other, error: Custom { kind: Other, error: Kind(UnexpectedEof) } })', libcore/result.rs:945:5\nnote: Run with `RUST_BACKTRACE=1` for a backtrace.. I tried updating the dependencies to the latest versions hoping there's a fix but there doesn't seem to be a fix for it yet. Where should I be reporting this issue if it really is the TLS handshake problem? :sweat_smile: . ",
    "SunDoge": "Use Arc to wrap the container.. ",
    "lambdasqd": "PR #1634 should fix this.\nHere is a comparison of the Apache Bench output before and after.\nbefore change\n```\n$ ab -k http://127.0.0.1:3000/\nThis is ApacheBench, Version 2.3 <$Revision: 1807734 $>\nCopyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/\nLicensed to The Apache Software Foundation, http://www.apache.org/\nBenchmarking 127.0.0.1 (be patient)...apr_pollset_poll: The timeout specified has expired (70007)\n```\nafter change\n```\n$ ab -k http://127.0.0.1:3000/\nThis is ApacheBench, Version 2.3 <$Revision: 1807734 $>\nCopyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/\nLicensed to The Apache Software Foundation, http://www.apache.org/\nBenchmarking 127.0.0.1 (be patient).....done\nServer Software:      \nServer Hostname:        127.0.0.1\nServer Port:            3000\nDocument Path:          /\nDocument Length:        12 bytes\nConcurrency Level:      1\nTime taken for tests:   0.001 seconds\nComplete requests:      1\nFailed requests:        0\nKeep-Alive requests:    1\nTotal transferred:      112 bytes\nHTML transferred:       12 bytes\nRequests per second:    939.85 [#/sec] (mean)\nTime per request:       1.064 [ms] (mean)\nTime per request:       1.064 [ms] (mean, across all concurrent requests)\nTransfer rate:          102.80 [Kbytes/sec] received\nConnection Times (ms)\n              min  mean[+/-sd] median   max\nConnect:        0    0   0.0      0       0\nProcessing:     1    1   0.0      1       1\nWaiting:        1    1   0.0      1       1\nTotal:          1    1   0.0      1       1\n```. ",
    "liufuyang": "As I got some help from gitter, this way of doing worked for me\n```\n// rt::run(fut);\nlet mut runtime = Runtime::new().unwrap();\nmatch runtime.block_on(fut) {\n     Ok(s) => {\n            println!(\"After wait: SMReslt: {:#?}\", &s);\n      }\n      Err(_) => (),\n};\n```. ",
    "madmaxio": "I think https://tokio-rs.github.io/tokio/tokio/runtime/current_thread/fn.block_on_all.html from tokio master branch should work, have not tested though.. What do you mean by public mocks?. ",
    "theshmurph": "no more error, thank you !\n. ",
    "jongiddy": "Thanks for the clear explanation. I will close this issue.. ",
    "nivkner": "added a cfg to allow building on rust 1.21 as requested.. Removed breaking change. ",
    "jesskfullwood": "Thanks for you suggestion. However, changing the http1_writev setting made no difference.\nAfter testing a little more carefully I have concluded that it doesn't matter whether the external request is HTTP or HTTPS, it will still be corrupted if the server is using TLS (and succeed otherwise).\nTo be clear, the server handshakes all succeed and the headers all seem in order. It is just the payload body that is corrupted.. @seanmonstar Well spotted, it seems I was using rustls for the server and hyper-tls for the client (client is pretty much copy-pasta of https://github.com/hyperium/hyper-tls/blob/dc8a13409b753ce212aada925ad5edb58e185349/examples/client.rs) But the errors occurred whether the external call was http or https so I think we can rule out errors in hyper-tls.\nI'll try to set up a reproduction.. I couldn't reproduce the problem locally (with a self signed cert) so I ssh'd into the EC2 box and tested it 'locally' on the server with curl, and the problem disappeared. I ssh'd into a different EC2 instance and tested it from there and the problem reappeared. So it only seems to happen when serving external requests.. I've made a repro here - https://github.com/jesskfullwood/hyper-proxy-bug. Unfortunately you need a spare server to deploy it. Agree rustls seems the likely culprit.. ",
    "quininer": "I think here needs your help. @ctz. Ah, tokio-rustls 0.5 doesn't have this problem, but I neglected this when I migrated to rustls::Stream.\n\nFrom: ctz notifications@github.com\nSent: Friday, August 17, 2018 4:59:05 AM\nTo: hyperium/hyper\nCc: quininer; Manual\nSubject: Re: [hyperium/hyper] TLS server corrupts large client responses (#1631)\nOK, I now understand what's happening. It revolves around use of rustls::Stream with non-blocking transports. This wasn't really supported, and indeed the documentationhttps://docs.rs/rustls/0.13.0/rustls/struct.Stream.html (though alas not the std::io type system) for the type states the requirement for a blocking transport. This can be made to work, and I'll push a version of rustls which supports this shortly.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHubhttps://github.com/hyperium/hyper/issues/1631#issuecomment-413682764, or mute the threadhttps://github.com/notifications/unsubscribe-auth/AF_tqSdoD2RsbE25RqRvxYzQeXPkQqTUks5uRd0ZgaJpZM4V5FIT.\n. I just published tokio-rustls 0.7.2, which should fix the problem. By the way, it also has writev support.. @LucioFranco Ah, this looks like what I want!. After reading it, I found that tower-hyper will actually reimplement a Client. It currently lacks many of the capabilities that hyper should have, such as h2 and connection pool.\n@LucioFranco Will tower-hyper reimplement these? Still possible to reuse hyper?. @carllerche I am looking forward!\n@LucioFranco This sounds reasonable. but the tower-hyper Connector dropped Connected, which made hyper unable to use h2 via alpn.. @LucioFranco It's interesting! I will try to use tower.. > The issue this creates is that in order for something to be both a BufStream and Body, it could only manually implement BufStream, and assume the blanket Body implementation, which skips trailers.\nI think tower-http-service takes this into account. We can implement the Body and then get BufStream by BodyExt.. ",
    "ctz": "Thanks for the repro, I'll look at this asap. I can reproduce this, and echo the difficulty getting a reproduction over loopback. The discontinuities seem to be non-deterministic, too. So I'm currently thinking the bug is happening only when TCP buffers get filled, and then somewhere backpressure goes wrong. Still looking.. I've dumped the plaintext data going into rustls and it's pretty clearly going wrong before there:\n$ tail plaintext.14.dat \n16114\n16115\n16116\n16117\n16118\n16119\n16120\n16121\n16122\n161\n$ head plaintext.15.dat \n4762\n14763\n14764\n14765\n14766\n14767\n14768\n14769\n14770\n14771\nThese are two sequential writes, so 'plaintext.15.dat' should've started 23\\r\\n16124. However plaintext.14.dat is a prefix of plaintext.15.dat, so it feels like something is failing to move a buffer along somewhere.. OK, I now understand what's happening. It revolves around use of rustls::Stream with non-blocking transports. This wasn't really supported, and indeed the documentation (though alas not the std::io type system) for the type states the requirement for a blocking transport. This can be made to work, and I'll push a version of rustls which supports this shortly.. I've just published rustls 0.13.1 too.. ",
    "neowutran": "Probably the same bug:\nhttps://github.com/actix/actix-web/issues/438#issuecomment-410017947 \nOpenSSL -> OK\nRustls -> Nop \nCannot be reproduced on localhost, you need a spare server to deploy it. \n. ",
    "JeanMertz": "Thank you for the pointer @seanmonstar. That helped me move forward.\nedit here's the full source code of the second (non-working) example: https://gist.github.com/JeanMertz/4278c2cfaebae9c8e57a4c69e5c75435\nedit 2 Turns out it was as simple as turning req.body_mut() into req.into_body(), still have to figure out why that is (it \"Consumes the request\", but I don't quite understand yet how that relates to the borrow checker), but it works :smiley:\n\nI'm close, but having difficulty wrapping this up:\n```rust\nfn main() {\n    let addr = ([127, 0, 0, 1], 3000).into();\n    let service = || service_fn(proxy);\nlet server = Server::bind(&addr)\n    .serve(service)\n    .map_err(|e| eprintln!(\"server error: {}\", e));\n\nhyper::rt::run(server);\n\n}\nfn proxy(req: Request) -> impl Future, Error = Error> {\n    let client = Client::new();\nreq.body_mut()\n    .concat2()\n    .map(|chunk| chunk.to_vec())\n    .map(|vec| {\n        let uri = uri_from_request_body(&vec);\n        let mut new_request = Request::builder();\n\n        new_request.version(req.version()).method(req.method());\n\n        for (key, value) in req.headers() {\n            new_request.header(key, value);\n        }\n\n        new_request\n            .uri(&uri)\n            .header(http::header::HOST, uri.host().unwrap())\n            .body(Body::from(vec))\n            .unwrap()\n    }).and_then(|req| client.request(req))\n\n}\n```\nThere's a lot of unwrapping going on (trying to get the happy path to work first), but this example doesn't compile yet, and I'm not sure yet how to tackle this:\nhttps://gist.github.com/JeanMertz/a38abfa49ad12f6faa60aca48f8b0fba\nAny thoughts on the proposed solution and how to handle the cannot be shared between threads safely error?\nI had another solution that made the Future simpler, but caused problems with the borrow checker:\n```rust\nreq.body_mut()\n    .concat2()\n    .map(|chunk| chunk.to_vec())\n    .map(move |vec| {\n        let uri = uri_from_request_body(&vec);\n    new_request\n        .uri(&uri)\n        .header(http::header::HOST, uri.host().unwrap())\n        .body(Body::from(vec))\n        .unwrap()\n}).and_then(move |new_req| client.request(new_req))\n\n```\nerror[E0597]: `req` does not live long enough\n   --> src/main.rs:148:5\n    |\n148 |     req.body_mut()\n    |     ^^^ borrowed value does not live long enough\n...\n160 | }\n    | - borrowed value only lives until here\n    |\n    = note: borrowed value must be valid for the static lifetime.... ",
    "kschiess": "I've found that decomposing 'req' into '.parts()', I can more easily clone/reuse parts of the request for a client connection. Here's a bit of code: \nrust\nlet (mut parts, body) = req.into_parts();\n// Use and clone at will\nlet req = Request::from_parts(parts, body);\nMaybe that helps?. ",
    "piaojin": "This is my Cargo.toml:\n[package]\nname = \"hyper_demo\"\nversion = \"0.1.0\"\nauthors = [\"Zoey Weng zoey.weng@ringcentral.com\"]\n[dependencies]\nhyper = \"0.12\"\n[lib]\ncrate-type = [\"staticlib\"]\nAnd make file:\nARCHS = i386-apple-ios x86_64-apple-ios aarch64-apple-ios armv7s-apple-ios armv7-apple-ios\nLIB = hyper_demo.a\nall: $(LIB)\n.PHONY: $(ARCHS)\n$(ARCHS): %:\n    cargo build --target $@\n$(LIB): $(ARCHS)\n    lipo -create -output $@ $(foreach arch,$(ARCHS),$(wildcard target/$(arch)/debug/$(LIB))). Thank you all the same!. @seanmonstar I have solved this problem by using cargo lipo.. ",
    "tamoyal": "When I do that, I get this error:\nrt::run(server);\n^^^^^^^ expected tuple, found (). This is what I have going on now (let me know if you want a full example):\n```\n...\nlet new_service = move || {\n  service_fn(...)\n};\nlet server = Server::bind(&addr)\n    .serve(new_service);\nlet f = server\n  .map_err(|e| panic!(\"server error: {}\", e))\n  .select(shutdown_rx.then(|| {\n     println!(\"Got shutdown_rx\");\n    Ok(())\n})).then(|| Ok(()));\nrt::run(f);\nprintln!(\"Server shutdown\");\n```\nI do get the \"Got shutdown_rx\" message but never the \"Server shutdown\" message so I still cannot invoke a server shutdown. ",
    "dmexe": "@seanmonstar \nI've created RFC with the more generic solution\nhttps://github.com/hyperium/http/issues/241. ",
    "niklasf": "Makes sense. Thanks.. ",
    "Eijebong": "Yup, fixed by the http PR :+1: Thanks !. ",
    "rainchen": "+1 for this request, ip address info is very useful for a network service. ",
    "miquels": "See also https://github.com/carllerche/tower-web/issues/71. hey, I was about to send in a similar patch. I wrote hyper-tls-hack , an implementation of AddrIncoming that supports TLS using tokio-tls. It has a from_std_listener(std_listener: StdTcpListener,.... method, which I was about to split off and add to hyper's AddrIncoming. See the code here .. ",
    "felipenoris": "I'm working on a reverse proxy using hyper (new version for https://github.com/brendanzab/hyper-reverse-proxy), and this is quite useful to implement x-forwarded-for header. The former version was hooked directly to TcpListener, which is quite low level.. Yes, the idea is to have something similar to go's httputils. See https://golang.org/pkg/net/http/httputil/#ReverseProxy .\nI understand that this might seem too high level for this library, in which case you can just reject this idea and close this issue.. Thank you! It works!!. ",
    "tristan957": "Thanks Sean. I believe you were probably right. I never got a chance to go back to look at the code, as the project has started to take a different direction, but thank you for the time you gave me.. ",
    "gngeorgiev": "Alright, I get it, thanks. I want to use the tokio current_thread runtime which should work fine with the futures hyper returns. What I saw in the activity monitor was that the hyper client spawns 4 additional threads and uses a few hundred more kb of memory, which led me to believe that it initializes it's own runtime, which I will never use anyways, that's why I wanted to disable it. . @seanmonstar Thank you for your replies they were very helpful.\nImplementing Connect is definitely on the table but I will leave that optimization for further along. For the time being, I opted for creating an HttpConnector with a smaller pool.\nlet connector = hyper::client::HttpConnector::new(1);\nlet client: hyper::Client<hyper::client::HttpConnector, hyper::body::Body> =\n        hyper::client::Builder::default().build(connector);\nI will close this issue now, hopefully, it will help someone in the future.. ",
    "Nemo157": "Here\u2019s a WIP blog post on the compatibility layer available since futures-preview 0.3.0-alpha.3, it should be possible with this to use hyper in an async fn. In fact, rereading it now the final example is using hyper.. ",
    "johnkarasev": "ok thanks. is it in crates.io? \n. ",
    "Firstyear": "Another example that would be useful is how to correctly use status codes to then provide logic of how to decode json for example, as the use of futures and their integration with these libraries is not always clear. Having a reference written by experts is really useful as a lesson for inexperienced futures users like myself to understand the right way to use these.. ",
    "hbobenicio": "I feel your pain and I also miss a lot more guide docs and a lot more examples about clients in hyper (either synchronously and asynchronously).\nI'm a newcomer and I've already spent a day trying to start N client requests with hyper. Still struggling...\nThe first headache I've encountered is that the docs only says:\n\n\"By default, hyper can make use of the Tokio runtime, via hyper::rt\"\n\nAnd that's all about it. What is a Tokio runtime? How do I start it? Why there is now snippet showing how to start it in the guide docs? \nAll it has are these comments:\n\n// still inside rt::run...\n\nAt the end of the guide, we also have this:\n\nAnd that\u2019s it! You can see the full example here.\n\nThere are only 2 examples there: client.rs and client_json.rs\nReading them I finally discover that I need to run hyper::rt::run(my_future);\nOk... got it and it works (for 1 future only). But how about an example or a guide section showing how to run N client futures? And what if we want them to run syncronously or asyncronously? After a long reading about Tokio Futures, I've discovered about .wait() and .join()... but those doen't fit well with hyper::rt::run I guess ... do I need to use tokio::run instead? I have no clue...\n. ",
    "arsing": "rust\nlet res = client.get(\"unix://foo/containers/json\".parse().unwrap());\nlet res = runtime.block_on(res)?;\nprintln!(\"{:?}\", res);\nResponse { status: 200, version: HTTP/1.1, headers: {\"api-version\": \"1.38\", \"content-type\": \"application/json\", \"docker-experimental\":\"false\", \"ostype\": \"linux\", \"server\": \"Docker/18.06.1-ce (linux)\", \"date\": \"Thu, 27 Sep 2018 21:01:33 GMT\", \"content-length\": \"932\"}, body: Body }\nrust\nlet res = res.into_body().concat2();\nlet res = runtime.block_on(res)?;\nprintln!(\"{}\", std::str::from_utf8(&*res).unwrap());\n```\n[{\"Id\":\"2fe4d77abfdc10ea49957e80817ef4067d9d7a293ceed7dbfe2a333a5434441b\",\"Names\":[\"/priceless_mendeleev\"],\"Image\":\"ubuntu:18.04\",\"ImageID\":\"sha256:cd6d8154f1e16e38493c3c2798977c5e142be5e5d41403ca89883840c6d51762\",\"Command\":\"/bin/bash\",\"Created\":1537995262,\"Ports\":[],\"Labels\":{},\"State\":\"running\",\"Status\":\"Up 24 hours\",\"HostConfig\":{\"NetworkMode\":\"default\"},\"NetworkSettings\":{\"Networks\":{\"bridge\":{\"IPAMConfig\":null,\"Links\":null,\"Aliases\":null,\"NetworkID\":\"16b3fa2409d924d53d7df7e61b80183e468f1009ea3b47c8b812f54b548f4d36\",\"EndpointID\":\"ce2d65005e22641d9ddcd58b90da09cef9480bf0e1b0767e3cf0746c625ae7ab\",\"Gateway\":\"172.17.0.1\",\"IPAddress\":\"172.17.0.3\",\"IPPrefixLen\":16,\"IPv6Gateway\":\"\",\"GlobalIPv6Address\":\"\",\"GlobalIPv6PrefixLen\":0,\"MacAddress\":\"02:42:ac:11:00:03\",\"DriverOpts\":null}}},\"Mounts\":[{\"Type\":\"bind\",\"Source\":\"/var/run/docker.sock\",\"Destination\":\"/var/run/docker.sock\",\"Mode\":\"\",\"RW\":true,\"Propagation\":\"rprivate\"}]}]\n``. Another wrench in the works is that reverting 6530a00a8e3449a8fd7e4ed6ad1231b6b1579c38 does *not* make my actual code (from which I created the minimal repro in the OP) work. The only way I could get my actual code to work was disablingkeep_alive` on the Client builder, which presumably makes it so that the connections never get pooled and reused. But I'll open a new issue about that later unless you think it's relevant to this one.. \n\nRUST_LOG=hyper=trace\n\n```\n TRACE hyper::proto::h1::conn       > flushed({role=client}): State { reading: Body(Chunked(Body, 16685)), writing: KeepAlive, keep_alive: Busy, error: None }\n TRACE hyper::client::pool          > checkout waiting for idle connection: (\"unix://foo\", Http1)\n TRACE hyper::proto::h1::conn       > read_keep_alive; is_mid_message=false\n TRACE hyper::proto::h1::conn       > flushed({role=client}): State { reading: Init, writing: Init, keep_alive: Busy, error: None }\n TRACE hyper::proto::h1::conn       > read_keep_alive; is_mid_message=false\n TRACE hyper::proto::h1::role       > Client::encode method=GET, body=None\n DEBUG hyper::proto::h1::io         > flushed 44 bytes\n TRACE hyper::proto::h1::conn       > flushed({role=client}): State { reading: Init, writing: KeepAlive, keep_alive: Busy, error: None }\n TRACE hyper::proto::h1::conn       > Conn::read_head\n DEBUG hyper::proto::h1::io         > read 2356 bytes\n TRACE hyper::proto::h1::role       > Response.parse([Header; 100], [u8; 2356])\n TRACE hyper::proto::h1::role       > Response.parse Complete(213)\n DEBUG hyper::proto::h1::io         > parsed 7 headers\n DEBUG hyper::proto::h1::conn       > incoming body is chunked encoding\n TRACE hyper::proto::h1::decode     > decode; state=Chunked(Size, 0)\n TRACE hyper::proto::h1::decode     > Read chunk hex size\n TRACE hyper::proto::h1::decode     > Read chunk hex size\n TRACE hyper::proto::h1::decode     > Read chunk hex size\n TRACE hyper::proto::h1::decode     > Read chunk hex size\n TRACE hyper::proto::h1::decode     > Chunk size is 2131\nuds response 1: Response { status: 200, version: HTTP/1.1, headers: {\"api-version\": \"1.38\", \"content-type\": \"application/json\", \"docker-experimental\":\"false\", \"ostype\": \"linux\", \"server\": \"Docker/18.06.1-ce (linux)\", \"date\": \"Thu, 27 Sep 2018 21:56:34 GMT\", \"transfer-encoding\": \"chunked\"}, body: Body }\nDEBUG hyper::proto::h1::decode     > incoming chunked header: 0x853 (2131 bytes)\n TRACE hyper::proto::h1::decode     > Chunked read, remaining=2131\n TRACE hyper::proto::h1::conn       > flushed({role=client}): State { reading: Body(Chunked(BodyCr, 0)), writing: KeepAlive, keep_alive: Busy, error: None }\n TRACE hyper::proto::h1::decode     > decode; state=Chunked(BodyCr, 0)\n TRACE hyper::proto::h1::decode     > Read chunk hex size\n TRACE hyper::proto::h1::decode     > Read chunk hex size\n TRACE hyper::proto::h1::decode     > Chunk size is 0\n TRACE hyper::proto::h1::decode     > end of chunked\n DEBUG hyper::proto::h1::conn       > incoming body completed\n TRACE hyper::proto::h1::conn       > maybe_notify; read_from_io blocked\n TRACE hyper::proto::h1::conn       > read_keep_alive; is_mid_message=false\n TRACE hyper::client::pool          > put; add idle connection for (\"unix://foo\", Http1)\n DEBUG hyper::client::pool          > pooling idle connection for (\"unix://foo\", Http1)\n TRACE hyper::proto::h1::conn       > read_keep_alive; is_mid_message=false\nuds response 1: [[{\"Id\":\"2b4becd634bc7889aaafa37d40428087b7c75dd574d0fcc4f1a4433c58cd9931\",\"Names\":[\"/gifted_stallman\"],\"Image\":\"opensuse/leap\",\"ImageID\":\"sha256:955e76b95d1182923e18705b6e38fb8d17d359b35326229f23ae36c25d729942\",\"Command\":\"/bin/bash\",\"Created\":1538083890,\"Ports\":[],\"Labels\":{\"org.openbuildservice.disturl\":\"'obs://build.opensuse.org/openSUSE:Leap:15.0:Images/images/38c57b233e3f5117449dda35187b617a-opensuse-leap-image:docker'\"},\"State\":\"running\",\"Status\":\"Up 25 minutes\",\"HostConfig\":{\"NetworkMode\":\"default\"},\"NetworkSettings\":{\"Networks\":{\"bridge\":{\"IPAMConfig\":null,\"Links\":null,\"Aliases\":null,\"NetworkID\":\"16b3fa2409d924d53d7df7e61b80183e468f1009ea3b47c8b812f54b548f4d36\",\"EndpointID\":\"cd67a2a1c54e518f2b254b7dafecf6147201967c753bb073aaca33d12814d134\",\"Gateway\":\"172.17.0.1\",\"IPAddress\":\"172.17.0.2\",\"IPPrefixLen\":16,\"IPv6Gateway\":\"\",\"GlobalIPv6Address\":\"\",\"GlobalIPv6PrefixLen\":0,\"MacAddress\":\"02:42:ac:11:00:02\",\"DriverOpts\":null}}},\"Mounts\":[{\"Type\":\"bind\",\"Source\":\"/home/arsing/iotedge\",\"Destination\":\"/iotedge\",\"Mode\":\"\",\"RW\":true,\"Propagation\":\"rprivate\"},{\"Type\":\"bind\",\"Source\":\"/var/run/docker.sock\",\"Destination\":\"/var/run/docker.sock\",\"Mode\":\"\",\"RW\":true,\"Propagation\":\"rprivate\"}]},{\"Id\":\"2fe4d77abfdc10ea49957e80817ef4067d9d7a293ceed7dbfe2a333a5434441b\",\"Names\":[\"/priceless_mendeleev\"],\"Image\":\"ubuntu:18.04\",\"ImageID\":\"sha256:cd6d8154f1e16e38493c3c2798977c5e142be5e5d41403ca89883840c6d51762\",\"Command\":\"/bin/bash\",\"Created\":1537995262,\"Ports\":[],\"Labels\":{},\"State\":\"running\",\"Status\":\"Up 25 hours\",\"HostConfig\":{\"NetworkMode\":\"default\"},\"NetworkSettings\":{\"Networks\":{\"bridge\":{\"IPAMConfig\":null,\"Links\":null,\"Aliases\":null,\"NetworkID\":\"16b3fa2409d924d53d7df7e61b80183e468f1009ea3b47c8b812f54b548f4d36\",\"EndpointID\":\"ce2d65005e22641d9ddcd58b90da09cef9480bf0e1b0767e3cf0746c625ae7ab\",\"Gateway\":\"172.17.0.1\",\"IPAddress\":\"172.17.0.3\",\"IPPrefixLen\":16,\"IPv6Gateway\":\"\",\"GlobalIPv6Address\":\"\",\"GlobalIPv6PrefixLen\":0,\"MacAddress\":\"02:42:ac:11:00:03\",\"DriverOpts\":null}}},\"Mounts\":[{\"Type\":\"bind\",\"Source\":\"/var/run/docker.sock\",\"Destination\":\"/var/run/docker.sock\",\"Mode\":\"\",\"RW\":true,\"Propagation\":\"rprivate\"}]}]\n]\nTRACE hyper::client::pool          > take? (\"unix://foo\", Http1): expiration = Some(90s)\n DEBUG hyper::client::pool          > reuse idle connection for (\"unix://foo\", Http1)\n TRACE hyper::proto::h1::conn       > read_keep_alive; is_mid_message=false\n TRACE hyper::proto::h1::role       > Client::encode method=GET, body=None\n```\n\n\n\n\n`RUST_LOG=trace`\n\n\n\n```\n TRACE tokio_threadpool::worker     > stole task\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=45\n TRACE tokio_threadpool::task       > Task::run; state=Running\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=45\n TRACE tokio_threadpool::task       >     -> not ready\n TRACE tokio_threadpool::sender     > execute; count=5\n TRACE tokio_threadpool::worker     > try_steal_task -- signal_work; self=43; from=42\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=47\n TRACE tokio_threadpool::pool       > submit to existing worker; idx=44; state=worker::State { lifecycle: Sleeping, is_pushed: true }\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(46)\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=46\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=44\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(42)\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=47\n TRACE tokio_threadpool::worker     > found work while draining; signal_work\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=46\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=42\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=46\n TRACE tokio_threadpool::worker     > stole task\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=42\n TRACE tokio_threadpool::task       > Task::run; state=Running\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=46\n TRACE hyper::client::pool          > checkout waiting for idle connection: (\"unix://foo\", Http1)\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(45)\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=45\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(47)\n TRACE mio::poll                    > registering with poller\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(44)\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=45\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(46)\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=47\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=44\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=46\n TRACE tokio_reactor                > event Writable Token(8388610)\n TRACE tokio_threadpool::task       >     -> not ready\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=46\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=47\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=44\n TRACE tokio_threadpool::worker     > try_steal_task -- signal_work; self=43; from=44\n TRACE tokio_threadpool::notifier   > Notifier::notify; id=0x7fb661e611d0\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=46\n TRACE tokio_threadpool::pool       > submit to existing worker; idx=44; state=worker::State { lifecycle: Sleeping, is_pushed: true }\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=46\n DEBUG tokio_reactor                > loop process - 1 events, 0.000s\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=44\n TRACE tokio_threadpool::worker     > found work while draining; signal_work\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=47\n TRACE tokio_threadpool::worker     > stole task\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=47\n TRACE tokio_threadpool::task       > Task::run; state=Running\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(43)\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=43\n TRACE tokio_threadpool::sender     > execute; count=6\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=43\n TRACE tokio_threadpool::pool       >     -> submit internal; idx=46\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=43\n TRACE tokio_threadpool::worker     > stole task\n TRACE tokio_threadpool::task       > Task::run; state=Running\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=43\n TRACE tokio_threadpool::task       >     -> not ready\n TRACE hyper::proto::h1::conn       > read_keep_alive; is_mid_message=false\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(47)\n TRACE tokio_threadpool::worker     > try_steal_task -- signal_work; self=46; from=44\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=47\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=45\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=47\n TRACE want                         > signal: Want\n TRACE want                         > signal found waiting giver, notifying\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=45\n TRACE tokio_threadpool::notifier   > Notifier::notify; id=0x7fb661e611d0\n TRACE tokio_threadpool::pool       >     -> submit internal; idx=44\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=47\n TRACE tokio_threadpool::worker     > stole task\n TRACE tokio_threadpool::task       > Task::run; state=Running\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=47\n TRACE hyper::proto::h1::conn       > flushed({role=client}): State { reading: Init, writing: Init, keep_alive: Busy, error: None }\n TRACE want                         > poll_want: taker wants!\n TRACE tokio_threadpool::task       >     -> not ready\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(46)\n TRACE tokio_threadpool::worker     > try_steal_task -- signal_work; self=44; from=46\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=46\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=42\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=46\n TRACE tokio_threadpool::notifier   > Notifier::notify; id=0x7fb65f8531d0\n TRACE tokio_reactor                > event Readable | Writable Token(4194305)\n TRACE tokio_threadpool::pool       >     -> submit internal; idx=43\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=42\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=46\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(47)\n DEBUG tokio_reactor                > loop process - 1 events, 0.000s\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=47\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(45)\n TRACE tokio_threadpool::task       >     -> not ready\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=46\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=47\n TRACE tokio_threadpool::worker     > stole task\n TRACE tokio_reactor                > event Readable | Writable Token(4194305)\n TRACE tokio_threadpool::worker     > try_steal_task -- signal_work; self=43; from=44\n TRACE tokio_threadpool::task       > Task::run; state=Running\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=45\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=47\n TRACE hyper::proto::h1::conn       > read_keep_alive; is_mid_message=false\n DEBUG tokio_reactor                > loop process - 1 events, 0.000s\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=45\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=47\n TRACE hyper::proto::h1::role       > Client::encode method=GET, body=None\n TRACE tokio_reactor                > event Readable | Writable Token(4194305)\n DEBUG tokio_reactor                > loop process - 1 events, 0.000s\n DEBUG hyper::proto::h1::io         > flushed 44 bytes\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(46)\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=46\n TRACE hyper::proto::h1::conn       > flushed({role=client}): State { reading: Init, writing: KeepAlive, keep_alive: Busy, error: None }\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=46\n TRACE tokio_reactor                > event Writable Token(8388610)\n TRACE tokio_threadpool::task       >     -> not ready\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(43)\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(42)\n TRACE tokio_threadpool::worker     > try_steal_task -- signal_work; self=44; from=43\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(47)\n DEBUG tokio_reactor                > loop process - 1 events, 0.000s\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=46\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=42\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=47\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=43\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=46\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=42\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=43\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=47\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(44)\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=44\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(46)\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=44\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=46\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=46\n TRACE tokio_reactor                > event Readable | Writable Token(8388610)\n TRACE tokio_threadpool::notifier   > Notifier::notify; id=0x7fb65f8531d0\n TRACE tokio_threadpool::pool       > submit to existing worker; idx=46; state=worker::State { lifecycle: Sleeping, is_pushed: true }\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=46\n DEBUG tokio_reactor                > loop process - 1 events, 0.000s\n TRACE tokio_threadpool::worker     > found work while draining; signal_work\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=44\n TRACE tokio_threadpool::task       > Task::run; state=Running\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=44\n TRACE hyper::proto::h1::conn       > Conn::read_head\n DEBUG hyper::proto::h1::io         > read 2356 bytes\n TRACE hyper::proto::h1::role       > Response.parse([Header; 100], [u8; 2356])\n TRACE hyper::proto::h1::role       > Response.parse Complete(213)\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(44)\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=44\n DEBUG hyper::proto::h1::io         > parsed 7 headers\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=44\n DEBUG hyper::proto::h1::conn       > incoming body is chunked encoding\n TRACE tokio_threadpool::notifier   > Notifier::notify; id=0x7fb661e611d0\n TRACE tokio_threadpool::pool       >     -> submit internal; idx=46\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=44\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=44\n TRACE hyper::proto::h1::decode     > decode; state=Chunked(Size, 0)\n TRACE hyper::proto::h1::decode     > Read chunk hex size\n TRACE hyper::proto::h1::decode     > Read chunk hex size\n TRACE tokio_threadpool::worker     > stole task\n TRACE hyper::proto::h1::decode     > Read chunk hex size\n TRACE tokio_threadpool::task       > Task::run; state=Running\n TRACE hyper::proto::h1::decode     > Read chunk hex size\n TRACE hyper::proto::h1::decode     > Chunk size is 2131\n TRACE tokio_threadpool::notifier   > Notifier::notify; id=0x7fb65f8531d0\n TRACE tokio_reactor                > event Readable | Writable Token(4194305)\n DEBUG hyper::proto::h1::decode     > incoming chunked header: 0x853 (2131 bytes)\n TRACE tokio_threadpool::sender     > execute; count=7\n TRACE hyper::proto::h1::decode     > Chunked read, remaining=2131\n DEBUG tokio_reactor                > loop process - 1 events, 0.000s\n TRACE tokio_threadpool::pool       >     -> submit internal; idx=44\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=43\n TRACE hyper::proto::h1::conn       > flushed({role=client}): State { reading: Body(Chunked(BodyCr, 0)), writing: KeepAlive, keep_alive: Busy, error: None }\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=43\n TRACE tokio_threadpool::task       >     -> task complete\n TRACE tokio_threadpool::task       >     -> not ready\nuds response 1: Response { status: 200, version: HTTP/1.1, headers: {\"api-version\": \"1.38\", \"content-type\": \"application/json\", \"docker-experimental\":\"false\", \"ostype\": \"linux\", \"server\": \"Docker/18.06.1-ce (linux)\", \"date\": \"Thu, 27 Sep 2018 21:57:41 GMT\", \"transfer-encoding\": \"chunked\"}, body: Body }\n TRACE tokio_threadpool::worker     > stole task\n\n TRACE tokio_threadpool::task       > Task::run; state=Running\n TRACE tokio_threadpool::worker     > task complete; state=pool::State { lifecycle: Running, num_futures: 6 }\n TRACE tokio_threadpool::task       > Task::run; state=Running\n TRACE tokio_threadpool::sender     > execute; count=7\n TRACE tokio_threadpool::worker     > try_steal_task -- signal_work; self=44; from=46\n TRACE tokio_threadpool::task       >     -> not ready\n TRACE hyper::proto::h1::conn       > flushed({role=client}): State { reading: Body(Chunked(BodyCr, 0)), writing: KeepAlive, keep_alive: Busy, error: None }\n TRACE tokio_threadpool::worker     > try_steal_task -- signal_work; self=43; from=44\n TRACE tokio_threadpool::pool       > submit to existing worker; idx=47; state=worker::State { lifecycle: Sleeping, is_pushed: true }\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=42\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=45\n TRACE tokio_threadpool::task       >     -> not ready\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=42\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=47\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=45\n TRACE tokio_threadpool::worker     > found work while draining; signal_work\n TRACE tokio_threadpool::worker     > stole task\n TRACE tokio_threadpool::pool       > signal_work -- spawn; idx=41\n TRACE tokio_threadpool::task       > Task::run; state=Running\n TRACE tokio_threadpool::notifier   > Notifier::notify; id=0x7fb65f8531d0\n TRACE tokio_threadpool::pool       >     -> submit internal; idx=46\n TRACE tokio_threadpool::pool       > signal_work -- spawn; idx=40\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(43)\n TRACE tokio_threadpool::worker     > stole task\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(44)\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=43\n TRACE tokio_threadpool::task       > Task::run; state=Running\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=44\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=43\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=44\n TRACE hyper::proto::h1::decode     > decode; state=Chunked(BodyCr, 0)\n TRACE tokio_threadpool::task       >     -> not ready\n TRACE hyper::proto::h1::decode     > Read chunk hex size\n TRACE tokio_threadpool::worker     > try_steal_task -- signal_work; self=46; from=47\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(45)\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=44\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(47)\n TRACE hyper::proto::h1::decode     > Read chunk hex size\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=47\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=45\n TRACE hyper::proto::h1::decode     > Chunk size is 0\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=47\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=44\n TRACE hyper::proto::h1::decode     > end of chunked\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=45\n DEBUG hyper::proto::h1::conn       > incoming body completed\n TRACE hyper::proto::h1::conn       > maybe_notify; read_from_io blocked\n TRACE tokio_threadpool::notifier   > Notifier::notify; id=0x7fb661e612b0\n TRACE tokio_threadpool::pool       >     -> submit internal; idx=42\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=45\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(46)\n TRACE tokio_threadpool::worker     > stole task\n TRACE tokio_threadpool::notifier   > Notifier::notify; id=0x7fb661e612b0\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=46\n TRACE tokio_threadpool::task       > Task::run; state=Running\n TRACE hyper::proto::h1::conn       > read_keep_alive; is_mid_message=false\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=46\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=45\n TRACE tokio_threadpool::task       >     -> not ready\n TRACE want                         > signal: Want\n TRACE tokio_threadpool::worker     > try_steal_task -- signal_work; self=44; from=42\n TRACE want                         > signal found waiting giver, notifying\n TRACE tokio_threadpool::worker     > stole task\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=46\n TRACE tokio_threadpool::notifier   > Notifier::notify; id=0x7fb65ec3f0f0\n TRACE tokio_threadpool::task       > Task::run; state=Running\n TRACE tokio_threadpool::pool       >     -> submit internal; idx=42\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=46\n TRACE tokio_threadpool::task       >     -> not ready\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=47\n TRACE tokio_threadpool::worker     > try_steal_task -- signal_work; self=45; from=44\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=43\n TRACE tokio_threadpool::worker     > stole task\n TRACE tokio_threadpool::task       >     -> not ready\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=47\n TRACE tokio_threadpool::task       > Task::run; state=Running\n TRACE tokio_threadpool::worker     > try_steal_task -- signal_work; self=42; from=46\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=43\n TRACE want                         > poll_want: taker wants!\n TRACE tokio_threadpool::pool       > signal_work -- spawn; idx=39\n TRACE hyper::client::pool          > put; add idle connection for (\"unix://foo\", Http1)\n DEBUG hyper::client::pool          > pooling idle connection for (\"unix://foo\", Http1)\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(46)\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=46\n TRACE tokio_threadpool::sender     > execute; count=8\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=46\n TRACE tokio_threadpool::pool       >     -> submit internal; idx=44\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(45)\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=46\n TRACE tokio_threadpool::worker     > stole task\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(41)\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=45\n TRACE tokio_threadpool::task       > Task::run; state=Running\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=41\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=46\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(43)\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=41\n TRACE tokio_threadpool::notifier   > Notifier::notify; id=0x7fb661e612b0\n TRACE tokio_threadpool::task       >     -> not ready\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=43\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=45\n TRACE tokio_threadpool::worker     > try_steal_task -- signal_work; self=47; from=44\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=43\n TRACE tokio_threadpool::pool       >     -> submit internal; idx=44\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(40)\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(42)\n TRACE tokio_threadpool::worker     > stole task\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=40\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=43\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=42\n TRACE tokio_threadpool::task       > Task::run; state=Running\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=40\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=41\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=42\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=43\n TRACE tokio_threadpool::notifier   > Notifier::notify; id=0x7fb65f8531d0\n TRACE tokio_threadpool::task       >     -> task complete\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=41\n TRACE tokio_threadpool::pool       >     -> submit internal; idx=46\n TRACE tokio_threadpool::worker     > task complete; state=pool::State { lifecycle: Running, num_futures: 7 }\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=42\n TRACE tokio_threadpool::worker     > stole task\n TRACE tokio_threadpool::worker     > try_steal_task -- signal_work; self=44; from=42\n TRACE tokio_threadpool::task       > Task::run; state=Running\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=42\nuds response 1: [ TRACE tokio_threadpool::task       >     -> task complete\n[{\"Id\":\"2b4becd634bc7889aaafa37d40428087b7c75dd574d0fcc4f1a4433c58cd9931\",\"Names\":[\"/gifted_stallman\"],\"Image\":\"opensuse/leap\",\"ImageID\":\"sha256:955e76b95d1182923e18705b6e38fb8d17d359b35326229f23ae36c25d729942\",\"Command\":\"/bin/bash\",\"Created\":1538083890,\"Ports\":[],\"Labels\":{\"org.openbuildservice.disturl\":\"'obs://build.opensuse.org/openSUSE:Leap:15.0:Images/images/38c57b233e3f5117449dda35187b617a-opensuse-leap-image:docker'\"},\"State\":\"running\",\"Status\":\"Up 26 minutes\",\"HostConfig\":{\"NetworkMode\":\"default\"},\"NetworkSettings\":{\"Networks\":{\"bridge\":{\"IPAMConfig\":null,\"Links\":null,\"Aliases\":null,\"NetworkID\":\"16b3fa2409d924d53d7df7e61b80183e468f1009ea3b47c8b812f54b548f4d36\",\"EndpointID\":\"cd67a2a1c54e518f2b254b7dafecf6147201967c753bb073aaca33d12814d134\",\"Gateway\":\"172.17.0.1\",\"IPAddress\":\"172.17.0.2\",\"IPPrefixLen\":16,\"IPv6Gateway\":\"\",\"GlobalIPv6Address\":\"\",\"GlobalIPv6PrefixLen\":0,\"MacAddress\":\"02:42:ac:11:00:02\",\"DriverOpts\":null}}},\"Mounts\":[{\"Type\":\"bind\",\"Source\":\"/home/arsing/iotedge\",\"Destination\":\"/iotedge\",\"Mode\":\"\",\"RW\":true,\"Propagation\":\"rprivate\"},{\"Type\":\"bind\",\"Source\":\"/var/run/docker.sock\",\"Destination\":\"/var/run/docker.sock\",\"Mode\":\"\",\"RW\":true,\"Propagation\":\"rprivate\"}]},{\"Id\":\"2fe4d77abfdc10ea49957e80817ef4067d9d7a293ceed7dbfe2a333a5434441b\",\"Names\":[\"/priceless_mendeleev\"],\"Image\":\"ubuntu:18.04\",\"ImageID\":\"sha256:cd6d8154f1e16e38493c3c2798977c5e142be5e5d41403ca89883840c6d51762\",\"Command\":\"/bin/bash\",\"Created\":1537995262,\"Ports\":[],\"Labels\":{},\"State\":\"running\",\"Status\":\"Up25 hours\",\"HostConfig\":{\"NetworkMode\":\"default\"},\"NetworkSettings\":{\"Networks\":{\"bridge\":{\"IPAMConfig\":null,\"Links\":null,\"Aliases\":null,\"NetworkID\":\"16b3fa2409d924d53d7df7e61b80183e468f1009ea3b47c8b812f54b548f4d36\",\"EndpointID\":\"ce2d65005e22641d9ddcd58b90da09cef9480bf0e1b0767e3cf0746c625ae7ab\",\"Gateway\":\"172.17.0.1\",\"IPAddress\":\"172.17.0.3\",\"IPPrefixLen\":16,\"IPv6Gateway\":\"\",\"GlobalIPv6Address\":\"\",\"GlobalIPv6PrefixLen\":0,\"MacAddress\":\"02:42:ac:11:00:03\",\"DriverOpts\":null}}},\"Mounts\":[{\"Type\":\"bind\",\"Source\":\"/var/run/docker.sock\",\"Destination\":\"/var/run/docker.sock\",\"Mode\":\"\",\"RW\":true,\"Propagation\":\"rprivate\"}]}]\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=40\n]\n\n TRACE hyper::proto::h1::conn       > read_keep_alive; is_mid_message=false\n TRACE tokio_threadpool::worker     > task complete; state=pool::State { lifecycle: Running, num_futures: 6 }\n TRACE tokio_threadpool::worker     > try_steal_task -- signal_work; self=46; from=44\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=40\n TRACE want                         > signal: Want\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=45\n TRACE tokio_threadpool::sender     > execute; count=7\n TRACE tokio_threadpool::task       >     -> not ready\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(47)\n TRACE tokio_threadpool::worker     > try_steal_task -- signal_work; self=43; from=46\n TRACE tokio_threadpool::pool       > submit to existing worker; idx=38; state=worker::State { lifecycle: Shutdown, is_pushed: true }\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=47\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=45\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(42)\n TRACE tokio_threadpool::pool       > signal_work -- spawn; idx=37\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(41)\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(44)\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=42\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=47\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=44\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=42\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=41\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=44\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=41\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(46)\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=46\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(40)\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=46\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=40\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=40\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(45)\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(43)\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=45\n TRACE tokio_threadpool::worker     > found work while draining; signal_work\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=43\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=45\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=43\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=45\n TRACE tokio_threadpool::worker     > stole task\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=45\n TRACE tokio_threadpool::task       > Task::run; state=Running\n TRACE hyper::client::pool          > take? (\"unix://foo\", Http1): expiration = Some(90s)\n DEBUG hyper::client::pool          > reuse idle connection for (\"unix://foo\", Http1)\n TRACE tokio_threadpool::notifier   > Notifier::notify; id=0x7fb65f8531d0\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(45)\n TRACE tokio_threadpool::pool       >     -> submit internal; idx=39\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=45\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=45\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=43\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=43\n TRACE tokio_threadpool::task       >     -> not ready\n TRACE tokio_threadpool::worker     > try_steal_task -- signal_work; self=39; from=38\n TRACE tokio_threadpool::worker     > stole task\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=45\n TRACE tokio_threadpool::task       > Task::run; state=Running\n TRACE hyper::proto::h1::conn       > read_keep_alive; is_mid_message=false\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=45\n TRACE hyper::proto::h1::role       > Client::encode method=GET, body=None\n TRACE tokio_threadpool::task       >     -> not ready\n TRACE tokio_threadpool::worker     > try_steal_task -- signal_work; self=43; from=39\n TRACE tokio_threadpool::pool       > signal_work -- wakeup; idx=40\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(39)\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(45)\n TRACE tokio_threadpool::worker     >     -> wakeup; idx=40\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=39\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(37)\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=45\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=39\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=37\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=45\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=37\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(38)\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(43)\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=38\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=43\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=38\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=43\n TRACE tokio_threadpool::worker     > Worker::sleep; worker=WorkerId(40)\n TRACE tokio_threadpool::worker     >   sleeping -- push to stack; idx=40\n TRACE tokio_threadpool::worker     >     -> starting to sleep; idx=40\n```\n\n\n. Ah, so it was there after all. Thanks!\nEdit: I confirmed that fixed the issue with my actual code too.. ",
    "paperplanes53": "Okay, I see. Now, when I do let server = Server::bind(&addr).serve(new_service); I get hyper::Server<hyper::server::conn::AddrIncoming, [closure@src/installed.rs:105:35: 109:18]>.\nI have a struct with a server field and have now set the type to Option<Server<AddrIncoming, NewService>>.\nNewService is highlighted with the following errors:\n\n\nerror[E0191]: the value of the associated type ReqBody (from the trait hyper::service::NewService) must be specified\n\n\nerror[E0191]: the value of the associated type Error (from the trait hyper::service::NewService) must be specified\n\n\nerror[E0191]: the value of the associated type Service (from the trait hyper::service::NewService) must be specified\n  --> src/installed.rs:67:41\n\n\nerror[E0191]: the value of the associated type Future (from the trait hyper::service::NewService) must be specified\n\n\nerror[E0191]: the value of the associated type InitError (from the trait hyper::service::NewService) must be specified\n\n\nLooking at the new_service.rs code , I thought the implementation section set the types already.. The error makes sense then, thank you.. ",
    "avborhanian": "Damn, much too slow! I'll keep benching/testing locally then. Is there a particular bench test I should look at making sure I get to a lower iter time? Or do I need to make one in this case for the content-length: 0 situation.. ",
    "legokichi": "it solved. thank you.. ",
    "Jezza": "I understand, but doesn't tokio::run block until the runtime itself is shutdown, meaning self won't be dropped until the end of the method?\nHm, is there a safe way to hand out a reference, because the application itself isn't dropped until after the runtime is killed?\nPreferably, without a runtime cost.... ",
    "jonas-schievink": "Apparently Azure Pipelines allows up to 10 parallel builds for open source projects, so that might be an alternative. It also supports Windows, macOS and Linux.. ",
    "JeffLabonte": "I will take this issue and work on it! . Would you have something in mind as well? @seanmonstar . @seanmonstar Fixed in Pull request #1722 . I might need some help to fix the commit-message-check error.. I will create a new branch with the right git message!. ",
    "mackeyja92": "I can\u2019t reproduce this with any other client nor am I able to reproduce it with hyper when I\u2019m doing it with only a single thread on rayon. It seems the client is shutting down before some of the parallel requests are finished. \nThe requests themselves can take awhile to process (30ish seconds). The keep alive on the server is 600 seconds. . ",
    "cuviper": "Looks good -- thanks for the quick fix!. ",
    "johndoe52": "\nThere is HttpConnector::set_local_address already.\nOr do you mean setting it differently depending on the destination? If so, you could try implementing a custom Connect that is tailored for your workflow.\n\nYes the API exists but requires creating a new client which destroys efficiency.\nSetting source address directly when making a request with hyper would be better (not in client builder)\nAnd thus would need to check for source address when doing HTTP pipelining in connection pool\nPlease see my other issues.\nFor now the Hyper http client does not scale due to TCP port exhaustion when using a single source IP address, and creating new clients for this destroys efficiency.. > > Yes the API exists but requires creating a new client which destroys efficiency. Setting source address directly when making a request with hyper would be better (not in client builder).\n\nYour use case sounds possible to support, but also a bit detailed. That's OK! That's why the Client is generic over a connector. You can implement Connect on a new type, such that you can inspect the Destination::hostname(), and from that, configure a TcpStream with a certain local address, and then connect.\nIs there a reason this wouldn't work in your situation?\n\nI will experiment with this.\nI'm looking forward to have this merged directly in Hyper though!. > My feeling is that this functionality is fairly niche, so I'm going to close the issue for now. If there's lots of need that I don't know about, we can reconsider!\nFor example, building a web spider over hyper would require this to scale.. https://github.com/hyperium/hyper/issues/1657\nTo extract body from response\nadd use hyper::rt::Stream;\nBox::new(CLIENT.request(req)\n             .and_then(move |res| {\n                 count.fetch_add(1, Ordering::SeqCst);\n                 if res.status().is_success() { \n                     // book page fetched, do whatever with res.body()\n                     // ...\n                     //\n                     tokio::spawn(fetch_page(count, book, page + 1));\n                     return res.into_body().concat2() // returns a future, resolved in .map\n                 } else if res.status().as_u16() == 429 {\n                     // server sends rate limit ms in retry-after if it wants us to slow down\n                     // should actually synchronize this with tokio and make tokio pause execution\n                     // of futures for that time\n                     tokio::spawn(tokio_timer::sleep(\n                             time::Duration::from_millis(res.headers()\n                                                         .get(\"retry-after\").unwrap().to_str().unwrap()\n                                                         .parse().unwrap()))\n                         .and_then(move |_| {\n                             tokio::spawn(fetch_page(count, book, page));\n                             ok(())\n                         }).map_err(|_| {}));\n                     ok(())\n                 } else if res.status().as_u16() == 404 {\n                     // book pages fetched\n                     println!(\"book {} fetched\", book);\n                     ok(())\n                 } else if res.status().is_server_error() {\n                     // server error, retrying\n                     tokio::spawn(fetch_page(count, book, page));         \n                     ok(())\n                 } else {\n                     println!(\"unhandled status: {} book: {}\", res.status().as_u16(), book);\n                     ok(())\n                 }\n             }).map(|body| {\n                 println!(\"body: {}\", ::std::str::from_utf8(&body).unwrap()); // prints downloaded body here\n             }).map_err(move |e| {\n                 eprintln!(\"{}\", e);\n             })). ",
    "KenanSulayman": "I think this should be a top-priority.\nIn the wild you'll only find massively interweaved examples of hyper being used via trait, and frankly it's what stopped me from migrating to hyper 0.11 / 0.12 so far -- I'd very much appreciate a complete example (i.e. a server with a redis-backed store, ...) and if possible a guide on what to consider when migrating from 0.9, 0.10 to 0.12.. ",
    "MartyIX": "Thank you very much :-). ",
    "d653": "Shouldn't hyper give a more meaningful error, instead of some \"FRAME_SIZE_ERROR\"? \nI got the same error for:\n- sites that do not support HTTP/2 like docs.rs\n- sites that support HTTP/2 (i tried google.com and api.telegram.org)\nShouldn't there be something useful in the documentation regarding this?. ",
    "vorner": "Thank you. I don't know the internals, but from a na\u00efve look at it, it looks fine.\nOne question, though. Was the problem present in http2 too? Because it seems there are only changes relating to http1.. Thanks, this will be of help :-) Though the hiding from the docs might discourage users from actually using it for their trait bounds (or discovering \u2012 the only way I found it was that the docs of serve mentioned it and it didn't link anywhere) \u2012 would it be better to show it and explain the purpose clearly and when it is appropriate to use?. That wouldn't really improve my situation with associated types in a trait, though :-(.. Yes, that helps, it compiles now. Would you accept a PR to change the example to show the AddrStream? Because the compiler error is not very helpful at pointing the mismatched types out, so at least the example might show the most common usage (if someone is going to tweak the server, they'll probably guess they have to tweak it here too, but the other way around\u2026).. Hmm. It says some of the commit messages are invalid, but I don't see the explanation \u2012 the Details button leads to the https://gitcop.com/ home page, without any details :-(. So I don't see what to fix.. OK, I've took inspiration in some other example around to disable it without the features.. ",
    "goriunov": "Video is available on reddit https://www.reddit.com/r/rust/comments/9ulbj3/weird_rust_hyper_async_behaviour_why/. Repo with simplified code: https://github.com/goriunov/rust-test. @seanmonstar  Thank you for your suggestion. I have removed that code long time ago and it still has the same problem could you please check this code. I am not sure what can be wrong (can not solve that problem for a while and no one really explains properly what is going on). ",
    "rrichardson": "Not the buffer of the socket itself. \nIt's the buffer in Buffered which is used by Connection.  It reads from AsyncRead.  I've verified that if the BytesMut has a len of 2MB it can fill the buffer in a single read command. \nSo I guess that means that TcpStream's AsyncRead::read disregards packet boundaries, which is a great optimization, IMO. \nSince this is for Client only,  it doesn't really increase the risk of DOS attacks. . maybe initial_read_buf()?. \nOk.  But we'll need to somehow let the user know that if they set the read_buf/chunk_size they'll need to also up the max buffer size otherwise it will panic.  \nMy inclination is to get rid of the initial check, and assume that if the user ups the read_buf_size they know what they are doing..  I'm not sure, though. . thinking about this a bit more, I think maybe we just set the max size to 4x the initial buffer size if the user updates the initial buffer size. . If we take this approach,  I think that we'll need to go to a two buffer system,  since the read buffer is extended as needed to handle the contents of the AsyncRead::read.  I am fairly sure that, at this function, the buffer size is compared to the max buf size, even on the client. . IOW, current we have a single, contiguous buffer that gets extended to handle the entire http message (if it is not chunked) .    We would need to move away from this. (might be a good idea anyways). ",
    "starsheriff": "Hei, I was looking for an easy task to start contributing to the world of rust. Could I give that one a shot or is anyone already working on it?. changed the method name as suggested to tcp_sleep_on_accept_errors, longer but more self descriptive.. I didn't copy this sentence on purpose. I thought that if this default changes it's easy to forget to update the documentation in other places. Hence, the link. Up to you though, if you prefer to have it here I add it.. ",
    "leohahn": "Thank you very much for the answer!. ",
    "nifker": "@sfackler ok that worked - I seem to get an 404 Error and the Stream is not being entered at all. Fixed using hyper::rt::spawn().. ",
    "luben": "I will try and report back tomorrow.. I tried. It's not fixed. The way to reproduce it:\n1. Run the broker.\n2. Run the worker.\n...\n3. Restart the worker. The broker should report \"Dropping Next()\" but does not.\nnext curl request fails.. I think the bug is on the server, not the client: the broker is the server and it does not drop the future on disconnect from the client (worker). When I run it with trace log-level, the messages after I cancel the worker are:\n2018-11-26 22:57:43 TRACE [tokio_reactor] event Readable | Writable | Hup Token(4194305)\n2018-11-26 22:57:43 TRACE [tokio_reactor] loop process - 1 events, 0.000s\n... and nothing else. So looks like nobody is polling the connection while the response future is waiting on the oneshot::Receiver for the Body.\n. Hm, will look how it is implemented on the h2 side and try to come with a patch.. Just for test, I disabled the check for is_mid_message but it still don't drop the response future. Here is the trace (with some more trace logs added):\n2018-11-26 23:31:57 TRACE [tokio_reactor] event Readable | Writable | Hup Token(8388609)\n2018-11-26 23:31:57 TRACE [tokio_reactor] loop process - 1 events, 0.000s\n2018-11-26 23:31:57 TRACE [hyper::proto::h1::dispatch] poll_catch\n2018-11-26 23:31:57 TRACE [hyper::proto::h1::dispatch] poll_inner\n2018-11-26 23:31:57 TRACE [hyper::proto::h1::dispatch] poll_read\n2018-11-26 23:31:57 TRACE [hyper::proto::h1::conn] read_keep_alive; is_mid_read=false\n2018-11-26 23:31:57 TRACE [hyper::proto::h1::io] io.read_buf -> Ready(0)\n2018-11-26 23:31:57 DEBUG [hyper::proto::h1::io] read 0 bytes\n2018-11-26 23:31:57 TRACE [hyper::proto::h1::conn] try_io_read; found EOF on connection: State { reading: KeepAlive, writing: Init, keep_alive: Busy, error: None }\n2018-11-26 23:31:57 TRACE [hyper::proto::h1::conn] State::close_read()\n2018-11-26 23:31:57 TRACE [hyper::proto::h1::dispatch] poll_write\n2018-11-26 23:31:57 TRACE [hyper::proto::h1::dispatch] poll_flush\n2018-11-26 23:31:57 TRACE [hyper::proto::h1::conn] flushed({role=server}): State { reading: Closed, writing: Init, keep_alive: Disabled, error: None }\n2018-11-26 23:31:57 TRACE [hyper::proto::h1::dispatch] poll_inner.is_done?\n2018-11-26 23:31:57 TRACE [hyper::proto::h1::conn] conn.is_read_closed true\n2018-11-26 23:31:57 TRACE [hyper::proto::h1::conn] conn.is_write_closed false\n2018-11-26 23:31:57 TRACE [hyper::proto::h1::dispatch] poll_inner.is_done -> false\n2018-11-26 23:31:57 TRACE [tokio_reactor] event Readable Token(4194303)\n2018-11-26 23:31:57 TRACE [tokio_reactor] loop process - 1 events, 0.000s\n2018-11-26 23:31:57 TRACE [tokio_reactor] loop process - 0 events, 0.000s. Yes, you are right.. thanks!. It's consistently leaking with payloads of 1 MB. I have only tried and reproduced in on Linux.. I have just added a negative example with src/bin/worker-non-stream.rs - if we .concat2() the body (i.e. not stream it back) there is no leak.. The connection between the worker and the broker is not closed from both sides - verified with lsof.. LGTM, let me try to test it on the broker example.. Works as expected. One suggestion: can we surface it through the server::Builder as the rest of the connection config options - I did the change locally in order to test it.\n```patch\nindex a0e0b01..4bcd618 100644\n--- a/src/server/mod.rs\n+++ b/src/server/mod.rs\n@@ -280,6 +280,14 @@ impl Builder {\n         self\n     }\n\n/// Set whether half-closed connections are considered open.\n///\n/// Default is true.\npub fn http1_half_close(mut self, val: bool) -> Self {\nself.protocol.http1_half_close(val);\nself\n}\n+\n. Changed the commit message to fit the limits and force pushed it in my branch to update the PR.. I will push the name change in a minute. Thanks David, corrected it.. I wanted to to an \"upgrade\" and get hands on the raw fd. Then redirect my stderr there. Obviously I needed some other logging around, including the remote address. I tried to do it with the low-level server::conn API but I couldn't get my head around how to do the upgrades.. Thanks!. This fixes (with returning back the ` should_error_on_parse_eof()`) the failing `empty_parse_eof_does_not_return_error` but I am not sure it's the right approach:rust\n(T::should_error_on_parse_eof() || !self.state.allow_half_close) && !self.state.is_idle()\n```. \n",
    "TheNeikos": "Sorry for the delay!\nSo, the reason why I needed this to be Sync, is because the Error type of MakeService has a Sync bound, and I had in my error chain then which caused the Body to be entangled in all of that.\nIt took some time but I managed to untangle the futures to find this. Hence my question if you had made similar experiences before with Body being required Sync.\n\u2014\u2014\u2014\u2014\nIn general I\u2019d like to thank you for answering my questions and I\u2019m sorry if they seem a bit odd at times, futures are still quite new and hyper a large library.. ",
    "nerdrew": "I spent a bit of time trying to figure this out recently. Might be nice to add this to an example.. ",
    "nlevitt": "\ud83c\udf1e\ud83c\udf1d The Name is the mother of the ten thousand things.. ",
    "kahing": "I suppose that works if you pre-copy all the info you want from Request and response headers into your Payload type, that's not really possible in our case (or rather, what I want to avoid). that's an interesting strategy but unfortunately doesn't fit into our logging scheme.. a client side configurable max read buffer size sounds exactly what I need. ",
    "LucioFranco": "@seanmonstar good point! I will take a look. Do you think it may be good to just use the default Uri::default and then use the setters to actually set the values of the destination so that we can just reuse the check within the setters?\nrust\npub fn new(uri: Uri) -> Self {\n    let dst = Destination { uri: Uri::default() };\n    dst.set_scheme(uri.scheme())?;\n    dst.set_host(uri.host())?;\n    dst.set_port(uri.port())?;\n    dst\n}. That would work, though I wonder if this may be something that could be added to http so Uri::is_abosolute? And I think that is the right way to go about it, I will add a check to make sure that scheme and authority exist. I assume authority will work since it will check host and port. \nThen once TryFrom is stable Destination can just implement TryFrom<Uri>.. @seanmonstar I've moved it to try_from_uri and now has error checking. I went with the Parse::Uri error as it seems to fit this the best without actually adding more errors to the struct. Though if you have other ideas I am open to that.. @quininer in tower we have been working on this trait right here https://github.com/tower-rs/tower/blob/master/tower-util/src/make_connection.rs#L21 would this work for your use case? It allows you to use your own generic parameter for the connect function.. @quininer so tower-hyper's goals are to just provide a sort of compat layer between hypers low level components and the middleware of tower. tower-hyper itself only exposes an interface for MakeService and then the Service generated from that. If you combine, a lot of the middleware already in tower you will get the connection pool, load balancing (between connections), retries, reconnecting the transport etc. hyper already includes h2 so you just need to setup the connection builder to force http2.. @LucioFranco Right, I havent gotten far enough to try http2 yet, that is my next goal for it. I still need to get that part figured out \ud83d\ude04 .. @quininer I did some playing around, so without the need to upgrade etc http2 works with tower-hyper, just need to setup the correct request versions etc. I believe the ALPN negotiation can be done inside the make_connection future that returns a AsyncReady + AsyncWrite which means that the transport provided by MakeConnection is http2 ready. I'm not too versed, yet, with http2 so Im not totally sure if that is the right approach. But it does return a future from the trait allowing you to do more connection based io, like TLS, DNS, etc. If you are wanting to look more into tower-hyper feel free to create an issue in that repo or come talk to us on the tower gitter.. @seanmonstar do you think this would be a good time for hyper to move to the actual tower traits?. First, I am really excited for this!\nSo at a high level, is it worth it right now to introduce kinda a halfway there approach instead of going all in and releasing 0.13.0? Are these compatibility types something that could in the meantime just live in tower-hyper?\nFor me the biggest things I'd like to see in the transition to tower is:\n- Transition to BufStream instead of Payload so that we can take advantage of the tower ecosystem without having to do any \"lifting\". This would enable us to use hyper with tower-grpc and tower-consul since they both use HttpService.\n- Provide full compatibility with the growing tower ecosystem layers.\nThat said, with the BufStream transition we could in theory provide all the tower compatability without having to include tower within the main hyper crate as done in tower-hyper.\nFor the clients, I'm not totally sure what the right path is for them as well. I have been going back and forth between providing a Service interface for hyper::Client or providing the lower-level MakeService and Service for the hyper::client::conn::* utils. Ideally I guess I would love to see the pool decoupled from hyper itself and implemented as its own tower-http utility, which should allow for us to provide different pool strategies, so maybe this is something worth exploring?\nAll in all, Im really excited to move this forward but I still think there are some unanswered questions still in tower itself around what is a client, does it provide a target -> Future<Service> interface or would it just be a Service + Clone out of the box kind of like how hyper::Client is right now.. And to add something else, at work we have been using the Service + Clone method to wrap rusoto and hyper. It seems to be working quite well but have not explored it enough. But would love to hear more on that!. @seanmonstar could we add an impl<T: Payload> Body for T>?. ",
    "lukaseller": "Thanks very much - this answers my question. . ",
    "dtantsur": "Hi folks! Should we fix the client example https://github.com/hyperium/hyper/blob/master/examples/client.rs then? It uses hyper::rt::run, which in turn uses tokio::run, which will hang the way described in this bug (I also got hit by it).. ",
    "operutka": "I can see the same behaviour with the latest Hyper v0.12.24 (tokio v0.1.15, tokio-io v0.1.11). The application works correctly when I put it behind nginx proxy.. Yes, I also think it's at this line. I'm not sure which log message you mean. If you mean the stack trace, then it's also correct. Every time I interrupt the process in GDB, I get this stack trace (or a stack trace corresponding to this one but reaching only one of the callers).. Sorry, I did not have much time to analyse it. I got back to it today.\nI've discovered that the flushed message appears regularly until I stop the Docker container with my client. Once the container is stopped, the message stops appearing entirely. This would probably suggest that the self.io.write_buf(...) method returns NotReady and the try_ready!(...) macro does early return over and over again.. I've managed to create a minimum working example (see the attachment below). It's a simple Hyper server that responds with an infinite streamed response to every request. The project contains also a directory called \"test\". The directory contains a simple Python script that polls data from the server and a Docker file for creating a Docker image with the Python script.\nYou can re-create the problem using the following steps:\n```bash\nunzip the file and enter the project directory and then:\ncargo build\nthe server will by default listen on 0.0.0.0:12345:\ntarget/debug/hyper-loop\n```\nin a separate terminal:\n```bash\nenter the project directory and then:\ncd test\ndocker build -t hyper-loop-test .\nnote: replace 172.17.42.1 with the address of your docker network interface\ndocker run --name=kill-me hyper-loop-test python3 -u test.py http://172.17.42.1:12345/\n```\nand finally kill the \"kill-me\" Docker container from a separate terminal:\nbash\ndocker rm -f kill-me\nThe server will never print the \"client has left\" message as defined in main.rs on line 29 and it will get into an infinite loop.\nI've also noticed that it's sensitive to the amount of data the server sends at once. The bigger chunks of data I send, the bigger is the chance for getting stuck in an infinite loop.\nAttachment: hyper-loop.zip\n. As I mentioned, the line \"flushed n bytes\" stops appearing when I stop the Docker container with my client. Here is a trace log that I captured from the server example:\nTRACE - loop process - 0 events, 0.000s\nTRACE - loop process - 0 events, 0.000s\nTRACE -     -> wakeup; idx=3\nTRACE - loop process - 0 events, 0.000s\nTRACE - Notifier::notify; id=0x7fa820002e70\nTRACE -     -> submit internal; idx=3\nTRACE - signal_work -- notify; idx=3\nTRACE -     -> wakeup; idx=3\nTRACE - Task::run; state=Running\nTRACE - encoding chunked 340000B\nDEBUG - flushed 340009 bytes\nTRACE - flushed({role=server}): State { reading: KeepAlive, writing: Body(Encoder { kind: Chunked, is_last: false }), keep_alive: Busy }\nTRACE -     -> not ready\nTRACE - event Readable Token(4194303)\nTRACE - loop process - 1 events, 0.000s\nTRACE - Worker::sleep; worker=WorkerId(3)\nTRACE -   sleeping -- push to stack; idx=3\nTRACE -     -> starting to sleep; idx=3\nTRACE - loop process - 0 events, 0.000s\nTRACE - event Readable | Writable | Hup Token(4194305)\nTRACE - loop process - 1 events, 0.000s\nTRACE -     -> wakeup; idx=3\nTRACE - loop process - 0 events, 0.000s\nTRACE -     -> wakeup; idx=3\nTRACE - loop process - 0 events, 0.000s\nTRACE - Notifier::notify; id=0x7fa820002e70\nTRACE -     -> submit internal; idx=3\nTRACE - signal_work -- notify; idx=3\nTRACE -     -> wakeup; idx=3\nTRACE - Task::run; state=Running\nTRACE - encoding chunked 340000B\nDEBUG - flushed 340009 bytes\nTRACE - flushed({role=server}): State { reading: KeepAlive, writing: Body(Encoder { kind: Chunked, is_last: false }), keep_alive: Busy }\nTRACE -     -> not ready\nTRACE - event Readable Token(4194303)\nTRACE - loop process - 1 events, 0.000s\nTRACE - Worker::sleep; worker=WorkerId(3)\nTRACE -   sleeping -- push to stack; idx=3\nTRACE -     -> starting to sleep; idx=3\nTRACE - loop process - 0 events, 0.000s\nTRACE - loop process - 0 events, 0.000s\nTRACE -     -> wakeup; idx=3\nTRACE - loop process - 0 events, 0.000s\nTRACE -     -> wakeup; idx=3\nTRACE - loop process - 0 events, 0.000s\nTRACE - Notifier::notify; id=0x7fa820002e70\nTRACE -     -> submit internal; idx=3\nTRACE - signal_work -- notify; idx=3\nTRACE -     -> wakeup; idx=3\nTRACE - Task::run; state=Running\nTRACE - encoding chunked 340000B\nDEBUG - flushed 271 bytes\nTRACE - Notifier::notify; id=0x7fa820002e70\nTRACE -     -> not ready\nTRACE - event Readable Token(4194303)\nTRACE - loop process - 1 events, 0.000s\nTRACE - Task::run; state=Running\nTRACE - Notifier::notify; id=0x7fa820002e70\nTRACE -     -> not ready\nTRACE - Task::run; state=Running\nTRACE - Notifier::notify; id=0x7fa820002e70\nTRACE -     -> not ready\nTRACE - Task::run; state=Running\nTRACE - Notifier::notify; id=0x7fa820002e70\nTRACE -     -> not ready\n...\nThe last three lines repeat over and over again. Clearly, there's a HUP event processed by the event loop (the line TRACE - event Readable | Writable | Hup Token(4194305)) but the application keeps calling the flush method even though it probably should not do it.. Thank you for the info. Setting http1_half_close to false in the server builder helped.\nI'm just wondering if this should not be the default behaviour. I realize it's a breaking change for some applications. However, if half-closed connections are enabled by default, it'll lead to this problem sooner or later. I guess that we don't want production applications to end up with 100% CPU usage for no apparent reason. It might be even considered a DoS vulnerability.\nRegarding EPIPE - in my opinion, writing into a (half) closed socket does not necessarily have to end up with EPIPE as the remote peer might be behind firewall/NAT. In such case, the remote end would simply drop all incoming packets instead of sending an RST TCP packet.. ",
    "nickelc": "You can use hyper-old-types or hyperx.. ",
    "technic": "Great. Thanks!. ",
    "cake4289": "Hello David, I am only using sleep here as an example - in reality I have a long-running calculation and want to serve other requests in the meantime.\nIs it really the case that async hyper (using futures) is really synchronous? It is incredibly surprising to me that a long-running calculation (say, a large file or slow database request) could gum up the server when the tokio runtime uses a threadpool.\nFor reference, here is an async version:\n```rust\nextern crate futures;\nextern crate hyper;\nuse std::error::Error;\nuse std::time::Duration;\nuse std::thread::sleep;\nuse futures::lazy;\nuse futures::Poll;\nuse hyper::{Body, Method, Request, Response};\nuse hyper::rt::Future;\nuse hyper::service::Service;\nstruct MyService;\nimpl Service for MyService {\n    type ReqBody = Body;\n    type ResBody = Body;\n    type Error = Box;\n    type Future = Box, Error=Self::Error> + Send>;\nfn call(&mut self, request: Request<Body>) -> Self::Future {\n    println!(\"Received request\");\n    match (request.method(), request.uri().path()) {\n        (&Method::GET, \"/sleep\") => {\n            Box::new(lazy(|| {\n                println!(\"Sleeping...\");\n                sleep(Duration::from_secs(20));\n                println!(\"Sleep completed\");\n                Ok(Response::new(Body::from(\"\")))\n            }))\n        }\n        (&Method::GET, \"/\") | (&Method::GET, \"\") => {\n            Box::new(lazy(|| {\n                Ok(Response::new(Body::from(r#\"\n                    <!doctype HTML>\n                    <html>\n                        <button onclick=\"\n                            var req = new XMLHttpRequest();\n                            req.open('GET', '/sleep');\n                            req.send(null);\n                        \">\n                            Sleep\n                        </button>\n                    </html>\n                \"#)))\n            }))\n        }\n        _ => panic!()\n    }\n}\n\n}\nimpl Future for MyService {\n    type Item = MyService;\n    type Error = Box;\nfn poll(&mut self) -> Poll<Self::Item, Self::Error> {\n    Ok(From::from(MyService))\n}\n\n}\nfn main() {\n    let sockaddr = \"127.0.0.1:10022\".parse().unwrap();\n    let server = hyper::Server::bind(&sockaddr)\n        .serve(|| MyService)\n        .map_err(|e| println!(\"Server error: {}\", e));\nhyper::rt::run(server);\n\n}\n```. The reason I am confused is that this problem does not occur with tokio on its own. Is it because requests queued on a single connection are pinned to the same thread? Here is a tokio example which does not block the other thread - it takes 5 seconds only\n```rust\nextern crate futures;\nextern crate tokio;\nuse std::time::Duration;\nuse std::thread::sleep;\nuse futures::lazy;\nfn main() {\n    tokio::run(lazy(|| {\n        for i in 0..4 {\n            tokio::spawn(lazy(move || {\n                println!(\"{} Sleeping...\", i);\n                sleep(Duration::from_secs(5));\n                println!(\"{} Sleep completed\", i);\n                Ok(())\n            }));\n        }\n        for i in 4..100 {\n            tokio::spawn(lazy(move || {\n                println!(\"{} Running\", i);\n                Ok(())\n            }));\n        }\n        Ok(())\n    }));\n}\n```\nMeanwhile my example above blocks the request even with only 2 requests.. Thank you very much for clarifying, I guess I can't rely on hyper to distribute requests to different threads on the same connection, and that's why my code is getting stuck. I will look at adding another layer of indirection to my slow-running code (so it can work more like an async request as intended).. Thanks Sean, I also found this in the tokio docs:\n\nCooperative scheduling is used to schedule tasks on executors. A single executor is expected to manage many tasks across a small set of threads. There will be a far greater number of tasks than threads. There also is no pre-emption. This means that when a task is scheduled to execute, it blocks the current thread until the poll function returns.\nBecause of this, it is important for implementations of poll to only execute for very short periods of time. For I/O bound applications, this usually happens automatically. However, if a task must run a longer computation, it should defer work to a blocking pool or break up the computation into smaller chunks and yield back to the executor after each chunk.\n\nWhich was counter to my mental model of how it worked.\nI have added a tokio_threadpool and used the spawn_handle function to run computations (it returns a future). I will code up an example since this could be a common use case (running computations in response to an http request).. Even better -\nhttps://docs.rs/tokio-threadpool/0.1/tokio_threadpool/fn.blocking.html. ",
    "andrew-d": "Nitpick: extra quote here.\n. ",
    "nickgonzales": "With the following implementation already existing for Response:\nimpl Response<Body> {\n    /// Take the `Body` of this response.\n    #[inline]\n    pub fn body(mut self) -> Body {\n        self.body.take().unwrap_or(Body::empty())\n    }\n}\nWould this make more sense?\n```\nimpl Request {...\n    /// Read the Request body.\n    #[inline]\n    pub fn body_ref(&self) -> Option<&B> { self.body.as_ref() }\n...}\nimpl Request {\n    /// Take the Request body.\n    #[inline]\n    pub fn body(self) -> Body { self.body.unwrap_or_default() }\n}\n```\nMy only concern with returning a default is that I think the caller should be able to identify if a body exists or not, but body_ref() seems to cover that use case.\nAlso, should I change the above impl for Response to use self instead of mut self so it consumes the response? Or should I leave it as-is? This would reduce the differences further.. ",
    "gootorov": "@seanmonstar, Just randomly stumbled upon this repo. I think there's a way to simplify this if I'm not missing anything:\nRust\nmatch (self.version, *version) {\n    (Ver::Http1, _) if *version != HttpVersion::Http10 && *version != HttpVersion::Http11 => {\n        *version = HttpVersion::Http11;\n    },\n    _ => {},\n}. ",
    "kleimkuhler": "Why do you have max.into() here, but\nif let Some(max) = max.into {\n    ...\n}\nin src/server/conn?. Oh okay!. Oh no this makes sense. h2's fn max_concurrent_streams needs a value, while here you are passing in an Option to conn::Http's wrapper.. Okay that makes sense. I was back and forth on documentation here because of that situation, but glad to mention the difference here instead.. ",
    "hawkw": "This should probably be \nsuggestion\n    pub fn http2_initial_stream_window_size(&mut self, sz: impl Into<Option<u32>>) -> &mut Self {\nfor consistency with the other functions added in this branch.... suggestion\n    pub fn http2_initial_connection_window_size(&mut self, sz: impl Into<Option<u32>>) -> &mut Self {. "
}