{
    "julien-f": "Do you have an idea for the implementation?\nMaybe a got.stream(url, [callback]) which:\n- if called with callback, calls it with the following arguments (err, response)\n- otherwise, returns a proxy readable stream to the response. \n. It is indeed easier, but with your proposal, you cannot have access to both the stream and the response object.\nBut that may be an edge case not worth considering :)\n. Would you like a PR for this one too?\n. I am not an expert in streams but AFAIU:\n- when readable is emitted, you can call stream.read() and it will returns some data;\n- when data is emitted, you get the data directly.\nOne more thing: adding an handler for the data event switch the stream in flowing mode which the documentation recommends.\nI think I should have used the last one.\n. After some more thoughts, I think non flowing mode is useful for back pressure (e.g. allowing a file stream to retrieve data only when needed) but is useless for this case. \n. Yep.\n. Are you waiting for something before publishing the new version or have you simply forgotten? ;)\n. got 1.1.0 supports Buffer but not the stream mode :)\n. Thanks mate :)\n. @sindresorhus do you plan upgrade the major version as this breaks the API?\n. With all theses changes, is there still a reason for sent to exist?\n. @floatdrop Sure I could, why? (I am not sure I understand the purpose of your question :p)\n. @floatdrop IMHO, you should never unpublish a module, you don't know who might depend on it, deprecation should be enough :)\n. @floatdrop I think explicit options should take precedence.\n. @floatdrop To validate but I think you can overwrite the proxy stream write() method to throw an exception to make it non writable.\njavascript\nproxy.write = function () {\n  throw new Error('got\\'s stream is not writable when options.body is used');\n};\n. AFAIK _write() is really an implementation detail, write() is called by the parent stream so I think it makes more sense to override it.\n. What do you mean by Mocha is bloated?\n. Fair enough :)\n. Personally I like Mocha because of:\n- the BDD interface;\n- the support of asynchronous tests with callbacks or promises;\n- the ability to chose the assertion lib (usually Chai or Must.js).\n. At first thought I would be against but if @substack does it\u2026 :p\n. Having the same behavior on Node 0.10 & 0.12 is reason enough to do it.\n. Too much magic for me\u2026\nUsers should set the agent if they need to limit the number of connections. \n. @sindresorhus I get it now, seems a good idea.\n. Good idea, :+1: \n. Again, for me it makes no sense to attempt to connect to port 0\u2026\n. Ahhh, I understand now!\nIndeed it would make sense for all errors to be async.\n. As a user I do not mind setting the content type myself if I already have to format my data.\n. It's because host is ${hostname}:${port}, therefore it takes precedence.\n. Like anagentoption which would be passed directly tonew http.Agent()?\n. LGTM :)\n. Yes but the issue is there https://github.com/sindresorhus/got/blob/master/index.js#L59\n. I should probably not use bothpathandquery` but this is not explicit in the doc and it worked in 3.2.\n. By experience, the error should also contain the raw response.\n. I mean, content, but why not the response object too.\nSee xmlrpc for inspiration.\n. My bad, it is enough as it is :)\nThat leads me to another question, how can we promisify correctly such an API which has both an error and a result?\n. I need it to send a request with a stream body I don't know the length of, without using chunked encoding.\nMaybe there is a better to do it but I did not find it\u2026\n. In fact it's a very bad use case because it does not work at all for what I wanted :p\nMight still be useful for other use cases, I dunno.\n. I think it would be good (not necessarily in the near future) to bring the promise and stream APIs closer:\njs\nconst { stream } = await got.stream('http://example.org')\n- easy to use with ES2015's generators and ES2016's async functions\n- no more complexity to implement retrial on top of streams\n- should be more intuitive to use\n- should be easier to maintain\n. Open a PR to make readable-stream optional :)\n. @floatdrop Where is IncomingMessage#destroy() documented? The only thing I found in the documentation is ClientRequest#abort()\u2026\n. Unfortunatly, I don't think there is a way to access it with got :/\n. My bad :)\n. It already is :)\nEdit: too late :p\n. So there is a way to abort the connection in stream mode but what is the equivalent in promise mode?\n. In a project of mine, I solved this issue using a @cancellable decorator which injects a cancellation promise as a first argument and augment the returned promise with a cancel() method.\n. Why are these considered typos?\n. I see, I generally tend to follow Flow conventions myself.\n. It should be fine.\n. @floatdrop I don't think it works or it is a good idea, the response stream is already piped into the proxy stream and a readable stream should only be pipe into a single writable stream or there will be issues regarding back pressure.\n. IMHO, this is out of got's scope, if it starts to support this kind of thing it will get bigger than request.\n. As far as I know, the http2 module is not well maintained, you should use spdy instead.\nAnd I don't believe it is needed to detect HTTP2, simply use spdy to make the request and the protocol will be properly negotiated.\n@sindresorhus, @floatdrop you could make this optional by using a try {} catch (e) {} (like I did in this module) and documenting that spdy can be installed to enable HTTP2 support.\n. I think I've read somewhere that spdy is the HTTP2 implementation that will be merged into Node in the future.\n. That's indeed the easiest approach, but it still requires to specify the agent everywhere while the inclusion in got make it transparent\u2026\n. I tend to agree with @floatdrop because getting an object when not expecting one is not very nice :)\nAlthough an explicit option (json: 'auto') could do.\n. @floatdrop This has been fixed in make-error, perhaps you should consider using it\u2026\n. Perhaps because it's not easy to find good modules on npm :p\nOr perhaps I did not use the right keywords :)\nAnyway, if you prefer make-error over create-error-class I believe you should deprecate latter in favor of the first.\n. @sindresorhus Nope, no benefits other than avoiding a duplicate library :)\nBy the way, I am getting fed up with abandoned repos were the maintainers (and often only npm owner) do not answer anymore so I created a GitHub organization (@JsCommunity) to avoid this kind of issues. Any opinion on this? (This might not be the best place to discuss about this, feel free to open an issue there).\n. IMHO, if you want to be compatible with browsers, you should avoid extend Error for now.\n. I don't know the ratio of browsers which correctly support inheriting from Error.\n. @thisconnect, @sindresorhus can squash on merge, I don't think you have to create a new PR.\n. Got use the available Promise implementation, if you want to have .finally() you can simply use Bluebird :)\njs\nglobal.Promise = require('bluebird'). I don't think it's a good idea to start exposing this kind of option.\nAnd it work for nested use of got.\nIMHO, at the application level it's better to simply set Promise to Bluebird.. The 304 code should be treated differently because it usually does not contain the response content.. @lukechilds It's just my opinion, but if got does not behave differently (rejects) in case of 304, it force users to handle this case or they will find themselves without any content.\nI know that it should only happen when the correct headers are set but still, I think it's much more obvious to debug when an error is thrown.. @sindresorhus I think it makes sense to add extensions for non-js files.\nAnyway it seems like a fairly minor change to help people using Webpack.. Why did you close your issue?. You should go for promise.cancel(), at least it will be aligned with Bluebird.. What do you mean?\n. I extracted some code from the get() inner function because it needed to be run only once.\n. Isn't it res.code instead?\n. You could test the presence of content-length directly in the if above instead.\n. Nope, I put === undefined because I want the user to be able to prevent a specific head (here content-length) to be defined.\n. It is documented for ServerResponse, not for ClientRequest even if they both inherit from the same internal classOutgoingMessage.\n. ",
    "sindresorhus": "I like how you can do this with request:\njs\nrequest('http://google.com/doodle.png').pipe(fs.createWriteStream('doodle.png'));\n. You could emit a custom response event on the stream, but not sure how useful it would be.\n. Yes, that would be lovely :)\n. :+1: \n. Available in 1.0.0\n. Yeah, I initially created this for a specific use-case I had, but I agree that would be nice.\nSeems like request has an option for encoding:\n\nencoding - Encoding to be used on setEncoding of response data. If null, the body is returned as a Buffer.\n\nBut I tend to prefer returning a buffer and let the user choose what to do with it.\n\nOT, but curious why you're using stream.on('readable') rather than stream.on('data'). I don't get when to use which.\n\n@floatdrop thoughts on this?\n. Hmm, yeah, when thinking about it, you'll want text in almost every case, so makes more sense to default to that. encoding option it is.\n@julien-f Wanna do a PR?\n. @shaunc From the docs:\n\nEncoding to be used on setEncoding of the response data. If null, the body is returned as a Buffer.\n\nbinary is a string encoding, not actual binary nor buffer.. Thanks :)\n. Nice! Lgtm.\n@floatdrop lgty?\n. Thanks @julien-f :)\n. Sorry, it got lost in a tab somewhere. 1.2.0 :)\n. I don't really care about proxy support, but I would consider a good PR ;)\nMaybe by using https://github.com/koichik/node-tunnel\n. @floatdrop Maybe we should just mention it in the docs?\n. @floatdrop tunnel-agent looks like is just node-tunnel: https://github.com/mikeal/tunnel-agent/issues/2\n. I'm open to it, but it would need to be in a form of a good PR (preferably with as much code as possible in depending modules) with promise to continue maintaining it, as I'm not interested.\n\nso Node should do it as well (but apparently it won't joyent/node#1973).\n\nThat issue is old so someone could try again, but that person should make sure the new issue has a lot of good arguments and evidence of why it should be in core.\n\nas for Node, it should be part of core IMHO\n\nAgreed!\n\nI do wonder why Node can't just use the system proxy settings.\n. No worries. I've done that multiple times by accident too. Lgtm. Feel free to commit directly if you're not looking for review ;)\nShortened it https://github.com/sindresorhus/got/commit/a2501bf122dcc87410d17b3fb0c2c605f0a89d7f and did a patch release. Thanks :)\n. Could be either resCode/statusCode/code. What are others using?\n. Yes\n. @julien-f Yes. Anything else of breaking changes would be good to get in now ;)\n. Well if they're just working with status codes they can do a HEAD request instead.\nI guess this is fine, but would be nice to get some eyes on it.\n// @kevva @julien-f\n. @floatdrop added you to the npm package.\n. What does request do?\n. Awesome!\nIs there anymore breaking changes we want to do before doing a 2.0 release?\n. Then let's go for body to be consistent. request also uses body.\n. Thanks! :)\n. > should got be pipe-able in callback mode?\nNo\n. This will be fixed in npm in the next version I think. It will then be forcefully included even though it's not specified in the files property. And no, not going to include anything not needed for running. You have git clone for that.\n. > Would it be useful to add some shortcuts?\nYes. I've been wanting that too.\n. > IMHO, you should never unpublish a module, you don't know who might depend on it, deprecation should be enough :)\n:+1: Bump major and deprecate that version. This makes it so that current users doesn't notice anything, but new users will get the deprecation notice.\n. > @sindresorhus what got should do if request is POST and options.body is present - ignore options or ignore proxy?\nI don't get it. POST and options.body aren't mutually exclusive.\n. > stream.pipe(got.post('...', { body: Buffer() }));\nI think we should throw. It's ambiguous and could be assumed both ways.\n. Yes, because it's already in options.body mode and those two aren't compatible. There's no good reason to want to do this. I'd rather know about it as it would definitely be a mistake.\n. Thanks @floatdrop. Looks superb to me :)\n. This is not a breaking change, right? Thinking about releasing it as 2.2.0.\n. Mocha is horrible so happy with this change. Will review it soon :)\n. Awesome! :)\nI don't know how to do that either. Can you open an issue and I'll try to look into it at some point.\n. Why? What's the use-case? I'm trying really hard not to end up like request with a gadzillion useless options.\n. > One of usecases is to get content of 3xx page\nWhy would you want that? Redirects are there for a reason.\n. > Other problem pops, if you must use API, that does 11 redirects. :)\nLet's wait and see if an actual use-case comes up worthy of supporting this. I know it seems minor to add an option, but it easily bloats up, and suddenly we have request.\n\nOther problem pops, if you must use API, that does 11 redirects. :)\n\nIf that ever happens I want it to fail. Lol.\n. > if you have some constant in code, it should be configurable.\nThere's probably where we differ. I'm more into Apple's approach of providing a seamless experience for the 95% use-case. If someone needs this, which I really doubt, they can just use request.\nAnd I would never implement something just because others did.\nAnother downside is that now the user have to learn about this option, learn about redirects, consider if they need to change it, etc.\n. Yes, as long as we document it. I think it's fixed in Node 0.11 though.\n. Node 0.10 will still be have to supported for a long time after (or if ever) node 0.12 is released. I think we should do it.\n. Thanks for the tip @silverwind :)\n. Why?\nAccording to its docs it was only needed because of an old buggy Node version:\n\ndisableGzip set to false, to disable content gzipping, needed for Node v0.5.9 which has buggy zlib\n. Yeah, I don't see the point of that. We should optimize for the common case. For super edge-cases like these people can use request.\n. Woot! Much PRs :D\n. Nice! :)\n. $ npm i -g superb\n$ superb\ngroovy\n. I'm fine with that tradeoff.\n. @julien-f Just badly worded. Check the PR for better description: https://github.com/floatdrop/infinity-agent/pull/1\n. Thanks for adding this :heart: \n\nI was planning to. Promise :)\n. Agh, so why don't node do that for us then...\nDoes any of the other tiny HTTP libs implement this?\n. :+1: I'm always happy to improve error messages.\n. Hah, I saw that too. Of course not.\n. @floatdrop :+1: \n. Lgtm. @floatdrop?\n. Should be noted in the readme somewhere.\n. Woot :)\n. :+1: Good calls all around :)\n. I think we should if the response content-type is JSON.\n. yeah, nvm\n. :+1: :shipit: \n. :+1: \n. Lgtm. Glad to see it's now more aligned with Node. I don't mind the verbosity. It's going away at some point anyways :)\n. Generally not a fan of promise wrappers, but sure, since it's you :)\n. We can evaluate on a case-by-case basis.\n. Re got-promise, I think it would be nicer if you exposed the promise as the main export, and dropped the .promise property. If people want a callback API they can just use vanilla got.\n. > what got call returning without having gotPromise variable around.\nNot sure what you mean. Mind showing an example?\n\nAlso it is easier to migrate from callback to Promises with this drop-in replacement.\n\nIf you mean gradual migration, they could just use both temporarily. Don't really see the benefit here either.\n. If you insist on having the old API available I would at least do:\n``` js\nvar got = require('got-promise');\ngot() // => Promise\ngot.raw() // => Stream\n```\n. Headers are case-insensitive. We lowercase them so we can more easily deduplicate.\n. There's no reason to do so, but I believe Node normalizes them for us, so they'll get sent as you want.\n. > By the way, placing host in options will break readirects because of this line.\nCan you open an issue about that?\n. :+1: Makes sense.\n. > got('host.com', { host: 'newhost.com' }).pipe(process.stdout);\nCan't we just throw on this? I see no sane reason why this should be supported. What even is the expected outcome if it were allowed?\n. > got('host.com', { host: 'newhost.com' }).pipe(process.stdout);\nCan't we just throw on this? I see no sane reason why this should be supported. What even is the expected outcome if it were allowed?\n. Sounds good :+1: \n. 2\n. :+1: \n. I have no idea how this is supposed to work tbh. What does the spec say? What does request do?\n. :+1: \n. Thanks, but not interested in listing a gadzillion wrappers. co has full support for promises, so you can just use got-promise.\nAlso, from co readme:\n\nThunks are functions that only have a single argument, a callback. Thunk support only remains for backwards compatibility and may be removed in future versions of co.\n. Hot\n. Agree with everything :star2: :+1: \nIt seems like resolving to Object make much more sens - order of vars is not matters and user can access body, without response (or vice versa with different order).\n\nYes, I would prefer an object too.\n\n@kevva @julien-f @silverwind @arthurvr @shinnn\n. Is there an io.js ticket for this? If not, can you open one? I don't see how this is relevant to got though. We're just a consumer of the HTTP API.\n. Seems like it's fixed in Node 4:\n\u276f node -e 'require(\"./\")(\"http://127.0.0.1:0\", err => console.error(err));'     \n{ [RequestError: connect EADDRNOTAVAIL 127.0.0.1 - Local (0.0.0.0:65229)]\n  message: 'connect EADDRNOTAVAIL 127.0.0.1 - Local (0.0.0.0:65229)',\n  code: 'EADDRNOTAVAIL',\n  host: '127.0.0.1:0',\n  hostname: '127.0.0.1',\n  method: 'GET',\n  path: '/' }\n. Thanks, but we're making got promisified by default, so none of these should be needed for much longer.\n. You can easily use it with a proxy: https://github.com/sindresorhus/got#proxy\nBuilt-in proxy support will come when someone implements it. I don't need or care about it.\n. What does request do?\n. @kevva :arrow_up: \n. :+1:\n. > It seems that http(s).request(url) uses url.path while urlLib.format(url) uses url.pathname.\nShould we maybe open an issue on iojs? Seems like that should be consistent.\n. > Side-effect: now you can specify got options in first argument:\nShould this be documented?\n. Super nice cleanup and improvements @floatdrop :D\n. \n. I'm not sure tbh. Empty response on 200 is invalid, so we shouldn't do anything there. 204 is valid with blank response, so we should maybe handle that somehow (suggestions?). Maybe we should only try to parse JSON when content-type is \"application/json\"? I assume servers don't send that on 204?.\n. @stevenvachon \u2192 https://github.com/sindresorhus/got/pull/159#issuecomment-173184834\n. New thread about adding proxy support to Node.js core: https://github.com/nodejs/node/issues/8381 (Vote/comment please)\n. > NPM works fine with --https-proxy and --proxy, so its only logical that all modules built on top of it support this basic mechanism. \nGot is not built on top of npm.\n\nSo maybe this needs a another look as \"A nicer interface to the built-in http module\" (from your readme) is a big call if basic http modules functions are not replicated...\n\nThe Node.js core http API doesn't support proxies built-in either.. Closing this as I don't see us adding native proxy support. It's just too complicated and would bloat Got. It can already be done by the user by following this recipe.. :+1: Looks good.\n. Maybe we should do a patch release now before the 4.0.0?\n. \n. Yay! \\o/\n\nGave it a quick shim and generally looks good. Will give it a proper review tomorrow.\n\n// @julien-f @kevva @shinnn @arthurvr \n. Sorry about the delay. I'm traveling in Iceland at the moment. Will be back on Friday.\n. Ok, found some time on the airport to review. Expect for some super minor nitpick this looks really good! I like how the code is a lot more readable now. Great work :)\nFeel free to merge when the inline comments are resolved.\n. @floatdrop Anything else we want to get into 4.0.0? Breaking changes would be nice to get in now so 5.0.0 can be far in the future.\n. :+1: \n. I prefer statusCode as it's a clearer intent.\n. @floatdrop What happened to https://github.com/floatdrop/got/commit/58bfb201fbecd0a3e9934e5f36cb1e98d59a8671 in the 4.0.0 PR? Did you back out of it?\n. Yeah, that seems like a bug in https://github.com/sindresorhus/prepend-http Will fix.\nI didn't realize got works in the browser through browserify. That's awesome! I assume browserify shims the http module using XHR.\n. Definitely!\n. @lukehorvat Should be fixed now. Try reinstalling got ;)\n. @lukehorvat Alright, paste in the link to the issue when you do so we can follow along.\n. @floatdrop Woot! Try gzipping too. That gives more accurate numbers.\n. :+1: \n// @kevva \n. Awesome :)\n. An option for this is not going to happen.\n. gh-got haven't implemented the got promise API yet: https://github.com/sindresorhus/gh-got/issues/7\n. :+1: \n@vdemedes Can you add some docs? Similar to https://github.com/request/request#unix-domain-sockets Preferably with real use-cases.\n@floatdrop What do you think?\n. I didn't mean we should implement all the retry options. I just want a option-less sane default.\nThe benefit of including it in core is that all consumers benefit without doing any extra work, or more importantly without having to know it's needed in the first place. Most wouldn't even be aware they should be using retry with got. If we decide to recommend it in the readme instead, all got consumers will have to do the same with their readmes, etc...\n. Yay!\n\nUse ES2015 in tests (maybe after sindresorhus/ava#50)\n\nNah, don't have to wait for that. Tests will only be a tiny bit slower to start.\n. > Fix body in GET test on NodeJS 0.10\nMaybe try running it as test.serial. Might be some kind of race issue.\n. :fireworks:\n. Passing Basic Auth in the URL is deprecated and not even possible anymore in Chrome and IE.\nhttp://serverfault.com/questions/371907/can-you-pass-user-pass-for-http-basic-authentication-in-url-parameters\nI think we should add a note now about using auth header instead and in the next major throw if user try to do that instead of using the header. @floatdrop Thoughts?\n. > yes, username:password is deprecated by rfc3986, but this format is supported by Node url.parse method, so I don't see why we should explicitly forbid that.\nIn contrast to Node, we can actually prevent its usage. Node has way too much baggage and dependence to do something like that. As for reasoning, it's deprecated and it would help users doing the right thing, and not end up with problems like this one. I see no downside doing this: https://github.com/sindresorhus/got/issues/106\n. Chrome caving to users doesn't mean deprecating it wasn't the right move and doesn't mean we should follow them.. You're right that it's not our battle, and I don't really care enough to do all this. Let's just remove the check.. > \u2716 MaxRedirectsError: Redirected 10 times. Aborting.\nThat means your internet connection is somehow intercepting the connection and making it redirect in an infinite loop. The alternative is that got would never finish and indefinity stall the install process.\n. Yeah, I'm planning on fixing that in the next XO release. For now we can just ignore the test folder.\n. Awesome! :heart: \n. Looks good. Can't think of anything else. got is now pretty much feature complete in my view.\n. :+1:\n. Can you provide a realistic example of when someone would need this?\n. Then I'm :-1:. @floatdrop ?\n. :+1: \n. > code: undefined,\nIs there any point in including the code prop when it's undefined?\n. Closing. People have fetch-based libs now that are better suited for the browser. Got's focus is Node.js.. :+1:\n. I would just drop them both at once. The next one is Node.js 4.2 which brings a lot of improvements and ES2015 goodies.\n. I would also like to drop callback-API support in that version.\n. @floatdrop I think we should just drop parse-json. I don't think it's worth its size (100kb) in this case.\n. Lol, I was literally just writing this exact ticket :p\n. When we depend on at least Node.js 4, I don't really see the point of having a dependency on readable-stream. It's huge.\n. Yup, that will be the first thing we'll try, unless we find a way to do what we need without it.\n. I would prefer a solution that don't result in more options. How about just improving the default?\n. Why? Does lowering it not solve your problem?\n. I guess this is a good compromise and frees us from more requests about retries.\n. Shouldn't it be 0 and not false?\n. @floatdrop Those aren't realistic examples, though. For both of those you would just do retries: 0 instead. The thought with 0 is that it's already using numbers, so we keep it to one type.\n@maxvipon Thoughts on this?\n. Looks good to me.\n@maxvipon ?\n. :+1: Looks really good to me! When do we want to release this?\n. Can you drop the inherits dependency from create-error-class? Just use normal JS subclassing with Object.create().\nCan you do a scoped package @floatdrop/duplexer2 for https://github.com/floatdrop/duplexer2/commit/f770b342321823b20bcf86177961178ac619be69 ? I don't want us to depend on a git repo.\n. > Thanks! I'm thinking about rc version to test changes\n:+1: https://docs.npmjs.com/cli/dist-tag\n. Yay! \\o/\nSuper nice work on all this @floatdrop :)\n\n. @floatdrop I think we should document it, for clarity.\n. Yes, but we don't linkify the response to the corresponding Node.js docs (we should do this too), and even if we did I think it's worth be explicit about it as the Node.js docs are pretty messy. Just to make it simple for people.\n. > or you are talking about additional Aborting stream section in readme?\nYes. Doesn't have to be a section, could just be somewhere in the docs as a tip or something.\n. @julien-f Promises can't yet be cancelled. https://twitter.com/phuunet/status/668576359728422912\n. Nice! :)\n. :+1: \n// @jonasfj @techniq \n. The current is valid, but I guess this is a bit more readable.\n. Sure.\n@floatdrop Can you publish it as duplexer3 (makes sense since it's now using Streams 3).\n\n// @bcoe @othiym23 Just fyi. Would be nice if the docs for scoped public packages mentioned all the known issues so people would know not to use them. Currently as far as I know: They don't work for replication, they don't show up in search, they don't have stats, they fail on older Node.js versions, and some more issues I can't remember right now.\n. That's unfortunately how promises works. They are silent by default. You have to explicitly .catch() it.\n. You might find https://github.com/sindresorhus/loud-rejection useful ;)\n. :shipit: \n. From that issue:\n\nI would prefer for the solution to be an external module got can just depend on as I don't want to have to maintain it. Maybe https://github.com/mikeal/tunnel-agent.\n. > I guess you would rather have it replace http/https?\n\nYes, or even better, a custom http agent.\n. @alexsantos Yes, something like that is what I was thinking. Unfortunately the proxy-agent dependency takes up 7.4 MB, which is way too much.\n. // @floatdrop \n. @floatdrop Unfortunately not to achieve what most people requesting this want, as they want modules or modules of modules using got somewhere in the chain to support proxies transparently. Should be possible to find/create a smaller dependency though.\n. The first example in the readme shows how you can access the body in an error.\njs\n    .catch(error => {\n        console.log(error.response.body);\n        //=> 'Internal server error ...'\n    });\n. > some servers\nWhat servers? I don't like the idea of having to support broken servers.\n. Adding stuff just because of broken servers is a slippery slope. Probably better to try to add it to requests which is huge for a reason and covers a lot more legacy and broken behavior than got.\n. You can already do that. The url argument can be a string or object. https://github.com/sindresorhus/got#url\n. It should redirect automatically for you when the code is 301: https://github.com/sindresorhus/got/blob/db420fbab9fe5c3c6fdbea3f19a32600e1f3c7b0/index.js#L35 Maybe the location header is missing in the response.\n. After much thinking I'm :+1: on this. @floatdrop You ok with this?\n. @floatdrop We don't have a maxRedirects option. ?\n. I'm not a big fan of -1 input, and in that case it could just be 0, but still, I don't really see the need for a maxRedirects option, and since we have neither at the moment, I'd rather just expose a followRedirects option that is actually requested by multiple people.\n. Why not just use the agent option?\njs\ngot('google.com', {agent: require('spdy').createAgent()});\n. I guess we could try/catch it, but let's see what @floatdrop says.\n. @floatdrop To be clear how it would work. Node.js module resolution reads dependencies recursively upwards in the dependency tree. That means we can try/catch trying to require spdy even though we don't directly depend on it, and we'll be able to require it if the user that also depends on got, depends on spdy. I think that's the best way to support it right now.\n. Relevant: https://github.com/nodejs/node-eps/pull/38\n. I welcome a PR for this, but it's not something I can prioritize right now.. Relevant request issue: https://github.com/request/request/issues/2033. Relevant Node.js issue about bringing HTTP2 support out of experimental: https://github.com/nodejs/node/issues/19453. @hisco You should compare notes with @szmarczak. He made https://github.com/szmarczak/http2-wrapper for the same purpose. Also see: https://github.com/sindresorhus/got#experimental-http2-support. @floatdrop Most servers are compliant, though, and it would be nice not having to set the JSON option for those. Maybe we should think of the JSON option as an override in the edge-case of the server being non-compliant?\n. @SamVerschueren Yup\n. @floatdrop That's true, but if the server sends application/json, I think we should trust the server. The whole point of content-type's is that server can indicate what it supports. If it suddenly changes behavior it can break a lot of other things regardless of this change.\n. What does the HTTP spec say?\n. I just checked now and we're not using @ in the user-agent string: https://github.com/sindresorhus/got/blob/3dc219e70474e54c4ec4b2c27468f6ff722f8c6b/index.js#L205\n. @avyaznikov Works for me. Can you do a PR? Also need to update https://github.com/sindresorhus/got#tip\n. Thanks :)\n. @spencerhakim Can you provide a code example of how it would look like?\n. Reopening, but we're not likely to do another major in the near future.\n. Wouldn't it make more sense to pass the object literal in body?\n. Not interested adding a temporary workaround when it's possible for you to stringify it yourself. We'll add support for passing object literal in body when json: true in the next major release.\n. @floatdrop I don't really see the confusion. json: true makes it clear it has different behavior. Just need clear docs.\nrequest supports the same:\n\nbody - entity body for PATCH, POST and PUT requests. Must be a Buffer, String or ReadStream. If json is true, then body must be a JSON-serializable object.\n. > for example API that accepts form in body, but returns JSON\n\nHm, I didn't think of that use-case.\nrequest has a separate form option for posting an object serialized as application/x-www-form-urlencoded. I think that would be a less surprising way. Since the JSON thing would be a breaking change, it might worth doing this too.\n. PR welcome for the change described in https://github.com/sindresorhus/got/issues/174#issuecomment-227001985. Would be nice to have this included in the next major version.. I feel we're overthinking it a bit here and trying to consider too many imaginary edge-cases. The JSON option is just meant to cover the common case. If someone wants more advanced configurability they can just not use it.\nProposal:\n\nIf json: false, body will be required to be a string, buffer, readableStream.\nIf json: true, body will be required to be a plain object and will be JSON stringified and correct headers set and response will be JSON parsed.\nIf form: true, body will be required to be a plain object and will be stringified with querystring.stringify and sent as application/x-www-form-urlencoded. If json: true, only the response will be parsed.\n\nI'm open to suggestions on how we could simplify this further.. > your proposal means dropping the default querystring serializing of object values passed as the body, like I proposed in #265 right?\n\ud83d\udc4d \n\nI want to suggest we support all inputs that querystring.stringify and JSON.stringify support, or maybe their shared subset.\n\nI'm not sure what this means. Can you elaborate?. I vote 1. I'm ok with also supporting an array, but querystring.stringify is IMHO too loose.\n\nI for one do use the plain values.\n\nReally? I've never seen that before.. @AlexTes That's actually a good way to do development. Let's call it Complaint-Based-Development. It's so easy to try to solve every imaginary use-case and get bloated. Implementing the minimum and rather change later if many people complain means you only implement what most people need.. From #79:\n\nI would prefer for the solution to be an external module got can just depend on as I don't want to have to maintain it.\n\nWe're not interested in having to maintain all this custom proxy code which is definitely going to need a lot of maintenance in the future, talking from experience and having seen how much churn the proxy code in request got and still get. The solution is a library we can just plug in without having to maintain.\n\nAlso see https://github.com/sindresorhus/got/pull/159, where @tgandrews said he was working on a lib.\n. @floatdrop Is this something you still want?\n. @julien-f Would there be any actual benefits of switching?\n. Ok, then I don't really see the point of switching.\n\n\nAny opinion on this? (This might not be the best place to discuss about this, feel free to open an issue there).\n\nCan you open an issue there called Feedback and mention me?\n. @floatdrop Now that we target Node.js 4, wouldn't it be better to actually subclass the errors?\nFor example:\njs\nclass HttpError extends Error {\n    constructor(message) {\n        super(message);\n        this.name = this.constructor.name;\n    }\n}\n. @julien-f Why?\n. Yeah, I don't know either. Just assumed it would be ok since we already target Node.js 4 JS features.\nWe can do it sometime in the future though: https://github.com/sindresorhus/got/issues/190\n. I don't really know. How does request handle it? Maybe someone smarter than me will come along here and inform us. We could at least handle it correctly for non-streams, right?\n. https://github.com/request/request/blob/c289759d10ebd76ff4138e81b39c81badde6e274/lib/redirect.js#L117-L118\n. > I'm good with this\n\ud83d\udc4d \n. :+1:\n. It's right in the linked Node.js docs: https://nodejs.org/api/http.html#http_http_request_options_callback\n. @floatdrop Not sure it's worth doing, but we could expose just the URL on the result, not the rest of the options.\n. For simplicity we could add a requestUrl property that is the initial URL as string. So #191 would add .url which is the final resolved URL and requestUrl would be the initial URL. What do you think about that @floatdrop?\n. Cool.\n@luanmuniz Can you update this PR accordingly (and mention it in the docs)?\n. Duplicate of https://github.com/sindresorhus/got/pull/166. Can you elaborate on why you need this?\n. I'm \ud83d\udc4d on this.\n@floatdrop ?\n. Needs to be documented in the readme and merge conflict fixed.\n. I don't see the point of this. Just use version 5 if you need to support older browsers. Browsers are not the main target of got anyways.\n. Both Node.js 0.10 and 0.12 are out of active LTS, so we dropped support for them. No point in introducing the overhead of a build-step when we get what we need natively with Node.js >=4.\n. I now accept TypeScript definitions if anyone looking is interested in submitting.\nSee: https://github.com/sindresorhus/ama/issues/439#issuecomment-414212229\nPlease follow this guide: https://github.com/sindresorhus/typescript-definition-style-guide. This is not a solution we're interested in. I do however see that it how it works can be an issue. I don't really have a solution, but happy to discuss in an issue if you have a better proposal :)\n. Duplicate of https://github.com/sindresorhus/got/issues/79.\n. No thanks :)\n. @floatdrop You good with this?\n. LGTM\n. @floatdrop I don't think that applies anymore with Streams 2.\n. No idea, but Node.js supports it, so might be something you can pass to the options. Most of the got options are just passed through to the https module.\n. Agreed\n. This is supported by Node.js. Anything Webpack doesn't handle that Node.js does is on you to handle.\n@eugeneross You should open an issue on Webpack for it to handle require'd JSON ;)\n. @jamestalmage That's is if you want to load JSON yourself. Webpack should handle the case of Node modules using require for JSON. It's a very common convention. Users shouldn't have to care if a dependency they use do this.\n. The Promise API is cancelable now and we expose many of the Stream events on the Promise APIs. I don't think a full merge will be possible or even wanted. So I'm closing this now. If there's anything else we can improve, open separate focused issues about it.. @bisubus Functions are objects. util.isObject is deprecated.\n. @bisubus We could always just do isObj(body) && body !== 'function'.\n. Needs a test\n. // @jamestalmage FYI, for follow-redirects.\n. \ud83d\udc4d \n@floatdrop ?\n. Agreed.\n@bisubus Would you mind adding a test and fixing the merge conflict?\n. Wouldn't it be better to do that in the http polyfill Browserify uses so anything using Browserify and http would benefit?\n. We're not going to do this. fetch() was built for the browser, the HTTP APIs in Node.js are much more powerful. You can just use node-fetch.. OAuth 1 or 2?\n. For OAuth 1, there's https://github.com/ddo/oauth-1.0a and https://github.com/bettiolo/oauth-signature-js\nMore here: https://npms.io/search?term=oauth\n. Let us know if you find a good solution so we could add it to the readme ;)\n. I prefer the second one too. Would you mind doing a pull request adding that to the readme? Using the header method would be best. The query string method, from what I can remember, is for when you can't send a header, like JSONP.\n. The test should send a request and check that correct headers were actually sent. See other tests for how to do it.\n. ping @DylanPiercey :)\n. LGTM when https://github.com/sindresorhus/got/pull/220#discussion_r77452874 is fixed. @floatdrop ?\n. Actually, I'll just fix it when merging. Thanks @DylanPiercey :)\n. \ud83d\udc4d \n{ url: url, method: 'GET' } => {url, method: 'GET'}\n. Looks great! Thanks @thisconnect :)\n. Shouldn't we look more into why it's hanging? Maybe there's something we could improve regarding the retry logic or even reduce the number of retries to 1 or 2. It would be too bad to set it to 0. Network is generally pretty unstable and having retrying by default in theory means more reliable network requests.\n\nalmost every person, that uses got stumbles on hanging calls for some urls and almost every time this caused by silent retries.\n\nI've never stumbled upon that, and I use got in a lot of modules.\n. @floatdrop No, you're not exaggerating if it's the case that it's just hanging. That's bad. Having a test case that reproduces the hanging would be very beneficial, so we could do some experimenting. We should understand the problem before trying to fix it. Could be something unrelated to the number of retries. Maybe the is-retry-allowed blacklist is missing a problematic status code.\n. @floatdrop What should we do about this? I wonder if it works better in latest Node.js?. Can you elaborate a bit more. How will exponential=>constant help? I don't even know what the problem actually was.. I think we should lower the default retry to 3 in the next major. I can't imagine something that is working needing more than 2 requests, and 3 just to be sure. That would make the default max 7 seconds. Is that acceptable?\n\n\nIn other hand, backing up retries can reduce traffic amplification, when something goes wrong and all services start retrying endpoint.\n\nThundering herd problem. @AlexTes Any thoughts?. Seems like a case of the content having no body. (Relevant: https://github.com/request/request/pull/2176).\n. @floatdrop Maybe it could simplify your timed-out module?\n. Why? Please include a issue description.\n. Haven't had a chance to think this through yet, but sounds like a pretty good venue for security issues.\nfetch() intentionally doesn't support file://.\n. Please read the actual text there about it.\n. Going to pass on this. See https://github.com/bitinn/node-fetch/issues/75#issuecomment-299755555 for reasoning.. Please include a more comprehensive issue description.\nWhat exactly would you like to see changed in Got?\n. Can you provide a code example of how you would like to use URL with Got?\n. I don't think it's essential enough to add more dependencies for Node.js 4 support, but happy to add support for WHATWG URL when a user is on Node.js 8.. \ud83d\udc4d  We already do this for normal got usage (https://github.com/sindresorhus/got/commit/1409f828fee8ef3fb95cf06071a01600d64de0e5), but I think we forgot about the stream case.\nInterested in doing a pull request? :)\n. We now set requestUrl twice in different places. I think we could set it once in the requestAsEventEmitter instead, though haven't tested it.\n. @floatdrop LGTY?\n. As I already commented in #50, headers are case-insensitive.\n. got is made for compliant servers. Sounds like request would be a better choice for you :)\n. This test contradicts your statement: https://github.com/sindresorhus/got/blob/205e224bcd3e1cc756841c62d0f6a0e503d7dfbb/test/error.js#L24\nSubmit a failing test and we'll look into it ;)\n. Let's go the explicit route with a urls property.. Would you mind submitting a failing test? That would make it a lot easier for us to fix the problem ;)\n. Agreed\n. Just do feature testing by checking if Buffer.from exists.\n. Got, like most other promise returning modules, just uses the standard Promise API, which doesn't yet have support for .finally.\nIf you want finally, do global.Promise = require('bluebird') (or any other promise lib with .finally support) in your app (never do this in a reusable module!). Or use https://github.com/sindresorhus/p-finally. You could probably use aws4 and pass in the result to Got. Happy to accept a recipe in the readme when you figure it out. See the OAuth one for reference.. \ud83d\udc4d Pull request welcome :). Not something we're interested in exposing, no. You also can't realistically ask every dependency you use to expose such option. Either override global.Promise or Bluebird.resolve(got()). Or you could use a Babel plugin: https://github.com/59naga/babel-plugin-transform-bluebird. I don't think we should throw, but instead make it clear in the readme that the response body might be empty if you choose to send a if-modified-since header.\nHow does request handle this?. Seems like what we should do too. I searched the request issue tracker and couldn't find any issues with 403 and JSON, so seems that solution is working fine for them.. @lukechilds A test and the mentioned readme update.. > When writing it I noticed that the mock 404 route is wrapped with setTimeout? Why is this? Tests still pass if I comment out setTimout. Should I be doing that for my 304 route?\nNah, you don't need. According to git blame, it was added to workaround some flakyness. Probably related to older Node.js versions. https://github.com/sindresorhus/got/commit/46d0d4a4f404d633beb4a5235cf2fec1e9b4fc1a\n@floatdrop Let's just remove that setTimeout now? I don't think it applies anymore.\n\nRegarding the readme update, is it really necessary to mention a 304 response will have an empty body in the readme? That's normal HTTP behaviour, if people are sending if-modified-since headers then they are gonna be expecting to handle 304s.\n\nExpecting users to know something is like asking for support questions. Doesn't hurt to have a quick reminder about it.. Yup. Looks good. Thanks again :). Thank you :). I think there's a reason those libs doesn't provide a default timeout. Python doesn't have a default timeout either. Got doesn't know what it's being used for. Maybe someone needs a request to take one hour. What do we know. There's really no good default that fits all. Better to just never timeout and then let consumers with more knowledge set it to what they want. We should probably make this more clear in the readme.. @floatdrop \u2b06\ufe0f . Is it really necessary to have that distinction? When will you ever need to set the connection timeout manually? What about a \"whole body timeout\"? That what I would care about. A timeout for the total request.. > They are quite different things and often confuse beginners. I'm good with setting timeout option for whole request timeout, but keep socketTimeout and connectionTimeout tuneable.\n\ud83d\udc4d Alright. Let's do that.. No, the main target is Node.js. It's up to you to properly transpile it if needed in the browser. You could also use version 5, which uses ES5 syntax.. This is not really the place to ask for AWS support. We only have that recipe for convenience. AWS support is not part of Got. Maybe @reconbot, which added the recipe, can help you. Otherwise, I'd recommend asking on Stack Overflow.. Duplicate of https://github.com/sindresorhus/got/issues/259.. Very good PR and reasoning @AlexTes. Sorry not getting to this sooner.\nI'm not entirely sold on the change itself though. The reason we added a json option is that JSON is the 95% use-case and we wanted to optimize for that. I've honestly never used any other encoding than plain and JSON. I would rather want to fix any confusion with the JSON option than replacing it with something more flexible.. Yeah, always hard to close PRs that had a lot of work gone into them, but that's why opening an issue first is often beneficial.. package is package.json. Extensions are optional.. Always happy to improve the tests. Thanks for the PR. I think it would be better to switch the whole test to use t.throws() instead though:\njs\ntest('should have statusCode in err', async t => {\n    const err = await t.throws(got(`${s.url}/non200-invalid`, {json: true}), got.ParseError);\n    t.is(err.statusCode, 500);\n});. > If I understand ava's blowing up correctly we shouldn't wrap the main got function in an anonymous function because it's caught at some point and returned in the form of a rejected promise.\nYes, no need, since we're passing in a promise, which is handled by t.throws.\n\nbreaking the test causes the following message:\n\nHow are you breaking the test?. @AlexTes Hmm. Weird. See: https://github.com/avajs/ava/blob/master/docs/recipes/debugging-with-chrome-devtools.md for debugging.. > Submit a PR to Ava! When .throws catches an error that is not judged valid by optional second arg we use the optional message from the third arg if there is any.\nThis ;) Could you open an issue (or PR) on AVA about this?. Oh wow. Good debugging! :). > Hope to keep contributing \ud83d\ude04 .\nPlease do! I'm in https://gitter.im/sindresorhus/meta if you have any questions. Sorry about the delay. I was busy in real life.. From the Node.js docs:\n\nNote: Today's browsers follow the WHATWG spec which aliases both 'latin1' and ISO-8859-1 to win-1252. This means that while doing something like http.get(), if the returned charset is one of those listed in the WHATWG spec it's possible that the server actually returned win-1252-encoded data, and using 'latin1' encoding may incorrectly decode the characters. - https://nodejs.org/api/buffer.html#buffer_buffers_and_character_encodings. I don't know. The Node.js docs are unclear about what you should do. I guess the safest thing to do would be to manually convert using something like https://github.com/ashtuchkin/iconv-lite. Duplicate of https://github.com/sindresorhus/got/issues/259.. I don't really see how that's something Got should fix. It is Webpack not following the Node.js resolution logic.\n\n// @thelarkinn. @TheLarkInn Webpack should resolve .json in sub-dependencies no matter what people define in the extensions option. This is how the Node.js require resolving works and by giving people ability to shoot themselves in the foot by forgetting to include .json when they override the option, Webpack ends up just wasting everyone's time in issues like this. (I've had to deal with this problem at least 10 times in the past).\nI'm not going to change anything in Got as it's Webpack that is not compatible with Node.js and I'm tired of all the churn. People always want the easy solution instead of fixing the actual problem.. Maybe this would work, or if not, we could always just check the individual properties:\njs\nconst err = await t.throws(got(`${s.url}/non200-invalid`, {json: true}));\nt.deepEqual(err, got.ParseError(new Error(), 500, {}, ''));. \ud83d\udc4d . I think we should rather expose an abort() method on the promise. Official promise cancellation is not happening, so we can just go with something homemade. Could maybe use https://github.com/sindresorhus/p-cancelable. @floatdrop Thoughts?. @AlexTes Did you figure it out? If not, I'd be happy to take a look if you do a PR of what you got.. I vote for Sam's proposal in https://github.com/sindresorhus/got/issues/278#issuecomment-285441196.\n@floatdrop Thoughts?. Lol \ud83d\ude1d\n\n. Maybe https://github.com/pornel/http-cache-semantics might be of some use. It seems to have a pretty extensive coverage of all caching possibilities and quirks in HTTP. Even if it's just for inspiration.. > maybe it would be better to limit the cached responses to only basic data\nYes, let's limit it to the basic data. statusCode, headers, body, url.\n\nI'm happy to create a new one.\n\nSeems like you need to do that regardless as you have yet to get a response on your PR.. Instead of adding an additional parameter to .set(). Couldn't we just create additional keys for meta data. So if there's a key called https://sindresorhus.com, we could also create a __ttl__$__https://sindresorhus.com (Or something), with the TTL value. I would really prefer to keep a simple glue API, so user could just input for example Map() directly without anything extra. Alternatively we could store the TTL in the data, so instead of putting the data {foo: true}, we put {ttl: 123123, data: {foo: true}.\n\nthen we could require a Promise interface which would be a bit neater.\n\nWe can just run the input through Promise.resolve(), so the user can submit any value or a Promise, and it's awaited if it's a Promise.. > I'm not too sure what you mean regarding creating a new cache entry for the TTL, I don't think I explained myself very well. I mean it's useful for other people to use the TTL in storage adapters, not that it's useful to store.\nI was proposing we just support TTL natively, so users can use any kind of \"dumb\" storage and get TTL support without doing anything extra.. I guess I'm misunderstanding how this all works. I assumed we get a TTL from the server, save it, and the next time the same resource is requested, we check the cache, check whether the TTL has expired or not, and than either uses the cache, or deletes the cache entry and TTL, and refetches from the server.. Ok. Makes sense. Thanks for elaborating :). I think that should be up to the consumer. If they choose to get a buffer encoding, it's up to them to properly handle it. With in-memory caching, it's easy as you can just save the buffer directly. When it's saved to disk, however, it's a little bit harder as you need a data format/database that supports blobs, or serialize it yourself.. Streams can only be read from once. If it's works now it's probably because you're sending something small which is still buffered.\nInstead, you should do the caching later on in the code. For example, we wouldn't want to cache an error response. I would do the caching here: https://github.com/lukechilds/got/blob/7d4365ec2569a4a5adbcca03e62bba2605f089dd/index.js#L173 And hook into the pipeline here: https://github.com/lukechilds/got/blob/7d4365ec2569a4a5adbcca03e62bba2605f089dd/index.js#L227. Ok, I looked more into this. You can get away with multiple listeners if you add them in the same tick. Since the stream will start pumping right when it has a subscriber, the second subscriber might miss something if it's added in a different tick. So, if you can add two listeners at once, the it should be ok. Alternatively, you could use a PassThrough stream to duplicate it: http://stackoverflow.com/a/19561718/64949. @lukechilds Just wanted to say that I'm totally \ud83d\udc4d on this approach.. > Does that seem like the better solution to you?\nIt's unclear to me what the difference is?. @lukechilds Ah ok, got it. Makes sense.. @lukechilds What's the status on this? Could you fix the merge conflict?. Looks really good :)\nTip: Use this view for reviewing (to ignore whitespace changes): https://github.com/sindresorhus/got/pull/284/files?w=1. > There are currently two headings titled \"cache\", which means the href #cache goes to the api docs, and #cache-1 goes to the main cache section.\nI think you can use an HTML link to force it:\n```markdown\n\nCache\n```. Landed! Thank you so much for working on this \ud83d\ude4c\n\n. Sorry, I'm not going to change something because of Webpack. It's up to Webpack to support the Node.js ecosystem. Open an issue on Webpack ;). @AlexTes require works perfectly for this use-case. We want to read the package.json once and cache it for the lifetime of the process. read-pkg would read it for every Got usage. require is also faster and less dependencies.. @AlexTes Add Fixes #666 (Use the actual issue number of course) to PR descriptions so the issue is closed when the PR is merged. More tips here: https://github.com/tiimgreen/github-cheat-sheet. It also makes it easy to quickly click into the issue.. @floatdrop Looks good to you?. This also needs to be documented: https://github.com/sindresorhus/got#errors Forgot about that.. Yes, I think we can abort the request whenever, so I think all we have to do is make promise.cancel() call request.abort().. > Fix the PCancelable rejection blowing up instead of hitting our catch handler. \nWhere is this happening?. Would you be able to submit a failing test for p-cancelable? I never got time to dig into this. A failing test would make it much easier to investigate.. > not sure about canceling before the request event is emitted. used an approach that waits for the request to start then tells Node to abort.\nIs that really necessary? I think you can abort a request whenever.\n\np-cancelable immediately when asked to cancel a settled promise.\n\nIt immediately does what?. > Anyway, last two commits show the issue - not a pretty test - and apply the stash I had that solves the issue.\nAh ok. I get it now.. @AlexTes In case you missed it, note: https://github.com/sindresorhus/got/pull/287#discussion_r115069123. Can you mention cancelation in the readme intro?. Can you add commits instead of rebasing? Makes it easier to see what changed. We'll squash on merge anyways.. > Any better method of testing is very welcome, as are of course any pointers to clean up the code more.\nI can't think of any better way either.. This is great stuff @AlexTes. Really appreciate all the hard work and thoughts you put into it. \ud83d\ude4c\n\n. I think this is the correct approach. We just want to support WHATWG URLs now, not use them internally. Can you also document this?. @stevenvachon Can you review?. @AlexTes Tests are failing. Why not global.Promise  = require('bluebird') like most people use in their application? That way you don't have to convince every single module you use to expose its Promise constructor.. I highly doubt Promise is the slow part of Got which deals with networking \ud83d\ude1c. @AlexTes I agree with your assessment. @floatdrop ?\n\nFor reference:\n\n303\nIf a server responds to a POST or other non-idempotent request with a 303 See Other response and a value for the location header, the client is expected to obtain the resource mentioned in the location header using the GET method; - https://en.m.wikipedia.org/wiki/HTTP_303. > There were an idea to switch to follow-redirects module, but it does not support 303 and 308 codes too.\n\nI don't really see any upsides of doing that then. Only potential subtle regressions.. > we should implement it, if rfc says so. \ud83d\udc4d\nCool. Pull request welcome then :). Done. > This fix would probably be as simple as adding a check around here \u2013 what do you think?\n\ud83d\udc4d . Thanks @pioul :). Readme updated. I missed it too.\nRight now we're targeting a new major release in a couple of weeks.. I don't mind tiny PRs. Easy to review and easy to merge.. @floatdrop What do you think of these changes? See my proposal in https://github.com/sindresorhus/got/issues/174#issuecomment-298292987. > I'm considering a second PR. Specifically what I feel could be better:\n:+1: Wait until this lands first though.. Thank you for yet another excellent pull request @AlexTes. I'd like to invite you to join the project if you're interested? \ud83d\ude4f. @floatdrop It's not a blocker. Just would be nice, as I'd like to have it on by default, which would be a breaking change.. @lukechilds Do you think it will be ready in a couple of weeks? Or should we just defer it to another release?. @lukechilds Alright. No pressure. We can add it in a minor release later on. I don't want to rush this feature.. @floatdrop We need to write a good changelog first. Hop into Gitter.. @maccelerated Glad you liked that. Do let us know in a new issue if there's anything else that could be improved ;). @sonicdoe Can you add a note in the readme about the behavior?. Thank you! :). I think this should be fixed in Node.js core if it's actually a big issue in the wild. We're just using the zlib.createUnzip() method. They could do the detection there. That way everyone would benefit instead of just Got users.\nResources:\n\nhttps://github.com/request/request/pull/2335\nhttp://stackoverflow.com/questions/37519828/how-can-we-distinguish-deflate-stream-from-deflateraw-stream/37528114#37528114\n\nSo please open an issue on Node.js instead.. Very soon: https://github.com/sindresorhus/got/issues/298. Perfect. Thank you @djmadeira :). > Should there be an option for whether GET or HEAD are used to follow up a 303?\nFrom what I could tell from https://en.m.wikipedia.org/wiki/HTTP_303 it should use the original method, unless it's POST, then it should be changed to GET. Make sure it works like this here.. > except maybe the surprising behavior of changing from POST/PUT/DELETE to GET on a 303 response\nI think that would be enough. Can you add that to the readme?\n\nSeems like a case for a changelog entry if one existed.\n\nIt does: https://github.com/sindresorhus/got/releases\n\nWhile we're on the topic, according to the spec, we should probably do something similar in response to a 300:\n\nI guess we could redirect then too if a location header exists. If not, it's up to the user to handle it.. @floatdrop @AlexTes :shipit: ?. > I've tried doing so in my error handler, but it appears the second request never starts, as if duplexer3 couldn't handle multiple requests\nYes, you can't reuse a stream.. I agree. We should support this.. > should we cache streamed body to allow retries?\nYou mean so it can continue where it left off in case the connection is broken in the middle of a request? Is that even possible? Or am I misunderstanding?. @floatdrop Agreed. We might be able to build that upon what's being added in https://github.com/sindresorhus/got/pull/284.. What @kevva said. It's because those statements create two new promise pipelines, and the last one doesn't have a catch handler. Promises are not mutable. Each catch/then handler creates a new promise.. What are you trying to use it for? Are using it with browserify/webpack in an Atom plugin?. @lselden Can you try latest master? I added support for running in the Electron renderer process.. @sonicdoe Great! Thanks for testing.. Confirmed, but it works on Node.js 8 RC1. Node.js 8 should be out in a few days.\nTry it yourself with: https://nodejs.org/download/rc/v8.0.0-rc.1/\nMy test-case:\n```js\nconst got = require('got');\n(async () => {\n  const getting = got('https://sindresorhus.com')\n  console.log('getting', getting)\n  const resp = await getting\n  console.log('resp', resp)\n})();\n``. @timdp Promise subclassing is probably buggy in that V8 version as async/await was just added then.. Just stay on Got v6 until you can upgrade to Node.js 8. I'm not really interested in spending time or code churn on this.. @timdp If you remove theextends Promiseandsuper()call from [p-cancelable](https://github.com/sindresorhus/p-cancelable/blob/master/index.js) it should work in Node.js 7. I prefer to beinstanceofcompatible withPromise` though. Node.js 7 is non-LTS release, so it's pretty much unsupported in a few days when Node.js 8 comes out anyways.. I'm open to consider a workaround for Node.js 7 if it's important to you. I just assumed it would be easier to upgrade to Node.js 8, as it will be the supported long-term release and it's pretty similar to Node.js 7, so should be an easy upgrade in theory.\n\nThat being said, the way p-cancelable calls the super constructor rightaway kinda scares me\n\nI think it's ok. It wastes one promise, but that shouldn't matter much.. > (Come to think of it, do you need to call resolve to begin with? I'm guessing that's mainly for the garbage collector?)\nGC yes, it's not required to work.. The json option is for POST'ing and receiving JSON. Why is your body a string?. > Won't decompressResponse always be a function?\nIt was added as the decompress-response package is not included when Got is browserified, so we need to handle it not existing.. > One use case that would massively benefit from this is implementing a reverse proxy server with Got.\nCan you include the use-case in the options definition? Not everyone realize what the option might be useful for.. \ud83c\udf70. @vadimdemedes Thanks for the quick turn-around.. Can you apply https://github.com/sindresorhus/got/pull/322#discussion_r125171040 to the other test.cb tests too?. @AlexTes @floatdrop I'll merge this on monday unless it gets any objections by then ;). Yay! Vadim, your sambuca-powered work is finally merged. Thanks for working on it. Good times.\n\n. @floatdrop @AlexTes Feel free to add your review still. I'm not gonna do a release yet.. Yes. > I think I'll kick this back over to the issue for further discussion.\n@AlexTes Which issue?. @AlexTes :arrow_up:. Either you specify an URL as the first argument and options as the second argument, or you only specify an options object as the first argument with the URL as URL parts (protocol, host, path). The first string argument is just a convenience shortcut. I do agree we should have better validation and docs on this.\ntl;dr You can't specify a url option if the first argument is an options argument. Not sure whether we should support this or not. If not, we should at least throw a helpful error.\nI'll try to find some time to add a good POST usage example to the readme.. I don't think we should support an url option, but I do think we should detect the mistake and throw a useful error.. \ud83d\udc4d Can you do a pull request?. > Maybe mentioning the json option in some way. It's pretty neat imo.\nDone. Yeah, we're are strict by default, with no way to turn it off, so that option does indeed look moot.. These are all problems with Webpack. Open an issue on the Webpack issue tracker.. Use Node.js 8. Node.js 7 is not LTS.. https://github.com/sindresorhus/decompress-response/pull/13#issuecomment-331626197. Node.js issue about adding it natively: https://github.com/nodejs/node/issues/18964. The docs needs to be updated to reflect this change.. Can you reproduce this with master branch?\n$ npm i sindresorhus/got. Not reproducible in master.. Can you add a test?. Thanks :). Got considers anything other than 2xx a failure. If you want to handle it yourself, you can simply .catch() it. The response is attached to the error.. Thanks for reporting. Looks like an oversight on our part.\nThe timeout should cancel the request, yes, but I don't think that's working either right now.\n// @djmadeira. Does it make sense if p-timeout calls .cancel() on the input promise if that method exists when a timeout happens? And p-timeout should have a .cancel() method itself that cancels the timeout and calls the .cancel() method of the input promise if any. How does that sound?\n// @floatdrop @lukechilds @AlexTes . https://github.com/sindresorhus/got/pull/360 fixes the issue with a workaround, but I prefer to eventually fix this properly in p-timeout, so reopening this so we don't forget.. This is a problem with Webpack. It shouldn't throw on a require that's inside a conditional. Open an issue on Webpack.. Electron issue: https://github.com/electron/electron/issues/10017. @lukechilds https://github.com/sindresorhus/eslint-plugin-unicorn/issues/107. https://github.com/sindresorhus/p-cancelable#cancelable-vs-cancellable. https://en.m.wiktionary.org/wiki/cancelation. In the end I just prefer consistency.. No thanks, the current package ordering is exactly how we want it.. Thanks for the suggestion, but we're already using XO for linting and code style. I might integrate Prettier into XO itself at some point though.\nIt's usually best to open an issue before doing changes like these as code style is very subjective.. What exact version of Got do you have installed and how are you using it (Promise API or Streaming)?. Wonder if it's something like https://github.com/request/request/issues/2120 or https://stackoverflow.com/questions/43194065/node-js-http-typeerror-the-header-content-contains-invalid-characters. I think this is fixed in master. Could you try running master?\nI could reproduce the unhandled exception when I put a throw statement in 7.1.0 here: https://github.com/sindresorhus/got/blob/b725ef576864fc6dd331b4df58ddb12f2f7d6b3a/index.js#L48 When I did the same in master, it was handled, since we now correctly catch and propagate errors: https://github.com/sindresorhus/got/blob/8b040afc0749523fcaaf6db81702c27e74f7a1d2/index.js#L258-L260. Not sure. Usually, that warning is just an annoying false positive though. Try to reduce your test suite until it runs again to narrow down what's causing it.. You're missing a ) at the end of your provided code. If I add that it works fine for me:\n{ ParseError: Unexpected token < in JSON at position 0 in \"https://www.google.com/\":\n<!doctype html><html itemscope=\"\" itemtype=\"http://schema.org/WebPage\" lang=\"...\n    at stream.catch.then.data (/Users/sindresorhus/dev/oss/got/index.js:176:15)\n    at <anonymous>\n    at process._tickCallback (internal/process/next_tick.js:188:7)\n  name: 'ParseError',\n  host: 'www.google.com',\n  hostname: 'www.google.com',\n  method: 'GET',\n  path: '/',\n  protocol: 'https:',\n  url: 'https://www.google.com/',\n  statusCode: 200,\n  statusMessage: 'OK' }. Maybe try upgrading your Node.js version. I've tried with Node.js 4, 6, 8, and it works fine for me.. 6.2.0 is a very old version of the 6.x.x line. Please try upgrading to the latest 6.x.x before we continue this. I'm on macOS too, so I doubt it's platform specific.. Got returns the final URL in the response object, so you can use that to resolve it to an IP-address. Untested, but something like this should do it:\n```js\nconst util = require('util');\nconst dns = require('dns');\nconst got = require('got');\n(async () => {\n    const response = await got('sindresorhus.com');\n    const ip = await util.promisify(dns.lookup)(new URL(response.url).hostname, {family: 4}).address;\n    console.log(ip);\n})();\n``. Duplicate of https://github.com/sindresorhus/got/issues/344. I'm ok with this workaround for now. Thanks :). \ud83d\udc4d . @Lancher Without theawait`, yes.. Duplicate of https://github.com/sindresorhus/got/issues/266 and https://github.com/sindresorhus/got/pull/349\nThis is a problem with Webpack and its bad compatibility with the Node.js ecosystem. Open an issue on Webpack: https://github.com/webpack/webpack/issues. I understand that and I'm sorry for the trouble, but I don't want to set a precedence that Webpack can do whatever they want and force the Node.js ecosystem to change. Webpack is the one that is interacting badly and should be fixed, not every Node.js module using a supported feature.\nSee: https://nodejs.org/api/modules.html#modules_file_modules\nPlease do open an issue on Webpack and let them know they're causing pain for both Webpack users and Node.js module maintainers.. > but when running from a separate directory where got is a dependency\nAre you running master version of Got from that directory?\nErrors should already be handled by: https://github.com/sindresorhus/got/blob/8b040afc0749523fcaaf6db81702c27e74f7a1d2/index.js#L258-L260. Yes, I'm planning a new release very soon. I just didn't want to do one yet as I've been busy and wouldn't have had time to deal with potential issues the new version.. Closing as v8 is the latest release now.. Thanks :). Duplicate of https://github.com/sindresorhus/got/issues/363, https://github.com/sindresorhus/got/issues/266, https://github.com/sindresorhus/got/pull/349. Submit a pull request with a failing test and I'll take a closer look.. Got rejects the promise for anything that is not a success (unlike request). We think it's better to handle unsuccessful requests in an alternative code-path (catch()).. Duplicate of #345. Got only uses Electron when in an Electron environment where the electron dependency is injected for you.. got.stream is a readable stream, not a transform stream.. Try asking on Stack Overflow ;). Thanks :). > Exposing the CancelError to check the Error instance type would be useful.\nPR welcome. I would be ok with that, as we already have a good whitelist and blacklist, so the error.code check would only apply to unknown errors.\n@reconbot Can you think of any downside with doing this?\n@floatdrop @AlexTes @lukechilds Thoughts?. Duplicate of https://github.com/sindresorhus/got/pull/372. >  (in my experience it was querystring.parse()) .\nI can't reproduce that:\njs\nisPlainObj(querystring.parse('x'));\n//=> true. >  I've just checked it, and it seems that it was changed in Node 8, \nI got the same result in latest Node.js 4 and 6 too.\n\nRegardless, we'll consider your request to change this.. I used n and the Node.js REPL.. Pull request welcome to loosen the restriction again, but should come with a test so it's not regressed in the future.. Yes, Sinon is fine. I plan to do a new release in a couple of days.. Thank you :). Excellent. Thank you @pietermees :). > Also, can anybody explain what test/helpers.js is testing? It's unclear to me, it looks like it could be tidied up a bit though.\nSee: https://github.com/lukechilds/got/commit/718bacdd3fddf736d6e5e0e71460ec5209325f3a#diff-8cdd6af9921d65cb55c40e628e46afcc Looks like it's just testing that got.get() works too, which is what got() is aliased to.. > While I'm working on this PR do you want me to clean it up a bit? Maybe also add tests for got.post, got.put, got.patch, got.head and got.delete?\nSure, that would be great.. @lukechilds Do you think you'll ever finish this or should I close? Happy to keep it open if you think you will at some point.. Closing this for now. We can reopen later on.. Closing as this would have to be done from scratch anyway and it's not a priority right now, the current tests are working fine.. Hard to say what it could be. There were a lot of changes between v6 and v7: https://github.com/sindresorhus/got/compare/v6.7.1...v7.0.0\nIf I were to guess, it might be caused by: https://github.com/sindresorhus/got/commit/578f38d5276d78be33bf55eff2d38b79ed6482d6#diff-168726dbe96b3ce427e7fedce31bb0bcR15 (Which upgraded the dependency) (This commit was the main change: https://github.com/sindresorhus/decompress-response/commit/79ee2525958ebf30e33f08d4ff97e9bd9bc4c086)\nCould also be New Relic hooking into something Got depends on and being naughty. It wouldn't be the first time: https://github.com/sindresorhus/p-cancelable/pull/4\nAlso might be an issue in Node.js itself: https://stackoverflow.com/questions/34396566/error-invalid-distance-too-far-back-when-inflate-html-gzip-content. @puzrin I tracked down the unhandled error event: https://github.com/sindresorhus/got/pull/424\nAs for why it's throwing in the first place, I think it's because browsers are more lenient to incorrect responses than Node.js:\n\nTurns out many browsers over the years implemented an incorrect deflate algorithm. Instead of expecting the zlib header in RFC 1950 they simply expected the compressed payload. Similarly various web servers made the same mistake.\nSo, over the years browsers started implementing a fuzzy logic deflate implementation, they try for zlib header and adler checksum, if that fails they try for payload.\n-https://stackoverflow.com/questions/388595/why-use-deflate-instead-of-gzip-for-text-files-served-by-apache#9856879. I plan to do a new release today or tomorrow. Nothing is stopping you from using npm i sindresorhus/got directly though.. New release is out: https://github.com/sindresorhus/got/releases/tag/v8.0.0. What exactly is this fixing? Can you add a test?. They're not really missing, as they're not documented to be part of the Promise interface. The readme should also be updated then. We document these already, so I guess we could just move them out of the Streams section and into a section for Promise & Stream API events or something.\n\nOut of curiosity, what's your use-case for needing these events on the Promise API?. > Why isn't part of Promise interface?\nMostly because we never saw any use-case for it.\nI'm ok with adding this, however, when test and docs updates are done.. @jgdev Interested in finishing this up? :). Ping :). This still needs documentation, as mentioned earlier.. @jgdev Still interested in finishing this up? :). Closing for lack of response. @jgdev Happy to reopen if you ever want to finish it up :). > The fact that http.request could throw was never accounted for so in Promise mode the thrown http error caused the Promise to reject.\nHow is the Promise rejecting incorrect? It is currently accounted for in Promise mode, as https://github.com/sindresorhus/got/commit/92ed73ad7f2a9ab3bb582a208f9f8eb7623092f5 proves. No idea about Stream mode though.. > Potential solution in lukechilds/cacheable-request#14 that would align neatly with Got's functionality.\n\ud83d\udc4d . Yes, we should fix this in AVA.. Is this with master branch or the latest version? A lot of things have changed since the last version.. Duplicate of https://github.com/sindresorhus/got/pull/349. Can you include a test?. @lukechilds I'll make sure to point that out in the release notes.. Thanks @sleewoo :). It's just an oversight. It should proxy headers too.. If you actually read the spec (not just the MDN page), you'll see:\n\nThe type, subtype, and parameter name tokens are case-insensitive.\n\nThe keys are case-insensitive, so lowercase is totally valid.. I don't think this is Got's fault: https://www.google.com/search?q=write+EPROTO. Uglify doesn't support ES6.. Thanks for fixing this and the comprehensive test addition :). Duplicate of #345. Agreed. Would you be interested in doing a pull request?. Looks good :). Thanks Brandon :). Great!. I think we should do this.\nI propose is that we retry on the following methods and status codes by default:\nMethods: GET PUT HEAD DELETE OPTIONS TRACE\nStatus codes: 408 413 429 500 502 503 504\n(Sourced from experience and other request clients)\nWe also need to respect the Retry-After header.\nRelated issue: https://github.com/sindresorhus/got/issues/379\n@lukechilds @reconbot @floatdrop @brandon93s Thoughts?. Networks are inherently unreliable. I think retrying by default makes sense, but we should be very conservative with the default.. > Would this functionality be rolled up into the existing retries option, or separated for more control? For API simplicity it makes sense to combine them\nI was thinking of combining them, but also allow passing an object where people can customize:\njs\nretries: {\n    retry: Number | Function,\n    methods: string[],\n    statusCodes: number[]\n}\nThoughts?\n\nbut the proposed functionality is more likely to need disabling than the current implementation.\n\nWhy do you think so?\n\n413 may be an odd one to retry since the retry would be sent with an identical payload.\n\nI agree. Let's take it out.. Actually, regarding 413:\n\n6.5.11.  413 Payload Too Large\nThe 413 (Payload Too Large) status code indicates that the server is\n   refusing to process a request because the request payload is larger\n   than the server is willing or able to process.  The server MAY close\n   the connection to prevent the client from continuing the request.\n If the condition is temporary, the server SHOULD generate a\n   Retry-After header field to indicate that it is temporary and after\n   what time the client MAY try again.\n- https://tools.ietf.org/html/rfc7231#section-6.5.11\n\nSo it seems we could handle 413 as long as it has a Retry-After header and the time specified there is below the set timeout. Am I interpreting it correctly?. > Replace is-plain-obj dependency with is and leverage throughout for additional readability and code clarity: (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, etc)\n\nExtract errors into separate file and use an assignment syntax similar to http methods (e.g. for (error of errors))\n\nWe can do these today. No need to wait. PR welcome.. I plan to target Node.js 8. Yup. I've started the work on this (https://github.com/sindresorhus/got/commit/2b1453734a0b51e5b5663b29c258a831dfe926f8). Let me know if anyone wants to help out.. > Use require('url').URL (WHATWG URL) as a replacement for isurl and url-to-options dependencies\n@brandon93s I've replaced isurl now, but not sure how we can replace url-to-options as it's needed so we get an object to pass to http.request(). What did you have in mind?. @szmarczak That would be amazing! I could definitely use some help. I'm trying to get out a new major release now and want to fix as many issues as possible, especially things that require a breaking change.. Join me in https://gitter.im/got-dev/Lobby if you want to chat. I'll go to sleep soon, but I'll be back there tomorrow.. > url-to-options is a bit outdated. The newer version is:\nYup, I've already changed to bundling it here instead.. > It's not needed to pass an object to http.request().\nBut there's no way to pass an URL and options to http.request... You have to choose either.. I think we should handle this somehow. It seems like a common need and the workaround is ugly. How should we handle it though? We could ignore the json option when it's a stream and it was created by extend/create, and document it? Any other suggestions?. Alright. Let's do that then.. Got 9 is out now: https://github.com/sindresorhus/got/releases/tag/v9.0.0 \u2728. > Only set default accept-encoding when decompress option is enabled\n@dastoori Thanks for your patience. Yes, that makes sense. PR welcome :). Thanks for elaborating @brandon93s. I think the correct fix here is to detect the case early in Got and throw a user-friendly error about the URL having an invalid encoding.. Yes. Can you change this to use GET? Retrying on POST by default is not safe, so even when we support retrying on HTTP status codes, we won't do POST by default.. I don't like this way of opting in. It should be even more explicit. I have some ideas on how the retry functionality can be significantly improved: https://github.com/sindresorhus/got/issues/417#issuecomment-366602879. Yay. This also slightly improves the code readability.. > Do you think it'd be worth giving a brief summary of the supported caching behaviour and referring people to cacheable-request for more info in the readme?\nYeah, I think it would be useful with a succinct summary in the Got readme.. Nice! :). https://en.wiktionary.org/wiki/cancelation. I think this should be fixed in the Browserify http polyfill instead. That way it would benefit every HTTP lib, not just Got. Working around Browserify polyfills is a slippery slope.. I find async/await more readable, but I guess that's debatable. The wrapper is only there because await can't yet be used top-level. It will hopefully eventually happen and we can then remove the wrapper. Even with the boilerplate, I still find it more readable than .then(), so not interested in changing that, sorry.. I'm lukewarm to the idea. It does simplify the above code, but it doesn't look like something you would commonly do. I'm gonna see what the other team members think.. Let's go with @lukechilds' proposal.. Those are Node.js built-ins and should not be defined as dependencies.\nhttps://nodejs.org/api/modules.html#modules_core_modules. Use http://webchat.freenode.net/?channels=node.js for Node.js support questions ;). Please don't open duplicate issues. I already answered your question.. You need to add errors.js to the files property in package.json. Yeah, I think we should expose it too and rename it to GotError.. Looks good :). Why? What problem are you trying to solve with this?. Perfect :). Cool idea :). Looks good. Thanks @brandon93s.. Can you try https://github.com/sindresorhus/got/pull/429 and see if it fixes your problems?\nCan you also open an issue on Electron about adding the missing connection property?. The response should be available on all errors, see docs. You could check for instanceof got.ParseError.. Relevant Node.js issue: https://github.com/nodejs/node/issues/11865. Thanks @brandon93s :). Can you also document it?. Great. Thank you, Juan :). Check out nock. It's great for this.\nNote to self: We should add something about it to the readme.. I think it's worth mentioning it. Nock should be good enough for most REST API tests, but sometimes you need real integration tests, and that's when create-test-server becomes useful.. @lukechilds LGTY?. Thanks Kevin \ud83d\udc4c\u2728. Ugh, I dread having to support older Node.js versions. Revert that change then.... Thanks, Juan :). I think people should know what buffers are in Node, but I don't mind improving the docs either.. Thanks :). Fixed by #459 . I think it would be more appropriate to remove the useElectronNet option altogether. The Electron implementation is far from compatible and they're not really fixing any of the issues. It sounded promising when I first added it, but it's only been a headache since then.. @wwwouter I'll keep it in Got for now. The best you could do is open Electron issues with test cases on the Electron issue tracker for any issue you encounter, and also paste the link to the issue here. These issues have to be fixed there.. I tried your tests from this PR in https://github.com/sindresorhus/got/commit/871c3bd25442edd3cd89190c3d4788c0efd5c2db, and they pass, so either that commit fixes the issue or your tests are faulty. Can you rebase from master?. @szmarczak Your test passes even without your changes in index.js.. > but I haven't added a test for it.\nCan you add a test for that?. Great. Thank you :). We already check for this here: https://github.com/gasi/got/blob/c3daa9e2e9c7f9070dfa405a7747f75a3a058b04/index.js#L50-L52 So there might be an issue with that check.. I don't think this is a good idea. window.fetch behaves the same way and forces you to explicitly choose the format you want await (await fetch()).json().. I agree with @brandon93s.. @AsaAyers Try moving the test to its own file. That way other tests will not affect it (Test files are run in separate processes).. @AsaAyers The other handles are probably ones used by AVA, the test runner. I think hard-coding is the best we can do.. No, sorry, NTLM will never be supported here.\nCheck out https://github.com/SamDecrock/node-http-ntlm or https://npms.io/search?q=ntlm. I like the idea in general but sounds risky as there might be other subtle differences between them. In a month, Node.js 4 will be deprecated and I plan to target Node.js 8 then (https://github.com/sindresorhus/got/issues/418), which has URLSearchParams. So I'd rather wait on that, than risk breaking existing users now.\nIf you wanna do a PR switching to URLSearchParams, that would be welcome.. Thanks for the PR, but I had other changes I had to get in too, so was easier to do it all myself.. Stream-mode refers to using got.stream() and piping the response. The body option is only for when using got() (Not got.stream()), and it can be a stream too, that's not related to stream-mode.. Not sure how this worked before since you're not authenticating, at least not in the code you've posted here. https://developer.github.com/v3/gists/#authentication. Cool. Also check out https://github.com/sindresorhus/gh-got which makes it easier to use the Github API.. @szmarczak has confirmed that Nock now works with the latest code in master.. See: https://stackoverflow.com/questions/10888610/ignore-invalid-self-signed-ssl-certificate-in-node-js-with-https-request?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa\nGot passes options to https.request.. I don't know, sorry. Whatever is correct for Node.js, is correct for Got.. Can you submit a pull request with a failing test? I'm requesting this as most issues like these are just users using the module incorrectly or an unrelated problem.. We've discussed this previously, but if you need that you can just handle the JSON manually. It's not a common case and it's not worth the overhead of adding a new option. Thanks for the suggestion though.. See: https://nodejs.org/api/https.html#https_https_request_options_callback\nI've fixed the docs.. No thanks. You can just use qs directly instead of the built-in query string handling if you need this.. What's your use-case? It optional, true, but it's a good practice to set it.. > Maybe allowing users to opt-out is a good compromise? E.G. Explicitly setting user-agent: null will remove it, if nothing is specified add the default user-agent.\nThat's how it currently works: https://github.com/sindresorhus/got/blob/a03d21e697311825c275d086e9335947a5538059/test/headers.js#L128-L136\nWe should document that better.. That's an issue with Browserify. It's up to Browserify to correctly polyfill Node.js APIs.. @VasiliiKuznecov Got never added a transfer-encoding header AFAIK. What did change in 8.3.1 is that Got now adds a content-length header when you use form-data (https://github.com/sindresorhus/got/commit/de9514d897ca58ec70bbf82acc52e43b44cca870).\nWould you be able to submit a pull request with a failing test?. @zuban The only difference for you is that content-length is now correct, which is how it should be. The behavior in Got 8.3.0 was incorrect, see https://github.com/sindresorhus/got/pull/466.. Released as 8.3.2. I'm already working on reducing dependencies in master, but it's a non-goal to remove dependencies for the sake of it.. > Reducing dependencies would therefore increase score on that website and therefore visibility.\nAn arbitrary score on a random website is not something I care about.. Yes, was going to comment, solution 2.. Can you also open an issue on cacheable-request? It seems it's not properly catching and propagating all errors.. This is a nice feature. I'll take a closer look this weekend and merge.. This looks great \ud83d\ude4c\nIt will probably be at least a week until I can publish this as I'm currently preparing for a big v9 release.. > I found myself wanting to create an instance with a hostname option and using only the path as the argument to my instance. ie:\n@ewolfe That would be very handy. Can you open a new issue about it?. Great! Can you document the behavior here https://github.com/sindresorhus/got#user-agent and here https://github.com/sindresorhus/got#api. @szmarczak Your change seems to fail on master. Could you take a look?. I'm not surprised. That test has a lot of assumptions. Probably best to just make it a macOS-only test as it seems to reliably pass there. Or better yet, improve the test.. \ud83e\udd47 . Sorry, I moved the source files into a source directory earlier... Could you update the PR?. Really good! \ud83d\ude4c. Can you explain the change?. Looks good. Nice work @szmarczak :). I'm a little bit worried that we're exposing too many internals now, especially got.normalizeArguments.. What's the difference between .fork() and .create()?. I really like how much it simplifies gh-got though. I'm sure it will enable more useful niche versions of Got.. We should list fork() first then, as that's what most end-users would want. They just want to tweak some of the defaults.. A common use-case is just overriding a few defaults when creating a new instance. I don't like how you now need to specify a nested object to set a few options.\nI think got.fork() should be optimized for the common-case and only allow overriding options, not handler/methods. If users need more advanced control, they can use got.create() and pass in the exposed got.defaults.\nSo got.fork():\njs\nconst client = got.fork({headers: {'x-foo': 'bar'});\nAlso, is fork the best word for this? Some alternatives would be extend() or defaults(). Not saying it's not. Just putting it out there.. Can you add a small tip to the Tips section (https://github.com/sindresorhus/got#tips) on how to use the endpoint option with got.extend() to quickly get an endpoint specific Got instance? I think that's a common need, so would be good to have a clear example for that specific thing.. @brandon93s Good point. Let's move it out into a separate file like you've described.. @szmarczak I don't think @brandon93s was suggesting we rename it, but rather just pointing out the benefit of moving got.create() out of the readme.. This is perfect now. Amazing work @szmarczak \ud83d\ude4c\n\n. Great!. I usually prefer not to as AppVeyor can be unreliable and annoying, but since there has been a couple of Windows-specific test failures, sure, I'll do it.. Looks good. And I've added AppVeyor in master.. This needs more tests as there are quite a few moving pieces here.\n\nNeeds a test to see what happens when you specify an empty array for methods. Same with statusCodes.\nSome more variations of the options.. This is looking very good. I'm excited to see this land.. Don't forget that 413 should only be retried if the Retry-After header is valid, while 429 and 503 can be retried even without the Retry-After header, but should adhere to it if it exists. I would also like to see a test for this; One that proves 413 is not retried without a Retry-After header and one that proves 429 and 503 are retried even without a Retry-After header).. This is super awesome! Huge \ud83d\ude4c to @szmarczak for implementing this very complicated logic.. @brandon93s Please do give this a look and comment here if you see anything I missed ;). \ud83d\udc4d . I'm also struggling to imagine a use-case for this. What actual (not just example) problem does this solve? I'm not saying it's not a good feature, I just don't see when I would use it.. @szmarczak You got a comment on your gist: https://gist.github.com/szmarczak/86217216ad2fbc0c8a3e833e5f290460#gistcomment-2642454 (Mentioning since there are no notifications for gists).. @brandon93s Can you do your gist comment here instead? As it's easier to follow the discussion here.. There might be use-cases for this, but I'm a little bit reluctant as this locks us into supporting the ability to arbitrarily merge instances. There might be features we want to add in the future that makes this difficult. Like @brandon93s said, it also adds some maintenance overhead. And we have yet to figure out a way to support plugins, which might or might not overlap or conflict with this.\n\nSo in short, I just feel like this is rushing into supporting a huge API surface without enough time and exploration to see what problems it solves and the alternatives.. > Imagine there are got plugins. You can limit download & upload, use GitHub API, send random User Agent and many more.\nWe should consider what other ways there are to solve these problems.. This is looking good now :). @ikokostya You're the first one, from what I can remember, to request this. I have also never seen any API ever require you to send a top-level JSON serialized string.\nThe current validation is helpful in case users don't realize (or forget) we do the JSON stringifying for them. {json: true, body: JSON.stringify({foo: true})} would be double stringified and could cause hard to debug errors.\nEven if your solution is more techincally correct, I prefer to be pragmatic and optimize for the common-case instead.. Makes sense to have tests for this. We might want to make changes to that file in the future.. Good stuff, @alextes \ud83d\udc4c. @szmarczak Events are meant as one-way notifications. Hooks let us transform.. This looks great now. Thank you so much for working on this, @jstewmon :). This needs tests.. Wouldn't it be better to fix it at the source: https://github.com/lukechilds/cacheable-request/issues/42 ?. > if cacheable-request wants to maintain the same contract as http.request\nYes, the point of it is to be a drop-in replacement of http.request, so it should maintain the same contract.\n\nthen we can fix the issue there by formatting the key according to the options understood by http.request.\n\n\ud83d\udc4d . @jstewmon cacheable-request@4 is out. Can you bump the version, revert the normalize-arguments.js changes, but keep the test change?. I've opened an issue on ESLint so we can enforce this in the future: https://github.com/eslint/eslint/issues/10605. You're reading the readme of master. This is not released yet. You want the readme for the latest version: https://github.com/sindresorhus/got/tree/v8.3.2. When it's done. Hopefully by next weekend. https://github.com/sindresorhus/got/milestone/6 :). Got 9 is out now: https://github.com/sindresorhus/got/releases/tag/v9.0.0 \u2728. // @jstewmon . Closing in favor of #534. Thanks for the suggestion, but this is expected knowledge and how most projects on GitHub operate.. Makes sense to me, but then assignOptions needs to be documented properly in the API docs: https://github.com/sindresorhus/got#api. Other than the https://github.com/sindresorhus/got/pull/532#discussion_r204534554 nitpick, this looks good to me :). Duplicate of #522. @jstewmon This is great! Thanks for doing such a thorough investigating into timeouts. \ud83d\ude4c. Are we absolutely sure ESOCKETTIMEDOUT can never be thrown?. I've decided. Let's go with ignoring undefined and rename the method to mergeOptions.\nI think we should also deep clone the array, not because it solves all the problems, but it makes it less likely that the user will encounter a problem with references, and I think that is worth the neglible performance we save by not doing it. This is also how lodash.merge works and what users would expect:\n\nArray and plain object properties are merged recursively. Other objects and value types are overridden by assignment. Source objects are applied from left to right. - lodahs.merge docs\n\nWe can pretty much reuse the above description for our mergeOptions docs.. > I wasn't sure whether you meant to just make a copy of the source array or merge the array into the target's property value\nI meant, make a copy, yes.. Thanks for the PR, @jstewmon :). > hooks are called by reference,\nNot sure I see the point of this. Example use-case? I generally prefer not exposing this unless absolutely necessary.\n\nmerge() is a different file now,\n\nCan you leave it where it is for now so we get a diff?\n\n[] instead of new Array in merge().\n\n\ud83d\udc4d . Your example doesn't really convince me otherwise. That problem can be solved without using this too. I think it should be up to users to bind methods if they want to use this.. #539 made these changes moot.. > because I tried passing a Buffer as body and this doesn't even get called.\nYou have to pass a stream. The buffer testing is testing a property on the stream.. @szmarczak Hmm, then maybe it returns here: https://github.com/sindresorhus/got/blob/6ba9e68c7f496a69641a8aac51be0781f1ae0eac/source/get-body-size.js#L10 Add a debugger statement to each if and figure out where it returns.. > Yeah, you're right, checked it. So, is it needed? IMO we can get rid of that.\nSee: https://github.com/sindresorhus/got/blob/4d92eb6bef37637c0d85986faae314e17e9cd9bc/source/request-as-event-emitter.js#L163-L166\nThis should be done in a separate PR though. > We also need tests for electron support.\nNah, don't care. If it prevents us from getting 100% test coverage, we can just mock it.\n\nNote: Missing test for #490 and for:\n\nDo you intend to do that in this PR? Asking so I know whether this is ready to merge or not.. Something is failing here: https://ci.appveyor.com/project/sindresorhus/got/build/1.0.245/job/nunr63w0rttwjv0t. Yup, AppVeyor is annoying. We had so many problems with it over at https://github.com/avajs/ava too.... \ud83d\udc4d I'm extra happy that doing this actually caught a couple of potential bugs.. Can you add a test?. And it's inconsistent to uppercase these while others are lowercased: https://github.com/sindresorhus/got/blob/3fd590a781b04f4ab62522693682966c71dc75f4/source/index.js#L18-L23. Please read the release notes, version 9 requires Node.js 8, which means support for async/await. You either need to transpile or use version 8 if you target an environment without async/await.. That is a non-goal for this project, but it should in theory still work in the browser if you run it through Browserify or Webpack (as they bundle shims for Node.js APIs). I remember Got v7 working in the browser after being run through Browserify.. Related issue: https://github.com/sindresorhus/got/issues/288#issuecomment-302970189. @styfle Done: https://github.com/sindresorhus/got/pull/556. @pgilad That would be really cool indeed, but could probably only handle the simplest of cases.. @DRSDavidSoft Yeah, I agree, would be nice with a comprehensive beginner guide. I would guess most beginners don't just need an intro to Got, but also Node.js and HTTP in general.. @DRSDavidSoft Anything specific?. Would be useful. I think @jstewmon wanted something like this too.. Yeah, happy to have support for Flow if you're willing to do the work to add it.. I have a style guide for TypeScript now, which should also mostly apply to Flow: https://github.com/sindresorhus/typescript-definition-style-guide. Just to clarify, by \"have support for Flow\", I mean adding a Flow definition file, not to rewrite Got in Flow.. Yes, but if I were to rewrite Got, I would do it in TypeScript, not Flow, as that's what I'm familiar with and prefer.. Closing in favor of #700.. I agree this would be useful. I think roarr is a bit heavyweight to include in Got, but how about we just expose a metadata event and people can log using whatever they want? We could also log by default using util.debuglog().. > When you have an application which depends on modules that use got, there is no way to enable got logging without digging through node_modules/ and patching the code.\nEnvironment variable? Alternatively or in addition to, we could have a singleton emitter, that logs for all instances, so you could just require('got').on('metadata', () => {}) and get logs even when got is used in sub-dependencies.. > Not if you go with the custom event approach. Environment variables can only toggle logging, not configure the hooks.\nI was responding to the comment about the problem of not being able to toggle it.\n\nUnfortunately, you cannot do that either, because the application will loose access to the singleton if modules depend on incompatible Got versions.\n\nGot could use global internally to orchestrate the singleton listeners, like roarr, and then just expose that global. We should use a Symbol so it's only accessible by a Got instance.. > If you use a Symbol, then you are back to square one \u2013 Symbols are not going to be shared between incompatible Got versions. Of course, you could create a dedicated package just for the symbol... thats a bit of stretch.\nRight, good point.. Relevant Node.js thread: https://github.com/nodejs/node/issues/21888 Please comment your use-cases and needs there.. I think we should just recommend https://github.com/np-maintain/global-tunnel for that. Proxy support is really hard to get right and not something I'm interested in spending time on and I don't want to bloat Got with dependencies to support it.. @gajus What do you think about recommending https://github.com/np-maintain/global-tunnel ? With that module it would work for any request library in the dependency-tree, not just Got.. global-tunnel is not for package authors. You use it in your app to enable proxy support for everything that uses http.request internally, which is most request libs.\n\n\nGot could check for global.GOT_AGENT variable and default to it if it is configured. This way I could quickly override default agent for all dependencies that use Got.\n\nThis sounds fragile. What if a Got wrapper expects some special functionality from an agent and stops working when it gets a different agent?. @jstewmon I don't really see why we need to expose such a big API surface. What's the benefit of this over just doing what request does and record the timing internally and expose a timings object on the response? Do you have any other use-cases in mind for this that I'm not seeing?. I guess this would be more appropriate for solving #559, but even then, I would prefer something simpler, or something simpler in addition to this. People that need to do low-level advanced stuff can already directly listen to the request/response.. With this abstraction, users also lose ability to unsubscribe when they're done with an event.. If we were to expose something like this, I would prefer just a single firehose event that includes a type attribute to indicate the type of event of the message.. > users would be saved from creating memory leaks if they're using keepAlive and subscribing to socket events.\n\nI also thought it was really convenient to be able to subscribe to an arbitrary event without having to wire up all the intermediate listeners.\n\nThose are some good points. I'm warming up to the idea.\nDid you consider any other APIs for this? Not saying we should do it differently, just wondering what you considered.. >> With this abstraction, users also lose ability to unsubscribe when they're done with an event.\n\nI don't know what you mean by this.\n\nFor example, a user wants to listen to response.data events, but only the first 10 events. I don't see any way to unsubscribe to the event after 10 events. Of course there could just be an if-statement that returns early after 10 events, but that means it's doing work when it's not needed.. > That's certainly possible, but it will less efficient because we'll have to subscribe to everything and call the user's handler for every event.\nI don't imagine anyone would use this in production, but could be useful to get a complete picture of what's happening. You could do got.on('firehose', console.log);. Could be an addition to this though.. That is a bug. I incorrectly assumed the base parameter to new URL() accepted any URL, but seems it just silently throws away the path part...\njs\n(new URL('/foo', 'https://sindresorhus/unicorn')).toString();\n//=> 'https://sindresorhus/foo'\nWe should also update the baseUrl docs to be explicit about supporting an URL even with a path.. In my defence, the MDN docs are not clear at all about this:\n\nbase - A USVString representing the base URL to use in case url is a relative URL. If not specified, it defaults to ''.  - https://developer.mozilla.org/en-US/docs/Web/API/URL/URL. @marswong I think you misunderstood. It's indeed a bug in Got. We need to handle the path part, yes.. @szmarczak Ah, I totally missed that. I think the current behavior is ok, but we should make it much clearer in the docs.. @szmarczak Is there a technical reason the baseUrl has to end in an / other than because that's how new URL() works? If not, I think we should not normalize and add a / to the baseUrl if it doesn't exist. The less unexpected behavior we have to document, the better.. > It's an expected behaviour, but it may be confusing. I'd leave that as it is.\n\nWhy is it an expected behavior? It's not like <a> works. You can have https://sindresorhus/foo (without trailing /) and still have relative links.. > Why it isn't?\nI commented that above. Because it's not like how <a> works, and it seems like the expected behavior is split, so why not handle both.\n\nThis is the current behavior (which is fine). \n\nI'm confused. We have already established it is not the current behavior. (https://github.com/sindresorhus/got/issues/562#issuecomment-412812259)\n\nSo, the absolute URL is https://sindresorhus/. Visiting bar won't lead to https://sindresorhus/foo/bar but https://sindresorhus/bar.\n\nThis example is invalid. I can't really reply until I know what you were trying to argue.\n\nAnyway, like @beac0n has mentioned, I'd just update the docs.\n\nWhy not just append the / then? I don't see any downside in doing so, and you haven't provided any arguments why we shouldn't do it either.. >> redirects are handled with a recursive call to get, so deferred\nrecursion with setImmediate\n\nSee my comment above.\n\nI've reverted this: https://github.com/sindresorhus/got/pull/564/commits/731c470de8cc246b0043400304e33d45c7706027\n\n\ntest server enhancement:\n\nCould this be placed in a separate PR please?\n\nI agree this should have been a separate change, but we decided we can live with it as we want to get out a new minor release today, and it's just nitpick.. Thanks for fixing this, @jstewmon \ud83d\ude4c. @lorenzofox3 This causes a test failure.. Makes sense. I don't think we want to directly depend on touch-cookie as it's pretty big, but we could add a cookie option that expects a new tough.CookieJar() instance? Or just {cookie: require('touch-cookie')}, not sure which is better.. The types are from: https://github.com/DefinitelyTyped/DefinitelyTyped Not by us. You would have to open an issue over there.. @rarkins What kind of solution are you looking for then?. @szmarczak Nah. Most projects on GitHub use master as the default branch and development branch. For the latest version, users should visit the npm package or the readme in the relevant Git tag. This is expected knowledge.. In general, the performance should be the same since the underlying stack is the same. They're all using the core http.request method underneath. The bottleneck is not the implementation, but rather your network connection. Got is the only one to support caching though, so if you enable the cache option, Got will be faster in general.. You cannot benchmark using nock. The results are meaningless. If you want to do an actual benchmark, you need to run a local server, but even then, it's hard to get reliable results.. \ud83d\udc4c\u2728. The docs needs to be updated too.. > Rewrite the baseUrl option\nWould be more descriptive to title the PR:\n\nNormalize the URL in the baseUrl option. Can you comment on why it was necessary to split it out into a preNormalize step?. Just a comment on this thread is fine.. Looking great!\n\n\n. \u00af\u2060\\_(\u30c4)_/\u2060\u00af There are always people publishing forked packages without any explanation and just littering npm. You could report it to npm to have them take it down.. https://github.com/sindresorhus/got/pull/583#discussion_r212383890. I think we should be explicit and accept the request function, not a library with a request function.. @pietermees Can you include an example of the URL you're trying to use? Doesn't have to be the exact same URL as long as it uses the same formatting.. @pietermees I agree. This is a bug. We should not touch the query in the url argument unless you specify the query option.. But it\u2019s not an invalid URL. new URL parses it fine.. It requires support for async functions, which means Node.js 8 or higher.. No, the agentkeepalive example doesn't have anything to do with proxies. I've fixed this now.. Ok, great. We should at least implement the same tests as https://github.com/request/request/pull/2904/files#diff-5db92d37ce5156ccbf7499555bdd0bf9R183 so we don't accidentally regress in the future.. Awesome! Can you add some docs?. > Sure, but please check out #592 first :)\nDone. Can you explain why this is a more proper fix?. I think each migration should be a separate file.. Can you link to this at the top of the readme with a link text like:\n\nMoving from Request?. Looking good :)\n\nStill some minor things left, but these things can be done in a follow-up PR:\n\n[ ] https://github.com/sindresorhus/got/pull/595#discussion_r230579249\n[ ] https://github.com/sindresorhus/got/pull/595#discussion_r230174879\n[ ] https://github.com/sindresorhus/got/pull/595#discussion_r238534446. @gajus Are you happy with this?. \ud83d\udcaf \ud83d\udc4d . > Secondly, why would cache even be used when retrying request?\n\nIf this is correct, it sounds like a valid bug. It should not use cache for retrying.. There's no 502 status code here:\n\nhttps://github.com/kornelski/http-cache-semantics/blob/d0bf1baf301dc6044a839ac309685e9385fb6c3b/index.js#L3\n\n^ That's the lib cacheable-request uses to determine cacheability.. Can you fix the merge conflict?. Failing test docs: https://github.com/avajs/ava#failing-tests. @szmarczak I guess it could be useful, but then we need to clearly document that the response may be empty depending on when the timeout occurred.. @szmarczak In what form? Can you provide an example of how it would look like using it?. Can you add a test?. @brandon93s I strongly disagree. We should not add complicated logic just to work around faulty servers. HTTP1 specifies headers as case-insensitive and HTTP2 enforces lowercase headers, so the most future-proof way forward is to lowercase headers. Got has always lowercased headers and it has not been a problem. It was only accidentally left out recently.. @conechan Ping :). diff\n- const list = await custom('/transferrecipient');\n+ const list = await custom.post('/transferrecipient');. FYI, you don't need to set \"Content-Type\": \"application/json\",. The {json: true} option does that for you.. Latter. Makes sense.\nThe docs needs to be updated too: https://github.com/sindresorhus/got#gothttperror. We'll do a new version when we're ready. We have a few more changes to land before that. You can always just do npm i sindresorhus/got to get master branch for now until the release is out.. ```js\nclass FooError extends Error {\n    constructor() {\n        super();\n        this.unicorn = 'not logged';\n    }\n}\nconsole.log(new FooError());\n// Error\n//  at :8:13\n``. Got doesn't support proxies out of the box, so this is more likely a problem with https://github.com/kevva/download which thepngquant-bin` package depends on.. Those are not the same packages. Please include a description in the PR of why this change is needed. You also included an unnecessary newline.. Just an oversight I think.. A few extra object allocations should be negligible compared to the network request itself. I'm really curious why you're calling Got so many times per minute.. That being said, I don't mind a PR to improve it, as long as it doesn't change any observable behavior.. > I think an RxJS-based HTTP client for Node would be an interesting experiment.\nRxJS comes with its own problems.. @szmarczak I think you're confused about what this PR is about. Yes, we disallow got({url: '\u2026'}), but we do document support for got({host: '\u2026', headers: {\u2026}}). The fact that this is no longer supported is a regression.\n\nThe URL to request, as a string, a https.request options object, or a WHATWG URL.\n\nThe https.request options-object can contain a header field.. This is an awesome cleanup!. > Destroying got.stream(...) cancels the request\n\nFixed unhandled ParseErrors (metioned by @aghuddleston in #631)\nFixed unhandled TimeoutErrors (metioned by @timdp in #631)\n\nThese needs accompanying tests.. Looks good. Nice work on the refactor. \ud83d\ude4c. @timdp Not really interested in adding an extra dependency just for this. And if we were, would probably be better to use https://github.com/sindresorhus/quick-lru, as it can use anything as keys, including objects.. Yes, that's as designed, and also in the docs:\n\nQuery string object that will be added to the request URL. This will override the query string in url.\n\nI don't think it's common enough need to add an appendQuery option. You can easily handle that yourself with new URL().. > Stream API: node-fetch has res.body.pipe.\nThat's just the built-in Node.js http.request response body stream, right? Which is not that useful for most cases, as you'll lose the benefit of node-fetch, compatibility with Fetch. Got has a dedicated .stream() method that returns a stream that also proxies headers and other things. For node-fetch, the equivalent would be https://github.com/bitinn/node-fetch/issues/387.\n\nCustom defaults: node-fetch does merge Headers and Request options correctly per spec.\n\nThat's just a small part of it. The other libs that support 'custom defaults' supports it for all options.. >  res.body.pipe isn't a standard API in Fetch spec but .pipe is exactly what people are looking for on nodejs.\nBut people use node-fetch to have a familiar API or most often identical API on the server-side as in the browser and this breaks that promise.\n\nI just think it's unfair to categorize got as having stream api while node-fetch is categorized as doesn't simply because of spec compliance issue.\n\nIt would also be unfair to got and request if it was categorized as such though.\n\nnode-fetch is isomorphic, but only supports a \"stream\" API for Node.js.\nThe stream API is not a first-class citizen. It's just exposing the Node.js response stream. It doesn't have nice conveniences like forwarding headers, redirect handling, etc.\n\nWe can add a \u2716 [1] and add a note that node-fetch somewhat supports streams.. There are multiple common ways to represent arrays in query strings. I don't think Got should be opinionated about which one to use.\nI suggest we update the docs to say that it should be an object with key/value as string, and then show an example of using a custom URLSearchParams instance:\njs\nconst res = await got('https://site.com', {\n    query: new URLSearchParams([['some', 'a'],['some', 'b']])\n});\nAnd in the next major version of Got, we can validate the input and throw a user-friendly error if the object has non-string values.\nThoughts?. > @sindresorhus Maybe we should add querystring option (function)?\nFor what purpose? Show an example of usage.. @szmarczak No, I mean, show an example of what your proposed \"querystring option (function)\" would look like.. @szmarczak That just feels like needless bloat. We already support both URLSearchParams and string, both of which can be used to achieve it:\njs\nconst res = await got('https://site.com', {\n    query: new URLSearchParams([['some', 'a'],['some', 'b']])\n});\nor\njs\nconst res = await got('https://site.com', {\n    query: require('query-string').stringify({some: ['a', 'b']})\n});\nAnd I would never introduce two similarly named options with different purpose. That's just bad API design.. > querystring: require('query-string/qs/querystring'),\nThis wouldn't always work anyway as users wouldn't be able to specify any options for those packages.. > Yes, but none of them are some=a,b, aren't they?\nI have seen that in the wild, but not as common. I even had a PR for it that was never merged: https://github.com/sindresorhus/query-string/pull/150/files\n\nIt's just confusing that the \"query as an object\" leads to an invalid query string eventually.\n\nI totally agree.. Yup. I\u2019ll do a PR later.. @szmarczak What do you think about renaming the query option to searchParams to align with Ky and WHATWG URL terms. Would be more familiar for people coming from the browser.. @szmarczak Would it be hard to support both query and searchParams at the same time in v9? That would be optimal as we could then change the docs to searchParams so new users use the correct option naming and we could then slowly phase it out. We could throw a deprecation error for it in v10 and then remove it completely in v11.. Yes, we would like to rewrite in TS. Just need the time or someone interested in doing the work.. > replace uploadProgress and downloadProgress with hooks,\nWhy? I don't think this would benefit enough from hooks as you're actually not modifying anything in them.\n\ndeprecate redirect event (use beforeRedirect hook instead),\n\nWhy? And are you sure beforeRedirect handles all the use-cases of the redirect event?\n\nmake promise.on('error', cb) work?\n\nCan you elaborate on how this is different from promise.catch() and what use-cases it solves?. I have been thinking about whether we should deprecate the ability to not use a scheme in the URL. It only saves a few characters, but it creates an ambiguity for people that don't know whether Got defaults to HTTPS or HTTP. It also creates an incompatibility with browser request libraries, which cannot support this as it's then considered a relative path.\ndiff\n- got('sindresorhus.com');\n+ got('https://sindresorhus.com');\nIt seemed like a nice shortcut when Got was just a toy, but now that's it's being used in serious deployments, we should prioritize strictness and clarity.\n@szmarczak Thoughts?. > Generic error handler. That's the only one I've come up with. It's just a simple wrapper:\nI still don't fully understand its purpose. What do you mean by \"generic error handler\"? How is that different from .catch()?. > Whenever you use promise or stream you want to use the same error handler (eg. you want to call specific logger). But you can still achieve that using handlers...\nIsn't that exactly what the beforeError hook is for?. @szmarczak Your mention use-case was logging though, which could be done in beforeError, but yes, actually handling the error cannot. I'm still dubious about the use-case. Have you actually encountered this need in real code?. @szmarczak Regarding https://github.com/sindresorhus/ky/pull/82/files#r248375929, I didn't realize Got had this behavior and I honestly don't like it. I think it's too magical. I think we should remove this behavior in v10. If you pass body when using GET, it should throw a helpful error instead. // @sholladay. @szmarczak Thoughts on https://github.com/sindresorhus/got/issues/639#issuecomment-453808392 ?. Another item we should do: Use undefined instead of null whenever possible.. This is not what I proposed in https://github.com/sindresorhus/got/issues/638#issuecomment-432597514.. No, my point in https://github.com/sindresorhus/got/issues/638#issuecomment-432597514, is that we should only accept an object with string values, not an object with array values nor a top-level array. I would prefer to keep it simple. If people need things like a top-level array, it's much clearer to just wrap it in new URLSearchParams(). We document this now, and we can enforce it in the next major release.. > We could avoid that, if default options would be exposed publicly (is there an option to do that?)\nYou can access the defaults on got.defaults or instance.defaults if you used got.create/extend. I realize now that have haven't properly documented this.. > Thing is that for our purposes, we construct the request handler on top of request-as-event-emitter\nWould you be able to elaborate on why you need to do that? Could you elaborate on your use-case? Maybe there's something we can improve in Got to make your use-case easier to achieve.. > I discovered also few other breaking (on that level) changes between v9.2 and v9.3. So for now, after we patched that, we locked ourselves to 9.3.x\nIn general, I would always recommend locking down dependencies if you use internal stuff. There's no stability promise for that.\n\nResolve body on basis of content type (e.g. we automatically resolve to JSON if there' response type is application/json (no need for options.json: true).\n\nWe intentionally don't support that. It's better to be explicit. The request client should be the one deciding what format it expects. This is also how WHATWG Fetch works (await request.json()).\n\nit'll be good to achieve first two use cases without a need of introduction of some decorator that should be required instead - so that aside we can hook into general got configuration, and then have all requests (made via got required directly) automatically affected\n\nSo you want a singleton. How about creating the custom Got instance in a file called got.js with your customizations and you require that one everywhere instead of got? That's how I usually handle it.. @timdp Can you try this out?. @szmarczak Can you include a description in the PR body?. @szmarczak We already let people configure which HTTP status codes to retry on, maybe we should also allow people to specify which network errors codes to retry on?. Same as https://github.com/sindresorhus/ky/issues/60. https://github.com/sindresorhus/got/issues/656#issuecomment-437216960. Awesome to see this supported in node-fetch \ud83c\udf89. Node.js has ability to get the TTL of DNS lookups: https://github.com/nodejs/node/pull/9296 So we could potentially implement a simple automatic cache based on that.\nSome prior art (which all seems to require setting TTL manually):\n\nhttps://github.com/yahoo/dnscache\nhttps://github.com/devswede/dns-cache\nhttps://github.com/eduardbcom/lookup-dns-cache\nhttp://blog.dmcquay.com/optimization/2017/06/14/nodejs-connection-pooling-and-dns-caching.html. options.dnsCache. It should be request, not req.. @Rowno https://github.com/sindresorhus/got/pull/622#issuecomment-472773011. @Rowno Next time, open a new issue instead of creating two separate discussions in old PRs about the same thing.. If you want to support older browsers, you need to transpire it with Babel.. Can you fix the merge conflict?. If we go for this, we could potentially remove the encoding option since got(...) and got(...).buffer() would do the same.. @GHNewbiee The time you wasted on nonsense in this issue, you could instead have used to contribute to the comparison table. Try to remember that next time. \ud83d\udc4c. > Could it be that the host in question hasn't properly configured their SSL cert?\n\nYes, it means the certificate is somehow invalid. You can set the {rejectUnauthorized: false} option to ignore such errors, but I would not recommend that.. Sounds related to https://github.com/sindresorhus/got/issues/388#issuecomment-346275633.. Tip: Use the form option instead of concatenating the query strings.\nhttps://github.com/sindresorhus/got#form. It's weird that the colon is not bold too.. Run Node.js with $ node --trace-warnings to get a stack trace of where the event emitter leak warning is coming from.. Sorry, no. You can decode the URL yourself before passing it to Got.. > I'm still not sure if promise.json() should return a Response object or just the JSON...\nYeah. I'm conflicted too. I would really like it to be the same as ky, which does return the JSON directly, but then there's no shortcut to get the body as JSON, but also the response body. Well, there is, you could use the responseType option if you also need the response and not just the body.. > the json option was removed. The body will be JSON.parsed automatically when it's an object/array.\nWhat's the argument for just handling automatically in the body option instead of what ky does, which is to have a json option that the user gives an object/array instead of the body option. I'm not sure which solution is the best, but I would like got and ky to agree on this either way. We should look at how other request libraries handles this (even not just in the Node.js ecosystem).. // @sholladay Since this might result in changes to ky too.. So this is decided:\n\nresponseType: 'json' returns the response like normal\n.json(), .text() and .buffer() returns the body directly (no response).\n    We should document that users need to use responseType instead if they want the full response. These methods are just shortcuts.\n\nI'm still undecided about json vs body. I'll need a few more days to think about it.. > I'm still undecided about json vs body. I'll need a few more days to think about it.\nI made a poll: https://twitter.com/sindresorhus/status/1085773733384470528. > Fixes sindresorhus/gh-got:index.js@master\nI wouldn't say it fixes that issue. This just works around it. We still need to properly fix handler.. Does the hook catch absolutely all errors? If not, it should be documented what it doesn't catch. For example, I don't think it currently catches input validation errors (Neither should it IMHO).. Wouldn't beforeError be a more correct name for this?. Can you fix the merge conflict?. Can you copy-paste all the tests you've changed here from master (with the query naming) into a new file called query.js so we can ensure we don't break anything related to the query option in the future? Then we can just delete the query.js file before Got v11. You should still keep the naming changes you've done here though.. There are still some mentions of query. Try searching all the files for the string query.. Can you fix the merge conflict?. Still mentions of query:\n``\n\u276f rgs query\nmigration-guides.md\n59:-qs\u2192 [query](https://github.com/sindresorhus/got#query)\n70:The [queryoption](https://github.com/sindresorhus/got#query) is always serialized using [URLSearchParams](https://developer.mozilla.org/en-US/docs/Web/API/URLSearchParams) unless it's astring`.\ntest/arguments.js\n227:test('throws if the query key is invalid', async t => {\n229:        query: {\n235:test('throws if the query value is invalid', async t => {\n237:        query: {\ntest/redirects.js\n93: http.on('/relativeQuery?bang', (request, response) => {\n158:test('query in options are not breaking redirects', async t => {\n159:    t.is((await got(${http.url}/relativeQuery, {searchParams: 'bang'})).body, 'reached');\nsource/utils/validate-search-params.js\n4:module.exports = query => {\n7:          throw new TypeError(The query ${type} '${value}' must be a string, number, boolean or null);\n11: for (const [key, value] of Object.entries(query)) {\n```\n. And Travis is failing.. It's mainly about familiarity and popularity. Popularity means it's easier to attract potential contributors. But I've also noticed that TS has better error messages, and the fact that TS is written in TS (meaning JS) is definitely a bonus. Very few knows OCaml.. > Do you have an example of a specific error that TS produces that is more developer friendly than what Flow would produce?\nIt's a common sentiment (there are multiple popular blog posts mentioning this, but can't find them right now), not just my experience. I have dabbled in Flow too and experienced hard to understand errors.. @ferdaber Yes, that would be helpful. See https://github.com/sindresorhus/is for how to do the TS setup. Should use https://github.com/sindresorhus/tsconfig and https://github.com/xojs/tslint-xo.. @medikoo The codebase is already quite complex. Adding types will let us be more confident about doing changes. Another big benefit is that we don't have to maintain a separate TS type definition file, which could easily get out of sync.. > Can't this be solved simply with JSDoc? I haven't explored that deeply, but I think TS can read types of out it as well\nNo, JSDoc helps to some degree, but TS is much more powerful.\nThis is also not really the place to discuss the merits of TS. We have already decided to use it. I would recommend asking in my AMA instead.. > Do you remember any specific issues that wouldn't happen if it'll be TS already?\nNot specifically, but I remember some instances where we shipped bugs because of unpredicted conditions that would have been caught with stronger types. It's not just about catching problems either, but it makes it easier for us to work on Got. We now get auto-completion for everything and can do large refactors with ease.\n\nThis move also makes more difficult to contribute for JS developers not interested or not familiar with TS. It narrows the audience.\n\nI'm ok with that. By requiring TS I think we'll get higher quality contributions too, as it sets a higher minimum JS/TS knowledge level. In reality though, this is irrelevant as 99.9% of the commit in Got are by the maintainers.. The TS setup is done, so now it's possible to convert to TS file-by-file. If you want to contribute, pick one or more files you think you can manage and have fun. Just rename the .js file to .ts and try to build ($ npm run build). Make sure you read https://github.com/sindresorhus/typescript-definition-style-guide for the style we use and document all public interfaces (you can steal text from the readme) (bonus points for documenting private ones too). Also try not to do files that are touched a lot in the open PRs, to avoid conflicts.\nNote: To import a TS file into a JS file, you need to use require('foo').default instead of require('foo').. @michaeldera Pick any .js file you think you can handle and that's not already being worked on in an open PR ;)\nFor example: https://github.com/sindresorhus/got/blob/master/source/create.js. We are still looking for help getting this done. \ud83d\ude4c\nLeft to do:\n\n[x] source/as-promise.js\n[ ] source/normalize-arguments.js\n[ ] source/request-as-event-emitter.js\n[ ] source/index.js (the above files should be done first)\n\nWhen these are done, we'll need help converting the tests to TypeScript.\n. > To work around the difficulty of writing tests to check the robustness of APIs against any arbitrary types of values thrown at them, one ends up doing a lot of any cast gymnastics.\nI've been doing that in other TS-written modules. It's not a big problem to write a few as any.. @tobenna \ud83d\udc4d Great. Thank you, @ferdaber \ud83d\ude4c. I've done a quick review and it looks fine. I'm still not sure about the resolveBodyOnly option, but we'll add it for now. We can always change/remove it before release. I'm gonna merge now to unblock other work, but will do a more in-depth review tomorrow.. Looks good now. Thank you, @scttcper \ud83d\ude4c. Can you explain your thinking behind this change? It's quite a big breaking change, so we should not do it lightly. Also not sure I'm a fan of overloading got.extend() with so much functionality.. Can you show how this will make it easier to create reusable plugins for Got?. > imports of decompress-response and mimic-respons, Should I create d.ts files, install @types or leave it as require?\nPreferably we should add type definitions in those packages directly, but for now, if you can find them on @types, use those.\n\nI don't know all properties of options and maybe the interface should be in some shared space?\n\nI looks like we just pass it the whole Got options-object, which is not TS defined yet, so you can just leave it as is for now, but add a TODO comment above it about using the Got options-object types.. There are also some lint errors: https://travis-ci.org/sindresorhus/got/jobs/482317993\nJust run npx xo --fix locally to fix most of them.. This is looking great, @ltciro. Thanks for the awesome contribution \ud83d\ude4c. There are also some lint errors: https://travis-ci.org/sindresorhus/got/jobs/482315362\nJust run npx xo --fix locally to fix them.. Nice work! Thanks for the contribution :). Can you explain your changes?. Can you also update the got.create() docs showing how the async handlers will be used?. > What type I should use in error parameter?\nError. > Do you refer to the Error interface? because in the d.ts it does not have those properties.\ne.g body - statusCode etc...\nThis is about the input error. Those errors doesn't have any custom properties.. Looks good. Thank you @ricardorojass and @fnky \ud83d\ude4c. @fnky => https://github.com/sindresorhus/got/pull/712#discussion_r253043722. From the top of the readme:\n\nThis readme reflects the next major version that is currently in development. You probably want the v9 readme.. Thank you, @fnky! This is excellent \ud83d\ude4c. Don't forget to do https://github.com/sindresorhus/got/pull/720#discussion_r253345815.. Nice work, @Magellol \ud83d\ude4c. Can you do the first commit as just renaming .js to .ts using git mv? That way GitHub can show an actual diff between the files. Right now it's impossible to review the differences.. There's no need to close or open a new PR. You can just push additional commits to this PR ;). > Please forgive my ignorance... the first commit, where I am supposed to do git mv so it is possible to see the diff, that is the part I cannot get around adding that commit... tried rebasing but not quite getting that bit right\n\nCopy-paste your changes somewhere as a backup, create a new branch from master, rename the .js file to .ts, commit this change, then copy-paste back your changes to the file, now commit these changes as a new commit, then force push to this remote PR branch.. No need to create a new PR. Force push is your friend.. Shouldn't the hook be called beforePaginate for consistency? And I think the the signature should be (options, isFirstPage) => {}, unless you have other use-cases for the previous response? Should it have some built-in automatic behavior for the Link header?. > The response could give a link to the next page.\nIt should at least be called previousResponse, not response.\n\nI have no idea. Maybe it should be an option (paginate)... And the hook should be called beforePaginate. I think that way would be better.\n\nYeah, maybe drop the hook aspect from it altogether? I wonder if we could make it got(\u2026, {paginate: 'link'}) for automatic Link-header support and got(\u2026, {paginate: (options, previousResponse) => {}}) for custom handling.. Some other use-cases:\n\nI want the first 4 pages of a request. Would be nice if we could make got() work normally in that case and just gather up the first 4 pages for us instead of requiring the verbose async iterator coe.\nI want to get new pages until I say I'm done. For example, I want to get pages, filter results, and end it when I have enough filtered items. Would be nice if this too was possible without the verbose async iterator syntax.. I would also include a currentPage argument in the paginate method with the page number.. > The number of returned entries per page is usually an endpoint restriction and users ultimately care about total entries, not total pages.\n\n\ud83d\udc4d This is my experience too. I take back wanting to specify pages. What I actually want is to be able to specify item count.. > I'm not sure if it should be implemented. You can achieve the same in a few lines of code:\nSure, but you can achieve pagination in Got today too, it's just verbose. The point of this issue is figuring out the most common use-case, and making those super easy, while still giving user's the power to do custom logic.. > > 1. I want to get new pages until I say I'm done. For example, I want to get pages, filter results, and end it when I have enough filtered items. Would be nice if this too was possible without the verbose async iterator syntax.\n\nNot possible. The Got logic is async.\n\nI don't understand this statement. Got being async is exactly what makes this possible. Got would handle getting the required pages by using got.paginate internally and then gather up the results for me, so I only had to call:\njs\ngot(\u2026, {\n    pagination: {\n        itemCount: 100,\n        filter: item => item.isUnicorn\n    }\n});\nIn the above example, Got would fetch items and paginate until it had gathered 100 items with item.isUnicorn === true.. > What do you mean specifically?\nInstead of:\njs\nconst results = [];\nfor await (const response of got.paginate(\u2026)) {\n    results.concat(response.items);\n}\nI could just do something like this:\njs\nconst results = await got(\u2026, {\n    pagination: true\n});\nAnd it would gather all the items for me.. > That just returns an array, right?\nYes. > If you need web server to be listening on port 80, remember to use sudo (Linux will not allow non-privileged process to bind to port 80). For ports greater than 1024, using sudo is not necessary (and not recommended).\n\n- https://docs.travis-ci.com/user/gui-and-headless-browsers/#starting-a-web-server. Can't you pick a different port than 80?. > So I guess it should be sudo nyc ava?\n\nThen we would have to have sudo enabled on Travis too, which means we couldn't use their fast Docker images, which would make Travis much slower.... > IMO using sudo shouldn't affect the performance...\nIt's not \"using sudo\" that makes it slow. It's just that the Docker images on Travis don't support sudo, so when you enable sudo support there it will use the old non-Docker images, which are slower.. If 443 works, I would prefer that. Otherwise, nock is ok.. This sounds like a Jest bug and should be reported on the Jest issue tracker.. > If options.body is set and options.method is not, the latter will be set to 'POST', as documented here.\nWe plan to change this to throw instead for this, see: https://github.com/sindresorhus/got/issues/639#issuecomment-455042713. It's better to be explicit about your intention. Both for code readability and predictability. As Got has become more mature, we're trying hard to remove implicit behavior.\nSo I think we should do the same for json, throw a user-friendly error message.. Can you link to some prior art about this? Like whether it's done and how it's done in other request libraries, like request, superagent, etc.\nShould it be enabled by default? Why / why not?. No need to force push. It's easier to review when we can see what's changed. We squash on merge anyway.. Thank you for helping out, @kevcenteno \ud83d\ude4c. We should document this.. Demos of what specifically? Can you elaborate?. We need https://github.com/webpack/webpack/issues/8826\nI have been asking the Webpack team for years to add a way to ignore require calls, but they have been unresponsive.. > Maybe this hack was necessary once, but it would nice to use something more standard that works out of the box.\nThere's nothing standard, that's the problem.. @atombrenner If Got is deep in the dependency-tree, people will not understand why they would suddenly get such a warning, and most don't even know about the externals trick.\nIt's just silly that we have to waste so much energy trying to \"trick\" Webpack. This is far from the first time I had to waste time on Webpack related things.. We could try this trick instead: https://twitter.com/kamilogorek/status/1102272038411137025. module.require. Yeah. Closing as this can be handled at https://github.com/szmarczak/http-timer/issues/4. You might be able to handle in a beforeError hook: https://github.com/sindresorhus/got#hooksbeforeerror. Nah. There's some docs that are not updated: https://github.com/sindresorhus/got#json-mode\nTry grepping for got( and find the places using json or body. There might be more places in the code and other docs.. some indentation issue here\n. nvm, just me being an idiot...\n. Why not use the request.setTimeout method?\n. Yeah\n. lowercase\n. since there's no default, just drop it.\n. mehtod => method\n. Don't you have to set GET as default method somewhere now?\n. Instead of supporting a ReadableStream here, should we rather have got also be a writable stream, like request?\n. In the above case it would start to stream the content, not wait for it.\n. > But in this, it should:\nI'm uncertain what you mean now.\ngot(/*...*/); isn't actually valid by itself. Do you mean got(/*...*/, function () {});?\n. Hmm, yeah I get what you're saying. Wonder how request manages to make that work though. I don't have time right now, but will try to look into how request does it, unless you beat me to it.\n. Sure, can you open an issue so we don't forget? And remove the stream support from body.\n. Because the way we have discussed is a better API for it and I don't like having two ways to do the same thing. If we keep it in for now, it makes it a lot harder to remove when we implement #16.\n. > This option and stream mode are mutually exclusive.\n. > Sets options.method to POST and makes a request.\n. Shouldn't we also support PATCH requests?\n. Done.\n. .. => ../\n. Can you open an issue instead of TODO? TODOs have a tendency to get lost.\n. code style\n. function (port, opts) {\n. https://github.com/sindresorhus/object-assign\n. Should we maybe generate our own self-signed certs?\n. .. => ../\n. .. => ../\n. Better to recommend null rather than undefined.\n. Can you add a TODO about removing this when Node 0.10 is not supported anymore?\n. Hmm, yeah, that's not good as users would expect that to work.\n. Lol. But yeah... Lets do it.\n. formatting yak\n. :heart: \n. This doesn't sound right.\n. this comment is somewhat useful though\n. > - Promise wrapper\n. Use objectAssign here?\n. Why?\n. js\nasCallback(opts, cb);\nreturn;\nTo make it clear it doesn't return the function as value.\n. Make it clear it's fixed in Node 0.12 and higher, so it's only needed to do this if you care about Node 0.10 compatibility in your application.\n. Can be simplified:\nAlso the space after function\njs\ngot.HTTPError = createErrorClass('HTTPError', function () {\n  this.statusMessage = http.STATUS_CODES[this.statusCode];\n  this.message = 'Response code ' + this.statusCode + ' (' + this.statusMessage + ')';\n});\n. You pass in url and method here, but I don't see it used in the error construction.\n. js\nee.emit('response', unzipResponse(res));\n?\n. We should probably not nest function statements. Make it an expression instead:\njs\nvar get = function (opts) {\n. MaxRedirectsError uses statusCode, while this uses code. We should make it consistent.\n. ReadError doesn't have a method property.\n. We should probably document if any of these have extra properties.\n. Use https://github.com/sindresorhus/is-plain-obj instead. I made it specifically because is-plain-object were suboptimal.\n. If `body` is a plain Object, it will be stringified and sent as `application/x-www-form-urlencoded`.\n. Handle the err.\nt.error(err);\n. Can you add a test to make sure unix:%s:%s', socketPath, '/' works too? We support protocol-less URLs for normal URLs.\n. ``` js\ngot('http://unix:/var/run/docker.sock:/containers/json');\n// or\ngot('unix:/var/run/docker.sock:/containers/json');\n.\n- PROTOCOL - http or https (optional)\n``\n. Can you linkifyunix domain socketsto an article/page where the user can read more about unix domain sockets?\n. Linkify to some Docker docs about it?\n. Same as above.\n.t.error=>t.ifError. The above test could uset.regexTest. Why not just tell them to use thehttp.requestauth` option?\n\nBasic authentication must be done with the auth option\n. Where did you find these?\n. js\ngot(`${s.url}/knock-twice`,\n. I think we should start using the promise interface as default for new tests. It makes the test a lot simpler.\n\nThis one can be:\njs\ntest('retry - timeout errors', async t => {\n    t.is(await got(`${s.url}/knock-twice`, {timeout: 1000}), 'who`s there?');\n});\n. Do we really have to expose this option? I'd rather have a good default.\n. Yeah: https://github.com/sindresorhus/got/issues/115\nThough, you can still change this one, though, as we already have it:\njs\ntest('retry - timeout errors', async t => {\n    t.is(await got(`${s.url}/knock-twice`, {timeout: 1000}), 'who`s there?');\n});\n. Don't know. Maybe @vdemedes does?\n. Ok\n. error => network errors?\n. with\n. Node => Node.js\n. Looks documented to me: https://nodejs.org/api/http.html#http_response_removeheader_name\nCan you find out in which Node.js version it was introduced?\n. Alright, then we can just remove this check and warning.\n. enumerable is false by default\n. Sure. Up to you. It's clear for me since I know that all the configs are false by default.\n. Actually, since we include the URL, we can remove sindresorhus- from the first part.\n. Wonder if this makes more sense:\njs\nif (opts.json && statusCode !== 204 && res.body) {\nThis way we don't try to read the body, even if there is one when the server tells us there shouldn't be one.\n@floatdrop Thoughts?\n. :+1: \n. Don't change this.\n. Use this instead:\nReturns a Promise for a `response` object with a `body` property, a `url` property with the final URL after redirects, and a `requestUrl` property with the original request URL.\n. You need to specify the json: true option\n. Link to the GitHub repo\n. Unclear where these variables (CONSUMER_SECRET) are coming from. Use process.env.CONSUMER_SECRET for all of these.\n. Should be camelCase\n. Yeah, just noticed. Never mind.\n. requestData would be ok.\n. js\n`multipart/form-data; boundary=${body.getBoundary()}`;\n. Just make it an inline arrow function.\n. The ; is a syntax error.\n. What's pojo?. Should be lowercase.. Why not just t.is(err.constructor, got.ParseError);?. Use t.notThrows rather than try/catch:\njs\nconst p = got(`${s.url}/304`)\nawait t.notThrows(p);\nconst response = await p;\nt.is(response.statusCode, 304);\nt.is(response.body, '');. > status code 304 doesn't throw. js\nconst encoding = opts.encoding === null ? 'buffer' : opts.encoding;\nconst stream = getStream(stream, {encoding});. It's 1.0.0-alpha5 now. And ^4.7.1. // @stevenvachon. Test pass without this. Can you add a test to cover it?. What is this about?. It works exactly like trying to reject a settled promise. When I promise is settled, it's by the name of it settled. Same with cancel. If the user use .cancel(), they should be aware they might call it too late and handle that themselves if they need. We can document this well. They can even check the promise whether it was canceled or not with promise.canceled (Which is false if you try canceling it after the promise is settled). I think p.cancel() throwing based on timing could lead to race issues and would be surprising to the user.\nPlease call me out if you think I'm totally wrong in this. I'm happy to discuss.. js\nawait t.notThrows(cancelPromise);. js\nbody.push('1');. request => Request. Place this after from 'ava'. Can you place this above the Proxies section?. Maybe we should say Canceling the request instead?. got => Got\n.cancel => .cancel()\n\nI would make it more succinct:\n\nThe promise returned by Got has a .cancel() function, which when called, aborts the request.. We don't need this anymore.. js\nawait t.notThrows(cancelPromise);. No, I just prefer the order:\n\n\nbuiltins\nava (placed here because it's the main external import)\nexternal\nlocal. @AlexTes t.notThrows either accepts a promise that rejects or a function that throws. AVA is actually catching a bug in your test here as cancelPromise is null, not a Promise. Try: console.log(cancelPromise === null);. HasredirectUrlsproperty => Includes aredirectUrlsproperty\n\ngot => Got. opts should be last. Unrelated, but change this to:\nIncludes `statusCode`, `statusMessage`, and `redirectUrls` properties.. Ping :). You don't need to name the class. JS engines are able to infer it.\njs\ngot.RequestError = class extends StdError {\nSame with the others.. This would be a good use for Set(). You could then use .has() instead of .includes() on line 50.. We still support Node.js 4. Just do .includes(opts.method) => .indexOf(opts.method) !== -1. This could be more readable. Can you move it (line 111 to 113) out into a separate variable?. I know it's not from this change, but Option acceptsobjectwith separate => This also accepts anobjectwith separate.. This doesn't match the docs. Here you explicitly set encoding: null, but in the docs you say it's returned as a compressed Buffer when decompress: false.. This causes a non-compressed response to be a Buffer, even a plain text response. Is that really wanted/expected?. > Copy/paste:\n\ud83d\udc4d . What you have is good.. Personal preference, consistency, and it's faster.. You're repeating (isPlainObj(body) || Array.isArray(body)) 3 times. That should be DRY'd up.. isValidBody or something. Better to describe the intent than the contents.. Why did we go with 150? Can you move 150 into a variable with a descriptive name of why it's 150.. Would be nicer to use pify here and on line 66, so we don't have to wrap the whole thing in the Promise constructor.. Remove the empty line here.. Remove the empty line here.. Would be better to do the Object.assign thing inside the asStream function.. js\nfor (const [index, event] of events.entries()) {. You could use https://github.com/sindresorhus/get-stream here to be able to use async/await instead of test.cb.. pify binds to the original object by default, so the bind here is moot I think.. Should definitely be clearer in the code then. 150 is very specific, wonder why we didn't just go with 100.. It's not wrapping it in a Number object, it's coercing it to a number.. Mostly just consistency. I also use Boolean() to coerce something to a Boolean. Same with String().. These comments are not aligned with the below code.. Link to the cache section here.. object => Object. Can you include when it could fail?. . fromCache and any other extra properties on the response needs to be documented.. --save is no longer needed.. > For example, the following are all valid storage adapters:. I think the option names should be without : and unquoted.. Better to just overload the agent option. It's confusing to have two so similarly named options.. Semi-colon. agents => agent. /\\n|\\r/gm => /\\r?\\n/g. This is the offending line. The other ones are just safeguarding for future memory leaks.. js\nfor (const error of Object.keys(errors)) {\n    got[error] = errors[error];\n}. Actually, can just use Object.assign:\njs\nObject.assign(got, errors);. Shouldn't this be called right (on line 319) away, like the stream version, instead of waiting for the body to be fetched? . Use test.failing. See: https://github.com/avajs/ava#failing-tests. This is not needed. It will be set for us by Node.. Remove this. Use something shorter, like Error.. Use s.on('/retry-503', (req, res) => {. Can you use Reflect.has() instead?. > do not set accept-encoding header when decompress options is false. Can you move the contents of the try into a function and call it from the try, so we don't add more nesting.. I just noticed an existing issue. p-cancelable was never designed for multiple onCancel handlers, but we call it twice. Here and on line 306. So the first onCancel handler is ignored. I've fixed this in https://github.com/sindresorhus/got/commit/871c3bd25442edd3cd89190c3d4788c0efd5c2db. Shouldn't it return here? I don't think you want to run the below code if the socket is destroyed.. The = {} is no longer needed here.. Ugh, yeah I didn't notice options was used outside the extend call.... Nah, I think what you have here is fine.. normalizedArgs => normalizedOptions would be more accurate, but that's quite verbose.\nWhat's wrong with just:\njs\noptions = normalizeArguments(url, options);\nDo we need the original options somewhere?. Since we plan to use this for gh-got, I think we should just link to it as an example now.. methods => request methods. Maybe also document how to just use the defaults methods: methods: got.defaults.methods?. I think we should do url = (new URLGlobal(path, options.endpoint)).toString() so it handles things like options.endpoint ending in a slash and path starting with a slash. That would end up with https://foo.com//path here (Could you add a test for the specifically too?).. !/^https?/ => !/^https?:\\/\\//. Maybe a simpler test would be:\njs\nif (options.endpoint && options.endpoint.startsWith('/')) {. The above if (options.endpoint && !/^https?/.test(path)) { check can actually be simplified to just if (options.endpoint) { then.. I'm not sure about the word endpoint anymore. It is too much connected to REST APIs. This one is more generic. Maybe we should follow new URL() and just call it base or baseUrl? I prefer the latter.. Can you also mention that this one is especially useful with got.extend() to create niche specific Got instances?. Object. Function. Couldn't this just be: To use the default handler, just omit specifying this.?. > use [destructuring assignment]\nDid you mean to say \"object spread\"?. next => next(). We should be more explicit here about got.create() having no good defaults included by default and how it's different from got.extend().. We can deep clone it with the extend dependency, I think.. Use a for-of loop and Object.entries().. Use the is module here: is.object. This should be in your own global gitignore. The project gitignore is only for project-related ignores. https://gist.github.com/subfuzion/db7f57fff2fb6998a16c. I would prefer the inverse here:\njs\nt.is(Number(headers['content-length']), size);. Object.entries() is better as it gives you the value too right away, instead of having to do options.headers[key].. got.extend() should stay in the readme, it was only got.create() that supposed to be moved out.. We don't need to check ._connecting here. See: https://github.com/sindresorhus/got/blob/bd3315b6c61d20a68944831d8b3a05046d5554ad/index.js#L194. For new assertions, we should use the improve t.throws API: https://github.com/avajs/ava#throwsthrower-expected-message\nIn this case, it would be:\njs\nawait t.throws(\n    got(s.url, {\n        timeout: 0,\n        retries: 0\n    }),\n    {\n        code: 'ETIMEDOUT'\n    }\n);. No point in using a template literal when there's no other content than the variable.. Can you make 40 a constant at the top of the file and use that instead? Makes it easier if we ever need to change it.. js\nt.not(headers['user-agent'], undefined);\nSame with the other test.. I think forward is a confusing name as it sounds like you're forwarding the request. If this were to be added, it would make more sense to just let got.extend and got.create accept a parent instance.. method => methods. I think we should link up (to MDN) the status codes (like I did in the issue), so people can quickly check what they mean. Would save them some time.. Keep in mind this comment: https://github.com/sindresorhus/got/issues/417#issuecomment-364760887 We need to set some sort of upper limit (and document it). What kind of limit do you think makes sense?. I meant a constant with a descriptive name.. I think we should remove support for retries: Function and just require retries: { retry: Function} }.. It's no longer just network errors.. Why is this not just options.gotRetries = 0;?. You can use Date.parse(error.headers['retry-after']) instead of (new Date(error.headers['retry-after'])).getTime(). This needs to be named more specific. lastTried => lastTried413access. iter - Use the full word.. Use the new t.throws API. Don't reuse tests for different purposes. This should be a new test.. Not immediately clear from reading the code what 2000 is. Make it a constant like TOTAL_REQUEST_TIME or something.. I was referring to a time limit, not redirect limit.. > We can set a timeout, if it exceeds the timeout then throw.\nWhat should the timeout be? Should it be configurable?\nHow does retry interact with the set timeout?. \ud83d\udc4d . I don't think to define a custom method is that common and it would be nice to simplify the options. Right now it's quite confusing, with IMHO too many variations. Then it would just be either a number (common case) or object (full power).. @brandon93s Thoughts?. > Yes, we should specify retries: { ..., timeout: number }. That would override the timeout option. By default it should be set to 15000 or 30000 I think.\nSo why wouldn't the user just change the timeout option themselves instead then? If options.retries.timeout just overrides options.timeout.\n\nI think I should note that in the docs.\n\nYes. Oh right... Never mind then.. This needs to be updated. Use a Set here. These need to be documented in the readme.. isRetryAllowed => isRetryOnNetworkErrorAllowed would be more correct.. href: githubURL,. const githubURL = 'https://user:password@github.com:443/';. Converts => converts. Would be better to use {instanceOf: TypeError}. 500 and 100 should be constants at the top (with descriptive names) and used here and elsewhere. Makes it much clearer and easier to change.. > Out of curiosity, why Reflect? Why not hasOwnProperty?\n.hasOwnProperty won't work with Object.create(null) created objects.\n\nBecause AVA. (throws an error IIRC)\n\nYou mean XO ;). methods => HTTP methods. And shouldn't **or** be **and**?. Should either be retryAfterStatusCodes or RETRY_AFTER_STATUS_CODES. The filename needs to be renamed too.. It should still have number here.. representing retry => representing retries. I think beforeRequest would be a clearer name.. @szmarczak We could handle that while merging options if needed. if beforeRequest is set and we're merging in options with another beforeRequest, we just wrap it in a function that calls both.\nI don't like events that allow mutation.. Use the delay module (we already have it as a devDependency here).. Yes. The way it's written makes it sound like if you specify methods it will not retry on network errors.\nWe can improve it to:\n\nIt retries only on the specified methods, status codes, and on these network errors:. This is missing >. beforeRequest needs to be nested in hooks. @szmarczak I don't think we should add variables that are not defined in the example. Ideally, examples should be copy-paste runnnable. I also think the comment helps make it clearer.. @szmarczak Let's try not to nitpick too much. The super minor stuff we can just fix ourselves when merging.. I prefer just a simple array too.\n\n@szmarczak Making it just an array enables the user to construct it however they want. They can, for example, order it based on a condition.\nSame reason we have:\njs\ngot(..., {\n    headers: {foo: true}\n});\nInstead of:\njs\ngot.headers.add({foo: true});. @jstewmon I agree. I feel like I never know when to put it in uppercase. Better to just always use normal camelcase, indeed.. Use get-stream here for simplicity. We should change all of the t.throws assertions to the new format. Should not be done in this PR though. Just a note to myself.. You don't need parens around await. @brandon93s I would consider that a feature. Immutability is good, it prevents a lot of weird bugs.\nDo you have any use-case for when you would want to modify hooks after instantiation?. Usually better with early returns to reduce nesting.\njs\nif (!destination.headersSent) {\n  continue;\n}. Can you add a short code comment why we don't set this? Are there other headers we shouldn't overwrite?. isFinished. It's not clear what this does exactly? What changes does it prevent? All? I think it needs a more explicit name.. This method needs some internal docs in form of a code comment above. What it does exactly.\nFor readability, I think deep = false, excluded = [] should be converted into an options object. deep is a boolean trap: https://ariya.io/2011/08/hall-of-api-shame-boolean-trap. The ESLint rule is there for a reason ;). In this case, nothing major, but very often it creates harder to read code.. @jstewmon Could you submit the above test? The more tests, the better! :). @szmarczak I know you don't mean anything bad by it, but your tone does come off a bit condescending. If you don't understand a comment, ask for clarification instead of assuming the other part doesn't know what they're talking about. It's easy to talk past each other. Clarity is key in technical conversations. \ud83c\udf70\nImportant to keep in mind, we all want the same thing, to create a great project.. I think this should be moved out of the if/else into a standalone if above:\n``js\nif (!is.string(url) && !is.object(url)) {\n    throw new TypeError(Parameter `url` must be a string or object, not ${is(url)}`);\n}\nif (options.baseUrl && (is.string(url) || is(url) === 'URL')) {\n...\n``.as it may give unwanted result:=>as it doesn't work recursively:. I made https://github.com/sindresorhus/random-bytes-readable-stream, but I see you already solved the problem :). I agree, this should not have been included here, but since I'm gonna accept #525, I'll allow it.. I think it's worth keeping. I see the mistake of using Object.assign/object-spread for deep objects all the time. This also gives context to why we have this custom method.. Both arguments are valid and both are common.Object.assign/object-spread will overwrite withundefined, while many extends libs will not. I definitely find it more convenient when{foo: true}, {foo: undefined}end up as{foo: true}, but that also means there's no way to explicitly unset a value, like with headers. Maybe we do a middle ground and say thatnulloverrides, whileundefineddoes not. This is how default function arguments work. They only work withundefinednotnull. So to unset a header you setnull`.\n```\n{foo: true}, {foo: false}\n// {foo: false}\n{foo: true}, {foo: undefined}\n// {foo: true}\n{foo: true}, {foo: null}\n// {foo: null}\n```\nThoughts?. > I'm not gonna explain simple things.\nArguments are worthless if the other part doesn't understand you. Not everyone is in your exact mindset. We all need to be on the same page. I was also confused by your comment.. I just realized that my proposal is how lodash.merge works.\n\nBut, I also can't think of a reason why an object would contain a key with the value set to undefined in this context b/c the key could simply be omitted to get the same behavior.\n\nIt allows you to do inline conditionals:\njs\nfoo({\n    unicorn: checkForUnicorns() && '\ud83e\udd84'\n});\nWithout, I would have to do:\n```js\nconst options = {};\nif (shouldUseUnicorns()) {\n    options.unicorn = '\ud83e\udd84';\n}\nfoo(options);\n```\nI'm not yet sure it's worth the divergence from Object.assign/object-spread. There's value having the same semantics as the native methods. Especially when our method is using the word assign.\n\nI backed off your change b/c it overreached what we had discussed. I don't mind maintainer commits for nits or agreed upon changes, but please don't make behavioral changes when consensus has not been reached.\n\n@szmarczak Don't modify other people's PRs before we have agreed on a solution.. > Do you think it would be helpful to explicitly mention in the got.extend and got.create that the resulting object is frozen, so that any reference types will be frozen? We could also mention that a workaround is to use something like _.deepClone if users need to preserve a mutable instance of a config setting.\nYes, that would be useful.\n. Shouldn't this be 'user-agent': undefined?. Why was this removed? I guess we could shorten it a little bit, but I like to keep the note about you should treat objects passed to these methods as immutable. somewhere.. \ud83d\udc4d . How is this related to the JSON change and what does read-only mean here? . Why was this removed? . But you changed the meaning. Previously it said that the option cannot be used with got.stream() at all. Now you're saying that it can, but that the stream will be read-only. If this is true, can you point to a test proving that?. \ud83d\udc4d Great :). Good point. I think we need a try/catch here though: https://github.com/sindresorhus/got/pull/542/files#diff-62bdc57f6f22ae58f495daef16f21f8bR141 In case the options.gotRetry.retries function throws.. Your answer is not confusing, but you're not answering my question. To be clear, I think we need to try/catch this line because it could throw: const backoff = options.gotRetry.retries(++retryTries, error);. >> I think we need to try/catch this line because it could throw\n\nGood point! Indeed. \ud83d\ude4c\n\nAnd of course a test ;). It's a good practice to put the message in a variable and use it in both to make absolutely sure they are the same and stay the same in the future too.. I think this check should be on line 21 for clarity and be if (Buffer.isBuffer(body)) {. Why is this removed?. .merge() is too ambiguous. Let's name it .mergeInstances().. n => index. Use a template literal.. Would be good to provide some actual use-cases for when it could be handy. Not all users would immediately realize its usefulness.. I would prefer to only have one way to merge instances. We could then drop the array requirement and just have got.mergeInstances(instanceA, instanceB, instanceC).. http => https. > These options are normalized, so assigning baseUrl here won't work.\nIs this enforced? If not, it should.. Can this be in a separate file?. Verbose is better than unclear. It's only a few extra characters and you don't write it that often. .merge() sounds more like options merging.. I don't have any ideas, but those sound good. Can you add those as example use-cases to the docs?. By enforced, I mean that it should throw if users accidentally assign baseUrl there. Better to fail loud than silently.. It is, but it's ugly...\njs\n({methods} = args[0].defaults);. That's what I commented I don't think we should do in https://github.com/sindresorhus/got/pull/510#discussion_r208347443 Better to have one way to do something. Pick one of those, not both.. I think the error should say why it's not mergeable. That's not clear.. I think it's still useful to declare all options up-front, even if they are false by default.. Why are you lowercasing them here, but uppercasing them in normalize-arguments?. Nvm. I missed the context. It's late here.... From what I can remember, it's something about JS parsing ambiguity.. The mergeable option is not documented (I we decide to keep it, it should be) and it's not clear what use-case it serves? Why do you need to make an instance unmergable?. _ => (). get: () => baseUrl. ?. The naming needs to be updated here.. When I asked for example use-cases, I really just meant a text list, but this is much better. Can you move the different examples into separate code-blocks with the comment as a header instead.. What's the use-case for this?. No, it's a user-error and should fail immediately.. Why are you suddenly removing all the methods fields?. require statements should be at the top of the file. In this case, line 12.. Examples. Can you add an entry to the Highlights section in the readme called Composable, which links to this section?. I think it would be nice to have something like this as an intro. Feel free to improve it.\n\nGot supports composing multiple instances together. This is very powerful. You can create a client that limits download speed and then compose it with an instance that signs a request. It's like plugins without any of the plugin mess. You just create instances and then compose them together.. > Some examples of what kind of instances you could compose together.. (in case your machine's got a little amount of RAM) should be in text below the title.. noUserAgent => The noUserAgent instance. are merged serially => are merged in order. Other modules => Other instances. There should be a header here called #### Putting it all together or something.. I agree \ud83d\udc4d . Can you also add a test with await instanceA('foobar');?. prenormalize is not a word, so should be preNormalize. And a couple of tests where the baseUrl is a WHATWG URL object.. Let's name it options._requestFunction so it's clear that it's readable and clear that not something we officially support.. ({fn} = options);. Yes... Ok, don't do it.. Fixed: https://github.com/xojs/eslint-config-xo/commit/20daf6d7798140b05e690dfab63959e7c21bfed9 You can remove the disable comment now.. You need to update this one too.. > The signature for a given listener can be found in the Node.js docs.\n\nMaybe we can link to at least the main events (request/response), so it's quicker for people to look it up.. What's the use-case for modifying the context object?. Can you place everything below here in a <details> tag so it won't take up so much space in the readme?. > Use Symbol properties to avoid collisions with multiple listeners.\nCan you include an example of this? Not clear how that would look like.. You should write that the main purpose of this is HTTP2 support and link to the example.. module => package. The distinction is that a module is what you import, while a package is what you publish to npm. A package can contain multiple modules. I'll fix it in the readme after merge.. I don't think we should use remote server when we can just use our local server. Using a remote endpoint slows down the tests and makes them more fragile.. Right... We could have used nock, but I guess this is good enough then.. This should explain what exactly setting this option does and link to the cookies section to read more.. Why this change?. e => error. Use Promise.all. Why not just this?\njs\nif (options.useElectronNet) {\n    response.trailers = [];\n    response.rawTrailers = [];\n}. It was like this for a reason. It's to prevent Webpack from complaining. I guess we should add a comment about that.. Yes, but it's not relevant to this PR. Just do a commit on master instead.. I see. You could use Object.defineProperty, but I guess this is safer.. Can you add a comment with a link to the Electron issue this fixes?. Let's ease people into it by showing a common use-case first in request and then in got.. jar => cookieJar. @szmarczak I disagree. We do that with other options as they're not explicit, but providing a cookieJar is an explicit action and if they also supply a header it's most likely a mistake. I see no reason to support both at once.. Click here kinda links is a bad pattern. Let's make it descriptive instead. Here, it can just be [Example.]().. Hmm, how about this then:\njs\nconst r = ({x: require})['yx'.slice(1)];\nconst electron = r('electron');\nI would be impressed if Webpack managed to decipher that \ud83d\ude1d. This is only used in one place, so just put it inline with the function call at line 50.. Not clear why you removed the defaults for useElectronNet and cache?. Put the properties on separate lines.. Won't this cache all requests forever and cause a memory leak?. I think it's better to define all defaults upfront. What if the check is foo === false, then it will never match, since the default is not there.. What if the requests are huge, then even 100 is too much. How do you pick a sensible number? This feels like the wrong way to solve the problem.\nIf it's slow to generate a CacheableRequest, why is this not being fixed at the source instead? In cacheable-request.. I think we should include some use-cases for each of the hooks. Not clear from looking here what you would do in each of these hooks.. Put them on separate lines.. Should we include the retry count too, like requested in the original issue?. ```suggestion\nconst errorString = 'oops';\n```. Should there be a way to stop retrying from this hook?. Can you linkifyresponse objectto docs about it?. Can you linkifyrequest options` to docs about it?. Would be nice to include an example on how to use it to change the redirect location if it's trying to redirect to a certain place you don't want, for example.. This is unrelated to this PR.. I don't understand this use-case. You can already do this without the hook:\njs\ngot('example.com').then(response => {\n    const content = response.body.split(','); // 8,5,6\n    response.body = {\n        ponies: content[0],\n        dogs: content[1],\n        cats: content[2]\n    };\n    return response;\n});\nI think we should find a better example for this hook.. That's exactly what I want to remove in the next major version. Then it will be; either use an object with string values or specify a URLSearchParams instance.. So either query: {foo: '1'} or new URLSearchParams({foo: 1}). I went with something that is consistent with the existing \"Browser only\".. mutable is too generic. I would prefer something explicit like mutableDefaults.. Why are you returning options here and not the response?. ?. Why this? It can just be specified as an option. It's also a boolean trap.. Needs to be updated.. The retryWithMergedOptions function needs to be document in text above on line 386.. Why this? I think it's surprising behavior that it suddenly doesn't throw on errors.. Why not just:\njs\nretry: {\n    retries: 0\n},. I don't fully understand this code, but this request should not be affected by the retry limit.. Why is this being removed?. I'm not a big fan of the \"asking questions you'll answer yourself\" thing. I would prefer just saying it:\n\nThese Got options are the same in with Request:. Are you sure this has the same behavior?. This has different behavior. We support URL too.. suggestion\nrequest('https://google.com', (error, response, body) => {. No point in having both an example using promises and one using async/await. Just drop this on. We should always use async/await.. no => No. suggestion\nhttp.createServer((request, response) => {. But doesn't mergeOptions normalize? I'm just asking, because if it doesn't normalize the retry there, it doesn't normalize updatedOptions either, which is problematic.. So this only let it run the hook once?. Test the error message too. A lot of things could accidentally be HTTP errors.. Alright. I think this behavior needs to be documented though.. But the problem is still there. The users options needs to be normalized as if they called got(options). That's what the user would expect. . > return the response or updated options\n\nThey don't return the updated options.. You are removing this hook and all hooks before it. Is that the intended behavior? Would be nice with a code comment then to explain the behavior.. I know this is from the Requests docs, but this makes no sense. Why would you guard response, but not body?.... Also no maxRedirects option. There are many more too that are not listed here.. Can you show an example of this too? I know this option is fairly common, so would be nice to give people an easy transition.. Can we provide any transition steps / alternatives for these options?. > I prefer to operate on parents, not children (options)\nWhat does that mean?. You're right. I'm too used to Got. It's just the Request API that makes no sense for me in general.. > It's counted as only one option: followRedirect. (followAllRedirects and followOriginalHttpMethod are the children of followRedirect, 'ya know what I mean?)\nYes, but is that clear enough to the end-user though? Why not be explicit about it? Some might just do Cmd+F to try to find what they're looking for. I think we should list them all to make it easy to the user to discover.\n\nAlso, some Request's options are not spec-compliant.\n\nSpec-compliant to what? HTTP? And does it matter? Then we list it and say that Got does not support that because it's not spec compliant.. > do with does not mean use.\nNot specifically, but in this context it's IMHO clear.\n\nOr: see what else you can achieve using hooks.\n\nI'm ok with this one too though. \ud83d\udc4d. I got (pun intended) what you meant. I just think we should list it no matter what.. Yes, https://github.com/sindresorhus/got/blob/50fdab303cb2a6b34383de13e5e0ece9ceaf80c9/package.json#L9. Yes, we need to preserve backwards compatibility. We can add it to https://github.com/sindresorhus/got/issues/639 if there's any benefit to it.. > @sindresorhus any thoughts?\nYes, like I said, backwards-compatibility must be preserved.. @szmarczak But if you think it should be changed, we can do so in Got 10. Add a comment https://github.com/sindresorhus/got/issues/639 if so.. We should also encourage submitting a PR with a failing test in addition. This will make it more likely for us to prioritize your issue and it's a good way to prove that the issue is with Got and not your code.\nAnd link to https://github.com/avajs/ava#failing-tests. Should also mention Node.js:\nsuggestion\n- [ ] I have tried my code with the latest version of Node.js and Got.. The first question should be:\n```\nWhat problem are you trying to solve?\n```\nMany times, people post ideas that sound like a bad idea, but the actual problem is valid, just needs a better solution. And sometimes the problem is already solved in a better way. That's why knowing the problem to solve is more important than the suggested idea.. Questions doesn't necessarily mean it's a problem.. suggestion\n- [ ] I have read the documentation.\n- [ ] I have included a pull request description of my changes.. suggestion\n- [ ] If it's a new feature, I have included documentation updates.. suggestion\n- [ ] I have read the documentation and made sure this feature doesn't already exist.. suggestion\n<!-- Include a usage example of the feature. If the feature is currently possible with a workaround, include that too. -->. ```suggestion\nDescribe the bug\n A clear and concise description of what the bug is. \n. We should also ask for the Node.js versions they can reproduce the issue with.. I think we should name it `errorCodes`, since they're from `error.code`.. Same in the other places you use \"error\".. @szmarczak Can you open a new issue about this?. I don't think you meant to delete `gotOptions`.. Let's throw a helpful error if the return value of `hook` is a Promise as it means someone accidentally made it async..suggestion\n                options.originalJson = options.json;\n```\n?. I would drop this part. The example is already complete without this.. Let's use the .is methods here.. This is becoming quite nested. Can you extract the logic here into a top-level validateSearchParams() function?. It should say that it will be a warning in v10 and removed in v11.. It should be explicit about this being a rename, not a different kind of option.. Use is.promise() here.. I didn't mean to remove the whole example. The example is actually very useful. I just meant remove this part:\njs\nif (response) {\n    error.rateLimit = getRateLimit(response);\n}. suggestion\n**Note**: The `query` option was renamed to `searchParams` in Got v10. The `query` option name is still functional, but is being deprecated and will be completely removed in Got v11.\n?. With that example there's no way to get the whole response though, so I don't think people should do that, even in custom instances.\nInstead they could just do:\n```js\nconst instance = got.extend({\n    resolveBody: true,\n    responseType: 'json'\n});\nconst {body} = await instance(url);\nconst body = await instance(url).json();\n```\nSo I don't think this option should be public.. For completeness, it should have .text() too.. Can you find a proper type for the response object? Should be in the NodeJS types.. Same as https://github.com/sindresorhus/got/pull/705/commits/c3c71b0ac63ea6c54efb35623fe9ae88285b1ab5#r249244253. Same as https://github.com/sindresorhus/got/pull/705/commits/c3c71b0ac63ea6c54efb35623fe9ae88285b1ab5#r249244253. Mistake. Yes, mistake. Let's use undefined instead of null. It's better in general to use undefined as it works better with modern features like default parameters. You also need to update https://github.com/sindresorhus/got/pull/708/files#diff-7bf54112e60a8714e49d3e1e98cf4e2bR15. This needs a more explicit type. Are you able to find a Node.js type for it? Look in the Node.js type definitions.. Use unknown instead of any.. download returns a Transform stream.. No, we can't change that (yet), as it's a public API that uses null: https://github.com/sindresorhus/got#encoding. This pattern is called deferred promise and is generally an anti-pattern, as unlike the constructors, thrown errors won't be caught and won't result in promise rejection.. This is not a reliable check. What are you trying to do here?. Use arrow function.. This could be simplified to:\njs\n(async () => {\n    try {\n        const normalizedOptions = await normalizeArguments(url, options, defaults);\n        await defaults.handler(normalizedOptions, promiseOrStream._sendRequest);\n    } catch (error) {\n        promiseOrStream._reject(error);\n    }\n})();. Use the format export class CacheError extends GotError { on all of these instead.. We need a better type for data. Can you console log it and check what possible types it might receive and then use that?. You forgot to convert this and some others to ES2015 module exports.. Add a console.log(typeof data); and then run the Got tests $ npm test.. response needs a better type too. I think it's IncomingMessage from import {IncomingMessage} from 'http';. https://github.com/petkaantonov/bluebird/wiki/Promise-Anti-patterns#the-deferred-anti-pattern. Can you move them into a utils/types.ts file for now? Same with interface Options.. I accept PRs to add type definitions to my packages, yes. So PR welcome for that if you're interested. Should follow https://github.com/sindresorhus/typescript-definition-style-guide. If not, you can just depend on @types/p-cancelable.. Use unknown instead of any.. - [ ] Doc comments for each hook.. You can disable it in package.json for now: https://github.com/sindresorhus/got/blob/99c23ef7536dd947d5263ffd8d1d32e2cd7ecb6d/package.json#L91. Should the docs be here or on the actual types? For example, line 11.. I don't think there's any @note tag. I usually just use Note:.. Why did you remove this? It could be moved into utils/types.ts.. Sounds good. I would prefer lowercase first as that's what I use.. Actually, wouldn't a const string enum be a nicer choice here?. https://github.com/sindresorhus/got/pull/714#discussion_r251441415. We should also add a comment that the line should be removed in the future when the TS migration is complete.. Yup. Hmm, yeah, not worth it.. @fnky Should we change https://github.com/sindresorhus/is/blob/ab586df0f9ff91e4c0e0d692a978cba110df1d7c/source/index.ts#L224 to \nts\nexport const plainObject = (value: unknown) => value is {[key: string]: unknown} {\n?. https://github.com/sindresorhus/is/pull/80. You can add a console.log to the code and check yourself whenever you wonder what the actual type is. Run the tests $ npm test and it shows up.. import {Readable as ReadableStream} from 'stream'; to improve code readability.. number | number;?. Correct. Good catch.. Don't import URL. We use the URL global.. Don't use any. Type it properly.. Got also supports a string in the url parameter.. Should use export default. RetryDescriptor => RetryOption. This should be constrained to the possible status codes.. This should be constrained to the possible error codes.. Yup: https://github.com/DefinitelyTyped/DefinitelyTyped/blob/master/types/node/events.d.ts\nCan you check if there's an issue in https://github.com/DefinitelyTyped/DefinitelyTyped, and if not, open one?. Transform => Transform as TransformStream. Isn't there a built-in type we can use for this?. suggestion\n    retry?: number | RetryDescriptor;\nhttps://github.com/sindresorhus/got#retry. Make sure it has everything from the docs: https://github.com/sindresorhus/got#retry. Example: https://github.com/DefinitelyTyped/DefinitelyTyped/blob/4a98006b062812c2cf10d267b1a3769c2e0c23e5/types/got/index.d.ts#L247. suggestion\n    http.on('/redirect-to-port-80', (request, response) => {. And why not keep this endpoint inside the test itself?. > Well, if we want to move the route into the specific test, then we should do it everywhere, not only here.\nYes, but that's an insane amount of work. I think we should at least do so for new tests. Better to do it iteratively.\n\nAlso, that would result in having two servers in one test function.\n\nWhy is that a problem?. > The code becomes less readable.\nI would actually argue for the opposite. By having all the related code in the test you can fully understand what it does. If the test calls the server code, you need to scroll up or look in another file to see what the server part of the test does. Also, having shared tests makes it very easy to reuse endpoints for different tests, which means if you want to change the logic of one test and endpoint, you need to change many tests.. Never mind. I got confused with Ky.. You're right that the statement was incorrect previously, but yours doesn't look correct either. I think it should be:\nsuggestion\n                    for (const [index, hook] of options.hooks.afterResponse.entries()) {. I would prefer using ! (non-null assertion operator) instead of guarding it here, as we already guarantee its existence, so it's just the TS compiler that is struggling.. Same as https://github.com/sindresorhus/got/pull/738/files#r259592816. This is not needed anymore.. Yes. ",
    "floatdrop": "Thanks!\n. I would prefer passing encoding into options and leave stuff related to binary data in stream mode of got. It just my opinion, but I often forget to do toString on buffers and get very obscure errors.\n. :+1: \nWill port it to sent tomorrow. And extract common library by the way.\n. @julien-f 1.1.0 is released for both got and sent. Or what do you mean?\n. @radum is node-tunnel solving your issue? It seems like right solution to your problem for me.\n. @sindresorhus there is another module - tunnel-agent, which is used in request. I think it worth to mention them in readme :+1:\n. @sindresorhus yeah, but with some patches. Hope they will be ported to node-tunnel soon.\n. @radum thanks for linking this conversation. I agree with @sindresorhus, that it should be implemented in default agent. For example Go has support of HTTP_PROXY (without HTTPS, lol), so Node should do it as well (but apparently it won't https://github.com/joyent/node/issues/1973).\n. @julien-f if you can - move shared code from sent and got - it would  be awesome :star2:\n. I stumbled on destroying response object before calling cb - it cleans all data, that was attached to 4xx   response (it was JSON with errors). It some how connected to this issue - returned response object is destroyed.\nShould this behavior be fixed as well?\n. Ready to merge.\n@sindresorhus @julien-f \n. @kevva yeah, data is not ungzipped on error. Added test on that, will fix soon - thanks!\n. Squashed commits\n. @sindresorhus could you merge ~~and publish~~ this?\n. It works with it's own object and storing req inside.\n. Custom timeouts can be implemented through agent-keepalive sort of thing. But how get request object is still a question.\n. I'm thinking about returning proxy-object for http.ClientRequest that will have additional event request or redirect. It will proxy all events from stored request to user and six methods from ClientRequest.\njs\ngot('http://todomvc.com')\n    .on('redirect', function(req) {\n        console.log('This was a redirect!');\n        req.abort();\n    });\nAlso it would be nice to have timeout method:\njs\ngot('http://todomvc.com')\n    .timeout(function() {\n         console.log('Todomvc is down');\n    }, 5000);\n\nP.s. proxy-object will cause multiple response events - which will confuse many people.\n. Fixed readme. Squashed commits.\n. I don't have any more suggestions :)\n. Maybe content is not quite right name, by the way. Curl using data and in node/express  documentation it called body.\n. Thanks for talking to me about WritableStream and review :)\n. license file is not excluded by .npmignore (which is not in repository at all). Isn't license field in package.json is enough?\n. @julien-f nope. Could you rewrite xo-cli to use got?\n. @julien-f I'm thinking to unpublish it.\n@sindresorhus what got should do if request is POST and options.body is present - ignore options or ignore proxy?\n. @sindresorhus I mean POST in Stream mode:\njs\nstream.pipe(got.post('...', { body: Buffer() }));\nIt is not clear what should got do in this situation.\n. I'm agreed with @julien-f, that in case of options.body presence got should use it and ignore incoming Stream. But there is another question, if it is so, should we support ReadableStream as options.body?\n. @sindresorhus it is tricky to catch this situations - for example we have this snippet:\n``` js\nvar s = got.post('...', { body: Buffer }); // Nothing wrong\nstream.pipe(s); // Should throw?\ns.write('...'); // Should throw either?\n``\n. @julien-f shouldn't implementations set_write` method instead?\nReady to merge, but it feels like tests should be rewritten to use local server and split in different files.\n. @julien-f fixed.\n. Does something should be done before merge, that I missed?\n. Cool, thanks for the reviews!\n. @sindresorhus yes, all changes were compatible.\n. @julien-f I thought, that before and after must be placed in describe.\nI more like tape approach, that does not require global variables to write tests and can be launched by bare node command.\n. Squashed commits.\n@sindresorhus glad you like it :)\n@julien-f I like mocha too, but ofter in node modules we don't use BDD style (in comparison to apps and UI's). Mocha is not async by default (until you pass done), but tape is - you must call plan or end to finish test. imo complex assertion library is overkill, since 90% of times we using equal and ok.\n. @sindresorhus fixed all, except certs - I don't know how to generate it and do not get reject error in https module, sorry.\n. @sindresorhus done. Thanks!\n. @sindresorhus I have no real use-case (never needed to disable redirects limit), but someone may have. Lets keep it open and see, how many people needs this. \n. One of usecases is to get content of 3xx page. Now you can't access this page, but with this option you can do this:\njs\ngot('http://google.com', {maxRedirects: 0}, function (err, data, res) {\n    // data is undefined, but res is readable for content\n});\n. > Why would you want that? Redirects are there for a reason.\nTo test output I guess.\nOther problem pops, if you must use API, that does 11 redirects. :)\n. >  I know it seems minor to add an option, but it easily bloats up, and suddenly we have request.\nFully agree, but there is another valid point - if you have some constant in code, it should be configurable. No rush, just updating and rebasing stuff in case of fire.\n. By the way, simple-get has this option - thats why I renamed it.\n. > If someone needs this, which I really doubt, they can just use request.\nSince there is no other people in thread \u2014 no one needs this at the moment (including me :dog:).\n\nAnd I would never implement something just because others did.\n\nI don't mean it at all, but maybe we should ask @feross \u2014 about usecases. This would not hurt anyone :)\n. Oops. Didn't mean to close it, but whatever.\n. Should we set agent to false by default as well? This seems like not obvious behaviour, but 5 sockets limit bothers me a lot.\n. @sindresorhus yes - this is fixed in 0.11.x. I would wait for release for some time, instead of setting default agent to false (it also breaks https tests) now and revert it back.\n. To track progress on this:\nSetting agent: false breaks https requests - https://github.com/substack/hyperquest/issues/19\nThere is another approach to this (see here) - setting maxSockets to Infinity (like 0.11 node does - https://github.com/joyent/node/commit/9fc9b87472806147b83c24d85b303c4f75d3021c#diff-5f7fb0850412c6be189faeddea6c5359R100):\njs\nopts.maxSockets = opts.maxSockets || Infinity;\n// ...\nvar fn;\nif (parsedUrl.protocol === 'https:') {\n    fn = https;\n    opts.agent = new https.Agent(opts);\n} else {\n    fn = http;\n    opts.agent = new http.Agent(opts);\n}\nBut this will leave connections in pool - so redirect test will not be completed.\n. Thanks @silverwind, it worked!\n. @sindresorhus to fetch gzipped content and store it. This is very rare usecase.\n. Squashed commits. Ready for review.\n. Rebased.\n. Incapsulated Node logic of creating https agent to infinity-agent module.\n. \\o/\n. @sindresorhus in fact, it does - https://github.com/joyent/node/blob/v0.10.35-release/lib/http.js#L1381-L1386\n. :+1: \nP.s. just don't make it silent like in request.\n. If someone have ideas, how this option should behave in Stream mode, please share - I can't think nothing better than making it exclusive for callback mode.\n. @kevva awesome module, but I tend to leave streaming on feature releases because:\n- Streaming JSON is rare\n- It needs some additional options (for parse and stringify/stringifyObject calls)\n- It will not break compatibility, if we add it later\nNow I'm digging through issues with json-like options in other modules and implementing it right might be harder, than it looks (or I'm just over-complicating).\n. After reading some issues with json option in request one idea came up. All this noise around json option comes from the fact, that enabling it have two separate effects:\n1. input - it enables serializing of body (and add headers, if they not set)\n2. output - parses incoming JSON\nSo, why don't just split them apart? For now, if we pass Object in body, we will get next error: TypeError: first argument must be a string or Buffer. What if we serialize it to JSON in this case (without setting any options)? Anyway we can't send it as is, so this seems reasonable. But two things needs to be considered:\n1. is it true, that most users want to serialize objects in body option instead of throwing error?\n2. if so, should we take care of toString property as well?\n. Partially implemented in 2.7.0 :tada:\n. Readme + test for it, please :star2:\n. @kevva I guess somewhere near https://github.com/sindresorhus/got#callbackerr-data-response \n. Lgtm, thanks @kevva :+1: \n. Ready to merge.\n@kevva @julien-f @sindresorhus thoughts?\n. In before question Why serializing is not enabled only when json option is true?:\nThere are cases, when server response is not JSON at all, but it expects JSON in request.\nWould it be confusing for user?\nI'm quite sure - yes.\n. After few more hours of thinking - writing JSON.stringify with right header is not that hard:\njs\ngot('jsonendpoint.com', {\n    body: JSON.stringify({ data: 'dog' }), \n    headers: { 'content-type': 'application/json' }, \nfunction () { });\nAuto-stringifying seems to me much more dangeuros, than one line in got call.\n. Ready to merge. @sindresorhus @kevva @julien-f ?\n. To my future self: I intentionally leave serialization out of this option, because it will block next usecase: user wants to parse JSON response, but send Stream (or Buffer, or string) of data. \nSo we could say: yup, we can check, that it is sendable type and do not stringify on it, but string is in both categories - it can be sended as it and it can be stringified to \"value\". \n. @sindresorhus well, this will introduce content-type matching, which I like to avoid. This still could be done in userland (because data is passed to callback anyway):\njs\ngot('nginx.com/errored', funciton (err, data, res) {\n    if (err) {\n        // Explicitly says, that we expect non-json responses\n        if (/text\\/json/.test(res.headers['content-type'])) {\n            //...\n        }\n    }\n});\nAnd it will be inconsistent with 200 responses (should we then add content-type matching there?).\n. Ready to merge. @kevva @sindresorhus \n. @sindresorhus I'm planning to release patch release 2.7.1, since in readme we never specified, that only successful responses will be parsed, so it is a bug. Is it ok?\n. Also infinity-agent now ignores http.Agent.defaultMaxSockets and uses Infinity always.\n. @sindresorhus i'm not quite sure about it either. Should we add all wrappers here then?\n. @sindresorhus yeah, I thought about it, but in this way it is easier to get, what got call returning without having gotPromise variable around. Also it is easier to migrate from callback to Promises with this drop-in replacement. But yes - not quite common way of doing promisification.\n. > Not sure what you mean. Mind showing an example?\n``` js\nvar got = require('got-promise');\ngot.promsie() // => Promise\ngot() // => Stream\n// --- vs ---\nvar got = require('got');\nvar gotPromise = require('got-promise');\ngotPromise() // => Promise\ngot() // => Stream\n```\nOne line is not a huge benefit :dog:\nWe have promise wrapper around request and it was easier to use request inside promise wrapper, than installing another instance of it in project. Now with got this is not a problem anymore, so you are right.\n. @artems if you want to send headers is capital case - use rawHeaders option.\n. Let start from simple - split this PR: one for query, one for object as first argument.\n. Okay, could you squash commits, provide clear description of PR (what it does, why you need it - there are no readme patches to figure this out)?\n. I like idea of passing url.parse object as first argument - this will simplify usecase of wrapping got in other module, that already parsed url string. But this should now take so much code to implement.\n. @golyshevd problem is that it is not a few lines. Less code to maintain and debug is always better imo.\n. @sindresorhus @kevva @julien-f thoughts?\n. By the way, placing host in options will break readirects because of this line.\n. woot\n\nCan you open an issue about that?\n\n~~This is not critical at all I think~~ It is quite bad for query option, opened PR with failing test - https://github.com/sindresorhus/got/pull/54\n. Will break this use case:\njs\ngot('host.com', { host: 'newhost.com' }).pipe(process.stdout);\nBut not query option.\n. @sindresorhus any hints on readme patch with this?\n. > Can't we just throw on this? I see no sane reason why this should be supported. What even is the expected outcome if it were allowed?\n@sindresorhus I guess we can. Also we can:\n- drop this feature and don't do objectAssign at all. All 'bad' properties would be just ignored.\n- drop those properties on redirect (this will allow got(conf.host, {path: '/mypath'}))\nAs you say - there is no sane reason to do so, so probably there is no sane way to deal with it.\n. @sindresorhus which one?\n. @sindresorhus what do you think?\n. @sindresorhus needle ignores cookies on redirect by default and request will store them in global cookie jar which is not quite good idea (how can I clear it?).\nMost browsers will set cookies on 30x response, some sites are using this for authentication.\nI have found only one thing about redirects and cookies in RFC 2109:\n\n4.3.5  Sending Cookies in Unverifiable Transactions\nUnverifiable transactions typically\n   arise when a user agent automatically requests inlined or embedded\n   entities or when it resolves redirection (3xx) responses from an\n   origin server.\nWhen it makes an unverifiable transaction, a user agent must enable a\n   session only if a cookie with a domain attribute D was sent or\n   received in its origin transaction, such that the host name in the\n   Request-URI of the unverifiable transaction domain-matches D.\n\nSo we should set cookies, if it is safe to set it. This will be not easy feature to implement, I guess.\n. In fact we have two problems:\n1. Getting cookies from redirect response\n2. Setting new cookies to redirect request\nWhile first is easly solved with new redirect event:\njs\ngot('cookie.com')\n    .on('redirect', function (res) {\n        console.log(res.headers);\n    });\nSecond is not quite straightforward. May be in this event we could pass headers as second argument:\njs\ngot('cookie.com')\n    .on('redirect', function (res, next) {\n        next.headers.cookie = cookie(res);\n    });\nIn this case we will be able to move stuff about cookies (which I like to avoid) to userland.\n@sindresorhus @kevva what do you think?\n. @km256 there is response event for this. Isn't it enough?\n. @km256 about code - it could be more verbose, PR maybe?\njs\ncb = function (err, data, response) {\n    proxy.emit('error', err, data, response);\n};\n. Published in 3.1.0\n. Add checks on data and response here - https://github.com/sindresorhus/got/blob/master/test/test-http.js#L93\n. lgtm, sqash commits please.\n. This should be mentioned in readme too - https://github.com/sindresorhus/got#json\n. lgtm. sqash please.\n. Thanks!\n. @stevenvachon hm... I get this error only on iojs@2, but not in IOjs@1.8.2, Node 0.10 or 0.12. Also  only 127.0.0.1:0 host is throwing error, which is pretty strange.\n. It make sense in browser environment, but in node (if body is String) text/plain is more accurate (String is plain text, right?). I'm not sure about Stream thou - it can be binary/octet-stream by default.\nMaybe mention it in readme somehow (like - example how to send form data)?\n. @kevva maybe, if body is plain object, it makes more sense to setup content-type and stringify object for user?\njs\ngot.post('http://somesite.com', {\n    body: {\n        search: 'text'\n    }\n});\n. Notice RFC 2616 Section 4.4:\n\nIf a Content-Length header field (section 14.13) is present, its decimal value in OCTETs represents both the entity-length and the transfer-length. The Content-Length header field MUST NOT be sent if these two lengths are different (i.e., if a Transfer-Encoding header field is present). If a message is received with both a Transfer-Encoding header field and a Content-Length header field, the latter MUST be ignored.\n. @julien-f nice catch. url.format is not quite good at formatting I think:\n\njs\nurl.format({protocol: 'http:', host: 'localhost', port: 6767});\n// => http://localhost without port\nSo in error messages (that was generated from got with Object as first argument) we don't have port now. :(\nMay be it worth trying to replace url.format with some module?\n. @maxogden yeah, I stumbled upon this day ago, because got uses infinity-agent and it quite hard to configure defaultMaxSockets in it. There should be nicer way to configure got agent I guess.\nProblem with agent options is that got should decide when create new Agent instance and how reuse them. \n. For now I can think only of exposing infinity-agent globalAgent:\njs\nvar got = require('got');\ngot.globalAgent.http.maxSockets = 1;\n. @maxogden yup, since this not quite standard error event (multiple arguments) - it should be in docs. :+1:\n. Since got already have redirect event - may be it make sense to emit response on 'non-redirect' responses.\n. Side-effect: now you can specify got options in first argument:\njs\ngot({host: 'google.com', timeout: 2000});\n. Technically - blank response (at least with 200 status code) is invalid response.\nhttp://stackoverflow.com/questions/11970962/valid-json-in-response\n. @connyay I think it is expected behaviour never less empty string is invalid JSON. request is behaving something like this.\n@sindresorhus what do you think?\n. @sindresorhus a lot of endpoints do not send application/json content-type in json responses. This was main point of strict json option - to parse body in any case.\n@connyay could you do a 204 check instead?\nRelated: https://github.com/visionmedia/superagent/issues/255\n. @connyay cool! Can you squash it into one commit?\n. :beers:\n. @Flet caw it is, I guess.\n. @sindresorhus yep, already did it :smile:\n. @sindresorhus friendly ping :)\n. I feel like some more time should be spent on Errors (because of #86, #72 and https://github.com/floatdrop/create-error-class/issues/1), so new Errors will move to another PR.\n@sindresorhus thanks for kind words :sparkles: I really miss 80-lines version of got, so tried to simplify things as much as I can.\n. @sindresorhus nothing, except new Errors (https://github.com/sindresorhus/got/pull/88).\n. Something like this:\n``` diff\ndiff --git a/index.js b/index.js\nindex 44f453a..b4bafb6 100644\n--- a/index.js\n+++ b/index.js\n@@ -41,7 +32,7 @@ function requestAsEventEmitter(opts) {\n                res.resume();\n            if (++redirectCount > 10) {\n\n\nee.emit('error', new GotError('Redirected 10 times. Aborting.'), undefined, res);\nee.emit('error', new MaxRedirectsError(statusCode, {url: url}), undefined, res);\n                    return;\n                }\n\n@@ -70,7 +61,7 @@ function requestAsEventEmitter(opts) {\n        ee.emit('response', res);\n    }).once('error', function (err) {\n\n\nee.emit('error', new GotError('Request to ' + url + ' failed', err));\nee.emit('error', new RequestError(err.message, {url: url, method: opts.method}));\n        });if (opts.timeout) {\n\n@@ -101,22 +92,21 @@ function asCallback(opts, cb) {\nee.on('response', function (res) {\n    readAllStream(res, opts.encoding, function (err, data) {\n        if (err) {\n-               cb(new GotError('Reading ' + url + ' response failed', err), null, res);\n+               cb(new ReadError(err.message, {url: url}), null, res);\n            return;\n        }\n    var statusCode = res.statusCode;\n\n    if (statusCode < 200 || statusCode > 299) {\n\n\nerr = new GotError(opts.method + ' ' + url + ' response code is ' + statusCode + ' (' + http.STATUS_CODES[statusCode] + ')', err);\nerr.code = statusCode;\nerr = new HTTPError(statusCode, {url: url, method: opts.method});\n        }if (opts.json && statusCode !== 204) {\n    try {\n        data = JSON.parse(data);\n    } catch (e) {\n\n\nerr = new GotError('Parsing ' + url + ' response failed', new GotError(e.message, err));\nerr = new ParseError(err.message, {url: url});\n        }\n    }\n``\n. Done in 1fe1e9a - please review :smiley: \n. There is one question, that's bothers me: should we store statusCode ascodeproperty? It was discussed in https://github.com/sindresorhus/got/issues/9, but in other places people tend to usestatusCode((https://github.com/trentm/node-bunyan#log-record-fields, https://github.com/jshttp/http-errors).\n. @sindresorhus yup, I will send a PR with this soon.\n. Thanks! This bug fromread-all-streamand fixed in3.0.1version. Update please.\n. @ArtskydJ you perfectly right, test was added inread-all-stream- https://github.com/floatdrop/read-all-stream/commit/e3e4e904a55888d9f51b8f627cfc1850f087b1c4#diff-1dd241c4cd3fd1dd89c570cee98b79ddR90\n. I thought this would do forpathandpathname` https://github.com/sindresorhus/got/blob/master/index.js#L50-L52\n\n\n\n\n\njs\n    if (opts.pathname) {\n        opts.path = opts.pathname;\n    }\n. @julien-f I'm really thinking about standalone module for parsing and normalization.\n. This could be resolved, if we drop pathname support in options (since it not used in http.request and will not use url.format to create message (to avoid #72 regression).\n. This is relevant to - https://github.com/mdlavin/nested-error-stacks/pull/6\n. @sindresorhus @julien-f please review.\n. Full list of browserified modules: https://gist.github.com/floatdrop/acfb074b261288655e45\nTop of size-eaters:\n- ~~browserify-zlib is 173.3 Kb~~ f9f2807e63635432ab175824859caa70e3c583aa\n- duplexify is 64.9 Kb\n- buffer is 43.7 Kb\n. With 6.0.0 version got is almost same size as simple-get, but still 10x bigger than xhr.\n```\n\u276f browserify -r got | wc -c\n  207787\n\u276f browserify -r simple-get | wc -c\n  194566\n\u276f browserify -r xhr | wc -c\n  11147\n``\n. @sindresorhus done.\n. Landed in4.1.0:dancer: \n. Yeah, errors at point when you have two sequential errors (HTTPErrorand thenParseError) are hard to reason about, but I still think that it should beParseError`, but maybe with additional fields about status code?\nReason behind it - some API (like github for example) will send with 404 a JSON payload, which you should parse. If JSON payload is broken - this is quite different error.\n\nHappy to hear any suggestions about it.\n. How about add status and statusCode to PraseError?\njs\n{ [ParseError: Unexpected end of input]\n  message: 'Unexpected end of input',\n  code: undefined,\n  host: 'registry.npmjs.org',\n  hostname: 'registry.npmjs.org',\n  method: 'GET',\n  path: '/nonexistent'\n  statusCode: 404,\n  statusMessage: 'Not Found' }\n. @julien-f you get body in response.body or second argument in callback mode, it does not disappear on error.\njs\ngot('google.com/broken', {json: true}, function (err, body, res) {\n    // err is ParseError\n    // body is String\n    // res is Response\n});\nUser can easily add body to error in the callback.\n. @julien-f just like you said to do, add response to error - https://github.com/sindresorhus/got/blob/master/index.js#L114\n. @eush77 I don't like to concatenate (or modify) error messages - it can become messy in long time run.\n. @maxvipon JSON.stringify does not throw SyntaxError - JSON.parse does. Do you really need try...catch here?\n. @maxvipon no problems. If you want to guard against CircularReference, you can use json-stringify-safe.\n. Object in body is querystringified, not JSON-stringified (it is quite confusing, but that's how things go for now). Glad, that you make it :)\n. :+1: Thank you!\n. Fixed in 4.2.0\n. @sindresorhus I'm kind of against retry functionality in got, yet it come in handy from time to time. Here's why:\n- retry will add quite a few options - retryCount, retryDelay and etc...\n- Streams will not support this without buffering and be useless by default (if retry will be enabled by default)\n- Same as redirect, retry should be enabled only for GET and HEAD, right? Should it be configurable?\nSo it is kind of heavy feature and I believe, that retry should be added consciously by developer.\n``` js\nconst retry = require('retry');\nconst got = require('got');\nlet result = await retry(() => { return got('google.com'); });\n```\n. > The only point is to deal with network failures, not response failures\n@vdemedes then I misunderstood issue a little - in this case streams still can be in game. Cool :palm_tree: \n. @dylang yeah, errors in Promise API should be returned as rejected promises. Good catch :+1:\n. @Jakobud afaik you can't mix callback mode with stream mode.\njs\nfs.createReadStream(fileInput)\n    .pipe(got.stream.put(url, options))\n    .on('response', (res) => { });\n    .pipe(process.stdout);\n\nSuch questions are better asked at Stack Overflow\n. Boom :boom:\n. @Jakobud auth option in http module computer should work for you.\nAnother question, should we parse out id and pass from url.\n\nhttp module will break on this url too:\n``` js\nlet res = require('http')\n    .get('http://user:pa##word@google.com', function (){});\nconsole.log(res._headers); // => 'GET /:pa HTTP/1.1\\r\\nHost: user\\r\\nConnection: close\\r\\n\\r\\n'\n``\n. @Jakobud on second thought you can pass#, but you must use [encodeURIComponent`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/encodeURIComponent):\n``` js\nlet res = require('http').get('http://user:' + encodeURIComponent('pa##word')+ '@google.com', function (){});\nconsole.log(res._headers); // => GET / HTTP/1.1\\r\\nHost: google.com\\r\\nAuthorization: Basic dXNlcjpwYSMjd29yZA==\\r\\nConnection: close\\r\\n\\r\\n\n```\n@sindresorhus yes, username:password is deprecated by rfc3986, but this format is supported by Node url.parse method, so I don't see why we should explicitly forbid that.\n. @sbrl got does not have cookie support out-of-the-box, but it can be easly achieved with cookie module:\n``` js\nlet got = require('got');\nlet cookie = require('cookie');\ngot('google.com', {\n    headers: {\n        cookie: cookie.serialize('foo', 'bar')\n    }\n});\n```\nSee also:\n- tough-cookie\n- cookies\n. @sbrl I'd recommend make all requests to this service through new module (like gh-got or vk-got) and add default jar storage into it.\n. @sbrl shared instance of tough-cookie for example.\n. @techniq seems like problem on the combine-stream side. I can recommend multistream as replacement:\n``` js\nvar MultiStream = require('multistream')\nvar got = require('got')\nvar count = 0;\nfunction factory (cb) {\n  if (count > 3) return cb(null, null)\n  count++\n  setTimeout(function () {\n    cb(null, got.stream('https://www.random.org/integers/?num='+count+'&min=1&max=6&col=1&base=10&format=plain&rnd=new'))\n  }, 100)\n}\nMultiStream(factory).pipe(process.stdout);\n``\n. Thats because you dump all data toon('data', function () { ... }), this is not an issue withgot. Use [through2`](https://www.npmjs.com/package/through2) to peek into stream.\n. Try this:\njs\nstream = stream.pipe(through2(function (chunk, enc, callback) {\n    this.push(chunk)\n    callback()\n  }))\n. Response event in stream mode will be overridden by error. I think this is most simple thing to do.\n//cc @kevva \n. xo will be a kind of problem here - with esnext option it will forbid var statements in index.js, but without it async keyword in test is Unexpected identifier.\n. Thanks for feedback @jonasfj!\nRetrying ENOTFOUND can be useful, when DNS server is failing (for example in cloud environment, when DNS is used in service resolution). Any way we decided to not stick to the list of possible errors (because they can be even platfrom specific) and there is no definitive list of those.\n\nAlso if error code is 5xx retry is often the right thing. But that might something to specify as an option.\n\nYou can wrap got (as got-retry does) and specify custom logic for responses with wrong status codes. This is recommended way - it allows you to tune logic all the ways you can imagine :)\nStill we are open to discussion about retry functionality in got, because it could be improved, I think.\n. @techniq retrying streamed data is quite hard - because you can't resend already sent data from Stream (once it's gone - it is gone), unless you buffer it or part of it. So quick solution is to dump data into buffer (with get-stream for example) and use buffered data in body option.\n. @techniq okay, now I get ya. Yes, your variant is quite close how it can be done now, but I would recommend to go with PassThrough stream inside:\n``` js\nvar got = require('got');\nvar PassThrough = require('readable-stream').PassThrough;\nfunction streamRetry() {\n    var through = new PassThrough();\n    var trys = 0;\nfunction request() {\n    if (trys++ > 5) {\n        through.emit('error', 'Max retries reached');\n        return;\n    }\n\n    var stream = got.stream('localhost:8000')\n        .on('error', request)\n        .on('response', function () {\n            stream.pipe(through);\n        });\n}\n\nrequest();\n\nreturn through;\n\n}\nstreamRetry().pipe(process.stdout);\n``\n. @jonasfj since we now haveretriesas function, this issue can be solved just by passingerrtoretriesfunction here - https://github.com/sindresorhus/got/blob/master/index.js#L59\n. @jonasfj you can returntrue/falsevalues - in first case request will be retried in next frame, in second it will not be retried.\n. There is no configuration option for Stream mode - you just call.stream` method of got:\n``` js\n// Stream mode\ngot.stream('todomvc.com').pipe(fs.createWriteStream('index.html'));\n// For POST, PUT and PATCH methods got.stream returns a WritableStream\nfs.createReadStream('index.html').pipe(got.stream.post('todomvc.com'));\n```\nAnd it should work (because tests and stuff).\nMay be you are using old version of got?\n. Feel free to reopen, if this still a problem.\n. Pass encoding: null in options to get raw Buffer from got.\n. We don't stumble on such problems yet. If it is not fixing any use case, I'd rather wait on it.\n. @julien-f anyway thanks for pointing thing about undefined - it can be source of bugs. And I'm quite sure we will stumble on this in production use in some time ;)\n. > Is there any point in including the code prop when it's undefined?\nNope, this bugs me as well. Will do in separate PR.\n. @ncuillery @ThariqS does catch callback outputs something to you?\njs\ngot(url).catch(err => console.log(err));\n. This code works fine with browserify (tested on 6.0.0version):\n``` js\n// Workaround for setImmediate\nglobal.setImmediate = setTimeout;\nconst got = require('got');\ngot('/bundle.js')\n    .then(res => {\n        console.log(res.body.length);\n    })\n    .catch(err => {\n        console.error(err);\n    });\n```\nIt could be, that Promise/http polyfill is broken in browsers.\n. @kevva could you provide example of how you getting got into browser? Browserify?\n. You don't added catch - so error was ignored.\n``` js\nvar got = require(\"got\")\ngot('http://requestb.in/udvtb2ud', {\n    body: {\n        test: 'kevin'      \n    },\n    json: true\n}).then(function (response) {\n    console.log(response)\n}).catch(function (error) {\n    console.log(error);\n});\n```\n. @kevinsimper \n\n. @kevinsimper I don't quite get a problem. json option is used to parse JSON response from endpoint. Requestbin is always returning ok - which is obviously not JSON - so that is an error.\n. @sindresorhus what do you think about 0.12? It's not maintained long after 0.10.\n. @julien-f I don't quite get it. Getting stream is synchronous operation - why should we use await on it?\n. @sheakelly seems like https:// is missing in url argument. Could you provide example how to reproduce?\n. > This is showing that despite using the 'https' library a non-secure request is sent and github is redirecting to ssl. So I think you need to set the port to 443 explicitly\n@sheakelly why so? github is redirecting you to https endpoint.\n. @sheakelly that's strange, https.request docs says:\n\nport: Port of remote server. Defaults to 443.\n\nSo it should work fine (unless you specify port explicitly).\n\nThere are a few npm packages involved in this issue so I am a bit unsure which package should be patched.\n\nI think, that proxy setup is not right, so https://github.com/kevva/download/issues/85 is right place to discuss this.\n. @sheakelly modify your code to use location, that github retruned in redirect and you will get 200 response. If you replace require('https') to require('http') you will get 301 again (even with fixed location). I'm quite sure, that there is no error in http or https library and port is set correctly. Probably proxy setup is broken.\n. @sindresorhus that's one way. I found it very useful on wrong backends responses - if we decide to drop it - first line of broken input should stay in error message. \n. @maxvipon yes, something like this, I guess noise can be lower too. :+1:\n. @maxvipon ++ operator was moved before retryCount variable - https://github.com/sindresorhus/got/commit/54bd6f5bbad9590be6ffc7baf004c381bf1ea7a9#diff-168726dbe96b3ce427e7fedce31bb0bcR65 therefore delays will start from ~1s.\n. > Shouldn't it be 0 and not false?\n@sindresorhus maybe. Would it be confusing, if retries: () => 0 will disable retries? Wouldn't retries: () => false be more readable/expectable?\n. > Looks really good to me! When do we want to release this?\nThanks!  I'm thinking about rc version to test changes, but have no idea when to publish major.\n. \n. Seems like http polyfil is lacking some methods on request object. Hard to say without knowing your build steps.\n. It works with browserify@12 and got@6:\njs\nglobal.setImmediate = setTimeout;\nconst got = require('got');\ngot('/bundle.js', {timeout: 5000})\n    .then(res => {\n        console.log(res.body.length);\n    })\n    .catch(err => {\n        console.error(err);\n    });\nAt least I see setTimeout method here - https://github.com/jhiesey/stream-http/blame/master/lib/request.js#L248. If you are using different http module polyfill - you can try to open issue about setTimeout method there.\n. Something like this should work:\njs\nlet request;\ngot.stream('...').on('request', req => request = req);\nsetTimeout(() => request.abort(), 1000);\n. @julien-f my bad, request.abort() is right method for it.\n. @julien-f why so? We are emitting it on stream.\n. @sindresorhus already is.\n. @sindresorhus or you are talking about additional Aborting stream section in readme?\n. @julien-f because all other types are in lowercase.\n. @jenslind @SamVerschueren thanks! Fixed in 5.2.1.\n. Yes, but pipe response argument instead of this.\n. @julien-f it is working, but you right - race condition can happen and first couple of chunks can be lost.\n. Done. Published as 6.0.1.\n. Hm... Maybe 6.0.0 works, because of switch to duplexer2 from duplexify - but I'm not sure. Meanwhile you can look how download and download-status solved this problem.\n\nRelated #148 \n. @just-boris yes, released as 5.3.1.\n. Fixed in 5.3.1.\n. @sergeyt don't see any problems there, should be pretty straightforward.\n. General answer: request have rich functionality and if you are using it (for example HAR, proxies, OAuth) - you will need to use corresponding modules with got. For some of those we have code-snippets on how you can implement them.\n. @sergeyt tunnel package provides http/https Agent to use proxies, not to create your own. I guess http-proxy is what you are looking for.\n. May be same trick as in http2 issue can be applied here as well?\n. @ksladkov we behaving like request module in this case, because if server responded with headers - then it is alive and working. I don't think we should remove timeout on response body end - suppose you have long-polling server or just response body size can vary. \n. @ksladkov yup, some places in readme still need to be improved. Fixed in https://github.com/sindresorhus/got/commit/db420fbab9fe5c3c6fdbea3f19a32600e1f3c7b0\n. @SEAPUNK I would suggest use something like .timeout from Bluebird in case of Promise and something similar for Stream API.\n. @SEAPUNK there is a way, but only for Streams, you can join discussion about cancelation in Promise API in got here #211\n. @stevenvachon ~~maybe~~ this can be achieved through abort on response event.\n. @stevenvachon I'd recommend you to create a module (like gh-got), that incapsulates these calls to a broken server.\nFor now there is not way to cancel request in Promise API, so shortcut to abort method could be handy.\n. js\nconst got = require('got');\ngot('http://www.cian.ru/cat.php?deal_type=sale&metro[0]=14')\n  .then(data => console.log(data), err => console.log(err));\n@a-x- this code works for me on 5.4.0 and 6.0.0 and gives HTML in output.\n. @a-x- okay, got it reproduced. Please use got.head(...) or got(..., {method: 'HEAD'}) for now until this is fixed.\n. 5.4.1 and 6.1.1 released with fix.\n. @ruyadorno thanks for the nice issue and PR!\nAfter some thinking I'm quite positive, that got is not the best solution to proxy request from other server to client \u2013 got will decompress content and send broken response with decompressed content and content-encoding: gzip (if you just passing headers by).\nMay be it will be a better solution to use native http module instead?\n. Released in 5.6.0 and 6.3.0 :tada:\n. @sindresorhus how about merge this with maxRedirects option? For example -1 in maxRedirects will disable redirect following.\n. @sindresorhus yep, just an idea.\n. @sindresorhus @ruyadorno are we ready to merge this option?\n. @sindresorhus I don't have clear opinion on this right now \u2013 there are many things to consider: \n- Is current interface of got suitable enough for HTTP2 features?\n- What will happen to users, that bundle got to browser?\n- Will spdy module increase performance or not?\nBut I like idea and have service on sight, that could be ported to HTTP2 to test this.\nWhat I'm certain about - this should be major release :smile:\nI will take deep look into it on weekend.\n. json is intentionally non-conditional \u2013 some servers will not send application/json content-type even if they respond in JSON. If option is set to true it should always parse body.\n. > Most servers are compliant, though, and it would be nice not having to set the JSON option for those.\n@sindresorhus yes, but if server changes behaviour (or something with proxy in front of it) \u2013 worst case scenario is that header and content will change. got will get you plain string object and (depends on your code) it can be silently processed (strings have props, right?). In current case you will get ParseError immediately.\n@SamVerschueren this is possible (or I don't see something), but this is major change.\n. After some time thinking \u2013 I'm sure, that automatic negation is not useful (and can be harmful). Heres why:\nWhen I want to get parsed data from endpoint I must do two things \u2013 ensure, that endpoint is returning json (almost always this easy to see in docs) and ensure, that content-type header is in place. With strict options I can skip last part and just type json: true.\nAlso I must worry about 404/503 pages, which almost never contains json and spit HTML on to you (with text/html content-type of course). This leads not to ParseError, but to very strange behaviours.\nMay be we can figure out how to solve these issues and get automatic negation about content (json: 'auto' maybe as stated above). But this solution should be improved.\n. @birhoff can you fix the tip here too?\n. @birhoff oops :blush:\n. > Or is it out of scope?\nI think so. You can use Form data snippet \u2013 it is quite simple to use form-data with got.\n. @paglias it is possible, but json option is responsible only for toggle parsing response from server and it will be kinda major change to make it stringify the body for request also.\n. @sindresorhus now passing object literal in body work as serializing it as application/x-www-form-urlencoded \u2013 wouldn't it make json option a bit confusing?\n. @sindresorhus it is clear, that json: true will change behaviour, but not in obvious way \u2013 without it Object in body was serialized as form, but with json: true it morphing to JSON object, which is not expected in many usecases (for example API that accepts form in body, but returns JSON).\nMaybe it is better way to choose serialization based on content-type header?\n. eval is used in create-error-class to provide name to constructor. May be it can be achieved in other way or removed there. Can you reopen issue there?\n. @artoale fixed in create-error-class@3.0.1.\n@julien-f I don't remember, why I ignored this module :blush: Can you do a PR? \n. Dups https://github.com/sindresorhus/got/issues/141 - reopen if this issue is not the same \ud83c\udf34\n. @ralphholzmann more like this is due wrong http polyfill, that used by default in Webpack \u2013 I think you can use custom shimming to override this.\n. @sindresorhus I don't know, they quite same to me.\n. @sindresorhus to be honest, I have not yet used class in my code, so \u2013 dunno. I guess this is right decision, but looking at code in make-error it could have some bumps. \n@julien-f can you advise \u2013 how safe is to extend from Error class directly?\n. No worries, released in 6.1.2 and 5.4.2.\n. @sindresorhus what should we do with Stream body? We have internal discussion about it and found no other way to implement POST redirects with Stream body than always buffer it.\n. @sindresorhus just pointing this detail. request is not redirecting in case of POST, etc...\n. @sindresorhus hm... we don't change method of request on any redirect code atm, so 307 code should work properly now. Not sure about other redirect codes.\n. > What do you guys think about just relying on follow-redirects. I'm basically the sole maintainer now, so if there's something you don't like, you know who to bother \ud83d\ude04.\nI'm good with this \u2013 redirection logic becomes quite sophisticated and can be moved out to a module. But how redirect event will work with this module?\n\nAs for caching the stream: https://github.com/jamestalmage/caching-stream.\n\nThis is cool, yet dangerous thing to do. What if server does not reply immediately with redirect code and waits for all upload to be finished (checks contents SHA for example)?\nI would love to hear about use cases for caching \u2013 is this a common thing to handle?\n. Dups #291 \u2013 will be done there.. Yes, it should for consistency, because other errors have these fields.\n. I think statusCode and statusMessage should be mentioned in readme also.\n. @satazor can you run npm show got dist-tags? I'm pretty sure, that 6.2.0 is latest version (https://npmjs.com/got is showing that).\n. @aniinprni this is strange - retries: 0 must disable retries.\n\nYou can check this with this snippet:\njs\nconst got = require('got');\ngot('https://www.google.com', {\n  timeout: 100, retries: 0\n})\n  .then(d => console.log(d))\n  .catch(e => console.log(e.stack));\nWhich outputs (at least on my machine) after 100ms:\nRequestError: Connection timed out on request to www.google.com\n    at ClientRequest.<anonymous> (/Users/floatdrop/github.com/test-got/node_modules/got/index.js:66:21)\n    ...\n. @reconbot I think got tries to do some retries. Can you set retries options to 0?\n. @reconbot I don't have any suggestions about turning off retries in testing/development. And yes, defaults is kind of rough. Any ideas?\n. Hi @luanmuniz. Putting options in result can cause troubles, because this will force Node to keep body property in memory until all requests are processed. For example, if you sending many files to server with serial \u2013 you will run out of memory.\nCode you provided is a way to go, but could be a little improved:\n``` js\nrequestsPromise = PackofURL.map(thisUrl =>\n    got(thisUrl.url)\n        .then(response => {fullUrl: thisUrl.url, response: response})\n);\nreturn Promise.all(requestsPromise)\n    .then(allRequests => {\n        allRequests.forEach((thisRequest, index) => {\n            if(CheckURLForSomething(thisRequest.fullUrl)) {\n                Requester.doSomething(thisRequest.response);\n            }\n        });\n    });\n. #191 looks like a good edge case for this PR \u2013 what should be in `res.request`, when redirect encountered?\n. @sindresorhus \ud83d\udc4d \n. Implemented in #166.\n. `+ got@5.5.1`\n. js\nconst got = require('got');\ngot('todomvc.com')\n    .then(response => {\n        console.log(response.body);\n        //=> '<!doctype html> ...'\n    })\n    .catch(error => {\n        console.log(error.response.body);\n        //=> 'Internal server error ...'\n    });\n```\n@sschuberth example works for both 5.x and 6.x. Please check got version and that you do not use caching npm proxies (or have function got() in scope :smile:).\n. @sschuberth Promise API was introduced in got since 4.x, please update package.\n. @sschuberth this is actually a bug in example. Thanks! Fixed in https://github.com/sindresorhus/got/commit/67ee190881f4ba9c498708dc41c1d71c5b6039a2\n. @sschuberth I think this is because todomvc.com is not supporting POST method :)\n. You can't capture exceptions with try...catch in callbacks - you can only check for error argument in callback (callback will be called either way).\ntry...catch will work thou, if you using async/await or yield with co for flow control:\n``` js\nconst co = require('co');\nco(function * () {\n  try {\n      yield got('google.com');\n  } catch (err) {\n      // Oops\n  }\n});\n``\n. @dragonfish-au from stacktrace I see, that error comes not fromgot, but fromdownloadpackage (at onetime (//node_modules/onetime/index.js:15:11)). As far as I know \u2013 all errors fromgotcan be captured either in Promise orerrorevent in stream mode (unless version ofgot` a bit old).\nCan you provide example code to reproduce it?\n. @cyounkins yes, but they should be updated from time to time.\n. @satazor yes, this is how things work now. As readme says:\n\nNumber of request retries when network errors happens.\n\nRetries will be applied only when network error happened. You can read this thread about retry feature.\n. @satazor you can look at this comment about caching streams (esp. https://github.com/jamestalmage/caching-stream) \u2013 it could fit your needs.\nClosing this for now, since it can be done in wrapper.\n. @DimitryDushkin we have test on this case, can you post a code, that reproduces this problem?\n. We have a lot of files, that just export got with default values. I would love to see a package got-api with some sweet stuff for generating cool API wrappers.\n. :+1:\n. @alex-phillips listening on stream returned form got will get you data from server, not uploaded chunks. I assume your endpoint is not answering anything, until upload is finished.\nTry to listed data event on stream, that you put in the stream option.\n. @alex-phillips yes, you can use promises with streams (and you do not need request object to get uploading progress) \u2013 just pass stream to body option:\n``` js\nconst stream = fs.createReadStream('');\nstream.on('data', chunk => console.log(Uploaded ${chunk.length} bytes...));\ngot.post('', {\n    body: stream\n}).then(res => {\n    console.log(Upload finished (${res.statusCode}));\n});\n``\n. @alex-phillips p.s. please, remember to callgotin same tick with.on('data', ...)`. Otherwise you can lose first chunks of data.\n. Fixed upstream.\n. I believe this code should catch such errors (and we have similar test).\nAlso this test is green:\njs\ntest('invalid url', async t => {\n    got('htttp://google.com').then(t.fail).catch(err => {\n        t.regex(err.message, /Protocol .+ not supported/);\n        t.pass();\n    });\n});\nCan you make a PR with failing test?\n. > maybe it's ok to throw synchronously since this method does not return a promise?\n@satazor I think so.\n. (I was writing long answer, but my browser crashed)\nLong story short: it is quite a hard problem to merge Stream API with Promise API. Mostly because Promises are lacking of cancel and progress features.\nThere is a discussion about aborting requests in fetch library (that ends up in cancelable promises proposal), so we could look in this way.\n. @bisubus I see positive side in this \u2013 you should explicitly set fields, that you are sending.\nP.s. why you are passing result of querystring.parse to body? Why not just pass query as is?\n. > makes a text/plain request and not application/x-www-form-urlencoded, not a very good thing for POST request (maybe a subject for another issue?)\nThis is right behaviour, if you pass String to body. Maybe we should move from is-plain-obj to is-obj.\n@bisubus mind to make a PR?\n. @pahud it is recommended to listen on data event to get data:\n``` js\n'use strict';\nconst got = require('got')\nconst url = 'http://requestb.in/1234gpr1'\ngot.stream( url )\n .on('response', resp=>resp.on('data', chunk => console.log(chunk) ))\n// or\n// got.stream( url ).on('data', chunk => console.log(chunk));\n``\n. @hustcer it could be related to #223 \u2013 try to listen on returned stream fromgot`:\njs\ngot.stream( url ).on('end', () => console.log('Ended'));\n. @luanmuniz lgtm, thanks :star:\n. @MarkHerhold ETIMEDOUT error is whitelisted for retrying \u2013 so setting retries: 0 fixes your issue.\n. @pasupulaphani can you tell, what is expected? I've tested this with added console.time and it gives me 1015.766ms before firing error.\n. @parro-it got is following redirects without exceptions (unless there are less than 10 redirects) with followRedirect enabled. If you wish to process 3xx response, you can disable followRedirect option, but still there will be no exception.\nCan you post got version and exception?\n. @parro-it it should work, we have test case for it.\nOrder in ternary-if is correct, because all codes that are greater than limitStatusCode should cause exception. In case of false in followRedirect - all codes that are greater than 399 should throw exception.\n. @parro-it yes, redirects for POST requests are forbidden by specification (and since you can pass Stream in body).\n. @sindresorhus test on this would be nice \ud83e\udd84\n. @bisubus thank you! :tada:\n. > Especially since in @2.0 the getHeaders function may have a deprecation warning.\nOkay then.\n\nLGTM when #220 (comment) is fixed. @floatdrop ?\n\nLgtm. Waiting for https://github.com/sindresorhus/got/pull/220#discussion_r77452874\n. @sindresorhus yeah, maybe I'm exaggerating things, but fact is \u2013 most of questions about got in Jabber is resolved by telling people about retries. If you know about it, it is never an issue, but if you don't \u2013 it takes quite amount of time to figure it out.\nMaybe docs improvement will help, maybe reducing retries. Maybe both.\n. @sindresorhus I would go with reducing retry delay time from exponential to constant (and default retries set to 2), because requests likely land in different backend (clouds and stuff). What do you think about this?. @sindresorhus for now we use this formula for calculating delay between retries \u2013 it grows exponentially. If server is not responding, we will wait 1, 2, 4, 8, 16 seconds (w/o adding timeout time). It sums up to half a minute waiting on dead service. If user set timeout to 100ms \u2013 isn't it expected to run about a second with 5 retries?\nIn other hand, backing up retries can reduce traffic amplification, when something goes wrong and all services start retrying endpoint.. This is because input and output streams, that returned from got is not piped anywhere and get stuck'd with filled buffer. In this situation node prefers to exit (even if there is stream, that can consume data).\n. I guess we can copy res properties and emit output stream here instead.. @sindresorhus maybe, but it was not backported to 4.x branch. So somewhere in the future.\n. Dups #257 \u2013 will be resolved there.. \ud83d\udc4d \n. @Jakobud yes, until got have an response object it can not assign it to error. In timeout case \u2013 there is no response by definition.\n. I saw nice trick in aggregate-error \u2013 we can make url an iterable with toString method that get last url. But this will be surprising for some people, I guess.\n. @kevva I think #230 covers this case, it just not released yet.\n. @kevva thanks!\n. @jewelsjacobs you can look, how retries implemented in got source code.\nFirst argument in callback is current number of retries, that happened before this callback, so you can just check it's value:\n`` js\noptions.retries = function(retry, error) {\n    if (retry > 5) {\n        // got promise will be rejected witherror`\n        return 0;\n    }\nreturn 2000;\n\n}\n``\n. Closing in favor of #222 \n. I see1.0.2innpm show unzip-response`:\n\u276f npm show unzip-response\n{ name: 'unzip-response',\n  description: 'Unzip a HTTP response if needed',\n  'dist-tags':\n   { latest: '2.0.1',\n     '1.x-branch': '1.0.2' },\n  versions:\n   [ '1.0.0',\n     '1.0.1',\n     '1.0.2',\n     '2.0.0',\n     '2.0.1' ],\n  maintainers:\n   [ 'sindresorhus <sindresorhus@gmail.com>',\n     'floatdrop <floatdrop@gmail.com>' ],\n  time:\n   { modified: '2016-11-01T08:28:04.401Z',\n     created: '2015-07-18T16:32:28.789Z',\n     '1.0.0': '2015-07-18T16:32:28.789Z',\n     '1.0.1': '2016-09-06T13:46:49.405Z',\n     '2.0.0': '2016-09-06T13:55:25.954Z',\n     '2.0.1': '2016-09-06T18:43:08.276Z',\n     '1.0.2': '2016-11-01T08:28:04.401Z' },\n  homepage: 'https://github.com/sindresorhus/unzip-response#readme',\n  keywords:\n   [ 'http',\n     'unzip',\n     'zlib',\n     'gzip',\n     'deflate',\n     'incoming',\n     'message',\n     'response',\n     'stream' ],\n  repository:\n   { type: 'git',\n     url: 'git+https://github.com/sindresorhus/unzip-response.git' },\n  bugs: { url: 'https://github.com/sindresorhus/unzip-response/issues' },\n  license: 'MIT',\n  readmeFilename: 'readme.md',\n  version: '2.0.1',\n  engines: { node: '>=4' },\n  scripts: { test: 'xo && ava' },\n  files: 'index.js',\n  devDependencies:\n   { ava: '*',\n     'get-stream': '^2.3.0',\n     pify: '^2.3.0',\n     rfpify: '^1.0.0',\n     xo: '*' },\n  xo: { esnext: true },\n  gitHead: '71858052fe94b89678d14ba54e8e96cacbda92c3',\n  dist:\n   { shasum: 'd2f0f737d16b0615e72a6935ed04214572d56f97',\n     tarball: 'https://registry.npmjs.org/unzip-response/-/unzip-response-2.0.1.tgz' },\n  directories: {} }\nWhich version of got you are using? Maybe you are using caching proxy or private registry?\n. @mmcbride1007 @squarejaw future testing was added in 6.6.2 \u2013 should work on 4.x now.\n. @tommytroylin replaced process.version with future testing \u2013 we prefer to keep process variable out of code, because it will be shimmed in browserified version of got. Thanks for PR \ud83c\udf89\n. @zeke you should add error handlers in both places (after stream and extractor), because thats how streams in Node.JS works.\n. @zeke added some tests for piping \u2013 they pass.  Error handler usually do not have return value.\nMay be you should not gunzip stream from got, because it will be gunzipped (if server sends valid content-encoding header).\n. @AlexTes @fritx there were problems with Node 7 at these version, so we put restriction in package.json, unfortunately I do not remember what exactly were broken.\nIt is recommended to upgrade onto 6.x branch, because some critical fixes landed there and 5.x branch is not maintained anymore.. @lukechilds got treats redirects as errors only on POST-like methods, otherwise it will follow redirect location (up to 5 redirects before throwing error). Can you post code to reproduce problem?. @lukechilds yup, you right \u2013 304 case will be treated as error. But error does contains headers under response property:\n\nIn Promise mode, the response is attached to the error.\n\nSo you can check for statusCode or response.headers in error object.\nMaybe it is better to make this case valid and not throw error thou (if you do not care about redirects, you can achieve this by disabling followRedirects option).. @lukechilds response property is hidden from console.log (because it is huge and spamming logs is bad). Try:\njs\n.catch((err) => console.log(err.response)). @lukechilds it should point on line 115 \u2013 maybe in /Users/lukechilds/Dev/oss/onionoo-node-client/node_modules/got/index.js data handler is on 114 (because local version can differ from master branch).. @lukechilds maybe, I'm still thinking about it. @sindresorhus what do you think?\nAlso this will be a major change and could be published only in 7.0.0 version. . @reconbot you can't rely on response = e.response \u2013 304 will not contain response you expecting to get in return from updateContent.. @sindresorhus yeah, it can be removed now. Tests were failing without it on 0.10/0.12 I think.. @ReklatsMasters sweet! Can you add Node 4.4.4 in .travis.yml to verify missing method case?. > I don't care for the comment I added. If you feel the reason is clear, I could remove it.\n@AlexTes Yeah, tests should be descriptive by themselves. \ud83d\udc4d . @yanivefraim we can, but I don't see default timeout in popular libraries (like request or axios). May be #203 is what you are looking for?. @yanivefraim okay, can you open issue in npm-name as well? It more likely, that timeout lands there first.. @AlexTes timeout option in Node is for connection timeout. For whole body timeout there is p-timeout and for response timeout it will take a few lines more, but we never used in production this case, so I considering it not popular.. On second glance \u2013 timeout option is for socket timeout in Node, but there is no option for connection timeout.\nI propose add separate option connectionTimeout.. > When will you ever need to set the connection timeout manually?\n@sindresorhus quite often, actually. Connection timeout is very handy, when we have network outages between data-centres and need to retry request on reachable backend.\n\nIs it really necessary to have that distinction?\n\nThey are quite different things and often confuse beginners. I'm good with setting timeout option for whole request timeout, but keep socketTimeout and connectionTimeout tuneable.. @shangxinbo such questions are better asked on stackoverflow \u2013 http://stackoverflow.com/a/17637900. @rightaway can you post code snippet, that reproduces error?. @ryderlee it is an error, if you specify body option or making POST request.. @ryderlee by HTTP specification browser (or client library) should ask user for resending POST body on redirects. got does not client interface to do this, so this considered an error.. Why not pass those dummy values to ParseError in test?. @sindresorhus sure,  this will be handy.. Problem is - you start sending res before response. res should explicitly wait for response event and only after call send.. > Also I don't get the part only after call send what does it mean ?\n@quocnguyen res.send sends headers and body (so does s.pipe(res)) and this is cause of error.\nThis code looks fine, can you post example, that reproduces that problem?. @Spy-Seth it is better to add them to flow-typed. See https://github.com/sindresorhus/ama/issues/439. @sindresorhus let's do this \ud83d\udc4d. @sindresorhus lgtm.. @sindresorhus @AlexTes we should implement it, if rfc says so. \ud83d\udc4d\nThere were an idea to switch to follow-redirects module, but it does not support 303 and 308 codes too. . @sindresorhus should we wait for #281 in 7.0.0?. @sindresorhus looks like it is time to ship. Should something be fixed before?. We should add a note about parsing error policy, I guess.. Regarding multiple choices in redirects \u2013 I never met this in real life. I would take location header and go with it, until issues comes up. . @djmadeira \ud83d\udc4d . @djmadeira nah, timeout is ok, I have fallen out of context a bit.. got.stream should support retries, because it reuses requestAsEventEmmitter code. Yet after body content is piped into stream no retries will be applied on stream errors.\n@sindresorhus should we cache streamed body to allow retries?. I mean, that content will be resent from beginning, if something goes wrong. In case of input streams it mesns we should save what we have sent somewhere.\n\u041e\u0442\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u043e \u0441 iPhone\n\n27 \u043c\u0430\u044f 2017 \u0433., \u0432 17:49, Sindre Sorhus notifications@github.com \u043d\u0430\u043f\u0438\u0441\u0430\u043b(\u0430):\nshould we cache streamed body to allow retries?\nYou mean so it can continue where it left off in case the connection is broken in the middle of a request? Is that even possible? Or am I misunderstanding?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. @sindresorhus what do you think?. Response is there, but property is not enumeratable \u2013 https://github.com/sindresorhus/got/blob/master/index.js#L327 (to not bloat output).\n\nCheck the response property (as readme suggests).. Lgtm. @sindresorhus can we issue a patch with this fix?. Yes.\n. Because it will attach timeout only when socket is created, but it can take more time, that expected. request does both. Should we do the same thing?\n. Done\n. GET is default for method in options - http://nodejs.org/api/http.html#http_http_request_options_callback\n. Fixed. Thanks :+1: \n. I should add server to tests, that will check method.\n. @sindresorhus this is neat feature, but implementation is not quite clear to me.\nSince all HTTP requests can have body, should we wait for content in this case?:\njs\ngot('http://somewhere.com');\n. So it should somehow now, that in this case req.end() should be called. But afaik got does not have this knowledge in his frame.\n. To be clear, in this case got should not call req.end() inside:\njs\nstream.pipe(got(/*...*/))\nBut in this, it should:\njs\ngot(/*...*/);\nOr user should always do this: got(...).end() which is not nice.\n. Now we have use cases like this (from readme):\n``` js\n// Stream mode.\ngot('http://todomvc.com').pipe(fs.createWriteStream('index.html'));\n// Therefore got('http://todomvc.com') call by itself is valid btw.\n```\nIn this case got calling req.end() inside, but if we want this to work:\njs\nstream.pipe(got('http://todomvc.com')).pipe(fs.createWriteStream('index.html'));\nWe should not call req.end() inside, right? At this point got can't determine this inside (or I missing something).\n\nP.s and there is this edge case, which is troublesome too:\njs\nstream.pipe(got(/*...*/, function () {}));\n. @sindresorhus I think we should leave it for next version thou. Seems like they restricting this feature to POST and PUT requests - if method is PUT and POST and callback is omitted - they will not call req.end().\n. Okay, but why exactly stream support should be removed?\n. Done.\n. Fixed.\n. Yes, it should be supported, but I almost never seen it irl.\n. I'm only worried about this - ca option should be passed to tls.connect, but it does not.\n. Node https.js has this code to achieve this:\njs\n  if (typeof options.agent === 'undefined') {\n    if (typeof options.ca === 'undefined' &&\n        typeof options.cert === 'undefined' &&\n        typeof options.ciphers === 'undefined' &&\n        typeof options.key === 'undefined' &&\n        typeof options.passphrase === 'undefined' &&\n        typeof options.pfx === 'undefined' &&\n        typeof options.rejectUnauthorized === 'undefined') {\n      options.agent = globalAgent;\n    } else {\n      options.agent = new Agent(options);\n    }\n  }\nShould we port this logic as well? It's, kind of, sucks.\n. fixed\n. Try'd to reword this, but still sounds weird.\n. done\n. done\n. done\n. This fixes erasing nested property, when GotError is nested in GotError.\n. So got() is valid now?\n. > got([url][, options][, callback])\nI don't think this is a good API. \n. opts.headers.accept = opts.headers.accept || 'application/json';\n. wil -> will\n. :+1: \n. Fixed a little bit - but still can be wrong/confusing.\np.s. This agent tuning does not affects compatibility (it will work on 0.10) - but, in some cases, performance.\n. I thought it was nice to read - return as callback, but to keep things consistent :+1: \n. To pass them to callback, I guess... :dog: (fixed)\n. It will copy internal fields and break unzip stream. Maybe turn it to a module?\n. :+1: \n. :+1:\n. They assigned to Error object as properties.\n. Okay, but what's the difference?\n. @sindresorhus about this - code contains class of Error in Node (like ETIMEDOUT or such) and in other places status of response/request stored in statusCode property (https://github.com/trentm/node-bunyan#log-record-fields, https://github.com/jshttp/http-errors and so on). Let's discuss it in #83.\n. Is this check belongs here? Why not in normalizeAgruments (redirect can return unix socket in headers?)?\n. Dunno. auth option makes more sense.\n. ETIMEDOUT and ESOCKETTIMEDOUT is from timed-out, EAI_AGAIN from issue. Is there definitive list of those?\n. > I think we should start using the promise interface as default for new tests. It makes the test a lot simpler.\nYup, it looks way better. I guess this would be in a separate PR.\n. Yes. I think there must be a way to disable retries.\n\nImagine script, that fetches lots of url's from unstable source (that can just freeze on some requests).\n. On second though, we should retry on any error in error handler of http.request. There also ECONNRESET and ECONNREFUSED that will occur, when remote server is restarting.\n. ok\n. Should !opts.headers['transfer-encoding'] be opts.headers['transfer-encoding'] === undefined then too?\n. Node.js 0.8.29 have this method - so it is safe to use.\n. Didn't know that, but I feel, that this way it is clearer why this code is here, compared with Object.defineProperty(err, 'response', {value: response}); - someone definitely will PR err.response = response; :smile:\n. I'm agree @sindresorhus \u2013 if status code is 204 we should not try to parse body, even if there is one.\n. Can you add a test with object {host: s.host, port: s.port} as argument?\n. @luanmuniz this will remove line breake before Default. You can see it in md preview.\n. @luanmuniz yup.\n. Won't res.requestUrl = urlLib.format(opts); suffice?\n. content-type is not the only header, that can be returned from getHeaders function. This line should contain call to getHeaders and assign user supplied headers over it.\n. Is typeof body !== 'funciton' is necessary? Looks like isPlainObj(function() {}) returns false.. options.body must be a plain Object when options.form or options.json is used. opts.method should be uppercased in this if-branch too.. Can we use p-timeout here instead?. Left over?. You should check for undefined here explicitly.. ",
    "shaunc": "Is there any way to get response.body as a buffer if you want it that way? Seems even with {encoding: 'binary'} response body is string. Or do you have to use stream?. ",
    "radum": "@floatdrop both node-tunnel and tunnel-agent work just fine, but my problem is not with got missing proxy support is with all the other modules using got and not implementing proxy support.\nI've already had this conversation some time ago with @sindresorhus (https://github.com/kevva/download/pull/13) and as he pointed out making every module downstream care about it doesn't work in real life because they suck and nobody cares about them but they are here to stay so IMHO I think proxy support should be handled by the low level modules that are actually doing the work.\nNow HTTP(S)_PROXY env vars are fairly common and most of us are using them as a standard across all major OS. As an example I think bower had the same issues a long time ago and is using those env vars to make the requests as do many other modules anyways.\n. Yeah the entire thing it's broken everywhere I know because I'm behind one and it's a pain everyday.\nPython guys have done it also for their request version http://docs.python-requests.org/en/latest/user/advanced/#proxies as for Node, it should be part of core IMHO. Thanks for the alternatives and the doc update anyways.\n. ",
    "vvo": "\nI do wonder why Node can't just use the system proxy settings.\n\nNow it's time to tackle this issue for good! :-)\n. ",
    "shinnn": "https://github.com/iojs/io.js/issues/1490\n. :+1: \n. https://github.com/kevva/download/issues/85 is fixed.\n@sheakelly Can you try download v4.4.2?\n. Will be fixed in the upstream project. https://github.com/mikeal/tunnel-agent/pull/15\n. Duplicate of https://github.com/sindresorhus/got/issues/241\nUse 4.5.0 or newer.\n. ",
    "kevva": "statusCode is what I meant ;p. But code is probably better. Don't know what others are using or if anyone is actually setting a custom property. Most authors probably just returns the status as the error message.\n. data is unreadable if there's an error. If you remove the status check you get the correct data though.\n. lgtm.\n. https://github.com/jshttp/statuses\n. :+1: I like it.\n. @floatdrop, by using https://github.com/dominictarr/JSONStream.\n. Yeah, haven't had a chance to look at it myself, but I agree we can leave this option for streams to future versions.\n. @floatdrop, any suggestion on where to put it? We aren't documenting any other events.\n. @floatdrop, alright, fixed!\n. :+1:\n. > Auto-stringifying seems to me much more dangeuros, than one line in got call.\n+1\n. Great work!\n. Give a compelling reason for why you want to do this other than that you want it.\n. :+1: for me. If we were to allow redirects for other methods we'd do that through an option I guess.\n. :+1:\n. :+1: Great idea.\n. They have a form option https://github.com/request/request#applicationx-www-form-urlencoded-url-encoded-forms.\nWhen thinking of it, maybe it makes sense to keep the defaults as they are. Form submission in a node environment might not be the top use case for POSTs (although it's kinda weird having to define when used in a browser environment).\n. cc @floatdrop @julien-f @arthurvr @shinnn\n. @floatdrop, yes, that'd be really useful.\n. Might be worth documenting, even though the error event is kinda standardized when using streams. But yeah, the additional arguments would be a counter point to not documenting it.\n. I created a module for this, but didn't get the tests passing IIRC. I'll try finishing it asap.\n. Yup, haven't been able to check if it's working correctly though.\n. If you look at https://github.com/koichik/node-tunnel, do you see something there that might fix it?\n. I'm not sure why this wouldn't work:\ngot('http://github.com', {\n    agent: caw()\n});\nAnd to address @alexpaluzzi issue, you don't have to set the NODE_TLS_REJECT_UNAUTHORIZED env flag. Just pass rejectUnauthorized: false to got.\n. Is there any differences from https://github.com/kevva/caw? Could really use a PR if you notice anything that can be improved upon.. Yup, I like it too. +1 for more clarity.\n. @sindresorhus, they recently added better support for streams too for browsers that supports it. https://github.com/substack/node-browserify/blob/master/changelog.markdown#1100.\n. https://github.com/sindresorhus/got/commit/66542fd92b95fbcb4be9550850a59aa557f33465 reduced the size from 471 KB to 268 KB, thanks @mattdesl.\n. Yup, exactly what I had in mind. Good job as always :).\n. :+1:\n. Yup, using got in the browser is no biggie to setup. I think the worst part is getting the tests to run.\n. :star:\nGreat job!\n. > Problem of the first approach is that the content will be downloaded to ram, making it a problem for big files.\nThat's why we have to streaming interface. Promises usually resolves when the operation is done.. All tests passes using 6.8.0 so I guess it doesn't have any direct implications.\n. @sindresorhus, done.\n. > Can you guys advice a good way to write a test that simulates a timeout when accessing a url?\nhttps://github.com/node-nock/nock#socket-timeout is probably the easiest without having to write a lot of boilerplate yourself.\n. We only set url when there are redirects. Maybe we should stay consistent and always add it @sindresorhus @floatdrop?\n. @floatdrop, nah, that's only requestUrl. He want the final URL that we set here. It's not that useful when there aren't any redirects but API-wise I think it's better to be consistent anyway.\n. Done.\n. I'm using this in the browser without any problems using babel-runtime and babel-plugin-transform-runtime but I've used set-immediate-shim in the past by doing window.setImmediate = require('set-immediate-shim');.. @transifex3, that's better asked on StackOverflow. I.e. \"how to use node modules in React Native\". Also try searching for answers on Google. There's https://github.com/staltz/react-native-node too.\nGoing to close this issue in favour of https://github.com/sindresorhus/got/issues/128.. You need to chain them:\njs\nrequest\n    .then(res => {\n        console.log(res);\n    })\n    .catch(err => {\n        console.log(err);\n    });. The following code will also result in a unhandled rejection:\n```js\nconst p = new Promise((resolve, reject) => {\n    reject(new Error('This is so much error'));\n});\np.catch(err => {\n    console.log(err);\n});\np.then(() => {\n    console.log('resolved');\n});\n``. UglifyJS doesn't support minifying ES2015 code. If you use Webpack, check out [babel-engine-plugin](https://github.com/SamVerschueren/babel-engine-plugin), which transpiles only the dependencies that needs to be transpiled and then UglifyJS shouldn't have any problems.. ![](https://media.giphy.com/media/CkqpoOOS0BCQU/giphy.gif). Maybe mentioning thejsonoption in some way. It's pretty neat imo.. LGTM \ud83d\udc4d . Is it worth adding a test for this maybe? Could use https://www.npmjs.com/package/brotli.. How do we decompress thebrcontent? Seems likezlib(which we are using indecompress-response) [doesn't](https://nodejs.org/api/zlib.html#zlib_class_zlib_unzip).. Yeah, but I mean when usinggotand you try to fetchbrencoded content, it wouldn't be decompressed ifdecompressistrue. We're only handlinggzipanddeflate` I think. Not that it affects this PR, but it might be worth handling it?. The module I linked further up should handle it without native deps I think, https://github.com/devongovett/brotli.js.. Yup, I'll work on a PR, but I'm willing to sacrifice performance over native deps tbh depending on the impact.. Sounds valid to me.\n\nor test both isPlainObject || isArray?\n\n:+1:. Can you log err.response.body? Looks like it's something wrong with your request body.. Yes, it's res.redirectUrls.. I Node.js v8 you have to use res.req.getHeader(name) or res.req.getHeaders(). See https://nodejs.org/dist/latest-v8.x/docs/api/http.html#http_response_getheader_name for more info.. There are plenty of closed issues about this already https://github.com/sindresorhus/got/search?q=package+json+webpack&type=Issues&utf8=%E2%9C%93. If the suggested solution doesn't work, I'd say it's something wrong with your configuration, or in ionic-app-scripts. This seems like it could cause it https://github.com/ionic-team/ionic-app-scripts/blob/master/config/optimization.config.js#L13-L15.. > But let me ask, what is so important with using the shortcut version without the filename? Is there a advantage?\nThere's no real reason to include the extension because of Webpack not being compatible with Node.js.. https://github.com/sindresorhus/got/search?q=package&type=Issues&utf8=%E2%9C%93.. In what environment? And what error does it give you?. > Either that or there's there's a bad initialization of opts.useElectronNet or process.versions.electron because it requires it anyway. I am personally not using electron and have an issue with it.\nWe assumes that if process.versions.electron is true that you're in a electron environment and therefore it shouldn't be added as a dependency. In @andreygmc case it looks like he's using electron though but that something failed within it.. We have a test for this here https://github.com/sindresorhus/got/blob/master/test/post.js#L72-L78. How do you parse it in the API?. Works fine for me.. The response body is still available on err.response.body:\ngot('http://service.unavailable').catch(err => {\n    console.log(err.response.body);    \n});. https://github.com/sindresorhus/got/issues/371#issuecomment-328633307. No worries :). It's easy to overlook sometimes, but it's in the usage section.. Could you post the error?. I think his code should work. When writing to got.stream the data gets posted to the URL and the response is then piped. We've one example in the tests https://github.com/sindresorhus/got/blob/master/test/stream.js#L50-L55.\nLooks like .pipe(ctx, res) should be inside the last ) though.. > or i can only set the headers manually?\nYes, you'll have to set them manually. got doesn't get them from the input stream.. Yes, it will. It's just the headers from the incoming request that doesn't get applied (I think).. Yes, if you do a POST, PUT or PATCH it'll return a Duplex stream, otherwise it's just a Readable. It's documented here. And the code is here.. Have you checked err.response.body?. > Why isn't part of Promise interface?\nBecause events are mostly used when working with streams.. > This also slightly improves the code readability.\nAmazingly much.. > Do you think it would be worth mentioning create-test-server here?\nMight be. I think their use cases are a little different. E.g. I would use nock for mocking real API requests while I would use create-test-server in other cases where I'd just need a server.. Doesn't this describe exactly what the previous sentence does?\n\nIf null, the body is returned as a Buffer.. Could you add a test for this?. > I've also added some files to work on VS Code on Windows. I can remove these if you want.\n\nYes :).. Could you add a test for this also?. This could probably be anonymous since it's not reused.\n. Get rid of this line break.\n. hm, yeah, thought it was kinda self explanatory, but we can keep it!\n. - :)\n. ``` js\n}\ncb(err, data, response);\n``\n. Missed this, but it should be defined at the top along with the other core node modules.\n.headers.accept. One line too many.\n. You don't need to check forjsontwice (you're in anifstatement).\n. Destructuring isn't supported in Node.js 4. Also, use camelCase instead of snake case.\n. Don't need aelse ifhere, just do a newifblock.. Usefor...ofinstead.. Should probably clarify that these can be used with thePromiseinterface too. It's a little ambiguous now since they're documented undergot.stream`.. ",
    "pnemade": "I am packaging this in Fedora and we have a policy whereby we need to ask upstream to also provide license text to make sure what license tag is in the source matches the license text.\nThanks sindresorhus for accepting this request. \n. ",
    "feross": "simple-get only has a maxRedirects option by chance. It's really an implementation detail of how redirects are handled. Whenever a redirect is encountered, the module recursively calls itself, decrementing the maxRedirects option by 1.\nI could just have easily made it private, but left it exposed in case someone cares to use it. I should probably remove maxRedirects from the example code in the readme since I agree with @sindresorhus that no one is likely to use it, and those who wish to can read the source to discover the option, or simply use request :)\n. ",
    "silverwind": "I use the pem module for this in another project, like this:\njs\nrequire(\"pem\").createCertificate({ days: 365, selfSigned: true }, function (err, keys) {\n  // keys.serviceKey = private key\n  // keys.certificate = certificate\n}\n. auto-tunnel looks promising. From a quick look, it seems to supports NO_PROXY which I think caw does not. I'd suggest to clean up the code and push a 1.0.0 and open a PR here.. I just thougth that there would be more useful stuff on the ClientRequest to justify exposing it as a whole, but looking at the class members there, there's really not much in there, so I guess a .abort() is okay.. Also, according to https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding, there's a possibilty for compress encoding, but I don't think this is worth adding here.. That would add a devDep on https://github.com/mayhemydg/iltorb, which requires a native module. I don't think it's worth that as gzip is already tested.. > How do we decompress the br content?\niltorb can both compress and decompress.. Oh, right. Looks like https://github.com/sindresorhus/decompress-response is lacking support for br. I guess it should be added there first.. Haven't seen that one yet, but iltorb is well maintained and I haven't had any issues with it yet, even under Windows. Brotli compression is very CPU intensive, so I'd definitely compare the performance before choosing a module.. Opened https://github.com/sindresorhus/decompress-response/issues/12 which blocks this issue.. ",
    "artems": "You are right, saying that headers must be  case-insensitive.\nBut what if I want send header in capital case, I can not do this.\n. @sindresorhus, nope, node sends headers as is.\n@floatdrop, rawHeaders is available only for incoming messages and node don't use them to send request.\n. ",
    "golyshevd": "Removed query feature commit\n. Ok, I will patch readme tonight and then squash commits after review\n. What problem that it is few additional lines of code?\nSimplest way to do it is to convert (opts, cb) to ('', opts, cb) but it is ugly in my opinion, and not quite right\n. You are absolutely right. But \"many code\" does not mean \"complex code\". In my opinion got becomes to be complex because of got is too polymorphic. But refactoring solutions is not a topic.\nPersonally, I need this feature in got and I have a plans to use got in future. But I have no idea how to do it with less diff\n. I did not thought about it earlier but in fact, yes, it will be like got({}). Need check for \"at least one argument\"?\n. ",
    "arthurvr": "I'm all for this! :+1:\n\nIt seems like resolving to Object make much more sens - order of vars is not matters and user can access body, without response (or vice versa with different order).\n\nYes, I would prefer an object too.\n\n\nMe too.\n. Super cool work, @floatdrop! :star:\n. > I didn't realize got works in the browser through browserify.\nI didn't eighter. Super cool! If we can confirm everything works fine I'd even say that's a welcome addition to the readme?\n. Cool! Looks good to me.\n. Yippeee! Nice work.\n. I'd also drop both. :+1: \n. ",
    "stevenvachon": "js\nvar req = require(\"http\").request({hostname:\"127.0.0.1\",port:0});\nreq.on(\"error\",function(e){throw e});\ndoes not produce the same error\n. It doesn't, and is the cause of dev error. But should it throw an error when all other errors are passed in the callback (in \"request\" and \"got\" libs)\n. Progress?\n. What do you guys think of https://github.com/stevenvachon/auto-tunnel before I publish?. auto-tunnel wasn't released because:\n\nit is so similar to caw that I decided to instead convince @kevva to conform to some of its features. He didn't respond to everything.\nhttps://github.com/TooTallNate/node-proxy-agent/issues/11. It was only removed from Chrome for a few versions. The feature was re-added https://bugs.chromium.org/p/chromium/issues/detail?id=123150\n\nI think this change should be reversed. @sindresorhus . Breaking the Internet is not a good idea.\nAs for supporting it in this library, consider this example:\n```js\nfunction doSomething(url) {\n  let auth = '';\n// shouldn't be necessary\n  if (url.username || url.password) {\n    url = new URL(url);  // wasted resources\n    auth = ${url.username}:${url.password};\n    url.username = url.password = '';\n  }\nreturn got(url, {auth});\n}\nconst url = new URL('http://user:pass@host/');  // from an HTML document\ndoSomething(url).then(() => {});\n```\nThis library's goal is to make requests easier, not annoying.. https://github.com/TooTallNate/node-proxy-agent ?\n. This feature is probably one of the things that makes request lib as big as it is.\n. Why fork node-proxy-agent when you could create a PR to bring it up to date? Or was that the intent?\n. Do we not need to support pac and socks proxies?. Yes, broken servers. This library sounds like it's trying to dumb down the process of making requests, though.\n. @floatdrop very cool. Considering this, would any of you agree that a shortcut to this functionality would still be a good idea? I think it contributes to this project's goal and doesn't bloat.\n. @floatdrop but then I'd need to maintain it :persevere: \nI'd think that if it were to be implemented in this library, which I hope that it will be, it should be its own method: got.pseudoHead()\n. I'd thought that request was unnecessarily bloated and messy. Interesting to know that it got that way for good reason. Fortunately, there's Request Next.\n. I take it back -- not just for broken servers. Some servers simply refuse to support http head and spit out a 405 error. One such example is linkedin.com\n. @sindresorhus please re-open -- see reason above.\n. Oops, thanks.\n. @sindresorhus http polyfill may be more concerned with older browsers as it's a core lib. Browsers that don't have fetch() or redirect option will be stuck.\n. This may not be necessary. As @sindresorhus pointed out, http can be built to use window.fetch in the future, but what is most interesting is that we can achieve this now by using stream-http in place of the \"http\" module with browserify.\n. Original comment updated.\n. file:// is part of the fetch() spec: https://fetch.spec.whatwg.org/#basic-fetch\n. Make it optional, then. That way, we could do something like:\njs\nconst baseUrl = new URL(\"http://domain/\")\nconst url = new URL(\"file://dir/file\", baseUrl)\ngot(url, { supportFileProtocol: baseUrl.protocol===\"file:\" })  // origin error\n. Now that I think of it, a separate package should be written to handle this as it can then be used with any similar request library. If we want, we can document its use in this package's readme.\n. @tommedema no, but I also haven't begun to use this library yet either.. This library does not support URL as it tries to merge parsed URL objects into other objects.\n. js\nconst url = new URL(\"http://domain/\")\ngot(url).then()\n. This may not be necessary, as http.request and https.request support URL natively. fs functions will soon.. Such support has been implemented in v7.x and, like all other URL features, will continue to be experimental and undocumented until v8.0\nThe main difference URL brings to properties on the request config object is a non-existent auth key, instead having username and password.. I've been writing universal-url for seamless Node v4+ and browser support.. Maybe I'll write a \"has-whatwg-url\" or similar package. Though, since this will likely be input only, isurl may only be necessary.. @AlexTes for what reason do you need URL feature detection? Could you not just check if the input is a URL and perform different operations (that are build into its instance)?. You could do both. #\u00ad1 would require a new module (\"hasurl\") that I could publish with code pulled from isomorphic-url. #\u00ad2 would require isurl for situations where hasURL === false.. @AlexTes check out hasurl for feature testing URL support. Currently, only Node 8.x nightlies will return true.. My original intent was to drop the use of url.parse for URL, which would require a re-implementation of \"url-parse-lax\". Keeping url.parse does not reach the goal of decreasing browserify bundle size (when/if paired with universal-url-lite), but it does avoid a major version bump.\nRegarding your PR, I don't see why a re-parse is necessary when you can abstract the mismatching properties with variables:\njs\nlet auth;\nif (!isURL(url)) {\n  url = urlParseLax(url);\n  auth = url.auth;\n}\nelse {\n  auth = `${url.username}:${url.password}`;\n  if (auth === ':') auth = '';\n}. The URLs that are included (in some redirects), also appear to be adding default ports in:\njs\n// redirect.html -> (302) redirect2.html -> (301) redirected.html\nrequire(\"got\").stream(\"http://domain/redirect.html\")\n.on(\"redirect\", response => console.log(response.url));\nlogs \"\" and \"http://domain:80/redirected.html\"\n. Hmm, \"Fixes\" didn't close this. Closing.. @AlexTes These URLs are the same:\nhttp://user@host/\nhttp://user:@host/\nThe issue you're describing sounds to be with Node's C/etc source and not JavaScript. You should take it up with them.. We're using url-to-options which was copied from Node.js source. I think that all of this should be fixed upstream. With that, it may be better to wait to merge.. We should likely remove url.parse() completely from this library [in a separate PR], as I'd originally requested in #228. Anyway, @sindresorhus please review.. isURL.lenient(url). It might be more complete to use universal-url here so that the Node v7 URL is included in tests when available.. There's no auth (username,password) check in this block like there is for string input.. This is more accurate:\n\n, or a WHATWG URL.. Also, reparsing the url is not the best idea for performance.. Alphabetical order.. \n",
    "andrefernandes": "Thanks for the quick answer :)\n. ",
    "maxogden": "its standardized but 90% of people (my own estimate) don't handle errors in streams correctly :)\n. BTW my workaround is currently\nvar isRedirect = require('is-redirect')\nrequest.on('response', function(res) {\n  if (isRedirect(res.statusCode)) return // hack for https://github.com/sindresorhus/got/issues/75\n  // handle final response here\n}\n. @floatdrop +1 to that idea!\n. ",
    "connyay": "The situation I hit this with was on a 204 response. I started this PR only\nchecking if the status code was 204, but figured an empty 2xx would be\npossible as well.\nThoughts?\nOn Fri, Jun 26, 2015 at 4:27 PM Vsevolod Strukchinsky \nnotifications@github.com wrote:\n\nTechnically - blank response (at least with 200 status code) is invalid\nresponse.\nhttp://stackoverflow.com/questions/11970962/valid-json-in-response\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/sindresorhus/got/pull/78#issuecomment-115871216.\n. @floatdrop switched to check for 204\n. @floatdrop should be good. \n\n:beers: \n. ",
    "Flet": "I've run into two great packages now that use got, but with no proxy support I can't use them :(\n@kevva is there anything I can do to help with your module?\n. ",
    "alexpaluzzi": "Is not working (as mentioned in other issue).\nSeveral companies don't have an actual \"proxy\" but rather, an HTTPS inspection point somewhere down the line. (Like, in my case, \"Check Point Firewall\"). This requires some self-signed certs to work and it definitely causes some issues by default with npm and other package managers.\nnpm is easily solved with \"strict-ssl=false\". Curl has a flag for it as well.\ndownload worked great before whatever tweaks were made a few weeks ago. @kevva's fix probably did help those that have \"real\" proxies.\nI'm not a network admin, so I'm probably messing some of this lingo up. I did speak with my network guys here, though, and after a few days of research, this is where we landed. Hopefully this helps somehow.\n. I immediately had the same thought after I saw your caw. Unfortunately, I don't see anything there. If I have some time, I'm going to look at npm and what exactly strict-ssl is doing. Even without an actual proxy, that config is the difference between working and not working.\n. @sindresorhus Tears of joy here.\nhttp doesn't have a way to handle these certificates. request does, of course (with agentOptions and strictSsl). I found a couple ancient issues from 2013 asking for a strict-ssl option. I don't see one yet.\nThe workaround for http is setting this environment variable (not my favorite solution, but it's the only one I've found):\nprocess.env.NODE_TLS_REJECT_UNAUTHORIZED = \"0\";\nI think your tunnel-agent is working good for traditional proxies. I wager this can be closed now. I'm certain there were people having my exact issue here, so hopefully this will help.\n. ",
    "tjwebb": "fwiw, the node yeoman generator is also experiencing this issue: https://github.com/trailsjs/generator-node/issues/1.\nIs there a patch available?. ",
    "chocolateboy": "Until this is fixed in Node, a workaround for Linux/BSD/macOS is to use proxychains-ng.\nYou'll need your proxy server's IP address and port:\n$ echo $http_proxy\nhttp://proxy.example.com:8080/\n\n$ ping proxy.example.com\nPING proxy.example.com (192.0.2.42) 56(84) bytes of data.\n\n- which should be added to the end of /etc/proxychains.conf (comment out the default rule) e.g.:\n# socks4 127.0.0.1 9050\nhttp 192.0.2.42 8080\n\nThen you're all set:\n$ proxychains -q npm-check    \nChecking for unused packages...\n\n$ alias npm-name=\"proxychains -q npm-name\"\n$ npm-name proxychains-ng-rocks\n\u2714 proxychains-ng-rocks is available.\n",
    "paambaati": "@kevva I can see that @stevenvachon's auto-tunnel is very similar to caw.. http/2 has now been in core for a while now. Even though the module's stability is marked as experimental, it would be worthwhile to start looking into this.. @szmarczak Thanks for the release! Is there a way I can modify the initial connect request options? I tried setting it in beforeRequest but I get a Parse Error.\nhttps://gist.github.com/paambaati/5e52b5bc42b2e6eebcfb55213d1853a1. @pietermees Have you tried using caw?. @kevva err doesn't have a response.. @kevva Simple repro \u2014\n```node\nconst http = require('http');\nconst got = require('got');\nconst server = http.createServer((request, response) => {\n    response.writeHead(500, { 'Content-Type': 'application/json' });\n    response.write(JSON.stringify({\n        error: true,\n        message: 'test error',\n        status: 999\n    }));\n    response.end();\n});\nserver.listen(1080, () => {\n    console.log(\"Server is listening\");\n    const gt = got('http://localhost:1080/');\n    gt.then(proxyResponse => {\n        console.log('RECEIVED RESPONSE!');\n    }).catch(err => {\n        console.error('ERROR', err);\n    });\n});\n```. ",
    "rightaway": "What's the recommended way to use got with HTTPS/SOCKS5 proxies?. @Jakobud Do you get a response property if the error is a 404?\n. Does it mean I need to change 'latin1' to 'win-1252' in the code sample above? I've tried it but still the same result. How can I get it to output the file as expected?. It was my own fault, got is in fact including response on the error.. @AlexTes first I just wanted to understand the issue more. Is there anything special you can see about this file? I've tried with so many other files and got 99% of the time returns the Content-Length as expected.\nI made a mistake in my original post, the command is actually (await got('http://webmaster.drtuber.com/export/big.csv', { method: 'head' })).headers, as it is a HEAD request. Shouldn't a HEAD request always return all headers?. I could take a look at it sure. Could you give me a pointer on which part of the code to study that would be relevant to this?. js\nawait got.post('https://jsonplaceholder.typicode.com/posts', {\n    body: {\n      title: 'foo',\n      body: 'bar',\n    },\n  })\nWhat happens to an object in body, does it get JSON stringified or turned into querystring or something?. I see that form/json parameter is required to use a plain object.. ",
    "wildone": "NPM works fine with --https-proxy and --proxy, so its only logical that all modules built on top of it support this basic mechanism. I had a situation using npm with proxy where another module was using your module to build its depenedecies... well that did not work at all. I ended up fixing the issue with a workaround. \nSo maybe this needs a another look as \"A nicer interface to the built-in http module\" (from your readme) is a big call if basic http modules functions are not replicated... thats just my 2cents. ",
    "ArtskydJ": "@floatdrop @sindresorhus Why not merge the test to avoid regressions?\nIf you don't like the way it's written, feel free to rewrite it, but I think it's good to have regression tests.\nAnd if not here, maybe in read-all-stream.\n. @floatdrop Whoops, I should've seen that. Thanks a lot!\n. ",
    "lukehorvat": "Thank you @sindresorhus. :dancer:\n. Just having a play around with it now. It seems to send the request to http://localhost:8000./ping, which still isn't correct, but is close. It looks like http-browserify is the cause of the problem this time, so I will open an issue in that repo.\n. @sindresorhus Okay, I've opened an issue here with an accompanying PR. Unfortunately there are 31 other pending PRs so I don't think it's going to get merged any time soon. :neutral_face:\n. Happy to report that as of stream-http v1.6.0, relative paths work when using got in the browser. :muscle:\n. Thanks. :smile:\n. ",
    "bendrucker": "http-browserify was replaced by https://github.com/jhiesey/stream-http in browserify@11\n. Also I'm gonna bring in @floatdrop's captureStackTrace ponyfill to nested-error-stacks in mdlavin/nested-error-stacks#6 instead of the naive initial solution I proposed. Right now got's not really compatible with browserify (b/c nested-error-stacks isn't). It'll work in Chrome, but any errors will result in an exception in a non-V8 browser (IE, Safari, Firefox).\n. ",
    "mattdesl": ":+1: \nI started got-xhr for this reason but haven't published it yet. If possible, I would rather build on an existing module than add more clutter to npm.\nBut with that said, it might be necessary to have a separate got-like module that has a more limited scope than got. Things like: \n- avoiding Buffer, and instead using ArrayBuffer since it is more common in the browser\n- avoiding zlib, since the browser handles gzip for us anyways (from what I understand?)\n- avoiding streams entirely since they add a pretty significant amount of bloat\n- just using xhr under the hood\n. Update: I'm now using xhr-request in node/browser for non-streamed requests. \nFor streamed requests, simple-get is pretty good, and half the size of got.\ngot could probably be almost as small as simple-get by doing something like this:\nhttps://github.com/feross/simple-get/blob/d212b1022d21b49c8ec83acf251d1dc4aeb38ca3/package.json#L10-L12\n. Nice!\ngzip can be misleading when you are considering how bundle size affects parse/execution time. :smile:\nMore details:\nhttps://timkadlec.com/2014/09/js-parse-and-execution-time/\n. But you should probably include uglifyjs -cm to get a better idea.\n. p.s. You can't run got through uglify-js right now because it has some ES6-isms (which also means it will break on safari, IE and the likes).\nsh\nbrowserify -r got | uglifyjs -cm | wc -c\nParse error at -:7172,5\nUnexpected token: name (redirectCount)\nError\n    at new JS_Parse_Error (eval at <anonymous> (/Users/matt/npm/lib/node_modules/uglify-js/tools/node.js:22:1), <anonymous>:1526:18)\n   ...\n. ",
    "thisconnect": "@mattdesl about Unexpected token: name (redirectCount) it is caused by let, see https://github.com/mishoo/UglifyJS2/issues/887\n. Thanks I'll give it a try, close?\n. @sindresorhus \n- using Node.js (both should work on the browser afaik)\n- tested with the Twitter api\n- using consumer_key, consumer_secret, access_token and access_token_secret\nFirst example with https://github.com/bettiolo/oauth-signature-js\n``` javascript\nconst got = require('got')\nconst oauth = require('oauth-signature')\n// borrowed from 'oauth-1.0a'\nfunction getTimeStamp(){\n    return parseInt(new Date().getTime()/1000, 10);\n}\n// borrowed from 'oauth-1.0a'\nfunction getNonce(){\n    var word_characters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789';\n    var result = '';\n    for (var i = 0; i < 32; i++){\n        result += word_characters[Math.floor(Math.random() * word_characters.length, 10)];\n    }\n    return result;\n}\nconst url = 'https://api.twitter.com/1.1/statuses/home_timeline.json'\nconst params = {\n  oauth_consumer_key: consumer_key,\n  oauth_token: access_token,\n  oauth_nonce: getNonce(),\n  oauth_timestamp: getTimeStamp(),\n  oauth_signature_method: 'HMAC-SHA1',\n  oauth_version: '1.0'\n}\nconst signature = oauth.generate('GET', url, params, consumer_secret, access_token_secret, { encodeSignature: false})\nparams.oauth_signature = signature\ngot(url, {\n  query: params\n})\n.then(res => console.log(res.body))\n.catch(error => console.error(error))\n```\nSecond example with https://github.com/ddo/oauth-1.0a\n``` javascript\nconst got = require('got')\nconst OAuth = require('oauth-1.0a')\nconst oauth = OAuth({\n  consumer: {\n    public: consumer_key,\n    secret: consumer_secret\n  },\n  signature_method: 'HMAC-SHA1'\n})\nconst token = {\n  public: access_token,\n  secret: access_token_secret\n}\nconst request_data = {\n  url: 'https://api.twitter.com/1.1/statuses/home_timeline.json',\n  method: 'GET'\n}\ngot(request_data.url, {\n  query: oauth.authorize(request_data, token)\n})\n.then(res => console.log(res.body))\n.catch(error => console.error(error))\n// OR\ngot(request_data.url, {\n  headers: oauth.toHeader(oauth.authorize(request_data, token))\n})\n.then(res => console.log(res.body))\n.catch(error => console.error(error))\n```\n. I personally prefer  https://github.com/ddo/oauth-1.0a\n. Sure, I'll send a PR after the weekend.\n. @sindresorhus I'll close this and open a new PR (squashed) ok?\n. nice to know, thanks :)\n. BTW: option.query can NOT be used with OAuth as the query has to be part of the requestData.url in oauth.authorize\n. alternative:\n``` js\nconst got = require('got');\nconst OAuth = require('oauth-1.0a');\nconst oauth = OAuth({\n    consumer: {\n        public: process.env.CONSUMER_KEY,\n        secret: process.env.CONSUMER_SECRET\n    },\n    signature_method: 'HMAC-SHA1'\n});\nconst token = {\n    public: process.env.ACCESS_TOKEN,\n    secret: process.env.ACCESS_TOKEN_SECRET\n};\nconst url = 'https://api.twitter.com/1.1/statuses/home_timeline.json';\ngot(url, {\n    headers: oauth.toHeader(oauth.authorize({ url: url, method: 'GET' }, token)),\n    json: true\n});\n``\n. Thank you too!!\n. thanks\n. Just had that because the url is used in 2 places. I'll update...\n. How about a url variable instead of request_data?\n. I copied that from the previous example. I am going to change form-data to link to github too.\n. like that:hash_function: (base_string, key) => crypto.createHmac('sha1', key).update(base_string).digest('base64')? I'm ok with, but it's slightly harder to read or not?\n. orconst { createHmac } = require('crypto')thenhash_function: (base_string, key) => createHmac('sha1', key).update(base_string).digest('base64')`\nand maybe base_string to base ?\nshortest 1liner hash_function: (base, key) => createHmac('sha1', key).update(base).digest('base64')\n. my comments are hard to read.. sorry :)\n. ",
    "Kikobeats": "I think that is more a problema related with the node version / server configuration. Nevermind.\n. Thanks! Works like a charm.. sorry, just because I suppose you are referencing this library in the proxy section as well:\nhttps://github.com/sindresorhus/got#proxies. ",
    "eush77": "@floatdrop Your reasoning makes sense to me.\nI can suggest two ways of solving this problem:\n1. Consulting Content-Type header for non-200 codes. Response is parsed as JSON if and only if its value is application/json. json option is simply ignored.\n2. Additional option controlling whether response with non-200 codes should be JSON-decoded. Then request to GitHub API would have { json: true, jsonError: true } and request to NPM API would have { json: true, jsonError: false }. { json: true } would be a shortcut for one or the other, whichever is more common in the real world.\n. > How about add status and statusCode to PraseError?\nThis is in fact combining HTTPError and ParseError into one type. How about combine error messages as well? This way err.toString() would be more useful.\njs\n{ [ParseError: Unexpected end of input (code 404)]\n  message: 'Unexpected end of input (code 404)',\n  code: undefined,\n  host: 'registry.npmjs.org',\n  hostname: 'registry.npmjs.org',\n  method: 'GET',\n  path: '/nonexistent'\n  statusCode: 404,\n  statusMessage: 'Not Found' }\nOr HTTPError: 404 Not Found (unexpected end of input).\n. ",
    "maxvipon": "my bad\n. thanks\n. 1000 \u2192 100 ?\n. @sindresorhus @floatdrop what about ability to use custom backoff function?\n. I think maybe 1sec timeout is good choice for most cases and\nlowering it from 2sec to 100ms will solve my problem (though now I use 10ms\nin my retry wrapper), but may occures little-ddos-like problem for others.\n. @floatdrop you decreased noise but not timeout))\n. In my opinion retries: () => 0 and retries: () => false are the same\n. :+1: \n. :fire: \n. ",
    "matiux": "I have solved!!\n```\n            var opts = {\n            method: 'POST',\n            encoding: 'utf8',\n            headers: {\n                'Content-Type': 'application/json'\n            },\n            body: JSON.stringify(body)\n\n        }\n\n```\n. ",
    "vadimdemedes": "@sindresorhus Yeah, sure, will do.\n. @sindresorhus done ;)\n. @sindresorhus Read all notes, fix is coming very soon, thx ;)\n. @floatdrop \n- Yes, more options would be added, but it is not a bad thing, is it?\n- True, but we can mention this behavior explicitly in the docs\n- retry would be enabled for all requests, because it would retry requests only on network failures, like EAI_AGAIN, ETIMEDOUT, etc.\nSo, to sum up, the implementation would be pretty lightweight, but the benefits are obvious. The only point is to deal with network failures, not response failures (interpreting status code, etc).\n. \ud83d\udc4d!\n. Thanks @sindresorhus, feedback addressed. Had to rebase and force push, because of a conflict.. @sindresorhus Oh yeah, missed the other ones.. @sindresorhus haha, best times!\nI don't know why, but when I searched \"sambucca\" on Giphy, this is what it gave me, so now I'm posting this instead of my favorite drink to celebrate the merge:\n. Segment is a happy user of Got! Got powers the main backend API that our app talks to. It's used by our in-house RPC client that we use to communicate with all microservices. Unfortunately, can't provide a link, because it's not public. Our website is https://segment.com and here's our logo:\n\n. Yeah, ok ;)\n. EAI_AGAIN and ETIMEDOUT cause the biggest pain in the ass. ECONNRESET and ECONNREFUSED also happen, but rarely. As for ESOCKETTIMEDOUT, never seen this one. \n. Would be definitely good to have retries option. \n. I'd rename this to cacheControl.. I think xo had a rule favoring Number(x) over parseInt(x, 10).. => Buffer.isBuffer(firstResponse.body). Since store isn't actually needed, perhaps the following would be simpler?\njs\nconst cache = {\n  get: () => {},\n  delete: () => {},\n  set: (key, val, ttl) => {\n    // your set() code\n  }\n};. Could you add a newline above too?. Nope, it fails without bind.. We just picked a random number for frequency of upload progress events.. Np ;). > Why is percent set to 1? Probably missing something here :).\nIt's calculating percent to be from 0 to 1. So 1 means it's the last upload progress event and it's done.\n\nI'm also wondering why it is emitted?\n\nInitially it was only for convenience. But there are also cases where total can be unavailable (like you said, when streaming), so got makes sure that percent is always available.. It can't change during upload, but there's no way to know when headers are sent, is there? So I placed it here to correctly calculate the body size.. No reason. It was just a guess on how to report progress events not too frequently, but still enough.. There's no explanation, I just observed this bug randomly and couldn't find a source of the issue.. ",
    "yanxyz": "Thx\n. ",
    "dylang": "Thanks @floatdrop! \n. Built-in typescript support? \nThe third party one in @types was a great effort but lots of deficiencies, such as not supporting extend.\nEdit: a re-write in TypeScript would probably not count breaking change, so this might be the wrong place for this feedback. Feel free to mark outdated.. ",
    "Jakobud": "Actually I just realized it was a bug in my code that was the problem. So this is a non-issue. I do not think that I need to specify method: put after all. Thanks,\n. Okay that makes sense. thanks.\n. So if I don't use username:password in the url for a particular service, should that service automatically accept the Header authentication alternative?\nThanks for answering this one. It's kind of a weird one.\n. Maybe I'm also confused on this but I'm experiencing the same thing. I disable my internet connection in order to force a timeout error:\ngot(api.somewhere.com, {\n        json: true,\n        timeout: 5000\n      }).then((res) => {\n        // some code here\n      }).catch((err) => {\n        console.error('timed out');\n        console.error(err.response);\n        console.error(err);\n      });\nThat prints out:\ntimed out\nundefined\nRequestError: getaddrinfo ENOTFOUND api.somewhere.com api.somewhere.com:443\n    at ClientRequest.req.once.err (d:\\myproject\\node_modules\\got\\index.js:70:21)\n    at ClientRequest.g (events.js:286:16)\n    at emitOne (events.js:101:20)\n    at ClientRequest.emit (events.js:188:7)\n    at TLSSocket.socketErrorListener (_http_client.js:308:9)\n    at emitOne (events.js:96:13)\n    at TLSSocket.emit (events.js:188:7)\n    at connectErrorNT (net.js:1016:8)\n    at _combinedTickCallback (internal/process/next_tick.js:74:11)\n    at process._tickCallback (internal/process/next_tick.js:98:9)\nAm I just misunderstanding something here?\n. Yes I do get the response with a 404. I wasn't aware that I would get no response without a network connection.\nCan you guys advice a good way to write a test that simulates a timeout when accessing a url?\n. > @Jakobud the response is only available if the request went trough and a response was received. If a network error occurred, such as being offline, then there will be no response.\nDoes this mean that if a request times out, I will also not get a response in that situation? Thanks,\n. ",
    "alextes": "~~@stevenvachon that doesn't change anything about the fact it's deprecated though. Are you saying we should ignore the RFC?~~\nPage hadn't refreshed yet. Sorry!. I'm with Steven on this one. I feel Chrome was very wrong to cave and other 'expectation setters' like browsers wrong to ignore the RFC. Node and other HTTP communicators should do more to protect their users' security, especially using plain HTTP. I also feel this is not our battle.\nQuestion: the only strongly worded issue I can find is the use of auth in URLs and if I understand correctly Node 4 is already silently rewriting those. Technically we'd still comply with the RFC no?. Hm, I read over this, the RFC, our code, node's code, and I'm not sure why we throw when we do. Node seems to already turn user:pass@host.tld into an Authorization header. So at least the current suggestion: Basic authentication must be done with the 'auth' option doesn't make much sense to me. If I'm reading our code right, we parse the url, and when we do, both old and new url parsing from node build an auth option for you. No reason to force the user to do this. I'd suggest removing that part.\nWhat would be cool is to help people not expose credentials by using basic auth over http. It feels like that was the original intention, in that case, I'd suggest we console.warn or throw an error, that helpfully explains we try to help you keep your users safe in the wild web west, but if you know what you're doing, set unsafeAuth to true, and we'll get out of your way.\nForced or annoying security usually leads to bypassed security.. >I realize I'm showing up after the work is done and then complaining about the outcome\nWe still appreciate the feedback \ud83d\ude0a .\nMaybe I can help conclude the discussion. I think I speak for all got maintainers when I say, we want to help devs as much as possible \ud83d\ude1a . With basic auth we faced an interesting dilemma. Would we help users more by silently exposing their credentials, or by loudly telling them there are better ways for what they're trying to do? We initially went with the latter, now we switched to the former.\nBoth your positions are noted. As soon as people show up sad that their credentials got exposed, in numbers greater than the one or two upset that an error got thrown, I'm sure we'd be happy to reconsider.. Noted. Although that doesn't seem to be an example of accidentally exposing credentials \ud83d\ude09 .. @floatdrop say one was able to get an automated browser test environment up and running. Browser launches, got is available to it. How would you run all the tests? AVA doesn't run in the browser last I checked \ud83d\ude1e.. Since this is a very common use case in my experience and the json flag works very differently from request/request which is the dominant http / request lib. Similarly visionmedia/superagent doesn't require the coder do much thinking with regards to JSON posts.\nI think many coders will require the same 5 - 10 min of messing about before they realise you do it manually with got. Perhaps even running into an unexpected error.\nAdding documentation for this common use case makes a lot of sense to me. I think the cost is low, even if only considering the benefit to the maintainers not having to deal with people creating issues like this. Would a PR be welcome?\nUnrelated but the same question for adding an index to the documentation. PR welcome? ^^\nThanks for creating what will undoubtedly be my new http lib goto.\n. After giving the code a thorough read (so concise<3) I can say I would love to take a stab at it @sindresorhus. I also feel I might be out of my depth with all the streaming going on. I'm hoping the greatest cats in nodejs won't mind that.\nMaybe good to summarize.\n* add to current json flag effect / body behaviour.\n  * If body is a plain object, it will be stringified with querystring.stringify and sent as application/x-www-form-urlencoded.\n  * If json is true, and body is a plain object, it will be stringified with JSON.stringify and sent as application/json.\nThis poses a problem for people wanting to send a querystring but receive json and have it parsed. Which is to be solved as follows.\n* add form option\n  * type: object(maybe string)\n  * takes a plain object which will be stringified with querystring.stringify and sent as application/x-www-form-urlencoded.\nThis does leave the hairy situation where a user sets both json and form and then passes a plain object or string as the body. Since content types are mutually exclusive (I think) what happens?\nThis is assuming the default body behaviour is to stay the same.\nMaybe you're going on the assumption querystring and json would both require explicit setting to affect the request. In that case, what is to be the default behaviour of body? Pass to req.end? What happens when passing an object which node doesn't support?\nFinal question, what about people wanting to send json but not receive it? Many will use json flag as they did with other libs, and perhaps be surprised when an error is thrown because we tried to parse their plain text response. These are probably few and far between. Still, asking the user to set a header and stringify the body themselves because you want to control your parsing on receiving does not seem straightforward.\nAgain, if it isn't too much trouble answering, I would love to take a stab at this PR ^^. Hm. I think considering to generalize this case makes sense @MarkHerhold. I've also got to add that's a bigger PR than I think I can take on, and wouldn't without the cats weighing in, and they seem busy. I think I'll simply open a PR, making the most straightforward choices I can. I like the general idea of having optional pre / post request processing. I wouldn't know the best way to implement it.. I thought about this quite a bit when making my first attempt at implementing and now am pretty convinced it's a bad idea. I think having the 'shortcut props' makes more sense. So form, lets you easily send application/x-www-form-urlencoded, maybe formData for multipart/form-data, JSON for application/json. That leaves parsing freed up to be a wholly separate thing. Creating a clear distinction between serializing and deserializing which we shouldn't mix I'd say. Most of the inspiration for this thinking comes from looking around, mostly at superagent. A small bonus is that you can start treating deserializing manually by specifying a parsing function or you can start looking at the content-type in the response headers for default behavior parsing which would make a lot of sense too.. Fair enough Sindre.\nI'll PR the above. It would make any switchover to got a lot smoother.\nJust to be clear, your proposal means dropping the default querystring serializing of object values passed as the body, like I proposed in #265 right?. I want to suggest we support all inputs that querystring.stringify and JSON.stringify support, or maybe their shared subset.. > I'm not sure what this means. Can you elaborate?\nI like when things work the way I imagine them to work. When I use a request library, specify a body, and ask to stringify the body, I imagine it:\n accepts any input the underlying stringify fn accepts\n (bonus) is helpful and refuses to stringify something that might be accepted by the stringify fn but isn't what I meant to do.\nCurrent proposal: only accept a plain object.\nquerystring.stringify accepts everything:\n```js\n\nqstr('alex')\n''\nqstr(24)\n''\nqstr(['alex'])\n'0=alex'\nqstr({name: 'alex'})\n'name=alex'\nqstr({name: null})\n'name='\nqstr(null)\n''\nqstr(undefined)\n''\n```\n\nJSON.stringify accepts everything (sorta):\n```js\n\njstr('alex')\n'\"alex\"'\njstr(24)\n'24'\njstr(['alex'])\n'[\"alex\"]'\njstr({name: 'alex'})\n'{\"name\":\"alex\"}'\njstr(null)\n'null'\njstr(undefined)\nundefined\n```\n\nProposals:\n\nJust support their common subset. Keep the API simple. body validation wouldn't depend on which of the flags you're using. Their common subset would be (Array and Object).\nStringify what the Node supports but don't stringify null or undefined, the user probably meant 'don't send a body'.\nDon't stringify null or undefined. Stringify what makes sense for each. Querystring that's Array and Object. (shh, don't worry about deep objects). For JSON that's Number, String, Array, and Object. I for one do use the plain values in my API. Example: add ten to a user's credits, or shift the position of an item in a list.\n\nI vote 3 \ud83d\ude4b.\nSidenote: wouldn't mind leaving this out of the milestone.. Alright, I'll do 1. but when the people come knocking for us to be less opinionated and support what is valid JSON, I'm with them \u270a.. @sindresorhus  Complaint-Based-Development \ud83d\ude01. Maybe call it Wish-Based-Development \u2728 instead \ud83d\ude4f. Fully agree with all your points!. I'd go with something simpler \ud83d\ude0a:\njs\ngot(url, {\n    headers: {\n        'content-type': 'application/json'\n    },\n    body: JSON.stringify(body);\n});. Alright, alright \ud83d\ude04 . Still like this version better in that case. No need to understand got's request lifecycle. Although, you got to hand it to you (pun intended?), not having to stringify the body is pretty cool \ud83d\ude0e .\njs\nconst jsonGot = got.extend({\n    headers: {\n        'content-type': 'application/json'\n    }\n})\njsonGot({\n    url,\n    body: JSON.stringify(post)\n})\n. Ah, we should've been a bit clearer @ash0080 .\njavascript\ngot(url, {\n    method: 'POST',\n    headers: {\n        'content-type': 'application/json'\n    },\n    body: JSON.stringify(body);\n});\nHowever, got is quite smart. It understands that if you're adding a body, you probably meant to post, and will set the method to POST all by itself, unless explicitly instructed otherwise.. I don't think we should stretch promises to be more than they are. I'm already skeptical the cancel bit was a good idea, but the next release covers your original example. If you care about the events, why not use the event emitter the stream mode returns? You cited the JSON option not working, but adding your own parsing should be a small effort with the many helpful libs out there.\nIs this still a standing request, and if so, what concretely would you like to see added beyond cancellation?. I'd love to help out with this one. Let's see if we can sketch a clear picture of the problem that needs solving.\nGot currently expects an URL to be a simple string (which it parses), or a node http request options object. In the future, node devs will ideally rely on WHATWG-URL.\n* got should correctly 'normalize' URL. So recognize and behave.\n  * there's some object assigning going on which is incompatible with the way URL works.\nI'll also do a naive implementation and see what breaks. Let me know if there's anything I missed and should consider before opening a PR!\n/cc @stevenvachon since you are clearly knowledgeable in the matter and might feel like giving me some pointers \ud83d\ude04.. I see. The URL object looks just like the options object http has expected since forever (forgive me not digging around to find out how far back this works). So that would just leave not manipulating the URL object in a way that breaks it. I'll look into it! Thanks @stevenvachon!. Alright, I played around with it a little. If I understand you correctly. Got would ideally be usingURL for its internal representation of URLs. Until got can support only Node v8 and up we can't rely on node for that, but we can use whatwg-url.\nThis means:\n no more object.assigning the props of the url object because that means we lose our pretty URL structure.\n some implications for dealing with auth I'll have to dig into.\nSounds like I can get to work \ud83d\ude04.. Started work on this, after a bunch of contemplating I realised I probably misunderstood something.\n@stevenvachon could you please verify all you meant earlier was for got to stop breaking whatwg-url on Node v8+ to seamlessly start supporting them whenever Node does?\nI'm quite sure it's what you meant. I'll continue work assuming this is true \ud83d\ude04. Sorry for taking so long to understand what you were after. In case you also meant for got to start supporting whatwg-url on Node v4+ (or in a month probably v6+) please give a suggestion as to how, or ask me to share some options I had puzzled out.. I've seen isomorphic-url! Nice to see you're building libs to help out the ecosystem.\nI agree with sindre that it seems a bit much to start supporting whatwg-url in node v4+ for such a lightweight lib.\nI would be happy to add v8+ support for whatwg-url too! (pls don't take 'my' PR @sindresorhus \ud83d\ude22). The only thing I'm not sure about is given that I find a way to make passing the `whatwg-url' in v8, and options object otherwise work, how does one feature detect node whatwg-url support or the running node version to be v8+?\nI guess for now I'm moving on to another issue, thanks you two :smile:.. Sorry, that's what I meant @stevenvachon. I confused terms.. Still lost on what you guys would like to see implementation wise. I can imagine:\n\nnot assigning parsed url opts because that breaks for whatwg-url objects. Instead I could leave the object intact and just read bits from it or passed 'got opts' as appropriate. Meaning it would JustWork\u2122 on Node 8.\ndetect whatwg-url and turn it into something that works with the current approach, leaving the rest of the code unchanged.. @stevenvachon \ud83d\ude4c \nI'll see about taking a stab at this.. @stevenvachon please check out the PR. You can probably explain why it's not okay to serialize and parse whatwg-url. I have the feeling I'm still not fully grasping your / whatwg's intentions here.. Nice detective work @sholladay!\nFirst off, I think it's very unlikely Node v7 will ever be flagged work with got >= v5.7 and < v6.\n\nI also disagree with the final suggestion @sholladay gives. It could be floatdrop found got v5 broke with Node v7, not that we actively broke compatibility with Node v7 in version v5.7 . Until @floatdrop comments, downgrading to got <=v5.6.0 and using it with Node >= v7 is risky.\nLike sholladay said, upgrading to got >= v6 seems effortless, unless you're on Node <=v0.12 in which case you should upgrade Node instead.\nIf a dependency of yours is still using got < v6 please ask them to upgrade, better yet PR or if you're unwilling to, please mention which dependency is using an outdated version of got and I'll take a look at opening a PR myself.. I guessed right \ud83d\ude1b.\nDidn't notice it was unmaintained @floatdrop. That's kinda bad. How about I PR the most popular dependents of v5 and we deprecate the releases?\nThis can be closed now.. ~I couldn't help it, sorry not sorry.~\n. @floatdrop Added two words to the descriptive error message. Removed the comment. I feel this would also work.. Your timed-out module currently supports a connection timeout which Node doesn't. Can you elaborate on this issue a little? Are you okay dropping it and just using the native timeout?. Just noticed there was a misguided commit in there. Dropped it and rewrote history to improve the PR. I think we can improve the test that confused me. The details will be in the PR under this comment.. Fair enough @sindresorhus. It's \ud83d\ude22 to close my first PR but I'll get over it \ud83d\ude09. I knew this chance as there from the beginning when I chose not to discuss my solution first. It was a fun and good way to familiarize myself with got.\nThanks for looking over the long PR and helping me in merging many other PRs by now.. #297 fixed this one going with option 1.. @sindresorhus hi Sindre!\nMe too! Should've thought of that. I'll update this one and then have a look around for others that could be improved that way \ud83d\ude3a .. I had no idea Ava's .throws could take an error to compare to, that's perfect!\nThanks for the suggestion.\nIf I understand ava's blowing up correctly we shouldn't wrap the main got function in an anonymous function because it's caught at some point and returned in the form of a rejected promise.\nSidenote: \nbreaking the test causes the following message:\njson \u203a should have statusCode in err\n  Cannot read property 'host' of undefined`\nThat seems less than ideal. I'm not sure why that happens or how to improve it. I'll do some digging  ^_^.. @sindresorhus\njs\ntest('should have statusCode in err', async t => {\n    const err = await t.throws(got(`${s.url}/non200-invalid`), got.ParseError);\n    t.is(err.statusCode, 500);\n});\nI'm having a very hard time tracing the cause of the AssertionError .throws seems to throw.\nTime to pull out node-inspector :p.\nAlso cool hat   \u0669(\u25d5\u203f\u25d5\uff61)\u06f6.. @sindresorhus I know ava pretty well. She's amazing! Was already messing around with that but I couldn't seem to break T_T.\nRegardless I almost got it. No need for you to spend time on this. Go be awesome!\nIf you're interested it's going wrong over at:\n```js\nfunction stdError(error, opts) {\n    if (error.code !== undefined) {\n        this.code = error.code;\n    }\nObject.assign(this, {\n    message: error.message,\n    host: opts.host,\n    hostname: opts.hostname,\n    method: opts.method,\n    path: opts.path\n});\n\n}\ngot.ParseError = createErrorClass('ParseError', function (e, statusCode, opts, data) {\n    stdError.call(this, e, opts);\n    this.statusCode = statusCode;\n    this.statusMessage = http.STATUS_CODES[this.statusCode];\n    this.message = ${e.message} in \"${urlLib.format(opts)}\": \\n${data.slice(0, 77)}...;\n});\n``. I finally understand @sindresorhus \ud83d\ude13 . The check is still valid. After adding some defaults aParseErrorno longer blows up with access of undefined and ava correctly checks we are looking at an instance of aParseError`. \nNow to the silly bit. The reported error by ava is influenced by the caught error. In the case of breaking the test not to throw the expected ParseError, a thrown HTTPError. Which in this case is an error that we don't want. I'm guessing when the code does not throw, we run into the HTTPError throw, ava notices they are unequal, and for a reason I don't understand uses the properties on the error that is not the one we're looking for when providing the user with feedback. In other words, when the test fails we end up with a very strange error message (in verbose mode):\n```\n  \u2716 json \u203a should have statusCode in err Response code 500 (Internal Server Error)\n1 test failed [23:32:50]\n\njson \u203a should have statusCode in err\n  AssertionError: Response code 500 (Internal Server Error)\n```\nOptions:\nCatching and rethrowing in the test to provide a clear error. Makes little sense.\nWe could go back to the code I originally PR'd. No .throws.\nWe could leave it like this. For the passing case, this is the cleanest way we could write things down I feel. It does go downhill fast when the test fails.. which is kinda what it should be built for. Ava also seems to prefer the received (incorrect / coincidentally thrown) error's message property to the message I can optionally pass so that doesn't help either.\nSubmit a PR to Ava! When .throws catches an error that is not judged valid by optional second arg we use the optional message from the third arg if there is any.\n\nFor the third option, I would also have to add a commit that sets defaults for the ParseError constructor since for a reason I'm not entirely sure about .throws ends up invoking the constructor passed to compare to, its a custom error constructor, and it needs at least an empty options object for one.\nI have a bit of a headache, but it was a good lesson! Hope to keep contributing \ud83d\ude04 .. > This ;) Could you open an issue (or PR) on AVA about this?\nOn it! I'll try and open a solid PR \ud83d\ude01.\n\nOh wow. Good debugging! :)\n\nty ty \ud83d\ude0a \n\nPlease do! I'm in [...]\n\nAwesome! See you there. \n\nSorry about the delay. I was busy in real life.\n\nNo problem of course. I get you're busy. You're still getting the cat gifs I promised over in NodeJS slack \ud83d\ude38.. @kvz changing the method to GET on 301 or 302 is a controversial topic. We like to be safe. \nBecause there is a clear need for the scenario you described 303 - See Other was added to the HTTP/1.1 spec. Unfortunately, Got currently does not support this either, but as soon as we fix #291 Got will.. That would be much nicer @floatdrop!\nI'd much rather have the test explicitly use less-sensible arguments than making the actual code more lenient by making the less-sensible arguments defaults.\nI didn't do this straight off because I didn't know it was possible. Looking at the ava docs for .throws: \n\nerror can be an error constructor, error message, regex matched against the error message, or validation function.\n\nRegardless, the following works:\njs\nconst err = await t.throws(got(`${s.url}/non200-invalid`, {json: true}), \n    got.ParseError(new Error(), 500, {}, ''));\nBut to my understanding that's passing an instance, not any of the above, and to make things worse, once I comply with the linting rules and use the 'new' keyword things stop working and I get confused.\nStarted digging around in the node source, and played around with argument binding, but neither have worked out yet and sadly I don't have more time this morning. I'll try and continue this soon!\nThanks for the suggestion @floatdrop.\n. I figured out why it worked without the new operator. It's because the custom error constructor returns undefined in that case. Which if you're interested fails this check which means node's assert throws nothing, and ava returns the result obtained here which is the HTTPError which also has a property statusCode set to 500.\nNow that I understand some of the internals of .throws in NodeJS and AVA that AVA PR we talked about in #267 should quickly follow \ud83d\ude01.\nErrors are notoriously inaccessible, you can't iterate them, I tried anyway, but deepEqual is out.\nI really like @sindresorhus 's suggestion to just check props then, the way I see it that means we have three okay options. Every error should have a constructor, a message, and a name. That would respectively make the output when some non ParseError was thrown:\nUsing constructor:\n\nUsing message:\n\nUsing name:\n\nI like constructor best because I know it's a solid way to tell if two instances come from the same object. Visually, using constructor sucks and comparing name seems most clear to me.\nSorry for taking so long to get back to you two. I'd say it's your call!. I started work on this with p-cancelable. Can't quite get p-cancelable to be happy yet on cancellation. Asked Sindre for help. If that doesn't work out I'll repost in here.. @sindresorhus completely forgot about this one. I found a branch and stash. I'll put it on my list and take a look tonight (in 8h).. I actually knew this one but man you are fast @floatdrop \ud83d\ude09 .\nAlso cool to see a flowtype definition @Spy-Seth. Been meaning to try it out more myself. Let me know if you don't feel like PR-ing it into flow-typed because I'll look into it then! This should be shared \ud83d\ude04 .. Fixed accidently basing this branch on my other branch instead of master. Sorry \ud83d\ude48, I'll be more careful next time.. I'm with Sam!\nI like 'always try to parse the response, if bad things happened don't expect json but be helpful, and try to parse the body as such'. It says: for 2xx we take strict responsibility to do as asked, the rest we'll try to help out but it's mainly on you.\nI also wouldn't object to saying 'no 200, no automagic parsing for you'. It's simpler, and doesn't beg the question if we don't mind breaking if a 201 json response gets changed to 204 no json response. Especially if both sport correct content-type headers. I would understand the user that feels the json option was meant as mere convenience not setting an ultimatum. It says: if things aren't simple you figure them out.\nFor the same reasons I'm also still a fan of dropping the json option. It causes too many issues. Using a parse option would make obvious when things are the user's responsibility and when they're ours. It would say: if asked we always try and parse for you, if the situation is more complex, you figure it out.. Hi @antony!\nI'm afraid you removed too much code for me to see what's really going wrong. From experience I'm guessing one of two things is happening:\n1. You're trying to create a got error without passing the required arguments. (maybe you're using nock's replyWithError?\n2. The testing lib you're using is trying to create a got error without passing the required arguments.\nHere's an example that works just fine, I can rewrite it using whatever testing lib you like, I used ava because she's really straightforward.\n```js\nconst test = require('ava');\nconst got = require('got');\nconst nock = require('nock');\nfunction post(url, body) {\n  return got('http://localhost:8080/', { body })\n    .catch((err) => { throw err; }); // this could be removed\n}\ntest('test error route', (t) => {\n  nock('http://localhost:8080/')\n    .get('/')\n    .reply(500, 'Intentional Error');\nreturn post('localhost:8080', { name: 'alex' })\n    .then(() => {\n      t.fail();\n    })\n    .catch(() => {\n      t.pass();\n    });\n});\ntest('throws', (t) => {\n  nock('http://localhost:8080/')\n    .post('/')\n    .reply(500, 'Intentional Error');\nreturn t.throws(got('localhost:8080/'), got.HTTPError);\n});\n```\nHope this helps!. I think one of us is confused about the interplay of nock and got. I don't think got can catch nocks errors, unless nock isn't acting like a server in the way I thought. Whatever the response is, got should be able to turn it into an error without issue. I'll try your scenario: pointing got at a route that doesn't match but somehow still gets caught by nock.\nAgain, it would be helpful if you supplied the code that demonstrates this behavior!. The way you were catching errors was one of the elements I was curious about seeing in action \ud83d\ude09 .\nGlad to see you figured it out!. Second approach as per Sindre's first comment.\nI'd much prefer not to have Got concern itself with managing a store. Picking a store means deciding on how to store. Better to leave that up to the user methinks. \n(Also nice to see a familiar face Luke, thanks for the zsh plugin \ud83d\ude09). Why not use read-pkg @sindresorhus?\nI like reading JSON to be explicit, but that's just intuition. \nInterestingly both read-pkg and load-json-file are yours. It's beside the point for this PR, but now I'm curious. Care to elaborate why we don't use them for got?. @sindresorhus it's in the commit message of the commit that fixes it. I'll use fixes from now on and add it to the initial PR comment instead. Makes more sense to me after thinking about the options.\nHm, the effect of the latter is nicer too I see. It includes a PR status badge. Thanks for the suggestion Sindre!. Done. Missed that on my previous PR - the one that added protocol - too.. Hi, thanks for the feedback, happy to get it \ud83d\ude01. \n```\n$ ava test/http.js\nbody is a stream, piping\ncalling cancel\n1 failed\ncancel in-progress request promise\n  node_modules/p-cancelable/index.js:65\n64:     this._canceled = true;\n   65:     this._reject(new CancelError());\n   66:   }\nError: undefined\nPromise.cancel (node_modules/p-cancelable/index.js:65:16)\n  Timeout._onTimeout (test/http.js:131:18)\nThe .only() modifier is used in some tests. 11 tests were not run\n``.p-cancelable` has been updated with a fix.\nFinal notes:\n not sure calling abort before the request event is emitted works nicely. I used an approach that waits for the request to start then tells Node to abort.\n p-cancelable returns immediately when asked to cancel a settled promise. I worry about the use-case where a user tries to cancel a settled promise but won't know the request went through. I can imagine that's problematic especially when a user doesn't care much about a response but is going for more of an RPC type deal.. Thanks, forgot to save the dep update!. > Is that really necessary? I think you can abort a request whenever.\nLet me make sure and test.\n\nIt immediately does what?\n\nSorry. 'p-cancelable returns immediately when asked to cancel a settled promise.'. Heyo, I predicted an issue (starting to get the hang of this \ud83d\ude1b) but forgot to make an effort to expand the test to catch the issue. I shelved it because the lovely version of the test doesn't work due to.. long story. Anyway, last two commits show the issue - not a pretty test - and apply the stash I had that solves the issue.. Not sure where to leave the documentation for this. It's a sort of indirect API. I took my best guess. . Sure, will do that in the future. I asked you on Gitter when you squash and when you don't. The only reason I was rebasing is because I wasn't sure if you'd squash.. I'll see about reviewing my own PR in the morning next time I'm coding late. Too many slip ups from code that changed heavily during the hour I was trying to find a strong way to write these tests.. Alright, ready for re-review @sindresorhus.. So I finally finished trying out all ideas I could come up with for solid tests. The in-flight one looks quite solid to me now. It starts a streamed body request, doesn't close the stream until the got triggers the cancel. To make sure we abort on cancel the test then verifies the server emitted an abort event, not a finish event.\nThe immediate cancel test is much harder. First off, by 'immediate cancel' I mean a user canceling a request before got's underlying event emitter has even emitted its request event. I tried all ideas I had, but the core issue remains. When you cancel a request, you end up with a rejected promise and pretty much lose the opportunity to get any further feedback. After extensive testing, it seems the 'connection' event is the event that hits a Node HTTP server first. This event doesn't fire with an immediate cancel. In other words, unless more of got's internals are exposed it appears impossible to make sure got ever triggered the abort. The compromise I've currently gone with is to make the following assumption: if the server has not received a request within 1000ms, the abort was executed client-side.\nAny better method of testing is very welcome, as are of course any pointers to clean up the code more. Sorry for taking so long, this PR has proven to be a very tough one to crack.. I guess this is our 'we want got in the browser!' issue.\nFair enough, I don't see one yet.\nI think #89 and #128 are two big blockers.\nMaking this step first could be smart. From what I can tell from ava/#24, set-immediate-shim or p-immediate are options to solve this.\nI can read-up on what the actual problem is, or someone can raise a green flag and I can open a PR and do some testing by hand (#128 looks hard).. Thanks for the feedback! Will update tomorrow \ud83d\ude04.. @sindresorhus @stevenvachon ready for review \ud83d\ude01!. @antony do keep in mind that if you're using async / await you lose your bluebird promise! (Think I noticed you use it in the previous issue)\nI dislike messing with globals because they have issues like the thing I just mentioned. I would humbly suggest:\n```js\nconst Promise = require('bluebird');\nconst got = require('got');\nPromise.resolve(got.get('URL'))\n  .catch(got.HTTPError, () => { / handle HTTPError / });\n``\nIf the promise resolving bit ofgotis slow, I'd much rather see an issue detailing this so we can try and speedgot` up. Perhaps by exposing a Promise implementation to use.. Fair point \ud83d\ude05.. No. I'm not an expert on HTTP, but I just did a lot of HTTP/1.1 RFC reading (fascinating!). Let me try and help out by adding my view and /cc someone who I sense is an expert on this.\n/cc @floatdrop \nRFC 7231, section 6.4.2\n\nIf the origin server will not make the requested PUT state change to\n   the target resource and instead wishes to have it applied to a\n   different resource, such as when the resource has been moved to a\n   different URI, then the origin server MUST send an appropriate 3xx\n   (Redirection) response; the user agent MAY then make its own decision\n   regarding whether or not to redirect the request.\n\nIn other words, it's entirely our choice. That said I'm in favor redirecting. The 303, 307 and 308 status codes were clearly meant to finally make redirecting unambiguous. What to do is very clear.\nCurrently, we only redirect GET and HEAD methods on all of the redirect status codes. \nI propose we:\n1. redirect POST on 303, and continue with GET.\n2. redirect any on 307 or 308 and continue with the same method.. @ninox92 you can use the emoji reactions in the top right of the comment boxes to avoid adding unnecessary activity \ud83d\ude09. Usually, people use the adequately named '+1' to indicate they share an opinion.. Can we maybe change the title to: 'Got throws an error instead of redirecting for 303, 307 or 308'?. Why do you expect got to time out by default @calebmer?\nIf you feel there's a reason, do share! \nIf you feel something could be improved to make it more visible got does not time out by default, do share!\n\ud83d\ude09\nIf you didn't know got does not time out by default, you can stop reading. If you forgot to add the timeout option in your example, I have something to add: Even if you added a 1ms timeout, it would take got ... 31 to 36 seconds to timeout. Did you know that, or do you perhaps find that surprising?. @calebmer no problem!\nHelpful to know it was the exponential backoff that surprised.. @mautematico yes it can! By setting the timeout option to whatever you want and overriding the default 2 retries and setting it to 0.\nThanks for letting us know it's currently confusing.. I got an avocado rainbow \ud83d\ude32 \u270a \u2764\ufe0f!\n(I'll wait \ud83d\ude01). @sindresorhus \ud83d\ude47 \ud83d\ude47 . You just made my day. And it's only 10 AM!\nHere we come v7!. @avimar releases is where you want to look \ud83d\ude09.\nHere's the changelog for v7.0.0.. I would always use GET. People can create an issue if there is a need for a GET or HEAD option.\nEDIT: sindresorhus if I remember correctly it's for any method. One can imagine deleting a resource that's maybe a child to a parent and thus the server redirects to the parent resource for the result.. @geosh03 I'm afraid that's not possible. Before Got even gets your arguments your JavaScript runtime attempts to read the items[0] and finds undefined. That's fine, but undefined does not have properties, so continuing on, trying to read .storage the runtime blows up because it doesn't know what to give to Got. In short: you can't read properties that aren't there.\nYou could try something like:\njs\nif (typeof output.items[0] !== 'undefined') {\n  got(output.items[0].storage.url, options, {retries: numRetries => numRetries < 10 && 500});\n}\nThere are other things you could likely improve but this has nothing to do with Got. There's usually very helpful people to be found on #node.js on Freenode (IRC) or the gitter.. I think node does 'chunked' transfer encoding by default. As per the spec section 4.4 3. this means the content-length header must not be included.\nWe could add an option to overwrite the default but with Node's streaming architecture the chunking probably makes a lot of sense. In any case, if you need this, explicitly setting the transfer-encoding header to any other accepted directive will work. You can read about the transfer encoding directives on MDN. \n@rightaway were you reporting this as a bug or as a feature request?. I was wrong @rightaway, Got is the causing the chunked transfer-encoding. Node doesn't cause this by default.\nSince compressing is more efficient Got sets the Accept header to gzip,deflate by default. Since the server serving the file agrees, it switches to compressing the file. However, the server only knows the size of the file uncompressed. So now it has two options:\n compress the whole file, check the new size, and then reply with the new content length\n compress and send in chunks, acknowledging that it doesn't know how many bytes it will be sending.\nThe latter is slightly faster because the server can compress and send at the same time. Ways to work around this are to overwrite our Accept header and set it to an empty string. Alternatively, you could compress the assets on the remote ahead of time so it does know how much data it will be sending.\nDoes that answer all your questions?. @timdp could be. Thanks for reporting, I'll take a look.. @abrkn I'd like to point you to the following line in our documentation for the json option.\n\nbody must be a plain object and will be stringified.\n\nIf that isn't what you want the json option should be set to false \ud83d\ude09.. @sindresorhus upon re-review I suggest we just close this. If we get a body on a 304 response (wrong behavior), and the user has requested json parsing of the response body, we do not throw in case we fail to parse the body (arguably wrong behavior).\nUntil someone wants to discuss this (@djmadeira ?) I think there's no reason to change anything. I think in this PR it was assumed 304's could have bodies that got should be parsing, they should not but in case anyone feels we should parse them regardless throw when failing they should open an issue to discuss it first. I for one disagree with that approach but would happily discuss \ud83d\ude04.. Neat. Now that I look at it again the way I wrote it is silly.\nOne note. This would in a sense be a breaking change. url-to-options turns the username (part of auth) in the url into ${username}:. In other words, if you set the username in a URL to user. and create a WHATWG-URL, the submitted authorization request header will be Basic dXNlcjo= which decodes as user:. It appends a colon. Without reading the spec, looking at curl and Node, this is correct in the sense that curl does this and Node clearly does this with WHATWG-URL too. So when using url-to-options the outgoing request will be the exact same as when you'd use Node with WHATWG-URL. However, currently, this is not the case. When getting the full URL through href the WHATWG-URL serializes to http://user@httpbin.org/get. We currently parse that, which results in the old Node behavior which does not append the colon, and thus results in a different header.\nI imagine there may be other edge-cases too. I'm guessing @stevenvachon, this one slipped by and you are not aware of any others? Would be good to know otherwise \ud83d\ude05.\nAlthough it is a breaking change, it's also a bugfix. Not sure how to handle this.. @stevenvachon well like I said. According to the spec, yes, but in practice no. One doesn't have a colon and encodes to a different base64 string with Node even if it clearly shouldn't. ~~I would bet Node can't fix that due to backward compatibility.~~ Just looked, can't find any such issue. I'll open one. RFC 2617 is pretty clear about the client having to add that ':'.\nRegardless, we need to make a small choice. This is a breaking change. Previously WHATWG-URLs would wrongly get Node to send without the colon. With this PR they will again. So I'm just saying if we're being strict this means new major. But I also imagine practically no one is relying on WHATWG-URLs getting basic authentication right with Got 7. So maybe minor or even patch. I'm inexperienced is this regard.. I see.\nnodejs/node #13571.. @SilentImp are you using Node 7 by chance? See: #316.\nIf that is not the case, can you give some more specifics on what version of Got, TypeScript and Node you're using?. @mjasinski5 check out the err.response property \ud83d\ude09. \nIn the Errors section there's the following line:\n\nIn Promise mode, the response is attached to the error.\n\nMaybe you feel it would be helpful if we explicitly mention this includes any response body?\nExample code:\n```js\nconst got = require('got');\ngot('http://httpbin.org/drip?numbytes=4&code=401')\n  .catch((err) => {\n    console.log(err.response.body); // logs: '****'\n  });\n```. @DerTieran total oversight on my part! Can we support sending arrays for both though?\nThat would also mean we don't have to split the logic regarding the argument validation like you have now.. @DerTieran\n(Sorry for taking so long to respond!)\n\nI didn't see the use in that or ever encountered an API like that.\n\nI could give use cases I imagine would be useful but I think it's more important to consider why I, and I'm pretty sure Sindre too, like wish-based-development \ud83d\ude01. I like it because it keeps the code simple. We only add what we need. But in this case, counter-intuitively perhaps, supporting less complicates the code more. The way I see it you're adding a feature we don't need: explicitly avoiding encoding of arrays as querystrings.\nSecondly, I feel we should only break with Node / browser behavior when it's helpful.\nThirdly, I can imagine a query like:\nquerying for a user and indicating you'd like some related or nested data to be included\n```js\n\nquerystring.stringify({\n  name: 'alex',\n  include: ['address', 'friends'],\n}\nretrieving data for a list of airports:js\nquerystring.stringify({\n  version: 1,\n  airports: ['AMS', 'BKK', 'JFK'],\n})\n``. As for your second comment, I wouldn't be a fan I'm afraid. I do notice there's some friction with the option and I've coincidently suggested the opposite, splitting out the parsing (#264). Sindre indicated that thejson` option tries to be helpful for the common use-case and from what I've understood his and Vsevolod's experience says that needs both.\n\nDoes that make sense?. @DerTieran Alright, I'm happy you agree \ud83d\ude04 .\nYea if you just update the PR as per my review and disregard the comment about adding a test, you're there and I can merge it!. Not released yes @framerate \ud83d\ude09 .\nYou need to take a look at the latest released README. Easiest to use the tagged commit or npm page.. @jotto Sindre is saying the code in master already handles the issue you're describing \ud83d\ude04 . \nWhen npm installs the 'latest' version it is the latest version we published. In other words, not every commit results in a new Got release. So probably the reason you can't reproduce is that the issue is fixed in master. \nSindre's linking code currently in master (8b040af), not yet released, you're talking about code of the installed version 7.1.0 (b725ef5). You can find that code in your node_modules dir or alternatively here, which I got by going to 'Code' -> 'releases' -> 'v7.1.0'.. \ud83d\udc4f. Hmm, seems that headers on the request are null sometimes when using got's provided writable stream. Not sure if there's a better way to get headers. In any case, it might be smart to use more defensive coding accessing an internal API like this.\nI'll have to do some more digging to fully understand the intricacies of reporting upload progress and how _headers gets populated during a request.\nInteresting to note the POST goes through fine. It's just the progress reporting that appears to break.\nThanks for reporting.. @brandon93s some part of me had been wanting to do this PR for soooo long haha.\nI'm a tiny bit jealous and mostly very thankful you made a long time wish of mine come true \ud83d\udc4f \ud83d\ude04 !. @ikokostya the key bit in the docs is:\n\nbody must be a plain object or array and will be stringified.\n\nSo when asking got to make JSON communication easier for you, it assumes it will be stringifying your body for you. Assuming this, we've discussed in depth what the simplest approach would be in #174 . See specifically this comment by Sindre. The most relevant bit being:\n\nThe JSON option is just meant to cover the common case. If someone wants more advanced configurability they can just not use it.\n\nNow I actually suggested to implement the behavior you expect, but Sindre felt it more complicated. If I had to guess why it's because there will be more users that accidentally pass a JSON string than users that want us to stringify a JavaScript string or number. So, to keep things helpful and simple, we only accept plain objects and arrays.\nI actually agree more with @sindresorhus now then I did then, still, your 'wish' is heard. Maybe you can add what your use-case is for making the body a string? That would be helpful \ud83d\ude4f .\nDoes that fully answer your questions @ikokostya  \ud83d\ude04 ?\n. Yea, pretty much completely agree with Sindre now.\nI think this answers the question. Our json option is just not for your use-case \ud83d\ude05. We've chosen a different but I think very tasteful trade-off. It creates a problem where there technically is none for you (false positive) but probably prevents a lot of incorrect use resulting in bugs for others (false negatives).\nYou could either:\n1. Not use the option, set the correct header, stringify, and parse yourself.\n2. Change the API from \"str\" to something like {\"descriptiveKey\": \"str\"}.. @clocked0ne currently our docs say:\n\njson\nType: boolean\nDefault: false\nIf you use got.stream(), this option will be ignored.\nIf set to true and Content-Type header is not set, it will be set to application/json.\nParse response body with JSON.parse and set accept header to application/json. If used in conjunction with the form option, the body will the stringified as querystring and the response parsed as JSON.\nbody must be a plain object or array and will be stringified.\n\nNote specifically the line:\n\nbody must be a plain object or array and will be stringified.\n\nWe can only code got to go with the most sensible default, and document exactly what that means in our case. You seem to dispute we have the second nailed down. I'm always happy to improve the documentation! How would you suggest we change it \ud83e\udd14\ud83d\ude09?. I'm against putting object or list of object as the type for body. That list should not depend on anything. I don't like the confusion there around the fact it can be but again, json is just for convenience.\nI'm not too opposed but still hesitant to the idea of copying the clarification to the body description \ud83e\udd14. After all, the issue is with the json option, people not using that seem to be fine. Are you sure you think this would help? \nWe only put things in the documentation that we feel provide value. Doubling warnings, adding emphasis, or increasing fonts, has a cost and should be used sparingly in my opinion. You can pass a JSON string just fine, as long as you're not also using the json option. If you're using the json option but not reading what it does, I'm not sure there's much we can do. In short, are you sure doubling documentation is the helpful approach rather than users reading the documentation in the first place?. @szmarczak the sentence is not grammatically correct, but I'm glad you found beauty in it haha \ud83d\ude04 .\nAlright. I remain quite unconvinced. Most users running into confusion around this option seem to because of their assumptions, not because of ambiguous documentation. That's understandable, but not helpful to try and compensate.\nAs always, anyone reading along hit by the same issue, please upvote the first comment. Currently, there are zero upvotes which makes me reluctant to change things. Still, I'm in a good mood, let me try to hit some middle ground \ud83d\ude01 .. @szmarczak hadn't seen that one yet! I think it's kinda beside the point but let's hope it solves it anyway \ud83d\ude01 !. From\n```\n-----------------------------|----------|----------|----------|----------|-------------------|\nFile                         |  % Stmts | % Branch |  % Funcs |  % Lines | Uncovered Line #s |\n-----------------------------|----------|----------|----------|----------|-------------------|\nAll files                    |    97.71 |     93.4 |    98.31 |    97.69 |                   |\n url-to-options.js           |    85.71 |     62.5 |      100 |    85.71 |                20 |\n-----------------------------|----------|----------|----------|----------|-------------------|\nTo\n-----------------------------|----------|----------|----------|----------|-------------------|\nFile                         |  % Stmts | % Branch |  % Funcs |  % Lines | Uncovered Line #s |\n-----------------------------|----------|----------|----------|----------|-------------------|\nAll files                    |    97.71 |     93.4 |    98.31 |    97.69 |                   |\n url-to-options.js           |      100 |      100 |      100 |      100 |                   |\n-----------------------------|----------|----------|----------|----------|-------------------|\n```\n\ud83d\ude01 . @szmarczak yea, already working on it, the odd thing is, I started with writing a failing test and can't quite seem to reproduce \ud83e\udd14 .\nOne sec.. Ah and same problem with hash of course.. Looks like a simple misunderstanding. Still I'm curious, @amio , why did you expect a timeout to take 100ms with timeout set to 100? Is it because you were unaware we retry twice by default?. I have the feeling I've seen this issue a bunch of times but looking through the issues says otherwise. If we get another I'm proposing an extension to the timeout docs explaining the in-practice timeout is not what one would naively expect \ud83d\ude05 .\nThanks for reporting amio\nClosing!. Sadly I hit my time limit for this issue.\nI have a fix, but sadly no test.\nTo clarify, got sends a request, a redirect comes back, the redirect neatly contains a Location: // header as it should, but the location is not a valid URL. Bad server \ud83d\ude45\u200d\u2640\ufe0f! \nSo got tries to helpfully redirect but in constructing the redirect URL blows up.\nFix is:\n```diff\ndiff --git a/source/request-as-event-emitter.js b/source/request-as-event-emitter.js\nindex 3187657..6bb9454 100644\n--- a/source/request-as-event-emitter.js\n+++ b/source/request-as-event-emitter.js\n@@ -120,7 +120,12 @@ module.exports = options => {\n                                }\n                            const bufferString = Buffer.from(response.headers.location, 'binary').toString();\n\n\nredirectUrl = (new URL(bufferString, urlLib.format(options))).toString();\ntry {\nredirectUrl = (new URL(bufferString, urlLib.format(options))).toString();\n} catch (error) {\nemitter.emit('error', new RequestError(error, options));\nreturn;\n}                        try {\n                                decodeURI(redirectUrl);\n\n```\n\n\nSadly, in trying to write the test for it I've gotten stuck on figuring out why the test gets stuck. The following hangs:\njs\ntest.only('bad URL should not result in unhandled exception', async t => {\n    await t.throwsAsync(() => got('//'));\n})\nDo the same in Node: got('//') and you immediately receive an unhandled rejection. If I were to guess I'd suppose ava has some protection in place to not blow up when a test blows up with an unhandled rejection, but because got violently explodes the returned promise by got never resolves.\nFor the one adding in a proper test here's what I have so far, it includes a quick curl exec to verify the new /invalid-redirect route is working.\nAdd this to the test/arguments.js server setup:\njs\n    s.on('/invalid-redirect', (_, response) => {\n        response.writeHead(302, {\n            Location: '//'\n        });\n        response.end();\n    });\nTest\n```js\nconst {exec} = require('child_process');\ntest('bad redirect should not result in unhandled exception', async t => {\n    console.log(s.url)\n    exec(curl -sLD - ${s.url}/invalid-redirect, (error, stdout) => {\n        console.log('cURL ERR\\n', error)\n        console.log('cURL OUT\\n', stdout);\n    });\n    await t.throwsAsync(() => got(${s.url}/invalid-redirect));\n});\n``. Nice work Brandon93. Lots of little improvements over what I wrote too. Unfortunately it does still suffer from the issue I flagged with the test. This test, like mine, is half functional. It lights up green beautifully, but imagine someone refactors and moves thenew URL` line out of the try/catch , the test won't show up red \ud83d\ude25 . It'll hang ava indefinitely which is something, but if possible I'd like the test red.\nLet's see if the other maintainers have an idea of how to fix it, if not, let's merge this and open an issue.\nTo reproduce try moving the line back out of the try/catch construct.. \ud83d\ude48 . TL;DR: All our logic depending on headers is wrongly ignoring othercased headers set by users.\nThere are a few places where we respond to or add headers whilst inspecting options.headers and assume they're in lowercase already. Normalization should lowercase all headers and prefer the passed ones. Example is: normalize-arguments.js where we add an accept header if the option json: true is present and no lowercase accept is set,  ignoring the fact there might be some Accept or ACCEPT header present already.\nIf you're interested why we have a green 'are headers being lowercased' test that should be red \ud83e\udd14 : the reason is that cacheable-request uses lowercase-keys and this package overwrites keys in the order the keys were set in. So keys with the same lowercased name set later in the execution flow overwrite earlier ones. The user-agent happens to be the one header that's a default, and gets set before the passed headers get merged and that's the reason the test passed. All others get set before got executes any logic that results in additional headers being set.. Not sure what this has to do with the json option \ud83e\udd14 . That option is there for convenience. If the common use case is to send and receive JSON, that's what I would have it cover. Whether that's through Ky-like response transformations seems beside the point. I'd ask the community if it's unclear what convenience options they'd like to have or remove the option and see what issues pop up.\nSecondly, you're proposing to split deserializing from serializing and content-type or accept header setting. I proposed this in #174 back in 2016. I still quite like that idea, although at the time Sindre felt it was too imaginary a problem.\nAs for the form of this interface, I get that Ky does it that way since it lives in browser land. I've always felt using methods to consume response objects containing streams, reading them to completion and then deserializing using a function unique to that particular method is quite ugly. Besides, got's promise interface already buffers the stream. I'd specify a deserialization or parsing function and optionally add some convenient way to define them.\nDisregard my points at your leisure, I feel preserving the positive momentum you've got going in improving got is much more valuable than the above @szmarczak \ud83d\udc4c \ud83d\ude1a.. > Well, it has been discussed in 6 issues mentioned above. I think it's enough to make a decision :)\nHm. I agree!\nRegarding the register function. Looks good \ud83d\udc4c. A small note is I would prefer an interface that only lets you pass a function for a given content type once. I would, therefore, gravitate towards some sort of option. Maps are like simple functions and I love simple functions haha.\nIt would also obliviate the need to call the parser. After all, why pass us the parser if we don't do the parsing for you?\nSomething like:\njs\ngot({\n  registerParsers: {\n    'application/json': JSON.parse\n  }\n}). I don't think there's any specific reason we haven't.\nAll it needs is a PR! \ud83d\ude04\nI'll leave this issue here, for now, to see if anyone wants to pick it up.. @GHNewbiee I'm afraid that is rarely how open source works \ud83d\ude05 . \nI mean, yes, they could probably get the change done the quickest, but one also needs time to do it, and a reason to. Considering that person already choose not to put SuperAgent in the table betting on them is not great even if you had put in the effort to look up who did it and kindly asked them to add SuperAgent.\nIf this is valuable to you, I suggest you add SuperAgent. We'll be happy to review \ud83d\ude0a . If enough people upvote your issue chances are a friendly person will go and do it for all those people. On the other hand, if no one else is running into this need and you don't care too much about it either, we'll just close this issue.\nDoes that sound fair?\nI'll also update the title to change the question to a feature request \ud83d\udc4d .. No haha, that does not sound fair to me @GHNewbiee , I have major disagreements with the points you're making \ud83d\ude05 , but also don't see a reason to get into it here.\nWith regard to your question:\n\nShould comparison table include SuperAgent?\nThe short answer is: 'Maybe, not sure. A PR is welcome. If many people ask, one of the maintainers might step up.'\n\nI'm unsure why you're talking about the possibility of closing \ud83e\udd14. To be clear, I see no reason to close this issue before people have had the time to upvote it. I'd say let's leave it open for now \ud83d\ude01.\nI do hope someone picks it up for your sake \ud83d\ude4f \ud83d\ude0a.. Thanks for sharing the possible improvement. I checked our example \ud83d\ude04 .\nI also took the liberty to debug your code. form-data's error is indeed quite cryptic (I'll open an issue in form-data). The only issue is that you're passing undefined as a value to append. Here's an annotated version of your code that highlights the problem:\n```js\nconst got = require('got');\nconst FormData = require('form-data');\nconst form = new FormData();\nconst user = { avatar_file: 'abc.png' }; // no nickname in here\nform.append('nickname', user.nickname); // <- you're passing undefined here\ngot('http://requestbin.fullcontact.com/18qsbve1', {\n    method: 'PUT',\n    body: form,\n})\n    .then(res => { res.statusCode === 200 && console.log('yay!'); })\n    .catch(() => { console.error('Uh oh'); });\n```\nSo got actually never got the formdata! The code blew up before that point. Good luck with the rest of the app \ud83d\ude4c !. @szmarczak you pointed out another inconsistency, I thought I'd might as well look at all emphasis use then.\n\nPrefixed lines warning about the effect of using an option with a **Note**:.\nNotes come after properties but before any explanation. This is the middle ground solution I came up with for #511 . It turns out this was already the case for some properties.\nLines that used full line emphasis to suggest an alternative now use **Tip**:.\nI escaped an asterisk (what a word \ud83d\ude02) in the comparison table.\n\nI in no way expect future PRs to follow the above. Wouldn't want to make doc changes hard. It's how people often get involved in projects. Don't want to be difficult there \ud83d\ude0a .. @sindresorhus I felt the same \ud83d\ude02! I should've taken the opportunity \ud83d\ude48.. Fair question. Too long ago to remember what the issue was. Fairly sure I tried. But maybe I wrongly assumed t.is would run into the same problem as t.throws. I'll try tonight!. You were super right. That works fine. Updated the PR.. This one doesn't work \ud83d\ude13 .. > p-cancelable returns immediately when asked to cancel a settled promise. I worry about the use-case where a user tries to cancel a settled promise but won't know the request went through. I can imagine that's problematic especially when a user doesn't care much about a response but is going for more of an RPC type deal.. Hmmm. Alright. That means coming up with a way to easily test the request actually gets canceled. Don't want to simply repeat what I did in the previous test. I'll come up with something clean. Give me a couple minutes.. Nice catch. I was confusing is-obj and is-plain-obj.. I did a little testing and a little thinking. Trying to resolve an already settled promise seems to do nothing in the case of Node too. A note in the documentation is enough.\nI think you're right on this.. Done :3.\nI don't think we should. It sounds worse, granted, but Node consistently calls it 'abort'.. \ud83e\udd26\u200d\u2640\ufe0f . Cool, so we alphabetize after complying with the import plugin rules?. I just tried this. The test fails without. Turned it back into what it was. I remember now I wrote it your suggested way first. Not sure why this demands to be lazily evaluated. My JS-foo is not strong enough (yet).. Of course. I'll fix it.. Sure. It'd be nice to test both the native and shim. I'm swapping it out. Just to make sure, how does the rest feel about going from a lib that's seen tons of use to something that's still in alpha?. Sorry \ud83d\ude05. It was late.. The rest of the tests tend to take this form:\njs\n    const err = await t.throws(got(`${s.url}/`, {\n        timeout: 1,\n        retries: 0\n    }));\n    t.is(err.code, 'ETIMEDOUT');\nI'd be in favor of testing this way because:\n it offloads worrying about if it throws to ava.\n consistent style is helpful in reducing complexity.. I'd prefer if we kept this joint, it's simpler. Let's discuss it over in the issue.. If we do choose to split the argument validation for json from form we should also have two tests to make sure both work the way we expect.. @vadimdemedes if you have a link to an issue explaining what exactly is amiss and how simply ignoring any bytes uploaded beyond the body size is the right solution. Do share, I'd be happy to add it to the comment. If you don't let me know and I'll go looking myself.. Just curious, is there a reason behind this number? 6 2/3 times a second?. Can header size change during upload? Otherwise, I don't see the point of putting this inside the interval or even the on 'connect'.. Why didn't you suggest this approach for the second test \ud83e\udd14 ? Did you know it would break?. Sorry for letting my ego creep into the code \ud83d\ude48 .. To be honest, I don't feel these are useful at all. I'd simply say that if we end up preferring global over imported URL and we're at a point where our lowest target is Node 10, anybody can feel free to change it.\nUntil then, even assuming it is a change we don't want to forget to make, I don't see the point in having the comment.\nRegardless, I don't like being too opinionated on a project I've been away from especially on a trivial two line change \ud83d\ude0a , so fixed!. This doesn't seem right \ud83e\udd14 .\n(Yet it passed the test). What can I tell you \ud83d\ude05 ? Computer says no.. Out of curiosity, why Reflect? Why not hasOwnProperty?. Just to be a little more clear \ud83d\ude05 , if Node feels that the default HTTPS port should not be added if the protocol is already HTTPS, I guess that's fine. I wouldn't write code to go against what Node does.. What \ud83d\ude05 .. Can this be more descriptive? Maybe something like 'init is called with options'?. ",
    "lpinca": "Would you accept a PR that reverts https://github.com/sindresorhus/got/commit/62ff082deb41e711ae29c9e09ce173eef04390d6? It doesn't make sense imho as the auth option is a valid option for http.request().\nOn top of this https://github.com/sindresorhus/got/pull/329 introduced a breaking change in version 7.1.0. Previously the error was thrown only when using a URL string. Now it is thrown even when using a URL object.\njs\ngot({ hostname: 'example.com', auth: 'foo:bar' })\nshould not throw/reject.\n. Does it make sense to return the unparsed body?\nIf I'm not mistaken if the status code is 204 and there is a body we only prevent it from being parsed.\n. Ok, I will update it and add a couple of tests in a bit.\n. I think we can remove the check for the 204 status code completely as no data chuck is fired on the client.\nHere is a test case:\n``` js\n'use strict';\nconst http = require('http');\nhttp.createServer((req, res) => {\n  res.statusCode = 204;\n  res.end(JSON.stringify({ a: 1 }));\n}).listen(3000);\n```\n``` js\n'use strict';\nconst http = require('http');\nhttp.get('http://localhost:3000', res => {\n  res.on('data', () => {\n    throw new Error('Chunk retrieved');\n  });\n});\n```\nIn short, there will never be something to parse if the status code is 204.\n. ",
    "felixfbecker": "I have a Node backend that is doing requests on arbitrary provided URLs. It seems pointless to me that I have to manually parse the URL, check if there is auth in it, then put it into the auth option. It's nothing but unneeded code and trips up users because they don't know/expect they need to handle this manually.. js\nconst auth = [url.username, url.password].filter(Boolean).join(':') || undefined\nconst u = new URL(url.href)\nu.password = ''\nu.username = ''\nawait got(u.href, { auth }). Note that auth and auth in the URL are not the same. There are APIs (e.g. GitHub, Sourcegraph) that allow you give an access token in the URL, which is convenient in environments where you can only configure a URL but not e.g. headers. But when put into the Authorization header, these APIs usually require it to be with the Bearer scheme (or Token), not Basic. auth however sets Basic, which is usually not recognized.\nI also don't understand why this decision was made based on Chrome's decision despite the readme saying\n\nGot is for Node.js. For browsers, we recommend Ky.\n\nwhen Node has never deprecated this (and I doubt ever will).. > Node seems to already turn user:pass@host.tld into an Authorization header.\nAre you sure? I used request and axios against an API that supports an auth token as the \"username\" in the URL, but not Authorization: Basic (only Authorization: token), and they both work (while got throws).. A console.warn() (made to only log once) and an option unsafeAuth sounds fine to me.. Imo if you want to prevent that you should add this validation at the top layer where the user input enters your application, not at the lowest layer where you start making the request.\nIt's a oneliner: url => !!new URL(url).username. Iirc joi supports adding your own validation functions.. Note that for example OAuth2 also specs the access_token query parameter, which is also part of the URL, but got doesn't throw or warn on that :). ",
    "szmarczak": "@sindresorhus What's your thoughts?. https://github.com/szmarczak/http2-wrapper. > From a very quick look on this source code szmarczak/http2-wrapper I think that it doesn't handle the http2 vs https negotiation.\nI don't think the https module automatically chooses when to use HTTP and when HTTPS, right? Like http is for HTTP only and https is for HTTPS only, so http2-wrapper is for HTTP/2 only.\nAs you pointed out, it's very easy to implemented the protocol negotiation using ALPN :)\n\nI've created an http2-client that completely mimcs the http / https native modules while supporting http2.\n\nI checked right now, I disagree. It doesn't not mimic the original http/https module behavior when using http2 :). Yeah, sure.\ngot uses modules which use the http/https API. http2-wrapper was created to use http2 like http, so there's no need to change your code when you need to support H2.. > If a server supports only H1.1 / H2 I afraid that it will require the client to make changes in his code.\nNot necessarily. We could make a TCP connection, get ALPN and make a request with that socket by passing createConnection option. But yeah, it isn't best practice.. @pietermees \n\nmy understanding is that it doesn't yet support connection reuse like you would do with an agent, correct?\n\nYes, it does:\nthere's a session option (accepts ClientHttp2Session) instead of the agent option.\nYou just need to do:\njs\nconst session = http2.connect(authority);\nconst request = wrapper.request({...options, session});\nconst secondRequest = wrapper.request({...options, session});. @pietermees \nExample:\n```js\nconst http2 = require('http2');\nconst {request} = require('http2-wrapper');\nconst got = require('got');\nconst h2got = got.extend({request});\nconst session = http2.connect('https://google.com');\n(async () => {\n    await h2got('https://google.com/someUrl', {session});\n    await h2got('https://google.com/someUrl', {session});\n})();\n``. @pietermees Could you make a [http2-wrapper](https://github.com/szmarczak/http2-wrapper) issue? So I don't forget :). New version of [http2-wrapper](https://github.com/szmarczak/http2-wrapper) released:0.4.0`. Many bug fixes etc. Upgrade very recommended. It's much stable now.\nHere's Got example for HTTP2 with ALPN negotiation (supports HTTP, HTTPS and HTTP2) :tada:\nhttps://gist.github.com/szmarczak/59db2fa713aa7f52949d343d9cf93ff6. @paambaati The problem is you are trying pass ClientRequest to options.request, while it should be a function. Just revert your changes and do this:\njs\n    const {body: h2body} = await got('https://nghttp2.org/httpbin/headers', {\n        json: true,\n        headerTableSize: 65536,\n        maxConcurrentStreams: 1000,\n        initialWindowSize: 6291456\n    });. http2-wrapper@0.4.1 has dedicated function for resolving ALPN using HTTP request options.\nNow, it's much simpler to create Got instance with ALPN negotiation :D\n```js\nconst http2 = require('http2-wrapper');\nconst {extend: gotExtend} = require('got');\nconst got = gotExtend({\n    hooks: {\n        beforeRequest: [\n            async options => {\n                if (options.protocol === 'https:' && !options.request) {\n                    const {alpnProtocol, socket} = await http2.auto.resolveALPN({\n                        ...options,\n                        resolveSocket: !options.createConnection\n                    });\n                if (socket) {\n                    options.createConnection = () => socket;\n                }\n\n                if (alpnProtocol === 'h2') {\n                    options.request = http2.request;\n                } else {\n                    options.session = options.socketSession;\n                }\n            }\n        }\n    ]\n}\n\n});\n. @pietermees You're right. It is so, because to solve https://github.com/szmarczak/http2-wrapper/issues/6 [`session[kState].pendingStreams`](https://github.com/nodejs/node/blob/master/lib/internal/http2/core.js#L952) (+some events) needs to be exposed. Let's raise a Node issue about that..js\nconst instance = got.extend({\n    hooks: {\n        beforeRequest: [\n            options => {\n                options.body = JSON.stringify(options.body);\n            }\n        ]\n});\ninstance(url, options);\n```. Custom instances are even simpler ;) No need to set headers every time or stringify the body :P. >  So how to make a request with json content but response is a html?\nAs far as I'm good with English, IOW you said to make a request which body is JSON, and the response body is HTML. So I think you're confused here :). Ability to add new options would be cool too.. Here it comes: #503. This can be fixed in a three ways:\n\nenable flowing mode (recommended)\n\njs\ngot.stream.get(GCC_URL)\n.on('response', function(res)\n{\n  res.pipe(fs.createWriteStream('out.tgz'))\n}).resume()\n\nsend the main stream to /dev/null (not recommended)\n\njs\ngot.stream.get(GCC_URL)\n.on('response', function(res)\n{\n  res.pipe(fs.createWriteStream('out.tgz'))\n}).pipe(fs.createWriteStream('/dev/null'))\n\nIncrease output's highWaterMark. (needed only if you want to process it later)\n\n\nOnce the total size of the internal read buffer reaches the threshold specified by highWaterMark, the stream will temporarily stop reading data from the underlying resource until the data currently buffered can be consumed (that is, the stream will stop calling the internal readable._read() method that is used to fill the read buffer).\n\njs\n    const input = new PassThrough();\n    const output = new PassThrough({highWaterMark: bytes});\n    const proxy = duplexer3(input, output);. Current workaround looks something like:\n```js\nfunction make(tries = 0) {\n    try {\n        got.stream(URL)...\n    } catch (err) {\n        if ((err.code === 'ESOCKETTIMEDOUT' || err.code === 'ETIMEDOUT') && tries < 2) {\n            make(tries + 1);\n        } else {\n            throw err;\n        }\n    }\n}\nmake(); // throws if tried 2 times and got timed out error\n``. @silentroach The thing is that if it errors while downloading you could get duplicated response.. @silentroach Not necessarily. If the response body is short, then everything will be sent in one packet, thus thedata` event will be emitted immediately.. Closed because of lack of response.. > I don't think we should support an url option, but I do think we should detect the mistake and throw a useful error.\nIt already does, but it isn't very useful.\nTypeError [ERR_INVALID_URL]: Invalid URL: http:\n    at onParseError (internal/url.js:234:17)\n    at parse (internal/url.js:243:3)\n    at new URL (internal/url.js:318:5)\n    at new URL (internal/url.js:316:14)\n    at module.exports (/home/szymon/Desktop/got-master/source/request-as-event-emitter.js:19:38)\n    at PCancelable (/home/szymon/Desktop/got-master/source/as-promise.js:13:19)\n    at PCancelable._promise.Promise (/home/szymon/Desktop/got-master/node_modules/p-cancelable/index.js:32:11)\n    at new Promise (<anonymous>)\n    at new PCancelable (/home/szymon/Desktop/got-master/node_modules/p-cancelable/index.js:29:19)\n    at module.exports.options (/home/szymon/Desktop/got-master/source/as-promise.js:12:21)\nTested on master.. Now it throws Error: Parameter 'url' is not an option. Use got(url, options) :tada: . readme.md (updated):\n\ntimeout\nType: number Object\nMilliseconds to wait for the server to end the response before aborting request with ETIMEDOUT error (a.k.a. request property). By default there's no timeout.\nThis also accepts an object with separate connect, socket, and request fields for connection, socket, and entire request timeouts.\n\n\n\nIs the following the exact equivalent of the above in 7.0.0, or do I not need to change anything?\n\nYes, it is. There's no need to change anything.. @brandon93s Yeah. Haven't checked this one.. I can help you :fire: . Lots of things is gonna change soon, so I see no sense of doing it right now. Tests need to be rewritten anyway. I've got an idea: add some new hooks, so we don't have to implement EventEmitter to listen for connection, abort events etc.. ```js\n'use strict';\nlet closes = 0;\nrequire('http').createServer().on('connection', (socket) => {\n    console.log(Date.now(), 'connection');\nsocket.on('end', () => {\n    console.log(Date.now(), 'disconnect')\n    closes++;\n});\n\n}).listen(31337);\nconst got = require('../got-api'); // change the folder if needed\nconst request = require('request-promise-native');\nconst func = got; // change this to request\n(async () => {\n    for (let i = 0; i < 1000; i++) {\n        try {\n            await func('http://localhost:31337', { timeout: 10 })\n        } catch (err) {}\n    console.log(`i=${i},` +\n                `handles=${process._getActiveHandles().length}, ` +\n                `requests=${process._getActiveRequests().length}, ` +\n                `closes=${closes}`);\n}\n\n})();\n```\nIt doesn't matter if it's got or request. After that I always get bunch of:\ntcp        0      0 localhost:XXXXX         localhost:31337         TIME_WAIT\nAccording to man netstat:\n\nTIME_WAIT\n              The socket is waiting after close to handle packets still in the network.. Not reproducible with master.. @sindresorhus I want to help :unicorn: . @sindresorhus It's not needed to pass an object to http.request(). See https://nodejs.org/dist/latest-v8.x/docs/api/http.html#http_http_request_options_callback\noptions \\<Object> | \\<string> | \\<URL>\n\nurl-to-options is a bit outdated. The newer version is:\nhttps://github.com/nodejs/node/blob/8476053c132fd9613aab547aba165190f8064254/lib/internal/url.js#L1321-L1340\nInstead:\nhttps://github.com/sindresorhus/got/blob/09eee393d71e5810c93a5cf62150f95798a0e21c/index.js#L537-L542\nWe can do something like this:\njavascript\n options = {\n    url,\n    ...options\n };\nI'll try to do that :fire:\n. > But there's no way to pass an URL and options to http.request... You have to choose either.\nOh, you're right. I forgot (headers etc.). :confused: I think we can't get rid of that then.. @DerTieran\n\nCould something like this be done by default?\n\nIt could be, but we need to discuss this. If it's the most what users want, then I think yes.\n\nOr is there a better solution for this already?\n\nNo.. > We could ignore the json option when it's a stream and it was created by extend/create, and document it?\n:+1:\n\nAny other suggestions?\n\nI don't see any. The solution above would be best IMO.. Similar ideas were proposed many, many times. I don't think it's worth it, because to achieve the same you just need one more line of code: let parsed = JSON.parse(response.body);. @rwlaschin This doesn't look like a Got issue \ud83e\udd14 . I can't reproduce: https://gist.github.com/szmarczak/61130bc351c72f2ee1e2228429b1df4d\nAPIs:\n - promises\n - streams\nVersions:\n - master\n - 8.3.2. @brandon93s No and yes. No, because the stacktrace should show more details. It's because setImmediate is used. But that's how Node.JS deals with that, so I don't think we can help with that.\n```js\n    const EventEmitter = require('events');\nconst givesPromise = () => new Promise((resolve, reject) => {\n    const ee = new EventEmitter();\n\n    ee.once('error', e => {\n        reject(e);\n    });\n    // ee.emit('error', new Error('stacktrace not lost')); return; // uncomment this line and you'll see it gives more info\n    setImmediate(async _ => {\n        ee.emit('error', new Error('stacktrace lost'));\n    })\n});\n\n(async function() {\n    try {\n        await givesPromise();\n    } catch (e) {\n        console.log(e);\n    }\n})();\n\n``. The most probably thing is that you setcontent-encoding` header. Got gives uncompressed body, so when the browser tries to decompress the [uncompressed] data it fails and closes the connection.. Try:\njs\n        Object.keys(response.headers).forEach(key => {\n            if (key !== 'content-encoding') res.setHeader(key, response.headers[key]);\n        });. @davalapar https://github.com/sindresorhus/got#json\n. @sindresorhus could you look at this?. Sorry, I messed up with the commits, check this one \ud83d\ude04 . @kevva Done.. @sindresorhus Yes, that commit fixes the issue \ud83d\ude03 The tests aren't faulty. But it still tries to retry after calling req.abort() (and on every retry it aborts the request again). req.abort() makes an error like this:\njavascript\n{ Error: socket hang up\n    at createHangUpError (_http_client.js:330:15)\n    at Socket.socketCloseListener (_http_client.js:362:23)\n    at Socket.emit (events.js:164:20)\n    at TCP._handle.close [as _onclose] (net.js:558:12) code: 'ECONNRESET' }\nwhich is catched here. I've updated my PR to fix this, please take a look at it.\n. @sindresorhus yes, but before your fix it wasn't passing it. It just tests 'does it perform the request after aborting'. Successfully it doesn't perform it, it gets aborted before it's executed. I hope you understand :P\nI don't test if it tries to retry. But yes, it still retries and I've fixed this in this PR, but I haven't added a test for it.. @sindresorhus Done \ud83d\ude03. @AsaAyers Hmm, I've checked your issue on Windows 10 (latest got version), I got such error, but there's no onSocketConnect. The process exits normally. Take a look:\n```\n\nnode blah\nclearInterval(undefined)\nerror { RequestError: connect ECONNREFUSED 127.0.0.1:55555\n    at ClientRequest.req.once.err (C:\\Users\\Szymon Marczak\\Desktop\\project\\node_modules\\got\\index.js:183:22)\n    at Object.onceWrapper (events.js:254:19)\n    at ClientRequest.emit (events.js:159:13)\n    at Socket.socketErrorListener (_http_client.js:389:9)\n    at Socket.emit (events.js:159:13)\n    at emitErrorNT (internal/streams/destroy.js:64:8)\n    at _combinedTickCallback (internal/process/next_tick.js:138:11)\n    at process._tickCallback (internal/process/next_tick.js:180:9)\n  name: 'RequestError',\n  code: 'ECONNREFUSED',\n  host: '127.0.0.1:55555',\n  hostname: '127.0.0.1',\n  method: 'GET',\n  path: '/',\n  protocol: 'http:',\n  url: 'http://127.0.0.1:55555/' }\n```. Sorry, but after half a year I've finally found the solution (I've just looked at the code for some improvements today). There's a bug:\n\nhttps://github.com/sindresorhus/got/blob/21bef3c54106a28e9a2198eb01cb249d2d555e87/source/progress.js#L62-L68\nIf the socket closed before it connected (important thing: line 62 must return false), onSocketConnect is called: socket.connecting is false but it isn't writable (so it's destroyed). Using defer-to-connect (v1.0.1) would fix that.. I did some digging:\n\noptions.body was added in 2c8ee3f\nWritableStreams were added in c080439\n\nIt's mutually exclusive, because if you provide the body option it's no longer writable:\nhttps://github.com/sindresorhus/got/blob/c080439382f1619fc664fcdb81788e4466d94b0e/index.js#L105-L110\nThe same piece of code you can find in v8.3.2 (the newest version as of 31.07.2018):\nhttps://github.com/sindresorhus/got/blob/ad7b361dcb2490c3864b845b979b756f13f7d89b/index.js#L441-L445\nhttps://github.com/sindresorhus/got/blob/ad7b361dcb2490c3864b845b979b756f13f7d89b/index.js#L457-L460. It doesn't matter if body is a string or stream.Readable. I think it's clear if you provide body then you want to pipe it to the request :)\nAnyway, I agree, we can clarify that sentence. Something like Providing this option will make the stream read-only.? I'm open to your ideas :)\n@sindresorhus What are your thoughts?. If the result of retries is 0, that means you don't want to retry. So that works as expected.\nhttps://github.com/sindresorhus/got/blob/ab5e8e1509d95b01756d40546eea0868849a1d35/source/request-as-event-emitter.js#L134-L147\nFrom the docs: https://github.com/sindresorhus/got#retries\n\nOption accepts function with retry and error arguments. Function must return delay in milliseconds (0 return value cancels retry).. > I was expecting a retry in case of REQUEST TIMEOUT,\n\nI've looked at the code, and that's how it works: throws an error.\nhttps://github.com/sindresorhus/got/blob/ab5e8e1509d95b01756d40546eea0868849a1d35/source/as-promise.js#L10-L13\n/cc @sindresorhus. Duplicate of #458. Not reproducible with master.. @sindresorhus Yes, it does, but then... You enforce the user-agent header. It gets replaced if there is one set by someone, but it got deleted because it was null. \ud83d\ude15 I'll send a PR.\nhttps://github.com/sindresorhus/got/blob/54cead2d7f9cde1a946f6d46e770bd951b37baed/index.js#L530-L540. You can use this API:\n\n.on('redirect', response, nextOptions)\nredirect event to get the response object of a redirect. The second argument is options for the next request to the redirect location.\n\nThen save HTTP status code for each redirect. If you want more, it could store all the responses, but there's no need. It'd be too bloated.. For me it seems this should be caught on our side. The constructor of cacheable-request may throw an error, so I think you're wrong...\nhttps://github.com/lukechilds/cacheable-request/blob/18df2e8893ba48bb462083d4d989fdd4d5006433/src/index.js#L14-L26\nWe call it without any catch.\nhttps://github.com/sindresorhus/got/blob/d7641e5bcc3c63e45842bc95726c63509c3d6b65/index.js#L96-L97\nThis line makes that error:\nhttps://github.com/lukechilds/cacheable-request/blob/18df2e8893ba48bb462083d4d989fdd4d5006433/src/index.js#L43\nThis is what it looks like:\ngot1 -> cacheable-request2 -> got3 -> cacheable-request4 -> normalize-url5 -> decodeURI (error)\n1 - Here we verify if requested URL is valid UTF-8.\n2 - cacheable-request doesn't throw an error, there's valid UTF-8.\n3 - got receives a redirect but doesn't validate the URL. Calls cacheable-request without any catch.\n4 - cacheable-request needs to normalize-url\n5 - decodeURI fails, but there's nothing to catch that.\n3 is our fail. We need to validate URL here or here (it doesn't matter, cuz we'll ee.emit('error', err) either way). We currently don't do that. Or we need to try { ... } catch (e) { ... } every time we call get(opts). It's caught here, but not here and not here.\n. I'm not sure if you're talking about errors thrown by callback on cacheable-request side. Yeah, it could be caught and emitted, but it depends on cacheable-request author's choice.. Done. Please see if it's good :unicorn: . Weird. Suddenly it fails. I'll send a PR.. Gotcha! :unicorn:\nrequire('extend')(true, {}, { x: undefined }) -> {}\nNot my fault. I had sent this PR before got has used extend dependency.\n058452b011ae2285697ef1b408ab5e8a4a9be0ae broke that.. Also, I sometimes get that on my Ubuntu 18.04, too.\n```bash\nsocket-destroyed \u203a clear the progressInterval if the socket has been destroyed\n/home/szymon/Desktop/got-patch-1/test/socket-destroyed.js:7\n6:   const err = await t.throws(got(http://127.0.0.1:55555, {retry: 0}));\n   7:   t.is(process._getActiveHandles().length - handlesComingFromAVA, 2); \n   8:   t.is(err.code, 'ECONNREFUSED');                                       \nDifference:\n\n1\n2\n```. I'll do my best :unicorn: . > Can you explain the change?\n\nWhat it does: it wraps p-timeout. I've changed that so it doesn't.\nPlease see the issues. The timeout has began since asPromise() was called. Until we make a request (real request, http(s).request) it may pass a few ms. Also, it doesn't retry on ETIMEDOUT because p-timeout throws that and rejects the promise. Merged request timeout into timed-out. :tada: \nhttps://github.com/sindresorhus/got/blob/ab5e8e1509d95b01756d40546eea0868849a1d35/source/as-promise.js#L10-L13\nForgot to add t.is(tried, true); to tests :smile: So this is why it has passed them without this change :boom: . > What's the difference between .fork() and .create()?\nFork - forks the options from parent instance (squashes them into a new piece, performs assignOptions again), replaces methods and handler if provided.\nCreate - imagine there are no options, no methods, no handler. You set it up from scratch. Like another got, not inherited from any instance.. @brandon93s I would leave the names unchanged. Previously got.extend() was named got.fork() (original creator named it got.create() but we need a real got.create() - no defaults). I would just note in readme.md/xxx.md the difference between got.create() and got.extend(). I can rename it anytime if it's needed.. @sindresorhus So I'll do that tomorrow then :unicorn: . @brandon93s You're right, I should've documented that better. \n\nDoes this imply that an app would be using three instances of got?\n\nNo. But it says so, I need to change the docs then.\n\nSeems that this could just be handled by constructing / merging numerous config objects together instead of mashing instances together.\n\nThat's how it's done!\nhttps://github.com/szmarczak/got/blob/074462ae98c8ea27108db17d8d59ee10199bd3c3/source/create.js#L46-L50\nNote: this comment is outdated.. I used to do limit(gotInstance, bytes) to limit download & upload or\nprocess(() => limit(gotInstance, bytes)) when I needed to make request many times + limit that.\nInstead of process(() => limit(gotInstance, bytes)) we can do something like\n```js\nconst instance = process.merge(limit);\ninstance(url, { limit: bytes })\n```. Real example (note: not tested): https://gist.github.com/szmarczak/86217216ad2fbc0c8a3e833e5f290460. @brandon93s Yeah. We could do something like this:\n```js\nconst merge = (a, b) => got.create({\n    methods: a.defaults.methods,\n    options: got.assignOptions(a.defaults.options, b.defaults.options),\n    handler: (options, next) => a.defaults.handler(options, options => b.defaults.handler(options, next));\n});\nconst ghLimit = merge(ghGot, limit);\n```\nBut consider merging many instances. Think about plugins, like limiting download & upload, switching to HTTPS where possible, new options etc. :). @jstewmon Can you review this? I'd be very grateful if you left some notes :smiley: . > It adds complexity (maintenance risk) to the code base for a very advanced used case.\nMaybe.\n\nSince extensive documentation is already needed for it, we could offer tips on how to merge instances in the readme as opposed to offering it in core.\n\n:+1: \n\nA separate module could also support this need.\n\nA separate file? Of course, but it's very hard to do so. create requires merge, merge requires create and so on. I know Node.JS supports circular require() calls, but I don't think it's gonna work.\nAnother idea:\njs\ngot.register('functionName', function() {});\ngot.functionName();. > There might be use-cases for this, but I'm a little bit reluctant as this locks us into support the ability to arbitrarily merge instances.\nIndeed.\n\nThere might be features we want to add in the future that makes this difficult. \n\nThat's with every single feature, isn't it? :)\n\nAnd we have yet to figure out a way to support plugins, which might or might not overlap or conflict with this.\nSo in short, I just feel like this is rushing into supporting a huge API surface without enough time and exploration to see what problems it solves and the alternatives.\n\nUnderstood. Better to consider all the alternatives we have here. I'll leave this PR open. This feature is too complicated to release it now.\nTomorrow I'll send two PRs with these changes:\n- expose assignOptions to enable proper options merging (custom instances)\n- better handler function: (normalizedOptions, next) instead of (options, next)\n  - move baseUrl option from main handler to normalize-arguments.js. This PR will receive a new feature: defaults.mergeable - tells whether an instance is mergeable or not. Throws if trying to merge not-mergeable instance.. TODO: define throwing setter for options.baseUrl here. > An alternative might have been to not make json a Boolean and instead make it the actual JSON body to be used instead\nTip: do not make things ambiguous. This beautiful sentence solves your problem:\n\nare you sure doubling documentation is the helpful rather than users reading the documentation in the first place?\n\nAnyway, I don't mind a note in the README that the body is stringified (though it's obvious) :). #671 is gonna solve this :). I would change:\njs\n    const options = {\n        protocol: url.protocol,\n        hostname: url.hostname.startsWith('[') ? url.hostname.slice(1, -1) : url.hostname,\n        hash: url.hash,\n        search: url.search,\n        pathname: url.pathname,\n        path: `${url.pathname}${url.search}`,\n        href: url.href\n    };\nto:\njs\n    const options = {\n        protocol: url.protocol,\n        hostname: url.hostname.startsWith('[') ? url.hostname.slice(1, -1) : url.hostname,\n        hash: url.hash,\n        search: url.search,\n        pathname: url.pathname,\n        path: `${url.pathname}`,\n        href: url.href\n    };\n    if (url.search !== null) {\n        options.path += url.search;\n    }. Opened an issue at node repo: https://github.com/nodejs/node/issues/21762. Note: creating got instances is still in the works.\nSeems good, but I don't see any sense of that. You could just do:\n```js\nconst sign = ...;\nconst instance = got.create({\n    options: got.defaults.options,\n    methods: got.defaults.methods,\n    handler: (url, options, next) => {\n        options.headers['sign'] = sign(options);\n    return next(url, options);\n}\n\n});\n```\n\nAlong the way, I made a couple of tweaks to other areas of the code, which I included here in separate commits.\n\nCan you do another PR for that? To make everything more clear :). @brandon93s +1. ~~~But how do hooks compare to EventEmitter? What's the advantage?~~~. @jstewmon Is this issue fixed in https://github.com/lukechilds/cacheable-request/pull/44?. > Should these go under hooks? These are actually EE listeners, so it might be better to give them a discrete top-level config key like listeners. This would also disambiguate them from hooks, which are stated to allow modification during the pipeline.\nYou're right.\n\nThe EE listeners can't modify anything, so they should not be awaited even if they are async.\n\nI don't understand. EE listeners aren't awaited.\n\nI don't think it makes sense to have some aspects of instance configuration be frozen while others are not. Pick one - frozen or unfrozen. I don't see a practical reason why the configuration is frozen... \n\nIt's frozen to prevent unwanted changes to the instance. But yeah, some people might want to keep them frozen and some people might want to not. My proposal: to enable freezing people will need to set defaults.preventChanges to true (false by default).. I'm closing this due to a GitHub crash. This PR doesn't see new commits. I'll create another PR when I'm done with fixing things. Big thanks to @jstewmon for letting me know what I've done wrong! :raised_hands: . > You're using callAll, which awaits the hook function, in response to an EE event.\nIt's fixed in the upcoming PR.. > Can we agree that the options should either be frozen or not?\nMy answer: defaults.preventChanges. The default value still needs to be discussed.. @jstewmon ping. > options should be frozen or not, without exceptional cases, so we don't need any of the changes that allow for hooks to be modified if the config is frozen.\nI think you're right \ud83d\udc4d If defaults.preventChanges is set to true, hooks should be frozen. If it's set to false, hooks shouldn't be frozen. Good point!\n\nonly known hooks should be validated, so that callers are not unnecessarily constrained on what is a valid object\n\nThe situation you describe was active in the previous PR. It's not active anymore. :)\n\nObject.entries is not an equivalent for for (... of ...) or Array.prototype.forEach\n\nI still don't see what's wrong with that. People can use this feature to name hooks.\nIt's not a bug. It's a feature!\ngot.hooks.beforeRequest.mySuperHook = .... @jstewmon Is it better now? I could take off the shortcut for hooks and make another PR for that, but that's just only a few lines so I don't think it's needed.\n@sindresorhus Can you say something regarding this PR?. I've just realized this PR doesn't change anything.. Yeah, completely forgot about this.. > Are we absolutely sure ESOCKETTIMEDOUT can never be thrown?\nYes. It has been created by request originally. I don't see that anywhere else.\n@jstewmon We should throw ECONNRESET: socket hang up instead of ETIMEDOUT when the socket is connected and one of the timeouts has occurred, as Node.js does.. Yeah, then better use ETIMEDOUT.. @jstewmon You forgot git add ;) There's no merge-options file.. @jstewmon I would send a review, but you've blocked me. :tada: Congratz.\n\n\nAvoid new Array. See this for more explanation.\n\n\nWhat does extend overwrites null mean?\n\n\nAlso please test markdown links because the ones you provided don't work.. > Not sure I see the point of this. Example use-case? I generally prefer not exposing this unless absolutely necessary.\nSimple example:\n```js\nconst {beforeRequest} = options.hooks;\nconst handler = function (options) {\n    options.headers['some-data'] = this.data; // this = options.hooks.beforeRequest\n};\nbeforeRequest.data = 'someData';\nbeforeRequest.push(handler);\n```\n\nCan you leave it where it is for now so we get a diff?\n\nWorking on it.. > I think it should be up to users to bind methods if they want to use this.\nRight, I'll revert that :). I'll leave this part:\nhttps://github.com/sindresorhus/got/blob/6ba9e68c7f496a69641a8aac51be0781f1ae0eac/source/timed-out.js#L30-L32\nthis makes us sure timed-out isn't called twice or more, although it's obvious we don't do it, so can't make a test for that.. We also need tests for electron support.. I just wonder if this piece of code is needed:\nhttps://github.com/sindresorhus/got/blob/6ba9e68c7f496a69641a8aac51be0781f1ae0eac/source/get-body-size.js#L31-L33\nbecause I tried passing a Buffer as body and this doesn't even get called.. Note: Missing test for #490 and for:\nhttps://github.com/sindresorhus/got/blob/6ba9e68c7f496a69641a8aac51be0781f1ae0eac/source/progress.js#L40-L43. @sindresorhus But it's converted to a stream here:\nhttps://github.com/sindresorhus/got/blob/6ba9e68c7f496a69641a8aac51be0781f1ae0eac/source/normalize-arguments.js#L111-L114. > Hmm, then maybe it returns here:\nYeah, you're right, checked it. So, is it needed? IMO we can get rid of that.. > This should be done in a separate PR though\nSo it will be :)\n\nIt's a good practice to put the message in a variable and use it in both to make absolutely sure they are the same and stay the same in the future too.\n\nDone :unicorn: . >  If it prevents us from getting 100% test coverage\nThe point is: not only that keeps us from 100%. But it's possible to achieve 99% :)\n\nDo you intend to do that in this PR? Asking so I know whether this is ready to merge or not.\n\nNo, that'll be a separate PR too. Yes, it's ready to merge now :). > Something is failing here\nAppVeyor is damn slow. Increasing the timeouts should fix the problem I think. If it does not, I'll fix it in the morning as it's 10:21 PM here.. See? Fixed :). It's hard to test #490 because it occurs randomly.. > Does the new behaviour fix a bug or is it best-practice?\nIt's best practice to avoid bugs. See #223.\nWe could emit the error after the stream.Readable's end event, but there's a chance you'll get only a piece of the response (e.g. flowing mode is on), and we don't want that when we are piping it to a HTTP response.. > If your URL is dynamic it's not a baseURL and you should just call got with a FQD each time instead of using a baseURL. A base url should be static.\nYeah, you're right \ud83d\ude0b . please verify before publish\n|                       |  got  | request | node-fetch | axios |\n|-----------------------|:-------:|:---------:|:------------:|:-------:|\n| HTTP/2 support        |    \u2716    |     \u2716    |       \u2716      |    \u2716   |\n| Promise API           |    \u2714    |     \u2714    |       \u2714      |    \u2714   |\n| Stream API            |    \u2714    |     \u2714    |       \u2716      |    \u2716   |\n| Request cancelation   |    \u2714    |     \u2716    |       \u2716      |    \u2714   |\n| RFC compliant caching |    \u2714    |     \u2716    |       \u2716      |    \u2716   |\n| Follows redirects     |    \u2714    |     \u2714    |       \u2714      |    \u2714   |\n| Retries on failure    |    \u2714    |     \u2716    |       \u2716      |    \u2716   |\n| Progress events       |    \u2714    |     \u2716    |       \u2716      |    \u2714   |\n| Handles gzip/deflate  |    \u2714    |     \u2714    |       \u2714      |    \u2714   |\n| Advanced timeouts     |    \u2714    |     \u2716    |       \u2716      |    \u2716   |\n| Errors with metadata  |    \u2714    |     \u2716    |       \u2716      |    \u2714   |\n| JSON mode             |    \u2714    |     \u2716    |       \u2716      |    \u2714   |\n| Custom defaults       |    \u2714    |     \u2714    |       \u2716      |    \u2714   |\n| Composable            |    \u2714    |     \u2716    |       \u2716      |    \u2716   |\n| Hooks                 |    \u2714    |     \u2716    |       \u2716      |    \u2714   |\n| Issues open           |  |  |      |  |\n| Issues closed         |  |  |      |  |\n| Downloads             |   |   |       |   |\n| Coverage              |   |   |       |   |\n| Build                 |   |   |       |   |\n| Dependents            |  |  |      |  |\n| Install size          |  |  |      | ![][ais] |\n ISSUES OPEN \n ISSUES CLOSED \n DOWNLOADS \n COVERAGE \n BUILD \n DEPENDENTS \n INSTALL SIZE \n[ais]: https://packagephobia.now.sh/badge?p=axios. You really need to check out https://github.com/sindresorhus/ky :heart: . We could use our timed-out.js module for that. It already does measurements. Small changes and it should be done.. https://github.com/szmarczak/http-timer Tomorrow I'll send a PR.. > Having Flowtype static typings would help to catch configuration errors.\nCan you elaborate on the configuration errors? I don't know what these mean, but I'm happy to know :)\n\nIt would add an extra layer of bug-proofness at a cost of additional build step.\n\nIs it really necessary? As for now, got works very well with no bugs (excluding upstream). . > It would be near impossible to code at this scale without static type checking.\nThere are many projects that don't use flow. But yeah, strict typing would be nice. :+1:. @gajus You can achieve what you want using custom instances. I'd use got.create and attach some listeners + logging and done.. > Thats what we are doing already.\nOh.\n\nLogging (not to confuse with debugging) serves the purpose of exposing all available information about application to enable a comprehensive view of all attributes associated with the application.\n\nIMO logging stands for saving data which are useful to improve user's experience. In most cases debugging means using a debugger. The name says that for itself: de-bug, getting rid of bugs.\n\nThats a responsibility of the log consumer, not the application.\n\nIt can be done in both ways. It's just a matter of choice, some people are comfortable with different ways.\n@sindresorhus\n\nI think roarr is a bit heavyweight to include in Got\n\nIt can be a dev dependency :)\nThere are many ways to implement logging. I don't know which way is better, because I only log the URLs of failed requests, so I can't say much. This issue needs more attention.. I see no sense of this, because you can achieve the same by listening to instance.on('request', req => { ... }) and instance.on('response', req => { ... }).\n\nMy suggestion for an implementation to address #557 is to create a peer dependency that exports an events configuration that is applied to a got instance\n\nIMO there's a better way. I'd implement the timings in  the timed-out.js file.. Closing due to lack of response.. @sindresorhus \nThis example is correct (because baseUrl is missing / in the end).\njs\n(new URL('/foo', 'https://sindresorhus/unicorn')).toString();\n//=> 'https://sindresorhus/foo'\nHowever this is a common mistake (/ in the beginning points to http://sindresorhus/):\njs\n(new URL('/foo', 'https://sindresorhus/unicorn/')).toString();\n//=> It returns 'https://sindresorhus/foo' but we expected 'https://sindresorhus/unicorn/foo'\nThere are three ways to fix this:\n\nDon't use / in the beginning:\n\njs\n(new URL('foo', 'https://sindresorhus/unicorn/')).toString();\n//=> 'https://sindresorhus/unicorn/foo'\n\nUse ./ instead /:\n\njs\n(new URL('./foo', 'https://sindresorhus/unicorn/')).toString();\n//=> 'https://sindresorhus/unicorn/foo'\n\nAs you suggested, we could handle it on our own, but I see no sense. That's how URL works.\n\n\nbut seems it just silently throws away the path part...\n\n<a> tags work the same way: http://jsfiddle.net/gp8ba51w/2/\nI'd just update the docs about that behaviour :). @marswong Got 9:\n```\n(async () => {\n    const {body} = await got('get', {baseUrl: 'http://nghttp2.org/httpbin/'});\n    console.log(body);\nconsole.log('---------------');\n\nconst instance = got.extend({baseUrl: 'http://nghttp2.org/httpbin/'});\nconst body2 = (await instance('get')).body;\nconsole.log(body2);\n\n})();\n```\nOutput:\n```\n{\n  \"args\": {},\n  \"headers\": {\n    \"Accept-Encoding\": \"gzip, deflate\",\n    \"Connection\": \"close\",\n    \"Host\": \"nghttp2.org\",\n    \"User-Agent\": \"got/9.0.0 (https://github.com/sindresorhus/got)\",\n    \"Via\": \"1.1 nghttpx\"\n  },\n  \"origin\": \"5.184.0.25\",\n  \"url\": \"http://nghttp2.org/httpbin/get\"\n}\n\n{\n  \"args\": {},\n  \"headers\": {\n    \"Accept-Encoding\": \"gzip, deflate\",\n    \"Connection\": \"close\",\n    \"Host\": \"nghttp2.org\",\n    \"User-Agent\": \"got/9.0.0 (https://github.com/sindresorhus/got)\",\n    \"Via\": \"1.1 nghttpx\"\n  },\n  \"origin\": \"5.184.0.25\",\n  \"url\": \"http://nghttp2.org/httpbin/get\"\n}\n```\nIt works as expected.\n. >  Is there a technical reason the baseUrl has to end in an / other than because that's how new URL() works? If not, I think we should not normalize and add a / to the baseUrl if it doesn't exist. The less unexpected behavior we have to document, the better.\nIt's an expected behaviour, but it may be confusing. I'd leave that as it is.\nIf you prefer the second way, we could throw an error if baseUrl doesn't end with / :). > Why is it an expected behavior?\nWhy it isn't?\n\nYou can have https://sindresorhus/foo (without trailing /) and still have relative links.\n\nThis is the current behavior (which is fine). So, the absolute URL is https://sindresorhus/. Visiting bar won't lead to https://sindresorhus/foo/bar but https://sindresorhus/bar.\nWHATWG URL says:\n\nA path-absolute-URL string must be U+002F (/) followed by a path-relative-URL string.\n\nSo what @marswong wanted is a path-absolute-URL. We could strictly check it and throw if it isn't an absolute URL, but I don't think it's a good idea.\nAnyway, like @beac0n has mentioned, I'd just update the docs.. > This example is invalid. I can't really reply until I know what you were trying to argue.\nLet's skip what I said then, it doesn't really matter because as you've pointed out, we were talking about different things, and I agree.\n\nWhy not just append the / then?\n\nThat behavior would be confusing (at least for me with the behaviour of the URL class). I'd prefer throwing an error if baseUrl doesn't end with a backslash. It should be strictly defined.. > Why not just add a slash at the end of baseUrl if none is present? The outcome would be the same for the user.\nPlease see my previous answer:\n\nThat behavior would be confusing (at least for me with the behaviour of the URL class).\n\n\n\nMaybe someone wants this behaviour.\n\nI can ask the opposite, right? :)\nI don't say no, but just in case to be safe. Similar thing was about the url argument (users thought it could be provided as an option too). So since that we throw now an useful error.. Ok, I think we've received enough feedback to make a decision :)\n\nbaseUrl should definitely be normalized so that there is no need to end it with a /\n\nSo let's do it :+1: We need to document it clearly.\n\nFor example, a baseUrl for GitHub Enterprise will normally be like https://github.mycompay.com/api/v3 and meanwhile GitHub always document their APIs with a leading slash\n\nI think it's OK then.. It's natural http behavior:\n```\n\nrequire('http').request({path:'friend\u2019s house'})\nTypeError [ERR_UNESCAPED_CHARACTERS]: Request path contains unescaped characters\n    at new ClientRequest (_http_client.js:105:13)\n    at Object.request (http.js:41:10)\n```\n\nbut IMO it'd be very nice to support it.. > I unfortunately don't have the capacity to deal with regressions in basic behaviour like this so I've already migrated from Got to a better-tested/more popular library and am unsubscribing from this issue\nI'm very sorry to hear that \ud83d\ude22 @jstewmon has fixed that in #564 which I believe will be merged ASAP.. @sindresorhus IMO it's ready to merge. \nhttps://github.com/sindresorhus/got/pull/564/files#diff-62bdc57f6f22ae58f495daef16f21f8bR93 is not needed, because the function is called when http.request emits the response.. > redirects are handled with a recursive call to get, so deferred\n  recursion with setImmediate\nSee my comment above.\n\ntest server enhancement:\n\nCould this be placed in a separate PR please?. @lorenzofox3 is right.\nThis:\nhttps://github.com/sindresorhus/got/blob/8f30f1fdefaa96ad55758a352730d00697862952/test/redirects.js#L85\nshould be\njs\n http.on('/relativeQuery?bang=', (request, response) => {\nand the tests would pass. I think we should use lukeed/polka because it's very lightweight and blazing fast. I highly recommend it :). I'd prefer cookieStorage instead of cookie. cookie is confusing with headers.cookies.. Fix: https://github.com/lukechilds/cacheable-request/pull/58. It does.\nhttps://github.com/sindresorhus/got/blob/ca2675e3e5c9db97015e827ce652493a8f9cc1f3/source/index.js#L17-L24. Sure, good point. Many people find this confusing.\n@sindresorhus Maybe we should point users to a last release branch by default?. @poppinlp Don't use Node.JS for server. It's very slow and will cause your CPU going 100% + you'll receive socket hang up errors. Use h2o.. I feel like there should be another section for the response object. What do you think?. > Can you comment on why it was necessary to split it out into a preNormalize step?\nCode comment or GitHub comment?. I'll leave this open because the bug isn't fixed yet:\njs\nquery: {\n    a: '123?456'\n}\n@jstewmon Could you make a node issue about urlSearchParams.toString() appears to be encoding more characters than it should?. Right. So these sentences:\n\nurlSearchParams.toString() appears to be encoding more characters than it should\nSo, the unexpected behavior seems to be the result of a bug in node.\n\naren't true, because there's no bug in Node and there was a bug in Got. Please correct me if I'm wrong :)\nUsually users want application/x-www-form-urlencoded. Anyway, as you've pointed out, a=123?456 is still a valid query (but it's not application/x-www-form-urlencoded serialized).. ```\n\nrequire('.')('http://httpbin.org/anything').then(resp => console.log(resp.body)) // using master\n...\n{\n  \"args\": {},\n  \"data\": \"\",\n  \"files\": {},\n  \"form\": {},\n  \"headers\": {\n    \"Accept-Encoding\": \"gzip, deflate\",\n    \"Connection\": \"close\",\n    \"Host\": \"httpbin.org\",\n    \"User-Agent\": \"got/9.1.0 (https://github.com/sindresorhus/got)\"\n  },\n  \"json\": null,\n  \"method\": \"GET\",\n  \"origin\": \"xxx.xxx.xxx.xxx\",\n  \"url\": \"http://httpbin.org/anything\"\n}\n```\n\nWireshark log:\nHypertext Transfer Protocol\n    GET /anything HTTP/1.1\\r\\n\n    user-agent: got/9.1.0 (https://github.com/sindresorhus/got)\\r\\n\n    accept-encoding: gzip, deflate\\r\\n\n    Host: httpbin.org\\r\\n\n    Connection: close\\r\\n\n    \\r\\n\n    [Full request URI: http://httpbin.org/anything]\n    [HTTP request 1/1]. Will do.. Sure, but please check out #592 first :). > How accurate is the start time? It's set automatically when timer is invoked. How close is this to when the request truly starts?\nI think 0~1ms\n\nShould this be opt-in? The overhead seems pretty minimal, so maybe keeping it simple and always running is OK.\n\nI agree.. IDK why but after git pull --rebase && git add . && git commit -m 'message' some commits got duplicated (from 7eeb352 to a4d0c47) here. Anyway, it's good to merge.. Because onSocketConnect doesn't get called if the socket has been destroyed. Initiating an interval and removing  it after 150ms is redutant (but it's a nice workaround if we don't know the cause, however it's not the case now). https://github.com/sindresorhus/got/pull/469#issuecomment-416316745. This PR is not my first priority right now, so it may take a while to finish this.. > I don't think that 502 responses should ever be cached\nGot depends on the cacheable-request module.\ncc @lukechilds . > If this is correct, it sounds like a valid bug. It should not use cache for retrying.\nIt does :P ~~I'll send a PR.~~ Actually, this should be fixed in cacheable-request. It should provide an ability allowing us to make request again even if we have some cache. Like \"forceUpdate\" or something like that.. @sindresorhus \nWe can fix this in two ways:\n1. disable cache when retrying\n2. force to update the cache (this needs to be implemented in cacheable-request)\nI prefer the latter.. Confirmed (fails):\n```js\n...\n    let calledFirstError = false;\n    s.on('/first-error', (request, response) => {\n        if (calledFirstError) {\n            response.end('ok');\n            return;\n        }\n    calledFirstError = true;\n    response.statusCode = 502;\n    response.end('received 502');\n});\n\n...\ntest('doesn\\'t cache response when received HTTP error', async t => {\n    const endpoint = '/first-error';\n    const cache = new Map();\nconst response = await got(s.url + endpoint, {cache, throwHttpErrors: false});\nt.is(response.statusCode, 200); // true\nt.deepEqual(response.body, 'ok'); // fails: got 'received 502'\n\n});\n```. Fix: https://github.com/lukechilds/cacheable-request/pull/55. https://nodejs.org/api/http.html#http_message_headers\n\nset-cookie is always an array. Duplicates are added to the array.. There is also a test which proves that: https://github.com/sindresorhus/got/blob/master/test/cookies.js#L44. Duplicate of #511 #383 #318 #467. Yup.. What got version are you using?. You need at least 9.1.0.\nNormalize the URL in the baseUrl option. (#579) c901c46. It should be 900 ms in total.\n\n300 ms timeout * (1 req + 2 retries) = 900ms. Also could you make a failing test? To be sure it's Got's failure.. > Set timeout: 100 in option, the request should failed no too much longer than 100ms\n@alextes is right. With timeouts enabled it should take 300ms in total and fail.. Can you show response.timings on latest got?. It should have.\nCc @sindresorhus. Agreed\n. @sindresorhus Maybe we should expose the retry delay?. @DenisKrsk Use retry: 0 instead of retries: 0. The API has changed a few versions ago.. @amio Sorry for late response, but I just recalled this:\nThe retry function delays the next request by ((2 ** (iteration - 1)) * 1000).\n@sindresorhus What about making a retry.delay option?\njs\n{\n    retry: {\n        retries: 2,\n        delay: iteration => Math.random() * 100\n    }\n}. cacheable-request nor keyv resets TTL when retrieving an element. Redis does not too.\nCould you please include a full example?. Could you try Got 9.2.1?. Could you try setting cache control (max age) to 3 seconds and try with 9.2.1?. > the ttl is purely for the key/value store to be able to clean up after itself, not any sort of control over how long you want to cache any particular responses.\nNo, it just sets default TTL if server didn't specify.\nThere was a bug in Got and it's fixed in 9.2.1.. > To reproduce try moving the line back out of the try/catch construct.\nSo don't move that. :>. Can you elaborate where's the problem?. What do you mean by \"global hooks\"?. Confirmed bug:\n```js\ntest('hooks are merged on got.extend()', t => {\n    const hooksA = [() => {}];\n    const hooksB = [() => {}];\nconst instanceA = got.create({options: {hooks: {beforeRequest: hooksA}}});\n\nconst extended = instanceA.extend({hooks: {beforeRequest: hooksB}});\nt.deepEqual(extended.defaults.options.hooks.beforeRequest, hooksA.concat(hooksB));\n\n});\n```\nEDIT: fixed the test\n```\nDifference:\n[\n  Function {},\n\n\nFunction {},\n    ]\n```. This is nonsense.\n\ngot calls normalizeArguments, where options are merged.\nhttps://github.com/sindresorhus/got/blob/7ae6939f920d1174b181063ce61056a8a6def4bc/source/create.js#L33\nhttps://github.com/sindresorhus/got/blob/7ae6939f920d1174b181063ce61056a8a6def4bc/source/normalize-arguments.js#L58. See #608. > What makes this preferable to #607?\nMy previous answer:\n\nThis is nonsense.\ngot calls normalizeArguments, where options are merged.\n\nSo that PR didn't change anything. This does.. No worries. Done :D. Could you paste stacktrace here?. let options = {\n    protocol: 'https'\n    port: 3003,\n    hostname: 'example.org',\n    path: '/path-to-test',\n    headers: {\n      accept: 'application/vnd.d.tld.mt+json, application/vnd.d.tld.errors.v1+json; q=0.1',\n    },\n  }\nInvalid protocol. It should be \"https:\". js\ninst('http://httpbin.org/', {});\ndoesn't work either.. Found solution, working on a fix.. Could you please provide an example?. @gajus PR won't be necessary. Got just follows the standard. I agree with @sindresorhus - we shouldn't add some bloat because of the faulty servers. That's not our fault - it's done right here.. Not possible to occur with master.. Can you add tests please?. I'll try to fix this :). Both forms are correct. @sindresorhus has discussed it somewhere and prefers to use \"cancelation\".. https://github.com/sindresorhus/got/blob/master/advanced-creation.md#limiting-download--upload. https://github.com/sindresorhus/got/blob/master/advanced-creation.md#signing-requests. timeout.ref() was added in Node v0.9.1. AFAIK electron uses Node's timers (with a wrapper to activate some event loop).. It should exist as this file tells so: https://github.com/electron/electron/blob/master/lib/common/init.js but maybe I've missed something\nCould you paste the stacktrace here?\n. Checked. Yeah, browsers doesn't have timeout.unref().\nThere are two ways:\n - use require('timers').setTimeout or\n - if (timeout.unref) { timeout.unref(); }\n@sindresorhus Any ideas which one we should use? I prefer the latter.. Node never throws \"ESOCKETTIMEDOUT\". Yeah, we can consider adding the rest.. @sindresorhus Any thoughts?. > The docs needs to be updated too: sindresorhus/got#gothttperror\ndone. @razor-x https://github.com/sindresorhus/got/milestone/7 also see #635. I've checked it myself and it works correctly on Got 9.2.2 without any errors.. You can always set retry to 0 or use a custom agent with keepAlive option set to true.\nYou're free to choose the options, nobody says you must stay with the defaults, do they? :)\nThere's no need to change the default value. That's what the most users want ;)\n\nthis pattern gets very dangerous if the upstream server starts failing\n\nNo. It depends on how you write the code. You can do an additional layer for the inner communication between the servers. \n\nEven if it recovers after a very short time, the client requesting the erroring upstream server have already aggregated a queue of some thousand requests.\n\nStop processing clients who have disconnected.. > So I'm looking to use got without any caching\nSo don't specify the cache option :)\n\nMy code calls got() hundreds of thousands of times per minute\n\nVery bad idea.\n\nperformance is critical\n\nYeah, Node is very slow compared to C++ :)\n\nIt also seems like the CacheableRequest factory is meant to be reused rather than creating a new one for every request.\n\nI think you're right.\n@sindresorhus what are your thoughts about it?. > it creates all those cache objects but it doesn't actually use them, and even if it did, they get recreated for the next request\nWhen caching is off it doesn't cache anything, so you're wrong. But CacheableRequest is created every new request, that's a con.\n\nI'm really curious why you're calling Got so many times per minute.\n\nMe too. Usually you don't do that unless you do exploiting some site or crawling the web. . > I can see how a few extra object allocations wouldn't matter that much\nYup, but it doesn't cache anything. It just initializes CacheableRequest, that's all.\n\nWe essentially operate a proxy service for server-to-server traffic.\n\nI wouldn't use Node for that. Networking's slow as f...\nI agree, it could be written better, we just need to figure out a way to do so. I tried optimalizing Got, but I ended up with a mess (performance increased but the code became unreadable)...\n\nAnd yes, that could be a PR.\n\nGreat! If you got any ideas, feel free to share :). Let's focus on optimizing Got then :) Two heads are better than one :). 1. Could you make it reproducible?\n2. What's the unhandled error? I'm not sure but did you mean that the unhandled error is the timed out error?\nI'm gonna look at it.. It seems like the emitter throws an error twice:\nhttps://github.com/sindresorhus/got/blob/8d2e91171509bc2aec71c4483978cfd421ebcf1d/source/as-promise.js#L95\nCan you try adding emitter.on('error', e => console.log('on each error:', e)); and try again?. I've looked at the timed-out file and it seems there are some holes.\nhttps://github.com/sindresorhus/got/blob/8d2e91171509bc2aec71c4483978cfd421ebcf1d/source/timed-out.js#L47-L49\n~1. There's missing request.setTimeout(0);.~ (nah Node handles it itself)\n\ntimeoutHandler may invoke two errors: socket hang up & the timeout one.\n\nAlso, we shouldn't proxy errors. It just gets worse when it's time to read them.\n@aghuddleston you're case is more complicated. I'm looking into it.. @aghuddleston If you could tell the previous error before that one, it'd help a lot.. >  we get uncaught TimeoutErrors on both 'lookup' [...]\nOn lookup? Impossible to happen. Full stack trace please?. > It's possible that they would also occur for the other configurable timeouts but we never run into those.\nNope, it's not.. @aghuddleston request.once.error gets called so this is the first time when the HTTP lib thrown an error. I guess you set timeouts, didn't you?. > Once the object enters the error state, it should really just stop doing things altogether.\nIgnoring further errors should be our last option if we don't come up with anything :). > My point was more that there should only be a single error event per EventEmitter\nThat's right.\n\nActually, scratch that: I can confirm that I really do see several of these in our logs\n\nThen I believe it's the fault of timed-out, because I've checked hundred times and it's the only way.\n\nYou should be able to reproduce it by using a slow or invalid DNS server. That's how I started noticing these errors in the first place.\n\nThanks for the advice. I'll give it a try.. I found a bug where using cookies and timeouts it may double-throw.\n@timdp Were you using cookies?. working on a fix + code cleanup: https://github.com/sindresorhus/got/compare/master...szmarczak:unhandled-fix. fixed!. You can reopen this one. I checked the code hundred times, it's hard to believe it's Got's failure. If that's the full stack trace, it looks like the request has no error event attached, which isn't true, so there are missing some functions [in the stacktrace] that the error is passed by. Is it the full stack trace?\nWhat's your Node and NPM version?\nOtherwise, if it isn't reproducible, I won't be able to help. If you could reproduce it somehow, that would be great :)\nAnyway, if it's really an uncaught error, you could make a handler for it and log the errors before (place it right after request.once('error, ...) in request-as-event-emitter. It would help very much.\n```js\nconst errors = [];\nrequest.on('error', error => {\n    errors.push(error);\n    if (error instanceof timedOut.TimeoutError && error.message === Timeout awaiting 'connect' for 500ms) {\n        console.log('verify uncaught error', errors);\n    }\n});\n```\nAlso, what are your got options?. > As far as I know, that's all you get with errors thrown from timers, at least by default?\nRight. Then pardon me, let's blame Node for that.\n\nI've also added longjohn to obtain the async stack trace.\n\nAwesome! It helps a lot :)\n\nIn timed-out.js, shouldn't you be checking the first argument of the lookup handler? It's an Error if the lookup fails, so in that case, you'll never get the connect event.\n\nYou're right. Good spot! \ud83d\udc4d\n\nBut then, that should still reject the promise rather than producing an uncaught error.\n\nYup.\n\nMaybe my example code never gets to response though.\n\nIt doesn't matter. It should caught it, and it doesn't.\nOn Windows 10 (Node 10) I get:\njs\nuncaught error: { TimeoutError: Timeout awaiting 'connect' for 1ms\n    at Immediate.timeoutHandler (C:\\Users\\Szymon Marczak\\Desktop\\got-master\\source\\utils\\timed-out.js:50:25)\n    at runCallback (timers.js:694:11)\n    at tryOnImmediate (timers.js:664:5)\n    at processImmediate (timers.js:646:5) name: 'TimeoutError', code: 'ETIMEDOUT', event: 'connect' }\nEDIT: The previous stacktrace was on my local [outdated] Got. I had to replace require('got') with require('.'), as I am working in the Got directory.. It's very weird. I logged request.once('error', ...) and this happens:\n```js\nrequest.once.error { TimeoutError: Timeout awaiting 'request' for 1ms\n    at Immediate.timeoutHandler [as _onImmediate] (C:\\Users\\Szymon Marczak\\Desktop\\got-master\\source\\utils\\timed-out.js:50:25)\n    at runCallback (timers.js:694:11)\n    at tryOnImmediate (timers.js:664:5)\n    at processImmediate (timers.js:646:5) name: 'TimeoutError', code: 'ETIMEDOUT', event: 'request' }\nuncaught error: { TimeoutError: Timeout awaiting 'connect' for 1ms\n    at Immediate.timeoutHandler (C:\\Users\\Szymon Marczak\\Desktop\\got-master\\source\\utils\\timed-out.js:50:25)\n    at runCallback (timers.js:694:11)\n    at tryOnImmediate (timers.js:664:5)\n    at processImmediate (timers.js:646:5) name: 'TimeoutError', code: 'ETIMEDOUT', event: 'connect' }\n```\nIt means that it doesn't prevent new timeouts. So, what happens:\n\nA request has been made.\nTimeout: request 1ms. Clears all the current timed-out timers.\nLookup gets called with an error. It creates a new timer for the connect event, but it shouldn't. Another timed-out error had been thrown before.\n\nI'll make a PR which will prevent further timeouts in the future.. Hmm... That's even more weird. I'll check it now.. Good spot! Fixed. I'll just send a PR right now.. Wrong usage of Got. Please read the API more closely. Use got(url, options).. I've even made a PR to not confuse url with options... https://github.com/sindresorhus/got/pull/514 Maybe it'll be supported, but not for now :). @sindresorhus We disallow the url option no longer.. Yes, then we can reopen this PR :tada:\n\nMaybe it'll be supported, but not for now :)\n\nThe time is now.. Final options is\ndiff\n...\n-  json: false,\n+  json: true,\n...\n...weird\nEDIT: fixed, but timeout tests won't finish...\nEDIT: fixed! ^_^. Sure, will do! :). If someone is interested to help with caching CacheableRequest instances, feel free: https://github.com/lukechilds/cacheable-request/compare/master...szmarczak:manager. . Let's summarize: node-fetch aims to be compatible with the fetch, we should not expect any additional features. So if there are any, they're node-specific. No need to argue about node-specific things (proxying headers etc.).\nI don't mind ticking node-fetch. But I think we should leave a note that it's a bit different than the window.fetch.\n@bitinn It'd be very nice to have .getReader() :)\n@sindresorhus thoughts?. Yes, you can. The MDN shows:\n\nvar params4 = new URLSearchParams({\"foo\" : 1 , \"bar\" : 2});\n\nNode API: https://nodejs.org/api/url.html#url_constructor_new_urlsearchparams_obj\n@sindresorhus Maybe we should add querystring option (function)?. > For what purpose? Show an example of usage.\nOP:\njavascript\nconst res = await got('https://site.com', {\n  query: {\n    some: ['a', 'b']\n  }\n});. js\nconst res = await got('https://site.com', {\n  querystring: require('query-string/qs/querystring'),\n  query: {\n    some: ['a', 'b']\n  }\n});\nOr we could transform the object (there's no need to implement the querystring option):\n```js\n{\n  some: ['a', 'b'],\n  foo: 'bar',\n  n: 3\n}\n[\n  ['some', 'a'],\n  ['some', 'b'],\n  ['foo', 'bar'],\n  ['n', 3]\n]\n```. > This wouldn't always work anyway as users wouldn't be able to specify any options for those packages.\nYeah, and as you pointed out users can do query: require(...)... so probably it is worthless.\n\nYes, but none of them are some=a,b, aren't they?\n\nNo.\n\nThat's exactly how it could be done now and it's fine. It's just confusing that the \"query as an object\" leads to an invalid query string eventually.\n\n+1. query: {some: ['a', 'b']} is more convenient than query: [['some', 'a'], ['some', 'b']] .. I guess we need to update the README then?. 100% yes!. options.retry.retries function should be called with the retry argument starting\nfrom 0 instead of 1.. @javierblancosp why?. @javierblancosp Sorry for late response. Well, it's not a good idea. It has been discussed here: #174 #318 #383 #467 #511 #600 \nUse this instead:\n```js\nconst instance = got.extend({\n    hooks: {\n        beforeRequest: [\n            options => {\n                options.body = JSON.stringify(options.body);\n            }\n        ]\n});\ninstance(url, options);\n```. @sindresorhus Nah, only a few lines of code. I agree. I'll send a PR :). A few suggestions:\n\nreplace uploadProgress and downloadProgress with hooks,\ndeprecate redirect event (use beforeRedirect hook instead),\nadd error hook to provide even nicer errors (similar to the afterResponse hook) :)\nmake promise.on('error', cb) work?. > Why? I don't think this would benefit enough from hooks as you're actually not modifying anything in them.\n\nYou're right \ud83d\ude05 My bad. Let's keep it that way :)\n\nWhy? And are you sure beforeRedirect handles all the use-cases of the redirect event?\n\nUmm... Not yet (everything but cancelling the request). There should be only one method to avoid duplicates.\n\nCan you elaborate on how this is different from promise.catch() and what use-cases it solves?\n\nGeneric error handler. That's the only one I've come up with. It's just a simple wrapper:\njs\npromise.on = (name, fn) => {\n    if (name === 'error') {\n        promise.catch(fn);\n    } else {\n        proxy.on(name, fn);\n    }\n    return promise;\n};\nBut it can be also achieved using a handler so I'm not sure... Maybe let's keep it off for now. . > I still don't fully understand its purpose. What do you mean by \"generic error handler\"?\nWhenever you use promise or stream you want to use the same error handler (eg. you want to call specific logger). But you can still achieve that using handlers.... No. beforeError just modifies the error. But it still will be thrown; we don't want that. We want to catch the error using the same handler - whenever it's a promise or stream.. > Have you actually encountered this need in real code?\nYup. Once. I was omitting 404 errors and logging the other errors using pino.. > I have been thinking about whether we should deprecate the ability to not use a scheme in the URL. It only saves a few characters, but it creates an ambiguity for people that don't know whether Got defaults to HTTPS or HTTP. It also creates an incompatibility with browser request libraries, which cannot support this as it's then considered a relative path.\nAgreed. I'll send a PR.\n\nI didn't realize Got had this behavior and I honestly don't like it. I think it's too magical. I think we should remove this behavior in v10.\n\n~~Well, I'm against this one.~~ @sindresorhus has convinced me:\n\n.post() is only 7 more characters\n\nLet's go with that! :tada:\n. @olistic Could you please make another issue for that?. @sindresorhus Regarding the GET body thing: https://github.com/sindresorhus/got/pull/756. What about now?. now?. According to https://github.com/nodejs/node/blob/8b4af64f50c5e41ce0155716f294c24ccdecad03/deps/http_parser/http_parser.c\nThe cause may be:\n\nDouble content-length header\nBoth headers present: chunked encoding & content length. Unfortunately, there's nothing Got can do about that :/. > Log following things: request, response status and headers (right after it's received), response body (after complete response is propagated). For first two I could probably rely on 'request' and 'response' events, but for last one there appears no clean solution (e.g. retries are handled behind the scene, where I would prefer to have all issued requests logged)\n\nUse hooks and/or custom handlers. There's a dedicated issue for logging: #559 \njs\nconst instance = got.extend({\n    hooks: {\n        beforeRequest: [\n            options => {\n                console.log('new request:', options);\n            }\n        ],\n        afterResponse: [\n            response => {\n                console.log('statusCode:', response.statusCode);\n                console.log('headers:', response.headers);\n                console.log('body:', response.body);\n                return response;\n            }\n        ]\n    }\n});\n\nPreset options.timeout for each request automatically (it's not about fixed static value, we run requests in AWS lambda's and want to ensure they timeout before lambda times out)\n\njs\nconst instance = (url, options) => got(url, {...options, timeout: computeTimeout()});\nIf it still isn't suitable for you, then you should use promise.cancel().\n\nResolve body on basis of content type (e.g. we automatically resolve to JSON if there' response type is application/json (no need for options.json: true).\n\nVery bad idea. But you can still use hooks for that:\n```js\nconst instance = got.extend({\n    hooks: {\n        afterResponse: [\n            response => {\n                try {\n                    const parsed = JSON.parse(response.body);\n                    response.body = parsed;\n                } catch (e) {}\n            ...\n\n            return response;\n        }\n    ]\n}\n\n});\n```\n\nGenerally it'll be good to achieve first two use cases without a need of introduction of some decorator that should be required instead - so that aside we can hook into general got configuration, and then have all requests (made via got required directly) automatically affected.\n\ngot.create() / got.extend()\n\nThe last one, is more a feature request, not sure why got doesn't do that by default, but maybe there's a good reason\n\n\nPerformance costs.\nIf you query mostly HTML/XML/... you don't want JSON. It's just useless code then.\n\nI could find more reasons but I'm lazy :P\n\nI discovered also few other breaking (on that level) changes between v9.2 and v9.3. So for now, after we patched that, we locked ourselves to 9.3.x\n\nrequest-as-event-emitter isn't meant to be used publicly. Don't do that. Everything you want to do you don't need that. Use promises or streams.\nThe documentation doesn't bite :smiley:\nYou should definitely read it, as it answers all your questions and also contains helpful tips.. > It's great that afterResponse hook was added with v9.3. That helps, still, it doesn't allow to address what I'm after in a way I described (e.g. have also result from JSON.parse available)\nAfter you parse the body you decide what to do with that. Want to hold both? Sure:\n```js\nconst instance = got.extend({\n    hooks: {\n        afterResponse: [\n            response => {\n                try {\n                    const {body} = response;\n                    const parsed = JSON.parse(body);\n                    response.body = {parsed, body};\n                } catch (e) {}\n            ...\n\n            return response;\n        }\n    ]\n}\n\n});\n```\nNote there can be many hooks.\n\nI specifically wrote: it'll be good to achieve first two use cases without a need of introduction of some decorator that should be required instead - so that aside we can hook into general got configuration, and then have all requests (made via got required directly) automatically affected\n\nI specifically wrote: got.create() / got.extend()\nMy hint is everywhere round that. All requests are affected. Like @sindresorhus said, you can create custom Got instance in a file and require it instead of Got. But that isn't safe. require doesn't guarantee you'll receive the same instance1.\n1 https://derickbailey.com/2016/03/09/creating-a-true-singleton-in-node-js-with-es6-symbols/\nIn 99% cases you don't any singleton if your code is written correctly.\n\nThat's far from constructive.\n\nSee @sindresorhus' comment.\n\nI did read it, but it doesn't look that you took effort to actually read with understanding my points, and acknowledge the context.\n\nNo you didn't. I've solved all your cases and you still haven't said why you do use request-as-event-emitter and no promise.\n\nMind intention of this issue was to discuss breaking changes between v9.2 and v9.3, and in last comment I was mostly referencing to version v9.2\n\nThere are no breaking changes. If you decided to use request-as-event-emitter for no matter why, then the problem is not ours, it's yours.\nI'll remind you: you asked if defaults were available publicly and if it was possible to built a handler on top of request-as-event-emitter, had not looked into the code, had not read the docs, @sindresorhus replied they are and asked why you used request-as-event-emitter, you replied with the use cases, I solved them. Done.\nreading with understanding doesn't bite \ud83d\ude03. Got 9.3.0 throws HTTPError: Response code 400 (Bad Request) because 'content-length': null.... Fix: line 279:\njs\nif (uploadBodySize > 0 || (options.method === 'PUT' && !is.nullOrUndefined(uploadBodySize))) {\nI'll make a PR.. > request.once('error', () => {}); // Ignore the socket hung up error made by request.abort()\nHmm... Is it a good idea to ignore all socket hung up errors? If users do promise.cancel(), they won't see them, unless they do promise.on('request', request => setTimeout(() => request.abort(), n)) . @UltCombo @timdp \nhttps://github.com/sindresorhus/got/blob/50fdab303cb2a6b34383de13e5e0ece9ceaf80c9/source/normalize-arguments.js#L209-L211\nwith retry: 0 it should reject immediately. I'll check it tomorrow.. Yup. It's a bug. From the docs:\n\nDelays between retries counts with function 1000 * Math.pow(2, retry) + Math.random() * 100, where retry is attempt number (starts from 0).\n\nLet's merge this PR then. I'll make another one for that to keep things organized :). Yes, the documentation states:\n\nretry\n...\nThe retries property can be a number or a function with retry and error arguments. The function must return a delay in milliseconds (0 return value cancels retry).\n\nIf you pass a function through the retry.retries option, it will use yours instead of the default one.. js\nconst defaultRetries = got.defaults.options.retry.retries;\nPlease tell me if it works or not :). I'll try to fix this when I'm back home.. @sindresorhus Definitely yes! I'll make a PR \ud83d\ude3a . What should we do when the DNS server offers us multiple IP addresses? Should we cache them?. > you can simply pass package or custom lookup function to got\nWell, there isn't one which will set TTL automatically... We need to create it :). Well, it sounds good... but it isn't. It's way too bloated. Is there any way to manage the database? I'll try to make a prototype now :). https://github.com/szmarczak/cacheable-lookup. @sindresorhus Any ideas on how to implement cacheable-lookup into Got? Should we reuse options.cache or use options.dnsCache instead?. Sorry, but you haven't made clear what you're trying to do. Can you explain?. Use streams.\njs\ngotStream.pause();\ngotStream.resume();. js\n// express with cors enabled, listening on: 8080\napp.all('/cors/*', async (req, res, next) => {\n  req.pipe(got.stream(req.params[0], {\n    method: req.method,\n    headers: req.header,\n    stream: true\n  })).pipe(res)\n}\nYou're missing error handler there.\n```js\napp.all('/*', async (req, res, next) => {\n    const stream = got.stream(req.params[0], {\n        method: req.method,\n        headers: req.header,\n        stream: true\n    });\nstream.on('error', error => {\n    res.statusCode = 500;\n\n    res.end(error.toString()); // never do that unless you're debugging\n});\n\nreq.pipe(stream).pipe(res);\n\n});\n```. done. > I don't see how this is clearer\nEvery single error has listed properties. There's no \"guessing\".\n\nbody is now missing as a property in all cases\n\nAccording to body: good spot, I just forgot to add it to docs :)\nAccording to property in all cases: no it's not in all cases. Please check the source code.. > it's still wrong and would be great to see that fixed :)\nIt is not wrong. It's always been like that. But if you want to request a feature, feel free to make an issue :). > I'd ask the community if it's unclear what convenience options they'd like to have or remove the option and see what issues pop up.\nWell, it has been discussed in 6 issues mentioned above. I think it's enough to make a decision :)\nNo need to rush, there's lots of time though :P\n\nI'd specify a deserialization or parsing function and optionally add some convenient way to define them.\n\nVery good idea! I've been thinking about this for a while:\n```js\ngot.modifiers.register('json', promise => {\n    return promise.then(response => {\n        response.body = JSON.parse(response.body);\n        return response;\n    });\n});\ngot(url, options).json();\n```\nWhat do y'all think about that?\n\nI feel preserving the positive momentum you've got going in improving got is much more valuable than the above\n\nThank you, but I have to disagree - your help is no less valuable than mine, so please don't lower your confidence :)\n. I am still not sure about the register function. It's like calling an afterResponse hook but just with a function. Also, the only use case I have come up with is parsing the body. I think there's a better solution...\nYour proposal sounds very good! I'd just modify it a bit :)\n```js\nconst instance = got.extend({\n    modifiers: {\n        'json': JSON.parse\n    }\n});\nawait instance(url).json();\n```\n@sindresorhus Any thoughts?. I'm looking forward to this issue, but it takes time to prepare the info. Also, there's not enough space in the comparison table, see https://github.com/amio/badgen-service/issues/211\n@alextes is right. You can't just say \"I want that, that and that\". That's not how open source works. That's how $$$ works. There's no deadline. You have to show some interest. OS is fair, everyone has the same rights. Made an issue? Well done. You have to wait. Or, you can help by sending a PR :). See #691. Could you complete the issue template please? To solve the issue we need know what you're trying to do, what error you got, etc.\nAs I see it there's nothing wrong with your code. Just do: response.headers.location for the redirect location.\nMake sure to read the documentation, it has many helpful tips. If there's any problem, I'll be happy to help.. Oh, I understand now. Thanks for clarification :)\nUnfortunately, you can't just stop processing redirects. It goes till the end.\nBut, you can do this (taken from advanced-creation.md, just modified a bit):\n```js\nconst processResponse = response => {\n    // do something\n};\nconst gotInstance = got.create({\n    options: got.defaults.options,\n    handler: (options, next) => {\n        const promiseOrStream = next(options);\n        return promiseOrStream.on('redirect', response => {\n            processResponse(response);\n        const host = new URL(response.url).host;\n        if (host === 'someSite') {\n            promiseOrStream.cancel(`Redirection stopped at ${host}`);\n        }\n    });\n}\n\n});\ngotInstance(...);\n```. Use after response hook.\n```js\nconst got = require('got');\nconst instance = got.extend({\n    hooks: {\n        afterResponse: [\n            (response, retryWithMergedOptions) => {\n                if (response.statusCode === 200) {\n                    response.body = process(body);\n                }\n            return response;\n        }\n    ]\n},\nmutableDefaults: true\n\n});\n```\n. > I was expecting this to work with streams because it wasn't stated anywhere that it shouldn't\nStreams are much different than the usual Promise implementation. Some hooks won't work there - you receive the data immediately; promises give you the whole result. Yup, a note in the README would be nice.\n.pipe() does the job. This test proves it.\n\nhowever apparently it was transforming all the request (incl headers). I just want to transform the response body\n\nCan you provide a fully-working example?. I'm glad you solved the issue :). > I'd like to open a PR for a readme update.\nSure! \ud83d\ude04 \n\nWhat hooks are supported for streams?\n\nWell, streams don't have retry support. So beforeRetry is promise-only. beforeRequest just modifies the options, so it works for both. afterResponse needs the whole response, so it works only with promises. beforeRedirect just checks the headers, it works for both.. Please read the API before making an issue.. > That's how I am doing it now. Is it right?\nYes. got.post(url, [options]) where options is this.. Thank you for the detailed report! ^_^ I'll fix this tomorrow ASAP :). js\n{ start: 1546537817663,\n  socket: 1546537817665,\n  lookup: 1546537817666,\n  connect: 1546537817667, // note this occurs later (socket `connect` event)\n  upload: 1546537817666,  // than this (request `finished` event)\n  response: 1546537817920,\n  end: 1546537817923,\n  error: null,\n  phases:\n   { wait: 2,\n     dns: 1,\n     tcp: 1,\n     request: 1546537817666,\n     firstByte: 254,\n     download: 3,\n     total: 260 } }\nEven if I include deferToConnect into the finished callback, it still fails because socket.connecting is false before emitting the connect event.. > I also see cases where upload < start\nHave you got any logs? As I find it impossible, because timer(...) is called before request.end().... Fixed in @szmarczak/http-timer@1.1.2 :tada:. Sure. I'll reopen this issue if you find anything wrong :). Can you set the retry option to 0 and try again?. Is it a Timeout Error?. Try setting timeout to 1000 and retry to 0. Does it fail?. > What is the purpose of setting request.setTimeout(0) after the request is canceled?\nrequest.setTimeout(0) removes the timeout.. > We started seeing a large increase in memory usage\nCan you provide any data? How much?. Indeed, somehow cancelers.push(() => request.setTimeout(0)); causes memory leak.... After removing request.setTimeout(...) and leaving cancelers.push(() => request.setTimeout(0)) I get:\n(node:17772) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 timeout listeners added. Use emitter.setMaxListeners() to increase limit\n    at _addListener (events.js:246:17)\n    at Socket.addListener (events.js:262:10)\n    at Socket.Readable.on (_stream_readable.js:826:35)\n    at Socket.once (events.js:291:8)\n    at listenSocketTimeout (_http_client.js:673:16)\n    at ClientRequest.setTimeout (_http_client.js:736:3)\n    at cancelers.push (C:\\Users\\Szymon Marczak\\Desktop\\Workspace\\got\\source\\utils\\timed-out.js:93:12)\n    at cancelers.forEach.cancelTimeout (C:\\Users\\Szymon Marczak\\Desktop\\Workspace\\got\\source\\utils\\timed-out.js:75:38)\n    at Array.forEach (<anonymous>)\n    at IncomingMessage.cancelTimeouts (C:\\Users\\Szymon Marczak\\Desktop\\Workspace\\got\\source\\utils\\timed-out.js:75:13). Reproducible without got: https://gist.github.com/szmarczak/6970bbc7b16b37f6a2b55fad5b064b26\n. @timdp Yup. Would you be interested in submitting an issue?. > I had a stab at writing my own version. Interestingly, it doesn't have the issue.\nI'll look at it.\n\nAre you sure you're interpreting the results correctly?\n\nYeah, I'm sure. I'll try to rewrite @voldern's example to use only the native http module.\n\nBut you were saying earlier that #694 doesn't fix it?\n\nPlease quote? I don't recall saying anything like that.. @timdp Updated the gist. Added an explaination. I hope there's everything clear now. There is no recursion anymore! :D. TypeError: Right-hand side of 'instanceof' is not an object\n    at normalize (node_modules/got/source/normalize-arguments.js:137:68)\n    at got (node_modules/got/source/create.js:32:28)\nhttps://github.com/sindresorhus/got/blob/91c0607b21f85adc568a0d182b47483e59855f95/source/normalize-arguments.js#L137. I ran require('url').URLSearchParams in the sandbox. It gives undefined. On my local machine it works perfectly.. @oknoorap You're running it through webpack. As metioned in the documentation, Got doesn't support browsers.. Fixed in Node: https://github.com/nodejs/node/pull/25536#issuecomment-456268128. I'm still not sure if promise.json() should return a Response object or just the JSON.... > What's the argument for just handling automatically in the body option instead of what ky does, which is to have a json option that the user gives an object/array instead of the body option.\nActually I see no difference here. \ud83e\udd14 The only thing I see is that json must be an object/array. While body handles the type automatically.... @sholladay Very well explained! Thank you :)\nI'm now convinced to use json instead of body... \ud83e\udd14 \n\nWhile I can see the benefit for someone who does need the response in addition to the JSON (or Buffer or whatever), I really don't think it's that common, and where it is needed, there may be better solutions.\n\nOh, believe me, it's very common.\n. > What do people need both the Response and the JSON for, on a successful response, other than pagination?\nFor example API rate limiting.. When programming bots it's very useful to know how many times you can make a request again. Because if you exceed that limit you get banned for half an hour or more. :). > But is it worth having responseType to make bots a little easier to write by, say, 4 or 5 lines of code?\nI'm pretty sure there are another use cases too :)\n\nFWIW, any API that bans on or before the first 429 response is a terrible API.\n\nAgreed.. @sholladay Then .text() and .buffer() should return the body too I think. The behavior can't be ambiguous.\n@sindresorhus What do you think about it? I'm still not sure about the json/body option. json is good if someone's forcing something to be JSON. body is good for objects/arrays (I don't think someone would pass a string to json though). I can't decide.... \n. git has just messed up. When I solved conflicts it just shouted out that I did not. Opening a new PR.. > I wouldn't say it fixes that issue. This just works around it. We still need to properly fix handler.\nTrue. But it's not that easy, it will take a while to solve it :P\n\nDoes the hook catch absolutely all errors? If not, it should be documented what it doesn't catch. For example, I don't think it currently catches input validation errors (Neither should it IMHO).\n\nYou're right. I'll document that.\n\nWouldn't beforeError be a more correct name for this?\n\nI have been still considering this. You just nailed it :) Will change that.\n. done. https://github.com/sindresorhus/got/issues/602#issuecomment-453769912. > if I were to rewrite Got, I would do it in TypeScript, not Flow, as that's what I'm familiar with and prefer.\nTypeScript is just more popular and @sindresorhus has had experience with TypeScript for a long time, it's easier to maintain so.. If someone's interested in doing this, here's some work I did: https://github.com/sindresorhus/got/pull/710\nIMO this is way too complicated:\n\n\nIn that PR returning a Response (or any other object) from a handler will do nothing - it won't be returned. To achieve that you would need to merge it into the base (promiseOrStream).\n\n\nThe other solution would be to return defaults.handler(...) directly, but... it won't work if the handler is async and you want stream. You would need to do await got.stream(...)\n\n\nReturning next(...).then or next(...).catch will result in different promise - it will be just a plain promise - you can't cancel it etc.. Hmm... I've checked that on my local machine and on runkit too and I couldn't reproduce that.\nCould you fill the bug template please? What's your Node version? What's the Got version?. @MorpheusXAUT Thank you for the detailed information! \ud83d\ude03 Have you tried it without Bluebird?. I'll check the Bluebird approach now.. > I'd personally try to avoid it and using await if possible.\nThat's not a good behavior though...\nI believe it's Bluebird failure. I'll let you know when I have figured out what's wrong :). I can't reproduce with Bluebird: https://runkit.com/szmarczak/5c41aaa1b1379d001634494d\nI'll try @hensmith's repo.. Unfortunately I couldn't reproduce it too: https://pastebin.com/raw/2vtaNA0L. @MorpheusXAUT \n\nI can put together a simple example project like @hensmith did using the rest of the dependencies described during this weekend though, if that'd be helpful!\n\nOf course! Any help is appreciated :)\nYou can also try upgrading to Node 10.. @hensmith @MorpheusXAUT Any updates on how to reproduce the issue?. @muliyul Are you able to reproduce the issue? Have you tried running it with native Promises?. @MorpheusXAUT Ok. Let us know if the issue still persists when using native Promises.. @MorpheusXAUT Heads up! It has been a month :P Any news?. Closing due to lack of response.. @scttcper I think it should be (request as any)._header then.. I just wonder if got.extend(...) should be renamed to got.use(...).... Also, I would move anything related to custom instances to advanced-creation.md.. Or maybe split got.extend() into got.extend(options | gotInstance) and got.use(handler)?. @ltciro Better not to force-push when merging conflicts \ud83d\ude03  Use git pull --rebase instead and resolve the conflicts manually if needed.\n\nLet me know if it's better to close PR and open a new one\n\nNo, we will fix this one. Make new PRs only when GitHub has messed up (it happens quite often).\nOtherwise if Git won't merge conflicts (e.g. empty head): make a backup of your changes, do git reset --hard origin/master, apply the changes, perform git add ., git commit and git push -f (that's what I've done). > thank you for the video so helpful\nNah, that was just an example where the HEAD is empty and Git wouldn't agree on the merge. It's no helpful, just an example :P\n\nI didn't be able to found where in the code the change to undefined was affected.\n\nThere's a bug in nyc that affects the code - this causes to display wrong stacktraces. For proper stacktraces do npm run build then run ava.\nI'm glad I could help. Every day we're being closer to the Got written fully in TypeScript :tada:. Reworked, it's much readable now :P The previous version of this PR was too bloated.\n\nCan you explain your changes?\n\nIn short, I added await pEvent(proxy, 'options') before requestAsEventEmitter(options).\nSo normalizing options can be async. And if that can be async, then all hooks can be async too - including handlers ;)\nRegarding the async handlers, it is quite broken for now... I'm fixing it now.\n\nCan you also update the got.create() docs showing how the async handlers will be used?\n\nWhat do you mean?. @ricardorojass If you want to, you can invite @fnky to your fork so you can work on it together. He's done some awesome work on #714 already :)\nI would help you rewriting the code if I could, but since Thursday I've been really sick. Anyway, this is still great work\ud83d\udc4c. You can either use the browser feature \"Resolve conflicts\". Resolve conflicts and then click \"Mark as resolved\". Or, you can git pull <remote> <branch> --rebase and do it in your favorite editor.\nThen git add . git commit -m \"<message here>\" and git push :)\nIf you encounter this for the first time, take a look at this: https://help.github.com/articles/resolving-a-merge-conflict-on-github/\nIf you want me to solve the conflict just let me know :) Or, I can do a GIF if that'd help :). Could you please fill the template out? The issue lacks many information, which could be very helpful for us to solve the issue.\n\nGot needs better error handling.\n\nOn what basis you say so? Do you catch the errors properly? If we could reproduce the issue, that'd be great :). > The issue is the cryptic stack.\nWhy is it cryptic? As I see it everything is clear here. Please describe what's unclear. What would you suppose to receive?\n\nThe issue isn't with external error handling, but got's internal error handling that isn't bubbling the error up properly.\n\nI disagree. The tests speak for themselves ;)\nPlease fill out the issue template, it helps a lot.\nWe cannot help if the issue isn't reproducible.\nIf you could use Runkit, that would be great.\n\nFrom looking at the code, I'd suggest essentially wrapping the whole call inside a promise like\n\nIt's done like that. See as-promise.js.\nIf you mean why the error is unhandled, the answer is you don't catch the promise. Try wrapping it in try/catch or got(url, options).catch(handler).. Currently lots of electron features are broken, because of the new electron updates. We haven't fixed that yet - currently we are focused on rewriting Got to TypeScript. Once we achieve that, we'll figure out the rest :). Sure! It may take a while until this is done, because now we're focused on rewriting Got into TypeScript. Meanwhile, PRs are welcome \ud83d\ude03 . Thanks for reaching out! Presetting port to null should solve the problem. We'll fix this in the upcoming release.. ~~Nope.~~ Maybe? IDK.\nhttps://github.com/sindresorhus/got/blob/6ae3b345e8108decba768c181ed7792f2da74f6a/source/request-as-event-emitter.js#L139-L142\nI think It should be:\njs\n                        const redirectOptions = {\n                            ...options,\n                            port: null,\n                            ...urlToOptions(redirectURL)\n                        };. @sindresorhus Any ideas?. @michaeldera Ping. Are you finishing this PR? Otherwise, I could work on it :). > If it is not too far off I can work on it over the weekend but you could work on it if you would like.\nSure! I'm glad I can help :) At the moment I'm focused on my other Got PRs - gotta fix them.. What about:\n```js\nconst options = {\n    hooks: {\n        pagination: (response, options) => {\n            if (!response) {\n                // First request\n                options.searchParams = {page: 0};\n            }\n        options.searchParams.page++;\n    }\n}\n\n};\nfor await (const response of got.paginate(url, options)) {\n    // ...\n}\n``. > Shouldn't the hook be calledbeforePaginate` for consistency?\nI have no idea. Maybe it should be an option (paginate)... And the hook should be called beforePaginate. I think that way would be better.\n\nunless you have other use-cases for the previous response\n\nThe response could give a link to the next page.\n\nShould it have some built-in automatic behavior for the Link header?\n\nSure, that would be nice.. That sounds good. Let's do it that way :). > 1. I want the first 4 pages of a request. Would be nice if we could make got() work normally in that case and just gather up the first 4 pages for us instead of requiring the verbose async iterator coe.\njs\nconst arrayOfResponses = await got.pagination(url, {\n    ...options,\n    pagination: {\n        paginate: (previousResponse, options) => {\n            // By default this would be the Link-header thing...\n        },\n        from: 1, // Default = 1\n        to: 4 // If specified, it will return an array.\n    }\n});\nI'm not sure if it should be implemented. You can achieve the same in a few lines of code:\njs\nconst arrayOfResponses = await Promise.all([\n    got(url, {searchParams: {page: 1}}),\n    got(url, {searchParams: {page: 2}}),\n    got(url, {searchParams: {page: 3}}),\n    got(url, {searchParams: {page: 4}})\n]);\n\n\nI want to get new pages until I say I'm done. For example, I want to get pages, filter results, and end it when I have enough filtered items. Would be nice if this too was possible without the verbose async iterator syntax.\n\n\nNot possible. The Got logic is async.. Can you elaborate on:\n\nwithout the verbose async iterator syntax\n\nWhat do you mean specifically?. Oh. I thought that by without the verbose async iterator syntax you meant the sync iterator :P\nThat just returns an array, right?. Closing this in favor of #746 . It follows the provided URL automatically unless you set followRedirect to false.. Could you fill the issue template first? It will help us better understand the problem you're facing.\nThere are many examples in the documentation.. I see now. You're trying to redirect on a POST request. From the source code:\njs\nconst getMethodRedirectCodes = new Set([300, 301, 302, 303, 304, 305, 307, 308]);\nconst allMethodRedirectCodes = new Set([300, 303, 307, 308]);\nAs you can see, 302 is accepted only for GET methods... You need to catch the error and make another request manually.. They're both right. @sholladay just forgot to mention that 302 will throw on POST.\n\nhere mentions the subsequent redirect will be a GET, even if I make manual redirect in POST, meaning initial POST with a 302 response, and manually making another POST on the redirected URL, got will turn that into GET?\n\nNo, he hasn't said anything like that.\nSee my comment for the solution.. @scheung38 \n\nYou need to catch the error and make another request manually.. > will fix this to 200 success\n\nIf you did handle the redirection right, then no.\n\nthere is no API POST available from NGINX server\n\nThen why do you make a POST request?. > Was given that, from POST -> redirect and then use got to catch this location and make another POST.\nNo. It's in the following way:\n1. Make a POST request\n2. Catch the error.\n3. Manually make another request - it should be a GET request.. > I am making a successful POST with a direct request to my redirected URL with 200, but getting 415 statusCode if accessing it via a redirect\nSorry, but this sentence makes no sense. Can you explain?. Why do you make POST B twice?\n\nIs it because GOT cannot handle this flow\n\nNo, Got handles everything according to the spec. You must have done something wrong.... > But you can confirm this flow of manually catching second redirect works or not?\nMaking another request (a.k.a. manual redirect) works. If for you it doesn't, that means you did something wrong.. diff\n-options.cache = {cache: storageAdapter}\n+options.cache = storageAdapter. Why does Travis need port 80? \ud83e\udd14 . > > If you need web server to be listening on port 80, remember to use sudo (Linux will not allow non-privileged process to bind to port 80). For ports greater than 1024, using sudo is not necessary (and not recommended).\n\n\n\ndocs.travis-ci.com/user/gui-and-headless-browsers/#starting-a-web-server\n\n\n\nSo I guess it should be sudo nyc ava?. > Can't you pick a different port than 80?\nYeah, I can. 443. The port has to be default one.\nOr... we could check the error if there's nothing listening on 80.... > Then we would have to have sudo enabled on Travis too, which means we couldn't use their fast Docker images, which would make Travis much slower...\nIMO using sudo shouldn't affect the performance... But I believe you're right :). > when you enable sudo support there it will use the old non-Docker images, which are slower.\nThanks for explaination, makes sense.. We could also use nock there.... > If 443 works, I would prefer that.\nBut 443 is below 1080, so it won't work.\n\nOtherwise, nock is ok.\n\nOk, I'll do it :). It's still in development. See #167. IMO this should be a Got plugin. If there were many such small features implemented in Got, the code wouldn't be readable at all. Got aims to follow the spec. There is not spec for XSRF yet - there are too many ways to implement the XSRF thing (e.g. forms).\nFor now, there is no docs on how to make a Got plugin - it is in the works, and the API might change (#707). We need to wait a little bit more. See the sneak peek.. Use async function with await instead. Using blocking I/O is not the right way. This is how Node is designed - use promises.. Also, you can't create a blocking function in Node, so this is not the right place to make an issue.. ~You can use Symbols.~\nIt won't work because the options are cloned. We need to discuss possible solutions.. I think the best would be to use a prefix. Like:\njs\noptions._myAppData = context;. @sindresorhus eval or the module.require thing?. You can easily do that using req.pipe(got(url, {headers: req.headers})).pipe(res). Right, we should document this.\n@sindresorhus Should this be the default behavior?. Why do you need it? What's the use case?. While I do understand the promise.then(...).catch(...) part, I don't quite see where you can't use throwHttpErrors: false and verify the error manually, like you have suggested it in the beginning.. @DRSDavidSoft I have encountered that some APIs provide JSON error key with proper value if something went wrong. It would be much easier to use throwHttpErrors: false and provide own success variable like you have done.\n@sindresorhus What do you think about this?. > I did not quite understand, do you think supporting success is a good idea, or do you think APIs should provide their own error field?\nIMO that's bad idea.\n\nIn addition to that, reverse-proxies (like cloudflare) could break a JSON API.\n\nThen you need to catch the JSON parse error.. > May I ask the reson, why do you think it's a bad idea?\nThe proper way is to use promise.then(loginSuccess).catch(loginFailure). Otherwise you want to manually verify the response. If you get duplicated code this way you need to split the code to parts. Example:\njs\npromise.then(response => {\n    ...\n    finishLogin(response);\n}).catch(error => {\n    ...\n    finishLogin(error);\n});\nProblem solved.\nThere is no point in having duplicated ways to do the same thing.\n. I couldn't reproduce it: https://runkit.com/szmarczak/5c85717524f42b0012ace6c6\nCould you provide another example please?\nI will see if such bug is even possible to happen tomorrow.. Thanks for the code! It really helps. I'll try to fix this ASAP.. We can't help, the issue is not on our side.\nI have checked - installing from github works.. Can you paste the full console output?. > Can you paste the full console output?\nThis is not a full console output.. Can you make a Runkit snippet demonstrating the issue? I can't reproduce it.. Can you add some beforeRetry hook and log the event to see if it really retries?. ~~This has happened also on https://travis-ci.org/sindresorhus/got/jobs/506835639~~ Nah, that was just PR-specific and it wasn't making another retry. Everything works properly.. > Maybe add http/https to your migration guide?\nI don't think we need to - http/https is very low level, almost no one uses it (also it's not a good start). It provides very few features.\n@sindresorhus What's your thoughts?. If you want to convert the other tests, feel free. Or, if you're currently busy I'll try to do it, just let me know :). Ah, forgot to update readme examples... Will do.. You haven't read the documentation:\n\nmethods: GET PUT HEAD DELETE OPTIONS TRACE\n\nIt doesn't retry on POST methods.. @sindresorhus Nope. Tests have failed :laughing: . Fixed that.. I think handler could use next directly. Like handler: next. This should be:\njavascript\n    if (options.endpoint && !/^https?/.test(path)) {\n        url = options.endpoint + path;\n    }. This should be:\njs\ngot.create = create;. Yeah, I was using that in my app but forgot about it :D. Yep, naming is mixed up in my head sometimes. I know about httpbin.org but I didn't think of it. I'll change this to httpbin.org and provide the commented result :). Yes, it's an option. Done in next commit.. You're right. We should deep freeze those or clone.. Oh wait, you mean users may not be familiar with httpbin.org? Then yes too. I'll replace that.. Deep cloning may lead to false information because it's still writable. Used deep freeze.. Wouldn't it be better: for-of and Object.keys? I don't see much difference. . Oh, right.. It's was a template literal before, but I was lazy and I didn't change that. Doing that right now.. I just saw @floatdrop was having this so I did that too :P. What if you use two different libs (instances of got)? Then you have no possibility to do that. Wait, you could do that this way: got.extend(instance). 1. There's limit of redirects set to 10.\n2. We can set a timeout, if it exceeds the timeout then throw.\n\nWe need to set some sort of upper limit (and document it). What kind of limit do you think makes sense?\n\nIndeed. It should be the retries option.. got.extend(instance) people would think it'll only merge options (not handlers), the same as got.extend(instance.defaults.options) but no the same as got.forward(instance). I'll rename it to got.merge.. That's not needed IMO.. The tests would fail then, because normalizeArguments gets called before and makes a function. Calling options.gotRetries.retry(++retryCount, error) would throw because options.gotRetries.retry is not a function. So it must be done like that.. > What should the timeout be? Should it be configurable?\nYes, we should specify retries: { ..., timeout: number }. That would override the timeout option. By default it should be set to 15000 or 30000 I think.\n\nHow does retry interact with the set timeout?\n\nIt just makes a new request and uses the timeout option provided by user.\nIf got 413 status code, then it overrides the timeout according to the Retry-After header (if exists). I think I should note that in the docs.. ```\ncustom retries\n/home/szymon/Desktop/retries-patch/test/retry.js:93\n92:   let tried = false;\n   93:   await t.throws(got(${s.url}/500, {\n   94:     throwHttpErrors: true,\nThe second argument to t.throws() contains unexpected properties\nCalled with:\n{\n    statusCode: 500,\n  }\n```. > So why wouldn't the user just change the timeout option themselves instead then? If options.retries.timeout just overrides options.timeout.\nOnly if retries. I think by default it should be {socket: 15000}.. > Be aware Number(null) is 0, which would cause an immediate retry. Maybe not worth coding for, though.\nIf it's 0, then it won't retry. See line 212. Yeah. Why not... :). Yeah. But if a user doesn't specify methods or statusCodes then it needs to be empty.. Indeed.. Keep in mind that since Node.JS 10 URL is a global :)\nI think we should duplicate that TODO comment and paste it there:\n// TODO: Use the `URL` global when targeting Node.js 10. It should be more complicated. Like:\njs\nconst githubURL = 'https://user:password@github.com:443/say?hello=world#awesome';\nAlso I would rename githubURL to exampleURL.. Shouldn't be there expected.port = 443?. Needs another test with no port:\njs\nconst noPortURL = 'https://github.com/';\nconst parsedURL = new url.URL(noPortURL);\nconst options = urlToOptions(parsedURL);\nconst expected = {\n    hash: '',\n    hostname: 'github.com',\n    href: 'https://github.com/',\n    path: '/',\n    pathname: '/',\n    protocol: 'https:',\n    search: ''\n};. Don't forget about t.false(Reflect.has(options, 'port') ;). You could change the port to another, e.g. to 8080 or 80. But I don't know if it's a good idea.\nI would just add a comment: // IPv6 + :443 = no port. Smart!\nurl.search is null in this case. It should add that to path. Instead:\nhttps://github.com/alextes/got/blob/dccde51438af10a8a5236288c52b643dd95eb969/source/url-to-options.js#L11\ndo:\njs\n    const options = {\n        protocol: url.protocol,\n        hostname: url.hostname.startsWith('[') ? url.hostname.slice(1, -1) : url.hostname,\n        hash: url.hash,\n        search: url.search,\n        pathname: url.pathname,\n        path: `${url.pathname}`,\n        href: url.href\n    };\n    if (url.search !== null) {\n        options.path += url.search;\n    }. Because AVA. (throws an error IIRC). The comment shouldn't be on a separate line I think :) Maybe (?):\njs\n    const parsedURL = new url.URL(IPv6URL); // TODO: Use the `URL` global when targeting Node.js 10. That's https? Then sorry, hadn't noticed that :D. yeah, forgot it's const. If there were and, people would think that there must occur an error and then it'll allow that rule. Both rules are independent.. ok then. If got.create wasn't existing, then it'd be very helpful. I think this option is useless.. Thanks for clarifying this out :). This should be .on('beforeRequest', ...). Options may be overridden.. > we just wrap it in a function that calls both.\n@sindresorhus We need to be strict here. Only for beforeRequest and retries.\n\nI decided that it was better to leave that choice to the caller, since I think it is pretty easy\n\nIt's OK for now. Lots of things is gonna change if #510 gets merged. #510 needs a lot of polishing.. ```js\nconst a = {headers: {cat: 'meow'}};\nconst b = {headers: {dog: 'woof'}};\n{...a, ...b}            // => {headers: {dog: 'woof'}}\ngot.assignOptions(a, b) // => {headers: {cat: 'meow', dog: 'woof'}}\n``. This is what I wanted! A real example :) Now I know the advantage ofbeforeRequest. It's always before request. No need to merge anything (you could, but you now, if you merge two merged groups the order is not what you wanted, sobeforeRequest` does that job :tada: ) Cool :unicorn: . Replace:\njs\nconst response = await awsClient('/endpoint/path', {\n    // Request-specific options\n});\nWith:\njs\nconst response = await awsClient('/endpoint/path', options);. I would do: await hook(options); // eslint-disable-line no-await-in-loop. I just want to note: got.create({options: {}, methods: [], handler: () => {}}) shouldn't throw. It'd be better if hooks were done like @brandon93s has suggested:\n\nAn API like the following would allow us to expand this to different hooks and provide support for multiple hooks at once:\n```js\nconst plugin = got.hooks.beforeRequest.add(async req => {\n});\ngot.hooks.beforeRequest.remove(plugin);\n```\nHooks here could be things like: \n\nAuthentication \nLogging / Debugging\nFor example: chalk() of network activity in development mode\nEtc. > If we allow the setting to be an array (without providing a custom interface)\n\n\nOK. But this doesn't change anything.\n\nRequiring the use of a custom interface adds no value and prohibits advanced configuration scenarios.\n\nI disagree. What advanced configuration scenarios does it prohibit?\n\nI think that might provide better mechanics for anyone wanting to apply a custom merge strategy to the options for a new instance (versus the function wrapping discussed earlier).\n\nYou're right here.\nLet's assume there's got.hooks and handler receives a new argument: hooks\njs\n{\n    options,\n    methods,\n    handler: (options, hooks, next) => ...\n}\nWhat about that? Maybe that's just me, probably I'm wrong. I just haven't seen that from your side.. This should be named KNOWN_HOOK_EVENTS to keep the consistency of the code style :). BTW, do we really need to specify empty hooks in the defaults?. Okay then :). I just want to note that we should keep the style of coding. That's all.. Maybe just Object.freeze that?. I agree. Or maybe just move\nhttps://github.com/jstewmon/got/blob/c0aa4d74b9d9d94c858520586b5def68440cd9a9/source/request-as-event-emitter.js#L246\nright after try before it calculates the body size?. > I did it this way, and ensured hooks are defined as arrays during normalization\nSo it's needed to specify them in the defaults? If not we can just get rid of that.. > That would violate the expectation that got will make no further changes to the options before the request is sent.\nBut that's only one header... I think that'd be fine :)\n@sindresorhus What do you think?. @jstewmon It's not as easy as it seems to be ;) That's for the future: Got plugins.. I don't :) But look: there are other properties that get redefined: options.timeout, options.followRedirect, options.retry and more. I don't think it's a big deal.. Oh, then you're right. You should note that too.. Butter butter. Don't repeat yourself ;)\n\njust before the request is sent\n\nit says that for itself :). If options.search gets changed then you need to change options.path too.. If #510 gets merged:\njs\ngot.create({\n    options: got.defaults.options,\n    methods: got.defaults.methods,\n    handler: (options, next) => { // these options are normalized already!\n        options.search = '?asdf=123'; // need to change options.path too then\n        next(options);\n    }\n});. You can change options.search using beforeRequest too.. Ok, so after this gets merged I'll do another PR for that.. Yup. Forgot because before I did const body = (...).body then I used const { body } = ... :). Why would someone assign non-hook object to hooks? What's the use case? What big problem does this solve? Sorry, but I don't see that.. > I'm not sure what the origin of this conditional block are, but I think the right way to handle this event is to remove the if block\n429\n\nActually, since onSocketConnect and onAbort should be attached to the request, I don't think these are sensible hooks for got to configure directly. If you want to configure these for a got instance, you really just need to configure a listener for request and attach the request event listeners in the request listener.\n\n~~Why would you do the same thing twice?~~ Oh wait. I do that twice. I'll change that.. Nope. https://github.com/szmarczak/got/blob/b22c3abbe8daf905aae4bed66cddfc7b9ed72170/source/normalize-arguments.js#L191-L199. It's not a bug. It's a feature!. Thank you for the detailed response, I really appreciate that! :+1: . > Maybe I'm missing something, but I don't think that was the right fix b/c if req.connection is just testing a race condition. Shouldn't it be:\nI don't know. Can you make another issue for that?. > I can see the convenience of low-friction hooks.\nGreat! We'll discuss this later. I was gonna send a PR with rewrited hooks from scratch but I decided current implementation is better. :). > Can you add a short code comment why we don't set this?\nYes.\n\nAre there other headers we shouldn't overwrite?\n\nNo.. You misled me :P You shouldn't negate the condition :D. I don't understand what's wrong with that :P I'll change it :). Thanks for telling me about that, very interesting :3. Refactoring should be done in a separate PR. Just Kidding :P \ud83d\udc4d . Do we really need that? It's aborted only when receives an error/someone cancels the request. The error got throws has nice details though.. I don't know.. #### Does this facilitate something?\n\nbefore: if you hadn't specified hooks in the defaults, got.hooks would be undefined\n\nI'd avoid duplicating access points.\nWhat's duplicated here?. Stream should be in. Extend no, because if someone doesn't like that function he can overwrite it :) What do you think?. Yeah. It should be set to false (default value).. Yes, I forgot to remove it when I was resolving a merge conflict.. Done.. Incorrect implementation here. See why:\n\n30c39bc1c3042a80ed3f6752677e0ab42cb1ca98\n13d6b68ba02413374519f490d75741a427d705ad. No, it's not. Consider looking at the JS docs ;) Or google object reference javascript.\n\njs\nlet a = {};\nlet b = a;\na.c = 123;\nconsole.log(a);. Fixin' right now. You have really sharp eyes!. > It looks like tests around this are contrived to pass\nMake another test and increase the timeout so the request finishes. Why hadn't you checked that? It passes. It doesn't throw, because the promise has been resolved already.. > I'd avoid duplicating access points.\nIt's not named access points. There's no such thing in Node. I think you meant object references. Google it.\n\nI was saying you're creating more than one way of accessing the same object: got.hooks and got.defaults.options.hooks.\n\nWhat's wrong with that? That's a shortcut. got.defaults.options.hooks is a long word, isn't it?\n\nWe can better understand each other by asking questions until the meaning is clear without presuming the other person is an idiot.\n\nAgreed. Using correct naming would end the argument. :tada: I've searched for access points but found nothing.. > await delay(reqDelay * 3);\nIf you used a Promise and attached some listeners, it would throw with that too.\nThe point is no one has added a delay because everybody assumed if the request finishes without any errors, it won't throw then. That's just an oversight. If you tell that I just omit this intentionally, then you're wrong.. @sindresorhus Yeah, you're right. My fault. I should better haven't said that. Sorry for being offensive.\n@jstewmon Please take my sincere apologies.\n\nTechnical conversations are usually a mixture of colloquial and technical terms.\n\nOn StackOverflow that behaviour is not welcome, just saying as I've experienced it myself.. I've looked deeply and I think it's safe to do so. Good job!. You both are right. The main intent was to emit response ASAP, so @floatdrop used setImmediate as it executes immediately after I/O operations. I'd leave setImmediate unchanged here.\n\nIf a callback is provided for request, it will be the first handler to run.\n\nI think @jstewmon is right here. We don't need setImmediate in this case (line 198).. > That's not how I read it.\nIf an error was emitted before the response, then boom.\n\nThe emitter response event is emitted from getResponse, so setImmediate here delays that.\n\nWhen #117 was merged there was sense to do that.\n\nI think a better solution to checking a timeout against the response event would be to use setImmediate in the timer callback\n\nCan you elaborate? The timer callback clears the timeout AFAIK.. So, you just delay throwing the error in favor of IO job (e.g. emitting the response)? If it emits the response, got instance resolves, but the error will be thrown anyway. The test you made (#528) would fail.\n@floatdrop added here setImmediate to emit response ASAP (to clear the timeouts, before there are any errors thrown).. Sorry, I just missed the second if somehow.\n\nDo you mean that setImmediate was added to allow the timeout event listeners to run before the response stream is handled by getResponse?\n\nI mean if a request receives a response, the timeout is cleared. But there is another job to do with the response and it might cause some delays:\n\nOn request-heavy applications (with short timeout option) lots of requests will be rejected, because of response handlers.\n\nBefore:\n\nFirst request:\ntimeout has been cleared\nthis thing makes some delay, because there's no setImmediate here\nSecond request: sorry, but too much time has passed, throws an error.\n\nAfter:\n1. First request:\n   - timeout has been cleared\n   - this thing doesn't make a big delay, because setImmediate is used here\n2. Second request: ok, go on\n3. First request: success.\n\nI am interested in adding a timeout for the response event b/c it's useful to abort the request if the server takes too long to respond to the request.\n\nUse socket timeout. If you use response.setTimeout() it'll throw unless whole response is received I think.. I just want to note we're talking about completely different things. They are not the same. Your example just gives the last chance for establishing the connection, but I don't know if that's the correct behavior.. Your example just gives the last chance for establishing the connection after the timeout has been called. Am I wrong?. > I think a better solution to checking a timeout against the response event would be to use setImmediate in the timer callback to defer the error emission to the check phase of the event loop in case the response had been received but was still queued due to load.\nSo the connection was established, because there's a response.\n\nHere's some code to illustrate what I meant about using setImmediate with timers.\n\nYou were trying to illustrate the first sentence using the connect timeout, though it had been connected already. Awesome.\nIs it possible to receive connect event and response (with some queued data) in the same loop?. > Have you carefully reviewed the doc I linked earlier about the event loop phases?\nYes, I have read it several times, not only today. \n\nThe point is that if we're checking connect timeout. The connection may have already been established, but its event hasn't fired when the timeout callback is run.\n\nThen the connection is not established. From the docs:\n\nEvent: 'connect'\nEmitted when a socket connection is successfully established.\nsocket.connecting\nIf true - socket.connect(options[, connectListener]) was called and haven't  yet finished. Will be set to false before emitting 'connect' event and/or  calling socket.connect(options[, connectListener])'s callback.. > Now that timeout.request is waiting for response.end, I think deferring the call to getResponse actually increases the possibility that the timeout will breach.\n\nNot true. Before I've copied timed-out into this repo there was pTimeout handling timeout.request, so it started counting immediately after the promise was called (no connection has been made yet). That's just only a note.\n\nThe underlying system operation completes before we're notified. That's the purpose of the poll phase - to notify us that the IO operations we listened for are complete.\n\nI still disagree here. It has its own time to establish the connection. But this change is not significant I think. Let's skip this subject.\n\nNo, the statement you quoted was in my original analysis. I was suggesting that there was a more precise way of mitigating #117 than deferring the response piping with setImmediate.\n\nSo if these are two different things, I've got only one question: what is the better way to avoid bottleneck with emitting the response and handling it? (Line 107) What else if not setImmediate? You haven't implemented it yet. It just delays establishing another connections for now (if there's big amount of requests).. Yep. Doing right now.. Done. Also I've moved baseUrl handling into if (is.string(url)) { ... } to avoid checking is.string(url) two times.. I'm curious about the naming of response timeout and request timeout.\nShould be these names swapped (as the timeouts say how much time can pass until it reaches the event)?. Can we leave this unchanged as this is being discussed in #525? Try not to duplicate PRs.. Love the new timed-out.js. \u2764\ufe0f \ud83d\ude4c . > I'd suggest renaming request to overall or total.\n\ud83d\udc4d \n\nsocket may be more expressive as idleSocket, but I think it's too pedantic to justify the incompatibility.\n\nAgreed. socket is enough IMO.. Ok. Seems good. Is it ready to merge?. Wouldn't be this better:\n\nOne of the timeouts has occured.\n\nI don't think breach is a good word here to describe that. Any thoughts?. target = {} is useless here. :+1:. use const {URL} = require('url');. Consider this example:\njs\ntest('extend overwrites arrays', t => {\n    let statusCodes = [408];\n    const a = got.extend({retry: {statusCodes}});\n    statusCodes[0] = 500;\n    t.deepEqual(a.defaults.options.retry.statusCodes, [408]);\n    t.not(a.defaults.options.retry.statusCodes, statusCodes);\n});\nIt shouldn't fail. It should deep copy arrays IMO.. Oh. Defaults are deep frozen here: https://github.com/sindresorhus/got/blob/da7f055749780438999d459dca5455a61abab8ba/source/create.js#L45\nand ain't cloned before.. :-1: It should keep the old value.. :-1: The feature is meant only for headers. Otherwise, if the new value is undefined, it shouldn't be replaced.. Look at the other merge / extend libs :) They omit undefined values.  I mean users would think that if you leave another property undefined it will remain unchanged. It's header-specific.. > Just to clarify, based on your complete suggestion below, you think undefined values in the source should be noop and the target value should be preserved, right?\nyes.. I'd leave this note about avoiding object spread because mostly that's not what users want.. @sindresorhus What are your thoughts on that?. I strongly agree :) This behaviour is more clear IMO.. @jstewmon Could you allow edits from maintainers? I did what @sindresorhus said, I just wanted to push one commit. You'll change that (or revert) if you'd like to.\nEdit: Oh, wait. It's been enabled already.. I wouldn't support this, as it might be confusing with got.extend({ ... }), where setting to undefined keeps the old value.. OK, I've made another PR :). Already did.. > What's the rationale for, or problem solved, by deep merging arrays?\nYou don't even simply clone them, so let's start with that. With arrays there should be no exception. I'm not gonna explain simple things.\nI really appreciate you want to do it on your own :). > Arguments are worthless if the other part doesn't understand you. Not everyone is in your exact mindset. We all need to be on the same page. I was also confused by your comment.\nI'll sum up: going through shortcuts won't end well, just a hint. Another hint: references, arrays, deep freeze. This says a lot.\n\nDon't modify other people's PRs before we have agreed on a solution.\n\nI've just proposed a solution based on yours. Do what you want, I'm off. I'll be happy with any (current one is cool too).. > Yeah, I made it only deep copy plain object, since all other types are merged by replacement.\nI don't think obvious things need an explanation, do they? You've just repeated yourself: that's what your code does, doesn't it? Please come up with a real argument. I'll illustrate if you have problems with understanding mine:\n\nSomeone creates an array.\nThe array is passed to assignOptions through got.extend().\nIt is passed by reference (please keep that word in mind my friend).\nIt's deep frozen (got.extend() -> got.create() -> deepFreeze())\nSomeone wants to reuse the array.\n:boom:. > I was also concerned with performance, since this method is called not only by got.extend and got.create, but also by every call to got().\n\nThen why? There are many nitpicks that could improve performance a bit (it's unnoticeable) like this one and you're nothing about that. Please, be serious.\n\nDo you think it would be helpful to explicitly mention in the got.extend and got.create that the resulting object is frozen, so that any reference types will be frozen?\n\nNo. That's dumb. All plain objects are frozen and other objects like arrays are not? That doesn't have any sense. BTW, It's OK to pass references to other types than objects and arrays since got doesn't use them.. Wait. What's with user-agent? You need to change the test name if you change the behaviour too.. Use Reflect.has() for consistency.. Also I suggest figuring out a better test name.. After I read the test name I still don't know what's this about.. Stop guessing. You need to change the URL to #gotassignoptionsparentoptions-newoptions.. I've removed that part (\"or undefined\") to not confuse people with the behaviour of got.mergeOptions, where setting to undefined may keep the old value.. Yeah, must missed that when was merging with master. Fixed.. I consider it's no longer needed, because the defaults are cloned, so your object is safe, nothing will change :) This proves it.. AFAIK form option is converted to body option here. read-only means the stream is no longer writable.\nThe only related thing is that I've changed the messages about streams.. I've just changed the sentence to make things clearer. The behaviour of form option remains the same.. This fixes a bug: at first I thought is.number won't return true for NaN, but I was wrong.\nMath.max is not needed BTW.. get() does not throw any errors directly. It uses emitter.emit('error', error);. > Previously it said that the option cannot be used with got.stream() at all.\nYeah, but practically it wasn't true.\n\ncan you point to a test proving that?\n\nSure :). Here you go: https://github.com/sindresorhus/got/blob/b504346f92b7e59942e6fdfd1da264762b300267/test/stream.js#L62-L66\nSee? I hope it proves it :). I see I've added it here. It's no longer needed because decodeURI error is catched here. If it wasn't there then we would need to catch on setTimeout too. But there's no need as metioned :)\nI'll deny my answer:\n\nIt's caught here, but not here and not here.\n\nIt was caught nowhere. I don't know how I did get that :confused:\nTo sum up: the removal is good, I'm sure 10000% :). I hope my answer is no confusing :P. > you're not answering my question.\nSorry, if you're talking about the second one then it hadn't popped up when I was writing the answer. Pardon my confusion.\n\nI think we need to try/catch this line because it could throw\n\nGood point! Indeed. \ud83d\ude4c . Done! I hope it satisfies you :). Yeah.. I think && !is.nodeStream(body) is missing here.... Because it's not needed. See https://github.com/sindresorhus/got/blob/master/source/request-as-event-emitter.js#L43. > Is this enforced?\nWhat do you mean by enforced?\n\nThese options are normalized, so assigning baseUrl here won't work.\n\nThis should be: These options are normalized, so assigning baseUrl here won't have any effect.. > .merge() is too ambiguous.\nMaybe. But I prefer this way :P\n\nLet's name it .mergeInstances().\n\nIsn't that too long a bit?. Is it even possible to do: let x; {x} = {x: 123};. Not yet \ud83d\ude15 . This hack enables merging two instances by instanceA.merge(instanceB). You can always do got.merge(instanceA, instanceB).. Note: many errors should have their own classes.. Agreed. Mine are:\n\ncontrolling redirects,\nlimiting download & upload (e.g. your machine has 512MB RAM and you are downloading 1GB file hue hue hue),\nusing custom API (e.g. ghGot),\nsending random user-agent.\n\nAlso you can use beforeRequest hook to sign requests. All these as a single instance.\nDo you have any ideas?. I wonder why it's needed to enclose it in the () brackets.. Sure!. Will do.. Ok.. It's not mergeable because instance.defaults.mergeable is set to false. This is the only way to make it unmergeable.\n\nI think the error should say why it's not mergeable.\n\nInstance {$index} refused to be merged?. Ok, I'll leave that then.. > Why are you lowercasing them here,\nImagine calling got.POST instead of got.post :P\n\nbut uppercasing them in normalize-arguments?\n\nTo keep things consistent; because error.method is uppercased :). Okay, I'll change it then.. That's ok, answering questions is my job :P It's a bit late here too :). > The mergeable option is not documented (I we decide to keep it, it should be)\nYeah, it should be.\n\nWhy do you need to make an instance unmergable?\n\nI assume instances can be very complicated, e.g. override the current behaviour, or merging it with other instances may somehow result in incompatibility. I see no other reasons. If you feel it's not needed, I'll remove it.. Done.. I'll remove it. As for now I don't see any useful use-case. We can add this feature later if needed.. done.. done.. The same result we can achieve using:\njs\nObject.defineProperty(options, 'baseUrl', {\n    writable: false\n});\nBut the error will just say it's not writable, no other details.. We could return throwing EventEmitter here. What do you think?. Oh, I was playing with cyclic modules. Removed it.. Done.. It's not needed at all (that was an old idea). These are just an aliases to the instance. (got.get(), got.post() etc) Hang on, I'll fix it.. Sure! :). ~~Then node will throw an error that setter is missing an argument, because how you can set something to somewhat without knowing the value?~~. Weird. Usually it threw an error that setter is missing an argument. I'll change it :). Removed.. Should the examples be moved to the top?. These are just aliases. If methods are set to ['get'] you can't do got.post() but you can do got(url, {method: 'POST'});. I see no reason why we should let users to modify the aliases.. Sounds good!. Sure. yup. I've split normalize-argument.js into two parts:\n- preNormalize handles all the stuff which is related with static options like baseUrl, followRedirect, hooks etc.\n  It is used in got.create() to  normalize defaults.options.\n - normalize does preNormalize + handles all the stuff related with dynamic options like url, headers, body etc.. Isn't it ugly? :P. I decided to name it module because that word is used everywhere in the readme. Should I replace all modules with package?. Good point.. Listening on 80 or 443 is likely to crash (EACCESS). Wait, I forgot about nock. I'll just push a commit.. It's more readable.. Because electron set throwing getters for these. We need to override the getters.. IDK why but the \"global\" approach was throwing an error for me. I'll try that again.. K. Yeah, I'll do.. Good point!. Hmmm. The cookie header should be taken instead (if it's specified).. This is what I get:\njs\n(node:8174) UnhandledPromiseRejectionWarning: Unhandled promise rejection (rejection id: 1): TypeError: global.require is not a function. Yeah, true.. Ok then. Hmm... Smart :P. done. This should be before that if.. changed. Seems good to me. I'll try that. Thank you ;). I tried it, and unfortunately it doesn't work...\n```js\nz = require('mem')((x, y) => Math.random())\n[Function]\n\na = new Map()\nMap {}\nb = new Map()\nMap {}\nz(1, a)\n0.7761714954957284\nz(1, b)\n0.7761714954957284\n```\n\nAlthough a and b aren't the same objects, it gives the same results. It causes the tests fail.. @sindresorhus ~~is it a bug? ^^^^^~~ Nah, we need to update the cacheKey function.. Yeah, did already so! :). It's not needed. There are many options which are false by default and those aren't here :) IMO we should only set defaults which point to true, it's more clear. Others are false implicitly.. I thought about it too. But this'd require to generate new cache per request.\nPerhaps we could limit the size of the cache to 100 items?. You're right. Then let's do it that way :). > What if the requests are huge [...]\nI meant limiting the amount of CacheableRequest instances to 100.\n\nIf it's slow to generate a CacheableRequest, why is this not being fixed at the source instead?\n\nGood point. I haven't looked at it in that way. I'll do that tomorrow.. > Why would it cache the requests?\nWhat do you mean?\n\nI agree that memoization could be a feature of the package itself or one around it though.\n\n+1. > Should we include the retry count too, like requested in the original issue?\ny\n\nShould there be a way to stop retrying from this hook?\n\ny. y. y. > Should there be a way to stop retrying from this hook?\nIt is already: throw an error.. yeah, just forgot git stash :P. okay then. you don't have to create a new URLSearchParams instance... it'll be done in normalize-arguments.js.\njs\ngot('https://example.com', {query: [['key', 'a'], ['key', 'b']]});. okay :D. maybe Node-specific (I'm good with both)?. with => using. If you return an object from afterResponse, it makes a new retry with those options.. Ok, will change that.. You're right :). Maybe Did you know, that Got has some options in common with Request?. need to link tough-cookie. Object<string, string/number>. These options are normalized. retry.retries is a function.. This code was used for retrying when afterResponse returned a plain object as the updated options.. Then it'd be possible to have infinite loop. Assume it always returns 401, no matter what. Then it keeps retrying, and retrying... Keep in mind that the hooks are still present.. This is used only to get the response object (not an error). The original asPromise determines if it should throw or not.. No, the hook is ran anyway, no matter if is it a normal request or a retry. But if it fails anyway, it loops (server keeps returning 401 and we keep retrying). And to prevent the infinite loop we need to check the retries.. yup, I forgot about it, sorry :p. forgot about it. fixin. here's a test: https://github.com/sindresorhus/got/pull/647/commits/98e51810797c8c93cc0b2fe55f5d0e6d2e7eb687#diff-0920de5c123084fabef750aa0967f8d4R309\nalso you may set it to true and you'll see it fails. Or we can stop executing next hooks in the retry, then we won't need emitter.retry(null) == false. Example:\nhook 1\nhook 2 - retries\n--- hook 1\nhook 3\nHook 3 is called twice.\nCurrent behavior (very bad, it shouldn't be done like that):\nhook 1   <-----------|\nhook 2 - retries     |\n--- hook 1           |\n--- hook 2 ----------|\n--- hook 3\nhook3\nHook 3 is called only once.. nah, you confused me! :P mergeOptions doesn't normalize. It just merges them.. > Alright. I think this behavior needs to be documented though.\nNo need to have that behavior. Fixed! There's no infinity loop. See my previous comment :). Right. I'll change that.. That'll be just a note. The behavior is the same, but we accept additionally URL.. Ok :fire:. Will do! :). Will be :). With Got, it would be: -> With Got, it is:\n(both are correct but the second is more appropriate IMO). sure!. I prefer to operate on parents, not children (options) :P. I think it's more clear.. There is much sense! :D If response is null/undefined you can refer to undefinded by response.statusCode. It throws. But you can log undefined, right?. Try:\njs\nconst a = undefined;\nconsole.log(a.b);\nconsole.log(a);. AFAIK if there's an error the rest is null (callback style). I'm not sure if Request applies to this.. js\nagent: new agentClass(agentOptions)\nforever-agent\npool implementation:\n```js\nconst agentSymbol = Symbol('agent');\nconst pools = new Map();\nconst getKeyFromPool = pool => ...; // TODO\nconst getAgent = (pool, options) => {\n    const merged = {...pool, ...options};\n    const key = getKeyFromPool(merged);\nif (!pools.has(key)) {\n    pools.set(key, new specifiedAgentByUserOrDefault(pool));\n}\n\nreturn pools.get(key);\n\n};\n```. will do :). > followRedirect - follow HTTP 3xx responses as redirects (default: true). This property can also be implemented as function which gets response object as a single argument and should return true if redirects should continue or false otherwise.\n\nfollowAllRedirects - follow non-GET HTTP 3xx responses as redirects (default: false)\nfollowOriginalHttpMethod - by default we redirect to HTTP method GET. you can enable this property to redirect to the original HTTP method (default: false)\n\nIt's counted as only one option: followRedirect. (followAllRedirects and followOriginalHttpMethod are the children of followRedirect, 'ya know what I mean?). Also, some Request's options are not spec-compliant.. see what else you can do with hooks. -> see what else you can use the hooks for.\nOr: see what else you can achieve using hooks. do with does not mean use.. I did not say we should have no such feature because it isn't spec-compliant. I meant Got's more spec-compliant than Request. Anyway, nevermind. It doesn't matter. I'll just list them.. > The client can provide a custom retries function and it expects to receive 1 for the iteration argument in the first retry. This breaks the contract, it's a SEMVER-MAJOR change. I'd prefer to keep the old behavior.\nActually, no. It's a bug. According to the docs, it should start with 0:\n\nDelays between retries counts with function 1000 * Math.pow(2, retry) + Math.random() * 100, where retry is attempt number (starts from 0).. @sindresorhus \nwe need to preserve backwards compatibility\n\nCompatibility with the docs or compatibility with the previous mechanism?. In case we agree to save the previous mechanism, then yes.\n@sindresorhus any thoughts?. Right. Then it starts from 1.. Just a visual thing. People would replace it with their own text. But I guess you've already known that. For me it doesn't matter if it's ... or empty or <!-- Provide information here. -->. I'm good with anything :P\nSo, to stay consistent I'll use comments :). I agree.. It'd be nice to have a note here that it is not http.ClientRequest.. you're right, fixed :D. It must be synchronous - otherwise normalizeArguments would be asynchronous, so errors thrown here wouldn't be caught.. suggestion\n**Note**: *`body` must be a plain object or array and will be stringified.*. I'm not sure if \"note\" is really needed. It's just default values :P. To be consistent: \"If you provide this option, ...\". Of course :D I'll rename other hook tests too.. :+1:. Whoops \ud83d\ude05 Will do that.. Custom instances:\n```js\nconst instance = got.extend({\n    resolveBody: true,\n    responseType: 'json'\n});\nawait instance(url) // returns the body\n```. > With that example there's no way to get the whole response though\nNope:\njs\ninstance(url, {resolveBody: false}); // returns the whole response instead\n\nSo I don't think this option should be public.\n\nThen what if someone wants the body instead of the response for all requests?. It should be named resolveBodyOnly. it has. updating the readme now :). I believe it's import {IncomingMessage} from 'http';. This should be ClientRequest. no .default here?. Why is it a function?. If supportsBrotli needs to be a function then it should be supportsBrotli(). You needed just this change: https://github.com/sindresorhus/got/pull/708/files#diff-bc120f022c76c025170acc93be719a59R30. Nevermind. I'll fix it :P. > thrown errors won't be caught\nCan you elaborate on this one? I'm not sure what do you mean by that.... I'm not sure why the void type is here... Shouldn't it be just Error | Promise<Error>?. I think it should be\ndiff\n-retryWithMergedOptions: (options: Options) => IncomingMessage | CancelableRequest<IncomingMessage>\n+retryWithMergedOptions: (options: Options) => CancelableRequest<IncomingMessage>. @sindresorhus Do we need to double the documentation?. I'm not a TypeScript master either :P\nIs there maybe another way? For example the Hooks interface:\nts\nconst hooks: Hooks = {}. The type of merged should be Options. This would fix that. Is the Options type needed here?. Agreed on that thing. Sorry I didn't shape my question correctly: I mean, generally, do we need to redocument everything in the code, isn't the README just enough?. Some of the properties should be moved to different errors, for example, timings should be moved into TimeoutError.. > If we redocument everything, we can later generate the documentation.\nLooks promising! Let's do that way then :). ping?. Oh, thanks for the explaination, it's clear now. I'll try to think of something.... Nope: https://github.com/sindresorhus/got/blob/master/source/request-as-event-emitter.js#L137. @sindresorhus I think we should mention in the README that the URLs are stringified.. Also, body shouldn't be located in GotError. ParseError and HTTPError only.. same here. Actually, it should be:\nts\ninterface Timings {\n    start: number;\n    socket: number | null;\n    lookup: number | null;\n    connect: number | null;\n    upload: number | null;\n    response: number | null;\n    end: number | null;\n    error: number | null;\n    phases: { \n        wait: number | null;\n        dns: number | null;\n        tcp: number | null;\n        request: number | null;\n        firstByte: number | null;\n        download: number | null;\n        total: number | null;\n    };\n}\nSince it may throw an error, the rest can be null except start.. Forgot to mention: it should be string[]. Ok :). Why not make error optional and use undefined instead {}?. This has been deprecated a while ago, no longer needed.. Parts. Also isn't Partial<Options> enough? It has defined hooks: Partial<Hooks> already.... It should be removed. Lemme do it.. Seems good. Let's go with that.. @sindresorhus Does TypeScript resolve it automatically if using Node 8?. Well, if we want to move the route into the specific test, then we should do it everywhere, not only here.\nAlso, that would result in having two servers in one test function.. > Why is that a problem?\nThe code becomes less readable.\n\nYes, but that's an insane amount of work. I think we should at least do so for new tests. Better to do it iteratively.\n\nOk so.. remove this. The behavior is the same, this just fixes some some linting error :P. Moved from the lasting if. Just a more readable code, behavior is the same.. Performance nitpick.. A small fix.. This is not needed. You can simply do s.host = 'localhost';. @sindresorhus Shouldn't it be named s.hostname?. ",
    "paulmelnikow": "I noticed this discussion via the changelog. I realize I'm showing up after the work is done and then complaining about the outcome\u2026\u00a0so take this heavily salted!\nFor what it's worth, I appreciated the check, and wanted to offer support of the intent behind it. In-URL auth is obscure. Most devs probably do not think about the fact that a URL can contain a username and password which ends up in a header.\nI'm also passing off user-provided URLs to make request on the server. I don't want to accept in-url auth, which I can handle with validation. Unfortunately the validation library I'm using (Joi) doesn't support this yet, so this is in the backlog.\nIn the rare case someone wants to use in-URL auth, suppressing the warning could be handled using an option like unsafeAuth: true as @alextes suggested.\n\nBut when put into the Authorization header, these APIs usually require it to be with the Bearer scheme (or Token), not Basic. auth however sets Basic, which is usually not recognized.\n\nIs that really true? It sounds like the auth string is not sent to the server in the URL. Rather, it's the requester's job to translate the username and password to a Basic auth header. https://serverfault.com/a/371918. And \u2013 thank you all so much for your work on this useful library! I've just adopted it in another project and appreciate how easy it is to use, and for other contributors to pick up.. Yea. It's in the backlog :). I will give source/request-as-event-emitter.js a shot!\nAdded: Making progress: https://github.com/sindresorhus/got/compare/master...paulmelnikow:request-as-event-emitter-ts. ",
    "sbrl": "Ok, Thanks! I was hoping that there would be built in support. I'll see what I can do. The problem is that I need to make multiple different requests and save the cookie state after each one in order to login to a particular online service :/\n. Default jar storage? What's that?\n. @floatdrop Right. I don't understand how I can pass a default jar into a gh-got or vk-got instance without doing it manually - in which case I should use vanilla got instead. Sorry for all the questions :(\n. ",
    "FranklinYu": "Bloated request has built-in cookie jar support.. ",
    "gajus": "This thread doesn't answer the question how to use tough-cookie with got, e.g. How will the redirects be handled?. > Can you elaborate on the configuration errors? I don't know what these mean, but I'm happy to know :)\nReferring to API contract validation, e.g.\n```js\ngot('http://gajus.com/', {\n  followRedirects: true,\n  payload: Buffer.from('test')\n});\n```\nThe above contains two errors that are hard to notice for a user and will not be caught by the program until runtime validation.\nIf there were static typings, e.g.\n```js\ntype HttpClientConfiguration = {|\n  +body?: string,\n  +followRedirect?: boolean\n|};\ntype HttpClient = (url: string, configuration: HttpClientConfiguration) => Promise;\nconst got: HttpClient = async (url, configuration) => {}\n```\nThen the above code example would throw the following errors at a compilation step:\n``\n10: got('http://gajus.com/', {                             ^ Cannot callgotwith object literal bound toconfigurationbecause propertyfollowRedirectsis missing inHttpClientConfiguration[1] but exists in object literal [2].\nReferences:\n6: type HttpClient = (url: string, configuration: HttpClientConfiguration) => Promise<any>;\n                                                  ^ [1]\n10: got('http://gajus.com/', {                             ^ [2]\n10: got('http://gajus.com/', {                             ^ Cannot callgotwith object literal bound toconfigurationbecause propertypayloadis missing inHttpClientConfiguration` [1] but exists in object literal [2].\nReferences:\n6: type HttpClient = (url: string, configuration: HttpClientConfiguration) => Promise;\n                                                  ^ [1]\n10: got('http://gajus.com/', {                             ^ [2]\n```\nhttps://flow.org/try/#0C4TwDgpgBAEsxgMIBsCWEB2xEHsMDNUBzAVwCcBDYVPKAXigG8AfAKCigGoAjHAExAB+AFxQAzsDKoMRADTsu+HMmQ4A7gCUIfVGQgBjYCKi9lEChlbMAvgG5WrUJFjwkaTMHpQAFOWSiJKRlZKH08QlJKajxROAQUdCxcAmJyKhoMAEp6AD4oAAUyHABbVDEIAB4LEBz7VjCMCSgiHGBY1wSPLwoxEAx9Hz8Qhoi06KzcpmsHFuBvAHIAC1dhAHpVogoAKxIxADow4tX5kMYFJRV1LR09QzFRSRIIeQ4wChBVCj5ReeAICXmrGsmVsQA\nI am maintaining projects with dozens of freelancers working and literally thousands of individual scripts. It would be near impossible to code at this scale without static type checking. We can definitely wrap got internally with our own types (we are going to do that anyway to restrict some features), but a type-safe project would definitely be a huge incentive for me to choose got over the other available alternatives.. > Just to clarify, by \"have support for Flow\", I mean adding a Flow definition file, not to rewrite Got in Flow.\nYeah, I realised that. Thats why I quietly backed away.\nI personally think that this is a fragile approach: you end up replicating changes in 2 different places (with TS support: 3 different places). However, thats better than nothing from the consumer's perspective.. > I think roarr is a bit heavyweight to include in Got, [..]\nI have refactored Roarr into two packages:\n\nhttps://github.com/gajus/roarr\nhttps://github.com/gajus/roarr-cli\n\nNow Roarr logger package is 304K.\nNow the bulk of the size comes from sprintf-js, which I cannot do much about.\nIf the intent is to compete with other packages on package size, then this is going to compromise your position.\n\nbut how about we just expose a metadata event and people can log using whatever they want?\n\nThis approach works great for applications, but it sucks for modules. I explain the distinction in https://github.com/gajus/roarr#motivation.\ntl;dr;\nWhen you have an application which depends on modules that use got, there is no way to enable got logging without digging through node_modules/ and patching the code.\n\nWe could also log by default using util.debuglog().\n\nI like util.debuglog(). However, it does not provide structured logs. Modern logging stacks (ELK, Splunk) ingest structured logs (JSON), which allows to implement monitoring/ alerting and even scaling based on log attributes. This is primary reason for using logs in the first place \u2013\u00a0nowadays debugging is better achieved with --inspect anyway.. > Environment variable?\nNot if you go with the custom event approach. Environment variables can only toggle logging, not configure the hooks.\ndebug (module) and util.debuglog() already provide this functionality with DEBUG and NODE_DEBUG variables. The only downside is that the logs are not structured.\n\nAlternatively or in addition to, we could have a singleton emitter, that logs for all instances, so you could just require('got').on('metadata', () => {}) and get logs even when got is used in sub-dependencies.\n\nUnfortunately, you cannot do that either, because the application will loose access to the singleton if modules depend on incompatible Got versions.\nThis is the reason why Roarr is using global to register log handler/ push logs to. It is the only approach to have interoperable log handling between all components, regardless of the version. Resolving version incompatibilities then becomes the responsibility of the logger itself \u2013\u00a0every initialisation of Roarr logger promotes handling of global space to the highest available Roarr version.. > We should use a Symbol so it's only accessible by a Got instance.\nIf you use a Symbol, then you are back to square one \u2013\u00a0Symbols are not going to be shared between incompatible Got versions. Of course, you could create a dedicated package just for the symbol... thats a bit of stretch.\nIn general, yes, this approach would work. I am not recommending it as it is effectively inlining logger logic into the package, but it does the job.. > I think it's important that the software directly consuming got must explicitly enable logging and that all other instances of got be unaffected by that.\nI argue for the exact opposite.\nLogging (not to confuse with debugging) serves the purpose of exposing all available information about application to enable a comprehensive view of all attributes associated with the application. One of these attributes is HTTP requests. Therefore, if I enable HTTP logging for an application, I expect a comprehensive view of all requests made either by my application or descendent components.\nWhat is the logic for what you are arguing?. > With an allowance for redaction of sensitive information, I agree. The issue is the \"if I enable\" part. I'm saying settings made in or for a descendant or sibling component should not affect what I have here.\nThats a responsibility of the log consumer, not the application.\nSomething like Logstash would be responsible for stripping away the data that is not supposed to leave enter the log database, e.g. passwords and such. This is a manual process and a responsibility of your sysops.. > I might agree, but that's making a lot of assumptions about the stack. How many users of got or its dependents do you think have a dedicated sysops team? What is your suggestion for those who don't?\n\nMost of the users who do not have sysops are going to be jacks of all trades and can implement this themselves.\nMost of the users who do not have sysops are unlikely to have a centralised log aggregation system either. Those that do, will have the technical knowledge of how to configure the aggregators.\n\nThere are a lot bigger security concerns prior to concerning with log neutralisation.. > @gajus You can achieve what you want using custom instances. I'd use got.create and attach some listeners + logging and done.\nThats what we are doing already.\nThe point was to have logging that would enable inspection of all application traffic, including its dependencies.. Just saw that this is a duplicate of:\n\nhttps://github.com/sindresorhus/got/issues/200\nhttps://github.com/sindresorhus/got/issues/79. > @gajus What do you think about recommending https://github.com/np-maintain/global-tunnel ? With that module it would work for any request library in the dependency-tree, not just Got.\n\nIt is a good solution, but unless every package author that uses Got also adds global-tunnel, then it isn't useful for the purpose that I have described (enabling HTTP traffic inspection across the entire application). And if every author needs to add global-tunnel as a dependency, then it might as well be a direct dependency of Got.\nAlternatively... Got could check for global.GOT_AGENT variable and default to it if it is configured. This way I could quickly override default agent for all dependencies that use Got.. > global-tunnel is not for package authors. You use it in your app to enable proxy support for everything that uses http.request internally, which is most request libs.\nSorry, assumed the contents of the package based on the name of the package (tunnel being the other one).\nhttps://github.com/np-maintain/global-tunnel looks decent.\n\nThis sounds fragile. What if a Got wrapper expects some special functionality from an agent and stops working when it gets a different agent?\n\nAnything when used in a global space is fragile. Absolutely valid concern.\nYou could of course workaround it by making global.GOT_AGENT a factory function that is called with the version of Got package and returns Agent compatible to that version of Got (similar to how Roarr handles logger registration). I don't recommend this approach though.. In terms of implementing cookie support:\nYou need to construct the initial request with a cookie:\n```js\nconst jar = configuration.jar;\nif (jar) {\n  httpClientConfiguration.headers = {\n    ...httpClientConfiguration.headers,\n    cookie: jar.getCookieStringSync(configuration.url)\n  };\n}\n```\nYou need to handle recording the cookie upon receiving a response:\n(This configuration assumes that you have {throwHttpErrors: false}.)\n```js\nactiveRequest\n  .then((response) => {\n    if (userConfiguration.jar) {\n      const jar = userConfiguration.jar;\n  if (response.headers['set-cookie']) {\n    jar.setCookieSync(response.headers['set-cookie'], response.url);\n  }\n}\n\n});\n```\n... and you need to register cookie upon a redirect:\n```js\nconst activeRequest = got(url, httpClientConfiguration);\nif (userConfiguration.jar) {\n  const jar = userConfiguration.jar;\nactiveRequest.on('redirect', (response, nextConfiguration) => {\n    if (response.headers['set-cookie']) {\n      jar.setCookieSync(response.headers['set-cookie'], response.url);\n  const cookie = jar.getCookieStringSync(nextConfiguration.href);\n\n  if (cookie) {\n    nextConfiguration.headers = {\n      ...nextConfiguration.headers,\n      cookie\n    };\n  }\n}\n\n});\n}\n```\nIt is not a whole lot of code, but everyone implementing this themselves is going to create a whole lot of bugs.. Looks like \"set-cookie\" can be an array.\n```js\nif (response.headers['set-cookie']) {\n  const headers = Array.isArray(response.headers['set-cookie']) ? response.headers['set-cookie'] : [response.headers['set-cookie']];\nfor (const header of headers) {\n    jar.setCookieSync(header, response.url);\n  }\n}\n```. It appears that this behaviour is implemented for 303 response type:\n\nNote that if a 303 is sent by the server in response to any request type (POST, DELETE, etc.), Got will automatically request the resource pointed to in the location header via GET. This is in accordance with the spec.\n\nProblem is that not all services use the appropriate HTTP status code to signal redirect, esp. when it comes to 301/ 302/ 303.. > I believe the current implementation to be RFC compliant and should remain as implemented.\nProblem is that in practise there are a lot of websites that are not compliant with this behaviour.\nEither way, I have solved this by using a wrapper around Got.\nI have raised this as a problem to bring it to the attention of the library maintainers.. Looks like a bug in nock then. @gr2m. > @brandon93s I strongly disagree. We should not add complicated logic just to work around faulty servers. HTTP1 specifies headers as case-insensitive and HTTP2 enforces lowercase headers, so the most future-proof way forward is to lowercase headers. Got has always lowercased headers and it has not been a problem. It was only accidentally left out recently.\nThis is a bummer.\nI have been using got to make HTTP requests in a proxy service.\nThis proxy service interacts with tens of thousands different websites.\nAfter recent Got upgrade, I got reports of many requests failing.\nAfter some digging, it was traced back to Got lower-casing the HTTP request headers.\nI am digging the argument let's keep it simple. However, this literally makes the library unusable for those of us who need to interact with Internet at large, not just select websites that respect the standard, and as our experience shows, there are still websites (some with copyright dates of pre-2000s era) that require headers in a certain way.\nI have published a library that abstracts working with headers in case-insensitive way.\nhttps://github.com/gajus/http-header\nHappy to raise a PR.. Seems like I have already had a comparable issue with \"request\" module:\n\nhttps://github.com/request/request/issues/2091\n\nA post in the same thread (https://github.com/request/request/issues/2091#issuecomment-431913038) suggests that the problem is due to server response including transfer-encoding: chunked and content-length headers, and that the solution (at a request initiator side) is to tolerate this behaviour. This behaviour can be tolerated using a custom HTTP parser:\n```js\nprocess.binding('http_parser').HTTPParser = require('http-parser-js').HTTPParser;\n```\nI doubt if Got can do much about this issue.\nWould be nice to have a test case at least so that we are aware of the issue.. I can confirm that the subject response indeed includes chunked encoding & content length headers.\n```diff\n-< HTTP/1.1 302 Found\n-< cache-control: private\n+< transfer-encoding: chunked\n-< content-type: text/html; charset=utf-8\n-< location: /[..]\n- Server Microsoft-IIS/8.5 is not blacklisted\n-< server: Microsoft-IIS/8.5\n-< x-aspnet-version: 4.0.30319\n- Added cookie AspxAutoDetectCookieSupport=\"1\" for domain [..], path /, expire 0\n-< set-cookie: AspxAutoDetectCookieSupport=1; path=/\n-< x-powered-by: ASP.NET\n-< date: Sat, 27 Oct 2018 10:54:51 GMT\n-< connection: close\n-< x-raygun-version: 4.17.1\n-< x-raygun-request-id: 01CTTJK61183BHG2NN2WJXJA79\n+< content-length: 228\n-< x-rayman-checksum-sha256-hex: 110f5c9149e6c2fd977182943ab2ea5a16a4e913fff4d7539e17539dfaabbc31\n-< x-rayman-cache-hit: false\n-< x-rayman-forward-proxy: [..]\n```. It could use the custom parser, though thats probably excessive.\nEither way, nice to have it documented in the issue thread.\nThe solution is to change the HTTP parser globally.\n```js\nprocess.binding('http_parser').HTTPParser = require('http-parser-js').HTTPParser;\n```. I can confirm that changing the parser fixes the issue.. What is the reason for choosing TS of Flow?. @sindresorhus Do you have an example of a specific error that TS produces that is more developer friendly than what Flow would produce?\nThe other two arguments make sense. OCaml codebase indeed makes it for a steep entry barrier to contribute to the codebase, and TS has gained a lot of popularity over the last 6 months.. That comment is one year old.\nFlow errors improved a lot over the last 12 months.\nNow errors show where the issue originates and walks you through all incompatibilities down the graph.\n\nThis helps a lot with refactoring.\nI am biased of course as I hardly use TS. Flow feels like a second skin.\nEither way, I think that TS is the right choice for Got for the other reasons you have suggested. I was more curious what is driving the decision rather than influencing the decision.. I would throw an error if cookie header is provided and cookieJar is configured.. ",
    "techniq": "@floatdrop Perfect, thanks\n. Hmm, I just tried to add a a through2 transform to my pipeline that just passes data through and I still go no output when using got.stream but works fine with request.  Sorry, I'm just getting into using streams so it might be something simple.\n``` js\nvar MultiStream = require('multistream')\nvar through2 = require('through2')\nvar got = require('got')\nvar request = require('request')\nvar count = 0;\nfunction factory (cb) {\n  if (count > 3) return cb(null, null)\n  count++\n  var stream = got.stream('https://www.random.org/integers/?num='+count+'&min=1&max=6&col=1&base=10&format=plain&rnd=new')\n  // var stream = request('https://www.random.org/integers/?num='+count+'&min=1&max=6&col=1&base=10&format=plain&rnd=new')\nstream.pipe(through2(function (chunk, enc, callback) {\n    this.push(chunk)\n    callback()\n  }))\nsetTimeout(function () {\n    cb(null, stream)\n  }, 100)\n}\nMultiStream(factory).pipe(process.stdout);\n``\n. @floatdrop Thanks, that worked.  It's odd thatrequestworks without setting the stream instance back onto the same variable.  I tested withfs.createReadStreamand it behaves likegot.stream.  Thanks again for your help.\n. I've been struggling to find a way to perform a retry on 5xx errors when usinggot.stream()`.  I tried using something like https://github.com/feross/multistream (which I'm using to stream paginated api calls),  but so far I keep running into issues.\nAny ideas how I could wrap got.stream to retry a set number of attempts and then continue piping if say on the second attempt it was successfully?\nThe api I'm accessing returns 504 gateway timeouts regularly I'm trying to retry against.\n. I ended up coming up with this using highland.js (might be overkill but works)\n``` js\nfunction retryStream(streamFunc, retries) {\n  let resultStream = _((push, next) => {\n    let attempt = 1;\n    retries = retries || 3;\n(function attemptStream() {\n  let stream = streamFunc()\n    .on('error', (err) => {\n      console.log(`Error, attempt (${attempt} of ${retries})`, err);\n      if (attempt < retries) {\n        attempt++;\n        attemptStream();\n      } else {\n        push('Max attempts reached');\n      }\n    })\n    .on('response', () => {\n      // console.log('success');\n      stream.pipe(resultStream);\n    })\n}());\n\n});\nreturn resultStream;\n}\n```\nexample usage (contrived example)\njs\n  streamPageRetry(page, perPage, retries) {\n    return retryStream(() => got.stream('http://localhost'), retries)\n      .pipe(JSONStream.parse('data.*'))\n  }\n. @floatdrop In my case I'm streaming data down and not posting it up (if I'm understanding your comment correctly).  I was needing to retry a GET whenever it returned a 504 (Gateway Time-out) (for example).  Once it's successfully it then pipes it onward (to JSONStream.parse, etc).  What I posted above is working for me.\n. Looks good, thanks\n. ",
    "ajayindfw": "Is there way I can check what URL is it trying to go to so I can test it with our proxy administrators? Where would I be putting a log message to test it.\n. ",
    "jonasfj": "Yeah, passing err as an argument to retries would be nice...\nAlso allowing retries to just return true/false in case someone doesn't want to reimplement the backoff logic.\nIt should be possible to support both true/false and number, as numbers can be treated differently.\n. ",
    "ncuillery": "+1\nSame problem here :fire_engine: \n. ",
    "ThariqS": "also experiencing this\n. ",
    "ewnd9": "+1, I've tried either \ngot(url).then((res) => console.log(res)).catch((err) => console.log(err));\ngot(url).then((res) => console.log(res), (err) => console.log(err));\nPromise returned from got call always stays \"pending\", but I see in developer tools that actual http request was successfully completed. I am using got v5.2.0 bundled with webpack\n. Webpack build is still not working, but problem related to webpack's http polyfill, not got\nsource\n```\n// index.js\nconst http = require('http');\nconst getStream = require('get-stream');\nconst req = http.request({\n  port: 8000,\n  hostname: 'localhost',\n  method: 'GET',\n  path: '/bundle.js'\n}, function(stream) {\n  console.log(stream);\n  getStream(stream).then(s => console.log(s.length))\n                   .catch(err => console.log(err));\n});\nreq.end();\n```\nwebpack 1.12.10\njs\n// webpack.config.js\nmodule.exports = {\n    entry: \"./index.js\",\n    output: {\n        path: __dirname,\n        filename: \"bundle.js\"\n    }\n};\n$ node_modules/.bin/webpack index.js\n\nbrowserify 12.0.2\n$ node_modules/.bin/browserify index.js > bundle.js\n\n. ",
    "sholladay": "I like fetch(), but I haven't seen any higher-level libraries that I like.\nIf someone wants to collaborate on a got-like library for the browser, I'd be interested. In particular, I want:\n - Promise API, caching, redirect following, request cancellation (all easy thanks to fetch())\n - Timeouts\n - Automatic retries\n - Errors with metadata\n - JSON mode\nAnd maybe custom instances (.create(), .extend()). The first order of business is to make sure you are on an up-to-date version of npm, as they decided that engineStrict in package.json was a bad idea and removed support for it. Doesn't look like got was ever using that, though, and Node 7 should come with modern npm anyway. But I would npm install --global npm to update npm and then remove and reinstall your dependencies (e.g. rm -rf node_modules && npm install), just to be safe.\nNow that being said, if you are using the engine-strict config option, which is still supported, or you cannot update npm for some reason, then I think you will find this useful. \ud83d\ude09 \nsh\n$ npm show got@5 engines\ngot@5.0.0 { node: '>=0.10.0' }\ngot@5.1.0 { node: '>=0.10.0' }\ngot@5.2.0 { node: '>=0.10.0' }\ngot@5.2.1 { node: '>=0.10.0' }\ngot@5.3.0 { node: '>=0.10.0' }\ngot@5.3.1 { node: '>=0.10.0' }\ngot@5.3.2 { node: '>=0.10.0' }\ngot@5.4.0 { node: '>=0.10.0' }\ngot@5.4.1 { node: '>=0.10.0' }\ngot@5.4.2 { node: '>=0.10.0' }\ngot@5.5.0 { node: '>=0.10.0' }\ngot@5.5.1 { node: '>=0.10.0' }\ngot@5.6.0 { node: '>=0.10.0' }\ngot@5.7.0 { node: '>=0.10.0 <7' }\ngot@5.7.1 { node: '>=0.10.0 <7' }\nsh\n$ npm show got@6 engines\ngot@6.0.0 { node: '>=4' }\ngot@6.0.1 { node: '>=4' }\ngot@6.0.2 { node: '>=4' }\ngot@6.1.0 { node: '>=4' }\ngot@6.1.1 { node: '>=4' }\ngot@6.1.2 { node: '>=4' }\ngot@6.2.0 { node: '>=4' }\ngot@6.3.0 { node: '>=4' }\ngot@6.5.0 { node: '>=4' }\ngot@6.6.0 { node: '>=4' }\ngot@6.6.1 { node: '>=4' }\ngot@6.6.2 { node: '>=4.5.0' }\ngot@6.6.3 { node: '>=4' }\ngot@6.7.0 { node: '>=4' }\ngot@6.7.1 { node: '>=4' }\nI'll note that got@6 was released well over a year ago, so you should probably upgrade. It basically amounts to changing callbacks to promises (see the release notes).\nIf you have to stay on the very specific combination of Node 7 and got@5 and engine-strict for some reason, then you should probably use ~5.6.0 in your package.json. I'm not sure it will work 100% correctly, but it's worth a try. If you have time, you can go explore the codebase back when it was at https://github.com/sindresorhus/got/commit/fbeab05f5bb56052d1af0b22959e0a6a1a992e6e. Maybe some of the nearby commits or issues from that time period will mention Node 7 incompatibility.. Generally speaking, I like the idea of body being automatically serialized to JSON where possible - smaller API surface and all that. It does limit the user a bit though, by only supporting arrays and objects at the top level. I'm sure that is fine for most REST API calls, but there may be some outliers where people want to send other types of values as JSON. ky's json option makes this easy, because it is an alternative to body. Actually, it's best practice to only send objects at the top level, for security reasons, but I don't know how many people are aware of this.\nIt also makes string bodies feel kind of ambiguous to me. For example, does got(url, { body : 'hello world' }) send a request body of 'hello world' or '\"hello world\"' (the latter being the result of JSON.stringify('hello world'))? I could imagine this tripping some people up, no matter which one we actually do. The semantics are a bit blurry unless you study the docs.\nI guess overall I'm +0.5 on removing the json option. \ud83d\udc4d \nI think promise.json() should only return the JSON, not the response. I almost never need the response when the response is 200 OK, I generally only need it when an error occurs. One thing that got does, which I think it awesome, and which we don't have in ky, is setting the accept header when .json() is called.\nThe responseType option is a bit more peculiar to me. While I can see the benefit for someone who does need the response in addition to the JSON (or Buffer or whatever), I really don't think it's that common, and where it is needed, there may be better solutions. For example, the main case I can think of is pagination that requires reading response headers. But pagination should probably be solved with async iterators (as Sindre mentioned here) or other means. And imitating .json() manually in userland is pretty trivial if someone really needs it for some edge case.. > Oh, believe me, it's very common.\nWhat do people need both the Response and the JSON for, on a successful response, other than pagination?. A client should generally keep making requests as normal until it receives a 429 Too Many Requests, which is of course an error response, and error.response ought to be provided, for sure.\nI don't find pre-emptive, client-side rate limiting based on successful API responses to be very useful. The client inherently has no way to know the state of rate limiting until it makes a request anyway. The response details about rate limiting are completely non-standardized and different providers handle it differently. And then even if you normalize the response details and keep track of them across requests, the data can get stale because you have no way of knowing whether there are other clients in use that are affecting the rate limit.\nMaybe it's still worth it. I'm just skeptical.. But is it worth having responseType to make bots a little easier to write by, say, 4 or 5 lines of code? FWIW, any API that bans on or before the first 429 response is a terrible API.. Sure, maybe. If you want to keep responseType, I would still have got(url, { responseType : 'json' }) return the Response and got(url).json() return the parsed object. In other words, responseType is about semantics of the request and response, whereas .json() and friends are additional sugar for getting the response body itself. I would strongly prefer not to return the whole Response from .json().. got automatically follows redirects:\nhttps://github.com/sindresorhus/got#followredirect\nYou don't have to write any code to make it do this. Just point got at a URL and it will make another request to the location before returning the result. If got is throwing, the final destination URL may be responding with an error code - it's not because of the redirect.\nI also want to point out that this code is useless:\njs\ncatch (error) {\n    throw error\n}\nYou should remove the try / catch.. Should this be a public option?\nWould there be any reason for a user to set this to true instead of using one of the shortcut methods?. ",
    "jleaders": "Could someone point me to these fetch-based libs that are as beautiful and simple to use as got()? I don't want to have to be dealing with ReaderStream Uint16 Arrayss when getting a simple response body text.. ",
    "kevinsimper": "@floatdrop Try to create a new requestbin, it does not work\n\n. Try to create a new requestbin :)\n. ",
    "sheakelly": "```\nvar https = require('https');\nvar request = function(opts) {\n  console.log('hostname: ' + opts.hostname);\n  console.log('path: ' + opts.path);\n  var req = https.request(opts, function(res) {\n    console.log('res.statusCode: ' + res.statusCode);\n    console.log('res.headers.location: ' + res.headers.location);\n  });\nreq.end();\nreq.on('error', function(e) {\n    console.error(e);\n  });\n};\nvar opts = {\n  hostname: 'raw.github.com',\n  path: '/imagemin/pngquant-bin/v3.0.0/vendor/win/pngquant.exe',\n  method: 'GET'\n};\nrequest(opts);\n```\nWhen you run the example code above the console output is as follows:\nhostname: raw.github.com\npath: /imagemin/pngquant-bin/v3.0.0/vendor/win/pngquant.exe\nres.statusCode: 301\nres.headers.location: https://raw.githubusercontent.com/imagemin/pngquant-bin/v3.0.0/vendor/win/pngquant.exe\nThis is showing that despite using the 'https' library a non-secure request is sent and github is redirecting to ssl. So I think you need to set the port to 443 explicitly\n. That is exactly the problem. The code is attempting to make a https request by using the 'https' library. But the request is sent outbound as a non-secure http request because the port is not set as 443. The result is a 301 redirect to the secure version of the url. \nIn your module you are using the following code to select whether or not to make a secure or non-secure http request. Looks like you will always be making a non-secure request.\nvar fn = opts.protocol === 'https:' ? https : http;\nThat might be ok in some cases however the issue I am experiencing is that when the request is via a squid proxy using a http agent. The 'got' module issues a http request over a https secure tunnel. This confuses the squid proxy. \nThere are a few npm packages involved in this issue so I am a bit unsure which package should be patched. The dependency chain is:  imagemin/pngquant-bin -> kevva/download -> sindresorhus/got. The http agent is setup via the kevva/caw package the uses mikeal/tunnel-agent to create the tunnelling socket when the proxy is configured.\n. I have tested with the latest version or(download)https://github.com/kevva/download and gettting the same issue. Still getting a request on port 80.\nTCP_TUNNEL/200 0 CONNECT raw.github.com:80\nI understand that the docs say the port defaults to 443 however if you run the code in my second comment you will get a redirect response from github. i.e. even though you are using the 'https' library you are making a non-secure request. Do you think this is a bug with nodejs? Should log it there?\n. Unfortunately the url is not under my control. But my code above is reproducing the issue. The problem is also not specific to a proxy configuration. Without a proxy agent configured 'https' lib will request over port 80 and github redirects to port 443.The redirect if followed perfectly by your library hiding the problem however when I use a squid proxy the request just hangs. I acknowledge that the documentation says it should default to 443. Just does not appear to behave that way. I will raise an issue with the nodejs team. Thanks for your help and responding quickly to my issue. I will let you know if I find out any more details.\n. ",
    "marc-guenther": "which has just been released as 0.4.2 :)\n. ",
    "SamVerschueren": "Thnx for the merge :) \n. Can you provide an URL that's not working?\n. Can reproduce on node 5.1.1. It does not occur on 4.2.1.\nMore information for the core team\nexample\n``` js\n'use strict';\nconst got = require('got');\ngot.head('http://google.com').catch(err => {\n    console.error(err);\n    //=> ReadError: unexpected end of file\n});\n```\nerror stack\nReadError: unexpected end of file\n    at Unzip.<anonymous> (/Users/sam/Projects/playground/got/node_modules/got/index.js:97:8)\n    at Unzip.g (events.js:260:16)\n    at emitOne (events.js:82:20)\n    at Unzip.emit (events.js:169:7)\n    at Zlib._handle.onerror (zlib.js:366:10)\n. Create a spdy-got wrapper module that sets the agent for you? Little bit like gh-got.\n. But then it should be possible to set json to false in order to not parse it, even if the Content-Type is application/json. With the current implementation, that is not possible.\n. If opts.json is false but the content type is application/json, the statement still resolves to true.\n. Upgrade your node version.\n. Mmmh, then it's not the node version. Promises where added since 0.12. \nWhat version of got are you using?\n. Or submit them to DefinitelyTyped.\n. Why isn't that correct? A timeout is per individual call.\nLet's say I have an endpoint and I set the timeout to 10 seconds. With this PR, this means that my retry count is set to 0 and will stop executing if the first call fails due to a network error. timeout and retries or 2 separate settings, I don't believe there is a link between those two.\n. It's just basic query string and headers stuff, no?\n. I'm playing with this in my head since the issue was created. So what I personally think would be nice is that got only throws a ParseError if the status code indicates success 2xx and the body is not json.\njs\ntry {\n    return JSON.parse(response);\n} catch (err) {\n    throw new ParseError(err);\n}\nIn all the other cases, if an error status code is returned like 4xx or 5xx, it should try to parse the response (if json is set to true), if it fails to parse the response, it should throw an HttpError with the unparsed body.\njs\ntry {\n    throw new HttpError(statusCode, JSON.parse(response));\n} catch (err) {\n    throw new HttpError(statusCode, response);\n}. Yes, I think that a lot of APIs just return a \"descriptive\" error message when something goes wrong instead of returning a JSON object with that error message.\nIf everything is ok (status 2xx) and the developer sets json to true, that means he expects JSON and if not, we can safely throw a ParseError because it's not JSON.\nIn all the other cases we should try to parse but if that fails it means the body is not parseable and is most likely a string error message. If you throw a ParseError here, it's not clear that actually what happened was an HttpError but the body is not parseable which actually hides what really happened imo.. Remove spaces inside the object {url, method: 'GET'}\n. In that case, I tend to write things like this:\njs\nhash_function: (base_string, key) => crypto\n    .createHmac('sha1', key)\n    .update(base_string)\n    .digest('base64')\n. Just generally interested what the benefit is of wrapping this in a Number object?. Why is percent set to 1? Probably missing something here :).\nI'm also wondering why it is emitted? If some wants to calculate the percentage, he can easily do transferred / total. I would rather not have it emitted, but that might just be me :).. 1024 bytes send against 10240 in total means 10% and thus percent should be 0.1.. Is percent emitted because total can be null when streaming?. Any benefit over parseInt? I never used Number directly so that's why I'm asking :).. ",
    "stevemao": "The types were wrong. body's type is string and it's an instance of String.\n. ",
    "jenslind": "This for example:\nhttps://github.com/sindresorhus/got/releases/latest\nBut tested with random url's like google.com and it didn't work.\nAlso forgot to mention I'm using got.head.\nhttps://github.com/jenslind/electron-gh-releases/issues/13\n. ",
    "just-boris": "Now it work as expected, thanks!\n. Do you make a release for 5.x branch?\n. ",
    "sergeyt": "@floatdrop so I can use just tunnel package to simulate proxy behavior, right?\n. @floatdrop thanks for answers!\n. ",
    "mrgodhani": "I just figure out that it was due to retries. By default it retries 5 times. So I had to explicitly make to 0.\n. ",
    "joshy": "I can send it with json=false option. Closing this issue. Sorry.\n. ",
    "tgandrews": "Sorry, I should have read the issue properly.\nI will move it. I guess you would rather have it replace http/https?\nProbably will make it easier from my PoV as well.\nOn Wed, 20 Jan 2016 at 10:59, Sindre Sorhus notifications@github.com\nwrote:\n\nFrom that issue:\nI would prefer for the solution to be an external module got can just\ndepend on as I don't want to have to maintain it. Maybe\nhttps://github.com/mikeal/tunnel-agent.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/sindresorhus/got/pull/159#issuecomment-173171282.\n. Closing as will create a new one referencing a new npm lib.\n. I have a branch with this working. No tests yet. I will push on Monday once\nI have some tests working.\nOn Sat, 23 Jan 2016 at 16:45, Steven Vachon notifications@github.com\nwrote:\nhttps://github.com/TooTallNate/node-proxy-agent ?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/sindresorhus/got/pull/159#issuecomment-174199158.\n. @alexsantos I'll try and dig out the branch. I had a bit of down time in a new job (with big company network setup) but have not looked at this for a while.\n. @sindresorhus @alexsantos  My branch was using proxy-agent as well. I guess we need to support just HTTP and HTTPS proxies? If we are doing the whole whack then I doubt we are going to do better than node-proxy-agent\n. OK, I guess there are two options:\n1. Fork node-proxy-agent and remove PAC support.\n2. Work on node-pac-proxy-agent and reduce the external dependencies to make it smaller. Then node-proxy-agent can be taken wholesale with PAC support.\n\nAnd @alexsantos is looking(?) into number 1, so I'll have a look at number 2 then if I get some free time.\n. @alexsantos Let me know if there is anything I can do to help.\n. ",
    "alexsantos": "@tgandrews , I've seen your branch but what I miss is a way where got uses proxies in a transparent way, without passing a opts.proxy value. This follows the need for proxies when using tools like npm-name, generator-node, etc... I've did some work on https://github.com/sindresorhus/got/issues/178 following the approach from request but @sindresorhus pointed out how wrong it could get :-1: \n. @tgandrews and @sindresorhus , I have another branch which I think is the minimalist solution for this. It depends on proxy-from-env and proxy-agent modules. Can you have a look here? https://github.com/alexsantos/got/tree/proxy-from-env/index.js\nBasically, it's 6 lines of code...\njavascript\nif (!opts.agent) {\n  const proxy = getProxyForUrl(url);\n  if (proxy) {\n    opts.agent = new ProxyAgent(proxy);\n  }\n}\nI could have done a PR but didn't want to bug Sindre again :-)\n. @floatdrop , just to back @sindresorhus message, I came here because I want to use yeoman generators at work and I can't because of the lack of proxy support on got.\n. @tgandrews The size of node-proxy-agent is derived from the fact that it supports PAC and that module specfically needs degenerator/esprima which is a huge dependency. If we abandon PAC then it gets pretty small. I've been doing some work on that module so I'll might drop PAC and fork it to a smaller one.\n. @tgandrews , I already have a stripped version of node-pac-resolver (now with Promises) that gets rid of regenerator. https://github.com/alexsantos/node-pac-resolver/tree/nodev4-compat\nForking the whole node-proxy-agent would also bring this modules to got standards, like v4, xo, nyc, etc...\n. @stevenvachon , node-proxy-agent has pac-proxy support, which is a huge dependency for got. \n. Hi @sindresorhus , I have to agree on that (about the way request is doing it) :+1: \nI'll move this to an individual module.\n. ",
    "luanmuniz": "You are right. So sorry for not notice that before\n. @floatdrop Its only a few more variables. In this PR at least, its not the http request itself.\nDoesn't Node need to keep body in memory until i use it anyway? Add a few more variables should not be a problem. Can you explain better how adding those properties can cause a problem, or give me a few directions do i can search and study this better?\nbtw: thanks for the suggestion, i will implement it! i always forget map :(\n. @sindresorhus This is the opts object:\n{ protocol: 'http:',\n  path: '/',\n  retries: [Function: backoff],\n  slashes: true,\n  auth: null,\n  host: 'luanmuniz.com.br',\n  port: null,\n  hostname: 'site.com',\n  hash: null,\n  search: null,\n  query: null,\n  pathname: '/',\n  href: 'http://site.com/',\n  headers:\n   { 'user-agent': 'got/6.2.0 (https://github.com/sindresorhus/got)',\n     'accept-encoding': 'gzip,deflate' },\n  method: 'GET' }\nmaybe href, method and headers? The rest we can build with something like urlparser form the href.\nWhat the name of the variables should be? Just say the word and i'll update the PR\n. @floatdrop good question. I think the original request since it was the request that was made.\nWhat do you think about it?\n. I couldn't update this because the repository doesn't exist anymore. The updated PR is in #205\nSorry about that.\nWe should close this PR e continue in #205\n. On it\n. @sindresorhus Its fixed, but i'm having a small problem if compatibility.\nI found 2 ways to fix this:\nnew Buffer(res.headers.location, 'binary').toString()\nand\nBuffer.from(res.headers.location, 'binary').toString()\nWhile the first one is deprecated in v6 the second doesn't exist in v4 and since the tests check for 4, 5 and 6 i don't know how it should be.\nObs.: It's working with the first option\nObs2.: Don't merge it yet, i will write tests for this case\n. @sindresorhus Done. Ready to merge\nJust one thing. I tried to add the following test:\n``\nhttp.on('/redirect-with-utf8', (req, res) => {\n    res.writeHead(302, {\n        location:${http.url}/utf8-url-\u00e1\u00e9`\n    });\n    res.end();\n});\ntest('redirect response contains utf8', async t => {\n    t.is((await got(${http.url}/redirect-with-utf8)).body, 'reached');\n});\n```\nBut than the retry -> works on timeout errordon't pass.\nAny idea what it can be?\n. @sindresorhus Anything else to do here?\n. This is just a trailing space\n. I think its done. Can you check if what i did is what you ask for?\n. No, when sending an object we don't have opts.href and urlLib.format(opts) don't return the opts.path in it. I just put the opts.href because if it exist we don't need to send to the functions. But it is removable.\n. I just added a <br> like in the other lines\n. ",
    "ksladkov": "@floatdrop thank you, it makes sense. But we need to wait the response no longer than some fixed time and abort when time is over. Sure, it is not a problem to use some external function for this, but is exists any way to get such behavior with got? If not, I think, the documentation for the timeout option should be fixed a bit to remove ambiguity.\n. ",
    "SEAPUNK": "...but say that you do want a timeout for end-of-response, what would you suggest?\n. Alright, thanks!\n. Is there a way to abort a got request mid-way on given timeout? There could be an instance where a keep-alive connection never finishes sending the response body (even if it's very rare).\n. Okay, thank you!\n. ",
    "a-x-": "hm, i forgot write here about this: got(uri, { method: 'head' })\n. thank you! ^_^\n. ",
    "ruyadorno": "hi @floatdrop!\nI understand your reasoning, I have thought the same thing and as a matter of fact I actually reimplemented three times the same micro-service to try different approaches but got was the clear winner for me.\nThe reason being that I actually want to fetch all the data from the server, parse it, modify and send it back to the user - got abstracts a lot of the hard work from that, such as gzipping on prod but not on local development, not to say the beautiful API it provides.\nThat said, I really don't mean to make any pressure, please take time to evaluate if this is a constructive addition to other users/use cases and feel free to close the PR if that's not the case :blush: \n:+1: thanks again!\n. rebased\n. @RoobinGood that's a good point, I'm not really sure of anything :blush: \nIt does make sense in the context of the original use case behind this idea, as described in #165 but at the end of the day I just want to access the original redirect HTTP response in case of a 300 error, I guess that could also be achieved by attaching the response to the thrown got.HTTPError object but then I'm even less sure that's a better option.\nIt's also worth noting that we're talking about an optional configuration, it won't change the way got behaves if you don't use the followRedirect config property.\n. \ud83d\udc4d sure, it was a good point brought to the discussion by @RoobinGood but I still think the current implementation is better \ud83d\ude0a we're getting more people interested in having this option... let's merge this \n. ",
    "dfilatov": "+1 to add this feature. I have some cases when I have to parse location of redirect.\n. @floatdrop Thanks!\n. ",
    "knksmith57": "+1\n. /cc @jstewmon in case you wanted to take a pass at this. @ewolfe thanks for taking a look! Super glad you find the feature useful.\nre simplified interface: I would love to get there with got and have a few ideas on how to support that sort of functionality without polluting the public API-- @jstewmon's suggestion to support something like baseUrl is definitely one way to do it.\nFor what it's worth, everything from your example snippet except the URI prefixing is made possible by this feature (protocol + hostname + default headers).\nIf there's interest, I'd be happy to put together a proposal PR. Thanks again for taking a look!. how do y'all feel about this @sindresorhus / @lukechilds / @brandon93s?. the global defaults are inherited as the top-level got export dogfoods this interface and all public create() calls operate off of that instance (or a descendant of it):\njs\nconst got = create(defaults);  // L43. heads up that, unless I'm missing something, this should be covered by the preserve global defaults test case in test/create.js starting on line 18. ",
    "RoobinGood": "@ruyadorno are you sure that making redirect a successful result for request is a good idea? As far as I know it is not usual behavior.\n. @sindresorhus I've just need this options in my tests on work project to check if the resource is reachable for user. If resource is not reachable server redirects user, so I need followRedirect is false to check status and location.\nAlso this options is represented in request. Previously I used request for testing, but got is lightly and easier. However I need some compatibility with request.\n. ",
    "gunta": "Support for it can be detected with this: https://github.com/stefanjudis/is-http2\n. That's nice to know :)\n. It should, but it seems that is going to take time since there are too many arguing for it/against it.\nThe try/catch solution or perhaps adding spdy as an optional dependency should be a good solution meanwhile.\n. ",
    "pietermees": "Seems like this is going to merge soon: https://github.com/nodejs/node/pull/14239. I was wondering if there was any update on this now that it has made its way into Node 8?. @szmarczak my understanding is that it doesn't yet support connection reuse like you would do with an agent, correct? Persistent connections are an important capability for performance reasons. Is there any plan to add support for that?. @szmarczak right, I guess my point was that there is a need for an equivalent helper like Agent to manage ClientHttp2Sessions :)\nWith http/https 1.1 this is transparently handled for you simply by passing in the right agent option.\nThis component would have a few responsibilities:\n- Establishing a new connection when none is available or max concurrent streams has been reached on the existing one\n- Detecting connection failures and re-establishing a new session when needed\n- Probably expose both an Agent interface for h1 and a ClientHttp2SessionManager for h2 so that it can be used transparently and handle ALPN for you. It can then establish a connection, figure out through ALPN what the remote host supports, add the connection to that connection pool, and remember this for subsequent requests.. @szmarczak https://github.com/szmarczak/http2-wrapper/issues/6. @szmarczak @sindresorhus if we would like to use https://github.com/zentrick/alpn-agent to negotiate h2 vs https with ALPN, we'd need to make a modification to got so the request extend function doesn't need to synchronously return a response object. We only know what response object we want to use (http2 or https) once ALPN negotiation completes.\nAny objections or concerns about making that change?. @szmarczak awesome! I still have a test on my todo list, will let you know ;). @szmarczak I still feel like haven\u2019t solved the connection caching and reuse question well. As far as I can tell we\u2019ll still establish a new Socket for every request. I\u2019ve tried to address this in alpn-agent and I\u2019ll try to splice that into the example in the next couple of days.. Per the continued discussion on that thread, I think there's enough in place to provide a solution today, without changes to Node. But I'll try to prove that out with an example :). @szmarczak I've created a demo using got with @zentrick/alpn-agent and http2-wrapper here.\nSeems to work great!\nYou can see debug output by running the script with DEBUG=alpn-agent* env var. You'll see how it caches TLS sessions, reuses connections, and deals transparently with h1 and h2.. That would be 7.1.0 and Promise mode\nOn Sat, Aug 5, 2017 at 7:43 AM Sindre Sorhus notifications@github.com\nwrote:\n\nWhat exact version of Got do you have installed and how are you using it\n(Promise API or Streaming)?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/sindresorhus/got/issues/353#issuecomment-320439094,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AG3lJXs6no_dGb3T8aiwuFB5XcZ7DfFwks5sVFVSgaJpZM4OuIJB\n.\n. When I update to the latest commit on master and run my test suite, the process never exits and I'm getting a (node:56384) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 connect listeners added. Use emitter.setMaxListeners() to increase limit warning.\n\nCould it be that some sort of memory leak was introduce in the master codebase since 7.1.0?. Yeah, I've noticed ;)\nAlthough in this case it does seem to correlate with a bigger issue of my\nprocess not exiting. No other errors or warnings though.\nOn Mon, Aug 7, 2017 at 5:05 PM Sindre Sorhus notifications@github.com\nwrote:\n\nNot sure. Usually, that warning is just an annoying false positive though.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/sindresorhus/got/issues/353#issuecomment-320780467,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AG3lJUuFpEQAAEe30YYrTWQXDZ4JMgvkks5sV3wpgaJpZM4OuIJB\n.\n. I've been able to replicate this in my load tests. It seems that more and more listeners are added somewhere in the code and not cleaned up. Could it be that if a request fails some listeners are not removed?\n\nCould this be somehow related to me using agentkeepalive to reuse sockets? Others might not be running into this if sockets are not being reused for thousands of requests?. @petitchevalroux seems like @timdp opened up a new issue for the memory leak\nI'll close this issue. @paambaati unfortunately that doesn't cover all our requirements. Not sure why the cancel tests fail on Node 6, but that seems to be a general problem that randomly occurred before?. @sindresorhus updated in response to your review. Rebased & tests seem to be passing now. @sindresorhus added test case, I think this might actually be the first test coverage for the agent option. @sindresorhus I think this is ready for review, as usual the tests seem to fail randomly on the cancelation though. @brandon93s this PR also changes the default value from gzip,deflate to gzip, deflate. At first I thought the space was required, but it seems that's only specified as such in the Fetch API (see https://fetch.spec.whatwg.org/#concept-header-value-combined) while the HTTP spec says that a simple , is fine. I thought it might make sense to align closer to fetch moving forward?. @jstewmon thanks for the suggestion, we can definitely do that as a workaround, but still it's a bit strange that the library insists on rewriting a URL we're passing in as a string. Why can't our requested URL be fired as provided? I can't imagine any need for the library to assume the path has a standard format and would need to inspect anything in it?\n@sindresorhus sure thing! Here's an example:\nhttps://www.someserver.com/my/path?query=abc&test=def&final=https://www.somethingelse.com/?extra=extra. Indeed, components further down the URL are less restrictive in terms of allowed characters, so once you've passed the first ? for example, you may use it again without issue.\nYou're right that an & would cause the final URL to be split in the search params, which is not exactly the semantic meaning of the API:\njs\nnew URL('https://www.someserver.com/my/path?query=abc&test=def&final=https://www.somethingelse.com/?extra=extra&bla=xyz')\nreturns:\nURL {\n  href:\n   'https://www.someserver.com/my/path?query=abc&test=def&final=https://www.somethingelse.com/?extra=extra&bla=xyz',\n  origin: 'https://www.someserver.com',\n  protocol: 'https:',\n  username: '',\n  password: '',\n  host: 'www.someserver.com',\n  hostname: 'www.someserver.com',\n  port: '',\n  pathname: '/my/path',\n  search:\n   '?query=abc&test=def&final=https://www.somethingelse.com/?extra=extra&bla=xyz',\n  searchParams:\n   URLSearchParams {\n  'query' => 'abc',\n  'test' => 'def',\n  'final' => 'https://www.somethingelse.com/?extra=extra',\n  'bla' => 'xyz' },\n  hash: '' }\nWhile\njs\nnew URL('https://www.someserver.com/my/path?query=abc&test=def&final=https://www.somethingelse.com/?extra=extra&bla=xyz').toString()\ncorrectly serializes the URL back to\nhttps://www.someserver.com/my/path?query=abc&test=def&final=https://www.somethingelse.com/?extra=extra&bla=xyz\nHowever\njs\nnew URL('https://www.someserver.com/my/path?query=abc&test=def&final=https://www.somethingelse.com/?extra=extra&bla=xyz').searchParams.toString()\nresults in\nquery=abc&test=def&final=https%3A%2F%2Fwww.somethingelse.com%2F%3Fextra%3Dextra&bla=xyz\nSo got's logic results in:\njs\nconst url = new URL('https://www.someserver.com/my/path?query=abc&test=def&final=https://www.somethingelse.com/?extra=extra&bla=xyz')\nurl.search = url.searchParams.toString()\nwhich will return the following when you do url.toString():\nhttps://www.someserver.com/my/path?query=abc&test=def&final=https%3A%2F%2Fwww.somethingelse.com%2F%3Fextra%3Dextra&bla=xyz\nConclusion:\nI'm not sure what the reason was for parsing the search string and then re-serializing it, but I don't think this is necessary.\n1. I don't think there's a need for got to actually read the parsed search params. The faulty assumption here is that a URL has to be formatted this way, it does not.\n2. I don't think got should re-serialize the path string like it does now. This process causes URLs to change in unintended ways and it's not clear what the benefit is of doing so.. Wouldn't it make sense to simply accept a lookup function like the Node APIs do? Then you can use one of the existing DNS cache implementations like redns?. @morozRed sorry, I should have been clearer. I meant to ask why DNS caching should be part of got rather than an external thing you can plug in.\nThe reason why I ask is that Node APIs already allow overriding DNS lookups on TCP/HTTP/HTTPS/H2 connects by providing a custom lookup function. Existing packages like redns and other leverage that to provide DNS caching capabilities similar to what you're trying to implement here.\nMy main point is that adding a lookup option to got similar to the lookup option in socket.connect. That would allow you to easily plug in any of the existing DNS cache packages.. Having played around with some of the DNS cache implementations that are around, I think you'll find that you can't easily provide a default DNS cache that is fully transparant (i.e. handles DNS exactly the same way as the system would).\nAs you've indicated you have to use the dns.resolve API which behaves differently than getaddrinfo. This impacts /etc/hosts but also IPv6 vs IPv4 preferences etc.\nWith that in mind, I don't think it's possible to provide an implementation that's enabled by default and does not change semantics for all got users.\nHence my suggestion to use the lookup option (I didn't know that already worked, thanks!).\n1. It's already available\n2. You can use an existing DNS cache package without having to write anything\n3. If it can't be enabled by default, you'd have to provide an option to activate it anyway, so it's the same amount of work as just providing a custom lookup function. @brandon93s I think the confusion is the use of == null, which actually returns true if the value is undefined (note the == rather than ===). That should result in the line being reachable and executing as expected.\nIn our internal code style policies this is the idiomatic way of doing such checks, but if you prefer another code style using is.undefined, hasOwnProperty or the || approach I'm happy to do either one :). And I see the test error is actually a code style error where it's instructing not to use == null, so I guess I just answered my own question ;). ",
    "hisco": "I've created an http2-client that completely mimcs the http / https native modules while supporting http2.\nIt was very easy to integrate it with this module (and a few others) : \nhttp2-got - I literally created this integration module today.\nHowever, it has very few lines of code, all it's behavior comes from :  http2-client , got\nHope it somehow helps...\n. Forgot to say, it's obviously negotiates with the server the correct protocol (ALPN) to choose, https vs http2.\nI would be happy to contribute in any way I can.\n. I actually learned on @szmarczak effort a few minutes ago.\n@szmarczak It's a very impressive http2 / https compatible implementation - if you would like to compare note or join forces let me know \ud83d\ude04  .\nFrom a very quick look on this source code https://github.com/szmarczak/http2-wrapper I think that it doesn't handle the http2 vs https negotiation.\nTherefore, While the two might seem to have the same purpose, the http2-client module have an additional purpose to make the decision of which protocol to use transparent to the user and based on server compatibility.\nYes, that's the kind of integration I made, got is a very easy module to extend =)\nThanks!. @szmarczak You are correct =) , my mistake.\nHowever, I do think that ALPN https1 vs https1.1 is negotiated by core modules.\nTherefore, I totally agree it cannot actually mimc... I meant to say mimic the interface, while I'm sure there are some differences.\n. @szmarczak If a server supports only H1.1 / H2 I afraid that it will require the client to make changes in his code.\nI think that the following should be the analogy:\nShould a client code differently to make an https request to https1.1 server vs https1 server.\nAs such I hope clients shouldn't distinguish between http2 vs http1.1 - only when using compatibility mode of course...\n. ",
    "Autarc": "Sure it shouldn't replace the existing option but just extend it for convenience. If someone expects the response of a request to be JSON because its mentioned in a documentation, it shouldn't be necessary to manually set it as the server already provides the hint.\n. ",
    "avyaznikov": "RFC 2616 Section 14.43 defines the syntax for the User-Agent header as:\nUser-Agent     = \"User-Agent\" \":\" 1*( product | comment )\nwhereby\nproduct = token [\"/\" product-version]\nproduct-version = token\ntoken = 1*<any CHAR except CTLs or separators>\nseparators = \"(\" | \")\" | \"<\" | \">\" | \"@\"\n                  | \",\" | \";\" | \":\" | \"\\\" | <\">\n                  | \"/\" | \"[\" | \"]\" | \"?\" | \"=\"\n                  | \"{\" | \"}\" | SP | HT\nCTL = <any US-ASCII control character (octets 0 - 31) and DEL (127)>\ncomment = \"(\" *( ctext | quoted-pair | comment ) \")\"\nctext = <any TEXT excluding \"(\" and \")\">\nTEXT = <any OCTET except CTLs, but including LWS>\nquoted-pair = \"\\\" CHAR\nCHAR = <any US-ASCII character (octets 0 - 127)>\nSo @ characters are only allows in comments\n. Oh, semicolon after https is not a valid, because it's a separator.\nIf you want to have a link to github project, comment - is a best place. For example: \nsindresorhus-got/6.6.1 (https://github.com/sindresorhus/got)\n. ",
    "birhoff": "PR for new user-agent: https://github.com/sindresorhus/got/pull/171\n. this is not that one? https://github.com/sindresorhus/got/pull/171/files#diff-0730bb7c2e8f9ea2438b52e419dd86c9R269\n. :up: \n. ",
    "dsblv": "@floatdrop thanks.\nIt was a good idea to add an example to readme. :+1: Too bad it wasn't there when I visited last time.\nClosing.\n. ",
    "spencerhakim": "It would be a major change, but not necessarily a bad one. At least having the option to enable it would be nice. Like, if json is an object instead of just true seems like a reasonable compromise.\nEdit - Tagging @sindresorhus, since it's his project\n. Current way:\n``` js\nvar options = {\n  json: true, // if truthy, parse response as JSON\n  headers: {\n    'Content-type': 'application/json'\n  },\n  body: JSON.stringify({ // have to manually stringify object in body\n    name: 'whatever',\n    category: 'toy',\n    description: 'Hello World'\n  })\n};\ngot.post(http://example.com/api/createThing, options)\n  .then((resp) => {\n    // ...\n  });\n```\nPossible new way (should be functionally equivalent to the above):\n``` js\nvar options = {\n  json: { // typeof json === 'object', not 'boolean', so send body as JSON instead of form-encoded\n    name: 'whatever',\n    category: 'toy',\n    description: 'Hello World'\n  }\n};\ngot.post(http://example.com/api/createThing, options)\n  .then((resp) => {\n    // ...\n  });\n```\nComing from request, I was surprised that got didn't follow the same semantics for handling JSON or offer any way of automatically serializing sent objects as JSON. This approach should be backwards compatible with current usage, so I don't think it requires a major version bump.\n. Yes, but that approach would likely require a major version bump.\n. ",
    "bishtawi": "@sindresorhus What about making the json attribute an object that takes req and res as keys. Setting req to true means the request body should be JSON encoded, setting res to true means the response body should be JSON parsed.\nThe current json attribute being a boolean could be deprecated but not removed till the next major rev bump. Setting json to true would be translated to { req: false, res: true}. Omitting the json attribute or setting it to false would translate to { req: false, res: false}. This would keep backwards compatibility while easily supporting a way to JSON encode the request body.\nvar options = {\n  json: {\n    req: true,\n    res: true\n  },\n  body: {\n    name: 'whatever',\n    category: 'toy',\n    description: 'Hello World'\n  }\n};\nThe above example would JSON encode/decode the request/response body.\n. ",
    "bisubus": "@sindresorhus The flexibility seems to be appropriate in this case. Switched to got from superagent recently. The latter has got 3 different methods (type, accept, parse) for setting serialization type, accept header and forced parsing.\n. @floatdrop I feel sorry for your long comment, the short one seems fine too.\nThanks for the reference, good to know. Cancelable promises seem to be a long run, what about Bluebird cancellation at this moment? It is quite conventional in Node land and nonintrusive (third optional argument in promise constructor). The promise magically gets cancel method.\nThis does not solve the other part, hooks. The promise still has to be augmented with additional methods (on?) in this case.\nA good example is superagent, it went the opposite direction. It returns an augmented, thenable stream. Which may be inconvenient, too, because it should be converted to a real promise any way.\n. @AlexTes Thanks for the up, I'm happy that there's cancelling at last. Yes, I still have use case I've described in the OP. Streams are must have for big things, but I never actually needed streaming in Got to decrease RAM footprint, all data is small enough to be efficiently handled with promises. \nSure, I can use stream if I need to get info on redirects with redirect hook (and I need it). But what's the point to use Got at all if this results in usual EE mess instead of neat promise async/await flow control? At this point http can be used directly and parsed with JSON.stringify. Considering that it is supposed to be A nicer interface to the built-in http module, I don't think that there's something 'nice' in a situation like that.\nFor my case I ended up with customized 'convenience wrapper' over another 'convenience wrapper'. And I'm feeling that the library could cover more use cases without adding more complexity. Considering that Got is promise-first and it already uses streams under the hood, it would make sense to just expose used event emitter on the promise, as stream prop or toStream method... case solved.. @floatdrop Why to not just get own enumerable properties from the object in this case? As for the example above, the workaround should be Object.assign({}, querystring.parse(query)), it doesn't add much clarity.\nI'm quite sure (don't have this piece of code at hand at this moment) that this was done because got.post(url, { data: query }) makes a text/plain request and not application/x-www-form-urlencoded, not a very good thing for POST request (maybe a subject for another issue?)\n. @floatdrop \nSure, will do this. I see that is-obj allows functions. Wouldn't it be better to stick to util.isObject instead?\n. @sindresorhus That's correct. This requires this spec to be fixed but otherwise it looks fine. Function type shouldn't be reserved for future use as callbacks here, should it?\n. @sindresorhus My guess that the code cannot gain much from is-obj dependency then, right?\n. @sindresorhus Sure thing, I'll get down to this PR a bit later.\n. @sindresorhus Added a couple of tests to match an object that can be passed as a body, since it is no longer validated by is-plain-obj.\n. @yeze322 Yes, it looks like there was a regression in #297. A quick fix is Object.assign({}, obj).. @sindresorhus I've just checked it, and it seems that it was changed in Node 8, querystring.parse('x') directly inherits from null. isPlainObj(querystring.parse('x')) should be false in lower Node versions. This is the point where the problem becomes sinister. It's a very good thing that this issue came up before I've updated Got to 7 in the project where I actually had this case, I'd rack my brains trying to figure out why it works in one environment and throws up in another.\nI'm sure this is edge case. And I think it's very illustrative of why it's may be not the best idea idea to provide breaking changes just because we can. I'm not the only user of Got, and there can be infinite amount of edge cases - I was notified of it by another user.\nPeople have to resort to Object.assign({}, obj) hack here, and it smells. {...obj} is better, but was just added to Node, it even doesn't exist in 8.0.. @sindresorhus I wonder how did you switch between versions. I have separate node executables for that, and I've got same results in runkit, https://runkit.com/sub/59d4947b71579b001199681e and https://runkit.com/sub/59d495ca735bd50012ba27bc . I'd expect it to be that way because that's what Node sources tell.. ",
    "MarkHerhold": "I just converted from request-promise and had the same need as others here. request-promise would automatically stringify JSON bodies and set the appropriate header. I solved this by wrapping got with a local module and doing the same. Here's a snippet from my wrapper:\nStringify JSON Objects and Arrays and set Content-Type\njs\n    // stringify object and array bodies\n    if (options.json === true && options.body && (typeof options.body === 'object' || Array.isArray(options.body))) {\n        options.headers = options.headers || {};\n        options.headers['Content-Type'] = 'application/json';\n        options.body = JSON.stringify(options.body);\n    }\n. Alex, I think you are on point. I too wrote a wrapper around got for\nserializing JSON bodies.. There are a lot of valid what-if questions here. My fear is that we implement this or another approach, someone ends up not liking it, then we add another set of options to accommodate that use case, and soon the got becomes 500k lines long, competing in the got vs request bloat competition. :laughing: \nAlternatively, we could devise a plugin architecture, possibly via beforeRequest()/afterRequest() hooks, making this PR a plugin that ships with got, but not enabled by default. This would allow others to write their own JSON plugin that fits other use cases without bloating the core.. I should also note that needle (another minimal HTTP request library I am looking at) does timeouts correctly as well.\nThis code terminates after 500ms :+1:\n``` js\n// note that I manually promisified this code, which isn't shown\nconst url = 'http://10.155.155.155';\nconst options = {\n    timeout: 500\n};\nneedle.get(url, options).then(function(res) {\n    console.log(res.body);\n}).catch(function (err) {\n    console.error(err);\n})\n```\nOutput:\n{ Error: socket hang up\n    at createHangUpError (_http_client.js:252:15)\n    at Socket.socketCloseListener (_http_client.js:284:23)\n    at emitOne (events.js:101:20)\n    at Socket.emit (events.js:188:7)\n    at TCP._handle.close [as _onclose] (net.js:492:12) code: 'ECONNRESET' }\n. Ah! Novice mistake. Thanks @floatdrop \n. Reopening for @pasupulaphani \n. Just wanted to chime in and mention that it would be nice to also consider\nwebpack users. Great idea!. Ah, my apologies. I was staring at the README from master while using got v9.0.0.. I agree with @sindresorhus. Just made a novice mistake. Thanks!. ",
    "ash0080": "\nNot interested adding a temporary workaround when it's possible for you to stringify it yourself. We'll add support for passing object literal in body when json: true in the next major release.\n\n@sindresorhus So how to make a request with json content but response is a html?. Excuse me? what u discussed is requesting a json, but what I asked is post a json, responsed is html :joy:. Ahhha~  Sorry, I am messed up. what we discussed is right.\nSorry for my chaotic mind :joy:. suggest use proxy-agent for instead\nauto fit for both http or https proxy. Besides, node-tunnel has a bug, \ntypically say, the tunnel.httpsOverHttp still use port 80 for a mistake,\nso, it's not suitable for Got, at least not for current version.\nunless append :443 on all urls if making a https request. OK,  I got it, the followRedirect false will throw an Error. \nso new question is how to stop the next request gracefully and keep the result. @szmarczak I have read all docs, the problem in this practice is there are several redirects, I only want to get the specific intermediate one match the condition and stop it Immediately, or else, the later redirect will be post an error to server and all recorded urls will be expired. special use case, I understand, but it exists.. @szmarczak I use await async pattern, so I try to make it like this\ntry {\n      await got(url, {\n        headers: {\n          userAgent: CONFIG.USER_AGENT,\n        },\n        agent,\n        timeout: CONFIG.TIMEOUT,\n        hooks: {\n          beforeRedirect: [\n            options => {\n              if (options.hostname === 'MATCH_PATTERN') {\n                redirectArray.push(options.href)\n                options.followRedirect = false\n              }\n            }\n          ]\n        }\n      })\n    } catch (error) {\n      if (error.statusCode === 302) {\n        const redirectTo = _.last(redirectArray)\n        return redirectTo\n      }\n      throw new Error('NO MATCH')\n    }\nbut the problem i faced is the options.href should match options.hostname but not in fact. strange. ",
    "artoale": "@floatdrop thanks for the super quick fix. Working perfectly now!\n. ",
    "ralphholzmann": "@jandet looks like this is due to us using webpack instead of browserify\n. ",
    "jamestalmage": "FYI: https://github.com/jamestalmage/browser-redirect-test\n. What do you guys think about just relying on follow-redirects. I'm basically the sole maintainer now, so if there's something you don't like, you know who to bother \ud83d\ude04.\nAs for caching the stream: https://github.com/jamestalmage/caching-stream. The main advantage over other caching implementations I have seen is that you can abandon the cache or pass through any time you want. So if you received a redirect you would .endPassThrough(), and if you became certain you were not going to be redirected, .dropCache(). Unfortunately, I'm not sure there's anyway to actually know when it's safe to drop either, so it would probably have to be some type of configurable thing.\nThe other solution I considered for follow-redirects is allowing opts.body to be a function that returns a Stream. That breaks compatibility with the core http library, which is a goal of follow-redirects, so I never proceeded. got isn't restricted in the same way though. \n. > This is cool, yet dangerous thing to do.\nAgreed, it's why I never actually pulled it into follow-redirects. It's probably why you don't see other libraries doing it either.\nI think you would be better of just allowing a stream generator function that can be called many times:\ngot.post('url',{\n  body: () => fs.createReadStream('path')\n});\n. https://webpack.github.io/docs/using-loaders.html\nhttps://github.com/webpack/json-loader\n. ",
    "ninox92": "+1\nNeed a 307 PUT request to follow redirect. +1. My bad, found it:\nawait got(s.url, {\n        strictSSL: true,\n        ca: caRootCert,\n        headers: {host: 'sindresorhus.com'}\n});. > @ninox92 Did you open or find any got related Issue or PR there? It's hard to find one because of the name. ;-)\nhttps://github.com/DefinitelyTyped/DefinitelyTyped/issues/29735#issue-370125038. ",
    "satazor": "PR done. \n. I haven't added because thats already covered in the error introduction:\n\nEach error contains (if available) statusCode, statusMessage, host, hostname, method and path properties to make debugging easier.\n\nStill do you want the statusCode and statusMessage mentioned in the ParseError?\n. Oh nvm you added that recently aha. :dancer: \n. Oh, this is a problem with david.. it uses the last entry from the times object: \njs\n\"6.2.0\": \"2016-03-03T07:54:01.845Z\",\n\"5.5.0\": \"2016-03-03T08:00:46.060Z\"\nSee: https://david-dm.org/IndigoUnited/node-gh-issues-stats\n. Doing a got wrapper that deals with retries the way I want is easy except when wrapping got.stream. That will be harder to do since I don't have access to the internal event emitter. In this case I have to do it in the upper surface of the code.\n. @floatdrop sorry the test is wrong, I should have used got.stream since the bug is there.\nHow should we adjust this then?\n. @floatdrop maybe it's ok to throw synchronously since this method does not return a promise?\n. Agree! Closing this.\n. @Jakobud the response is only available if the request went trough and a response was received. If a network error occurred, such as being offline, then there will be no response.\n. You are right, perhaps it was being thrown in some older versions.. MOXY uses it for a variety of libraries/projects: https://moxy.studio\nYou already have our logo in the README :). ",
    "canac": "OK, now I see that the documentation says the options argument supports \"any of the http.request options.\" I should have read it more carefully. Thanks for making this awesome module; it's a pleasure to use it!\n. ",
    "reconbot": "well, I'll be damed\n. Any suggestions on how to turn that off during testing?\nI'm also assuming that the default 5 tries takes a bit longer than 30\nseconds by default.\nOn Sun, Mar 20, 2016, 3:16 AM Vsevolod Strukchinsky \nnotifications@github.com wrote:\n\n@reconbot https://github.com/reconbot I think got tries to do some\nretries. Can you set retries options to 0?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/sindresorhus/got/issues/187#issuecomment-198862642\n. I added some configuration to my library to control the behavior.\n. It works like a charm. I have an elastic search example.\n\n```js\nimport AWS from 'aws-sdk'\nimport got from 'got'\nimport aws4 from 'aws4'\nimport config from './config'\nconst { region, host } = config\nconst awsConfig = new AWS.Config({ region })\nfunction request (options) {\n  const opts = Object.assign({\n    region: awsConfig.region,\n    host,\n    protocol: 'https:',\n    headers: {\n      accept: 'application/json',\n      'Content-Type': 'application/json'\n    },\n    json: true,\n  }, options)\n  aws4.sign(opts, awsConfig.credentials)\n  return got(opts).then(resp => resp.body)\n}\nfunction get ({index, type, id}) {\n  return request({\n    path: /${index}/${type}/${id},\n    method: 'GET'\n  })\n}\n```. I hit this recently too, in an aysnc/await context having to do a try/catch on a valid response is a bit awkward. This is a bit of a contrived example but...\n```js\nasync function updateContent(lastModified) {\n  const { body } = await got('https://example.com/status', {\n    headers: { 'if-modified-since': lastModified }\n  })\n  if (body) {\n    await doSomething(body)\n  }\n}\n// vs\nasync function updateContent(lastModified) {\n  let response\n  try {\n    response = await got('https://example.com/status', {\n      headers: { 'if-modified-since': lastModified }\n    })\n  } catch (e) {\n    if (e.statusCode === 304) {\n      response = e.response\n    } else {\n      throw e\n    }\n  }\n  const { body } = response\n  if (body) {\n    await doSomething(body)\n  }\n}\n```\nIf you're using bluebird\n// bluebird catch\nasync function updateContent(lastModified) {\n  const { body } = await Promise.resolve(got('https://example.com/status', {\n    headers: { 'if-modified-since': lastModified }\n  })).catch({ statusCode: 304 }, e => e.response)\n  if (body) {\n    await doSomething(body)\n  }\n}. I'm expecting no content if it's not modified. That's why I sent the extra header.. My pleasure =). I'd have to see some more sample code, I'd guess you're not sending something correctly, I hit this by accident a few times as the example code isn't the usual way we send requests so it's pretty easy to overlook something.. I love this, yeah a pluggable key value store would make this pretty straightforward and flexible. I wonder if using a leveldown compatible adaptor would be the way to go. Off hand we have memdown and redisdown which are both battle tested and have many friends.\nIt would be pretty small if people didn't use it and didn't want to bring in a storage adaptor. I'm all for this in core.. I'd prefer the second, needs more documentation but keeps got tiny.\nOn Mon, Mar 20, 2017, 11:28 PM Luke Childs notifications@github.com wrote:\n\nYeah LevelUP + LevelDOWN adapter looks good.\nShould LevelUP + memdown be a dependency of Got so we can cache OOB? e.g:\nconst got = require('got');\ngot('foo.com', { cache: true });\nThen { cache } could also be a LevelUP config object to use an adapter\nother than memory.\nOr should we require a LevelUP DB instance to be passed in to Got? e.g:\nconst got = require('got');const levelup = require('levelup');const redisdown = require('redisdown');const db = levelup('mydb', { db: redisdown, host: 'localhost', port: 6379 });\ngot('foo.com', {cache: db});\nI think the second method is better, it's a bit more verbose but it keeps\nGot slim and we're also not then tied to LevelUP. Any module that exposes .put(key,\nval) and .get(key) could be passed in to { cache } like in Sindre's first\ncomment.\nThoughts?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/sindresorhus/got/issues/281#issuecomment-287966585,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABlbuU25ix7YjuQp8ENNvE2BrDmRkyBks5rn0PMgaJpZM4McPJs\n.\n. Retry after support is awesome. I think automatically retrying is probably not a great idea in general,\nthis would be a good time to change that behavior.\n\nOn Sun, Feb 11, 2018, 10:42 AM Luke Childs notifications@github.com wrote:\n\nOne potential side effect to be aware of, especially if we're thinking of\nenabling this by default:\nConsider you reach the request limit quota for the API you're using and\nthey return 429 Too Many Requests with a Retry-After header set for when\nyour quota resets next month.\nThis would mean, if we by default retry 429s and respect Retry-After,\nthat making a request with Got to your API once you've hit your quota would\nreturn a Promise that may not resolve for up to 30 days in the future.\nThat doesn't seem very intuitive and could cause bugs that would be a\nnightmare to track down.\nThis seems like a great feature but might be better as opt in or not\nwhitelisting 429.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/sindresorhus/got/issues/417#issuecomment-364760887,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AABlbl7-8eIcQ1WuaJLl-2zgTRhB62q1ks5tTwplgaJpZM4QgQwm\n.\n. \ud83d\udc4f . plain old javascript object, I'll update it. fixed. \n",
    "Rowno": "I've fixed the merge conflict and documented the url property.\n. Looks like #469 didn't fix the issue.. Probably a good idea, I thought the response object wasn't documented at all until I stumbled upon that sentence. \ud83d\ude05 . Doesn't this introduce a security issue for people logging errors? Since the body could easily contain sensitive data.. I mean logging errors with packages like winston or sentry, which also log all the enumerable properties on the Error object.. Doesn't this introduce a security issue people logging errors? Since the body option could easily contain sensitive data.. ",
    "Darkle": "Fair enough.\n. ",
    "sschuberth": "I just downloaded and installed Node today:\n$ node --version\nv4.4.3\nWhich version do you expect me to use?\n. I'm playing around with the spdx-license-list project, so I'm using got version 2.9.2.\n. Done, now I get\n```\ngot.stream('todomvc.com').pipe(fs.createWriteStream('index.html'));\n                               ^\nReferenceError: fs is not defined\n```\nSorry if this is something obvious, I'm completely new to Node.js development.\n. Now I get\nevents.js:141\n      throw er; // Unhandled 'error' event\n      ^\n HTTPError: Response code 405 (Method Not Allowed)\nIs that also a bug in the example, or an acceptable error due to an incomplete example?\n. Makes sense :-) So I agree the example is now good enough. Thanks for your quick responses!\n. ",
    "PhantomRay": "Yes I know try/catch is not supposed for error handling of async functions, but depends on how the code is written, sometimes it make sense only in rare scenarios.\nThis issue is more about the library will crash the program in a scenario mentioned above, and this kind of error cannot be captured by callback.\n. ",
    "Firnis": "But if your endPoint is not answering, then you will be waiting 5*10 seconds.\nI see your point, but you can set count of retries manually if you need.\n. ",
    "a0viedo": "@sindresorhus for any specific reason? can I ask if you have an existing policy for updating dependencies?\nFor new mayor versions it may not matter but for security disclosures having an automated process might warn the package consumers.\n. ",
    "hustcer": "Sorry, made a mistake.\n. @floatdrop\nIt seemed that the end event of res never triggered?\nOr did I missed something? Thanks.\nresp.on('end', function(){\n    console.log('This never happened?');\n});\n. @floatdrop \nI have tried:\ngot.stream( url ).on('end', () => console.log('Ended'));\nbut still not work.\nI want to get the full response body, something like this:\njavascript\n            let body = '';\n            res.on('data', data => {\n                body += data.toString();\n            })\n            .on('end', () => {\n                console.log(body);\n            });\n. Is there any workaround? Thanks\n. May this issue help: https://github.com/visionmedia/superagent/issues/857\n. ",
    "alex-phillips": "I believe you're right. It's just not receiving anything FROM the server until the end of the upload. The way I was previously able to accomplish this in the request package was that var request = request.get(...), but since this is a promise-based library, it returns a promise instead.\nI was just curious if there was any way to get that request object while still being a promise based flow.\n. This is perfect, thanks!\n. ",
    "astoilkov": "Ok. Thanks for the information and will investigate more and look into the source code to figure it out.\n. Oops. I found out why. The commit is after the 7.1.0 release. It would be awesome to use this feature.\n@sindresorhus Is a 7.2.0 release coming soon or should I use a more complicated approach?. ",
    "eugeneross": "@sindresorhus  @jamestalmage Thanks, but I'm curious to why a json loader would be needed for Got since all of these packages have package.json files themselves?\n. ",
    "piranna": "First we should define why we want the promises. Got seems to resolve them when the transfer has finished and you have downloaded the full content body, while I would find more interesting that it resolve at the same time the response event is dispatched and give a stream ready to be read... Problem of the first approach is that the content will be downloaded to ram, making it a problem for big files.\n. I've found this also happens when using the request event.\n. > This is because input and output streams, that returned from got is not\n\npiped anywhere and get stuck'd with filled buffer. In this situation node\nprefers to exit (even if there is stream, that can consume data).\n\nThe point is that app exit without error at all, and I'm using async.js and\ncallbacks are not being called too. Is that the expected behaviour?\nShouldn't exit with a \"buffers filled\" exception or something? Should I\nopen an issue on Node.js?\nOn the other hand, I think this is a valid use case, or is it intended to\nuse only the returned proxy and the 'request' and 'response' events are\nmostly internal details? If so, I would deprecate them and use them\ninternally to fill the proxy object with the request and response methods.\nI'm asking this because I'm doing a get request and need to wait to the\n'request' event to get a reference to the request object so later I can be\nable to call .abort() to interrupt it, so I think it would enought (and\nsimple) by adding a .abort() method and others alike to the proxy object.\n. I have searched for it and didn't find anything, hope this issue helps :-) It's not needed a new option if json one is reused, but I understand it's a not so common case, just only a desirabled one. I'm already processing the output myself, it's just a matter I would have liked that got itself does it for code clarity.. ",
    "DimitryDushkin": "Please write about it in documentation. It's totally unclear.\n. ",
    "pasupulaphani": "Still an issue. Timeout is not respected when it is greater than 1000ms.\n```\nconst got = require('got');\nconst url = 'http://10.15.15.234';\nconst options = {\n    timeout: 1000,\n    retries: 0\n};\ngot(url, options).then(function(res) {\n    console.log(res.body);\n}).catch(function (err) {\n    console.error(err);\n})\n```\n. @floatdrop Sorry for the false alarm. Looks like I made mistake. Not a bug.\n. ",
    "parro-it": "I'm using got version 6.3.0\n\nfailed with \"Response code 303 (See Other)\"\n      stream.catch.then.e (node_modules/got/index.js:115:13)\n    process._tickCallback (internal/process/next_tick.js:103:7)\n\n@floatdrop, to work as you said, it seems that this line of code:\njs\nconst limitStatusCode = opts.followRedirect ? 299 : 399;\nshould be instead:\njs\nconst limitStatusCode = opts.followRedirect ? 399 : 299;\nOtherwise, if followRedirect is true, got throws on any 3xx response.\n. Ok I think I understood the problem. In function requestAsEventEmitter, you are doing redirection only for GET and HEAD method. \nSince I'm doing a POST request, requestAsEventEmitter doesn't redirect and the 303 response will reach the point above, and since 303 > 299, it throws the exception.\n. ",
    "yeze322": "Was this PR reverted? Seems the validator is still using is-plain-obj for now, class instances cannot be used as body.. ",
    "DylanPiercey": "@sindresorhus, I'd recommend using something like https://github.com/matthew-andrews/isomorphic-fetch or https://github.com/bitinn/node-fetch, it'd make an eventual browser port much easier.\n. @sindresorhus sorry forgot about this one, I'll try to get to it later today.\n@floatdrop currently formdata getHeaders only returns content-type and that will not change so I figured this was the most appropriate api. Especially since in @2.0 the getHeaders function may have a deprecation warning.\n. @sindresorhus does that look better? (Added some tests).\n. Let me know if anything else is needed @sindresorhus \ud83d\ude00.\n. ",
    "tommedema": "@stevenvachon are you aware of any such package?. ",
    "f-mer": "Some services do not respect rfc and misbehave as pointed out here.\nWould it be possible to remove the default headers safely?\n. Thanks for taking your time. Really like the simplicity of got.\n. ",
    "tiaantiaan": "Ah, it is working now. I am using version 5.7.0. It was a problem on my side. It seems that my local repository cache took a  while to update to the new version that was only published 2 hours ago. \nThanks for your trouble, and the great work!\n. ",
    "squarejaw": "Buffer.from was backported to v4.5.0, so it would be nice if that was the minimum version required.\n. Looks like the property isredirectUrls.\n```js\nconst got = require('got');\ngot('httpbin.org/redirect/6').then(response => console.log(response.redirectUrls));\nOutputs:\n[ 'http://httpbin.org/relative-redirect/5',\n  'http://httpbin.org/relative-redirect/4',\n  'http://httpbin.org/relative-redirect/3',\n  'http://httpbin.org/relative-redirect/2',\n  'http://httpbin.org/relative-redirect/1',\n  'http://httpbin.org/get' ]\n```. ",
    "tommytroylin": "@sindresorhus Actually  Buffer.from function is exist on node 4.4.4 runtime\nSo Buffer.from ? Buffer.from(...) : new Buffer(...) won't work.\n. ",
    "zeke": "Yeah but this doesn't work:\ngot.stream(tarballUrl)\n  .on('error', function (e) {\n    callback(e)\n  })\n  .pipe(gunzip())\n  .pipe(extractor)\nThe .on is not properly chaining to the next .pipe. Does the error handler need to return something?\n. Thanks for the info, @floatdrop. Much appreciated.\n. ",
    "wtgtybhertgeghgtwtg": "Thank you.. I think it's important that the software directly consuming got must explicitly enable logging and that all other instances of got be unaffected by that.  So, I I have the following\nrequire('my-got');\nconst ghGot = require('gh-got');\nghGot('users/wtgtybhertgeghgtwtg', {token: 'my-token'});\nwhatever goes on in my-got should not affect what gh-got logs.  I believe that neither a solution based on environmental variables (where my-got can just add the variable) nor one using a singleton (where it can require('got').on('metadata', data => console.log(data))) can account for this.. > Therefore, if I enable HTTP logging for an application, I expect a comprehensive view of all requests made either by my application or descendent components.\nWith an allowance for redaction of sensitive information, I agree.  The issue is the \"if I enable\" part.  I'm saying settings made in or for a descendant or sibling component should not affect what I have here.. I might agree, but that's making a lot of assumptions about the stack.  How many users of got or its dependents do you think have a dedicated sysops team?  What is your suggestion for those who don't?. > It's way too bloated.\nTo be fair, that's mostly because it pulls in async (to get IPv4 and IPv6 stuff in parallel) and lodash (to do input validation).  If the maintainer's willing, it wouldn't be that hard to pull those out.. ",
    "txssseal": "Aaahhh. Thanks, didn't know this.. ",
    "fritx": "Same issue here:\nI've installed the latest npm as @sholladay  mentioned. Still not work.\nRecently, I cannot install many pkgs due to got@5, which is annoying.\nAnd when I switch to node6, it is fine.\nplain\n$ npm i -g npm\n$ node -v\nv7.7.4\n$ npm -v\n4.4.4\n```plain\n$ npm i -g hotel\nnpm ERR! code ENOTSUP\nnpm ERR! notsup Unsupported engine for got@5.7.1: wanted: {\"node\":\">=0.10.0 <7\"} (current: {\"node\":\"7.7.4\",\"npm\":\"4.4.4\"})\nnpm ERR! notsup Not compatible with your version of node/npm: got@5.7.1\nnpm ERR! notsup Not compatible with your version of node/npm: got@5.7.1\nnpm ERR! notsup Required: {\"node\":\">=0.10.0 <7\"}\nnpm ERR! notsup Actual:   {\"npm\":\"4.4.4\",\"node\":\"7.7.4\"}\nnpm ERR! A complete log of this run can be found in:\nnpm ERR!     /Users/fritx/.npm/_logs/2017-04-10T08_07_41_408Z-debug.log\n``. Just removedengine-strict=true` in ~/.npmrc and it works. My bad!. ",
    "lukechilds": "304 isn't a redirect, it means the content hasn't been modified.\nI'm doing a GET request with a date set in the if-modified-since header. The API is returning a 304 meaning the resource hasn't changed since the copy in my cache but this causes got to throw an error.\n2 secs, just putting some code together.. ```js\nconst got = require('got')\n// Make API request\ngot('https://onionoo.torproject.org/summary?limit=1')\n  .then(res => {\n  // Log response info (should be 200)\n  console.log(res.statusCode, res.headers)\n\n  // Make another request with if-modified-since set\n  // This should give us a 304\n  return got('https://onionoo.torproject.org/summary?limit=1', {\n    headers: {\n      'if-modified-since': res.headers['last-modified']\n    }\n  })\n\n})\n// This should run, but got throws an error\n  .then(res => console.log(res.statusCode, res.headers))\n// You can see we got a successful 304 response\n  .catch(console.log)\n```. Oops, just seen your reply.\nThe headers aren't in the error object, that's my problem. You can see in the output from the above code:\n200 { 'last-modified': 'Tue, 20 Dec 2016 10:22:54 GMT',\n  'access-control-allow-origin': '*',\n  'content-type': 'application/json;charset=utf-8',\n  'cache-control': 'public, max-age=300',\n  date: 'Tue, 20 Dec 2016 11:13:43 GMT',\n  'x-varnish': '295213998',\n  age: '0',\n  via: '1.1 varnish-v4',\n  'content-length': '211',\n  connection: 'close',\n  'accept-ranges': 'bytes',\n  'strict-transport-security': 'max-age=15768000' }\n{ HTTPError\n    at stream.catch.then.data (/Users/lukechilds/Dev/oss/onionoo-node-client/node_modules/got/index.js:114:13)\n    at process._tickCallback (internal/process/next_tick.js:103:7)\n  message: 'Response code 304 (Not Modified)',\n  host: 'onionoo.torproject.org',\n  hostname: 'onionoo.torproject.org',\n  method: 'GET',\n  path: '/summary?limit=1',\n  statusCode: 304,\n  statusMessage: 'Not Modified' }. Ahhh, thank you, I didn't realise that. Well that gives me a way to resolve this on my end. It definitely seems odd to me that it throws on a 304 though.\nJust had a look and it appears to be reading the body stream that's causing the error. Although the console log says it's an HTTPError the line it points to (114) is a ReadError.\nCould this be caused by the 304 having no body?. Oops, yep just realised that.. Would you accept a PR to \"whitelist\" 304 in the status code check?. Ok, it's only a simple change, just submitted a PR.\nTake it or leave it \u00af\\_(\u30c4)_/\u00af. @julien-f when you say treated differently do you mean treated differently as in not having an error thrown or treated differently as in I need to do something else in my PR?. @julien-f Ah I see, that's a valid point.\nHowever, I still think it shouldn't throw an error because, like you said, a 304 should only be returned if someone's asking whether their cached version is still good, so they'll be expecting to handle it.. @sindresorhus request doesn't throw. It returns as normal with request.body as an empty string.. Good stuff, is https://github.com/sindresorhus/got/pull/252 ok or do you need anything else?. @sindresorhus Continuing discussion from here: https://github.com/sindresorhus/got/issues/251#issuecomment-285131422\nI've added a test \ud83d\udc4d\nWhen writing it I noticed that the mock 404 route is wrapped with setTimeout? Why is this? Tests still pass if I comment out setTimout. Should I be doing that for my 304 route?\nRegarding the readme update, is it really necessary to mention a 304 response will have an empty body in the readme? That's normal HTTP behaviour, if people are sending if-modified-since headers then they are gonna be expecting to handle 304s.. Ok, I've made those changes.\n@sindresorhus is the wording/position in the readme ok?. I've had this on my todo list for a while, I've already implemented this on top of Got for lukechilds/onionoo-node-client. I was gonna pull my implementation out and do it as a wrapper but happy to have a bash it implementing it in core. I used an in memory store by default but you can pass options in to use Redis/MongoDB for production.\nThere's a possibility I'll be quite busy with paid work over the next month so I might not have time for a while. If anyone else wants to start on it then go ahead. You may also find this helpful: lukechilds/expired.\nAnd btw, for the caching, I used node-cache-manager, but I don't think I'd recommend it. The different store engines don't all implement the full API and have inconsistent behaviour so they're not just drop in config options like they appear to be. I had to submit a PR to get Redis working at all. cacheman and jugglingdb look like better options, although I haven't used them.. Apologies for messy code in onionoo-node-client btw, I know it's not the neatest. I kinda struggled with the async control flow.. Yeah LevelUP + LevelDOWN adapter looks good.\nShould LevelUP + memdown be a dependency of Got so we can cache OOB? e.g:\n```js\nconst got = require('got');\ngot('foo.com', { cache: true });\n```\nThen { cache } could also be a LevelUP config object to use an adapter other than memory.\nOr should we require a LevelUP DB instance to be passed in to Got? e.g:\n```js\nconst got = require('got');\nconst levelup = require('levelup');\nconst redisdown = require('redisdown');\nconst db = levelup('mydb', { db: redisdown, host: 'localhost', port: 6379 });\ngot('foo.com', {cache: db});\n```\nI think the second method is better, it's a bit more verbose but it keeps Got slim and we're also not then tied to LevelUP. Any module that exposes .put(key, val) and .get(key) could be passed in to { cache } like in Sindre's first comment.\nThoughts?. Got it working, http-response-object doesn't implement the Readable Stream interface. Works with this PR: https://github.com/ForbesLindesay/http-response-object/pull/4\nIs http-response-object \"good enough\" to return instead of a native response? If not this may need to be a Got wrapper that just exposes url/headers/body and none of the Node.js response stuff.. Ok, I've done some digging and a Node.js response is an instance of http.IncomingMessage. So to make the cached version compatible with the Node.js response there's quite a few things we need to support as well as some methods/properties that we can't support on the cached response (e.g response.socket).\nWe'll need to either add support to all these things in http-response-object or if @ForbesLindesay thinks this is beyond the scope of his module I'm happy to create a new one.\nThere is also the issue that we'll need to manually keep the cached response up to date with http.IncomingMessage. For example if someone uses a new version of Node.js that has a new method on response, they'll be able to use that new method on normal responses but it won't exist on cached responses until it's implemented in our response package.\nThis seems like kind of a hacky solution, maybe it would be better to limit the cached responses to only basic data, although this is probably not gonna be obvious to people unless they read the docs. Or alternatively just do this as a wrapper that never exposes the Node.js response.\nI'll wait for feedback before going any further with this.. http-cache-semantics looks perfect \ud83d\ude0d. I wish I'd seen that before writing expired.... Just an idea but http-response-object gives us a TTL so we know how long a cache item can be stored for. LevelUP is just get/set with no concept of a TTL. If it's stored, it's stored forever. This isn't a massive issue, we can manually delete items from the cache if we see they're stale on a future request or if LevelUP is backed by a LRU store then it'll take care of itself.\nHowever this functionality is being written in a way that will allow someone to use any cache store with Got and I think TTL is useful information to pass through. What about if we change the cache.put signature to cache.put(key, val, ttl, cb) rather than the current LevelUP signature of cache.put(key, val, cb).\nThen we could provide a LevelUP cache plugin for Got so using with LevelUP and friends is still simple:\n```js\nconst got = require('got');\nconst gotCacheLevelup = require('got-cache-levelup');\nconst db = gotCacheLevelup('mydb', { db: require('redisdown'), host: 'localhost', port: 6379 });\ngot('foo.com', {cache: db});\n```\nBut then if someone wanted implement a native Redis cache plugin for Got they could make use of the TTL.\nAlso, I was just using callbacks so it worked OOB with a LevelUP db instance. If we are setting our own spec for cache \"plugins\" then we could require a Promise interface which would be a bit neater.\nIn my mind I see a cache plugin looking like this:\njs\nmodule.exports = {\n  set: (key, val, ttl) => new Promise(),\n  get: key => new Promise(),\n  del: key => new Promise()\n};\nThoughts?. We can still pass the TTL as the third argument to set and match the Map() API. map.set will just ignore the TTL:\njs\nconst map = new Map();\nmap.set('foo', 'bar', 100);\nmap.get('foo');\n// \"bar\"\nSo got('foo.com', {cache: new Map()}); would work fine. I'm not too sure what you mean regarding creating a new cache entry for the TTL, I don't think I explained myself very well. I mean it's useful for other people to use the TTL in storage adapters, not that it's useful to store.\ne.g: If some-cache-store had native TTL functionality to clear old values we could do:\n```js\nconst cache = require('some-cache-store');\nconst gotCachePlugin = {\n  set: (key, val, ttl) => cache.put(key, val, ttl),\n  get: key => cache.get(key),\n};\nmodule.exports = gotCachePlugin;\n```\n\nWe can just run the input through Promise.resolve(), so the user can submit any value or a Promise, and it's awaited if it's a Promise.\n\nSounds good \ud83d\udc4c. I see. But theres no benefit to checking the TTL when we retrieve a cached item, everything is already checked inside policy.satisfiesWithoutRevalidation().\nThe only use for storing the TTL would be to, on a regular interval, loop over all items from the cache and delete each item which has exceeded it's TTL. IMHO that's not a good idea and would be a job better handled by the underlying database.. Nah, that's not quite how it works. We make a request, save the response along with the cache policy generated by http-cache-semantics, then the next time the resource is requested we check the cache, check whether the cache policy is still valid, then either use the cached response or refetch. We don't need to store the TTL, everything required to check that the cached response is fresh is handled by policy.satisfiesWithoutRevalidation() from http-cache-semantics.\nThe TTL would be useful so the DB can clear out stale cache entries ASAP rather than waiting for them to be requested again before checking.\ne.g If you make lots of requests to different URLs that you won't request again, you'll end up with loads of entries filling up your cache.. What do you think would be the best way to handle binary responses? I'm struggling to get my head round it.\nThe simple solution would be b64 encode => cache => b64 decode. But that seems like it could have pretty major performance implications. If you're using an image API for example,  reading the cache is gonna block the event loop while decoding potentially MBs of data.\nAnother solution would be to store as a hex string in the cache. That could then be loaded directly into a buffer but it's gonna take up loads of space in the cache.\nAny ideas?. Oh yeah, of course \ud83d\udc4c. For some reason I was thinking we needed to serialize all the data we're caching to a JSON string, but that's just specific to the LevelUP implementation.. Is it safe forgetStream() to be called twice on responses that are going to be cached? Once to get a buffer to cache and then again inside asPromise() to be returned to the user?\nIt seems to be working ok but I'm not sure if maybe reading from the same stream twice could cause problems. Maybe I should be cloning the stream and using one for the cache and another to pass to asPromise()/asStream() like this: https://github.com/nodejs/readable-stream/issues/202. I've moved the caching around like you suggested, however after taking another look at this I think maybe it was better how it was before. I think (I might be wrong) it's ok to read a stream multiple times, as long as your read at the same time, not after it's already started being read.\ne.g this is fine: \njs\nconst stream = got.stream('todomvc.com');\ngetStream(stream).then(txt => console.log(txt.length));\ngetStream(stream).then(txt => console.log(txt.length));\n// 254806\n// 254806\nThis isn't:\njs\nconst stream = got.stream('todomvc.com');\ngetStream(stream).then(txt => {\n    console.log(txt.length)\n    getStream(stream).then(txt => console.log(txt.length));\n});\n// 254806\n// 0\nThe previous method I had wasn't doing anything else with the stream inside the then(). The other read was happening outside. This had the benefit of having all the cache logic once inside get() rather than checking twice inside both asPromise() and asStream(). It also meant that we would only ever try to cache responses from get() and not getFromCache(). Now the caching is inside asPromise()/asStream() I need to check whether the response came from  get()/getFromCache() and make sure we don't try and cache responses that were already served from the cache.\nDoes this make sense? Do you think it was ok how it was previously or is there a reason it needs to be like this?. Yep, I think that's the best solution. I don't think a PassThrough stream would work well in this scenario as it's not just a stream but an instance of http.IncomingMessage. So we can't just return a new stream, we'd need to copy all the relevant properties from the response to the duplicated stream which would be kind of messy.. Ok, this seems to be pretty much sorted and working.\n\nAll cacheable responses are cached.\nCache API is compatible with Map so new Map() works OOB.\nFresh cache entries are served directly from the cache.\nStale cache entries with either Last-Modified or ETag headers are revalidated.\n304 responses from the revalidation requests will use the cached body (user doesn't have to manually handle 304)\nRevalidation responses are re-cached (headers may have changed)\nUses http-cache-semantics to check responses are cacheable/fresh/revalidated so should conform fully to HTTP RFC 7234\n\nYou can view test/cache.js for an overview of the new behaviour.\nThe revalidation code (https://github.com/sindresorhus/got/pull/284/commits/07a403c1528abda166275b626a89c3e3eee90f8e) is a bit messy, I'm working on refactoring that into something more readable. Also there are a few other things I wanna tidy up and a couple of edge cases I wanna test.\nIs there any functionality you think I've missed or have I covered everything?. Ok, after having a think about this it occurred to me that I'm going about this the wrong way. Rather than trying to bake all the caching logic directly into Got without breaking any existing Got functionality, it would be much simpler to just extract what I've got so far into a separate module that wraps http.request with caching support. Then, rather than bloating Got with about 33% extra code we can just require the cache module and wrap http.request with it if opts.cache is set.\nIt'll return an event emitter and pass all request events through if a request needs to be made for the resource. That means it will automatically work with all of Got's existing functionality.\nSo just to keep you in the loop, there won't be any activity on this PR for a while, don't worry though, I'm still working on it, I'll just be focusing on getting the standalone cache module working. Once the cache module's implemented it should just be +~3 line change for all the same functionality we've discussed. \ud83c\udf89. @sindresorhus Great \ud83c\udf89 \nBtw, in my last message I said:\n\nIt'll return an event emitter and pass all request events through if a request needs to be made for the resource. That means it will automatically work with all of Got's existing functionality.\n\nHowever I think it would be better to leave the request events and allow listening to them via a single request event for the event listeners to be attached. e.g:\njs\ncacheableRequest(http.request, opts, cb)\n  .on('error', handleCacheError)\n  .on('request', req => {\n    req.on('error', handleRequestError);\n    req.end();\n  });\nDoes that seem like the better solution to you?. @vadimdemedes thanks for reviewing, a lot of these tests are actually duplicated in cached-request so I need to go though and remove some of them from Got.. @sindresorhus so originally I was thinking cacheableRequest should have the same API as http.request so they would be completely interchangeable, just a drop in upgrade. e.g:\njs\ncacheableRequest(http.request, opts, cb)\n    .on('error', handleError);\n    .end();\nHowever I realised afterwards that was going to be pretty messy to implement because we don't know if we actually need to make a request until after cacheableRequest has returned. So we'd have to manually patch all methods events over to the emitter we've already returned if/when we have the request object. \ud83d\ude10\nSo instead I decided to just return the request object inside a request event. Then you can do all your normal request stuff in the request event. And handle cache specific event on the main event emitter:\njs\ncacheableRequest(http.request, opts, cb)\n  .on('error', handleCacheError)\n  .on('request', req => {\n    req.on('error', handleRequestError);\n    req.end();\n  });. @sindresorhus current status is that I'm finishing off storage adapters (in a separate repo) and then writing docs. If it's all the same to you I'll focus on getting that done first and clean up the merge conflict after. Now that everything's handled in external modules the changes to the Got codebase are minimal.. Keyv and cacheable-request are now stable and I've updated this PR to use them and fixed all merge conflicts.\n@sindresorhus I've built a load of error handling into Keyv/cacheable-request but not sure how to expose it through Got.\nShould I create a got.CacheError class? Currently cacheable-request emits the raw error straight from the DB client so they could have different properties depending on which storage adapter is used.. Would this be enough:\njs\ngot.CacheError = class extends StdError {\n    constructor(error, opts) {\n        super(error.message, error, opts);\n        this.name = 'CacheError';\n    }\n};\nOr should I also attach the underlying DB error, with something like:\njs\ngot.CacheError = class extends StdError {\n    constructor(error, opts) {\n        super(error.message, error, opts);\n        this.name = 'CacheError';\n    this.error = error;\n    }\n};\nSeems the DB error would be useful to have but accessing it as err.error just seems wrong.. @jotto How are you calculating Got's size?\nIn a fresh directory I get:\nshell\n$ npm install got && du -hd 0 node_modules\n584K    node_modules\nSo Got is 584K without cacheable-request.\nThanks for bringing this up though, cacheable-request is currently 708K. There's currently no .npmignore used in cacheable-request or any other modules I've published that it depends on. I'll fix that which should make a significant reduction in size.\nEdit: Adding .npmignore to projects, reduced cacheable-request down to 440K. Over half of the current size (260K) is http-cache-semantics and normalize-url which are out of my control.\nDouble Edit: Also, worth mentioning, cacheable-request shares a few packages with Got so although it's 440k by itself, it only increases Got by 356k, bringing Got to a total size of 940k.. Is this ok to be merged?. @sindresorhus thanks for taking the time to go over this!\nAll latest requested changes have been implemented.\nTwo things I'm not quite sure about:\nNew Properties\n\n.fromCache and any other extra properties on the response needs to be documented.\nhttps://github.com/sindresorhus/got/pull/284#discussion_r142334164\n\nIs this ok: https://github.com/sindresorhus/got/pull/284/commits/4d9ab592dfb34ec43977c2a44e3bf4744336760e\nPulled straight from cacheable-request docs:\nhttps://github.com/lukechilds/cacheable-request#cb\nCache link\nThere are currently two headings titled \"cache\", which means the href #cache goes to the api docs, and #cache-1 goes to the main cache section.\nIs this ok? Obviously works fine as is but wondering if re-ordering or something in the future could break the other link.\nhttps://github.com/lukechilds/got/tree/cache#cache\nhttps://github.com/lukechilds/got/tree/cache#cache-1. Is this ok?\nhttps://github.com/sindresorhus/got/pull/284/commits/0a75785812c9acf33cc1dc8b8a4ad863a243b6c6\n\nRather say it will be responselike when it's from the cache, but it should behave exactly like the original\n\nIt's worth noting, it won't behave exactly like the original, because the original has references to the socket and stuff which I obviously can't do with a cached response. However none of those core Node.js HTTP response stream methods are actually explicitly mentioned in the Got docs so you could consider them undocumented properties from Got's perspective and argue the behaviour is exactly the same.\nAnyway, I linked to the responselike module so they can view more information on exactly what properties it supports. Hey, just incase you're about to merge this, can I just make a quick tweak to Keyv first. It won't change any current behaviour but it will store the data in a way that will make it much easier for me to make changes to Keyv in the future without affecting 3rd party users like Got.\nI want to get this in before Keyv gets more usage, it's literally only a tiny change, just not backwards compatible, working on it now.. Sorted!\nDetails on why the change was needed here: https://github.com/lukechilds/keyv/pull/29. My pleasure!\n. I would like to say it will be ready in a couple of weeks but I'm waiting to hear back on some client work which will take priority so I can't guarantee anything unfortunately.\nRegarding enabling cache by default, I think it'll have to be opt in as we aren't bundling a cache store with Got. To enable caching the user will have to manually install and pass in a cache store:\n```js\nconst got = require('got');\nconst levelup = require('levelup');\nconst redisdown = require('redisdown');\nconst db = levelup('mydb', { db: redisdown, host: 'localhost', port: 6379 });\ngot('foo.com', {cache: db});\n```\nNo caching by default so would just be a SemVer minor release.. Submitted PR #320 for reference. Also, is the existing typeof decompressResponse === 'function' check necessary or can it be removed?\nWon't decompressResponse always be a function?. > the decompress-response package is not included when Got is browserified\nAhh, makes sense \ud83d\udc4d . Yeah, sure.\nI added a more generic explanation:\n\ndecompress\nType: boolean\nDefault: true\nDefines if compressed responses should be decompressed automatically.\nIf this is disabled the body is returned as a compressed Buffer. This may be useful if you want to handle decompression yourself or stream the raw compressed data.\n\nThat ok?. Is there anything else needed for this?. @sindresorhus Any idea why this didn't get picked up by XO in unicorn/catch-error-name?. I agree, retries should be whitelist only.\nThere may be multiple proprietary errors along the lines of API_LIMIT_REACHED which should obviously not be retried.\nEdit: Oh wait, those are Node.js errors right? Not HTTP errors. So moot point about API limit responses, but still agree it should be whitelist only.. @petitchevalroux Just to keep you updated:\n\nI wish to contribute by adding unit tests to the current version in order to avoid any future issue\n\nIn the next release the behaviour will be slightly different. If the request function throws, Got will throw an instance of got.RequestError rather than throwing the raw error from the request function.\nYour code will most likely continue to work with this change but just a heads up.\nMore info here: https://github.com/sindresorhus/got/pull/412. Ok, all good.\nSame functionality as before with 190 fewer lines of code.\nAlso, can anybody explain what test/helpers.js is testing? It's unclear to me, it looks like it could be tidied up a bit though.. Ahh, ok. All the other test files are pretty self explanatory, this one isn't IMO, especially in master where a few other bits have creeped in and the test name isn't that relevant.\nWhile I'm working on this PR do you want me to clean it up a bit? Maybe also add tests for got.post, got.put, got.patch, got.head and got.delete?. Yeah, I definitely want to finish this.\nOSS has taken a back seat while I'm working on a paid project but there are a few things on Got/AVA/Keyv that are high on my list once the paid work is over.. Just FYI, I still fully intend to finish this, I just haven't because life.\nBut yeah, no point keeping it open for now \ud83d\udc4d . Oh no :/\nStrange that the tests weren't failing on Travis in the PR builds \ud83d\ude15 \nI finally got myself some paid work \ud83c\udf89  but it's on a really tight deadline and I've lost a few days from travel (I'm back in Thailand). I need to catch up on some work but I'll get this fixed ASAP. Probably either tonight or tomorrow night.. Regarding 2bc2b90, it seems to me this was originally a bug in Got. The fact that http.request could throw was never accounted for so in Promise mode the thrown http error caused the Promise to reject. Before the cache PR, in stream mode that error would never be caught, so definitely a bug IMO.\nSo this bug has now just moved to cacheable-request. It also existed in request: https://github.com/request/request/issues/2120\nWe should definitely fix this so thrown requests (as opposed to errored) can be handled properly, however I don't think implementing the previous behaviour and returning the raw http error is a good idea. This isn't documented anywhere in Got and appears to just be side affect from previous code. I would suggest either throwing this as a got.RequestError or creating a new error class to differentiate between requests that error and requests that immediately throw.\nThoughts?\nEdit: Potential solution in https://github.com/lukechilds/cacheable-request/issues/14 that would align neatly with Got's functionality.. > How is the Promise rejecting incorrect? It is currently accounted for in Promise mode, as 92ed73a proves. No idea about Stream mode though.\nAhh, my bad. If it's intentional then IMO it would be nicer if it could be returned as one of the proper Got error types, like got.RequestError.\nI'll make that proposed change to cacheable-request and then we can throw a got.RequestError if http.request() throws.. First bullet point in your original comment should be resolved in #412.\nActively looking into the failing cancel test. It's pretty difficult to pin down though, it never fails for me locally and only occasionally fails on Travis.. In fact it might be better to get this resolved directly in AVA as this will affect a lot of other projects running tests in containers.\nSubmitted a PR: https://github.com/avajs/ava/pull/1551. You can pass the character encoding to be used with the Buffer directly through with options.encoding.\nhttps://github.com/sindresorhus/got#encoding. Hmmnn, yeah I just had a play, getting the same issue even without Got if I just load the page into a buffer with http.request.\nPossibly an issue with weird encoding used by the web server? Node.js can definitely handle those characters if they're properly encoded with UTF-8:\n```js\nconst buffer = Buffer.from('\u041a\u0430\u0445\u043e\u0432\u0441\u044c\u043a\u043e\u043c\u0443', 'utf8');\n// \nbuffer.toString('utf8');\n// '\u041a\u0430\u0445\u043e\u0432\u0441\u044c\u043a\u043e\u043c\u0443'\n```\nGonna close this issue as it seems like it's unrelated to Got. Feel free to re-open if you discover otherwise.\nDon't forget to post back here with the solution if you find it! I would be interested to know.. Does tweaking this option help?\nhttps://github.com/sindresorhus/got#useelectronnet. Those options apply to got and all helper methods.. Yeah, I know Sindre had similar issues with electron: https://github.com/sindresorhus/got/issues/315\nWe were using electron.net by default in Electron but due to buggyness we've reverted back to http.request, electron.net is now behind an option.\nThis is in master but not released on npm yet, a new release is planned soon.. Sorry, edited my last comment with more info as you were replying ^. We've made some major changes to Got in master, however a few obscure bugs sneaked their way in, unfortunately I've been too busy with client work recently to iron them out.\nHoping to get them sorted next week so a new release should be out very soon.. I support this change but just wanna point out potential breakage.\nAny existing user code like:\njs\nif (err.statusMessage === 'Too Many Requests') {\n  handleAPILimit();\n}\nwill fail after this change if the API returns it's own error message.. This is probably what you're looking for:\nhttps://github.com/sindresorhus/got/blob/0c5e44ce3cdb0e274fcb0e3d68cd9df297baf1ce/index.js#L461-L464. @sindresorhus Ok, I think I might know what's causing the cancel test to intermittently fail.\nI think it's because on Travis (with AVA concurrency at 4 but only one thread available) any extra async code introduces significant overhead. Because the thread is tied up with four processes, simply calling Promise.resolve(value).then(fn) means fn has to wait until the thread is free again which could be a while. In most production environments this would take milliseconds but in our specific CI environment this could potentially be in the hundreds of milliseconds due to the thread being overworked.\nI think possibly the extra overhead of the Promises introduced in the cache option code is enough to (sometimes) break the cancel tests because it relies on a setTimeout(fn, 100) for the stream to be established before cancelling it.\nThis is supported by the fact that increasing to setTimeout(fn, 500) means that the tests consistently pass. I've re-ran the Travis build about 30 times and tests passed every time.\nWith setTimeout(fn, 100) roughly every 1 in 5 Travis builds failed.\nI'm not 100% sure this is the reason why but it seems to make sense. Hopefully the commit messages help you understand how I reached this conclusion.\nWhat are your thoughts?. Also, for whatever reason, the Travis builds don't seem to be showing up for every commit in this PR. You can view the identical PR on my repo for all the commit builds: https://github.com/lukechilds/got/pull/1. > Sorry for writing a flaky test \ud83d\ude48.\nHaha, it's a pretty odd edge case, I'm still not 100% sure that's the reason.\n\nYou could consider returning a connection event emitter from the abort server too if it turns flaky again.\n\nI like this solution, if that works we can be pretty sure the problem won't come back again. I'll give it a bash now.. Ok, so ensuring we reliably wait for the connection via listening to an event as opposed to setTimeout definitely seems to resolve the issue.\nJust ran the most recent Travis Build another 30 times without any test failures.\n\nI think this can be merged.. One potential side effect to be aware of, especially if we're thinking of enabling this by default:\nConsider you reach the request limit quota for the API you're using and they return 429 Too Many Requests with a Retry-After header set for when your quota resets next month.\nThis would mean, if we by default retry 429s and respect Retry-After, that making a request with Got to your API once you've hit your quota would return a Promise that may not resolve for up to 30 days in the future.\nThat doesn't seem very intuitive and could cause bugs that would be a nightmare to track down.\nThis seems like a great feature but might be better as opt in or not whitelisting 429.. My understanding from the .travis.yml was that all maintained LTS releases are supported. Is that correct @sindresorhus?\nIf so, when 4.x reaches EOL (end of this month) we'll drop support.\nAnd when 10.x is released (sometime this month) we'll add support.\n\nEdit: I'm guessing we'd be looking to target 6 as a minimum version next, not 8?\n\nYeah, at some point this month we should be supporting:\nyml\nnode_js:\n  - '10'\n  - '8'\n  - '6'. And drop support for 6? Great.\nObject spread all the things!. @rarkins Yeah sure, nice work on Renovate btw!\n\n\nIf queries are made for the exact same package (URL) twice within 5 minutes, will the second receive an answer directly from cache, or only after a conditional query with 304 response?\n\n\nWe follow RFC 7234 so if the cached response is still valid it'll be pulled directly from the cache. If the cached response has expired we send an If-Modified-Since/If-None-Match revalidation request, then if we get a 301 response the cached body is used (with updated headers from the request), if we don't get a 301 then the cached response is deleted and the new response is returned.\n\n\nWill cached values ever \"expire\", or will they remain in cache indefinitely for use in If-Modified-Since and If-None-Match headers in future?\n\n\nAs far as Got is concerned they will be stored indefinitely for future use with revalidation requests. If a request fails to be revalidated it will be deleted. However all storage is controlled by Keyv, so you can back Keyv with an LRU cache to limit it to a certain size/number (e.g quick-lru, Redis).\nYou can read more about the cache functionality on the underlying cache module's repo: https://github.com/lukechilds/cacheable-request\n@sindresorhus Do you think it'd be worth giving a brief summary of the supported caching behaviour and referring people to cacheable-request for more info in the readme?\nCurrently we only mention it's \"RFC compliant\" without going into any detail on what that covers. Somebody on Twitter also asked for more clarification.. I can recreate the issue, it's being caused by this line:\nhttps://github.com/sindresorhus/got/blob/974473aadb2f43a7feacfd0e9246af8690ac016e/index.js#L229\n\nHave I done something incorrectly?\n\nNope, we just released v8.0.0, one of the new features was progress events (introduced in #322) which uses request.connection to listen for the socket connection. Looks like browserify's http polyfill doesn't support request.connection.\n@sindresorhus We could easily stop errors in browsers by just testing request.connection exists before using it. Not sure if the browser is actually an intended target though, do you want a fix for this?. Good point, I'm not sure if browser APIs expose enough to implement request.connection though. It gives access to the underlying socket.\nI'll take a proper look tomorrow.. Yeah, I've had a look and I don't think there's a reliable way to implement request.connection in the browser.\nWe could probably implement the functionality we need for progress with browser APIs and expose it through request.connection which would work for our specific use case. But then all Browserify targets would have a half implemented request.connection which is probably worse than no implementation at all.. @zckrs @NotteJacob are you guys getting the exact same error as @austinfrey?\nUncaught TypeError: Cannot read property 'once' of undefined\n    at EventEmitter.ee.once.req ...\nBecause that's caused by the Browserify http shim and shouldn't occur in Node.js.\nBugs caused by using with p-map or opts.agent should be totally unrelated. Can you open a separate issue if you have a different error.. > Maybe cacheable-request return sometime a req without connection pprt.\n@zckrs Spot on! Sorry, I totally overlooked that. request.connection is a reference to the network socket. If a response is returned from cache we obviously can't return a reference to a socket (there is none).\n@NotteJacob That still doesn't explain the agent issues you're experiencing though.\nCan you guys test this branch? It should resolve your problems.\nhttps://github.com/sindresorhus/got/pull/429. @zckrs cany you just confirm, you have cache enabled right?. Hmmn, ok, are you able to provide me with a reproducibe code example?. Ok, this is going to be quite difficult to fix without being able to reproduce.\nAlso, just to clarify, the issues you are experiencing (@NotteJacob and @zckrs) are completely seperate from the original post. It's the same property that doesn't exist but in a browser it's not expected to exist. In Node.js it should (unless coming from the cache). So #429 isn't a valid solution, it's just surpressing the errors.. @zckrs @NotteJacob Are either of you interested in putting a fully working reproducible scenario together for me?\nWould love to get this fixed for you but I'm limited in what I can do without a repro.. @NotteJacob Thanks!. Thanks for the extra info @destroyerofbuilds.\nIs it only a certain url/scenario that gives you the error or does it always occur unless you add {agent: ''}?\nI'm limited on how much time I can spend on OSS at the moment, however this is high on my list of OSS priorities so hopefully will get a chance to look further into this very soon.. @sindresorhus This is obviously causing a lot of problems for people. I'd recommend we merge #429 to suppress the issue.\nIt will stop the errors but obviously progress events will not work in these scenarios.\nI would like to spend more time in the future to figure out exactly why request.connection sometimes doesn't exist on Node.js but unfortunately I don't have the time right now.\nMy gut feeling is that certain proxy agents are manipulating/recreating request and not updating/adding the connection property. This is incompatible with the new progress events introduced in #322.\nIf that's the case it may even be that #429 is the only valid solution and we should just document that progress events won't work with some proxy agents.. req.connection also sometimes appears to be missing in Node.js when Got is used with a proxy agent.. It's a tricky one, if you're expecting non 200 responses it is currently kind of awkward to handle. But returning the error could cause some serious confusion if you end up accidentally passing an error to code that's expecting a response object and vice versa. The only way to cater for that would be to check whether you've got a response or error first, but then that's not much cleaner than try/catch.\nOne alternative solution could be to have an option to not throw on bad HTTP response codes at all, just return the response and let the user handle the status code. That seems like a more generic solution that would be helpful for more use cases.\nSomething like:\n```js\nawait got('/500-error');\n// throws Error\nawait got('/500-error', {throwHttpErrors: false});\n// returns response object with 500 status code\nawait got('/network-error', {throwHttpErrors: false});\n// throws Error\n``. Thanks!. WilldecodeURI()` only ever throw if the URI contains non UTF-8 chars?\nIf there are any other circumstances that could cause it to throw then it might be worth either purely checking for non UTF-8 chars or changing the error message to \"valid URI\".\nHowever it looks like we're ok:\n\nThrows an URIError (\"malformed URI sequence\") exception when encodedURI contains invalid character sequences.\n\nhttps://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/decodeURI. Is the server definitely returning UTF-8 encoded text?\nCheck this: #396. > This still could be an issue with Electron.net not behaving in the same way as node's http, but I'm getting a bit lost trying to track down where it goes wrong.\nYeah, that's the issue.\nThe parseCacheControl() function is called like this:\njs\nparseCacheControl(res.headers['cache-control']);\nres.headers should be a \"Key-value pairs of header names and values.\". If Electron is returning an array for res.headers['cache-control'] then it's behaving completely differently to the built in HTTP client.\nIn Got 8 we introduced two big features, progress events and caching, that rely on lower level HTTP functionality. We've noticed quite a few problems (#315) with electron.net which is why it's now disabled by default. I'd recommend not setting useElectronNet to true unless you absolutely need it until it has better compatibility with Node.js.\nAre you also able to open an issue on Electron about strange header behaviour?. Thanks for the detailed description, if you can provide some code reproducing the error I'll take a look as soon as I can.. The underlying implementation Got uses is here: https://github.com/lukechilds/cacheable-request\nAs far as I'm aware it follows RFC 7234 exactly. If the caching behave's differently to how you want then either:\n\nRFC 7234 caching is not what you want to do, in which case you should disable Got's built in caching and implement your own custom cache logic.\nThere is a bug in my RFC 7234 implementation and it's not behaving correctly.\nThere is a bug in the server's RFC 7234 implementation and it's not behaving correctly.\n\nIf you can provide some test code and tell me how you're expecting ti to behave and what it's doing instead I can tell you which one of those is happening. And push a fix if it's 2.. @reggiezhang Do you still get the same issue if you use got instead of got.stream?\nIt's possible that you're consuming the stream before I get a chance to copy it which would also explain the apparent random occurrence.. cacheable-request@6.0.0 published which I think should resolve this. I'd be grateful if anyone who was encountering the issue could test this.\n@szmarczak @sindresorhus We'll obvs need to update cacheable-request in Got to get the major version so might be better if we can get some users to test this before we pull the trigger.\nIt is also technically a breaking change due to the fact it changes the API, but only at a very minor level that people shouldn't really be relying on anyway. So although it's unlikely to cause any issues, if we update Got to use this version we should probably major bump Got too.. https://github.com/sindresorhus/got#body. Can you provide some runnable code reproducing your problem.. >What happens to an object in body, does it get JSON stringified or turned into querystring or something?\nNothing happens to it, that's why you're getting errors.\nThe supported types for the body property are listed in the docs: https://github.com/sindresorhus/got#body. Because you're just re-downloading the file on every request and piping it through. Got is functioning as expected.\nIf you want to allow partial downloads for simultaneous download connections or resumable downloads you need to implement range requests in your application code or use a proxy lib that does this for you.\nHelpful links:\nhttps://en.wikipedia.org/wiki/Byte_serving\nhttps://tools.ietf.org/html/rfc7233. Do you think it would be worth mentioning create-test-server here?\nThe official Got tests will actually be using this once #387 is merged.. Yeah, perfect \ud83d\udc4c. Hang in there Node.js 4 is EOL in April \ud83d\ude4f. Let me know if there's anything I can do in cacheable-request.. Thanks for reporting with details. Definitely looks like an issue with cacheable-request. Would you mind reporting this over there?. @bdougherty sorry, I've been really busy on other projects recently. I'll have some free time coming up soon, if you can reproduce this error with cacheable-request and create an issue over there with an example I will get this resolved.. @aoberoi Woops, this slipped under the radar, looks good to me.\n@egorovli Thanks for tracking down the issue! Apologies for the delay.. I'm quite busy no another project right now so I haven't reviewed the code in depth, but I really like the idea.\nMuch nicer than having to manually create a wrapper function and should make writing API clients with Got simpler too.. @jstewmon what OS are you on?\nDo cacheable-request tests pass for you?. Sorry, autoclosed due to merging https://github.com/lukechilds/cacheable-request/pull/55\nRe-opened.. @szmarczak Released your fix in cacheable-request@5.0.0.. This should be resolved now as of cacheable-request@5.2.1.. \ud83d\udc4c. Woops, sorry, completely missed that.\nEncoding should be set to null internally if decompress is false. I'll update.. Fixed and updated test in https://github.com/sindresorhus/got/pull/320/commits/c99b2500f46673fd4ffa13d8e0e698d6d4b74e50. facepalm. Of course, sorry.\nWhat's the best solution here?\nCopy/paste:\njs\nif (['gzip', 'deflate'].indexOf(res.headers['content-encoding']) === -1)\nstraight from decompress-response?\nOr maybe publish it separately as responseIsGzipped() and require in both Got and decompress-response so they're both in sync?. Fixed. Also added test to check opts.decompress doesn't alter encoding of uncompressed responses.. @sindresorhus is !opts.decompress ok here? It's a boolean. Or should I do opts.decompress === false?. @kevva Done \ud83d\udc4d\nWhy is for of preferable over forEach?. There's a lot going on in this line and it's inconsistent with the rest of the codebase.\ne.g forEach instead of for...of, && instead of if.\nI would suggest the following for better readability and consistency.\njs\nfor (const key of Object.keys(headers)) {\n  if (headers[key] === null || headers[key] === undefined) {\n    delete headers[key];\n  }\n}. cacheable-request could potentially emit more than one error. These should be passed through.. This is fine, we can only reject once, so we should do it on the first error.. cacheable-request could potentially emit more than one error. These should be passed through.. Yep, all good.. ",
    "yanivefraim": "@floatdrop - thanks for answering. I'm not using got directly. I'm using Yeoman's inquirer-npm-name, which uses npm-name, which uses got...\nThe final result is, that when I ask the user for npm module name, inside my Yeoman generator, and for some reason connection to npm fails, the UI gets stuck (with no timeout).. @floatdrop - yes, thanks!\n. ",
    "nathantbaker": "Thanks, the feedback is appreciated. Cheers.. ",
    "frenchbread": "+1. ",
    "jkeczan": "@reconbot I appreciate the response.\nMy code works with this path: GET /fs-test\nMy code does not work with GET or POST /fs-test/_search\nI am using an almost exact approach from your http-aws-es module.....\n```\n'use strict';\nlet AWS = require('aws-sdk');\nlet aws4 = require('aws4');\nlet bole = require('bole');\nlet got = require('got');\nlet bluebird = require('bluebird');\nconst url = require('url');\nconst logger = bole('es-client');\nconst region = process.env.region;\nconst host = process.env.host || 'es-search.domain.com';\nconst awsConfig = new AWS.Config({region});\nfunction request(options) {\n    const opts = Object.assign({\n        host,\n        region: awsConfig.region,\n        protocol: 'https:',\n        headers: {\n            'Content-Type': 'application/json',\n            'Access-Control-Allow-Origin':'*'\n        },\n        json: true\n    }, options);\n    aws4.sign(opts, awsConfig.credentials);\n    const method = opts.method;\n    const path = opts.path;\n    console.log({method, path, host}, 'Performing request'); //this line outputs EXACT as you would expect and works without a /_search\n    return Promise.resolve(got(opts)).then(resp => resp.body)\n}\nconst es = {};\nconst METHODS = [\n    'get',\n    'post',\n    'put',\n    'delete'\n];\nMETHODS.forEach(method => {\n    es[method] = (path, body) => request({\n        path,\n        method: method.toUpperCase(),\n        body: JSON.stringify(body)\n    })\n});\nes.bulk = ops => request({\n    path: '/_bulk',\n    method: 'POST',\n    body: ops.map(op => ${JSON.stringify(op)}\\n).join('')\n});\nes.getRecord = function(index, type, id) { console.log(index, type, id); es.get(${index}/${type}/${id}); };\nes.indexRecord = function(index, type, id, body) { console.log(index, type, id); es.put(/${index}/${type}/${id}, body); };\nes.deleteRecord = function (index, type, id) { console.log(index, type, id); es.delete(/${index}/${type}/${id}); };\nmodule.exports = es;\n```. ",
    "pgiani": "Thanks \n. ",
    "hugohil": "I leave that here because it can help people facing similar issue.\nI was having an issue with the got module (through vue-resource) like this:\nERROR in ./~/got/index.js\nModule not found: Error: Can't resolve './package' in '/path/to/project/node_modules/got'\nI found that the issue was caused by webpack not resolving the extension automatically, so I added this to my webpack.config.js file:\nresolve: {\n    extensions: ['.js', '.json']\n}\nso now I can omit the .json extension when I require() a module.\nHope this helps someone :). ",
    "GabrielDuarteM": "@hugohil Sir, you helped me a lot with this, i was having this './package' error, and your fix solved it!. ",
    "ryderlee": "But it doesn't make sense isn't it? It is so common to make a post call and then do a 302 redirect.\n. ",
    "kvz": "You don't have to repost tho right? \nConsider the flow of:\n\nPOST username & password to server /login\nServer accepts and 302 forwards to /dashboard\nprofit\n\nWhen followRedirect is enabled, I'd expect got not to repost the credentials to /dashboard, but i do expect it to return the body of the dashboard. Currently for me, it also is an error (HTTPError at stream.catch.then.data (/Users/kvz/code/api2/crm/node_modules/got/index.js:123:13) at process._tickCallback (internal/process/next_tick.js:103:7) message: 'Response code 302 (Found)', host: 'www-vbox.transloadit.com', hostname: 'www-vbox.transloadit.com', method: 'POST', path: '/accounts/login/sso:heroku', statusCode: 302, statusMessage: 'Found'). Does this make sense or no?. Thanks for clarifying. I think I can easily change to 303 on our end, so i'll be tracking that PR and upgrading when I can. Thanks again!. ",
    "vardrop": "request-promise has the option simple: false which changes the expected behaviour for 3xx responses. \nas got does not have this option it makes it impossible to use for request as an drop-in alternative.\nEDIT: nvm, i figured that when you do a post to the location of the 302 it should work. ",
    "cgrossde": "@sindresorhus I agree that this is webpack not following require convention. However you would do me a big favour in merging this. It would be an easy fix for anyone using webpack with your package. It could be weeks until webpack fixes this. It also has no effect on your code.. @TheLarkInn, damn you are right. I was migrating vom webpack v1 to v2 and never thought of adding new extensions, just removed the empty one.\nBefore (webpack v1):\nresolve: {\n    extensions: ['', '.js', '.jsx', '.scss']\n  },\nAfter (webpack v2) - results in the mentioned error:\nresolve: {\n    extensions: ['.js', '.jsx', '.scss']\n  },\nSolution:\nresolve: {\n    extensions: ['.js', '.jsx', '.scss', '.json]\n  },\nSry guys, was working on it after a long day at work. Missed the obvious.. ",
    "TheLarkInn": "@sindresorhus what part of the pattern is off? . Um so webpack does have extentions for .js and .json by default (in that respective order). @cgrossde can you please share your webpack config for me, I have a suspicion that you have resolveExtentions overrides incorrectly. @sindresorhus thanks fur the ping \ud83d\udc36. @cgrossde no prob you can always check webpack.js.org/configuration to see the defaults. In this case the array is an complete override so order is important. . ",
    "TayBill": "Ran into this problem with an Angular2 based app, the angularcli, and default assumptions about webpack.  The recommended approach was was run ng eject to generate a non default webpack config file.  That all worked, but ended up making big changes to my package.json.  The changes were big enough that I'm not going to continue with this approach.  Bottom line:  It sure would be nice if this  merge request (changing from package to package.json) was accepted.  It would make things a lot simpler.  See also #285 . ",
    "quocnguyen": "I did wait for response with the following code\n```\nconst s = got.stream(TARGET_URL, { headers })\ns\n  .on('error', handleError)\n  .on('response', (response) => {\n    res.statusCode = response.statusCode\n    Object.keys(response.headers).forEach(key => {\n      res.setHeader(key, response.headers[key])\n    })\ns.pipe(res)\n\n})\n```\nbut still got error Error: Can't set headers after they are sent. not sure what I did wrong in these lines of code.\nAlso I don't get the part  only after call send  what does it mean ?. I think my problem is when the underlying res closed, got duplexer stream still continue buffer up and pipe to res. I will set up a example code when I got free time. I solve it by abort request when res close event emit.\nThank you for this great lib, I learn a lot about duplexer stream and stuffs through got.  \ud83d\udc4d . ",
    "sonicdoe": "I have taken a look at a few other HTTP client libraries which do something similar. To give an overview:\n\nrequest just logs a debug message (see also https://github.com/request/request/issues/440)\naxios ignores parsing errors (see also https://github.com/mzabriskie/axios/issues/61)\nUnirest ignores parsing errors (see source)\nhttparty parses based on Content-Type (see docs/README.md#parsing-json)\nFaraday parses based on Content-Type but also tries to parse JSON-like responses (see source)\nTesla parses based on Content-Type (see source)\n\nThis is also related to #168 (automatic parsing based on Content-Type) as it would solve this issue with, at least, Travis CI\u2019s API because it actually returns the correct Content-Type.. > In all the other cases, if an error status code is returned like 4xx or 5xx, it should try to parse the response (if json is set to true), if it fails to parse the response, it should throw an HttpError with the unparsed body.\nI don\u2019t think ignoring parsing errors (even only on error responses) is a good idea. This leads to errors like https://github.com/mzabriskie/axios/issues/61#issue-68540010.\nI\u2019m still undecided but I would like to float the following idea by you:\njs\ngot('https://api.travis-ci.org', {\n  parse: res => {\n    if (res.statusCode === 403) return res.body\n    return JSON.parse(res.body)\n  }\n})\nThis builds upon @AlexTes\u2019s proposal in https://github.com/sindresorhus/got/pull/264. This would make sure that the user knows what to expect for body in case of 403 Forbidden but still allows a ParseError to be thrown on, for example, 400 Bad Request.. Of course, done.. As mentioned by @brandon93s in https://github.com/sindresorhus/got/issues/397#issuecomment-403233339, this should be working now. I\u2019ve tried the example in the original post with got v8.3.2 and Electron v2.0.4 and it worked \ud83d\udc4d. ",
    "antony": "A bit of further clarification which might be useful.\nThe error comes from nock throwing an Error due to a non-matching request. The line which then tries to turn that into a got.RequestError is here:\nhttps://github.com/sindresorhus/got/blob/master/index.js#L73\nand it fails because err is a generic Error object:\n```\n{ Error: Nock: No match for request {\n  \"method\": \"POST\",\n  \"url\": \"https://xxx.yyy\",\n  \"headers\": {\n    \"user-agent\": \"got/6.7.1 (https://github.com/sindresorhus/got)\",\n    \"accept-encoding\": \"gzip,deflate\",\n    \"authorization\": \"Basic aaa:bbb\",\n    \"accept\": \"application/json\",\n    \"content-type\": \"application/x-www-form-urlencoded\",\n    \"content-length\": 7\n  },\n  \"body\": \"foo=bar\"\n}\n```. Hi @AlexTes \nThanks for the swift response!\nI think I found out what it is - but unfortunately it does still indicate a problem in got.\nWhen a route doesn't match in nock, nock throws an error to say that there is no match.\nWhat happens is that got tries to add info to this error, and fails, and ends up throwing the error I listed above - which isn't useful because there is no indication that the route didn't match - the error gets swallowed.\nThere should be a check before trying to append to errors, and potentially wrapping an existing error before trying to append to it would be a good fix.. Hi Alexander,\nOf course! I'll try to create a sample project, sorry :)\nCheers,\nAntony\nOn Fri, 10 Mar 2017, 10:42 Alexander Tesfamichael, notifications@github.com\nwrote:\nI think one of us is confused about the interplay of nock and got. I don't\nthink got can catch nocks errors, unless nock isn't acting like a server in\nthe way I thought. Whatever the response is, got should be able to turn it\ninto an error without issue. I'll try your scenario: pointing got at a\nroute that doesn't match but somehow still gets caught by nock.\nAgain, it would be helpful if you supplied the code that demonstrates this\nbehavior!\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/sindresorhus/got/issues/279#issuecomment-285636684,\nor mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AANXRV8IN2R5HlLgkYYpfciT8q4107Rnks5rkSj0gaJpZM4MYGR2\n.\n. Took me a while - here is a demonstration of the problem. The thing to note is that I'm trying to log errors, and then re-throw them to the catching code.\nhttps://github.com/vendigo-group/got-problems\nAs you can see, the nock errors are swallowed, and the result is a test fail. The error of the fail is thrown from the got code.. In hindsight... I think I might have figured this out.\nOur old library request-promise allowed bluebird as a promise library. I'm using a multiple-catch, which native promises do not support. I think this can probably be closed!. That is an excellent idea - I'd not considered that approach. Thanks!. ",
    "utter-step": "Found error.request, sorry.). ",
    "jotto": "Echoing the comment here: https://github.com/sindresorhus/got/issues/281#issuecomment-288059738\n\nI'd prefer the second, needs more documentation but keeps got tiny.\n\nI'd like to gently point out that got is currently 0.16M, but if cacheable-request is added, it gains 0.39M (0.53M total). My favorite thing about got is how tiny it is.. @lukechilds I used https://github.com/siddharthkp/cost-of-modules\nSize of npm package is, historically not an issue, but suddenly more important since \"serverless\" AKA function as a service (AWS Lambda etc.) has some size constraints.. I really just wanted cancel fixed so I could do this:\njavascript\nconst got = require(\"got\");\nconst req = got(\"http://localhost:3000\", { retries: 0, timeout: 100 });\nreq.catch(err => {\n  if (err.name === \"RequestError\" && err.code === \"ETIMEDOUT\") {\n    console.log(\"request timed out, canceling\");\n    return req.cancel();\n  } else {\n    return Promise.reject(err);\n  }\n});\nso I think I agree from the comments in #344 that a timeout should automatically call cancel, I just didn't want to make any behavior changes in the interest of getting this through sooner than later.. diff with whitespace removed: https://github.com/sindresorhus/got/pull/364/files?w=1. I'm so far unable to reproduce this from the got repo itself (hence no tests), but when running from a separate directory where got is a dependency - the snippet from the description can reproduce it.. > Are you running master version of Got from that directory?\nbash\nmkdir got-test\ncd got-test\nyarn add got\nwhich results in a package.json of:\njson\n{\n  \"dependencies\": {\n    \"got\": \"^7.1.0\"\n  }\n}. oh, I see now. Thank you @AlexTes! Sorry for the misunderstanding.\nSo may I gently ask for a release of master?. > Yes, I'm planning a new release very soon. I just didn't want to do one yet as I've been busy and wouldn't have had time to deal with potential issues the new version.\nvery gentle bump/ping. ",
    "mcjohnalds": "While got does work in the browser, it uses ES6 syntax along with some of its dependencies, which means you have to add some of your node_modules directories to babel's includes to work in the browser. Though I wouldn't recommend this as it increases build time and breaks easily.. ",
    "ghost": "How about on react-native? Is it possible to implement there?. I recently ran into the same issue reported by @zckrs and @NotteJacob while using a tool called renovate on a RHEL 7 system using Node 9.3.0.\nThe error message I receive is:\n```bash\n/app/node_modules/got/index.js:230\n                req.connection.once('connect', () => {\n                               ^\nTypeError: Cannot read property 'once' of null\n    at EventEmitter.ee.once.req (/app/node_modules/got/index.js:230:20)\n    at Object.onceWrapper (events.js:254:19)\n    at EventEmitter.emit (events.js:164:20)\n    at Immediate.setImmediate (/app/node_modules/got/index.js:265:8)\n    at runCallback (timers.js:773:18)\n    at tryOnImmediate (timers.js:734:5)\n    at processImmediate [as _immediateCallback] (timers.js:711:5)\ninfo Visit https://yarnpkg.com/en/docs/cli/run for documentation about this command.\nerror Command failed with exit code 1.\n```\nIf I set the agent property to an empty string, (Found in renovate here) I no longer receive the error:\nbash\n$ git diff HEAD~1\ndiff --git c/lib/manager/npm/registry.js w/lib/manager/npm/registry.js\nindex ec5531c..34a06ee 100644\n--- c/lib/manager/npm/registry.js\n+++ w/lib/manager/npm/registry.js\n@@ -55,6 +55,7 @@ async function getDependency(name) {\n       cache: map,\n       json: true,\n       headers,\n+      agent: ``,\n     })).body;\n     // Determine repository URL\n     let repositoryUrl;\nI also tried removing the cache option, and not setting agent, but I still received the same error. Setting agent to an empty string seemed to be the only way to avoid the error.\nI have not tried #429, but I assume that because it checks for req.connection that it would work to resolve the issue I am encountering.. > Is it only a certain url/scenario that gives you the error or does it always occur unless you add {agent: ''}?\nThe URLs are all requests to an Artifactory deployment that's acting as a proxy to the npm registry. The URL requests are of the form:\n* http://artifactory.example.com/artifactory/api/npm/npm/npm-publish-git-tag\nI haven't been able to figure out which request is actually causing the crash (Requests are in parallel, and I can't reproduce this issue myself locally; only seeing this issue in a server environment). As soon as setImmediate is called on line 265, a connection property is available on the request object in all but a few cases.\nThe following URLs had undefined connection properties:\n http://artifactory.example.com/artifactory/api/npm/npm/watchify\n http://artifactory.example.com/artifactory/api/npm/npm/winston\n* http://artifactory.example.com/artifactory/api/npm/npm/yargs\nI ran the following code through a tight loop (1000 simultaneous requests) to see if I could replicate the issue:\njavascript\n  got(`http://artifactory.example.com/artifactory/api/npm/npm/watchify`, {\n    json: true,\n    headers: {},\n  });\nThe options passed to got are identical to those used in Renovate (where I can replicate this issue).\nSo far I haven't been able to replicate the issue using the code above.\nI also discovered that I only encounter this issue when using Renovate and an Artifactory proxy. I cannot replicate this issue using Renovate and the standard npm registry.. ",
    "calebmer": "Here is an example in RunKit: https://runkit.com/58e023b82830330014a733fb/58e0300e2830330014a73666 (although I\u2019m sure they have a timeout of their own for the Node.js process). Ah, sorry for not investigating further! I assumed that got had a timeout by default (which is not a safe assumption). In the code I\u2019m actually running I have a generous timeout set (10s) with 5 retries and I didn\u2019t do the exponential retry math. I let it run for about one and a half minutes and didn\u2019t see any timeout errors, so I tried to reproduce and didn\u2019t set out a timeout in my reproduction.\nSorry about that \ud83d\ude0a. ",
    "mautematico": "\n31 to 36 seconds to timeout.\n\nthat number is exactly what I was looking for. Why is that (so high)? can it be overriden?. ",
    "pioul": "\ud83d\udc4d @sindresorhus Of course! Just realizing now that there's a bit of doc I haven't updated if you want to quickly add a line there: https://github.com/sindresorhus/got#errors\nBy the way, how often are you releasing? I'd love to take advantage of that addition in a dependent (probe-image-size) once the next release is out :). Thanks, sounds great!. urlParseLax returns null for all properties that weren't parsed, so protocol: null used to take over the default protocol: 'http:' all the time for protocol-less urls; this change remedies that.. ",
    "starburn": "I just needed to say that options.body being an object instead of a string made my day. Thank you for the awesome module.. I tracked it down into Electron's IPC code. It seems to be the perfect storm between get-stream and Electron's _writable_stream.js and remote calling .write() with global scope instead of the steam instance. This is probably Electron's job to fix.. Root of the problem and its fix.\n```JavaScript\nconst stream = require('stream')\nconst {net} = require('electron').remote\nconst request = net.request('https://example.com');\nrequest.on('response', (response) => {\n  const str = new stream.PassThrough()\n  str.write = str.write.bind(str)\n  str.once = str.once.bind(str)\n  str.end = str.end.bind(str)\n  str.on = str.on.bind(str)\n  response.pipe(str);\n})\nrequest.end()\n``. Movinggotout of the renderer was going to be unrealistic, so now I just have theuseElectronNetoption hardcoded everywhere I usegot. If someone else's package is usinggot`, that'll be a different story.. ",
    "avimar": "@sindresorhus Where is that changelog? I see you're talking about breaking changes but I can't find a list. (Semver of breaking changes since my current version 6.5...)\nThanks!. Thanks, got it! (Was expecting a CHANGELOG file like many projects have now.). ",
    "djmadeira": "@sindresorhus addressed comments.. Fails on node4, which shouldn't be a blocker for changes to 7.0.0 release.. From RFC 7231:\n\nThe 303 (See Other) status code indicates that the server is\nredirecting the user agent to a different resource, as indicated by a\nURI in the Location header field, which is intended to provide an\nindirect response to the original request.  A user agent can perform\na retrieval request targeting that URI (a GET or HEAD request if\nusing HTTP), which might also be redirected, and present the eventual\nresult as an answer to the original request.  Note that the new URI\nin the Location header field is not considered equivalent to the\neffective request URI.\nThis status code is applicable to any HTTP method.  It is primarily\nused to allow the output of a POST action to redirect the user agent\nto a selected resource, since doing so provides the information\ncorresponding to the POST response in a form that can be separately\nidentified, bookmarked, and cached, independent of the original\nrequest.\nA 303 response to a GET request indicates that the origin server does\nnot have a representation of the target resource that can be\ntransferred by the server over HTTP.  However, the Location field\nvalue refers to a resource that is descriptive of the target\nresource, such that making a retrieval request on that other resource\nmight result in a representation that is useful to recipients without\nimplying that it represents the original target resource.  Note that\nanswers to the questions of what can be represented, what\nrepresentations are adequate, and what might be a useful description\nare outside the scope of HTTP.\n\nMy reading:\n\nCan apply to any request method, including GET\nWhen in response to GET, means the server can't represent the entity over HTTP, but something descriptive of the entity can be found at the Location header\n\nBased on this, maybe we should have some kind of error response specific to receiving a 303 in response to a GET? Since clients may need to make a decision about how to proceed.\nWhile we're on the topic, according to the spec, we should probably do something similar in response to a 300:\n\nThe 300 (Multiple Choices) status code indicates that the target\nresource has more than one representation, each with its own more\nspecific identifier, and information about the alternatives is being\nprovided so that the user (or user agent) can select a preferred\nrepresentation by redirecting its request to one or more of those\nidentifiers.  In other words, the server desires that the user agent\nengage in reactive negotiation to select the most appropriate\nrepresentation(s) for its needs (Section 3.4).\nIf the server has a preferred choice, the server SHOULD generate a\nLocation header field containing a preferred choice's URI reference.\nThe user agent MAY use the Location field value for automatic\nredirection.\nFor request methods other than HEAD, the server SHOULD generate a\npayload in the 300 response containing a list of representation\nmetadata and URI reference(s) from which the user or user agent can\nchoose the one most preferred.  The user agent MAY make a selection\nfrom that list automatically if it understands the provided media\ntype.  A specific format for automatic selection is not defined by\nthis specification because HTTP tries to remain orthogonal to the\ndefinition of its payloads.  In practice, the representation is\nprovided in some easily parsed format believed to be acceptable to\nthe user agent, as determined by shared design or content\nnegotiation, or in some commonly accepted hypertext format.. Actually not sure what I would update in the README, except maybe the surprising behavior of changing from POST/PUT/DELETE to GET on a 303 response? Seems like a case for a changelog entry if one existed.. @sindresorhus updated README. 300 redirects are already followed; my question was whether, since the spec describes a 300 response as containing multiple choices, we should throw an error in this case so the consumer has a chance to decide which resource to request next.. @floatdrop so should we just name the option gotTimeout?. @floatdrop @AlexTes addressed comments.. @sindresorhus @floatdrop addressed comments.. \n",
    "simoncpu": "Thank you for this contribution. I spent a few hour struggling to find out why I wasn't catching the timeout errors, so I resorted to reading the code. Lo and behold, a fix was merged on v7.0.0 so all I had to do was update my version of got. Thanks, man! =). ",
    "Flackus": "-Milliseconds to wait for a server to send response headers before aborting request with `ETIMEDOUT` error.\n--\n+Milliseconds to wait for the server to end the response before aborting request with `ETIMEDOUT` error.\nIt should have been a major release probably :(\nWe now have (although already fixed) an issue with our module, which is designed for downloding big chunks of data, and it was handling \"connection\" timeout via got and the whole \"download\" timeout separately on it's side.\nAfter 6.7.0 got's timeout: 2000 suddenly became the timeout for the whole request and everything went crazy.. ",
    "overlookmotel": "I've just published a module that uses got and resumes after network errors: https://www.npmjs.com/package/got-resume\nIf a request fails, the next request picks up from where the last one left off, using HTTP range headers.\nIt's designed for downloading large files where network errors are common.. Any thoughts on this?. ",
    "silentroach": "Why not retry requests if no input streams used? For example I use got to stream the response from server to parser.. @szmarczak what about \"bad\" response status/codes? it will throw before I will get any data.. sad :{\nthank you for explanation. ",
    "geosh03": "Indeed you are correct. I'm starting to see the issue is with mailgun-js. Thank you for your comments. . ",
    "wayneashleyberry": "I'm using node v7.10.0. @kevva out of interest, why? I've used a ton of promises without chaining like that before.. ",
    "lselden": "No, I'm testing out code by requiring from the Atom developer tools. I'm using a customized version of https://github.com/douglascalhoun/eval-javascript to eval code on the fly. It's admittedly an edge case, but might be relevant to plugin developers.. Specifying the useElectronNet: false option worked. Without specifying that option it failed.\nI think the issue is that the electron version in the current build of atom is 1.3.15, and it looks like the .net module was only added in v1.4 (judging by v1.3 vs v1.4 docs.. ",
    "marwenlandoulsi": "hi @sindresorhus \ndid you find any solution. i have the same issue :(. ",
    "framerate": "Looks like I was seeing it too, damn #397 . Ok thank you!\nOn Aug 19, 2017 5:09 PM, \"Alexander Tesfamichael\" notifications@github.com\nwrote:\n\nNot released yes @framerate https://github.com/framerate \ud83d\ude09 .\nYou need to take a look at the latest released README. Either through the tagged\ncommit https://github.com/sindresorhus/got/tree/v7.1.0#readme or npm\npage https://www.npmjs.com/package/got.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/sindresorhus/got/issues/361#issuecomment-323547859,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAEiM48nOomz4py6Yyfn2P1zI61Cvo9xks5sZ07vgaJpZM4O8b_e\n.\n. #366 just popped up too, @AlexTes, if you have any info on how we can help wrap up the latest release! Seems like people really want the feature! :). I'm also curious what the status of the new release is! Is there a roadmap we can see or somehow we can help finish it?. UPDATE:\n\nI tried using request instead.\nconst request = require('request');\n    request('https://s3-us-west-1.amazonaws.com/scl-cdn/doomtrooper/assets/video.md5').pipe(fs.createWriteStream(path.join(__dirname, '/fuckyou.md5')));\nprints b05eea1123e1b191dc4aa198ec62422f to file. \nThis seems to be a bug in got... Help!. > Does tweaking this option help?\nUnless I'm misreading the README, it appears that option is for HTTP mode, not stream mode:\ngot(url, [options])\nCould just be the layout of the README though?. > Those options apply to got and all helper methods.\nGotcha, I'll give it another try. I reverted everything to request and everything is working as expected. I've spent the last 2 days debugging this thinking I was going crazy! Definitely something wonky going on here. \nIf you want to investigate too, that file should be public.. @lukechilds that looks like it entirely could be the same bug. I assume that fix is NOT on npm yet? . > Sorry, edited my last comment with more info as you were replying\nGot it! Thanks for the quick response. How frustrating this weekend has been for me!\nI hope this new release is out soon, I think it includes the progress event and I'm eager to work that into my app!. ",
    "timdp": "Yeah but Node 7.6+ has native support for async as well. I wonder what's wrong with it then.. I'd still be slightly worried that p-cancelable has a bug in Node 7, but it's up to you.\nFor what it's worth, I was curious so I've established that all this works fine in Node 7.9.0:\n```js\nclass Promise2 extends Promise {}\nclass Thenable {\n  constructor (delay) {\n    this._delay = delay\n  }\nthen (cb1, cb2) {\n    setTimeout(cb1, this._delay)\n  }\ncatch (cb) {}\n}\n;(async () => {\n  const start1 = Date.now()\n  await new Promise2((resolve, reject) => {\n    setTimeout(resolve, 500)\n  })\n  console.log(Date.now() - start1)\nconst start2 = Date.now()\n  await new Thenable(500)\n  console.log(Date.now() - start2)\n})()\n``. @sindresorhus Yeah, I'm actually trying to come up with a PR for that as we speak. But I definitely understand the rationale behind trying to extend the nativePromise. That being said, the wayp-cancelablecalls the super constructor rightaway kinda scares me--not that I have a better solution. It feels like a reason not to extendPromise` though.\nAnyway, sorry to go off topic. I suppose this should be in a p-cancelable issue, but if you're not looking to support it, it's not worth it.\nShouldn't this be made explicit though? I.e., shouldn't p-cancelable complain if it's running on Node 7, through package.json engines or even just the readme? Of course, it's \"just\" await that's affected, but that's a pretty big one, given that a lot of people will probably have upgraded to Node 7 just to get that.\nI know it's a passing phenomenon, but for example, at our company, we're using the natively supported Node 7.6.0 on AWS Elastic Beanstalk, and the native async is the reason why we are doing that. A lot of our apps on Beanstalk use got (yay!) so it's a bit of a downer that upgrading will break our code, even if it's just for a while. Yes, our tests will catch it (although more as a side effect) but it's still something extra to keep in mind. Moreover, if some transitive dependency upgrades to the new got or another package that uses p-cancelable, it'll also bite us, and it'll be harder to notice.\nSorry to be bitching about this. It just feels a bit like you're underestimating the impact, but I'll happily be proven wrong.. > I'm open to consider a workaround for Node.js 7 if it's important to you.\nThat's okay. We'll just hope for a Beanstalk upgrade soonish. Like you said, it's the LTS release, so here's hoping the AWS guys will scramble to support it. And the LTS element should solve other people's issues as well because they'll all be very similar.\n\nIt wastes one promise, but that shouldn't matter much.\n\nI don't mind the small performance loss from that one promise. It was more about resolving the promise itself and yet overriding the whole \"thenable\" API, which basically negates the whole superclass. (Come to think of it, do you need to call resolve to begin with? I'm guessing that's mainly for the garbage collector?)\nI'll just close this issue. It's pretty clear that the message is \"just use Node 8.\" :wink:\nThanks for taking the time to reply, I know you're busy. :+1:. @sindresorhus Can you retry the Node 6 test? Seems unrelated to this PR. Thanks!. This is awesome. Thanks, guys!. > So don't specify the cache option :)\nI'm not. { cache: false } is the default.\nBased on the documentation, it's not overly clear what that option does. However, if I call got(url) on a cacheable resource multiple times, it just re-requests it. This also confirms how I understood the code: it creates all those cache objects but it doesn't actually use them, and even if it did, they get recreated for the next request.\nSo maybe the documentation should clarify that at the very least, you need to pass { cache: someMap } to enable caching? Right now, it states:\n\nGot implements RFC 7234 compliant HTTP caching which works out of the box in-memory and is easily pluggable with a wide range of storage adapters. \n\nThat's misleading to me. But anyway, I'm not looking to enable caching personally. :slightly_smiling_face: \n\nVery bad idea.\n\nWhy? Even without performance as an explicit design goal for got, I don't see why invoking it multiple times (whether it's ten, hundred, or hundreds of thousands) would be such a stretch. We've been doing this since version 6 and on the whole, it's working out quite well.\n\nYeah, Node is very slow compared to C++ :)\n\nI never said it wasn't, but it's fast enough for my use case. I also wasn't talking about speed per se, although the object allocations do of course influence garbage collection and therefore execution time.\nAnyway, independent of the language, my point was that with default settings, a bunch of throwaway objects seem to get allocated, so my suggestion would be to only allocate those conditionally. :slightly_smiling_face: . Because we make that many outgoing requests every minute. :-). I don't think I'm wrong. I added console.log() statements at key points in the code of got, cacheable-request and keyv and then simply called got('https://www.google.com/'). This logged:\ngot: new CacheableRequest()\ncacheable-request: this.cache = new Keyv()\nkeyv: new Map()\ngot: cacheableRequest()\nHence, all of the objects listed above are getting created. I can see how a few extra object allocations wouldn't matter that much, but I also think it should be quite doable to not create a CacheableRequest if you're not going to use caching anyway. And yes, that could be a PR.\nAs for the use case: we're not exploiting anything. We essentially operate a proxy service for server-to-server traffic. It's a totally legitimate scenario and a cornerstone of our business at that. I'm also not sure why I need to defend my use case because all I did was point out that the default behavior (i.e., no options passed) is wasteful of resources. That even matters if you're making a single request, especially if it happens with the default configuration.. > I wouldn't use Node for that.\nLittle late for that. We've succesfully built a business around it. Got contributes to that, so definitely kudos to you guys, but also all of the above. :-)\nAs for juggling performance against maintainability: given all the async state, I think an RxJS-based HTTP client for Node would be an interesting experiment. However, that's more of a thought experiment and the grass is always greener on the other side.. That it does.. 1. It happens under high load, which would make sense for a timeout: it doesn't finish whatever it was doing in time.\n2. The error is in my original message: there's some EventEmitter that emits an error event and the argument of that is the TimeoutError that gets logged.. I haven't been able to isolate it as it doesn't happen too often, but in our server logs, I can see that we get uncaught TimeoutErrors on both 'lookup' and 'response'. It's possible that they would also occur for the other configurable timeouts but we never run into those.. I did look at the code when I originally reported this and my assessment was also that it would have to be multiple 'error' events on the same EventEmitter. Perhaps it's worth adding code that generically protects against that on every emitter created. Once the object enters the error state, it should really just stop doing things altogether.. > > Once the object enters the error state, it should really just stop doing things altogether.\n\nIgnoring further errors should be our last option if we don't come up with anything :)\n\nMy point was more that there should only be a single error event per EventEmitter, at which point its internal state is updated to reflect that there was an error and that there's no coming back from it. To be frank, I don't know what the policy is around that in Node's internal APIs, but promises and observables both have this concept of a final, deterministic error state and it makes things a lot clearer.. > > we get uncaught TimeoutErrors on both 'lookup' [...]\n\nOn lookup? Impossible to happen. Full stack trace please?\n\nI'm pretty sure we saw the log lines from my original message in our logs but with lookup instead of response. I might be confusing uncaught errors with warnings from failed requests though.\nWe've since started using DNS caching and switched to a different DNS provider to decrease the likelihood of running into DNS-related issues, because Node's internal implementation doesn't handle errors very well. We haven't seen the errors anymore since then, but given that we didn't upgrade got either, I would expect them to reoccur if we reverted our patch.\nWe don't log async stack traces, so all I have is the Immediate.timeoutHandler one. However, the message is clearly from got. Additionally, we did see it in the debugger at one point, and all signs pointed to timed-out.js there as well.\nYou should be able to reproduce it by using a slow or invalid DNS server. That's how I started noticing these errors in the first place.. Actually, scratch that: I can confirm that I really do see several of these in our logs:\nUncaught error: TimeoutError: Timeout awaiting 'lookup' for 500ms \n  at Immediate.timeoutHandler (node_modules/got/source/timed-out.js:39:25)\nThese are from before the aforementioned DNS patch to our own code, but as explained above, the issue must still exist with got.. Our system never sets any cookies on the request. It might get some back on the response though (which we ignore).\nThe error presumably occurred under high load (due to the unreliable DNS) so it almost has to be latency-induced.. Unfortunately, with v9.3.0, I'm getting this error even more:\nTimeoutError: Timeout awaiting 'connect' for 500ms \n  at Immediate.timeoutHandler (node_modules/got/source/utils/timed-out.js:50:25). @sindresorhus @szmarczak Should I create a new issue or do you want to reopen this one?. Yes, it's the full stack trace. As far as I know, that's all you get with errors thrown from timers, at least by default?\nI think this is related to the retry option. I can reproduce it by passing in a hostname that has never been looked up before, setting all timeouts to 1 ms, and setting retry to 1:\n```js\nconst got = require('got')\nprocess.once('uncaughtException', err => {\n  console.error('uncaught error:', err)\n  process.exit(1)\n})\nprocess.once('unhandledRejection', err => {\n  console.error('unhandled rejection:', err)\n  process.exit(1)\n})\nconst url = http://${Date.now()}.dev/\nconst options = {\n  retry: 1,\n  timeout: {\n    lookup: 1,\n    connect: 1,\n    secureConnect: 1,\n    socket: 1,\n    response: 1,\n    send: 1,\n    request: 1\n  }\n}\n;(async () => {\n  try {\n    await got(url, options)\n  } catch (err) {\n    console.error('caught:', err)\n  }\n})()\n```\nWith got v9.3.1 on Node v8.12.0, that logs:\nuncaught error: { TimeoutError: Timeout awaiting 'connect' for 1ms\n    at Immediate.timeoutHandler [as _onImmediate] (node_modules/got/source/utils/timed-out.js:50:25)\n    at runCallback (timers.js:814:20)\n    at tryOnImmediate (timers.js:768:5)\n    at processImmediate [as _immediateCallback] (timers.js:745:5) name: 'TimeoutError', code: 'ETIMEDOUT', event: 'connect' }\nI get the same behavior with Node 10 and 11.\nStrange that it times out on connect as well. That would mean that the DNS lookup happened, failed (the hostname is invalid), and the timeout logic for the TCP socket still kicked in. Perhaps that's part of the problem?\nI've also added longjohn to obtain the async stack trace. That gives me:\n```\nuncaught error: { TimeoutError: Timeout awaiting 'connect' for 1ms\n    at Immediate.timeoutHandler (node_modules/got/source/utils/timed-out.js:50:25)\n    at runCallback (timers.js:814:20)\n    at tryOnImmediate (timers.js:768:5)\n    at processImmediate [as _immediateCallback] (timers.js:745:5)\n\nat Timeout.setTimeout (node_modules/got/source/utils/timed-out.js:21:15)\nat ontimeout (timers.js:498:11)\nat Timer.unrefdHandle (timers.js:611:5)\n\n\nat addTimeout (node_modules/got/source/utils/timed-out.js:20:18)\nat timeConnect (node_modules/got/source/utils/timed-out.js:93:28)\nat Socket.socket.once (node_modules/got/source/utils/timed-out.js:102:30)\nat emitMany (events.js:152:20)\nat Socket.emit (events.js:224:7)\nat GetAddrInfoReqWrap.emitLookup [as callback] (net.js:1092:12)\nat GetAddrInfoReqWrap.onlookup [as oncomplete] (dns.js:67:17)\n\n\nat Socket.Readable.on (_stream_readable.js:772:35)\nat Socket.once (events.js:341:8)\nat ClientRequest.request.once.socket (node_modules/got/source/utils/timed-out.js:101:13)\nat emitOne (events.js:121:20)\nat ClientRequest.emit (events.js:211:7)\nat ClientRequest.origin.emit.args [as emit] (node_modules/@szmarczak/http-timer/source/index.js:36:11)\nat tickOnSocket (_http_client.js:653:7)\n\n\nat ClientRequest.once (events.js:341:8)\nat module.exports (node_modules/got/source/utils/timed-out.js:89:11)\nat handleRequest (node_modules/got/source/request-as-event-emitter.js:176:5)\nat get (node_modules/got/source/request-as-event-emitter.js:219:5)\nat Immediate.setImmediate (node_modules/got/source/request-as-event-emitter.js:291:10)\nat <anonymous> name: 'TimeoutError', code: 'ETIMEDOUT', event: 'connect' }\n\n```\nIn timed-out.js, shouldn't you be checking the first argument of the lookup handler? It's an Error if the lookup fails, so in that case, you'll never get the connect event. But then, that should still reject the promise rather than producing an uncaught error.. Ah, I see I originally reported this about response. I do seem to recall getting connect failures as well. Maybe my example code never gets to response though.. @szmarczak We're making progress, but this is still not fully resolved in v9.3.2:\nUncaught error: TimeoutError: Timeout awaiting 'socket' for 1000ms \n  at timeoutHandler (node_modules/got/source/utils/timed-out.js:63:25) \n  at ClientRequest.request.setTimeout (node_modules/got/source/utils/timed-out.js:86:4) \n  at ClientRequest.origin.emit.args [as emit] (node_modules/@szmarczak/http-timer/source/index.js:36:11)\nThe server that encountered it was under heavy load, so the error isn't common. However, it's still an uncaught async exception rather than a promise rejection.. Looks like it's because the socket timeout handler doesn't call addTimeout()? The timeoutHandler that it calls doesn't guarantee that it will emit an error at most once.. > Don't use CacheableRequest when there's no need\n\ud83d\ude0d. Indeed, very nice work! :+1:\nFor the caching of cacheable-request, how about introducing the lru-cache package? You'd have to do some magic to map arguments to keys though. (I wanted to mention this on a PR but it doesn't exist yet.). What you want is an LRU cache with multi-valued keys though, so a mix of LRU and multimap. I'm sure that exists somewhere.. @szmarczak I ran\nbash\nyarn add 'szmarczak/got#fix-timeouts'\nand the test from #631 worked as expected:\ncaught: { RequestError: getaddrinfo ENOTFOUND 1541424862699.dev 1541424862699.dev:80\nHowever, it noticeably takes a while to execute. I added console.time() and consistently got execution times of just over two seconds. In the readme, it says that the time between retries is\n1000 * Math.pow(2, retry) + Math.random() * 100\nwhich, with retry = 0, means that the maximum execution time should be 1,100 ms plus a few milliseconds for the timeout, right? I don't get where the extra second goes.. Indeed. The retry parameter starts at 1, not 0.. Also, I want to point out that the concept of cancelers is basically what RxJS used to call Disposable until version 4. We still have some code that depends on it at our company. Just another argument to support what I originally said  about async state, even if it's not very pragmatic. :-). Yeah, but my original reproduction of the issue used retry: 1, so I kept that and discovered a second issue.. Same with v9.5.0.. - Now that we know how to reproduce it, can we add a test? Tests for memory leaks aren't pleasant to write but I've found the weak package to be a great start.\n\n\nSocket#setTimeout returns this so we're returning the socket itself from the canceler. Seems like bad style.\n\n\nI think you just want to explicitly remove the timeout listener in the canceler. Removing the timeout setting itself will still keep the listener attached to the socket, so any implementation that reuses sockets is going to leak.\n\n\nI think I've mentioned this before but I wrote the event-registry package to deal with bulk-removing EventEmitter listeners. It's basically a formalization of the cancelers.. So this should be reported to nodejs/node?. Sure. I'll get on it later today.. I'm not crazy about how you call makeRequest() recursively in your PoC, so I had a stab at writing my own version. Interestingly, it doesn't have the issue. Are you sure you're interpreting the results correctly?\n\n\nBut you were saying earlier that #694 doesn't fix it?. Thanks for the clarification and the patch. :+1: I'll turn it into a bug report with Node today.. Aren't you basically saying that == null isn't allowed and Pieter should instead use is.undefined()? I don't see how it would break existing functionality.. Am I missing something or would this work?\n```js\nconst mem = require('mem')\n// memoized factory\nconst createCacheableRequest = mem((request, cache) => new CacheableRequest(request, cache))\nif (options.cache) {\n  const cacheReq = createCacheableRequest(fn.request, options.cache)(options, handleResponse)\n  // ... do stuff ...\n}\n```\n. Yeah, I just discovered that it JSON-stringifies the args. Darn. I suppose you could put a symbol on the cache to uniquely identify it.. Why would it cache the requests? Cacheable-request just returns a factory method so it should be able to GC the return value of that.\nI agree that memoization could be a feature of the package itself or one around it though.. Cacheable-request exports a class (for some reason) that actually just gives you the cacheable factory method bound to the actual request factory (request in your code, which is a function, right?) and the cache. Calling the return value of new CacheableRequest is what actually produces the request, and there's no caching going on at that level. Hence, all you're doing is caching a function and some state, not the request itself. Therefore, v8 should GC it just fine. Correct me if I'm wrong.. ",
    "gpoitch": "Ended up just explicitly ignoring the electron dependency in my webpack config.. @aviaryan add electron to externals in your webpack config e.g.\njs\nexternals: {\n  'electron': 'electron'\n}. ",
    "aviaryan": "@gdub22 Can you tell me how to do so? I am facing the same problem. . ",
    "abrkn": "Behaves as expected in v6.7.1. My payload is signed, so I'd like to take care of the serialization myself.. ",
    "talbergs": "@sindresorhus .. thank you for the great work on this lib\nI can't figure this case -\njs\ngot('url/u', {json: true, method: 'POST', body: {asd: 1}}).then(console.log)\nall works good, but some docker api endpoints return just lines of text, not json. So I get this error:\nParseError: Unexpected token C in JSON at position 0 in \"http://unix/var/run/docker.sock:/exec/b37de4c64a65105cac691b176101ac42de4e10ccbd28cb50e207d34d161d5f37/start\": ...\nMay you please guide how to use this lib in such case? In order to disable automatic JSON.parse\n\nUPDTE: nvm, the solution:\njs\nheaders = {'accept': 'application/json','content-type': 'application/json',}\ngot('url/u', {json: !true, method: 'POST', body: JSON.stringify({asd: 1}), headers}).then(console.log)\nand json parse the response as/if needed\n. ",
    "brandon93s": "See https://github.com/sindresorhus/got/issues/467#issuecomment-403189894 for discussion and decision on the behavior of the jsonoption.\n@talbergs solution above is the recommended approach if you need to support sending a JSON body while receiving a non-JSON response:\n```js\nconst headers = {\n   'content-type': 'application/json'\n}\ngot('example.com', {\n  json: false,\n  method: 'POST',\n  body: JSON.stringify({your: 'data'}),\n  headers\n})\n`.err.responseis now provided by got (tested against master) and the original error can be found inerr.response.body`.\nUsing the sample reproduction script above, change the error log to console.log('Original Error', err.response.body) to log the original error:\n\n. The form + json support in got pertains to application/x-www-form-urlencoded data and not multipart/form-data.\n\nbody must be a plain object. It will be converted to a query string using (new URLSearchParams(object)).toString()\n\nTo support your use case, you can manually parse the response body:\n```js\nlet form = new FormData();\nform.append('file', buffer);\nconst {body} = await got('/upload', {\n    method: 'POST',\n    headers: form.getHeaders(),\n    body: form\n});\nconst jsonBody = JSON.parse(body);\n```. The code sample looks valid.\n@szmarczak - Think #501 would have addressed any issues here?. This appears to be functioning correctly with electron@latest and current got master.\n```js\n// demo.js\nconst fs = require('fs');\nconst path = require('path');\nconst got = require('./source/index');\ngot.stream('https://s3-us-west-1.amazonaws.com/scl-cdn/doomtrooper/assets/video.md5')\n.pipe(fs.createWriteStream(path.join(__dirname, '/demo.md5')));\n```\n```sh\ngot master = $ node .\\demo.js\ngot master = $ cat .\\demo.md5\nf3dabdb85243b4b772da84fba640989b\ngot master = $ npx electron .\\demo.js\ngot master = $ cat .\\demo.md5\nf3dabdb85243b4b772da84fba640989b\n``. \ud83d\udc4d replacedforEachwithfor..of`. > Methods: GET PUT HEAD DELETE OPTIONS TRACE\nThis list is sensible, as these methods should be safe or idempotent.\nWould this functionality be rolled up into the existing retries option, or separated for more control? For API simplicity it makes sense to combine them, but the proposed functionality is more likely to need disabling than the current implementation. \n\nStatus codes: 408 413 429 500 502 503 504\n\n413 may be an odd one to retry since the retry would be sent with an identical payload. . Agreed, retry 413 if and only if (iff) the response provides a Retry-After header. Retry-After could probably serve as a base case to enable retry, regardless of error, for the HTTP methods mentioned before. \n\nI was thinking of combining them, but also allow passing an object where people can customize\n\nLooks good to me. This can also be made backwards compatible by mapping retries Number | Function to retry.retries when we normalize arguments. \n\nWhy do you think so?\n\nThe aforementioned errors should be safe, but I've encountered some fairly non-standard APIs where I wouldn't want to retry on a 500 for example because I'm not confident the method is safe / idempotent. But, being able to specify methods and statusCodes solves for this.. - Use util.promisify over pify \n- ~~Replace is-plain-obj dependency with is and leverage throughout for additional readability and code clarity: (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, etc)~~\n- Use require('url').URL (WHATWG URL) as a replacement for isurl and url-to-options dependencies\n- ~~Extract errors into separate file and use an assignment syntax similar to http methods (e.g. for (error of errors))~~ . I'll tackle the is implementation once https://github.com/sindresorhus/is/pull/34 lands!. @sindresorhus @lukechilds - Now that 8.x is LTS, what timeline would you guys like to target for switching over to targeting 8?\nVersion Metrics\nEdit: I'm guessing we'd be looking to target 6 as a minimum version next, not 8?. > @brandon93s I've replaced isurl now, but not sure how we can replace url-to-options as it's needed so we get an object to pass to http.request(). What did you have in mind?\nReviewed again, not sure what I was thinking. Appears necessary. . Explanation of failure:\nThis website is windows-1252 encoded which is unsupported by js-native decode utilities which operate on and assume UTF-8 input. The encoded portion of the provided URLs contain sequences that are invalid for UTF-8 encoding, and as a result cannot be decoded properly. This error can be reproduced in any browser console or repl properly implementing the spec (e.g. repl.it) which is expecting UTF-8.\nTake %D2%E0%EB%EB%E8%ED as an example which represents \u00d2\u00e0\u00eb\u00eb\u00e8\u00ed in windows-1252 encoding. The equivalent in UTF-8 would be %C3%92%C3%A0%C3%AB%C3%AB%C3%A8%C3%AD giving a URL of https://www.kinopoisk.ru/community/city/%C3%92%C3%A0%C3%AB%C3%AB%C3%A8%C3%AD/. Unfortunately, this URL won't work due to the encoding of the website.\n\nWhy this fails now, but not before:\nThe introduction of caching via lukechilds/cacheable-request introduced the package sindresorhus/normalize-url which uses decodeURI internally. This module could perform a best-effort decoding - falling back to the encoded value - when the string is not UTF-8 encoded. This would allow URLs that happen to be encoded unexpectedly to process successfully.\nI don't think a fix, if any, would be applied here directly in Got.. According to RFC 3986, UTF-8 encoding of URLs is spec and a requirement. The widely used Express will also throw on non UTF-8 encoded URLs. Got throwing is now enforcing URLs to be spec compliant before making a request, which isn't necessarily a bad thing. . @sindresorhus Are we okay with a brute force try...catch around a decodeURI early-ish on in normalizeArguments to catch any potential errors with a user-friendly message? Any decodeURI failure will present an issue, so we might as well check upfront and inform the consumer! \nGlad to implement.... Covered by:\n\nAny of the http.request options.\n. - Renamed to GotError and exposed\n- Simplify with Object.assign\n- Include errors.js in files. See https://github.com/sindresorhus/got/issues/318#issuecomment-403235732 and https://github.com/sindresorhus/got/issues/467#issuecomment-403189894 for additional details and recommendations on working with APIs that do not return JSON.. Got now maintains the stacktrace as expected for the HTTPError:\n\n\nNote that you can also set throwHttpErrors to false if you'd prefer to handle these yourself as a response.\nTested against master.. The json option is a shorthand intended to support JSON request / JSON response APIs. Fortunately, headers, parsing and encoding can all be configured by the user when the API they are interacting with does not conform to JSON/JSON. \nWhen comparing to other libraries:\nfetch\n\nMust serialize your own data\nMust read data as json with .json()\n\nrequest\n\njson indicates write and read as JSON (similar to got)\n\naxios\n\nsupports a responseType (default is json)\nsets content type and serializes if data is an object\n\nSince the option is intended to be a convenience and does not prohibit users from configuring got to handle more specific use-cases, I would prefer the API remain as-is.. @mdybich see the updated streamData implementation below. The Content-Range header needs to be a sliding window of the format {starting-byte}-{ending-byte}/{total-bytes}. Using the 'downloadProgress' event we can extract out the missing pieces of information required for this request. \n```js\nfunction streamData(s3Url, oneDriveUploadUrl) {\n    let total = 0;\n    let transferred = 0;\n    const stream = got.stream(s3Url);\n// capture progress\nstream.on('downloadProgress', progress => {\n    total = progress.total\n    transferred = progress.transferred\n})\n\n// put part to one drive\nstream.on('data', data => {\n    got.put(oneDriveUploadUrl, {\n        headers: {\n            \"Content-Length\": data.length,\n            \"Content-Range\": `bytes ${transferred}-${data.length - 1}/${total}`\n        },\n        body: data\n    })\n})\n\n}\n```\nBased on OneDrive API documentation.. You may be able to test this with process._getActiveHandles with an assertion that the count is the same before and after the tested code. A failing test could be written demonstrating the lingering handle. . Whoops! My comment was wrong. Undefined check shouldn't be negated. . @kirillgroshkov does this still require assistance? It looks like a work-around was found: https://github.com/kornelski/http-cache-semantics/issues/9. @sindresorhus //label=external. Building upon @szmarczak's suggestion, the following code snippet produces the output you desire:\n```js\nconst redirects = [];\nconst request = got.get('https://httpbin.org/relative-redirect/5');\nrequest.on('redirect', info => {\n    redirects.push([info.statusCode, info.url]);\n});\nconst response = await request;\n``. I've setup a few separate test cases and haven't had any luck reproducing this.Transfer-Encoding: chunked` is only supported by HTTP/1.1 (not 1.0, not /2) and implementation support is spotty. I can't see where got was ever sending this header, though. \nTypically, support for this header is going to live in a reverse proxy or firewall. Without knowing more about the server that these requests were made against, I'm afraid there isn't much that can be done here. . I'm a bit concerned that a user is going to be confused as to whether they should be using get.extend() or got.create() for their use case. Most users are just going to want to provide new defaults, but extend has a small blurb in the docs compared to the in-depth create section which could mislead them. create seems to cater primarily to library / module creation (e.g. gh-got) and not everyday use. It may be time to consider breaking out some advanced sections of the docs into separate files and linking to them to avoid information overload:\n\nNeed more control over the behavior of got? Check out the advanced creation options.\n\nLooking elsewhere, axios has axios.create() and request has request.defaults() which are functionally equivalent to got.extend(). Users coming from axios may reach for create and have a very different experience. . @sindresorhus - thoughts on turning AppVeyor on? Glad to open a PR to add the appveyor.yml and the CI badge but you'd need to flip the switch as the repo owner.. What is the use case for this?\n\nE.g. one instance can limit download & upload and second instance may set some headers. Join them through the got.forward function! instanceC = instanceA.forward(instanceB)\n\nDoes this imply that an app would be using three instances of got? Seems that this could just be handled by constructing / merging numerous config objects together instead of mashing instances together.. The json option requires a JSON request body and a JSON response. When this is not the case, you can set the headers manually to support the endpoints you're interacting with.\nMore info: https://github.com/sindresorhus/got/issues/467#issuecomment-403189894. To clarify, the json option does the stringify and parse operations for you while also configuring headers to support JSON. Because of this, a plan object or an array are required so that got can handle the conversion to JSON. When passing a string, got cannot confirm that the input is valid JSON (without a parse anyways) and therefore does not want to make invalid assumptions in configuring headers on your behalf. . This is similar in objective to interceptors in axios. It's also a great place to add support for plugins, or hooks. An API like the following would allow us to expand this to different hooks and provide support for multiple hooks at once:\n```js\nconst plugin = got.hooks.beforeRequest.add(async req => {\n});\ngot.hooks.beforeRequest.remove(plugin);\n```\nHooks here could be things like: \n\nAuthentication \nLogging / Debugging\nFor example: chalk() of network activity in development mode\n\n\nEtc\n\nI support the current implementation, but wanted to bring up the alternative above if we want to future proof the implementation. . Why is this needed?\nIf your URL is dynamic it's not a baseURL and you should just call got with a FQD each time instead of using a baseURL. A base url should be static. . According to RFC 2616, for 301:\n\nIf the 301 status code is received in response to a request other\n   than GET or HEAD, the user agent MUST NOT automatically redirect the\n   request unless it can be confirmed by the user, since this might\n   change the conditions under which the request was issued.\nNote: When automatically redirecting a POST request after\n   receiving a 301 status code, some existing HTTP/1.0 user agents\n   will erroneously change it into a GET request.\n\nIt goes on the read the following for 302:\n\nNote: RFC 1945 and RFC 2068 specify that the client is not allowed\n      to change the method on the redirected request.\n\nAnd finally for 303: \n\nThe response to the request can be found under a different URI and\n   SHOULD be retrieved using a GET method on that resource.\n\n\n301 and 302 are explicit in maintaining the request type. Further, they require user confirmation before attempting the redirect given the implication of retrying non-idempotent requests. \n303 is explicit in always performing a GET request. \nI believe the current implementation to be RFC compliant and should remain as implemented. . @rarkins - cacheable-request uses https://github.com/lukechilds/keyv as the underlying cache, which supports a \"global\" TTL. Setting the TTL to your desired max cache time should accomplish what you're after. \nSee the docs for passing in a cache store here: https://github.com/sindresorhus/got/blob/master/readme.md#cache-adapters. Very nice! The output provided is very useful, particularly the phases portion. A few questions:\n\n\nHow accurate is the start time? It's set automatically when timer is invoked. How close is this to when the request truly starts? Synchronous event emmiters still run after this point. \n\n\nShould this be opt-in? The overhead seems pretty minimal, so maybe keeping it simple and always running is OK. . See https://github.com/avajs/ava/issues/1931 for related issue. . What makes this preferable to #607?. Ah, I missed the file delete from the diff originally, making this change look larger than it is. \n\n\nMind adding tests to cover what this fixes?. I advise strongly against this approach. Instead, we should update code in got that directly modifies (adds, removes, edits) headers to handle case sensitivity (e.g. find existing header in a case insensitive manner). \nHeaders in HTTP/1.1, per RFC 7230, are case insensitive. The problem is, any server that is checking for a specific header (case-sensitive) value, could now fail because we are forcing the user's headers to be all lowercase. I have experienced this in a production application and had resulting outages. \nHTTP/2 makes this more complicated: headers are required to be all lowercase. If got is to ever adopt native HTTP/2 support, this would need to be accounted for at that time. \nExample:\n```js\n// Client\nawait got('/api', {\n  headers: {\n      'X-My-Custom-Header': 'unicorn'\n  }\n})\n// API\nif (request.headers['X-My-Custom-Header']) {\n   // this fails now if headers are forced to lowercase\n}\n```\nThis very scenario is one of several issues with legacy applications migrating to HTTP/2 support in the wild.. Fair enough. If this was the previous behavior, it shouldn't be a surprise to any current users. . got currently retires on errors only. Supporting retries on success for non-standard implementations would require a fairly significant refactor. The current implementation does not allow you to \"skip\" a retry in a manner that would indicate success, which would need to be supported for this.\nI'm not sure this is something that should be handled internally given the additional complexity and non-standard behavior. . I think the ideal implementation would be an automatic TTL cache by simply respecting the TTL of the DNS record itself. If the upstream DNS server(s) are respecting TTL to spec, they will be caching for the same TTL meaning a value lower than set on the DNS record is unnecessary. \n\nAs for a size limit, I don't think it's necessary. Absolute worst case, a domain (63 characters) and IPv6 address (128 bit) pair are represented in 79 bytes. That means you can store 12,658 cached DNS entries per megabyte of memory. In practice, you'd get 25,000+ since domains are shorter. For long running processes, we could implement an asynchronous tick (e.g. setInterval) to clean out expired entries every few minutes if it becomes absolutely necessary.\nIf we implement it similar to request caching, the user can bring their own cache if they need to manage it more closely. For instance, passing in a custom instance of keyv enabling them to clear entries as necessary.\nWe should however offer an option to disable it. This leaves us with two modes:\n- On, fully automated, no limit\n- Off\nJust my $0.02.. > Actually, can just use Object.assign:\nAh, duh!. This breaks existing functionality. opts.headers['accept-encoding'] will always evaluate to false due to L522. This means the default headers will never be added.\nYou'd either need to fix the check, e.g. if (opts.decompress && !is.undefined(opts.headers['accept-encoding']) or update the assignment to keep existing values: opts.headers['accept-encoding'] = opts.headers['accept-encoding'] || 'gzip, deflate';.. Line 531 is unreachable. The change needs the respect an existing header value, but it's preventing the default from being applied entirely. . To elaborate... the value can't be null here, it'd be undefined or a user provided value. A similarly effective check would be a has own property check for accept-encoding. . \n\ud83e\udd14 Ah I see now... that's actually new to me! I've always been in a === enforced setup and haven't run into that. . Not best practice to use @global with proxyquire but it does not currently result in any side-effects in the tests. An alternative would be to introduce a mimic-response-wrapper.js that exports a named function we can stub with Sinon and then use that in got. \n. \"will be prepended with baseUrl\" is a bit more clear.\nShould we note that this only applies to relative URLs? If you specify an absolute URL it will skip the baseUrl.. The placement in the docs has this as a separate parameter to the got api. I think it's just part of the options, however. If that's the case it should be moved into the options section below. . See other notes, baseUrl is an option. This feels redundant. . This example is a bit unclear if you're not familiar with httpbin.org and knowing that this endpoint will reflect headers back in the body. Maybe something like this would help illustrate: \n```js\nconst client = got.extend({\n    baseUrl: 'https://example.com',\n    headers: {\n        'x-unicorn': 'rainbow'\n    }\n});\nclient.get('/demo')\n/ HTTP Request => \n * GET /demo HTTP/1.1\n * Host: example.com\n * x-unicorn: rainbow\n /\n```. Exposing this and having it used in the closure could lead to some unexpected behavior if defaults are modified: \n```js\ntest('tampering with defaults', async t => {\n    const instance = got.create({\n        handler: got.defaults.handler,\n        methods: got.defaults.methods,\n        options: { ...got.defaults.options,\n            baseUrl: 'example'\n        }\n    });\nconst instance2 = instance.create({\n    handler: instance.defaults.handler,\n    methods: instance.defaults.methods,\n    options: instance.defaults.options\n});\n\n// Tamper Time\ninstance.defaults.options.baseUrl = 'http://google.com'\n\nt.is(instance.defaults.options.baseUrl, instance2.defaults.options.baseUrl);\n\n});\n```\nI think I'd expect two instances created with .create to be independent and not impact each other. Similar tampering could be performed on the global got.defaults that the module exports.\nThoughts?. \ud83d\udc4d thanks for the link & read. Updated.. Agreed, keep the API surface as small as possible.. What about 500?. Could this just default to {}? Replicating the structure of the object, but options should already have defaults merged into it if it is an object.. Could \"normalize\" methods and statusCodes into a Set for more efficient lookups for the lifetime of the instance. . Be aware Number(null) is 0, which would cause an immediate retry. Maybe not worth coding for, though.. > What should the timeout be? Should it be configurable?\nIt could be the already configured timeout. If retry-after > options.gotTimeout.request, then don't retry. Not sure I'd add a new timeout until it's needed.. iter here, too. Full word?. The array approach does come with the caveat that we can't support addition or removal of hooks from an instance since the options are run through an Object.freeze. A new instance would have to be created to modify hooks - they must be provided at instantiation. . No, nothing in particular comes to mind. I'm comfortable with how it has been implemented here. I prefer the consistent API over additional methods to maintain hooks. . I'm not sure we want to allow things to be mutated by default, or via a configuration for that matter. Why was this necessary or even wanted?. A method named defineConstProperty with configurable behavior doesn't feel right.. Isn't this the same as line 15?. Would suggest we document the merge strategy. Which options are merged, in what order, etc.. I suspect this was added to control the call stack, ensuring that the method ran to completion before any errors were emitted. This changes that behavior. There doesn't appear to be any tests failing from the change, but I would guess that this introduces behavioral changes.. Originally added in https://github.com/sindresorhus/got/pull/117.. Shouldn't parameter 1 be response instead of request?. Should we set writable to true if mutation is enabled? I may have a set of options objects that I'd like to just swap out with an assignment. . Remove .only. Consider copying the note here as well. Wasn't immediately clear why we were waiting. \n\n// Wait a bit more to check if there are any unhandled errors. What are the ... in these for?. \n",
    "marianoguerra": "is there any plan to make a release with this change?. ",
    "Qix-": "Oh, the url parts part wasn't clear in the docs (or maybe I missed it). It'd be nice if it also supported just a string.. ",
    "nomad3k": "It's not a webpack bug.  You just need to amend the resolve.extensions in your webpack.config.\nresovle: {\n    extensions: ['', '.js', '.jsx', '.json']\n}.\n",
    "SilentImp": "$ node --version\nv7.9.0\n. ",
    "mjasinski5": "hmm Im using async await (wrapped in https://github.com/danielstjules/swaddle) and there's no response in try/catch. Ive also tried pure promise version (ofc in swaddle) and it doesnt work as well. After quick test, within this change: https://github.com/mjasinski5/got/commit/31bf33c2960865b5872565dcc6690f90d5180eb9 it worked as expected.\nEDIT:\nany thoughts? . To close, Ive fixed that.. its fine on your side :). ",
    "dertieran": "@AlexTes I thought about that, but for querystrings your example was:\n```js\n\nqstr(['alex'])\n'0=alex'\n``\nI didn't see the use in that or ever encountered an API like that.\nAnd because of your guy's **Complaint-Based-Development** \ud83d\ude09 I just added what I needed.. But when we are already talking.\nI had another thought I first worked around the problem by justJSON.stringifythe Array.\nBut then I needed to do everything by myself (setting headers etc.), what do you think about just skipping thestringify` process.\nYou could also parse it first to see if it's valid, but I don't think that's needed.. @AlexTes Sure I can see your point and I don't have a problem adding Array support to both.\n\nAs I said it was mainly I needed to send an Array as JSON, so I added it.\nRegarding the second comment, I think thats a valid point. I think when Arrays are supported I wouldn't need to use stringify myself.\nShould I just add Array support to form too?\nOr do you guys want to discuss this and add it yourself?\n. Hey, not sure if this is the right place to give, I can also move this into a separate issue.\nAfter playing around with got.extend for building API wrappers, I ran into a problem with the stream and json option.\nLet's say I want to build a wrapper arround jsonplaceholder my normal use case would be to set the json option by default\n```js\nconst placeholder = got.extend({\n  baseUrl: 'https://jsonplaceholder.typicode.com',\n  json: true,\n});\nconst { body: posts } = await placeholder('posts');\n```\nBut now I get an error when using placeholder.stream('posts')\nGot can not be used as a stream when the `json` option is used\nMy solution for now felt a bit hacky and I guess I wouldn't be the only one who needs to do something like this\njs\nconst placeholder = got.extend({\n  baseUrl: 'https://jsonplaceholder.typicode.com',\n  hooks: {\n    beforeRequest: [\n      options => {\n        options.json = !options.stream;\n      },\n    ],\n  },\n});\nCould something like this be done by default?\nOr is there a better solution for this already?\n. > Any other suggestions?\nI just had another idea, because I needed to use a API where I need to encode the body as form and decode as json.\n(Often used in OAuth2 when exchangin a code for a token)\njs\ngot.post('unicorn.com/oauth/token', {\n  form: true,\n  json: true,\n  body: { code: 'rainbows' },\n})\nFor me this was always hard to read and needed an understanding how got handles this special case.\nWhy not just add a encode/decode option or something similar?\nThis way the stream problem could be generalized to only allow encode or ignore decode.\nencode might be confusing because there is already encoding\nSo it might look like this\njs\ngot.post('unicorn.com/oauth/token', {\n  encode: 'form',\n  decode: 'json',\n  body: { code: 'rainbows' },\n})\nMaybe there are better names for these option or I might be alone with this problem.. True, changed it.\n(Hope you guys are okay with amending the last commit). Sure something like isPlainObjOrArray?. ",
    "Dreamacro": "Sorry, create additional test cases now.. ",
    "gunjam": "Ah! Ok, sorry :) Thanks for the info.. ",
    "bertolo1988": "@sindresorhus thanks alot for clarifying.. ",
    "Lalem001": "While on the topic of cancel and timeout, should the timeout cancel the request?. ",
    "janpio": "Thanks.. I created an issue for Webpack: https://github.com/webpack/webpack/issues/5294. Fair enough.\nBut let me ask, what is so important with using the shortcut version without the filename? Is there a advantage?. Thanks for the pointer to the optimization.config.js - I wasn't aware of that and now created a PR to fix it.. ",
    "sbj42": "For anyone coming across this, the conclusion from the webpack discussion that helped me was to add the IgnorePlugin, as:\njs\n  plugins: [new webpack.IgnorePlugin(/^electron$/)]. ",
    "Siilwyn": "\nMaybe I am not supposed to be doing network labor in the renderer processes.\nWhy not?\n\nJust bumped into the same problem, what would the best workaround be?. See: https://github.com/sindresorhus/got/issues/346. ",
    "josephfrazier": "Thanks for the link. FWIW, the site it links to also mentions:\n\nThe spelling distinction ... does not extend to cancellation, which everywhere is spelled with two l\u2019s.\n\nLanguage is weird, but I understand if you still want to keep it consistent with canceled/canceling/cancelable :man_shrugging: . That makes sense :) Thanks for all your work!. ",
    "rodrigooler": "@sindresorhus I understand, in the next suggestions I will open. tks. ",
    "petitchevalroux": "@pietermees as stated in #382 original issue seems ok in master branch\nI get the MaxListenersExceededWarning warning too on connect and request event but it may be better to open a new issue\n. @sindresorhus this issue affect npm published version but not current master.\nTo reproduce just clone this branch https://github.com/petitchevalroux/got/tree/uncatched-error\nand run code here : \nnode uncatched.js\n/Users/patrick/code/got/uncatched.js:7\n    throw new TypeError(\"Request path contains unescaped characters\");\n    ^\nTypeError: Request path contains unescaped characters\n    at Object.http.request (/Users/patrick/code/got/uncatched.js:7:11)\n    at get (/Users/patrick/code/got/node_modules/got/index.js:49:18)\n    at Immediate.setImmediate (/Users/patrick/code/got/node_modules/got/index.js:124:3)\n    at runCallback (timers.js:672:20)\n    at tryOnImmediate (timers.js:645:5)\n    at processImmediate [as _immediateCallback] (timers.js:617:5)\nI wish to contribute by adding unit tests to the current version in order to avoid any future issue but I can't find any mock framework in this project in order to cleanly mock http.request behavior.\nDid you plan to use one ? If not I suggest sinon.js\nAnd last question do you plan to publish current master to npm ?\nEdit: spelling. As stated in https://stackoverflow.com/questions/37900687/problems-with-ava-asynchronous-tests-when-stubbing-with-sinon test.serial seems mandatory. Duplicate of #382. @lukechilds ty for the update ;). @sindresorhus you are welcome ;). ",
    "DaveLo": "Ahh, that makes more sense. I appreciate the help.. ",
    "json2d": "@sindresorhus oops that was a typo the post, here's a screenshot of my run:\n\nAs you can see here there's no output. So I'm running node v6.2.0. Do you rule out it being a platform specific issue?. Yep you were totally right, updated node and issue is gone. Thanks for your patience!. ",
    "andreygmc": "We got the same problem (got: \"7.1.0\", electron: \"1.6.6\"):\nTypeError: this.on is not a function\nat once (events.js:305:8)\nat CallbacksRegistry.apply (.../electron.asar/common/api/callbacks-registry.js:48:42)\nat EventEmitter.<anonymous> (.../electron.asar/renderer/api/remote.js:299:21)\nat emitThree (events.js:116:13)\nat EventEmitter.emit (events.js:194:7)\nuseElectronNet = false fixes the problem. ",
    "carvallegro": "Looking at package.json file, there's no electron dependency. I'd look around this.\nIn this commit, electron is required and we can see that in the package.json \"electron\" has been added to the keywords, not to the dependencies. \nEither that or there's there's a bad initialization of opts.useElectronNet or process.versions.electron because it requires it anyway. I am personally not using electron and have an issue with it\nThank you for the workaround tho @ngprasad . I understand that @sindresorhus . However it won't break your code to use *.json and it's not a huge refactoring. Dropping the filetype in require is usually for js files, not json. I understand your position @sindresorhus , I do. And the extensions fix in webpack worked for me.\nHowever I don't think it is about setting a precedence and giving up to webpack. Ultimately it comes to making life easier for the users. And it is true that nowadays, lots of user are using webpack. You chose to open-source your code and that's wonderful because your tool is damn fine. But open sourcing is also about listening to the community. And as you said, lots of issues has been opened regarding this require. \nI don't want to create a debate here, I just want to express my opinion, hoping that you'll consider it. \nThank you anyway for creating got. ",
    "pregnantboy": "Any idea when will this feature be released?. ",
    "Lancher": "So it will be something like returning a new stream object from got()?\nconst stream = await got(url, {stream: true, ...})\nstream.pipe(process.stdout). ",
    "zfoster": "Thanks! \ud83d\udc4d . ",
    "KyleAMathews": "Oh hmmm\u2026 been awhile since I've used streams so forgot about on('finish'). . Oh I guess I need on('end'). ",
    "joaom182": "@kevva if you pass two items in array, it's works... but if you pass only one not works.\nI'm using hapi to receive request, so the hapi request body parser it works when the request is from client side, but if come from a server side got request not works correctly.\nI'm analysing if the problem can be from hapi. ",
    "MySidesTheyAreGone": "Oh sorry guys, I see it's in the docs after all; I missed it. Thanks!. Ahem, do you do that in stream mode too? Because I'm not seeing it. Here's all the keys on the error object:\n[ 'name',\n  'host',\n  'hostname',\n  'method',\n  'path',\n  'protocol',\n  'url',\n  'statusCode',\n  'statusMessage',\n  'headers' ]\nI use streaming so I can abort if the download size is too large.\nedit: I guess I can still concat all the chunks though?\nedit2: yep, solved, stupid question, thanks again for the help :). ",
    "rhodgkins": "Ah, I missed that - cheers! Did think it was odd it wasn't there already!. ",
    "JasonBoy": "@kevva inside the () or not should be the same since pipe will return the stream inside .pipe(), and  I try to recoding the requests from got, looks like all the headers were discarded, only with some default headers added by got, resulting all the session info from cookies are missed, so the result is that I cannot just pipe the request to got? or i can only set the headers manually?. and on the other hand, got.stream 's http response, including headers will not pipe to ctx.res?. @sindresorhus if got.stream is a readable stream, then the code in readme: \nfs.createReadStream('index.html').pipe(got.stream.post('todomvc.com')); it pipes a readable stream to got.stream.post(is this a writable stream?), pipe() should pipe to a writable stream , right? \nor the got.stream and got.stream.post returns a different type of stream?\n\nlooks like the comment above the line makes it clear, a get method will return readable stream, but is it the same as the method provided in options: \njavascript\ngot.stream(url, {method: 'post'})\n//equal ?\ngot.stream['post'](url). Use snippet below works great:\njavascript\nrouter.all('*', ctx => {\n    ctx.body = ctx.req.pipe(got.stream(url, {...options}));\n  });\nand manually set headers, method for stream() options, also you may need to set throwHttpErrors: false, otherwise, non 2xx request won't be piped to client. ",
    "SkeLLLa": "Same on 8.X.X. . Why got couldn't read Content-Type header from server response and if it's application/json do what it does if body is not form?. Got the same error.. ",
    "puzrin": "AFAIK, zlib was changed in ~ node 8.3.x or later. Try with node 8.2.1 for sure.\n@sindresorhus possible regression from got 6 -> 7. I got this report https://github.com/nodeca/probe-image-size/issues/16 and the only change was got upgrate to 7.. That's a minimal sample to reproduce problem, thanks to @wong2 for url address:\n```js\nlet stream = require('got').stream('https://mp.weixin.qq.com/mp/qrcode?scene=10000004&size=102&__biz=MjM5MzA0MzczMg==');\nstream.on('error', err => console.log('===', err));\n```\n=>\n```sh\n node test.js \nevents.js:182\n      throw er; // Unhandled 'error' event\n      ^\nError: incorrect header check\n    at Unzip.zlibOnError (zlib.js:152:15)\n```\nThere are 2 problems:\n\nUnhandled 'error' event should not be thrown.\nBrowsers can open that url and show something (json with error info)\n\nIs my sample correct? Seems enougth to prohibit global exceptions from stream.. That's without stream:\n```js\nlet r = require('got')('https://mp.weixin.qq.com/mp/qrcode?scene=10000004&size=102&__biz=MjM5MzA0MzczMg==');\nr.then(data => console.log('+++', data)).catch(err => console.log('---', err));\n```\n=>\nsh\nnode test.js \n--- { ReadError: incorrect header check\n    at stream.catch.err (/home/vitaly/\u041a\u043e\u0434\u0438\u043d\u0433/probe-image-size/node_modules/got/index.js:164:26)\n    at <anonymous>\n  name: 'ReadError',\n  code: 'Z_DATA_ERROR',\n  host: 'mp.weixin.qq.com',\n  hostname: 'mp.weixin.qq.com',\n  method: 'GET',\n  path: '/mp/qrcode?scene=10000004&size=102&__biz=MjM5MzA0MzczMg==',\n  protocol: 'https:',\n  url: 'https://mp.weixin.qq.com/mp/qrcode?scene=10000004&size=102&__biz=MjM5MzA0MzczMg==' }\nStill error, but no global exception.. @sindresorhus both problems (zlib error + global throw) still exist in 8.0.0. That's regression after 6.x and (IMHO) critical thing when you do massive scans of arbitrary addresses.. Thanks! Fix for unhandled errors should solve the most unpleasant problem.\nAbout zlib header error - can't say the right behaviour. At least, request processes it without error. Don't remember exactly about got v6:\n```js\nrequire('request')({\n  uri: 'https://mp.weixin.qq.com/mp/qrcode?scene=10000004&size=102&__biz=MjM5MzA0MzczMg=='\n}, function (err, res, body) {\n  if (err) {\n    console.log('---', err);\n    return;\n  }\nconsole.log(body);\n});\n```\n. ",
    "jgdev": "I just update the description, I will be updating the PR with the test as soon possible.. Just for debugging purposes.\nWhy isn't part of Promise interface?. OK, but I don't have any way to get the request using json:true?. Yeah, I'll finish the test today.. I don't know exactly what is the best way to test these events, I just test if the events are beign called.\nAnother way maybe is matching the class constructor name of Request and Response objects?. Yeah, you right let me remove it.. ",
    "rlidwka": "It is with master.\nInitial report was about latest version, but I've just tested it on master with the same results.. ",
    "IonicaBizau": "@lukechilds Even when I'm using encoding: null, when I stringify it, those weird characters appear.\nThanks!. OK, I've asked a Stackoverflow question: https://stackoverflow.com/q/46970062/1420197. ",
    "sleewoo": "cranking a test. yep, much better. ",
    "allevo": "Sorry, it is already implemented because of\nerror.response.body. ",
    "TehShrike": "hmm, how would that work?  response isn't a standard stream event. ",
    "revelt": "aha! thanks anyway. I got request working and can't get got working to fetch simple data from GitHub. The GitHub API returns null so I'm checking what is wrong.\nCurrently, simplest thing copied from documentation is not working:\nfunction getUserInfo(username) {\n  return got(`https://api.github.com/users/${username}`, {\n    headers: {\n      'user-agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0',\n    },\n  })\nI tried all user agents (like legit-ones above), no luck.. ",
    "edouard-lopez": "uglifyjs-webpack-plugin version \u22651.0.0 support ES6 via uglify-es (cf. example). ",
    "harryparkdotio": "since got takes in any <key>: <value> set in headers and passes them to the request, the recommended approach would be to do the following:\njs\n{\n    ...\n    headers: {\n        ...\n        cookie: [cookie.serialize('foo', 'bar'), cookie.serialize('fizz', 'buzz')].join(';'),\n        ...\n    },\n    ...\n}. ",
    "gkcgautam": "@rightaway You may use the set-cookie-parser package for parsing the set-cookie header. The output from this module is similar to what you need.. ",
    "petermetz": "https://github.com/sindresorhus/got/pull/421. > Can you change this to use GET? Retrying on POST by default is not safe, so even when we support retrying on HTTP status codes, we won't do POST by default.\nThis should've been more clear in my PR explanation: I'm not proposing to change the default behavior. I do propose that the documented feature of the iter callback to be operational for POST verbs as it is for get. This in my opinion doesn't make POST retries the default, but it makes it possible for people to opt-in.\nMy use-case for this was about writing integration tests and verifying some error handling logic on the server side (can't remember the exact details to be honest).\nSo with all that said my answer is that if you don't approve of the opt-in POST retries idea, then the whole PR is pointless anyway and I will rest my case by simply closing the PR.. ",
    "alixaxel": "@sindresorhus I'd like to use auto-retries on a 202 response (since it's async).\nHowever, it seems that statusCodes only plays an effect if it's >= 400, is that right?. ",
    "millette": "Meanwhile,  #526 (link to current docs) might be helpful.. ",
    "dastoori": "@sindresorhus. ",
    "rarkins": "@lukechilds thanks for the clarification.\nGreat that the behaviour is to suppress the round trip if the result is still valid, because Renovate is typically network-bound waiting on API responses.\nI think I will try as you suggest and just let got + cache do its thing for now and fall back to quick-lru if I find memory use is too high, but right now memory use is the least concern so may not be a problem at all!\nMy question is answered, but I will leave this open in case you wanted to use it as a reminder for documenting the readme.. @lukechilds are you aware of this or have any insight? I had a disaster with Renovate when I enabled caching for querying Docker Hub. I never got back to debugging it but it sounds very similar to the above.. FYI, the global-tunnel package does not support NO_PROXY so that's a dealbreaker in many corporate environments that need the ability to bypass the proxy for certain hosts.. In my opinion:\n- baseUrl should definitely be normalized so that there is no need to end it with a /\n- I don't like the URL behaviour and think it's unfortunate if got needs to follow it out of convention\nFor example, a baseUrl for GitHub Enterprise will normally be like https://github.mycompay.com/api/v3 and meanwhile GitHub always document their APIs with a leading slash:\n\nIn my (unmerged) PR to gh-got I supported leading/trailing slashes as follows:\njs\nconst url = /^https?/.test(path) ? path : opts.endpoint.replace(/\\/$/, '') + '/' + path.replace(/^\\//, '');. Whoops, I meant to raise this in lukechilds/cacheable-request instead. Cc @lukechilds . @brandon93s thanks for the suggestion. I think this could be a workaround, but not a perfect solution. The imperfect part is that stale cache entries will be purged by keyv and not available for revalidation. This would significantly increase the volume of data transferred because the majority of lookups are (a) stale, but (b) revalidated.. @sindresorhus from a user perspective it would be an option named like maxCacheAge which serves to set an upper limit on how long the result is used directly from cache before revalidating. A value of 0 would mean to always invalidate.\nIf only the max-age value in Cache-Control could be considered (e.g. not also the Expires value if present), then it could be done in at least two different ways:\n\n\ngot looks at response.headers['Cache-Control] and modifies the max-age value if necessary before passing to cacheable-request, or\n\n\nNo logic change to got and the option is passed transparently to cacheable-request and similar logic is performed there instead. I looked into the details of http-cache-semantics and I think this is already possible, although I'd need to write a test to be sure.\n\n\nThe relevant code is: https://github.com/kornelski/http-cache-semantics/blob/d0bf1baf301dc6044a839ac309685e9385fb6c3b/index.js#L148-L150\nif (requestCC['max-age'] && this.age() > requestCC['max-age']) {\n            return false;\n        }\ni.e. the response will be stored in cache and \"not stale\" for as long as the server says, however there's a function satisfiesWithoutRevalidation() that will return false if the age of that cached response exceeds the max-age in the subsequent request's Cache-Control header.. Renovate uses got, gh-got and gl-got to send millions of queries per day to GitHub, GitLab, npmjs, PyPi, Packagist, Docker Hub, Terraform, CircleCI, and more.\n. For my primary use case, I simply want all paginated results with a single got command, e.g. something like await got(url, { paginate: true }).\nFor my secondary use case, I would like to add a limit to how many results are returned, e.g. maximum 1000. If you prefer that the caller calculate this instead using number of pages returned, it's also OK. But I think users usually think in terms of number of results, not number of pages. The number of returned entries per page is usually an endpoint restriction and users ultimately care about total entries, not total pages. The only downside might be if the number of entries per page is not divisible by the total and hence you need to crop the results.. ",
    "amitmerchant1990": "Cool.. ",
    "austinfrey": "@lukechilds thanks for following up. good to know I'm not crazy :). haven't checked this in awhile but thanks to everyone who worked on it!. ",
    "zckrs": "I have same issue in Node environnement. I try isolate code to demonstrate the bug. \nCurrently  I know bug occurs when I use p-map with a infinite concurrency or superior to length of first argument.. @NotteJacob o_O\nOverride agent fix problem\ngot(url, {json: true, agent: ''})\n. I'm just surprised to fix my problem with this override.\n(node: v6.9.4 here). Exactly same :-/\nMaybe cacheable-request return sometime a req without connection pprt.\n\n. No problem. :smiley: \n429  resolve problem  :tada: . No. Cache is disable :-/ . @lukechilds sorry I try to isolate code who reproduce  bug but without success.\nAnd I can't share the complete application.. ",
    "NotteJacob": "I'm having the same issue but only pops up when I'm using an agent in the options (node.js 8.9.1).\nAlso tried different agents (caw, tunnel) and both have the same result. Version 7.1.0 does not have any issues.\nThe code that reproduced this issue: (error is thrown on the await statement).\n```\nlet agent = new HttpsProxyAgent(this._proxy);\nlet options = {\n    decompress: true,\n    headers: headers,\n    json: true,\n    agent: agent,\n    retries: 2\n};\ntry {\n    let response = await got(this._url, options);\n} catch (error) {\n    console.log(error);\n}\n. @zckrs I need the agent for a proxied request. I'm currently using got version 7.1.0 which works without any issues. @zckrs oh, like that :-) So there might be something up with the agent handling of version 8.0.0. @lukechilds I'm getting the exact same error when I use an http proxy agent in nodejs. I am not getting this error with got version 7.1.0, only with 8.0.0, haven't tried earlier version though.\nThe  code to reproduce the error:\n\"use strict\";\nlet got = require(\"got\");\nlet HttpsProxyAgent = require(\"https-proxy-agent\");\nlet agent = new HttpsProxyAgent(\"{username}:{password}@{hostname}:{port}\"); // http proxy\nlet options = {\n    decompress: true,\n    json: true,\n    agent: agent\n};\nlet request = got(\"{url}\", options);\nlet body;\nlet error;\nasync function doRequest() {\n    try {\n        let response = await request;\n        body = response.body;\n    } catch (err) {\n        error = err;\n    } finally {\n        console.log(error, body);\n    }\n}\ndoRequest().then().catch();\n```\nThis screenshot is my test script to reproduce the error with in the bottom left the error it throws \nwhen running it. In the bottom right you see the node version and npm version.\n. #429 resolved my problem. @lukechilds this zip file contains the index.js and package.json file which reproduces the error on my machine on Node version 8.9.1.\nreproduce.zip\n. ",
    "authguidance-examples": "I can reproduce this in a NodeJS OAuth Secured API that uses the OpenId-Client Library which in turn uses GOT.\nThe API makes introspection calls to validate received tokens. The problem only occurs when I want to view these HTTPS requests in a debugger (Fiddler or Charles), in which case my code needs to configure an agent:\nif (process.env.HTTPS_PROXY) {\n    OpenIdClient.Issuer.defaultHttpOptions = {\n        agent: createMyAgent()\n    }\n}\nThat is, any developer running a server side process that uses GOT is unable to look at HTTP(S) calls, which of course is a common requirement when developing.\n\nTypeError: Cannot read property 'once' of null (index.js 229:19)\n\nLooking at code, the req.connection object is always null when running Fiddler or Charles:\n* req.connection.once('connect', () => {\nSo it feels like the earlier suggestion to check whether req.connection is present would be useful for server side usage also.\nMy code is available here by the way, and is a referred to in a blog I'm writing.\nOther that that GOT is a very nice library - but for now I'm using an old version of OpenId-Client to work around the problem.. Just to say that this is fixed and using Fiddler / Charles in the latest version is fine - great work guys. ",
    "rwlaschin": "I'm seeing this problem :(\nI'm using babel-node/fastify, connecting to mysql db using mysql2.  Everything is running off of localhost.\nnpx clinic doctor --autocannon -- ./node_modules/.bin/babel-node server/index.js\n\"clinic\": \"^2.2.1\",\n\"@babel/cli\": \"^7.2.3\",\n\"autocannon\": \"^3.2.0\",\n\n/Users/rwlaschin/Work/Wholosophy/wholosophy-web/node_modules/on-net-listen/index.js:14\n          resource.owner.once('listening', function () {\n                         ^\nTypeError: Cannot read property 'once' of null\n    at /Users/rwlaschin/Work/Wholosophy/wholosophy-web/node_modules/on-net-listen/index.js:14:26\n    at process._tickCallback (internal/process/next_tick.js:61:11)\n    at Function.Module.runMain (internal/modules/cjs/loader.js:745:11)\n    at Object. (/Users/rwlaschin/Work/Wholosophy/wholosophy-web/node_modules/@babel/node/lib/_babel-node.js:234:23)\n    at Module._compile (internal/modules/cjs/loader.js:689:30)\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:700:10)\n    at Module.load (internal/modules/cjs/loader.js:599:32)\n    at tryModuleLoad (internal/modules/cjs/loader.js:538:12)\n    at Function.Module._load (internal/modules/cjs/loader.js:530:3)\n    at Function.Module.runMain (internal/modules/cjs/loader.js:742:12)\n/Users/rwlaschin/Work/Wholosophy/wholosophy-web/node_modules/clinic/bin.js:376\n      if (err) throw err. ",
    "Angelk90": "@sindresorhus : I had to install them manually, one by one, otherwise it did not work, so what should I do?\n. ",
    "sangram7031": "please send me the link or solution I have the same issue. ",
    "buschtoens": "Facing the same problems. tunnel-agent works though.\nFor anyone stumbling across this, who wants HTTP_PROXY and HTTPS_PROXY environment variables to just work :tm: , install caw as suggested in #79.\njs\ngot('http://github.com', {\n  agent: {\n    http: caw({ protocol: 'http' }),\n    https: caw({ protocol: 'https' })\n  }\n});. ",
    "panva": "How would you feel about exposing StdError as well? When working with got promise rejections a developer might find checking for the following useful.\n```js\n((async () => {\n  try {\n    await got.get(url);\n  } catch (err) {\n    if (err instanceof StdError) {\n      //\n    } else {\n      //\n    }\n  }\n})();\nmaybe considering a different name, such as GotError too?. ",
    "paulknulst": "Hi,\nsorry that does not really solve a problem. I just want to fork your project. pressed the wrong buttons i guess.\nwhat i want to do:\nDuring communication between a REST-API and my project i need to send a POST containing only a string and no json object. additionally i have to set the headers accept/content-type to application/json.\ni know that this is not the standard use case for post calls but the api im working with is kinda stupid. because i want to use your very good implemented package i change this line of code so i can use it with the REST-API im working with.. ",
    "khaosdoctor": "Thank you! \ud83d\ude04 . ",
    "mgbennet": "Using #429, I bypassed the above error but got caught on a second error that I was getting before but didn't mention because I thought it was related to the first. \nException has occurred: TypeError\nTypeError: header.trim is not a function\n    at parseCacheControl (c...\\node_modules\\http-cache-semantics\\node4\\index.js:24:24)\n    at new CachePolicy (...\\node_modules\\http-cache-semantics\\node4\\index.js:89:23)\n    at ClientRequest.handler (...\\node_modules\\cacheable-request\\src\\index.js:62:30)\n    at Object.onceWrapper (events.js:316:30)\n    at emitOne (events.js:115:13)\n    at ClientRequest.emit (events.js:210:7)\n    at URLRequest.ClientRequest.urlRequest.on (...\\node_modules\\electron\\dist\\resources\\electron.asar\\browser\\api\\net.js:207:12)\n    at emitOne (events.js:115:13)\n    at URLRequest.emit (events.js:210:7)\nI'll see about opening an issue on Electron about the missing property.. Ok, so #429 did fix the first issue, and with 8.0.2 I get a bit further.\nBut I still get the second error I mentioned above. This error occurs in http-cache-semantics/index.js, in the function parseCacheControl. With useElectronNet set to false, this function receives a string, With useElectronNet set to true, though, it receives an array instead of length 1, containing the string that should be passed.\nThis still could be an issue with Electron.net not behaving in the same way as node's http, but I'm getting a bit lost trying to track down where it goes wrong.\nMaybe I can fix this with the right options? I'm not sure.. I found it has been reported a year ago in this issue. I've made a note that its affecting version 8.0.0 of got and asked for an update. \nHowever, I did rewind to version 7.1.0 and it works fine. I believe I can live without the features of 8.0.0 for now, so that might be the fix for now if you really need to use Electron.net like I do.. ",
    "jrobison153": "okay maybe this an issue on our end. Looks like npmjs.com has removed the bad version. Our internal npm reg mirror has it cached still. Will close for now. . ",
    "jvetyska": "Maybe this can be solved with got adding an option to force the use of cache.\nThe problem seems to arise when you are requesting from server that has no-cache policy or none specified.\nUsing got you may not be aware of it and still want to cache the pages in memory (Map for example) but what you end up with instead is a mess. It is common practice for servers to return 304 response if the content didn't change - and that is the big problem with current way got is implemented with caching requests - as you will end up with cached 304 response with no content.\nThere are application when many URLs need to be requested and many may be duplicates so the caching is very useful feature. However it seems that it would be very beneficial to be able to override the cache policy of the response or just simply allow stale content.. @lukechilds, I think the first case is more relevant. I think it's the fact that got allows caching of requests, there can be a lot of unforeseen issues down the road, because the caching fully depends on the headers, but it may provide false hope that all the requests are indeed cached. And you are well aware of all the problems with 304 server response. \nSo I think it is great to follow the RFC spec, however it might be good idea to help clear the air and solve a lot of potential issues by adding a flag that would force got to use cached content when available to avoid all the potential revalidation response issues and make the code more predictable for those application that expect to use the cache without the need to reinvent the wheel. . ",
    "reggiezhang": "I also encounter this issue randomly with got 8.2.0.\ngot.stream(imgUrl, { cache: keyv }).pipe(res);\nrecords in mongodb:\n{\n    \"_id\": ObjectID(\"5ab084465a793ecc436a7849\"),\n    \"key\": \"cacheable-request:GET:https://farm2.staticflickr.com/1521/26180297656_675e75a2ce_h.jpg\",\n    \"value\": \"{\\\"value\\\":{\\\"cachePolicy\\\":{\\\"v\\\":1,\\\"t\\\":1521635364661,\\\"sh\\\":true,\\\"ch\\\":0.1,\\\"imm\\\":86400000,\\\"st\\\":200,\\\"resh\\\":{\\\"date\\\":\\\"Wed, 21 Mar 2018 12:29:24 GMT\\\",\\\"connection\\\":\\\"close\\\",\\\"expires\\\":\\\"Wed, 28 Mar 2018 12:29:24 UTC\\\",\\\"cache-control\\\":\\\"max-age=604800,public\\\",\\\"via\\\":\\\"http/1.1 pc-pool116.flickr.gq1.yahoo.com (ApacheTrafficServer [cMsSfW])\\\",\\\"server\\\":\\\"ATS\\\",\\\"x-photo-farm\\\":\\\"2\\\",\\\"x-photo-farm-guess\\\":\\\"2\\\",\\\"access-control-allow-origin\\\":\\\"*\\\",\\\"access-control-allow-methods\\\":\\\"POST, GET, OPTIONS\\\"},\\\"rescc\\\":{\\\"max-age\\\":\\\"604800\\\",\\\"public\\\":true},\\\"m\\\":\\\"GET\\\",\\\"a\\\":true,\\\"reqh\\\":null,\\\"reqcc\\\":{}},\\\"url\\\":\\\"\\\",\\\"statusCode\\\":304,\\\"body\\\":\\\":base64:\\\"},\\\"expires\\\":null}\",\n    \"expiresAt\": null\n}. @lukechilds I haven't try got instead of got.stream currently. I'll let you know if I meet same issue by got later.. ",
    "malsatin": "In new versions this code prevents me from catching all parse errors\nif (statusCode >= 200 && statusCode < 300) {\n    throw new got.ParseError(err, statusCode, opts, data);\n}\nAnd event when I can catch parseError I am not able to get full responce, because it is cut by data.slice(0, 77). @ronnyhaase can you show in sources, where error.responce is set in errors? Because I don't have much opportunity to test errors by hands and just analysing sources. Yes, thanks. I think this issue can be closed. ",
    "ronnyhaase": "I'm just running into a similar problem:\nIn case the server e.g. sends a 400 or 422, it's very likely that there is a body containing details what is wrong, which I can not access because body is not passed in erroring response...\nAm I missing something?. OK, I've got my answer: I can use the response property from the error, error.response.body.\nWhere error is what I receive in a catch.\nStill, it might be considerable to also pass body to the error object in case of a HTTPError or add documentation for this case?. @MattRh \nRight here \ud83d\ude09:\nhttps://github.com/sindresorhus/got/blob/master/index.js#L347\nSo you have access to the response (incl. the body), like this:\ngot(/* ... *).catch(error => error.response /* ... */)\n. @MattRh It should also be possible to solve your scenario:\ngot('https://httpstat.us/400', { json: true }).catch(e => console.error(e.response.body))\nSo I tell GOT to expect JSON, while I get text. Still e.response.body is a String. No additional parsing error or something.. ",
    "ErikPettersson": "This gets the response body \u2014 but it doesn't feel like the most suitable solution.\nPossibly it might not ever close the stream if there is no body sent?\nWhy couldn't this be injected into the error event as the docs say?\ngot.stream(stuff)\n     .on('error', (err, thisIsAlwaysNull, res) => {\n            var body = \"\";\n            res.on('data', (data) => {\n              const decoder = new StringDecoder('utf8');\n              body = decoder.write(data)\n            })\n            res.on('end', () => {\n              console.log(\"END\", body)\n            }). ",
    "davalapar": "https://github.com/sindresorhus/got/issues/450#issuecomment-448253456\n. Truly confusing as hell, turns out yes json and form is required if you want to pass a plain object as the body instead of a form-data instance.\njs\n        got('https://www.google.com/recaptcha/api/siteverify', {\n          json: true,\n          form: true,\n          body: {\n            secret: 'XYZ',\n            response: 'XYZ',\n          },\n        }). ",
    "sotojuan": "\ud83d\udc4d . @sindresorhus Seems like Node 4 doesn't support Reflect.. \ud83d\udc4d . ",
    "dcharbonnier": "It is but the think is that people don't read a full doc, people search for what they need and what I need is to get \"binary\" data so I search \"binary\" and not \"Buffer\". I don't think it hurt to add it and it may save some time for other people but you can close if you disagree.. ",
    "vnenkpet": ":+1:  \nI have the exact same problem. What is strange is that sometimes it actually works OK, sometimes it throws this error.\nI'm pretty much only doing\njs\ngot.stream(downloadUrl).pipe(got.stream.put(uploadUrl))\n . ",
    "arturmuller": "Hey @alextes, thanks for responding over the weekend! \ud83d\ude4f \nWhat do you mean by internal APIs? I thought streams were regular, public (and awesome!) part of Got?\nAnyhow, do you have any tips how to get this to work? Doesn't have to be elegant.. ",
    "mnmkng": "Just wanna reference this other issue that seems very related: https://github.com/sindresorhus/got/issues/476\n@alextes Yes, null req._headers are the cause of our issue too. For us, downgrading to 8.2.0 fixes the problem though.. I just wanted to note, that this PR ( with the return suggested by @sindresorhus ) fixes the issue in my comment in: https://github.com/sindresorhus/got/issues/476 . I can confirm that I'm getting the same error, in an unrelated use case. For me, the byteLength function fails randomly when I receive a RequestError:\n[-] RequestError: getaddrinfo ENOTFOUND xxx.net xxx.net:443\n    RequestError: getaddrinfo ENOTFOUND xxx.net xxx.net:443\n        at ClientRequest.req.once.err (.../node_modules/got/index.js:220:22)\n        at Object.onceWrapper (events.js:315:30)\n        at emitOne (events.js:121:20)\n        at ClientRequest.emit (events.js:211:7)\n        at TLSSocket.socketErrorListener (_http_client.js:387:9)\n        at emitOne (events.js:116:13)\n        at TLSSocket.emit (events.js:211:7)\n        at emitErrorNT (internal/streams/destroy.js:64:8)\n        at _combinedTickCallback (internal/process/next_tick.js:138:11)\n        at process._tickCallback (internal/process/next_tick.js:180:9)\nWhich is correct, I purposefully hit a nonexistent URL to isolate the problem (I obfuscated the address as well as the paths in the error messages)\nThe server will die with:\n```\nbuffer.js:481\n    throw new TypeError('\"string\" must be a string, Buffer, or ArrayBuffer');\n    ^\nTypeError: \"string\" must be a string, Buffer, or ArrayBuffer\n    at Function.byteLength (buffer.js:481:11)\n    at Timeout.setInterval [as _onTimeout] (.../node_modules/got/index.js:202:35)\n    at ontimeout (timers.js:482:11)\n    at tryOnTimeout (timers.js:317:5)\n    at Timer.listOnTimeout (timers.js:277:5)\n```\nThe reason for byteLength throwing is the fact that req._headers are null.\nDowngrading to 8.2.0 fixes the issue.\nThanks for looking into it.. @sindresorhus Sorry for troubling, but there is conflicting information available on the interwebz. Node.js docs state that to be able to use the rejectUnauthorized option, you need to provide a custom Agent. Yet, some of the resources available say that it is unnecessary.\nIn relation to got, is the correct way to pass the rejectUnauthorized option directly to got, or should I pass an Agent configured with the rejectUnauthorized option?\nThank you.. ",
    "rainder": "Ok so the problem lays here \nhttps://github.com/sindresorhus/got/blob/master/index.js#L206\nreplacing \nconst headersSize = Buffer.byteLength(req._header); \nwith \nconst headersSize = req._header ? Buffer.byteLength(req._header) : 0;\nfixes the problem and doesn't break any existing behaviour.. I have the same problem I guess.\n```js\nconst got = require('got');\nconst readStream = got.stream.get('http://domain.com/');\nconst writeStream = got.stream.post('http://domain.com/');\nreadStream.pipe(writeStream);\n```\nthis code just crashes the entire app with the error\n```\nbuffer.js:514\n    throw new ERR_INVALID_ARG_TYPE(\n    ^\nTypeError [ERR_INVALID_ARG_TYPE]: The \"string\" argument must be one of type string, Buffer, or ArrayBuffer. Received type object\n    at Function.byteLength (buffer.js:514:11)\n    at Timeout.setInterval [as _onTimeout] (/private/tmp/got/node_modules/got/index.js:207:35)\n    at ontimeout (timers.js:427:11)\n    at tryOnTimeout (timers.js:289:5)\n    at listOnTimeout (timers.js:252:5)\n    at Timer.processTimers (timers.js:212:10)\n```\nhttps://github.com/sindresorhus/got/blob/master/index.js#L206\nreq._header is set to null in this case, hence error is thrown in setTimeout callback function which crashes the app. Any ideas?. the only way to make my example work is to wait for a response event to be emitted before creating writeStream.\n```js\nconst got = require('got');\nconst readStream = got.stream.get('http://domain.com/');\nreadStream.once('response', () => {\n  const writeStream = got.stream.post('http://domain.com/');\n  readStream.pipe(writeStream);\n});\n```\nalso, same error occurs if you just create post stream without piping to it anything\n```js\nconst got = require('got');\ngot.stream.post('http://domain.com/'); //throws TypeError [ERR_INVALID_ARG_TYPE]: The \"string\" argument must be one of type string, Buffer, or ArrayBuffer. Received type object\n```. any update on this?. ",
    "wwwouter": "I've put the code in a getResponse function and added a test.\nThis test will fail with the old code, but succeeds with the changes.\nI've also added some files to work on VS Code on Windows. I can remove these if you want.. Also: Travis is timing out, but this shows it's ok for at least node 4 and 8: https://travis-ci.org/sindresorhus/got/builds/346221646 . Ok, removed the .vscode folder!. You're welcome!\nCould you take a quick peek at #461? \nNow at least I can catch the error, but it would be even better if there wasn't an error to catch :). That would be too bad, because for us the combination of got and electron works perfectly, except for this error...\nWould it be possible to wrap electron support in a provider and keep it out of the got codebase, but still be available for people who want to use it at their own peril?. ",
    "gasi": "\nWe already check for this here: https://github.com/gasi/got/blob/c3daa9e2e9c7f9070dfa405a7747f75a3a058b04/index.js#L50-L52 So there might be an issue with that check.\n\nI saw that but I am fairly sure it didn\u2019t kick in my case. It\u2019s been a while but the code above should help you repro the issue.. Thanks, @sindresorhus \ud83d\ude04 . ",
    "aoberoi": "related issues:\n446 - i believe this could result in a more elegant solution for OP since they wouldn't have to catch an error in order to get a hold of the response body.\n383, #318 - these would be solved\n. well well, it looks like this discussion was already had in #168. it seems to have concluded that a better solution is something you all would be interested in. is the above proposal something you all can get behind? if not, the json: 'auto' idea sounds interesting to me too.\ncc @floatdrop @sindresorhus @SamVerschueren @Autarc. @sindresorhus i don't think window.fetch behaves the same way, but please correct me if i misunderstood. in your example, the .json() is called on an instance of Response, and only signals that the response body can be parsed and returned as JSON. the request body is completely independent, and the caller of fetch() is responsible for serializing it on their own.\nmy proposal boils down to specifying that the json option is a statement about how the caller wants to serialize the request body (helpful, since fetch() doesn't provide this). but if we want to be more aligned with window.fetch, then we shouldn't even attempt to parse the response body until the caller somehow signals that. all this proposal says is that we shouldn't fail when the caller doesn't signal and the server says the response shouldn't be parsed as JSON.\nit would be helpful to know if you disagree with the specific proposal (and i'm happy to continue discussing) or if you disagree that there is a need. for the latter, i think the justification is both that this keeps coming up (see linked issues) and that window.fetch would allow me to do something that currently got does not.. @sindresorhus @floatdrop @alextes @lukechilds any intention to merge this?. ",
    "AsaAyers": "Thanks. It doesn't seem like a simple count works, I think it's because ava runs tests in parallel. \n\nNote that this only applies to tests within a particular test file. AVA will still run multiple tests files at the same time unless you pass the --serial CLI flag.\n\ntest.serial('Clear the progressInterval if the socket has been destroyed', async t => {\n    const handleCount = process._getActiveHandles().length;\n    const err = await t.throws(got(`http://127.0.0.1:55555/`, { retry: 0 }));\n    t.is(err.code, 'ECONNREFUSED');\n    t.is(process._getActiveHandles().length, handleCount)\n})\nI think it might work to see how many of the handles are timers. Using logging Object.getPrototypeOf(handle) I can see something that says its a Timer, but I don't know how else I can get a reference to that prototype to filter the list with. Object.getPrototypeOf(setInterval(... seems to give me a different thing named Timer.. The problem exists on Mac and Linux, I didn't know if it would trigger on windows. . I added the early return and moved the test into its own file. There are 2 more handles getting created that I can't account for.\nhttps://github.com/sindresorhus/got/blob/9e0d054f726e31f2ef50473d68b1fe74fc9dc2a3/test/socket-destroyed.js#L4-L15\n. ",
    "roblav96": "Can't argue that one :P. ",
    "Hoishin": "@sindresorhus I see. That looks way better and safer solution. I'd be willing to work on it and do a PR for it.. Closing in favor of https://github.com/sindresorhus/got/commit/2b1453734a0b51e5b5663b29c258a831dfe926f8. ",
    "davidtheclark": "I believe the above code, which handles body options, will run whether you initialize with got({ stream: true, body: thing, .. }) or got.stream({ body: thing, .. }). Also found a test that asserts that got.stream({ body: someStream, .. }) works: \nhttps://github.com/sindresorhus/got/blob/81f2537e6950643e986c09c182dbf29d5fcee8e2/test/stream.js#L92-L96\ngot.stream({ body: streamOrString, .. }) is what I was trying myself, and was surprised that it worked fine because the docs seem to suggest it shouldn't.. I noticed today that adding a file with the body option is the only way to get an estimate of its size, which improves progress events. So it seems to me that using body in stream mode might be not just a working option but also the preferred option.. Another point of confusion: If a stream-mode request that could have a body (post, patch, put) does have a body option, you do not need to call req.end() yourself; but if it does not have a body option, or the body is falsy, you do need to call req.end(). I wonder if that can be smoothed out. But, again, I'm not really sure what the intention is around body in stream mode.. @szmarczak The documentation still isn't clear, though, or there wouldn't be this issue. \nI don't see anywhere that says \"stream mode\" means you're piping a stream into the request, and has nothing to do with whether your response is used as a stream or not. That's particularly confusing when it says things like body can be a stream.Readable but \"is mutually exclusive with stream mode\". \nIf the phrase \"stream mode\" were universally replaced with \"piping a stream into the request\", that would be accurate and clarify things, right? Are you open to a PR with that change?\nOr we could add a short section explaining what \"stream mode\" means.. ",
    "MikeyBurkman": "Yeah I think there's a confusion in the docs between request.body and response.body. What @davidtheclark is referring to is that the docs say you can't provide a body in the request while in stream mode, which (I assume) is not correct. Stream mode only affects how the response is parsed and returned to the caller, right?. I'm not really sure why \"stream mode\" would ever need to be specified for the request. If the opts.body is a readable stream, then the body should be streamed, and when the stream ends, the request should be ended automatically. \nStream mode should only be there to specify \"stream the response instead of loading it all into a single object in memory\". I really think that stream mode should only affect the response. \nDisclaimer: I'm just some random dude and I'm just describing how I think the library should behave. I do not know exactly what it actually does. Hence why there's this issue -- the docs are not clear on this.. ",
    "BannerBomb": "I found out why it wasn't it is because in March GitHub disabled anonymous gist uploading which requires you to provide Authentication now.. ",
    "aviadatsnyk": "same here, the solution we found was just wrapping the call to got with a try ... catch and calling is_retry_allowed inside the catch block.\nThis is using got@8.3.1\n\\CC @orsagie. ",
    "ikokostya": "I think error response body already available using err.response property:\n```js\n'use strict';\nconst got = require('got');    \n(async () => {   \n    try {  \n        await got('https://github.com/sindresorhus/got/404');  \n    } catch (err) {  \n        console.log(err.response.body);  \n    }  \n})();\n``. @brandon93s What you mean underJSON request body? Body wrapped withJSON.stringify()` is valid json body, no matter it's object (hash) or not. \n. > When passing a string, got cannot confirm that the input is valid JSON\nWhy? got converts body to string with JSON.stringify: https://github.com/sindresorhus/got/blob/ad7b361dcb2490c3864b845b979b756f13f7d89b/index.js#L583\nJSON.stringify() takes any type:\n```\n\nJSON.parse(JSON.stringify(null))\nnull\nJSON.parse(JSON.stringify(1))\n1\nJSON.parse(JSON.stringify('str'))\n'str\n``. @brandon93s  ?. To be clear:json = true` option is a convenience method to convert body to valid JSON string and setup corresponding request header. Current behavior is incorrect and unobvious. \n\nUnlike request, response body always parsed https://github.com/sindresorhus/got/blob/ad7b361dcb2490c3864b845b979b756f13f7d89b/index.js#L377 without checking its type, but it can be primitive type.. @sindresorhus ?. @alextes Thanks for the exhaustive answer.\n\nMaybe you can add what your use-case is for making the body a string?\n\nI want to send POST request with string body as JSON:\njs\ngot(url, {\n   headers: {\n       'content-type': 'applicaiton/json'\n   },\n   body: JSON.stringify('str')\n})\nOf course, I try to use json: true option to simplify my code. \n\nIf I had to guess why it's because there will be more users that accidentally pass a JSON string than users that want us to stringify a JavaScript string or number.\n\nNow I get TypeError when provide non-object as request body. Without this restriction body will be successfully converted to string and another service can return response with 400 status code. Technically it's more correct behavior, because we send correct JSON payload, but in invalid format. There are no big difference between object and non-object payload, because user can also send object payload in invalid format. That's why I think current restriction is not very helpful. If user want to check body shape for another service, it should make it explicitly.\n. ",
    "jas0ncn": "oh, thanks a lot. It's my negligence...I'll close this pr.. ",
    "kirillgroshkov": "Yes, workaround still works for me, thanks!. ",
    "iflp": "Thanks for the fast reply.\nI need to explicitly send the request without setting a user-agent. It's weird I know, but that's the requirement. I'm aware of the best practices and whilst I appreciate the intention behind making it compulsory, I think we should follow the RFC spec and let the user decide what to do.\nMaybe allowing users to opt-out is a good compromise? E.G. Explicitly setting  user-agent: null will remove it, if nothing is specified add the default user-agent.. ",
    "kaatt": "Explicitly setting user-agent: null doesn't remove the header. Maybe it works for unicorns but not user-agent.\n```\nconst got = require('got')\ngot('http://httpbin.org/anything', {\n  headers: {\n    'user-agent': null\n  }\n}).then(r => console.log(JSON.parse(r.body)))\n```. ",
    "unquietwiki": "@sindresorhus Acknowledged; just wanted to bring it to your attention. Thanks!. ",
    "jstewmon": "This issue was a bit tricky - it came down to got's normalized arguments not accounting for the fact that cacheable-request uses url.format to create the cache key. url.format doesn't use the same option parameters as http.request, so the options have to be explicitly aligned for everything to work correctly. I suppose this type of issue can be more easily mitigated if everyone standardizes on the WHATWG URL API.. @ewolfe that feature is usually implemented with a discrete option baseUrl to disambiguate the caller's intent. I'd say that's a complementary feature to being able to create an instance, but deserving of its own PR, since it would add a config param.. I actually ended up coming back to got for this after trying to solve the problem with axios interceptors. :-)\naxios request interceptors run before their dispatchRequest method, which is where they normalize the request.\nBut, that's not your point...\nI considered allowing the config setting an array or a function, but I decided that it was best to start the conversation around the feature by making it as simple as possible.\nIf we allow the setting to be an array (without providing a custom interface), I think that might provide better mechanics for anyone wanting to apply a custom merge strategy to the options for a new instance (versus the function wrapping discussed earlier).\nIf it's conceivable that additional hook points would be added in the future, then we might consider having a top-level hooks setting, which is an object where they keys are the hook names and the values are Array|Function.. I rebased off master and updated the interface to reflect the discussion about future-proofing the configuration interface for additional hook events.. I noticed that I used inconsistent formatting on the EE proxy commit, so I pushed an update to make them look the same.. This is a complicated issue due to the inconsistencies of the node apis for urls and http requests...\nThe http.request options argument aligns more closely with the legacy [urlObject] structure when the argument is an options object (not an instance of URL) in that it expects auth, not username and password. http.request requires path to be ${pathname}${search}.\nI originally thought it would be better to use WHATWG URL because it only has pathname and search, which would mean that got would know to set search, not path in normalize-arguments, but what about the additional request options, which are not members of URL?\nI'm not sure yet what http.request will do if the argument is an instance of URL with additional option properties that are not part of the URL interface (localAddress, etc).\nI skimmed the cacheable-request docs and it doesn't actually document the contract it uses to compute the cache key, so that also needs clarification.\nIn summary, both url apis use pathname and search to format the href string while http.request expects a path option with the two combined.\ncacheable-request stipulates the contract for determining the cache key, so my goal here was to ensure that got's normalized arguments conform to both the http.request api it tells cacheable-request to use when sending the request and to the api used to format the cache key.\n@sindresorhus if you have a suggestion on how to create better alignment between the url apis, http.request, cacheable-request and got, I can try to work something out, but it appears arduous to me. I'd suggest taking this change to fix the current bug if a more elaborate plan is conceived.\n[urlObject]: https://nodejs.org/dist/latest-v8.x/docs/api/url.html#url_legacy_urlobject. It looks like node will drop any additional properties if options is an instance of URL.\nThe ClientRequest constructor will reassign the options variable to the result of [urlToOptions], which plucks only the known URL class properties.\n[urlToOptions]: https://github.com/nodejs/node/blob/v8.11.3/lib/internal/url.js#L1298. Here's an idea - if cacheable-request wants to maintain the same contract as http.request, then we can fix the issue there by formatting the key according to the options understood by http.request. I'll update the linked issue with that suggestion.. I updated to cacheable-request@4, but the new version is causing something to hang. I don't have time to look into it right now.\ncc @lukechilds . Yeah,  I suspect that the got test is hanging because the path being used in the request does not match a route the server is listening for. I think we just need to verify that the cacheable-request behavior is correct and that the test set up is incorrect .. I found the problem. There's a bug in https://github.com/lukechilds/cacheable-request/pull/43. The search property doesn't have the leading ?.\nI'll file an issue and submit a patch.. Indeed, it is. I updated this PR to cacheable-request@4.0.1 and all tests are now passing.. Thanks for opening that issue - I reviewed the docs today when I made this change and was disappointed that they didn't have an option to disallow _ when the alpha chars are uppercase.. I really like being able to configure event listeners on a per-instance basis - it's really useful for being able to add instrumentation to a client without having to litter every request site with the event listeners.\nI have a few questions regarding the implementation:\n\nShould these go under hooks? These are actually EE listeners, so it might be better to give them a discrete top-level config key like listeners. This would also disambiguate them from hooks, which are stated to allow modification during the pipeline.\nThe EE listeners can't modify anything, so they should not be awaited even if they are async.\nI don't think it makes sense to have some aspects of instance configuration be frozen while others are not. Pick one - frozen or unfrozen. I don't see a practical reason why the configuration is frozen... Freezing makes perfect sense when there is state synchronization that happens during instance setup, which would cause modifications to the configuration to be ignored by the instance, but I don't think that's the case with got, so I'd say got should not freeze configuration. If a user wants to ensure the config is not modified, they can freeze it themselves when they create the instance.. > I don't understand. EE listeners aren't awaited.\n\nYou're using callAll, which awaits the hook function, in response to an EE event.. Can we agree that the options should either be frozen or not? If so, then I think you can cut down this PR by reverting the changes to how the configuration is setup and normalized, right? That will allow us to focus on the interface for the event listeners.. @szmarczak can you make separate pull requests out of these changes? I think there are three things happening here that aren't strictly related:\n- new option to not freeze options\n- hooks option default assignment is moved into got.create\n- whitespace reformatting\nThere are some changes leftover from the other PR that appear to be extraneous - defineConstPoperty and changes to hooks normalization.. Per the previous discussion on #523:\n- options should be frozen or not, without exceptional cases, so we don't need any of the changes that allow for hooks to be modified if the config is frozen.\n- only known hooks should be validated, so that callers are not unnecessarily constrained on what is a valid object\n- Object.entries is not an equivalent for for (... of ...) or Array.prototype.forEach\nI thought we were in agreement on those points, which is makes the three changes I mentioned above unrelated. I think @sindresorhus agrees (based on thumbs up on my request to split)?. > I still don't see what's wrong with that. People can use this feature to name hooks.\nThey can't b/c we iterate the hooks as an array to evaluate them. The API describes that the hooks are Array<Function>, so that's what I suggest we validate.\nI don't have a great example why someone would attach a property to an Array, but I'm sure it happens.\nHonestly, I can't believe we discussing whether it's sensible to iterate an Array with Object.entries. I think it's nonsensical.. Can we close now that #534 has landed?. Please hold on merging for a few minutes. I can figure out a test for the promise interface too.. Ok, tests added for both interfaces. er... i neglected git add, so only one test was included. I'll open another PR. I rebased this on master, since #525 is still being discussed, and the two PRs are not coupled.. @szmarczak thanks for the flattering review :-). I'm not certain it will never be thrown. I searched through node and libuv without finding any reference to it, but that's not proof.\nI ended up removing it b/c I couldn't think of how to describe it in the docs.. I'm not convinced we should use ECONNRESET for the client's idle socket timeout. It's true that node uses that code, but when node raises the error, it's ambiguous as to which side hung up.\nI think we should keep our socket timeout error code as ETIMEDOUT to disambiguate it from a hangup by the server.\n```\nconst http = require('http');\nconst {promisify} = require('util');\nconst s = http.createServer((req, res) => {\n  res.setTimeout(1);\n});\nconst listen = promisify(s.listen.bind(s));\n(async () => {\n  await listen()\n  const request = http.request({port: s.address().port});\n  request.on('error', logError)\n  request.end();\n})();\nfunction logError (error) {\n  console.error('%o', error);\n}\n```\n{ Error: socket hang up\n    at createHangUpError (_http_client.js:331:15)\n    at Socket.socketOnEnd (_http_client.js:423:23)\n    at emitNone (events.js:111:20)\n    at Socket.emit (events.js:208:7)\n    at endReadableNT (_stream_readable.js:1064:12)\n    at _combinedTickCallback (internal/process/next_tick.js:138:11)\n    at process._tickCallback (internal/process/next_tick.js:180:9)\n  [stack]: 'Error: socket hang up\\n    at createHangUpError (_http_client.js:331:15)\\n    at Socket.socketOnEnd (_http_client.js:423:23)\\n    at emitNone (events.js:111:20)\\n    at Socket.emit (events.js:208:7)\\n    at endReadableNT (_stream_readable.js:1064:12)\\n    at _combinedTickCallback (internal/process/next_tick.js:138:11)\\n    at process._tickCallback (internal/process/next_tick.js:180:9)',\n  [message]: 'socket hang up',\n  code: 'ECONNRESET' }. @sindresorhus I wasn't sure whether you meant to just make a copy of the source array or merge the array into the target's property value (like lodash). I assumed (and implemented) the former, since that's closest to what we've been discussing, but your comment about lodash gave me some doubt.. Hmm... I'm not sure I see how it did so. Obviously, I can see the paragraph was removed, but the behavior appears to be the same.\njs\ntest('extend freezes without copying', async t => {\n    const makeCounter = (() => {\n        const hook = () => {\n            hook.count++;\n        };\n        hook.count = 0;\n        return hook;\n    });\n    const reqCounter = makeCounter();\n    const a = got.extend({hooks: {beforeRequest: [reqCounter]}});\n    await a(s.url);\n    t.is(reqCounter.count, 1)\n});\n```\n  1 test failed\nextend freezes without copying\n/Users/jstewmon/dev/forks/got/test/create.js:83\n82:     const hook = () => {\n   83:       hook.count++;\n   84:     };\nRejected promise returned by test. Reason:\nTypeError {\n    message: Cannot assign to read only property 'count' of function '() => {\u240a\n          hook.count++;\u240a\n        }',\n  }\nhook (test/create.js:83:4)\n  Immediate.setImmediate (source/request-as-event-emitter.js:177:11)\n```. Yesterday, I sketched out something to enable this. I should have a straw man ready to post tonight or tomorrow.. @gajus would you mind taking a look at #561 (WIP)? I think it would facilitate the introspection features you're describing. I'm looking for feedback on the interface and mechanics, so feel free to add your perspective.\nNotably, cache hit/miss is not facilitated. I need to look again, but I think those have to be inferred by 'response' without 'request' (for a hit) and 'request' (for a miss).. Note: I didn't do anything related to the retry event b/c it's essentially a private event. I think it's possible to infer when a retry occurs using the options object (since the instance is unique and persistent across request attempts), but it may be more ergonomic to expose the retry event.. The set of events is large, but I didn't really consider that to affect the API surface area. Consider that if instead of an object, you called addListener, then there's just one new method.\nI thought it was worth providing a porcelain interface, so that users would be saved from creating memory leaks if they're using keepAlive and subscribing to socket events.\nI also thought it was really convenient to be able to subscribe to an arbitrary event without having to wire up all the intermediate listeners.\n\nWith this abstraction, users also lose ability to unsubscribe when they're done with an event.\n\nI don't know what you mean by this.\n\nIf we were to expose something like this, I would prefer just a single firehose event that includes a type attribute to indicate the type of event of the message.\n\nThat's certainly possible, but it will less efficient because we'll have to subscribe to everything and call the user's handler for every event.. @lostfictions I'm not able to reproduce your issue (see #564). What version of node are you using?. Ah, this does seem to be a bug in got's redirect handling. In your example, google responds with a http to https redirect. got uri-decodes the location header in the response, resulting in a new request with unescaped path option.\nIntroduced in 38931e2.. You can use the beforeRequest hook to modify the path option that will be sent in the request.. @sindresorhus, maybe there should be a normalizeUrl option for this. Changing the behavior could break lots of apps that expect got to ensure the request is sent with a valid URI.. Ok, I was thinking that reserved characters were required to be percent-encoded, but they are not when their meaning is not significant in the component in which they appear. So, in the case of the query string, :/? are not significant. However, if an & appeared in that uri-with-query parameter value, it would be interpreted as a query delimiter.\nGot's handling of this case changed in b8a086f8da53d57fdf11ba49eefa01d778a4f69f - urlSearchParams.toString() appears to be encoding more characters than it should ([source])(https://github.com/nodejs/node/blob/8b4af64f50c5e41ce0155716f294c24ccdecad03/lib/internal/url.js#L826). :/ are not in the ranges specified for encoding by WHATWG's query spec.\nSo, the unexpected behavior seems to be the result of a bug in node.\nStill, we can easily fix the issue in got by simply fixing the normalization routing to not round-trip query through URLSearchParams when it is a string.\nEdit: The portion of the WHATWG spec I referenced above was for parsing, not serializing.\nThe serialization spec requires a much larger character set to be encoded.. I erroneously reference the parsing spec, not the serialization spec in that comment. I've amended the comment to clarify. I don't see any problem with the serialization implementation.\nThe case you gave illustrates the difference between what must be encoded vs what may be encoded for the URI to be valid. I think the WHATWG spec encodes all chars that may be encoded.. It looks like the global defaults are not inherited? Was that intentional? My expectation would be that when I create a client, the global defaults are inherited.\nI think you can easily address by renaming the function argument to clientDefaults and making this line:\njs\nopts = extend(true, {}, defaults, clientDefaults, opts);. Ok, I see now that got.create is assigned at the end of this method, so that the exported got has create which uses the closure binding to preserve the global defaults.. I'm sorry, but we are completely misunderstanding each other.\nIf I understand your suggestion regarding a handler, then a custom handler would run before the default handler.\nThe entire point of this feature is to create an opportunity to add a signature after the request has been normalized, just before it is sent.\nHere's a little test that might illustrate the difference:\njs\ntest('does something useful', async t => {\n    const instance = got.create({\n        baseUrl: `${s.url}/api/`,\n        options: got.defaults.options,\n        methods: got.defaults.methods,\n        handler: (url, options, next) => {\n            t.is(options.hostname, 'localhost')\n            t.is(options.path, '/api/?foo=bar')\n            return next(url, options);\n        }\n    });\n    await instance('?foo=bar');\n});\nresult:\n```\n1 test failed\ndoes something useful\n/Users/jstewmon/dev/forks/got/test/finalize.js:95\n94:     handler: (url, options, next) => {\n   95:       t.is(options.hostname, 'example.com')\n   96:       t.is(options.path, '/api/?foo=bar')\nDifference:\n\nundefined\n'example.com'\n\nObject.handler (test/finalize.js:95:6)\n  got (source/create.js:34:20)\n  test/finalize.js:100:8\n``. I'm ok with that. I chosefinalize` to indicate that this is the very last thing that happens before the request is sent.\nI'll rename.. I considered doing that in assignOptions, but I decided that it was better to leave that choice to the caller, since I think it is pretty easy:\njs\nconst got = require('got');\nconst a = got.extend({beforeRequest: opts => { opts.header.foo = 'bar'; }});\nconst b = a.extend({beforeRequest: opts => { a.defaults.beforeRequest(opts); opts.header.bar = 'foo'; }});\nIf the functions are chained, I don't think there's a convenient way to replace the beforeRequest option if that's the behavior one desires.. I took a look at #510 and had the same initial reaction as others - I don't get it. :-)\nPersonally, I don't see providing merge/extend features as creating a lot of leverage. Since the options are accessible on a got instance, the caller can always use a merge strategy of their choosing to create the configuration for a new client. If it were my choice, I'd probably just provide Object.assign({}, old, new) semantics for creating new instances.. Ah, I didn't see it. Thanks and done!. Is it worth noting that changing the body is not recommended, since the content-length has already been set?. I strongly disagree. I'll repeat the rationale I provided earlier in the discussion:\n\nIf we allow the setting to be an array (without providing a custom interface), I think that might provide better mechanics for anyone wanting to apply a custom merge strategy to the options for a new instance (versus the function wrapping discussed earlier).\n\nRequiring the use of a custom interface adds no value and prohibits advanced configuration scenarios.. I saw RETRY_AFTER_STATUS_CODES was chosen recently in #508, but I'm wondering if y'all would like to reconsider that choice and make it retryAfterStatusCodes as was the alternative suggestion in that discussion.\nThis is the only place in this package where this naming style is used. I know that uppercase constants is conventional in some languages, but not JS. Further, having two styles for variable names requires a decision to be made about when to use the uppercase style. Is it for all vars declared as const? It is for const outside of a function? . > BTW, do we really need to specify empty hooks in the defaults?\nI did it this way, and ensured hooks are defined as arrays during normalization, so that when hooks are evaluated, we don't have to do any type checking or defaulting.. There are a few ways this could be strictly prohibited, but I think this is case where it's best to provide guidance but not prohibit advanced usage. Someone may have a valid reason for modifying the body, so this note is here to hint they they probably need to reassign content-length if they change body.. That would violate the expectation that got will make no further changes to the options before the request is sent. ;-). Ah, I see your point now...\nI suspect that there is a performance advantage to defining the defaults.\nWithout the defaults, an object and knownHookEvents.length arrays will be created for every request, resulting in more work for the garbage collector.\nFurther, I think that dynamically creating the properties will introduce a new [hidden class] for every request. So, I think it is best to keep the default defined.\nThese are certainly micro optimizations, but I don't see a disadvantage to defining the defaults. Do you?\n[hidden class]: https://draft.li/blog/2016/12/22/javascript-engines-hidden-classes/. If that is a signed header, it will break the whole thing. It's a big deal.. I updated to say that Got will make no further changes to the request before it is sent.\nI used the signing feature as an example of why I did not want to move the call before the last attempt to set content-length, but we shouldn't specifically mention request signing in the docs for beforeRequest, since it's not tightly coupled to request signing.. This fails to validate the known hooks if something other than an array is provided, which will result in an error upstream.. This is not equivalent to the current implementation. Consider these examples:\njs\nconst a = [1, 2];\na.foo = 'bar';\nObject.entries(a); // [ [ '0', 1 ], [ '1', 2 ], [ 'foo', 1 ] ]. The point of this test is to show that extra keys are not required to pass validation b/c they should be ignored. The test title could be more clear.. I'm not sure what the origin of this conditional block are, but I think the right way to handle this event is to remove the if block and make this:\njs\nreq.on('socket', () => { ... });\nhttps://nodejs.org/dist/latest-v8.x/docs/api/http.html#http_event_socket. Actually, since onSocketConnect and onAbort should be attached to the request, I don't think these are sensible hooks for got to configure directly. If you want to configure these for a got instance, you really just need to configure a listener for request and attach the request event listeners in the request listener.. It allows for encapsulation. Here's a contrived example:\n```js\nclass GotHooks {\nconstructor () {\n    this.message = 'Encapsulated Got Hooks';\n    this.beforeRequest = [\n      () => this.runRook()\n    ];\n  }\nasync runRook() {\n    console.log(this.message);\n  }\n}\n```\nIf got validates only the properties it is concerned with, then everything is fine. If got extraneously demands that the object only have properties that correspond to known hooks, then the user has to jump through some hoops to create an object that accomplishes the same thing.. Thanks for the reference to #429. Maybe I'm missing something, but I don't think that was the right fix b/c if req.connection is just testing a race condition. Shouldn't it be:\njs\nreq.once('socket', (sock) => {\n  sock.once('connect', conn => {\n    // ...\n  }\n};\nI can see the convenience of low-friction hooks. Maybe there's a way to make the configuration a sort of DSL that got can use to wire these up. Something like this:\njs\n{\n  events: {\n    request: {\n      ['on|once']: {\n        socket: {\n          null: [(sock) => { console.log('request.on(socket)') }],\n          connect: [(conn) => { console.log('socket.on(connect)') }]\n        }\n      },\n    }\n  }\n}\nWith the above, the configuration can be traversed and the listeners can be subscribed without having to add handling code to got for every event.\nI used null as a sentinel value to mean the subscriber for the event as opposed to a child subscription. Something else (symbol?) would work also.. Ah, thanks - I got tripped up reviewing the diff.. It's not needed. I don't know why I put it there. \ud83e\udd2a. I considered it, but when I looked at the diff, I didn't think the one line change raised the cognitive burden enough to warrant a separate commit. \ud83d\ude05. Does this facilitate something? I'd avoid duplicating access points.. I think this is overkill. If it's not overkill, I guess I'd say just call defineConstProperty(got, got) b/c it looks like stream and extend were arbitrarily omitted.. I see it was like this before, but why is configurable set to true? We're locking it unless you're serious enough about changing it to redefine the property?. got.defaults.options.hooks is duplicated. Consider why all options properties aren't copied to the got instance.. I would just get rid of it. When an object has a custom interface, those customizations should be documented, so that users have a way to learn about them. Documenting this stuff adds clutter to the documentation, adding friction for users.. I don't think this is right. I think the request timeout was introduced in https://github.com/sindresorhus/got/pull/308, which describes it as the time for the entire response to be received.\n'end' is not an event for http.ClientRequest, is it? It looks like tests around this are contrived to pass - I don't see a test that shows the timeout is not raised if the request (and response) completes before the timeout.\nI think this should be something like:\n```js\nreq.on('response', res => {\n  res.on('end', () => {\n    clearTimeout(req.requestTimeoutTimeout)\n  })\n}). @brandon93s Thanks for the reference to #117.\nIt looks like the intent was to ensure the response data was handled after the event listeners that clear timeouts were run.\nIf a callback is provided for request, it will be the first handler to run.\nI can make another pass at this, to evaluate when the timeout clearing handlers are being run.\nDoes my analysis sound right? See any other issues?. You didn't parse my statement the way it was meant:\n\nI'd avoid duplicating access points.\n\nI was saying you're creating more than one way of accessing the same object: got.hooks and got.defaults.options.hooks. The paths to access are duplicated.\nMiscommunication and disagreement are bound to happen in async discourse, but we can figure things out without condescension. We can better understand each other by asking questions until the meaning is clear without presuming the other person is an idiot. \ud83e\udd17. I didn't think I needed to provide a test case just to report the problem because I could plainly see that the timeout would not be cleared.\nIt's working for the Promise interface because calls to reject are ignored if resolve has already been called.\nBut, we can verify that the implementation is wrong using the stream interface:\njs\ntest.only('no error when timeout not breached', async t => {\n    const stream = got.stream(s.url, {\n        retry: 0,\n        timeout: {\n            request: reqDelay * 2\n        }\n    })\n    stream.on('error', err => { t.fail(`error was emitted: ${err}`) });\n    await getStream(stream);\n    await delay(reqDelay * 3);\n    t.pass();\n});. I've reviewed those issues and do not think this change regresses either of them.\n\nThe problem reported in #427 and fixed in #429 was that req.connection may be undefined. I've removed the reference to req.connection in favor of subscribing to the socket event to get the connection. So, this should not regress that issue b/c we don't try to access a property which may be undefined.\nThe memory leak fix from #465 is addressed by the if (socket.connecting) check. It prevents unbounded event subscriptions with keep-alive is enabled on the agent.. Tests that have setup are always contrived to pass - I should have just said that tests are missing for cases where the timeout is not breached. I didn't mean that you deliberately introduced a bug. :-). Technical conversations are usually a mixture of colloquial and technical terms.\n\nI think it's reasonable to expect to be able to converse like we're people, without being rude or disrespectful.\nApparently, those expectations are not going to be met here. :-(. Thanks, no hard feelings. Note: this setImmediate deferral was introduced in https://github.com/sindresorhus/got/commit/a1eb3f7 in exchange for get being deferred. get is currently deferred (didn't track down the commit), so this does not need to be deferred.\nEither get or emitter.emit('request', req) needs to be deferred to give callers a chance to subscribe to the request event.. > The main intent was to emit response ASAP\nThat's not how I read it. There are 3 emitters involved, so I'm not sure which one you mean. The emitter response event is emitted from getResponse, so setImmediate here delays that. The req emitter's event isn't affected by this setImmediate.\nThis is the background information I found:\nThe version of timed-out being used at the time of #117 listened for the response event of the request to clear the timeout:\nhttps://github.com/floatdrop/timed-out/blob/v2.0.0/index.js#L31\nThe request object was passed to timed-out, which would setup that listener.\nThe statement that was deferred with setImmediate called unzipResponse from the http.request callback, which would have run before timed-out's listener.\nSo my assessment was that the intent was to allow timed-out's listener to run before the response stream was connected to unzipResponse.\nNow that timeout.request is waiting for response.end, I think deferring the call to getResponse actually increases the possibility that the timeout will breach.\nSince it is quite common to use a request callback, I think a better solution to checking a timeout against the response event would be to use setImmediate in the timer callback to defer the error emission to the check phase of the event loop in case the response had been received but was still queued due to load. At a minimum, the listener that clears the timeout could be subscribed with prependOnceListener to ensure it runs earlier.\nI thought there might be some practical purpose other than the ordering of the response handlers (like allowing subscriptions to some event emitter), but I don't see any such purpose, and I think we can clearly see that the response event listener order is no longer applicable.. > If an error was emitted before the response, then boom.\nI don't follow. The code in question is in the request callback, which is listening for the response event.\nHere's some code to illustrate what I meant about using setImmediate with timers. The big comment elaborates on the rationale.\n```js\nlet connected = false;\nlet connectTimeout = setTimeout(\n    () => {\n        if (!connected) {\n            // Timers run first in the event loop, so schedule the error\n            // after the IO events in this cycle in case the connection is\n            // ready. When load is low, this doesn't matter, but when load\n            // is high, there may be many IO events that are ready on each\n            // cycle, and the intent of the timeout is to cancel operations\n            // which are not ready.\n            setImmediate(\n                () => {\n                    if (!connected) {\n                        req.abort();\n                        const e = new Error('Connection timed out on request' + host);\n                        e.code = 'ETIMEDOUT';\n                        req.emit('error', e);\n                    }\n                }\n            )\n        }\n    },\n    delays.connect\n);\nreq.once('socket', socket => {\n    connected = !socket.connecting;\n    if (connected) {\n        clearTimeout(connectTimeout);\n    } else {\n        socket.once('connect', () => {\n            connected = true;\n            clearTimeout(clearTimeout);\n        })\n    }\n});\n\n``. I'm using a [double-check locking pattern](https://en.wikipedia.org/wiki/Double-checked_locking) to conditionally emit the error IFF the timer expired and the awaited resource was not ready in the poll phase queue. Take note thatconnected` is checked in both the setTimeout callback and the setImmediate callback.\n\n@floatdrop added here setImmediate to emit response ASAP (to clear the timeouts, before there are any errors thrown).\n\nDo you mean that setImmediate was added to allow the timeout event listeners to run before the response stream is handled by getResponse?\nI gave a detailed explanation above about why the event emission order is not actually affected by the setImmediate call. I also explained why the order of the listeners is not currently relevant b/c there are no timeouts that depend on the timing of the response event.\nI am interested in adding a timeout for the response event b/c it's useful to abort the request if the server takes too long to respond to the request.\nI'm suggesting that it is more expressive and, thus, more maintainable to address the problem of timeout errors being spuriously emitted when a system is under load by deferring timeout error emission until the poll phase following the timer expiration, which is what I've postulated was the intent behind wrapping getResponse (formerly unzipResponse) with setImmediate.. I think we're stuck talking in a circle. Maybe someone else can chime in an help us converge our understanding.\n@sindresorhus @brandon93s @knksmith57 any clarifying insights you can add?. I wouldn't say you're wrong, but I think it's more subtle than that. Have you carefully reviewed the doc I linked earlier about the [event loop phases]?\nThe timer callbacks get to run first, then the data callbacks, then setImmediate callbacks.\nSo, when the timer breaches, if the system has been busy, the data callbacks may be ready to execute, but they haven't had their turn. So, if we move the emit error call to setImmediate with that double-check pattern, we can allow the busy system to process the data callbacks that are ready but haven't had their turn.\nThe point is that if we're checking connect timeout. The connection may have already been established, but its event hasn't fired when the timeout callback is run.\n[event loop phases]: https://nodejs.org/en/docs/guides/event-loop-timers-and-nexttick/. This is a tricky topic because of the changes in behavior over time.\nWhen I've referred to the response event, I've been talking about the behavior and intent at the time (circa 2015) that the setImmediate deferral was added in #117. The response event is not currently used to clear any timeouts, so it is not relevant to this change.\n\nYou were trying to illustrate the first sentence using the connect timeout, though it had been connected already.\n\nNo, the statement you quoted was in my original analysis. I was suggesting that there was a more precise way of mitigating #117 than deferring the response piping with setImmediate.\nI didn't want to use the response event to illustrate how that suggestion would be implemented because none of the current timeouts depend on the timing of that event. I used the connect event as an example in the current code because it is used to clear the connect timeout.\n\nIs it possible to receive connect event and response (with some queued data) in the same loop?\n\nI don't see any reason why that would not be possible, but their listeners would be notified in FIFO order (connect before response). Does it matter?. > Then the connection is not established\nThe underlying system operation completes before we're notified. That's the purpose of the poll phase - to notify us that the IO operations we listened for are complete.. Being able to set timeouts around each phase is more useful that timing each phase from the beginning of the request.\nA concrete example is being able to time the response phase (TTFB) when the target is a load-balanced java service which may be undergoing garbage collection. We often want to set a very aggressive response timeout in this case, so that we can retry the request immediately against another instance.. I wasn't sure that this was the precise change needed. My objective was to expose the TimeoutError to a client using the Promise interface.. I think the names should be as transparent as possible. lookup, connect and response are nice because they map directly to the event that ends the phase.\nrequest and socket are the outliers, but I left them as they were to maximize backwards compatibility.\nIf we want to forego backwards compatibility, I'd suggest renaming request to overall or total. socket may be more expressive as idleSocket, but I think it's too pedantic to justify the incompatibility.. @sindresorhus what do you think about changing request to overall or total?. Following up on this, I realized that the response timer would start too soon if the request spent significant time writing to the socket, so I implemented a fix for that by emitting a custom event on the request when the body has been written.\nThis also enabled the addition of a send timer.\nIf we were starting from scratch I would name the send timer request and I would name the request timer overall. But, I worry that changing the meaning of those names is subtle enough to go overlooked by users, leading to bugs that can be avoided by just keeping the imperfect names.. Ugh, I forgot about AppVeyor. I'll look for an alternative. Suggestions welcome.. That looks handy :-). I updated these when I was working on #534, but I apparently lost the diff somewhere along the way.. Yes, sorry for tacking that on to this PR. I didn't expect you to review so quickly. I'm not working on any more changes. :-). This might not be necessary. Maybe we can just pick the right target based on whether is.array(objValue). I was running short on time, so I did this to get it working.\nI think we could ditch cloneDeep as a dep if that works.. Yeah, I made it only deep copy plain object, since all other types are merged by replacement.. I'm fine either way on this one.\nI interpreted the previous behavior as undefined being a sentinel value that can be used to remove a setting, i.e. a discrete feature of got's extension behavior.\nThere is a test that verifies that null headers are omitted from the normalized arguments, but I've addressed that case in normalize-arguments.\n@sindresorhus do you have a preference?. Ack. This is the same behavior as we're discussing above, so we'll resolve this when we resolve that.. Just to clarify, based on your complete suggestion below, you think undefined values in the source should be noop and the target value should be preserved, right?\nThat is what lodash.merge does, but I don't understand the rationale in that approach. If the key exists in the source, I think it expresses some intent of the caller vs the value being undefined b/c the key does not exist.\nI would suggest that when the key exists in the source and the value is undefined, the result should either be:\n- omit the key from the result\n- set the key to undefined in the result\nI could be persuaded that the source value should be ignored, but I the rationale isn't obvious to me.. I pruned it because I didn't think it was necessary for us to document the language feature, and the reader's attention to detail is inversely related to the length of the docs.\nI can put it back if you feel strongly that it will meaningfully assist users in making the right choice.. I lightly object b/c ignoring undefined precludes the possibility of removing a setting (hypothetically, null may be a significant of invalid value). I can't think of a reason why that would be a problem today. But, I also can't think of a reason why an object would contain a key with the value set to undefined in this context b/c the key could simply be omitted to get the same behavior.\nIn other words, the key's absence or presence is not significant if the value is undefined, which is not something I'd expect as a user. If I set the key in the passed options, I did so with a purpose.\n@szmarczak , I backed off your change b/c it overreached what we had discussed. I don't mind maintainer commits for nits or agreed upon changes, but please don't make behavioral changes when consensus has not been reached.\nI think the only significant change I reverted was the deep merging of arrays. I did that because got does not make changes to those arrays, so there is no need to make a copy of them, so copying adds unnecessarily to the runtime of the method.. This test had to be rewritten to use a header key that doesn't have a default value. The behavior is consistent as you wished. :-). We're trying to build consensus around these changes. Making a fork at this point is counterproductive.\nIf there's a change you want to see, we should talk about it.. You \ud83d\udc4d my explanation for why arrays are directly assigned, then changed the behavior in a push to my branch.\nYou rewrote the docs I wrote without having provided any remarks.\nYou implemented @sindresorhus proposition on my branch without giving me a chance to respond.\nI can appreciate that you are eager to land this, but we've had a productive conversation and are very close to achieving consensus on the implementation. By forging ahead, you undercut that process and then we have to have these unproductive meta conversations.\nWhat's the rationale for, or problem solved, by deep merging arrays?. @sindresorhus thanks for providing that example. I can appreciate the convenience that provides.\nIt occurred to me that, in the future, we could expose a symbol support deleting a key if the need for it arises. Similarly, we could expose a symbol to indicate that the result should be undefined if there's a need to explicitly set a key to undefined.\nUsing symbols for those cases would have the disadvantage of being a unique approach, but it would have the advantage of our interface being optimized for the most common scenarios.\nIf we're settled on ignoring undefined, we could rename assignOptions to mergeOptions to help clarify that its behavior is not congruent with Object.assign.. On closer inspection, I didn't actually remove this - I just inserted the function description before the warning. :-). I understand that concern, but I intentionally kept the implementation simple, so that the results are predictable.\nI was also concerned with performance, since this method is called not only by got.extend and got.create, but also by every call to got().\nThere are an infinite number of possible reference types that inherit from object, which may also have unexpected behavior when cloned, especially when only an object's own properties are cloned.\nI reluctantly chose to recursively merge source values that are plain objects when the target value is not a plain object for this reason because normalize-arguments currently requires that the options it receives are mutable. I would rather have refactored normalize-arguments, so that it selectively builds a new object from the input, but I thought that was too large a change to introduce here.\nDo you think it would be helpful to explicitly mention in the got.extend and got.create that the resulting object is frozen, so that any reference types will be frozen? We could also mention that a workaround is to use something like _.deepClone if users need to preserve a mutable instance of a config setting.\nWe could also reconsider whether freezing the options tips the balance of predicable behavior nearer or farther from the user's expectations.. Just clarify my position - I'm not strictly inflexible on the implementation, but I want to make sure my rationale is clearly expressed before we decide to change it.\n@sindresorhus do you have an opinion on this topic?. I think using urlLib.format to get the baseUrl has the same problem as was discussed in https://github.com/sindresorhus/got/pull/519#issuecomment-404950951.\nI can take a look at adding a test and fixing today.. The baseUrl won\u2019t have the right query string, but I don\u2019t think there\u2019s any value for new url for which it would affect the result. So this seems fine.. ",
    "scheung38": "Hi @brandon93s, How to add Bearer token in this call? as I am using it my my redirect but getting:\nheaders:\n   { server: 'nginx/1.12.1',\n     date: 'Thu, 31 Jan 2019 15:41:50 GMT',\n     'content-type': 'application/json',\n     'content-length': '15',\n     connection: 'close' },\n  body: 'No access token' }\nas I don't have issue if i use unirest\n```\nconst unirest = require(\"unirest\");\nconst req = unirest(\"POST\", \"https://xxxxxxx\");\nreq.send({\n    \"client_id\": \"xxxxxxxx\",\n    \"client_secret\": \"xxcxcxcxcxcxxcxcxcxcxcxcxcxcxcxcxcxcxc\",\n    \"audience\": \"https:/xcxcxcxcxcxcxcxx/\",\n    \"grant_type\": \"client_credentials\"\n});\nreq.end(function (res) {\n    if (res.error) throw new Error(res.error);\n    console.log(\"this is res.body : \", res.body);\n});\n```\naccess_token:\n   'eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsI\nwhich returns my expected access token, the longer I can't do this, I am  tempted to use unirest instead, only because rest of the team is using got therefore I am using it.. Hi @szmarczak, could you give simple example . Hi @szmarczak, so @sholladay was in incorrect? as I am redirecting from a POST so you confirming that I need to manually redirect via the catch block? Whereas @sholladay is correct if initial request was a GET? so why not:\nconst allMethodRedirectCodes = new Set([300, 303, 307, 308, 302 <--]);\nI have manually redirected by calling the function second time, within catch block, from the response of the first got POST call, but it is always saying 404 not found even though if I curl or POSTMAN via POST the redirected URL I am getting 200 ok? Any ideas? Using the followRedirects helps? Not sure how to set this followRedirects option...\n@brandon93s \nhttps://github.com/sindresorhus/got/issues/568\nhere mentions the subsequent redirect will be a GET, even if I make manual redirect in POST, meaning initial POST with a 302 response, and manually making another POST on the redirected URL, got will turn that into GET? If that is the case then maybe that is why I can curl 200, but manual redirect with another got POST will always be 404? Please confirm thanks. @szmarczak but NGINX server is only providing 302 after a POST which I like to redirect, it currently does not provide any other 3xx, so you solution is to ask API NGINX to throw one of\n, 303, 307, 308]); ? instead of 302?. Yes @szmarczak  that is what I did, within the catch block of got I made another POST got call but it is 415 Media Format Not Found which I suspect there is no API POST available from NGINX server, so changing from providing 302 to 303, if it is easy to do so, will fix this to 200 success?. Was given that, from POST -> redirect and then use got to catch this location and make another POST. Are you saying this is currently possible flow or not? Thanks. What if 3. is another POST request?  Because I am making a successful POST with a direct request to my redirected URL with 200, but getting  415 statusCode if accessing it via a redirect? . @szmarczak \nPost URL A -> 302 redirect caught in error -> Post URL B (415 status code)\nPost URL B -> 200\nURL B is having different status code depending on how it was accessed. Is it because GOT cannot handle this flow.\nDoes that make sense? Thanks\n. But you can confirm this flow of manually catching second redirect works or not?\nPost URL A -> 302 redirect caught in error -> Post URL B, will be 200 or 415 as you mentioned:\nconst getMethodRedirectCodes = new Set([300, 301, 302, 303, 304, 305, 307, 308]);\nconst allMethodRedirectCodes = new Set([300, 303, 307, 308]);\nthat is the main question thanks.. ",
    "zuban": "I have got the same error, \nHere is the comparison:\n```\nv8.3.1:\nPOST /api/v1/artbuyer/briefings HTTP/1.1\nuser-agent: got/8.3.1 (https://github.com/sindresorhus/got)\ncontent-type: multipart/form-data; boundary=--------------------------558951591065782284282183\nx-auth-token: ...\naccept-encoding: gzip, deflate\ncontent-length: 433\nHost: play:9000\nConnection: close\nv.8.3.0: \nPOST /api/v1/artbuyer/briefings HTTP/1.1\nuser-agent: got/8.3.0 (https://github.com/sindresorhus/got)\ncontent-type: multipart/form-data; boundary=--------------------------315337818893402991498635\nx-auth-token: ...\naccept-encoding: gzip,deflate\nHost: play:9000\nConnection: close\nContent-Length: 0\n```. ",
    "Nepoxx": "\nbut it's a non-goal to remove dependencies for the sake of it.\n\nThat's why I said \"problem\" (with quotes). The thing is that it's a security concern (as mentioned in the linked article).\n\nAn arbitrary score on a random website is not something I care about.\n\nNo need to be like this, I was simply making a suggestion to improve the code base, sorry it offended you.\nIf you change your mind, let me know and I'll make a MR to help you with that.. ",
    "ewolfe": "I just pulled this down and it works great :) \nI found myself wanting to create an instance with a hostname option and using only the path as the argument to my instance. ie:\n``js\nconst client = got.create({\n  hostname: 'https://example.com',\n  path: '/api',\n  headers: {\n    Authorization:Bearer ${TOKEN}`,\n  },\n});\nconst response = await client('/hello-world'); // GET https://example.com/api/hello-world\n```\nWhat are your thoughts on adding that functionality? I don't think it's too opinionated and is in the spirit of the tagline \"Simplified HTTP requests\". ",
    "clocked0ne": "@alextes  The documentation does not make it clear for the Request body option that setting json: true will cause this behaviour, it should be documented that object is a valid type to provide when json: true is also present.\nI had a thought that I would be caught out and tested using the Node REPL to see\n\nTypeError: The body option must be an Object or Array when the json option is used. @alextes  I would suggest to add to the body section as well, so it is obvious the two properties are linked:\nbody\nType: string Buffer stream.Readable form-data instance\nIf you provide this option, got.stream() will be read-only.\nThe body that will be sent with a POST request.\nIf present in options and options.method is not set, options.method will be set to POST.\nThe content-length header will be automatically set if body is a string / Buffer / fs.createReadStream instance / form-data instance, and content-length and transfer-encoding are not manually set in options.headers.\n\nAdd to the Type: line object or [object] and below this line a another italicized line:\nIf you set options.json to true then body must be a plain object or array \nSo altogether this could look like:\n\nbody\nType: string Buffer stream.Readable form-data instance [object]\nIf you provide this option, got.stream() will be read-only.\nIf you set options.json to true then body must be a plain object or array \nThe body that will be sent with a POST request.\nIf present in options and options.method is not set, options.method will be set to POST.\nThe content-length header will be automatically set if body is a string / Buffer / fs.createReadStream instance / form-data instance, and content-length and transfer-encoding are not manually set in options.headers.\n\nThen it is absolutely clear in either property what happens when both are used.. I can only think that this was a a gotcha that could easily have been avoided, especially for someone migrating from another library such as request or axios. Properties should not impact each other in ways that are not documented fully with either property. An alternative might have been to not make json a Boolean and instead make it the actual JSON body to be used instead, thereby removing the need for any explanation around the body property, then you could have simply noted that body would be ignored in favour of json. You could then have put a real check in for an Object or String and only stringified the value if necessary, avoiding the problem sindresorhus described.\nI would suggest either adding this clarification to the body so that people do not have to wait until they execute a call in this way to see the TypeError, or go further and make an additional body field for JSON, such as jsonBody so the two are no longer conflated (this could also behave as suggested above and ignore the body parameter). Under this circumstance If the body parameter was present but not jsonBody then the original behavour could resume, so this would be a non-breaking change.\nPersonally I'd rather just see the additional clarification in the body property documentation though. Given the prevalence of usage of JSON it is hardly a niche thing to support, I expect as many people use the json flag as do not.\nIf you won't do any of that, at least make:\n\nbody must be a plain object or array and will be stringified.\n\nbold so it won't be so easy to miss.. > \n\n\nAn alternative might have been to not make json a Boolean and instead make it the actual JSON body to be used instead\n\nI don't see how that is ambiguous vs adding to the body property to say it accepts objects, which it does, but only if you read further down to where the json property is mentioned...\n\nMaybe just link to the json property to reference it from the body property and it will probably be enough, I just don't understand the big defensive stance over the docs. Most developers write inadequate or terrible, assumptive documentation and this is actually quite good. I migrated from request because its bloated, then from axios because it is full of bugs and inconsistent, undocumented behaviour. I'm just trying to suggest a small change to benefit everyone and I really don't see the supposed detriment to making things clearer but maybe 671 solves it like you said anyway. This did make me laugh though:\n\nAnyway, I don't mind a note in the README that the body is stringified (though it's obvious) :)\nMost users running into confusion around this option seem to because of their assumptions\n\nI hope this doesn't come across as snarky, so happy holidays guys and thanks for the work on this package \ud83e\udd42 \n. @szmarczak @sindresorhus  I don't see how this is clearer given that body is now missing as a property in all cases? Why not leave the original indication at the top of the section and add the relevant \"includes\" that appear in each type of error?. Okay, so apparently body is only on HTTPError, but it's still wrong and would be great to see that fixed :). I didn't even think to check there \ud83d\ude28  closing. ",
    "StarpTech": "@sindresorhus thanks! When can we expect the new release?. Thanks, good to know.. ",
    "mesqueeb": "Definitely add Axios to the compare list!. ",
    "wescoder": "I'll give it a try again, but I remember getting errors about fs not being accessible.\nI'll report here with my findings.. I think it should.\nI will at least clarify this subject.. ",
    "styfle": "Should \"browser support\" be added to the Comparison table?\nhttps://github.com/sindresorhus/got#comparison. ",
    "pgilad": "Better yet, a codemod \ud83d\ude38 . ",
    "DRSDavidSoft": "@sindresorhus It would be also useful to write documentation for beginners who have started with got instead of the other libraries.\nCurrently, got documentation rely on external libraries knowledge too much IMHO.. @sindresorhus \ud83d\udc4d True, but you don't need to worry about guides for Node.js, Promises and HTTP mechanics -- since they're mostly covered pretty well outside the got docs.\ngot itself, however, could benefit from better documentation for beginners who choose to start with it.. @szmarczak I also agree with you on both topics\n- got should aim to implement IETF-standard RFCs\n- XSRF should be added as a plugin\nI think using the got hooks, it should be possible to implement most XSRF methods, if not all.. Basically the same reason as why we use then and catch as separate methods.\nAs to why I am not doing throwHttpErrors instead, this is my logic:\nSorry for the long comment ahead\n\nConsider that we have main.js and api-client.js.  The latter uses got in order to perform some actions, e.g.:\n\njavascript\nasync function login(username, password) { ... }\nasync function create post(title, body) { ... }\nasync function doSomethingElse() { ... }\n\n\nI'll first need to call login(..., ...) from main.js and await its response.\n\n\nPossible outcomes for this special website are:\n\nThe login is successful, I return with a success and then call the other methods\nThe attempt was rejected by the endpoint, I'll return an errorMessage with the corresponding error from the endpoint\ngot was unavailable to reach the endpoint, e.g. due to a network connectivity problem, or a reverse proxy blocking my request (e.g. CloudFlare, perimeterX, etc, which would return a 403 error), or simply a 503 error by the endpoint itself\n\nNow, by the design of my logic, I am expecting the http request to either succeed, or fail; so throwing an exception for a non 200 status code really isn't valid here. (If something else beside the http request itself fails, it'll unexpected and hence should throw an exception for me.)\nThe flow in case of outcomes 1 and 2 is clear - we simply parse and pass the resolved content.\nIn the case of outcome 3 however, it's not appropriate for my code to throw an exception here. What I need is to still parse the body (imagine when a rejected authentication request is 403ed from the server with a clear error message in the body (e.g. \"Login error!\"))\n -- then inspect the statusCode for the corresponding action.\nNow I understand that this can be simply done via a catch statement instead, but it messes the follow of my code.\nRemember, the same series of actions (often conditionally) need to be applied to the result in both scenarios. Not possible to do so, unless I repeat myself. (WET not DRY)\nThe only ways that I can achieve this (besides the aforementioned method in the first comment), is to either wrap got in another caller function (which I'd like to avoid), or ask you to add this rather small edit.\nAnd since a) currently, without disabling throwHttpErrors, this is relatively easy to differentiate and b) the proposed success property will fill the reject gap rather nicely for no-throw mode, I think this will be useful to implement.\nI know this may not be a standard for say a non-REST json-based api (e.g. /getWeatherInfo), because the author will be NOT expecting a non-200 status code -- and it should throw out of the function / method on a fail like this.\nI hope this all makes sense and I'm not unclear. :). @szmarczak I can. However, the purpose of this suggestion is to implement a counterpart to the reject(...), without repeating part of got in the user side:\njavascript\nconst success = statusCode === 304 || ( statusCode >= 200 && statusCode < 300);\nn.b. this has to be written for every got request.\nI am suggesting that it'd be easier to use a success property instead -- that should be equal to a successful request performed.. @szmarczak I did not quite understand, do you think supporting success is a good idea, or do you think APIs should provide their own error field?\nIn the case of latter, the issue is that an API can return any key independent of the statusCode (e.g. lack of error does not necessarily result in a 200 OK)\nIn addition to that, reverse-proxies (like cloudflare) could break a JSON API. Furthermore, we might not even be dealing with a REST API (e.g. using got to scrape a webpage). - May I ask the reson, why do you think it's a bad idea?\n\nWhat about the third situation?\nwe might not even be dealing with a REST API (e.g. using got to scrape a webpage)\n\n\n\ne.g. not a JSON-based API . ",
    "marswong": "\nThis is a bug.\n\nem, cuz the url module follows WHATWG URL Standard it may not be a bug\ud83d\ude02\nwe just need to support the path part. @szmarczak sorry, have u tried with got? i just removed the / of url, it still sucks :(. @szmarczak i try your sample, it works.\njust the baseUrl must be ended with /, or it would throw when meeting dynamic urls\ud83d\ude48, see:\njs\n(async () => {\n  const instance = got.extend({ baseUrl: 'https://api.douban.com/v2' });\n  const id = 1220562;\n  const body = (await instance.get(`book/${id}`)).body;\n  console.log(body);\n})();\nso it should be noted in the doc, thanks :). ",
    "beac0n": "In my opinion, this should be\n1. documented\n2. highlighted in the docs, because the behaviour is quite unintuitive\nSo the things @szmarczak and @marswong mentioned should be in the docs:\ndo NOT use / at the beginning\nDO use a / at the end. > I'd prefer throwing an error if baseUrl doesn't end with a backslash.\nWhy? The workflow for the user of the package would then be:\nuser uses baseUrl without slash => error gets thrown => user changes baseUrl to end with slash\nWhy not just add a slash at the end of baseUrl if none is present? The outcome would be the same for the user.\nWe should at most log a warning or something like that.\nHowever, I would prefer to document this thoroughly and the keep the code unchanged, as it would give the user the freedom to use the package as he/she sees fit. \nMaybe someone wants this behaviour.. ",
    "lostfictions": "That's odd -- I was also able to repro it on another system. I notice Got seems to not be using a lockfile or shrinkwrap and specifies version ranges instead of exact versions to boot -- maybe some dependency or transitive dependency broke something? Here's a transcription of a full session where I install from scratch and run the line of code above -- it repros immediately for me. Node version is 10.6.0, as verified below. I've also included the output of npm ls in case that's helpful in debugging.\n```\n~/Code$ mkdir temp && cd temp\n~/Code/test$ npm i got\nnpm WARN saveError ENOENT: no such file or directory, open 'test/package.json'\nnpm notice created a lockfile as package-lock.json. You should commit this file.\nnpm WARN enoent ENOENT: no such file or directory, open 'test/package.json'\nnpm WARN testt No description\nnpm WARN testt No repository field.\nnpm WARN testt No README data\nnpm WARN testt No license field.\n\ngot@9.0.0\nadded 19 packages from 7 contributors and audited 23 packages in 1.832s\nfound 0 vulnerabilities\n\n~/Code/test$ node -e 'require(\"got\")(\"http://google.com/search\", { query: { q: \"friend\u2019s house\" } }).then(() => console.log(\"ok\"))'\n(node:16167) UnhandledPromiseRejectionWarning: RequestError: Request path contains unescaped characters\n    at EventEmitter.cacheReq.on.error (node_modules/got/source/request-as-event-emitter.js:105:27)\n    at EventEmitter.emit (events.js:182:13)\n    at makeRequest (node_modules/cacheable-request/src/index.js:125:9)\n    at get (node_modules/cacheable-request/src/index.js:135:14)\n    at process._tickCallback (internal/process/next_tick.js:68:7)\n(node:16167) UnhandledPromiseRejectionWarning: Unhandled promise rejection. This error originated either by throwing inside of an async function without a catch block, or by rejecting a promise which was not handled with .catch(). (rejection id: 1)\n(node:16167) [DEP0018] DeprecationWarning: Unhandled promise rejections are deprecated. In the future, promise rejections that are not handled will terminate the Node.js process with a non-zero exit code.\n~/Code/test$ node --version\nv10.6.0\n~/Code/test$ npm ls\n\u2514\u2500\u252c got@9.0.0\n  \u251c\u2500\u252c @sindresorhus/is@0.11.0\n  \u2502 \u2514\u2500\u2500 symbol-observable@1.2.0\n  \u251c\u2500\u252c cacheable-request@4.0.1\n  \u2502 \u251c\u2500\u252c clone-response@1.0.2\n  \u2502 \u2502 \u2514\u2500\u2500 mimic-response@1.0.1 deduped\n  \u2502 \u251c\u2500\u2500 get-stream@3.0.0 deduped\n  \u2502 \u251c\u2500\u2500 http-cache-semantics@4.0.0\n  \u2502 \u251c\u2500\u252c keyv@3.0.0\n  \u2502 \u2502 \u2514\u2500\u2500 json-buffer@3.0.0\n  \u2502 \u251c\u2500\u2500 lowercase-keys@1.0.1\n  \u2502 \u251c\u2500\u2500 normalize-url@3.2.0\n  \u2502 \u2514\u2500\u252c responselike@1.0.2\n  \u2502   \u2514\u2500\u2500 lowercase-keys@1.0.1 deduped\n  \u251c\u2500\u252c decompress-response@3.3.0\n  \u2502 \u2514\u2500\u2500 mimic-response@1.0.1 deduped\n  \u251c\u2500\u2500 duplexer3@0.1.4\n  \u251c\u2500\u2500 get-stream@3.0.0\n  \u251c\u2500\u2500 mimic-response@1.0.1\n  \u251c\u2500\u2500 p-cancelable@0.5.0\n  \u251c\u2500\u2500 to-readable-stream@1.0.0\n  \u2514\u2500\u252c url-parse-lax@3.0.0\n    \u2514\u2500\u2500 prepend-http@2.0.0\n~/Code/test$ uname -rv\n4.15.0-30-generic #32~16.04.1-Ubuntu SMP Thu Jul 26 20:25:39 UTC 2018\n```. @szmarczak As I noted, it's a regression from previous behaviour. I unfortunately don't have the capacity to deal with regressions in basic behaviour like this so I've already migrated from Got to a better-tested/more popular library and am unsubscribing from this issue, but I hope you fix it!. ",
    "lorenzofox3": "@sindresorhus \nI think the test is failing is because the URLSearchParams implements properly the standard url encoder parser and serializer which means ?foo is correctly parsed and serialized to ?foo= (which dose not match the redirect url ?foo of the test server). I see then different solutions.\n\nModify the test and consider ?foo is equivalent ?foo= on the test server side (which is the case according to the spec aforementioned if I understand correctly)\nChange the implementation to have our own toString so that empty values are ignored and the = sign is not appended. However this could lead to inconsistent behavior. \nquery parameters with following parameters may not output the same queryString:\n?foo\n?foo=''\n?foo=''\n{query:undefined}\n{query:''}\n\nOn a side note: I am not sure whether it is a problem with the test framework or the reporter but when running the tests I man not able to say it is actually failing: when I run the tests the final output is \n\n. ",
    "krishna1st": "@gajus can you share how have you done it with wrapper. ",
    "sja": "@ninox92 Did you open or find any got related Issue or PR there? It's hard to find one because of the name. ;-). ",
    "poppinlp": "Hi. Thanks for your reply.\nI made a test for got, request, axios and node-fetch with nock to mock response and benchmark.js to run the benchmark. Here's the result i got:\n\nSeems those 3 libs are 3x faster than got in this case. I'm a little bit confused about this. Have i done something wrong in using got?\nHere's the test code:\n```js\nconst got = require(\"got\");\nconst axios = require(\"axios\");\nconst request = require(\"request\");\nconst fetch = require(\"node-fetch\");\nconst nock = require(\"nock\");\nconst { Suite } = require(\"benchmark\");\nconst suite = new Suite();\nsuite\n  .add(\"got\", {\n    defer: true,\n    fn: done => {\n      nock(\"https://abc.com\").get(\"/\").reply(200, \"hello world\");\n      got(\"https://abc.com\").then(() => done.resolve());\n    }\n  })\n  .add('request', {\n    defer: true,\n    fn: done => {\n      nock(\"https://abc.com\").get(\"/\").reply(200, \"hello world\");\n      request.get('https://abc.com', () => done.resolve());\n    }\n  })\n  .add('axios', {\n    defer: true,\n    fn: done => {\n      nock(\"https://abc.com\").get(\"/\").reply(200, \"hello world\");\n      axios.get('https://abc.com').then(() => done.resolve());\n    }\n  })\n  .add('node-fetch', {\n    defer: true,\n    fn: done => {\n      nock(\"https://abc.com\").get(\"/\").reply(200, \"hello world\");\n      fetch('https://abc.com').then(rsp => rsp.text()).then(txt => done.resolve());\n    }\n  })\n  .on(\"cycle\", event => {\n    console.log(String(event.target));\n  })\n  .on(\"complete\", function() {\n    console.log(\"Fastest is \" + this.filter(\"fastest\").map(\"name\"));\n  })\n  .run();\n``. OK. I start a server byfastify` and do the test again. Seems the gap is not that big. Thanks.. ",
    "jogold": "There is no getPromise() method.. ",
    "walkwel": "My node version is 8.11.1\n\n. ",
    "TomiTakussaari": "Thanks! Seems to be working now.. ",
    "tolec": "So, as I understood from https://github.com/sindresorhus/got/issues/383, the only way now to use both FormData and json option is to parse response myself, right?. ",
    "Moeriki": "I was wrong.\nStarting the request url with / resets the pathname, which makes sense. Though confusing if you don't immediately think of it.\n. Version 9.0.0.. ",
    "amio": "@szmarczak Sure, I'll take on this later :D. @alextes Yup, I didn't notice the default value for retry is 2, I thought \"retry\" is an optional feature :D\nI was testing if timeout works as expected, so set it to 100ms for triggering the error, then found it's response takes 6 seconds long =.=\nPS, I tried with retry: 0, the timing is in line with expectations.. The clarification solved my problem, thanks!\nPS, the timing still looks not quite as expected with default options (retry === 2), is it a problem?\n\nhttps://untitled-qvjzo3otxk19.runkit.sh/100 => timespan: 6397 (expect 300+)\nhttps://untitled-qvjzo3otxk19.runkit.sh/200 => timespan: 6763 (expect 600+)\nhttps://untitled-qvjzo3otxk19.runkit.sh/300 => timespan: 7087 (expect 900+)\n\nActing like expected time span plus extra 6000ms \ud83e\udd14. Seems the ETIMEOUT error object doesn't have a response attached. ",
    "voldern": "If I've understand the code correctly this happens because of how the default retry delay is calculated: https://github.com/sindresorhus/got/blob/master/source/normalize-arguments.js#L259.\nSo your request times out after 300ms, then it waits ((1 << 1) * 1000) + Math.random() * 100; so \u2243 2000ms, then it times out after 300ms and then waits ((1 << 2) * 1000) + Math.random() * 100; which is \u2243 4000ms. In total around 6600ms.\nIf you want a lower wait before it retries you would have to send in a function to the retries argument.. > Can you provide any data? How much?\nIn v9.3.2 it stays around 130mb, in v9.4.0 it continues to rise to 1gb over time and the process is killed because it consumes all of the available memory. It will only reduce the memory used after a while if we stop sending traffic to the container, so there seems to be something that holds on to the memory for a while.\nAfter a while we also see the following messages, not sure if that is directly related to the issue:\n(node:1) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 timeout listeners added. Use emitter.setMaxListeners() to increase limit\n. I was able to create a concise example that reproduces the issue: https://github.com/voldern/got-memory-leak.\nCheck out the repo above, run docker stats and then run docker-compose up. You should see the memory for the \"app\" container keep rising until the memory limit is reached.\nThe issue is not reproducible when not using the agentkeepalive or without timeout.socket set.\n\nRun Node.js with $ node --trace-warnings to get a stack trace of where the event emitter leak warning is coming from.\n\n```\napp_1     | (node:1) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 timeout listeners added. Use emitter.setMaxListeners() to increase limit\napp_1     |     at _addListener (events.js:243:17)\napp_1     |     at Socket.addListener (events.js:259:10)\napp_1     |     at Socket.Readable.on (_stream_readable.js:799:35)\napp_1     |     at Socket.once (events.js:290:8)\napp_1     |     at ClientRequest.req.on (_http_client.js:669:14)\napp_1     |     at ClientRequest.emit (events.js:187:15)\napp_1     |     at ClientRequest.origin.emit.args [as emit] (/usr/src/app/node_modules/@szmarczak/http-timer/source/index.js:36:11)\napp_1     |     at tickOnSocket (_http_client.js:654:7)\napp_1     |     at onSocketNT (_http_client.js:693:5)\napp_1     |     at process._tickCallback (internal/process/next_tick.js:63:19)\n```. ",
    "DenisKrsk": "Hey. I have the same problem. The timeout is longer than expected.\n 1000 => 6329; 2000 => 9232; 3000 => 12266; 4000 => 15291\n`const  got  =  require ( 'got' );\nconst  ProxyAgent  =  require ('proxy-agent');\n(async function(){\n    var startTime = Date.now()\n    var response = await got(\"https://gmail.com\",\n        { \n            timeout: 4000, \n            retries:0,\n            decompress:false,\n            agent: new ProxyAgent(\"https://192.168.1.11\")\n        }).catch(e=>{console.log(e)});\n    console.log(Date.now() - startTime);\n})();`. ",
    "chris-erickson": "This could be useful for me.  I have an upstream consumer with a hard coded max wait of 10s, and this backoff logic constrains me a bit.  I control the thing I'm calling with Got, and would prefer a lot of retries in a short time to the exponential backoff since it's likely a brief blip from a deploy and that 10s window to complete the request is always looming.  The only way I can account for this now is to shorten the timeout wait, but that starts to encroach on a legitimately long wait on the downstream service.. Resistbot uses Got to communicate from the API frontend where all correspondence ingresses, to the officials lookup database in back.  https://resist.bot\n. ",
    "chrisskilton": "@szmarczak sure thing. thanks for the response. here's some example code:\ntest server - this will increment an integer and return the string on every call to it\n```javascript\nconst http = require('http');\nlet response = 0;\nconst server = http.createServer((req, res) => {\n    res.writeHead(200, { 'Content-Type': 'text/plain' });\n    res.end(response.toString());\n    response++;\n});\nserver.listen(3000);\n```\nTest - this will use a regular keyv instance as a cache with got, using a ttl of 3000\n```javascript\nconst got = require('got');\nconst Keyv = require('keyv');\nconst cache = new Keyv({\n    ttl: 3000\n});\nconst fetch = async () => {\n    const response = await got('http://localhost:3000', {cache});\nconsole.log('Served from cache:', response.fromCache);\nconsole.log('Response:', response.body);\n\n};\nconst wait = () => {\n    console.log('waiting 1s...');\n    return new Promise(res => setTimeout(res, 1000));\n};\nconst run = async () => {\n    //first call should be a cache miss\n    await fetch();\n    await wait();\n//1s after first call should be a cache hit\nawait fetch();\nawait wait();\n\n//2s after first call should be a cache hit\nawait fetch();\nawait wait();\n\n//3s after first call should be a cache miss again\nawait fetch();\nawait wait();\n\n//4s should be a cache hit\nawait fetch();\nawait wait();\n\n//5s should be a cache hit\nawait fetch();\nawait wait();\n\n};\nrun();\n```\nEach call after the initial cacheing resets the cached value ttl to 3s again. \nConsole output:\nServed from cache: false\nResponse: 0\nwaiting 1s...\nServed from cache: true\nResponse: 0\nwaiting 1s...\nServed from cache: true\nResponse: 0\nwaiting 1s...\nServed from cache: true\nResponse: 0\nwaiting 1s...\nServed from cache: true\nResponse: 0\nwaiting 1s...\nServed from cache: true\nResponse: 0\nwaiting 1s...\nAs you can see after the first call, if there isn't a full 3s wait, the cached data isn't ever cleared.. got a feeling I'm making the same assumption you did here https://github.com/sindresorhus/got/pull/284#issuecomment-300193765. @szmarczak That version doesn't appear to ever hit the cache:\nUsing got 9.2.1:\nServed from cache: false\nResponse: 0\nwaiting 1s...\nServed from cache: false\nResponse: 1\nwaiting 1s...\nServed from cache: false\nResponse: 2\nwaiting 1s...\nServed from cache: false\nResponse: 3\nwaiting 1s...\nServed from cache: false\nResponse: 4\nwaiting 1s...\nServed from cache: false\nResponse: 5\nwaiting 1s.... adding cache control to the test server:\njavascript\nres.writeHead(200, {\n    'Content-Type': 'text/plain',\n    'Cache-Control': 'max-age=3'\n});\nyields:\nServed from cache: false\nResponse: 0\nwaiting 1s\nServed from cache: true\nResponse: 0\nwaiting 1s\nServed from cache: true\nResponse: 0\nwaiting 1s\nServed from cache: false\nResponse: 1\nwaiting 1s\nServed from cache: true\nResponse: 1\nwaiting 1s\nServed from cache: true\nResponse: 1\nwaiting 1s\nBingo. OK so the ttl is purely for the key/value store to be able to clean up after itself, not any sort of control over how long you want to cache any particular responses. All the caching decisions are made based on the headers on the resource coming back (the response).\nThanks for helping. . ",
    "mecurc": "hm, if i pass hook to .get('/') function then it works.\n```JavaScript\nconst got = require('got')\nconst noop = () => {}\nconst hooks = {\n  beforeRequest: [console.log],\n}\nconst client = got.create({\n  options: {\n    baseUrl: 'https://google.com',\n    hooks,\n  },\n})\n// not works\nclient\n  .get('/')\n  .then(noop)\n  .catch(noop)\n// works\nclient\n  .get('/', { hooks })\n  .then(noop)\n  .catch(noop)\n```. How i can define global hooks?\nwhen i replace handler i got \"compiled\" options, where query already attached to url.\nSo my solution is wrong. It just replaces hooks(as described here) https://github.com/sindresorhus/got#gotmergeoptionsparentoptions-newoptions. > What do you mean by \"global hooks\"?\nHooks that works for all children of instance. With extend we can add hooks. We can also manage hooks inside hooks. Now, when i use extend hooks are just replaces.\n\nCan you elaborate where's the problem?\n\n```JavaScript\n'use strict'\nconst got = require('got')\nconst noop = () => {}\nconst hooks = {\n  beforeRequest: [console.log],\n}\nconst client = got.create({\n  options: {\n    baseUrl: 'https://google.com',\n    hooks,\n  },\n})\n// hooks here, OK!\nconsole.log(client.defaults.options.hooks)\n// but it not works, hook not called\nclient\n  .post('/')\n  .then(noop)\n  .catch(noop)\n// when i pass directly hooks will be called\nclient\n  .post('/', { hooks })\n  .then(noop)\n  .catch(noop)\n``. Never write tests before. So, i try.. In python world withrequestspackage we have session object, that can be extended for the same behavior. . Options inside hooks are normalizedrequestoptions. So, for adding query options I should extract query, parse it, and replace param insideoptions. its pretty uncomfortable.. ",
    "SleeplessByte": "Trace: { \n  UnsupportedProtocolError: Unsupported protocol \"https\"\n    at get (...\\repo\\node_modules\\got\\source\\request-as-event-emitter.js:37:26)\n    at Immediate.setImmediate (...\\repo\\node_modules\\got\\source\\request-as-event-emitter.js:227:10)\n  name: 'UnsupportedProtocolError',\n  host: undefined,\n  hostname: 'example.org',\n  method: 'POST',\n  path: '/api/removed/for/issue',\n  socketPath: undefined,\n  protocol: 'https',\n  url: undefined \n}. Cross posting from ky#85\nFWIW, at fuel we are running into servers now wanting GET requests with body.\nBetween RFC2616's obsoletion and RFCs 7230-7237 a few changes were made regarding this. Most importantly the following has been removed\n\nRFC 216 Section 4.3\n[...] if the request method does not include defined semantics for an entity-body, then the message-body SHOULD be ignored when handling the request.\n\nTo my understanding this means that servers and peers may now accept bodies for GET (and HEAD) requests. The behaviour, just like with DELETE requests are not defined.\n\nRFC 7231 Section 4.3.1 and Section 4.3.2\nA payload within a GET request message has no defined semantics;\n   sending a payload body on a GET request might cause some existing\n   implementations to reject the request.\n. \n",
    "ryancole": "Nevermind. Can just use URLSearchParams! Thanks.. ",
    "loris": "I do confirm the issue against master.\nIt will only work this way:\ninst('http://httpbin.org/');\nIf you use method shortcut (ie, inst.get('http://httpbin.org/');) or any options (ie, inst('http://httpbin.org/', { method: 'GET' });, hooks will not fire.. ",
    "conechan": "Sorry, I've tried to write a test to reproduce it but failed. I will try again when I have spare time. Thanks.. ",
    "akinolu52": "thanks @sindresorhus . ",
    "phillipCouto": "I am more than happy to submit a merge request as it seems like a simple enough change.. Yes but the problem is in the renderer process it is the api from chrome and not nodeJS. Which is only setTimeout and clearTimeout. \nAs per the second part of my OP adding the same check as what is used by the immediate fixes the problem. \n. Sure here is what I am seeing in the window debug console:\nUncaught TypeError: timeout.unref is not a function\n    at addTimeout (node_modules/got/source/timed-out.js:22)\n    at timeConnect (node_modules/got/source/timed-out.js:90)\n    at TLSSocket.socket.once (node_modules/got/source/timed-out.js:103)\n    at Object.onceWrapper (events.js:325)\n    at emitMany (events.js:147)\n    at TLSSocket.emit (events.js:224)\n    at GetAddrInfoReqWrap.emitLookup [as callback] (net.js:1088)\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (dns.js:97)\nI changed the paths to remove any sensitive data in the first few lines.. @szmarczak any update on this?. Thank you @szmarczak and @sindresorhus!. ",
    "mrmlnc": "Maybe it makes sense to also pass request as field of the error instead of use only the body field?. Ok. Thanks for the quick response. It just worked before we upgrade from 8.3.2 to the got@9 version (this behavior is not described as Breaking changes). Sorry.\n```js\nconst got = require('got'); // got@8.3.2\n(async () => {\n    try {\n        const res = await got.get({\n            protocol: 'https:',\n            host: 'google.com',\n            path: '/',\n            headers: {\n                'X-Custom-Header': 'some-value'\n            }\n        });\n    console.dir('Requests headers', { colors: true });\n    console.dir(res.req.getHeaders(), { colors: true });\n} catch (error) {\n    console.dir(error, { colors: true });\n}\n\n})();\n```\njs\n'Requests headers'\n{ 'user-agent': 'got/8.3.2 (https://github.com/sindresorhus/got)',\n  'x-custom-header': 'some-value',\n  'accept-encoding': 'gzip, deflate',\n  host: 'www.google.com' }\nOr do you mean I shouldn't use extend? This is just an example to show the problem. We use the create method for logging and extended retry conditions.. Also you say in the documentation that we can use url as https.request options object. The documentation describes what the https.request may include headers property.\n\nProperties from options will override properties in the parsed url.\n\nBut I'm not passing options.\nIMHO, this is a bug.. Are you trying to tell me that a url argument can only be a string or WHATWG  URL? May be in this case it is necessary to write about it more explicitly in the documentation? Like, we only support the definition of protocol, host/hostname, and path \u2026 or we support all properties exclude headers and \u2026.\nI'm sorry, but it's not very obvious when the documentation explicitly says that a url argument can be a string, or a https.request options object, or a WHATWG URL.\n. ",
    "nuragic": "Hello! Any chance to bump a patch release for this one today? \ud83d\ude0c Thanks!. ",
    "razor-x": "@sindresorhus I am adopting Got for our project to replace request. So far it looks great, but I need this (and timings) in a new version before I can push stable stuff on my side (can't use the git version for internal reasons). \nBeen using the git version to develop with no issues, but :smile_cat: Can haz has release  :hamburger:  or ETA plz? :pray:. ",
    "lathil": "Yes, had a look at Download which setup a kind of proxy agent with Caw in the opts it provide to Got. That why the connection is setup correctly through the corporate proxy initialy toward raw.github.com.  It just that it is looping 10x time between\nconst get = opts => {\n..\nconst req = fn.request(opts, res => {\n.. and..\nget(redirectOpts);\n.. after the redirect 301 is received\ndon't know too much why since the original opts with proxy setting are re-copied in redirectOpts, it should work.\nI saw that in the latest versions of Download, they added code to to redirects themselves ( instead of setting followRedirect)\nThanks for your reply.. I had a look at what is hapenning with WireShark, the redirects are there but not due to Got.I close the issue. ",
    "mh81": "@alexandrino Would something like this accomplish what you're looking for?\n```js\nconst got = require('got');\nconst pRetry = require('p-retry');\nconst requestConfig = {\n  json: true,\n  baseUrl: 'http://legacyapi/',\n  timeout: 1000\n};\nconst response = await pRetry(\n  got('/failure', requestConfig)\n    .then(response => {\n      if (response.body.message !== 'OK') {\n        throw new Error(response.body.message);\n      }\n  return response;\n});\n\n);\n```. ",
    "alexandrino": "@mh81 awesome!!!! That's what I need, thanks a lot for your help!!!. ",
    "aghuddleston": "I believe I'm seeing something similar. It's also intermittent.  Trace looks like this\n```\nevents.js:165\n      throw er; // Unhandled 'error' event\n      ^\nRequestError: Parse Error\n    at ClientRequest.request.once.error (/Users/ahuddleston/dev/body-data-conversion/node_modules/got/source/request-as-event-emitter.js:173:14)\n    at Object.onceWrapper (events.js:272:13)\n    at ClientRequest.emit (events.js:185:15)\n    at ClientRequest.origin.emit.args [as emit] (/Users/ahuddleston/dev/body-data-conversion/node_modules/@szmarczak/http-timer/source/index.js:36:11)\n    at Socket.socketOnData (http_client.js:451:9)\n    at Socket.emit (events.js:180:13)\n    at addChunk (_stream_readable.js:274:12)\n    at readableAddChunk (_stream_readable.js:261:11)\n    at Socket.Readable.push (_stream_readable.js:218:10)\n    at TCP.onread (net.js:581:20)\nEmitted 'error' event at:\n    at emitter.emit.retried (/Users/ahuddleston/dev/body-data-conversion/node_modules/got/source/request-as-event-emitter.js:177:15)\n    at EventEmitter.emitter.on (/Users/ahuddleston/dev/body-data-conversion/node_modules/got/source/request-as-event-emitter.js:210:3)\n    at EventEmitter.emit (events.js:180:13)\n    at ClientRequest.request.once.error (/Users/ahuddleston/dev/body-data-conversion/node_modules/got/source/request-as-event-emitter.js:175:13)\n    at Object.onceWrapper (events.js:272:13)\n    [... lines matching original stack trace ...]\n    at addChunk (_stream_readable.js:274:12)\n```. Added the code but haven't been able to duplicate yet. . Yes, I set timeouts.  And, unfortunately, I have _not been able to duplicate once adding the code.  I'm using this as the call though, and I'll keep trying to recreate.  \nconst res = await got(url, { method: 'HEAD', timeout: 3000, retries: 0, throwHttpErrors: false }). ",
    "skynewborn": "Got it. Thanks.. ",
    "bitinn": "@sindresorhus I see your take, But:\n\nwe didn't switch to web stream because node-fetch are for nodejs and at the time getReader wasn't available. res.body.pipe isn't a standard API in Fetch spec but .pipe is exactly what people are looking for on nodejs. Note that we also support the standard .clone API which operates on stream.\nI just think it's unfair to categorize got as having stream api while node-fetch is categorized as doesn't simply because of spec compliance issue.\n\nAs for the custom defaults, sure, if your argument is \"only merging the main instance\" counts.. > node-fetch is isomorphic, but only supports a \"stream\" API for Node.js.\n\n\nIt's not isomorphic though, see https://github.com/bitinn/node-fetch#motivation\n\nWe did try very hard to stay consistent with Fetch API, but it's not perfect yet: https://github.com/bitinn/node-fetch#difference-from-client-side-fetch\nAnd it makes sense to have things like res.body.pipe and timeout because at the time of release Fetch Spec doesn't even provide a way to abort a request and web stream isn't ready for use in any browsers.\n\n\nThe stream API is not a first-class citizen. It's just exposing the Node.js response stream. It doesn't have nice conveniences like forwarding headers, redirect handling, etc.\n\n\nI see another side on this: Fetch Spec already provide a compliant way to access these info, and they are available on fetch resolve, so why would you not use it?\ngetReader isn't going to stream these info anyway: https://developer.mozilla.org/en-US/docs/Web/API/Streams_API/Using_readable_streams. PS: I know all these are just technicality and we both have better things to do than correcting a comparison table, so consider this a suggestion for change not a request :). @szmarczak love to get .getReader() working in some way. We were expecting whatwg stream to be a part of nodejs core but the PR didn't land. (see https://github.com/nodejs/node/pull/22352), so using a polyfill might be the only solution for now.. \n",
    "vitkarpov": "\nThere are multiple common ways to represent arrays in query strings.\n\nYes, but none of them are some=a,b, aren't they?\n\nWe already support both URLSearchParams and string, both of which can be used to achieve it\n\nThat's exactly how it could be done now and it's fine. It's just confusing that the \"query as an object\" leads to an invalid query string eventually.. ",
    "UltCombo": "\noptions.retry.retries function should be called with the retry argument starting\nfrom 1 instead of 0.\n\nLooks like that's the current (undocumented) behavior.. @timdp I can confirm there's a bug in the default retry delay logic.\nThe retries function gets 1 for the iteration argument in the first retry (see here), so the retry delay math is wrong (1 << 1 === 2).. Oh I've submitted the review with my work account, oops. :sweat_smile:  . Sent PR to cacheable-request: https://github.com/lukechilds/cacheable-request/pull/63. @szmarczak I see it as explaining the default logic, not the actual arguments. I'm using a custom retries function so it's a breaking change.\nThe documentation should also be updated to document what arguments the retries function gets.. I generally prefer 0-indexed collections, however in this specific case I believe it makes sense that iteration === 1 in the first retry attempt. Having retry attempt as 0 is not intuitive.\nHaving the first retry attempt as 1 allows writing semantic code like:\njs\ngot('url', {\n  retry: {\n    // Retry up to 2 times.\n    retries: retry => retry <= 2 ? getRetryDelay() : 0,\n  },\n});\n@sindresorhus @szmarczak . ",
    "javierblancosp": "What about when the request body is a stream (A multipart request), options.json can not be true. In the case i want to parse the response body as json i have to do it manually on a multipart request.I know is not a big deal but it could be nice to allow this somehow \ud83c\udfcb\ufe0f . @szmarczak mm i think if i expect a response to be a json the request body should not modify this, in may way of thinking :P. ",
    "olistic": "Right now, if options.body is set and options.method is not, the latter will be set to 'POST', as documented here. However, the same does not occur when options.json is set.. @szmarczak Reported in #736.. ",
    "mojavelinux": "Antora, a static site generator for creating documentation sites, uses got to download the UI bundle. In Antora, the UI bundle (aka theme) is maintained as a separate project. That project exports the UI as a zip file we call the UI bundle. The main site generator downloads that UI from a URL using got and streams it to vinyl zip to extract the files. Those files go on to be used to create the HTML pages and supporting assets.\nHere's the software module in Antora that uses got. https://yarnpkg.com/en/package/@antora/ui-loader\nHere's the project page for Antora: https://antora.org\nHere's the logo for Antora:\n\n. ",
    "danielkalen": "GetVoIP is happily using got in production. One of the unique capabilities of got is the ability to handle Unix sockets which enables us to build a full control interfaces for our docker stack.\nOur website is https://getvoip.com and our logo is:\n\n. ",
    "yamalight": "We're using got inside of Exoframe to handle all the communication between cli and server.\nExoframe is a self-hosted tool that allows simple one-command deployments using Docker\nLogo (also available in multiple variations in repo below):\n\nProject can be found at https://github.com/exoframejs/exoframe. ",
    "AxelTerizaki": "Karaoke Mugen uses it to fetch content updates from its online server : https://lab.shelter.moe/karaokemugen/karaokemugen-app (main website is http://karaokes.moe )\nLogo : \n\n. Well, after trial and error and looking through form-data's code, I found what was wrong : you actually have to specify an options object after the readable stream.\nThe part about it in got's readme says : \nform.append('my_file', fs.createReadStream('/foo/bar.jpg'));\nWhile it should be \nform.append('my_file', fs.createReadStream('/foo/bar.jpg'), 'bar.jpg');\nOptions can be either an object or a string.\nUpdating the readme would be nice :) (form-data's readme seems wrong as well). Thanks for pointing that out : I noticed that as well after writing this post but didn't think to report it back here.\nI spent a lot of time on this so I don't really want to experiment further with this now that it works :)\nWhat's a bit weird though is that I'm pretty sure form-data's code is pretty confusing and led me to believe it absolutely needed an options argument.. ",
    "muuvmuuv": "Sundial uses got to get the users locations (lat, long) through ipapi to use it in combination with suncalc to get his sunrise and sunset. Then Sundial use this information with the users preferences to change its VSCode-Theme.\n. ",
    "medikoo": "\nYou can access the defaults on got.defaults \n\nIndeed, I see that now (still in my case I didn't require got by main module, but of course I could get around to get that this way)\n\nWould you be able to elaborate on why you need to do that?\n\nSure, use cases we have:\n- Log following things: request, response status and headers (right after it's received), response body (after complete response is propagated). For first two I could probably rely on 'request' and 'response' events, but for last one there appears no clean solution (e.g. retries are handled behind the scene, where I would prefer to have all issued requests logged)\n- Preset options.timeout for each request automatically (it's not about fixed static value, we run requests in AWS lambda's and want to ensure they timeout before lambda times out)\n- Resolve body on basis of content type (e.g. we automatically resolve to JSON if there' response type is application/json (no need for options.json: true).\nGenerally it'll be good to achieve first two use cases without a need of introduction of some decorator that should be required instead - so that aside we can hook into general got configuration, and then have all requests (made via got required directly) automatically affected.\nThe last one, is more a feature request, not sure why got doesn't do that by default, but maybe there's a good reason\nI discovered also few other breaking (on that level) changes between v9.2 and v9.3. So for now, after we patched that, we locked ourselves to 9.3.x . >  Use hooks and/or custom handlers.\nMind intention of this issue was to discuss breaking changes between v9.2 and v9.3, and in last comment I was mostly referencing to version v9.2\nIt's great that afterResponse hook was added with v9.3. That helps, still, it doesn't allow to address what I'm after in a way I described (e.g. have also result from JSON.parse available)\n\nconst instance = (url, options) => got(url, {...options, timeout: computeTimeout()});\n\nI specifically wrote: it'll be good to achieve first two use cases without a need of introduction of some decorator that should be required instead - so that aside we can hook into general got configuration, and then have all requests (made via got required directly) automatically affected\nYour hint is nowhere near that.\n\nVery bad idea. \n\nThat's far from constructive.\n\nThe documentation doesn't bite \ud83d\ude03\n\nI did read it, but it doesn't look that you took effort to actually read with understanding my points, and acknowledge the context.\nSo I may respond in similar way: reading with understanding doesn't bite \ud83d\ude03 \n. > In general, I would always recommend locking down dependencies if you use internal stuff. There's no stability promise for that.\nIt was not perfectly clear to me that what's in scope of src is considered private , but indeed documentation references only require('got'), so it's probably more a misunderstanding on my side.\n\nWe intentionally don't support that. It's better to be explicit. The request client should be the one deciding what format it expects. This is also how WHATWG Fetch works (await request.json()).\n\nThat's absolutely right to not imply such behavior by default, but when we work with API's we know, having an option to turn on content type based resolution might be handy (anyway I can achieve that now by resorting to hooks introduced with v9.3)\n\nSo you want a singleton. How about creating the custom Got instance in a file called got.js with your customizations and you require that one everywhere instead of got? That's how I usually handle it.\n\nThat's what I'm doing now, and it looks with hooks introduced with v9.3 I should be able to achieve what I want without requiring internals directly, so that fixes.\nAbove I noted, that it might be handy to mock got aside (so all further modules that require got are affected), and it looks it'll also be doable by having access to default options. Still after giving it a second thought, I'd rather not pursue that, as that'll be less transparent for other developers in the project.\n. I indicated that I want to conditionally opt out from default behavior, and assuming I'll follow what you suggest (so provide my own retry.retries) I'm forced to copy and paste this part, which is not great.\nSo how can I do this cleanly:\n```javascript\nconst defaultRetries = resolveDefaultRetriesFromGot(); // What should be here?\ngot(url, {\n  retry: {\n    retries: (iteration, error) => {\n      if (error instanceof got.TimeoutError) return 0;\n      return defaultRetries(iteration, error);\n    }\n  }\n});\n``` . > Please tell me if it works or not :)\nNot really, as got.defaults.options.retry.retries equals 2 -> https://github.com/sindresorhus/got/blob/7f18ef397341214d9f46d774f69e65d6cdd95494/source/index.js#L8\nDefault function appears there only after options normalization is made.\nThat could be solved if normalized options would be exposed on promise as returned by got(url).\nThen I could just override options.retry.retries function with decorated version. Aren't you worried that complexity it'll add, will shadow the benefit?\ngot codebase is now pretty straightforward to get through, and library works very well (doesn't feel buggy in any part).\nWhat real problem converting to TS aims to solve?. > Another big benefit is that we don't have to maintain a separate TS type definition file, which could easily get out of sync.\nCan't this be solved simply with JSDoc? I haven't explored that deeply, but I think TS can read types of out it as well. > Adding types will let us be more confident about doing changes\nDo you remember any specific issues that wouldn't happen if it'll be TS already?\nThis move also makes more difficult to contribute for JS developers not interested or not familiar with TS. It narrows the audience.. ",
    "morozRed": "@sindresorhus I would like to work on that\nAlso, don't you want to set TTL and size manually?\nOr maybe for requests which are used often we can automatically increase TTL. btw can anyone assign this issue to me, because I'm already working on it (if it's necessary). ok, so the cache is almost ready but I don't know what to do with resolving localhost type of addresses, please check implementation docs on node dns.lookup/dns.resolve*\nSo my plan was to use dns.resolve4/dns.resolve6, but this methods are not checking etc.hosts, and I'm worried that if someone will set custom hosts there they will not be resolved. Any ideas?. @pietermees default dns.lookup method is not supporting providers ttl which we want to support. \nAlso, we want to support different types of storage (i.e. keyv).\nAbout dns.resolve(), dns.resolve*()\n\nThese functions are implemented quite differently than dns.lookup(). They do not use getaddrinfo(3) and they always perform a DNS query on the network. This network communication is always done asynchronously, and does not use libuv's threadpool.\nAs a result, these functions cannot have the same negative impact on other processing that happens on libuv's threadpool that dns.lookup() can have.\nThey do not use the same set of configuration files than what dns.lookup() uses. For instance, they do not use the configuration from /etc/hosts.\n\nFor more info please refer to this doc.\nAnd there is definitely no point to add another dependency because it's not so much code to do.. @pietermees oh ok, well the idea was to make automatic pre-initialized DNS cache, but still, you already able to do this:\njs\nawait got('google.com', { lookup: CUSTOM_DNS_CACHE.lookup });. ok so @sindresorhus @brandon93s what do you guys think about it? Maybe I can update the docs here at least?\n. @szmarczak you can cache all the addresses and then use round-robin strategy. But I'm not sure now if we do need to implement custom cache if you can simply pass package or custom lookup function to got. . @szmarczak this package supports provided DNS TTL. I've been working on cache for got but then I got stuck because of this discussion.. ",
    "alexandercerutti": "Well, I found a solution that may be good enough even if not perfect:\njavascript\nuris.map((r) => got(resource, { encoding: null }).then(r => r.body));\nThis is good because, on image fetching, a buffer is often needed.\nIs not good because it requires the \"filtering\" of the Promise result through Got promise.. ",
    "michaltk": "Thanks for reviewing! I've updated the docs and added tests.\n\nThere's an error: response.req may be undefined if using cache.\n\nShould I rather put gotOptions onto response instead of response.req since the cached response won't really have the req object?\nLet me know if you want any other changes, thanks!. @sindresorhus @szmarczak any chance of this getting merged soon?. ",
    "muliyul": "I'm also looking forward to that feature.. This didn't work for me. For some reason afterResponse doesn't get called.\nEDIT: I was expecting this to work with streams because it wasn't stated anywhere that it shouldn't. How can I transform a stream response body? I tried\njavascript\ngot.stream(...).pipe(through2((chunk, enc, done) => {...}).pipe(res). Got it to work using this. cheers!\njavascript\nconst B64 = require('b64')\ngot.stream(...).pipe(new B64.Decoder()).pipe(res). @szmarczak I'd like to open a PR for a readme update. What hooks are supported for streams? I know beforeRequest is but that's all I know.. I was experiencing the same issue with bluebird ^3.5.3. @szmarczak not able to reproduce with neither impl. (which is odd because I do remember bumping into this). ",
    "jamesbillinger": "Got is working perfectly in this scenario - I had another package that was lowercasing the url.  Sorry for the mistake, and thanks again for a great library.. Yeah, sorry, I was trying to use \"got\" to load URLs pulled from Twitter's API.  They return shortened \"t.co\" URLs that are case-sensitive.  Initially I was receiving 404 errors because the URLs were being passed as lowercase, and I mistakenly blamed \"got\" for the case changes.  LIke I said, I've since realized that it was a different lib that was responsible, and \"got\" was working perfectly.. ",
    "thomassuckow": "So your change to cacheable-request will change ParseError to a TimeoutError correct?. ",
    "FabricioMatteMassive": "@thomassuckow In this specific test case, yes. However, the PR fixes the root cause of the issue, which was cacheable-request caching responses for requests that timed out and were aborted by Got.\nThis means if a subsequent request succeeds within the time limit, the client will now get a successful response instead of a ParseError.. This is a breaking change:\nThe client can provide a custom retries function and it expects to receive 1 for the iteration argument in the first retry. This breaks the contract, it's a SEMVER-MAJOR change. I'd prefer to keep the old behavior.. Does got support Node.js >= 8 only? I'm not sure if this affects compatibility.. ",
    "tusbar": "Yes there is: https://github.com/sindresorhus/got/releases. ",
    "GHNewbiee": "IMHO, it is reasonable and makes sense the folk who wrote the comparison table to \"pick it up\", too.. I'm afraid that is not so rarely how open source \"wanna-be\" or \"claim-to-be\" members work.\nWhen one decides to create a comparison table with a \"good\" and \"pure\" purpose and publish it then:\n\nFair is to include all major players in the comparison table and not omit one who has 3 times more stars.  If one decides not to include one, then certain serious reasons should be given.\nFair is not a matter of time availability.\nFair does not need a reason to be fair.\nFair is not to look for someone else to do the moral task of the one who has begun the comparison.\nFair is not a matter of up-voting in order one decides to be fair.\nFair is not a suit tailor-made exclusively by one for one.\n\nYou can close the question any time. In fact, it is more easier and painless than trying to be fair!\nDoes that sound fair?. @alextes It does not sound fair to you because it is not convenient to you. Fair is a suit tailor-made by you exclusively for you!\n\nI'm unsure why you're talking about the possibility of closing thinking.\n\nBecause you wrote:\n\nOn the other hand, if no one else is running into this need and you don't care too much about it either, we'll just close this issue.\n\nSo, I do not really care AT ALL! It was just a suggestion! It seems that was an very unfortunate one!\n\nI do hope someone picks it up for your sake pray blush.\n\nReally alextes?! Really alextes?! For my sake??? Hahahahahahaha!!! I have not asked anyone to do that for my sake! I did write\n\n... for the sake of completeness.\n\nnot \"for my sake\". Really alextes?!\n@szmarczak \n\nAlso, there's not enough space in the comparison table\n\nOh, this is the most formidable argument I have ever heard! I shuddered!\n\n... \"I want that, that and that\". \"\n\nI have never wanted that, that and that!!! In fact, I do not want anything from you!!! It is your project. You want to accept my suggestion and improve the documentation, do it. You do not want, then don't do that! Life is beautiful! \n\nThere's no deadline. ... You have to wait....\n\nI have never set such a matter. I have never pressed anyone to do that now or even ever. You could have written, if you wanted, \"maybe sometime in the future or never!\".\n\nYou have to show some interest.\n\nI showed an interest! I contacted you in a very elegant and polite way wondering if SuperAgent should (not even \"could\") be included in the comparison table for the sake of completeness. One more time, you could write, \"Yes\", \"No\", \"maybe sometime in the future\", etc. But I do not accept public lessons of:\na) what sounds fair or not!, and\nb) how $$$ works\nUnless, you expect me to \"oil\", \"grease\" you guys with some $$$ through a donation in order you do my \"sake\" to be \"fair\". Really szmarczak?! Is that you expect??!! Eh, you know very well, in fact you are an expert in, how $$$ works! Right szmarczak?!! Eh, look elsewhere for suckers.\nPS: I am very proud because I am the ONE who has invented the most modern IT verb and its derivatives to describe the brainless behaviour of folks through internet; masturtype.\nSo dear friends, please, stop masturtyping in public!. ",
    "AbhishekMadiraju": "js\nlet beg = 'https://login.microsoftonline.com/organizations/oauth2/v2.0/token'; \nlet reqBody1 = 'client_id=' + client_id + '&scope=offline_access%20user.read%20mail.read' +\n '&code=' + output + '&redirect_uri=' + process.env.WEBAPP_ENDPOINT + '/msteamsauth';\nlet reqBody2 = '&grant_type=authorization_code' + '&client_secret=' + client_secret;\nlet reqBody = reqBody1 + reqBody2;\nconst resp = await got.post(beg, {\n           body: reqBody,\n           headers: {\n                    'content-type': 'application/x-www-form-urlencoded'\n            }\n });\nThat's how I am doing it now. Is it right?. ",
    "casret": "@szmarczak I think you are right, I must've been looking at the connect/upload timings that you mentioned in the thread.  I'll use 1.1.2 and check in production if anything is still off.. ",
    "lounsbrough": "With timeout set to 0, the connections fail almost instantly.. Yes.\nTimeoutError: Timeout awaiting 'request' for 0ms\n    at ClientRequest.request.once.error (E:\\nodejs\\determine-max-available-ship-quantity\\node_modules\\got\\source\\request-as-event-emitter.js:163:14)\n    at Object.onceWrapper (events.js:273:13)\n    at ClientRequest.emit (events.js:187:15)\n    at ClientRequest.origin.emit.args [as emit] (E:\\nodejs\\determine-max-available-ship-quantity\\node_modules\\@szmarczak\\http-timer\\source\\index.js:36:11)\n    at Immediate.timeoutHandler (E:\\nodejs\\determine-max-available-ship-quantity\\node_modules\\got\\source\\utils\\timed-out.js:63:11)\n    at processImmediate (timers.js:634:17). With retries set to 0, it also fails immediately.. I've found a workaround which is to reject the Promise with my own timeout. I'm going to close this issue and if it becomes a problem for me again I'll upload example code of the failure.\nThanks!. ",
    "piuccio": "No I can't because the server doesn't accept utf8, the URL itself if fine as it is because it's in ASCII, browsers and curl can handle it just fine. Try curl https://kw.travel.rakuten.co.jp/keyword/Search.do?f_query=%93%8C%8B%9E%89w you'll get a response, while got throws an exception\nI just want to disable that check in your code that prevents me from sending non utf8 values.\nIf you don't care it's fine I can use the native http module directly, but you dismissed me as if I'm asking something stupid.\nTo avoid extra options maybe that line should be\njs\nif (options.encoding !== nul) {\n   decodeURI(currentUrl);\n}\nso it's only disabled for people that specify their own encoding. ",
    "oknoorap": "@szmarczak \nI'm not running my code in the codesandbox, but also in my local machine too.I just put an example link in order to add a working project example (not just code / screenshot).\nSo, please reopen this issue.. @szmarczak okay i see. thank you.. @rohmanhm thanks dude... ",
    "rohmanhm": "https://github.com/sindresorhus/ky is a good alternative for browsers. ",
    "ferdaber": "This looks like an interesting project- I'd like to help! I can start with at least adding the TypeScript build/test steps.. ",
    "ricardorojass": "Hi everyone, I'd like to help with this project, I'll be going to rewrite source/errors.js in TS. . > > What type I should use in error parameter?\n\nError\n\nDo you refer to the Error interface?  because in the d.ts it does not have those properties.\ne.g body - statusCode etc...\nHelp :confused:. > Hey @ricardorojass just wanted to chime in. I am currently working on #714 which will need these changes at some point.\n\nDo you have any update on whether you still work on fixing this PR? Otherwise I could take a stab at it if you're busy :)\n\nHi @fnky, I'm working on that yet, I have two issues to resolve.\nI hope finished tomorrow.. > @ricardorojass If you want to, you can invite @fnky to your fork so you can work on it together. He's done some awesome work on #714 already :)\n\nI would help you rewriting the code if I could, but since Thursday I've been really sick. Anyway, this is still great work\ud83d\udc4c\n\nThank you @szmarczak, I just pushed some changes.\nGet well soon!. > @ricardorojass I would love to help out with the types! If you'd like you can add me as a contributor to your fork, so that I can push some changes to this PR \ud83d\ude0a\nThanks for that @fnky, I just added as a contributor :). @fnky Thanks for your effort, I appreciate it :clap:. @szmarczak could you confirm how to resolve conflicts. \nI guess I should pull MASTER and merge it into this branch :). Hi @sindresorhus, I need help here, I've been trying to understand how to console log it.\nI created a node js example using the Got library wiht a post request. I readed about ParseError in docs\n\nWhen server response code is 2xx, and parsing body fails. Includes body, statusCode and statusMessage properties.\n\nCould you tell me more detail about it. \nThank you for your patience :confused:. Hey @sindresorhus, I have doubts here, when i put IncomingMessage type to response I got some issues.\nthis.body = response.body;\nProperty 'body' does not exist on type 'IncomingMessage'.\n. @sindresorhus I added a console.log and ran npm test, nothing is logged.\ntypescript\nexport class ParseError extends GotError {\n    statusCode: number;\n    constructor(error: any, statusCode: number, options: any, data: any) {\n                console.log('=======', typeof data);\n        super(`${error.message} in \"${urlLib.format(options)}\"`, error, options);\n        this.name = 'ParseError';\n        this.body = data;\n        this.statusCode = statusCode;\n        this.statusMessage = http.STATUS_CODES[this.statusCode];\n    }\n}\nCould you provide more thoughts :confused:. Thanks a log @fnky. Could you explain how to add Timings interface here?\nif you mean creates one, how should I build the phases type?\n```typescript\ninterface Timings {\n    start: string;\n    socket: string;\n    lookup: string;\n    connect: string;\n    upload: string;\n    response: string;\n    end: string;\n    error: string;\n    phases: Phases;\n}\ninterface Phases { \n    wait: ????;\n    dns: ?????;\n        .......\n}\n```. Thanks @fnky, If you are available, I have this:\n```typescript\nimport http, {IncomingMessage, IncomingHttpHeaders} from 'http';\ninterface IncomingMessageExtended extends IncomingMessage {\n    body: string;\n    statusCode: number;\n}\n...\nconstructor(response: IncomingMessageExtended, options: Options)\n```\nBut I got some linter errors:\n\n. Thank you for teaching me that!. @szmarczak It is outdated, take a look https://github.com/sindresorhus/got/pull/712/files#diff-927aec1d2a3f423e62fb5bb4f954ae03R12. @szmarczak Good catch, I'm going to change it to string.\nCC: @fnky . @szmarczak  I'm going to change it, thanks\ncc: @fnky . Outdated https://github.com/sindresorhus/got/pull/712/files#diff-927aec1d2a3f423e62fb5bb4f954ae03R12. ",
    "michaeldera": "I would love to help rewrite the files in TypeScript, is there a specific file I can go for?. > @michaeldera Pick any .js file you think you can handle and that's not already being worked on in an open PR ;)\n\nFor example: https://github.com/sindresorhus/got/blob/master/source/create.js\n\nNow working on create.js\n. #721 converted create.js to TypeScript. Ran into one issue and could use help with that. I added the details in the PR. Alright. Let me redo the PR. . > \n\nThere's no need to close or open a new PR. You can just push additional commits to this PR ;)\n\nPlease forgive my ignorance... the first commit, where I am supposed to do git mv so it is possible to see the diff, that is the part I cannot get around adding that commit... tried rebasing but not quite getting that bit right. > @michaeldera Ping. Are you finishing this PR? Otherwise, I could work on it :)\nIf it is not too far off I can work on it over the weekend but you could work on it if you would like. . Great! That works! If I am able to do it before I certainly will :). Doing this over now . ",
    "Magellol": "Started to tackle https://github.com/sindresorhus/got/blob/master/source/as-stream.js in https://github.com/sindresorhus/got/pull/720 \ud83d\udc4d . TS build is now passing at this commit https://github.com/sindresorhus/got/pull/720/commits/d6600c7a8903a4772affe25bdc0754c9c203d211\nMy mistake was the intersection type between Defaults and Options. Instead of inferring the type from the actual value, I've created a dedicated type. Let me know if all is good \ud83d\udc4d . Thanks for the feedback. Will make changes as soon as I can.. @sindresorhus I believe I have adressed all requested changes. I will look into https://github.com/sindresorhus/got/pull/720#discussion_r253270974 asap.. @sindresorhus Sounds good. Thanks!\nYeah, it slipped my mind. I haven't seen an issue yet but I just glanced, I'll look more deeply.. This is the piece of code that fails the build. According to the doc retries can be number | () => number.\nTS complains because in defaults we set this value to be 2 but we quickly override it here regardless of its initial value. Once I understand more how this is used, maybe I'll be able to fix the typings.. Weirdly enough, I had to type cast this value, as opposed to simply typing it.\nnew EventEmitter from node#events seems to return a type of internal as opposed to return a EventEmitter. I'm a bit confused, it might be an issue with the node typings?. I'd like to confirm this change makes sense. I'm not super knowledgeable about what the actual code is doing. If someone could clarify this for me.. Like the comment says, I can also create an explicit typing for the defaults value. I use this value as a type directly using typeof operator.\nI just wanted to make sure:\nA) Are you guys okay with this, or would you prefer an explicit Default typing\nB) Am I correct to assume that as-stream receives a merged object from default and passed in options?. My first guess is retry would be a number but I just needed some clarifications.. I've removed the comment and fixed the retry type to be number.\nThe whole type is now (() => number) | number which I believe is accurate now? Let me know if it's not.\nEDIT:\nI've added surrounding () because TS wasn't inferring correctly the union type. . You're right, there is. See https://github.com/sindresorhus/got/pull/720/commits/775684bb9fe153bbf641d8a90993cede216f7c0e for the change.. Done. See 3e88c36 \ud83d\udc4d . ",
    "indiescripter": "fwiw and feel free to disagree but since a lot of people will consume this package in a JS project (meaning I'm just making this assumption)  then tests should probably remain in JS. Consumers calling from JS into TS do not get the benefit of static type safety and accordingly the Got APIs should not make any assumptions about validity of arguments passed in.\nIf the tests are written in TS and say an API function takes a number (and is typed as such) then when one tries to write a test that passes in, say, a string instead of a number then TS will produce a compile error. To work around the difficulty of writing tests to check the robustness of APIs against any arbitrary types of values thrown at them, one ends up doing a lot of any cast gymnastics.. ",
    "tobenna": "I can do source/normalize-arguments.js. ",
    "MorpheusXAUT": "I'm seeing a similar behavior when using Got in our TypeScript project.\nSame as shown above, using const res = await got(\"example.com\"); yields no result, but hangs indefinitely. On the contrary to @hensmith though, calling .then() did return a response as expected, just awaiting the returned promise somehow failed.\nI'm seeing the issues in a project using:\nNode: v8.15.0\nGot: v9.6.0\nTypeScript: v2.9.2\n@types/got: v9.4.0\nbluebird: v3.5.0\nOur TypeScript target is es5 using the commonjs module, similar to the example code provided above. Promises are polyfilled globally using bluebird.. Unfortunately, the rest of the project I've encountered the issue in depends on Bluebird promises, so removing them for the test would not be as trivial :smile:\nI can put together a simple example project like @hensmith did using the rest of the dependencies described during this weekend though, if that'd be helpful!. @hensmith Good to see it at least behaves the same for you :smile: Using .then() and handling the result that way is definitely a workaround that works fine, however given the rest of our code, I'd personally try to avoid it and using await if possible. Furthermore, I'm curious as to why awaiting the promise doesn't work, when it does apparently return just fine as it's thenable...\nI guess the awaiter generated by TypeScript when transpiling down to es5 might be causing some issues? :thinking: \n@szmarczak Thanks for looking into this, appreciated! Let me know if you need any other information or tests from my side!. Alright, I'll try to set up a small sample to reproduce it tomorrow or on Sunday \ud83d\udc4d Will post back here with results.. Sorry, been away all weekend, will try to put something together tonight or tomorrow latest!. @szmarczak I actually didn't manage to set up a standalone repository reproducing the issue we're seeing. I'll have to take another look at our project setup at work tomorrow to try and see what other differences we have.. ",
    "hensmith": "oh wow!!! this prompted me to revisit the .then() approach and you're right! i made the following change to my example code and it fixed the issue! i think when i first tried this, i may have forgotten to return the promise or something!\ndiff\n-  const html = await got('http://example.org')\n-  console.log(html)\n+  return got('http://example.org').then(r => {\n+    console.log(r.body)\n+  })\nim 100% satisfied with this workaround, and i hope it proves helpful for anyone else who shows up here after googling for this issue. thank you so much @MorpheusXAUT and @szmarczak \u2764\ufe0f. ",
    "scttcper": "Thanks for the feedback.\n@szmarczak @sindresorhus what would you like to do about https://nodejs.org/api/all.html#deprecations_dep0066_outgoingmessage_headers_outgoingmessage_headernames\ngetHeaders() returns an object\nts\nconst headersSize = request._header ? Buffer.byteLength(request._header) : 0;\n_header doesn't exist on the typescript definition, possibly because of the deprecation which seems premature.\nhttps://github.com/nodejs/node/blob/c1ac57888199ba13df7eda4912cdb53dcfb5a2ee/lib/_http_outgoing.js#L113-L129\n. ",
    "ltciro": "mmm It seems get-response.js was changed I added the change but it will be in conflict with master I don't know what to do. Let me know if it's better to close PR and open a new one, Thanks.. > @ltciro Better not to force-push when merging conflicts \ud83d\ude03 Use git pull --rebase instead and resolve the conflicts manually if needed.\n\nGot it now, sorry for that \ud83d\ude48 \nNo, we will fix this one. Make new PRs only when GitHub has messed up (it happens quite often) or Git won't let you merge conflicts (e.g. conflicts solved but git says no, you didn't do any changes).\nOhh thank you for the gif so helpful \ud83d\ude4f , and for the fixes, I didn't be able to found where in the code the change to undefined was affected. \n. yes, I found BufferEncoding,  Should I change this to undefined too? https://github.com/sindresorhus/got/blob/51d72433ccf0de0a9d089c484a3753362af9ac02/source/get-response.ts#L26. When I changed this to undefined, test failed \n\n. \n",
    "Cryrivers": "\nThere are also some lint errors: https://travis-ci.org/sindresorhus/got/jobs/482315362\nJust run npx xo --fix locally to fix them.\n\nSorry, my oversight. It has been fixed.. Fixed. ",
    "fnky": "Hey @ricardorojass  just wanted to chime in. I am currently working on #714 which will need these changes at some point.\nDo you have any update on whether you still work on fixing this PR? Otherwise I could take a stab at it if you're busy :). @ricardorojass I would love to help out with the types! If you'd like you can add me as a contributor to your fork, so that I can push some changes to this PR \ud83d\ude0a. Pushed some changes for types of arguments and error types.. Pushed some changes that fixes the tests failing and some types.. I have added some changes and commented on some specific points that I changed. This also fixes the tests.. I have pushed a few changes regarding the review.\n\nMoved the Options interface into utils/types.ts so it can be reused.\nAdded a new CancelableRequest type which extends from PCancelable with additional properties.\nFixed some types that were incorrect.\nAdded documentation for Hooks and its properties.\n\nThere are still some things that are needed to make it closer to what is documented:\nbeforeError error types\nThe error passed to the beforeError hook can be a number of different types of errors with different properties. I initially tried to make an AnyError type that was a union of these different errors, but I'll wait for #712 to be merged so we can discuss any concerns regarding what errors/properties are missing.\nCustom Response interface\nThere are multiple places where it is documented that you can retrieve for example .body from the response. Since IncomingMessage doesn't have this, we'll need to either make our own interface, based on responselike or use responselike's own Response.. I have addressed some of the comments :). The extranous Options interface is meant to be merged with the interface that was introduced in https://github.com/sindresorhus/got/pull/708 into a single shared interface.. XO fails at linting for exported types from known-hook-events.ts.. This one is quirky and probably not the best way to do it.\nI have tried multiple ways to reflect that we know that it's going to be populated later, in the loop underneath but we don't want to give it the values upfront.. I'm not too sure about all the usages of as casting to force TypeScript to make the types compatible down the chain.. Perhaps these types should be exported from another file to make them available across the codebase as well as the end-user API, if necessary.. I hope you understand the rationale here, even though it does look quite cumbersome.. There are types available through @types/pcancable but I didn't know where to go regarding this, as I noticed that @sindresorhus explained that he'd like to move the types into their respective modules.\nThis retry callback also returns an extended version of the PCancelable promise with helper methods such as json(), text(), etc.. I wasn\u2019t sure we wanted to do this across the project, but it makes it less confusing for future contributors.. This was on oversight on my part. I think I used this to check if you could document each property, and I think you can. I\u2019ll suggest we do it on the properties as well as the types, since both can be consumed by different means.. Sorry I got it confused with on the type of Hooks vs. the properties that takes the list of hooks.\nI tried to add the documentation at the type level, but TypeScript/VSCode apparently can't show the documentation for a documented type when typing in an array.\n\nI think it makes sense to add them to both in that case so they work independently of how they are used. Although that means that it needs to be kept up to date for both.. This was mostly due to IncomingMessage also used string for method, so I wanted to be consistent in that regard.\nBut seen as it gives more type information, I'll add it back.. What do you think to allow lowercase too, for example:\nts\ntype Method = 'GET' | 'PUT' | 'HEAD' ... | 'get' | 'put' | 'head' .... I think the issue with using the README is that you quickly end up with out of date documentation.\nFor example in the documentation for beforeError hook, the example uses onError as the property name\u2014this could be a typo or a change that didn't get updated, but nevertheless it makes it more difficult.\nIf we redocument everything, we can later generate the documentation.. We could, but this then requires TypeScript users to import it every time the need to update method. Do you think that would be too cumbersome for this?. Added explicit return type for merged function.. So the consensus is to add the same documentation for both types and the properties in Hooks?. I have tried that and also with as Hooks.\nts\nhooks[hook] = hooks[hook].concat(source.hooks[hook] || []);\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n                         [ts] Cannot invoke an expression whose type lacks a call signature.\n                         Type '{ (...items: ConcatArray<InitHook>[]): InitHook[]; (...items: (InitHook | ConcatArray<InitHook>)[]): InitHook[]; } | { (...items: ConcatArray<BeforeRequestHook>[]): BeforeRequestHook[]; (...items: (BeforeRequestHook | ConcatArray<...>)[]): BeforeRequestHook[]; } | { ...; } | { ...; } | { ...; } | { ...; }'\n                         has no compatible call signatures. [2349]\nSeen as this line is temporary, I don't think its much of an issue just an annoyance.. We need to extend from IncomingMessage or use responselike's Response type.. I think this should be URL[].\nSee got.MaxRedirectsError. This should be IncomingHttpHeaders from http module.. We should avoid making properties optional in error types, as they should always be available.\nSee the documentation about Errors to see which errors has which properties.. - error should be of type Error.\n- data should be type of string | Buffer. See get-stream.\n- options should be of type Options.. error argument should be of type Error for all error types that accepts it.. redirectUrls should be URL[].. timings argument should be an object according to http-timer.\nWe could add a Timings interface in this project temporarily.. I think something like this is sufficient:\nts\ninterface Timings {\n    start: number;\n    socket: number;\n    lookup: number;\n    connect: number;\n    upload: number;\n    response: number;\n    end: number;\n    error: number;\n    phases: { \n        wait: number;\n        dns: number;\n        tcp: number;\n        request: number;\n        firstByte: number;\n        download: number;\n        total: number;\n    };\n}. This is used to solve type errors for these cases:\n\nAn Error object is passed, which doesn't contain a code property.\nAn Error object is passed, which contains a code property. \u2014 See test/retry.js:165\nAn object is passed which doesn't contain a code property.\nAn object is passed which contains a code property. \u2014 See source/errors.js:102\n\nI think it would make sense to have some consistency. Perhaps rewrite it so that only Error | undefined can be passed. I don't know how people may use error types publicly, so this could be a breaking change.. I changed the type of this to better reflect that the merge can take an object of any arbitrary values.. This is needed since we don't have a temporary variable that stores the merged objects, but reuse the target passed in.. This type assertion is needed because is.plainObject returns a boolean and can't be used as a type guard to check if it is an object or an object literal.. The host property in Options is required but the mergeOptions can technically merge parts of the options.. I don't know if it is correct instances only contains parts of options or it contains all options.. Since the options argument is also required, we would need to do Error | undefined since we can't do code?: Error, options: Options.. In mergeInstances it sets the methods to what was passed to mergeInstances(..., methods).. Yeah I think that should work :). ",
    "iyobo": "As gotten From the error, simply await got('http://localhost:5984') or maybe even await got('localhost:5984') will throw this error, with this cryptic stack, if that url doesn't exist.\nThe issue is the cryptic stack. It shows a detachment from the execution stack.\nWhen errors like these happen, got should be throwing an Error up the execution stack so it's location is better deduced...\nThe issue isn't with external error handling, but got's internal error handling that isn't bubbling the error up properly. \nFrom looking at the code, I'd suggest essentially wrapping the whole call inside a promise like\nnew Promise( (resolve, reject)=>{\n   ...\n    req.once('error', err => {\n            ...\n                     reject( new got.RequestError(err, opts))\n        });\n   ...\n});\nor figure out a way to bubble it up properly within the context of promises.\nIt's basically an internally Unhandled Promise Error. ",
    "krishna01012002": "its working as expected , thank you. ",
    "markdboyd": "@szmarczak Would that be defaulting port to null in this object? If so, I'm happy to make a PR. > Nope. Maybe? IDK.\n\ngot/source/request-as-event-emitter.js\nLines 139 to 142 in 6ae3b34\nconst redirectOptions = { \n  ...options, \n  ...urlToOptions(redirectURL) \n }; \nI think It should be:\njs\n                      const redirectOptions = {\n                          ...options,\n                          port: null,\n                          ...urlToOptions(redirectURL)\n                      };\n\nThis would certainly fix my issue. The only reason I could see handling it inside urlToOptions would be if there are other cases where the code is merging request options and you want to ensure port will always get overwritten. But it seems like this operation only happens when handling redirects.. ",
    "rustlemills": "raised on wrong repository. ",
    "fider": "\nThe only library I know, that supports it by default is axios.\nIt have two options regarding xsrf:\nxsrfCookieName with default value 'XSRF-TOKEN'\nxsrfHeaderName with default value 'X-XSRF-TOKEN'\n\nCurrently in pre request hook I am reading cookies from cookieJar and if xsrf-token cookie is present then setting x-xsrf-token header.\n\n\nIt will be even better to enable it by default (but with option do disable it)\n\n\nHere you have short article of \"why\" to use xsrf protection https://stormpath.com/blog/angular-xsrf\n\n\nIf you have no time I contribute, it seemt that it is not so complicated.\nJust add something like below into pre request function:\n```javascript\nimport { parse } from 'cookie';\n// ...\nlet xsrfCookieName = 'XSRF-TOKEN'; // default value\nlet xsrfHeaderName = 'X-XSRF-TOKEN'; // default value\n// ...\nlet cookies = parse( cookieJar.getCookieString( host );\nxsrfToken = cookies[xsrfCookieName];\nif (xsrfToken) {\n  req.headers[xsrfHeaderName] = xsrfToken;\n}\n```. ",
    "kevcenteno": "@sindresorhus Force pushed the changes. ",
    "capaj": "@szmarczak that's not really true-see: https://github.com/ForbesLindesay/sync-request\nalso I am aware of async/await. I write async functions every day. But I also came across a usecase where I need to fetch something synchronously.\nI would be okay if you told me that it is out of scope of this project. Instead you first assume I don't know promises, then you assume it can't be done. Wrong on both accounts.\nI will assume it is out of scope for got and maybe if I have some spare time I'll wrap it in https://github.com/ForbesLindesay/sync-rpc myself and publish it as got-synchronous or something.. ",
    "juhovh": "Thank you for the quick response, I will go with the underscore prefix.. ",
    "atombrenner": "I'm also not a Webpack fan, but you can configure webpack to ignore certain requires (e.g. 'electron') like this: webpack.config.js l\njs\nmodule.exports = {\n  externals: ['zlib', 'electron']\n}\nIf you used the standard require('electron') instead of tricking webpack, users would be able to configure webpack to make the warning go away. . ",
    "gonejack": "@szmarczak It could happens in possibility, especially in bad network connection and larger file: https://runkit.com/gonejack/5c85aa5cc72b580012f83021\n\n. And retries would not work with stream API which documentation should state it.. ",
    "kairusds": "how so? i tried doing any workarounds i can think of but it won't install. it says Cannot find module \"got\" and the rest are thrown  exceptions by module.js. ",
    "kalitine": "After a further investigation, I found that it was my fault. I was importing got like this:\nimport { get } from 'got'\nSo no surprising that I was doing a GET request. Sorry for the issue, I thought that I paied attention to everything.. ",
    "lostpebble": "So, it appears that this issue might be outside of the control of got.\nI had to increase the timeout for my entire Node.js server here: https://nodejs.org/api/http.html#http_server_settimeout_msecs_callback\nAnd now I can run the request for as long as that allows.. But this has now lead me to another problem after running some more tests. When I deliberately set a timeout, the requests are still retrying even though I've set retries: 0.\nHere I've set timeout: 1000 on the POST request:\nconst response = await got(blueprint.endpoint, {\n        method: \"POST\",\n        retries: 0,\n        timeout: 1000,\n        body: payload,\n        headers: {\n          \"Content-Type\": blueprint.payloadType === ECronJobPayloadType.TEXT ? \"text/plain\" : \"application/json\",\n        }\n      });\nAnd this is what the receiving server logs look like now (3 requests received before it decided to stop retrying):\n16:38:55.195 index.js:52   <-- POST /_api/test/cron-slow\n16:38:55.197 ApiTestRouter.ts:19 [t4atGMyKA7BLWIZyLP5_K] Running really slow endpoint test (120 seconds)\n16:38:57.214 index.js:52   <-- POST /_api/test/cron-slow\n16:38:57.216 ApiTestRouter.ts:19 [nkuXOlQ-JIHUs9xmWdQuM] Running really slow endpoint test (120 seconds)\n16:39:00.250 index.js:52   <-- POST /_api/test/cron-slow\n16:39:00.252 ApiTestRouter.ts:19 [g6R4PD-0e9E3SBfN42zvL] Running really slow endpoint test (120 seconds). Okay, I think I've managed to solve the retry issue now. I was using retries because I saw it somewhere in an issue before and TypeScript complains if I try use retry as an option. BUT it seems that the correct option is retry, like so:\ntypescript\nconst response = await got(blueprint.endpoint, {\n        method: \"POST\",\n        // @ts-ignore\n        retry: 0,\n        timeout: blueprint.endpointTimeout || TimeUtils.CalculateMillis.minutesInMillis(2),\n        body: payload,\n        headers: {\n          \"Content-Type\": blueprint.payloadType === ECronJobPayloadType.TEXT ? \"text/plain\" : \"application/json\",\n        }\n      });. It was definitely re-retrying - although it seems like it was Node.js itself forcing the retry because of the default server settings (120 seconds timeout). All in all doesn't seem like the problem is on got's side for the original retry problem as its working fine now after upping the server's timeout settings. It might be useful to have some information about this in the docs though.. @szmarczak I'll close this issue as it appears to be resolved on my side. I do think that there should be mention in the docs that Node.js has a default timeout of 120 seconds which you need to increase to prevent timeouts as well.. ",
    "joh-klein": "Thanks for your quick reply! \nIf I add the hook, I am at the place, where err.code === 'HPE_INVALID_CONSTANT' but I don't have access to the data that was transmitted until then \u2013 or do I? And if so, where/how? . I guess, what I am asking is: is there something similar to this construct from node.http(s)?\njs\nres.on('data', chunk => {\n  body += chunk;\n});\nEDIT: I just found it in the issues, that it works pretty much the same here \u2013 since I am really not well versed in streams I assumed it couldn't if it wasn't in the readme.. To answer my own question, this does the same as my initial way with https().\n```js\nreturn new Promise((resolve, reject) => {\n  let body = '';\ngot\n    .stream(url)\n    .on('data', chunk => {\n      body += chunk;\n    })\n    .on('end', () => {\n      return resolve(body);\n    })\n    .on('error', err => {\n      if (body && err.code === 'HPE_INVALID_CONSTANT') {\n        return resolve(body);\n      } else {\n        console.log('Got error: ' + err.message);\n        reject(err);\n      }\n    });\n});\n```\nMaybe add http/https to your migration guide?. ",
    "mpfeil": "@szmarczak I can work on some more tests in the next days. ",
    "freenerd": "Thanks @szmarczak. I did read the documentation (as well as the retry test suite and the retry code) but just missed POST missing from the allowed methods in the default.\nI still can't explain why POST retries on errorCodes: [ undefined ] though, but I guess it doesn't matter much.\nFor everyone else landing here, explicitly allowing POST to be retried is the solution.\nconst resp = await got('http://localhost:3000/', {\n        method: 'POST',\n        retry: {\n            methods: ['POST'],\n            retries: 3\n        }\n    });. ",
    "km256": "you mean\nif (json) {\n   opts.headers.accept = opts.headers.accept || json && 'application/json';\n}\n?\n. Of course.... sorry, it's accident\n. ",
    "Nodge": "@floatdrop fixed. "
}